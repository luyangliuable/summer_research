/*

 * Copyright (c) 2005 Voltaire Inc.  All rights reserved.

 * Copyright (c) 2002-2005, Network Appliance, Inc. All rights reserved.

 * Copyright (c) 1999-2005, Mellanox Technologies, Inc. All rights reserved.

 * Copyright (c) 2005 Intel Corporation.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Consider gid attr in resolve phase */

 We set the DGID part, the rest was set earlier */

 Construct the family header first */

 Repair the nlmsg header length */

	/* Make the request retry, so when we get the response from userspace

	 * we will have something.

/**

 * rdma_copy_src_l2_addr - Copy netdevice source addresses

 * @dev_addr:	Destination address pointer where to copy the addresses

 * @dev:	Netdevice whose source addresses to copy

 *

 * rdma_copy_src_l2_addr() copies source addresses from the specified netdevice.

 * This includes unicast address, broadcast address, device type and

 * interface index.

 If we have a gateway in IB mode then it must be an IB network */

 If the device doesn't do ARP internally */

	/*

	 * If there's a gateway and type of device not ARPHRD_INFINIBAND,

	 * we're definitely in RoCE v2 (as RoCE v1 isn't routable) set the

	 * network type accordingly.

 A physical device must be the RDMA device to use */

		/*

		 * RDMA (IB/RoCE, iWarp) doesn't run on lo interface or

		 * loopback IP address. So if route is resolved to loopback

		 * interface, translate that to a real ndev based on non

		 * loopback IP address.

	/*

	 * Since we are holding the rcu, reading net and ifindex

	 * are safe without any additional reference; because

	 * change_net_namespace() in net/core/dev.c does rcu sync

	 * after it changes the state to IFF_DOWN and before

	 * updating netdev fields {net, ifindex}.

		/*

		 * If the request is for a specific gid attribute of the

		 * rdma_dev_addr, derive net from the netdevice of the

		 * GID attribute.

	/*

	 * Resolve neighbor destination address if requested and

	 * only if src addr translation didn't fail.

	/*

	 * Clear the addr net to go back to its original state, only if it was

	 * derived from GID attribute in this context.

 requeue the work for retrying again */

	/*

	 * Although the work will normally have been canceled by the workqueue,

	 * it can still be requeued as long as it is on the req_list.

/**

 * rdma_addr_cancel - Cancel resolve ip request

 * @addr:	Pointer to address structure given previously

 *		during rdma_resolve_ip().

 * rdma_addr_cancel() is synchronous function which cancels any pending

 * request if there is any.

			/*

			 * Removing from the list means we take ownership of

			 * the req

	/*

	 * sync canceling the work after removing it from the req_list

	 * guarentees no work is running and none will be started.

/*

 * Copyright (c) 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005, 2006 Cisco Systems.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2005 Voltaire, Inc. All rights reserved.

 * Copyright (c) 2005 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Must be called with the ufile->device->disassociate_srcu held, and the lock

 * must be held until use of the ucontext is finished.

	/*

	 * We do not hold the hw_destroy_rwsem lock for this flow, instead

	 * srcu is used. It does not matter if someone races this with

	 * get_context, we get NULL or valid ucontext.

 If device was disassociated and no event exists set an error */

 for XRC target qp's, check that qp is live */

 The first async_event_file becomes the default one for the file. */

 Pairs with the put in ib_uverbs_release_file */

 not extended command */

		/*

		 * rdma-core v18 and v19 have a bug where they send DESTROY_CQ

		 * with a 16 byte write instead of 24. Old kernels didn't

		 * check the size so they allowed this. Now that the size is

		 * checked provide a compatibility work around to not break

		 * those userspaces.

 only valid if bundle has uobject */

			/*

			 * The macros check that if has_resp is set

			 * then the command request structure starts

			 * with a '__aligned u64 response' member.

/*

 * The VMA has been dup'd, initialize the vm_private_data with a new tracking

 * struct

 We are racing with disassociation */

	/*

	 * Disassociation already completed, the VMA should already be zapped.

	/*

	 * We can't allow the VMA to be created with the actual IO pages, that

	 * would break our API contract, and it can't be stopped at this

	 * point, so zap it.

	/*

	 * The vma holds a reference on the struct file that created it, which

	 * in turn means that the ib_uverbs_file is guaranteed to exist at

	 * this point.

/*

 * Once the zap_vma_ptes has been called touches to the VMA will come here and

 * we return a dummy writable zero page for all the pfns.

 Read only pages can just use the system zero page. */

		/*

		 * This VMA is forced to always be shared so this doesn't have

		 * to worry about COW.

 Get an arbitrary mm pointer that hasn't been cleaned yet */

		/*

		 * The umap_lock is nested under mmap_lock since it used within

		 * the vma_ops callbacks, so we have to clean the list one mm

		 * at a time to get the lock ordering right. Typically there

		 * will only be one mm, so no big deal.

/*

 * ib_uverbs_open() does not need the BKL:

 *

 *  - the ib_uverbs_device structures are properly reference counted and

 *    everything else is purely local to the file being created, so

 *    races against other open calls are not a problem;

 *  - there is no ioctl method to race against;

 *  - the open method will either immediately run -ENXIO, or all

 *    required initialization will be done.

	/* In case IB device supports disassociate ucontext, there is no hard

	 * dependency between uverbs device and its low level device.

	/*

	 * To support DRIVER_ID binding in userspace some of the driver need

	 * upgrading to expose their PCI dependent revision information

	 * through get_context instead of relying on modalias matching. When

	 * the drivers are fixed they can drop this flag.

 Pending running commands to terminate */

		/* We must release the mutex before going ahead and calling

		 * uverbs_cleanup_ufile, as it might end up indirectly calling

		 * uverbs_close, for example due to freeing the resources (e.g

		 * mmput).

		/* We disassociate HW resources and immediately return.

		 * Userspace will see a EIO errno for all future access.

		 * Upon returning, ib_device may be freed internally and is not

		 * valid any more.

		 * uverbs_device is still available until all clients close

		 * their files, then the uverbs device ref count will be zero

		 * and its resources will be freed.

		 * Note: At this point no more files can be opened since the

		 * cdev was deleted, however active clients can still issue

		 * commands and close their open files.

/*

 * Copyright (c) 2004, 2005 Intel Corporation.  All rights reserved.

 * Copyright (c) 2004 Topspin Corporation.  All rights reserved.

 * Copyright (c) 2004, 2005 Voltaire Corporation.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 * Copyright (c) 2005 Open Grid Computing, Inc. All rights reserved.

 * Copyright (c) 2005 Network Appliance, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 iWARP uses negative errnos */

/*

 * The following services provide a mechanism for pre-allocating iwcm_work

 * elements.  The design pre-allocates them  based on the cm_id type:

 *	LISTENING IDS: 	Get enough elements preallocated to handle the

 *			listen backlog.

 *	ACTIVE IDS:	4: CONNECT_REPLY, ESTABLISHED, DISCONNECT, CLOSE

 *	PASSIVE IDS:	3: ESTABLISHED, DISCONNECT, CLOSE

 *

 * Allocating them in connect and listen avoids having to deal

 * with allocation failures on the event upcall from the provider (which

 * is called in the interrupt context).

 *

 * One exception is when creating the cm_id for incoming connection requests.

 * There are two cases:

 * 1) in the event upcall, cm_event_handler(), for a listening cm_id.  If

 *    the backlog is exceeded, then no more connection request events will

 *    be processed.  cm_event_handler() returns -ENOMEM in this case.  Its up

 *    to the provider to reject the connection request.

 * 2) in the connection request workqueue handler, cm_conn_req_handler().

 *    If work elements cannot be allocated for the new connect request cm_id,

 *    then IWCM will call the provider reject method.  This is ok since

 *    cm_conn_req_handler() runs in the workqueue thread context.

/*

 * Save private data from incoming connection requests to

 * iw_cm_event, so the low level driver doesn't have to. Adjust

 * the event ptr to point to the local copy.

/*

 * Release a reference on cm_id. If the last reference is being

 * released, free the cm_id and return 1.

/*

 * This is really the RDMAC CLOSING state. It is most similar to the

 * IB SQD QP state.

/*

 * CM_ID <-- CLOSING

 *

 * Block if a passive or active connection is currently being processed. Then

 * process the event as follows:

 * - If we are ESTABLISHED, move to CLOSING and modify the QP state

 *   based on the abrupt flag

 * - If the connection is already in the CLOSING or IDLE state, the peer is

 *   disconnecting concurrently with us and we've already seen the

 *   DISCONNECT event -- ignore the request and return 0

 * - Disconnect on a listening endpoint returns -EINVAL

 Wait if we're currently in a connect or accept downcall */

 QP could be <nul> for user-mode client */

 remote peer closed first */

 accept or connect returned !0 */

		/*

		 * App called disconnect before/without calling accept after

		 * connect_request event delivered.

 Can only get here if wait above fails */

		/*

		 * If both sides are disconnecting the QP could

		 * already be in ERR or SQD states

/*

 * CM_ID <-- DESTROYING

 *

 * Clean up all resources associated with the connection and release

 * the initial reference taken by iw_create_cm_id.

	/*

	 * Wait if we're currently in a connect or accept downcall. A

	 * listening endpoint should never block here.

	/*

	 * Since we're deleting the cm_id, drop any events that

	 * might arrive before the last dereference.

 destroy the listening endpoint */

 Abrupt close of the connection */

		/*

		 * App called destroy before/without calling accept after

		 * receiving connection request event notification or

		 * returned non zero from the event callback function.

		 * In either case, must tell the provider to reject.

/*

 * This function is only called by the application thread and cannot

 * be called by the event thread. The function will wait for all

 * references to be released on the cm_id and then kfree the cm_id

 * object.

/**

 * iw_cm_check_wildcard - If IP address is 0 then use original

 * @pm_addr: sockaddr containing the ip to check for wildcard

 * @cm_addr: sockaddr containing the actual IP address

 * @cm_outaddr: sockaddr to set IP addr which leaving port

 *

 *  Checks the pm_addr for wildcard and then sets cm_outaddr's

 *  IP to the actual (cm_addr).

/**

 * iw_cm_map - Use portmapper to map the ports

 * @cm_id: connection manager pointer

 * @active: Indicates the active side when true

 * returns nonzero for error only if iwpm_create_mapinfo() fails

 *

 * Tries to add a mapping for a port using the Portmapper. If

 * successful in mapping the IP/Port it will check the remote

 * mapped IP address for a wildcard IP address and replace the

 * zero IP address with the remote_addr.

/*

 * CM_ID <-- LISTEN

 *

 * Start listening for connect requests. Generates one CONNECT_REQUEST

 * event for each inbound connect request.

/*

 * CM_ID <-- IDLE

 *

 * Rejects an inbound connection request. No events are generated.

/*

 * CM_ID <-- ESTABLISHED

 *

 * Accepts an inbound connection request and generates an ESTABLISHED

 * event. Callers of iw_cm_disconnect and iw_destroy_cm_id will block

 * until the ESTABLISHED event is received from the provider.

 Get the ib_qp given the QPN */

 An error on accept precludes provider events */

/*

 * Active Side: CM_ID <-- CONN_SENT

 *

 * If successful, results in the generation of a CONNECT_REPLY

 * event. iw_cm_disconnect and iw_cm_destroy will block until the

 * CONNECT_REPLY event is received from the provider.

 Get the ib_qp given the QPN */

 success */

/*

 * Passive Side: new CM_ID <-- CONN_RECV

 *

 * Handles an inbound connect request. The function creates a new

 * iw_cm_id to represent the new connection and inherits the client

 * callback function and other attributes from the listening parent.

 *

 * The work item contains a pointer to the listen_cm_id and the event. The

 * listen_cm_id contains the client cm_handler, context and

 * device. These are copied when the device is cloned. The event

 * contains the new four tuple.

 *

 * An error on the child should not affect the parent, so this

 * function does not return a value.

	/*

	 * The provider should never generate a connection request

	 * event with a bad status.

 If the cm_id could not be created, ignore the request */

	/*

	 * We could be destroying the listening id. If so, ignore this

	 * upcall.

 Call the client CM handler */

/*

 * Passive Side: CM_ID <-- ESTABLISHED

 *

 * The provider generated an ESTABLISHED event which means that

 * the MPA negotion has completed successfully and we are now in MPA

 * FPDU mode.

 *

 * This event can only be received in the CONN_RECV state. If the

 * remote peer closed, the ESTABLISHED event would be received followed

 * by the CLOSE event. If the app closes, it will block until we wake

 * it up after processing this event.

	/*

	 * We clear the CONNECT_WAIT bit here to allow the callback

	 * function to call iw_cm_disconnect. Calling iw_destroy_cm_id

	 * from a callback handler is not allowed.

/*

 * Active Side: CM_ID <-- ESTABLISHED

 *

 * The app has called connect and is waiting for the established event to

 * post it's requests to the server. This event will wake up anyone

 * blocked in iw_cm_disconnect or iw_destroy_id.

	/*

	 * Clear the connect wait bit so a callback function calling

	 * iw_cm_disconnect will not wait and deadlock this thread

 REJECTED or RESET */

 Wake up waiters on connect complete */

/*

 * CM_ID <-- CLOSING

 *

 * If in the ESTABLISHED state, move to CLOSING.

/*

 * CM_ID <-- IDLE

 *

 * If in the ESTBLISHED or CLOSING states, the QP will have have been

 * moved by the provider to the ERR state. Disassociate the CM_ID from

 * the QP,  move to IDLE, and remove the 'connected' reference.

 *

 * If in some other state, the cm_id was destroyed asynchronously.

 * This is the last reference that will result in waking up

 * the app thread blocked in iw_destroy_cm_id.

/*

 * Process events on the work_list for the cm_id. If the callback

 * function requests that the cm_id be deleted, a flag is set in the

 * cm_id flags to indicate that when the last reference is

 * removed, the cm_id is to be destroyed. This is necessary to

 * distinguish between an object that will be destroyed by the app

 * thread asleep on the destroy_comp list vs. an object destroyed

 * here synchronously when the last reference is removed.

/*

 * This function is called on interrupt context. Schedule events on

 * the iwcm_wq thread to allow callback functions to downcall into

 * the CM and/or block.  Events are queued to a per-CM_ID

 * work_list. If this is the first event on the work_list, the work

 * element is also queued on the iwcm_wq thread.

 *

 * Each event holds a reference on the cm_id. Until the last posted

 * event has been delivered and processed, the cm_id cannot be

 * deleted.

 *

 * Returns:

 * 	      0	- the event was handled.

 *	-ENOMEM	- the event was not handled due to lack of resources.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Each of the three rwsem locks (devices, clients, client_data) protects the

 * xarray of the same name. Specifically it allows the caller to assert that

 * the MARK will/will not be changing under the lock, and for devices and

 * clients, that the value in the xarray is still a valid pointer. Change of

 * the MARK is linked to the object state, so holding the lock and testing the

 * MARK also asserts that the contained object is in a certain state.

 *

 * This is used to build a two stage register/unregister flow where objects

 * can continue to be in the xarray even though they are still in progress to

 * register/unregister.

 *

 * The xarray itself provides additional locking, and restartable iteration,

 * which is also relied on.

 *

 * Locks should not be nested, with the exception of client_data, which is

 * allowed to nest under the read side of the other two locks.

 *

 * The devices_rwsem also protects the device name list, any change or

 * assignment of device name must also hold the write side to guarantee unique

 * names.

/*

 * devices contains devices that have had their names assigned. The

 * devices may not be registered. Users that care about the registration

 * status need to call ib_device_try_get() on the device to ensure it is

 * registered, and keep it registered, for the required duration.

 *

/*

 * If client_data is registered then the corresponding client must also still

 * be registered.

/*

 * A list of net namespaces is maintained in an xarray. This is necessary

 * because we can't get the locking right using the existing net ns list. We

 * would require a init_net callback after the list is updated.

/*

 * rwsem to protect accessing the rdma_nets xarray entries.

/**

 * rdma_dev_access_netns() - Return whether an rdma device can be accessed

 *			     from a specified net namespace or not.

 * @dev:	Pointer to rdma device which needs to be checked

 * @net:	Pointer to net namesapce for which access to be checked

 *

 * When the rdma device is in shared mode, it ignores the net namespace.

 * When the rdma device is exclusive to a net namespace, rdma device net

 * namespace is checked against the specified one.

/*

 * xarray has this behavior where it won't iterate over NULL values stored in

 * allocated arrays.  So we need our own iterator to see all values stored in

 * the array. This does the same thing as xa_for_each except that it also

 * returns NULL valued entries if the array is allocating. Simplified to only

 * work on simple xarrays.

 RCU hash table mapping netdevice pointers to struct ib_port_data */

 Pointer to the RCU head at the start of the ib_port_data array */

/*

 * Caller must perform ib_device_put() to return the device reference count

 * when ib_device_get_by_index() returns valid device pointer.

/**

 * ib_device_put - Release IB device reference

 * @device: device whose reference to be released

 *

 * ib_device_put() releases reference to the IB device to allow it to be

 * unregistered and eventually free.

/**

 * ib_device_get_by_name - Find an IB device by name

 * @name: The name to look for

 * @driver_id: The driver ID that must match (RDMA_DRIVER_UNKNOWN matches all)

 *

 * Find and hold an ib_device by its name. The caller must call

 * ib_device_put() on the returned pointer.

	/*

	 * It would be nice to pass the node GUID with the event...

	/* This BUILD_BUG_ON is intended to catch layout change

	 * of union of ib_core_device and device.

	 * dev must be the first element as ib_core and providers

	 * driver uses it. Adding anything in ib_core_device before

	 * device will break this assumption.

/**

 * _ib_alloc_device - allocate an IB device struct

 * @size:size of structure to allocate

 *

 * Low-level drivers should use ib_alloc_device() to allocate &struct

 * ib_device.  @size is the size of the structure to be allocated,

 * including any private data used by the low-level driver.

 * ib_dealloc_device() must be used to free structures allocated with

 * ib_alloc_device().

	/*

	 * client_data needs to be alloc because we don't want our mark to be

	 * destroyed if the user stores NULL in the client data.

/**

 * ib_dealloc_device - free an IB device struct

 * @device:structure to free

 *

 * Free a structure allocated with ib_alloc_device().

	/*

	 * ib_unregister_driver() requires all devices to remain in the xarray

	 * while their ops are callable. The last op we call is dealloc_driver

	 * above.  This is needed to create a fence on op callbacks prior to

	 * allowing the driver module to unload.

 Expedite releasing netdev references */

 Balances with device_initialize */

/*

 * add_client_context() and remove_client_context() must be safe against

 * parallel calls on the same device - registration/unregistration of both the

 * device and client can be occurring in parallel.

 *

 * The routines need to be a fence, any caller must not return until the add

 * or remove is fully completed.

	/*

	 * So long as the client is registered hold both the client and device

	 * unregistration locks.

	/*

	 * Another caller to add_client_context got here first and has already

	 * completely initialized context.

			/*

			 * If a client fails to add then the error code is

			 * ignored, but we won't call any more ops on this

			 * client.

 Readers shall not see a client until add has been completed */

	/*

	 * Notice we cannot be holding any exclusive locks when calling the

	 * remove callback as the remove callback can recurse back into any

	 * public functions in this module and thus try for any locks those

	 * functions take.

	 *

	 * For this reason clients and drivers should not call the

	 * unregistration functions will holdling any locks.

 This can only be called once the physical port range is defined */

 Reserve U32_MAX so the logic to go over all the ports is sane */

	/*

	 * device->port_data is indexed directly by the port number to make

	 * access to this data as efficient as possible.

	 *

	 * Therefore port_data is declared as a 1 based array with potential

	 * empty slots at the beginning.

	/*

	 * The rcu_head is put in front of the port data array and the stored

	 * pointer is adjusted since we never need to see that member until

	 * kfree_rcu.

/**

 * ib_port_immutable_read() - Read rdma port's immutable data

 * @dev: IB device

 * @port: port number whose immutable data to read. It starts with index 1 and

 *        valid upto including rdma_end_port().

	/*

	 * Create and add compat device in all namespaces other than where it

	 * is currently bound to.

	/*

	 * The first of init_net() or ib_register_device() to take the

	 * compat_devs_mutex wins and gets to add the device. Others will wait

	 * for completion here.

		/* Hold nets_rwsem so that any other thread modifying this

		 * system param can sync with this thread.

		/* Hold nets_rwsem so that any other thread modifying this

		 * system param can sync with this thread.

	/* enable/disable of compat devices is not supported

	 * when more than default init_net exists.

	/*

	 * Prevent the ID from being re-used and hide the id from xa_for_each.

		/*

		 * Release the devices_rwsem so that pontentially blocking

		 * device_del, doesn't hold the devices_rwsem for too long.

		/*

		 * If the real device is in the NS then move it back to init.

 No need to create any compat devices in default init_net. */

		/* Hold nets_rwsem so that netlink command cannot change

		 * system configuration for device sharing mode.

/*

 * Assign the unique string device name and the unique device index. This is

 * undone by ib_dealloc_device.

 Assign a unique name to the device */

/*

 * setup_device() allocates memory and sets up data that requires calling the

 * device ops, this is the only reason these actions are not done during

 * ib_alloc_device. It is undone by ib_dealloc_device().

	/*

	 * Remove clients in LIFO order, see assign_client_id. This could be

	 * more efficient if xarray learns to reverse iterate. Since no new

	 * clients can be added to this ib_device past this point we only need

	 * the maximum possible client_id value here.

 Pairs with refcount_set in enable_device */

	/*

	 * compat devices must be removed after device refcount drops to zero.

	 * Otherwise init_net() may add more compatdevs after removing compat

	 * devices and before device is disabled.

/*

 * An enabled device is visible to all clients and to all the public facing

 * APIs that return a device pointer. This always returns with a new get, even

 * if it fails.

	/*

	 * One ref belongs to the xa and the other belongs to this

	 * thread. This is needed to guard against parallel unregistration.

	/*

	 * By using downgrade_write() we ensure that no other thread can clear

	 * DEVICE_REGISTERED while we are completing the client setup.

/**

 * ib_register_device - Register an IB device with IB core

 * @device: Device to register

 * @name: unique string device name. This may include a '%' which will

 * 	  cause a unique index to be added to the passed device name.

 * @dma_device: pointer to a DMA-capable device. If %NULL, then the IB

 *	        device will be used. In this case the caller should fully

 *		setup the ibdev for DMA. This usually means using dma_virt_ops.

 *

 * Low-level drivers use ib_register_device() to register their

 * devices with the IB core.  All registered clients will receive a

 * callback for each device that is added. @device must be allocated

 * with ib_alloc_device().

 *

 * If the driver uses ops.dealloc_driver and calls any ib_unregister_device()

 * asynchronously then the device pointer may become freed as soon as this

 * function returns.

	/*

	 * If the caller does not provide a DMA capable device then the IB core

	 * will set up ib_sge and scatterlist structures that stash the kernel

	 * virtual address into the address field.

	/*

	 * Ensure that ADD uevent is not fired because it

	 * is too early amd device is not initialized yet.

		/*

		 * If we hit this error flow then we don't want to

		 * automatically dealloc the device since the caller is

		 * expected to call ib_dealloc_device() after

		 * ib_register_device() fails. This is tricky due to the

		 * possibility for a parallel unregistration along with this

		 * error flow. Since we have a refcount here we know any

		 * parallel flow is stopped in disable_device and will see the

		 * special dealloc_driver pointer, causing the responsibility to

		 * ib_dealloc_device() to revert back to this thread.

 Mark for userspace that device is ready */

 Callers must hold a get on the device. */

	/*

	 * We have a registration lock so that all the calls to unregister are

	 * fully fenced, once any unregister returns the device is truely

	 * unregistered even if multiple callers are unregistering it at the

	 * same time. This also interacts with the registration flow and

	 * provides sane semantics if register and unregister are racing.

 Expedite removing unregistered pointers from the hash table */

	/*

	 * Drivers using the new flow may not call ib_dealloc_device except

	 * in error unwind prior to registration success.

/**

 * ib_unregister_device - Unregister an IB device

 * @ib_dev: The device to unregister

 *

 * Unregister an IB device.  All clients will receive a remove callback.

 *

 * Callers should call this routine only once, and protect against races with

 * registration. Typically it should only be called as part of a remove

 * callback in an implementation of driver core's struct device_driver and

 * related.

 *

 * If ops.dealloc_driver is used then ib_dev will be freed upon return from

 * this function.

/**

 * ib_unregister_device_and_put - Unregister a device while holding a 'get'

 * @ib_dev: The device to unregister

 *

 * This is the same as ib_unregister_device(), except it includes an internal

 * ib_device_put() that should match a 'get' obtained by the caller.

 *

 * It is safe to call this routine concurrently from multiple threads while

 * holding the 'get'. When the function returns the device is fully

 * unregistered.

 *

 * Drivers using this flow MUST use the driver_unregister callback to clean up

 * their resources associated with the device and dealloc it.

/**

 * ib_unregister_driver - Unregister all IB devices for a driver

 * @driver_id: The driver to unregister

 *

 * This implements a fence for device unregistration. It only returns once all

 * devices associated with the driver_id have fully completed their

 * unregistration and returned from ib_unregister_device*().

 *

 * If device's are not yet unregistered it goes ahead and starts unregistering

 * them.

 *

 * This does not block creation of new devices with the given driver_id, that

 * is the responsibility of the caller.

/**

 * ib_unregister_device_queued - Unregister a device using a work queue

 * @ib_dev: The device to unregister

 *

 * This schedules an asynchronous unregistration using a WQ for the device. A

 * driver should use this to avoid holding locks while doing unregistration,

 * such as holding the RTNL lock.

 *

 * Drivers using this API must use ib_unregister_driver before module unload

 * to ensure that all scheduled unregistrations have completed.

/*

 * The caller must pass in a device that has the kref held and the refcount

 * released. If the device is in cur_net and still registered then it is moved

 * into net.

	/*

	 * If a device not under ib_device_get() or if the unregistration_lock

	 * is not held, the namespace can be changed, or it can be unregistered.

	 * Check again under the lock.

	/*

	 * At this point no one can be using the device, so it is safe to

	 * change the namespace.

	/*

	 * Currently rdma devices are system wide unique. So the device name

	 * is guaranteed free in the new namespace. Publish the new namespace

	 * at the sysfs level.

 Try and put things back and re-enable the device */

		/*

		 * This shouldn't really happen, but if it does, let the user

		 * retry at later point. So don't disable the device.

	/*

	 * All the ib_clients, including uverbs, are reset when the namespace is

	 * changed and this cannot be blocked waiting for userspace to do

	 * something, so disassociation is mandatory.

	/*

	 * The add/remove callbacks must be called in FIFO/LIFO order. To

	 * achieve this we assign client_ids so they are sorted in

	 * registration order.

/**

 * ib_register_client - Register an IB client

 * @client:Client to register

 *

 * Upper level users of the IB drivers can use ib_register_client() to

 * register callbacks for IB device addition and removal.  When an IB

 * device is added, each registered client's add method will be called

 * (in the order the clients were registered), and when a device is

 * removed, each client's remove method will be called (in the reverse

 * order that clients were registered).  In addition, when

 * ib_register_client() is called, the client will receive an add

 * callback for all devices already registered.

/**

 * ib_unregister_client - Unregister an IB client

 * @client:Client to unregister

 *

 * Upper level users use ib_unregister_client() to remove their client

 * registration.  When ib_unregister_client() is called, the client

 * will receive a remove callback for each IB device still registered.

 *

 * This is a full fence, once it returns no client callbacks will be called,

 * or are running in another thread.

 We do not want to have locks while calling client->remove() */

	/*

	 * remove_client_context() is not a fence, it can return even though a

	 * removal is ongoing. Wait until all removals are completed.

		/*

		 * The cdev is guaranteed valid as long as we are inside the

		 * client_data_rwsem as remove_one can't be called. Keep it

		 * valid for the caller.

/**

 * ib_get_client_nl_info - Fetch the nl_info from a client

 * @ibdev: IB device

 * @client_name: Name of the client

 * @res: Result of the query

/**

 * ib_set_client_data - Set IB client context

 * @device:Device to set context for

 * @client:Client to set context for

 * @data:Context to set

 *

 * ib_set_client_data() sets client context data that can be retrieved with

 * ib_get_client_data(). This can only be called while the client is

 * registered to the device, once the ib_client remove() callback returns this

 * cannot be called.

/**

 * ib_register_event_handler - Register an IB event handler

 * @event_handler:Handler to register

 *

 * ib_register_event_handler() registers an event handler that will be

 * called back when asynchronous IB events occur (as defined in

 * chapter 11 of the InfiniBand Architecture Specification). This

 * callback occurs in workqueue context.

/**

 * ib_unregister_event_handler - Unregister an event handler

 * @event_handler:Handler to unregister

 *

 * Unregister an event handler registered with

 * ib_register_event_handler().

/**

 * ib_query_port - Query IB port attributes

 * @device:Device to query

 * @port_num:Port number to query

 * @port_attr:Port attributes

 *

 * ib_query_port() returns the attributes of a port through the

 * @port_attr pointer.

		/*

		 * We cannot do hash_add_rcu after a hash_del_rcu until the

		 * grace period

/**

 * ib_device_set_netdev - Associate the ib_dev with an underlying net_device

 * @ib_dev: Device to modify

 * @ndev: net_device to affiliate, may be NULL

 * @port: IB port the net_device is connected to

 *

 * Drivers should use this to link the ib_device to a netdev so the netdev

 * shows up in interfaces like ib_enum_roce_netdev. Only one netdev may be

 * affiliated with any port.

 *

 * The caller must ensure that the given ndev is not unregistered or

 * unregistering, and that either the ib_device is unregistered or

 * ib_device_set_netdev() is called with NULL when the ndev sends a

 * NETDEV_UNREGISTER event.

	/*

	 * Drivers wish to call this before ib_register_driver, so we have to

	 * setup the port data early.

			/*

			 * If this is the last dev_put there is still a

			 * synchronize_rcu before the netdev is kfreed, so we

			 * can continue to rely on unlocked pointer

			 * comparisons after the put

	/*

	 * New drivers should use ib_device_set_netdev() not the legacy

	 * get_netdev().

	/*

	 * If we are starting to unregister expedite things by preventing

	 * propagation of an unregistering netdev.

/**

 * ib_device_get_by_netdev - Find an IB device associated with a netdev

 * @ndev: netdev to locate

 * @driver_id: The driver ID that must match (RDMA_DRIVER_UNKNOWN matches all)

 *

 * Find and hold an ib_device that is associated with a netdev via

 * ib_device_set_netdev(). The caller must call ib_device_put() on the

 * returned pointer.

/**

 * ib_enum_roce_netdev - enumerate all RoCE ports

 * @ib_dev : IB device we want to query

 * @filter: Should we call the callback?

 * @filter_cookie: Cookie passed to filter

 * @cb: Callback to call for each found RoCE ports

 * @cookie: Cookie passed back to the callback

 *

 * Enumerates all of the physical RoCE ports of ib_dev

 * which are related to netdevice and calls callback() on each

 * device for which filter() function returns non zero.

/**

 * ib_enum_all_roce_netdevs - enumerate all RoCE devices

 * @filter: Should we call the callback?

 * @filter_cookie: Cookie passed to filter

 * @cb: Callback to call for each found RoCE ports

 * @cookie: Cookie passed back to the callback

 *

 * Enumerates all RoCE devices' physical ports which are related

 * to netdevices and calls callback() on each device for which

 * filter() function returns non zero.

/*

 * ib_enum_all_devs - enumerate all ib_devices

 * @cb: Callback to call for each found ib_device

 *

 * Enumerates all ib_devices and calls callback() on each device.

/**

 * ib_query_pkey - Get P_Key table entry

 * @device:Device to query

 * @port_num:Port number to query

 * @index:P_Key table index to query

 * @pkey:Returned P_Key

 *

 * ib_query_pkey() fetches the specified P_Key table entry.

/**

 * ib_modify_device - Change IB device attributes

 * @device:Device to modify

 * @device_modify_mask:Mask of attributes to change

 * @device_modify:New attribute values

 *

 * ib_modify_device() changes a device's attributes as specified by

 * the @device_modify_mask and @device_modify structure.

/**

 * ib_modify_port - Modifies the attributes for the specified port.

 * @device: The device to modify.

 * @port_num: The number of the port to modify.

 * @port_modify_mask: Mask used to specify which attributes of the port

 *   to change.

 * @port_modify: New attribute values for the port.

 *

 * ib_modify_port() changes a port's attributes as specified by the

 * @port_modify_mask and @port_modify structure.

/**

 * ib_find_gid - Returns the port number and GID table index where

 *   a specified GID value occurs. Its searches only for IB link layer.

 * @device: The device to query.

 * @gid: The GID value to search for.

 * @port_num: The port number of the device where the GID value was found.

 * @index: The index into the GID table where the GID was found.  This

 *   parameter may be NULL.

/**

 * ib_find_pkey - Returns the PKey table index where a specified

 *   PKey value occurs.

 * @device: The device to query.

 * @port_num: The port number of the device to search for the PKey.

 * @pkey: The PKey value to search for.

 * @index: The index into the PKey table where the PKey was found.

 if there is full-member pkey take it.*/

no full-member, if exists take the limited*/

/**

 * ib_get_net_dev_by_params() - Return the appropriate net_dev

 * for a received CM request

 * @dev:	An RDMA device on which the request has been received.

 * @port:	Port number on the RDMA device.

 * @pkey:	The Pkey the request came on.

 * @gid:	A GID that the net_dev uses to communicate.

 * @addr:	Contains the IP address that the request specified as its

 *		destination.

 *

	/*

	 * Holding the read side guarantees that the client will not become

	 * unregistered while we are calling get_net_dev_by_params()

 CONFIG_INFINIBAND_VIRT_DMA */

 Make sure that any pending umem accounting work is done. */

/* ib core relies on netdev stack to first register net_ns_type_operations

 * ns kobject type before ib_core initialization.

/*

 * Copyright (c) 2015, Mellanox Technologies inc.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 For in6_dev_get/in6_dev_put */

 No primary slave or the device isn't a slave in bonding */

/**

 * is_ndev_for_default_gid_filter - Check if a given netdevice

 * can be considered for default GIDs or not.

 * @ib_dev:		IB device to check

 * @port:		Port to consider for adding default GID

 * @rdma_ndev:		rdma netdevice pointer

 * @cookie:             Netdevice to consider to form a default GID

 *

 * is_ndev_for_default_gid_filter() returns true if a given netdevice can be

 * considered for deriving default RoCE GID, returns false otherwise.

	/*

	 * When rdma netdevice is used in bonding, bonding master netdevice

	 * should be considered for default GIDs. Therefore, ignore slave rdma

	 * netdevices when bonding is considered.

	 * Additionally when event(cookie) netdevice is bond master device,

	 * make sure that it the upper netdevice of rdma netdevice.

/**

 * is_upper_ndev_bond_master_filter - Check if a given netdevice

 * is bond master device of netdevice of the the RDMA device of port.

 * @ib_dev:		IB device to check

 * @port:		Port to consider for adding default GID

 * @rdma_ndev:		Pointer to rdma netdevice

 * @cookie:	        Netdevice to consider to form a default GID

 *

 * is_upper_ndev_bond_master_filter() returns true if a cookie_netdev

 * is bond master device and rdma_ndev is its lower netdevice. It might

 * not have been established as slave device yet.

/**

 * del_default_gids - Delete default GIDs of the event/cookie netdevice

 * @ib_dev:	RDMA device pointer

 * @port:	Port of the RDMA device whose GID table to consider

 * @rdma_ndev:	Unused rdma netdevice

 * @cookie:	Pointer to event netdevice

 *

 * del_default_gids() deletes the default GIDs of the event/cookie netdevice.

	/* Lock the rtnl to make sure the netdevs does not move under

	 * our feet

			/*

			 * Filter and add default GIDs of the primary netdevice

			 * when not in bonding mode, or add default GIDs

			 * of bond master device, when in bonding mode.

/**

 * rdma_roce_rescan_device - Rescan all of the network devices in the system

 * and add their gids, as needed, to the relevant RoCE devices.

 *

 * @ib_dev:         the rdma device

/* The following functions operate on all IB devices. netdevice_event and

 * addr_event execute ib_enum_all_roce_netdevs through a work.

 * ib_enum_all_roce_netdevs iterates through all IB devices.

	/*

	 * When a lower netdev is linked to its upper bonding

	 * netdev, delete lower slave netdev's default GIDs.

 Now add bonding upper device default GIDs */

 Now add bonding upper device IP based GIDs */

 Add default GIDs of the bond device */

 Add IP based GIDs of the bond device */

	/* We relay on the netdevice notifier to enumerate all

	 * existing devices in the system. Register to this notifier

	 * last to make sure we will not miss any IP add/del

	 * callbacks.

	/* Ensure all gid deletion tasks complete before we go down,

	 * to avoid any reference to free'd memory. By the time

	 * ib-core is removed, all physical devices have been removed,

	 * so no issue with remaining hardware contexts.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 HGST, a Western Digital Company.

/*

 * Report whether memory registration should be used. Memory registration must

 * be used for iWarp devices because of iWARP-specific limitations. Memory

 * registration is also enabled if registering memory might yield better

 * performance than using multiple SGE entries, see rdma_rw_io_needs_mr()

/*

 * Check if the device will use memory registration for this RW operation.

 * For RDMA READs we must use MRs on iWarp and can optionally use them as an

 * optimization otherwise.  Additionally we have a debug option to force usage

 * of MRs to help testing this code path.

 arbitrary limit to avoid allocating gigantic resources */

 Caller must have zero-initialized *reg. */

/**

 * rdma_rw_ctx_init - initialize a RDMA READ/WRITE context

 * @ctx:	context to initialize

 * @qp:		queue pair to operate on

 * @port_num:	port num to which the connection is bound

 * @sg:		scatterlist to READ/WRITE from/to

 * @sg_cnt:	number of entries in @sg

 * @sg_offset:	current byte offset into @sg

 * @remote_addr:remote address to read/write (relative to @rkey)

 * @rkey:	remote key to operate on

 * @dir:	%DMA_TO_DEVICE for RDMA WRITE, %DMA_FROM_DEVICE for RDMA READ

 *

 * Returns the number of WQEs that will be needed on the workqueue if

 * successful, or a negative error code.

	/*

	 * Skip to the S/G entry that sg_offset falls into:

/**

 * rdma_rw_ctx_signature_init - initialize a RW context with signature offload

 * @ctx:	context to initialize

 * @qp:		queue pair to operate on

 * @port_num:	port num to which the connection is bound

 * @sg:		scatterlist to READ/WRITE from/to

 * @sg_cnt:	number of entries in @sg

 * @prot_sg:	scatterlist to READ/WRITE protection information from/to

 * @prot_sg_cnt: number of entries in @prot_sg

 * @sig_attrs:	signature offloading algorithms

 * @remote_addr:remote address to read/write (relative to @rkey)

 * @rkey:	remote key to operate on

 * @dir:	%DMA_TO_DEVICE for RDMA WRITE, %DMA_FROM_DEVICE for RDMA READ

 *

 * Returns the number of WQEs that will be needed on the workqueue if

 * successful, or a negative error code.

/*

 * Now that we are going to post the WRs we can update the lkey and need_inval

 * state on the MRs.  If we were doing this at init time, we would get double

 * or missing invalidations if a context was initialized but not actually

 * posted.

/**

 * rdma_rw_ctx_wrs - return chain of WRs for a RDMA READ or WRITE operation

 * @ctx:	context to operate on

 * @qp:		queue pair to operate on

 * @port_num:	port num to which the connection is bound

 * @cqe:	completion queue entry for the last WR

 * @chain_wr:	WR to append to the posted chain

 *

 * Return the WR chain for the set of RDMA READ/WRITE operations described by

 * @ctx, as well as any memory registration operations needed.  If @chain_wr

 * is non-NULL the WR it points to will be appended to the chain of WRs posted.

 * If @chain_wr is not set @cqe must be set so that the caller gets a

 * completion notification.

/**

 * rdma_rw_ctx_post - post a RDMA READ or RDMA WRITE operation

 * @ctx:	context to operate on

 * @qp:		queue pair to operate on

 * @port_num:	port num to which the connection is bound

 * @cqe:	completion queue entry for the last WR

 * @chain_wr:	WR to append to the posted chain

 *

 * Post the set of RDMA READ/WRITE operations described by @ctx, as well as

 * any memory registration operations needed.  If @chain_wr is non-NULL the

 * WR it points to will be appended to the chain of WRs posted.  If @chain_wr

 * is not set @cqe must be set so that the caller gets a completion

 * notification.

/**

 * rdma_rw_ctx_destroy - release all resources allocated by rdma_rw_ctx_init

 * @ctx:	context to release

 * @qp:		queue pair to operate on

 * @port_num:	port num to which the connection is bound

 * @sg:		scatterlist that was used for the READ/WRITE

 * @sg_cnt:	number of entries in @sg

 * @dir:	%DMA_TO_DEVICE for RDMA WRITE, %DMA_FROM_DEVICE for RDMA READ

/**

 * rdma_rw_ctx_destroy_signature - release all resources allocated by

 *	rdma_rw_ctx_signature_init

 * @ctx:	context to release

 * @qp:		queue pair to operate on

 * @port_num:	port num to which the connection is bound

 * @sg:		scatterlist that was used for the READ/WRITE

 * @sg_cnt:	number of entries in @sg

 * @prot_sg:	scatterlist that was used for the READ/WRITE of the PI

 * @prot_sg_cnt: number of entries in @prot_sg

 * @dir:	%DMA_TO_DEVICE for RDMA WRITE, %DMA_FROM_DEVICE for RDMA READ

/**

 * rdma_rw_mr_factor - return number of MRs required for a payload

 * @device:	device handling the connection

 * @port_num:	port num to which the connection is bound

 * @maxpages:	maximum payload pages per rdma_rw_ctx

 *

 * Returns the number of MRs the device requires to move @maxpayload

 * bytes. The returned value is used during transport creation to

 * compute max_rdma_ctxts and the size of the transport's Send and

 * Send Completion Queues.

	/*

	 * Each context needs at least one RDMA READ or WRITE WR.

	 *

	 * For some hardware we might need more, eventually we should ask the

	 * HCA driver for a multiplier here.

	/*

	 * If the devices needs MRs to perform RDMA READ or WRITE operations,

	 * we'll need two additional MRs for the registrations and the

	 * invalidation.

 inv + reg */

	/*

	 * But maybe we were just too high in the sky and the device doesn't

	 * even support all we need, and we'll have to live with what we get..

/*

 * Copyright (c) 2014 Chelsio, Inc. All rights reserved.

 * Copyright (c) 2014 Intel Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/**

 * iwpm_init - Allocate resources for the iwarp port mapper

 * @nl_client: The index of the netlink client

 *

 * Should be called when network interface goes up.

/**

 * iwpm_exit - Deallocate resources for the iwarp port mapper

 * @nl_client: The index of the netlink client

 *

 * Should be called when network interface goes down.

/**

 * iwpm_create_mapinfo - Store local and mapped IPv4/IPv6 address

 *                       info in a hash table

 * @local_sockaddr: Local ip/tcp address

 * @mapped_sockaddr: Mapped local ip/tcp address

 * @nl_client: The index of the netlink client

 * @map_flags: IWPM mapping flags

/**

 * iwpm_remove_mapinfo - Remove local and mapped IPv4/IPv6 address

 *                       info from the hash table

 * @local_sockaddr: Local ip/tcp address

 * @mapped_local_addr: Mapped local ip/tcp address

 *

 * Returns err code if mapping info is not found in the hash table,

 * otherwise returns 0

 remove all the mapinfo data from the list */

 free the hash list */

 remove all the remote info from the list */

 free the hash list */

/**

 * iwpm_get_remote_info - Get the remote connecting peer address info

 *

 * @mapped_loc_addr: Mapped local address of the listening peer

 * @mapped_rem_addr: Mapped remote address of the connecting peer

 * @remote_addr: To store the remote address of the connecting peer

 * @nl_client: The index of the netlink client

 *

 * The remote address info is retrieved and provided to the client in

 * the remote_addr. After that it is removed from the hash table

 valid client */

 valid client */

 valid client */

 if port mapper isn't available */

 check if all mappings can fit in one skb */

 and leave room for NLMSG_DONE */

 send the skb */

/*

 * Copyright (c) 2017 Mellanox Technologies Inc.  All rights reserved.

 * Copyright (c) 2010 Voltaire Inc.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/* Synchronizes between ongoing netlink commands and netlink client

	 * unregistration.

	/*

	 * This BUILD_BUG_ON is intended to catch addition of new

	 * RDMA netlink protocol without updating the array above.

	/*

	 * Currently only NLDEV client is supporting netlink commands in

	 * non init_net net namespace.

		/*

		 * Didn't get valid reference of the table, attempt module

		 * load once.

 Pairs with the READ_ONCE in is_nl_valid() */

	/*

	 * LS responses overload the 0x100 (NLM_F_ROOT) flag.  Don't

	 * mistakenly call the .dump() function.

 FIXME: Convert IWCM to properly handle doit callbacks */

/*

 * This function is similar to netlink_rcv_skb with one exception:

 * It calls to the callback for the netlink messages without NLM_F_REQUEST

 * flag. These messages are intended for RDMA_NL_LS consumer, so it is allowed

 * for that consumer only.

		/*

		 * Generally speaking, the only requests are handled

		 * by the kernel, but RDMA_NL_LS is different, because it

		 * runs backward netlink scheme. Kernel initiates messages

		 * and waits for reply with data to keep pathrecord cache

		 * in sync.

 Skip control messages */

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Voltaire, Inc.  All rights reserved.

 * Copyright (c) 2006 Intel Corporation.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

msecs */

 protects class port info set */

 Local svc request list */

 Local svc request sequence number */

 Local svc timeout */

 How will the pathrecord be used */

 Construct the family header first */

 Now build the attributes */

	/*

	 * Make sure that at least some of the required comp_mask bits are

	 * set.

 Add the family header */

 Put nlmsg header only for now */

 Add attributes */

 Repair the nlmsg header length */

 Put the request on the list.*/

 Start the timeout if this is the only request */

 Let the timeout to take care of the callback */

				/*

				 * Get the first one. In the future, we may

				 * need to get up to 6 pathrecords.

 Hold the lock to protect against query cancellation */

 Get the new delay from the first entry */

		/*

		 * If the query is cancelled, let the timeout routine

		 * take care of it.

 if the result is a failure, send out the packet via IB */

/**

 * ib_sa_cancel_query - try to cancel an SA query

 * @id:ID of query to cancel

 * @query:query pointer to cancel

 *

 * Try to cancel an SA query.  If the id and query don't match up or

 * the query has already completed, nothing is done.  Otherwise the

 * query is canceled and will complete with a status of -EINTR.

	/*

	 * If the query is still on the netlink request list, schedule

	 * it to be cancelled by the timeout routine. Otherwise, it has been

	 * sent to the MAD layer and has to be cancelled from there.

/**

 * ib_init_ah_attr_from_path - Initialize address handle attributes based on

 *   an SA path record.

 * @device: Device associated ah attributes initialization.

 * @port_num: Port on the specified device.

 * @rec: path record entry to use for ah attributes initialization.

 * @ah_attr: address handle attributes to initialization from path record.

 * @gid_attr: SGID attribute to consider during initialization.

 *

 * When ib_init_ah_attr_from_path() returns success,

 * (a) for IB link layer it optionally contains a reference to SGID attribute

 * when GRH is present for IB link layer.

 * (b) for RoCE link layer it contains a reference to SGID attribute.

 * User must invoke rdma_destroy_ah_attr() to release reference to SGID

 * attributes which are initialized using ib_init_ah_attr_from_path().

	/*

	 * Always check if sm_ah has valid dlid assigned,

	 * before querying for class port info

 Special case, very small timeout_ms */

	/*

	 * It's not safe to dereference query any more, because the

	 * send may already have completed and freed the query in

	 * another context.

/*

 * opa_pr_query_possible - Check if current PR query can be an OPA query.

 *

 * Retuns PR_NOT_SUPPORTED if a path record query is not

 * possible, PR_OPA_SUPPORTED if an OPA path record query

 * is possible and PR_IB_SUPPORTED if an IB path record

 * query is possible.

/**

 * ib_sa_path_rec_get - Start a Path get query

 * @client:SA client

 * @device:device to send query on

 * @port_num: port number to send query on

 * @rec:Path Record to send in query

 * @comp_mask:component mask to send in query

 * @timeout_ms:time to wait for response

 * @gfp_mask:GFP mask to use for internal allocations

 * @callback:function called when query completes, times out or is

 * canceled

 * @context:opaque user context passed to callback

 * @sa_query:query context, used to cancel query

 *

 * Send a Path Record Get query to the SA to look up a path.  The

 * callback function will be called when the query completes (or

 * fails); status is 0 for a successful response, -EINTR if the query

 * is canceled, -ETIMEDOUT is the query timed out, or -EIO if an error

 * occurred sending the query.  The resp parameter of the callback is

 * only valid if status is 0.

 *

 * If the return value of ib_sa_path_rec_get() is negative, it is an

 * error code.  Otherwise it is a query ID that can be used to cancel

 * the query.

 Support GuidInfoRecord */

	/* If the classport info is valid, nothing

	 * to do here.

	/* If the classport info is still not valid, the query should have

	 * failed for some reason. Retry issuing the query

 No callback -- already got recv */

	/*

	 * The OPA sm_lid of 0xFFFF needs special handling so that it can be

	 * differentiated from a permissive LID of 0xFFFF.  We set the

	 * grh_required flag here so the SA can program the DGID in the

	 * address handle appropriately

	/*

	 * We register our event handler after everything is set up,

	 * and then update our cached info after the event handler is

	 * registered to avoid any problems if a port changes state

	 * during our initialization.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright 2018-2019 Amazon.com, Inc. or its affiliates. All rights reserved.

 * Copyright 2019 Marvell. All rights reserved.

/**

 * rdma_umap_priv_init() - Initialize the private data of a vma

 *

 * @priv: The already allocated private data

 * @vma: The vm area struct that needs private data

 * @entry: entry into the mmap_xa that needs to be linked with

 *       this vma

 *

 * Each time we map IO memory into user space this keeps track of the

 * mapping. When the device is hot-unplugged we 'zap' the mmaps in user space

 * to point to the zero page and allow the hot unplug to proceed.

 *

 * This is necessary for cases like PCI physical hot unplug as the actual BAR

 * memory may vanish after this and access to it from userspace could MCE.

 *

 * RDMA drivers supporting disassociation must have their user space designed

 * to cope in some way with their IO pages going to the zero page.

 *

 vm_ops is setup in ib_uverbs_mmap() to avoid module dependencies */

/**

 * rdma_user_mmap_io() - Map IO memory into a process

 *

 * @ucontext: associated user context

 * @vma: the vma related to the current mmap call

 * @pfn: pfn to map

 * @size: size to map

 * @prot: pgprot to use in remap call

 * @entry: mmap_entry retrieved from rdma_user_mmap_entry_get(), or NULL

 *         if mmap_entry is not used by the driver

 *

 * This is to be called by drivers as part of their mmap() functions if they

 * wish to send something like PCI-E BAR memory to userspace.

 *

 * Return -EINVAL on wrong flags or size, -EAGAIN on failure to map. 0 on

 * success.

 Driver is using this wrong, must be called by ib_uverbs_mmap */

/**

 * rdma_user_mmap_entry_get_pgoff() - Get an entry from the mmap_xa

 *

 * @ucontext: associated user context

 * @pgoff: The mmap offset >> PAGE_SHIFT

 *

 * This function is called when a user tries to mmap with an offset (returned

 * by rdma_user_mmap_get_offset()) it initially received from the driver. The

 * rdma_user_mmap_entry was created by the function

 * rdma_user_mmap_entry_insert().  This function increases the refcnt of the

 * entry so that it won't be deleted from the xarray in the meantime.

 *

 * Return an reference to an entry if exists or NULL if there is no

 * match. rdma_user_mmap_entry_put() must be called to put the reference.

	/*

	 * If refcount is zero, entry is already being deleted, driver_removed

	 * indicates that the no further mmaps are possible and we waiting for

	 * the active VMAs to be closed.

/**

 * rdma_user_mmap_entry_get() - Get an entry from the mmap_xa

 *

 * @ucontext: associated user context

 * @vma: the vma being mmap'd into

 *

 * This function is like rdma_user_mmap_entry_get_pgoff() except that it also

 * checks that the VMA is correct.

	/*

	 * Erase all entries occupied by this single entry, this is deferred

	 * until all VMA are closed so that the mmap offsets remain unique.

/**

 * rdma_user_mmap_entry_put() - Drop reference to the mmap entry

 *

 * @entry: an entry in the mmap_xa

 *

 * This function is called when the mapping is closed if it was

 * an io mapping or when the driver is done with the entry for

 * some other reason.

 * Should be called after rdma_user_mmap_entry_get was called

 * and entry is no longer needed. This function will erase the

 * entry and free it if its refcnt reaches zero.

/**

 * rdma_user_mmap_entry_remove() - Drop reference to entry and

 *				   mark it as unmmapable

 *

 * @entry: the entry to insert into the mmap_xa

 *

 * Drivers can call this to prevent userspace from creating more mappings for

 * entry, however existing mmaps continue to exist and ops->mmap_free() will

 * not be called until all user mmaps are destroyed.

/**

 * rdma_user_mmap_entry_insert_range() - Insert an entry to the mmap_xa

 *					 in a given range.

 *

 * @ucontext: associated user context.

 * @entry: the entry to insert into the mmap_xa

 * @length: length of the address that will be mmapped

 * @min_pgoff: minimum pgoff to be returned

 * @max_pgoff: maximum pgoff to be returned

 *

 * This function should be called by drivers that use the rdma_user_mmap

 * interface for implementing their mmap syscall A database of mmap offsets is

 * handled in the core and helper functions are provided to insert entries

 * into the database and extract entries when the user calls mmap with the

 * given offset. The function allocates a unique page offset in a given range

 * that should be provided to user, the user will use the offset to retrieve

 * information such as address to be mapped and how.

 *

 * Return: 0 on success and -ENOMEM on failure

	/*

	 * We want the whole allocation to be done without interruption from a

	 * different thread. The allocation requires finding a free range and

	 * storing. During the xa_insert the lock could be released, possibly

	 * allowing another thread to choose the same range.

 We want to find an empty range */

 First find an empty index */

 Is there enough room to have the range? */

		/*

		 * Now look for the next present entry. If an entry doesn't

		 * exist, we found an empty range and can proceed.

	/*

	 * Internally the kernel uses a page offset, in libc this is a byte

	 * offset. Drivers should not return pgoff to userspace.

/**

 * rdma_user_mmap_entry_insert() - Insert an entry to the mmap_xa.

 *

 * @ucontext: associated user context.

 * @entry: the entry to insert into the mmap_xa

 * @length: length of the address that will be mmapped

 *

 * This function should be called by drivers that use the rdma_user_mmap

 * interface for handling user mmapped addresses. The database is handled in

 * the core and helper functions are provided to insert entries into the

 * database and extract entries when the user calls mmap with the given offset.

 * The function allocates a unique page offset that should be provided to user,

 * the user will use the offset to retrieve information such as address to

 * be mapped and how.

 *

 * Return: 0 on success and -ENOMEM on failure

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2019 Mellanox Technologies. All rights reserved.

/*

 * rdma_counter_set_auto_mode() - Turn on/off per-port auto mode

 *

 * @dev: Device to operate

 * @port: Port to use

 * @mask: Mask to configure

 * @extack: Message to the user

 *

 * Return 0 on success. If counter mode wasn't changed then it is considered

 * as success as well.

 * Return -EBUSY when changing to auto mode while there are bounded counters.

 *

/*

 * rdma_get_counter_auto_mode - Find the counter that @qp should be bound

 *     with in auto mode

 *

 * Return: The counter (with ref-count increased) if found

/*

 * rdma_counter_bind_qp_auto - Check and bind the QP to a counter base on

 *   the auto-mode rule

/*

 * rdma_counter_unbind_qp - Unbind a qp from a counter

 * @force:

 *   true - Decrease the counter ref-count anyway (e.g., qp destroy)

/*

 * rdma_counter_get_hwstat_value() - Get the sum value of all counters on a

 *   specific port, including the running ones and history data

/*

 * rdma_counter_bind_qpn() - Bind QP @qp_num to counter @counter_id

/*

 * rdma_counter_bind_qpn_alloc() - Alloc a counter and bind QP @qp_num to it

 *   The id of new counter is returned in @counter_id

/*

 * rdma_counter_unbind_qpn() - Unbind QP @qp_num from a counter

/*

 * Copyright (c) 2016, Mellanox Technologies inc.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * In order to indicate we no longer needs this uobject, uverbs_uobject_put

 * is called. When the reference count is decreased, the uobject is freed.

 * For example, this is used when attaching a completion channel to a CQ.

	/*

	 * When a shared access is required, we use a positive counter. Each

	 * shared access request checks that the value != -1 and increment it.

	 * Exclusive access is required for operations like write or destroy.

	 * In exclusive access mode, we check that the counter is zero (nobody

	 * claimed this object) and we set it to -1. Releasing a shared access

	 * lock is done simply by decreasing the counter. As for exclusive

	 * access locks, since only a single one of them is is allowed

	 * concurrently, setting the counter to zero is enough for releasing

	 * this lock.

 lock is exclusive */

/*

 * This must be called with the hw_destroy_rwsem locked for read or write,

 * also the uobject itself must be locked for write.

 *

 * Upon return the HW object is guaranteed to be destroyed.

 *

 * For RDMA_REMOVE_ABORT, the hw_destroy_rwsem is not required to be held,

 * however the type's allocat_commit function cannot have been called and the

 * uobject cannot be on the uobjects_lists

 *

 * For RDMA_REMOVE_DESTROY the caller should be holding a kref (eg via

 * rdma_lookup_get_uobject) and the object is left in a state where the caller

 * needs to call rdma_lookup_put_uobject.

 *

 * For all other destroy modes this function internally unlocks the uobject

 * and consumes the kref on the uobj.

 Nothing to be done, wait till ucontext will clean it */

	/*

	 * For DESTROY the usecnt is not changed, the caller is expected to

	 * manage it via uobj_put_destroy(). Only DESTROY can remove the IDR

	 * handle.

		/*

		 * Pairs with the get in rdma_alloc_commit_uobject(), could

		 * destroy uobj.

	/*

	 * When aborting the stack kref remains owned by the core code, and is

	 * not transferred into the type. Pairs with the get in alloc_uobj

/*

 * This calls uverbs_destroy_uobject() using the RDMA_REMOVE_DESTROY

 * sequence. It should only be used from command callbacks. On success the

 * caller must pair this with uobj_put_destroy(). This

 * version requires the caller to have already obtained an

 * LOOKUP_DESTROY uobject kref.

	/*

	 * Once the uobject is destroyed by RDMA_REMOVE_DESTROY then it is left

	 * write locked as the callers put it back with UVERBS_LOOKUP_DESTROY.

	 * This is because any other concurrent thread can still see the object

	 * in the xarray due to RCU. Leaving it locked ensures nothing else will

	 * touch it.

/*

 * uobj_get_destroy destroys the HW object and returns a handle to the uobj

 * with a NULL object pointer. The caller must pair this with

 * uobj_put_destroy().

/*

 * Does both uobj_get_destroy() and uobj_put_destroy().  Returns 0 on success

 * (negative errno on failure). For use by callers that do not need the uobj.

 alloc_uobj must be undone by uverbs_destroy_uobject() */

	/*

	 * user_handle should be filled by the handler,

	 * The object is added to the list in the commit stage.

	/*

	 * Allocated objects start out as write locked to deny any other

	 * syscalls from accessing them until they are committed. See

	 * rdma_alloc_commit_uobject

       /*

        * We start with allocating an idr pointing to NULL. This represents an

        * object which isn't initialized yet. We'll replace it later on with

        * the real object once we commit.

 Returns the ib_uobject or an error. The caller should check for IS_ERR. */

	/*

	 * The idr_find is guaranteed to return a pointer to something that

	 * isn't freed yet, or NULL, as the free after idr_remove goes through

	 * kfree_rcu(). However the object may still have been released and

	 * kfree() could be called at any time.

	/*

	 * fget(id) ensures we are not currently running

	 * uverbs_uobject_fd_release(), and the caller is expected to ensure

	 * that release is never done while a call to lookup is possible.

 must be UVERBS_IDR_ANY_OBJECT, see uapi_get_object() */

	/*

	 * If we have been disassociated block every command except for

	 * DESTROY based commands.

 Note that uverbs_uobject_fd_release() is called during abort */

	/*

	 * The hw_destroy_rwsem is held across the entire object creation and

	 * released during rdma_alloc_commit_uobject or

	 * rdma_alloc_abort_uobject

 Matches the kref in alloc_commit_idr_uobject */

	/*

	 * We already allocated this IDR with a NULL object, so

	 * this shouldn't fail.

	 *

	 * NOTE: Storing the uobj transfers our kref on uobj to the XArray.

	 * It will be put by remove_commit_idr_uobject()

	/*

	 * New must be an object that been allocated but not yet committed, this

	 * moves the pre-committed state to obj_old, new still must be comitted.

 Matching put will be done in uverbs_uobject_fd_release() */

 This shouldn't be used anymore. Use the file object instead */

	/*

	 * NOTE: Once we install the file we loose ownership of our kref on

	 * uobj. It will be put by uverbs_uobject_fd_release()

/*

 * In all cases rdma_alloc_commit_uobject() consumes the kref to uobj and the

 * caller can no longer assume uobj is valid. If this function fails it

 * destroys the uboject, including the attached HW object.

 kref is held so long as the uobj is on the uobj list. */

 matches atomic_set(-1) in alloc_uobj */

 alloc_commit consumes the uobj kref */

 Matches the down_read in rdma_alloc_begin_uobject */

/*

 * new_uobj will be assigned to the handle currently used by to_uobj, and

 * to_uobj will be destroyed.

 *

 * Upon return the caller must do:

 *    rdma_alloc_commit_uobject(new_uobj)

 *    uobj_put_destroy(to_uobj)

 *

 * to_uobj must have a write get but the put mode switches to destroy once

 * this is called.

	/*

	 * If this fails then the uobject is still completely valid (though with

	 * a new ID) and we leak it until context close.

/*

 * This consumes the kref for uobj. It is up to the caller to unwind the HW

 * object and anything else connected to uobj before calling this.

		/*

		 * If the driver couldn't destroy the object then go ahead and

		 * commit it. Leaking objects that can't be destroyed is only

		 * done during FD close after the driver has a few more tries to

		 * destroy it.

 Matches the down_read in rdma_alloc_begin_uobject */

	/*

	 * This indirectly calls uverbs_uobject_fd_release() and free the

	 * object

	/*

	 * In order to unlock an object, either decrease its usecnt for

	 * read access or zero it in case of exclusive access. See

	 * uverbs_try_lock_object for locking schema information.

 Pairs with the kref obtained by type->lookup_get */

	/*

	 * At this point uverbs_cleanup_ufile() is guaranteed to have run, and

	 * there are no HW objects left, however the xarray is still populated

	 * with anything that has not been cleaned up by userspace. Since the

	 * kref on ufile is 0, nothing is allowed to call lookup_get.

	 *

	 * This is an optimized equivalent to remove_handle_idr_uobject

/*

 * Users of UVERBS_TYPE_ALLOC_FD should set this function as the struct

 * file_operations release method.

	/*

	 * This can only happen if the fput came from alloc_abort_fd_uobject()

		/*

		 * lookup_get_fd_uobject holds the kref on the struct file any

		 * time a FD uobj is locked, which prevents this release

		 * method from being invoked. Meaning we can always get the

		 * write lock here, or we have a kernel bug.

 Matches the get in alloc_commit_fd_uobject() */

 Pairs with filp->private_data in alloc_begin_fd_uobject */

/*

 * Drop the ucontext off the ufile and completely disconnect it from the

 * ib_device

	/*

	 * If we are closing the FD then the user mmap VMAs must have

	 * already been destroyed as they hold on to the filep, otherwise

	 * they need to be zap'd.

	/*

	 * This shouldn't run while executing other commands on this

	 * context. Thus, the only thing we should take care of is

	 * releasing a FD while traversing this list. The FD could be

	 * closed and released from the _release fop of this FD.

	 * In order to mitigate this, we add a lock.

	 * We take and release the lock per traversal in order to let

	 * other threads (which might still use the FDs) chance to run.

		/*

		 * if we hit this WARN_ON, that means we are

		 * racing with a lookup_get.

/*

 * Destroy the ucontext and every uobject associated with it.

 *

 * This is internally locked and can be called in parallel from multiple

 * contexts.

	/*

	 * If a ucontext was never created then we can't have any uobjects to

	 * cleanup, nothing to do.

 Actual destruction is done inside uverbs_handle_method */

	/*

	 * refcounts should be handled at the object level and not at the

	 * uobject level. Refcounts of the objects themselves are done in

	 * handlers.

/*

 * Copyright (c) 2017, Mellanox Technologies inc.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 HGST, a Western Digital Company.

 Max size for shared CQ, may require tuning */

 # of WCs to poll for with a single call to ib_poll_cq */

 # of WCs to iterate over before yielding */

	/*

	 * budget might be (-1) if the caller does not

	 * want to bound this call, thus we need unsigned

	 * minimum here.

/**

 * ib_process_cq_direct - process a CQ in caller context

 * @cq:		CQ to process

 * @budget:	number of CQEs to poll for

 *

 * This function is used to process all outstanding CQ entries.

 * It does not offload CQ processing to a different context and does

 * not ask for completion interrupts from the HCA.

 * Using direct processing on CQ with non IB_POLL_DIRECT type may trigger

 * concurrent processing.

 *

 * Note: do not pass -1 as %budget unless it is guaranteed that the number

 * of completions that will be processed is small.

/**

 * __ib_alloc_cq - allocate a completion queue

 * @dev:		device to allocate the CQ for

 * @private:		driver private data, accessible from cq->cq_context

 * @nr_cqe:		number of CQEs to allocate

 * @comp_vector:	HCA completion vectors for this CQ

 * @poll_ctx:		context to poll the CQ from.

 * @caller:		module owner name.

 *

 * This is the proper interface to allocate a CQ for in-kernel users. A

 * CQ allocated with this interface will automatically be polled from the

 * specified context. The ULP must use wr->wr_cqe instead of wr->wr_id

 * to use this CQ abstraction.

/**

 * __ib_alloc_cq_any - allocate a completion queue

 * @dev:		device to allocate the CQ for

 * @private:		driver private data, accessible from cq->cq_context

 * @nr_cqe:		number of CQEs to allocate

 * @poll_ctx:		context to poll the CQ from

 * @caller:		module owner name

 *

 * Attempt to spread ULP Completion Queues over each device's interrupt

 * vectors. A simple best-effort mechanism is used.

/**

 * ib_free_cq - free a completion queue

 * @cq:		completion queue to free.

	/*

	 * Allocate at least as many CQEs as requested, and otherwise

	 * a reasonable batch size so that we can share CQs between

	 * multiple users instead of allocating a larger number of CQs.

/**

 * ib_cq_pool_get() - Find the least used completion queue that matches

 *   a given cpu hint (or least used for wild card affinity) and fits

 *   nr_cqe.

 * @dev: rdma device

 * @nr_cqe: number of needed cqe entries

 * @comp_vector_hint: completion vector hint (-1) for the driver to assign

 *   a comp vector based on internal counter

 * @poll_ctx: cq polling context

 *

 * Finds a cq that satisfies @comp_vector_hint and @nr_cqe requirements and

 * claim entries in it for us.  In case there is no available cq, allocate

 * a new cq with the requirements and add it to the device pool.

 * IB_POLL_DIRECT cannot be used for shared cqs so it is not a valid value

 * for @poll_ctx.

 Project the affinty to the device completion vector range */

	/*

	 * Find the least used CQ with correct affinity and

	 * enough free CQ entries

			/*

			 * Check to see if we have found a CQ with the

			 * correct completion vector

		/*

		 * Didn't find a match or ran out of CQs in the device

		 * pool, allocate a new array of CQs.

/**

 * ib_cq_pool_put - Return a CQ taken from a shared pool.

 * @cq: The CQ to return.

 * @nr_cqe: The max number of cqes that the user had requested.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Trace points for core RDMA functions.

 *

 * Author: Chuck Lever <chuck.lever@oracle.com>

 *

 * Copyright (c) 2019, Oracle and/or its affiliates. All rights reserved.

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright (c) 2020 Intel Corporation. All rights reserved.

 modify the sg list in-place to match umem address and length */

	/*

	 * Although the sg list is valid now, the content of the pages

	 * may be not up-to-date. Wait for the exporter to finish

	 * the migration.

 retore the original sg list */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016 HGST, a Western Digital Company.

/*

 * Copyright (c) 2004-2007 Voltaire, Inc. All rights reserved.

 * Copyright (c) 2005 Intel Corporation.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies Ltd.  All rights reserved.

 * Copyright (c) 2009 HNR Consulting. All rights reserved.

 * Copyright (c) 2014,2018 Intel Corporation.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 These are common */

 Port list lock */

 Forward declarations */

/*

 * Returns a ib_mad_port_private structure or NULL for a device/port

 * Assumes ib_mad_port_list_lock is being held

/*

 * Wrapper function to return a ib_mad_port_private structure or NULL

 * for a device/port

 Alias IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE to 0 */

/*

 * ib_register_mad_agent - Register to send/receive MADs

 *

 * Context: Process context.

 Validate parameters */

 Validate MAD registration request if supplied */

			/*

			 * IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE is the only

			 * one in this range currently allowed

			/*

			 * Class 0 is reserved in IBA and is used for

			 * aliasing of IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE

			/*

			 * If class is in "new" vendor range,

			 * ensure supplied OUI is not zero

 Make sure class supplied is consistent with RMPP */

 Make sure class supplied is consistent with QP type */

 No registration request supplied */

 Validate device and port */

	/* Verify the QP requested is supported. For example, Ethernet devices

	 * will not have QP0.

 Allocate structures */

 Now, fill in the various structures */

	/*

	 * The mlx4 driver uses the top byte to distinguish which virtual

	 * function generated the MAD, so we must avoid using it.

	/*

	 * Make sure MAD registration (if supplied)

	 * is non overlapping with any existing ones

 "New" vendor class range */

 Note that we could still be handling received MADs */

	/*

	 * Canceling all sends results in dropping received response

	 * MADs, preventing us from queuing additional work

/*

 * ib_unregister_mad_agent - Unregisters a client from using MAD services

 *

 * Context: Process context.

/*

 * Return 0 if SMP is to be sent

 * Return 1 if SMP was consumed locally (whether or not solicited)

 * Return < 0 if error

	/*

	 * Directed route handling starts if the initial LID routed part of

	 * a request or the ending LID routed part of a response is empty.

	 * If we are at the start of the LID routed part, don't update the

	 * hop_ptr or hop_cnt.  See section 14.2.2, Vol 1 IB spec.

 Check to post send on QP or process locally */

 Check to post send on QP or process locally */

 No GRH for DR SMP */

			/*

			 * Reference MAD agent until receive

			 * side of local completion handled

 Treat like an incoming receive MAD */

			/*

			 * No receiving agent so drop packet and

			 * generate send completion.

 Reference MAD agent until send side of local completion handled */

 Queue local completion to local list */

 Allocate data segments. */

 Zero any padding */

 OPA MADs don't have to be the full 2048 bytes */

 Set WR ID to find mad_send_wr upon completion */

/*

 * ib_post_send_mad - Posts MAD(s) to the send queue of the QP associated

 *  with the registered client

 Walk list of send WRs and post each on send list */

		/*

		 * Save pointer to next work request to post in case the

		 * current one completes, and the user modifies the work

		 * request associated with the completion

 error */

 locally consumed */

 Timeout will be updated after send completes */

 Reference for work request to QP + response */

 Reference MAD agent until send completes */

 Fail send request */

/*

 * ib_free_recv_mad - Returns data buffers used to receive

 *  a MAD to the access layer

 Allocate management method table */

/*

 * Check to see if there are any methods still in use

/*

 * Check to see if there are any method tables for this class still in use

 Is there matching OUI for this vendor class ? */

 Remove any methods for this mad agent */

 Allocate management class table for "new" class version */

 Allocate method table for this management class */

 Allocate method table for this management class */

 Now, make sure methods are not already in use */

 Finally, add in methods being registered */

 Remove any methods for this mad agent */

 Now, check to see if there are any methods in use */

 If not, release management method table */

 "New" vendor (with OUI) class */

 Allocate mgmt vendor class table for "new" class version */

 Allocate table for this management vendor class */

 Is there matching OUI for this vendor class ? */

 OUI slot available ? */

 Allocate method table for this OUI */

 Now, make sure methods are not already in use */

 Finally, add in methods being registered */

 Remove any methods for this mad agent */

 Now, check to see if there are any methods in use */

 If not, release management method table */

	/*

	 * Was MAD registration request supplied

	 * with original registration ?

 Remove any methods for this mad agent */

 Now, check to see if there are any methods still in use */

 If not, release management method table */

 Any management classes left ? */

 If not, release management class table */

 normalize mgmt_class to vendor range 2 */

 Remove any methods for this mad agent */

			/*

			 * Now, check to see if there are

			 * any methods still in use

 If not, release management method table */

 Any OUIs left ? */

 If not, release vendor class table */

 Any other vendor classes left ? */

		/*

		 * Routing is based on high 32 bits of transaction ID

		 * of MAD.

		/*

		 * Routing is based on version, class, and method

		 * For "newer" vendor MADs, also based on OUI

 Find matching OUI */

 Make sure MAD base version is understood */

 Filter SMI packets sent to other than QP0 */

 CM attributes other than ClassPortInfo only use Send method */

 Filter GSI packets sent to QP0 */

 both requests, or both responses. GIDs different */

 Assume not equal, to avoid false positives. */

 one has GID, other does not.  Assume different */

 is request/response. */

		    /*

		     * Don't check GID for direct routed MADs.

		     * These might have permissive LIDs.

	/*

	 * It's possible to receive the response before we've

	 * been notified that the send has completed

		    /*

		     * Don't check GID for direct routed MADs.

		     * These might have permissive LIDs.

 Verify request has not been canceled */

 Complete corresponding request */

				/* user rmpp is in effect

				 * and this is an active RMPP MAD

				/* not user rmpp, revert to normal behavior and

				 * drop the mad

 Defined behavior is to complete response before request */

 don't forward */

 forward case for switches */

 don't forward */

 forward case for switches */

		/*

		 * Receive errors indicate that the QP has entered the error

		 * state - error handling/shutdown code will cleanup

 Setup MAD receive work completion from "normal" work completion */

 Validate MAD */

 Give driver "right of first refusal" on incoming MAD */

		/*

		 * recv is freed up in error cases in ib_mad_complete_recv

		 * or via recv_handler in ib_mad_complete_recv()

 Post another receive request for this QP */

 Reschedule a work item if we have a shorter timeout */

/*

 * Process a send work completion

 Remove send from MAD agent and notify client of completion */

 Release reference on agent taken when sending */

 Move queued send to the send queue */

	/*

	 * Send errors will transition the QP to SQE - move

	 * QP to RTS and repost flushed work requests

 Repost send */

 Transition QP to RTS and fail offending send */

 Empty wait list to prevent receives from finding a request */

 Report all cancelled requests */

			/*

			 * Defined behavior is to complete response

			 * before request

 Complete send */

/*

 * Allocate receive MADs and post receive WRs for them

 Initialize common scatter list fields */

 Initialize common receive WR fields */

 Allocate and map receive buffer */

 Post receive WR */

/*

 * Return all the posted receive MADs

 Remove from posted receive MAD list */

/*

 * Start the port

		/*

		 * PKey index for QP1 is irrelevant but

		 * one is needed for the Reset to Init transition

 It's worse than that! He's dead, Jim! */

 Use minimum queue sizes unless the CQ is resized */

/*

 * Open the port

 * Create the QP, PD, MR, and CQ if needed

 Create new device info */

/*

 * Close the port

 * If there are no classes using the port, free the port

 * resources (CQ, MR, PD, QP) and remove the port's info structure

 XXX: Handle deallocation of MAD registration tables */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

 Copyright (c) 2008-2019, IBM Corporation */

 not used */

/*

 * Reap one CQE from the CQ. Only used by kernel clients

 * during CQ normal operation. Might be called during CQ

 * flush for user mapped CQE array as well.

		/*

		 * During CQ flush, also user land CQE's may get

		 * reaped here, which do not hold a QP reference

		 * and do not qualify for memory extension verbs.

/*

 * siw_cq_flush()

 *

 * Flush all CQ elements.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

 Copyright (c) 2008-2019, IBM Corporation */

/*

 * Stag lookup is based on its index part only (24 bits).

 * The code avoids special Stag of zero and tries to randomize

 * STag values between 1 and SIW_STAG_MAX_INDEX.

 Set the STag index part */

/*

 * siw_mem_id2obj()

 *

 * resolves memory from stag given by id. might be called from:

 * o process context before sending out of sgl, or

 * o in softirq when resolving target memory

 Set the STag index part */

 make STag invalid visible asap */

/*

 * siw_check_mem()

 *

 * Check protection domain, STAG state, access permissions and

 * address range for memory object.

 *

 * @pd:		Protection Domain memory should belong to

 * @mem:	memory to be checked

 * @addr:	starting addr of mem

 * @perms:	requested access permissions

 * @len:	len of memory interval to be checked

 *

	/*

	 * check access permissions

	/*

	 * Check if access falls into valid memory interval.

/*

 * siw_check_sge()

 *

 * Check SGE for access rights in given interval

 *

 * @pd:		Protection Domain memory should belong to

 * @sge:	SGE to be checked

 * @mem:	location of memory reference within array

 * @perms:	requested access permissions

 * @off:	starting offset in SGE

 * @len:	len of memory interval to be checked

 *

 * NOTE: Function references SGE's memory object (mem->obj)

 * if not yet done. New reference is kept if check went ok and

 * released if check failed. If mem->obj is already valid, no new

 * lookup is being done and mem is not released it check fails.

 Check if user re-registered with different STag key */

		/*

		 * SIW_OP_INVAL_STAG and SIW_OP_REG_MR

		 * do not hold memory references

	/*

	 * Per RDMA verbs definition, an STag may already be in invalid

	 * state if invalidation is requested. So no state check here.

/*

 * Gets physical address backed by PBL element. Address is referenced

 * by linear byte offset into list of variably sized PB elements.

 * Optionally, provides remaining len within current element, and

 * current PBL index for later resume at same element.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

 Copyright (c) 2008-2019, IBM Corporation */

 transmit from user buffer, if possible */

/* Restrict usage of GSO, if hardware peer iwarp is unable to process

 * large packets. try_gso = true lets siw try to use local GSO,

 * if peer agrees.  Not using GSO severly limits siw maximum tx bandwidth.

 Attach siw also with loopback devices */

 We try to negotiate CRC on, if true */

 MPA CRC on/off enforced */

 Control TCP_NODELAY socket option */

 Select MPA version to be used during connection setup */

/* Selects MPA P2P mode (additional handshake during connection

 * setup, if true.

 Skip HT cores */

	/*

	 * Additional hardware support can be added here

	 * (e.g. ARPHRD_FDDI, ARPHRD_ATM, ...) - see

	 * <linux/if_arp.h> for type identifiers.

/*

 * Choose CPU with least number of active QP's from NUMA node of

 * TX interface.

 no CPU on this NUMA node */

 Skip any cores which have no TX thread */

		/*

		 * siw_qp_id2obj() increments object reference count

		/*

		 * The loopback device does not have a HW address,

		 * but connection mangagement lib expects gid != 0

	/*

	 * Current model (one-to-one device association):

	 * One Softiwarp device per net_device or, equivalently,

	 * per physical port.

 Disable TCP port mapping */

/*

 * Network link becomes unavailable. Mark all

 * affected QP's accordingly.

		/*

		 * Device registration now handled only by

		 * rdma netlink commands. So it shall be impossible

		 * to end up here with a valid siw device.

	/*

	 * Todo: Below netdev events are currently not handled.

/*

 * siw_init_module - Initialize Softiwarp module and register with netdev

 *                   subsystem.

	/*

	 * Locate CRC32 algorithm. If unsuccessful, fail

	 * loading siw only, if CRC is required.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

 Copyright (c) 2008-2019, IBM Corporation */

	/*

	 * Must be page aligned

 Revisit atomic caps if RFC 7306 gets supported */

	/*

	 * All zero

	 *

	 * attr->lid = 0;

	 * attr->bad_pkey_cntr = 0;

	 * attr->qkey_viol_cntr = 0;

	 * attr->sm_lid = 0;

	 * attr->lmc = 0;

	 * attr->max_vl_num = 0;

	 * attr->sm_sl = 0;

	 * attr->subnet_timeout = 0;

	 * attr->init_type_repy = 0;

 subnet_prefix == interface_id == 0; */

/*

 * siw_create_qp()

 *

 * Create QP of requested size on given device.

 *

 * @qp:		Queue pait

 * @attrs:	Initial QP attributes.

 * @udata:	used to provide QP ID, SQ and RQ size back to user.

	/*

	 * NOTE: we allow for zero element SQ and RQ WQE's SGL's

	 * but not for a QP unable to hold any WQE (SQ + RQ)

	/* All queue indices are derived from modulo operations

	 * on a free running 'get' (consumer) and 'put' (producer)

	 * unsigned counter. Having queue sizes at power of two

	 * avoids handling counter wrap around.

 Zero sized SQ is not supported */

		/*

		 * SRQ support.

		 * Verbs 6.3.7: ignore RQ size, if SRQ present

		 * Verbs 6.3.5: do not check PD of SRQ against PD of QP

 Make those two tunables fixed for now. */

/*

 * Minimum siw_query_qp() verb interface.

 *

 * @qp_attr_mask is not used but all available information is provided

	/*

	 * Mark QP as in process of destruction to prevent from

	 * any async callbacks to RDMA core

/*

 * siw_copy_inline_sgl()

 *

 * Prepare sgl of inlined data for sending. For userland callers

 * function checks if given buffer addresses and len's are within

 * process context bounds.

 * Data from all provided sge's are copied together into the wqe,

 * referenced by a single sge.

 Complete SQ WR's without processing */

 Complete RQ WR's without processing */

/*

 * siw_post_send()

 *

 * Post a list of S-WR's to a SQ.

 *

 * @base_qp:	Base QP contained in siw QP

 * @wr:		Null terminated list of user WR's

 * @bad_wr:	Points to failing WR in case of synchronous failure.

	/*

	 * Try to acquire QP state lock. Must be non-blocking

	 * to accommodate kernel clients needs.

			/*

			 * ERROR state is final, so we can be sure

			 * this state will not change as long as the QP

			 * exists.

			 *

			 * This handles an ib_drain_sq() call with

			 * a concurrent request to set the QP state

			 * to ERROR.

			/*

			 * Immediately flush this WR to CQ, if QP

			 * is in ERROR state. SQ is guaranteed to

			 * be empty, so WR complets in-order.

			 *

			 * Typically triggered by ib_drain_sq().

			/*

			 * iWarp restricts RREAD sink to SGL containing

			 * 1 SGE only. we could relax to SGL with multiple

			 * elements referring the SAME ltag or even sending

			 * a private per-rreq tag referring to a checked

			 * local sgl with MULTIPLE ltag's.

			/*

			 * NOTE: zero length RREAD is allowed!

 make SQE only valid after completely written */

	/*

	 * Send directly if SQ processing is not in progress.

	 * Eventual immediate errors (rv < 0) do not affect the involved

	 * RI resources (Verbs, 8.3.1) and thus do not prevent from SQ

	 * processing, if new work is already pending. But rv must be passed

	 * to caller.

	/*

	 * Immediate error

/*

 * siw_post_receive()

 *

 * Post a list of R-WR's to a RQ.

 *

 * @base_qp:	Base QP contained in siw QP

 * @wr:		Null terminated list of user WR's

 * @bad_wr:	Points to failing WR in case of synchronous failure.

	/*

	 * Try to acquire QP state lock. Must be non-blocking

	 * to accommodate kernel clients needs.

			/*

			 * ERROR state is final, so we can be sure

			 * this state will not change as long as the QP

			 * exists.

			 *

			 * This handles an ib_drain_rq() call with

			 * a concurrent request to set the QP state

			 * to ERROR.

			/*

			 * Immediately flush this WR to CQ, if QP

			 * is in ERROR state. RQ is guaranteed to

			 * be empty, so WR complets in-order.

			 *

			 * Typically triggered by ib_drain_rq().

	/*

	 * Serialize potentially multiple producers.

	 * Not needed for single threaded consumer side.

 make sure RQE is completely written before valid */

/*

 * siw_create_cq()

 *

 * Populate CQ of requested size

 *

 * @base_cq: CQ as allocated by RDMA midlayer

 * @attr: Initial CQ attributes

 * @udata: relates to user context

/*

 * siw_poll_cq()

 *

 * Reap CQ entries if available and copy work completion status into

 * array of WC's provided by caller. Returns number of reaped CQE's.

 *

 * @base_cq:	Base CQ contained in siw CQ.

 * @num_cqe:	Maximum number of CQE's to reap.

 * @wc:		Array of work completions to be filled by siw.

/*

 * siw_req_notify_cq()

 *

 * Request notification for new CQE's added to that CQ.

 * Defined flags:

 * o SIW_CQ_NOTIFY_SOLICITED lets siw trigger a notification

 *   event if a WQE with notification flag set enters the CQ

 * o SIW_CQ_NOTIFY_NEXT_COMP lets siw trigger a notification

 *   event if a WQE enters the CQ.

 * o IB_CQ_REPORT_MISSED_EVENTS: return value will provide the

 *   number of not reaped CQE's regardless of its notification

 *   type and current or new CQ notification settings.

 *

 * @base_cq:	Base CQ contained in siw CQ.

 * @flags:	Requested notification flags.

		/*

		 * Enable CQ event for next solicited completion.

		 * and make it visible to all associated producers.

		/*

		 * Enable CQ event for any signalled completion.

		 * and make it visible to all associated producers.

/*

 * siw_dereg_mr()

 *

 * Release Memory Region.

 *

 * @base_mr: Base MR contained in siw MR.

 * @udata: points to user context, unused.

/*

 * siw_reg_user_mr()

 *

 * Register Memory Region.

 *

 * @pd:		Protection Domain

 * @start:	starting address of MR (virtual address)

 * @len:	len of MR

 * @rnic_va:	not used by siw

 * @rights:	MR access rights

 * @udata:	user buffer to communicate STag and Key.

 Just used to count number of pages being mapped */

 Merge PBL entries if adjacent */

/*

 * siw_get_dma_mr()

 *

 * Create a (empty) DMA memory region, where no umem is attached.

/*

 * siw_create_srq()

 *

 * Create Shared Receive Queue of attributes @init_attrs

 * within protection domain given by @pd.

 *

 * @base_srq:	Base SRQ contained in siw SRQ.

 * @init_attrs:	SRQ init attributes.

 * @udata:	points to user context

/*

 * siw_modify_srq()

 *

 * Modify SRQ. The caller may resize SRQ and/or set/reset notification

 * limit and (re)arm IB_EVENT_SRQ_LIMIT_REACHED notification.

 *

 * NOTE: it is unclear if RDMA core allows for changing the MAX_SGE

 * parameter. siw_modify_srq() does not check the attrs->max_sge param.

 resize request not yet supported */

/*

 * siw_query_srq()

 *

 * Query SRQ attributes.

/*

 * siw_destroy_srq()

 *

 * Destroy SRQ.

 * It is assumed that the SRQ is not referenced by any

 * QP anymore - the code trusts the RDMA core environment to keep track

 * of QP references.

/*

 * siw_post_srq_recv()

 *

 * Post a list of receive queue elements to SRQ.

 * NOTE: The function does not check or lock a certain SRQ state

 *       during the post operation. The code simply trusts the

 *       RDMA core environment.

 *

 * @base_srq:	Base SRQ contained in siw SRQ

 * @wr:		List of R-WR's

 * @bad_wr:	Updated to failing WR if posting fails.

	/*

	 * Serialize potentially multiple producers.

	 * Also needed to serialize potentially multiple

	 * consumers.

 Make sure S-RQE is completely written before valid */

	/*

	 * Do not report asynchronous errors on QP which gets

	 * destroyed via verbs interface (siw_destroy_qp())

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

          Fredy Neeser */

          Greg Joyce <greg@opengridcomputing.com> */

 Copyright (c) 2008-2019, IBM Corporation */

 Copyright (c) 2017, Open Grid Computing, Inc. */

/*

 * Set to any combination of

 * MPA_V2_RDMA_NO_RTR, MPA_V2_RDMA_READ_RTR, MPA_V2_RDMA_WRITE_RTR

	/*

	 * Check if first frame was successfully processed.

	 * Signal connection full establishment if yes.

	 * Failed data processing would have already scheduled

	 * connection drop.

 not needed again */

 kfree(NULL) is safe */

/*

 * siw_cm_upcall()

 *

 * Upcall to IWCM to inform about async connection events

 Signal IRD and ORD */

 Signal negotiated IRD/ORD values we will use */

 Signal private data and address information */

			/*

			 * hand over MPA private data

 Hide MPA V2 IRD/ORD control */

/*

 * siw_qp_cm_drop()

 *

 * Drops established LLP connection if present and not already

 * scheduled for dropping. Called from user context, SQ workqueue

 * or receive IRQ. Caller signals if socket can be immediately

 * closed (basically, if not in IRQ).

			/*

			 * Immediately close socket

/*

 * Expects params->pd_len in host byte order

/*

 * Receive MPA Request/Reply header.

 *

 * Returns 0 if complete MPA Request/Reply header including

 * eventual private data was received. Returns -EAGAIN if

 * header was partially received or negative error code otherwise.

 *

 * Context: May be called in process context only

	/*

	 * At least the MPA Request/Reply header (frame not including

	 * private data) has been received.

	 * Receive (or continue receiving) any private data.

		/*

		 * We must have hdr->params.pd_len == 0 and thus received a

		 * complete MPA Request/Reply frame.

		 * Check against peer protocol violation.

	/*

	 * At this point, we must have hdr->params.pd_len != 0.

	 * A private data buffer gets allocated if hdr->params.pd_len != 0.

/*

 * siw_proc_mpareq()

 *

 * Read MPA Request from socket and signal new connection to IWCM

 * if success. Caller must hold lock on corresponding listening CEP.

 allow for 0, 1, and 2 only */

 Prepare for sending MPA reply */

		/*

		 * MPA version 2 must signal IRD/ORD values and P2P mode

		 * in private data if header flag MPA_RR_FLAG_ENHANCED

		 * is set.

 MPA Markers: currently not supported. Marker TX to be added. */

		/*

		 * RFC 5044, page 27: CRC MUST be used if peer requests it.

		 * siw specific: 'mpa_crc_strict' parameter to reject

		 * connection with CRC if local CRC off enforced by

		 * 'mpa_crc_strict' module parameter.

 Enable CRC if requested by module parameter */

		/*

		 * Peer requested ORD becomes requested local IRD,

		 * peer requested IRD becomes requested local ORD.

		 * IRD and ORD get limited by global maximum values.

 May get overwritten by locally negotiated values */

		/*

		 * Support for peer sent zero length Write or Read to

		 * let local side enter RTS. Writes are preferred.

		 * Sends would require pre-posting a Receive and are

		 * not supported.

		 * Propose zero length Write if none of Read and Write

		 * is indicated.

 Keep reference until IWCM accepts/rejects */

 allow for 0, 1,  and 2 only */

			/*

			 * Protocol failure: The responder MUST reply with

			 * MPA version 2 and MUST set MPA_RR_FLAG_ENHANCED.

		/*

		 * Always report negotiated peer values to user,

		 * even if IRD/ORD negotiation failed

			/*

			 * If the initiator IRD is insuffient for the

			 * responder ORD, send a TERM.

		/*

		 * Check if we requested P2P mode, and if peer agrees

				/*

				 * We requested RTR mode(s), but the peer

				 * did not pick any mode we support.

 Move socket RX/TX under QP control */

 Send extra RDMA frame to trigger peer RTS if negotiated */

/*

 * siw_accept_newconn - accept an incoming pending connection

 *

 debug only. should disappear */

	/*

	 * 4: Allocate a sufficient number of work elements

	 * to allow concurrent handling of local + peer close

	 * events, MPA header processing + MPA timeout.

	/*

	 * Copy saved socket callbacks from listening CEP

	 * and assign new socket with new CEP

		/*

		 * Connection already aborted by peer..?

	/*

	 * See siw_proc_mpareq() etc. for the use of new_cep->listen_cep.

		/*

		 * MPA REQ already queued

			/*

			 * CEP already moved out of MPA handshake.

			 * any connection management already done.

			 * silently ignore the mpa packet.

		/*

		 * QP scheduled LLP close

				/*

				 * MPA reply not received, but connection drop

				/*

				 * NOTE: IW_CM_EVENT_DISCONNECT is given just

				 *       to transition IWCM into CLOSING.

			/*

			 * for other states there is no connection

			 * known to the IWCM.

				/*

				 * Wait for the ulp/CM to call accept/reject

				/*

				 * Socket close before MPA request received.

			/*

			 * MPA request timed out:

			 * Hide any partially received private data and signal

			 * timeout

			/*

			 * No MPA request received after peer TCP stream setup.

			/*

			 * Serialize a potential race with application

			 * closing the QP and calling siw_qp_cm_drop()

 endpoint already disassociated */

		/*

		 * handle accepting socket as special case where only

		 * new connection is possible

	/*

	 * Make address available again asap.

	/*

	 * Respect any iwarp port mapping: Use mapped remote address

	 * if valid. Local address must not be mapped, since siw

	 * uses kernel TCP stack.

	/*

	 * NOTE: For simplification, connect() is called in blocking

	 * mode. Might be reconsidered for async connection setup at

	 * TCP level.

 Associate QP with CEP */

 siw_qp_get(qp) already done by QP lookup */

	/*

	 * 4: Allocate a sufficient number of work elements

	 * to allow concurrent handling of local + peer close

	 * events, MPA header processing + MPA timeout.

	/*

	 * Associate CEP with socket

	/*

	 * Set MPA Request bits: CRC if required, no MPA Markers,

	 * MPA Rev. according to module parameter 'mpa_version', Key 'Request'.

 Adjust also module parameter */

	/*

	 * If MPA version == 2:

	 * o Include ORD and IRD.

	 * o Indicate peer-to-peer mode, if required by module

	 *   parameter 'peer_to_peer'.

 Remember own P2P mode requested */

	/*

	 * Reset private data.

/*

 * siw_accept - Let SoftiWARP accept an RDMA connection request

 *

 * @id:		New connection management id to be used for accepted

 *		connection request

 * @params:	Connection parameters provided by ULP for accepting connection

 *

 * Transition QP to RTS state, associate new CM id @id with accepted CEP

 * and get prepared for TCP input by installing socket callbacks.

 * Then send MPA Reply and generate the "connection established" event.

 * Socket callbacks must be installed before sending MPA Reply, because

 * the latter may cause a first RDMA message to arrive from the RDMA Initiator

 * side very quickly, at which time the socket callbacks must be ready.

 Free lingering inbound private data */

		/*

		 * Signal back negotiated IRD and ORD values

 Associate QP with CEP */

 siw_qp_get(qp) already done by QP lookup */

 Move socket RX/TX under QP control */

/*

 * siw_reject()

 *

 * Local connection reject case. Send private data back to peer,

 * close connection and dereference connection id.

 put last reference */

 reject */

/*

 * siw_create_listen - Create resources for a listener's IWCM ID @id

 *

 * Starts listen on the socket address id->local_addr.

 *

	/*

	 * Allow binding local port when still in TIME_WAIT from last close.

 For wildcard addr, limit binding to current device only */

 For wildcard addr, limit binding to current device only */

	/*

	 * In case of a wildcard rdma_listen on a multi-homed device,

	 * a listener's IWCM id is associated with more than one listening CEP.

	 *

	 * We currently use id->provider_data in three different ways:

	 *

	 * o For a listener's IWCM id, id->provider_data points to

	 *   the list_head of the list of listening CEPs.

	 *   Uses: siw_create_listen(), siw_destroy_listen()

	 *

	 * o For each accepted passive-side IWCM id, id->provider_data

	 *   points to the CEP itself. This is a consequence of

	 *   - siw_cm_upcall() setting event.provider_data = cep and

	 *   - the IWCM's cm_conn_req_handler() setting provider_data of the

	 *     new passive-side IWCM id equal to event.provider_data

	 *   Uses: siw_accept(), siw_reject()

	 *

	 * o For an active-side IWCM id, id->provider_data is not used at all.

	 *

	/*

	 * In case of a wildcard rdma_listen on a multi-homed device,

	 * a listener's IWCM id is associated with more than one listening CEP.

	/*

	 * create_single_workqueue for strict ordering

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

 Copyright (c) 2008-2019, IBM Corporation */

/*

 * siw_rx_umem()

 *

 * Receive data of @len into target referenced by @dest_addr.

 *

 * @srx:	Receive Context

 * @umem:	siw representation of target memory

 * @dest_addr:	user virtual address

 * @len:	number of bytes to place

 siw internal error */

				/*

				 * Do CRC on original, not target buffer.

				 * Some user land applications may

				 * concurrently write the target buffer,

				 * which would yield a broken CRC.

				 * Walking the skb twice is very ineffcient.

				 * Folding the CRC into skb_copy_bits()

				 * would be much better, but is currently

				 * not supported.

/*

 * siw_rresp_check_ntoh()

 *

 * Check incoming RRESP fragment header against expected

 * header values and update expected values for potential next

 * fragment.

 *

 * NOTE: This function must be called only if a RRESP DDP segment

 *       starts but not for fragmented consecutive pieces of an

 *       already started DDP segment.

	/* Below checks extend beyond the semantics of DDP, and

	 * into RDMAP:

	 * We check if the read response matches exactly the

	 * read request which was send to the remote peer to

	 * trigger this read response. RFC5040/5041 do not

	 * always have a proper error code for the detected

	 * error cases. We choose 'base or bounds error' for

	 * cases where the inbound STag is valid, but offset

	 * or length do not match our response receive state.

/*

 * siw_write_check_ntoh()

 *

 * Check incoming WRITE fragment header against expected

 * header values and update expected values for potential next

 * fragment

 *

 * NOTE: This function must be called only if a WRITE DDP segment

 *       starts but not for fragmented consecutive pieces of an

 *       already started DDP segment.

/*

 * siw_send_check_ntoh()

 *

 * Check incoming SEND fragment header against expected

 * header values and update expected MSN if no next

 * fragment expected

 *

 * NOTE: This function must be called only if a SEND DDP segment

 *       starts but not for fragmented consecutive pieces of an

 *       already started DDP segment.

 initialize user memory write position */

 only valid for SEND_INV and SEND_SE_INV operations */

 can be re-used by appl */

 Test SRQ limit */

/*

 * siw_proc_send:

 *

 * Process one incoming SEND and place data into memory referenced by

 * receive wqe.

 *

 * Function supports partially received sends (suspending/resuming

 * current receive wqe processing)

 *

 * return value:

 *	0:       reached the end of a DDP segment

 *	-EAGAIN: to be called again to finish the DDP segment

 all data bytes available */

 sum of data bytes rcvd */

 zero length SEND */

 A zero length SEND will skip below loop */

 data bytes avail for SGE */

 just skip empty sge's */

		/*

		 * check with QP's PD if no SRQ present, SRQ's PD otherwise

/*

 * siw_proc_write:

 *

 * Place incoming WRITE after referencing and checking target buffer



 * Function supports partially received WRITEs (suspending/resuming

 * current receive processing)

 *

 * return value:

 *	0:       reached the end of a DDP segment

 *	-EAGAIN: to be called again to finish the DDP segment

 zero length WRITE */

	/*

	 * Check if application re-registered memory with different

	 * key field of STag.

/*

 * Inbound RREQ's cannot carry user data.

/*

 * siw_init_rresp:

 *

 * Process inbound RDMA READ REQ. Produce a pseudo READ RESPONSE WQE.

 * Put it at the tail of the IRQ, if there is another WQE currently in

 * transmit processing. If not, make it the current WQE to be processed

 * and schedule transmit processing.

 *

 * Can be called from softirq context and from process

 * context (RREAD socket loopback case!)

 *

 * return value:

 *	0:      success,

 *		failure code otherwise

		/*

		 * immediately schedule READ response w/o

		 * consuming IRQ entry: IRQ must be empty.

		/* Keep aside message sequence number for potential

		 * error reporting during Read Response generation.

 RRESP now valid as current TX wqe or placed into IRQ */

/*

 * Only called at start of Read.Resonse processing.

 * Transfer pending Read from tip of ORQ into currrent rx wqe,

 * but keep ORQ entry valid until Read.Response processing done.

 * No Queue locking needed.

 make sure ORQ indices are current */

 RRESP is a TAGGED RDMAP operation */

 make sure WQE is completely written before valid */

/*

 * siw_proc_rresp:

 *

 * Place incoming RRESP data into memory referenced by RREQ WQE

 * which is at the tip of the ORQ

 *

 * Function supports partially received RRESP's (suspending/resuming

 * current receive processing)

		/*

		 * fetch pending RREQ from orq

 zero length RRESPONSE */

 there is only one */

		/*

		 * check target memory which resolves memory on first fragment

	/*

	 * Receive remaining pieces of TERM if indicated

	/* Do not take the effort to reassemble a network fragmented

	 * TERM message

 Again, no network fragmented TERM's */

	/*

	 * CRC32 is computed, transmitted and received directly in NBO,

	 * so there's never a reason to convert byte order.

		/*

		 * copy a mimimum sized (tagged) DDP frame control part

	/*

	 * Figure out len of current hdr: variable length of

	 * iwarp hdr may force us to copy hdr information in

	 * two steps. Only tagged DDP messages are already

	 * completely received.

	/*

	 * DDP/RDMAP header receive completed. Check if the current

	 * DDP segment starts a new RDMAP message or continues a previously

	 * started RDMAP message.

	 *

	 * Alternating reception of DDP segments (or FPDUs) from incomplete

	 * tagged and untagged RDMAP messages is supported, as long as

	 * the current tagged or untagged message gets eventually completed

	 * w/o intersection from another message of the same type

	 * (tagged/untagged). E.g., a WRITE can get intersected by a SEND,

	 * but not by a READ RESPONSE etc.

		/*

		 * Restart CRC computation

			/*

			 * The last inbound RDMA operation of same type

			 * (tagged or untagged) is left unfinished.

			 * To complete it in error, make it the current

			 * operation again, even with the header already

			 * overwritten. For error handling, only the opcode

			 * and current rx context are relevant.

 free current orq entry */

 resume SQ processing */

/*

 * siw_rdmap_complete()

 *

 * Complete processing of an RDMA message after receiving all

 * DDP segmens or ABort processing after encountering error case.

 *

 *   o SENDs + RRESPs will need for completion,

 *   o RREQs need for  READ RESPONSE initialization

 *   o WRITEs need memory dereferencing

 *

 * TODO: Failed WRITEs need local error to be surfaced.

		/*

		 * Handle STag invalidation request

 possible RREQ in ORQ left untouched */

			/*

			 * Handle any STag invalidation request

		/*

		 * All errors turn the wqe into signalled.

 Disable current ORQ element */

		/*

		 * Free References from memory object if

		 * attached to receive context (inbound WRITE).

		 * While a zero-length WRITE is allowed,

		 * no memory reference got created.

/*

 * siw_tcp_rx_data()

 *

 * Main routine to consume inbound TCP payload

 *

 * @rd_desc:	read descriptor

 * @skb:	socket buffer

 * @off:	offset in skb

 * @len:	skb->len - offset : payload in skb

 Do not process any more data */

			/*

			 * Another data fragment of the same DDP segment.

			 * Setting first_ddp_seg = 0 avoids repeating

			 * initializations that shall occur only once per

			 * DDP segment.

			/*

			 * Headers will be checked by the opcode-specific

			 * data receive function below.

			/*

			 * read CRC + any padding

				/*

				 * FPDU completed.

				 * complete RDMAP message if last fragment

 more frags */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

 Copyright (c) 2008-2019, IBM Corporation */

/*

 * Copy short payload at provided destination payload address

 Kernel client using kva */

/*

 * siw_qp_prepare_tx()

 *

 * Prepare tx state for sending out one fpdu. Builds complete pkt

 * if no user data or only immediate data are present.

 *

 * returns PKT_COMPLETE if complete pkt built, PKT_FRAGMENTED otherwise.

 NBO */

 Add pad, if needed */

 advance CRC location after payload */

		/*

		 * Do complete CRC if enabled and short packet

	/*

	 * Allow direct sending out of user buffer if WR is non signalled

	 * and payload is over threshold.

	 * Per RDMA verbs, the application should not change the send buffer

	 * until the work completed. In iWarp, work completion is only

	 * local delivery to TCP. TCP may reuse the buffer for

	 * retransmission. Changing unsent data also breaks the CRC,

	 * if applied.

/*

 * Send out one complete control type FPDU, or header of FPDU carrying

 * data. Used for fixed sized packets like Read.Requests or zero length

 * SENDs, WRITEs, READ.Responses, or header only.

/*

 * 0copy TCP transmit interface: Use do_tcp_sendpages.

 *

 * Using sendpage to push page by page appears to be less efficient

 * than using sendmsg, even if data are copied.

 *

 * A general performance limitation might be the extra four bytes

 * trailer checksum segment to be pushed after user data.

/*

 * siw_0copy_tx()

 *

 * Pushes list of pages to TCP socket. If pages from multiple

 * SGE's, all referenced pages of each SGE are pushed in one

 * shot.

	/*

	 * Work backwards through the array to honor the kmap_local_page()

	 * ordering requirements.

/*

 * siw_tx_hdt() tries to push a complete packet to TCP where all

 * packet fragments are referenced by the elements of one iovec.

 * For the data portion, each involved page must be referenced by

 * one extra element. All sge's data can be non-aligned to page

 * boundaries. Two more elements are referencing iWARP header

 * and trailer:

 * MAX_ARRAY = 64KB/PAGE_SIZE + 1 + (2 * (SIW_MAX_SGE - 1) + HDR + TRL

/*

 * Write out iov referencing hdr, data and trailer of current FPDU.

 * Update transmit state dependent on write return status

 walk the list of SGE's */

			/*

			 * tx from kernel virtual address: either inline data

			 * or memory region with assigned kernel buffer

 Remember for later kunmap() */

 Update SGE variables at end of SGE */

 trailer */

 Not even complete hdr pushed or negative rv */

 all user data pushed to TCP or no data to push */

 Save the current state for next tx */

 all pushed */

 Maybe some user data pushed to TCP */

			/*

			 * Some bytes out. Recompute tx state based

			 * on old state and bytes pushed

 Loopback may give odd numbers */

/*

 * siw_prepare_fpdu()

 *

 * Prepares transmit context to send out one FPDU if FPDU will contain

 * user data and user data are not immediate data.

 * Computes maximum FPDU length to fill up TCP MSS if possible.

 *

 * @qp:		QP from which to transmit

 * @wqe:	Current WQE causing transmission

 *

 * TODO: Take into account real available sendspace on socket

 *       to avoid header misalignment due to send pausing within

 *       fpdu transmission

	/*

	 * Update target buffer offset if any

 Untagged message */

 Tagged message */

 Trim DDP payload to fit into current TCP segment */

	/*

	 * Init MPA CRC computation

/*

 * siw_check_sgl_tx()

 *

 * Check permissions for a list of SGE's (SGL).

 * A successful check will have all memory referenced

 * for transmission resolved and assigned to the WQE.

 *

 * @pd:		Protection Domain SGL should belong to

 * @wqe:	WQE to be checked

 * @perms:	requested access permissions

 *

		/*

		 * rdma verbs: do not check stag for a zero length sge

/*

 * siw_qp_sq_proc_tx()

 *

 * Process one WQE which needs transmission on the wire.

				/*

				 * Reference memory to be tx'd w/o checking

				 * access for LOCAL_READ permission, since

				 * not defined in RDMA core.

			/*

			 * End current TCP segment, if SQ runs empty,

			 * or siw_tcp_nagle is not set, or we bail out

			 * soon due to no burst credit left.

		/*

		 * One segment sent. Processing completed if last

		 * segment, Do next segment otherwise.

			/*

			 * Verbs, 6.4.: Try stopping sending after a full

			 * DDP segment if the connection goes down

			 * (== peer halfclose)

 Refresh STag since user may have changed key part */

/*

 * siw_qp_sq_process()

 *

 * Core TX path routine for RDMAP/DDP/MPA using a TCP kernel socket.

 * Sends RDMAP payload for the current SQ WR @wqe of @qp in one or more

 * MPA FPDUs, each containing a DDP segment.

 *

 * SQ processing may occur in user context as a result of posting

 * new WQE's or from siw_sq_work_handler() context. Processing in

 * user context is limited to non-kernel verbs users.

 *

 * SQ processing may get paused anytime, possibly in the middle of a WR

 * or FPDU, if insufficient send space is available. SQ processing

 * gets resumed from siw_sq_work_handler(), if send space becomes

 * available again.

 *

 * Must be called with the QP state read-locked.

 *

 * Note:

 * An outbound RREQ can be satisfied by the corresponding RRESP

 * _before_ it gets assigned to the ORQ. This happens regularly

 * in RDMA READ via loopback case. Since both outbound RREQ and

 * inbound RRESP can be handled by the same CPU, locking the ORQ

 * is dead-lock prone and thus not an option. With that, the

 * RREQ gets assigned to the ORQ _before_ being sent - see

 * siw_activate_tx() - and pulled back in case of send failure.

	/*

	 * Stop QP processing if SQ state changed

		/*

		 * WQE processing done

			/*

			 * already enqueued to ORQ queue

		/*

		 * WQE processing failed.

		 * Verbs 8.3.2:

		 * o It turns any WQE into a signalled WQE.

		 * o Local catastrophic error must be surfaced

		 * o QP must be moved into Terminate state: done by code

		 *   doing socket state change processing

		 *

		 * o TODO: Termination message must be sent.

		 * o TODO: Implement more precise work completion errors,

		 *         see enum ib_wc_status in ib_verbs.h

		/*

		 * RREQ may have already been completed by inbound RRESP!

 Cleanup pending entry in ORQ */

		/*

		 * immediately suspends further TX processing

		/*

		 * llist_del_all returns a list with newest entry first.

		 * Re-order list for fairness among QP's.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

 Authors: Bernard Metzler <bmt@zurich.ibm.com> */

 Copyright (c) 2008-2019, IBM Corporation */

/*

 * iWARP (RDMAP, DDP and MPA) parameters as well as Softiwarp settings on a

 * per-RDMAP message basis. Please keep order of initializer. All MPA len

 * is initialized to minimum packet size.

 RDMAP_RDMA_WRITE */

 RDMAP_RDMA_READ_REQ */

 RDMAP_RDMA_READ_RESP */

 RDMAP_SEND */

 RDMAP_SEND_INVAL */

 RDMAP_SEND_SE */

 RDMAP_SEND_SE_INVAL */

 RDMAP_TERMINATE */

			/*

			 * Implements data receive operation during

			 * socket callback. TCP gracefully catches

			 * the case where there is nothing to receive

			 * (not calling siw_tcp_rx_data() then).

	/*

	 * SIW_QP_STATE_CLOSING:

	 *

	 * This is a forced close. shall the QP be moved to

	 * ERROR or IDLE ?

	/*

	 * Dereference closing CEP

/*

 * socket callback routine informing about newly available send space.

 * Function schedules SQ work for processing SQ items.

/*

 * Send a non signalled READ or WRITE to peer side as negotiated

 * with MPAv2 P2P setup protocol. The work request is only created

 * as a current active WR and does not consume Send Queue space.

 *

 * Caller must hold QP state lock.

	/*

	 * While it must not be checked for inbound zero length

	 * READ/WRITE, some HW may treat STag 0 special.

/*

 * Map memory access error to DDP tagged error

		/*

		 * RFC 5041 (DDP) lacks an ecode for insufficient access

		 * permissions. 'Invalid STag' seem to be the closest

		 * match though.

/*

 * Map memory access error to RDMAP protection error

/*

 * Send a TERMINATE message, as defined in RFC's 5040/5041/5044/6581.

 * Sending TERMINATE messages is best effort - such messages

 * can only be send if the QP is still connected and it does

 * not have another outbound message in-progress, i.e. the

 * TERMINATE message must not interfer with an incomplete current

 * transmit operation.

 QP not yet in RTS. Take socket from connection end point */

 No additional DDP/RDMAP header to be included */

			/*

			 * Complete RDMAP frame will get attached, and

			 * DDP segment length is valid

				/* Inbound RREQ error, detected during

				 * RRESP creation. Take state from

				 * current TX work queue element to

				 * reconstruct peers RREQ.

 Provide RREQ's MSN as kept aside */

				/* Take RDMAP/DDP information from

				 * current (failed) inbound frame.

 SEND type */

			/* Do not report DDP hdr information if packet

			 * layout is unknown

 Only DDP frame will get attached */

		/* Report error encountered while DDP processing.

		 * This can only happen as a result of inbound

		 * DDP processing

		/* Do not report DDP hdr information if packet

		 * layout is unknown

 Adjust DDP Segment Length parameter, if valid */

/*

 * Handle all attrs other than state

		/*

		 * Initialize iWARP TX state

		/*

		 * Initialize iWARP RX state

		/*

		 * init IRD free queue, caller has already checked

		 * limits.

		/*

		 * Verbs: move to IDLE if SQ and ORQ are empty.

		 * Move to ERROR otherwise. But first of all we must

		 * close the connection. So we keep CLOSING or ERROR

		 * as a transient state, schedule connection drop work

		 * and wait for the socket state change upcall to

		 * come back closed.

		/*

		 * This is an emergency close.

		 *

		 * Any in progress transmit operation will get

		 * cancelled.

		 * This will likely result in a protocol failure,

		 * if a TX operation is in transit. The caller

		 * could unconditional wait to give the current

		 * operation a chance to complete.

		 * Esp., how to handle the non-empty IRQ case?

		 * The peer was asking for data transfer at a valid

		 * point in time.

		/*

		 * The LLP may already moved the QP to closing

		 * due to graceful peer close init

		/*

		 * QP was moved to CLOSING by LLP event

		 * not yet seen by user.

/*

 * Caller must hold qp->state_lock

 First copy SQE to kernel private memory */

 A READ cannot be fenced */

 We negotiated not to send READ req's */

			/*

			 * Make an immediate copy in ORQ to be ready

			 * to process loopback READ reply

 Clear SQE, can be re-used by application */

/*

 * Must be called with SQ locked.

 * To avoid complete SQ starvation by constant inbound READ requests,

 * the active IRQ will not be served after qp->irq_burst, if the

 * SQ has pending work.

	/*

	 * Avoid local WQE processing starvation in case

	 * of constant inbound READ request stream

 start READ RESPONSE */

	/* Retain original RREQ's message sequence number for

	 * potential error reporting cases.

 mark current IRQ entry free */

/*

 * Check if current CQ state qualifies for calling CQ completion

 * handler. Must be called with CQ lock held.

 Read application shared notification state */

		/*

		 * CQ notification is one-shot: Since the

		 * current CQE causes user notification,

		 * the CQ gets dis-aremd and must be re-aremd

		 * by the user for a new notification.

 mark CQE valid for application */

 recycle SQE */

 recycle SQE */

 mark CQE valid for application */

 recycle RQE */

 recycle RQE */

/*

 * siw_sq_flush()

 *

 * Flush SQ and ORRQ entries to CQ.

 *

 * Must be called with QP state write lock held.

 * Therefore, SQ and ORQ lock must not be taken.

	/*

	 * Start with completing any work currently on the ORQ

	/*

	 * Flush an in-progress WQE if present

			/*

			 * An in-progress Read Request is already in

			 * the ORQ

	/*

	 * Flush the Send Queue

			/*

			 * Shall IB_EVENT_SQ_DRAINED be supressed if work

			 * completion fails?

/*

 * siw_rq_flush()

 *

 * Flush recv queue entries to CQ. Also

 * takes care of pending active tagged and untagged

 * inbound transfers, which have target memory

 * referenced.

 *

 * Must be called with QP state write lock held.

 * Therefore, RQ lock must not be taken.

	/*

	 * Flush an in-progress untagged operation if present

	/*

	 * Flush the Receive Queue

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

	/* pick a source UDP port number for this QP based on

	 * the source QPN. this spreads traffic for different QPs

	 * across different NIC RX queues (while using a single

	 * flow for a given QP to maintain packet order).

	 * the port number must be in the Dynamic Ports range

	 * (0xc000 - 0xffff).

 These caps are limited by rxe_qp_chk_cap() done by the caller */

 Can't be set for UD/UC in modify_qp */

 called by the create qp verb */

 called by the query qp verb */

/* called by the modify qp verb, this routine checks all the parameters before

 * making any changes

 move the qp to the reset state */

 stop tasks from running */

 stop request/comp */

 move qp to the reset state */

	/* let state machines reset themselves drain work and packet queues

	 * etc.

 cleanup attributes */

 reenable tasks */

 drain the send queue */

 move the qp to the error state */

 drain work and packet queues */

 called by the modify qp verb */

 According to the spec, timeout = 4.096 * 2 ^ attr->timeout [us] */

 Not possible from modify_qp. */

 called by the query qp verb */

		/* applications that get this state

		 * typically spin on it. yield the

		 * processor

 called by the destroy qp verb */

 flush out any receive wr's or pending requests */

 called when the last reference to the qp is dropped */

 called when the last reference to the qp is dropped */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 *attr being zeroed by the caller, avoid zeroing it here */

 test if new user provider */

 create index > 0 */

 only if new user provider */

 only if old user provider */

 local operation */

 Utilize process context to do protocol processing */

/* build next_map_set from scatterlist

 * The IB_WR_REG_MR WR will swap map_sets

 takes a ref on grp if successful */

	/*

	 * Note that rxe may be invalid at this point if another thread

	 * unregistered it.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

/* Return a random 8 bit key value that is

 * different than the last_key. Set last_key to -1

 * if this is the first key for an MR or MW

	/* set ibmr->l/rkey and also copy into private l/rkey

	 * for user MRs these will always be the same

	 * for cases where caller 'owns' the key portion

	 * they may be different until REG_MR WQE is executed.

/**

 * rxe_mr_alloc() - Allocate memory map array(s) for MR

 * @mr: Memory region

 * @num_buf: Number of buffer descriptors to support

 * @both: If non zero allocate both mr->map and mr->next_map

 *	  else just allocate mr->map. Used for fast MRs

 *

 * Return: 0 on success else an error

 always allow remote access for FMRs */

/* copy data from a range (vaddr, vaddr+length-1) to or from

 * a mr object starting at iova.

/* copy data in or out of a wqe, i.e. sg list

 * under the control of a dma descriptor

/* (1) find the mr corresponding to lkey/rkey

 *     depending on lookup_type

 * (2) verify that the (qp) pd matches the mr pd

 * (3) verify that the mr can support the requested access

 * (4) verify that mr state is valid

/* user can (re)register fast MR by executing a REG_MR WQE.

 * user is expected to hold a reference on the ib mr until the

 * WQE completes.

 * Once a fast MR is created this is the only way to change the

 * private keys. It is the responsibility of the user to maintain

 * the ib mr keys in sync with rxe mr keys.

 user can only register MR in free state */

 user can only register mr with qp in same protection domain */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

/*

 * this locking is due to a potential race where

 * a second caller finds the task already running

 * but looks just after the last call to func

		/* soneone tried to run the task since the last time we called

		 * func, so we will call one more time regardless of the

		 * return value

	/*

	 * Mark the task, then wait for it to finish. It might be

	 * running in a non-tasklet (direct call) context.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

/**

 * rxe_icrc_init() - Initialize crypto function for computing crc32

 * @rxe: rdma_rxe device object

 *

 * Return: 0 on success else an error

/**

 * rxe_crc32() - Compute cumulative crc32 for a contiguous segment

 * @rxe: rdma_rxe device object

 * @crc: starting crc32 value from previous segments

 * @next: starting address of current segment

 * @len: length of current segment

 *

 * Return: the cumulative crc32 checksum

/**

 * rxe_icrc_hdr() - Compute the partial ICRC for the network and transport

 *		  headers of a packet.

 * @skb: packet buffer

 * @pkt: packet information

 *

 * Return: the partial ICRC

	/* pseudo header buffer size is calculate using ipv6 header size since

	 * it is bigger than ipv4

	/* This seed is the result of computing a CRC with a seed of

	 * 0xfffffff and 8 bytes of 0xff representing a masked LRH.

 IPv4 */

 IPv6 */

 exclude bth.resv8a */

 And finish to compute the CRC on the remainder of the headers. */

/**

 * rxe_icrc_check() - Compute ICRC for a packet and compare to the ICRC

 *		      delivered in the packet.

 * @skb: packet buffer

 * @pkt: packet information

 *

 * Return: 0 if the values match else an error

/**

 * rxe_icrc_generate() - compute ICRC for a packet.

 * @skb: packet buffer

 * @pkt: packet information

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

		/* check to see if we are drained;

		 * state_lock used by requester and completer

 comp just finished */

 comp not done yet */

 length from start of bth to end of icrc */

 pkt->hdr, port_num and mask are initialized in ifc layer */

 init skb */

 init bth */

 init optional headers */

 number of packets left to send including current one */

 handle zero length packet case */

 Limit the number of inflight SKBs per QP */

			/* C10-93.1.1: If the total sum of all the buffer lengths specified for a

			 * UD message exceeds the MTU of the port as returned by QueryHCA, the CI

			 * shall not emit any packets for this message. Further, the CI shall not

			 * generate an error due to this condition.

 fake a successful UD send */

	/*

	 * To prevent a race on wqe access between requester and completer,

	 * wqe members state and psn need to be set before calling

	 * rxe_xmit_packet().

	 * Otherwise, completer might initiate an unjustified retry flow.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

	/* queue is comprised from header and the memory

	 * of the actual queue. See "struct rxe_queue_buf" in rxe_queue.h

	 * reset only the queue itself and not the management header

 num_elem == 0 is allowed, but uninteresting */

 used in resize, only need to copy used part of queue */

 pad element up to at least a cacheline and always a power of 2 */

/* copies elements from original q to new q and then swaps the contents of the

 * two q headers. This is so that if anyone is holding a pointer to q it will

 * still work

 update private index copies */

 exchange rxe_queue headers */

 new/old dep on err */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 check that QP matches packet opcode type and is in a valid state */

 lookup mcast group corresponding to mgid, takes a ref */

 mcast group not registered */

	/* this is unreliable datagram service so we let

	 * failures to deliver a multicast packet to a

	 * single QP happen and just move on and try

	 * the rest of them on the list

 validate qp for incoming packet */

		/* for all but the last QP create a new clone of the

		 * skb and pass to the QP. Pass the original skb to

		 * the last QP in the list.

 mark consumed */

 drop ref from rxe_pool_get_key. */

	/* This only occurs if one of the checks fails on the last

	 * QP in the list above

/**

 * rxe_chk_dgid - validate destination IP address

 * @rxe: rxe device that received packet

 * @skb: the received packet buffer

 *

 * Accept any loopback packets

 * Extract IP address from packet and

 * Accept if multicast packet

 * Accept if matches an SGID table entry

 rxe_rcv is called from the interface driver */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 not reached - checked in rxe_av_chk_attr */

 only new user provider or kernel client */

 only old user provider for UD sends*/

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2017 Mellanox Technologies Ltd. All rights reserved.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 We have an issue, and we want to rerun the completer */

 The completer finished successflly */

	/* we come here whether or not we found a response packet to see if

	 * there are any posted WQEs

 no WQE or requester has not started it yet */

 WQE does not require an ack */

 WQE caused an error */

 we have a WQE, if we also have an ack check its PSN */

	/* check to see if response is past the oldest WQE. if it is, complete

	 * send/write or error read/atomic

 compare response packet to expected response */

		/* response is most likely a retried packet if it matches an

		 * uncompleted WQE go complete it else ignore it

 Check the sequence only */

 Will catch all *_ONLY cases. */

			/* read retries of partial data may restart from

			 * read response first or response only.

 Check operation validity. */

		/* (IB_OPCODE_RC_RDMA_READ_RESPONSE_MIDDLE doesn't have an AETH)

				/* a nak implicitly acks all packets with psns

				 * before

/*

 * IBA Spec. Section 10.7.3.1 SIGNALED COMPLETIONS

 * ---------8<---------8<-------------

 * ...Note that if a completion error occurs, a Work Completion

 * will always be generated, even if the signaling

 * indicator requests an Unsignaled Completion.

 * ---------8<---------8<-------------

 do we need to post a completion */

	/*

	 * we completed something so let req run again

	 * if it is trying to fence

 state_lock used by requester & completer */

			/* re reset the timeout counter if

			 * (1) QP is type RC

			 * (2) the QP is alive

			 * (3) there is a packet sent by the requester that

			 *     might be acked (we still might get spurious

			 *     timeouts but try to keep them as few as possible)

			 * (4) the timeout parameter is set

			/* we come here if the retry timer fired and we did

			 * not receive a response packet. try to retry the send

			 * queue if that makes sense and the limits have not

			 * been exceeded. remember that some timeouts are

			 * spurious since we do not reset the timer but kick

			 * it down the road or let it expire

 there is nothing to retry in this case */

			/* if we've started a retry, don't start another

			 * retry sequence, unless this is a timeout.

				/* no point in retrying if we have already

				 * seen the last ack that the requester could

				 * have caused

					/* tell the requester to retry the

					 * send queue next time around

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 caller should hold mc_grp_pool->pool_lock */

 check to see of the qp is already a member of the group */

 each qp holds a ref on the grp */

 ref held by QP */

 ref from get_key */

 ref from get_key */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

/* useful information about work request opcodes and pkt opcodes in

 * table form

 not supported */

 UC */

 RD */

 UD */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

	/* takes a reference on rxe->ib_dev

	 * drop when skb is freed

 Create UDP socket */

 Setup UDP tunnel */

/* fix up a send packet to match the packets

 * received from UDP before looping them back

 FIXME: hold reference to this netdev until life of this skb. */

/*

 * this is required by rxe_cfg to match rxe devices in

 * /sys/class/infiniband up with their underlying ethernet devices

 Caller must hold net_info_lock */

 Caller must hold net_info_lock */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

		/*

		 * This is completely screwed up, the response is supposed to

		 * be in the outbuf not like this.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

/* free resources for a rxe device all objects created for this device must

 * have been destroyed

 initialize rxe device parameters */

 initialize port attributes */

/* initialize port state, note IB convention that HCA ports are always

 * numbered from 1

 init pools of managed objects */

 initialize rxe device state */

 init default device parameters */

 init pending mmap list */

 Make sure that new MTU in range */

/* called by ifc layer to create new rxe device.

 * The caller should allocate memory for rxe by calling ib_alloc_device.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 rxe_recv calls here to add a request packet to the input queue */

 go drain recv wr queue */

 don't trust user space data */

		/* it is the requesters job to not send

		 * too many read/atomic ops, we just

		 * recycle the responder resource queue

 A zero-byte op is not required to set an addr or rkey. */

				/* This case may not be exactly that

				 * but nothing else fits.

 Guarantee atomicity of atomic operations at the machine level. */

 check vaddr is 8 bytes aligned. */

	/*

	 * allocate packet

/* RDMA read response. If res is not NULL, then we have a current RDMA request

 * being processed or replayed.

		/* This is the first time we process that request. Get a

		 * resource

 note res inherits the reference to mr from qp */

/* Executes a new request. A retried request never reach that function (send

 * and writes are discarded, and reads and atomics are retried elsewhere.

 For RDMA Read we can increment the msn now. See C9-148. */

 Unreachable */

 next expected psn, read handles this separately */

 We successfully processed this new request. */

		/* fields after byte_len are different between kernel and user

		 * space

 have copy for srq and reference for !srq */

 SEND. Ack again and cleanup. C9-105. */

			/* Resource not found. Class D error.  Drop the

			 * request.

			/* Ensure this new request is the same as the previous

			 * one or a subset of it.

 Reset the resource, except length. */

 Replay the RDMA read reply. */

 Find the operation in our list of responder resources. */

 Resend the result. */

 Resource not found. Class D error. Drop the request. */

 Process a class A or C. Both are treated the same in this implementation. */

 indicate that we should go through the ERROR state */

 UC */

 Class E */

		/* Class D1. This packet may be the start of a

		 * new message and could be valid. The previous

		 * message is invalid and ignored. reset the

		 * recv wr to its original state

 RC only - Class B. Drop packet. */

 RC Only - Class C. */

 RC - class B */

 UD/UC - class D */

 Class C */

 UC/SRQ Class D */

 UC/non-SRQ Class E. */

 RC - Class J. */

 Class C */

 UC/UD - class E */

 UC/UD - class D */

 All, Class A. */

 All - Class G */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 Copy argument and remove trailing CR. Return the new length. */

 Remove newline. */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2020 Hewlett Packard Enterprise, Inc. All rights reserved.

 o10-36.2.2 */

 o10-37.2.30 */

 C10-72 */

 o10-37.2.40 */

 remaining checks only apply to a nonzero MR */

 C10-73 */

 C10-74 */

 C10-75 */

 o10-37.2.26 */

 valid type 2 MW will always have a QP pointer */

 valid type 2 MW will always have an MR pointer */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2016 Mellanox Technologies Ltd. All rights reserved.

 * Copyright (c) 2015 System Fabric Works, Inc. All rights reserved.

 buf */

/*

 * open and close keep track of how many times the memory region is mapped,

 * to avoid releasing it.

/**

 * rxe_mmap - create a new mmap region

 * @context: the IB user context of the process making the mmap() call

 * @vma: the VMA to be initialized

 * Return zero if the mmap is OK. Otherwise, return an errno.

	/*

	 * Search the device's list of objects waiting for a mmap call.

	 * Normally, this list is very short since a call to create a

	 * CQ, QP, or SRQ is soon followed by a call to mmap().

 Don't allow a mmap larger than the object. */

/*

 * Allocate information for rxe_mmap

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 - 2020 Intel Corporation.

/*

 * Convert the AETH RNR timeout code into the number of microseconds.

 00: 655.36 */

 01:    .01 */

 02     .02 */

 03:    .03 */

 04:    .04 */

 05:    .06 */

 06:    .08 */

 07:    .12 */

 08:    .16 */

 09:    .24 */

 0A:    .32 */

 0B:    .48 */

 0C:    .64 */

 0D:    .96 */

 0E:   1.28 */

 0F:   1.92 */

 10:   2.56 */

 11:   3.84 */

 12:   5.12 */

 13:   7.68 */

 14:  10.24 */

 15:  15.36 */

 16:  20.48 */

 17:  30.72 */

 18:  40.96 */

 19:  61.44 */

 1A:  81.92 */

 1B: 122.88 */

 1C: 163.84 */

 1D: 245.76 */

 1E: 327.68 */

 1F: 491.52 */

/*

 * Note that it is OK to post send work requests in the SQE and ERR

 * states; rvt_do_send() will process them and generate error

 * completions as per IB 1.2 C10-96.

 platform specific: return the last level cache (llc) size, in KiB */

 assume that the boot CPU value is universal for all CPUs */

 platform specific: cacheless copy */

	/*

	 * Use the only available X64 cacheless copy.  Add a __user cast

	 * to quiet sparse.  The src agument is already in the kernel so

	 * there are no security issues.  The extra fault recovery machinery

	 * is not invoked.

 coded to handle partially initialized and repeat callers */

/*

 * rvt_wss_init - Init wss data structures

 *

 * Return: 0 on success

 check for a valid percent range - default to 80 if none or invalid */

 reject a wildly large period */

 reject a zero period */

	/*

	 * Calculate the table size - the next power of 2 larger than the

	 * LLC size.  LLC size is in KiB.

 one bit per page in rounded up table */

/*

 * Advance the clean counter.  When the clean period has expired,

 * clean an entry.

 *

 * This is implemented in atomics to avoid locking.  Because multiple

 * variables are involved, it can be racy which can lead to slightly

 * inaccurate information.  Since this is only a heuristic, this is

 * OK.  Any innaccuracies will clean themselves out as the counter

 * advances.  That said, it is unlikely the entry clean operation will

 * race - the next possible racer will not start until the next clean

 * period.

 *

 * The clean counter is implemented as a decrement to zero.  When zero

 * is reached an entry is cleaned.

 become the cleaner if we decrement the counter to zero */

		/*

		 * Set, not add, the clean period.  This avoids an issue

		 * where the counter could decrement below the clean period.

		 * Doing a set can result in lost decrements, slowing the

		 * clean advance.  Since this a heuristic, this possible

		 * slowdown is OK.

		 *

		 * An alternative is to loop, advancing the counter by a

		 * clean period until the result is > 0. However, this could

		 * lead to several threads keeping another in the clean loop.

		 * This could be mitigated by limiting the number of times

		 * we stay in the loop.

		/*

		 * Uniquely grab the entry to clean and move to next.

		 * The current entry is always the lower bits of

		 * wss.clean_entry.  The table size, wss.num_entries,

		 * is always a power-of-2.

 clear the entry and count the bits */

 only adjust the contended total count if needed */

/*

 * Insert the given address into the working set array.

 assumes this ends up a shift */

/*

 * Is the working set larger than the threshold?

	/*

	 * Free the page if someone raced with us installing it.

/**

 * init_qpn_table - initialize the QP number table for a device

 * @rdi: rvt dev struct

 * @qpt: the QPN table

	/*

	 * Drivers may want some QPs beyond what we need for verbs let them use

	 * our qpn table. No need for two. Lets go ahead and mark the bitmaps

	 * for those. The reserved range must be *after* the range which verbs

	 * will pick from.

 Figure out number of bit maps needed before reserved range */

 This should always be zero */

 Starting with the first reserved bit map */

 next page */

/**

 * free_qpn_table - free the QP number table for a device

 * @qpt: the QPN table

/**

 * rvt_driver_qp_init - Init driver qp resources

 * @rdi: rvt dev strucutre

 *

 * Return: 0 on success

	/*

	 * If driver is not doing any QP allocation then make sure it is

	 * providing the necessary QP functions.

 allocate parent object */

 allocate hash table */

 initialize qpn map */

/**

 * rvt_free_qp_cb - callback function to reset a qp

 * @qp: the qp to reset

 * @v: a 64-bit value

 *

 * This function resets the qp and removes it from the

 * qp hash table.

 Reset the qp and remove it from the qp hash list */

 Increment the qp_inuse count */

/**

 * rvt_free_all_qps - check for QPs still in use

 * @rdi: rvt device info structure

 *

 * There should not be any QPs still in use.

 * Free memory for table.

 * Return the number of QPs still in use.

/**

 * rvt_qp_exit - clean up qps on device exit

 * @rdi: rvt dev structure

 *

 * Check for qp leaks and free resources.

/**

 * alloc_qpn - Allocate the next available qpn or zero/one for QP type

 *	       IB_QPT_SMI/IB_QPT_GSI

 * @rdi: rvt device info structure

 * @qpt: queue pair number table pointer

 * @type: the QP type

 * @port_num: IB port number, 1 based, comes from core

 * @exclude_prefix: prefix of special queue pair number being allocated

 *

 * Return: The queue pair number

 offset carries bit 0 */

			/*

			 * This qpn might be bogus if offset >= BITS_PER_PAGE.

			 * That is OK.   It gets re-assigned below

		/*

		 * In order to keep the number of pages allocated to a

		 * minimum, we scan the all existing pages before increasing

		 * the size of the bitmap table.

 start at incr with current bit 0 */

 start at incr with current bit 0 */

 wrap to first map page, invert bit 0 */

 there can be no set bits in low-order QoS bits */

/**

 * rvt_clear_mr_refs - Drop help mr refs

 * @qp: rvt qp data structure

 * @clr_sends: If shoudl clear send side or not

 see qp_set_savail */

/**

 * rvt_swqe_has_lkey - return true if lkey is used by swqe

 * @wqe: the send wqe

 * @lkey: the lkey

 *

 * Test the swqe for using lkey

/**

 * rvt_qp_sends_has_lkey - return true is qp sends use lkey

 * @qp: the rvt_qp

 * @lkey: the lkey

/**

 * rvt_qp_acks_has_lkey - return true if acks have lkey

 * @qp: the qp

 * @lkey: the lkey

/**

 * rvt_qp_mr_clean - clean up remote ops for lkey

 * @qp: the qp

 * @lkey: the lkey that is being de-registered

 *

 * This routine checks if the lkey is being used by

 * the qp.

 *

 * If so, the qp is put into an error state to elminate

 * any references from the qp.

 avoid special QPs */

/**

 * rvt_remove_qp - remove qp form table

 * @rdi: rvt dev struct

 * @qp: qp to remove

 *

 * Remove the QP from the table so it can't be found asynchronously by

 * the receive routine.

/**

 * rvt_alloc_rq - allocate memory for user or kernel buffer

 * @rq: receive queue data structure

 * @size: number of request queue entries

 * @node: The NUMA node

 * @udata: True if user data is available or not false

 *

 * Return: If memory allocation failed, return -ENONEM

 * This function is used by both shared receive

 * queues and non-shared receive queues to allocate

 * memory.

 need kwq with no buffers */

 need kwq with buffers */

/**

 * rvt_init_qp - initialize the QP state to the reset state

 * @rdi: rvt dev struct

 * @qp: the QP to init or reinit

 * @type: the QP type

 *

 * This function is called from both rvt_create_qp() and

 * rvt_reset_qp().   The difference is that the reset

 * patch the necessary locks to protect against concurent

 * access.

/**

 * _rvt_reset_qp - initialize the QP state to the reset state

 * @rdi: rvt dev struct

 * @qp: the QP to reset

 * @type: the QP type

 *

 * r_lock, s_hlock, and s_lock are required to be held by the caller

 Let drivers flush their waitlist */

 Stop the send queue and the retry timer */

 Wait for things to stop */

 take qp out the hash and wait for it to be unused */

 grab the lock b/c it was locked at call time */

		/*

		 * Let the driver do any tear down or re-init it needs to for

		 * a qp that has been reset

/**

 * rvt_reset_qp - initialize the QP state to the reset state

 * @rdi: the device info

 * @qp: the QP to reset

 * @type: the QP type

 *

 * This is the wrapper function to acquire the r_lock, s_hlock, and s_lock

 * before calling _rvt_reset_qp().

/**

 * rvt_free_qpn - Free a qpn from the bit map

 * @qpt: QP table

 * @qpn: queue pair number to free

/**

 * get_allowed_ops - Given a QP type return the appropriate allowed OP

 * @type: valid, supported, QP type

/**

 * free_ud_wq_attr - Clean up AH attribute cache for UD QPs

 * @qp: Valid QP with allowed_ops set

 *

 * The rvt_swqe data structure being used is a union, so this is

 * only valid for UD QPs.

/**

 * alloc_ud_wq_attr - AH attribute cache for UD QPs

 * @qp: Valid QP with allowed_ops set

 * @node: Numa node for allocation

 *

 * The rvt_swqe data structure being used is a union, so this is

 * only valid for UD QPs.

/**

 * rvt_create_qp - create a queue pair for a device

 * @ibqp: the queue pair

 * @init_attr: the attributes of the queue pair

 * @udata: user data for libibverbs.so

 *

 * Queue pair creation is mostly an rvt issue. However, drivers have their own

 * unique idea of what queue pair numbers mean. For instance there is a reserved

 * range for PSM.

 *

 * Return: 0 on success, otherwise returns an errno.

 *

 * Called by the ib_create_qp() core verbs function.

 Check receive queue parameters if no SRQ is specified. */

 initialize timers needed for rc qp */

		/*

		 * Driver needs to set up it's private QP structure and do any

		 * initialization that is needed.

		/*

		 * ib_create_qp() will initialize qp->ibqp

		 * except for qp->ibqp.qp_num.

 Don't support raw QPs */

	/*

	 * Return the address of the RWQ as the offset to mmap.

	 * See rvt_mmap() for details.

	/*

	 * Maintain a busy_jiffies variable that will be added to the timeout

	 * period in mod_retry_timer and add_retry_timer. This busy jiffies

	 * is scaled by the number of rc qps created for the device to reduce

	 * the number of timeouts occurring when there is a large number of

	 * qps. busy_jiffies is incremented every rc qp scaling interval.

	 * The scaling interval is selected based on extensive performance

	 * evaluation of targeted workloads.

/**

 * rvt_error_qp - put a QP into the error state

 * @qp: the QP to put into the error state

 * @err: the receive completion error to signal if a RWQE is active

 *

 * Flushes both send and receive work queues.

 *

 * Return: true if last WQE event should be generated.

 * The QP r_lock and s_lock should be held and interrupts disabled.

 * If we are already in error state, just return.

 Schedule the sending tasklet to drain the send work queue. */

 qp->ip used to validate if there is a  user buffer mmaped */

 sanity check pointers before trusting them */

/*

 * Put the QP into the hash table.

 * The hash table holds a reference to the QP.

/**

 * rvt_modify_qp - modify the attributes of a queue pair

 * @ibqp: the queue pair who's attributes we're modifying

 * @attr: the new attributes

 * @attr_mask: the mask of attributes to modify

 * @udata: user data for libibverbs.so

 *

 * Return: 0 on success, otherwise returns an errno.

 for gcc warning only */

	/*

	 * Don't allow invalid path_mtu values.  OK to set greater

	 * than the active mtu (or even the max_cap, if we have tuned

	 * that to a small mtu.  We'll set qp->path_mtu

	 * to the lesser of requested attribute mtu and active,

	 * for packetizing messages.

	 * Note that the QP port has to be set in INIT and MTU in RTR.

 Allow event to re-trigger if QP set to RTR more than once */

/**

 * rvt_destroy_qp - destroy a queue pair

 * @ibqp: the queue pair to destroy

 * @udata: unused by the driver

 *

 * Note that this can be called while the QP is actively sending or

 * receiving!

 *

 * Return: 0 on success.

 qpn is now available for use again */

/**

 * rvt_query_qp - query an ipbq

 * @ibqp: IB qp to query

 * @attr: attr struct to fill in

 * @attr_mask: attr mask ignored

 * @init_attr: struct to fill in

 *

 * Return: always 0

/**

 * rvt_post_recv - post a receive on a QP

 * @ibqp: the QP to post the receive on

 * @wr: the WR to post

 * @bad_wr: the first bad WR is put here

 *

 * This may be called from interrupt context.

 *

 * Return: 0 on success otherwise errno

 Check that state is OK to post receive. */

			/*

			 * Make sure queue entry is written

			 * before the head index.

/**

 * rvt_qp_valid_operation - validate post send wr request

 * @qp: the qp

 * @post_parms: the post send table for the driver

 * @wr: the work request

 *

 * The routine validates the operation based on the

 * validation table an returns the length of the operation

 * which can extend beyond the ib_send_bw.  Operation

 * dependent flags key atomic operation validation.

 *

 * There is an exception for UD qps that validates the pd and

 * overrides the length to include the additional UD specific

 * length.

 *

 * Returns a negative error or the length of the work request

 * for building the swqe.

 UD specific */

/**

 * rvt_qp_is_avail - determine queue capacity

 * @qp: the qp

 * @rdi: the rdmavt device

 * @reserved_op: is reserved operation

 *

 * This assumes the s_hlock is held but the s_last

 * qp variable is uncontrolled.

 *

 * For non reserved operations, the qp->s_avail

 * may be changed.

 *

 * The return value is zero or a -ENOMEM.

 see rvt_qp_wqe_unreserve() */

 see rvt_qp_wqe_unreserve() */

 non-reserved operations */

 See rvt_qp_complete_swqe() */

 insure we don't assign a negative s_avail */

/**

 * rvt_post_one_wr - post one RC, UC, or UD send work request

 * @qp: the QP to post on

 * @wr: the work request to send

 * @call_send: kick the send engine into gear

 IB spec says that num_sge == 0 is OK. */

	/*

	 * Local operations include fast register and local invalidate.

	 * Fast register needs to be processed immediately because the

	 * registered lkey may be used by following work requests and the

	 * lkey needs to be valid at the time those requests are posted.

	 * Local invalidate can be processed immediately if fencing is

	 * not required and no previous local invalidate ops are pending.

	 * Signaled local operations that have been processed immediately

	 * need to have requests with "completion only" flags set posted

	 * to the send queue in order to generate completions.

 check for avail */

 cplen has length from above */

	/*

	 * Calculate and set SWQE PSN values prior to handing it off

	 * to the driver's check routine. This give the driver the

	 * opportunity to adjust PSN values based on internal checks.

 general part of wqe valid - allow for driver checks */

 see request builders */

 release mr holds */

/**

 * rvt_post_send - post a send on a QP

 * @ibqp: the QP to post the send on

 * @wr: the list of work requests to post

 * @bad_wr: the first bad WR is put here

 *

 * This may be called from interrupt context.

 *

 * Return: 0 on success else errno

	/*

	 * Ensure QP state is such that we can send. If not bail out early,

	 * there is no need to do this every time we post a send.

	/*

	 * If the send queue is empty, and we only have a single WR then just go

	 * ahead and kick the send engine into gear. Otherwise we will always

	 * just schedule the send to happen later.

		/*

		 * Only call do_send if there is exactly one packet, and the

		 * driver said it was ok.

/**

 * rvt_post_srq_recv - post a receive on a shared receive queue

 * @ibsrq: the SRQ to post the receive on

 * @wr: the list of work requests to post

 * @bad_wr: A pointer to the first WR to cause a problem is put here

 *

 * This may be called from interrupt context.

 *

 * Return: 0 on success else errno

 Make sure queue entry is written before the head index. */

/*

 * rvt used the internal kernel struct as part of its ABI, for now make sure

 * the kernel struct does not change layout. FIXME: rvt should never cast the

 * user struct to a kernel struct.

/*

 * Validate a RWQE and fill in the SGE state.

 * Return 1 if OK.

 Check LKEY */

 Signal solicited completion event. */

/**

 * get_rvt_head - get head indices of the circular buffer

 * @rq: data structure for request queue entry

 * @ip: the QP

 *

 * Return - head index value

/**

 * rvt_get_rwqe - copy the next RWQE into the QP's RWQE

 * @qp: the QP

 * @wr_id_only: update qp->r_wr_id only, not qp->r_sge

 *

 * Return -1 if there is a local error, 0 if no RWQE is available,

 * otherwise return 1.

 *

 * Can be called from interrupt level.

 Validate tail before using it since it is user writable. */

 Make sure entry is read after the count is read. */

	/*

	 * Even though we update the tail index in memory, the verbs

	 * consumer is not supposed to post more entries until a

	 * completion is generated.

		/*

		 * Validate head pointer value and compute

		 * the number of remaining WQEs.

/**

 * rvt_comm_est - handle trap with QP established

 * @qp: the QP

/*

 *  rvt_rnr_tbl_to_usec - return index into ib_rvt_rnr_table

 *  @index - the index

 *  return usec from an index into ib_rvt_rnr_table

/*

 *  rvt_add_retry_timer_ext - add/start a retry timer

 *  @qp - the QP

 *  @shift - timeout shift to wait for multiple packets

 *  add a retry timer on the QP

 4.096 usec. * (1 << qp->timeout) */

/**

 * rvt_add_rnr_timer - add/start an rnr timer on the QP

 * @qp: the QP

 * @aeth: aeth of RNR timeout, simulated aeth for loopback

/**

 * rvt_stop_rc_timers - stop all timers

 * @qp: the QP

 * stop any pending timers

 Remove QP from all timers */

/**

 * rvt_stop_rnr_timer - stop an rnr timer

 * @qp: the QP

 *

 * stop an rnr timer and return if the timer

 * had been pending.

 Remove QP from rnr timer */

/**

 * rvt_del_timers_sync - wait for any timeout routines to exit

 * @qp: the QP

/*

 * This is called from s_timer for missing responses.

/*

 * This is called from s_timer for RNR timeouts.

/**

 * rvt_qp_iter_init - initial for QP iteration

 * @rdi: rvt devinfo

 * @v: u64 value

 * @cb: user-defined callback

 *

 * This returns an iterator suitable for iterating QPs

 * in the system.

 *

 * The @cb is a user-defined callback and @v is a 64-bit

 * value passed to and relevant for processing in the

 * @cb.  An example use case would be to alter QP processing

 * based on criteria not part of the rvt_qp.

 *

 * Use cases that require memory allocation to succeed

 * must preallocate appropriately.

 *

 * Return: a pointer to an rvt_qp_iter or NULL

 number of special QPs (SMI/GSI) for device */

/**

 * rvt_qp_iter_next - return the next QP in iter

 * @iter: the iterator

 *

 * Fine grained QP iterator suitable for use

 * with debugfs seq_file mechanisms.

 *

 * Updates iter->qp with the current QP when the return

 * value is 0.

 *

 * Return: 0 - iter->qp is valid 1 - no more QPs

	/*

	 * The approach is to consider the special qps

	 * as additional table entries before the

	 * real hash table.  Since the qp code sets

	 * the qp->next hash link to NULL, this works just fine.

	 *

	 * iter->specials is 2 * # ports

	 *

	 * n = 0..iter->specials is the special qp indices

	 *

	 * n = iter->specials..rdi->qp_dev->qp_table_size+iter->specials are

	 * the potential hash bucket entries

	 *

/**

 * rvt_qp_iter - iterate all QPs

 * @rdi: rvt devinfo

 * @v: a 64-bit value

 * @cb: a callback

 *

 * This provides a way for iterating all QPs.

 *

 * The @cb is a user-defined callback and @v is a 64-bit

 * value passed to and relevant for processing in the

 * cb.  An example use case would be to alter QP processing

 * based on criteria not part of the rvt_qp.

 *

 * The code has an internal iterator to simplify

 * non seq_file use cases.

/*

 * This should be called with s_lock held.

/**

 * rvt_copy_sge - copy data to SGE memory

 * @qp: associated QP

 * @ss: the SGE state

 * @data: the data to copy

 * @length: the length of the data

 * @release: boolean to release MR

 * @copy_last: do a separate copy of the last 8 bytes

			/*

			 * NOTE: this *assumes*:

			 * o The first vaddr is the dest.

			 * o If multiple pages, then vaddr is sequential.

 enforce byte transfer ordering */

	/*

	 * For RC, the requester would timeout and retry so

	 * shortcut the timeouts and just signal too many retries.

/**

 * rvt_ruc_loopback - handle UC and RC loopback requests

 * @sqp: the sending QP

 *

 * This is called from rvt_do_send() to forward a WQE addressed to the same HFI

 * Note that although we are single threaded due to the send engine, we still

 * have to protect against post_send().  We don't have to worry about

 * receive interrupts since this is a connected protocol and all packets

 * will pass through here.

	/*

	 * Note that we check the responder QP state after

	 * checking the requester's state.

 Return if we are already busy processing a work request. */

 Return if it is not OK to start a new work request. */

 We are in the error state, flush the work request. */

	/*

	 * We can rely on the entry not changing without the s_lock

	 * being held until we update s_last.

	 * We increment s_cur to indicate s_last is in progress.

 skip copy_last set and qp_access_flags recheck */

 Perform atomic OP and save result. */

 Signal completion event if the solicited bit is set. */

 Handle RNR NAK */

	/*

	 * Note: we don't need the s_lock held since the BUSY flag

	 * makes this single threaded.

 responder goes to error state */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

/**

 * rvt_driver_srq_init - init srq resources on a per driver basis

 * @rdi: rvt dev structure

 *

 * Do any initialization needed when a driver registers with rdmavt.

/**

 * rvt_create_srq - create a shared receive queue

 * @ibsrq: the protection domain of the SRQ to create

 * @srq_init_attr: the attributes of the SRQ

 * @udata: data from libibverbs when creating a user SRQ

 *

 * Return: 0 on success

	/*

	 * Need to use vmalloc() if we want to support large #s of entries.

	/*

	 * Return the address of the RWQ as the offset to mmap.

	 * See rvt_mmap() for details.

	/*

	 * ib_create_srq() will initialize srq->ibsrq.

/**

 * rvt_modify_srq - modify a shared receive queue

 * @ibsrq: the SRQ to modify

 * @attr: the new attributes of the SRQ

 * @attr_mask: indicates which attributes to modify

 * @udata: user data for libibverbs.so

 *

 * Return: 0 on success

 Check that the requested sizes are below the limits. */

 Check that we can write the offset to mmap. */

		/*

		 * validate head and tail pointer values and compute

		 * the number of remaining WQEs.

			/*

			 * Return the offset to mmap.

			 * See rvt_mmap() for details.

			/*

			 * Put user mapping info onto the pending list

			 * unless it already is on the list.

/**

 * rvt_query_srq - query srq data

 * @ibsrq: srq to query

 * @attr: return info in attr

 *

 * Return: always 0

/**

 * rvt_destroy_srq - destory an srq

 * @ibsrq: srq object to destroy

 * @udata: user data for libibverbs.so

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

/*

 * Convert the AETH credit code into the number of credits.

 0 */

 1 */

 2 */

 3 */

 4 */

 5 */

 6 */

 7 */

 8 */

 9 */

 A */

 B */

 C */

 D */

 E */

 F */

 10 */

 11 */

 12 */

 13 */

 14 */

 15 */

 16 */

 17 */

 18 */

 19 */

 1A */

 1B */

 1C */

 1D */

 1E */

/**

 * rvt_compute_aeth - compute the AETH (syndrome + MSN)

 * @qp: the queue pair to compute the AETH for

 *

 * Returns the AETH.

		/*

		 * Shared receive queues don't generate credits.

		 * Set the credit field to the invalid value.

 sanity check pointers before trusting them */

			/*

			 * Compute the number of credits available (RWQEs).

			 * There is a small chance that the pair of reads are

			 * not atomic, which is OK, since the fuzziness is

			 * resolved as further ACKs go out.

		/*

		 * Binary search the credit table to find the code to

		 * use.

/**

 * rvt_get_credit - flush the send work queue of a QP

 * @qp: the qp who's send work queue to flush

 * @aeth: the Acknowledge Extended Transport Header

 *

 * The QP s_lock should be held.

	/*

	 * If the credit is invalid, we can send

	 * as many packets as we like.  Otherwise, we have to

	 * honor the credit field.

 Compute new LSN (i.e., MSN + credit) */

/**

 * rvt_restart_sge - rewind the sge state for a wqe

 * @ss: the sge state pointer

 * @wqe: the wqe to rewind

 * @len: the data length from the start of the wqe in bytes

 *

 * Returns the remaining data length.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

/**

 * rvt_mmap_init - init link list and lock for mem map

 * @rdi: rvt dev struct

/**

 * rvt_release_mmap_info - free mmap info structure

 * @ref: a pointer to the kref within struct rvt_mmap_info

/**

 * rvt_mmap - create a new mmap region

 * @context: the IB user context of the process making the mmap() call

 * @vma: the VMA to be initialized

 *

 * Return: zero if the mmap is OK. Otherwise, return an errno.

	/*

	 * Search the device's list of objects waiting for a mmap call.

	 * Normally, this list is very short since a call to create a

	 * CQ, QP, or SRQ is soon followed by a call to mmap().

 Only the creator is allowed to mmap the object */

 Don't allow a mmap larger than the object. */

/**

 * rvt_create_mmap_info - allocate information for hfi1_mmap

 * @rdi: rvt dev struct

 * @size: size in bytes to map

 * @udata: user data (must be valid!)

 * @obj: opaque pointer to a cq, wq etc

 *

 * Return: rvt_mmap struct on success, ERR_PTR on failure

/**

 * rvt_update_mmap_info - update a mem map

 * @rdi: rvt dev struct

 * @ip: mmap info pointer

 * @size: size to grow by

 * @obj: opaque pointer to cq, wq, etc.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 - 2019 Intel Corporation.

 for prints */

/**

 * rvt_check_ah - validate the attributes of AH

 * @ibdev: the ib device

 * @ah_attr: the attributes of the AH

 *

 * If driver supports a more detailed check_ah function call back to it

 * otherwise just check the basics.

 *

 * Return: 0 on success

/**

 * rvt_create_ah - create an address handle

 * @ibah: the IB address handle

 * @init_attr: the attributes of the AH

 * @udata: pointer to user's input output buffer information.

 *

 * This may be called from interrupt context.

 *

 * Return: 0 on success

/**

 * rvt_destroy_ah - Destroy an address handle

 * @ibah: address handle

 * @destroy_flags: destroy address handle flags (see enum rdma_destroy_ah_flags)

 * Return: 0 on success

/**

 * rvt_modify_ah - modify an ah with given attrs

 * @ibah: address handle to modify

 * @ah_attr: attrs to apply

 *

 * Return: 0 on success

/**

 * rvt_query_ah - return attrs for ah

 * @ibah: address handle to query

 * @ah_attr: return info in this

 *

 * Return: always 0

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

/**

 * rvt_alloc_pd - allocate a protection domain

 * @ibpd: PD

 * @udata: optional user data

 *

 * Allocate and keep track of a PD.

 *

 * Return: 0 on success

	/*

	 * While we could continue allocating protecetion domains, being

	 * constrained only by system resources. The IBTA spec defines that

	 * there is a max_pd limit that can be set and we need to check for

	 * that.

 ib_alloc_pd() will initialize pd->ibpd. */

/**

 * rvt_dealloc_pd - Free PD

 * @ibpd: Free up PD

 * @udata: Valid user data or NULL for kernel object

 *

 * Return: always 0

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

/**

 * rvt_driver_mcast_init - init resources for multicast

 * @rdi: rvt dev struct

 *

 * This is per device that registers with rdmavt

	/*

	 * Anything that needs setup for multicast on a per driver or per rdi

	 * basis should be done in here.

/**

 * rvt_mcast_qp_alloc - alloc a struct to link a QP to mcast GID struct

 * @qp: the QP to link

 Notify hfi1_destroy_qp() if it is waiting. */

/**

 * rvt_mcast_alloc - allocate the multicast GID structure

 * @mgid: the multicast GID

 * @lid: the muilticast LID (host order)

 *

 * A list of QPs will be attached to this structure.

/**

 * rvt_mcast_find - search the global table for the given multicast GID/LID

 * NOTE: It is valid to have 1 MLID with multiple MGIDs.  It is not valid

 * to have 1 MGID with multiple MLIDs.

 * @ibp: the IB port structure

 * @mgid: the multicast GID to search for

 * @lid: the multicast LID portion of the multicast address (host order)

 *

 * The caller is responsible for decrementing the reference count if found.

 *

 * Return: NULL if not found.

 MGID/MLID must match */

/*

 * rvt_mcast_add - insert mcast GID into table and attach QP struct

 * @mcast: the mcast GID table

 * @mqp: the QP to attach

 *

 * Return: zero if both were added.  Return EEXIST if the GID was already in

 * the table but the QP was added.  Return ESRCH if the QP was already

 * attached and neither structure was added. Return EINVAL if the MGID was

 * found, but the MLID did NOT match.

 Search the QP list to see if this is already there. */

/**

 * rvt_attach_mcast - attach a qp to a multicast group

 * @ibqp: Infiniband qp

 * @gid: multicast guid

 * @lid: multicast lid

 *

 * Return: 0 on success

	/*

	 * Allocate data structures since its better to do this outside of

	 * spin locks and it will most likely be needed.

 Neither was used: OK to attach the same QP twice. */

 The mcast wasn't used */

 Exceeded the maximum number of mcast groups. */

 Invalid MGID/MLID pair */

/**

 * rvt_detach_mcast - remove a qp from a multicast group

 * @ibqp: Infiniband qp

 * @gid: multicast guid

 * @lid: multicast lid

 *

 * Return: 0 on success

 Find the GID in the mcast table. */

 MGID/MLID must match */

 Search the QP list. */

		/*

		 * We found it, so remove it, but don't poison the forward

		 * link until we are sure there are no list walkers.

 If this was the last attached QP, remove the GID too. */

 QP not attached */

	/*

	 * Wait for any list walkers to finish before freeing the

	 * list element.

/**

 * rvt_mcast_tree_empty - determine if any qps are attached to any mcast group

 * @rdi: rvt dev struct

 *

 * Return: in use count

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 - 2018 Intel Corporation.

/**

 * rvt_cq_enter - add a new entry to the completion queue

 * @cq: completion queue

 * @entry: work completion entry to add

 * @solicited: true if @entry is solicited

 *

 * This may be called with qp->s_lock held.

 *

 * Return: return true on success, else return

 * false if cq is full.

	/*

	 * Note that the head pointer might be writable by

	 * user processes.Take care to verify it is a sane value.

 Make sure entry is written before the head index. */

		/*

		 * This will cause send_complete() to be called in

		 * another thread.

	/*

	 * The completion handler will most likely rearm the notification

	 * and poll for all pending entries.  If a new completion entry

	 * is added while we are in this routine, queue_work()

	 * won't call us again until we return so we check triggered to

	 * see if we need to call the handler again.

		/*

		 * IPoIB connected mode assumes the callback is from a

		 * soft IRQ. We simulate this by blocking "bottom halves".

		 * See the implementation for ipoib_cm_handle_tx_wc(),

		 * netif_tx_lock_bh() and netif_tx_lock().

/**

 * rvt_create_cq - create a completion queue

 * @ibcq: Allocated CQ

 * @attr: creation attributes

 * @udata: user data for libibverbs.so

 *

 * Called by ib_create_cq() in the generic verbs code.

 *

 * Return: 0 on success

	/*

	 * Allocate the completion queue entries and head/tail pointers.

	 * This is allocated separately so that it can be resized and

	 * also mapped into user space.

	 * We need to use vmalloc() in order to support mmap and large

	 * numbers of entries.

	/*

	 * Return the address of the WC as the offset to mmap.

	 * See rvt_mmap() for details.

	/*

	 * ib_create_cq() will initialize cq->ibcq except for cq->ibcq.cqe.

	 * The number of entries should be >= the number requested or return

	 * an error.

/**

 * rvt_destroy_cq - destroy a completion queue

 * @ibcq: the completion queue to destroy.

 * @udata: user data or NULL for kernel object

 *

 * Called by ib_destroy_cq() in the generic verbs code.

/**

 * rvt_req_notify_cq - change the notification type for a completion queue

 * @ibcq: the completion queue

 * @notify_flags: the type of notification to request

 *

 * This may be called from interrupt context.  Also called by

 * ib_req_notify_cq() in the generic verbs code.

 *

 * Return: 0 for success.

	/*

	 * Don't change IB_CQ_NEXT_COMP to IB_CQ_SOLICITED but allow

	 * any other transitions (see C11-31 and C11-32 in ch. 11.4.2.2).

/*

 * rvt_resize_cq - change the size of the CQ

 * @ibcq: the completion queue

 *

 * Return: 0 for success.

	/*

	 * Need to use vmalloc() if we want to support large #s of entries.

 Check that we can write the offset to mmap. */

	/*

	 * Make sure head and tail are sane since they

	 * might be user writable.

		/*

		 * Return the offset to mmap.

		 * See rvt_mmap() for details.

/**

 * rvt_poll_cq - poll for work completion entries

 * @ibcq: the completion queue to poll

 * @num_entries: the maximum number of entries to return

 * @entry: pointer to array where work completions are placed

 *

 * This may be called from interrupt context.  Also called by ib_poll_cq()

 * in the generic verbs code.

 *

 * Return: the number of completion entries polled.

 The kernel can only poll a kernel completion queue */

 The kernel doesn't need a RMB since it has the lock. */

/**

 * rvt_driver_cq_init - Init cq resources on behalf of driver

 *

 * Return: 0 on success

/**

 * rvt_cq_exit - tear down cq reources

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

/**

 * rvt_driver_mr_init - Init MR resources per driver

 * @rdi: rvt dev struct

 *

 * Do any intilization needed when a driver registers with rdmavt.

 *

 * Return: 0 on success or errno on failure

	/*

	 * The top hfi1_lkey_table_size bits are used to index the

	 * table.  The lower 8 bits can be owned by the user (copied from

	 * the LKEY).  The remaining bits act as a generation number or tag.

 ensure generation is at least 4 bits */

/**

 * rvt_mr_exit - clean up MR

 * @rdi: rvt dev structure

 *

 * called when drivers have unregistered or perhaps failed to register with us

 count returning the ptr to user */

/**

 * rvt_alloc_lkey - allocate an lkey

 * @mr: memory region that this lkey protects

 * @dma_region: 0->normal key, 1->restricted DMA key

 *

 * Returns 0 if successful, otherwise returns -errno.

 *

 * Increments mr reference count as required.

 *

 * Sets the lkey field mr for non-dma regions.

 *

 special case for dma_mr lkey == 0 */

 Insure published written first */

 Find the next available LKEY */

	/*

	 * Make sure lkey is never zero which is reserved to indicate an

	 * unrestricted LKEY.

	/*

	 * bits are capped to ensure enough bits for generation number

 Insure published written first */

/**

 * rvt_free_lkey - free an lkey

 * @mr: mr to free from tables

 insure published is written before pointer */

 insure published is written before pointer */

 Allocate struct plus pointers to first level page tables. */

	/*

	 * ib_reg_phys_mr() will initialize mr->ibmr except for

	 * lkey and rkey.

/**

 * rvt_get_dma_mr - get a DMA memory region

 * @pd: protection domain for this memory region

 * @acc: access flags

 *

 * Return: the memory region on success, otherwise returns an errno.

/**

 * rvt_reg_user_mr - register a userspace memory region

 * @pd: protection domain for this memory region

 * @start: starting userspace address

 * @length: length of region to register

 * @virt_addr: associated virtual address

 * @mr_access_flags: access flags for this memory region

 * @udata: unused by the driver

 *

 * Return: the memory region on success, otherwise returns an errno.

/**

 * rvt_dereg_clean_qp_cb - callback from iterator

 * @qp: the qp

 * @v: the mregion (as u64)

 *

 * This routine fields the callback for all QPs and

 * for QPs in the same PD as the MR will call the

 * rvt_qp_mr_clean() to potentially cleanup references.

 skip PDs that are not ours */

/**

 * rvt_dereg_clean_qps - find QPs for reference cleanup

 * @mr: the MR that is being deregistered

 *

 * This routine iterates RC QPs looking for references

 * to the lkey noted in mr.

/**

 * rvt_check_refs - check references

 * @mr: the megion

 * @t: the caller identification

 *

 * This routine checks MRs holding a reference during

 * when being de-registered.

 *

 * If the count is non-zero, the code calls a clean routine then

 * waits for the timeout for the count to zero.

 avoid dma mr */

 @mr was indexed on rcu protected @lkey_table */

/**

 * rvt_mr_has_lkey - is MR

 * @mr: the mregion

 * @lkey: the lkey

/**

 * rvt_ss_has_lkey - is mr in sge tests

 * @ss: the sge state

 * @lkey: the lkey

 *

 * This code tests for an MR in the indicated

 * sge state.

 first one */

 any others */

/**

 * rvt_dereg_mr - unregister and free a memory region

 * @ibmr: the memory region to free

 * @udata: unused by the driver

 *

 * Note that this is called to free MRs created by rvt_get_dma_mr()

 * or rvt_reg_user_mr().

 *

 * Returns 0 on success.

 will set completion if last */

/**

 * rvt_alloc_mr - Allocate a memory region usable with the

 * @pd: protection domain for this memory region

 * @mr_type: mem region type

 * @max_num_sg: Max number of segments allowed

 *

 * Return: the memory region on success, otherwise return an errno.

/**

 * rvt_set_page - page assignment function called by ib_sg_to_pages

 * @ibmr: memory region

 * @addr: dma address of mapped page

 *

 * Return: 0 on success

/**

 * rvt_map_mr_sg - map sg list and set it the memory region

 * @ibmr: memory region

 * @sg: dma mapped scatterlist

 * @sg_nents: number of entries in sg

 * @sg_offset: offset in bytes into sg

 *

 * Overwrite rvt_mr length with mr length calculated by ib_sg_to_pages.

 *

 * Return: number of sg elements mapped to the memory region

/**

 * rvt_fast_reg_mr - fast register physical MR

 * @qp: the queue pair where the work request comes from

 * @ibmr: the memory region to be registered

 * @key: updated key for this memory region

 * @access: access flags for this memory region

 *

 * Returns 0 on success.

 not applicable to dma MR or user MR */

/**

 * rvt_invalidate_rkey - invalidate an MR rkey

 * @qp: queue pair associated with the invalidate op

 * @rkey: rkey to invalidate

 *

 * Returns 0 on success.

/**

 * rvt_sge_adjacent - is isge compressible

 * @last_sge: last outgoing SGE written

 * @sge: SGE to check

 *

 * If adjacent will update last_sge to add length.

 *

 * Return: true if isge is adjacent to last sge

 overrun, caller will catch */

/**

 * rvt_lkey_ok - check IB SGE for validity and initialize

 * @rkt: table containing lkey to check SGE against

 * @pd: protection domain

 * @isge: outgoing internal SGE

 * @last_sge: last outgoing SGE written

 * @sge: SGE to check

 * @acc: access flags

 *

 * Check the IB SGE for validity and initialize our internal version

 * of it.

 *

 * Increments the reference count when a new sge is stored.

 *

 * Return: 0 if compressed, 1 if added , otherwise returns -errno.

	/*

	 * We use LKEY == zero for kernel virtual addresses

	 * (see rvt_get_dma_mr()).

		/*

		 * page sizes are uniform power of 2 so no loop is necessary

		 * entries_spanned_by_off is the number of times the loop below

		 * would have executed.

/**

 * rvt_rkey_ok - check the IB virtual address, length, and RKEY

 * @qp: qp for validation

 * @sge: SGE state

 * @len: length of data

 * @vaddr: virtual address to place data

 * @rkey: rkey to check

 * @acc: access flags

 *

 * Return: 1 if successful, otherwise 0.

 *

 * increments the reference count upon success

	/*

	 * We use RKEY == zero for kernel virtual addresses

	 * (see rvt_get_dma_mr()).

 insure mr read is before test */

		/*

		 * page sizes are uniform power of 2 so no loop is necessary

		 * entries_spanned_by_off is the number of times the loop below

		 * would have executed.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 - 2018 Intel Corporation.

/**

 * rvt_alloc_device - allocate rdi

 * @size: how big of a structure to allocate

 * @nports: number of ports to allocate array slots for

 *

 * Use IB core device alloc to allocate space for the rdi which is assumed to be

 * inside of the ib_device. Any extra space that drivers require should be

 * included in size.

 *

 * We also allocate a port array based on the number of ports.

 *

 * Return: pointer to allocated rdi

/**

 * rvt_dealloc_device - deallocate rdi

 * @rdi: structure to free

 *

 * Free a structure allocated with rvt_alloc_device()

	/*

	 * Return rvt_dev_info.dparms.props contents

	/*

	 * There is currently no need to supply this based on qib and hfi1.

	 * Future drivers may need to implement this though.

/**

 * rvt_query_port - Passes the query port call to the driver

 * @ibdev: Verbs IB dev

 * @port_num: port number, 1 based from ib core

 * @props: structure to hold returned properties

 *

 * Return: 0 on success

 props being zeroed by the caller, avoid zeroing it here */

 Populate the remaining ib_port_attr elements */

/**

 * rvt_modify_port - modify port

 * @ibdev: Verbs IB dev

 * @port_num: Port number, 1 based from ib core

 * @port_modify_mask: How to change the port

 * @props: Structure to fill in

 *

 * Return: 0 on success

/**

 * rvt_query_pkey - Return a pkey from the table at a given index

 * @ibdev: Verbs IB dev

 * @port_num: Port number, 1 based from ib core

 * @index: Index into pkey table

 * @pkey: returned pkey from the port pkey table

 *

 * Return: 0 on failure pkey otherwise

	/*

	 * Driver will be responsible for keeping rvt_dev_info.pkey_table up to

	 * date. This function will just return that value. There is no need to

	 * lock, if a stale value is read and sent to the user so be it there is

	 * no way to protect against that anyway.

/**

 * rvt_query_gid - Return a gid from the table

 * @ibdev: Verbs IB dev

 * @port_num: Port number, 1 based from ib core

 * @guid_index: Index in table

 * @gid: Gid to return

 *

 * Return: 0 on success

	/*

	 * Driver is responsible for updating the guid table. Which will be used

	 * to craft the return value. This will work similar to how query_pkey()

	 * is being done.

/**

 * rvt_alloc_ucontext - Allocate a user context

 * @uctx: Verbs context

 * @udata: User data allocated

/**

 * rvt_dealloc_ucontext - Free a user context

 * @context: Unused

 Must always be last! */

		/*

		 * These functions are not part of verbs specifically but are

		 * required for rdmavt to function.

		/*

		 * rdmavt does not support modify device currently drivers must

		 * provide.

/**

 * rvt_register_device - register a driver

 * @rdi: main dev structure for all of rdmavt operations

 *

 * It is up to drivers to allocate the rdi and fill in the appropriate

 * information.

 *

 * Return: 0 on success otherwise an errno.

	/*

	 * Check to ensure drivers have setup the required helpers for the verbs

	 * they want rdmavt to handle

 Once we get past here we can use rvt_pr macros and tracepoints */

 Queue Pairs */

 Address Handle */

 Shared Receive Queue */

 Multicast */

 Mem Region */

 Memory Working Set Size */

 Completion queues */

 Protection Domain */

	/*

	 * There are some things which could be set by underlying drivers but

	 * really should be up to rdmavt to set. For instance drivers can't know

	 * exactly which functions rdmavt supports, nor do they know the ABI

	 * version, so we do all of this sort of stuff here.

 We are now good to announce we exist */

/**

 * rvt_unregister_device - remove a driver

 * @rdi: rvt dev struct

/**

 * rvt_init_port - init internal data for driver port

 * @rdi: rvt_dev_info struct

 * @port: rvt port

 * @port_index: 0 based index of ports, different from IB core port num

 * @pkey_table: pkey_table for @port

 *

 * Keep track of a list of ports. No need to have a detach port.

 * They persist until the driver goes away.

 *

 * Return: always 0

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 Intel Corporation.

/**

 * rvt_process_mad - process an incoming MAD packet

 * @ibdev: the infiniband device this packet came in on

 * @mad_flags: MAD flags

 * @port_num: the port number this packet came in on, 1 based from ib core

 * @in_wc: the work completion entry for this packet

 * @in_grh: the global route header for this packet

 * @in: the incoming MAD

 * @in_mad_size: size of the incoming MAD reply

 * @out: any outgoing MAD reply

 * @out_mad_size: size of the outgoing MAD reply

 * @out_mad_pkey_index: unused

 *

 * Note that the verbs framework has already done the MAD sanity checks,

 * and hop count/pointer updating for IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE

 * MADs.

 *

 * This is called by the ib_mad module.

 *

 * Return: IB_MAD_RESULT_SUCCESS or error

	/*

	 * MAD processing is quite different between hfi1 and qib. Therefore

	 * this is expected to be provided by the driver. Other drivers in the

	 * future may choose to implement this but it should not be made into a

	 * requirement.

/**

 * rvt_create_mad_agents - create mad agents

 * @rdi: rvt dev struct

 *

 * If driver needs to be notified of mad agent creation then call back

 *

 * Return 0 on success

/**

 * rvt_free_mad_agents - free up mad agents

 * @rdi: rvt dev struct

 *

 * If driver needs notification of mad agent removal make the call back

/*

 * Copyright (c) 2004, 2005, 2006 Voltaire, Inc. All rights reserved.

 * Copyright (c) 2005, 2006 Cisco Systems.  All rights reserved.

 * Copyright (c) 2013-2014 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *	- Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *	- Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * iser_create_device_ib_res - creates Protection Domain (PD), Completion

 * Queue (CQ), DMA Memory Region (DMA MR) with the device associated with

 * the adaptor.

 *

 * Return: 0 on success, -1 on failure

/*

 * iser_free_device_ib_res - destroy/dealloc/dereg the DMA MR,

 * CQ and PD created with the device associated with the adaptor.

/**

 * iser_alloc_fastreg_pool - Creates pool of fast_reg descriptors

 * for fast registration work requests.

 * @ib_conn: connection RDMA resources

 * @cmds_max: max number of SCSI commands for this connection

 * @size: max number of pages per map request

 *

 * Return: 0 on success, or errno code on failure

/**

 * iser_free_fastreg_pool - releases the pool of fast_reg descriptors

 * @ib_conn: connection RDMA resources

/*

 * iser_create_ib_conn_res - Queue-Pair (QP)

 *

 * Return: 0 on success, -1 on failure

/*

 * based on the resolved device node GUID see if there already allocated

 * device for this device. If there's no such, create one.

 find if there's a match using the node GUID */

 assign this device to the device */

 init the device and link it into ig device list */

 if there's no demand for this device, release it */

/*

 * Called with state mutex held

 Wait for conn_stop to complete */

 Wait for IB resouces cleanup to complete */

/**

 * iser_free_ib_conn_res - release IB related resources

 * @iser_conn: iser connection struct

 * @destroy: indicator if we need to try to release the

 *     iser device and memory regoins pool (only iscsi

 *     shutdown and DEVICE_REMOVAL will use this).

 *

 * This routine is called with the iser state mutex held

 * so the cm_id removal is out of here. It is Safe to

 * be invoked multiple times.

/**

 * iser_conn_release - Frees all conn objects and deallocs conn descriptor

 * @iser_conn: iSER connection context

 In case we endup here without ep_disconnect being invoked. */

	/*

	 * In case we never got to bind stage, we still need to

	 * release IB resources (which is safe to call more than once).

/**

 * iser_conn_terminate - triggers start of the disconnect procedures and

 * waits for them to be done

 * @iser_conn: iSER connection context

 *

 * Called with state mutex held

 terminate the iser conn only if the conn state is UP */

 suspend queuing of new iscsi commands */

	/*

	 * In case we didn't already clean up the cma_id (peer initiated

	 * a disconnection), we need to Cause the CMA to change the QP

	 * state to ERROR.

 block until all flush errors are consumed */

/*

 * Called with state mutex held

	/*

	 * FRs without SG_GAPS can only map up to a (device) page per entry,

	 * but if the first entry is misaligned we'll end up using two entries

	 * (head and tail) for a single page worth data, so one additional

	 * entry is required.

/*

 * Called with state mutex held

 bailout */

 connection T10-PI support */

/*

 * Called with state mutex held

 bailout */

 bailout */

	/*

	 * We are not guaranteed that we visited disconnected_handler

	 * by now, call it here to be safe that we handle CM drep

	 * and flush errors.

		/*

		 * we *must* destroy the device as we cannot rely

		 * on iscsid to be around to initiate error handling.

		 * also if we are not in state DOWN implicitly destroy

		 * the cma_id.

/*

 * starts the process of connecting to the target

 * sleeps until the connection is established or rejected

 the device is known only --after-- address resolution */

 mark end of work requests list */

/**

 * iser_post_send - Initiate a Send DTO operation

 * @ib_conn: connection RDMA resources

 * @tx_desc: iSER TX descriptor

 * @signal: true to send work request as SIGNALED

 *

 * Return: 0 on success, -1 on failure

 Not a lot we can do, return ambiguous guard error */

/*

 * Copyright (c) 2004, 2005, 2006 Voltaire, Inc. All rights reserved.

 * Copyright (c) 2013-2014 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *	- Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *	- Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/* Register user buffer memory and initialize passive rdma

 *  dto descriptor. Data size is stored in

 *  task->data[ISER_DIR_IN].data_len, Protection size

 *  os stored in task->prot[ISER_DIR_IN].data_len

/* Register user buffer memory and initialize passive rdma

 *  dto descriptor. Data size is stored in

 *  task->data[ISER_DIR_OUT].data_len, Protection size

 *  is stored at task->prot[ISER_DIR_OUT].data_len

 creates a new tx descriptor and adds header regd buffer */

 make sure we never redo any unmapping */

 cmds_max is 2^N */

 make sure we never redo any unmapping */

 check if this is the last login - going to full feature phase */

	/*

	 * Check that there is one posted recv buffer

	 * (for the last login response).

 Initial post receive buffers */

/**

 * iser_send_command - send command PDU

 * @conn: link to matching iscsi connection

 * @task: SCSI command task

 build the tx desc regd header and add it to the tx desc dto */

 using a scatter list */

/**

 * iser_send_data_out - send data out PDU

 * @conn: link to matching iscsi connection

 * @task: SCSI command task

 * @hdr: pointer to the LLD's iSCSI message header

 build the tx desc */

 build the tx desc regd header and add it to the tx desc dto */

	/* decrementing conn->post_recv_buf_count only --after-- freeing the   *

	 * task eliminates the need to worry on tasks which are completed in   *

	 * parallel to the execution of iser_conn_term. So the code that waits *

 this arithmetic is legal by libiscsi dd_data allocation */

/*

 * Copyright (c) 2004, 2005, 2006 Voltaire, Inc. All rights reserved.

 * Copyright (c) 2013-2014 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *	- Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *	- Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * FIXME: rework the registration code path to differentiate

	 * rkey/lkey use cases

	/*

	 * The signature MR cannot be invalidated and reused without checking.

	 * libiscsi calls the check_protection transport handler only if

	 * SCSI-Response is received. And the signature MR is not checked if

	 * the task is completed for some other reason like a timeout or error

	 * handling. That's why we must check the signature MR here before

	 * putting it to the free pool.

	/*

	 * At the moment we hard code those, but in the future

	 * we will take them from sc.

/*

 * iSCSI Initiator over iSER Data-Path

 *

 * Copyright (C) 2004 Dmitry Yusupov

 * Copyright (C) 2004 Alex Aizman

 * Copyright (C) 2005 Mike Christie

 * Copyright (c) 2005, 2006 Voltaire, Inc. All rights reserved.

 * Copyright (c) 2013-2014 Mellanox Technologies. All rights reserved.

 * maintained by openib-general@openib.org

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *	- Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *	- Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 * Credits:

 *	Christoph Hellwig

 *	FUJITA Tomonori

 *	Arne Redlich

 *	Zhenyu Wang

 * Modified by:

 *      Erez Zilber

/*

 * iscsi_iser_recv() - Process a successful recv completion

 * @conn:         iscsi connection

 * @hdr:          iscsi header

 * @rx_data:      buffer containing receive data payload

 * @rx_data_len:  length of rx_data

 *

 * Notes: In case of data length errors or iscsi PDU completion failures

 *        this routine will signal iscsi layer of connection failure.

 verify PDU length */

/**

 * iscsi_iser_pdu_alloc() - allocate an iscsi-iser PDU

 * @task:     iscsi task

 * @opcode:   iscsi command opcode

 *

 * Netes: This routine can't fail, just assign iscsi task

 *        hdr and max hdr size.

/**

 * iser_initialize_task_headers() - Initialize task headers

 * @task:       iscsi task

 * @tx_desc:    iser tx descriptor

 *

 * Notes:

 * This routine may race with iser teardown flow for scsi

 * error handling TMFs. So for TMF we should acquire the

 * state mutex to avoid dereferencing the IB device which

 * may have already been terminated.

/**

 * iscsi_iser_task_init() - Initialize iscsi-iser task

 * @task: iscsi task

 *

 * Initialize the task for the scsi command or mgmt command.

 *

 * Return: Returns zero on success or -ENOMEM when failing

 *         to init task headers (dma mapping error).

 mgmt task */

/**

 * iscsi_iser_mtask_xmit() - xmit management (immediate) task

 * @conn: iscsi connection

 * @task: task management task

 *

 * Notes:

 *	The function can return -EAGAIN in which case caller must

 *	call it again later, or recover. '0' return code means successful

 *	xmit.

 *

	/* since iser xmits control with zero copy, tasks can not be recycled

	 * right after sending them.

	 * The recycling scheme is based on whether a response is expected

	 * - if yes, the task is recycled at iscsi_complete_pdu

	 * - if no,  the task is recycled at iser_snd_completion

 Send data-out PDUs while there's still unsolicited data to send */

 the buffer description has been passed with the command */

 Send the command */

/**

 * iscsi_iser_task_xmit() - xmit iscsi-iser task

 * @task: iscsi task

 *

 * Return: zero on success or escalates $error on failure.

 Send the cmd PDU */

 Send unsolicited data-out PDU(s) if necessary */

/**

 * iscsi_iser_cleanup_task() - cleanup an iscsi-iser task

 * @task: iscsi task

 *

 * Notes: In case the RDMA device is already NULL (might have

 *        been removed in DEVICE_REMOVAL CM event it will bail-out

 *        without doing dma unmapping.

 DEVICE_REMOVAL event might have already released the device */

 mgmt tasks do not need special cleanup */

/**

 * iscsi_iser_check_protection() - check protection information status of task.

 * @task:     iscsi task

 * @sector:   error sector if exsists (output)

 *

 * Return: zero if no data-integrity errors have occured

 *         0x1: data-integrity error occured in the guard-block

 *         0x2: data-integrity error occured in the reference tag

 *         0x3: data-integrity error occured in the application tag

 *

 *         In addition the error sector is marked.

/**

 * iscsi_iser_conn_create() - create a new iscsi-iser connection

 * @cls_session: iscsi class connection

 * @conn_idx:    connection index within the session (for MCS)

 *

 * Return: iscsi_cls_conn when iscsi_conn_setup succeeds or NULL

 *         otherwise.

	/*

	 * due to issues with the login code re iser sematics

	 * this not set in iscsi_conn_setup - FIXME

/**

 * iscsi_iser_conn_bind() - bind iscsi and iser connection structures

 * @cls_session:     iscsi class session

 * @cls_conn:        iscsi class connection

 * @transport_eph:   transport end-point handle

 * @is_leading:      indicate if this is the session leading connection (MCS)

 *

 * Return: zero on success, $error if iscsi_conn_bind fails and

 *         -EINVAL in case end-point doesn't exsits anymore or iser connection

 *         state is not UP (teardown already started).

	/* the transport ep handle comes from user space so it must be

	/* binds the iSER connection retrieved from the previously

	 * connected ep_handle to the iSCSI layer connection. exchanges

/**

 * iscsi_iser_conn_start() - start iscsi-iser connection

 * @cls_conn: iscsi class connection

 *

 * Notes: Here iser intialize (or re-initialize) stop_completion as

 *        from this point iscsi must call conn_stop in session/connection

 *        teardown so iser transport must wait for it.

/**

 * iscsi_iser_conn_stop() - stop iscsi-iser connection

 * @cls_conn:  iscsi class connection

 * @flag:      indicate if recover or terminate (passed as is)

 *

 * Notes: Calling iscsi_conn_stop might theoretically race with

 *        DEVICE_REMOVAL event and dereference a previously freed RDMA device

 *        handle, so we call it under iser the state lock to protect against

 *        this kind of race.

	/*

	 * Userspace may have goofed up and not bound the connection or

	 * might have only partially setup the connection.

 unbind */

/**

 * iscsi_iser_session_destroy() - destroy iscsi-iser session

 * @cls_session: iscsi class session

 *

 * Removes and free iscsi host.

/**

 * iscsi_iser_session_create() - create an iscsi-iser session

 * @ep:             iscsi end-point handle

 * @cmds_max:       maximum commands in this session

 * @qdepth:         session command queue depth

 * @initial_cmdsn:  initiator command sequnce number

 *

 * Allocates and adds a scsi host, expose DIF supprot if

 * exists, and sets up an iscsi session.

	/*

	 * older userspace tools (before 2.0-870) did not pass us

	 * the leading conn's ep so this will be NULL;

 TBD */

/**

 * iscsi_iser_conn_get_stats() - get iscsi connection statistics

 * @cls_conn:    iscsi class connection

 * @stats:       iscsi stats to output

 *

 * Output connection statistics.

 always 0 */

 always 0 */

/**

 * iscsi_iser_ep_connect() - Initiate iSER connection establishment

 * @shost:          scsi_host

 * @dst_addr:       destination address

 * @non_blocking:   indicate if routine can block

 *

 * Allocate an iscsi endpoint, an iser_conn structure and bind them.

 * After that start RDMA connection establishment via rdma_cm. We

 * don't allocate iser_conn embedded in iscsi_endpoint since in teardown

 * the endpoint will be destroyed at ep_disconnect while iser_conn will

 * cleanup its resources asynchronuously.

 *

 * Return: iscsi_endpoint created by iscsi layer or ERR_PTR(error)

 *         if fails.

/**

 * iscsi_iser_ep_poll() - poll for iser connection establishment to complete

 * @ep:            iscsi endpoint (created at ep_connect)

 * @timeout_ms:    polling timeout allowed in ms.

 *

 * This routine boils down to waiting for up_completion signaling

 * that cma_id got CONNECTED event.

 *

 * Return: 1 if succeeded in connection establishment, 0 if timeout expired

 *         (libiscsi will retry will kick in) or -1 if interrupted by signal

 *         or more likely iser connection state transitioned to TEMINATING or

 *         DOWN during the wait period.

 if conn establishment failed, return error code to iscsi */

 success, this is the equivalent of EPOLLOUT */

 timeout */

 signal */

/**

 * iscsi_iser_ep_disconnect() - Initiate connection teardown process

 * @ep:    iscsi endpoint handle

 *

 * This routine is not blocked by iser and RDMA termination process

 * completion as we queue a deffered work for iser/RDMA destruction

 * and cleanup or actually call it immediately in case we didn't pass

 * iscsi conn bind/start stage, thus it is safe.

	/*

	 * if iser_conn and iscsi_conn are bound, we must wait for

	 * iscsi_conn_stop and flush errors completion before freeing

	 * the iser resources. Otherwise we are safe to free resources

	 * immediately.

 session management */

 connection management */

 iscsi host params */

 IO */

 recovery */

 device init is called only after the first addr resolution */

/*

 * Copyright (c) 2005 Cisco Systems.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/**

 * srp_destroy_fr_pool() - free the resources owned by a pool

 * @pool: Fast registration pool to be destroyed.

/**

 * srp_create_fr_pool() - allocate and initialize a pool for fast registration

 * @device:            IB device to allocate fast registration descriptors for.

 * @pd:                Protection domain associated with the FR descriptors.

 * @pool_size:         Number of descriptors to allocate.

 * @max_page_list_len: Maximum fast registration work request page list length.

/**

 * srp_fr_pool_get() - obtain a descriptor suitable for fast registration

 * @pool: Pool to obtain descriptor from.

/**

 * srp_fr_pool_put() - put an FR descriptor back in the free list

 * @pool: Pool the descriptor was allocated from.

 * @desc: Pointer to an array of fast registration descriptor pointers.

 * @n:    Number of descriptors to put back.

 *

 * Note: The caller must already have queued an invalidation request for

 * desc->mr->rkey before calling this function.

/**

 * srp_destroy_qp() - destroy an RDMA queue pair

 * @ch: SRP RDMA channel.

 *

 * Drain the qp before destroying it.  This avoids that the receive

 * completion handler can access the queue pair while it is

 * being destroyed.

 queue_size + 1 for ib_drain_rq() */

/*

 * Note: this function may be called without srp_alloc_iu_bufs() having been

 * invoked. Hence the ch->[rt]x_ring checks.

 If srp_new_cm_id() succeeded but srp_create_ch_ib() not, return. */

	/*

	 * Avoid that the SCSI error handler tries to use this channel after

	 * it has been freed. The SCSI error handler can namely continue

	 * trying to perform recovery actions after scsi_remove_host()

	 * returned.

	/*

	 * Pick some arbitrary defaults here; we could make these

	 * module parameters if anyone cared about setting them.

	/*

	 * In the published SRP specification (draft rev. 16a), the

	 * port identifier format is 8 bytes of ID extension followed

	 * by 8 bytes of GUID.  Older drafts put the two halves in the

	 * opposite order, so that the GUID comes first.

	 *

	 * Targets conforming to these obsolete drafts can be

	 * recognized by the I/O Class they report.

	/*

	 * Topspin/Cisco SRP targets will reject our login unless we

	 * zero out the first 8 bytes of our initiator port ID and set

	 * the second 8 bytes to the local node GUID.

 XXX should send SRP_I_LOGOUT request */

/**

 * srp_del_scsi_host_attr() - Remove attributes defined in the host template.

 * @shost: SCSI host whose attributes to remove from sysfs.

 *

 * Note: Any attributes defined in the host template and that did not exist

 * before invocation of this function will be ignored.

/**

 * srp_connected_ch() - number of connected channels

 * @target: SRP target port.

		/*

		 * The CM event handling code will set status to

		 * SRP_PORT_REDIRECT if we get a port redirect REJ

		 * back, or SRP_DLID_REDIRECT if we get a lid/qp

		 * redirect REJ back.

/**

 * srp_claim_req - Take ownership of the scmnd associated with a request.

 * @ch: SRP RDMA channel.

 * @req: SRP request.

 * @sdev: If not NULL, only take ownership for this SCSI device.

 * @scmnd: If NULL, take ownership of @req->scmnd. If not NULL, only take

 *         ownership of @req->scmnd if it equals @scmnd.

 *

 * Return value:

 * Either NULL or a pointer to the SCSI command the caller became owner of.

/**

 * srp_free_req() - Unmap data and adjust ch->req_lim.

 * @ch:     SRP RDMA channel.

 * @req:    Request to be freed.

 * @scmnd:  SCSI command associated with @req.

 * @req_lim_delta: Amount to be added to @target->req_lim.

 Calculate maximum initiator to target information unit length. */

/*

 * It is up to the caller to ensure that srp_rport_reconnect() calls are

 * serialized and that no concurrent srp_queuecommand(), srp_abort(),

 * srp_reset_device() or srp_reset_host() calls will occur while this function

 * is in progress. One way to realize that is not to call this function

 * directly but to call srp_reconnect_rport() instead since that last function

 * serializes calls of this function via rport->mutex and also blocks

 * srp_queuecommand() calls before invoking this function.

	/*

	 * Now get a new local CM ID so that we avoid confusing the target in

	 * case things are really fouled up. Doing so also ensures that all CM

	 * callbacks will have finished before a new QP is allocated.

		/*

		 * Whether or not creating a new CM ID succeeded, create a new

		 * QP. This guarantees that all completion callback function

		 * invocations have finished before request resetting starts.

/*

 * Map up to sg_nents elements of state->sg where *sg_offset_p is the offset

 * where to start in the first element. If sg_offset_p != NULL then

 * *sg_offset_p is updated to the offset in state->sg[retval] of the first

 * byte that has not yet been mapped.

/*

 * Register the indirect data buffer descriptor with the HCA.

 *

 * Note: since the indirect data buffer descriptor has been allocated with

 * kmalloc() it is guaranteed that this buffer is a physically contiguous

 * memory buffer.

 hack! */

 hack^2 */

/**

 * srp_map_data() - map SCSI data buffer onto an SRP request

 * @scmnd: SCSI command to map

 * @ch: SRP RDMA channel

 * @req: SRP request

 *

 * Returns the length in bytes of the SRP_CMD IU or a negative value if

 * mapping failed. The size of any immediate data is not included in the

 * return value.

		/*

		 * The midlayer only generated a single gather/scatter

		 * entry, or DMA mapping coalesced everything to a

		 * single entry.  So a direct descriptor along with

		 * the DMA MR suffices.

	/*

	 * We have more than one scatter/gather entry, so build our indirect

	 * descriptor table, trying to merge as many entries as we can.

	/* We've mapped the request, now pull as much of the indirect

	 * descriptor table as we can into the command buffer. If this

	 * target is not using an external indirect table, we are

	 * guaranteed to fit into the command, as the SCSI layer won't

	 * give us more S/G entries than we allow.

		/*

		 * Memory registration collapsed the sg-list into one entry,

		 * so use a direct descriptor.

/*

 * Return an IU and possible credit to the free pool

/*

 * Must be called with ch->lock held to protect req_lim and free_tx.

 * If IU is not sent, it must be returned using srp_put_tx_iu().

 *

 * Note:

 * An upper limit for the number of allocated information units for each

 * request type is:

 * - SRP_IU_CMD: SRP_CMD_SQ_SIZE, since the SCSI mid-layer never queues

 *   more than Scsi_Host.can_queue requests.

 * - SRP_IU_TSK_MGMT: SRP_TSK_MGMT_SQ_SIZE.

 * - SRP_IU_RSP: 1, since a conforming SRP target never sends more than

 *   one unanswered SRP request to an initiator.

 Initiator responses to target requests do not consume credits */

/*

 * Note: if this function is called from inside ib_drain_sq() then it will

 * be called without ch->lock being held. If ib_drain_sq() dequeues a WQE

 * with status IB_WC_SUCCESS then that's a bug.

/**

 * srp_post_send() - send an SRP information unit

 * @ch: RDMA channel over which to send the information unit.

 * @iu: Information unit to send.

 * @len: Length of the information unit excluding immediate data.

 XXX Handle target logout */

/**

 * srp_tl_err_work() - handle a transport layer error

 * @work: Work structure embedded in an SRP target port.

 *

 * Note: This function may get invoked before the rport has been created,

 * hence the target->rport test.

		/*

		 * If we ran out of memory descriptors (-ENOMEM) because an

		 * application is queuing many requests with more than

		 * max_pages_per_mr sg-list elements, tell the SCSI mid-layer

		 * to reduce queue depth temporarily.

	/*

	 * Avoid that the loops that iterate over the request ring can

	 * encounter a dangling SCSI command pointer.

/*

 * Note: the resources allocated in this function are freed in

 * srp_free_ch_ib().

	/*

	 * According to section 11.2.4.2 in the IBTA spec (Modify Queue Pair,

	 * table 91), both the QP timeout and the retry count have to be set

	 * for RC QP's during the RTR to RTS transition.

	/*

	 * Set target->rq_tmo_jiffies to one second more than the largest time

	 * it can take before an error completion is generated. See also

	 * C9-140..142 in the IBTA spec for more information about how to

	 * convert the QP Local ACK Timeout value to nanoseconds.

		/*

		 * Reserve credits for task management so we don't

		 * bounce requests back to the SCSI mid-layer.

			/*

			 * Topspin/Cisco SRP gateways incorrectly send

			 * reject reason code 25 when they mean 24

			 * (port redirect).

/**

 * srp_change_queue_depth - setting device queue depth

 * @sdev: scsi device struct

 * @qdepth: requested queue depth

 *

 * Returns queue depth.

	/*

	 * Lock the rport mutex to avoid that srp_create_ch_ib() is

	 * invoked while a task management function is being sent.

/*

 * Return values:

 * < 0 upon failure. Caller is responsible for SRP target port cleanup.

 * 0 and target->state == SRP_TARGET_REMOVED if asynchronous target port

 *    removal has been scheduled.

 * 0 and target->state != SRP_TARGET_REMOVED upon success.

/**

 * srp_conn_unique() - check whether the connection to a target is unique

 * @host:   SRP host.

 * @target: SRP target port.

/*

 * Target ports are added by writing

 *

 *     id_ext=<SRP ID ext>,ioc_guid=<SRP IOC GUID>,dgid=<dest GID>,

 *     pkey=<P_Key>,service_id=<service ID>

 * or

 *     id_ext=<SRP ID ext>,ioc_guid=<SRP IOC GUID>,

 *     [src=<IPv4 address>,]dest=<IPv4 address>:<port number>

 *

 * to the add_target sysfs attribute.

/**

 * srp_parse_in - parse an IP address and port number combination

 * @net:	   [in]  Network namespace.

 * @sa:		   [out] Address family, IP address and port number.

 * @addr_port_str: [in]  IP address and port number.

 * @has_port:	   [out] Whether or not @addr_port_str includes a port number.

 *

 * Parse the following address formats:

 * - IPv4: <ip_address>:<port>, e.g. 1.2.3.4:5.

 * - IPv6: \[<ipv6_address>\]:<port>, e.g. [1::2:3%4]:5.

	/*

	 * Avoid that the SCSI host can be removed by srp_remove_target()

	 * before this function returns.

			/*

			 * FR can only map one HCA page per entry. If the start

			 * address is not aligned on a HCA page boundary two

			 * entries will be used for the head and the tail

			 * although these two entries combined contain at most

			 * one HCA page of data. Hence the "+ 1" in the

			 * calculation below.

			 *

			 * The indirect data buffer descriptor is contiguous

			 * so the memory for that buffer will only be

			 * registered if register_always is true. Hence add

			 * one to mr_per_cmd if register_always has been set.

		/*

		 * If a call to srp_remove_target() has not been scheduled,

		 * drop the network namespace reference now that was obtained

		 * earlier in this function.

	/*

	 * Use the smallest page size supported by the HCA, down to a

	 * minimum of 4096 bytes. We're unlikely to build large sglists

	 * out of smaller entries.

		/*

		 * Wait for the sysfs entry to go away, so that no new

		 * target ports can be created.

		/*

		 * Remove all target ports.

		/*

		 * Wait for tl_err and target port removal tasks.

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 set correct QKey for QP */

 attach QP to multicast group */

 Can't set this in a INIT->RTR transition */

 1 extra for rx_drain_qp */

/*

 * Copyright (c) 2012 Mellanox Technologies. -  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 For ARPHRD_xxx */

 IFLA_IPOIB_PKEY   */

 IFLA_IPOIB_MODE   */

 IFLA_IPOIB_UMCAST */

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 * Copyright (c) 2004 Voltaire, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 For ARPHRD_xxx */

 Bring up any child interfaces too */

 Bring down any child interfaces too */

 dev->mtu > 2K ==> connected mode */

 notify lower level on the real mtu */

 Called with an RCU read lock taken */

/*

 * Find the master net_device on top of the given net_device.

 * @dev: base IPoIB net_device

 *

 * Returns the master net_device with a reference held, or the same net_device

 * if no master exists.

/**

 * ipoib_get_net_dev_match_addr - Find a net_device matching

 * the given address, which is an upper device of the given net_device.

 *

 * @addr: IP address to look for.

 * @dev: base IPoIB net_device

 *

 * If found, returns the net_device with a reference held. Otherwise return

 * NULL.

/* returns the number of IPoIB netdevs on top a given ipoib device matching a

 * pkey_index and address, if one exists.

 *

 * @found_net_dev: contains a matching net_device if the return value >= 1,

			/* Verify the net_device matches the IP address, as

 Check child interfaces */

/* Returns the number of matching net_devs found (between 0 and 2). Also

 * return the matching net_device in the @net_dev parameter, holding a

 See if we can find a unique device matching the L2 parameters */

	/* Couldn't find a unique device with L2 parameters only. Use L3

 flush paths if we switch modes so that connections are restarted */

 remove all neigh connected to this path */

 CONFIG_INFINIBAND_IPOIB_DEBUG */

		/*

		 * pathrec.dgid is used as the database key from the LLADDR,

		 * it must remain unchanged even if the SA returns a different

		 * GID to use in the AH.

				/*

				 * Dropping the ah reference inside

				 * priv->lock is safe here, because we

				 * will hold one more reference from

				 * the original value of path->ah (ie

				 * old_ah).

	/* To avoid race condition, make sure that the

	 * neigh will be added only once.

 no broadcast means that all paths are (going to be) not valid */

			/*

			 * make sure there are no changes in the existing

			 * path record

 multicast, arrange "if" according to probability */

 ethertype not supported by IPoIB */

 Add in the P_Key for multicast*/

 unicast, arrange "switch" according to probability */

 for unicast ARP and RARP should always perform path find */

 ethertype not supported by IPoIB */

 note we now hold a ref to neigh */

 XXX reset QP, etc. */

	/*

	 * we don't rely on dst_entry structure,  always stuff the

	 * destination address into skb hard header so we can figure out where

	 * to send the packet later.

 parent interface */

 child/vlan interface */

	/*

	 * Use only the address parts that contributes to spreading

	 * The subnet prefix is not used as one can not connect to

	 * same remote port (GUID) using the same remote QPN via two

	 * different subnets.

 qpn octets[1:4) & port GUID octets[12:20) */

 found, take one ref on behalf of the caller */

 deleted */

 neigh is obsolete if it was idle for two GC periods */

 was the neigh idle for two GC periods */

 remove from path/mc list */

 one ref on behalf of the caller */

	/* need to add a new neigh, but maybe some other thread succeeded?

	 * recalc hash, maybe hash resize took place so we do a search

 found, take one ref on behalf of the caller */

 deleted */

 one ref on behalf of the hash table */

 put in hash */

 neigh reference count was dropprd to zero */

 Called as a result of removal from hash table */

 note TX context may hold another ref */

 found */

 remove from parent list */

 start garbage collection */

 remove all neigh connected to a given path or mcast */

 delete neighs belong to this parent */

 remove from parent list */

 remove from path/mc list */

 Allocate RX/TX "rings" to hold queued skbs */

 priv->tx_head, tx_tail and global_tx_tail/head are already 0 */

 after qp created set dev address */

	/*

	 * the various IPoIB tasks assume they will never race against

	 * themselves, so always use a single thread workqueue

 create pd, which used both for control and datapath*/

/*

 * This must be called before doing an unregister_netdev on a parent device to

 * shutdown the IB event handler.

	/*

	 * ipoib_set_mac checks netif_running before pushing work, clearing

	 * running ensures the it will not add more work.

 ipoib_event() cannot be running once this returns */

	/*

	 * Work on the queue grabs the rtnl lock, so this cannot be done while

	 * also holding it.

 Let's set this one too for backwards compatibility. */

 MTU will be reset when mcast join happens */

	/*

	 * Set the full membership bit, so that we join the right

	 * broadcast group, etc.

	/*

	 * ipoib_remove_one guarantees the children are removed before the

	 * parent, and that is the only place where a parent can be removed.

 no more works over the priv->wq */

 See ipoib_mcast_carrier_on_task() */

	/*

	 * unregister_netdev always frees the netdev, we use this mode

	 * consistently to unify all the various unregister paths, including

	 * those connected to rtnl_link_ops which require it.

	/*

	 * Only the child register_netdev flows can handle priv_destructor

	 * being set, so we force it to NULL here and handle manually until it

	 * is safe to turn on.

	/*

	 * Upon success the caller must ensure ipoib_intf_free is called or

	 * register_netdevice succeed'd and priv_destructor is set to

	 * ipoib_intf_free.

	/*

	 * There are some error flows around register_netdev failing that may

	 * attempt to call priv_destructor twice, prevent that from happening.

 unregister/destroy is very complicated. Make bugs more obvious. */

	/* Make sure the QPN, reserved and subnet prefix match the current

	 * lladdr, it also makes sure the lladdr is unicast.

/*

 * We erroneously exposed the iface's port number in the dev_id

 * sysfs field long after dev_port was introduced for that purpose[1],

 * and we need to stop everyone from relying on that.

 * Let's overload the shower routine for the dev_id file here

 * to gently bring the issue up.

 *

 * [1] https://www.spinics.net/lists/netdev/msg272123.html

	/*

	 * ndev->dev_port will be equal to 0 in old kernel prior to commit

	 * 9b8b2a323008 ("IB/ipoib: Use dev_port to expose network interface

	 * port numbers") Zero was chosen as special case for user space

	 * applications to fallback and query dev_id to check if it has

	 * different value or not.

	 *

	 * Don't print warning in such scenario.

	 *

	 * https://github.com/systemd/systemd/blob/master/src/udev/udev-builtin-net_id.c#L358

 call event handler to ensure pkey in sync */

	/*

	 * We cannot set priv_destructor before register_netdev because we

	 * need priv to be always valid during the error flow to execute

	 * ipoib_parent_unregister_pre(). Instead handle it manually and only

	 * enter priv_destructor mode once we are completely registered.

	/*

	 * When copying small received packets, we only copy from the

	 * linear data part of the SKB, so we rely on this condition.

	/*

	 * We create a global workqueue here that is used for all flush

	 * operations.  However, if you attempt to flush a workqueue

	 * from a task on that same workqueue, it deadlocks the system.

	 * We want to be able to flush the tasks associated with a

	 * specific net device, so we also create a workqueue for each

	 * netdevice.  We queue up the tasks for that device only on

	 * its private workqueue, and we only queue up flush events

	 * on our global flush workqueue.  This avoids the deadlocks.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * Since the legacy sysfs interface uses pkey for deletion it cannot

	 * support more than one interface with the same pkey, it creates

	 * ambiguity.  The RTNL interface deletes using the netdev so it does

	 * not have a problem to support duplicated pkeys.

	/*

	 * First ensure this isn't a duplicate. We check the parent device and

	 * then all of the legacy child interfaces to make sure the Pkey

	 * doesn't match.

/*

 * NOTE: If this function fails then the priv->dev will remain valid, however

 * priv will have been freed and must not be touched by caller in the error

 * case.

 *

 * If (ndev->reg_state == NETREG_UNINITIALIZED) then it is up to the caller to

 * free the net_device (just as rtnl_newlink does) otherwise the net_device

 * will be freed when the rtnl is unlocked.

	/*

	 * We do not need to touch priv if register_netdevice fails, so just

	 * always use this flow.

	/*

	 * Racing with unregister of the parent must be prevented by the

	 * caller.

		/*

		 * register_netdevice sometimes calls priv_destructor,

		 * sometimes not. Make sure it was done.

 RTNL childs don't need proprietary sysfs entries */

/*

 * sysfs callbacks of a netdevice cannot obtain the rtnl lock as

 * unregister_netdev ultimately deletes the sysfs files while holding the rtnl

 * lock. This deadlocks the system.

 *

 * A callback can use rtnl_trylock to avoid the deadlock but it cannot call

 * unregister_netdev as that internally takes and releases the rtnl_lock.  So

 * instead we find the netdev to unregister and then do the actual unregister

 * from the global work queue where we can obtain the rtnl_lock safely.

 Unregistering tasks can race with another task or parent removal */

/*

 * Copyright (c) 2006 Mellanox Technologies. All rights reserved

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * IPoIB adds a IPOIB_ENCAP_LEN byte header, this will align the

	 * IP header to a multiple of 16.

	/* We only reserved 1 extra slot in CQ for drain WRs, so

	/*

	 * QPs on flush list are error state.  This way, a "flush

	 * error" WC will be immediately generated for each WR we post.

 For drain WR */

 For drain WR */

 FIXME: 0 Seems not to work */

	/*

	 * Current Mellanox HCA firmware won't generate completions

	 * with error for drain WRs unless the QP has been moved to

	 * RTS first. This work-around leaves a window where a QP has

	 * moved to error asynchronously, but this will eventually get

	 * fixed in firmware, so let's not error out if modify QP

	 * fails.

	/* Add this entry to passive ids list head, but do not re-add it

 Adjust length of skb with fragments to match received data */

 put header into skb */

 don't need this page */

			/* Move this entry to list head, but do not re-add it

		/*

		 * If we can't allocate a new RX buffer, dump

		 * this packet and reuse the old buffer.

 XXX get correct PACKET_ type here */

 Does skb_linearize return ok without reducing nr_frags? */

	/*

	 * We put the skb into the tx_ring _before_ we call post_send()

	 * because it's entirely possible that the completion handler will

	 * run before we execute anything after the post_send().  That

	 * means we have to make sure everything is properly recorded and

	 * our state is consistent before we call post_send().

 FIXME: is this right? Shouldn't we only increment on success? */

		/* IB_WC[_RNR]_RETRY_EXC_ERR error is part of the life cycle,

		 * so don't make waves.

 Wait for all RX to be drained */

			/*

			 * assume the HW is wedged and just free up everything.

 FIXME */;

 FIXME */

	/*

	 * Pick some arbitrary defaults here; we could make these

	 * module parameters if anyone cared about setting them.

 RFC draft warns against retries */

 RFC draft warns against retries */

 Wait for all sends to complete */

		/*

		 * As long as the search is with these 2 locks,

		 * path existence indicates its validity.

		/* List is sorted by LRU, start from tail,

	/* The assumption is that the function ipoib_set_mode returned

	 * with the rtnl held by it, if not the value -EBUSY returned,

	 * then no need to rtnl_unlock

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 * Copyright (c) 2004 Voltaire, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 join state that allows creating mcg with sendonly member request */

/*

 * This should be called with the priv->lock held

	/*

	 * We will be scheduling *something*, so cancel whatever is

	 * currently scheduled first

		/*

		 * We had a failure and want to schedule a retry later

		/*

		 * Mark this mcast for its delay, but restart the

		 * task immediately.  The join task will make sure to

		 * clear out all entries without delays, and then

		 * schedule itself to run again when the earliest

		 * delay expires

		/*

		 * Special case of retrying after a failure to

		 * allocate the broadcast multicast group, wait

		 * 1 second and try again

 remove all neigh connected to this mcast */

	/* Set the multicast MTU and cached Q_Key before we attach if it's

	 * the broadcast group.

update priv member according to the new mcast*/

 assume if the admin and the mcast are the same both can be changed */

 use original error */

 actually send any queued packets */

	/*

	 * Take rtnl_lock to avoid racing with ipoib_stop() and

	 * turning the carrier back on while a device is being

	 * removed.  However, ipoib_stop() will attempt to flush

	 * the workqueue while holding the rtnl lock, so loop

	 * on trylock until either we get the lock or we see

	 * FLAG_OPER_UP go away as that signals that we are bailing

	 * and can safely ignore the carrier on work.

 We trap for port events ourselves. */

		/*

		 * Defer carrier on work to priv->wq to avoid a

		 * deadlock on rtnl_lock here.  Requeue our multicast

		 * work too, which will end up happening right after

		 * our carrier on task work and will allow us to

		 * send out all of the non-broadcast joins

			/*

			 * We only retry sendonly joins once before we drop

			 * the packet and quit trying to deal with the

			 * group.  However, we leave the group in the

			 * mcast list as an unjoined group.  If we want to

			 * try joining again, we simply queue up a packet

			 * and restart the join thread.  The empty queue

			 * is why the join thread ignores this group.

 Requeue this join task with a backoff delay */

	/*

	 * Make sure to set mcast->mc before we clear the busy flag to avoid

	 * racing with code that checks for BUSY before checking mcast->mc

/*

 * Caller must hold 'priv->lock'

		/*

		 * RFC 4391:

		 *  The MGID MUST use the same P_Key, Q_Key, SL, MTU,

		 *  and HopLimit as those used in the broadcast-GID.  The rest

		 *  of attributes SHOULD follow the values used in the

		 *  broadcast-GID as well.

		/*

		 * Send-only IB Multicast joins work at the core IB layer but

		 * require specific SM support.

		 * We can use such joins here only if the current SM supports that feature.

		 * However, if not, we emulate an Ethernet multicast send,

		 * which does not require a multicast subscription and will

		 * still send properly. The most appropriate thing to

		 * do is to create the group if it doesn't exist as that

		 * most closely emulates the behavior, from a user space

		 * application perspective, of Ethernet multicast operation.

 Requeue this join task with a backoff delay */

			/*

			 * Restart us after a 1 second delay to retry

			 * creating our broadcast group and attaching to

			 * it.  Until this succeeds, this ipoib dev is

			 * completely stalled (multicast wise).

	/*

	 * We'll never get here until the broadcast group is both allocated

	 * and attached

 Found the next unjoined group */

 Remove ourselves from the multicast group */

/*

 * Check if the multicast group is sendonly. If so remove it from the maps

 * and add to the remove list

 Is this multicast ? */

	/*

	 * make sure the in-flight joins have finished before we attempt

	 * to leave

 Let's create a new send only group now */

 put pseudoheader back on for next time */

			/* Make sure that the neigh will be added only

			 * once to mcast list.

 reserved QPN, prefix, scope */

 signature lower, pkey */

		/*

		 * shortcut...on shutdown flush is called next, just

		 * let it do all the work

	/*

	 * Unfortunately, the networking core only gives us a list of all of

	 * the multicast hardware addresses. We need to figure out which ones

	 * are new and which ones have been removed

 Clear out the found flag */

 Mark all of the entries that are found or don't exist */

 ignore group which is directly joined by userspace */

 Not found or send-only group, let's add a new entry */

 Destroy the send only entry */

 Remove all of the entries don't exist anymore */

 Move to the remove list */

	/*

	 * Double check that we are still up

 CONFIG_INFINIBAND_IPOIB_DEBUG */

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2004, 2005 Voltaire, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * the IP header will be at IPOIP_HARD_LEN + IB_GRH_BYTES, that is

	 * 64 bytes aligned

	/*

	 * If we can't allocate a new RX buffer, dump

	 * this packet and reuse the old buffer.

 First byte of dgid signals multicast when 0xff */

	/*

	 * Drop packets that this interface sent, ie multicast packets

	 * that the HCA has replicated.

/*

 * As the result of a completion error the QP Can be transferred to SQE states.

 * The function checks if the (send)QP is in SQE state and

 * moves it back to RTS state, that in order to have it functional again.

 currently support only in SQE->RTS transition*/

 Does skb_linearize return ok without reducing nr_frags? */

	/*

	 * We put the skb into the tx_ring _before_ we call post_send()

	 * because it's entirely possible that the completion handler will

	 * run before we execute anything after the post_send().  That

	 * means we have to make sure everything is properly recorded and

	 * our state is consistent before we call post_send().

 increase the tx_head after send success, but use it for queue state */

	/*

	 * After ipoib_stop_ah_reaper() we always go through

	 * ipoib_reap_dead_ahs() which ensures the work is really stopped and

	 * does a final flush out of the dead_ah's list

 print according to the new-state and the previous state.*/

	/*

	 * Move our QP to the error state and then reinitialize in

	 * when all work requests have completed or have been flushed.

 Wait for all sends and receives to complete */

			/*

			 * assume the HW is wedged and just free up

			 * all our pending work requests.

	/*

	 * We call completion handling routines that expect to be

	 * called from the BH-disabled NAPI poll context, so disable

	 * BHs here too.

			/*

			 * Convert any successful completions to flush

			 * errors to avoid passing packets up the

			 * stack after bringing the device down.

 nothing */

/*

 * Takes whatever value which is in pkey index 0 and updates priv->pkey

 * returns 0 if the pkey value was changed.

		/*

		 * Update the pkey in the broadcast address, while making sure to set

		 * the full membership bit, so that we join the right broadcast group.

/*

 * returns 0 if pkey value was found in a different slot.

/*

 * returns true if the device address of the ipoib interface has changed and the

 * new address is a valid one (i.e in the gid table), return false otherwise.

	/* The subnet prefix may have changed, update it now so we won't have

	 * to do it later

		/* There was a change while we were looking up the gid, bail

		 * here and let the next work sort this out

	/* The next section of code needs some background:

	 * Per IB spec the port GUID can't change if the HCA is powered on.

	 * port GUID is the basis for GID at index 0 which is the basis for

	 * the default device address of a ipoib interface.

	 *

	 * so it seems the flow should be:

	 * if user_changed_dev_addr && gid in gid tbl

	 *	set bit dev_addr_set

	 *	return true

	 * else

	 *	return false

	 *

	 * The issue is that there are devices that don't follow the spec,

	 * they change the port GUID when the HCA is powered, so in order

	 * not to break userspace applications, We need to check if the

	 * user wanted to control the device address and we assume that

	 * if he sets the device address back to be based on GID index 0,

	 * he no longer wishs to control it.

	 *

	 * If the user doesn't control the the device address,

	 * IPOIB_FLAG_DEV_ADDR_SET is set and ib_find_gid failed it means

	 * the port GUID has changed and GID at index 0 has changed

	 * so we need to change priv->local_gid and priv->dev->dev_addr

	 * to reflect the new GID.

	/*

	 * Flush any child interfaces too -- they might be up even if

	 * the parent is down.

 Make sure the dev_addr is set even if not flushing */

 interface is down. update pkey and leave. */

		/* child devices chase their origin pkey value, while non-child

		 * (parent) devices should always takes what present in pkey index 0

 restart QP only if P_Key index is changed */

 restart QP only if P_Key value changed */

		/* Set IPoIB operation as down to prevent races between:

		 * the flush flow which leaves MCG and on the fly joins

		 * which can happen during that time. mcast restart task

		 * should deal with join requests we missed.

	/*

	 * The device could have been brought down between the start and when

	 * we get here, don't bring it back up if it's not configured up

	/*

	 * We must make sure there are no more (path) completions

	 * that may wish to touch priv fields that are no longer valid

	/*

	 * All of our ah references aren't free until after

	 * ipoib_mcast_dev_flush(), ipoib_flush_paths, and

	 * the neighbor garbage collection is stopped and reaped.

	 * That should all be done now, so make a final ah flush.

/*

 * Copyright (c) 2007 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * These values are saved in the private data and returned

	 * when ipoib_get_coalesce() is called

 Return lane speed in unit of 1e6 bit/sec */

	/* Except the following are set, the other members of

	 * the struct ethtool_link_settings are initialized to

	 * zero in the function __ethtool_get_link_ksettings.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 nothing for now */

 nothing for now */

/*

 * Copyright (c) 2006 - 2009 Mellanox Technology Inc.  All rights reserved.

 * Copyright (C) 2008 - 2011 Bart Van Assche <bvanassche@acm.org>.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 Name of this kernel module. */

/*

 * Global Variables

 Protects srpt_dev_list. */

 List of srpt_device structures. */

 Protects both rdma_cm_port and rdma_cm_id. */

 Port number RDMA/CM will bind to. */

/*

 * The only allowed channel state changes are those that change the channel

 * state into a state with a higher numerical value. Hence the new > prev test.

/**

 * srpt_event_handler - asynchronous IB event callback function

 * @handler: IB event handler registered by ib_register_event_handler().

 * @event: Description of the event that occurred.

 *

 * Callback function called by the InfiniBand core when an asynchronous IB

 * event occurs. This callback may occur in interrupt context. See also

 * section 11.5.2, Set Asynchronous Event Handler in the InfiniBand

 * Architecture Specification.

 Refresh port data asynchronously. */

/**

 * srpt_srq_event - SRQ event callback function

 * @event: Description of the event that occurred.

 * @ctx: Context pointer specified at SRQ creation time.

/**

 * srpt_qp_event - QP event callback function

 * @event: Description of the event that occurred.

 * @ch: SRPT RDMA channel.

/**

 * srpt_set_ioc - initialize a IOUnitInfo structure

 * @c_list: controller list.

 * @slot: one-based slot number.

 * @value: four-bit value.

 *

 * Copies the lowest four bits of value in element slot of the array of four

 * bit elements called c_list (controller list). The index slot is one-based.

/**

 * srpt_get_class_port_info - copy ClassPortInfo to a management datagram

 * @mad: Datagram that will be sent as response to DM_ATTR_CLASS_PORT_INFO.

 *

 * See also section 16.3.3.1 ClassPortInfo in the InfiniBand Architecture

 * Specification.

/**

 * srpt_get_iou - write IOUnitInfo to a management datagram

 * @mad: Datagram that will be sent as response to DM_ATTR_IOU_INFO.

 *

 * See also section 16.3.3.3 IOUnitInfo in the InfiniBand Architecture

 * Specification. See also section B.7, table B.6 in the SRP r16a document.

 set present for slot 1 and empty for the rest */

/**

 * srpt_get_ioc - write IOControllerprofile to a management datagram

 * @sport: HCA port through which the MAD has been received.

 * @slot: Slot number specified in DM_ATTR_IOC_PROFILE query.

 * @mad: Datagram that will be sent as response to DM_ATTR_IOC_PROFILE.

 *

 * See also section 16.3.3.4 IOControllerProfile in the InfiniBand

 * Architecture Specification. See also section B.7, table B.7 in the SRP

 * r16a document.

/**

 * srpt_get_svc_entries - write ServiceEntries to a management datagram

 * @ioc_guid: I/O controller GUID to use in reply.

 * @slot: I/O controller number.

 * @hi: End of the range of service entries to be specified in the reply.

 * @lo: Start of the range of service entries to be specified in the reply..

 * @mad: Datagram that will be sent as response to DM_ATTR_SVC_ENTRIES.

 *

 * See also section 16.3.3.5 ServiceEntries in the InfiniBand Architecture

 * Specification. See also section B.7, table B.8 in the SRP r16a document.

/**

 * srpt_mgmt_method_get - process a received management datagram

 * @sp:      HCA port through which the MAD has been received.

 * @rq_mad:  received MAD.

 * @rsp_mad: response MAD.

/**

 * srpt_mad_send_handler - MAD send completion callback

 * @mad_agent: Return value of ib_register_mad_agent().

 * @mad_wc: Work completion reporting that the MAD has been sent.

/**

 * srpt_mad_recv_handler - MAD reception callback function

 * @mad_agent: Return value of ib_register_mad_agent().

 * @send_buf: Not used.

 * @mad_wc: Work completion reporting that a MAD has been received.

 will destroy_ah & free_send_mad in send completion */

/**

 * srpt_refresh_port - configure a HCA port

 * @sport: SRPT HCA port.

 *

 * Enable InfiniBand management datagram processing, update the cached sm_lid,

 * lid and gid values, and register a callback function for processing MADs

 * on the specified port.

 *

 * Note: It is safe to call this function more than once for the same port.

/**

 * srpt_unregister_mad_agent - unregister MAD callback functions

 * @sdev: SRPT HCA pointer.

 * @port_cnt: number of ports with registered MAD

 *

 * Note: It is safe to call this function more than once for the same device.

/**

 * srpt_alloc_ioctx - allocate a SRPT I/O context structure

 * @sdev: SRPT HCA pointer.

 * @ioctx_size: I/O context size.

 * @buf_cache: I/O buffer cache.

 * @dir: DMA data direction.

/**

 * srpt_free_ioctx - free a SRPT I/O context structure

 * @sdev: SRPT HCA pointer.

 * @ioctx: I/O context pointer.

 * @buf_cache: I/O buffer cache.

 * @dir: DMA data direction.

/**

 * srpt_alloc_ioctx_ring - allocate a ring of SRPT I/O context structures

 * @sdev:       Device to allocate the I/O context ring for.

 * @ring_size:  Number of elements in the I/O context ring.

 * @ioctx_size: I/O context size.

 * @buf_cache:  I/O buffer cache.

 * @alignment_offset: Offset in each ring buffer at which the SRP information

 *		unit starts.

 * @dir:        DMA data direction.

/**

 * srpt_free_ioctx_ring - free the ring of SRPT I/O context structures

 * @ioctx_ring: I/O context ring to be freed.

 * @sdev: SRPT HCA pointer.

 * @ring_size: Number of ring elements.

 * @buf_cache: I/O buffer cache.

 * @dir: DMA data direction.

/**

 * srpt_set_cmd_state - set the state of a SCSI command

 * @ioctx: Send I/O context.

 * @new: New I/O context state.

 *

 * Does not modify the state of aborted commands. Returns the previous command

 * state.

/**

 * srpt_test_and_set_cmd_state - test and set the state of a command

 * @ioctx: Send I/O context.

 * @old: Current I/O context state.

 * @new: New I/O context state.

 *

 * Returns true if and only if the previous command state was equal to 'old'.

/**

 * srpt_post_recv - post an IB receive request

 * @sdev: SRPT HCA pointer.

 * @ch: SRPT RDMA channel.

 * @ioctx: Receive I/O context pointer.

/**

 * srpt_zerolength_write - perform a zero-length RDMA write

 * @ch: SRPT RDMA channel.

 *

 * A quote from the InfiniBand specification: C9-88: For an HCA responder

 * using Reliable Connection service, for each zero-length RDMA READ or WRITE

 * request, the R_Key shall not be validated, even if the request includes

 * Immediate data.

	/*

	 * The pointer computations below will only be compiled correctly

	 * if srp_cmd::add_data is declared as s8*, u8*, s8[] or u8[], so check

	 * whether srp_cmd::add_data has been declared as a byte pointer.

	/*

	 * According to the SRP spec, the lower two bits of the 'ADDITIONAL

	 * CDB LENGTH' field are reserved and the size in bytes of this field

	 * is four times the value specified in bits 3..7. Hence the "& ~3".

/**

 * srpt_get_desc_tbl - parse the data descriptors of a SRP_CMD request

 * @recv_ioctx: I/O context associated with the received command @srp_cmd.

 * @ioctx: I/O context that will be used for responding to the initiator.

 * @srp_cmd: Pointer to the SRP_CMD request data.

 * @dir: Pointer to the variable to which the transfer direction will be

 *   written.

 * @sg: [out] scatterlist for the parsed SRP_CMD.

 * @sg_cnt: [out] length of @sg.

 * @data_len: Pointer to the variable to which the total data length of all

 *   descriptors in the SRP_CMD request will be written.

 * @imm_data_offset: [in] Offset in SRP_CMD requests at which immediate data

 *   starts.

 *

 * This function initializes ioctx->nrbuf and ioctx->r_bufs.

 *

 * Returns -EINVAL when the SRP_CMD request contains inconsistent descriptors;

 * -ENOMEM when memory allocation fails and zero upon success.

	/*

	 * The lower four bits of the buffer format field contain the DATA-IN

	 * buffer descriptor format, and the highest four bits contain the

	 * DATA-OUT buffer descriptor format.

 DATA-IN: transfer data from target to initiator (read). */

 DATA-OUT: transfer data from initiator to target (write). */

 initialize data_direction early as srpt_alloc_rw_ctxs needs it */

		/*

		 * The immediate data buffer descriptor must occur before the

		 * immediate data itself.

/**

 * srpt_init_ch_qp - initialize queue pair attributes

 * @ch: SRPT RDMA channel.

 * @qp: Queue pair pointer.

 *

 * Initialized the attributes of queue pair 'qp' by allowing local write,

 * remote read and remote write. Also transitions 'qp' to state IB_QPS_INIT.

/**

 * srpt_ch_qp_rtr - change the state of a channel to 'ready to receive' (RTR)

 * @ch: channel of the queue pair.

 * @qp: queue pair to change the state of.

 *

 * Returns zero upon success and a negative value upon failure.

 *

 * Note: currently a struct ib_qp_attr takes 136 bytes on a 64-bit system.

 * If this structure ever becomes larger, it might be necessary to allocate

 * it dynamically instead of on the stack.

/**

 * srpt_ch_qp_rts - change the state of a channel to 'ready to send' (RTS)

 * @ch: channel of the queue pair.

 * @qp: queue pair to change the state of.

 *

 * Returns zero upon success and a negative value upon failure.

 *

 * Note: currently a struct ib_qp_attr takes 136 bytes on a 64-bit system.

 * If this structure ever becomes larger, it might be necessary to allocate

 * it dynamically instead of on the stack.

/**

 * srpt_ch_qp_err - set the channel queue pair state to 'error'

 * @ch: SRPT RDMA channel.

/**

 * srpt_get_send_ioctx - obtain an I/O context for sending to the initiator

 * @ch: SRPT RDMA channel.

	/*

	 * transport_init_se_cmd() does not initialize all fields, so do it

	 * here.

/**

 * srpt_abort_cmd - abort a SCSI command

 * @ioctx:   I/O context associated with the SCSI command.

	/*

	 * If the command is in a state where the target core is waiting for

	 * the ib_srpt driver, change the state to the next state.

		/*

		 * Do nothing - defer abort processing until

		 * srpt_queue_response() is invoked.

		/*

		 * SRP_RSP sending failed or the SRP_RSP send completion has

		 * not been received in time.

/**

 * srpt_rdma_read_done - RDMA read completion callback

 * @cq: Completion queue.

 * @wc: Work completion.

 *

 * XXX: what is now target_execute_cmd used to be asynchronous, and unmapping

 * the data that has been transferred via IB RDMA had to be postponed until the

 * check_stop_free() callback.  None of this is necessary anymore and needs to

 * be cleaned up.

/**

 * srpt_build_cmd_rsp - build a SRP_RSP response

 * @ch: RDMA channel through which the request has been received.

 * @ioctx: I/O context associated with the SRP_CMD request. The response will

 *   be built in the buffer ioctx->buf points at and hence this function will

 *   overwrite the request data.

 * @tag: tag of the request for which this response is being generated.

 * @status: value for the STATUS field of the SRP_RSP information unit.

 *

 * Returns the size in bytes of the SRP_RSP response.

 *

 * An SRP_RSP response contains a SCSI status or service response. See also

 * section 6.9 in the SRP r16a document for the format of an SRP_RSP

 * response. See also SPC-2 for more information about sense data.

	/*

	 * The lowest bit of all SAM-3 status codes is zero (see also

	 * paragraph 5.3 in SAM-3).

 residual data from an underflow write */

 residual data from an underflow read */

 residual data from an overflow write */

 residual data from an overflow read */

/**

 * srpt_build_tskmgmt_rsp - build a task management response

 * @ch:       RDMA channel through which the request has been received.

 * @ioctx:    I/O context in which the SRP_RSP response will be built.

 * @rsp_code: RSP_CODE that will be stored in the response.

 * @tag:      Tag of the request for which this response is being generated.

 *

 * Returns the size in bytes of the SRP_RSP response.

 *

 * An SRP_RSP response contains a SCSI status or service response. See also

 * section 6.9 in the SRP r16a document for the format of an SRP_RSP

 * response.

/**

 * srpt_handle_cmd - process a SRP_CMD information unit

 * @ch: SRPT RDMA channel.

 * @recv_ioctx: Receive I/O context.

 * @send_ioctx: Send I/O context.

/**

 * srpt_handle_tsk_mgmt - process a SRP_TSK_MGMT information unit

 * @ch: SRPT RDMA channel.

 * @recv_ioctx: Receive I/O context.

 * @send_ioctx: Send I/O context.

 *

 * Returns 0 if and only if the request will be processed by the target core.

 *

 * For more information about SRP_TSK_MGMT information units, see also section

 * 6.7 in the SRP r16a document.

/**

 * srpt_handle_new_iu - process a newly received information unit

 * @ch:    RDMA channel through which the information unit has been received.

 * @recv_ioctx: Receive I/O context associated with the information unit.

/*

 * This function must be called from the context in which RDMA completions are

 * processed because it accesses the wait list without protection against

 * access from other threads.

/**

 * srpt_send_done - send completion callback

 * @cq: Completion queue.

 * @wc: Work completion.

 *

 * Note: Although this has not yet been observed during tests, at least in

 * theory it is possible that the srpt_get_send_ioctx() call invoked by

 * srpt_handle_new_iu() fails. This is possible because the req_lim_delta

 * value in each response is set to one, and it is possible that this response

 * makes the initiator send a new request before the send completion for that

 * response has been processed. This could e.g. happen if the call to

 * srpt_put_send_iotcx() is delayed because of a higher priority interrupt or

 * if IB retransmission causes generation of the send completion to be

 * delayed. Incoming information units for which srpt_get_send_ioctx() fails

 * are queued on cmd_wait_list. The code below processes these delayed

 * requests one at a time.

/**

 * srpt_create_ch_ib - create receive and send completion queues

 * @ch: SRPT RDMA channel.

	/*

	 * We divide up our send queue size into half SEND WRs to send the

	 * completions, and half R/W contexts to actually do the RDMA

	 * READ/WRITE transfers.  Note that we need to allocate CQ slots for

	 * both both, as RDMA contexts will also post completions for the

	 * RDMA READ case.

/**

 * srpt_close_ch - close a RDMA channel

 * @ch: SRPT RDMA channel.

 *

 * Make sure all resources associated with the channel will be deallocated at

 * an appropriate time.

 *

 * Returns true if and only if the channel state has been modified into

 * CH_DRAINING.

/*

 * Change the channel state into CH_DISCONNECTING. If a channel has not yet

 * reached the connected state, close it. If a channel is in the connected

 * state, send a DREQ. If a DREQ has been received, send a DREP. Note: it is

 * the responsibility of the caller to ensure that this function is not

 * invoked concurrently with the code that accepts a connection. This means

 * that this function must either be invoked from inside a CM callback

 * function or that it must be invoked with the srpt_port.mutex held.

 Send DREQ and wait for DREP. */

/*

 * Look up (i_port_id, t_port_id) in sport->nexus_list. Create an entry if

 * it does not yet exist.

/*

 * Shut down the SCSI target session, tell the connection manager to

 * disconnect the associated RDMA channel, transition the QP to the error

 * state and remove the channel from the channel list. This function is

 * typically called from inside srpt_zerolength_write_done(). Concurrent

 * srpt_zerolength_write() calls from inside srpt_close_ch() are possible

 * as long as the channel is on sport->nexus_list.

/**

 * srpt_cm_req_recv - process the event IB_CM_REQ_RECEIVED

 * @sdev: HCA through which the login request was received.

 * @ib_cm_id: IB/CM connection identifier in case of IB/CM.

 * @rdma_cm_id: RDMA/CM connection identifier in case of RDMA/CM.

 * @port_num: Port through which the REQ message was received.

 * @pkey: P_Key of the incoming connection.

 * @req: SRP login request.

 * @src_addr: GID (IB/CM) or IP address (RDMA/CM) of the port that submitted

 * the login request.

 *

 * Ownership of the cm_id is transferred to the target session if this

 * function returns zero. Otherwise the caller remains the owner of cm_id.

	/*

	 * ch->rq_size should be at least as large as the initiator queue

	 * depth to avoid that the initiator driver has to report QUEUE_FULL

	 * to the SCSI mid-layer.

 ib_srpt does not use se_sess->sess_cmd_map */

 Retry without leading "0x" */

	/*

	 * Once a session has been created destruction of srpt_rdma_ch objects

	 * will decrement sport->refcount. Hence increment sport->refcount now.

 create srp_login_response */

 create cm reply */

	/*

	 * Hold the sport mutex while accepting a connection to avoid that

	 * srpt_disconnect_ch() is invoked concurrently with this code.

		/*

		 * Tell the caller not to free cm_id since

		 * srpt_release_channel_work() will do that.

 Transform srp_login_req_rdma into srp_login_req. */

/**

 * srpt_cm_rtu_recv - process an IB_CM_RTU_RECEIVED or USER_ESTABLISHED event

 * @ch: SRPT RDMA channel.

 *

 * An RTU (ready to use) message indicates that the connection has been

 * established and that the recipient may begin transmitting.

	/*

	 * Note: calling srpt_close_ch() if the transition to the LIVE state

	 * fails is not necessary since that means that that function has

	 * already been invoked from another thread.

 Trigger wait list processing. */

/**

 * srpt_cm_handler - IB connection manager callback function

 * @cm_id: IB/CM connection identifier.

 * @event: IB/CM event.

 *

 * A non-zero return value will cause the caller destroy the CM ID.

 *

 * Note: srpt_cm_handler() must only return a non-zero value when transferring

 * ownership of the cm_id to a channel by srpt_cm_req_recv() failed. Returning

 * a non-zero value in any other case will trigger a race with the

 * ib_destroy_cm_id() call in srpt_release_channel().

/*

 * srpt_write_pending - Start data transfer from initiator to target (write).

/**

 * srpt_queue_response - transmit the response to a SCSI command

 * @cmd: SCSI target command.

 *

 * Callback function called by the TCM core. Must not block since it can be

 * invoked on the context of the IB completion handler.

 For read commands, transfer the data to the initiator. */

/*

 * This function is called for aborted commands if no response is sent to the

 * initiator. Make sure that the credits freed by aborting a command are

 * returned to the initiator the next time a response is sent by incrementing

 * ch->req_lim_delta.

/**

 * srpt_release_sport - disable login and wait for associated channels

 * @sport: SRPT HCA port.

/**

 * srpt_add_one - InfiniBand device addition callback function

 * @device: Describes a HCA.

 print out target login information */

	/*

	 * We do not have a consistent service_id (ie. also id_ext of target_id)

	 * to identify this target. We currently use the guid of the first HCA

	 * in the system as service_id; therefore, the target_id will change

	 * if this HCA is gone bad and replaced by different HCA

/**

 * srpt_remove_one - InfiniBand device removal callback function

 * @device: Describes a HCA.

 * @client_data: The value passed as the third argument to ib_set_client_data().

 Cancel any work queued by the just unregistered IB event handler. */

	/*

	 * Unregistering a target must happen after destroying sdev->cm_id

	 * such that no new SRP_LOGIN_REQ information units can arrive while

	 * destroying the target.

/**

 * srpt_close_session - forcibly close a session

 * @se_sess: SCSI target session.

 *

 * Callback function invoked by the TCM core to clean up sessions associated

 * with a node ACL when the user invokes

 * rmdir /sys/kernel/config/target/$driver/$port/$tpg/acls/$i_port_id

/**

 * srpt_sess_get_index - return the value of scsiAttIntrPortIndex (SCSI-MIB)

 * @se_sess: SCSI target session.

 *

 * A quote from RFC 4455 (SCSI-MIB) about this MIB object:

 * This object represents an arbitrary integer used to uniquely identify a

 * particular attached remote initiator port to a particular SCSI target port

 * within a particular SCSI target device within a particular SCSI instance.

 Note: only used from inside debug printk's by the TCM core. */

/**

 * srpt_parse_i_port_id - parse an initiator port ID

 * @name: ASCII representation of a 128-bit initiator port ID.

 * @i_port_id: Binary 128-bit port ID.

/*

 * configfs callback function invoked for mkdir

 * /sys/kernel/config/target/$driver/$port/$tpg/acls/$i_port_id

 *

 * i_port_id must be an initiator port GUID, GID or IP address. See also the

 * target_alloc_session() calls in this driver. Examples of valid initiator

 * port IDs:

 * 0x0000000000000000505400fffe4a0b7b

 * 0000000000000000505400fffe4a0b7b

 * 5054:00ff:fe4a:0b7b

 * 192.168.122.76

 Log out all initiator systems before changing 'use_srq'. */

/**

 * srpt_make_tpg - configfs callback invoked for mkdir /sys/kernel/config/target/$driver/$port/$tpg

 * @wwn: Corresponds to $driver/$port.

 * @name: $tpg.

/**

 * srpt_drop_tpg - configfs callback invoked for rmdir /sys/kernel/config/target/$driver/$port/$tpg

 * @tpg: Target portal group to deregister.

/**

 * srpt_make_tport - configfs callback invoked for mkdir /sys/kernel/config/target/$driver/$port

 * @tf: Not used.

 * @group: Not used.

 * @name: $port.

/**

 * srpt_drop_tport - configfs callback invoked for rmdir /sys/kernel/config/target/$driver/$port

 * @wwn: $port.

	/*

	 * Setup function pointers for generic logic in

	 * target_core_fabric_configfs.c

/**

 * srpt_init_module - kernel module initialization

 *

 * Note: Since ib_register_client() registers callback functions, and since at

 * least one of these callback functions (srpt_add_one()) calls target core

 * functions, this driver must be registered with the target core before

 * ib_register_client() is called.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RDMA Transport Layer

 *

 * Copyright (c) 2014 - 2018 ProfitBricks GmbH. All rights reserved.

 * Copyright (c) 2018 - 2019 1&1 IONOS Cloud GmbH. All rights reserved.

 * Copyright (c) 2019 - 2020 1&1 IONOS SE. All rights reserved.

 first remove sysfs itself to avoid deadlock */

		/*

		 * Device needs to be registered only on the first session

	/*

	 * Suppress user space notification until

	 * sysfs files are created

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RDMA Transport Layer

 *

 * Copyright (c) 2014 - 2018 ProfitBricks GmbH. All rights reserved.

 * Copyright (c) 2018 - 2019 1&1 IONOS Cloud GmbH. All rights reserved.

 * Copyright (c) 2019 - 2020 1&1 IONOS SE. All rights reserved.

 Must be power of 2, see mask from mr->page_size in ib_sg_to_pages() */

 We guarantee to serve 10 paths at least */

	/* WR will fail with length error

	 * if this is 0

 Only one key is actually used */

	/*

	 * From time to time we have to post signaled sends,

	 * or send queue will fill up and only QP reset can help.

/**

 * send_io_resp_imm() - respond to client with empty IMM on failed READ/WRITE

 *                      requests or on successful WRITE request.

 * @con:	the connection to send back result

 * @id:		the id associated with the IO

 * @errno:	the error number of the IO.

 *

 * Return 0 on success, errno otherwise.

 Only one key is actually used */

	/*

	 * From time to time we have to post signalled sends,

	 * or send queue will fill up and only QP reset can help.

/**

 * rtrs_srv_resp_rdma() - Finish an RDMA request

 *

 * @id:		Internal RTRS operation identifier

 * @status:	Response Code sent to the other side for this operation.

 *		0 = success, <=0 error

 * Context: any

 *

 * Finish a RDMA operation. A message is sent to the client and the

 * corresponding memory areas will be released.

/**

 * rtrs_srv_set_sess_priv() - Set private pointer in rtrs_srv.

 * @srv:	Session pointer

 * @priv:	The private pointer that is associated with the session.

	/*

	 * Here we map queue_depth chunks to MR.  Firstly we have to

	 * figure out how many chunks can we map per MR.

		/*

		 * in order to do invalidate for each chunks of memory, we needs

		 * more memory regions.

 Eventually dma addr for each chunk can be cached */

 Mark session as established */

 when a client with same uuid and same sessname tried to add a path */

		/*

		 * Fill in reg MR request and chain them *backwards*

	/*

	 * We do not account number of established connections at the current

	 * moment, we rely on the client, which should send info request when

	 * all connections are successfully established.  Thus, simply notify

	 * listener with a proper event if we are the first path.

 Send info response */

 Prepare for getting info response */

		/*

		 * post_recv() RDMA write completions of IO reqs (read/write)

		 * and hb

		/*

		 * post_send() RDMA write completions of IO reqs (read/write)

		 * and hb.

/**

 * rtrs_srv_get_sess_name() - Get rtrs_srv peer hostname.

 * @srv:	Session

 * @sessname:	Sessname buffer

 * @len:	Length of sessname buffer

/**

 * rtrs_srv_get_queue_depth() - Get rtrs_srv qdepth.

 * @srv:	Session

 last put to release the srv structure */

	/*

	 * If this request is not the first connection request from the

	 * client for this session then fail and return error.

 need to allocate a new srv */

 return true if addresses are the same, error other wise */

	/*

	 * Degrade ref count to the usual model with a single shared

	 * atomic_t counter

 Wait for all completion */

 Notify upper layer if we are the last path */

 Bounce errno back */

		/*

		 * All receive and all send (each requiring invalidate)

		 * + 2 for drain and heartbeat

 when always_invlaidate enalbed, we need linv+rinv+mr+imm */

		/*

		 * If we have all receive requests posted and

		 * all write requests posted and each read request

		 * requires an invalidate request + drain

		 * and qp gets into error state.

 TODO: SOFTIRQ can be faster, but be careful with softirq context */

	/*

	 * Change context from server to current connection.  The other

	 * way is to use cm_id->qp->qp_context, which does not work on OFED.

 temporary until receiving session-name from client */

 Sanity check */

 Sanity check */

 Session already holds a reference */

		/*

		 * Sanity checks

		/*

		 * Since session has other connections we follow normal way

		 * through workqueue, but still return an error to tell cma.c

		 * to call rdma_destroy_id() for current connection.

		/*

		 * Since current connection was successfully added to the

		 * session we follow normal way through workqueue to close the

		 * session, thus return 0 to tell cma.c we call

		 * rdma_destroy_id() ourselves.

		/*

		 * In case of error cma.c will destroy cm_id,

		 * see cma_process_remove()

 Nothing here */

	/*

	 * We accept both IPoIB and IB connections, so we need to keep

	 * two cm id's, one for each socket type and port space.

	 * If the cm initialization of one of the id's fails, we abort

	 * everything.

	/*

	 * Since our CM IDs are NOT bound to any ib device we will create them

	 * only once

		/*

		 * We errored out here.

		 * According to the ib code, if we encounter an error here then the

		 * error code is ignored, and no more calls to our ops are made.

	/*

	 * Keep a track on the number of ib devices added

	/*

	 * Since our CM IDs are NOT bound to any ib device we will remove them

	 * only once, when the last device is removed

/**

 * rtrs_srv_open() - open RTRS server context

 * @ops:		callback functions

 * @port:               port to listen on

 *

 * Creates server context with specified callbacks.

 *

 * Return a valid pointer on success otherwise PTR_ERR.

/**

 * rtrs_srv_close() - close RTRS server context

 * @ctx: pointer to server context

 *

 * Closes RTRS server context with all client sessions.

	/*

	 * Check if IB immediate data size is enough to hold the mem_id and the

	 * offset inside the memory chunk

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RDMA Transport Layer

 *

 * Copyright (c) 2014 - 2018 ProfitBricks GmbH. All rights reserved.

 * Copyright (c) 2018 - 2019 1&1 IONOS Cloud GmbH. All rights reserved.

 * Copyright (c) 2019 - 2020 1&1 IONOS SE. All rights reserved.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RDMA Transport Layer

 *

 * Copyright (c) 2014 - 2018 ProfitBricks GmbH. All rights reserved.

 * Copyright (c) 2018 - 2019 1&1 IONOS Cloud GmbH. All rights reserved.

 * Copyright (c) 2019 - 2020 1&1 IONOS SE. All rights reserved.

	/*

	 * If one of the sges has 0 size, the operation will fail with a

	 * length error

 Reschedule work without sending hb */

	/*

	 * We can use some of the IPv6 functions since GID is a valid

	 * IPv6 address format

	/*

	 * Use the same TCP server port number as the IB service ID

	 * on the IB port space range

/**

 * rtrs_str_to_sockaddr() - Convert rtrs address string to sockaddr

 * @addr:	String representation of an addr (IPv4, IPv6 or IB GID):

 *              - "ip:192.168.1.1"

 *              - "ip:fe80::200:5aee:feaa:20a2"

 *              - "gid:fe80::200:5aee:feaa:20a2"

 * @len:        String address length

 * @port:	Destination port

 * @dst:	Destination sockaddr structure

 *

 * Returns 0 if conversion successful. Non-zero on error.

/**

 * sockaddr_to_str() - convert sockaddr to a string.

 * @addr:	the sockadddr structure to be converted.

 * @buf:	string containing socket addr.

 * @len:	string length.

 *

 * The return value is the number of characters written into buf not

 * including the trailing '\0'. If len is == 0 the function returns 0..

/**

 * rtrs_addr_to_str() - convert rtrs_addr to a string "src@dst"

 * @addr:	the rtrs_addr structure to be converted

 * @buf:	string containing source and destination addr of a path

 *		separated by '@' I.e. "ip:1.1.1.1@ip:1.1.1.2"

 *		"ip:1.1.1.1@ip:1.1.1.2".

 * @len:	string length

 *

 * The return value is the number of characters written into buf not

 * including the trailing '\0'.

/**

 * rtrs_addr_to_sockaddr() - convert path string "src,dst" or "src@dst"

 * to sockaddreses

 * @str:	string containing source and destination addr of a path

 *		separated by ',' or '@' I.e. "ip:1.1.1.1,ip:1.1.1.2" or

 *		"ip:1.1.1.1@ip:1.1.1.2". If str contains only one address it's

 *		considered to be destination.

 * @len:	string length

 * @port:	Destination port number.

 * @addr:	will be set to the source/destination address or to NULL

 *		if str doesn't contain any source address.

 *

 * Returns zero if conversion successful. Non-zero otherwise.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RDMA Transport Layer

 *

 * Copyright (c) 2014 - 2018 ProfitBricks GmbH. All rights reserved.

 * Copyright (c) 2018 - 2019 1&1 IONOS Cloud GmbH. All rights reserved.

 * Copyright (c) 2019 - 2020 1&1 IONOS SE. All rights reserved.

 Careful here, override s pointer */

	/*

	 * successful_cnt will be set to 0 after session

	 * is established for the first time

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RDMA Transport Layer

 *

 * Copyright (c) 2014 - 2018 ProfitBricks GmbH. All rights reserved.

 * Copyright (c) 2018 - 2019 1&1 IONOS Cloud GmbH. All rights reserved.

 * Copyright (c) 2019 - 2020 1&1 IONOS SE. All rights reserved.

/*

 * Wait a bit before trying to reconnect after a failure

 * in order to give server time to finish clean up which

 * leads to "false positives" failed reconnect attempts

/*

 * Wait for additional random time between 0 and 8 seconds

 * before starting to reconnect to avoid clients reconnecting

 * all at once in case of a major network outage

 limit to 128 * 4k = 512k max IO */

	/*

	 * Adapted from null_blk get_tag(). Callers from different cpus may

	 * grab the same bit, since find_first_zero_bit is not atomic.

	 * But then the test_and_set_bit_lock will fail for all the

	 * callers but one, so that they will loop again.

	 * This way an explicit spinlock is not required.

/**

 * rtrs_clt_get_permit() - allocates permit for future RDMA operation

 * @clt:	Current session

 * @con_type:	Type of connection to use with the permit

 * @can_wait:	Wait type

 *

 * Description:

 *    Allocates permit for the following RDMA operation.  Permit is used

 *    to preallocate all resources and to propagate memory pressure

 *    up earlier.

 *

 * Context:

 *    Can sleep if @wait == RTRS_PERMIT_WAIT

/**

 * rtrs_clt_put_permit() - puts allocated permit

 * @clt:	Current session

 * @permit:	Permit to be freed

 *

 * Context:

 *    Does not matter

	/*

	 * rtrs_clt_get_permit() adds itself to the &clt->permits_wait list

	 * before calling schedule(). So if rtrs_clt_get_permit() is sleeping

	 * it must have added itself to &clt->permits_wait before

	 * __rtrs_put_permit() finished.

	 * Hence it is safe to guard wake_up() with a waitqueue_active() test.

/**

 * rtrs_permit_to_clt_con() - returns RDMA connection pointer by the permit

 * @sess: client session pointer

 * @permit: permit for the allocation of the RDMA buffer

 * Note:

 *     IO connection starts from 1.

 *     0 connection is for user messages.

/**

 * rtrs_clt_change_state() - change the session state through session state

 * machine.

 *

 * @sess: client session to change the state of.

 * @new_state: state to change to.

 *

 * returns true if sess's state is changed to new state, otherwise return false.

 *

 * Locks:

 * state_wq lock must be hold.

		/*

		 * Normal scenario, reconnect if we were successfully connected

		/*

		 * Error can happen just on establishing new connection,

		 * so notify waiter with error state, waiter is responsible

		 * for cleaning the rest and reconnect if needed.

 Complete request from INV callback */

			/*

			 * We are here to invalidate read requests

			 * ourselves.  In normal scenario server should

			 * send INV for all read requests, but

			 * we are here, thus two things could happen:

			 *

			 *    1.  this is failover, when errno != 0

			 *        and can_wait == 1,

			 *

			 *    2.  something totally bad happened and

			 *        server forgot to send INV, so we

			 *        should do that ourselves.

 This should be IO path, so always notify */

 Save errno for INV callback */

				/*

				 * Something went wrong, so request will be

				 * completed from INV callback.

 user data and user message in the first list element */

	/*

	 * From time to time we have to post signalled sends,

	 * or send queue will fill up and only QP reset can help.

 Drop need_inv if server responded with send with invalidation */

/*

 * Post x2 empty WRs: first is for this RDMA with IMM,

 * second is for RECV with INV, which happened earlier.

 Chain backwards */

		/*

		 * post_recv() RDMA write completions of IO reqs (read/write)

		 * and hb

			/*

			 * Post x2 empty WRs: first is for this RDMA with IMM,

			 * second is for RECV with INV, which happened earlier.

		/*

		 * Key invalidations from server side

		/*

		 * post_send() RDMA write completions of IO reqs (read/write)

		 * and hb.

		/*

		 * x2 for RDMA read responses + FR key invalidations,

		 * RDMA writes do not require any FR registrations.

/**

 * list_next_or_null_rr_rcu - get next list element in round-robin fashion.

 * @head:	the head for the list.

 * @ptr:        the list head to take the next element from.

 * @type:       the type of the struct this is embedded in.

 * @memb:       the name of the list_head within the struct.

 *

 * Next element returned in round-robin fashion, i.e. head will be skipped,

 * but if list is observed as empty, NULL will be returned.

 *

 * This primitive may safely run concurrently with the _rcu list-mutation

 * primitives such as list_add_rcu() as long as it's guarded by rcu_read_lock().

/**

 * get_next_path_rr() - Returns path in round-robin fashion.

 * @it:	the path pointer

 *

 * Related to @MP_POLICY_RR

 *

 * Locks:

 *    rcu_read_lock() must be hold.

	/*

	 * Here we use two RCU objects: @paths_list and @pcpu_path

	 * pointer.  See rtrs_clt_remove_path_from_arr() for details

	 * how that is handled.

/**

 * get_next_path_min_inflight() - Returns path with minimal inflight count.

 * @it:	the path pointer

 *

 * Related to @MP_POLICY_MIN_INFLIGHT

 *

 * Locks:

 *    rcu_read_lock() must be hold.

	/*

	 * add the path to the skip list, so that next time we can get

	 * a different one

/**

 * get_next_path_min_latency() - Returns path with minimal latency.

 * @it:	the path pointer

 *

 * Return: a path with the lowest latency or NULL if all paths are tried

 *

 * Locks:

 *    rcu_read_lock() must be hold.

 *

 * Related to @MP_POLICY_MIN_LATENCY

 *

 * This DOES skip an already-tried path.

 * There is a skip-list to skip a path if the path has tried but failed.

 * It will try the minimum latency path and then the second minimum latency

 * path and so on. Finally it will return NULL if all paths are tried.

 * Therefore the caller MUST check the returned

 * path is NULL and trigger the IO error.

	/*

	 * add the path to the skip list, so that next time we can get

	 * a different one

	/*

	 * The skip_list is used only for the MIN_INFLIGHT policy.

	 * We need to remove paths from it, so that next IO can insert

	 * paths (->mp_skip_entry) into a skip_list again.

/**

 * rtrs_clt_init_req() - Initialize an rtrs_clt_io_req holding information

 * about an inflight IO.

 * The user buffer holding user control message (not data) is copied into

 * the corresponding buffer of rtrs_iu (req->iu->buf), which later on will

 * also hold the control message of rtrs.

 * @req: an io request holding information about IO.

 * @sess: client session

 * @conf: conformation callback function to notify upper layer.

 * @permit: permit for allocation of RDMA remote buffer

 * @priv: private pointer

 * @vec: kernel vector containing control message

 * @usr_len: length of the user message

 * @sg: scater list for IO data

 * @sg_cnt: number of scater list entries

 * @data_len: length of the IO data

 * @dir: direction of the IO.

	/*

	 * From time to time we have to post signalled sends,

	 * or send queue will fill up and only QP reset can help.

 Align the MR to a 4K page size to match the block virt boundary */

 put rtrs msg after sg and user message */

 rtrs message on server side will be after user data and message */

	/*

	 * Update stats now, after request is successfully sent it is not

	 * safe anymore to touch it.

 put our message into req->buf after user message*/

 Further invalidation is required */

	/*

	 * rtrs message will be after the space reserved for disk data and

	 * user message

	/*

	 * Update stats now, after request is successfully sent it is not

	 * safe anymore to touch it.

/**

 * rtrs_clt_failover_req() - Try to find an active path for a failed request

 * @clt: clt context

 * @fail_req: a failed io request.

 Success path */

		/*

		 * Safely (without notification) complete failed request.

		 * After completion this request is still useble and can

		 * be failovered to another path.

 Failover failed, notify anyway */

	/*

	 * Use the smallest page size supported by the HCA, down to a

	 * minimum of 4096 bytes. We're unlikely to build large sglists

	 * out of smaller entries.

	/*

	 * irqmode and poll

	 * +1: Extra connection for user messages

	/*

	 * rdma_resolve_addr() passes src_addr to cma_bind_addr, which

	 * checks the sa_family to be non-zero. If user passed src_addr=NULL

	 * the sess->src_addr will contain only zeros, which is then fine.

 Map first two connections to the first CPU */

 Align with srv, init as 1 */

 We must be the first here */

		/*

		 * The whole session uses device from user connection.

		 * Be careful not to close user connection before ib dev

		 * is gracefully put.

		/*

		 * Two (request + registration) completion for send

		 * Two for recv if always_invalidate is set on server

		 * or one for recv.

		 * + 2 for drain and heartbeat

		 * in case qp gets into error state.

		/*

		 * Here we assume that session members are correctly set.

		 * This is always true if user connection (cid == 0) is

		 * established first.

 Shared between connections */

 QD * (REQ + RSP + FR REGS or INVS) + drain */

 alloc iu to recv new rkey reply when server reports flags set */

	/*

	 * In case of error we do not bother to clean previous allocations,

	 * since destroy_con_cq_qp() must be called.

	/*

	 * Be careful here: destroy_con_cq_qp() can be called even

	 * create_con_cq_qp() failed, see comments there.

			/*

			 * Stop any more reconnection attempts

		/*

		 * Global IO size is always a minimum.

		 * If while a reconnection server sends us a value a bit

		 * higher - client does not care and uses cached minimum.

		 *

		 * Since we can have several sessions (paths) restablishing

		 * connections in parallel, use lock.

		/*

		 * Cache the hca_port and hca_name for sysfs

 set for_new_clt, to allow future reconnect on any path */

			/*

			 * Report success and wake up. Here we abuse state_wq,

			 * i.e. wake up without state change, but we set cm_err.

 No message for disconnecting */

		/*

		 * Device removal is a special case.  Queue close and return 0.

		/*

		 * cm error makes sense only on connection establishing,

		 * in other cases we rely on normal procedure of reconnecting.

 allow the port to be reused */

	/*

	 * Combine connection status and session events. This is needed

	 * for waiting two possible cases: cm_err has something meaningful

	 * or session state was really changed to error by device removal.

 Timedout or interrupted */

 Device removal */

	/*

	 * We can fire RECONNECTED event only when all paths were

	 * connected on rtrs_clt_open(), then each was disconnected

	 * and the first one connected again.  That's why this nasty

	 * game with counter value.

	/*

	 * Here it is safe to access paths num directly since up counter

	 * is greater than MAX_PATHS_NUM only while rtrs_clt_open() is

	 * in progress, thus paths removals are impossible.

 Mark session as established */

	/*

	 * Possible race with rtrs_clt_open(), when DEVICE_REMOVAL comes

	 * exactly in between.  Start destroying after it finishes.

	/*

	 * All IO paths must observe !CONNECTED state before we

	 * free everything.

	/*

	 * The order it utterly crucial: firstly disconnect and complete all

	 * rdma requests with error (thus set in_use=false for requests),

	 * then fail outstanding requests checking in_use for each, and

	 * eventually notify upper layer about session disconnection.

	/*

	 * Wait for graceful shutdown, namely when peer side invokes

	 * rdma_disconnect(). 'connected_cnt' is decremented only on

	 * CM events, thus if other side had crashed and hb has detected

	 * something is wrong, here we will stuck for exactly timeout ms,

	 * since CM does not fire anything.  That is fine, we are not in

	 * hurry.

 Call cmpxchg() without sparse warnings */

 Make sure everybody observes path removal. */

	/*

	 * At this point nobody sees @sess in the list, but still we have

	 * dangling pointer @pcpu_path which _can_ point to @sess.  Since

	 * nobody can observe @sess in the list, we guarantee that IO path

	 * will not assign @sess to @pcpu_path, i.e. @pcpu_path can be equal

	 * to @sess, but can never again become @sess.

	/*

	 * Decrement paths number only after grace period, because

	 * caller of do_each_path() must firstly observe list without

	 * path and only then decremented paths number.

	 *

	 * Otherwise there can be the following situation:

	 *    o Two paths exist and IO is coming.

	 *    o One path is removed:

	 *      CPU#0                          CPU#1

	 *      do_each_path():                rtrs_clt_remove_path_from_arr():

	 *          path = get_next_path()

	 *          ^^^                            list_del_rcu(path)

	 *          [!CONNECTED path]              clt->paths_num--

	 *                                              ^^^^^^^^^

	 *          load clt->paths_num                 from 2 to 1

	 *                    ^^^^^^^^^

	 *                    sees 1

	 *

	 *      path is observed as !CONNECTED, but do_each_path() loop

	 *      ends, because expression i < clt->paths_num is false.

	/*

	 * Get @next connection from current @sess which is going to be

	 * removed.  If @sess is the last element, then @next is NULL.

	/*

	 * @pcpu paths can still point to the path which is going to be

	 * removed, so change the pointer manually.

			/*

			 * synchronize_rcu() was called just after deleting

			 * entry from the list, thus IO code path cannot

			 * change pointer back to the pointer which is going

			 * to be removed, we are safe here.

		/*

		 * We race with IO code path, which also changes pointer,

		 * thus we have to be careful not to overwrite it.

			/*

			 * @ppcpu_path was successfully replaced with @next,

			 * that means that someone could also pick up the

			 * @sess and dereferencing it right now, so wait for

			 * a grace period is required.

	/*

	 * On every new session connections increase reconnect counter

	 * to avoid clashes with previous sessions not yet closed

	 * sessions on a server side.

 Establish all RDMA connections  */

	/*

	 * If we've never taken async path and got an error, say,

	 * doing rdma_resolve_addr(), switch to CONNECTION_ERR state

	 * manually to keep reconnecting.

	/*

	 * Check if IB immediate data size is enough to hold the mem_id and

	 * the offset inside the memory chunk.

 Sanity check */

 Prepare for getting info response */

 Send info request */

 Wait for state change */

 If we've never taken async path because of malloc problems */

/**

 * init_sess() - establishes all session connections and does handshake

 * @sess: client session.

 * In case of error full close or reconnect procedure should be taken,

 * because reconnect or close async works can be started.

 Close a session completely if max attempts is reached */

 Stop everything */

	/*

	 * Suppress user space notification until

	 * sysfs files are created

 release callback will free clt in last put */

/**

 * rtrs_clt_open() - Open a session to an RTRS server

 * @ops: holds the link event callback and the private pointer.

 * @sessname: name of the session

 * @paths: Paths to be established defined by their src and dst addresses

 * @paths_num: Number of elements in the @paths array

 * @port: port to be used by the RTRS session

 * @pdu_sz: Size of extra payload which can be accessed after permit allocation.

 * @reconnect_delay_sec: time between reconnect tries

 * @max_reconnect_attempts: Number of times to reconnect on error before giving

 *			    up, 0 for * disabled, -1 for forever

 * @nr_poll_queues: number of polling mode connection using IB_POLL_DIRECT flag

 *

 * Starts session establishment with the rtrs_server. The function can block

 * up to ~2000ms before it returns.

 *

 * Return a valid pointer on success otherwise PTR_ERR.

/**

 * rtrs_clt_close() - Close a session

 * @clt: Session handle. Session is freed upon return.

 Firstly forbid sysfs access */

 Now it is safe to iterate over all paths without locks */

		/*

		 * flush_delayed_work() queues pending work for immediate

		 * execution, so do the flush if we have queued something

		 * right now or work is pending.

	/*

	 * Continue stopping path till state was changed to DEAD or

	 * state was observed as DEAD:

	 * 1. State was changed to DEAD - we were fast and nobody

	 *    invoked rtrs_clt_reconnect(), which can again start

	 *    reconnecting.

	 * 2. State was observed as DEAD - we have someone in parallel

	 *    removing the path.

/**

 * rtrs_clt_request() - Request data transfer to/from server via RDMA.

 *

 * @dir:	READ/WRITE

 * @ops:	callback function to be called as confirmation, and the pointer.

 * @clt:	Session

 * @permit:	Preallocated permit

 * @vec:	Message that is sent to server together with the request.

 *		Sum of len of all @vec elements limited to <= IO_MSG_SIZE.

 *		Since the msg is copied internally it can be allocated on stack.

 * @nr:		Number of elements in @vec.

 * @data_len:	length of data sent to/from server

 * @sg:		Pages to be sent/received to/from server.

 * @sg_cnt:	Number of elements in the @sg

 *

 * Return:

 * 0:		Success

 * <0:		Error

 *

 * On dir=READ rtrs client will request a data transfer from Server to client.

 * The data that the server will respond with will be stored in @sg when

 * the user receives an %RTRS_CLT_RDMA_EV_RDMA_REQUEST_WRITE_COMPL event.

 * On dir=WRITE rtrs client will rdma write data in sg to server side.

 Get kvec length */

 Success path */

 If no path, return -1 for block layer not to try again */

/**

 * rtrs_clt_query() - queries RTRS session attributes

 *@clt: session pointer

 *@attr: query results for session attributes.

 * Returns:

 *    0 on success

 *    -ECOMM		no connection to the server

 Cap max_io_size to min of remote buffer size and the fr pages */

		/*

		 * When all the paths are removed for a session,

		 * the addition of the first path is like a new session for

		 * the storage server

	/*

	 * It is totally safe to add path in CONNECTING state: coming

	 * IO will never grab it.  Also it is very important to add

	 * path before init, since init fires LINK_CONNECTED event.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RDMA Transport Layer

 *

 * Copyright (c) 2014 - 2018 ProfitBricks GmbH. All rights reserved.

 * Copyright (c) 2018 - 2019 1&1 IONOS Cloud GmbH. All rights reserved.

 * Copyright (c) 2019 - 2020 1&1 IONOS SE. All rights reserved.

 distinguish "mi" and "min-latency" with length */

 SPDX-License-Identifier: GPL-2.0-or-later

/*******************************************************************************

 * This file contains iSCSI extentions for RDMA (iSER) Verbs

 *

 * (c) Copyright 2013 Datera, Inc.

 *

 * Nicholas A. Bellinger <nab@linux-iscsi.org>

 *

 Check signature cap */

 Set max inflight RDMA READ requests */

		/*

		 * use remote invalidation if the both initiator

		 * and the HCA support it

		/*

		 * This means iscsi doesn't know this connection

		 * so schedule a cleanup ourselves

/**

 * isert_conn_terminate() - Initiate connection termination

 * @isert_conn: isert connection struct

 *

 * Notes:

 * In case the connection state is BOUND, move state

 * to TEMINATING and start teardown sequence (rdma_disconnect).

 * In case the connection state is UP, complete flush as well.

 *

 * This routine must be called with mutex held. Thus it is

 * safe to call multiple times.

 FALLTHRU */

 FALLTHRU */

		/*

		 * return non-zero from the callback to destroy

		 * the rdma cm id

 mark end of work requests list */

		/*

		 * if the descriptor is not in-use we already reposted it

		 * for recv, so just silently return

 Now we are in FULL_FEATURE phase */

		/*

		 * Setup the initial iscsi_login values from the leading

		 * login request PDU.

	/*

	 * FIXME: Unexpected unsolicited_data out

	/*

	 * FIXME: Non page-aligned unsolicited_data out

	/*

	 * multiple data-outs on the same command can arrive -

	 * so post the buffer before hand

	/*

	 * FIXME: Add support for NOPOUT payload using unsolicited RDMA payload

			/*

			 * Check for special case during comp_err where

			 * WRITE_PENDING has been handed off from core,

			 * but requires an extra target_put_sess_cmd()

			 * before transport_generic_free_cmd() below.

 If the continue bit is on, keep the command alive */

		/*

		 * Handle special case for REJECT when iscsi_add_reject*() has

		 * overwritten the original iscsi_opcode assignment, and the

		 * associated cmd->se_cmd needs to be released.

		/*

		 * transport_generic_request_failure() expects to have

		 * plus two references to handle queue-full, so re-add

		 * one here as target-core will have already dropped

		 * it after the first isert_put_datain() callback.

		/*

		 * XXX: isert_put_response() failure is not retried.

	/*

	 * transport_generic_request_failure() will drop the extra

	 * se_cmd->cmd_kref reference after T10-PI error, and handle

	 * any non-zero ->queue_status() callback error retries.

	/*

	 * Attach SENSE DATA payload to iSCSI Response PDU

	/*

	 * At the moment we hard code those, but if in the future

	 * the target core would like to use it, we will take it

	 * from se_cmd.

		/*

		 * Build isert_conn->tx_desc for iSCSI response PDU and attach

		/*

		 * Special case for sending non GOOD SCSI status from TX thread

		 * context during pre se_cmd excecution failure.

	/*

	 * Allow both IPv4 and IPv6 sockets to bind a single port

	 * at the same time.

	/*

	 * Setup the np->np_sockaddr from the passed sockaddr setup

	 * in iscsi_target_configfs.c code..

	/*

	 * For login requests after the first PDU, isert_rx_login_req() will

	 * kick schedule_delayed_work(&conn->login_work) as the packet is

	 * received, which turns this callback from iscsi_target_do_login_rx()

	 * into a NOP.

		/*

		 * No point in stalling here when np_thread

		 * is in state RESET/SHUTDOWN/EXIT - bail

	/*

	 * FIXME: At this point we don't have a good way to insure

	 * that at this point we don't have hanging connections that

	 * completed RDMA establishment but didn't start iscsi login

	 * process. So work-around this by cleaning up what ever piled

	 * up in accepted and pending lists.

/**

 * isert_put_unsol_pending_cmds() - Drop commands waiting for

 *     unsolicitate dataout

 * @conn:    iscsi connection

 *

 * We might still have commands that are waiting for unsolicited

 * dataouts messages. We must put the extra reference on those

 * before blocking on the target_wait_for_session_cmds

/*

 * Copyright(c) 2017 Intel Corporation.

 *

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * BSD LICENSE

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *  - Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *  - Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *  - Neither the name of Intel Corporation nor the names of its

 *    contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

/*

 * This file contains OPA Virtual Network Interface Controller (VNIC) driver

 * netdev functionality.

 This function is overloaded for opa_vnic specific implementation */

 opa_netdev_start_xmit - transmit function */

 pad to ensure mininum ethernet packet length */

 pass entropy and vl as metadata in skb */

 Operational state can only be DROP_ALL or FORWARDING */

 opa_vnic_process_vema_config - process vema configuration updates */

 If the base_mac_addr is changed, update the interface mac address */

 Handle MTU limit change */

 Update flow to default port redirection table */

	/*

	 * Build the flow table. Flow table is required when destination LID

	 * is not available. Up to OPA_VNIC_FLOW_TBL_SIZE flows supported.

	 * Each flow need a default port number to get its dlid from the

	 * u_ucast_dlid array.

 update state */

/*

 * Set the power on default values in adapter's vema interface structure.

 opa_vnic_set_mac_addr - change mac address */

/*

 * opa_vnic_mac_send_event - post event on possible mac list exchange

 *  Send trap when digest from uc/mc mac list differs from previous run.

 *  Digest is evaluated similar to how cksum does.

 opa_vnic_set_rx_mode - handle uc/mc mac list change */

 opa_netdev_open - activate network interface */

 Update status and send trap */

 opa_netdev_close - disable network interface */

 Update status and send trap */

 netdev ops */

 opa_vnic_add_netdev - create vnic netdev interface */

 opa_vnic_rem_netdev - remove vnic netdev interface */

/*

 * Copyright(c) 2017 Intel Corporation.

 *

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * BSD LICENSE

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *  - Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *  - Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *  - Neither the name of Intel Corporation nor the names of its

 *    contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

/*

 * This file contains OPA VNIC encapsulation/decapsulation function.

 OPA 16B Header fields */

 L2+L4 hdr len is 20 bytes (5 quad words) */

 h[1]: LT=1, 16B L2=10 */

 Extract and set 4 upper bits and 20 lower bits of the lids */

/*

 * Using a simple hash table for mac table implementation with the last octet

 * of mac address as a key.

 opa_vnic_release_mac_tbl - empty and free the mac table */

/*

 * opa_vnic_query_mac_tbl - query the mac table for a section

 *

 * This function implements query of specific function of the mac table.

 * The function also expects the requested range to be valid.

 populate entry in the tbl corresponding to the index */

/*

 * opa_vnic_update_mac_tbl - update mac table section

 *

 * This function updates the specified section of the mac table.

 * The procedure includes following steps.

 *  - Allocate a new mac (hash) table.

 *  - Add the specified entries to the new table.

 *    (except the ones that are requested to be deleted).

 *  - Add all the other entries from the old mac table.

 *  - If there is a failure, free the new table and return.

 *  - Switch to the new table.

 *  - Free the old table and return.

 *

 * The function also expects the requested range to be valid.

 allocate new mac table */

 add updated entries to the new mac table */

 if the entry is being removed, do not add it */

 add other entries from current mac table to new mac table */

 switch to new table */

 upon failure, free the new table; otherwise, free the old table */

 opa_vnic_chk_mac_tbl - check mac table for dlid */

 if related to source mac, skip */

 mac address found */

 opa_vnic_get_dlid - find and return the DLID */

 opa_vnic_get_sc - return the service class */

 opa_vnic_get_rc - return the routing control */

 opa_vnic_calc_entropy - calculate the packet entropy */

 store XOR of all bytes in lower 8 bits */

 return lower 8 bits as entropy */

 opa_vnic_get_def_port - get default port based on entropy */

 Add the upper and lower 4-bits of entropy to get the flow id */

 Calculate packet length including OPA header, crc and padding */

 padding for 8 bytes size alignment */

 opa_vnic_encap_skb - encapsulate skb packet with OPA header and meta data */

/*

 * Copyright(c) 2017 Intel Corporation.

 *

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * BSD LICENSE

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *  - Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *  - Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *  - Neither the name of Intel Corporation nor the names of its

 *    contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

/*

 * This file contains OPA VNIC EMA Interface functions.

/**

 * opa_vnic_vema_report_event - sent trap to report the specified event

 * @adapter: vnic port adapter

 * @event: event to be reported

 *

 * This function calls vema api to sent a trap for the given event.

/**

 * opa_vnic_get_summary_counters - get summary counters

 * @adapter: vnic port adapter

 * @cntrs: pointer to destination summary counters structure

 *

 * This function populates the summary counters that is maintained by the

 * given adapter to destination address provided.

	/*

	 * This loop depends on layout of

	 * opa_veswport_summary_counters opa_vnic_stats structures.

/**

 * opa_vnic_get_error_counters - get error counters

 * @adapter: vnic port adapter

 * @cntrs: pointer to destination error counters structure

 *

 * This function populates the error counters that is maintained by the

 * given adapter to destination address provided.

/**

 * opa_vnic_get_vesw_info -- Get the vesw information

 * @adapter: vnic port adapter

 * @info: pointer to destination vesw info structure

 *

 * This function copies the vesw info that is maintained by the

 * given adapter to destination address provided.

/**

 * opa_vnic_set_vesw_info -- Set the vesw information

 * @adapter: vnic port adapter

 * @info: pointer to vesw info structure

 *

 * This function updates the vesw info that is maintained by the

 * given adapter with vesw info provided. Reserved fields are stored

 * and returned back to EM as is.

/**

 * opa_vnic_get_per_veswport_info -- Get the vesw per port information

 * @adapter: vnic port adapter

 * @info: pointer to destination vport info structure

 *

 * This function copies the vesw per port info that is maintained by the

 * given adapter to destination address provided.

 * Note that the read only fields are not copied.

/**

 * opa_vnic_set_per_veswport_info -- Set vesw per port information

 * @adapter: vnic port adapter

 * @info: pointer to vport info structure

 *

 * This function updates the vesw per port info that is maintained by the

 * given adapter with vesw per port info provided. Reserved fields are

 * stored and returned back to EM as is.

/**

 * opa_vnic_query_mcast_macs - query multicast mac list

 * @adapter: vnic port adapter

 * @macs: pointer mac list

 *

 * This function populates the provided mac list with the configured

 * multicast addresses in the adapter.

/**

 * opa_vnic_query_ucast_macs - query unicast mac list

 * @adapter: vnic port adapter

 * @macs: pointer mac list

 *

 * This function populates the provided mac list with the configured

 * unicast addresses in the adapter.

 loop through dev_addrs list first */

 Do not include EM specified MAC address */

 loop through uc list */

/*

 * Copyright(c) 2017 Intel Corporation.

 * Copyright(c) 2021 Cornelis Networks.

 *

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * BSD LICENSE

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *  - Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *  - Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *  - Neither the name of Intel Corporation nor the names of its

 *    contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

/*

 * This file contains OPX Virtual Network Interface Controller (VNIC)

 * Ethernet Management Agent (EMA) driver

/*

 * The trap service level is kept in bits 3 to 7 in the trap_sl_rsvd

 * field in the class port info MAD.

 Cap trap bursts to a reasonable limit good for normal cases */

/*

 * VNIC trap limit timeout.

 * Inverse of cap2_mask response time out (1.0737 secs) = 0.9

 * secs approx IB spec 13.4.6.2.1 PortInfoSubnetTimeout and

 * 13.4.9 Traps.

 Maximum number of VNIC ports supported */

/**

 * struct opa_vnic_vema_port -- VNIC VEMA port details

 * @cport: pointer to port

 * @mad_agent: pointer to mad agent for port

 * @class_port_info: Class port info information.

 * @tid: Transaction id

 * @port_num: OPA port number

 * @vports: vnic ports

 * @event_handler: ib event handler

 * @lock: adapter interface lock

 Lock to query/update network adapter */

/**

 * vema_get_vport_num -- Get the vnic from the mad

 * @recvd_mad:  Received mad

 *

 * Return: returns value of the vnic port number

/**

 * vema_get_vport_adapter -- Get vnic port adapter from recvd mad

 * @recvd_mad: received mad

 * @port: ptr to port struct on which MAD was recvd

 *

 * Return: vnic adapter

/**

 * vema_mac_tbl_req_ok -- Check if mac request has correct values

 * @mac_tbl: mac table

 *

 * This function checks for the validity of the offset and number of

 * entries required.

 *

 * Return: true if offset and num_entries are valid

/*

 * Return the power on default values in the port info structure

 * in big endian format as required by MAD.

/**

 * vema_add_vport -- Add a new vnic port

 * @port: ptr to opa_vnic_vema_port struct

 * @vport_num: vnic port number (to be added)

 *

 * Return a pointer to the vnic adapter structure

/**

 * vema_get_class_port_info -- Get class info for port

 * @port:  Port on whic MAD was received

 * @recvd_mad: pointer to the received mad

 * @rsp_mad:   pointer to respose mad

 *

 * This function copies the latest class port info value set for the

 * port and stores it for generating traps

	/*

	 * Set capability mask bit indicating agent generates traps,

	 * and set the maximum number of VNIC ports supported.

	/*

	 * Since a get routine is always sent by the EM first we

	 * set the expected response time to

	 * 4.096 usec * 2^18 == 1.0737 sec here.

/**

 * vema_set_class_port_info -- Get class info for port

 * @port:  Port on whic MAD was received

 * @recvd_mad: pointer to the received mad

 * @rsp_mad:   pointer to respose mad

 *

 * This function updates the port class info for the specific vnic

 * and sets up the response mad data

/**

 * vema_get_veswport_info -- Get veswport info

 * @port:      source port on which MAD was received

 * @recvd_mad: pointer to the received mad

 * @rsp_mad:   pointer to respose mad

/**

 * vema_set_veswport_info -- Set veswport info

 * @port:      source port on which MAD was received

 * @recvd_mad: pointer to the received mad

 * @rsp_mad:   pointer to respose mad

 *

 * This function gets the port class infor for vnic

 Process the new config settings */

/**

 * vema_get_mac_entries -- Get MAC entries in VNIC MAC table

 * @port:      source port on which MAD was received

 * @recvd_mad: pointer to the received mad

 * @rsp_mad:   pointer to respose mad

 *

 * This function gets the MAC entries that are programmed into

 * the VNIC MAC forwarding table. It checks for the validity of

 * the index into the MAC table and the number of entries that

 * are to be retrieved.

/**

 * vema_set_mac_entries -- Set MAC entries in VNIC MAC table

 * @port:      source port on which MAD was received

 * @recvd_mad: pointer to the received mad

 * @rsp_mad:   pointer to respose mad

 *

 * This function sets the MAC entries in the VNIC forwarding table

 * It checks for the validity of the index and the number of forwarding

 * table entries to be programmed.

/**

 * vema_set_delete_vesw -- Reset VESW info to POD values

 * @port:      source port on which MAD was received

 * @recvd_mad: pointer to the received mad

 * @rsp_mad:   pointer to respose mad

 *

 * This function clears all the fields of veswport info for the requested vesw

 * and sets them back to the power-on default values. It does not delete the

 * vesw.

 Process the new config settings */

/**

 * vema_get_mac_list -- Get the unicast/multicast macs.

 * @port:      source port on which MAD was received

 * @recvd_mad: Received mad contains fields to set vnic parameters

 * @rsp_mad:   Response mad to be built

 * @attr_id:   Attribute ID indicating multicast or unicast mac list

/**

 * vema_get_summary_counters -- Gets summary counters.

 * @port:      source port on which MAD was received

 * @recvd_mad: Received mad contains fields to set vnic parameters

 * @rsp_mad:   Response mad to be built

/**

 * vema_get_error_counters -- Gets summary counters.

 * @port:      source port on which MAD was received

 * @recvd_mad: Received mad contains fields to set vnic parameters

 * @rsp_mad:   Response mad to be built

/**

 * vema_get -- Process received get MAD

 * @port:      source port on which MAD was received

 * @recvd_mad: Received mad

 * @rsp_mad:   Response mad to be built

/**

 * vema_set -- Process received set MAD

 * @port:      source port on which MAD was received

 * @recvd_mad: Received mad contains fields to set vnic parameters

 * @rsp_mad:   Response mad to be built

/**

 * vema_send -- Send handler for VEMA MAD agent

 * @mad_agent: pointer to the mad agent

 * @mad_wc:    pointer to mad send work completion information

 *

 * Free all the data structures associated with the sent MAD

/**

 * vema_recv -- Recv handler for VEMA MAD agent

 * @mad_agent: pointer to the mad agent

 * @send_buf: Send buffer if found, else NULL

 * @mad_wc:    pointer to mad send work completion information

 *

 * Handle only set and get methods and respond to other methods

 * as unsupported. Allocate response buffer and address handle

 * for the response MAD.

 Lock ensures network adapter is not removed */

		/*

		 * with post send successful ah and send mad

		 * will be destroyed in send handler

/**

 * vema_get_port -- Gets the opa_vnic_vema_port

 * @cport: pointer to control dev

 * @port_num: Port number

 *

 * This function loops through the ports and returns

 * the opa_vnic_vema port structure that is associated

 * with the OPA port number

 *

 * Return: ptr to requested opa_vnic_vema_port strucure

 *         if success, NULL if not

/**

 * opa_vnic_vema_send_trap -- This function sends a trap to the EM

 * @adapter: pointer to vnic adapter

 * @data: pointer to trap data filled by calling function

 * @lid:  issuers lid (encap_slid from vesw_port_info)

 *

 * This function is called from the VNIC driver to send a trap if there

 * is somethng the EM should be notified about. These events currently

 * are

 * 1) UNICAST INTERFACE MACADDRESS changes

 * 2) MULTICAST INTERFACE MACADDRESS changes

 * 3) ETHERNET LINK STATUS changes

 * While allocating the send mad the remote site qpn used is 1

 * as this is the well known QP.

 *

 Set up address handle */

	/*

	 * check for trap lid validity, must not be zero

	 * The trap sink could change after we fashion the MAD but since traps

	 * are not guaranteed we won't use a lock as anyway the change will take

	 * place even with locking.

 Set up common MAD hdr */

 Set up vendor OUI */

 Setup notice attribute portion */

 copy the actual trap data */

 If successful send set up rate limit timeout else bail */

/**

 * vema_unregister -- Unregisters agent

 * @cport: pointer to control port

 *

 * This deletes the registration by VEMA for MADs

 Lock ensures no MAD is being processed */

/**

 * vema_register -- Registers agent

 * @cport: pointer to control port

 *

 * This function registers the handlers for the VEMA MADs

 *

 * Return: returns 0 on success. non zero otherwise

 register ib event handler and mad agent for each port on dev */

/**

 * opa_vnic_ctrl_config_dev -- This function sends a trap to the EM

 * by way of ib_modify_port to indicate support for ethernet on the

 * fabric.

 * @cport: pointer to control port

 * @en: enable or disable ethernet on fabric support

/**

 * opa_vnic_vema_add_one -- Handle new ib device

 * @device: ib device pointer

 *

 * Allocate the vnic control port and initialize it.

 Initialize opa vnic management agent (vema) */

/**

 * opa_vnic_vema_rem_one -- Handle ib device removal

 * @device: ib device pointer

 * @client_data: ib client data

 *

 * Uninitialize and free the vnic control port.

/*

 * Copyright(c) 2017 Intel Corporation.

 *

 * This file is provided under a dual BSD/GPLv2 license.  When using or

 * redistributing this file, you may do so under either license.

 *

 * GPL LICENSE SUMMARY

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of version 2 of the GNU General Public License as

 * published by the Free Software Foundation.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU

 * General Public License for more details.

 *

 * BSD LICENSE

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 *  - Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *  - Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *  - Neither the name of Intel Corporation nor the names of its

 *    contributors may be used to endorse or promote products derived

 *    from this software without specific prior written permission.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR

 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT

 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,

 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT

 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,

 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY

 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE

 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

/*

 * This file contains OPA VNIC ethtool functions

 NETDEV stats */

 SUMMARY counters */

 ERROR counters */

 vnic_get_drvinfo - get driver info */

 vnic_get_sset_count - get string set count */

 vnic_get_ethtool_stats - get statistics */

 vnic_get_strings - get strings */

 ethtool ops */

 opa_vnic_set_ethtool_ops - set ethtool ops */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Allocate the dma buffer for storing ROCEE table entries

 *

 * @size: required size

 * @page_shift: the unit size in a continuous dma address range

 * @flags: HNS_ROCE_BUF_ flags to control the allocation flow.

 The minimum shift of the page accessed by hw is HNS_HW_PAGE_SHIFT */

 Calc the trunk size and num by required size and page_shift */

 In nofail mode, it's only failed when the alloced size is 0 */

 convert system page cnt to hw page cnt */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * make sure we signal QP destroy leg that flush QP was completed

	 * so that it can safely proceed ahead now and destroy QP

	/*

	 * Hip08 hardware cannot flush the WQEs in SQ/RQ if the QP state

	 * gets into errored mode. Hence, as a workaround to this

	 * hardware limitation, driver needs to assist in flushing. But

	 * the flushing operation uses mailbox to convey the QP state to

	 * the hardware and which can sleep due to the mutex protection

	 * around the mailbox calls. Hence, use the deferred flush for

	 * now.

 the QPN should keep increasing until the max value is reached. */

 the lower 3 bits is bankid */

 when hw version is v1, the sqpn is allocated */

 add QP to device's QP list for softwc */

 In v1 engine, GSI QP context is saved in the RoCE hw's register */

 Alloc memory for QPC */

 Alloc memory for IRRL */

 Alloc memory for TRRL */

 Alloc memory for SCC CTX */

 In v1 engine, GSI QP context is saved in the RoCE hw's register */

 The lower 3 bits of QPN are used to hash to different banks */

	/* Reserve SGEs only for HIP08 in kernel; The userspace driver will

	 * calculate number of max_sge with reserved SGEs when allocating wqe

	 * buf, so there is no need to do this again in kernel. But the number

	 * may exceed the capacity of SGEs recorded in the firmware, so the

	 * kernel driver should just adapt the value accordingly.

 If srq exist, set zero for relative number of rq */

 Check the validity of QP support capacity */

 GSI/UD QP only has extended sge */

	/* If the number of extended sge is not zero, they MUST use the

	 * space of HNS_HW_PAGE_SIZE at least.

 Sanity check SQ size before proceeding */

 SQ WQE */

 extend SGE WQE in SQ */

 RQ WQE */

 sync the parameters of kernel QP to user's configuration */

 allocate recv inline buf */

 Allocate a continuous buffer for all inline sge we need */

 Assign buffers of sg_list to each inline wqe */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Using bitmap to manager UAR index */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 HIP08 needs to record vlan info in Address Vector */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-2-Clause) */

/*

 * Copyright (c) 2017 Hisilicon Limited.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 This should never fail -- we just allocated an empty page: */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Allocate a key for mr from mr_table */

 MR key */

 fast MR's buffer is alloced before mapping, not at creation */

 Allocate mailbox memory */

 Allocate memory region key */

 Allocate memory region key */

 prepare HEM entry memory */

 Allocate a key for mw from mr_table */

	/* because the mtr only one root base address, when hopnum is 0 means

	 * root base address equals the first buffer address, thus all alloced

	 * memory must in a continuous space accessed by direct mode.

/*

 * check the given pages in continuous address space

 * Returns 0 on success, or the error page num.

 release user buffers */

 release kernel buffers */

 alloc a tmp array to store buffer's dma address */

	/*

	 * Only use the first page address as root ba when hopnum is 0, this

	 * is because the addresses of all pages are consecutive in this case.

 if hopnum is 0, no need to map pages in this region */

 no mtt memory in direct mode, so just return the buffer address */

 If mtt is disabled, all pages must be within a continuous range */

		/* When HEM buffer uses 0-level addressing, the page size is

		 * equal to the whole buffer size, and we split the buffer into

		 * small pages which is used to check whether the adjacent

		 * units are in the continuous space and its size is fixed to

		 * 4K based on hns ROCEE's requirement.

 The ROCEE requires the page size to be 4K * 2 ^ N. */

	/* Convert buffer size to page index and page count for each region and

	 * the buffer's offset needs to be appended to the first region.

/**

 * hns_roce_mtr_create - Create hns memory translate region.

 *

 * @hr_dev: RoCE device struct pointer

 * @mtr: memory translate region

 * @buf_attr: buffer attribute for creating mtr

 * @ba_page_shift: page shift for multi-hop base address table

 * @udata: user space context, if it's NULL, means kernel space

 * @user_addr: userspace virtual address to start at

	/* The caller has its own buffer list and invokes the hns_roce_mtr_map()

	 * to finish the MTT configuration.

 Write buffer's dma address to MTT */

 release multi-hop addressing resource */

 free buffers */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 the lower 2 bits is bankid */

 The lower 2 bits of CQN are used to hash to different banks */

 Get CQC memory HEM(Hardware Entry Memory) table */

 Allocate mailbox memory */

 Send mailbox to hw */

 Waiting interrupt process procedure carried out */

 wait for all interrupt processed */

 used as cqe index */

	/*

	 * For the QP created by kernel space, tptr value should be initialized

	 * to zero; For the QP created by user space, it will cause synchronous

	 * problems if tptr is set to zero here, so we initialize it in user

	 * space.

 SPDX-License-Identifier: (GPL-2.0 OR BSD-2-Clause)

 Copyright (c) 2019 Hisilicon Limited.

/*

 * Copyright (c) 2016 Hisilicon Limited.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/**

 * hns_get_gid_index - Get gid index.

 * @hr_dev: pointer to structure hns_roce_dev.

 * @port:  port, value range: 0 ~ MAX

 * @gid_index:  gid_index, value range: 0 ~ MAX

 * Description:

 *    N ports shared gids, allocation method as follow:

 *		GID[0][0], GID[1][0],.....GID[N - 1][0],

 *		GID[0][0], GID[1][0],.....GID[N - 1][0],

 *		And so on

 Corresponding to the RC and RD type wqe process separately */

 Ctrl field, ctrl set type: sig, solic, imm, fence */

 SO wait for conforming application scenarios */

 sqe num is two */

 Set DB return */

 SW update GSI rq header */

 Find the HEM(Hardware Entry Memory) entry */

 Currently iter only a chunk */

 Configure SDB/ODB extend mode */

 Configure SDB */

 Configure ODB */

 Configure extend SDB threshold */

 Configure extend SDB base addr */

 Configure extend SDB depth */

	/*

	 * 44 = 32 + 12, When evaluating addr to hardware, shift 12 because of

	 * using 4K page, and shift more 32 because of

	 * calculating the high 32 bit value evaluated to hardware.

 Configure extend ODB threshold */

 Configure extend ODB base addr */

 Configure extend ODB depth */

 Reserved cq for loop qp */

 Disable read ability */

 Use arbitrary values as rq_psn and sq_psn */

 Default DB mode */

 Init extend DB */

 Configure raq extended address. 48bit 4K align */

 Configure raq_shift */

	/*

	 * 44 = 32 + 12, When evaluating addr to hardware, shift 12 because of

	 * using 4K page, and shift more 32 because of

	 * calculating the high 32 bit value evaluated to hardware.

 Configure raq threshold */

 Enable extend raq */

 Enable raq drop */

 Open all ports */

 Close all ports */

	/*

	 * This buffer will be used for CQ's tptr(tail pointer), also

	 * named ci(customer index). Every CQ will use 2 bytes to save

	 * cqe ci in hip06. Hardware will read this area to get new ci

	 * when the queue is almost full.

/**

 * hns_roce_v1_reset - reset RoCE

 * @hr_dev: RoCE device struct pointer

 * @dereset: true -- drop reset, false -- reset

 * return 0 - success , negative --fail

 check if this is DT/ACPI case */

 2 SQP per port, six ports total 12 */

 Six ports shared 16 GID in v1 engine */

 DMAE user config */

 Memory barrier */

	/*

	 * When mac changed, loopback may fail

	 * because of smac not equal to dmac.

	 * We Need to release and create reserved qp again.

 MPT filled into mailbox buf */

 DMA memory register */

 Register user mr */

 Get cqe when Owner bit is Conversely with the MSB of cons_idx */

	/*

	 * Now backwards through the CQ, removing CQ entries

	 * that match our QP by overwriting them with next entries.

 In v1 engine, not support SRQ */

 Get the tptr for this CQ. */

 Register cq_context members */

 Dedicated hardware, directly set 0 */

	/**

	 * 44 = 32 + 12, When evaluating addr to hardware, shift 12 because of

	 * using 4K page, and shift more 32 because of

	 * calculating the high 32 bit value evaluated to hardware.

 The initial value of cq's ci is 0 */

	/*

	 * flags = 0; Notification Flag = 1, next

	 * flags = 1; Notification Flag = 0, solocited

 Find cqe according consumer index */

 Memory barrier */

 0->SQ, 1->RQ */

 Local_qpn in UD cqe is always 1, so it needs to compute new qpn */

 CQE status error, directly return */

 SQ conrespond to CQE */

			/*

			 * If sg_signal_bit is 1,

			 * firstly tail pointer updated to wqe

			 * which current cqe correspond to

 RQ conrespond to CQE */

 Update tail pointer, record wr_id */

		/* Note: In v1 engine, HW doesn't support RST2INIT.

		 * We use RST2INIT cmd instead of INIT2INIT.

 Search QP buf's MTTs */

 Copy context to QP1C register */

 Modify QP1C status */

 Search qp buf's mtts */

 Search IRRL's mtts */

	/*

	 * Reset to init

	 *	Mandatory param:

	 *	IB_QP_STATE | IB_QP_PKEY_INDEX | IB_QP_PORT | IB_QP_ACCESS_FLAGS

	 *	Optional param: NA

 when dmac equals smac or loop_idc is 1, it should loopback */

 Configure GID index */

 For chip resp ack */

 If exist optional param, return error */

 Every status migrate must change state */

 SW pass context to HW */

	/*

	 * Use rst2init to instead of init2init with drv,

	 * need to hw to flash RQ HEAD by DB again

	/*

	 * Before freeing cq buffer, we need to ensure that the outstanding CQE

	 * have been written by checking the CQE counter.

		/* Make sure we read the AEQ entry after we have checked the

		 * ownership bit

		/* Make sure we read CEQ entry after we have checked the

		 * ownership bit

 CEQ irq routine, CEQ is pulse irq, not clear */

 AEQ irq routine, AEQ is pulse irq, not clear */

	/*

	 * Abnormal interrupt:

	 * AEQ overflow, ECC multi-bit err, CEQ overflow must clear

	 * interrupt, mask irq, clear irq, cancel mask operation

 AEQE overflow */

 Set mask */

 Clear int state(INT_WC : write 1 clear) */

 Clear mask */

 CEQ almost overflow */

 Set mask */

 Clear int state(INT_WC : write 1 clear) */

 Clear mask */

 ECC multi-bit error alarm */

 AEQ INT */

 CEQ INT */

 IRQ mask */

 Configure eq extended address 12~44bit */

	/*

	 * Configure eq extended address 45~49 bit.

	 * 44 = 32 + 12, When evaluating addr to hardware, shift 12 because of

	 * using 4K page, and shift more 32 because of

	 * calculating the high 32 bit value evaluated to hardware.

 Configure eq consumer index */

 CEQ */

 AEQ */

 Disable irq */

 Configure ce int interval */

 Configure ce int burst num */

 Disable EQ */

 get the 'device' corresponding to the matching 'fwnode' */

 get the platform device */

 check if we are compatible with the underlying SoC */

 get the mapped register base address */

 read the node_guid of IB device from the DT or ACPI */

 get the RoCE associated ethernet ports or netdevices */

 cmd issue mode: 0 is poll, 1 is event */

 read the interrupt names from the DT or ACPI */

 fetch the interrupt numbers */

/**

 * hns_roce_probe - RoCE driver entrance

 * @pdev: pointer to platform device

 * Return : int

 *

/**

 * hns_roce_remove - remove RoCE device

 * @pdev: pointer to platform device

/*

 * Copyright (c) 2016-2017 Hisilicon Limited.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * mapped-value = 1 + real-value

 * The hns wr opcode real value is start from 0, In order to distinguish between

 * initialized and uninitialized map values, we plus 1 to the actual value when

 * defining the mapping, so that the validity can be identified by checking the

 * mapped value is greater than 0.

 use ib_access_flags */

 Data structure reuse may lead to confusion */

	/* When copying data to extended sge space, the left length in page may

	 * not long enough for current user's sge. So the data should be

	 * splited into several parts, one in the first page, and the others in

	 * the subsequent pages.

	/*

	 * The pipeline can sequentially post all valid WQEs into WQ buffer,

	 * including new WQEs waiting for the doorbell to update the PI again.

	 * Therefore, the owner bit of WQE MUST be updated after all fields

	 * and extSGEs have been written into DDR instead of cache.

	/*

	 * The pipeline can sequentially post all valid WQEs into WQ buffer,

	 * including new WQEs waiting for the doorbell to update the PI again.

	 * Therefore, the owner bit of WQE MUST be updated after all fields

	 * and extSGEs have been written into DDR instead of cache.

 All kinds of DirectWQE have the same header field layout */

 Corresponding to the QP type, wqe process separately */

 Skip zero-length sge */

 Fill a reserved sge to make hw stop reading remaining segments */

 Clear remaining segments to make ROCEE ignore sges */

 rq support inline data */

 always called with interrupts disabled. */

	/* When hardware reset has been completed once or more, we should stop

	 * sending mailbox&cmq&doorbell to hardware. If now in .init_instance()

	 * function, we should exit with error. If now at HNAE3_INIT_CLIENT

	 * stage of soft reset process, we should exit with error, and then

	 * HNAE3_INIT_CLIENT related process can rollback the operation like

	 * notifing hardware to free resources, HNAE3_INIT_CLIENT related

	 * process will exit with error to notify NIC driver to reschedule soft

	 * reset process once again.

	/* When hardware reset is detected, we should stop sending mailbox&cmq&

	 * doorbell to hardware. If now in .init_instance() function, we should

	 * exit with error. If now at HNAE3_INIT_CLIENT stage of soft reset

	 * process, we should exit with error, and then HNAE3_INIT_CLIENT

	 * related process can rollback the operation like notifing hardware to

	 * free resources, HNAE3_INIT_CLIENT related process will exit with

	 * error to notify NIC driver to reschedule soft reset process once

	 * again.

	/* When software reset is detected at .init_instance() function, we

	 * should stop sending mailbox&cmq&doorbell to hardware, and exit

	 * with error.

 the current instance stage */

 the current reset stage */

	/* Get information about reset from NIC driver or RoCE driver itself,

	 * the meaning of the following variables from NIC driver are described

	 * as below:

	 * reset_cnt -- The count value of completed hardware reset.

	 * hw_resetting -- Whether hardware device is resetting now.

	 * sw_resetting -- Whether NIC's software reset process is running now.

 Make sure to write CI first and then PI */

 Write to hardware */

 check the result of hardware write back */

 FW/HW reset or incorrect number of desc */

 Use default caps when hns_roce_query_pf_caps() failed or init VF profile */

 The following configuration are only valid for HIP08 */

 EQ */

 Link Table */

 MR */

 QP */

 CQ */

 SRQ */

 GMV */

 Apply all loaded caps before setting to hardware */

 The following configurations don't need to be got from firmware. */

 The following configurations will be overwritten */

 The following configurations are not got from firmware */

 Configure the size of QPC, SCCC, etc. */

 Alloc data table */

 Alloc config table */

 Alloc memory for source address table buffer space chunk */

 Alloc memory for QPC Timer buffer space chunk */

 Alloc memory for CQC Timer buffer space chunk */

 The hns ROCEE requires the extdb info to be cleared before using */

 No pending message exists in ROCEE mbox. */

 Ignore all errors if the mbox is unavailable. */

 Waiting for the mbox to be idle */

 Post new message to mbox */

 Aligned to the hardware address access unit */

 Get cqe when Owner bit is Conversely with the MSB of cons_idx */

	/*

	 * Now backwards through the CQ, removing CQ entries

	 * that match our QP by overwriting them with next entries.

	/*

	 * flags = 0, then notify_flag : next

	 * flags = 1, then notify flag : solocited

	/*

	 * For hns ROCEE, GENERAL_ERR is an error type that is not defined in

	 * the standard protocol, the driver must ignore it and needn't to set

	 * the QP to an error state.

/*

 * mapped-value = 1 + real-value

 * The ib wc opcode's real value is start from 0, In order to distinguish

 * between initialized and uninitialized map values, we plus 1 to the actual

 * value when defining the mapping, so that the validity can be identified by

 * checking whether the mapped value is greater than 0.

 Memory barrier */

		/* If sg_signal_bit is set, tail pointer will be updated to

		 * the WQE corresponding to the current CQE.

	/*

	 * When the device starts to reset, the state is RST_DOWN. At this time,

	 * there may still be some valid CQEs in the hardware that are not

	 * polled. Therefore, it is not allowed to switch to the software mode

	 * immediately. When the state changes to UNINIT, CQE no longer exists

	 * in the hardware, and then switch to software mode.

 configure the tag and op */

 The qpc size of HIP08 is only 256B, which is half of HIP09 */

	/*

	 * In v2 engine, software pass context and context mask to hardware

	 * when modifying qp. If software need modify some fields in context,

	 * we should set all bits of the relevant fields in context mask to

	 * 0 at the same time, else set them to 0x1.

 No VLAN need to set 0xFFF */

	/*

	 * In v2 engine, software pass context and context mask to hardware

	 * when modifying qp. If software need modify some fields in context,

	 * we should set all bits of the relevant fields in context mask to

	 * 0 at the same time, else set them to 0x1.

 Search qp buf's mtts */

	/*

	 * In v2 engine, software pass context and context mask to hardware

	 * when modifying qp. If software need modify some fields in context,

	 * we should set all bits of the relevant fields in context mask to

	 * 0 at the same time, else set them to 0x1.

 search qp buf's mtts */

	/*

	 * In v2 engine, software pass context and context mask to hardware

	 * when modifying qp. If software need modify some fields in context,

	 * we should set all bits of the relevant fields in context mask to

	 * 0 at the same time, else set them to 0x1.

 Search IRRL's mtts */

 Search TRRL's mtts */

 when dmac equals smac or loop_idc is 1, it should loopback */

 MTU * (2 ^ LP_PKTN_INI) shouldn't be bigger than 16KB */

 ACK_REQ_FREQ should be larger than or equal to LP_PKTN_INI */

 rocee send 2^lp_sgen_ini segs every time */

 Not support alternate path and path migration */

	/*

	 * Set some fields in context to zero, Because the default values

	 * of all fields in context are zero, we need not set them to 0 again.

	 * but we should set the relevant fields of context mask to 0.

	/* If no dgid is found, a new dip and a mapping between dgid and

	 * dip_idx will be created.

 different congestion types match different configurations */

 if dip is disabled, there is no need to set dip idx */

 Only HIP08 needs to set the vlan_en bits in QPC */

 no RQ */

	/*

	 * In v2 engine, software pass context and context mask to hardware

	 * when modifying qp. If software need modify some fields in context,

	 * we should set all bits of the relevant fields in context mask to

	 * 0 at the same time, else set them to 0x1.

 When QP state is err, SQ and RQ WQE should be flushed */

 Configure the optional fields */

 Every status migrate must change state */

 SW pass context to HW */

 Modify qp to reset before destroying qp */

 set scc ctx clear done flag */

 clear scc context */

 query scc context clear is done or not */

 Get physical address of idx que buf */

 Get the physical address of srq buf */

 Resizing SRQs is not supported yet */

		/* Make sure we read AEQ entry after we have checked the

		 * ownership bit

		/* Make sure we read CEQ entry after we have checked the

		 * ownership bit

 Completion event interrupt */

 Asychronous event interrupt */

 Abnormal interrupt */

 Set reset level for reset_event() */

 if not multi-hop, eqe buffer only use one trunk */

 Allocate mailbox memory */

 irq contains: abnormal + AEQ + CEQ */

 create eq */

 CEQ */

 AEQ */

 enable irq */

 Disable irq */

 required last entry */

 Get info from NIC driver. */

 cmd issue mode: 0 is poll, 1 is event */

		/* when reset notify type is HNAE3_INIT_CLIENT In reset notify

		 * callback function, RoCE Engine reinitialize. If RoCE reinit

		 * failed, we should inform NIC driver.

/*

 * Copyright (c) 2016 Hisilicon Limited.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 indicate which index is available */

	/*

	 * QPC/MTPT/CQC/SRQC/SCCC alloc hem for buffer pages.

	 * MTT/CQE alloc hem for bt pages.

		/*

		 * Alloc memory one time. If failed, don't alloc small block

		 * memory, directly return fail.

 alloc L1 BA's chunk */

 alloc L2 BA's chunk */

	/*

	 * alloc buffer space chunk for QPC/MTPT/CQC/SRQC/SCCC.

	 * alloc bt space chunk for MTT/CQE.

 set HEM base address to hardware */

 Set HEM base address(128K/page, pa) to Hardware */

 8 bytes per BA and 8 BA per segment */

 mtt mhop */

 link all hems in the same bt level */

 link all hems in last hop for mtt */

 max ba numbers */

 start buf offset in this hem */

 end buf offset in this hem */

 All HEM items are linked in a tree structure */

 assign L0 table address to hem from root bt */

	/*

	 * hopnum    base address table levels

	 * 0		L0(buf)

	 * 1		L0 -> buf

	 * 2		L0 -> L1 -> buf

	 * 3		L0 -> L1 -> L2 -> buf

/*

 * calc base address entries num

 * @hopnum: num of mutihop addressing

 * @bt_level: base address table level

 * @unit: ba entries per bt page

	/*

	 * hopnum  bt_level   range

	 * 1	      0       unit

	 * ------------

	 * 2	      0       unit * unit

	 * 2	      1       unit

	 * ------------

	 * 3	      0       unit * unit * unit

	 * 3	      1       unit * unit

	 * 3	      2       unit

/*

 * calc the root ba entries which could cover all regions

 * @regions: buf region array

 * @region_cnt: array size of @regions

 * @unit: ba entries per bt page

 config L1 bt to last bt and link them to corresponding parent */

 link bt to parent bt */

 indicate to last region */

 if exist mid bt, link L1 to L0 */

 all regions's mid[x][0] shared the root_bt's trunk */

		/* if hopnum is 0 or 1, cut a new fake hem from the root bt

		 * which's address share to all regions.

 List head for storing all allocated HEM items */

 construct the base address table and link them by address hop config */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 this should be called with "poll_sem" */

/*

 * Copyright (c) 2016 Hisilicon Limited.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

		/*

		 * In v1 engine, only support all ports closed together.

 props being zeroed by the caller, avoid zeroing it here */

	/*

	 * FIXME: using io_remap_pfn_range on the dma address returned

	 * by dma_alloc_coherent is totally wrong.

/**

 * hns_roce_setup_hca - setup host channel adapter

 * @hr_dev: pointer to hns roce device

 * Return : int

 EQ depends on poll mode, event mode depends on EQ */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2018 Hisilicon Limited.

	/* Reserve SGEs only for HIP08 in kernel; The userspace driver will

	 * calculate number of max_sge with reserved SGEs when allocating wqe

	 * buf, so there is no need to do this again in kernel. But the number

	 * may exceed the capacity of SGEs recorded in the firmware, so the

	 * kernel driver should just adapt the value accordingly.

 SPDX-License-Identifier: (GPL-2.0 OR BSD-2-Clause)

 Copyright (c) 2019 Hisilicon Limited.

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

 types of hmc objects */

/**

 * irdma_iwarp_ce_handler - handle iwarp completions

 * @iwcq: iwarp cq receiving event

/**

 * irdma_puda_ce_handler - handle puda completion events

 * @rf: RDMA PCI function

 * @cq: puda completion q for event

/**

 * irdma_process_ceq - handle ceq for completions

 * @rf: RDMA PCI function

 * @ceq: ceq having cq for completion

/**

 * irdma_process_aeq - handle aeq events

 * @rf: RDMA PCI function

/**

 * irdma_ena_intr - set up device interrupts

 * @dev: hardware control device structure

 * @msix_id: id of the interrupt to be enabled

/**

 * irdma_dpc - tasklet for aeq and ceq 0

 * @t: tasklet_struct ptr

/**

 * irdma_ceq_dpc - dpc handler for CEQ

 * @t: tasklet_struct ptr

/**

 * irdma_save_msix_info - copy msix vector information to iwarp device

 * @rf: RDMA PCI function

 *

 * Allocate iwdev msix table and copy the msix info to the table

 * Return 0 if successful, otherwise return error

/**

 * irdma_irq_handler - interrupt handler for aeq and ceq0

 * @irq: Interrupt request number

 * @data: RDMA PCI function

/**

 * irdma_ceq_handler - interrupt handler for ceq

 * @irq: interrupt request number

 * @data: ceq pointer

/**

 * irdma_destroy_irq - destroy device interrupts

 * @rf: RDMA PCI function

 * @msix_vec: msix vector to disable irq

 * @dev_id: parameter to pass to free_irq (used during irq setup)

 *

 * The function is called when destroying aeq/ceq

/**

 * irdma_destroy_cqp  - destroy control qp

 * @rf: RDMA PCI function

 * @free_hwcqp: 1 if hw cqp should be freed

 *

 * Issue destroy cqp request and

 * free the resources associated with the cqp

/**

 * irdma_destroy_aeq - destroy aeq

 * @rf: RDMA PCI function

 *

 * Issue a destroy aeq request and

 * free the resources associated with the aeq

 * The function is called during driver unload

/**

 * irdma_destroy_ceq - destroy ceq

 * @rf: RDMA PCI function

 * @iwceq: ceq to be destroyed

 *

 * Issue a destroy ceq request and

 * free the resources associated with the ceq

/**

 * irdma_del_ceq_0 - destroy ceq 0

 * @rf: RDMA PCI function

 *

 * Disable the ceq 0 interrupt and destroy the ceq 0

/**

 * irdma_del_ceqs - destroy all ceq's except CEQ 0

 * @rf: RDMA PCI function

 *

 * Go through all of the device ceq's, except 0, and for each

 * ceq disable the ceq interrupt and destroy the ceq

/**

 * irdma_destroy_ccq - destroy control cq

 * @rf: RDMA PCI function

 *

 * Issue destroy ccq request and

 * free the resources associated with the ccq

/**

 * irdma_close_hmc_objects_type - delete hmc objects of a given type

 * @dev: iwarp device

 * @obj_type: the hmc object type to be deleted

 * @hmc_info: host memory info struct

 * @privileged: permission to close HMC objects

 * @reset: true if called before reset

/**

 * irdma_del_hmc_objects - remove all device hmc objects

 * @dev: iwarp device

 * @hmc_info: hmc_info to free

 * @privileged: permission to delete HMC objects

 * @reset: true if called before reset

 * @vers: hardware version

/**

 * irdma_create_hmc_obj_type - create hmc object of a given type

 * @dev: hardware control device structure

 * @info: information for the hmc object to create

/**

 * irdma_create_hmc_objs - create all hmc objects for the device

 * @rf: RDMA PCI function

 * @privileged: permission to create HMC objects

 * @vers: HW version

 *

 * Create the device hmc objects and allocate hmc pages

 * Return 0 if successful, otherwise clean up and return error

 destroy the hmc objects of a given type */

/**

 * irdma_obj_aligned_mem - get aligned memory from device allocated memory

 * @rf: RDMA PCI function

 * @memptr: points to the memory addresses

 * @size: size of memory needed

 * @mask: mask for the aligned memory

 *

 * Get aligned memory of the requested size and

 * update the memptr to point to the new aligned memory

 * Return 0 if successful, otherwise return no memory error

/**

 * irdma_create_cqp - create control qp

 * @rf: RDMA PCI function

 *

 * Return 0, if the cqp and all the resources associated with it

 * are successfully created, otherwise return error

 populate the cqp init info */

 init the waitqueue of the cqp_requests and add them to the list */

/**

 * irdma_create_ccq - create control cq

 * @rf: RDMA PCI function

 *

 * Return 0, if the ccq and the resources associated with it

 * are successfully created, otherwise return error

 populate the ccq init info */

/**

 * irdma_alloc_set_mac - set up a mac address table entry

 * @iwdev: irdma device

 *

 * Allocate a mac ip entry and add it to the hw table Return 0

 * if successful, otherwise return error

/**

 * irdma_cfg_ceq_vector - set up the msix interrupt vector for

 * ceq

 * @rf: RDMA PCI function

 * @iwceq: ceq associated with the vector

 * @ceq_id: the id number of the iwceq

 * @msix_vec: interrupt vector information

 *

 * Allocate interrupt resources and enable irq handling

 * Return 0 if successful, otherwise return error

/**

 * irdma_cfg_aeq_vector - set up the msix vector for aeq

 * @rf: RDMA PCI function

 *

 * Allocate interrupt resources and enable irq handling

 * Return 0 if successful, otherwise return error

/**

 * irdma_create_ceq - create completion event queue

 * @rf: RDMA PCI function

 * @iwceq: pointer to the ceq resources to be created

 * @ceq_id: the id number of the iwceq

 * @vsi: SC vsi struct

 *

 * Return 0, if the ceq and the resources associated with it

 * are successfully created, otherwise return error

/**

 * irdma_setup_ceq_0 - create CEQ 0 and it's interrupt resource

 * @rf: RDMA PCI function

 *

 * Allocate a list for all device completion event queues

 * Create the ceq 0 and configure it's msix interrupt vector

 * Return 0, if successfully set up, otherwise return error

/**

 * irdma_setup_ceqs - manage the device ceq's and their interrupt resources

 * @rf: RDMA PCI function

 * @vsi: VSI structure for this CEQ

 *

 * Allocate a list for all device completion event queues

 * Create the ceq's and configure their msix interrupt vectors

 * Return 0, if ceqs are successfully set up, otherwise return error

/**

 * irdma_create_aeq - create async event queue

 * @rf: RDMA PCI function

 *

 * Return 0, if the aeq and the resources associated with it

 * are successfully created, otherwise return error

 physically mapped aeq failed. setup virtual aeq */

/**

 * irdma_setup_aeq - set up the device aeq

 * @rf: RDMA PCI function

 *

 * Create the aeq and configure its msix interrupt vector

 * Return 0 if successful, otherwise return error

/**

 * irdma_initialize_ilq - create iwarp local queue for cm

 * @iwdev: irdma device

 *

 * Return 0 if successful, otherwise return error

/**

 * irdma_initialize_ieq - create iwarp exception queue

 * @iwdev: irdma device

 *

 * Return 0 if successful, otherwise return error

/**

 * irdma_reinitialize_ieq - destroy and re-create ieq

 * @vsi: VSI structure

/**

 * irdma_hmc_setup - create hmc objects for the device

 * @rf: RDMA PCI function

 *

 * Set up the device private memory space for the number and size of

 * the hmc objects and create the objects

 * Return 0 if successful, otherwise return error

/**

 * irdma_del_init_mem - deallocate memory resources

 * @rf: RDMA PCI function

/**

 * irdma_initialize_dev - initialize device

 * @rf: RDMA PCI function

 *

 * Allocate memory for the hmc objects and initialize iwdev

 * Return 0 if successful, otherwise clean up the resources

 * and return error

/**

 * irdma_rt_deinit_hw - clean up the irdma device resources

 * @iwdev: irdma device

 *

 * remove the mac ip entry and ipv4/ipv6 addresses, destroy the

 * device queues and free the pble and the hmc objects

/**

 * irdma_get_used_rsrc - determine resources used internally

 * @iwdev: irdma device

 *

 * Called at the end of open to get all internal allocations

/**

 * irdma_rt_init_hw - Initializes runtime portion of HW

 * @iwdev: irdma device

 * @l2params: qos, tc, mtu info from netdev driver

 *

 * Create device queues ILQ, IEQ, CEQs and PBLEs. Setup irdma

 * device resource objects.

		/* handles asynch cleanup tasks - disconnect CM , free qp,

		 * free cq bufs

/**

 * irdma_ctrl_init_hw - Initializes control portion of HW

 * @rf: RDMA PCI function

 *

 * Create admin queues, HMC obejcts and RF resource objects

 Handles processing of CQP completions */

/**

 * irdma_set_hw_rsrc - set hw memory resources.

 * @rf: RDMA PCI function

/**

 * irdma_calc_mem_rsrc_size - calculate memory resources size.

 * @rf: RDMA PCI function

/**

 * irdma_initialize_hw_rsrc - initialize hw resource tracking array

 * @rf: RDMA PCI function

 qp 2 IEQ */

 qp 1 ILQ */

 stag index mask has a minimum of 14 bits */

/**

 * irdma_cqp_ce_handler - handle cqp completions

 * @rf: RDMA PCI function

 * @cq: cq for cqp completions

/**

 * cqp_compl_worker - Handle cqp completions

 * @work: Pointer to work structure

/**

 * irdma_lookup_apbvt_entry - lookup hash table for an existing apbvt entry corresponding to port

 * @cm_core: cm's core

 * @port: port to identify apbvt entry

/**

 * irdma_next_iw_state - modify qp state

 * @iwqp: iwarp qp to modify

 * @state: next state for qp

 * @del_hash: del hash

 * @term: term message

 * @termlen: length of term message

/**

 * irdma_del_local_mac_entry - remove a mac entry from the hw

 * table

 * @rf: RDMA PCI function

 * @idx: the index of the mac ip address to delete

/**

 * irdma_add_local_mac_entry - add a mac ip address entry to the

 * hw table

 * @rf: RDMA PCI function

 * @mac_addr: pointer to mac address

 * @idx: the index of the mac ip address to add

/**

 * irdma_alloc_local_mac_entry - allocate a mac entry

 * @rf: RDMA PCI function

 * @mac_tbl_idx: the index of the new mac address

 *

 * Allocate a mac address entry and update the mac_tbl_idx

 * to hold the index of the newly created mac address

 * Return 0 if successful, otherwise return error

/**

 * irdma_cqp_manage_apbvt_cmd - send cqp command manage apbvt

 * @iwdev: irdma device

 * @accel_local_port: port for apbvt

 * @add_port: add ordelete port

/**

 * irdma_add_apbvt - add tcp port to HW apbvt table

 * @iwdev: irdma device

 * @port: port for apbvt

/**

 * irdma_del_apbvt - delete tcp port from HW apbvt table

 * @iwdev: irdma device

 * @entry: apbvt entry object

	/* apbvt_lock is held across CQP delete APBVT OP (non-waiting) to

	 * protect against race where add APBVT CQP can race ahead of the delete

	 * APBVT for same port.

/**

 * irdma_manage_arp_cache - manage hw arp cache

 * @rf: RDMA PCI function

 * @mac_addr: mac address ptr

 * @ip_addr: ip addr for arp cache

 * @ipv4: flag inicating IPv4

 * @action: add, delete or modify

/**

 * irdma_send_syn_cqp_callback - do syn/ack after qhash

 * @cqp_request: qhash cqp completion

/**

 * irdma_manage_qhash - add or modify qhash

 * @iwdev: irdma device

 * @cminfo: cm info for qhash

 * @etype: type (syn or quad)

 * @mtype: type of qhash

 * @cmnode: cmnode associated with connection

 * @wait: wait for completion

/**

 * irdma_hw_flush_wqes_callback - Check return code after flush

 * @cqp_request: qhash cqp completion

 RQ WQE flush was requested but did not happen */

/**

 * irdma_hw_flush_wqes - flush qp's wqe

 * @rf: RDMA PCI function

 * @qp: hardware control qp

 * @info: info for flush

 * @wait: flag wait for completion

 RQ WQE flush was requested but did not happen */

			/*

			 * Handling case where WQE is posted to empty SQ when

			 * flush has not completed

 SQ WQE flush was requested but did not happen */

/**

 * irdma_gen_ae - generate AE

 * @rf: RDMA PCI function

 * @qp: qp associated with AE

 * @info: info for ae

 * @wait: wait for completion

 Set flush info fields*/

 Generate userflush errors in CQE */

 Issue flush */

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

 PFINT_RATEN not used in FPK */

/**

 * i40iw_config_ceq- Configure CEQ interrupt

 * @dev: pointer to the device structure

 * @ceq_id: Completion Event Queue ID

 * @idx: vector index

 * @enable: Enable CEQ interrupt when true

/**

 * i40iw_ena_irq - Enable interrupt

 * @dev: pointer to the device structure

 * @idx: vector index

/**

 * i40iw_disable_irq - Disable interrupt

 * @dev: pointer to the device structure

 * @idx: vector index

 Setup the hardware limits, hmc may limit further */

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_free_sqbuf - put back puda buffer if refcount is 0

 * @vsi: The VSI structure of the device

 * @bufp: puda buffer to free

/**

 * irdma_record_ird_ord - Record IRD/ORD passed in

 * @cm_node: connection's node

 * @conn_ird: connection IRD

 * @conn_ord: connection ORD

/**

 * irdma_copy_ip_ntohl - copy IP address from  network to host

 * @dst: IP address in host order

 * @src: IP address in network order (big endian)

/**

 * irdma_copy_ip_htonl - copy IP address from host to network order

 * @dst: IP address in network order (big endian)

 * @src: IP address in host order

/**

 * irdma_get_addr_info

 * @cm_node: contains ip/tcp info

 * @cm_info: to get a copy of the cm_node ip/tcp info

/**

 * irdma_fill_sockaddr4 - fill in addr info for IPv4 connection

 * @cm_node: connection's node

 * @event: upper layer's cm event

/**

 * irdma_fill_sockaddr6 - fill in addr info for IPv6 connection

 * @cm_node: connection's node

 * @event: upper layer's cm event

/**

 * irdma_get_cmevent_info - for cm event upcall

 * @cm_node: connection's node

 * @cm_id: upper layers cm struct for the event

 * @event: upper layer's cm event

/**

 * irdma_send_cm_event - upcall cm's event handler

 * @cm_node: connection's node

 * @cm_id: upper layer's cm info struct

 * @type: Event type to indicate

 * @status: status for the event type

 Wait if we are in RTS but havent issued the iwcm event upcall */

/**

 * irdma_timer_list_prep - add connection nodes to a list to perform timer tasks

 * @cm_core: cm's core

 * @timer_list: a timer list to which cm_node will be selected

/**

 * irdma_create_event - create cm event

 * @cm_node: connection's node

 * @type: Event type to generate

/**

 * irdma_free_retrans_entry - free send entry

 * @cm_node: connection's node

/**

 * irdma_cleanup_retrans_entry - free send entry with lock

 * @cm_node: connection's node

/**

 * irdma_form_ah_cm_frame - get a free packet and build frame with address handle

 * @cm_node: connection's node ionfo to use in frame

 * @options: pointer to options info

 * @hdr: pointer mpa header

 * @pdata: pointer to private data

 * @flags:  indicates FIN or ACK

/**

 * irdma_form_uda_cm_frame - get a free packet and build frame full tcpip packet

 * @cm_node: connection's node ionfo to use in frame

 * @options: pointer to options info

 * @hdr: pointer mpa header

 * @pdata: pointer to private data

 * @flags:  indicates FIN or ACK

 5 * 4Byte words, IP headr len */

/**

 * irdma_send_reset - Send RST packet

 * @cm_node: connection's node

/**

 * irdma_active_open_err - send event for active side cm error

 * @cm_node: connection's node

 * @reset: Flag to send reset or not

/**

 * irdma_passive_open_err - handle passive side cm error

 * @cm_node: connection's node

 * @reset: send reset or just free cm_node

/**

 * irdma_event_connect_error - to create connect error event

 * @event: cm information for connect event

/**

 * irdma_process_options - process options from TCP header

 * @cm_node: connection's node

 * @optionsloc: point to start of options

 * @optionsize: size of all options

 * @syn_pkt: flag if syn packet

/**

 * irdma_handle_tcp_options - setup TCP context info after parsing TCP options

 * @cm_node: connection's node

 * @tcph: pointer tcp header

 * @optionsize: size of options rcvd

 * @passive: active or passive flag

/**

 * irdma_build_mpa_v1 - build a MPA V1 frame

 * @cm_node: connection's node

 * @start_addr: address where to build frame

 * @mpa_key: to do read0 or write0

/**

 * irdma_build_mpa_v2 - build a MPA V2 frame

 * @cm_node: connection's node

 * @start_addr: buffer start address

 * @mpa_key: to do read0 or write0

 initialize the upper 5 bytes of the frame */

 initialize RTR msg */

/**

 * irdma_cm_build_mpa_frame - build mpa frame for mpa version 1 or version 2

 * @cm_node: connection's node

 * @mpa: mpa: data buffer

 * @mpa_key: to do read0 or write0

/**

 * irdma_send_mpa_request - active node send mpa request to passive node

 * @cm_node: connection's node

/**

 * irdma_send_mpa_reject -

 * @cm_node: connection's node

 * @pdata: reject data for connection

 * @plen: length of reject data

/**

 * irdma_negotiate_mpa_v2_ird_ord - negotiate MPAv2 IRD/ORD

 * @cm_node: connection's node

 * @buf: Data pointer

 parse rtr message */

 responder */

 initiator */

 Remote peer doesn't support RDMA0_READ */

 no resources available */

 Not supported RDMA0 operation */

/**

 * irdma_parse_mpa - process an IETF MPA frame

 * @cm_node: connection's node

 * @buf: Data pointer

 * @type: to return accept or reject

 * @len: Len of mpa buffer

/**

 * irdma_schedule_cm_timer

 * @cm_node: connection's node

 * @sqbuf: buffer to send

 * @type: if it is send or close

 * @send_retrans: if rexmits to be done

 * @close_when_complete: is cm_node to be removed

 *

 * note - cm_node needs to be protected before calling this. Encase in:

 *		irdma_rem_ref_cm_node(cm_core, cm_node);

 *		irdma_schedule_cm_timer(...)

 *		refcount_inc(&cm_node->refcnt);

 type == IRDMA_TIMER_TYPE_SEND */

/**

 * irdma_retrans_expired - Could not rexmit the packet

 * @cm_node: connection's node

/**

 * irdma_handle_close_entry - for handling retry/timeouts

 * @cm_node: connection's node

 * @rem_node: flag for remove cm_node

 TIME_WAIT state */

/**

 * irdma_cm_timer_tick - system's timer expired callback

 * @t: Pointer to timer_list

/**

 * irdma_send_syn - send SYN packet

 * @cm_node: connection's node

 * @sendack: flag to set ACK bit or not

 Sending MSS option */

/**

 * irdma_send_ack - Send ACK packet

 * @cm_node: connection's node

/**

 * irdma_send_fin - Send FIN pkt

 * @cm_node: connection's node

/**

 * irdma_find_listener - find a cm node listening on this addr-port pair

 * @cm_core: cm's core

 * @dst_addr: listener ip addr

 * @dst_port: listener tcp port num

 * @vlan_id: virtual LAN ID

 * @listener_state: state to match with listen node's

 walk list and find cm_node associated with this session ID */

 compare node pair, return node handle if a match */

/**

 * irdma_del_multiple_qhash - Remove qhash and child listens

 * @iwdev: iWarp device

 * @cm_info: CM info for parent listen node

 * @cm_parent_listen_node: The parent listen node

/**

 * irdma_netdev_vlan_ipv6 - Gets the netdev and mac

 * @addr: local IPv6 address

 * @vlan_id: vlan id for the given IPv6 address

 * @mac: mac address for the given IPv6 address

 *

 * Returns the net_device of the IPv6 address and also sets the

 * vlan id and mac for that address.

 Match rdma_vlan_dev_vlan_id() */

/**

 * irdma_get_vlan_ipv4 - Returns the vlan_id for IPv4 address

 * @addr: local IPv4 address

/**

 * irdma_add_mqh_6 - Adds multiple qhashes for IPv6

 * @iwdev: iWarp device

 * @cm_info: CM info for parent listen node

 * @cm_parent_listen_node: The parent listen node

 *

 * Adds a qhash and a child listen node for every IPv6 address

 * on the adapter and adds the associated qhash filter

/**

 * irdma_add_mqh_4 - Adds multiple qhashes for IPv4

 * @iwdev: iWarp device

 * @cm_info: CM info for parent listen node

 * @cm_parent_listen_node: The parent listen node

 *

 * Adds a qhash and a child listen node for every IPv4 address

 * on the adapter and adds the associated qhash filter

/**

 * irdma_add_mqh - Adds multiple qhashes

 * @iwdev: iWarp device

 * @cm_info: CM info for parent listen node

 * @cm_listen_node: The parent listen node

/**

 * irdma_reset_list_prep - add connection nodes slated for reset to list

 * @cm_core: cm's core

 * @listener: pointer to listener node

 * @reset_list: a list to which cm_node will be selected

/**

 * irdma_dec_refcnt_listen - delete listener and associated cm nodes

 * @cm_core: cm's core

 * @listener: pointer to listener node

 * @free_hanging_nodes: to free associated cm_nodes

 * @apbvt_del: flag to delete the apbvt

 free non-accelerated child nodes for this listener */

/**

 * irdma_cm_del_listen - delete a listener

 * @cm_core: cm's core

 * @listener: passive connection's listener

 * @apbvt_del: flag to delete apbvt

/**

 * irdma_addr_resolve_neigh - resolve neighbor address

 * @iwdev: iwarp device structure

 * @src_ip: local ip address

 * @dst_ip: remote ip address

 * @arpindex: if there is an arp entry

/**

 * irdma_get_dst_ipv6 - get destination cache entry via ipv6 lookup

 * @src_addr: local ipv6 sock address

 * @dst_addr: destination ipv6 sock address

/**

 * irdma_addr_resolve_neigh_ipv6 - resolve neighbor ipv6 address

 * @iwdev: iwarp device structure

 * @src: local ip address

 * @dest: remote ip address

 * @arpindex: if there is an arp entry

/**

 * irdma_find_node - find a cm node that matches the reference cm node

 * @cm_core: cm's core

 * @rem_port: remote tcp port num

 * @rem_addr: remote ip addr

 * @loc_port: local tcp port num

 * @loc_addr: local ip addr

 * @vlan_id: local VLAN ID

 no owner node */

/**

 * irdma_add_hte_node - add a cm node to the hash table

 * @cm_core: cm's core

 * @cm_node: connection's node

/**

 * irdma_ipv4_is_lpb - check if loopback

 * @loc_addr: local addr to compare

 * @rem_addr: remote address

/**

 * irdma_ipv6_is_lpb - check if loopback

 * @loc_addr: local addr to compare

 * @rem_addr: remote address

/**

 * irdma_cm_create_ah - create a cm address handle

 * @cm_node: The connection manager node to create AH for

 * @wait: Provides option to wait for ah creation or not

/**

 * irdma_cm_free_ah - free a cm address handle

 * @cm_node: The connection manager node to create AH for

/**

 * irdma_make_cm_node - create a new instance of a cm node

 * @cm_core: cm's core

 * @iwdev: iwarp device structure

 * @cm_info: quad info for connection

 * @listener: passive connection's listener

 create an hte and cm_node for this instance */

 set our node specific transport info */

 associate our parent CM core */

 if the node is destroyed before connection was accelerated */

/**

 * irdma_rem_ref_cm_node - destroy an instance of a cm node

 * @cm_node: connection's node

 wait for all list walkers to exit their grace period */

/**

 * irdma_handle_fin_pkt - FIN packet received

 * @cm_node: connection's node

		/*

		 * Wait for ACK as this is simultaneous close.

		 * After we receive ACK, do not send anything.

		 * Just rm the node.

/**

 * irdma_handle_rst_pkt - process received RST packet

 * @cm_node: connection's node

 * @rbuf: receive buffer

 Drop down to MPA_V1*/

 send a syn and goto syn sent state */

/**

 * irdma_handle_rcv_mpa - Process a recv'd mpa buffer

 * @cm_node: connection's node

 * @rbuf: receive buffer

 ACK received MPA request */

/**

 * irdma_check_syn - Check for error on received syn ack

 * @cm_node: connection's node

 * @tcph: pointer tcp header

/**

 * irdma_check_seq - check seq numbers if OK

 * @cm_node: connection's node

 * @tcph: pointer tcp header

/**

 * irdma_handle_syn_pkt - is for Passive node

 * @cm_node: connection's node

 * @rbuf: receive buffer

 Rcvd syn on active open connection */

 Passive OPEN */

 drop pkt */

 drop pkt */

/**

 * irdma_handle_synack_pkt - Process SYN+ACK packet (active side)

 * @cm_node: connection's node

 * @rbuf: receive buffer

 active open */

 setup options */

 ACK  for the syn_ack */

/**

 * irdma_handle_ack_pkt - process packet with ACK

 * @cm_node: connection's node

 * @rbuf: receive buffer

/**

 * irdma_process_pkt - process cm packet

 * @cm_node: connection's node

 * @rbuf: receive buffer

/**

 * irdma_make_listen_node - create a listen node with params

 * @cm_core: cm's core

 * @iwdev: iwarp device structure

 * @cm_info: quad info for connection

 cannot have multiple matching listeners */

		/* create a CM listen node

		 * 1/2 node to compare incoming traffic to

/**

 * irdma_create_cm_node - make a connection node with params

 * @cm_core: cm's core

 * @iwdev: iwarp device structure

 * @conn_param: connection parameters

 * @cm_info: quad info for connection

 * @caller_cm_node: pointer to cm_node structure to return

 create a CM connection node */

 set our node side to client (active) side */

/**

 * irdma_cm_reject - reject and teardown a connection

 * @cm_node: connection's node

 * @pdata: ptr to private data for reject

 * @plen: size of private data

/**

 * irdma_cm_close - close of cm connection

 * @cm_node: connection's node

/**

 * irdma_receive_ilq - recv an ETHERNET packet, and process it

 * through CM

 * @vsi: VSI structure of dev

 * @rbuf: receive buffer

 if vlan, then maclen = 18 else 14 */

		/* Only type of packet accepted are for the

		 * PASSIVE open (syn only)

/**

 * irdma_setup_cm_core - setup top level instance of a cm core

 * @iwdev: iwarp device structure

 * @rdma_ver: HW version

 Handles CM event work items send to Iwarp core */

/**

 * irdma_cleanup_cm_core - deallocate a top level instance of a

 * cm core

 * @cm_core: cm's core

/**

 * irdma_init_tcp_ctx - setup qp context

 * @cm_node: connection's node

 * @tcp_info: offload info for tcp

 * @iwqp: associate qp for the connection

/**

 * irdma_cm_init_tsa_conn - setup qp for RTS

 * @iwqp: associate qp for the connection

 * @cm_node: connection's node

 once tcp_info is set, no need to do it again */

/**

 * irdma_cm_disconn - when a connection is being closed

 * @iwqp: associated qp for the connection

/**

 * irdma_qp_disconnect - free qp and close cm

 * @iwqp: associate qp for the connection

 close the CM node down if it is still active */

/**

 * irdma_cm_disconn_true - called by worker thread to disconnect qp

 * @iwqp: associate qp for the connection

 make sure we havent already closed this connection */

/**

 * irdma_disconnect_worker - worker for connection close

 * @work: points or disconn structure

/**

 * irdma_free_lsmm_rsrc - free lsmm memory and deregister

 * @iwqp: associate qp for the connection

/**

 * irdma_accept - registered call for connection to be accepted

 * @cm_id: cm information for passive connection

 * @conn_param: accpet parameters

 setup our first outgoing iWarp send WQE (the IETF frame response) */

/**

 * irdma_reject - registered call for connection to be rejected

 * @cm_id: cm information for passive connection

 * @pdata: private data to be sent

 * @pdata_len: private data length

/**

 * irdma_connect - registered call for connection to be established

 * @cm_id: cm information for passive connection

 * @conn_param: Information about the connection

 set up the connection params for the node */

/**

 * irdma_create_listen - registered call creating listener

 * @cm_id: cm information for passive connection

 * @backlog: to max accept pending count

/**

 * irdma_destroy_listen - registered call to destroy listener

 * @cm_id: cm information for passive connection

/**

 * irdma_teardown_list_prep - add conn nodes slated for tear down to list

 * @cm_core: cm's core

 * @teardown_list: a list to which cm_node will be selected

 * @ipaddr: pointer to ip address

 * @nfo: pointer to cm_info structure instance

 * @disconnect_all: flag indicating disconnect all QPs

/**

 * irdma_cm_event_connected - handle connected active node

 * @event: the info for cm_node of connection

/**

 * irdma_cm_event_reset - handle reset

 * @event: the info for cm_node of connection

/**

 * irdma_cm_event_handler - send event to cm upper layer

 * @work: pointer of cm event info.

/**

 * irdma_cm_post_event - queue event request for worker thread

 * @event: cm node's info for up event call

/**

 * irdma_cm_teardown_connections - teardown QPs

 * @iwdev: device pointer

 * @ipaddr: Pointer to IPv4 or IPv6 address

 * @nfo: Connection info

 * @disconnect_all: flag indicating disconnect all QPs

 *

 * teardown QPs where source or destination addr matches ip addr

/**

 * irdma_qhash_ctrl - enable/disable qhash for list

 * @iwdev: device pointer

 * @parent_listen_node: parent listen node

 * @nfo: cm info node

 * @ipaddr: Pointer to IPv4 or IPv6 address

 * @ipv4: flag indicating IPv4 when true

 * @ifup: flag indicating interface up when true

 *

 * Enables or disables the qhash for the node in the child

 * listen list that matches ipaddr. If no matching IP was found

 * it will allocate and add a new child listen node to the

 * parent listen node. The listen_list_lock is assumed to be

 * held when called.

 if not found then add a child listener if interface is going up */

/**

 * irdma_if_notify - process an ifdown on an interface

 * @iwdev: device pointer

 * @netdev: network device structure

 * @ipaddr: Pointer to IPv4 or IPv6 address

 * @ipv4: flag indicating IPv4 when true

 * @ifup: flag indicating interface up when true

 Disable or enable qhash for listeners */

 disconnect any connected qp's on ifdown */

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_puda_get_listbuf - get buffer from puda list

 * @list: list to use for buffers (ILQ or IEQ)

/**

 * irdma_puda_get_bufpool - return buffer from resource

 * @rsrc: resource to use for buffer

/**

 * irdma_puda_ret_bufpool - return buffer to rsrc list

 * @rsrc: resource to use for buffer

 * @buf: buffer to return to resource

/**

 * irdma_puda_post_recvbuf - set wqe for rcv buffer

 * @rsrc: resource ptr

 * @wqe_idx: wqe index to use

 * @buf: puda buffer for rcv q

 * @initial: flag if during init time

 Synch buffer for use by device */

 make sure WQE is written before valid bit is set */

/**

 * irdma_puda_replenish_rq - post rcv buffers

 * @rsrc: resource to use for buffer

 * @initial: flag if during init time

/**

 * irdma_puda_alloc_buf - allocate mem for buffer

 * @dev: iwarp device

 * @len: length of buffer

/**

 * irdma_puda_dele_buf - delete buffer back to system

 * @dev: iwarp device

 * @buf: buffer to free

/**

 * irdma_puda_get_next_send_wqe - return next wqe for processing

 * @qp: puda qp for wqe

 * @wqe_idx: wqe index for caller

/**

 * irdma_puda_poll_info - poll cq for completion

 * @cq: cq for poll

 * @info: info return for successful completion

 update cq tail in cq shadow memory also */

/**

 * irdma_puda_poll_cmpl - processes completion for cq

 * @dev: iwarp device

 * @cq: cq getting interrupt

 * @compl_err: return any completion err

 reusing so synch the buffer for CPU use */

 Get all the tcpip information in the buf header */

 reusing so synch the buffer for CPU use */

 update cq tail in cq shadow memory also */

/**

 * irdma_puda_send - complete send wqe for transmit

 * @qp: puda qp for send

 * @info: buffer information for transmit

 number of 32 bits DWORDS in header */

 Third line of WQE descriptor */

 maclen is in words */

 Dest_QPN and Dest_QKey only for UD */

 Forth line of WQE descriptor */

 Forth line of WQE descriptor */

 make sure WQE is written before valid bit is set */

/**

 * irdma_puda_send_buf - transmit puda buffer

 * @rsrc: resource to use for buffer

 * @buf: puda buffer to transmit

	/* if no wqe available or not from a completion and we have

	 * pending buffers, we must queue new buffer

	/* if we are coming from a completion and have pending buffers

	 * then Get one from pending list

 Synch buffer for use by device */

/**

 * irdma_puda_qp_setctx - during init, set qp's context

 * @rsrc: qp's resource

/**

 * irdma_puda_qp_wqe - setup wqe for qp create

 * @dev: Device

 * @qp: Resource qp

 make sure WQE is written before valid bit is set */

/**

 * irdma_puda_qp_create - create qp for resource

 * @rsrc: resource to use for buffer

/**

 * irdma_puda_cq_wqe - setup wqe for CQ create

 * @dev: Device

 * @cq: resource for cq

 make sure WQE is written before valid bit is set */

/**

 * irdma_puda_cq_create - create cq for resource

 * @rsrc: resource for which cq to create

/**

 * irdma_puda_free_qp - free qp for resource

 * @rsrc: resource for which qp to free

/**

 * irdma_puda_free_cq - free cq for resource

 * @rsrc: resource for which cq to free

/**

 * irdma_puda_dele_rsrc - delete all resources during close

 * @vsi: VSI structure of device

 * @type: type of resource to dele

 * @reset: true if reset chip

 Free all allocated puda buffers for both tx and rx */

/**

 * irdma_puda_allocbufs - allocate buffers for resource

 * @rsrc: resource for buffer allocation

 * @count: number of buffers to create

/**

 * irdma_puda_create_rsrc - create resource (ilq or ieq)

 * @vsi: sc VSI struct

 * @info: resource information

 Initialize all ieq lists */

/**

 * irdma_ilq_putback_rcvbuf - ilq buffer to put back on rq

 * @qp: ilq's qp resource

 * @buf: puda buffer for rcv q

 * @wqe_idx:  wqe index of completed rcvbuf

 Synch buffer for use by device */

 make sure WQE is written before valid bit is set */

/**

 * irdma_ieq_get_fpdu_len - get length of fpdu with or without marker

 * @pfpdu: pointer to fpdu

 * @datap: pointer to data in the buffer

 * @rcv_seq: seqnum of the data buffer

/**

 * irdma_ieq_copy_to_txbuf - copydata from rcv buf to tx buf

 * @buf: rcv buffer with partial

 * @txbuf: tx buffer for sending back

 * @buf_offset: rcv buffer offset to copy from

 * @txbuf_offset: at offset in tx buf to copy

 * @len: length of data to copy

/**

 * irdma_ieq_setup_tx_buf - setup tx buffer for partial handling

 * @buf: reeive buffer with partial

 * @txbuf: buffer to prepare

/**

 * irdma_ieq_check_first_buf - check if rcv buffer's seq is in range

 * @buf: receive exception buffer

 * @fps: first partial sequence number

/**

 * irdma_ieq_compl_pfpdu - write txbuf with full fpdu

 * @ieq: ieq resource

 * @rxlist: ieq's received buffer list

 * @pbufl: temporary list for buffers for fpddu

 * @txbuf: tx buffer for fpdu

 * @fpdu_len: total length of fpdu

 copied full fpdu */

 copy partial fpdu */

 last buffer on the list*/

/**

 * irdma_ieq_create_pbufl - create buffer list for single fpdu

 * @pfpdu: pointer to fpdu

 * @rxlist: resource list for receive ieq buffes

 * @pbufl: temp. list for buffers for fpddu

 * @buf: first receive buffer

 * @fpdu_len: total length of fpdu

/**

 * irdma_ieq_handle_partial - process partial fpdu buffer

 * @ieq: ieq resource

 * @pfpdu: partial management per user qp

 * @buf: receive buffer

 * @fpdu_len: fpdu len in the buffer

 partial buffer list */

/**

 * irdma_ieq_process_buf - process buffer rcvd for ieq

 * @ieq: ieq resource

 * @pfpdu: partial management per user qp

 * @buf: receive buffer

 copy full pdu's in the txbuf and send them out */

 modify txbuf's buffer header */

 copy full fpdu's to new buffer */

/**

 * irdma_ieq_process_fpdus - process fpdu's buffers on its list

 * @qp: qp for which partial fpdus

 * @ieq: ieq resource

 This could be out of order or missing packet */

 keep processing buffers from the head of the list */

 create CQP for AE */

/**

 * irdma_ieq_create_ah - create an address handle for IEQ

 * @qp: qp pointer

 * @buf: buf received on IEQ used to create AH

/**

 * irdma_ieq_handle_exception - handle qp's exception

 * @ieq: ieq resource

 * @qp: qp receiving excpetion

 * @buf: receive buffer

 first partial seq # in q2 */

 clean up qp as it is new partial sequence */

 First_Partial_Sequence_Number check */

 throw away out-of-order, duplicates*/

 Insert buf before head */

/**

 * irdma_ieq_receive - received exception buffer

 * @vsi: VSI of device

 * @buf: exception buffer received

	/*

	 * ieq->rx_wqe_idx is used by irdma_puda_replenish_rq()

	 * on which wqe_idx to start replenish rq

/**

 * irdma_ieq_tx_compl - put back after sending completed exception buffer

 * @vsi: sc VSI struct

 * @sqwrid: pointer to puda buffer

/**

 * irdma_ieq_cleanup_qp - qp is being destroyed

 * @ieq: ieq resource

 * @qp: all pending fpdu buffers

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2017 - 2021 Intel Corporation */

/**

 * irdma_alloc_node - Allocate a WS node and init

 * @vsi: vsi pointer

 * @user_pri: user priority

 * @node_type: Type of node, leaf or parent

 * @parent: parent node pointer

/**

 * irdma_free_node - Free a WS node

 * @vsi: VSI stricture of device

 * @node: Pointer to node to free

/**

 * irdma_ws_cqp_cmd - Post CQP work scheduler node cmd

 * @vsi: vsi pointer

 * @node: pointer to node

 * @cmd: add, remove or modify

/**

 * ws_find_node - Find SC WS node based on VSI id or TC

 * @parent: parent node of First VSI or TC node

 * @match_val: value to match

 * @type: match type VSI/TC

/**

 * irdma_tc_in_use - Checks to see if a leaf node is in use

 * @vsi: vsi pointer

 * @user_pri: user priority

	/* Check if the traffic class associated with the given user priority

	 * is in use by any other user priority. If so, nothing left to do

/**

 * irdma_remove_leaf - Remove leaf node unconditionally

 * @vsi: vsi pointer

 * @user_pri: user priority

 Check if VSI node can be freed */

 Free head node there are no remaining VSI nodes */

/**

 * irdma_ws_add - Build work scheduler tree, set RDMA qs_handle

 * @vsi: vsi pointer

 * @user_pri: user priority

 Find a second tier node that matches the VSI */

 If VSI node doesn't exist, add one */

 Add leaf node */

		/*

		 * callback to LAN to update the LAN tree with our node

	/*

	 * Iterate through other UPs and update the QS handle if they have

	 * a matching traffic class.

 Free head node there are no remaining VSI nodes */

/**

 * irdma_ws_remove - Free WS scheduler node, update WS tree

 * @vsi: vsi pointer

 * @user_pri: user priority

/**

 * irdma_ws_reset - Reset entire WS tree

 * @vsi: vsi pointer

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2017 - 2021 Intel Corporation */

/**

 * icrdma_ena_irq - Enable interrupt

 * @dev: pointer to the device structure

 * @idx: vector index

 2 usec units */

/**

 * icrdma_disable_irq - Disable interrupt

 * @dev: pointer to the device structure

 * @idx: vector index

/**

 * icrdma_cfg_ceq- Configure CEQ interrupt

 * @dev: pointer to the device structure

 * @ceq_id: Completion Event Queue ID

 * @idx: vector index

 * @enable: True to enable, False disables

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_set_fragment - set fragment in wqe

 * @wqe: wqe for setting fragment

 * @offset: offset value

 * @sge: sge length and stag

 * @valid: The wqe valid

/**

 * irdma_set_fragment_gen_1 - set fragment in wqe

 * @wqe: wqe for setting fragment

 * @offset: offset value

 * @sge: sge length and stag

 * @valid: wqe valid flag

/**

 * irdma_nop_1 - insert a NOP wqe

 * @qp: hw qp ptr

 make sure WQE is written before valid bit is set */

/**

 * irdma_clr_wqes - clear next 128 sq entries

 * @qp: hw qp ptr

 * @qp_wqe_idx: wqe_idx

/**

 * irdma_uk_qp_post_wr - ring doorbell

 * @qp: hw qp ptr

 valid bit is written and loads completed before reading shadow */

 read the doorbell shadow area */

/**

 * irdma_qp_ring_push_db -  ring qp doorbell

 * @qp: hw qp ptr

 * @wqe_idx: wqe index

/**

 * irdma_qp_get_next_send_wqe - pad with NOP if needed, return where next WR should go

 * @qp: hw qp ptr

 * @wqe_idx: return wqe index

 * @quanta: size of WR in quanta

 * @total_size: size of WR in bytes

 * @info: info on WR

 WR fits in current chunk */

 Need to pad with NOP */

/**

 * irdma_qp_get_next_recv_wqe - get next qp's rcv wqe

 * @qp: hw qp ptr

 * @wqe_idx: return wqe index

 rq_wqe_size_multiplier is no of 32 byte quanta in one rq wqe */

/**

 * irdma_uk_rdma_write - rdma write operation

 * @qp: hw qp ptr

 * @info: post sq information

 * @post_sq: flag to post sq

 if not an odd number set valid bit in next fragment */

 make sure WQE is populated before valid bit is set */

/**

 * irdma_uk_rdma_read - rdma read command

 * @qp: hw qp ptr

 * @info: post sq information

 * @inv_stag: flag for inv_stag

 * @post_sq: flag to post sq

 if not an odd number set valid bit in next fragment */

 make sure WQE is populated before valid bit is set */

/**

 * irdma_uk_send - rdma send command

 * @qp: hw qp ptr

 * @info: post sq information

 * @post_sq: flag to post sq

 if not an odd number set valid bit in next fragment */

 make sure WQE is populated before valid bit is set */

/**

 * irdma_set_mw_bind_wqe_gen_1 - set mw bind wqe

 * @wqe: wqe for setting fragment

 * @op_info: info for setting bind wqe values

/**

 * irdma_copy_inline_data_gen_1 - Copy inline data to wqe

 * @dest: pointer to wqe

 * @src: pointer to inline data

 * @len: length of inline data to copy

 * @polarity: compatibility parameter

/**

 * irdma_inline_data_size_to_quanta_gen_1 - based on inline data, quanta

 * @data_size: data size for inline

 *

 * Gets the quanta based on inline and immediate data.

/**

 * irdma_set_mw_bind_wqe - set mw bind in wqe

 * @wqe: wqe for setting mw bind

 * @op_info: info for setting wqe values

/**

 * irdma_copy_inline_data - Copy inline data to wqe

 * @dest: pointer to wqe

 * @src: pointer to inline data

 * @len: length of inline data to copy

 * @polarity: polarity of wqe valid bit

 point to additional 32 byte quanta */

/**

 * irdma_inline_data_size_to_quanta - based on inline data, quanta

 * @data_size: data size for inline

 *

 * Gets the quanta based on inline and immediate data.

/**

 * irdma_uk_inline_rdma_write - inline rdma write operation

 * @qp: hw qp ptr

 * @info: post sq information

 * @post_sq: flag to post sq

 make sure WQE is populated before valid bit is set */

/**

 * irdma_uk_inline_send - inline send operation

 * @qp: hw qp ptr

 * @info: post sq information

 * @post_sq: flag to post sq

 make sure WQE is populated before valid bit is set */

/**

 * irdma_uk_stag_local_invalidate - stag invalidate operation

 * @qp: hw qp ptr

 * @info: post sq information

 * @post_sq: flag to post sq

 make sure WQE is populated before valid bit is set */

/**

 * irdma_uk_post_receive - post receive wqe

 * @qp: hw qp ptr

 * @info: post rq information

 if not an odd number set valid bit in next fragment */

 make sure WQE is populated before valid bit is set */

/**

 * irdma_uk_cq_resize - reset the cq buffer info

 * @cq: cq to resize

 * @cq_base: new cq buffer addr

 * @cq_size: number of cqes

/**

 * irdma_uk_cq_set_resized_cnt - record the count of the resized buffers

 * @cq: cq to resize

 * @cq_cnt: the count of the resized cq buffers

/**

 * irdma_uk_cq_request_notification - cq notification request (door bell)

 * @cq: hw cq

 * @cq_notify: notification type

 make sure WQE is populated before valid bit is set */

/**

 * irdma_uk_cq_poll_cmpl - get cq completion info

 * @cq: hw cq

 * @info: cq poll information returned

 Ensure CQE contents are read after valid bit is checked */

 Ensure ext CQE contents are read after ext valid bit is checked */

 Set the min error to standard flush error code for remaining cqes */

 q_type is IRDMA_CQE_QTYPE_SQ */

cease posting push mode on push drop*/

/**

 * irdma_qp_round_up - return round up qp wq depth

 * @wqdepth: wq depth in quanta to round up

/**

 * irdma_get_wqe_shift - get shift count for maximum wqe size

 * @uk_attrs: qp HW attributes

 * @sge: Maximum Scatter Gather Elements wqe

 * @inline_data: Maximum inline data size

 * @shift: Returns the shift needed based on sge

 *

 * Shift can be used to left shift the wqe size based on number of SGEs and inlind data size.

 * For 1 SGE or inline data <= 8, shift = 0 (wqe size of 32

 * bytes). For 2 or 3 SGEs or inline data <= 39, shift = 1 (wqe

 * size of 64 bytes).

 * For 4-7 SGE's and inline <= 101 Shift of 2 otherwise (wqe

 * size of 256 bytes).

/*

 * irdma_get_sqdepth - get SQ depth (quanta)

 * @uk_attrs: qp HW attributes

 * @sq_size: SQ size

 * @shift: shift which determines size of WQE

 * @sqdepth: depth of SQ

 *

/*

 * irdma_get_rqdepth - get RQ depth (quanta)

 * @uk_attrs: qp HW attributes

 * @rq_size: RQ size

 * @shift: shift which determines size of WQE

 * @rqdepth: depth of RQ

/**

 * irdma_setup_connection_wqes - setup WQEs necessary to complete

 * connection.

 * @qp: hw qp (user and kernel)

 * @info: qp initialization info

/**

 * irdma_uk_qp_init - initialize shared qp

 * @qp: hw qp (user and kernel)

 * @info: qp initialization info

 *

 * initializes the vars used in both user and kernel mode.

 * size of the wqe depends on numbers of max. fragements

 * allowed. Then size of wqe * the number of wqes should be the

 * amount of memory allocated for sq and rq.

/**

 * irdma_uk_cq_init - initialize shared cq (user and kernel)

 * @cq: hw cq

 * @info: hw cq initialization info

/**

 * irdma_uk_clean_cq - clean cq entries

 * @q: completion context

 * @cq: cq to clean

/**

 * irdma_nop - post a nop

 * @qp: hw qp ptr

 * @wr_id: work request id

 * @signaled: signaled for completion

 * @post_sq: ring doorbell

 make sure WQE is populated before valid bit is set */

/**

 * irdma_fragcnt_to_quanta_sq - calculate quanta based on fragment count for SQ

 * @frag_cnt: number of fragments

 * @quanta: quanta for frag_cnt

 when immediate data is present */

/**

 * irdma_fragcnt_to_wqesize_rq - calculate wqe size based on fragment count for RQ

 * @frag_cnt: number of fragments

 * @wqe_size: size in bytes given frag_cnt

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2016 - 2021 Intel Corporation */

/**

 * irdma_sc_access_ah() - Create, modify or delete AH

 * @cqp: struct for cqp hw

 * @info: ah information

 * @op: Operation

 * @scratch: u64 saved to be used during cqp completion

 need write block before writing WQE header */

/**

 * irdma_create_mg_ctx() - create a mcg context

 * @info: multicast group context info

 index in the array */

 index in the MG context */

/**

 * irdma_access_mcast_grp() - Access mcast group based on op

 * @cqp: Control QP

 * @info: multicast group context info

 * @op: operation to perform

 * @scratch: u64 saved to be used during cqp completion

 need write memory block before writing the WQE header. */

/**

 * irdma_compare_mgs - Compares two multicast group structures

 * @entry1: Multcast group info

 * @entry2: Multcast group info in context

/**

 * irdma_sc_add_mcast_grp - Allocates mcast group entry in ctx

 * @ctx: Multcast group context

 * @mg: Multcast group info

 find either an identical or a free entry for a multicast group */

/**

 * irdma_sc_del_mcast_grp - Delete mcast group

 * @ctx: Multcast group context

 * @mg: Multcast group info

 *

 * Finds and removes a specific mulicast group from context, all

 * parameters must match to remove a multicast group.

 find an entry in multicast group context */

 Remove gap if element was not the last */

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_arp_table -manage arp table

 * @rf: RDMA PCI function

 * @ip_addr: ip address for device

 * @ipv4: IPv4 flag

 * @mac_addr: mac address ptr

 * @action: modify, delete or add

/**

 * irdma_add_arp - add a new arp entry if needed

 * @rf: RDMA function

 * @ip: IP address

 * @ipv4: IPv4 flag

 * @mac: MAC address

/**

 * wr32 - write 32 bits to hw register

 * @hw: hardware information including registers

 * @reg: register offset

 * @val: value to write to register

/**

 * rd32 - read a 32 bit hw register

 * @hw: hardware information including registers

 * @reg: register offset

 *

 * Return value of register content

/**

 * rd64 - read a 64 bit hw register

 * @hw: hardware information including registers

 * @reg: register offset

 *

 * Return value of register content

/**

 * irdma_inetaddr_event - system notifier for ipv4 addr events

 * @notifier: not used

 * @event: event for notifier

 * @ptr: if address

/**

 * irdma_inet6addr_event - system notifier for ipv6 addr events

 * @notifier: not used

 * @event: event for notifier

 * @ptr: if address

/**

 * irdma_net_event - system notifier for net events

 * @notifier: not used

 * @event: event for notifier

 * @ptr: neighbor

/**

 * irdma_netdevice_event - system notifier for netdev events

 * @notifier: not used

 * @event: event for notifier

 * @ptr: netdev

/**

 * irdma_add_ipv6_addr - add ipv6 address to the hw arp table

 * @iwdev: irdma device

/**

 * irdma_add_ipv4_addr - add ipv4 address to the hw arp table

 * @iwdev: irdma device

/**

 * irdma_add_ip - add ip addresses

 * @iwdev: irdma device

 *

 * Add ipv4/ipv6 addresses to the arp cache

/**

 * irdma_alloc_and_get_cqp_request - get cqp struct

 * @cqp: device cqp ptr

 * @wait: cqp to be used in wait mode

/**

 * irdma_get_cqp_request - increase refcount for cqp_request

 * @cqp_request: pointer to cqp_request instance

/**

 * irdma_free_cqp_request - free cqp request

 * @cqp: cqp ptr

 * @cqp_request: to be put back in cqp list

/**

 * irdma_put_cqp_request - dec ref count and free if 0

 * @cqp: cqp ptr

 * @cqp_request: to be put back in cqp list

/**

 * irdma_free_pending_cqp_request -free pending cqp request objs

 * @cqp: cqp ptr

 * @cqp_request: to be put back in cqp list

/**

 * irdma_cleanup_pending_cqp_op - clean-up cqp with no

 * completions

 * @rf: RDMA PCI function

/**

 * irdma_wait_event - wait for completion

 * @rf: RDMA PCI function

 * @cqp_request: cqp request to wait

/**

 * irdma_cqp_crit_err - check if CQP error is critical

 * @dev: pointer to dev structure

 * @cqp_cmd: code for last CQP operation

 * @maj_err_code: major error code

 * @min_err_code: minot error code

/**

 * irdma_handle_cqp_op - process cqp command

 * @rf: RDMA PCI function

 * @cqp_request: cqp request to process

/**

 * irdma_get_qp - get qp address

 * @device: iwarp device

 * @qpn: qp number

/**

 * irdma_remove_cqp_head - return head entry and remove

 * @dev: device

/**

 * irdma_cqp_sds_cmd - create cqp command for sd

 * @dev: hardware control device structure

 * @sdinfo: information for sd cqp

 *

/**

 * irdma_cqp_qp_suspend_resume - cqp command for suspend/resume

 * @qp: hardware control qp

 * @op: suspend or resume

/**

 * irdma_term_modify_qp - modify qp for term message

 * @qp: hardware control qp

 * @next_state: qp's next state

 * @term: terminate code

 * @term_len: length

/**

 * irdma_terminate_done - after terminate is completed

 * @qp: hardware control qp

 * @timeout_occurred: indicates if terminate timer expired

/**

 * irdma_terminate_start_timer - start terminate timeout

 * @qp: hardware control qp

/**

 * irdma_terminate_del_timer - delete terminate timeout

 * @qp: hardware control qp

/**

 * irdma_cqp_query_fpm_val_cmd - send cqp command for fpm

 * @dev: function device struct

 * @val_mem: buffer for fpm

 * @hmc_fn_id: function id for fpm

/**

 * irdma_cqp_commit_fpm_val_cmd - commit fpm values in hw

 * @dev: hardware control device structure

 * @val_mem: buffer with fpm values

 * @hmc_fn_id: function id for fpm

/**

 * irdma_cqp_cq_create_cmd - create a cq for the cqp

 * @dev: device pointer

 * @cq: pointer to created cq

/**

 * irdma_cqp_qp_create_cmd - create a qp for the cqp

 * @dev: device pointer

 * @qp: pointer to created qp

/**

 * irdma_dealloc_push_page - free a push page for qp

 * @rf: RDMA PCI function

 * @qp: hardware control qp

/**

 * irdma_free_qp_rsrc - free up memory resources for qp

 * @iwqp: qp ptr (user or kernel)

/**

 * irdma_cq_wq_destroy - send cq destroy cqp

 * @rf: RDMA PCI function

 * @cq: hardware control cq

/**

 * irdma_hw_modify_qp_callback - handle state for modifyQPs that don't wait

 * @cqp_request: modify QP completion

/**

 * irdma_hw_modify_qp - setup cqp for modify qp

 * @iwdev: RDMA device

 * @iwqp: qp ptr (user or kernel)

 * @info: info for modify qp

 * @wait: flag to wait or not for modify qp completion

/**

 * irdma_cqp_cq_destroy_cmd - destroy the cqp cq

 * @dev: device pointer

 * @cq: pointer to cq

/**

 * irdma_cqp_qp_destroy_cmd - destroy the cqp

 * @dev: device pointer

 * @qp: pointer to qp

/**

 * irdma_ieq_mpa_crc_ae - generate AE for crc error

 * @dev: hardware control device structure

 * @qp: hardware control qp

/**

 * irdma_init_hash_desc - initialize hash for crc calculation

 * @desc: cryption type

/**

 * irdma_free_hash_desc - free hash desc

 * @desc: to be freed

/**

 * irdma_ieq_check_mpacrc - check if mpa crc is OK

 * @desc: desc for hash

 * @addr: address of buffer for crc

 * @len: length of buffer

 * @val: value to be compared

/**

 * irdma_ieq_get_qp - get qp based on quad in puda buffer

 * @dev: hardware control device structure

 * @buf: receive puda buffer on exception q

/**

 * irdma_send_ieq_ack - ACKs for duplicate or OOO partials FPDUs

 * @qp: qp ptr

/**

 * irdma_puda_ieq_get_ah_info - get AH info from IEQ buffer

 * @qp: qp pointer

 * @ah_info: AH info pointer

/**

 * irdma_gen1_ieq_update_tcpip_info - update tcpip in the buffer

 * @buf: puda to update

 * @len: length of buffer

 * @seqnum: seq number for tcp

/**

 * irdma_ieq_update_tcpip_info - update tcpip in the buffer

 * @buf: puda to update

 * @len: length of buffer

 * @seqnum: seq number for tcp

/**

 * irdma_gen1_puda_get_tcpip_info - get tcpip info from puda

 * buffer

 * @info: to get information

 * @buf: puda buffer

/**

 * irdma_puda_get_tcpip_info - get tcpip info from puda buffer

 * @info: to get information

 * @buf: puda buffer

/**

 * irdma_hw_stats_timeout - Stats timer-handler which updates all HW stats

 * @t: timer_list pointer

/**

 * irdma_hw_stats_start_timer - Start periodic stats timer

 * @vsi: vsi structure pointer

/**

 * irdma_hw_stats_stop_timer - Delete periodic stats timer

 * @vsi: pointer to vsi structure

/**

 * irdma_process_stats - Checking for wrap and update stats

 * @pestat: stats structure pointer

/**

 * irdma_cqp_gather_stats_gen1 - Gather stats

 * @dev: pointer to device structure

 * @pestat: statistics structure

/**

 * irdma_process_cqp_stats - Checking for wrap and update stats

 * @cqp_request: cqp_request structure pointer

/**

 * irdma_cqp_gather_stats_cmd - Gather stats

 * @dev: pointer to device structure

 * @pestat: pointer to stats info

 * @wait: flag to wait or not wait for stats

/**

 * irdma_cqp_stats_inst_cmd - Allocate/free stats instance

 * @vsi: pointer to vsi structure

 * @cmd: command to allocate or free

 * @stats_info: pointer to allocate stats info

/**

 * irdma_cqp_ceq_cmd - Create/Destroy CEQ's after CEQ 0

 * @dev: pointer to device info

 * @sc_ceq: pointer to ceq structure

 * @op: Create or Destroy

/**

 * irdma_cqp_aeq_cmd - Create/Destroy AEQ

 * @dev: pointer to device info

 * @sc_aeq: pointer to aeq structure

 * @op: Create or Destroy

/**

 * irdma_cqp_ws_node_cmd - Add/modify/delete ws node

 * @dev: pointer to device structure

 * @cmd: Add, modify or delete

 * @node_info: pointer to ws node info

/**

 * irdma_ah_cqp_op - perform an AH cqp operation

 * @rf: RDMA PCI function

 * @sc_ah: address handle

 * @cmd: AH operation

 * @wait: wait if true

 * @callback_fcn: Callback function on CQP op completion

 * @cb_param: parameter for callback function

 *

 * returns errno

/**

 * irdma_ieq_ah_cb - callback after creation of AH for IEQ

 * @cqp_request: pointer to cqp_request of create AH

/**

 * irdma_ilq_ah_cb - callback after creation of AH for ILQ

 * @cqp_request: pointer to cqp_request of create AH

/**

 * irdma_puda_create_ah - create AH for ILQ/IEQ qp's

 * @dev: device pointer

 * @ah_info: Address handle info

 * @wait: When true will wait for operation to complete

 * @type: ILQ/IEQ

 * @cb_param: Callback param when not waiting

 * @ah_ret: Returned pointer to address handle if created

 *

/**

 * irdma_puda_free_ah - free a puda address handle

 * @dev: device pointer

 * @ah: The address handle to free

/**

 * irdma_gsi_ud_qp_ah_cb - callback after creation of AH for GSI/ID QP

 * @cqp_request: pointer to cqp_request of create AH

/**

 * irdma_prm_add_pble_mem - add moemory to pble resources

 * @pprm: pble resource manager

 * @pchunk: chunk of memory to add

 each pble is 8 bytes hence shift by 3 */

/**

 * irdma_prm_get_pbles - get pble's from prm

 * @pprm: pble resource manager

 * @chunkinfo: nformation about chunk where pble's were acquired

 * @mem_size: size of pble memory needed

 * @vaddr: returns virtual address of pble memory

 * @fpm_addr: returns fpm address of pble memory

 list.next used macro */

 3 is sizeof pble divide */

/**

 * irdma_prm_return_pbles - return pbles back to prm

 * @pprm: pble resource manager

 * @chunkinfo: chunk where pble's were acquired and to be freed

/**

 * irdma_pble_free_paged_mem - free virtual paged memory

 * @chunk: chunk to free with paged memory

/**

 * irdma_pble_get_paged_mem -allocate paged memory for pbles

 * @chunk: chunk to add for paged memory

 * @pg_cnt: number of pages needed

/**

 * irdma_alloc_ws_node_id - Allocate a tx scheduler node ID

 * @dev: device pointer

/**

 * irdma_free_ws_node_id - Free a tx scheduler node ID

 * @dev: device pointer

 * @node_id: Work scheduler node ID

/**

 * irdma_modify_qp_to_err - Modify a QP to error

 * @sc_qp: qp structure

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_get_qp_from_list - get next qp from a list

 * @head: Listhead of qp's

 * @qp: current qp

/**

 * irdma_sc_suspend_resume_qps - suspend/resume all qp's on VSI

 * @vsi: the VSI struct pointer

 * @op: Set to IRDMA_OP_RESUME or IRDMA_OP_SUSPEND

 issue cqp suspend command */

/**

 * irdma_change_l2params - given the new l2 parameters, change all qp

 * @vsi: RDMA VSI pointer

 * @l2params: New parameters from l2

/**

 * irdma_qp_rem_qos - remove qp from qos lists during destroy qp

 * @qp: qp to be removed from qos

/**

 * irdma_qp_add_qos - called during setctx for qp to be added to qos

 * @qp: qp to be added to qos

/**

 * irdma_sc_pd_init - initialize sc pd struct

 * @dev: sc device struct

 * @pd: sc pd ptr

 * @pd_id: pd_id for allocated pd

 * @abi_ver: User/Kernel ABI version

/**

 * irdma_sc_add_arp_cache_entry - cqp wqe add arp cache entry

 * @cqp: struct for cqp hw

 * @info: arp entry information

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_del_arp_cache_entry - dele arp cache entry

 * @cqp: struct for cqp hw

 * @scratch: u64 saved to be used during cqp completion

 * @arp_index: arp index to delete arp entry

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_manage_apbvt_entry - for adding and deleting apbvt entries

 * @cqp: struct for cqp hw

 * @info: info for apbvt entry to add or delete

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_manage_qhash_table_entry - manage quad hash entries

 * @cqp: struct for cqp hw

 * @info: info for quad hash to manage

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 *

 * This is called before connection establishment is started.

 * For passive connections, when listener is created, it will

 * call with entry type of  IRDMA_QHASH_TYPE_TCP_SYN with local

 * ip address and tcp port. When SYN is received (passive

 * connections) or sent (active connections), this routine is

 * called with entry type of IRDMA_QHASH_TYPE_TCP_ESTABLISHED

 * and quad is passed in info.

 *

 * When iwarp connection is done and its state moves to RTS, the

 * quad hash entry in the hardware will point to iwarp's qp

 * number and requires no calls from the driver.

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_qp_init - initialize qp

 * @qp: sc qp

 * @info: initialization qp info

/**

 * irdma_sc_qp_create - create qp

 * @qp: sc qp

 * @info: qp create info

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_qp_modify - modify qp cqp wqe

 * @qp: sc qp

 * @info: modify qp info

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_qp_destroy - cqp destroy qp

 * @qp: sc qp

 * @scratch: u64 saved to be used during cqp completion

 * @remove_hash_idx: flag if to remove hash idx

 * @ignore_mw_bnd: memory window bind flag

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_get_encoded_ird_size -

 * @ird_size: IRD size

 * The ird from the connection is rounded to a supported HW setting and then encoded

 * for ird_size field of qp_ctx. Consumers are expected to provide valid ird size based

 * on hardware attributes. IRD size defaults to a value of 4 in case of invalid input

/**

 * irdma_sc_qp_setctx_roce - set qp's context

 * @qp: sc qp

 * @qp_ctx: context ptr

 * @info: ctx info

/* irdma_sc_alloc_local_mac_entry - allocate a mac entry

 * @cqp: struct for cqp hw

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_add_local_mac_entry - add mac enry

 * @cqp: struct for cqp hw

 * @info:mac addr info

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_del_local_mac_entry - cqp wqe to dele local mac

 * @cqp: struct for cqp hw

 * @scratch: u64 saved to be used during cqp completion

 * @entry_idx: index of mac entry

 * @ignore_ref_count: to force mac adde delete

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_qp_setctx - set qp's context

 * @qp: sc qp

 * @qp_ctx: context ptr

 * @info: ctx info

/**

 * irdma_sc_alloc_stag - mr stag alloc

 * @dev: sc device struct

 * @info: stag info

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_mr_reg_non_shared - non-shared mr registration

 * @dev: sc device struct

 * @info: mr info

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_dealloc_stag - deallocate stag

 * @dev: sc device struct

 * @info: dealloc stag info

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_mw_alloc - mw allocate

 * @dev: sc device struct

 * @info: memory window allocation information

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_mr_fast_register - Posts RDMA fast register mr WR to iwarp qp

 * @qp: sc qp struct

 * @info: fast mr info

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_gen_rts_ae - request AE generated after RTS

 * @qp: sc qp struct

 make sure WQE is written before valid bit is set */

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_send_lsmm - send last streaming mode message

 * @qp: sc qp struct

 * @lsmm_buf: buffer with lsmm message

 * @size: size of lsmm buffer

 * @stag: stag of lsmm buffer

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_send_rtt - send last read0 or write0

 * @qp: sc qp struct

 * @read: Do read0 or write0

 make sure WQE is written before valid bit is set */

/**

 * irdma_iwarp_opcode - determine if incoming is rdma layer

 * @info: aeq info for the packet

 * @pkt: packet for error

/**

 * irdma_locate_mpa - return pointer to mpa in the pkt

 * @pkt: packet with data

 skip over ethernet header */

 Skip over IP and TCP headers */

/**

 * irdma_bld_termhdr_ctrl - setup terminate hdr control fields

 * @qp: sc qp ptr for pkt

 * @hdr: term hdr

 * @opcode: flush opcode for termhdr

 * @layer_etype: error layer + error type

 * @err: error cod ein the header

/**

 * irdma_bld_termhdr_ddp_rdma - setup ddp and rdma hdrs in terminate hdr

 * @pkt: ptr to mpa in offending pkt

 * @hdr: term hdr

 * @copy_len: offending pkt length to be copied to term hdr

 * @is_tagged: DDP tagged or untagged

/**

 * irdma_bld_terminate_hdr - build terminate message header

 * @qp: qp associated with received terminate AE

 * @info: the struct contiaing AE information

/**

 * irdma_terminate_send_fin() - Send fin for terminate message

 * @qp: qp associated with received terminate AE

/**

 * irdma_terminate_connection() - Bad AE and send terminate to remote QP

 * @qp: qp associated with received terminate AE

 * @info: the struct contiaing AE information

/**

 * irdma_terminate_received - handle terminate received AE

 * @qp: qp associated with received terminate AE

 * @info: the struct contiaing AE information

 did not validate the frame - do it now */

 Bad terminate recvd - send back a terminate */

 do nothing */

 do nothing */

/**

 * irdma_sc_vsi_init - Init the vsi structure

 * @vsi: pointer to vsi structure to initialize

 * @info: the info used to initialize the vsi struct

/**

 * irdma_get_fcn_id - Return the function id

 * @vsi: pointer to the vsi

/**

 * irdma_vsi_stats_init - Initialize the vsi statistics

 * @vsi: pointer to the vsi structure

 * @info: The info structure used for initialization

/**

 * irdma_vsi_stats_free - Free the vsi stats

 * @vsi: pointer to the vsi structure

/**

 * irdma_get_encoded_wqe_size - given wq size, returns hardware encoded size

 * @wqsize: size of the wq (sq, rq) to encoded_size

 * @queue_type: queue type selected for the calculation algorithm

	/* cqp sq's hw coded value starts from 1 for size of 4

	 * while it starts from 0 for qp' wq's.

/**

 * irdma_sc_gather_stats - collect the statistics

 * @cqp: struct for cqp hw

 * @info: gather stats info structure

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_manage_stats_inst - allocate or free stats instance

 * @cqp: struct for cqp hw

 * @info: stats info structure

 * @alloc: alloc vs. delete flag

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_set_up_map - set the up map table

 * @cqp: struct for cqp hw

 * @info: User priority map info

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_manage_ws_node - create/modify/destroy WS node

 * @cqp: struct for cqp hw

 * @info: node info structure

 * @node_op: 0 for add 1 for modify, 2 for delete

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_qp_flush_wqes - flush qp's wqe

 * @qp: sc qp

 * @info: dlush information

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_gen_ae - generate AE, uses flush WQE CQP OP

 * @qp: sc qp

 * @info: gen ae information

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/*** irdma_sc_qp_upload_context - upload qp's context

 * @dev: sc device struct

 * @info: upload context info ptr for return

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_manage_push_page - Handle push page

 * @cqp: struct for cqp hw

 * @info: push page info

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_suspend_qp - suspend qp for param change

 * @cqp: struct for cqp hw

 * @qp: sc qp struct

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_resume_qp - resume qp after suspend

 * @cqp: struct for cqp hw

 * @qp: sc qp struct

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_cq_ack - acknowledge completion q

 * @cq: cq struct

/**

 * irdma_sc_cq_init - initialize completion q

 * @cq: cq struct

 * @info: cq initialization info

/**

 * irdma_sc_cq_create - create completion q

 * @cq: cq struct

 * @scratch: u64 saved to be used during cqp completion

 * @check_overflow: flag for overflow check

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_cq_destroy - destroy completion q

 * @cq: cq struct

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_cq_resize - set resized cq buffer info

 * @cq: resized cq

 * @info: resized cq buffer info

/**

 * irdma_sc_cq_modify - modify a Completion Queue

 * @cq: cq struct

 * @info: modification info struct

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag to post to sq

 make sure WQE is written before valid bit is set */

/**

 * irdma_check_cqp_progress - check cqp processing progress

 * @timeout: timeout info struct

 * @dev: sc device struct

/**

 * irdma_get_cqp_reg_info - get head and tail for cqp using registers

 * @cqp: struct for cqp hw

 * @val: cqp tail register value

 * @tail: wqtail register value

 * @error: cqp processing err

/**

 * irdma_cqp_poll_registers - poll cqp registers

 * @cqp: struct for cqp hw

 * @tail: wqtail register value

 * @count: how many times to try for completion

 SUCCESS */

/**

 * irdma_sc_decode_fpm_commit - decode a 64 bit value into count and base

 * @dev: sc device struct

 * @buf: pointer to commit buffer

 * @buf_idx: buffer index

 * @obj_info: object info pointer

 * @rsrc_idx: indexs of memory resource

/**

 * irdma_sc_parse_fpm_commit_buf - parse fpm commit buffer

 * @dev: pointer to dev struct

 * @buf: ptr to fpm commit buffer

 * @info: ptr to irdma_hmc_obj_info struct

 * @sd: number of SDs for HMC objects

 *

 * parses fpm commit info and copy base value

 * of hmc objects in hmc_info

 skiping RSRVD */

 skipping RSVD. */

 searching for the last object in HMC to find the size of the HMC area. */

 add 1 for remainder */

/**

 * irdma_sc_decode_fpm_query() - Decode a 64 bit value into max count and size

 * @buf: ptr to fpm query buffer

 * @buf_idx: index into buf

 * @obj_info: ptr to irdma_hmc_obj_info struct

 * @rsrc_idx: resource index into info

 *

 * Decode a 64 bit value from fpm query buffer into max count and size

/**

 * irdma_sc_parse_fpm_query_buf() - parses fpm query buffer

 * @dev: ptr to shared code device

 * @buf: ptr to fpm query buffer

 * @hmc_info: ptr to irdma_hmc_obj_info struct

 * @hmc_fpm_misc: ptr to fpm data

 *

 * parses fpm query buffer and copy max_cnt and

 * size value of hmc objects in hmc_info

/**

 * irdma_sc_find_reg_cq - find cq ctx index

 * @ceq: ceq sc structure

 * @cq: cq sc structure

/**

 * irdma_sc_add_cq_ctx - add cq ctx tracking for ceq

 * @ceq: ceq sc structure

 * @cq: cq sc structure

/**

 * irdma_sc_remove_cq_ctx - remove cq ctx tracking for ceq

 * @ceq: ceq sc structure

 * @cq: cq sc structure

/**

 * irdma_sc_cqp_init - Initialize buffers for a control Queue Pair

 * @cqp: IWARP control queue pair pointer

 * @info: IWARP control queue pair init info pointer

 *

 * Initializes the object and context buffers for a control Queue Pair.

 for the cqp commands backlog. */

/**

 * irdma_sc_cqp_create - create cqp during bringup

 * @cqp: struct for cqp hw

 * @maj_err: If error, major err number

 * @min_err: If error, minor err number

/**

 * irdma_sc_cqp_post_sq - post of cqp's sq

 * @cqp: struct for cqp hw

/**

 * irdma_sc_cqp_get_next_send_wqe_idx - get next wqe on cqp sq

 * and pass back index

 * @cqp: CQP HW structure

 * @scratch: private data for CQP WQE

 * @wqe_idx: WQE index of CQP SQ

/**

 * irdma_sc_cqp_destroy - destroy cqp during close

 * @cqp: struct for cqp hw

/**

 * irdma_sc_ccq_arm - enable intr for control cq

 * @ccq: ccq sc struct

 make sure shadow area is updated before arming */

/**

 * irdma_sc_ccq_get_cqe_info - get ccq's cq entry

 * @ccq: ccq sc struct

 * @info: completion q entry to return

  move the head for cq */

 update cq tail in cq shadow memory also */

 make sure shadow area is updated before moving tail */

/**

 * irdma_sc_poll_for_cqp_op_done - Waits for last write to complete in CQP SQ

 * @cqp: struct for cqp hw

 * @op_code: cqp opcode for completion

 * @compl_info: completion q entry to return

 make sure op code matches*/

/**

 * irdma_sc_manage_hmc_pm_func_table - manage of function table

 * @cqp: struct for cqp hw

 * @scratch: u64 saved to be used during cqp completion

 * @info: info for the manage function table operation

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_commit_fpm_val_done - wait for cqp eqe completion

 * for fpm commit

 * @cqp: struct for cqp hw

/**

 * irdma_sc_commit_fpm_val - cqp wqe for commit fpm values

 * @cqp: struct for cqp hw

 * @scratch: u64 saved to be used during cqp completion

 * @hmc_fn_id: hmc function id

 * @commit_fpm_mem: Memory for fpm values

 * @post_sq: flag for cqp db to ring

 * @wait_type: poll ccq or cqp registers for cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_query_fpm_val_done - poll for cqp wqe completion for

 * query fpm

 * @cqp: struct for cqp hw

/**

 * irdma_sc_query_fpm_val - cqp wqe query fpm values

 * @cqp: struct for cqp hw

 * @scratch: u64 saved to be used during cqp completion

 * @hmc_fn_id: hmc function id

 * @query_fpm_mem: memory for return fpm values

 * @post_sq: flag for cqp db to ring

 * @wait_type: poll ccq or cqp registers for cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_ceq_init - initialize ceq

 * @ceq: ceq sc structure

 * @info: ceq initialization info

/**

 * irdma_sc_ceq_create - create ceq wqe

 * @ceq: ceq sc structure

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_cceq_create_done - poll for control ceq wqe to complete

 * @ceq: ceq sc structure

/**

 * irdma_sc_cceq_destroy_done - poll for destroy cceq to complete

 * @ceq: ceq sc structure

/**

 * irdma_sc_cceq_create - create cceq

 * @ceq: ceq sc structure

 * @scratch: u64 saved to be used during cqp completion

/**

 * irdma_sc_ceq_destroy - destroy ceq

 * @ceq: ceq sc structure

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_process_ceq - process ceq

 * @dev: sc device struct

 * @ceq: ceq sc structure

 *

 * It is expected caller serializes this function with cleanup_ceqes()

 * because these functions manipulate the same ceq

/**

 * irdma_sc_cleanup_ceqes - clear the valid ceqes ctx matching the cq

 * @cq: cq for which the ceqes need to be cleaned up

 * @ceq: ceq ptr

 *

 * The function is called after the cq is destroyed to cleanup

 * its pending ceqe entries. It is expected caller serializes this

 * function with process_ceq() in interrupt context.

/**

 * irdma_sc_aeq_init - initialize aeq

 * @aeq: aeq structure ptr

 * @info: aeq initialization info

/**

 * irdma_sc_aeq_create - create aeq

 * @aeq: aeq structure ptr

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_aeq_destroy - destroy aeq during close

 * @aeq: aeq structure ptr

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_get_next_aeqe - get next aeq entry

 * @aeq: aeq structure ptr

 * @info: aeqe info to be returned

/**

 * irdma_sc_repost_aeq_entries - repost completed aeq entries

 * @dev: sc device struct

 * @count: allocate count

/**

 * irdma_sc_ccq_init - initialize control cq

 * @cq: sc's cq ctruct

 * @info: info for control cq initialization

 control cq is id 0 always */

 Only applicable to CQs other than CCQ so initialize to zero */

/**

 * irdma_sc_ccq_create_done - poll cqp for ccq create

 * @ccq: ccq sc struct

/**

 * irdma_sc_ccq_create - create control cq

 * @ccq: ccq sc struct

 * @scratch: u64 saved to be used during cqp completion

 * @check_overflow: overlow flag for ccq

 * @post_sq: flag for cqp db to ring

/**

 * irdma_sc_ccq_destroy - destroy ccq during close

 * @ccq: ccq sc struct

 * @scratch: u64 saved to be used during cqp completion

 * @post_sq: flag for cqp db to ring

 make sure WQE is written before valid bit is set */

/**

 * irdma_sc_init_iw_hmc() - queries fpm values using cqp and populates hmc_info

 * @dev : ptr to irdma_dev struct

 * @hmc_fn_id: hmc function id

 parse the fpm_query_buf and fill hmc obj info */

/**

 * irdma_sc_cfg_iw_fpm() - commits hmc obj cnt values using cqp

 * command and populates fpm base address in hmc_info

 * @dev : ptr to irdma_dev struct

 * @hmc_fn_id: hmc function id

 RSRVD */

 RSVD */

 RSVD */

/**

 * cqp_sds_wqe_fill - fill cqp wqe doe sd

 * @cqp: struct for cqp hw

 * @info: sd info for wqe

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_update_pe_sds - cqp wqe for sd

 * @dev: ptr to irdma_dev struct

 * @info: sd info for sd's

 * @scratch: u64 saved to be used during cqp completion

/**

 * irdma_update_sds_noccq - update sd before ccq created

 * @dev: sc device struct

 * @info: sd info for sd's

/**

 * irdma_sc_static_hmc_pages_allocated - cqp wqe to allocate hmc pages

 * @cqp: struct for cqp hw

 * @scratch: u64 saved to be used during cqp completion

 * @hmc_fn_id: hmc function id

 * @post_sq: flag for cqp db to ring

 * @poll_registers: flag to poll register for cqp completion

 make sure WQE is written before valid bit is set */

 check for cqp sq tail update */

/**

 * irdma_cqp_ring_full - check if cqp ring is full

 * @cqp: struct for cqp hw

/**

 * irdma_est_sd - returns approximate number of SDs for HMC

 * @dev: sc device struct

 * @hmc_info: hmc structure, size and count for HMC objects

 add 1 for remainder */

/**

 * irdma_sc_query_rdma_features_done - poll cqp for query features done

 * @cqp: struct for cqp hw

/**

 * irdma_sc_query_rdma_features - query RDMA features and FW ver

 * @cqp: struct for cqp hw

 * @buf: buffer to hold query info

 * @scratch: u64 saved to be used during cqp completion

 make sure WQE is written before valid bit is set */

/**

 * irdma_get_rdma_features - get RDMA features

 * @dev: sc device struct

/**

 * irdma_cfg_fpm_val - configure HMC objects

 * @dev: sc device struct

 * @qp_count: desired qp count

 Reserved */

 Do not reduce resources further. All objects fit with max SDs */

/**

 * irdma_exec_cqp_cmd - execute cqp cmd when wqe are available

 * @dev: rdma device

 * @pcmdinfo: cqp command info

 switch to calling through the call table */

/**

 * irdma_process_cqp_cmd - process all cqp commands

 * @dev: sc device struct

 * @pcmdinfo: cqp command info

/**

 * irdma_process_bh - called from tasklet for cqp list

 * @dev: sc device struct

/**

 * irdma_cfg_aeq- Configure AEQ interrupt

 * @dev: pointer to the device structure

 * @idx: vector index

 * @enable: True to enable, False disables

/**

 * sc_vsi_update_stats - Update statistics

 * @vsi: sc_vsi instance to update

/**

 * irdma_wait_pe_ready - Check if firmware is ready

 * @dev: provides access to registers

/**

 * irdma_sc_dev_init - Initialize control part of device

 * @ver: version

 * @dev: Device pointer

 * @info: Device init info

 for CQP command backlog */

 Setup the hardware limits, hmc may limit further */

/**

 * irdma_update_stats - Update statistics

 * @hw_stats: hw_stats instance to update

 * @gather_stats: updated stat counters

 * @last_gather_stats: last stat counters

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_destroy_pble_prm - destroy prm during module unload

 * @pble_rsrc: pble resources

/**

 * irdma_hmc_init_pble - Initialize pble resources during module load

 * @dev: irdma_sc_dev struct

 * @pble_rsrc: pble resources

 Start pble' on 4k boundary */

/**

 * get_sd_pd_idx -  Returns sd index, pd index and rel_pd_idx from fpm address

 * @pble_rsrc: structure containing fpm address

 * @idx: where to return indexes

/**

 * add_sd_direct - add sd direct for pble

 * @pble_rsrc: pble resource ptr

 * @info: page info for sd

/**

 * fpm_to_idx - given fpm address, get pble index

 * @pble_rsrc: pble resource management

 * @addr: fpm address for index

/**

 * add_bp_pages - add backing pages for sd

 * @pble_rsrc: pble resource management

 * @info: page info for sd

/**

 * irdma_get_type - add a sd entry type for sd

 * @dev: irdma_sc_dev struct

 * @idx: index of sd

 * @pages: pages in the sd

/**

 * add_pble_prm - add a sd entry for pble resoure

 * @pble_rsrc: pble resource management

/**

 * free_lvl2 - fee level 2 pble

 * @pble_rsrc: pble resource management

 * @palloc: level 2 pble allocation

/**

 * get_lvl2_pble - get level 2 pble resource

 * @pble_rsrc: pble resource management

 * @palloc: level 2 pble allocation

 number of full 512 (4K) leafs) */

/**

 * get_lvl1_pble - get level 1 pble resource

 * @pble_rsrc: pble resource management

 * @palloc: level 1 pble allocation

/**

 * get_lvl1_lvl2_pble - calls get_lvl1 and get_lvl2 pble routine

 * @pble_rsrc: pble resources

 * @palloc: contains all inforamtion regarding pble (idx + pble addr)

 * @level1_only: flag for a level 1 PBLE

/**

 * irdma_get_pble - allocate pbles from the prm

 * @pble_rsrc: pble resources

 * @palloc: contains all inforamtion regarding pble (idx + pble addr)

 * @pble_cnt: #of pbles requested

 * @level1_only: true if only pble level 1 to acquire

	/*check first to see if we can get pble's without acquiring

	 * additional sd's

 if level1_only, only go through it once */

/**

 * irdma_free_pble - put pbles back into prm

 * @pble_rsrc: pble resources

 * @palloc: contains all information regarding pble resource being freed

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_query_device - get device attributes

 * @ibdev: device pointer from stack

 * @props: returning device attributes

 * @udata: user data

/**

 * irdma_get_eth_speed_and_width - Get IB port speed and width from netdev speed

 * @link_speed: netdev phy link speed

 * @active_speed: IB port speed

 * @active_width: IB port width

/**

 * irdma_query_port - get port attributes

 * @ibdev: device pointer from stack

 * @port: port number for query

 * @props: returning device attributes

 no need to zero out pros here. done by caller */

/**

 * irdma_disassociate_ucontext - Disassociate user context

 * @context: ib user context

/**

 * irdma_mmap - user memory map

 * @context: context created during alloc

 * @vma: kernel info for user memory map

 Legacy support for libi40iw with hard-coded mmap key */

/**

 * irdma_alloc_push_page - allocate a push page for qp

 * @iwqp: qp pointer

/**

 * irdma_alloc_ucontext - Allocate the user context data structure

 * @uctx: uverbs context pointer

 * @udata: user data

 *

 * This keeps track of all objects associated with a particular

 * user-mode client.

 GEN_1 legacy support with libi40iw */

/**

 * irdma_dealloc_ucontext - deallocate the user context data structure

 * @context: user context created during alloc

/**

 * irdma_alloc_pd - allocate protection domain

 * @pd: PD pointer

 * @udata: user data

/**

 * irdma_dealloc_pd - deallocate pd

 * @ibpd: ptr of pd to be deallocated

 * @udata: user data

/**

 * irdma_get_pbl - Retrieve pbl from a list given a virtual

 * address

 * @va: user virtual address

 * @pbl_list: pbl list to search in (QP's or CQ's)

/**

 * irdma_clean_cqes - clean cq entries for qp

 * @iwqp: qp ptr (user or kernel)

 * @iwcq: cq ptr

 skip over db page */

 push wqe page */

 push doorbell page */

/**

 * irdma_destroy_qp - destroy qp

 * @ibqp: qp's ib pointer also to get to device's qp address

 * @udata: user data

/**

 * irdma_setup_virt_qp - setup for allocation of virtual qp

 * @iwdev: irdma device

 * @iwqp: qp ptr

 * @init_info: initialize info to return

/**

 * irdma_setup_kmode_qp - setup initialization for kernel mode qp

 * @iwdev: iwarp device

 * @iwqp: qp ptr (user or kernel)

 * @info: initialize info to return

 * @init_attr: Initial QP create attributes

/**

 * irdma_create_qp - create qp

 * @ibqp: ptr of qp

 * @init_attr: attributes for qp

 * @udata: user data for create qp

 GEN_1 legacy support with libi40iw does not have expanded uresp struct */

/**

 * irdma_query_qp - query qp attributes

 * @ibqp: qp pointer

 * @attr: attributes pointer

 * @attr_mask: Not used

 * @init_attr: qp attributes to return

/**

 * irdma_query_pkey - Query partition key

 * @ibdev: device pointer from stack

 * @port: port number

 * @index: index of pkey

 * @pkey: pointer to store the pkey

/**

 * irdma_modify_qp_roce - modify qp request

 * @ibqp: qp's pointer for modify

 * @attr: access attributes

 * @attr_mask: state mask

 * @udata: user data

/**

 * irdma_modify_qp - modify qp request

 * @ibqp: qp's pointer for modify

 * @attr: access attributes

 * @attr_mask: state mask

 * @udata: user data

/**

 * irdma_cq_free_rsrc - free up resources for cq

 * @rf: RDMA PCI function

 * @iwcq: cq ptr

/**

 * irdma_free_cqbuf - worker to free a cq buffer

 * @work: provides access to the cq buffer to free

/**

 * irdma_process_resize_list - remove resized cq buffers from the resize_list

 * @iwcq: cq which owns the resize_list

 * @iwdev: irdma device

 * @lcqe_buf: the buffer where the last cqe is received

/**

 * irdma_destroy_cq - destroy cq

 * @ib_cq: cq pointer

 * @udata: user data

/**

 * irdma_resize_cq - resize cq

 * @ibcq: cq to be resized

 * @entries: desired cq size

 * @udata: user data

 CQ resize not supported with legacy GEN_1 libi40iw */

 Kmode CQ resize */

 GEN1 does not support CQ create flags */

/**

 * irdma_create_cq - create cq

 * @ibcq: CQ allocated

 * @attr: attributes for cq

 * @udata: user data

 Kmode allocations */

/**

 * irdma_get_mr_access - get hw MR access permissions from IB access flags

 * @access: IB access flags

/**

 * irdma_free_stag - free stag resource

 * @iwdev: irdma device

 * @stag: stag to free

/**

 * irdma_create_stag - create random stag

 * @iwdev: irdma device

/**

 * irdma_next_pbl_addr - Get next pbl address

 * @pbl: pointer to a pble

 * @pinfo: info pointer

 * @idx: index

/**

 * irdma_copy_user_pgaddrs - copy user page address to pble's os locally

 * @iwmr: iwmr for IB's user page addresses

 * @pbl: ple pointer to save 1 level or 0 level pble

 * @level: indicated level 0, 1 or 2

/**

 * irdma_check_mem_contiguous - check if pbls stored in arr are contiguous

 * @arr: lvl1 pbl array

 * @npages: page count

 * @pg_size: page size

 *

/**

 * irdma_check_mr_contiguous - check if MR is physically contiguous

 * @palloc: pbl allocation struct

 * @pg_size: page size

/**

 * irdma_setup_pbles - copy user pg address to pble's

 * @rf: RDMA PCI function

 * @iwmr: mr pointer for this memory registration

 * @use_pbles: flag if to use pble's

/**

 * irdma_handle_q_mem - handle memory for qp and cq

 * @iwdev: irdma device

 * @req: information for q memory management

 * @iwpbl: pble struct

 * @use_pbles: flag to use pble

/**

 * irdma_hw_alloc_mw - create the hw memory window

 * @iwdev: irdma device

 * @iwmr: pointer to memory window info

/**

 * irdma_alloc_mw - Allocate memory window

 * @ibmw: Memory Window

 * @udata: user data pointer

/**

 * irdma_dealloc_mw - Dealloc memory window

 * @ibmw: memory window structure.

/**

 * irdma_hw_alloc_stag - cqp command to allocate stag

 * @iwdev: irdma device

 * @iwmr: irdma mr pointer

/**

 * irdma_alloc_mr - register stag for fast memory registration

 * @pd: ibpd pointer

 * @mr_type: memory for stag registrion

 * @max_num_sg: man number of pages

/**

 * irdma_set_page - populate pbl list for fmr

 * @ibmr: ib mem to access iwarp mr pointer

 * @addr: page dma address fro pbl list

/**

 * irdma_map_mr_sg - map of sg list for fmr

 * @ibmr: ib mem to access iwarp mr pointer

 * @sg: scatter gather list

 * @sg_nents: number of sg pages

 * @sg_offset: scatter gather list for fmr

/**

 * irdma_hwreg_mr - send cqp command for memory registration

 * @iwdev: irdma device

 * @iwmr: irdma mr pointer

 * @access: access for MR

/**

 * irdma_reg_user_mr - Register a user memory region

 * @pd: ptr of pd

 * @start: virtual start address

 * @len: length of mr

 * @virt: virtual address

 * @access: access of mr

 * @udata: user data

/**

 * irdma_reg_phys_mr - register kernel physical memory

 * @pd: ibpd pointer

 * @addr: physical address of memory to register

 * @size: size of memory to register

 * @access: Access rights

 * @iova_start: start of virtual address for physical buffers

/**

 * irdma_get_dma_mr - register physical mem

 * @pd: ptr of pd

 * @acc: access for memory

/**

 * irdma_del_memlist - Deleting pbl list entries for CQ/QP

 * @iwmr: iwmr for IB's user page addresses

 * @ucontext: ptr to user context

/**

 * irdma_dereg_mr - deregister mr

 * @ib_mr: mr ptr for dereg

 * @udata: user data

/**

 * irdma_post_send -  kernel application wr

 * @ibqp: qp ptr for wr

 * @ib_wr: work request ptr

 * @bad_wr: return of bad wr if err

/**

 * irdma_post_recv - post receive wr for kernel application

 * @ibqp: ib qp pointer

 * @ib_wr: work request for receive

 * @bad_wr: bad wr caused an error

/**

 * irdma_flush_err_to_ib_wc_status - return change flush error code to IB status

 * @opcode: iwarp flush code

/**

 * irdma_process_cqe - process cqe info

 * @entry: processed cqe

 * @cq_poll_info: cqe info

/**

 * irdma_poll_one - poll one entry of the CQ

 * @ukcq: ukcq to poll

 * @cur_cqe: current CQE info to be filled in

 * @entry: ibv_wc object to be filled for non-extended CQ or NULL for extended CQ

 *

 * Returns the internal irdma device error code or 0 on success

/**

 * __irdma_poll_cq - poll cq for completion (kernel apps)

 * @iwcq: cq to poll

 * @num_entries: number of entries to poll

 * @entry: wr of a completed entry

 go through the list of previously resized CQ buffers */

 QP using the CQ is destroyed. Skip reporting this CQE */

 save the resized CQ buffer which received the last cqe */

 check the current CQ for new cqes */

 QP using the CQ is destroyed. Skip reporting this CQE */

 all previous CQ resizes are complete */

 only CQ resizes up to the last_buf are complete */

 report to the HW the number of complete CQ resizes */

/**

 * irdma_poll_cq - poll cq for completion (kernel apps)

 * @ibcq: cq to poll

 * @num_entries: number of entries to poll

 * @entry: wr of a completed entry

/**

 * irdma_req_notify_cq - arm cq kernel application

 * @ibcq: cq to arm

 * @notify_flags: notofication flags

 32bit names */

 64bit names */

/**

 * irdma_alloc_hw_port_stats - Allocate a hw stats structure

 * @ibdev: device pointer from stack

 * @port_num: port number

/**

 * irdma_get_hw_stats - Populates the rdma_hw_stats structure

 * @ibdev: device pointer from stack

 * @stats: stats pointer from stack

 * @port_num: port number

 * @index: which hw counter the stack is requesting we update

/**

 * irdma_query_gid - Query port GID

 * @ibdev: device pointer from stack

 * @port: port number

 * @index: Entry index

 * @gid: Global ID

/**

 * mcast_list_add -  Add a new mcast item to list

 * @rf: RDMA PCI function

 * @new_elem: pointer to element to add

/**

 * mcast_list_del - Remove an mcast item from list

 * @mc_qht_elem: pointer to mcast table list element

/**

 * mcast_list_lookup_ip - Search mcast list for address

 * @rf: RDMA PCI function

 * @ip_mcast: pointer to mcast IP address

/**

 * irdma_mcast_cqp_op - perform a mcast cqp operation

 * @iwdev: irdma device

 * @mc_grp_ctx: mcast group info

 * @op: operation

 *

 * returns error status

/**

 * irdma_mcast_mac - Get the multicast MAC for an IP address

 * @ip_addr: IPv4 or IPv6 address

 * @mac: pointer to result MAC address

 * @ipv4: flag indicating IPv4 or IPv6

 *

/**

 * irdma_attach_mcast - attach a qp to a multicast group

 * @ibqp: ptr to qp

 * @ibgid: pointer to global ID

 * @lid: local ID

 *

 * returns error status

 Only if there is a change do we need to modify or create */

/**

 * irdma_detach_mcast - detach a qp from a multicast group

 * @ibqp: ptr to qp

 * @ibgid: pointer to global ID

 * @lid: local ID

 *

 * returns error status

/**

 * irdma_create_ah - create address handle

 * @ibah: address handle

 * @attr: address handle attributes

 * @udata: User data

 *

 * returns 0 on success, error otherwise

/**

 * irdma_destroy_ah - Destroy address handle

 * @ibah: pointer to address handle

 * @ah_flags: flags for sleepable

/**

 * irdma_query_ah - Query address handle

 * @ibah: pointer to address handle

 * @ah_attr: address handle attributes

/**

 * irdma_init_roce_device - initialization of roce rdma device

 * @iwdev: irdma device

/**

 * irdma_init_iw_device - initialization of iwarp rdma device

 * @iwdev: irdma device

/**

 * irdma_init_rdma_device - initialization of rdma device

 * @iwdev: irdma device

/**

 * irdma_port_ibevent - indicate port event

 * @iwdev: irdma device

/**

 * irdma_ib_unregister_device - unregister rdma device from IB

 * core

 * @iwdev: irdma device

/**

 * irdma_ib_register_device - register irdma device to IB core

 * @iwdev: irdma device

/**

 * irdma_ib_dealloc_device

 * @ibdev: ib device

 *

 * callback from ibdev dealloc_driver to deallocate resources

 * unber irdma device

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * i40iw_l2param_change - handle mss change

 * @cdev_info: parent lan device information structure with data/ops

 * @client: client for parameter change

 * @params: new parameters from L2

/**

 * i40iw_close - client interface operation close for iwarp/uda device

 * @cdev_info: parent lan device information structure with data/ops

 * @client: client to close

 * @reset: flag to indicate close on reset

 *

 * Called by the lan driver during the processing of client unregister

 * Destroy and clean up the driver resources

/**

 * i40iw_open - client interface operation open for iwarp/uda device

 * @cdev_info: parent lan device information structure with data/ops

 * @client: iwarp client information, provided during registration

 *

 * Called by the lan driver during the processing of client register

 * Create device resources, set up queues, pble and hmc objects and

 * register the device with the ib verbs interface

 * Return 0 if successful, otherwise return error

 client interface functions */

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

/**

 * irdma_find_sd_index_limit - finds segment descriptor index limit

 * @hmc_info: pointer to the HMC configuration information structure

 * @type: type of HMC resources we're searching

 * @idx: starting index for the object

 * @cnt: number of objects we're trying to create

 * @sd_idx: pointer to return index of the segment descriptor in question

 * @sd_limit: pointer to return the maximum number of segment descriptors

 *

 * This function calculates the segment descriptor index and index limit

 * for the resource defined by irdma_hmc_rsrc_type.

/**

 * irdma_find_pd_index_limit - finds page descriptor index limit

 * @hmc_info: pointer to the HMC configuration information struct

 * @type: HMC resource type we're examining

 * @idx: starting index for the object

 * @cnt: number of objects we're trying to create

 * @pd_idx: pointer to return page descriptor index

 * @pd_limit: pointer to return page descriptor index limit

 *

 * Calculates the page descriptor index and index limit for the resource

 * defined by irdma_hmc_rsrc_type.

/**

 * irdma_set_sd_entry - setup entry for sd programming

 * @pa: physical addr

 * @idx: sd index

 * @type: paged or direct sd

 * @entry: sd entry ptr

/**

 * irdma_clr_sd_entry - setup entry for sd clear

 * @idx: sd index

 * @type: paged or direct sd

 * @entry: sd entry ptr

/**

 * irdma_invalidate_pf_hmc_pd - Invalidates the pd cache in the hardware for PF

 * @dev: pointer to our device struct

 * @sd_idx: segment descriptor index

 * @pd_idx: page descriptor index

/**

 * irdma_hmc_sd_one - setup 1 sd entry for cqp

 * @dev: pointer to the device structure

 * @hmc_fn_id: hmc's function id

 * @pa: physical addr

 * @sd_idx: sd index

 * @type: paged or direct sd

 * @setsd: flag to set or clear sd

/**

 * irdma_hmc_sd_grp - setup group of sd entries for cqp

 * @dev: pointer to the device structure

 * @hmc_info: pointer to the HMC configuration information struct

 * @sd_index: sd index

 * @sd_cnt: number of sd entries

 * @setsd: flag to set or clear sd

/**

 * irdma_hmc_finish_add_sd_reg - program sd entries for objects

 * @dev: pointer to the device structure

 * @info: create obj info

/**

 * irdma_sc_create_hmc_obj - allocate backing store for hmc objects

 * @dev: pointer to the device structure

 * @info: pointer to irdma_hmc_create_obj_info struct

 *

 * This will allocate memory for PDs and backing pages and populate

 * the sd and pd entries.

 update the pd table entry */

/**

 * irdma_finish_del_sd_reg - delete sd entries for objects

 * @dev: pointer to the device structure

 * @info: dele obj info

 * @reset: true if called before reset

/**

 * irdma_sc_del_hmc_obj - remove pe hmc objects

 * @dev: pointer to the device structure

 * @info: pointer to irdma_hmc_del_obj_info struct

 * @reset: true if called before reset

 *

 * This will de-populate the SDs and PDs.  It frees

 * the memory for PDS and backing storage.  After this function is returned,

 * caller should deallocate memory allocated previously for

 * book-keeping information about PDs and backing storage.

/**

 * irdma_add_sd_table_entry - Adds a segment descriptor to the table

 * @hw: pointer to our hw struct

 * @hmc_info: pointer to the HMC configuration information struct

 * @sd_index: segment descriptor index to manipulate

 * @type: what type of segment descriptor we're manipulating

 * @direct_mode_sz: size to alloc in direct mode

 allocate a 4K pd page or 2M backing page */

/**

 * irdma_add_pd_table_entry - Adds page descriptor to the specified table

 * @dev: pointer to our device structure

 * @hmc_info: pointer to the HMC configuration information structure

 * @pd_index: which page descriptor index to manipulate

 * @rsrc_pg: if not NULL, use preallocated page instead of allocating new one.

 *

 * This function:

 *	1. Initializes the pd entry

 *	2. Adds pd_entry in the pd_table

 *	3. Mark the entry valid in irdma_hmc_pd_entry structure

 *	4. Initializes the pd_entry's ref count to 1

 * assumptions:

 *	1. The memory for pd should be pinned down, physically contiguous and

 *	   aligned on 4K boundary and zeroed memory.

 *	2. It should be 4K in size.

/**

 * irdma_remove_pd_bp - remove a backing page from a page descriptor

 * @dev: pointer to our HW structure

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: the page index

 *

 * This function:

 *	1. Marks the entry in pd table (for paged address mode) or in sd table

 *	   (for direct address mode) invalid.

 *	2. Write to register PMPDINV to invalidate the backing page in FV cache

 *	3. Decrement the ref count for the pd _entry

 * assumptions:

 *	1. Caller can deallocate the memory used by backing storage after this

 *	   function returns.

/**

 * irdma_prep_remove_sd_bp - Prepares to remove a backing page from a sd entry

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: the page index

/**

 * irdma_prep_remove_pd_page - Prepares to remove a PD page from sd entry.

 * @hmc_info: pointer to the HMC configuration information structure

 * @idx: segment descriptor index to find the relevant page descriptor

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2019 Intel Corporation */

 SPDX-License-Identifier: GPL-2.0 or Linux-OpenIB

 Copyright (c) 2015 - 2021 Intel Corporation */

 Wait for all qp's to suspend */

/**

 * irdma_request_reset - Request a reset

 * @rf: RDMA PCI function

/**

 * irdma_lan_register_qset - Register qset with LAN driver

 * @vsi: vsi structure

 * @tc_node: Traffic class node

/**

 * irdma_lan_unregister_qset - Unregister qset with LAN driver

 * @vsi: vsi structure

 * @tc_node: Traffic class node

/*

 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 PPF or Native -- real SQP */

 VF or PF -- proxy SQP */

 used for INIT/CLOSE port logic */

 PPF or Native -- real QP0 */

 VF or PF -- proxy QP0 */

/*

 * Stamp a SQ WQE so that it is invalid if prefetched by marking the

 * first four bytes of every 64 byte chunk with 0xffffffff, except for

 * the very first chunk of the WQE.

	/*

	 * UD WQEs must have a datagram segment.

	 * RC and UC WQEs might have a remote address segment.

	 * MLX WQEs need two extra inline data segments (for the UD

	 * header and space for the ICRC).

 Sanity check RQ size before proceeding */

 HW requires >= 1 RQ entry with >= 1 gather entry */

 leave userspace return values as they were, so as not to break ABI */

 Sanity check SQ size before proceeding */

	/*

	 * For MLX transport we need 2 extra S/G entries:

	 * one for the header and one for the checksum at the end

	/*

	 * We need to leave 2 KB + 1 WR of headroom in the SQ to

	 * allow HW to prefetch.

 We don't support inline sends for kernel QPs (yet) */

 Sanity check SQ size before proceeding */

			/*

			 * Hash according to inner headers if exist, otherwise

			 * according to outer headers.

 Set dummy send resources to be compatible with HV and PRM */

/*

 * This function allocates a WQN from a range which is consecutive and aligned

 * to its size. In case the range is full, then it creates a new range and

 * allocates WQN from it. The new range will be used for following allocations.

		/*

		 * Requesting a new range (>1) when last range is still open, is

		 * not valid.

	/*

	 * A range which one of its WQNs is destroyed, won't be able to be

	 * reused for further WQN allocations.

	 * The next created WQ will allocate a new range.

	/*

	 * Hardware wants QPN written in big-endian order (after

	 * shifting) for send doorbell.  Precompute this value to save

	 * a little bit when posting sends.

	/* Maintain device to QPs access, needed for further handling

	 * via reset flow

	/* Maintain CQ to QPs access, needed for further handling

	 * via reset flow

 When tunneling special qps, we use a plain UD qp */

 add extra sg entry for tunneling */

		/* we are definitely in the PPF here, since we are creating

		/* Raw packet QPNs may not have bits 6,7 set in their qp_num;

		 * otherwise, the WQE BlueFlame setup flow wrongly causes

	/*

	 * Hardware wants QPN written in big-endian order (after

	 * shifting) for send doorbell.  Precompute this value to save

	 * a little bit when posting sends.

	/* Maintain device to QPs access, needed for further handling

	 * via reset flow

	/* Maintain CQ to QPs access, needed for further handling

	 * via reset flow

 del from lists under both locks above to protect reset flow paths */

 Native or PPF */

 PF or VF -- creating proxies */

	/*

	 * We only support LSO, vendor flag1, and multicast loopback blocking,

	 * and only for kernel UD QPs.

 Internal QP created with ib_create_qp */

 Don't support raw QPs */

 both valid vlan ids */

 different VIDs.  unreg old and reg new */

 no current vlan tag in qp */

 have current vlan tag. unregister it at modify-qp success */

		/* get smac_index for RoCE use.

		 * If no smac was yet assigned, register one.

		 * If one was already assigned, but the new mac differs,

		 * unregister the old one and register the new one.

 register candidate now, unreg if needed, after success */

 put MAC table smac index for IBoE */

/*

 * Go over all RSS QP's childes (WQs) and apply their HW state according to

 * their logic state if the RSS QP is the first RSS QP associated for the WQ.

		/* Mlx4_ib restrictions:

		 * WQ's is associated to a port according to the RSS QP it is

		 * associates to.

		 * In case the WQ is associated to a different port by another

		 * RSS QP, return a failure.

 Currently support just toeplitz */

 APM is not supported under RoCE */

 PRM RSS receive side should be left zeros */

 Set dummy CQs to be compatible with HV and PRM */

 Set "fast registration enabled" for all kernel QPs */

 proxy and tunnel qp qkeys will be changed in modify-qp wrappers */

 don't fsm */

 handle smac_index */

 set QP to receive both tunneled & non-tunneled packets */

	/*

	 * Before passing a kernel QP to the HW, make sure that the

	 * ownership bits of the send queue are set and the SQ

	 * headroom is stamped so that the hardware doesn't start

	 * processing stale work requests.

	/*

	 * If we moved QP0 to RTR, bring the IB link up; if we moved

	 * QP0 to RESET or ERROR, bring the link back down.

	/*

	 * If we moved a kernel QP to RESET, clean up all old CQ

	 * entries and reinitialize the QP.

			/* no sense in changing port_num

 for proxy-qp0 sends, need to add in size of tunnel header */

 for tunnel-qp0 sends, tunnel header is already in s/g list */

 force loopback */

	/*

	 * Inline data segments may not cross a 64 byte boundary.  If

	 * our UD header is bigger than the space available up to the

	 * next 64 byte boundary in the WQE, use two inline data

	 * segments to hold the UD header.

		/*

		 * Need a barrier here to make sure all the data is

		 * visible before the byte_count field is set.

		 * Otherwise the HCA prefetcher could grab the 64-byte

		 * chunk with this inline segment and get a valid (!=

		 * 0xffffffff) byte count but stale data, and end up

		 * generating a packet with bad headers.

		 *

		 * The first inline segment's byte_count field doesn't

		 * need a barrier, because it comes after a

		 * control/MLX segment and therefore is at an offset

		 * of 16 mod 64.

			/* When multi-function is enabled, the ib_core gid

			 * indexes don't necessarily match the hw ones, so

				/* When multi-function is enabled, the ib_core gid

				 * indexes don't necessarily match the hw ones, so

				 * we must use our own cache

 force loopback */

	/*

	 * Inline data segments may not cross a 64 byte boundary.  If

	 * our UD header is bigger than the space available up to the

	 * next 64 byte boundary in the WQE, use two inline data

	 * segments to hold the UD header.

		/*

		 * Need a barrier here to make sure all the data is

		 * visible before the byte_count field is set.

		 * Otherwise the HCA prefetcher could grab the 64-byte

		 * chunk with this inline segment and get a valid (!=

		 * 0xffffffff) byte count but stale data, and end up

		 * generating a packet with bad headers.

		 *

		 * The first inline segment's byte_count field doesn't

		 * need a barrier, because it comes after a

		 * control/MLX segment and therefore is at an offset

		 * of 16 mod 64.

 XXX -- is this just for ZBVA? */

 force loopback */

 no GRH */

 Use QKEY from the QP context, which is set by master */

	/*

	 * Need a barrier here before writing the byte_count field to

	 * make sure that all the data is visible before the

	 * byte_count field is set.  Otherwise, if the segment begins

	 * a new cacheline, the HCA prefetcher could grab the 64-byte

	 * chunk and get a valid (!= * 0xffffffff) byte count but

	 * stale data, and end up sending the wrong data.

	/*

	 * Need a barrier here before writing the byte_count field to

	 * make sure that all the data is visible before the

	 * byte_count field is set.  Otherwise, if the segment begins

	 * a new cacheline, the HCA prefetcher could grab the 64-byte

	 * chunk and get a valid (!= * 0xffffffff) byte count but

	 * stale data, and end up sending the wrong data.

 No extra segments required for sends */

 this is a UD qp used in MAD responses to slaves. */

 set the forced-loopback bit in the data seg av */

 to start tunnel header on a cache-line boundary */

			/* If we are tunneling special qps, this is a UD qp.

			 * In this case we first add a UD segment targeting

			 * the tunnel qp, and then add a header with address

		/*

		 * Write data segments in reverse order, so as to

		 * overwrite cacheline stamp last within each

		 * cacheline.  This avoids issues with WQE

		 * prefetching.

 Add one more inline data segment for ICRC for MLX sends */

		/*

		 * Possibly overwrite stamping in cacheline with LSO

		 * segment only after making sure all data segments

		 * are written.

		/*

		 * Make sure descriptor is fully written before

		 * setting ownership bit (because HW can start

		 * executing as soon as we do).

		/*

		 * We can improve latency by not stamping the last

		 * send queue WQE until after ringing the doorbell, so

		 * only stamp here if there are still more WQEs to post.

		/*

		 * Make sure that descriptors are written before

		 * doorbell record.

 use dma lkey from upper layer entry */

		/*

		 * Make sure that descriptors are written before

		 * doorbell record.

 qp_attr->en_sqd_async_notify is only applicable in modify qp */

	/*

	 * We don't support inline sends for kernel QPs (yet), and we

	 * don't know what userspace's value should be.

 Dummy CQ */

	/* ib_qp.state represents the WQ HW state while ib_wq.state represents

	 * the WQ logic state.

	/* Need to protect against the parent RSS which also may modify WQ

	 * state.

	/* Can update HW state only if a RSS QP has already associated to this

	 * WQ, so we can apply its port on the WQ.

 This function returns only once the drained WR was completed */

 Make sure that the CQ handler won't run if wasn't run yet */

 Wait for any scheduled/running task to be ended */

		/* Run the CQ handler - this makes sure that the drain WR will

		 * be processed if wasn't processed yet.

/*

 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Sanity check SRQ size before proceeding */

 We don't support resizing SRQs (yet?) */

 always called with interrupts disabled. */

		/*

		 * Make sure that descriptors are written before

		 * doorbell record.

/*

 * Copyright (c) 2012 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Lock should be taken before called */

 Go to the bottom of the tree */

error flow*/

make sure that there is no schedule inside the scheduled work.*/

 Adjust timeout if already scheduled */

 If a retry, adjust delayed work */

 Even if this fails, we pass on the REQ to the slave */

 slave = -1 ==> all slaves */

 TBD -- call paravirt clean for single slave.  Need for slave RESET event */

 cancel all delayed work queue entries */

 make sure all timers were flushed */

 now, remove all leftover entries from databases*/

 first, move nodes belonging to slave to db remove list */

 remove those nodes from databases */

 add remaining nodes from cm_list */

 free any map entries left behind due to cancel_delayed_work above */

/*

 * Copyright (c) 2012 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

**********************************************************/

This file support the handling of the Alias GUID feature. */

**********************************************************/

/*

The driver keeps the current state of all guids, as they are in the HW.

Whenever we receive an smp mad GUIDInfo record, the data will be cached.

		/* The location of the specific index starts from bit number 4

 cache the guid: */

 set to run immediately */

/*

 * Whenever new GUID is set/unset (guid table change) create event and

 * notify the relevant slave (master also should be notified).

 * If the GUID value is not as we have in the cache the slave will not be

 * updated; in this case it waits for the smp_snoop or the port management

 * event to call the function and to update the slave.

 * block_number - the index of the block (16 blocks available)

 * port_number - 1 or 2

calculate the slaves and notify them*/

 the location of the specific index runs from bits 4..11 */

 this port isn't available for the VF */

		/*

		 * Check if guid is not the same as in the cache,

		 * If it is different, wait for the snoop_smp or the port mgmt

		 * change event to update the slave on its port state change

 may notify port down if value is 0 */

2 cases: Valid GUID, and Invalid Guid*/

valid GUID*/

 request to invalidate GUID */

 A new value was set till we got the response */

		/* check if the SM didn't assign one of the records.

		 * if it didn't, re-ask for.

 properly assigned record. */

		       /* We save the GUID we just got from the SM in the

			* admin_guid in order to be persistent, and in the

 Warn only on first retry */

 using the minimum value among all entries in that record */

	/*

	The func is call here to close the cases when the

	sm doesn't send smp, so in the sa response the driver

	notifies the slave.

 calculate the comp_mask for that record.*/

		/*

		check the admin value: if it's for delete (~00LL) or

		it is the first guid of the first record (hw guid) or

		the records is not in ownership of the sysadmin and the sm doesn't

		need to assign GUIDs, then don't put it up for assignment.

check the port was configured by the sm, otherwise no need to send */

Check if the SM doesn't need to assign the GUIDs*/

 no request for the 0 entry (hw guid) */

		/*

		make sure no work waits in the queue, if the work is already

		queued(not on the timer) the cancel will fail. That is not a problem

		because we just want the work started.

/* return index of record that should be updated based on lowest

 * rescheduled time

/* The function returns the next record that was

		/* If there is pending one should cancel then run, otherwise

		  * won't run till previous one is ended as same work

		  * struct is used.

 mark each val as it was deleted */

prepare the records, set them to be allocated by sm*/

/*

 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * If sgid_attr is NULL we are being called by mlx4_ib_create_ah_slave

	 * and we are directly creating an AV for a slave's gid_index.

 mlx4_ib_create_ah_slave fills in the s_mac and the vlan */

	/*

	 * HW requires multicast LID so we just choose one.

		/*

		 * TBD: need to handle the case when we get

		 * called in an atomic context and there we

		 * might sleep.  We don't expect this

		 * currently since we're working with link

		 * local addresses which we can translate

		 * without going to sleep.

 get rid of force-loopback bit */

/*

 * Copyright (c) 2012 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 MGID string */

	/* refcount is the reference count for the following:

	   1. Each queued request

	   2. Each invocation of the worker thread

	   3. Membership of the port at the SA

 delayed work to clean pending SM request */

 port is not yet Active, sm_ah not ready */

 Our agent might not yet be registered when mads start to arrive */

 opensm lid */

 we rely on a mad request as arrived from a VF */

 fix port GID to be the real one (slave 0) */

 assign our own TID */

 keep it for later validation */

 set timeout handler */

 calls mlx4_ib_mcg_timeout_handler */

 keep it for later validation */

 set timeout handler */

 calls mlx4_ib_mcg_timeout_handler */

 resetting tid to 0 */

 ignored on responses, see IBTA spec */

 reconstruct VF's requested join_state and port_gid */

 src is group record, dst is request record */

 MGID must already match */

 Port_GID we always replace to our Port_GID, so it is a match */

 join_state checked separately, proxy_join ignored */

/* release group, return 1 if this was last release and group is destroyed

 remove bits that slave is already member of, and adjust */

 make sure we're not deleting unset bits */

 port's membership need not change */

 port's membership needs to be updated */

 release_count - this is for the scheduled work */

	/* First, let's see if a response from SM is waiting regarding this group.

	 * If so, we need to update the group's REC. If this is a bad response, we

	 * may need to send a bad response to a VF waiting for it. If VF is waiting

 cancels mlx4_ib_mcg_timeout_handler */

 successfull join */

 We should now go over pending join/leave requests, as long as we are idle. */

		/* For a leave request, we will immediately answer the VF, and

		 * update our internal counters. The actual leave will be sent

 Handle leaves */

 A race between our code and SM. Silently cleaning the new one */

 for the request */

 for scheduling the work */

 calls mlx4_ib_mcg_work_handler */

 in group we kept the modified TID */

 calls mlx4_ib_mcg_work_handler */

 consumed */

 not consumed, pass-through to guest over tunnel */

 consumed */

 consumed */

 not consumed, pass-through */

 consumed */

 clear pending requests of this VF */

/*

 * Copyright (c) 2012 Mellanox Technologies.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

#include "core_priv.h"*/

/*show_admin_alias_guid returns the administratively assigned value of that GUID.

 * Values returned in buf parameter string:

 *	0			- requests opensm to assign a value.

 *	ffffffffffffffff	- delete this entry.

 *	other			- value assigned by administrator.

/* store_admin_alias_guid stores the (new) administratively assigned value of that GUID.

 * Values in buf parameter string:

 *	0			- requests opensm to assign a value.

 *	0xffffffffffffffff	- delete this entry.

 *	other			- guid value assigned by the administrator.

0-15*/

0 - 7*/

 Change the state to be pending for update */

 set the record index */

 get the physical gid and pkey table sizes.*/

	/* Directory structure:

	 * iov -

	 *   port num -

	 *	admin_guids

	 *	gids (operational)

	 *	mcg_table

 admin GUIDs */

 gids subdirectory (operational gids) */

 physical port pkey table */

 MCGs table */

 once more for create_and_add buff */

	/* pci_name format is: bus:dev:func -> xxxx:yy:zz.n

	 * with no ARI only 3 last bits are used so when the fn is higher than 8

	 * need to add it to the dev num, so count in the last number will be

 do not allow remapping Dom0 virtual pkey table */

 do not display entries if eth transport, or if master */

 extra put for the device_parent create_and_add */

/*

 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Can't be smaller than the number of outstanding CQEs */

	/* Find uncompleted WQEs belonging to that cq and return

	 * simulated FLUSH_ERR completions

	/*

	 * Make sure we read CQ entry contents after we've checked the

	 * ownership bit.

 Resize CQ in progress */

		/*

		 * We do not have to take the QP table lock here,

		 * because CQs will be locked while QPs are removed

		 * from the table.

 SRQ is also in the radix tree */

	/*

	 * First we need to find the current producer index, so we

	 * know where to start cleaning from.  It doesn't matter if HW

	 * adds new entries after this loop -- the QP we're worried

	 * about is already in RESET, so the new entries won't come

	 * from our QP and therefore don't need to be checked.

	/*

	 * Now sweep backwards through the CQ, removing CQ entries

	 * that match our QP by copying older entries on top of them.

		/*

		 * Make sure update of buffer contents is done before

		 * updating consumer index.

/*

 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * Align the MTT start address to the mtt_size.

	 * Required to handle cases when the MR starts in the middle of an MTT

	 * record. Was not required in old code since the physical addresses

	 * provided by the dma subsystem were page aligned, which was also the

	 * MTT size.

 A new block is started ... */

		/*

		 * Be friendly to mlx4_write_mtt() and pass it chunks of

		 * appropriate size.

	/* Check whether the alignment of the new block is aligned as well as

	 * the previous block.

	 * Block address must start with zeros till size of entity_size.

		/*

		 * It is not as well aligned as the previous block-reduce the

		 * mtt size accordingly. Here we take the last right bit which

		 * is 1.

	/*

	 * Check whether the alignment of the end of previous block - is it

	 * aligned as well as the start of the block

		/*

		 * It is not as well aligned as the start of the block -

		 * reduce the mtt size accordingly.

 still the same block */

		/*

		 * A new block is started ...

		 * If len is malaligned, write an extra mtt entry to cover the

		 * misaligned area (round up the division)

 Handle the last block */

		/*

		 * If len is malaligned, write an extra mtt entry to cover

		 * the misaligned area (round up the division)

/*

 * Calculate optimal mtt size based on contiguous pages.

 * Function will return also the number of pages that are not aligned to the

 * calculated mtt_size to be added to total number of pages. For that we should

 * check the first chunk length & last chunk length and if not aligned to

 * mtt_size we should increment the non_aligned_pages number. All chunks in the

 * middle already handled as part of mtt shift calculation for both their start

 * & end addresses.

		/*

		 * Initialization - save the first chunk start as the

		 * current_block_start - block means contiguous pages.

			/*

			 * Find the bits that are different between the physical

			 * address and the virtual address for the start of the

			 * MR.

			 * umem_get aligned the start_va to a page boundary.

			 * Therefore, we need to align the start va to the same

			 * boundary.

			 * misalignment_bits is needed to handle the  case of a

			 * single memory region. In this case, the rest of the

			 * logic will not reduce the block size.  If we use a

			 * block size which is bigger than the alignment of the

			 * misalignment bits, we might use the virtual page

			 * number instead of the physical page number, resulting

			 * in access to the wrong data.

		/*

		 * Go over the scatter entries and check if they continue the

		 * previous scatter entry.

 If we have a split (non-contig.) between two blocks */

			/*

			 * If we reached the minimum shift for 4k page we stop

			 * the loop.

			/*

			 * If not saved yet we are in first block - we save the

			 * length of first block to calculate the

			 * non_aligned_pages number at the end.

 Start a new block */

		/* The scatter entry is another part of the current block,

		 * increase the block size.

		 * An entry in the scatter can be larger than 4k (page) as of

		 * dma mapping which merge some blocks together.

 Account for the last block in the total len */

 Add to the first block the misalignment that it suffers from. */

		/*

		 * If shift is less than the min we set a warning and return the

		 * min shift.

	/*

	 * Force registering the memory as writable if the underlying pages

	 * are writable.  This is so rereg can change the access permissions

	 * from readable to writable without having to run through ib_umem_get

	 * again

		/*

		 * FIXME: Ideally this would iterate over all the vmas that

		 * cover the memory, but for now it requires a single vma to

		 * entirely cover the MR to support RO mappings.

	/* Since we synchronize this call and mlx4_ib_dereg_mr via uverbs,

	 * we assume that the calls can't run concurrently. Otherwise, a

	 * race exists.

 Prevent mlx4_ib_dereg_mr from free'ing invalid pointer */

	/* If we couldn't transfer the MR to the HCA, just remember to

	 * return a failure. But dereg_mr will free the resources.

	/* Ensure that size is aligned to DMA cacheline

	 * requirements.

	 * max_pages is limited to MLX4_MAX_FAST_REG_PAGES

	 * so page_map_size will never cross PAGE_SIZE.

 Prevent cross page boundary allocation. */

/*

 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Port mgmt change event handling */

 size in bytes */

	/*

	 * Key check traps can't be generated unless we have in_wc to

	 * tell us where to send the trap.

/*

 * Snoop SM MADs for port info, GUID info, and  P_Key table sets, so we can

 * synthesize LID change, Client-Rereg, GID change, and P_Key change events.

			/* at this point, we are running in the master.

			 * Slaves do not receive SMPs.

 paravirtualized master's guid is guid 0 -- does not change */

if master, notify relevant slaves*/

			/* cache sl to vl mapping changes for use in

			 * filling QP1 LRH VL field when sending packets

		/*

		 * We rely here on the fact that MLX QPs don't use the

		 * address handle after the send is posted (this is

		 * wrong following the IB spec strictly, but we know

		 * it's OK for our devices).

 dispatch to different sa handlers */

 take first partial pkey index found */

 check if proxy qp created */

 compute P_Key index to put in tunnel header for slave */

 get tunnel tx data buf for slave */

	/* create ah. Just need an empty one with the port num for the post send.

 allocate tunnel tx buf after pass failure returns */

 copy over to tunnel buffer */

 adjust tunnel data */

 VST mode */

				/* Packet vlan is not the VST-assigned vlan.

				 * Drop the packet.

				/* Remove the vlan tag before forwarding

				 * the packet to the VF.

 Initially assume that this mad is for us */

 See if the slave id is encoded in a response mad */

255 indicates the dom0*/

 remap tid */

 If a grh is present, we demux according to it */

 Class-specific handling */

 255 indicates the dom0 */

 for a VF. drop unsolicited MADs */

 Drop unsupported classes for slaves in tunnel mode */

make sure that no slave==255 was not handled yet.*/

		/*

		 * Don't process SMInfo queries -- the SMA can't handle them.

 slaves get node desc from FW */

 set return bit in status of directed route responses */

 no response for trap repress */

	/* iboe_process_mad() which uses the HCA flow-counters to implement IB PMA

	 * queries, should be called only by VFs and for that specific purpose

 re-configure the alias-guid and mcg's */

	/* Update the sl to vl table from inside client rereg

	 * only if in secure-host mode (snooping is not possible)

	 * and the sl-to-vl change event is not generated by FW.

			/* already in work queue from mlx4_ib_event queueing

			 * mlx4_handle_port_mgmt_change_event, which calls

			 * this procedure. Therefore, call sl2vl_update directly.

		/* Update the SM ah - This should be done before handling

 Check if it is a lid change event */

 Generate GUID changed event */

if master, notify all slaves*/

 paravirtualized master's guid is guid 0 -- does not change */

if master, notify relevant slaves*/

		/* cache sl to vl mapping changes for use in

		 * filling QP1 LRH VL field when sending packets

 dispatch to different sa handlers */

 check if proxy qp created */

 create ah */

 Get slave that sent this packet */

 Map transaction ID */

 nothing */;

 Class-specific handling */

 Drop unsupported classes for slaves in tunnel mode */

	/* We are using standard ib_core services to send the mad, so generate a

 if slave have default vlan use it */

 It's worse than that! He's dead, Jim! */

/*

 * IB MAD completion callback for real SQPs

 have QP0 only if link layer is IB */

 for master, destroy real sqp resources */

 destroy the tunnel qp resources */

 create the tunnel qp resources */

 for master, create the real sqp resources */

 initialize or tear down tunnel QPs for the master */

/*

 * Copyright (c) 2006, 2007 Cisco Systems, Inc. All rights reserved.

 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 HW has space */

 Check if extended speeds (EDR/FDR/...) are supported */

 If reported active speed is QDR, check if is FDR-10 */

 Checking LinkSpeedActive for FDR-10 */

 Avoid wrong speed value returned by FW if the IB link is down. */

56Gb*/) ?

56Gb*/) ?

 required to get upper dev */

 props being zeroed by the caller, avoid zeroing it here */

 returns host view */

 For any index > 0, return the null guid */

	/*

	 * If possible, pass node desc to FW, so it can generate

	 * a 144 trap.  If cmd fails, just ignore.

	/* return OK if this is RoCE. CM calls ib_modify_port() regardless

	 * of whether port link layer is ETH or IB. For ETH ports, qkey

	 * violations and port capabilities are not meaningful.

 Field is the last supported field */

 we assume the specs are sorted */

 same layer but different type */

 same layer, try match next one */

 same layer and same type */

 no rule */

 invalid rule */

 We must put empty rule, qpn is being ignored */

 Add default flows */

 do nothing */

 do nothing */

 if all is zero than MC and UC */

			/* Above xor was only on MC bit, non empty mask is valid

			 * only if this bit is set and rest are zero.

		/* If dont trap flag (continue match) is set, under specific

		 * condition traffic be replicated to given qp,

		 * without stealing it

			/* Application always sees one port so the mirror rule

			 * must be on port #2

 function to create mirror rule */

		/*

		 * i == 1 means we are building port counters, set a different

		 * stats ops without port stats callback.

 no need for update QP1 and mac registration in non-SRIOV */

 if old port was zero, no mac was yet registered for this QP */

 master has the identity virt2phys pkey mapping */

 initialize pkey cache */

 Advertise the new number of EQs to clients */

 no eqs were allocated */

 Reset the advertised EQ number */

 No point in registering a device with no ports... */

 if failed to allocate a new counter, use default */

 IB_LINK_LAYER_INFINIBAND use the default counter */

 create paravirt contexts for any VFs which are active */

 not supposed to be here */

 Add an empty rule for IB L2 */

 initialize or tear down tunnel QPs for the slave */

 Go over qp list reside on that ibdev, sync with create/destroy qp.*/

 Now, handle the QP's receive queue */

 no handling is needed for SRQ */

 need to queue only for port owner, which uses GEN_EQE */

 here, p is the slave id */

 here, p is the slave id */

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

 0th UAR is taken by the device. */

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

  Initialize some device related stuff */

 Check if SRQ is supported by backend */

 Legacy intr */

 1:1 mapping for now. */

 1:1 mapping for now. */

 1:1 mapping for now. */

	/*

	 * Don't process events until the IB device is registered. Otherwise

	 * we'll try to ib_dispatch_event() on an invalid device.

 Update sgid table. */

 vmxnet3 will have same bus, slot. But func will be 0 */

 this is our netdev */

 Allocate zero-out device */

 Enable 64-Bit DMA */

 Map register space */

 Setup per-device UAR. */

 Setup the shared region */

 Command slot. */

 Response slot. */

 Async event ring */

 CQ notification ring */

	/*

	 * Write the PA of the shared region to the device. The writes must be

	 * ordered such that the high bits are written last. When the writes

	 * complete, the device will have filled out the capabilities.

 Make sure the write is complete before reading status. */

 The driver supports RoCE V1 and V2. */

 Paired vmxnet3 will have same bus, slot. But func will be 0 */

 Interrupt setup */

 Allocate UAR table. */

 Allocate GID table */

 Activate pvrdma device */

 Make sure the write is complete before reading status. */

 Check if device was successfully activated */

 Register IB device */

 Unregister ib device */

 Deactivate pvrdma device */

 Free pci resources */

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

 ms */

 Serializiation */

 Make sure the request is written before reading status. */

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

 Clean up cqes */

	/*

	 * Reset queuepair. The checks are because usermode queuepairs won't

	 * have kernel ringstates.

 Write back */

 Write back */

 Note: one extra page for the header. */

/**

 * pvrdma_create_qp - create queue pair

 * @ibqp: queue pair

 * @init_attr: queue pair attributes

 * @udata: user data

 *

 * @return: the 0 on success, otherwise returns an errno.

 Userspace supports qpn and qp handles? */

 set qp->sq.wqe_cnt, shift, buf_size.. */

 Skip header page. */

 Recv queue pages are after send pages. */

 Ring state is always the first page. */

 Not supported */

 max_send_wr/_recv_wr/_send_sge/_recv_sge/_inline_data */

 In case cq is polling */

	/*

	 * We're now unlocking the CQs before clearing out the qp handle this

	 * should still be safe. We have destroyed the backend QP and flushed

	 * the CQEs so there should be no other completions for this QP.

/**

 * pvrdma_destroy_qp - destroy a queue pair

 * @qp: the queue pair to destroy

 * @udata: user data or null for kernel object

 *

 * @return: always 0.

/**

 * pvrdma_modify_qp - modify queue pair attributes

 * @ibqp: the queue pair

 * @attr: the new queue pair's attributes

 * @attr_mask: attributes mask

 * @udata: user data

 *

 * @returns 0 on success, otherwise returns an errno.

 Sanity checking. Should need lock here */

/**

 * pvrdma_post_send - post send work request entries on a QP

 * @ibqp: the QP

 * @wr: work request list to post

 * @bad_wr: the first bad WR returned

 *

 * @return: 0 on success, otherwise errno returned.

	/*

	 * In states lower than RTS, we can fail immediately. In other states,

	 * just post and let the device figure it out.

		/*

		 * Only support UD, RC.

		 * Need to check opcode table for thorough checking.

		 * opcode		_UD	_UC	_RC

		 * _SEND		x	x	x

		 * _SEND_WITH_IMM	x	x	x

		 * _RDMA_WRITE			x	x

		 * _RDMA_WRITE_WITH_IMM		x	x

		 * _LOCAL_INV			x	x

		 * _SEND_WITH_INV		x	x

		 * _RDMA_READ				x

		 * _ATOMIC_CMP_AND_SWP			x

		 * _ATOMIC_FETCH_AND_ADD		x

		 * _MASK_ATOMIC_CMP_AND_SWP		x

		 * _MASK_ATOMIC_FETCH_AND_ADD		x

		 * _REG_MR				x

		 *

			/*

			 * Use qkey from qp context if high order bit set,

			 * otherwise from work request.

 Need to check wqe_size 0 or max size */

 Make sure wqe is written before index update */

 Update shared sq ring */

/**

 * pvrdma_post_recv - post receive work request entries on a QP

 * @ibqp: the QP

 * @wr: the work request list to post

 * @bad_wr: the first bad WR returned

 *

 * @return: 0 on success, otherwise errno returned.

	/*

	 * In the RESET state, we can fail immediately. For other states,

	 * just post and let the device figure it out.

 Make sure wqe is written before index update */

 Update shared rq ring */

/**

 * pvrdma_query_qp - query a queue pair's attributes

 * @ibqp: the queue pair to query

 * @attr: the queue pair's attributes

 * @attr_mask: attributes mask

 * @init_attr: initial queue pair attributes

 *

 * @returns 0 on success, otherwise returns an errno.

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

/**

 * pvrdma_req_notify_cq - request notification for a completion queue

 * @ibcq: the completion queue

 * @notify_flags: notification flags

 *

 * @return: 0 for success.

/**

 * pvrdma_create_cq - create completion queue

 * @ibcq: Allocated CQ

 * @attr: completion queue attributes

 * @udata: user data

 *

 * @return: 0 on success

 One extra page for shared ring state */

 Skip header page. */

 Ring state is always the first page. Set in library for user cq. */

 Copy udata back. */

/**

 * pvrdma_destroy_cq - destroy completion queue

 * @cq: the completion queue to destroy.

 * @udata: user data or null for kernel object

 free cq's resources */

 Lock held */

 Ensure cqe is valid. */

 Update shared ring state */

/**

 * pvrdma_poll_cq - poll for work completion queue entries

 * @ibcq: completion queue

 * @num_entries: the maximum number of entries

 * @wc: pointer to work completion array

 *

 * @return: number of polled completion entries

 Ensure we do not return errors from poll_cq */

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

/**

 * pvrdma_query_device - query device

 * @ibdev: the device to query

 * @props: the device properties

 * @uhw: user data

 *

 * @return: 0 on success, otherwise negative errno

/**

 * pvrdma_query_port - query device port attributes

 * @ibdev: the device to query

 * @port: the port number

 * @props: the device properties

 *

 * @return: 0 on success, otherwise negative errno

 props being zeroed by the caller, avoid zeroing it here */

/**

 * pvrdma_query_gid - query device gid

 * @ibdev: the device to query

 * @port: the port number

 * @index: the index

 * @gid: the device gid value

 *

 * @return: 0 on success, otherwise negative errno

/**

 * pvrdma_query_pkey - query device port's P_Key table

 * @ibdev: the device to query

 * @port: the port number

 * @index: the index

 * @pkey: the device P_Key value

 *

 * @return: 0 on success, otherwise negative errno

/**

 * pvrdma_modify_port - modify device port attributes

 * @ibdev: the device to modify

 * @port: the port number

 * @mask: attributes to modify

 * @props: the device properties

 *

 * @return: 0 on success, otherwise negative errno

/**

 * pvrdma_alloc_ucontext - allocate ucontext

 * @uctx: the uverbs countext

 * @udata: user data

 *

 * @return:  zero on success, otherwise errno.

 get ctx_handle from host */

 copy back to user */

/**

 * pvrdma_dealloc_ucontext - deallocate ucontext

 * @ibcontext: the ucontext

 Free the UAR even if the device command failed */

/**

 * pvrdma_mmap - create mmap region

 * @ibcontext: the user context

 * @vma: the VMA

 *

 * @return: 0 on success, otherwise errno.

 Map UAR to kernel space, VM_LOCKED? */

/**

 * pvrdma_alloc_pd - allocate protection domain

 * @ibpd: PD pointer

 * @udata: user data

 *

 * @return: the ib_pd protection domain pointer on success, otherwise errno.

 Check allowed max pds */

 u32 pd handle */

/**

 * pvrdma_dealloc_pd - deallocate protection domain

 * @pd: the protection domain to be released

 * @udata: user data or null for kernel object

 *

 * @return: Always 0

/**

 * pvrdma_create_ah - create an address handle

 * @ibah: the IB address handle

 * @init_attr: the attributes of the AH

 * @udata: pointer to user data

 *

 * @return: 0 on success, otherwise errno.

/**

 * pvrdma_destroy_ah - destroy an address handle

 * @ah: the address handle to destroyed

 * @flags: destroy address handle flags (see enum rdma_destroy_ah_flags)

 *

/*

 * Copyright (c) 2016-2017 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

/**

 * pvrdma_query_srq - query shared receive queue

 * @ibsrq: the shared receive queue to query

 * @srq_attr: attributes to query and return to client

 *

 * @return: 0 for success, otherwise returns an errno.

/**

 * pvrdma_create_srq - create shared receive queue

 * @ibsrq: the IB shared receive queue

 * @init_attr: shared receive queue attributes

 * @udata: user data

 *

 * @return: 0 on success, otherwise returns an errno.

 No support for kernel clients. */

 Copy udata back. */

 There is no support for kernel clients, so this is safe. */

/**

 * pvrdma_destroy_srq - destroy shared receive queue

 * @srq: the shared receive queue to destroy

 * @udata: user data or null for kernel object

 *

 * @return: 0 for success.

/**

 * pvrdma_modify_srq - modify shared receive queue attributes

 * @ibsrq: the shared receive queue to modify

 * @attr: the shared receive queue's new attributes

 * @attr_mask: attributes mask

 * @udata: user data

 *

 * @returns 0 on success, otherwise returns an errno.

 Only support SRQ limit. */

/*

 * Copyright (c) 2012-2016 VMware, Inc.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of EITHER the GNU General Public License

 * version 2 as published by the Free Software Foundation or the BSD

 * 2-Clause License. This program is distributed in the hope that it

 * will be useful, but WITHOUT ANY WARRANTY; WITHOUT EVEN THE IMPLIED

 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.

 * See the GNU General Public License version 2 for more details at

 * http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program available in the file COPYING in the main

 * directory of this source tree.

 *

 * The BSD 2-Clause License

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS

 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT

 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS

 * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE

 * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,

 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR

 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,

 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)

 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED

 * OF THE POSSIBILITY OF SUCH DAMAGE.

/**

 * pvrdma_get_dma_mr - get a DMA memory region

 * @pd: protection domain

 * @acc: access flags

 *

 * @return: ib_mr pointer on success, otherwise returns an errno.

 Support only LOCAL_WRITE flag for DMA MRs */

/**

 * pvrdma_reg_user_mr - register a userspace memory region

 * @pd: protection domain

 * @start: starting address

 * @length: length of region

 * @virt_addr: I/O virtual address

 * @access_flags: access flags for memory region

 * @udata: user data

 *

 * @return: ib_mr pointer on success, otherwise returns an errno.

/**

 * pvrdma_alloc_mr - allocate a memory region

 * @pd: protection domain

 * @mr_type: type of memory region

 * @max_num_sg: maximum number of pages

 *

 * @return: ib_mr pointer on success, otherwise returns an errno.

/**

 * pvrdma_dereg_mr - deregister a memory region

 * @ibmr: memory region

 * @udata: pointer to user data

 *

 * @return: 0 on success.

/* This file is part of the Emulex RoCE Device Driver for

 * RoCE (RDMA over Converged Ethernet) adapters.

 * Copyright (C) 2012-2015 Emulex. All rights reserved.

 * EMULEX and SLI are trademarks of Emulex.

 * www.emulex.com

 *

 * This software is available to you under a choice of one of two licenses.

 * You may choose to be licensed under the terms of the GNU General Public

 * License (GPL) Version 2, available from the file COPYING in the main

 * directory of this source tree, or the BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * - Redistributions of source code must retain the above copyright notice,

 *   this list of conditions and the following disclaimer.

 *

 * - Redistributions in binary form must reproduce the above copyright

 *   notice, this list of conditions and the following disclaimer in

 *   the documentation and/or other materials provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR

 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF

 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Contact Information:

 * linux-drivers@emulex.com

 *

 * Emulex

 * 3333 Susan Street

 * Costa Mesa, CA 92626

 Alloc mbox command mem*/

 Alloc debugfs mem */

 Print the threshold stats */

 update */

 Update PD counters from PD resource manager */

 Threshold stata*/

 No partial reads */

 Create post stats base dir */

 Create base dir in debugfs root dir */

/* This file is part of the Emulex RoCE Device Driver for

 * RoCE (RDMA over Converged Ethernet) adapters.

 * Copyright (C) 2012-2015 Emulex. All rights reserved.

 * EMULEX and SLI are trademarks of Emulex.

 * www.emulex.com

 *

 * This software is available to you under a choice of one of two licenses.

 * You may choose to be licensed under the terms of the GNU General Public

 * License (GPL) Version 2, available from the file COPYING in the main

 * directory of this source tree, or the BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * - Redistributions of source code must retain the above copyright notice,

 *   this list of conditions and the following disclaimer.

 *

 * - Redistributions in binary form must reproduce the above copyright

 *   notice, this list of conditions and the following disclaimer in

 *   the documentation and/or other materials provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR

 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF

 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Contact Information:

 * linux-drivers@emulex.com

 *

 * Emulex

 * 3333 Susan Street

 * Costa Mesa, CA 92626

 Unsupported */

 props being zeroed by the caller, avoid zeroing it here */

 try allocating DPP PD, if not available then normal PD */

/*

 * NOTE:

 *

 * ocrdma_ucontext must be used here because this function is also

 * called from ocrdma_alloc_ucontext where ib_udata does not have

 * valid ib_ucontext pointer. ib_uverbs_get_context does not call

 * uobj_{alloc|get_xxx} helpers which are used to store the

 * ib_ucontext in uverbs_attr_bundle wrapping the ib_udata. so

 * ib_udata does NOT imply valid ib_ucontext here!

 store the page address in pbe */

		/* if the given pbl is full storing the pbes,

		 * move to next pbl.

 it could be user registered memory. */

 Don't stop cleanup, in case FW is unresponsive */

 this must be user flow! */

	/* Last irq might have scheduled a polling thread

	 * sync-up with it before hard flushing.

 Skip the check for QP1 to support CM size of 128 */

 unprivileged user space cannot create special QP */

 allow creating only one GSI type of QP */

 verify consumer QPs are not trying to use GSI QP's CQ */

 user space QP's wr_id table are managed in library */

	/* if new and previous states are same hw doesn't need to

	 * know about it.

 syncronize with multiple context trying to change, retrive qps */

 syncronize with wqe, rqe posting and cqe processing contexts */

 Sync driver QP state with FW */

 discard the cqe for a given QP */

	/* traverse through the CQEs in the hw CQ,

	 * find the matching CQE for a given qp,

	 * mark the matching one discarded by clearing qpn.

	 * ring the doorbell in the poll_cq() as

	 * we don't complete out of order cqe.

 find upto when do we reap the cq. */

		/* if (a) done reaping whole hw cq, or

		 *    (b) qp_xq becomes empty.

		 * then exit

 if previously discarded cqe found, skip that too. */

 check for matching qp */

		/* mark cqe discarded so that it is not picked up later

		 * in the poll_cq().

 sync with any active CQ poll */

 change the QP state to ERROR */

	/* ensure that CQEs for newly created QP (whose id may be same with

	 * one which just getting destroyed are same), dont get

	 * discarded until the old CQEs are discarded.

	/*

	 * acquire CQ lock while destroy is in progress, in order to

	 * protect against proessing in-flight CQEs for this QP.

 unprivileged verbs and their support functions. */

 Max size is 256M 4096 << 16 */

		/* if the pbl is full storing the pbes,

		 * move to next pbl.

 make sure wqe is written before adapter can access it */

 inform hw to start processing it */

 update pointer, counter for next wr */

 make sure rqe is written before adapter can access it */

 inform hw to start processing it */

 update pointer, counter for next wr */

/* cqe for srq's rqe can potentially arrive out of order.

 * index gives the entry in the shadow table where to store

 * the wr_id. tag/index is returned in cqe to reference back

 * for a given rqe.

 Use from index 1 */

 make sure rqe is written before adapter can perform DMA */

 inform hw to start processing it */

 update pointer, counter for next wr */

 Undo the hdr->cw swap */

	/* if wqe/rqe pending for which cqe needs to be returned,

	 * trigger inflating it.

	/* when hw sq is empty, but rq is not empty, so we continue

	 * to keep the cqe in order to get the cq event again.

		/* when cq for rq and sq is same, it is safe to return

		 * flush cqe for RQEs.

			/* stop processing further cqe as this cqe is used for

			 * triggering cq event on buddy cq of RQ.

			 * When QP is destroyed, this cqe will be removed

			 * from the cq's hardware q.

 Do nothing */

 WC cannot be consumed yet */

 Coalesced CQE can't be consumed yet */

	/* when hw_rq is empty, but wq is not empty, so continue

	 * to keep the cqe to get the cq event again.

 Do nothing */

 clear valid bit */

 check whether valid cqe or not */

 ignore discarded cqe */

 clear qpn to avoid duplicate processing by discard_cqe() */

 insert error cqe if the QP's SQ or RQ's CQ matches the CQ under poll. */

 poll cqes from adapter CQ */

		/* adapter returns single error cqe when qp moves to

		 * error state. So insert error cqes with wc_status as

		 * FLUSHED for pending WQEs and RQEs of QP's SQ and RQ

		 * respectively which uses this CQ.

/* This file is part of the Emulex RoCE Device Driver for

 * RoCE (RDMA over Converged Ethernet) adapters.

 * Copyright (C) 2012-2015 Emulex. All rights reserved.

 * EMULEX and SLI are trademarks of Emulex.

 * www.emulex.com

 *

 * This software is available to you under a choice of one of two licenses.

 * You may choose to be licensed under the terms of the GNU General Public

 * License (GPL) Version 2, available from the file COPYING in the main

 * directory of this source tree, or the BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * - Redistributions of source code must retain the above copyright notice,

 *   this list of conditions and the following disclaimer.

 *

 * - Redistributions in binary form must reproduce the above copyright

 *   notice, this list of conditions and the following disclaimer in

 *   the documentation and/or other materials provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR

 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF

 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Contact Information:

 * linux-drivers@emulex.com

 *

 * Emulex

 * 3333 Susan Street

 * Costa Mesa, CA 92626

 seconds */

	/* disarm EQ so that interrupts are not generated

	 * during freeing and EQ delete is in progress.

 log2(len) + 1 */

 Request link events on this  MQ. */

 Alloc completion queue for Mailbox queue */

 Alloc Mailbox queue */

 mqe_ctx lock synchronizes with any other pending cmds. */

	/*

	 * Some FW version returns wrong qp or cq ids in CQEs.

	 * Checking whether the IDs are valid

 Not interested evts. */

 async CQE processing */

		/* if wq and rq share the same cq, than comp_handler

		 * is already invoked.

		/* if completion came on sq, rq's cq is buddy cq.

		 * if completion came on rq, sq's cq is buddy cq.

	/* Go through list of QPs in error state which are using this CQ

	 * and invoke its callback handler to trigger CQE processing for

	 * error/flushed CQE. It is rare to find more than few entries in

	 * this list as most consumers stops after getting error CQE.

	 * List is traversed only once when a matching buddy cq found for a QP.

	/* Check if buddy CQ is present.

	 * true - Check for  SQ CQ

	 * false - Check for RQ CQ

 if there is valid buddy cq, look for its completion handler */

 process the MQ-CQE. */

 ring eq doorbell as soon as its consumed. */

 check whether its CQE or not. */

		/* There can be a stale EQE after the last bound CQ is

		 * destroyed. EQE valid and budget == 0 implies this.

 make sure descriptor is written before ringing doorbell */

 30 sec timeout */

 issue a mailbox command on the MQ */

 This is for embedded cmds. */

 For non embedded, rsp errors are handled in ocrdma_nonemb_mbx_cmd */

		/* For non embedded, only CQE failures are handled in

		 * ocrdma_mbx_cmd. We need to check for RSP errors.

 can be issued only during init time. */

 can be issued only during init time. */

 Cache the old stats */

 Copy from cache, if mbox fails */

 Pre allocate the DPP PDs */

 Enable PD resource manager */

 return normal PDs to firmware */

 return DPP PDs to firmware */

 find the possible lowest possible multiplier */

 number of PBEs in PBL */

 page size */

 ah_entry size */

/* Multiple CQs uses the EQ. This routine returns least used

 * EQ to associate with CQ. This will distributes the interrupt

 * processing and CPU load to associated EQ, vector and so to that CPU.

	/* find the EQ which is has the least number of

	 * CQs associated with it.

 Set cnt to 3 to indicate more than 1024 cq entries */

 shared eq between all the consumer cqs. */

 pd_id valid only for v3 */

 if there is no more pbls to register then exit. */

		/* if we reach the end of the pbls, then need to set the last

		 * bit, indicating no more pbls to register for this memory key.

 sync with wqe and rqe posting */

 QP1 may exceed 127 */

 GIDs */

 convert them to LE format. */

 set the default mac address for UD, GSI QPs */

 one eq is sufficient for data path to work */

 create the eqs  */

 cleanup the control path */

 cleanup the eqs */

/* This file is part of the Emulex RoCE Device Driver for

 * RoCE (RDMA over Converged Ethernet) adapters.

 * Copyright (C) 2012-2015 Emulex. All rights reserved.

 * EMULEX and SLI are trademarks of Emulex.

 * www.emulex.com

 *

 * This software is available to you under a choice of one of two licenses.

 * You may choose to be licensed under the terms of the GNU General Public

 * License (GPL) Version 2, available from the file COPYING in the main

 * directory of this source tree, or the BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * - Redistributions of source code must retain the above copyright notice,

 *   this list of conditions and the following disclaimer.

 *

 * - Redistributions in binary form must reproduce the above copyright

 *   notice, this list of conditions and the following disclaimer in

 *   the documentation and/or other materials provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR

 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF

 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Contact Information:

 * linux-drivers@emulex.com

 *

 * Emulex

 * 3333 Susan Street

 * Costa Mesa, CA 92626

 OCRDMA sysfs interface */

 mandatory to support user space verbs consumer. */

 Query Link state and update */

 Init stats */

 Interrupt Moderation */

	/* first unregister with stack to stop all the active traffic

	 * of the registered clients.

/* event handling via NIC driver ensures that all the NIC specific

 * initialization done before RoCE driver notifies

 * event to stack.

/* This file is part of the Emulex RoCE Device Driver for

 * RoCE (RDMA over Converged Ethernet) adapters.

 * Copyright (C) 2012-2015 Emulex. All rights reserved.

 * EMULEX and SLI are trademarks of Emulex.

 * www.emulex.com

 *

 * This software is available to you under a choice of one of two licenses.

 * You may choose to be licensed under the terms of the GNU General Public

 * License (GPL) Version 2, available from the file COPYING in the main

 * directory of this source tree, or the BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * - Redistributions of source code must retain the above copyright notice,

 *   this list of conditions and the following disclaimer.

 *

 * - Redistributions in binary form must reproduce the above copyright

 *   notice, this list of conditions and the following disclaimer in

 *   the documentation and/or other materials provided with the distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE

 * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR

 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF

 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Contact Information:

 * linux-drivers@emulex.com

 *

 * Emulex

 * 3333 Susan Street

 * Costa Mesa, CA 92626

 Protocol Number */

 VLAN */

 MAC */

 Eth HDR */

 Get network header type for this GID */

 if pd is for the user process, pass the ah_id to user space */

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

	/*

	 * The QP res chunk, used to derive qp indices,

	 * are just indices of the RQs

 Reserve Port */

 Create Flow */

 Create Flow Handle */

 Get and check socket */

 Create flow */

 Create qp_flow */

 NO-OP */

				/*

				 * Optional to specify filters.

				/*

				 * Doesn't make sense to go into INIT state

				 * from INIT state w/o adding filters.

 NO-OP FOR NOW */

 Do Nothing */

		/*

		 * Copy port_num to stack first and then to *id,

		 * so that the short to int cast works for little

		 * and big endian systems.

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 * Author: Upinder Malhi <umalhi@cisco.com>

 * Author: Anant Deepak <anadeepa@cisco.com>

 * Author: Cesare Cantu' <cantuc@cisco.com>

 * Author: Jeff Squyres <jsquyres@cisco.com>

 * Author: Kiran Thirumalai <kithirum@cisco.com>

 * Author: Xuyang Wang <xuywang@cisco.com>

 * Author: Reese Faucette <rfaucett@cisco.com>

 *

 Callback dump funcs */

 End callback dump funcs */

 Start of netdev section */

 End of netdev section */

 Start of inet section */

 End of inet section*/

 Start of PF discovery section */

 End of PF discovery section */

 Start of PCI section */

	/*

	 * Save max settings (will be same for each VF, easier to re-write than

	 * to say "if (!set) { set_values(); set=1; }

 PCI driver entry points */

 End of PCI section */

 Start of module section */

 End of module section */

/*

 * Copyright (c) 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2013 Cisco Systems.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * If the combination of the addr and size requested for this memory

	 * region causes an integer overflow, return error.

 Workaround for RH 970401 */

 First page of the interval */

 PAs are not contiguous */

 Last page of the interval */

			/*

			 * Hit last entry of the chunk,

			 * hence advance to next chunk

	/*

	 * Intel IOMMU map throws an error if a translation entry is

	 * changed from read to write.  This module may not unmap

	 * and then remap the entry after fixing the permission

	 * b/c this open up a small windows where hw DMA may page fault

	 * Hence, make all entries to be writable.

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

USNIC_TRANSPORT_UNKNOWN*/

USNIC_TRANSPORT_ROCE_CUSTOM*/

USNIC_TRANSPORT_IPV4_UDP*/

 Try to find resouces on a used vf which is in pd */

 Try to find resources on an unused vf */

 Start of ib callback functions */

	/* Owned by Userspace

	/*

	 * usdev_lock is acquired after (and not before) ib_get_eth_speed call

	 * because acquiring rtnl_lock in ib_get_eth_speed, while holding

	 * usdev_lock could lead to a deadlock.

 props being zeroed by the caller, avoid zeroing it here */

 Userspace will adjust for hdrs */

 usnic devices only have one port */

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 Issue Devcmd */

		/*

		 * Log the error and fake success to the caller because if

		 * a flow fails to be deleted in the firmware, it is an

		 * unrecoverable error.

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

/*

 * Report the configuration for this PF

		/*

		 * bus name seems to come with annoying prefix.

		 * Remove it if it is predictable

/*

 * Definitions for supporting QPN entries in sysfs

 create kernel object for looking at individual QPs */

/*

 * Copyright (c) 2014, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 long to int */

		/*

		 * Invariant: Set [start, pivot] is either in diff_set or root,

		 * but not in both.

		/*

		 * Invariant - lpivot is the left edge of next interval to be

		 * inserted

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 ROCE */

CHAR_BIT*/ * sizeof(u16)))/8 
/*

 * reserve a port number.  if "0" specified, we will try to pick one

 * starting at roce_next_port.  roce_next_port will take on the values

 * 1..4096

 start */,

 nr */,

 align */);

 sockfd_lookup will internally do a fget */

 Do not ever allocate bit 0, hence set it here */

/*

 * Copyright (c) 2013, Cisco Systems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

/*

 * Copyright (c) 2009-2010 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * uP clears EQ contexts when the connection exits rdma mode,

	 * so no need to post a RESET WR for these EQs.

/*

 * Determine the BAR2 virtual address and qid. If pbar2_pa is not NULL,

 * then this is a user mapping so compute the page-aligned physical address

 * for mapping.

FIXME

		/*

		 * RQT must be a power of 2 and at least 16 deep.

	/*

	 * User mode must have bar2 access.

 build fw_ri_res_wr */

	/*

	 * eqsize is the number of 64B entries plus the status page size.

 no host cidx updates */

 don't keep in chip cache */

 set by uP at ri_init time */

		/*

		 * eqsize is the number of 64B entries plus the status page size

 no host cidx updates */

 don't keep in chip cache */

 set by uP at ri_init time */

	/*

	 * iWARP protocol supports 64 bit immediate data but rdma api

	 * limits it to 32bit.

	/*

	 * This code assumes the struct fields preceding the write isgl

	 * fit in one 64B WR slot.  This is because the WQE is built

	 * directly in the dma queue, and wrapping is only handled

	 * by the code buildling sgls.  IE the "fixed part" of the wr

	 * structs must all fit in 64B.  The WQE build code should probably be

	 * redesigned to avoid this restriction, but for now just add

	 * the BUILD_BUG_ON() to catch if this WQE struct gets too big.

 SEND_INV SGL */

 WRITE SGL */

	/*

	 * The sw_sq entries still look like a WRITE and a SEND and consume

	 * 2 slots. The FW WR, however, will be a single uber-WR.

 WRITE swsqe */

 just bump the sw_sq */

 SEND_WITH_INV swsqe */

	/*

	 * If the qp has been flushed, then just insert a special

	 * drain cqe.

	/*

	 * Fastpath for NVMe-oF target WRITE + SEND_WITH_INV wr chain which is

	 * the response for small NVMEe-oF READ requests.  If the chain is

	 * exactly a WRITE->SEND_WITH_INV or a WRITE->SEND and the sgl depths

	 * and lengths meet the requirements of the fw_ri_write_cmpl_wr work

	 * request, then build and post the write_cmpl WR. If any of the tests

	 * below are not true, then we continue on with the tradtional WRITE

	 * and SEND WRs.

	/*

	 * If the qp has been flushed, then just insert a special

	 * drain cqe.

/*

 * Assumes qhp lock is held.

 locking hierarchy: cqs lock first, then qp lock. */

 for user qps, qhp->wq.flushed is protected by qhp->mutex */

 Process attr changes if in IDLE */

			/*

			 * Ref the endpoint here and deref when we

			 * disassociate the endpoint from the QP.  This

			 * happens in CLOSING->IDLE transition or *->ERROR

			 * transition.

		/*

		 * Allow kernel users to move to ERROR for qp draining.

 disassociate the LLP connection */

	/*

	 * If disconnect is 1, then we need to initiate a disconnect

	 * on the EP.  This can be a normal close (RTS->CLOSING) or

	 * an abnormal close (RTS/CLOSING->ERROR).

	/*

	 * If free is 1, then we've disassociated the EP from the QP

	 * and we need to dereference the EP.

 iwarp does not support the RTR state */

 Make sure we still have something left to do */

	/*

	 * Use SQ_PSN and RQ_PSN to pass in IDX_INC values for

	 * ringing the queue db when we're in DB_FULL mode.

	 * Only allow this on T4 devices.

	/*

	 * XXX 0 mask == a SW interrupt for srq_limit reached...

 no support for this yet */

	/*

	 * User mode must have bar2 access.

 build fw_ri_res_wr */

	/*

	 * eqsize is the number of 64B entries plus the status page size.

 no host cidx updates */

 don't keep in chip cache */

 set by uP at ri_init time */

 relaxed_ordering */

	/*

	 * SRQ RQT and RQ must be a power of 2 and at least 16 deep.

/*

 * Copyright (c) 2009-2014 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Atomically lookup the ep ptr given the tid and grab a reference on the ep.

/*

 * Atomically lookup the ep ptr given the stid and grab a reference on the ep.

	/*

	 * If we have a hwtid, then remove it from the idr table

	 * so lookups will no longer find this endpoint.  Otherwise

	 * we have a race where one thread finds the ep ptr just

	 * before the other thread is freeing the ep memory.

/*

 * Try and reuse skbs already allocated...

/*

 * Fake up a special CPL opcode and call sched() so process_work() will call

 * _put_ep_safe() in a safe context to free the ep resources.  This is needed

 * because ARP error handlers are called in an ATOMIC context, and

 * _c4iw_free_ep() needs to block.

 Set our special ARP_FAILURE opcode */

	/*

	 * Save ep in the skb->cb area, after where sched() will save the dev

	 * ptr.

 Handle an ARP failure for an accept */

/*

 * Handle an ARP failure for an active open.

/*

 * Handle an ARP failure for a CPL_ABORT_REQ.  Change it into a no RST variant

 * and send it along.

	/*

	 * keep a ref on the ep so the tcb is not unlocked before this

	 * cpl completes. The ref is released in read_tcb_rpl().

	/*

	 * Specify the largest window that will fit in opt0. The

	 * remainder will be specified in the rx_data_ack.

	/*

	 * Reference the mpa skb.  This ensures the data area

	 * will remain in memory until the hw acks the tx.

	 * Function fw4_ack() will deref it.

	/*

	 * Reference the mpa skb again.  This ensures the data area

	 * will remain in memory until the hw acks the tx.

	 * Function fw4_ack() will deref it.

	/*

	 * Reference the mpa skb.  This ensures the data area

	 * will remain in memory until the hw acks the tx.

	 * Function fw4_ack() will deref it.

 setup the hwtid for this connection */

 dealloc the atid */

 start MPA negotiation */

 this means MPA_v2 is used */

 this means MPA_v1 is used */

 this means MPA_v2 is used */

 this means MPA_v1 is used. Send max supported */

	/*

	 * If we couldn't specify the entire rcv window at connection setup

	 * due to the limit in the number of bits in the RCV_BUFSIZ field,

	 * then add the overage in to the credits returned.

/*

 * process_mpa_reply - process streaming mode MPA reply

 *

 * Returns:

 *

 * 0 upon success indicating a connect request was delivered to the ULP

 * or the mpa request is incomplete but valid so far.

 *

 * 1 if a failure requires the caller to close the connection.

 *

 * 2 if a failure requires the caller to abort the connection.

	/*

	 * If we get more than the supported amount of private data

	 * then we must fail this connection.

	/*

	 * copy the new data into our accumulation buffer.

	/*

	 * if we don't even have the mpa message, then bail.

 Validate MPA header. */

	/*

	 * Fail if there's too much private data.

	/*

	 * If plen does not account for pkt size

	/*

	 * If we don't have all the pdata yet, then bail.

	 * We'll continue process when more data arrives.

	/*

	 * Stop mpa timer.  If it expired, then

	 * we ignore the MPA reply.  process_timeout()

	 * will abort the connection.

	/*

	 * If we get here we have accumulated the entire mpa

	 * start reply message including private data. And

	 * the MPA header is valid.

			/*

			 * This is a double-check. Ideally, below checks are

			 * not required since ird/ord stuff has been taken

			 * care of in c4iw_accept_cr

	/*

	 * If responder's RTR does not match with that of initiator, assign

	 * FW_RI_INIT_P2PTYPE_DISABLED in mpa attributes so that RTR is not

	 * generated when moving QP to RTS state.

	 * A TERM message will be sent after QP has moved to RTS state

 bind QP and TID with INIT_WR */

	/*

	 * If responder's RTR requirement did not match with what initiator

	 * supports, generate TERM message

	/*

	 * Generate TERM if initiator IRD is not sufficient for responder

	 * provided ORD. Currently, we do the same behaviour even when

	 * responder provided IRD is also not sufficient as regards to

	 * initiator ORD.

/*

 * process_mpa_request - process streaming mode MPA request

 *

 * Returns:

 *

 * 0 upon success indicating a connect request was delivered to the ULP

 * or the mpa request is incomplete but valid so far.

 *

 * 1 if a failure requires the caller to close the connection.

 *

 * 2 if a failure requires the caller to abort the connection.

	/*

	 * If we get more than the supported amount of private data

	 * then we must fail this connection.

	/*

	 * Copy the new data into our accumulation buffer.

	/*

	 * If we don't even have the mpa message, then bail.

	 * We'll continue process when more data arrives.

	/*

	 * Validate MPA Header.

	/*

	 * Fail if there's too much private data.

	/*

	 * If plen does not account for pkt size

	/*

	 * If we don't have all the pdata yet, then bail.

	/*

	 * If we get here we have accumulated the entire mpa

	 * start reply message including private data.

 drive upcall */

	/*

	 * If this TCB had a srq buffer cached, then we must complete

	 * it. For user mode, that means saving the srqidx in the

	 * user/kernel status page for this qp.  For kernel mode, just

	 * synthesize the CQE now.

	/*

	 * Specify the largest window that will fit in opt0. The

	 * remainder will be specified in the rx_data_ack.

/*

 * Some of the error codes above implicitly indicate that there is no TID

 * allocated with the result of an ACT_OPEN.  We use this predicate to make

 * that explicit.

	/* When MPA revision is different on nodes, the node with MPA_rev=2

	 * tries to reconnect with MPA_rev 1 for the same EP through

	 * c4iw_reconnect(), where the same EP is assigned with new tid for

	 * further connection establishment. As we are using the same EP pointer

	 * for reconnect, few skbs are used during the previous c4iw_connect(),

	 * which leaves the EP with inadequate skbs for further

	 * c4iw_reconnect(), Further causing a crash due to an empty

	 * skb_list() during peer_abort(). Allocate skbs which is already used.

	/*

	 * Allocate an active TID to initiate a TCP connection.

 find a route */

 send connect request to rnic */

	/*

	 * remember to send notification to upper layer.

	 * We are in here so the upper layer is not aware that this is

	 * re-connect attempt and so, upper layer is still waiting for

	 * response of 1st connect request.

	/*

	 * Log interesting failures.

	/*

	 * Specify the largest window that will fit in opt0. The

	 * remainder will be specified in the rx_data_ack.

 Find output route */

		/*

		 * We're gonna mark this puppy DEAD, but keep

		 * the reference on it until the ULP accepts or

		 * rejects the CR. Also wake up anyone waiting

		 * in rdma connection migration (see c4iw_accept_cr()).

	/*

	 * Wake up any threads in rdma_init() or rdma_fini().

	 * However, this is not needed if com state is just

	 * MPA_REQ_SENT

			/*

			 * we just don't send notification upwards because we

			 * want to retry with mpa_v1 without upper layers even

			 * knowing it.

			 *

			 * do some housekeeping so as to re-initiate the

			 * connection

 Hold ep ref until finish_peer_abort() */

 we don't release if we want to retry with mpa_v1 */

 Dereferencing ep, referenced in peer_abort_intr() */

 The cm_id may be null if we failed to connect */

		/* As per draft-hilland-iwarp-verbs-v1.0, sec 6.2.3,

		 * when entering the TERM state the RNIC MUST initiate a CLOSE.

/*

 * Upcall from the adapter indicating data has been transmitted.

 * For us its just the single MPA request or reply.  We can now free

 * the skb holding the mpa message.

 bind QP to EP and move to RTS */

 bind QP and TID with INIT_WR */

	/*

	 * Allocate an active TID to initiate a TCP connection.

		/*

		 * Handle loopback requests to INADDR_ANY.

 find a route */

		/*

		 * Handle loopback requests to INADDR_ANY.

 find a route */

 send connect request to rnic */

	/*

	 * Allocate a server TID.

	/*

	 * Ref the ep here in case we have fatal errors causing the

	 * ep to be released and freed.

			/*

			 * if we close before we see the fw4_ack() then we fix

			 * up the timer state since we're reusing it.

	/* Examine the TF_RX_PDU_OUT (bit 49 of the t_flags) in order to

	 * determine if there's a rx PDU feedback event pending.

	 *

	 * If that bit is set, it means we'll need to re-read the TCB's

	 * rq_start value. The final value is the one present in a TCB

	 * with the TF_RX_PDU_OUT bit cleared.

 from get_ep_from_tid() */

 from read_tcb() */

 If TF_RX_PDU_OUT bit is set, re-read the TCB */

 Store values from cpl_rx_pkt in temporary location. */

	/*

	 * We need to parse the TCP options from SYN packet.

	 * to generate cpl_pass_accept_req.

 T6 and later */

	/*

	 * We store the qid in opt2 which will be used by the firmware

	 * to send us the wr response.

	/*

	 * We initialize the MSS index in TCB to 0xF.

	 * So that when driver sends cpl_pass_accept_rpl

	 * TCB picks up the correct value. If this was 0

	 * TP will ignore any value > 0 for MSS index.

/*

 * Handler for CPL_RX_PKT message. Need to handle cpl_rx_pkt

 * messages when a filter is being used instead of server to

 * redirect a syn packet. When packets hit filter they are redirected

 * to the offload queue and driver tries to establish the connection

 * using firmware work request.

 Drop all non-SYN packets */

	/*

	 * Drop all packets which did not hit the filter.

	 * Unlikely to happen.

	/*

	 * Calculate the server tid from filter hit index from cpl_rx_pkt.

 Calcuate filter portion for LE region. */

	/*

	 * Synthesize the cpl_pass_accept_req. We have everything except the

	 * TID. Once firmware sends a reply with TID we update the TID field

	 * in cpl and pass it through the regular cpl_pass_accept_req path.

/*

 * These are the real handlers that are called from a

 * work queue.

		/*

		 * These states are expected if the ep timed out at the same

		 * time as another thread was calling stop_ep_timer().

		 * So we silently do nothing for these states.

		/*

		 * Only insert if it is not already on the list.

/*

 * All the CM events are handled on a work queue to have a safe context.

	/*

	 * Save dev in the skb->cb area.

	/*

	 * Queue the skb and schedule the worker thread.

 This EP will be dereferenced in peer_abort() */

/*

 * Most upcalls from the T4 Core go to sched() to

 * schedule the processing on a work queue.

/*

 * Copyright (c) 2009-2010 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * Ingress WRITE and READ_RESP errors provide

	 * the offending stag, so parse and log it.

 Bad incoming write */

 Completion Events */

 Device Fatal Errors */

 QP Fatal Errors */

/*

 * Copyright (c) 2009-2010 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Crude resource management */

 nr_* must be power of 2 */

/*

 * returns 0 if no resource available

		/*

		 * now put the same ids on the qp list since they all

		 * map to the same db/gts page.

		/*

		 * now put the same ids on the cq list since they all

		 * map to the same db/gts page.

/*

 * PBL Memory Manager.  Uses Linux generic allocator.

 256B == min PBL size (32 entries) */

/*

 * RQT Memory Manager.  Uses Linux generic allocator.

 1KB == min RQT size (16 entries) */

	/*

	 * If SRQs are supported, then never use the first RQE from

	 * the RQT region. This is because HW uses RQT index 0 as NULL.

/*

 * On-Chip QP Memory.

 4KB == min ocqp size */

/*

 * Copyright (c) 2009-2010 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

		/*

		 * MA_SYNC register...

		/*

		 * Map user DB or OCQP memory...

		/*

		 * Map WQ or CQ contig dma memory...

 FIXME: these look like port stats */

/*

 * Copyright (c) 2018 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 WQ+SQ */

 RQ */

/*

 * Dump the first and last pending sqes.

 User qp state is not available, so don't dump user qps */

 Get a consistent snapshot */

 If there are any pending sqes, copy the first and last */

 Get a consistent snapshot */

 User cq state is not available, so don't dump user cqs */

 Get a consistent snapshot */

 t4_cq struct */

 get 2 hw cqes: cidx-1, and cidx */

 get first and last sw cqes */

/*

 * Copyright (c) 2009-2010 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * No need to lock; we drop the lock to call vmalloc so it's racy

	 * anyway.  Someone who cares should switch this over to seq_file

 Caller takes care of locking if needed */

	/*

	 * This implementation assumes udb_density == ucq_density!  Eventually

	 * we might need to support this but for now fail the open. Also the

	 * cqid and qpid range must match for now.

 This implementation requires a sge_host_page_size <= PAGE_SIZE. */

 init various hw-queue params based on lld info */

	/*

	 * For T5/T6 devices, we map all of BAR2 with WC.

	 * For T4 devices with onchip qp mem, we map only that part

	 * of BAR2 with WC.

	/*

	 * Allocate space for cpl_pass_accept_req which will be synthesized by

	 * driver. Once the driver synthesizes the request the skb will go

	 * through the regular cpl_pass_accept_req processing.

	 * The math here assumes sizeof cpl_pass_accept_req >= sizeof

	 * cpl_rx_pkt.

	/*

	 * This skb will contain:

	 *   rss_header from the rspq descriptor (1 flit)

	 *   cpl_rx_pkt struct from the rspq descriptor (2 flits)

	 *   space for the difference between the size of an

	 *      rx_pkt and pass_accept_req cpl (1 flit)

	 *   the packet data from the gl

 omit RSS and rsp_ctrl at end of descriptor */

 Wait for the dbfifo to drain */

 slow everybody down */

 flush the SGE contexts */

 Count active queues so we can build a list of queues to recover */

 add and ref each qp so it doesn't get freed */

 now traverse the list in a safe context to recover the db state*/

 we're almost done!  deref the qps and clean up */

/*

 * Copyright (c) 2009-2010 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * write len bytes of data into addr (32B aligned address)

 * If data is NULL, clear len byte of memory to zero.

/*

 * Build and write a TPT entry.

 * IN: stag key, pdid, perm, bind_enabled, zbva, to, len, page_size,

 *     pbl_size and pbl_addr

 * OUT: stag index

 write TPT entry */

/*

 * Copyright (c) 2009-2010 Chelsio, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *	  copyright notice, this list of conditions and the following

 *	  disclaimer in the documentation and/or other materials

 *	  provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 build fw_ri_res_wr */

			/*

			 * Insert this completed cqe into the swcq.

/*

 * Move all CQEs from the HWCQ into the SWCQ.

 * Deal with out-of-order and/or completions that complete

 * prior unsignalled WRs.

	/*

	 * This logic is similar to poll_cq(), but not quite the same

	 * unfortunately.  Need to move pertinent HW CQEs to the SW CQ but

	 * also do any translation magic that poll_cq() normally does.

		/*

		 * drop CQEs with no associated QP

			/* If we have reached here because of async

			 * event or other error, and have egress error

			 * then drop

			/* drop peer2peer RTR reads.

			/*

			 * Eat completions for unsignaled read WRs.

			/*

			 * Don't write to the HWCQ, create a new read req CQE

			 * in local memory and move it into the swcq.

		/* if its a SQ completion, then do the magic to move all the

		 * unsignaled and now in-order completions into the swcq.

/*

 * poll_cq

 *

 * Caller must:

 *     check the validity of the first CQE,

 *     supply the wq assicated with the qpid.

 *

 * credit: cq credit to return to sge.

 * cqe_flushed: 1 iff the CQE is flushed.

 * cqe: copy of the polled CQE.

 *

 * return value:

 *    0		    CQE returned ok.

 *    -EAGAIN       CQE skipped, try again.

 *    -EOVERFLOW    CQ overflow detected.

	/*

	 * skip cqe's not affiliated with a QP.

	/*

	* skip hw cqe's if the wq is flushed.

	/*

	 * skip TERMINATE cqes...

	/*

	 * Special cqe for drain WR completions...

	/*

	 * Gotta tweak READ completions:

	 *	1) the cqe doesn't contain the sq_wptr from the wr.

	 *	2) opcode not reflected from the wr.

	 *	3) read_len not reflected from the wr.

	 *	4) cq_type is RQ_TYPE not SQ_TYPE.

		/* If we have reached here because of async

		 * event or other error, and have egress error

		 * then drop

		/* If this is an unsolicited read response, then the read

		 * was generated by the kernel driver as part of peer-2-peer

		 * connection setup.  So ignore the completion.

		/*

		 * Eat completions for unsignaled read WRs.

		/*

		 * Don't write to the HWCQ, so create a new read req CQE

		 * in local memory.

	/*

	 * RECV completion.

		/*

		 * HW only validates 4 bits of MSN.  So we must validate that

		 * the MSN in the SEND is the next expected MSN.  If its not,

		 * then we complete this with T4_ERR_MSN and mark the wq in

		 * error.

	/*

	 * If we get here its a send completion.

	 *

	 * Handle out of order completion. These get stuffed

	 * in the SW SQ. Then the SW SQ is walked to move any

	 * now in-order completions into the SW CQ.  This handles

	 * 2 cases:

	 *	1) reaping unsignaled WRs when the first subsequent

	 *	   signaled WR is completed.

	 *	2) out of order read completions.

	/*

	 * Reap the associated WR(s) that are freed up with this

	 * completion.

		/*

		* Account for any unsignaled completions completed by

		* this signaled completion.  In this case, cidx points

		* to the first unsignaled one, and idx points to the

		* signaled one.  So adjust in_use based on this delta.

		* if this is not completing any unsigned wrs, then the

		* delta will be 0. Handle wrapping also!

	/*

	 * Flush any completed cqes that are now in-order.

	/*

	 * Simulate a SRQ_LIMIT_REACHED HW notification if required.

 Invalidate the MR if the fastreg failed */

/*

 * Get one cq entry from c4iw and map it to openib.

 *

 * Returns:

 *	0			cqe returned

 *	-ENODATA		EMPTY;

 *	-EAGAIN			caller must try again

 *	any other -errno	fatal error

 account for the status page. */

 IQ needs one extra entry to differentiate full vs empty. */

	/*

	 * entries must be multiple of 16 for HW.

	/*

	 * Make actual HW queue 2x to avoid cdix_inc overflows.

	/*

	 * Make HW queue at least 64 entries so GTS updates aren't too

	 * frequent.

	/*

	 * memsize must be a multiple of the page size if its a user cq.

 status page */

		/* communicate to the userspace that

		 * kernel driver supports 64B CQE

 locking heirarchy: cq lock first, then qp lock. */

 create a SRQ RECV CQE for srqidx */

/*

 * Copyright (c) 2011 Chelsio Communications.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Trivial bitmap-based allocator. If the random flag is set, the

 * allocator is designed to:

 * - pseudo-randomize the id returned such that it is not trivially predictable.

 * - avoid reuse of recently used id (at the expense of predictability)

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2020 Intel Corporation.

/*

 * This function is what we would push to the core layer if we wanted to be a

 * "first class citizen".  Instead we hide this here and rely on Verbs ULPs

 * to blindly pass the MTU enum value from the PathRecord to us.

 Constraining 10KB packets to 8KB packets */

/*

 * qp_set_16b - Set the hdr_type based on whether the slid or the

 * dlid in the connection is extended. Only applicable for RC and UC

 * QPs. UD QPs determine this on the fly from the ah in the wqe

 Update ah_attr to account for extended LIDs */

 Create 32 bit LIDs */

/**

 * hfi1_setup_wqe - set up the wqe

 * @qp: The qp

 * @wqe: The built wqe

 * @call_send: Determine if the send should be posted or scheduled.

 *

 * Perform setup of the wqe.  This is called

 * prior to inserting the wqe into the ring but after

 * the wqe has been setup by RDMAVT. This function

 * allows the driver the opportunity to perform

 * validation and additional setup of the wqe.

 *

 * Returns 0 on success, -EINVAL on failure

 *

		/*

		 * SM packets should exclusively use VL15 and their SL is

		 * ignored (IBTA v1.3, Section 3.5.8.2). Therefore, when ah

		 * is created, SL is 0 in most cases and as a result some

		 * fields (vl and pmtu) in ah may not be set correctly,

		 * depending on the SL2SC and SC2VL tables at the time.

	/*

	 * System latency between send and schedule is large enough that

	 * forcing call_send to true for piothreshold packets is necessary.

/**

 * _hfi1_schedule_send - schedule progress

 * @qp: the QP

 *

 * This schedules qp progress w/o regard to the s_flags.

 *

 * It is only used in the post send, which doesn't hold

 * the s_lock.

/**

 * hfi1_schedule_send - schedule progress

 * @qp: the QP

 *

 * This schedules qp progress and caller should hold

 * the s_lock.

 * @return true if the first leg is scheduled;

 * false if the first leg is not scheduled.

 Notify hfi1_destroy_qp() if it is waiting. */

		/*

		 * If we are sending a first-leg packet from the second leg,

		 * we need to clear the busy flag from priv->s_flags to

		 * avoid a race condition when the qp wakes up before

		 * the call to hfi1_verbs_send() returns to the second

		 * leg. In that case, the second leg will terminate without

		 * being re-scheduled, resulting in failure to send TID RDMA

		 * WRITE DATA and TID RDMA ACK packets.

		/*

		 * If we couldn't queue the DMA request, save the info

		 * and try again later rather than destroying the

		 * buffer and undoing the side effects of the copy.

 Make a common routine? */

	/*

	 * This happens when the send engine notes

	 * a QP in the error state and cannot

	 * do the flush work until that QP's

	 * sdma work has finished.

/**

 * qp_to_sdma_engine - map a qp to a send engine

 * @qp: the QP

 * @sc5: the 5 bit sc

 *

 * Return:

 * A send engine for the qp or NULL for SMI type qp.

/**

 * qp_to_send_context - map a qp to a send context

 * @qp: the QP

 * @sc5: the 5 bit sc

 *

 * Return:

 * A send context for the qp

 SMA packets to VL15 */

/**

 * qp_iter_print - print the qp information to seq_file

 * @s: the seq_file to emit the qp information on

 * @iter: the iterator for the qp hash list

 ack_queue ring pointers, size */

 remote QP info  */

 ack queue information */

 Init to a value to start the running average correctly */

 Clear any OPFN state */

/*

 * Switch to alternate path.

 * The QP s_lock should be held and interrupts disabled.

 values less than 0 are error */

/**

 * hfi1_qp_iter_cb - callback for iterator

 * @qp: the qp

 * @v: the sl in low bits of v

 *

 * This is called from the iterator callback to work

 * on an individual qp.

/**

 * hfi1_error_port_qps - put a port's RC/UC qps into error state

 * @ibp: the ibport.

 * @sl: the service level.

 *

 * This function places all RC/UC qps with a given service level into error

 * state. It is generally called to force upper lay apps to abandon stale qps

 * after an sl->sc mapping change.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015-2020 Intel Corporation.

 * Copyright(c) 2021 Cornelis Networks.

/*

 * The size has to be longer than this string, so we can append

 * board/chip information to it in the initialization code.

 general driver use */

/*

 * MAX_PKT_RCV is the max # if packets processed per receive interrupt.

/*

 * MAX_PKT_THREAD_RCV is the max # of packets processed before

 * the qp_wait_list queue is flushed.

 Get the changed bits (except the locked bit) */

 Remove any bits that are not allowed to change after driver load */

 Mask off any reserved bits */

 Clear any previously set and changing bits */

 Update the bits with the new capability */

 Check for any kernel/user restrictions */

 Set the bitmask to the final set */

/*

 * Return count of units with at least one port ACTIVE.

/*

 * Get address of eager buffer from it's index (allocated in chunks, not

 * contiguous).

/*

 * Validate and encode the a given RcvArray Buffer size.

 * The function will check whether the given size falls within

 * allowed size ranges for the respective type and, optionally,

 * return the proper encoding.

 For TIDERR and RC QPs preemptively schedule a NAK */

 in bytes */

 Sanity check packet */

 Check for GRH */

 Get the destination QP number. */

			/*

			 * Handle only RC QPs - for other QP types drop error

			 * packet.

 Check for valid receive state. */

 For now don't handle any other QP types */

 Unicast QP */

 Valid packet with TIDErr */

 handle "RcvTypeErr" flags */

 this should never happen */

			/*

			 * Only in pre-B0 h/w is the CNP_OPCODE handled

			 * via this code path.

 words */

 words */

 We support only two types - 9B and 16B for now */

/**

 * hfi1_process_ecn_slowpath - Process FECN or BECN bits

 * @qp: The packet's destination QP

 * @pkt: The packet itself.

 * @prescan: Is the caller the RXQ prescan

 *

 * Process the packet's FECN or BECN bits. By now, the packet

 * has already been evaluated whether processing of those bit should

 * be done.

 * The significance of the @prescan argument is that if the caller

 * is the RXQ prescan, a CNP will be send out instead of waiting for the

 * normal packet processing to send an ACK with BECN set (or a CNP).

 can be called from prescan */

	/*

	 * ACKNOWLEDGE packets do not get a CNP but this will be

	 * guarded by ignore_fecn above.

 Call appropriate CNP handler */

 not used with DMA_RTAIL */

 used only with DMA_RTAIL*/

	/*

	 * Control context can potentially receive an invalid rhf.

	 * Drop such packets.

 Control context must do seq counting */

/*

 * prescan_rxq - search through the receive queue looking for packets

 * containing Excplicit Congestion Notifications (FECNs, or BECNs).

 * When an ECN is found, process the Congestion Notification, and toggle

 * it off.

 * This is declared as a macro to allow quick checking of the port to avoid

 * the overhead of a function call if not enabled.

 just in case */

 turn off BECN, FECN */

	/*

	 * Iterate over all QPs waiting to respond.

	 * The list won't change since the IRQ is only run on one CPU.

 allow defered processing */

 Set up for the next packet */

 total length */

 in bytes */

 retrieve eager buffer details */

	/*

	 * Prefetch the contents of the eager buffer.  It is

	 * OK to send a negative length to prefetch_range().

	 * The +2 is the size of the RHF.

 Set up for the next packet */

 total length */

 in bytes */

 retrieve eager buffer details */

		/*

		 * Prefetch the contents of the eager buffer.  It is

		 * OK to send a negative length to prefetch_range().

		 * The +2 is the size of the RHF.

	/*

	 * Call a type specific handler for the packet. We

	 * should be able to trust that etype won't be beyond

	 * the range of valid indexes. If so something is really

	 * wrong and we can probably just let things come

	 * crashing down. There is no need to eat another

	 * comparison in this performance critical code.

 Set up for the next packet */

	/*

	 * Update head regs etc., every 16 packets, if not last pkt,

	 * to help prevent rcvhdrq overflows, when many packets

	 * are processed and queue is nearly full.

	 * Don't request an interrupt for intermediate updates.

	/*

	 * Nothing we need to free for the packet.

	 *

	 * The only thing we need to do is a final update and call for an

	 * interrupt

/*

 * handle_receive_interrupt_napi_fp - receive a packet

 * @rcd: the context

 * @budget: polling budget

 *

 * Called from interrupt handler for receive interrupt.

 * This is the fast path interrupt handler

 * when executing napi soft irq environment.

/*

 * Handle receive interrupts when using the no dma rtail option.

 prevent speculative reads of dma'ed hdrq */

	/*

	 * For dynamically allocated kernel contexts (like vnic) switch

	 * interrupt handler only for that context. Otherwise, switch

	 * interrupt handler for all statically allocated kernel contexts.

 HFI1_CTRL_CTXT must always use the slow path interrupt handler */

/**

 * set_armed_to_active  - the fast path for armed to active

 * @packet: the packet structure

 *

 * Return true if packet processing needs to bail.

/*

 * handle_receive_interrupt - receive a packet

 * @rcd: the context

 *

 * Called from interrupt handler for errors or receive interrupt.

 * This is the slow path interrupt handler.

 Control context will always use the slow path interrupt handler */

 prevent speculative reads of dma'ed hdrq */

		/*

		 * Control context can potentially receive an invalid

		 * rhf. Drop such packets.

 On to the next packet */

			/*

			 * Control context can potentially receive an invalid

			 * rhf. Drop such packets.

	/*

	 * Always write head at end, and setup rcv interrupt, even

	 * if no packets were processed.

/*

 * handle_receive_interrupt_napi_sp - receive a packet

 * @rcd: the context

 * @budget: polling budget

 *

 * Called from interrupt handler for errors or receive interrupt.

 * This is the slow path interrupt handler

 * when executing napi soft irq environment.

 On to the next packet */

	/*

	 * Always write head at end, and setup rcv interrupt, even

	 * if no packets were processed.

/*

 * We may discover in the interrupt that the hardware link state has

 * changed from ARMED to ACTIVE (due to the arrival of a non-SC15 packet),

 * and we need to update the driver's notion of the link state.  We cannot

 * run set_link_state from interrupt context, so we queue this function on

 * a workqueue.

 *

 * We delay the regular interrupt processing until after the state changes

 * so that the link will be in the correct state by the time any application

 * we wake up attempts to send a reply to any message it received.

 * (Subsequent receive interrupts may possibly force the wakeup before we

 * update the link state.)

 *

 * The rcd is freed in hfi1_free_ctxtdata after hfi1_postinit_cleanup invokes

 * dd->f_cleanup(dd) to disable the interrupt handler and flush workqueues,

 * so we're safe from use-after-free of the rcd.

 Received non-SC15 packet implies neighbor_normal */

	/*

	 * Interrupt all statically allocated kernel contexts that could

	 * have had an interrupt during auto activation.

/*

 * Convert a given MTU size to the on-wire MAD packet enumeration.

 * Return -1 if the size is invalid.

/*

 * set_mtu - set the MTU

 * @ppd: the per port data

 *

 * We can handle "any" incoming size, the issue here is whether we

 * need to restrict our outgoing size.  We do not deal with what happens

 * to programs that are already running when the size changes.

		/*

		 * MTU is specified per-VL. To ensure that no packet gets

		 * stuck (due, e.g., to the MTU for the packet's VL being

		 * reduced), empty the per-VL FIFOs before adjusting MTU.

 reopen all VLs */

	/*

	 * This pairs with the memory barrier in hfi1_start_led_override to

	 * ensure that we read the correct state of LED beaconing represented

	 * by led_override_timer_active

 Ensure the atomic_set is visible to all CPUs */

 Hand control of the LED to the DC for normal operation */

 Set up for next phase */

/*

 * To have the LED blink in a particular pattern, provide timeon and timeoff

 * in milliseconds.

 * To turn off custom blinking and return to normal operation, use

 * shutdown_led_override()

 Convert to jiffies for direct use in timer */

 Arbitrarily start from LED on phase */

	/*

	 * If the timer has not already been started, do so. Use a "quick"

	 * timeout so the handler will be called soon to look at our request.

 Ensure the atomic_set is visible to all CPUs */

/**

 * hfi1_reset_device - reset the chip if possible

 * @unit: the device to reset

 *

 * Whether or not reset is successful, we attempt to re-initialize the chip

 * (that is, much like a driver unload/reload).  We clear the INITTED flag

 * so that the various entry points will fail until we reinitialize.  For

 * now, we only allow this if no user contexts are open that use chip resources

 If there are any user/vnic contexts, we cannot reset */

 slid and dlid cannot be 0 */

 Compare port lid with incoming packet dlid */

 No multicast packets with SC15 */

 Packets with permissive DLID always on SC15 */

 Query commonly used fields from packet header */

	/*

	 * Bypass packets have a different header/payload split

	 * compared to an IB packet.

	 * Current split is set such that 16 bytes of the actual

	 * header is in the header buffer and the remining is in

	 * the eager buffer. We chose 16 since hfi1 driver only

	 * supports 16B bypass packets and we will be able to

	 * receive the entire LRH with such a split.

 hdr_len_by_opcode already has an IB LRH factored in */

 hdr_len_by_opcode already has an IB LRH factored in */

 Query commonly used fields from packet header */

 handle congestion notifications */

	/*

	 * We have split point after last byte of DETH

	 * lets strip padding and CRC and ICRC.

	 * tlen is whole packet len so we need to

	 * subtract header size as well.

/*

 * The following functions are called by the interrupt handler. They are type

 * specific handlers for each packet type.

 KHdrHCRCErr -- KDETH packet with a bad HCRC */

 just in case */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015, 2016 Intel Corporation.

 additive distance between non-SOP and SOP space */

 number of QUADWORDs in a block */

/**

 * pio_copy - copy data block to MMIO space

 * @dd: hfi1 dev data

 * @pbuf: a number of blocks allocated within a PIO send context

 * @pbc: PBC to send

 * @from: source, must be 8 byte aligned

 * @count: number of DWORD (32-bit) quantities to copy from source

 *

 * Copy data from source to PIO Send Buffer memory, 8 bytes at a time.

 * Must always write full BLOCK_SIZE bytes blocks.  The first block must

 * be written to the corresponding SOP=1 address.

 *

 * Known:

 * o pbuf->start always starts on a block boundary

 * o pbuf can wrap only at a block boundary

 8-byte data end */

 write the PBC */

 calculate where the QWORD data ends - in SOP=1 space */

		/*

		 * all QWORD data is within the SOP block, does *not*

		 * reach the end of the SOP block

		/*

		 * No boundary checks are needed here:

		 * 0. We're not on the SOP block boundary

		 * 1. The possible DWORD dangle will still be within

		 *    the SOP block

		 * 2. We cannot wrap except on a block boundary.

 QWORD data extends _to_ or beyond the SOP block */

 write 8-byte SOP chunk data */

 drop out of the SOP range */

		/*

		 * If the wrap comes before or matches the data end,

		 * copy until until the wrap, then wrap.

		 *

		 * If the data ends at the end of the SOP above and

		 * the buffer wraps, then pbuf->end == dend == dest

		 * and nothing will get written, but we will wrap in

		 * case there is a dangling DWORD.

 write 8-byte non-SOP, non-wrap chunk data */

 at this point we have wrapped if we are going to wrap */

 write dangling u32, if any */

	/*

	 * fill in rest of block, no need to check pbuf->end

	 * as we only wrap on a block boundary

 finished with this buffer */

/*

 * Handle carry bytes using shifts and masks.

 *

 * NOTE: the value the unused portion of carry is expected to always be zero.

/*

 * "zero" shift - bit shift used to zero out upper bytes.  Input is

 * the count of LSB bytes to preserve.

/*

 * "merge" shift - bit shift used to merge with carry bytes.  Input is

 * the LSB byte count to move beyond.

/*

 * Jump copy - no-loop copy for < 8 bytes.

/*

 * Read nbytes from "from" and and place them in the low bytes

 * of pbuf->carry.  Other bytes are left as-is.  Any previous

 * value in pbuf->carry is lost.

 *

 * NOTES:

 * o do not read from from if nbytes is zero

 * o from may _not_ be u64 aligned.

/*

 * Read nbytes bytes from "from" and put them at the end of pbuf->carry.

 * It is expected that the extra read does not overfill carry.

 *

 * NOTES:

 * o from may _not_ be u64 aligned

 * o nbytes may span a QW boundary

/*

 * Write a quad word using parts of pbuf->carry and the next 8 bytes of src.

 * Put the unused part of the next 8 bytes of src into the LSB bytes of

 * pbuf->carry with the upper bytes zeroed..

 *

 * NOTES:

 * o result must keep unused bytes zeroed

 * o src must be u64 aligned

/*

 * Write a quad word using all bytes of carry.

/*

 * Write a quad word using all the valid bytes of carry.  If carry

 * has zero valid bytes, nothing is written.

 * Returns 0 on nothing written, non-zero on quad word written.

 unused bytes are always kept zeroed, so just write */

/*

 * Segmented PIO Copy - start

 *

 * Start a PIO copy.

 *

 * @pbuf: destination buffer

 * @pbc: the PBC for the PIO buffer

 * @from: data source, QWORD aligned

 * @nbytes: bytes to copy

 8-byte data end */

 calculate where the QWORD data ends - in SOP=1 space */

		/*

		 * all QWORD data is within the SOP block, does *not*

		 * reach the end of the SOP block

		/*

		 * No boundary checks are needed here:

		 * 0. We're not on the SOP block boundary

		 * 1. The possible DWORD dangle will still be within

		 *    the SOP block

		 * 2. We cannot wrap except on a block boundary.

 QWORD data extends _to_ or beyond the SOP block */

 write 8-byte SOP chunk data */

 drop out of the SOP range */

		/*

		 * If the wrap comes before or matches the data end,

		 * copy until until the wrap, then wrap.

		 *

		 * If the data ends at the end of the SOP above and

		 * the buffer wraps, then pbuf->end == dend == dest

		 * and nothing will get written, but we will wrap in

		 * case there is a dangling DWORD.

 write 8-byte non-SOP, non-wrap chunk data */

 at this point we have wrapped if we are going to wrap */

 ...but it doesn't matter as we're done writing */

 save dangling bytes, if any */

PBC*/ + (nbytes >> 3);

/*

 * Mid copy helper, "mixed case" - source is 64-bit aligned but carry

 * bytes are non-zero.

 *

 * Whole u64s must be written to the chip, so bytes must be manually merged.

 *

 * @pbuf: destination buffer

 * @from: data source, is QWORD aligned.

 * @nbytes: bytes to copy

 *

 * Must handle nbytes < 8.

 8-byte data end */

 calculate 8-byte data end */

		/*

		 * Still within SOP block.  We don't need to check for

		 * wrap because we are still in the first block and

		 * can only wrap on block boundaries.

 SOP end */

		/*

		 * calculate the end of data or end of block, whichever

		 * comes first

 shift up to SOP=1 space */

 write 8-byte chunk data */

 shift down to SOP=0 space */

	/*

	 * At this point dest could be (either, both, or neither):

	 * - at dend

	 * - at the wrap

	/*

	 * If the wrap comes before or matches the data end,

	 * copy until until the wrap, then wrap.

	 *

	 * If dest is at the wrap, we will fall into the if,

	 * not do the loop, when wrap.

	 *

	 * If the data ends at the end of the SOP above and

	 * the buffer wraps, then pbuf->end == dend == dest

	 * and nothing will get written.

 write 8-byte non-SOP, non-wrap chunk data */

 handle carry and left-over bytes */

 there is enough to fill another qw - fill carry */

		/*

		 * One more write - but need to make sure dest is correct.

		 * Check for wrap and the possibility the write

		 * should be in SOP space.

		 *

		 * The two checks immediately below cannot both be true, hence

		 * the else. If we have wrapped, we cannot still be within the

		 * first block. Conversely, if we are still in the first block,

		 * we cannot have wrapped. We do the wrap check first as that

		 * is more likely.

 adjust if we have wrapped */

 jump to the SOP range if within the first block */

 flush out full carry */

 now adjust and read the rest of the bytes into carry */

 from is now not aligned */

 not enough to fill another qw, append the rest to carry */

/*

 * Mid copy helper, "straight case" - source pointer is 64-bit aligned

 * with no carry bytes.

 *

 * @pbuf: destination buffer

 * @from: data source, is QWORD aligned

 * @nbytes: bytes to copy

 *

 * Must handle nbytes < 8.

 8-byte data end */

 calculate 8-byte data end */

		/*

		 * Still within SOP block.  We don't need to check for

		 * wrap because we are still in the first block and

		 * can only wrap on block boundaries.

 SOP end */

		/*

		 * calculate the end of data or end of block, whichever

		 * comes first

 shift up to SOP=1 space */

 write 8-byte chunk data */

 shift down to SOP=0 space */

	/*

	 * At this point dest could be (either, both, or neither):

	 * - at dend

	 * - at the wrap

	/*

	 * If the wrap comes before or matches the data end,

	 * copy until until the wrap, then wrap.

	 *

	 * If dest is at the wrap, we will fall into the if,

	 * not do the loop, when wrap.

	 *

	 * If the data ends at the end of the SOP above and

	 * the buffer wraps, then pbuf->end == dend == dest

	 * and nothing will get written.

 write 8-byte non-SOP, non-wrap chunk data */

 we know carry_bytes was zero on entry to this routine */

/*

 * Segmented PIO Copy - middle

 *

 * Must handle any aligned tail and any aligned source with any byte count.

 *

 * @pbuf: a number of blocks allocated within a PIO send context

 * @from: data source

 * @nbytes: number of bytes to copy

 not enough bytes to fill a QW */

 misaligned source pointer - align it */

 bytes to read to align "from" */

		/*

		 * In the advance-to-alignment logic below, we do not need

		 * to check if we are using more than nbytes.  This is because

		 * if we are here, we already know that carry+nbytes will

		 * fill at least one QW.

 not enough align bytes to fill a QW */

 bytes to fill carry */

 bytes left over to be read */

 fill carry... */

 may not be enough valid bytes left to align */

 ...now write carry */

			/*

			 * The two checks immediately below cannot both be

			 * true, hence the else.  If we have wrapped, we

			 * cannot still be within the first block.

			 * Conversely, if we are still in the first block, we

			 * cannot have wrapped.  We do the wrap check first

			 * as that is more likely.

 adjust if we've wrapped */

 jump to SOP range if within the first block */

 read any extra bytes to do final alignment */

 this will overwrite anything in pbuf->carry */

			/*

			 * If no bytes are left, return early - we are done.

			 * NOTE: This short-circuit is *required* because

			 * "extra" may have been reduced in size and "from"

			 * is not aligned, as required when leaving this

			 * if block.

 at this point, from is QW aligned */

/*

 * Segmented PIO Copy - end

 *

 * Write any remainder (in pbuf->carry) and finish writing the whole block.

 *

 * @pbuf: a number of blocks allocated within a PIO send context

	/*

	 * The two checks immediately below cannot both be true, hence the

	 * else.  If we have wrapped, we cannot still be within the first

	 * block.  Conversely, if we are still in the first block, we

	 * cannot have wrapped.  We do the wrap check first as that is

	 * more likely.

 adjust if we have wrapped */

 jump to the SOP range if within the first block */

 write final bytes, if any */

		/*

		 * NOTE: We do not need to recalculate whether dest needs

		 * SOP_DISTANCE or not.

		 *

		 * If we are in the first block and the dangle write

		 * keeps us in the same block, dest will need

		 * to retain SOP_DISTANCE in the loop below.

		 *

		 * If we are in the first block and the dangle write pushes

		 * us to the next block, then loop below will not run

		 * and dest is not used.  Hence we do not need to update

		 * it.

		 *

		 * If we are past the first block, then SOP_DISTANCE

		 * was never added, so there is nothing to do.

 fill in rest of block */

 finished with this buffer */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2020 Cornelis Networks, Inc.

 * Copyright(c) 2016 - 2017 Intel Corporation.

 Unregister first so we don't get any more notifications. */

	/*

	 * Make sure the wq delete handler is finished running.  It will not

	 * be triggered once the mmu notifiers are unregistered above.

 move from LRU list to delete list */

 remove from LRU list */

 Caller must hold handler lock */

 remove from LRU list */

 move from LRU list to delete list */

/*

 * It is up to the caller to ensure that this function does not race with the

 * mmu invalidate notifier which may be calling the users remove callback on

 * 'node'.

 Validity of handler and node pointers has been checked by caller. */

 remove from LRU list */

 Guard against node removal. */

 move from LRU list to delete list */

/*

 * Call the remove function for the given handler and the list.  This

 * is expected to be called with a delete list extracted from handler.

 * The caller should not be holding the handler lock.

/*

 * Work queue function to remove all nodes that have been queued up to

 * be removed.  The key feature is that mm->mmap_lock is not being held

 * and the remove callback can sleep while taking it, if needed.

 remove anything that is queued to get removed */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2017 Intel Corporation.

/**

 * hfi1_exp_tid_set_init - initialize exp_tid_set

 * @set: the set

/**

 * hfi1_exp_tid_group_init - initialize rcd expected receive

 * @rcd: the rcd

/**

 * hfi1_alloc_ctxt_rcv_groups - initialize expected receive groups

 * @rcd: the context to add the groupings to

/**

 * hfi1_free_ctxt_rcv_groups - free  expected receive groups

 * @rcd: the context to free

 *

 * The routine dismantles the expect receive linked

 * list and clears any tids associated with the receive

 * context.

 *

 * This should only be called for kernel contexts and the

 * a base user context.

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2019 Intel Corporation.

 *

 Time after which the timer interrupt will re-enable ASPM */

 Time for which interrupts are ignored after a timer has been scheduled */

 Two interrupts within this time trigger ASPM disable */

	/*

	 * If the driver does not have access to the upstream component,

	 * it cannot support ASPM L1 at all.

 ASPM works on A-step but is reported as not supported */

 Set L1 entrance latency for slower entry to L1 */

	/*

	 * If the driver does not have access to the upstream component,

	 * it cannot support ASPM L1 at all.

 Enable ASPM L1 first in upstream component and then downstream */

 Disable ASPM L1 first in downstream component and then upstream */

 ASPM processing for each receive context interrupt */

 PSM contexts are open */

 An interrupt pair close together in time */

 Don't push out our timer till this much time has elapsed */

 Disable ASPM and schedule timer */

 Timer function for re-enabling ASPM in the absence of interrupt activity */

/*

 * Disable interrupt processing for verbs contexts when PSM or VNIC contexts

 * are open.

 Re-enable interrupt processing for verbs contexts */

 Start with ASPM disabled */

 Now turn on ASPM if configured */

 Turn on ASPM on exit to conserve power */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2016 - 2018 Intel Corporation.

 Free verbs_txreq and return to slab cache */

 refcount held until actual wake up */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2018 Intel Corporation.

/**

 * make_rc_ack - construct a response packet (ACK, NAK, or RDMA read)

 * @dev: the device for this QP

 * @qp: a pointer to the QP

 * @ohdr: a pointer to the IB header being constructed

 * @ps: the xmit packet state

 *

 * Return 1 if constructed; otherwise, return 0.

 * Note that we are in the responder's side of the QP context.

 * Note the QP s_lock must be held.

 Don't send an ACK if we aren't supposed to. */

 header size in 32-bit words LRH+BTH = (8+12)/4. */

 header size in 32-bit words 16B LRH+BTH = (16+12)/4. */

		/*

		 * We can increment the tail pointer now that the last

		 * response has been sent instead of only being

		 * constructed.

		/*

		 * Only advance the s_acked_ack_queue pointer if there

		 * have been no TID RDMA requests.

 Check for no next entry in the queue. */

 Check for tid write fence */

			/*

			 * If a RDMA read response is being resent and

			 * we haven't seen the duplicate request yet,

			 * then stop sending the remaining responses the

			 * responder has seen until the requester re-sends it.

 Copy SGE state in case we need to resend */

			/*

			 * If a TID RDMA WRITE RESP is being resent, we have to

			 * wait for the actual request. All requests that are to

			 * be resent will have their state set to

			 * TID_REQUEST_RESEND. When the new request arrives, the

			 * state will be changed to TID_REQUEST_RESEND_ACTIVE.

			/*

			 * If a TID RDMA read response is being resent and

			 * we haven't seen the duplicate request yet,

			 * then stop sending the remaining responses the

			 * responder has seen until the requester re-sends it.

 Copy SGE state in case we need to resend */

 COMPARE_SWAP or FETCH_ADD */

		/*

		 * 1. Check if RVT_S_ACK_PENDING is set. If yes,

		 *    goto normal.

		 * 2. Attempt to allocate TID resources.

		 * 3. Remove RVT_S_RESP_PENDING flags from s_flags

		 * 4. If resources not available:

		 *    4.1 Set RVT_S_WAIT_TID_SPACE

		 *    4.2 Queue QP on RCD TID queue

		 *    4.3 Put QP on iowait list.

		 *    4.4 Build IB RNR NAK with appropriate timeout value

		 *    4.5 Return indication progress made.

		 * 5. If resources are available:

		 *    5.1 Program HW flow CSRs

		 *    5.2 Build TID RDMA WRITE RESP packet

		 *    5.3 If more resources needed, do 2.1 - 2.3.

		 *    5.4 Wake up next QP on RCD TID queue.

		 *    5.5 Return indication progress made.

		/*

		 * Send scheduled RNR NAK's. RNR NAK's need to be sent at

		 * segment boundaries, not at request boundaries. Don't change

		 * s_ack_state because we are still in the middle of a request

 Do not free e->rdma_sge until all data are received */

			/*

			 * Increment qp->s_tail_ack_queue through s_ack_state

			 * transition.

		/*

		 * Send a regular ACK.

		 * Set the s_ack_state so we wait until after sending

		 * the ACK before setting s_ack_state to ACKNOWLEDGE

		 * (see above).

	/*

	 * Ensure s_rdma_ack_cnt changes are committed prior to resetting

	 * RVT_S_RESP_PENDING

/**

 * hfi1_make_rc_req - construct a request packet (SEND, RDMA r/w, ATOMIC)

 * @qp: a pointer to the QP

 * @ps: the current packet state

 *

 * Assumes s_lock is held.

 *

 * Return 1 if constructed; otherwise, return 0.

 header size in 32-bit words LRH+BTH = (8+12)/4. */

 header size in 32-bit words LRH+BTH = (8+12)/4. */

 header size in 32-bit words 16B LRH+BTH = (16+12)/4. */

 Sending responses has higher priority over sending requests. */

 We are in the error state, flush the work request. */

 If DMAs are in progress, we can't flush immediately. */

 will get called again */

 Send a request. */

		/*

		 * Resend an old request or start a new one.

		 *

		 * We keep track of the current SWQE so that

		 * we don't reset the "furthest progress" state

		 * if we need to back up.

 Check if send work queue is empty. */

			/*

			 * If a fence is requested, wait for previous

			 * RDMA read and atomic operations to finish.

			 * However, there is no need to guard against

			 * TID RDMA READ after TID RDMA READ.

			/*

			 * Local operations are processed immediately

			 * after all prior requests have completed

		/*

		 * Note that we have to be careful not to modify the

		 * original work request since we may need to resend

		 * it.

		/*

		 * Interlock between various IB requests and TID RDMA

		 * if necessary.

 If no credit, return. */

 Immediate data comes after the BTH */

 Invalidate rkey comes after the BTH */

 If no credit, return. */

 Immediate data comes after RETH */

				/*

				 * Limit the number of TID RDMA WRITE requests.

				/*

				 * The s_tid_cur pointer is advanced to s_cur if

				 * any of the following conditions about the WQE

				 * to which s_ti_cur currently points to are

				 * satisfied:

				 *   1. The request is not a TID RDMA WRITE

				 *      request,

				 *   2. The request is in the INACTIVE or

				 *      COMPLETE states (TID RDMA READ requests

				 *      stay at INACTIVE and TID RDMA WRITE

				 *      transition to COMPLETE when done),

				 *   3. The request is in the ACTIVE or SYNC

				 *      state and the number of completed

				 *      segments is equal to the total segment

				 *      count.

				 *      (If ACTIVE, the request is waiting for

				 *       ACKs. If SYNC, the request has not

				 *       received any responses because it's

				 *       waiting on a sync point.)

				/*

				 * A corner case: when the last TID RDMA WRITE

				 * request was completed, s_tid_head,

				 * s_tid_cur, and s_tid_tail all point to the

				 * same location. Other requests are posted and

				 * s_cur wraps around to the same location,

				 * where a new TID RDMA WRITE is posted. In

				 * this case, none of the indices need to be

				 * updated. However, the priv->s_state should.

				/*

				 * Pull back any segments since we are going

				 * to re-receive them.

			/*

			 * Don't allow more operations to be started

			 * than the QP limits allow.

			/*

			 * Don't allow more operations to be started

			 * than the QP limits allow. We could get here under

			 * three conditions; (1) It's a new request; (2) We are

			 * sending the second or later segment of a request,

			 * but the qp->s_state is set to OP(RDMA_READ_REQUEST)

			 * when the last segment of a previous request is

			 * received just before this; (3) We are re-sending a

			 * request.

				/*

				 * Set up s_sge as it is needed for TID

				 * allocation. However, if the pages have been

				 * walked and mapped, skip it. An earlier try

				 * has failed to allocate the TID entries.

 Re-send a request */

 Read one segment at a time */

 Wait for TID space */

 Check if this is the last segment */

			/*

			 * Don't allow more operations to be started

			 * than the QP limits allow.

		/*

		 * qp->s_state is normally set to the opcode of the

		 * last packet constructed for new requests and therefore

		 * is never set to RDMA read response.

		 * RDMA_READ_RESPONSE_FIRST is used by the ACK processing

		 * thread to indicate a SEND needs to be restarted from an

		 * earlier PSN without interfering with the sending thread.

		 * See restart_rc().

 Immediate data comes after the BTH */

 invalidate data comes after the BTH */

		/*

		 * qp->s_state is normally set to the opcode of the

		 * last packet constructed for new requests and therefore

		 * is never set to RDMA read response.

		 * RDMA_READ_RESPONSE_LAST is used by the ACK processing

		 * thread to indicate a RDMA write needs to be restarted from

		 * an earlier PSN without interfering with the sending thread.

		 * See restart_rc().

 Immediate data comes after the BTH */

		/*

		 * qp->s_state is normally set to the opcode of the

		 * last packet constructed for new requests and therefore

		 * is never set to RDMA read response.

		 * RDMA_READ_RESPONSE_MIDDLE is used by the ACK processing

		 * thread to indicate a RDMA read needs to be restarted from

		 * an earlier PSN without interfering with the sending thread.

		 * See restart_rc().

		/*

		 * This value for s_state is used for restarting a TID RDMA

		 * WRITE request. See comment in OP(RDMA_READ_RESPONSE_MIDDLE

		 * for more).

 This is used to restart a TID read request */

		/*

		 * Back down. The field qp->s_psn has been set to the psn with

		 * which the request should be restart. It's OK to use division

		 * as this is on the retry path.

		/*

		 * The following function need to be redefined to return the

		 * status to make sure that we find the flow. At the same

		 * time, we can use the req->state change to check if the

		 * call succeeds or not.

			/*

			 * Failed to find the flow. Release all allocated tid

			 * resources.

 Wait for TID space */

 Check if this is the last segment */

		/*

		 * If the current WR is not TID RDMA READ, or this is the start

		 * of a new request, we need to change the qp->s_state so that

		 * the request can be set up properly.

 Rate limiting */

 Read one segment at a time */

 Wait for TID space */

 Check if this is the last segment */

	/*

	 * If we didn't get a txreq, the QP will be woken up later to try

	 * again. Set the flags to indicate which work item to wake

	 * up.

 Schedule the send tasklet. */

 header size in 32-bit words LRH+BTH+AETH = (8+12+4)/4 */

 set PBC_DC_INFO bit (aka SC[4]) in pbc_flags */

 read pkey_index w/o lock (its atomic) */

	/*

	 * Inline ACKs go out without the use of the Verbs send engine, so

	 * we need to set the STL Verbs Extended bit here

 header size in 32-bit words 16B LRH+BTH+AETH = (16+12+4)/4 */

 read pkey_index w/o lock (its atomic) */

 Convert dwords to flits */

 We support only two types - 9B and 16B for now */

/*

 * hfi1_send_rc_ack - Construct an ACK packet and send it

 *

 * This is called from hfi1_rc_rcv() and handle_receive_interrupt().

 * Note that RDMA reads and atomics are handled in the

 * send side QP state and send engine.

 clear the defer count */

 Don't send ACK or NAK if a RDMA read or atomic is pending. */

 Ensure s_rdma_ack_cnt changes are committed */

 Don't try to send ACKs if the link isn't ACTIVE */

 Make the appropriate header */

 PBC */ + hwords + nwords;

		/*

		 * We have no room to send at the moment.  Pass

		 * responsibility for sending the ACK to the send engine

		 * so that when enough buffer space becomes available,

		 * the ACK is sent ahead of other outgoing packets.

 write the pbc and data */

/**

 * update_num_rd_atomic - update the qp->s_num_rd_atomic

 * @qp: the QP

 * @psn: the packet sequence number to restart at

 * @wqe: the wqe

 *

 * This is called from reset_psn() to update qp->s_num_rd_atomic

 * for the current wqe.

 * Called at interrupt level with the QP s_lock held.

/**

 * reset_psn - reset the QP state to send starting from PSN

 * @qp: the QP

 * @psn: the packet sequence number to restart at

 *

 * This is called from hfi1_rc_rcv() to process an incoming RC ACK

 * for the given QP.

 * Called at interrupt level with the QP s_lock held.

	/*

	 * If we are starting the request from the beginning,

	 * let the normal send code handle initialization.

 Find the work request opcode corresponding to the given PSN. */

 Point wqe back to the previous one*/

		/*

		 * If we are starting the request from the beginning,

		 * let the normal send code handle initialization.

	/*

	 * Set the state to restart in the middle of a request.

	 * Don't change the s_sge, s_cur_sge, or s_cur_size.

	 * See hfi1_make_rc_req().

		/*

		 * This case shouldn't happen since its only

		 * one PSN per req.

	/*

	 * Set RVT_S_WAIT_PSN as rc_complete() may start the timer

	 * asynchronously before the send engine can get scheduled.

	 * Doing it in hfi1_make_rc_req() is too late.

/*

 * Back up requester to resend the last un-ACKed request.

 * The QP r_lock and s_lock should be held and interrupts disabled.

			/*

			 * We need special handling for the OPFN request WQEs as

			 * they are not allowed to generate real user errors

				/*

				 * Call opfn_conn_reply() with capcode and

				 * remaining data as 0 to close out the

				 * current request

 need to handle delayed completion */

/*

 * Set qp->s_sending_psn to the next PSN after the given one.

 * This would be psn+1 except when RDMA reads or TID RDMA ops

 * are present.

 Find the work request corresponding to the given PSN. */

/**

 * hfi1_rc_verbs_aborted - handle abort status

 * @qp: the QP

 * @opah: the opa header

 *

 * This code modifies both ACK bit in BTH[2]

 * and the s_flags to go into send one mode.

 *

 * This serves to throttle the send engine to only

 * send a single packet in the likely case the

 * a link has gone down.

 ignore responses */

/*

 * This should be called with the QP s_lock held and interrupts disabled.

	/*

	 * Don't attempt to reset the sending PSN for packets in the

	 * KDETH PSN space since the PSN does not match anything.

 Handle TID RDMA WRITE packets differently */

		/*

		 * s_tid_cur is set to s_tid_head in the case, where

		 * a new TID RDMA request is being started and all

		 * previous ones have been completed.

		 * Therefore, we need to do a secondary check in order

		 * to properly determine whether we should start the

		 * RC timer.

	/*

	 * Start timer after a packet requesting an ACK has been sent and

	 * there are still requests that haven't been acked.

 Start TID RDMA ACK timer */

		/*

		 * The TID RDMA ACK packet could be received before this

		 * function is called. Therefore, add the timer only if TID

		 * RDMA ACK packets are actually pending.

	/*

	 * If we were waiting for sends to complete before re-sending,

	 * and they are now complete, restart sending.

/*

 * Generate a SWQE completion.

 * This is similar to hfi1_send_complete but has to check to be sure

 * that the SGEs are not being referenced if the SWQE is being resent.

	/*

	 * Don't decrement refcount and don't generate a

	 * completion if the SWQE is being resent until the send

	 * is finished.

		/*

		 * If send progress not running attempt to progress

		 * SDMA queue.

 For now use sc to find engine */

	/*

	 * Don't update the last PSN if the request being completed is

	 * a TID RDMA WRITE request.

	 * Completion of the TID RDMA WRITE requests are done by the

	 * TID RDMA ACKs and as such could be for a request that has

	 * already been ACKed as far as the IB state machine is

	 * concerned.

	/*

	 * If we are completing a request which is in the process of

	 * being resent, we can stop re-sending it since we know the

	 * responder has already seen it.

 Retry this request. */

/**

 * update_qp_retry_state - Update qp retry state.

 * @qp: the QP

 * @psn: the packet sequence number of the TID RDMA WRITE RESP.

 * @spsn:  The start psn for the given TID RDMA WRITE swqe.

 * @lpsn:  The last psn for the given TID RDMA WRITE swqe.

 *

 * This function is called to update the qp retry state upon

 * receiving a TID WRITE RESP after the qp is scheduled to retry

 * a request.

	/*

	 * If this is the first TID RDMA WRITE RESP packet for the current

	 * request, change the s_state so that the retry will be processed

	 * correctly. Similarly, if this is the last TID RDMA WRITE RESP

	 * packet, change the s_state and advance the s_cur.

/*

 * do_rc_ack - process an incoming RC ACK

 * @qp: the QP the ACK came in on

 * @psn: the packet sequence number of the ACK

 * @opcode: the opcode of the request that resulted in the ACK

 *

 * This is called from rc_rcv_resp() to process an incoming RC ACK

 * for the given QP.

 * May be called at interrupt level, with the QP s_lock held.

 * Returns 1 if OK, 0 if current operation should be aborted (NAK).

	/*

	 * Note that NAKs implicitly ACK outstanding SEND and RDMA write

	 * requests and implicitly NAK RDMA read and atomic requests issued

	 * before the NAK'ed request.  The MSN won't include the NAK'ed

	 * request but will include an ACK'ed request(s).

	/*

	 * The MSN might be for a later WQE than the PSN indicates so

	 * only complete WQEs that the PSN finishes.

		/*

		 * RDMA_READ_RESPONSE_ONLY is a special case since

		 * we want to generate completion events for everything

		 * before the RDMA read, copy the data, then generate

		 * the completion for the read.

		/*

		 * If this request is a RDMA read or atomic, and the ACK is

		 * for a later operation, this ACK NAKs the RDMA read or

		 * atomic.  In other words, only a RDMA_READ_LAST or ONLY

		 * can ACK a RDMA read and likewise for atomic ops.  Note

		 * that the NAK case can only happen if relaxed ordering is

		 * used and requests are sent after an RDMA read or atomic

		 * is sent but before the response is received.

			/*

			 * No need to process the ACK/NAK since we are

			 * restarting an earlier request.

 Restart sending task if fence is complete */

		/*

		 * TID RDMA WRITE requests will be completed by the TID RDMA

		 * ACK packet handler (see tid_rdma.c).

 ACK */

			/*

			 * Stop timers if we've received all of the TID RDMA

			 * WRITE * responses.

				/*

				 * Normally, the loop above would correctly

				 * process all WQEs from s_acked onward and

				 * either complete them or check for correct

				 * PSN sequencing.

				 * However, for TID RDMA, due to pipelining,

				 * the response may not be for the request at

				 * s_acked so the above look would just be

				 * skipped. This does not allow for checking

				 * the PSN sequencing. It has to be done

				 * separately.

				/*

				 * If the psn is being resent, stop the

				 * resending.

				/*

				 * We are expecting more ACKs so

				 * mod the retry timer.

				/*

				 * We can stop re-sending the earlier packets

				 * and continue with the next packet the

				 * receiver wants.

 No more acks - kill all timers */

		/*

		 * If the current request is a TID RDMA WRITE request and the

		 * response is not a TID RDMA WRITE RESP packet, s_last_psn

		 * can't be advanced.

 RNR NAK */

		/*

		 * The last valid PSN is the previous PSN. For TID RDMA WRITE

		 * request, s_last_psn should be incremented only when a TID

		 * RDMA WRITE RESP is received to avoid skipping lost TID RDMA

		 * WRITE RESP packets.

 NAK */

 The last valid PSN is the previous PSN. */

 PSN sequence error */

			/*

			 * Back up to the responder's expected PSN.

			 * Note that we might get a NAK in the middle of an

			 * RDMA READ response which terminates the RDMA

			 * READ.

 Invalid Request */

 Remote Access Error */

 Remote Operation Error */

 Ignore other reserved NAK error codes */

 2: reserved */

 Ignore reserved NAK codes. */

 cannot be reached  */

/*

 * We have seen an out of sequence RDMA read middle or last packet.

 * This ACKs SENDs and RDMA writes up to the first RDMA read or atomic SWQE.

 Remove QP from retry timer */

/**

 * rc_rcv_resp - process an incoming RC response packet

 * @packet: data packet information

 *

 * This is called from hfi1_rc_rcv() to process an incoming RC response

 * packet for the given QP.

 * Called at interrupt level.

 Ignore invalid responses. */

 Ignore duplicate responses. */

 Update credits for "ghost" ACKs */

	/*

	 * Skip everything other than the PSN we expect, if we are waiting

	 * for a reply to a restarted RDMA read or atomic op.

		/*

		 * If this is a response to a resent RDMA read, we

		 * have to be careful to copy the data to the right

		 * location.

 no AETH, no ACK */

		/*

		 * We got a response so update the timeout.

		 * 4.096 usec. * (1 << qp->timeout)

		/*

		 * Update the RDMA receive state but do the copy w/o

		 * holding the locks and blocking interrupts.

		/*

		 * Check that the data size is >= 0 && <= pmtu.

		 * Remember to account for ICRC (4).

		/*

		 * If this is a response to a resent RDMA read, we

		 * have to be careful to copy the data to the right

		 * location.

 ACKs READ req. */

		/*

		 * Check that the data size is >= 1 && <= pmtu.

		 * Remember to account for ICRC (4).

/**

 * rc_rcv_error - process an incoming duplicate or error RC packet

 * @ohdr: the other headers for this packet

 * @data: the packet data

 * @qp: the QP for this packet

 * @opcode: the opcode for this packet

 * @psn: the packet sequence number for this packet

 * @diff: the difference between the PSN and the expected PSN

 * @rcd: the receive context

 *

 * This is called from hfi1_rc_rcv() to process an unexpected

 * incoming RC packet for the given QP.

 * Called at interrupt level.

 * Return 1 if no more processing is needed; otherwise return 0 to

 * schedule a response to be sent.

 most recent ACK */

		/*

		 * Packet sequence error.

		 * A NAK will ACK earlier sends and RDMA writes.

		 * Don't queue the NAK if we already sent one.

 Use the expected PSN. */

			/*

			 * Wait to send the sequence NAK until all packets

			 * in the receive queue have been processed.

			 * Otherwise, we end up propagating congestion.

	/*

	 * Handle a duplicate request.  Don't re-execute SEND, RDMA

	 * write or atomic op.  Don't NAK errors, just silently drop

	 * the duplicate request.  Note that r_sge, r_len, and

	 * r_rcv_len may be in use so don't modify them.

	 *

	 * We are supposed to ACK the earliest duplicate PSN but we

	 * can coalesce an outstanding duplicate ACK.  We have to

	 * send the earliest so that RDMA reads can be restarted at

	 * the requester's expected PSN.

	 *

	 * First, find where this duplicate PSN falls within the

	 * ACKs previously sent.

	 * old_req is true if there is an older response that is scheduled

	 * to be sent before sending this one.

		/*

		 * If we didn't find the RDMA read request in the ack queue,

		 * we can ignore this request.

 RETH comes after BTH */

		/*

		 * Address range must be a subset of the original

		 * request and start on pmtu boundaries.

		 * We reuse the old ack_queue slot since the requester

		 * should not back up and request an earlier PSN for the

		 * same request.

		/*

		 * If we didn't find the atomic request in the ack queue

		 * or the send engine is already backed up to send an

		 * earlier entry, we can ignore this request.

		/*

		 * Ignore this operation if it doesn't request an ACK

		 * or an earlier RDMA read or atomic is going to be resent.

		/*

		 * Resend the most recent ACK if this request is

		 * after all the previous RDMA reads and atomics.

		/*

		 * Resend the RDMA read or atomic op which

		 * ACKs this duplicate request.

 keep timestamp in units of 1.024 usec */

	/*

	 * 1) increase CCTI (for this SL)

	 * 2) select IPG (i.e., call set_link_ipg())

	 * 3) start timer

 ccti_timer is in units of 1.024 usec */

/**

 * hfi1_rc_rcv - process an incoming RC packet

 * @packet: data packet information

 *

 * This is called from qp_rcv() to process an incoming RC packet

 * for the given QP.

 * May be called at interrupt level.

	/*

	 * Process responses (ACKs) before anything else.  Note that the

	 * packet sequence number will be for something in the send work

	 * queue rather than the expected receive packet sequence number.

	 * In other words, this QP is the requester.

 Compute 24 bits worth of difference. */

 Check for opcode sequence errors. */

		/*

		 * Note that it is up to the requester to not send a new

		 * RDMA read or atomic operation before receiving an ACK

		 * for the previous operation.

 OK, process the packet. */

 Check for invalid length PMTU or posted rwqe len. */

		/*

		 * There will be no padding for 9B packet but 16B packets

		 * will come in with some padding since we always add

		 * CRC and LT bytes which will need to be flit aligned

 consume RWQE */

 for SEND_ONLY_WITH_IMMEDIATE */

 Check for invalid length. */

 LAST len should be >= 1 */

 Don't count the CRC(and padding and LT byte for 16B). */

		/*

		 * It seems that IB mandates the presence of an SL in a

		 * work completion only for the UD transport (see section

		 * 11.4.2 of IBTA Vol. 1).

		 *

		 * However, the way the SL is chosen below is consistent

		 * with the way that IB/qib works and is trying avoid

		 * introducing incompatibilities.

		 *

		 * See also OPA Vol. 1, section 9.7.6, and table 9-17.

 zero fields that are N/A */

 Signal completion event if the solicited bit is set. */

 consume RWQE */

 Check rkey & NAK */

 peer will send again */

 s_ack_queue is size rvt_size_atomic()+1 so use > not >= */

 Check rkey & NAK */

			/*

			 * Update the next expected PSN.  We add 1 later

			 * below, so only add the remainder here.

		/*

		 * We need to increment the MSN here instead of when we

		 * finish sending the result since a duplicate request would

		 * increment it more than once.

 Schedule the send engine. */

 Process OPFN special virtual address */

 Check rkey & NAK */

 Perform atomic OP and save result. */

 Schedule the send engine. */

 NAK unknown opcodes. */

 Send an ACK if requested or required. */

 Queue RNR NAK for later */

 Queue NAK for later */

 Queue NAK for later */

 Only deal with RDMA Writes for now */

 Use the expected PSN. */

			/*

			 * Wait to send the sequence

			 * NAK until all packets

			 * in the receive queue have

			 * been processed.

			 * Otherwise, we end up

			 * propagating congestion.

 Out of sequence NAK */

 QP Request NAKs */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2020 Intel Corporation.

 *

/*

 * This file contains HFI1 support for netdev RX functionality

 Now allocate the RcvHdr queue and eager buffers. */

 Netdev contexts are always NO_RDMA_RTAIL */

	/*

	 * Disable receive context and interrupt available, reset all

	 * RcvCtxtCtrl bits to default values.

/**

 * hfi1_num_netdev_contexts - Count of netdev recv contexts to use.

 * @dd: device on which to allocate netdev contexts

 * @available_contexts: count of available receive contexts

 * @cpu_mask: mask of possible cpus to include for contexts

 *

 * Return: count of physical cores on a node or the remaining available recv

 * contexts for netdev recv context usage up to the maximum of

 * HFI1_MAX_NETDEV_CTXTS.

 * A value of 0 can be returned when acceleration is explicitly turned off,

 * a memory allocation error occurs or when there are no available contexts.

 *

 Always give user contexts priority over netdev contexts */

		/*

		 * Disable BUSY_POLL on this NAPI as this is not supported

		 * right now.

 wait for napi if it was scheduled */

/**

 * hfi1_netdev_rx_init - Incrememnts netdevs counter. When called first time,

 * it allocates receive queue data and calls netif_napi_add

 * for each queue.

 *

 * @dd: hfi1 dev data

/**

 * hfi1_netdev_rx_destroy - Decrements netdevs counter, when it reaches 0

 * napi is deleted and receive queses memory is freed.

 *

 * @dd: hfi1 dev data

 destroy the RX queues only if it is the last netdev going away */

/**

 * hfi1_alloc_rx - Allocates the rx support structure

 * @dd: hfi1 dev data

 *

 * Allocate the rx structure to support gathering the receive

 * resources and the dummy netdev.

 *

 * Updates dd struct pointer upon success.

 *

 * Return: 0 (success) -error on failure

 *

/**

 * hfi1_netdev_enable_queues - This is napi enable function.

 * It enables napi objects associated with queues.

 * When at least one device has called it it increments atomic counter.

 * Disable function decrements counter and when it is 0,

 * calls napi_disable for every queue.

 *

 * @dd: hfi1 dev data

/**

 * hfi1_netdev_add_data - Registers data with unique identifier

 * to be requested later this is needed for VNIC and IPoIB VLANs

 * implementations.

 * This call is protected by mutex idr_lock.

 *

 * @dd: hfi1 dev data

 * @id: requested integer id up to INT_MAX

 * @data: data to be associated with index

/**

 * hfi1_netdev_remove_data - Removes data with previously given id.

 * Returns the reference to removed entry.

 *

 * @dd: hfi1 dev data

 * @id: requested integer id up to INT_MAX

/**

 * hfi1_netdev_get_data - Gets data with given id

 *

 * @dd: hfi1 dev data

 * @id: requested integer id up to INT_MAX

/**

 * hfi1_netdev_get_first_data - Gets first entry with greater or equal id.

 *

 * @dd: hfi1 dev data

 * @start_id: requested integer id up to INT_MAX

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015, 2016 Intel Corporation.

/*

 * The EPROM is logically divided into three partitions:

 *	partition 0: the first 128K, visible from PCI ROM BAR

 *	partition 1: 4K config file (sector size)

 *	partition 2: the rest

 controller page size, in bytes */

 controller commands */

 controller interface speeds */

 full speed */

/*

 * How long to wait for the EPROM to become available, in ms.

 * The spec 32 Mb EPROM takes around 40s to erase then write.

 * Double it for safety.

 ms */

/*

 * Read a 256 byte (64 dword) EPROM page.

 * All callers have verified the offset is at a page boundary.

 close open page */

/*

 * Read length bytes starting at offset from the start of the EPROM.

	/*

	 * Make sure the read range is not outside of the controller read

	 * command address range.  Note that '>' is correct below - the end

	 * of the range is OK if it stops at the limit, but no higher.

 read the first partial page */

 partial starting page */

 align and read the page that contains the start */

 the rest of the page is available data */

 end is within this page */

 start is now page aligned */

 read whole pages */

 read the last partial page */

/*

 * Initialize the EPROM handler.

 only the discrete chip has an EPROM */

	/*

	 * It is OK if both HFIs reset the EPROM as long as they don't

	 * do it at the same time.

 reset EPROM to be sure it is in a good state */

 set reset */

 clear reset, set speed */

 wake the device with command "release powerdown NoID" */

 magic character sequence that begins an image */

 magic character sequence that might trail an image */

 EPROM file types */

 segment size - 128 KiB */

 size of the oprom, in bytes */

 version of this footer */

 must be last */

 file type */

 file offset from start of EPROM */

 file size, in bytes */

/*

 * Calculate the max number of table entries that will fit within a directory

 * buffer of size 'dir_size'.

/*

 * Read all of partition 1.  The actual file is at the front.  Adjust

 * the returned size if a trailing image magic is found.

 config partition is valid only if it starts with IMAGE_START_MAGIC */

 scan for image magic that may trail the actual data */

/*

 * The segment magic has been checked.  There is a footer and table of

 * contents present.

 *

 * directory is a u32 aligned buffer of size EP_PAGE_SIZE.

 the footer is at the end of the directory */

 make sure the structure version is supported */

 oprom size cannot be larger than a segment */

 the file table must fit in a segment with the oprom */

 find the file table start, which precedes the footer */

 the file table fits into the directory buffer handed in */

 need to allocate and read more */

 look for the platform configuration file in the table */

	/*

	 * Sanity check on the configuration file size - it should never

	 * be larger than 4 KiB.

 check for bogus offset and size that wrap when added together */

 allocate the buffer to return */

	/*

	 * Extract the file by looping over segments until it is fully read.

 calculate data bytes available in this segment */

 start with the bytes from the current offset to the end */

 subtract off footer and table from segment 0 */

			/*

			 * Sanity check: should not have a starting point

			 * at or within the directory.

 calculate bytes wanted */

 max out at the available bytes in this segment */

		/*

		 * Read from the EPROM.

		 *

		 * The sanity check for entry->offset is done in read_length().

		 * The EPROM offset is validated against what the hardware

		 * addressing supports.  In addition, if the offset is larger

		 * than the actual EPROM, it silently wraps.  It will work

		 * fine, though the reader may not get what they expected

		 * from the EPROM.

 set up for next segment */

 success */

/*

 * Read the platform configuration file from the EPROM.

 *

 * On success, an allocated buffer containing the data and its size are

 * returned.  It is up to the caller to free this buffer.

 *

 * Return value:

 *   0	      - success

 *   -ENXIO   - no EPROM is available

 *   -EBUSY   - not able to acquire access to the EPROM

 *   -ENOENT  - no recognizable file written

 *   -ENOMEM  - buffer could not be allocated

 *   -EINVAL  - invalid EPROM contentents found

 aligned buffer */

 read the last page of the segment for the EPROM format magic */

 last dword of the segment contains a magic value */

 segment format */

 partition format */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2018 Intel Corporation.

 must be a power of 2 >= 64 <= 32768 */

 max wait time for a SDMA engine to indicate it has halted */

 ms */

 all SDMA engine errors that cause a halt */

 sdma_sendctrl operations */

 handle long defines */

 declare all statics here rather than keep sorting */

/**

 * sdma_state_name() - return state string from enum

 * @state: state

/*

 * sdma_wait_for_packet_egress() - wait for the VL FIFO occupancy for

 * sdma engine 'sde' to drop to 0.

 counter is reest if accupancy count changes */

 timed out - bounce the link */

/*

 * sdma_wait() - wait for packet egress to complete for all SDMA engines,

 * and pause for credit return.

 protect against complete modifying */

/*

 * Complete all the sdma requests with a SDMA_TXREQ_S_ABORTED status

 *

 * Depending on timing there can be txreqs in two places:

 * - in the descq ring

 * - in the flush list

 *

 * To avoid ordering issues the descq ring needs to be flushed

 * first followed by the flush list.

 *

 * This routine is called from two places

 * - From a work queue item

 * - Directly from the state machine just before setting the

 *   state to running

 *

 * Must be called with head_lock held

 *

 flush from head to tail */

 copy flush list */

 flush from flush list */

 wakeup QPs orphaned on the dmawait list */

/*

 * Fields a work request for flushing the descq ring

 * and the flush list

 *

 * If the engine has been brought to running during

 * the scheduling delay, the flush is ignored, assuming

 * that the process of bringing the engine to running

 * would have done this flush prior to going to running.

 *

			/*

			 * Continue anyway.  This could happen if there was

			 * an uncorrectable error in the wrong spot.

 check progress on each engine except the current one */

		/*

		 * We must lock interrupts when acquiring sde->lock,

		 * to avoid a deadlock if interrupt triggers and spins on

		 * the same lock on same CPU

 skip non-running queues */

/*

 * flush ring for recovery

	/* The reason for some of the complexity of this code is that

	 * not all descriptors have corresponding txps.  So, we have to

	 * be able to skip over descs until we wander into the range of

	 * the next txp on the list.

 advance head, wrap if needed */

 if now past this txp's descs, do the callback */

 remove from list */

	/*

	 * At this point, the following should always be true:

	 * - We are halted, so no more descriptors are getting retired.

	 * - We are not running, so no one is submitting new work.

	 * - Only we can send the e40_sw_cleaned, so we can't start

	 *   running again until we say so.  So, the active list and

	 *   descq are ours to play with.

	/*

	 * In the error clean up sequence, software clean must be called

	 * before the hardware clean so we can use the hardware head in

	 * the progress routine.  A hardware clean or SPC unfreeze will

	 * reset the hardware head.

	 *

	 * Process all retired requests. The progress routine will use the

	 * latest physical hardware head - we are not running so speed does

	 * not matter.

	/*

	 * Reset our notion of head and tail.

	 * Note that the HW registers have been reset via an earlier

	 * clean up.

 Releasing this reference means the state machine has stopped. */

 stop waiting for all unfreeze events to complete */

 debugging bookkeeping */

/**

 * sdma_get_descq_cnt() - called when device probed

 *

 * Return a validated descq count.

 *

 * This is currently only used in the verbs initialization to build the tx

 * list.

 *

 * This will probably be deleted in favor of a more scalable approach to

 * alloc tx's.

 *

	/* count must be a power of 2 greater than 64 and less than

	 * 32768.   Otherwise return default.

/**

 * sdma_engine_get_vl() - return vl for a given sdma engine

 * @sde: sdma engine

 *

 * This function returns the vl mapped to a given engine, or an error if

 * the mapping can't be found. The mapping fields are protected by RCU.

/**

 * sdma_select_engine_vl() - select sdma engine

 * @dd: devdata

 * @selector: a spreading factor

 * @vl: this vl

 *

 *

 * This function returns an engine based on the selector and a vl.  The

 * mapping fields are protected by RCU.

	/* NOTE This should only happen if SC->VL changed after the initial

	 *      checks on the QP/AH

	 *      Default will return engine 0 below

/**

 * sdma_select_engine_sc() - select sdma engine

 * @dd: devdata

 * @selector: a spreading factor

 * @sc5: the 5 bit sc

 *

 *

 * This function returns an engine based on the selector and an sc.

/*

 * sdma_select_user_engine() - select sdma engine based on user setup

 * @dd: devdata

 * @selector: a spreading factor

 * @vl: this vl

 *

 * This function returns an sdma engine for a user sdma request.

 * User defined sdma engine affinity setting is honored when applicable,

 * otherwise system default sdma engine mapping is used. To ensure correct

 * ordering, the mapping from <selector, vl> to sde must remain unchanged.

	/*

	 * To ensure that always the same sdma engine(s) will be

	 * selected make sure the process is pinned to this CPU only.

 only need to check the first ctr entries for a match */

/*

 * Prevents concurrent reads and writes of the sdma engine cpu_mask

 Check if we have this already mapped */

 Add new user mappings */

 Populate the sde map table */

 Clean up old mappings */

 Don't cleanup sdes that are set in the new mask */

 Remove mappings for old sde */

 Free empty hash table entries */

/**

 * sdma_seqfile_dump_cpu_list() - debugfs dump the cpu to sdma mappings

 * @s: seq file

 * @dd: hfi1_devdata

 * @cpuid: cpu id

 *

 * This routine dumps the process to sde mappings per cpu

/*

 * Free the indicated map struct

/*

 * Handle RCU callback

/**

 * sdma_map_init - called when # vls change

 * @dd: hfi1_devdata

 * @port: port number

 * @num_vls: number of vls

 * @vl_engines: per vl engine mapping (optional)

 *

 * This routine changes the mapping based on the number of vls.

 *

 * vl_engines is used to specify a non-uniform vl/engine loading. NULL

 * implies auto computing the loading and giving each VLs a uniform

 * distribution of engines per VL.

 *

 * The auto algorithm computes the sde_per_vl and the number of extra

 * engines.  Any extra engines are added from the last VL on down.

 *

 * rcu locking is used here to control access to the mapping fields.

 *

 * If either the num_vls or num_sdma are non-power of 2, the array sizes

 * in the struct sdma_vl_map and the struct sdma_map_elem are rounded

 * up to the next highest power of 2 and the first entry is reused

 * in a round robin fashion.

 *

 * If an error occurs the map change is not done and the mapping is

 * not changed.

 *

 truncate divide */

 extras */

 add extras from last vl down */

 build new map */

 initialize back-map */

 save for wrap around */

 only allocate once */

 assign engines */

 wrap back to first engine */

 assign back-map */

 just re-use entry without allocating */

 newmap in hand, save old map */

 publish newmap */

 success, free any old map after grace period */

 free any partial allocation */

/**

 * sdma_clean - Clean up allocated memory

 * @dd:          struct hfi1_devdata

 * @num_engines: num sdma engines

 *

 * This routine can be called regardless of the success of

 * sdma_init()

/**

 * sdma_init() - called when device probed

 * @dd: hfi1_devdata

 * @port: port number (currently only zero)

 *

 * Initializes each sde and its csrs.

 * Interrupts are not required to be enabled.

 *

 * Returns:

 * 0 - success, -errno on failure

 can't exceed chip support */

 count must be >= vls */

 set up freeze waitqueue */

 alloc memory for array of send engines */

 Allocate memory for SendDMA descriptor FIFOs */

 Create a mask specifically for each interrupt source */

 Create a combined mask to cover all 3 interrupt sources */

 insure there is always a zero bit */

 set up reference counting */

 Allocate memory for DMA of head registers to memory */

 Allocate memory for pad */

 assign each engine to different cacheline and init registers */

/**

 * sdma_all_running() - called when the link goes up

 * @dd: hfi1_devdata

 *

 * This routine moves all engines to the running state.

 move all engines to running */

/**

 * sdma_all_idle() - called when the link goes down

 * @dd: hfi1_devdata

 *

 * This routine moves all engines to the idle state.

 idle all engines */

/**

 * sdma_start() - called to kick off state processing for all engines

 * @dd: hfi1_devdata

 *

 * This routine is for kicking off the state processing for all required

 * sdma engines.  Interrupts need to be working at this point.

 *

 kick off the engines state processing */

/**

 * sdma_exit() - used when module is removed

 * @dd: hfi1_devdata

		/*

		 * This waits for the state machine to exit so it is not

		 * necessary to kill the sdma_sw_clean_up_task to make sure

		 * it is not running.

/*

 * unmap the indicated descriptor

/*

 * return the mode as indicated by the first

 * descriptor in the tx.

/**

 * __sdma_txclean() - clean tx of mappings, descp *kmalloc's

 * @dd: hfi1_devdata for unmapping

 * @tx: tx request to clean

 *

 * This is used in the progress routine to clean the tx or

 * by the ULP to toss an in-process tx build.

 *

 * The code can be called multiple times without issue.

 *

 unmap first */

 determine number of AHG descriptors to skip */

 kmalloc'ed descp */

 this code is really bad for cache line trading */

 not wrapped */

 wrapped around */

 empty */

 try one more time, using csr */

 proceed as if no progress */

/*

 * This is called when there are send DMA descriptors that might be

 * available.

 *

 * This is called with head_lock held.

 at least one item */

 Harvest waiters wanting DMA descriptors */

 Find the top-priority wait memeber */

 Schedule the top-priority entry first */

 head_lock must be held */

	/* The reason for some of the complexity of this code is that

	 * not all descriptors have corresponding txps.  So, we have to

	 * be able to skip over descs until we wander into the range of

	 * the next txp on the list.

 advance head, wrap if needed */

 if now past this txp's descs, do the callback */

 remove from list */

 see if there is another txp */

	/*

	 * The SDMA idle interrupt is not guaranteed to be ordered with respect

	 * to updates to the dma_head location in host memory. The head

	 * value read might not be fully up to date. If there are pending

	 * descriptors and the SDMA idle interrupt fired then read from the

	 * CSR SDMA head instead to get the latest value from the hardware.

	 * The hardware SDMA head should be read at most once in this invocation

	 * of sdma_make_progress(..) which is ensured by idle_check_done flag

/*

 * sdma_engine_interrupt() - interrupt handler for engine

 * @sde: sdma engine

 * @status: sdma interrupt reason

 *

 * Status is a mask of the 3 possible interrupts for this engine.  It will

 * contain bits _only_ for this SDMA engine.  It will contain at least one

 * bit, it may contain more.

/**

 * sdma_engine_error() - error handler for engine

 * @sde: sdma engine

 * @status: sdma interrupt reason

	/*

	 * Set SendDmaLenGen and clear-then-set the MSB of the generation

	 * count to enable generation checking and load the internal

	 * generation counter.

 Commit writes to memory and advance the tail on the chip */

 see get_txhead() */

/*

 * This is called when changing to state s10_hw_start_up_halt_wait as

 * a result of send buffer errors or send DMA descriptor errors.

 Set SendDmaTail */

/*

 * set_sdma_integrity

 *

 * Set the SEND_DMA_CHECK_ENABLE register for send DMA engine 'sde'.

 Set SendDmaTail */

 sdma_dumpstate_helper(SEND_EGRESS_SEND_DMA_STATUS);  */

 print info for each entry in the descriptor queue */

/**

 * sdma_seqfile_dump_sde() - debugfs dump of sde

 * @s: seq file

 * @sde: send dma engine to dump

 *

 * This routine dumps the sde to the indicated seq file.

 print info for each entry in the descriptor queue */

/*

 * add the generation number into

 * the qw1 and return

/*

 * This routine submits the indicated tx

 *

 * Space has already been guaranteed and

 * tail side of ring is locked.

 *

 * The hardware tail update is done

 * in the caller and that is facilitated

 * by returning the new tail.

 *

 * There is special case logic for ahg

 * to not add the generation number for

 * up to 2 descriptors that follow the

 * first descriptor.

 *

 edits don't have generation */

 replace generation with real one for non-edits */

/*

 * Check for progress

 pulse the head_lock */

/**

 * sdma_send_txreq() - submit a tx req to ring

 * @sde: sdma engine to use

 * @wait: SE wait structure to use when full (may be NULL)

 * @tx: sdma_txreq to submit

 * @pkts_sent: has any packet been sent yet?

 *

 * The call submits the tx into the ring.  If a iowait structure is non-NULL

 * the packet will be queued to the list in wait.

 *

 * Return:

 * 0 - Success, -EINVAL - sdma_txreq incomplete, -EBUSY - no space in

 * ring (wait == NULL)

 * -EIOCBQUEUED - tx queued to iowait, -ECOMM bad sdma state

 user should have supplied entire packet */

/**

 * sdma_send_txlist() - submit a list of tx req to ring

 * @sde: sdma engine to use

 * @wait: SE wait structure to use when full (may be NULL)

 * @tx_list: list of sdma_txreqs to submit

 * @count_out: pointer to a u16 which, after return will contain the total number of

 *             sdma_txreqs removed from the tx_list. This will include sdma_txreqs

 *             whose SDMA descriptors are submitted to the ring and the sdma_txreqs

 *             which are added to SDMA engine flush list if the SDMA engine state is

 *             not running.

 *

 * The call submits the list into the ring.

 *

 * If the iowait structure is non-NULL and not equal to the iowait list

 * the unprocessed part of the list  will be appended to the list in wait.

 *

 * In all cases, the tx_list will be updated so the head of the tx_list is

 * the list of descriptors that have yet to be transmitted.

 *

 * The intent of this call is to provide a more efficient

 * way of submitting multiple packets to SDMA while holding the tail

 * side locking.

 *

 * Return:

 * 0 - Success,

 * -EINVAL - sdma_txreq incomplete, -EBUSY - no space in ring (wait == NULL)

 * -EIOCBQUEUED - tx queued to iowait, -ECOMM bad sdma state

 CONFIG SDMA temporary */

			/*

			 * If down, but running requested (usually result

			 * of link up, then we need to start up.

			 * This can happen when hw down is requested while

			 * bringing the link up with traffic active on

			 * 7220, e.g.

 and start dma engine */

 This reference means the state machine is started */

 notify caller this engine is done cleaning */

			/*

			* SW initiated halt does not perform engines

			* progress check

/*

 * _extend_sdma_tx_descs() - helper to extend txreq

 *

 * This is called once the initial nominal allocation

 * of descriptors in the sdma_txreq is exhausted.

 *

 * The code will bump the allocation up to the max

 * of MAX_DESC (64) descriptors. There doesn't seem

 * much point in an interim step. The last descriptor

 * is reserved for coalesce buffer in order to support

 * cases where input packet has >MAX_DESC iovecs.

 *

 Handle last descriptor */

 if tlen is 0, it is for padding, release last descriptor */

 allocate coalesce buffer with space for padding */

 reserve last descriptor for coalescing */

 copy ones already built */

/*

 * ext_coal_sdma_tx_descs() - extend or coalesce sdma tx descriptors

 *

 * This is called once the initial nominal allocation of descriptors

 * in the sdma_txreq is exhausted.

 *

 * This function calls _extend_sdma_tx_descs to extend or allocate

 * coalesce buffer. If there is a allocated coalesce buffer, it will

 * copy the input packet data into the coalesce buffer. It also adds

 * coalesce buffer descriptor once when whole packet is received.

 *

 * Return:

 * <0 - error

 * 0 - coalescing, don't populate descriptor

 * 1 - continue with populating descriptor

 If coalesce buffer is allocated, copy data into it */

 If there is more data, return */

 Whole packet is received; add any padding */

 padding is taken care of for coalescing case */

 dma map the coalesce buffer */

 Add descriptor for coalesce buffer */

 Update sdes when the lmc changes */

 tx not dword sized - pad */

 finish the one just added */

/*

 * Add ahg to the sdma_txreq

 *

 * The logic will consume up to 3

 * descriptors at the beginning of

 * sdma_txreq.

 compute mode */

 initialize to consumed descriptors to zero */

/**

 * sdma_ahg_alloc - allocate an AHG entry

 * @sde: engine to allocate from

 *

 * Return:

 * 0-31 when successful, -EOPNOTSUPP if AHG is not enabled,

 * -ENOSPC if an entry is not available

/**

 * sdma_ahg_free - free an AHG entry

 * @sde: engine to return AHG entry

 * @ahg_index: index to free

 *

 * This routine frees the indicate AHG entry.

/*

 * SPC freeze handling for SDMA engines.  Called when the driver knows

 * the SPC is going into a freeze but before the freeze is fully

 * settled.  Generally an error interrupt.

 *

 * This event will pull the engine out of running so no more entries can be

 * added to the engine's queue.

 set up the wait but do not wait here */

 tell all engines to stop running and wait */

 sdma_freeze() will wait for all engines to have stopped */

/*

 * SPC freeze handling for SDMA engines.  Called when the driver knows

 * the SPC is fully frozen.

	/*

	 * Make sure all engines have moved out of the running state before

	 * continuing.

 interrupted or count is negative, then unloading - just exit */

 set up the count for the next wait */

 tell all engines that the SPC is frozen, they can start cleaning */

	/*

	 * Wait for everyone to finish software clean before exiting.  The

	 * software clean will read engine CSRs, so must be completed before

	 * the next step, which will clear the engine CSRs.

 no need to check results - done no matter what */

/*

 * SPC freeze handling for the SDMA engines.  Called after the SPC is unfrozen.

 *

 * The SPC freeze acts like a SDMA halt and a hardware clean combined.  All

 * that is left is a software clean.  We could do it after the SPC is fully

 * frozen, but then we'd have to add another state to wait for the unfreeze.

 * Instead, just defer the software clean until the unfreeze step.

 tell all engines start freeze clean up */

/**

 * _sdma_engine_progress_schedule() - schedule progress on engine

 * @sde: sdma_engine to schedule progress

 *

 assume we have selected a good cpu */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2020 Intel Corporation.

 * Copyright(c) 2021 Cornelis Networks.

/*

 * This file contains all of the code that is specific to the HFI chip

/*

 * Default time to aggregate two 10K packets from the idle state

 * (timer not running). The timer starts at the end of the first packet,

 * so only the time for one 10K packet and header plus a bit extra is needed.

 * 10 * 1024 + 64 header byte = 10304 byte

 * 10304 byte / 12.5 GB/s = 824.32ns

 16 is for coalescing interrupt */

 same as qib */

 Other driver tunables */

 enable dynamic mode for rcv int mitigation*/

 skip LNI */

 the flag */

 description string */

 extra information */

 str must be a string constant */

 Send Error Consequences */

 per-context only */

 per-HFI only */

/*

 * RSM instance allocation

 *   0 - User Fecn Handling

 *   1 - Vnic

 *   2 - AIP

 *   3 - Verbs

 Bit offset into the GUID which carries HFI id information */

 extract the emulation revision */

 parallel and serial emulation versions are 3 and 4 respectively */

 RSM fields for Verbs */

 packet type */

 QPN[7..1] */

 LRH.BTH: QW 0, OFFSET 48 - for match */

 LRH.SC[3..0] QW 0, OFFSET 56 - for match */

 SC[n..0] QW 0, OFFSET 60 - for select */

 QPN[m+n:1] QW 1, OFFSET 1 */

 RSM fields for AIP */

 LRH.BTH above is reused for this rule */

 BTH.DESTQP: QW 1, OFFSET 16 for match */

 DETH.SQPN: QW 1 Offset 56 for select */

 We use 8 most significant Soure QPN bits as entropy fpr AIP */

 RSM fields for Vnic */

 L2_TYPE: QW 0, OFFSET 61 - for match */

 L4_TYPE QW 1, OFFSET 0 - for match */

 16B VESWID - for select */

 16B ENTROPY - for select */

 defines to build power on SC2VL table */

 all CceStatus sub-block freeze bits */

 all CceStatus sub-block TXE pause bits */

 all CceStatus sub-block RXE pause bits */

/*

 * CCE Error flags.

 0*/	FLAG_ENTRY0("CceCsrParityErr",

 1*/	FLAG_ENTRY0("CceCsrReadBadAddrErr",

 2*/	FLAG_ENTRY0("CceCsrWriteBadAddrErr",

 3*/	FLAG_ENTRY0("CceTrgtAsyncFifoParityErr",

 4*/	FLAG_ENTRY0("CceTrgtAccessErr",

 5*/	FLAG_ENTRY0("CceRspdDataParityErr",

 6*/	FLAG_ENTRY0("CceCli0AsyncFifoParityErr",

 7*/	FLAG_ENTRY0("CceCsrCfgBusParityErr",

 8*/	FLAG_ENTRY0("CceCli2AsyncFifoParityErr",

 9*/	FLAG_ENTRY0("CceCli1AsyncFifoPioCrdtParityErr",

10*/	FLAG_ENTRY0("CceCli1AsyncFifoPioCrdtParityErr",

11*/	FLAG_ENTRY0("CceCli1AsyncFifoRxdmaParityError",

12*/	FLAG_ENTRY0("CceCli1AsyncFifoDbgParityError",

13*/	FLAG_ENTRY0("PcicRetryMemCorErr",

14*/	FLAG_ENTRY0("PcicRetryMemCorErr",

15*/	FLAG_ENTRY0("PcicPostHdQCorErr",

16*/	FLAG_ENTRY0("PcicPostHdQCorErr",

17*/	FLAG_ENTRY0("PcicPostHdQCorErr",

18*/	FLAG_ENTRY0("PcicCplDatQCorErr",

19*/	FLAG_ENTRY0("PcicNPostHQParityErr",

20*/	FLAG_ENTRY0("PcicNPostDatQParityErr",

21*/	FLAG_ENTRY0("PcicRetryMemUncErr",

22*/	FLAG_ENTRY0("PcicRetrySotMemUncErr",

23*/	FLAG_ENTRY0("PcicPostHdQUncErr",

24*/	FLAG_ENTRY0("PcicPostDatQUncErr",

25*/	FLAG_ENTRY0("PcicCplHdQUncErr",

26*/	FLAG_ENTRY0("PcicCplDatQUncErr",

27*/	FLAG_ENTRY0("PcicTransmitFrontParityErr",

28*/	FLAG_ENTRY0("PcicTransmitBackParityErr",

29*/	FLAG_ENTRY0("PcicReceiveParityErr",

30*/	FLAG_ENTRY0("CceTrgtCplTimeoutErr",

31*/	FLAG_ENTRY0("LATriggered",

32*/	FLAG_ENTRY0("CceSegReadBadAddrErr",

33*/	FLAG_ENTRY0("CceSegWriteBadAddrErr",

34*/	FLAG_ENTRY0("CceRcplAsyncFifoParityErr",

35*/	FLAG_ENTRY0("CceRxdmaConvFifoParityErr",

36*/	FLAG_ENTRY0("CceMsixTableCorErr",

37*/	FLAG_ENTRY0("CceMsixTableUncErr",

38*/	FLAG_ENTRY0("CceIntMapCorErr",

39*/	FLAG_ENTRY0("CceIntMapUncErr",

40*/	FLAG_ENTRY0("CceMsixCsrParityErr",

41-63 reserved*/

/*

 * Misc Error flags

 0*/	FLAG_ENTRY0("CSR_PARITY", MES(CSR_PARITY)),

 1*/	FLAG_ENTRY0("CSR_READ_BAD_ADDR", MES(CSR_READ_BAD_ADDR)),

 2*/	FLAG_ENTRY0("CSR_WRITE_BAD_ADDR", MES(CSR_WRITE_BAD_ADDR)),

 3*/	FLAG_ENTRY0("SBUS_WRITE_FAILED", MES(SBUS_WRITE_FAILED)),

 4*/	FLAG_ENTRY0("KEY_MISMATCH", MES(KEY_MISMATCH)),

 5*/	FLAG_ENTRY0("FW_AUTH_FAILED", MES(FW_AUTH_FAILED)),

 6*/	FLAG_ENTRY0("EFUSE_CSR_PARITY", MES(EFUSE_CSR_PARITY)),

 7*/	FLAG_ENTRY0("EFUSE_READ_BAD_ADDR", MES(EFUSE_READ_BAD_ADDR)),

 8*/	FLAG_ENTRY0("EFUSE_WRITE", MES(EFUSE_WRITE)),

 9*/	FLAG_ENTRY0("EFUSE_DONE_PARITY", MES(EFUSE_DONE_PARITY)),

10*/	FLAG_ENTRY0("INVALID_EEP_CMD", MES(INVALID_EEP_CMD)),

11*/	FLAG_ENTRY0("MBIST_FAIL", MES(MBIST_FAIL)),

12*/	FLAG_ENTRY0("PLL_LOCK_FAIL", MES(PLL_LOCK_FAIL))

/*

 * TXE PIO Error flags and consequences

 0*/	FLAG_ENTRY("PioWriteBadCtxt",

 1*/	FLAG_ENTRY("PioWriteAddrParity",

 2*/	FLAG_ENTRY("PioCsrParity",

 3*/	FLAG_ENTRY("PioSbMemFifo0",

 4*/	FLAG_ENTRY("PioSbMemFifo1",

 5*/	FLAG_ENTRY("PioPccFifoParity",

 6*/	FLAG_ENTRY("PioPecFifoParity",

 7*/	FLAG_ENTRY("PioSbrdctlCrrelParity",

 8*/	FLAG_ENTRY("PioSbrdctrlCrrelFifoParity",

 9*/	FLAG_ENTRY("PioPktEvictFifoParityErr",

10*/	FLAG_ENTRY("PioSmPktResetParity",

11*/	FLAG_ENTRY("PioVlLenMemBank0Unc",

12*/	FLAG_ENTRY("PioVlLenMemBank1Unc",

13*/	FLAG_ENTRY("PioVlLenMemBank0Cor",

14*/	FLAG_ENTRY("PioVlLenMemBank1Cor",

15*/	FLAG_ENTRY("PioCreditRetFifoParity",

16*/	FLAG_ENTRY("PioPpmcPblFifo",

17*/	FLAG_ENTRY("PioInitSmIn",

18*/	FLAG_ENTRY("PioPktEvictSmOrArbSm",

19*/	FLAG_ENTRY("PioHostAddrMemUnc",

20*/	FLAG_ENTRY("PioHostAddrMemCor",

21*/	FLAG_ENTRY("PioWriteDataParity",

22*/	FLAG_ENTRY("PioStateMachine",

23*/	FLAG_ENTRY("PioWriteQwValidParity",

24*/	FLAG_ENTRY("PioBlockQwCountParity",

25*/	FLAG_ENTRY("PioVlfVlLenParity",

26*/	FLAG_ENTRY("PioVlfSopParity",

27*/	FLAG_ENTRY("PioVlFifoParity",

28*/	FLAG_ENTRY("PioPpmcBqcMemParity",

29*/	FLAG_ENTRY("PioPpmcSopLen",

30-31 reserved*/

32*/	FLAG_ENTRY("PioCurrentFreeCntParity",

33*/	FLAG_ENTRY("PioLastReturnedCntParity",

34*/	FLAG_ENTRY("PioPccSopHeadParity",

35*/	FLAG_ENTRY("PioPecSopHeadParityErr",

36-63 reserved*/

 TXE PIO errors that cause an SPC freeze */

/*

 * TXE SDMA Error flags

 0*/	FLAG_ENTRY0("SDmaRpyTagErr",

 1*/	FLAG_ENTRY0("SDmaCsrParityErr",

 2*/	FLAG_ENTRY0("SDmaPcieReqTrackingUncErr",

 3*/	FLAG_ENTRY0("SDmaPcieReqTrackingCorErr",

04-63 reserved*/

 TXE SDMA errors that cause an SPC freeze */

 SendEgressErrInfo bits that correspond to a PortXmitDiscard counter */

/*

 * TXE Egress Error flags

 0*/	FLAG_ENTRY0("TxPktIntegrityMemCorErr", SEES(TX_PKT_INTEGRITY_MEM_COR)),

 1*/	FLAG_ENTRY0("TxPktIntegrityMemUncErr", SEES(TX_PKT_INTEGRITY_MEM_UNC)),

 2 reserved */

 3*/	FLAG_ENTRY0("TxEgressFifoUnderrunOrParityErr",

 4*/	FLAG_ENTRY0("TxLinkdownErr", SEES(TX_LINKDOWN)),

 5*/	FLAG_ENTRY0("TxIncorrectLinkStateErr", SEES(TX_INCORRECT_LINK_STATE)),

 6 reserved */

 7*/	FLAG_ENTRY0("TxPioLaunchIntfParityErr",

 8*/	FLAG_ENTRY0("TxSdmaLaunchIntfParityErr",

 9-10 reserved */

11*/	FLAG_ENTRY0("TxSbrdCtlStateMachineParityErr",

12*/	FLAG_ENTRY0("TxIllegalVLErr", SEES(TX_ILLEGAL_VL)),

13*/	FLAG_ENTRY0("TxLaunchCsrParityErr", SEES(TX_LAUNCH_CSR_PARITY)),

14*/	FLAG_ENTRY0("TxSbrdCtlCsrParityErr", SEES(TX_SBRD_CTL_CSR_PARITY)),

15*/	FLAG_ENTRY0("TxConfigParityErr", SEES(TX_CONFIG_PARITY)),

16*/	FLAG_ENTRY0("TxSdma0DisallowedPacketErr",

17*/	FLAG_ENTRY0("TxSdma1DisallowedPacketErr",

18*/	FLAG_ENTRY0("TxSdma2DisallowedPacketErr",

19*/	FLAG_ENTRY0("TxSdma3DisallowedPacketErr",

20*/	FLAG_ENTRY0("TxSdma4DisallowedPacketErr",

21*/	FLAG_ENTRY0("TxSdma5DisallowedPacketErr",

22*/	FLAG_ENTRY0("TxSdma6DisallowedPacketErr",

23*/	FLAG_ENTRY0("TxSdma7DisallowedPacketErr",

24*/	FLAG_ENTRY0("TxSdma8DisallowedPacketErr",

25*/	FLAG_ENTRY0("TxSdma9DisallowedPacketErr",

26*/	FLAG_ENTRY0("TxSdma10DisallowedPacketErr",

27*/	FLAG_ENTRY0("TxSdma11DisallowedPacketErr",

28*/	FLAG_ENTRY0("TxSdma12DisallowedPacketErr",

29*/	FLAG_ENTRY0("TxSdma13DisallowedPacketErr",

30*/	FLAG_ENTRY0("TxSdma14DisallowedPacketErr",

31*/	FLAG_ENTRY0("TxSdma15DisallowedPacketErr",

32*/	FLAG_ENTRY0("TxLaunchFifo0UncOrParityErr",

33*/	FLAG_ENTRY0("TxLaunchFifo1UncOrParityErr",

34*/	FLAG_ENTRY0("TxLaunchFifo2UncOrParityErr",

35*/	FLAG_ENTRY0("TxLaunchFifo3UncOrParityErr",

36*/	FLAG_ENTRY0("TxLaunchFifo4UncOrParityErr",

37*/	FLAG_ENTRY0("TxLaunchFifo5UncOrParityErr",

38*/	FLAG_ENTRY0("TxLaunchFifo6UncOrParityErr",

39*/	FLAG_ENTRY0("TxLaunchFifo7UncOrParityErr",

40*/	FLAG_ENTRY0("TxLaunchFifo8UncOrParityErr",

41*/	FLAG_ENTRY0("TxCreditReturnParityErr", SEES(TX_CREDIT_RETURN_PARITY)),

42*/	FLAG_ENTRY0("TxSbHdrUncErr", SEES(TX_SB_HDR_UNC)),

43*/	FLAG_ENTRY0("TxReadSdmaMemoryUncErr", SEES(TX_READ_SDMA_MEMORY_UNC)),

44*/	FLAG_ENTRY0("TxReadPioMemoryUncErr", SEES(TX_READ_PIO_MEMORY_UNC)),

45*/	FLAG_ENTRY0("TxEgressFifoUncErr", SEES(TX_EGRESS_FIFO_UNC)),

46*/	FLAG_ENTRY0("TxHcrcInsertionErr", SEES(TX_HCRC_INSERTION)),

47*/	FLAG_ENTRY0("TxCreditReturnVLErr", SEES(TX_CREDIT_RETURN_VL)),

48*/	FLAG_ENTRY0("TxLaunchFifo0CorErr", SEES(TX_LAUNCH_FIFO0_COR)),

49*/	FLAG_ENTRY0("TxLaunchFifo1CorErr", SEES(TX_LAUNCH_FIFO1_COR)),

50*/	FLAG_ENTRY0("TxLaunchFifo2CorErr", SEES(TX_LAUNCH_FIFO2_COR)),

51*/	FLAG_ENTRY0("TxLaunchFifo3CorErr", SEES(TX_LAUNCH_FIFO3_COR)),

52*/	FLAG_ENTRY0("TxLaunchFifo4CorErr", SEES(TX_LAUNCH_FIFO4_COR)),

53*/	FLAG_ENTRY0("TxLaunchFifo5CorErr", SEES(TX_LAUNCH_FIFO5_COR)),

54*/	FLAG_ENTRY0("TxLaunchFifo6CorErr", SEES(TX_LAUNCH_FIFO6_COR)),

55*/	FLAG_ENTRY0("TxLaunchFifo7CorErr", SEES(TX_LAUNCH_FIFO7_COR)),

56*/	FLAG_ENTRY0("TxLaunchFifo8CorErr", SEES(TX_LAUNCH_FIFO8_COR)),

57*/	FLAG_ENTRY0("TxCreditOverrunErr", SEES(TX_CREDIT_OVERRUN)),

58*/	FLAG_ENTRY0("TxSbHdrCorErr", SEES(TX_SB_HDR_COR)),

59*/	FLAG_ENTRY0("TxReadSdmaMemoryCorErr", SEES(TX_READ_SDMA_MEMORY_COR)),

60*/	FLAG_ENTRY0("TxReadPioMemoryCorErr", SEES(TX_READ_PIO_MEMORY_COR)),

61*/	FLAG_ENTRY0("TxEgressFifoCorErr", SEES(TX_EGRESS_FIFO_COR)),

62*/	FLAG_ENTRY0("TxReadSdmaMemoryCsrUncErr",

63*/	FLAG_ENTRY0("TxReadPioMemoryCsrUncErr",

/*

 * TXE Egress Error Info flags

 0*/	FLAG_ENTRY0("Reserved", 0ull),

 1*/	FLAG_ENTRY0("VLErr", SEEI(VL)),

 2*/	FLAG_ENTRY0("JobKeyErr", SEEI(JOB_KEY)),

 3*/	FLAG_ENTRY0("JobKeyErr", SEEI(JOB_KEY)),

 4*/	FLAG_ENTRY0("PartitionKeyErr", SEEI(PARTITION_KEY)),

 5*/	FLAG_ENTRY0("SLIDErr", SEEI(SLID)),

 6*/	FLAG_ENTRY0("OpcodeErr", SEEI(OPCODE)),

 7*/	FLAG_ENTRY0("VLMappingErr", SEEI(VL_MAPPING)),

 8*/	FLAG_ENTRY0("RawErr", SEEI(RAW)),

 9*/	FLAG_ENTRY0("RawIPv6Err", SEEI(RAW_IPV6)),

10*/	FLAG_ENTRY0("GRHErr", SEEI(GRH)),

11*/	FLAG_ENTRY0("BypassErr", SEEI(BYPASS)),

12*/	FLAG_ENTRY0("KDETHPacketsErr", SEEI(KDETH_PACKETS)),

13*/	FLAG_ENTRY0("NonKDETHPacketsErr", SEEI(NON_KDETH_PACKETS)),

14*/	FLAG_ENTRY0("TooSmallIBPacketsErr", SEEI(TOO_SMALL_IB_PACKETS)),

15*/	FLAG_ENTRY0("TooSmallBypassPacketsErr", SEEI(TOO_SMALL_BYPASS_PACKETS)),

16*/	FLAG_ENTRY0("PbcTestErr", SEEI(PBC_TEST)),

17*/	FLAG_ENTRY0("BadPktLenErr", SEEI(BAD_PKT_LEN)),

18*/	FLAG_ENTRY0("TooLongIBPacketErr", SEEI(TOO_LONG_IB_PACKET)),

19*/	FLAG_ENTRY0("TooLongBypassPacketsErr", SEEI(TOO_LONG_BYPASS_PACKETS)),

20*/	FLAG_ENTRY0("PbcStaticRateControlErr", SEEI(PBC_STATIC_RATE_CONTROL)),

21*/	FLAG_ENTRY0("BypassBadPktLenErr", SEEI(BAD_PKT_LEN)),

 TXE Egress errors that cause an SPC freeze */

/*

 * TXE Send error flags

 0*/	FLAG_ENTRY0("SendCsrParityErr", SES(CSR_PARITY)),

 1*/	FLAG_ENTRY0("SendCsrReadBadAddrErr", SES(CSR_READ_BAD_ADDR)),

 2*/	FLAG_ENTRY0("SendCsrWriteBadAddrErr", SES(CSR_WRITE_BAD_ADDR))

/*

 * TXE Send Context Error flags and consequences

 0*/	FLAG_ENTRY("InconsistentSop",

 1*/	FLAG_ENTRY("DisallowedPacket",

 2*/	FLAG_ENTRY("WriteCrossesBoundary",

 3*/	FLAG_ENTRY("WriteOverflow",

 4*/	FLAG_ENTRY("WriteOutOfBounds",

 5-63 reserved*/

/*

 * RXE Receive Error flags

 0*/	FLAG_ENTRY0("RxDmaCsrCorErr", RXES(DMA_CSR_COR)),

 1*/	FLAG_ENTRY0("RxDcIntfParityErr", RXES(DC_INTF_PARITY)),

 2*/	FLAG_ENTRY0("RxRcvHdrUncErr", RXES(RCV_HDR_UNC)),

 3*/	FLAG_ENTRY0("RxRcvHdrCorErr", RXES(RCV_HDR_COR)),

 4*/	FLAG_ENTRY0("RxRcvDataUncErr", RXES(RCV_DATA_UNC)),

 5*/	FLAG_ENTRY0("RxRcvDataCorErr", RXES(RCV_DATA_COR)),

 6*/	FLAG_ENTRY0("RxRcvQpMapTableUncErr", RXES(RCV_QP_MAP_TABLE_UNC)),

 7*/	FLAG_ENTRY0("RxRcvQpMapTableCorErr", RXES(RCV_QP_MAP_TABLE_COR)),

 8*/	FLAG_ENTRY0("RxRcvCsrParityErr", RXES(RCV_CSR_PARITY)),

 9*/	FLAG_ENTRY0("RxDcSopEopParityErr", RXES(DC_SOP_EOP_PARITY)),

10*/	FLAG_ENTRY0("RxDmaFlagUncErr", RXES(DMA_FLAG_UNC)),

11*/	FLAG_ENTRY0("RxDmaFlagCorErr", RXES(DMA_FLAG_COR)),

12*/	FLAG_ENTRY0("RxRcvFsmEncodingErr", RXES(RCV_FSM_ENCODING)),

13*/	FLAG_ENTRY0("RxRbufFreeListUncErr", RXES(RBUF_FREE_LIST_UNC)),

14*/	FLAG_ENTRY0("RxRbufFreeListCorErr", RXES(RBUF_FREE_LIST_COR)),

15*/	FLAG_ENTRY0("RxRbufLookupDesRegUncErr", RXES(RBUF_LOOKUP_DES_REG_UNC)),

16*/	FLAG_ENTRY0("RxRbufLookupDesRegUncCorErr",

17*/	FLAG_ENTRY0("RxRbufLookupDesUncErr", RXES(RBUF_LOOKUP_DES_UNC)),

18*/	FLAG_ENTRY0("RxRbufLookupDesCorErr", RXES(RBUF_LOOKUP_DES_COR)),

19*/	FLAG_ENTRY0("RxRbufBlockListReadUncErr",

20*/	FLAG_ENTRY0("RxRbufBlockListReadCorErr",

21*/	FLAG_ENTRY0("RxRbufCsrQHeadBufNumParityErr",

22*/	FLAG_ENTRY0("RxRbufCsrQEntCntParityErr",

23*/	FLAG_ENTRY0("RxRbufCsrQNextBufParityErr",

24*/	FLAG_ENTRY0("RxRbufCsrQVldBitParityErr",

25*/	FLAG_ENTRY0("RxRbufCsrQHdPtrParityErr", RXES(RBUF_CSR_QHD_PTR_PARITY)),

26*/	FLAG_ENTRY0("RxRbufCsrQTlPtrParityErr", RXES(RBUF_CSR_QTL_PTR_PARITY)),

27*/	FLAG_ENTRY0("RxRbufCsrQNumOfPktParityErr",

28*/	FLAG_ENTRY0("RxRbufCsrQEOPDWParityErr", RXES(RBUF_CSR_QEOPDW_PARITY)),

29*/	FLAG_ENTRY0("RxRbufCtxIdParityErr", RXES(RBUF_CTX_ID_PARITY)),

30*/	FLAG_ENTRY0("RxRBufBadLookupErr", RXES(RBUF_BAD_LOOKUP)),

31*/	FLAG_ENTRY0("RxRbufFullErr", RXES(RBUF_FULL)),

32*/	FLAG_ENTRY0("RxRbufEmptyErr", RXES(RBUF_EMPTY)),

33*/	FLAG_ENTRY0("RxRbufFlRdAddrParityErr", RXES(RBUF_FL_RD_ADDR_PARITY)),

34*/	FLAG_ENTRY0("RxRbufFlWrAddrParityErr", RXES(RBUF_FL_WR_ADDR_PARITY)),

35*/	FLAG_ENTRY0("RxRbufFlInitdoneParityErr",

36*/	FLAG_ENTRY0("RxRbufFlInitWrAddrParityErr",

37*/	FLAG_ENTRY0("RxRbufNextFreeBufUncErr", RXES(RBUF_NEXT_FREE_BUF_UNC)),

38*/	FLAG_ENTRY0("RxRbufNextFreeBufCorErr", RXES(RBUF_NEXT_FREE_BUF_COR)),

39*/	FLAG_ENTRY0("RxLookupDesPart1UncErr", RXES(LOOKUP_DES_PART1_UNC)),

40*/	FLAG_ENTRY0("RxLookupDesPart1UncCorErr",

41*/	FLAG_ENTRY0("RxLookupDesPart2ParityErr",

42*/	FLAG_ENTRY0("RxLookupRcvArrayUncErr", RXES(LOOKUP_RCV_ARRAY_UNC)),

43*/	FLAG_ENTRY0("RxLookupRcvArrayCorErr", RXES(LOOKUP_RCV_ARRAY_COR)),

44*/	FLAG_ENTRY0("RxLookupCsrParityErr", RXES(LOOKUP_CSR_PARITY)),

45*/	FLAG_ENTRY0("RxHqIntrCsrParityErr", RXES(HQ_INTR_CSR_PARITY)),

46*/	FLAG_ENTRY0("RxHqIntrFsmErr", RXES(HQ_INTR_FSM)),

47*/	FLAG_ENTRY0("RxRbufDescPart1UncErr", RXES(RBUF_DESC_PART1_UNC)),

48*/	FLAG_ENTRY0("RxRbufDescPart1CorErr", RXES(RBUF_DESC_PART1_COR)),

49*/	FLAG_ENTRY0("RxRbufDescPart2UncErr", RXES(RBUF_DESC_PART2_UNC)),

50*/	FLAG_ENTRY0("RxRbufDescPart2CorErr", RXES(RBUF_DESC_PART2_COR)),

51*/	FLAG_ENTRY0("RxDmaHdrFifoRdUncErr", RXES(DMA_HDR_FIFO_RD_UNC)),

52*/	FLAG_ENTRY0("RxDmaHdrFifoRdCorErr", RXES(DMA_HDR_FIFO_RD_COR)),

53*/	FLAG_ENTRY0("RxDmaDataFifoRdUncErr", RXES(DMA_DATA_FIFO_RD_UNC)),

54*/	FLAG_ENTRY0("RxDmaDataFifoRdCorErr", RXES(DMA_DATA_FIFO_RD_COR)),

55*/	FLAG_ENTRY0("RxRbufDataUncErr", RXES(RBUF_DATA_UNC)),

56*/	FLAG_ENTRY0("RxRbufDataCorErr", RXES(RBUF_DATA_COR)),

57*/	FLAG_ENTRY0("RxDmaCsrParityErr", RXES(DMA_CSR_PARITY)),

58*/	FLAG_ENTRY0("RxDmaEqFsmEncodingErr", RXES(DMA_EQ_FSM_ENCODING)),

59*/	FLAG_ENTRY0("RxDmaDqFsmEncodingErr", RXES(DMA_DQ_FSM_ENCODING)),

60*/	FLAG_ENTRY0("RxDmaCsrUncErr", RXES(DMA_CSR_UNC)),

61*/	FLAG_ENTRY0("RxCsrReadBadAddrErr", RXES(CSR_READ_BAD_ADDR)),

62*/	FLAG_ENTRY0("RxCsrWriteBadAddrErr", RXES(CSR_WRITE_BAD_ADDR)),

63*/	FLAG_ENTRY0("RxCsrParityErr", RXES(CSR_PARITY))

 RXE errors that will trigger an SPC freeze */

/*

 * DCC Error Flags

/*

 * LCB error flags

 0*/	FLAG_ENTRY0("CSR_PARITY_ERR", LCBE(CSR_PARITY_ERR)),

 1*/	FLAG_ENTRY0("INVALID_CSR_ADDR", LCBE(INVALID_CSR_ADDR)),

 2*/	FLAG_ENTRY0("RST_FOR_FAILED_DESKEW", LCBE(RST_FOR_FAILED_DESKEW)),

 3*/	FLAG_ENTRY0("ALL_LNS_FAILED_REINIT_TEST",

 4*/	FLAG_ENTRY0("LOST_REINIT_STALL_OR_TOS", LCBE(LOST_REINIT_STALL_OR_TOS)),

 5*/	FLAG_ENTRY0("TX_LESS_THAN_FOUR_LNS", LCBE(TX_LESS_THAN_FOUR_LNS)),

 6*/	FLAG_ENTRY0("RX_LESS_THAN_FOUR_LNS", LCBE(RX_LESS_THAN_FOUR_LNS)),

 7*/	FLAG_ENTRY0("SEQ_CRC_ERR", LCBE(SEQ_CRC_ERR)),

 8*/	FLAG_ENTRY0("REINIT_FROM_PEER", LCBE(REINIT_FROM_PEER)),

 9*/	FLAG_ENTRY0("REINIT_FOR_LN_DEGRADE", LCBE(REINIT_FOR_LN_DEGRADE)),

10*/	FLAG_ENTRY0("CRC_ERR_CNT_HIT_LIMIT", LCBE(CRC_ERR_CNT_HIT_LIMIT)),

11*/	FLAG_ENTRY0("RCLK_STOPPED", LCBE(RCLK_STOPPED)),

12*/	FLAG_ENTRY0("UNEXPECTED_REPLAY_MARKER", LCBE(UNEXPECTED_REPLAY_MARKER)),

13*/	FLAG_ENTRY0("UNEXPECTED_ROUND_TRIP_MARKER",

14*/	FLAG_ENTRY0("ILLEGAL_NULL_LTP", LCBE(ILLEGAL_NULL_LTP)),

15*/	FLAG_ENTRY0("ILLEGAL_FLIT_ENCODING", LCBE(ILLEGAL_FLIT_ENCODING)),

16*/	FLAG_ENTRY0("FLIT_INPUT_BUF_OFLW", LCBE(FLIT_INPUT_BUF_OFLW)),

17*/	FLAG_ENTRY0("VL_ACK_INPUT_BUF_OFLW", LCBE(VL_ACK_INPUT_BUF_OFLW)),

18*/	FLAG_ENTRY0("VL_ACK_INPUT_PARITY_ERR", LCBE(VL_ACK_INPUT_PARITY_ERR)),

19*/	FLAG_ENTRY0("VL_ACK_INPUT_WRONG_CRC_MODE",

20*/	FLAG_ENTRY0("FLIT_INPUT_BUF_MBE", LCBE(FLIT_INPUT_BUF_MBE)),

21*/	FLAG_ENTRY0("FLIT_INPUT_BUF_SBE", LCBE(FLIT_INPUT_BUF_SBE)),

22*/	FLAG_ENTRY0("REPLAY_BUF_MBE", LCBE(REPLAY_BUF_MBE)),

23*/	FLAG_ENTRY0("REPLAY_BUF_SBE", LCBE(REPLAY_BUF_SBE)),

24*/	FLAG_ENTRY0("CREDIT_RETURN_FLIT_MBE", LCBE(CREDIT_RETURN_FLIT_MBE)),

25*/	FLAG_ENTRY0("RST_FOR_LINK_TIMEOUT", LCBE(RST_FOR_LINK_TIMEOUT)),

26*/	FLAG_ENTRY0("RST_FOR_INCOMPLT_RND_TRIP",

27*/	FLAG_ENTRY0("HOLD_REINIT", LCBE(HOLD_REINIT)),

28*/	FLAG_ENTRY0("NEG_EDGE_LINK_TRANSFER_ACTIVE",

29*/	FLAG_ENTRY0("REDUNDANT_FLIT_PARITY_ERR",

/*

 * DC8051 Error Flags

/*

 * DC8051 Information Error flags

 *

 * Flags in DC8051_DBG_ERR_INFO_SET_BY_8051.ERROR field.

/*

 * DC8051 Information Host Information flags

 *

 * Flags in DC8051_DBG_ERR_INFO_SET_BY_8051.HOST_MSG field.

/*

 * Error interrupt table entry.  This is used as input to the interrupt

 * "clear down" routine used for all second tier error interrupt register.

 * Second tier interrupt registers have a single bit representing them

 * in the top-level CceIntStatus.

 status CSR offset */

 clear CSR offset */

 mask CSR offset */

/*

 * Helpers for building HFI and DC error interrupt table entries.  Different

 * helpers are needed because of inconsistent register names.

/*

 * Table of the "misc" grouping of error interrupts.  Each entry refers to

 * another register containing more information.

 0*/	EE(CCE_ERR,		handle_cce_err,    "CceErr"),

 1*/	EE(RCV_ERR,		handle_rxe_err,    "RxeErr"),

 2*/	EE(MISC_ERR,	handle_misc_err,   "MiscErr"),

 3*/	{ 0, 0, 0, NULL }, 
 4*/	EE(SEND_PIO_ERR,    handle_pio_err,    "PioErr"),

 5*/	EE(SEND_DMA_ERR,    handle_sdma_err,   "SDmaErr"),

 6*/	EE(SEND_EGRESS_ERR, handle_egress_err, "EgressErr"),

 7*/	EE(SEND_ERR,	handle_txe_err,    "TxeErr")

 the rest are reserved */

/*

 * Index into the Various section of the interrupt sources

 * corresponding to the Critical Temperature interrupt.

/*

 * SDMA error interrupt entry - refers to another register containing more

 * information.

 0*/	{ 0, 0, 0, NULL }, 
 1*/	{ 0, 0, 0, NULL }, 
 2*/	EE(ASIC_QSFP1,	handle_qsfp_int,	"QSFP1"),

 3*/	EE(ASIC_QSFP2,	handle_qsfp_int,	"QSFP2"),

 4*/	{ 0, 0, 0, NULL }, 
 rest are reserved */

/*

 * The DC encoding of mtu_cap for 10K MTU in the DCC_CFG_PORT_CONFIG

 * register can not be derived from the MTU value because 10K is not

 * a power of 2. Therefore, we need a constant. Everything else can

 * be calculated.

/*

 * Table of the DC grouping of error interrupts.  Each entry refers to

 * another register containing more information.

 0*/	DC_EE1(DCC_ERR,		handle_dcc_err,	       "DCC Err"),

 1*/	DC_EE2(DC_LCB_ERR,	handle_lcb_err,	       "LCB Err"),

 2*/	DC_EE2(DC_DC8051_ERR,	handle_8051_interrupt, "DC8051 Interrupt"),

 3*/	
 the rest are reserved */

	/*

	 * counter name

	/*

	 * csr to read for name (if applicable)

	/*

	 * offset into dd or ppd to store the counter's value

	/*

	 * flags

	/*

	 * accessor for stat element, context either dd or ppd

 32bit RXE */

 64bit RXE */

 32bit TXE */

 64bit TXE */

 CCE */

 DC */

 ibp counters */

/**

 * hfi1_addr_from_offset - return addr for readq/writeq

 * @dd: the dd device

 * @offset: the offset of the CSR within bar0

 *

 * This routine selects the appropriate base address

 * based on the indicated offset.

/**

 * read_csr - read CSR at the indicated offset

 * @dd: the dd device

 * @offset: the offset of the CSR within bar0

 *

 * Return: the value read or all FF's if there

 * is no mapping

/**

 * write_csr - write CSR at the indicated offset

 * @dd: the dd device

 * @offset: the offset of the CSR within bar0

 * @value: value to write

 avoid write to RcvArray */

/**

 * get_csr_addr - return te iomem address for offset

 * @dd: the dd device

 * @offset: the offset of the CSR within bar0

 *

 * Return: The iomem address to use in subsequent

 * writeq/readq operations.

 Dev Access */

 Port Access */

 Software defined */

 A write can only zero the counter */

 Software counters for the error status bits within MISC_ERR_STATUS */

/*

 * Software counter for the aggregate of

 * individual CceErrStatus counters

/*

 * Software counters corresponding to each of the

 * error status bits within CceErrStatus

/*

 * Software counters corresponding to each of the

 * error status bits within RcvErrStatus

/*

 * Software counters corresponding to each of the

 * error status bits within SendPioErrStatus

/*

 * Software counters corresponding to each of the

 * error status bits within SendDmaErrStatus

/*

 * Software counters corresponding to each of the

 * error status bits within SendEgressErrStatus

/*

 * Software counters corresponding to each of the

 * error status bits within SendErrStatus

/*

 * Software counters corresponding to each of the

 * error status bits within SendCtxtErrStatus

/*

 * Software counters corresponding to each of the

 * error status bits within SendDmaEngErrStatus

 MISC_ERR_STATUS */

 CceErrStatus */

 RcvErrStatus */

 SendPioErrStatus */

 SendDmaErrStatus */

 SendEgressErrStatus */

 SendErrStatus */

 SendCtxtErrStatus */

 SendDmaEngErrStatus */

 ======================================================================== */

 return true if this is chip revision revision a */

 return true if this is chip revision revision b */

 return true is kernel urg disabled for rcd */

/*

 * Append string s to buffer buf.  Arguments curp and len are the current

 * position and remaining length, respectively.

 *

 * return 0 on success, 1 on out of room

 success */

 add a comma, if first in the buffer */

 out of room */

 copy the string */

 out of room */

 write return values */

/*

 * Using the given flag table, print a comma separated string into

 * the buffer.  End in '*' if the buffer is too short.

 make sure there is at least 2 so we can form "*" */

 leave room for a nul */

 any undocumented bits left? */

 add * if ran out of room */

 may need to back up to add space for a '*' */

 add final nul - space already allocated above */

 first 8 CCE error interrupt source names */

 0 */

 1 */

 2 */

 3 */

 4 */

 5 */

 6 */

 7 */

/*

 * Return the miscellaneous error interrupt name.

/*

 * Return the SDMA engine error interrupt name.

/*

 * Return the send context error interrupt name.

/*

 * Return the various interrupt name.

/*

 * Return the DC interrupt name.

 local block merge */

/*

 * Return the SDMA engine interrupt name.

 what interrupt */

 which engine */

/*

 * Return the receive available interrupt name.

/*

 * Return the receive urgent interrupt name.

/*

 * Return the send credit interrupt name.

/*

 * Return the reserved interrupt name.

	/*

	 * For most these errors, there is nothing that can be done except

	 * report or record it.

 this error requires a manual drop into SPC freeze mode */

 then a fix up */

 maintain a counter over all cce_err_status errors */

/*

 * Check counters for receive errors that do not have an interrupt

 * associated with them.

 Assume the hardware counter has been reset */

		/*

		 * Freeze mode recovery is disabled for the errors

		 * in RXE_FREEZE_ABORT_MASK

/*

 * We have had a "disallowed packet" error during egress. Determine the

 * integrity check which failed, and update relevant error counter, etc.

 *

 * Note that the SEND_EGRESS_ERR_INFO register has only a single

 * bit of state per integrity check, and so we can miss the reason for an

 * egress error if more than one packet fails the same integrity check

 * since we cleared the corresponding bit in SEND_EGRESS_ERR_INFO.

 read first */

 clear down all observed info as quickly as possible after read */

 Eventually add other counters for each bit */

		/*

		 * Count all applicable bits as individual errors and

		 * attribute them to the packet that triggered this handler.

		 * This may not be completely accurate due to limitations

		 * on the available hardware error information.  There is

		 * a single information register and any number of error

		 * packets may have occurred and contributed to it before

		 * this routine is called.  This means that:

		 * a) If multiple packets with the same error occur before

		 *    this routine is called, earlier packets are missed.

		 *    There is only a single bit for each error type.

		 * b) Errors may not be attributed to the correct VL.

		 *    The driver is attributing all bits in the info register

		 *    to the packet that triggered this call, but bits

		 *    could be an accumulation of different packets with

		 *    different VLs.

		 * c) A single error packet may have multiple counts attached

		 *    to it.  There is no way for the driver to know if

		 *    multiple bits set in the info register are due to a

		 *    single packet or multiple packets.  The driver assumes

		 *    multiple packets.

/*

 * Input value is a bit position within the SEND_EGRESS_ERR_STATUS

 * register. Does it represent a 'port inactive' error?

/*

 * Input value is a bit position within the SEND_EGRESS_ERR_STATUS

 * register. Does it represent a 'disallowed packet' error?

/*

 * Input value is a bit position of one of the SDMA engine disallowed

 * packet errors.  Return which engine.  Use of this must be guarded by

 * disallowed_pkt_err().

/*

 * Translate an SDMA engine to a VL.  Return -1 if the tranlation cannot

 * be done.

 range check */

/*

 * Translate the send context (sofware index) into a VL.  Return -1 if the

 * translation cannot be done.

 there is no information for user (PSM) and ack contexts */

 fls64() returns a 1-based offset, we want it zero based */

/*

 * The maximum number of times the error clear down will loop before

 * blocking a repeating error.  This value is arbitrary.

/*

 * Clear and handle an error register.  All error interrupts are funneled

 * through here to have a central location to correctly handle single-

 * or multi-shot errors.

 *

 * For non per-context registers, call this routine with a context value

 * of 0 so the per-context offset is zero.

 *

 * If the handler loops too many times, assume that something is wrong

 * and can't be fixed, so mask the error bits.

 read in a loop until no more errors are seen */

			/*

			 * Read-modify-write so any other masked bits

			 * remain masked.

/*

 * CCE block "misc" interrupt.  Source is < 16.

/*

 * Send context error interrupt.  Source (hw_context) is < 160.

 *

 * All send context errors cause the send context to halt.  The normal

 * clear-down mechanism cannot be used because we cannot clear the

 * error bits until several other long-running items are done first.

 * This is OK because with the context halted, nothing else is going

 * to happen on it anyway.

 tell the software that a halt has begun */

	/*

	 * Automatically restart halted kernel contexts out of interrupt

	 * context.  User contexts must ask the driver to restart the context.

	/*

	 * Update the counters for the corresponding status bits.

	 * Note that these particular counters are aggregated over all

	 * 160 contexts.

	/*

	* Update the counters for the corresponding status bits.

	* Note that these particular counters are aggregated over

	* all 16 DMA engines.

/*

 * CCE block SDMA error interrupt.  Source is < 16.

/*

 * CCE block "various" interrupt.  Source is < 8.

	/*

	 * TCritInt cannot go through interrupt_clear_down()

	 * because it is not a second tier interrupt. The handler

	 * should be called directly.

 src_ctx is always zero */

			/*

			 * Cable removed, reset all our information about the

			 * cache and cable capabilities

			/*

			 * We don't set cache_refresh_required here as we expect

			 * an interrupt when a cable is inserted

 Invert the ModPresent pin now to detect plug-in */

				/*

				 * The link is still in POLL. This means

				 * that the normal link down processing

				 * will not happen. We have to do it here

				 * before turning the DC off.

			/*

			 * Stop inversion of ModPresent pin to detect

			 * removal of the cable

 Schedule the QSFP work only if there is a cable attached. */

/*

 * Set the LCB selector - allow host access.  The DCC selector always

 * points to the host.

/*

 * Clear the LCB selector - allow 8051 access.  The DCC selector always

 * points to the host.

/*

 * Acquire LCB access from the 8051.  If the host already has access,

 * just increment a counter.  Otherwise, inform the 8051 that the

 * host is taking access.

 *

 * Returns:

 *	0 on success

 *	-EBUSY if the 8051 has control and cannot be disturbed

 *	-errno if unable to acquire access from the 8051

	/*

	 * Use the host link state lock so the operation of this routine

	 * { link state check, selector change, count increment } can occur

	 * as a unit against a link state change.  Otherwise there is a

	 * race between the state change and the count increment.

 this access is valid only when the link is up */

/*

 * Release LCB access by decrementing the use count.  If the count is moving

 * from 1 to 0, inform 8051 that it has control back.

 *

 * Returns:

 *	0 on success

 *	-errno if unable to release access to the 8051

	/*

	 * Use the host link state lock because the acquire needed it.

	 * Here, we only need to keep { selector change, count decrement }

	 * as a unit.

 restore host access if the grant didn't work */

/*

 * Initialize LCB access variables and state.  Called during driver load,

 * after most of the initialization is finished.

 *

 * The DC default is LCB access on for the host.  The driver defaults to

 * leaving access to the 8051.  Assign access now - this constrains the call

 * to this routine to be after all LCB set-up is done.  In particular, after

 * hf1_init_dd() -> set_up_interrupts() -> clear_all_interrupts()

/*

 * Write a response back to a 8051 request.

/*

 * Handle host requests from the 8051.

 no request */

 zero out COMPLETED so the response is seen */

 extract request details */

 Put the LCB, RX FPE and TX FPE into reset */

 Make sure the write completed */

 Hold the reset long enough to take effect */

 Take the LCB, RX FPE and TX FPE out of reset */

/*

 * Set up allocation unit vaulue.

 do not modify other values in the register */

/*

 * Set up initial VL15 credits of the remote.  Assumes the rest of

 * the CM credit registers are zero from a previous global or credit reset.

 * Shared limit for VL15 will always be 0.

 set initial values for total and shared credit limit */

	/*

	 * Set total limit to be equal to VL15 credits.

	 * Leave shared limit at 0.

/*

 * Zero all credit details from the previous connection and

 * reset the CM manager's internal counters.

 remove all previous VL credit limits */

 reset the CM block */

 reset cached value */

 convert a vCU to a CU */

 convert a CU to a vCU */

 convert a vAU to an AU */

/*

 * Graceful LCB shutdown.  This leaves the LCB FIFOs in reset.

 clear lcb run: LCB_CFG_RUN.EN = 0 */

 set tx fifo reset: LCB_CFG_TX_FIFOS_RESET.VAL = 1 */

 set dcc reset csr: DCC_CFG_RESET.{reset_lcb,reset_rx_fpe} = 1 */

 make sure the write completed */

 must hold for the longer of 16cclks or 20ns */

/*

 * This routine should be called after the link has been transitioned to

 * OFFLINE (OFFLINE state has the side effect of putting the SerDes into

 * reset).

 *

 * The expectation is that the caller of this routine would have taken

 * care of properly transitioning the link into the correct state.

 * NOTE: the caller needs to acquire the dd->dc8051_lock lock

 *       before calling this function.

 Shutdown the LCB */

	/*

	 * Going to OFFLINE would have causes the 8051 to put the

	 * SerDes into reset already. Just need to shut down the 8051,

	 * itself.

/*

 * Calling this after the DC has been brought out of reset should not

 * do any damage.

 * NOTE: the caller needs to acquire the dd->dc8051_lock lock

 *       before calling this function.

 Take the 8051 out of reset */

 Wait until 8051 is ready */

 Take away reset for LCB and RX FPE (set in lcb_shutdown). */

 lcb_shutdown() with abort=1 does not restore these */

/*

 * These LCB adjustments are for the Aurora SerDes core in the FPGA.

	/*

	 * These LCB defaults on emulator _s are good, nothing to do here:

	 *	LCB_CFG_TX_FIFOS_RADR

	 *	LCB_CFG_RX_FIFOS_RADR

	 *	LCB_CFG_LN_DCLK

	 *	LCB_CFG_IGNORE_LOST_RCLK

 else this is _p */

 all B0 use 0x2d or higher settings */

 release 0x12 and below */

		/*

		 * LCB_CFG_RX_FIFOS_RADR.RST_VAL = 0x9

		 * LCB_CFG_RX_FIFOS_RADR.OK_TO_JUMP_VAL = 0x9

		 * LCB_CFG_RX_FIFOS_RADR.DO_NOT_JUMP_VAL = 0xa

		/*

		 * LCB_CFG_TX_FIFOS_RADR.ON_REINIT = 0 (default)

		 * LCB_CFG_TX_FIFOS_RADR.RST_VAL = 6

 release 0x13 up to 0x18 */

 LCB_CFG_RX_FIFOS_RADR = 0x988 */

 release 0x19 */

 LCB_CFG_RX_FIFOS_RADR = 0xa99 */

 release 0x1a */

 LCB_CFG_RX_FIFOS_RADR = 0x988 */

 release 0x1b and higher */

 LCB_CFG_RX_FIFOS_RADR = 0x877 */

 LCB_CFG_IGNORE_LOST_RCLK.EN = 1 */

/*

 * Handle a SMA idle message

 *

 * This is a work-queue function outside of the interrupt.

	/*

	 * msg is bytes 1-4 of the 40-bit idle message - the command code

	 * is stripped off

	/*

	 * React to the SMA message.  Byte[1] (0 for us) is the command.

		/*

		 * See OPAv1 table 9-14 - HFI and External Switch Ports Key

		 * State Transitions

		 *

		 * Only expected in INIT or ARMED, discard otherwise.

		/*

		 * See OPAv1 table 9-14 - HFI and External Switch Ports Key

		 * State Transitions

		 *

		 * Can activate the node.  Discard otherwise.

/*

 * Called from all interrupt handlers to start handling an SPC freeze.

 enter frozen mode */

 notify all SDMA engines that they are going into a freeze */

 do halt pre-handling on all enabled send contexts */

 Send context are frozen. Notify user space */

 queue non-interrupt handler */

/*

 * Wait until all 4 sub-blocks indicate that they have frozen or unfrozen,

 * depending on the "freeze" parameter.

 *

 * No need to return an error if it times out, our only option

 * is to proceed anyway.

 waiting until all indicators are set */

 all done */

 waiting until all indicators are clear */

 all done */

/*

 * Do all freeze handling for the RXE block.

 disable port */

 disable all receive contexts */

/*

 * Unfreeze handling for the RXE block - kernel contexts only.

 * This will also enable the port.  User contexts will do unfreeze

 * handling on a per-context basis as they call into the driver.

 *

 enable all kernel contexts */

 Ensure all non-user contexts(including vnic) are enabled */

 HFI1_RCVCTRL_TAILUPD_[ENB|DIS] needs to be set explicitly */

 enable port */

/*

 * Non-interrupt SPC freeze handling.

 *

 * This is a work-queue function outside of the triggering interrupt.

 wait for freeze indicators on all affected blocks */

 SPC is now frozen */

 do send PIO freeze steps */

 do send DMA freeze steps */

 do send egress freeze steps - nothing to do */

 do receive freeze steps */

	/*

	 * Unfreeze the hardware - clear the freeze, wait for each

	 * block's frozen bit to clear, then clear the frozen flag.

 do send PIO unfreeze steps for kernel contexts */

 do send DMA unfreeze steps */

 do send egress unfreeze steps - nothing to do */

 do receive unfreeze steps for kernel contexts */

	/*

	 * The unfreeze procedure touches global device registers when

	 * it disables and re-enables RXE. Mark the device unfrozen

	 * after all that is done so other parts of the driver waiting

	 * for the device to unfreeze don't do things out of order.

	 *

	 * The above implies that the meaning of HFI1_FROZEN flag is

	 * "Device has gone into freeze mode and freeze mode handling

	 * is still in progress."

	 *

	 * The flag will be removed when freeze mode processing has

	 * completed.

 no longer frozen */

/**

 * update_xmit_counters - update PortXmitWait/PortVlXmitWait

 * counters.

 * @ppd: info of physical Hfi port

 * @link_width: new link width after link up or downgrade

 *

 * Update the PortXmitWait and PortVlXmitWait counters after

 * a link up or downgrade event to reflect a link width change.

	/*

	 * There are C_VL_COUNT number of PortVLXmitWait counters.

	 * Adding 1 to C_VL_COUNT to include the PortXmitWait counter.

/*

 * Handle a link up interrupt from the 8051.

 *

 * This is a work-queue function outside of the interrupt.

 cache the read of DC_LCB_STS_ROUND_TRIP_LTP_CNT */

	/*

	 * OPA specifies that certain counters are cleared on a transition

	 * to link up, so do that.

	/*

	 * And (re)set link up default values.

	/*

	 * Set VL15 credits. Use cached value from verify cap interrupt.

	 * In case of quick linkup or simulator, vl15 value will be set by

	 * handle_linkup_change. VerifyCap interrupt handler will not be

	 * called in those scenarios.

 enforce link speed enabled */

 oops - current speed is not enabled, bounce */

/*

 * Several pieces of LNI information were cached for SMA in ppd.

 * Reset these on link down

 return the neighbor link down reason string */

/*

 * Handle a link down interrupt from the 8051.

 *

 * This is a work-queue function outside of the interrupt.

 Go offline first, then deal with reading/writing through 8051 */

 link down reason is only valid if the link was up */

 the link went down, no idle message reason */

			/*

			 * The neighbor reason is only valid if an idle message

			 * was received for it.

		/*

		 * If no reason, assume peer-initiated but missed

		 * LinkGoingDown idle flits.

 went down while polling or going up */

 inform the SMA when the link transitions from up to down */

 disable the port */

	/*

	 * If there is no cable attached, turn the DC off. Otherwise,

	 * start the link bring up.

	/*

	 * Only do something if the link is currently up.

/*

 * Mask conversion: Capability exchange to Port LTP.  The capability

 * exchange has an implicit 16b CRC that is mandatory.

 this mode is mandatory */

/*

 * Convert an OPA Port LTP mask to capability mask

/*

 * Convert a single DC LCB CRC mode to an OPA Port LTP mask.

/*

 * Convert the given link width to the OPA link width bitmask.

		/*

		 * Simulator and quick linkup do not set the width.

		 * Just set it to 4x without complaint.

 no lanes up */

/*

 * Do a population count on the bottom nibble.

/*

 * Read the active lane information from the 8051 registers and return

 * their widths.

 *

 * Active lane information is found in these 8051 registers:

 *	enable_lane_tx

 *	enable_lane_rx

 read the active lanes */

 convert to counts */

	/*

	 * Set link_speed_active here, overriding what was set in

	 * handle_verify_cap().  The ASIC 8051 firmware does not correctly

	 * set the max_rate field in handle_verify_cap until v0.19.

 max_rate: 0 = 12.5G, 1 = 25G */

/*

 * Read verify_cap_local_fm_link_width[1] to obtain the link widths.

 * Valid after the end of VerifyCap and during LinkUp.  Does not change

 * after link up.  I.e. look elsewhere for downgrade information.

 *

 * Bits are:

 *	+ bits [7:4] contain the number of active transmitters

 *	+ bits [3:0] contain the number of active receivers

 * These are numbers 1 through 4 and can be different values if the

 * link is asymmetric.

 *

 * verify_cap_local_fm_link_width[0] retains its original value.

 print the active widths */

/*

 * Set ppd->link_width_active and ppd->link_width_downgrade_active using

 * hardware information when the link first comes up.

 *

 * The link width is not available until after VerifyCap.AllFramesReceived

 * (the trigger for handle_verify_cap), so this is outside that routine

 * and should be called when the 8051 signals linkup.

 get end-of-LNI link widths */

 use tx_width as the link is supposed to be symmetric on link up */

 link width downgrade active (LWD.A) starts out matching LW.A */

 per OPA spec, on link up LWD.E resets to LWD.S */

 cache the active egress rate (units {10^6 bits/sec]) */

/*

 * Handle a verify capabilities interrupt from the 8051.

 *

 * This is a work-queue function outside of the interrupt.

 print the active widths */

	/*

	 * The peer vAU value just read is the peer receiver value.  HFI does

	 * not support a transmit vAU of 0 (AU == 8).  We advertised that

	 * with Z=1 in the fabric capabilities sent to the peer.  The peer

	 * will see our Z=1, and, if it advertised a vAU of 0, will move its

	 * receive to vAU of 1 (AU == 16).  Do the same here.  We do not care

	 * about the peer Z value - our sent vAU is 3 (hardwired) and is not

	 * subject to the Z value exception.

	/*

	 * Set VL15 credits to 0 in global credit register. Cache remote VL15

	 * credits value and wait for link-up interrupt ot set it.

 set up the LCB CRC mode */

 order is important: use the lowest bit in common */

 set (14b only) or clear sideband credit */

 invalid value */

 remote_tx_rate: 0 = 12.5G, 1 = 25G */

 actual rate is highest bit of the ANDed rates */

	/*

	 * Cache the values of the supported, enabled, and active

	 * LTP CRC modes to return in 'portinfo' queries. But the bit

	 * flags that are returned in the portinfo query differ from

	 * what's in the link_crc_mask, crc_sizes, and crc_val

	 * variables. Convert these here.

 supported crc modes */

 enabled crc modes */

 active crc mode */

 set up the remote credit return table */

	/*

	 * The LCB is reset on entry to handle_verify_cap(), so this must

	 * be applied on every link up.

	 *

	 * Adjust LCB error kill enable to kill the link if

	 * these RBUF errors are seen:

	 *	REPLAY_BUF_MBE_SMASK

	 *	FLIT_INPUT_BUF_MBE_SMASK

 fixed in B0 */

 pull LCB fifos out of reset - all fifo clocks must be stable */

 give 8051 access to the LCB CSRs */

 mask LCB errors */

 tell the 8051 to go to LinkUp */

/**

 * apply_link_downgrade_policy - Apply the link width downgrade enabled

 * policy against the current active link widths.

 * @ppd: info of physical Hfi port

 * @refresh_widths: True indicates link downgrade event

 * @return: True indicates a successful link downgrade. False indicates

 *	    link downgrade event failed and the link will bounce back to

 *	    default link width.

 *

 * Called when the enabled policy changes or the active link widths

 * change.

 * Refresh_widths indicates that a link downgrade occurred. The

 * link_downgraded variable is set by refresh_widths and

 * determines the success/failure of the policy application.

 use the hls lock to avoid a race with actual link up */

 only apply if the link is up */

 still going up..wait and retry */

 arbitrary */

 the 8051 reported a dead link as a downgrade */

 downgrade is disabled */

 bounce if not at starting active width */

 Tx or Rx is outside the enabled policy */

/*

 * Handle a link downgrade interrupt from the 8051.

 *

 * This is a work-queue function outside of the interrupt.

 look at the flags */

 8051 information set by firmware */

 read DC8051_DBG_ERR_INFO_SET_BY_8051 for details */

		/*

		 * Handle error flags.

			/*

			 * LNI error indications are cleared by the 8051

			 * only when starting polling.  Only pay attention

			 * to them when in the states that occur during

			 * LNI.

 unknown frames can happen durning LNI, just count */

 report remaining errors, but do not do anything */

		/*

		 * Handle host message flags.

			/*

			 * Presently, the driver does a busy wait for

			 * host requests to complete.  This is only an

			 * informational message.

			 * NOTE: The 8051 clears the host message

			 * information *on the next 8051 command*.

			 * Therefore, when linkup is achieved,

			 * this flag will still be set.

 no downgrade action needed if going down */

 report remaining messages, but do not do anything */

		/*

		 * Lost the 8051 heartbeat.  If this happens, we

		 * receive constant interrupts about it.  Disable

		 * the interrupt after the first.

 report the error, but do not do anything */

		/*

		 * if the link is already going down or disabled, do not

		 * queue another. If there's a link down entry already

		 * queued, don't queue another one.

 no 7 */

 set status bit */

 this counter saturates at (2^32) - 1 */

 set status bit */

				/*

				 * lcl_reason cannot be derived from info

				 * for this error

 just report this */

 set status bit */

			/*

			 * save first 2 flits in the packet that caused

			 * the error

 just report this */

 informative only */

 informative only */

 report any remaining errors */

/*

 * CCE block DC interrupt.  Source is < 8.

 dc_lbm_int */) {

		/*

		 * This indicates that a parity error has occurred on the

		 * address/control lines presented to the LBM.  The error

		 * is a single pulse, there is no associated error flag,

		 * and it is non-maskable.  This is because if a parity

		 * error occurs on the request the request is dropped.

		 * This should never occur, but it is nice to know if it

		 * ever does.

/*

 * TX block send credit interrupt.  Source is < 160.

/*

 * TX block SDMA interrupt.  Source is < 48.

 *

 * SDMA interrupts are grouped by type:

 *

 *	 0 -  N-1 = SDma

 *	 N - 2N-1 = SDmaProgress

 *	2N - 3N-1 = SDmaIdle

 what interrupt */

 which engine */

 should not happen */

/**

 * is_rcv_avail_int() - User receive context available IRQ handler

 * @dd: valid dd

 * @source: logical IRQ source (offset from IS_RCVAVAIL_START)

 *

 * RX block receive available interrupt.  Source is < 160.

 *

 * This is the general interrupt handler for user (PSM) receive contexts,

 * and can only be used for non-threaded IRQs.

 OK */

 received an interrupt, but no rcd */

 received an interrupt, but are not using that context */

/**

 * is_rcv_urgent_int() - User receive context urgent IRQ handler

 * @dd: valid dd

 * @source: logical IRQ source (offset from IS_RCVURGENT_START)

 *

 * RX block receive urgent interrupt.  Source is < 160.

 *

 * NOTE: kernel receive contexts specifically do NOT enable this IRQ.

 OK */

 received an interrupt, but no rcd */

 received an interrupt, but are not using that context */

/*

 * Reserved range interrupt.  Should not be called in normal operation.

/*

 * start		 end

 *				name func		interrupt func

/*

 * Interrupt source interrupt - called when the given source has an interrupt.

 * Source is a bit index into an array of 64-bit integers.

 avoids a double compare by walking the table in-order */

 fell off the end */

/**

 * general_interrupt -  General interrupt handler

 * @irq: MSIx IRQ vector

 * @data: hfi1 devdata

 *

 * This is able to correctly handle all non-threaded interrupts.  Receive

 * context DATA IRQs are threaded and are not supported by this handler.

 *

 phase 1: scan and clear all handled interrupts */

 used later */

 only clear if anything is set */

 phase 2: call the appropriate handler */

 This read_csr is really bad in the hot path */

 clear the interrupt(s) */

 handle the interrupt(s) */

/*

 * Clear the receive interrupt.  Use a read of the interrupt clear CSR

 * to insure that the write completed.  This does NOT guarantee that

 * queued DMA writes to memory from the chip are pushed.

 force the above write on the chip and get a value back */

 force the receive interrupt */

/*

 * Return non-zero if a packet is present.

 *

 * This routine is called when rechecking for packets after the RcvAvail

 * interrupt has been cleared down.  First, do a quick check of memory for

 * a packet present.  If not found, use an expensive CSR read of the context

 * tail to determine the actual tail.  The CSR read is necessary because there

 * is no method to push pending DMAs to memory other than an interrupt and we

 * are trying to determine if we need to force an interrupt.

 fall back to a CSR read, correct indpendent of DMA_RTAIL */

/*

 * Common code for receive contexts interrupt handlers.

 * Update traces, increment kernel IRQ counter and

 * setup ASPM when needed.

/*

 * __hfi1_rcd_eoi_intr() - Make HW issue receive interrupt

 * when there are packets present in the queue. When calling

 * with interrupts enabled please use hfi1_rcd_eoi_intr.

 *

 * @rcd: valid receive context

/**

 * hfi1_rcd_eoi_intr() - End of Interrupt processing action

 *

 * @rcd: Ptr to hfi1_ctxtdata of receive context

 *

 *  Hold IRQs so we can safely clear the interrupt and

 *  recheck for a packet that may have arrived after the previous

 *  check and the interrupt clear.  If a packet arrived, force another

 *  interrupt. This routine can be called at the end of receive packet

 *  processing in interrupt service routines, interrupt service thread

 *  and softirqs

/**

 * hfi1_netdev_rx_napi - napi poll function to move eoi inline

 * @napi: pointer to napi object

 * @budget: netdev budget

 Receive packet napi handler for netdevs VNIC and AIP  */

/*

 * Receive packet IRQ handler.  This routine expects to be on its own IRQ.

 * This routine will try to handle packets immediately (latency), but if

 * it finds too many, it will invoke the thread handler (bandwitdh).  The

 * chip receive interrupt is *not* cleared down until this or the thread (if

 * invoked) is finished.  The intent is to avoid extra interrupts while we

 * are processing packets anyway.

 receive interrupt remains blocked while processing packets */

	/*

	 * Too many packets were seen while processing packets in this

	 * IRQ handler.  Invoke the handler thread.  The receive interrupt

	 * remains blocked.

/*

 * Receive packet thread handler.  This expects to be invoked with the

 * receive interrupt still blocked.

 receive interrupt is still blocked from the IRQ handler */

 ========================================================================= */

 clear current state, set new state */

/*

 * Use the 8051 to read a LCB CSR.

 register is an index of LCB registers: (offset - base) / 8 */

/*

 * Provide a cache for some of the LCB registers in case the LCB is

 * unavailable.

 * (The LCB is unavailable in certain link states, for example.)

 Update if we get good data */

/*

 * Read an LCB CSR.  Access may not be in host control, so check.

 * Return 0 on success, -EBUSY on failure.

 if up, go through the 8051 for the value */

 if going up or down, check the cache, otherwise, no access */

 otherwise, host has access */

/*

 * Use the 8051 to write a LCB CSR.

 register is an index of LCB registers: (offset - base) / 8 */

/*

 * Write an LCB CSR.  Access may not be in host control, so check.

 * Return 0 on success, -EBUSY on failure.

 if up, go through the 8051 for the value */

 if going up or down, no access */

 otherwise, host has access */

/*

 * Returns:

 *	< 0 = Linux error, not able to get access

 *	> 0 = 8051 command RETURN_CODE

 We can't send any commands to the 8051 if it's in reset */

	/*

	 * If an 8051 host command timed out previously, then the 8051 is

	 * stuck.

	 *

	 * On first timeout, attempt to reset and restart the entire DC

	 * block (including 8051). (Is this too big of a hammer?)

	 *

	 * If the 8051 times out a second time, the reset did not bring it

	 * back to healthy life. In that case, fail any subsequent commands.

	/*

	 * If there is no timeout, then the 8051 command interface is

	 * waiting for a command.

	/*

	 * When writing a LCB CSR, out_data contains the full value to

	 * to be written, while in_data contains the relative LCB

	 * address in 7:0.  Do the work here, rather than the caller,

	 * of distrubting the write data to where it needs to go:

	 *

	 * Write data

	 *   39:00 -> in_data[47:8]

	 *   47:40 -> DC8051_CFG_EXT_DEV_0.RETURN_CODE

	 *   63:48 -> DC8051_CFG_EXT_DEV_0.RSP_DATA

 must preserve COMPLETED - it is tied to hardware */

	/*

	 * Do two writes: the first to stabilize the type and req_data, the

	 * second to activate.

 wait for completion, alternate: interrupt */

 top 16 bits are in a different register */

	/*

	 * Clear command for next user.

/*

 * Read the 8051 firmware "registers".  Use the RAM directly.  Always

 * set the result, even on error.

 * Return 0 on success, -errno on failure

 address start depends on the lane_id */

 read is in 8-byte chunks, hardware will truncate the address down */

 extract the 4 bytes we want */

 Clear, then set field */

 no need to mask, all variable sizes match field widths */

/*

 * Read an idle LCB message.

 *

 * Returns 0 on success, -EINVAL on error

 return only the payload as we already know the type */

/*

 * Read an idle SMA message.  To be done in response to a notification from

 * the 8051.

 *

 * Returns 0 on success, -EINVAL on error

/*

 * Send an idle LCB message.

 *

 * Returns 0 on success, -EINVAL on error

/*

 * Send an idle SMA message.

 *

 * Returns 0 on success, -EINVAL on error

/*

 * Initialize the LCB then do a quick link up.  This may or may not be

 * in loopback.

 *

 * return 0 on success, -errno on error

 LCB_CFG_LOOPBACK.VAL = 2 */

 LCB_CFG_LANE_WIDTH.VAL = 0 */

 start the LCBs */

 LCB_CFG_TX_FIFOS_RESET.VAL = 0 */

 simulator only loopback steps */

 LCB_CFG_RUN.EN = 1 */

		/*

		 * When doing quick linkup and not in loopback, both

		 * sides must be done with LCB set-up before either

		 * starts the quick linkup.  Put a delay here so that

		 * both sides can be started and have a chance to be

		 * done with LCB set up before resuming.

 mask LCB errors */

	/*

	 * State "quick" LinkUp request sets the physical link state to

	 * LinkUp without a verify capability sequence.

	 * This state is in simulator v37 and later.

 watch LCB errors */

 success */

/*

 * Do all special steps to set up loopback.

 all loopbacks should disable self GUID check */

	/*

	 * The simulator has only one loopback option - LCB.  Switch

	 * to that option, which includes quick link up.

	 *

	 * Accept all valid loopback values.

	/*

	 * SerDes loopback init sequence is handled in set_local_link_attributes

 LCB loopback - handled at poll time */

 LCB is always quick linkup */

 not supported in emulation due to emulation RTL changes */

 external cable loopback requires no extra steps */

/*

 * Translate from the OPA_LINK_WIDTH handed to us by the FM to bits

 * used in the Verify Capability link width attribute.

/*

 * Set link attributes before moving to polling.

 reset our fabric serdes to clear any lingering problems */

 set the local tx rate - need to read-modify-write */

 set the tx rate to the fastest enabled */

 set the tx rate to all enabled */

 enable all four lanes */

	/*

	 * DC supports continuous updates.

 no power management */,

 continuous updates */);

 z=1 in the next call: AU of 0 is not supported by the hardware */

	/*

	 * SerDes loopback init sequence requires

	 * setting bit 0 of MISC_CONFIG_BITS

	/*

	 * An external device configuration request is used to reset the LCB

	 * to retry to obtain operational lanes when the first attempt is

	 * unsuccesful.

 let peer know who we are */

/*

 * Call this to start the link.

 * Do not do anything if the link is disabled.

 * Returns 0 if link is disabled, moved to polling, or the driver is not ready.

	/*

	 * Tune the SerDes to a ballpark setting for optimal signal and bit

	 * error rate.  Needs to be done before starting the link.

	/*

	 * FULL_MGMT_P_KEY is cleared from the pkey table, so that the

	 * pkey table can be configured properly if the HFI unit is connected

	 * to switch port with MgmtAllowed=NO

	/*

	 * Some QSFP cables have a quirk that asserts the IntN line as a side

	 * effect of power up on plug-in. We ignore this false positive

	 * interrupt until the module has finished powering up by waiting for

	 * a minimum timeout of the module inrush initialization time of

	 * 500 ms (SFF 8679 Table 5-6) to ensure the voltage rails in the

	 * module have stabilized.

	/*

	 * Check for QSFP interrupt for t_init (SFF 8679 Table 8-1)

		/*

		 * Clear the status register to avoid an immediate interrupt

		 * when we re-enable the IntN pin

 Disable INT_N from triggering QSFP interrupts */

 Reset the QSFP */

	/*

	 * Allow INT_N to trigger the QSFP interrupt to watch

	 * for alarms and warnings

	/*

	 * After the reset, AOC transmitters are enabled by default. They need

	 * to be turned off to complete the QSFP setup before they can be

	 * enabled again.

	/*

	 * The remaining alarms/warnings don't matter if the link is down.

 Byte 2 is vendor specific */

 Bytes 9-10 and 11-12 are reserved */

 Bytes 13-15 are vendor specific */

 This routine will only be scheduled if the QSFP module present is asserted */

 Sanity check */

	/*

	 * Turn DC back on after cable has been re-inserted. Up until

	 * now, the DC has been in reset to save power.

		/*

		 * Allow INT_N to trigger the QSFP interrupt to watch

		 * for alarms and warnings

 Clear current status to avoid spurious interrupts */

 Handle active low nature of INT_N and MODPRST_N pins */

 Enable the appropriate QSFP IRQ source */

/*

 * Do a one-time initialize of the LCB block.

 simulator does not correctly handle LCB cclk loopback, skip */

 the DC has been reset earlier in the driver load */

 set LCB for cclk loopback on the port */

/*

 * Perform a test read on the QSFP.  Return 0 on success, -ERRNO

 * on error.

	/*

	 * Report success if not a QSFP or, if it is a QSFP, but the cable is

	 * not present

 read byte 2, the status byte */

 success */

/*

 * Values for QSFP retry.

 *

 * Give up after 10s (20 x 500ms).  The overall timeout was empirically

 * arrived at from experience on a large cluster.

 msec */

/*

 * Try a QSFP read.  If it fails, schedule a retry for later.

 * Called on first link activation after driver load.

 read failed */

/*

 * Workqueue function to start the link after a delay.

 Set linkinit_reason on power up per OPA spec */

 one-time init of the LCB */

	/*

	 * Shut down the link and keep it down.   First turn off that the

	 * driver wants to allow the link to be up (driver_link_ready).

	 * Then make sure the link is not automatically restarted

	 * (link_enabled).  Cancel any pending restart.  And finally

	 * go offline.

 prevent more retries */

 disable the port */

/*

 * index is the index into the receive array

 4KB kernel address boundary */

		/*

		 * Eager entries are written and flushed

		 *

		 * Expected entries are flushed every 4 writes

 this could be optimized */

 allowed Link-width */

 currently active Link-width */

 allowed Link speeds */

 current Link speed */

 Auto-RX-polarity enable */

 Auto-Lane-reversal enable */

 VL arb high priority table size */

 VL arb low priority table size */

 IB overrun threshold */

 IB PHY error threshold */

 IB link default (sleep/poll) */

 Heartbeat off/enable/auto */

/*

 * The largest MAD packet size.

/*

 * Return the maximum header bytes that can go on the _wire_

 * for this device. This count includes the ICRC which is

 * not part of the packet held in memory but it is appended

 * by the HW.

 * This is dependent on the device's receive header entry size.

 * HFI allows this to be set per-receive context, but the

 * driver presently enforces a global value.

	/*

	 * The maximum non-payload (MTU) bytes in LRH.PktLen are

	 * the Receive Header Entry Size minus the PBC (or RHF) size

	 * plus one DW for the ICRC appended by HW.

	 *

	 * dd->rcd[0].rcvhdrqentsize is in DW.

	 * We use rcd[0] as all context will have the same value. Also,

	 * the first kernel context would have been allocated by now so

	 * we are guaranteed a valid value.

PBC/RHF*/ + 1
/*

 * Set Send Length

 * @ppd: per port data

 *

 * Set the MTU by limiting how many DWs may be sent.  The SendLenCheck*

 * registers compare against LRH.PktLen, so use the max bytes included

 * in the LRH.

 *

 * This routine changes all VL values except VL15, which it maintains at

 * the same value.

 adjust kernel credit return thresholds based on new MTUs */

 all kernel receive contexts have the same hdrqentsize */

 Adjust maximum MTU for the port in DC */

	/*

	 * Program 0 in CSR if port lid is extended. This prevents

	 * 9B packets being sent out for large lids.

	/*

	 * Iterate over all the send contexts and set their SLID check

 Now we have to do the same thing for the sdma engines */

 describe the given last state complete frame */

	/*

	 * Decode frame:

	 *  [ 0: 0] - success

	 *  [ 3: 1] - state

	 *  [ 7: 4] - next state timeout

	 *  [15: 8] - reason code

	 *  [31:16] - lanes

/*

 * Read the last state complete frames and explain them.  This routine

 * expects to be called if the link went down during link negotiation

 * and initialization (LNI).  That is, anywhere between polling and link up.

	/*

	 * Don't report anything if there is nothing to report.  A value of

	 * 0 means the link was taken down while polling and there was no

	 * training in-process.

 wait for wait_ms for LINK_TRANSFER_ACTIVE to go to 1 */

 watch LCB_STS_LINK_TRANSFER_ACTIVE */

 called when the logical link state is not down as it should be */

	/*

	 * Bring link up in LCB loopback

	/*

	 * Bring the link down again.

/*

 * Helper for set_link_state().  Do not call except from that routine.

 * Expects ppd->hls_mutex to be held.

 *

 * @rem_reason value to be sent to the neighbor

 *

 * LinkDownReasons only set if transition succeeds.

 start offline transition */

 Disabling AOC transmitters */

 not fatal, but should warn */

	/*

	 * Wait for the offline.Quiet transition if it hasn't happened yet. It

	 * can take a while for the link to go down.

	/*

	 * Now in charge of LCB - must be after the physical state is

	 * offline.quiet and before host_link_state is changed.

 watch LCB errors */

 make sure the logical state is also down */

 LCB access allowed */

	/*

	 * The LNI has a mandatory wait time after the physical state

	 * moves to Offline.Quiet.  The wait time may be different

	 * depending on how the link went down.  The 8051 firmware

	 * will observe the needed wait time and only move to ready

	 * when that is completed.  The largest of the quiet timeouts

	 * is 6s, so wait that long and then at least 0.5s more for

	 * other transitions, and another 0.5s for a buffer.

 state is really offline, so make it so */

	/*

	 * The state is now offline and the 8051 is ready to accept host

	 * requests.

	 *	- change our state

	 *	- notify others if we were previously in a linkup state

 went down while link was up */

 went down while attempting link up */

 The QSFP doesn't need to be reset on LNI failure */

 the active link width (downgrade) is 0 on link down */

 return the link state name */

 return the link state reason name */

/*

 * driver_pstate - convert the driver's notion of a port's

 * state (an HLS_*) into a physical state (a {IB,OPA}_PORTPHYSSTATE_*).

 * Return -1 (converted to a u32) to indicate error.

/*

 * driver_lstate - convert the driver's notion of a port's

 * state (an HLS_*) into a logical state (a IB_PORT_*). Return -1

 * (converted to a u32) to indicate error.

/**

 * data_vls_operational() - Verify if data VL BCT credits and MTU

 *			    are both set.

 * @ppd: pointer to hfi1_pportdata structure

 *

 * Return: true - Ok, false -otherwise.

/*

 * Change the physical and/or logical link state.

 *

 * Do not call this routine while inside an interrupt.  It contains

 * calls to routines that can take multiple seconds to finish.

 *

 * Returns 0 on success, -errno on failure.

 interpret poll -> poll as a link bounce */

	/*

	 * If we're going to a (HLS_*) link state that implies the logical

	 * link state is neither of (IB_PORT_ARMED, IB_PORT_ACTIVE), then

	 * reset is_sm_config_started to 0.

	/*

	 * Do nothing if the states match.  Let a poll to poll link bounce

	 * go through.

			/*

			 * Quick link up jumps from polling to here.

			 *

			 * Whether in normal or loopback mode, the

			 * simulator jumps from polling to link up.

			 * Accept that here.

 OK */

		/*

		 * Wait for Link_Up physical state.

		 * Physical and Logical states should already be

		 * be transitioned to LinkUp and LinkInit respectively.

 clear old transient LINKINIT_REASON code */

 enable the port */

		/*

		 * After link up, a new link width will have been set.

		 * Update the xmit counters with regards to the new

		 * link width.

		/*

		 * The simulator does not currently implement SMA messages,

		 * so neighbor_normal is not set.  Set it here when we first

		 * move to Armed.

 tell all engines to go running */

 Signal the IB layer that the port has went active */

 Hand LED control to the DC */

 quick linkup does not go into polling */

		/*

		 * Change the host link state after requesting DC8051 to

		 * change its physical state so that we can ignore any

		 * interrupt with stale LNI(XX) error, which will not be

		 * cleared until DC8051 transitions to Polling state.

		/*

		 * If an error occurred above, go back to offline.  The

		 * caller may reschedule another attempt.

 link is disabled */

 allow any state to transition to disabled */

 must transition to offline first */

 allow any state to transition to offline */

 transient within goto_offline() */

 transient within goto_offline() */

		/*

		 * The VL Arbitrator high limit is sent in units of 4k

		 * bytes, while HFI stores it in units of 64 bytes.

 IB link default (sleep/poll) */

 HFI only supports POLL as the default link down state */

	/*

	 * For link width, link width downgrade, and speed enable, always AND

	 * the setting with what is actually supported.  This has two benefits.

	 * First, enabled can't have unsupported values, no matter what the

	 * SM or FM might want.  Second, the ALL_SUPPORTED wildcards that mean

	 * "fill in with your supported value" have all the bits in the

	 * field set, so simply ANDing with supported has the desired result.

 set allowed Link-width */

 set allowed link width downgrade */

 allowed Link speeds */

 IB overrun threshold */

		/*

		 * HFI does not follow IB specs, save this value

		 * so we can report it, if asked.

 IB PHY error threshold */

		/*

		 * HFI does not follow IB specs, save this value

		 * so we can report it, if asked.

 begin functions related to vl arbitration table caching */

	/*

	 * Note that we always return values directly from the

	 * 'vl_arb_cache' (and do no CSR reads) in response to a

	 * 'Get(VLArbTable)'. This is obviously correct after a

	 * 'Set(VLArbTable)', since the cache will then be up to

	 * date. But it's also correct prior to any 'Set(VLArbTable)'

	 * since then both the cache, and the relevant h/w registers

	 * will be zeroed.

/*

 * vl_arb_lock_cache

 *

 * All other vl_arb_* functions should be called only after locking

 * the cache.

 end functions related to vl arbitration table caching */

		/*

		 * Before adjusting VL arbitration weights, empty per-VL

		 * FIFOs, otherwise a packet whose VL weight is being

		 * set to 0 could get stuck in a FIFO with no chance to

		 * egress.

		/*

		 * NOTE: The low priority shift and mask are used here, but

		 * they are the same for both the low and high registers.

 reopen all VLs */

/*

 * Read one credit merge VL register.

/*

 * Read the current credit merge limits.

 not all entries are filled in */

 OPA and HFI have a 1-1 mapping */

 NOTE: assumes that VL* and VL15 CSRs are bit-wise identical */

 each register contains 16 SC->VLnt mappings, 4 bits each */

 change only the shared limit portion of SendCmGLobalCredit */

 change only the total credit limit portion of SendCmGLobalCredit */

 set the given per-VL shared limit */

 set the given per-VL dedicated limit */

 spin until the given per-VL status mask bits clear */

 success */

 timed out */

	/*

	 * If this occurs, it is likely there was a credit loss on the link.

	 * The only recovery from that is a link bounce.

/*

 * The number of credits on the VLs may be changed while everything

 * is "live", but the following algorithm must be followed due to

 * how the hardware is actually implemented.  In particular,

 * Return_Credit_Status[] is the only correct status check.

 *

 * if (reducing Global_Shared_Credit_Limit or any shared limit changing)

 *     set Global_Shared_Credit_Limit = 0

 *     use_all_vl = 1

 * mask0 = all VLs that are changing either dedicated or shared limits

 * set Shared_Limit[mask0] = 0

 * spin until Return_Credit_Status[use_all_vl ? all VL : mask0] == 0

 * if (changing any dedicated limit)

 *     mask1 = all VLs that are lowering dedicated limits

 *     lower Dedicated_Limit[mask1]

 *     spin until Return_Credit_Status[mask1] == 0

 *     raise Dedicated_Limits

 * raise Shared_Limits

 * raise Global_Shared_Credit_Limit

 *

 * lower = if the new limit is lower, set the limit to the new value

 * raise = if the new limit is higher than the current value (may be changed

 *	earlier in the algorithm), set the new limit to the new value

	/*

	 * A0: add the variable any_shared_limit_changing below and in the

	 * algorithm above.  If removing A0 support, it can be removed.

 look at VL15 and less */

 find the new total credits, do sanity check on unused VLs */

 fetch the current values */

	/*

	 * Create the masks we will use.

	/*

	 * NOTE: Assumes that the individual VL bits are adjacent and in

	 * increasing order

 bracket the credit change with a total adjustment */

	/*

	 * Start the credit change algorithm.

 now raise all dedicated that are going up */

 next raise all shared that are going up */

 finally raise the global shared */

 bracket the credit change with a total adjustment */

	/*

	 * Determine the actual number of operational VLS using the number of

	 * dedicated and shared credits for each VL.

/*

 * Read the given fabric manager table. Return the size of the

 * table (in bytes) on success, and a negative error code on

 * failure.

		/*

		 * OPA specifies 128 elements (of 2 bytes each), though

		 * HFI supports only 16 elements in h/w.

		/*

		 * OPA specifies 128 elements (of 2 bytes each), though

		 * HFI supports only 16 elements in h/w.

 OPA specifies 128 elements, of 2 bytes each */

		/*

		 * OPA specifies that this is the same size as the VL

		 * arbitration tables (i.e., 256 bytes).

/*

 * Write the given fabric manager table.

/*

 * Disable all data VLs.

 *

 * Return 0 if disabled, non-zero if the VLs cannot be disabled.

/*

 * open_fill_data_vls() - the counterpart to stop_drain_data_vls().

 * Just re-enables all data VLs (the "fill" part happens

 * automatically - the name was chosen for symmetry with

 * stop_drain_data_vls()).

 *

 * Return 0 if successful, non-zero if the VLs cannot be enabled.

/*

 * drain_data_vls() - assumes that disable_data_vls() has been called,

 * wait for occupancy (of per-VL FIFOs) for all contexts, and SDMA

 * engines to drop to 0.

/*

 * stop_drain_data_vls() - disable, then drain all per-VL fifos.

 *

 * Use open_fill_data_vls() to resume using data VLs.  This pair is

 * meant to be used like this:

 *

 * stop_drain_data_vls(dd);

 * // do things with per-VL resources

 * open_fill_data_vls(dd);

/*

 * Convert a nanosecond time to a cclock count.  No matter how slow

 * the cclock, a non-zero ns will always have a non-zero result.

 simulation pretends to be ASIC */

 if ns nonzero, must be at least 1 */

/*

 * Convert a cclock count to nanoseconds. Not matter how slow

 * the cclock, a non-zero cclocks will always have a non-zero result.

 simulation pretends to be ASIC */

/*

 * Dynamically adjust the receive interrupt timeout for a context based on

 * incoming packet rate.

 *

 * NOTE: Dynamic adjustment does not allow rcv_intr_count to be zero.

	/*

	 * This algorithm doubles or halves the timeout depending on whether

	 * the number of packets received in this interrupt were less than or

	 * greater equal the interrupt count.

	 *

	 * The calculations below do not allow a steady state to be achieved.

	 * Only at the endpoints it is possible to have an unchanging

	 * timeout.

		/*

		 * Not enough packets arrived before the timeout, adjust

		 * timeout downward.

 already at minimum? */

		/*

		 * More than enough packets arrived before the timeout, adjust

		 * timeout upward.

 already at max? */

	/*

	 * timeout cannot be larger than rcv_intr_timeout_csr which has already

	 * been verified to be in range

	/*

	 * Need to write timeout register before updating RcvHdrHead to ensure

	 * that a new value is used when the HW decides to restart counting.

/*

 * Context Control and Receive Array encoding for buffer size:

 *	0x0 invalid

 *	0x1   4 KB

 *	0x2   8 KB

 *	0x3  16 KB

 *	0x4  32 KB

 *	0x5  64 KB

 *	0x6 128 KB

 *	0x7 256 KB

 *	0x8 512 KB (Receive Array only)

 *	0x9   1 MB (Receive Array only)

 *	0xa   2 MB (Receive Array only)

 *

 *	0xB-0xF - reserved (Receive Array only)

 *

 *

 * This routine assumes that the value has already been sanity checked.

 if invalid, go with the minimum size */

/**

 * encode_rcv_header_entry_size - return chip specific encoding for size

 * @size: size in dwords

 *

 * Convert a receive header entry size that to the encoding used in the CSR.

 *

 * Return a zero if the given size is invalid, otherwise the encoding.

 there are only 3 valid receive header entry sizes */

 invalid */

/**

 * hfi1_validate_rcvhdrcnt - validate hdrcnt

 * @dd: the device data

 * @thecnt: the header count

/**

 * set_hdrq_regs - set header queue registers for context

 * @dd: the device data

 * @ctxt: the context

 * @entsize: the dword entry size

 * @hdrcnt: the number of header entries

	/*

	 * Program dummy tail address for every receive context

	 * before enabling any receive context

 if the context already enabled, don't do the extra steps */

 reset the tail and hdr addresses, and sequence count */

 reset the cached receive header queue head value */

		/*

		 * Zero the receive header queue so we don't get false

		 * positives when checking the sequence number.  The

		 * sequence numbers could land exactly on the same spot.

		 * E.g. a rcd restart before the receive header wrapped.

 starting timeout */

 enable the context */

 clean the egr buffer size first */

 zero RcvHdrHead - set RcvHdrHead.Counter after enable */

 zero RcvEgrIndexHead */

 set eager count and base index */

		/*

		 * Set TID (expected) count and base index.

		 * rcd->expected_count is set to individual RcvArray entries,

		 * not pairs, and the CSR takes a pair-count in groups of

		 * four, so divide by 8.

		/*

		 * When receive context is being disabled turn on tail

		 * update with a dummy tail address and then disable

		 * receive context.

 Enabling RcvCtxtCtrl.TailUpd is intentional. */

 See comment on RcvCtxtCtrl.TailUpd above */

		/*

		 * In one-packet-per-eager mode, the size comes from

		 * the RcvArray entry.

 work around sticky RcvCtxtStatus.BlockedRHQFull */

		/*

		 * The interrupt timeout and count must be set after

		 * the context is enabled to take effect.

 set interrupt timeout */

 set RcvHdrHead.Counter, zero RcvHdrHead.Head (again) */

		/*

		 * If the context has been disabled and the Tail Update has

		 * been cleared, set the RCV_HDR_TAIL_ADDR CSR to dummy address

		 * so it doesn't contain an address that is invalid.

 Get the start of the block of counters */

		/*

		 * Now go and fill in each counter in the block.

 Nothing */

/*

 * Used by sysfs to create files for hfi stats to read

 Nothing */

 If its a synthetic counter there is more work we need to do */

 No need to read already saturated */

 32bit counters can wrap multiple times */

 hw wrapped */

 If we rolled we are saturated */

 return the full 64bit value */

 We do not want to bother for disabled contexts */

 We do not want to bother for disabled contexts */

	/*

	 * Rather than keep beating on the CSRs pick a minimal set that we can

	 * check to watch for potential roll over. We can do this by looking at

	 * the number of flits sent/recv. If the total flits exceeds 32bits then

	 * we have to iterate all the counters and update.

		/*

		 * May not be strictly necessary to update but it won't hurt and

		 * simplifies the logic here.

		/*

		 * We want the value in the register. The goal is to keep track

		 * of the number of "ticks" not the counter value. In other

		 * words if the register rolls we want to notice it and go ahead

		 * and force an update.

 15 chars + one for /0 */

 set up the stats timer; the add_timer is done at the end */

**********************/

 per device counters */

**********************/

 size names and determine how many we have*/

 Add ",32" for 32-bit counters */

 Add ",32" for 32-bit counters */

 +1 for newline. */

 Add ",32" for 32-bit counters */

 allocate space for the counter values */

 allocate space for the counter names */

 fill in the names */

 Nothing */

 Counter is 32 bits */

 Counter is 32 bits */

 Counter is 32 bits */

********************/

 per port counters */

********************/

	/*

	 * Go through the counters for the overflows and disable the ones we

	 * don't need. This varies based on platform so we need to do it

	 * dynamically here.

 size port counter names and determine how many we have*/

 Add ",32" for 32-bit counters */

 +1 for newline */

 Add ",32" for 32-bit counters */

 allocate space for the counter names */

 fill in port cntr names */

 Counter is 32 bits */

 Counter is 32 bits */

 allocate per port storage for counter values */

 CPU counters need to be allocated and zeroed */

 look at the HFI meta-states only */

 return the OPA port logical state name */

 return the OPA port physical state name */

/**

 * update_statusp - Update userspace status flag

 * @ppd: Port data structure

 * @state: port state information

 *

 * Actual port status is determined by the host_link_state value

 * in the ppd.

 *

 * host_link_state MUST be updated before updating the user space

 * statusp.

	/*

	 * Set port status flags in the page mapped into userspace

	 * memory. Do it here to ensure a reliable state - this is

	 * the only function called by all state handling code.

	 * Always set the flags due to the fact that the cache value

	 * might have been changed explicitly outside of this

	 * function.

/**

 * wait_logical_linkstate - wait for an IB link state change to occur

 * @ppd: port device

 * @state: the state to wait for

 * @msecs: the number of milliseconds to wait

 *

 * Wait up to msecs milliseconds for IB link state change to occur.

 * For now, take the easy polling route.

 * Returns 0 if state reached, otherwise -ETIMEDOUT.

/*

 * Read the physical hardware link state and check if it matches host

 * drivers anticipated state.

/*

 * wait_physical_linkstate - wait for an physical link state change to occur

 * @ppd: port device

 * @state: the state to wait for

 * @msecs: the number of milliseconds to wait

 *

 * Wait up to msecs milliseconds for physical link state change to occur.

 * Returns 0 if state reached, otherwise -ETIMEDOUT.

 sleep 2ms-ish */

/*

 * wait_phys_link_offline_quiet_substates - wait for any offline substate

 * @ppd: port device

 * @msecs: the number of milliseconds to wait

 *

 * Wait up to msecs milliseconds for any offline physical link

 * state change to occur.

 * Returns 0 if at least one state is reached, otherwise -ETIMEDOUT.

 sleep 2ms-ish */

/*

 * wait_phys_link_out_of_offline - wait for any out of offline state

 * @ppd: port device

 * @msecs: the number of milliseconds to wait

 *

 * Wait up to msecs milliseconds for any out of offline physical link

 * state change to occur.

 * Returns 0 if at least one state is reached, otherwise -ETIMEDOUT.

 sleep 2ms-ish */

 triggers is a 3-bit value - 1 bit per trigger. */

 ========================================================================= */

/**

 * read_mod_write() - Calculate the IRQ register index and set/clear the bits

 * @dd: valid devdata

 * @src: IRQ source to determine register index from

 * @bits: the bits to set or clear

 * @set: true == set the bits, false == clear the bits

 *

/**

 * set_intr_bits() - Enable/disable a range (one or more) IRQ sources

 * @dd: valid devdata

 * @first: first IRQ source to set/clear

 * @last: last IRQ source (inclusive) to set/clear

 * @set: true == set the bits, false == clear the bits

 *

 * If first == last, set the exact source.

 wrapped to next register? */

/*

 * Clear all interrupt sources on the chip.

/*

 * Remap the interrupt source from the general handler to the given MSI-X

 * interrupt.

 clear from the handled mask of the general interrupt */

 direct the chip source to the given MSI-X interrupt */

	/*

	 * SDMA engine interrupt sources grouped by type, rather than

	 * engine.  Per-engine interrupts are as follows:

	 *	SDMA

	 *	SDMAProgress

	 *	SDMAIdle

/*

 * Set the general handler to accept all interrupts, remap all

 * chip interrupts back to MSI-X 0.

 all interrupts handled by the general handler */

 all chip interrupts map to MSI-X 0 */

/**

 * set_up_interrupts() - Initialize the IRQ resources and state

 * @dd: valid devdata

 *

 mask all interrupts */

 clear all pending interrupts */

 reset general handler mask, chip MSI-X mappings */

 ask for MSI-X interrupts */

/*

 * Set up context values in dd.  Sets:

 *

 *	num_rcv_contexts - number of contexts being used

 *	n_krcv_queues - number of kernel contexts

 *	first_dyn_alloc_ctxt - first dynamically allocated context

 *                             in array of contexts

 *	freectxts  - number of free user contexts

 *	num_send_contexts - number of PIO send contexts being used

 *	num_netdev_contexts - number of contexts reserved for netdev

	/*

	 * Kernel receive contexts:

	 * - Context 0 - control context (VL15/multicast/error)

	 * - Context 1 - first kernel context

	 * - Context 2 - second kernel context

	 * ...

		/*

		 * n_krcvqs is the sum of module parameter kernel receive

		 * contexts, krcvqs[].  It does not include the control

		 * context, so add that.

	/*

	 * Every kernel receive context needs an ACK send context.

	 * one send context is allocated for each VL{0-7} and VL15

	/*

	 * User contexts:

	 *	- default to 1 user context per real (non-HT) CPU core if

	 *	  num_user_contexts is negative

	/*

	 * Adjust the counts given a global max.

 recalculate */

	/*

	 * The RMT entries are currently allocated as shown below:

	 * 1. QOS (0 to 128 entries);

	 * 2. FECN (num_kernel_context - 1 + num_user_contexts +

	 *    num_netdev_contexts);

	 * 3. netdev (num_netdev_contexts).

	 * It should be noted that FECN oversubscribe num_netdev_contexts

	 * entries of RMT because both netdev and PSM could allocate any receive

	 * context between dd->first_dyn_alloc_text and dd->num_rcv_contexts,

	 * and PSM FECN must reserve an RMT entry for each possible PSM receive

	 * context.

 recalculate */

 the first N are kernel contexts, the rest are user/netdev contexts */

	/*

	 * Receive array allocation:

	 *   All RcvArray entries are divided into groups of 8. This

	 *   is required by the hardware and will speed up writes to

	 *   consecutive entries by using write-combining of the entire

	 *   cacheline.

	 *

	 *   The number of groups are evenly divided among all contexts.

	 *   any left over groups will be given to the first N user

	 *   contexts.

	/*

	 * PIO send contexts

 success */

 success */

/*

 * Set the device/port partition key table. The MAD code

 * will ensure that, at least, the partial management

 * partition key is present in the table.

 Each register holds 4 PKey values. */

 Always enable HW pkeys check when pkeys table is set */

/*

 * These CSRs and memories are uninitialized on reset and must be

 * written before reading to set the ECC/parity bits.

 *

 * NOTE: All user context CSRs that are not mmaped write-only

 * (e.g. the TID flows) must be initialized even if the driver never

 * reads them.

 CceIntMap */

 SendCtxtCreditReturnAddr */

 PIO Send buffers */

 SDMA Send buffers */

	/*

	 * These are not normally read, and (presently) have no method

	 * to be read, so are not pre-initialized

 RcvHdrAddr */

 RcvHdrTailAddr */

 RcvTidFlowTable */

 RcvArray */

 RcvQPMapTable */

/*

 * Use the ctrl_bits in CceCtrl to clear the status_bits in CceStatus.

 is the condition present? */

 clear the condition */

 wait for the condition to clear */

 set CCE CSRs to chip reset defaults */

 CCE_REVISION read-only */

 CCE_REVISION2 read-only */

 CCE_CTRL - bits clear automatically */

 CCE_STATUS read-only, use CceCtrl to clear */

 CCE_ERR_STATUS read-only */

 CCE_ERR_FORCE leave alone */

 CCE_PCIE_CTRL leave alone */

 CCE_MSIX_PBA read-only */

 CCE_INT_STATUS read-only */

 CCE_INT_FORCE leave alone */

 CCE_INT_BLOCKED read-only */

 set MISC CSRs to chip reset defaults */

	/*

	 * MISC_CFG_SHA_PRELOAD leave alone - always reads 0 and can

	 * only be written 128-byte chunks

 init RSA engine to clear lingering errors */

 MISC_STS_8051_DIGEST read-only */

 MISC_STS_SBM_DIGEST read-only */

 MISC_STS_PCIE_DIGEST read-only */

 MISC_STS_FAB_DIGEST read-only */

 MISC_ERR_STATUS read-only */

 MISC_ERR_FORCE leave alone */

 set TXE CSRs to chip reset defaults */

	/*

	 * TXE Kernel CSRs

 reset CM internal state */

 SEND_CONTEXTS read-only */

 SEND_DMA_ENGINES read-only */

 SEND_PIO_MEM_SIZE read-only */

 SEND_DMA_MEM_SIZE read-only */

 SEND_PIO_INIT_CTXT */

 SEND_PIO_ERR_STATUS read-only */

 SEND_PIO_ERR_FORCE leave alone */

 SEND_DMA_ERR_STATUS read-only */

 SEND_DMA_ERR_FORCE leave alone */

 SEND_EGRESS_ERR_STATUS read-only */

 SEND_EGRESS_ERR_FORCE leave alone */

 SEND_ERR_STATUS read-only */

 SEND_ERR_FORCE read-only */

 SEND_CM_CREDIT_USED_STATUS read-only */

 SEND_CM_CREDIT_USED_VL read-only */

 SEND_CM_CREDIT_USED_VL15 read-only */

 SEND_EGRESS_CTXT_STATUS read-only */

 SEND_EGRESS_SEND_DMA_STATUS read-only */

 SEND_EGRESS_ERR_INFO read-only */

 SEND_EGRESS_ERR_SOURCE read-only */

	/*

	 * TXE Per-Context CSRs

	/*

	 * TXE Per-SDMA CSRs

 SEND_DMA_STATUS read-only */

 SEND_DMA_HEAD read-only */

 SEND_DMA_IDLE_CNT read-only */

 SEND_DMA_DESC_FETCHED_CNT read-only */

 SEND_DMA_ENG_ERR_STATUS read-only */

 SEND_DMA_ENG_ERR_FORCE leave alone */

/*

 * Expect on entry:

 * o Packet ingress is disabled, i.e. RcvCtrl.RcvPortEnable == 0

	/*

	 * Wait for DMA to stop: RxRbufPktPending and RxPktInProgress are

	 * clear.

		/*

		 * Give up after 1ms - maximum wait time.

		 *

		 * RBuf size is 136KiB.  Slowest possible is PCIe Gen1 x1 at

		 * 250MB/s bandwidth.  Lower rate to 66% for overhead to get:

		 *	136 KB / (66% * 250MB/s) = 844us

 do not busy-wait the CSR */

 start the init - expect RcvCtrl to be 0 */

	/*

	 * Read to force the write of Rcvtrl.RxRbufInit.  There is a brief

	 * period after the write before RcvStatus.RxRbufInitDone is valid.

	 * The delay in the first run through the loop below is sufficient and

	 * required before the first read of RcvStatus.RxRbufInintDone.

 wait for the init to finish */

 delay is required first time through - see above */

 do not busy-wait the CSR */

 give up after 100us - slowest possible at 33MHz is 73us */

 set RXE CSRs to chip reset defaults */

	/*

	 * RXE Kernel CSRs

 RCV_STATUS read-only */

 RCV_CONTEXTS read-only */

 RCV_ARRAY_CNT read-only */

 RCV_BUF_SIZE read-only */

 this is a clear-down */

 RCV_ERR_STATUS read-only */

 RCV_ERR_FORCE leave alone */

	/*

	 * RXE Kernel and User Per-Context CSRs

 kernel */

 RCV_CTXT_STATUS read-only */

 user */

 RCV_HDR_TAIL read-only */

 RCV_EGR_INDEX_TAIL read-only */

 RCV_EGR_OFFSET_TAIL read-only */

/*

 * Set sc2vl tables.

 *

 * They power on to zeros, so to avoid send context errors

 * they need to be set:

 *

 * SC 0-7 -> VL 0-7 (respectively)

 * SC 15  -> VL 15

 * otherwise

 *        -> VL 0

 init per architecture spec, constrained by hardware capability */

 HFI maps sent packets */

 DC maps received packets */

 initialize the cached sc2vl values consistently with h/w */

/*

 * Read chip sizes and then reset parts to sane, disabled, values.  We cannot

 * depend on the chip going through a power-on reset - a driver may be loaded

 * and unloaded many times.

 *

 * Do not write any CSR values to the chip in this routine - there may be

 * a reset following the (possible) FLR in this routine.

 *

	/*

	 * Put the HFI CSRs in a known state.

	 * Combine this with a DC reset.

	 *

	 * Stop the device from doing anything while we do a

	 * reset.  We know there are no other active users of

	 * the device since we are now in charge.  Turn off

	 * off all outbound and inbound traffic and make sure

	 * the device does not generate any interrupts.

 disable send contexts and SDMA engines */

 disable port (turn off RXE inbound traffic) and contexts */

 mask all interrupt sources */

	/*

	 * DC Reset: do a full DC reset before the register clear.

	 * A recommended length of time to hold is one CSR read,

	 * so reread the CceDcCtrl.  Then, hold the DC in reset

	 * across the clear.

		/*

		 * A FLR will reset the SPC core and part of the PCIe.

		 * The parts that need to be restored have already been

		 * saved.

 do the FLR, the DC reset will remain */

 restore command and BARs */

 clear the DC reset */

 Set the LED off */

	/*

	 * Clear the QSFP reset.

	 * An FLR enforces a 0 on all out pins. The driver does not touch

	 * ASIC_QSFPn_OUT otherwise.  This leaves RESET_N low and

	 * anything plugged constantly in reset, if it pays attention

	 * to RESET_N.

	 * Prime examples of this are optical cables. Set all pins high.

	 * I2CCLK and I2CDAT will change per direction, and INT_N and

	 * MODPRS_N are input only and their value is ignored.

 assign link credit variables */

 enough room for 8 MAD packets plus header - 17K */

/**

 * hfi1_get_qp_map - get qp map

 * @dd: device data

 * @idx: index to read

/**

 * init_qpmap_table - init qp map

 * @dd: device data

 * @first_ctxt: first context

 * @last_ctxt: first context

 *

 * This return sets the qpn mapping table that

 * is indexed by qpn[8:1].

 *

 * The routine will round robin the 256 settings

 * from first_ctxt to last_ctxt.

 *

 * The first/last looks ahead to having specialized

 * receive contexts for mgmt and bypass.  Normal

 * verbs traffic will assumed to be on a range

 * of receive contexts.

/*

 * Return an initialized RMT map table for users to fill in.  OK if it

 * returns NULL, indicating no table.

 0 is default if a0 ver. */

/*

 * Write the final RMT map table to the chip and free the table.  OK if

 * table is NULL.

 write table to chip */

 enable RSM */

 Is a receive side mapping rule */

/*

 * Add a receive side mapping rule.

 enable bit */

/*

 * Clear a receive side mapping rule.

 return the number of RSM map table entries that will be used for QOS */

 is QOS active at all? */

 determine bits for qpn */

 determine bits for vl */

 reject if too much is used */

/**

 * init_qos - init RX qos

 * @dd: device data

 * @rmt: RSM map table

 *

 * This routine initializes Rule 0 and the RSM map table to implement

 * quality of service (qos).

 *

 * If all of the limit tests succeed, qos is applied based on the array

 * interpretation of krcvqs where entry 0 is VL0.

 *

 * The number of vl bits (n) and the number of qpn bits (m) are computed to

 * feed both the RSM map table and the single rule.

 enough room in the map table? */

 add qos entries to the RSM map table */

 generate the index the hardware will produce */

 replace default with context number */

 add rule 0 */

 mark RSM map entries as used */

 map everything else to the mcast/err/vl15 context */

 Exclude context 0 */

 there needs to be enough room in the map table */

	/*

	 * RSM will extract the destination context as an index into the

	 * map table.  The destination contexts are a sequential block

	 * in the range start...num_rcv_contexts-1 (inclusive).

	 * Map entries are accessed as offset + extracted value.  Adjust

	 * the added offset so this sequence can be placed anywhere in

	 * the table - as long as the entries themselves do not wrap.

	 * There are only enough bits in offset for the table size, so

	 * start with that to allow for a "negative" offset.

 replace with identity mapping */

	/*

	 * For RSM intercept of Expected FECN packets:

	 * o packet type 0 - expected

	 * o match on F (bit 95), using select/match 1, and

	 * o match on SH (bit 133), using select/match 2.

	 *

	 * Use index 1 to extract the 8-bit receive context from DestQP

	 * (start at bit 64).  Use that as the RSM map table index.

 add rule 1 */

 We already have contexts mapped in RMT */

 Update RSM mapping table, 32 regs, 256 entries - 1 ctx per byte */

 Update map register with netdev context */

 Wrap up netdev ctx index */

 Write back map register */

	/*

	 * go through with the initialisation only if this rule actually doesn't

	 * exist yet

 Initialize RSM for VNIC */

 Add rule for vnic */

 Match 16B packets */

 Match ETH L4 packets */

 Calc context from veswid and entropy */

 only actually clear the rule if it's the last user asking to do so */

 enable all receive errors */

 set up QOS, including the QPN map table */

 record number of used rsm map entries for netdev */

	/*

	 * make sure RcvCtrl.RcvWcb <= PCIe Device Control

	 * Register Max_Payload_Size (PCI_EXP_DEVCTL in Linux PCIe config

	 * space, PciCfgCap2.MaxPayloadSize in HFI).  There is only one

	 * invalid configuration: RcvCtrl.RcvWcb set to its max of 256 and

	 * Max_PayLoad_Size set to its minimum of 128.

	 *

	 * Presently, RcvCtrl.RcvWcb is not modified from its default of 0

	 * (64 bytes).  Max_Payload_Size is possibly modified upward in

	 * tune_pcie_caps() which is called after this routine.

 Have 16 bytes (4DW) of bypass header available in header queue */

 enable all CCE errors */

 enable *some* Misc errors */

 enable all DC errors, except LCB */

/*

 * Fill out the given AU table using the given CU.  A CU is defined in terms

 * AUs.  The table is a an encoding: given the index, how many AUs does that

 * represent?

 *

 * NOTE: Assumes that the register layout is the same for the

 * local and remote tables.

 enable all PIO, SDMA, general, and Egress errors */

 enable all per-context and per-SDMA engine errors */

 set the local CU to AU mapping */

	/*

	 * Set reasonable default for Credit Return Timer

	 * Don't set on Simulator - causes it to choke.

 mask is always 1's */

 JOB_KEY_ALLOW_PERMISSIVE is not allowed by default */

	/*

	 * Enable send-side J_KEY integrity check, unless this is A0 h/w

 Enable J_KEY check on receive context. */

	/*

	 * Disable send-side J_KEY integrity check, unless this is A0 h/w.

	 * This check would not have been enabled for A0 h/w, see

	 * set_ctxt_jkey().

 Turn off the J_KEY on the receive side */

/*

 * Start doing the clean up the chip. Our clean up happens in multiple

 * stages and this is just the first.

/*

 * Information can be shared between the two HFIs on the same ASIC

 * in the same OS.  This function finds the peer device and sets

 * up a shared structure.

 pre-allocate the asic structure in case we are the first device */

 Find our peer device */

 use already allocated structure */

 self back-pointer */

 first one through - set up i2c devices */

/*

 * Set dd->boardname.  Use a generic name if a name is not returned from

 * EFI variable space.

 *

 * Return 0 on success, -ENOMEM if space could not be allocated.

 generic board description */

 use generic description */

/*

 * Check the interrupt registers to make sure that they are mapped correctly.

 * It is intended to help user identify any mismapping by VMM when the driver

 * is running in a VM. This function should only be called before interrupt

 * is set up properly.

 *

 * Return 0 on success, -EINVAL on failure.

 Clear CceIntMask[0] to avoid raising any interrupts */

 Clear all interrupt status bits */

 Set all interrupt status bits */

 Restore the interrupt mask */

/**

 * hfi1_init_dd() - Initialize most of the dd structure.

 * @dd: the dd device

 *

 * This is global, and is called directly at init to set up the

 * chip-specific function pointers for later use.

 implementation names */

 init common fields */

 DC supports 4 link widths */

 start out enabling only 4X */

 link width active is 0 when link is down */

 link width downgrade active is 0 when link is down */

 Set the default MTU. */

		/*

		 * Set the initial values to reasonable default, will be set

		 * for real when link is up.

 initialize supported LTP CRC mode */

 initialize enabled LTP CRC mode */

 start in offline */

	/*

	 * Do remaining PCIe setup and save PCIe values in dd.

	 * Any error printing is already done by the init code.

	 * On return, we have the chip mapped.

 Save PCI space registers to rewrite after device reset */

	/*

	 * Check interrupt registers mapping if the driver has no access to

	 * the upstream component. In this case, it is likely that the driver

	 * is running in a VM.

	/*

	 * obtain the hardware ID - NOT related to unit, which is a

	 * software enumeration

 the variable size will remove unwanted bits */

 speeds the hardware can support */

 speeds allowed to run at */

 give a reasonable active value, will be set on link up */

 fix up link widths for emulation _p */

 insure num_vls isn't larger than number of sdma engines */

	/*

	 * Convert the ns parameter to the 64 * cclocks used in the CSR.

	 * Limit the max if larger than the field holds.  If timeout is

	 * non-zero, then the calculated field will be at least 1.

	 *

	 * Must be after icode is set up - the cclock rate depends

	 * on knowing the hardware being used.

 needs to be done before we look for the peer device */

 set up shared ASIC data with peer device */

 obtain chip sizes, reset chip CSRs */

 read in the PCIe link speed information */

 call before get_platform_config(), after init_chip_resources() */

 Needs to be called before hfi1_firmware_init */

 read in firmware */

	/*

	 * In general, the PCIe Gen3 transition must occur after the

	 * chip has been idled (so it won't initiate any PCIe transactions

	 * e.g. an interrupt) and before the driver changes any registers

	 * (the transition will reset the registers).

	 *

	 * In particular, place this call after:

	 * - init_chip()     - the chip will not initiate any PCIe transactions

	 * - pcie_speeds()   - reads the current link speed

	 * - hfi1_firmware_init() - the needed firmware is ready to be

	 *			    downloaded

	/*

	 * This should probably occur in hfi1_pcie_init(), but historically

	 * occurs after the do_pcie_gen3_transition() code.

 start setting dd values and adjusting CSRs */

 alloc VNIC/AIP rx data */

 set initial RXE CSRs */

 set initial TXE CSRs */

 set initial non-RXE, non-TXE CSRs */

 set up KDETH QP prefix in both RX and TX CSRs */

 send contexts must be set up before receive contexts */

	/*

	 * Initialize aspm, to be done after gen3 transition and setting up

	 * contexts and before enabling interrupts

 sdma init */

 use contexts created by hfi1_create_kctxts */

 set up LCB access - must be after set_up_interrupts() */

	/*

	 * Serial number is created from the base guid:

	 * [27:24] = base guid [38:35]

	 * [23: 0] = base guid [23: 0]

 asymmetric with dispose_firmware() */

 The user refcount starts with one to inidicate an active device */

 rates here are in units of 10^6 bits/sec */

 shouldn't happen */

 we can't help go faster, only slower */

/**

 * create_pbc - build a pbc for transmission

 * @ppd: info of physical Hfi port

 * @flags: special case flags or-ed in built pbc

 * @srate_mbs: static rate

 * @vl: vl

 * @dw_len: dword length (header words + data words + pbc words)

 *

 * Create a PBC with the given flags, rate, VL, and length.

 *

 * NOTE: The PBC created will not insert any HCRC - all callers but one are

 * for verbs, which does not use this PSM feature.  The lone other caller

 * is for the diagnostic interface which calls this if the user does not

 * supply their own PBC.

/*

 * Initialize the thermal sensor.

 *

 * After initialization, enable polling of thermal sensor through

 * SBus interface. In order for this to work, the SBus Master

 * firmware has to be loaded due to the fact that the HW polling

 * logic uses SBus interrupts, which are not supported with

 * default firmware. Otherwise, no data will be returned through

 * the ASIC_STS_THERM CSR.

 Disable polling of thermal readings */

 Thermal Sensor Initialization */

    Step 1: Reset the Thermal SBus Receiver */

    Step 2: Set Reset bit in Thermal block */

    Step 3: Write clock divider value (100MHz -> 2MHz) */

    Step 4: Select temperature mode */

    Step 5: De-assert block reset and start conversion */

    Step 5.1: Wait for first conversion (21.5ms per spec) */

 Enable polling of thermal readings */

 Set initialized flag */

	/*

	 * Thermal Critical Interrupt

	 * Put the device into forced freeze mode, take link down to

	 * offline, and put DC into reset.

	/*

	 * Shut DC down as much and as quickly as possible.

	 *

	 * Step 1: Take the link down to OFFLINE. This will cause the

	 *         8051 to put the Serdes in reset. However, we don't want to

	 *         go through the entire link state machine since we want to

	 *         shutdown ASAP. Furthermore, this is not a graceful shutdown

	 *         but rather an attempt to save the chip.

	 *         Code below is almost the same as quiet_serdes() but avoids

	 *         all the extra work and the sleeps.

	/*

	 * Step 2: Shutdown LCB and 8051

	 *         After shutdown, do not restore DC_CFG_RESET value.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2017 - 2018 Intel Corporation.

/*

 * This file contains HFI1 support for VNIC SDMA functionality

/*

 * struct vnic_txreq - VNIC transmit descriptor

 * @txreq: sdma transmit request

 * @sdma: vnic sdma pointer

 * @skb: skb to send

 * @pad: pad buffer

 * @plen: pad length

 * @pbc_val: pbc value

 combine physically continuous fragments later? */

 PBC */

 add pbc */

 add the ulp payload */

 setup the last plen bypes of pad */

 When -ECOMM, sdma callback will be called with ABORT status */

/*

 * hfi1_vnic_sdma_sleep - vnic sdma sleep function

 *

 * This function gets called from sdma_send_txreq() when there are not enough

 * sdma descriptors available to send the packet. It adds Tx queue's wait

 * structure to sdma engine's dmawait list to be woken up when descriptors

 * become available.

/*

 * hfi1_vnic_sdma_wakeup - vnic sdma wakeup function

 *

 * This function gets called when SDMA descriptors becomes available and Tx

 * queue's wait structure was previously added to sdma engine's dmawait list.

 * It notifies the upper driver about Tx queue wakeup.

 Add a free descriptor watermark for wakeups */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2020 Intel Corporation.

 *

/*

 * This file contains HFI1 support for ipoib functionality

 attach QP to multicast group */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015-2018 Intel Corporation.

/*

 * Send Context functions

/*

 * Set the CM reset bit and wait for it to clear.  Use the provided

 * sendctrl register.  This routine has no locking.

 global control of PIO send */

 write sendctrl back */

 re-read sendctrl to make sure it is flushed */

 Disallow sending on VLs not enabled */

 CSR already written (and flushed) */

 flush write */

 number of send context memory pools */

 Send Context Size (SCS) wildcards */

 Send Context Count (SCC) wildcards */

 Send Context Size (SCS) constants */

 3 pkts of 2048B data + 128B header */

 default send context sizes */

 even divide, pool 0 */

 one per NUMA */

 even divide, pool 0 */

 one per CPU */

 send context memory pool configuration */

 % of memory, in 100ths of 1% */

 absolute block count */

 default memory pool configuration: 100% in pool 0 */

 centi%, abs blocks */

 pool 0 */

 pool 1 */

 memory pool information, used when calculating final sizes */

	int centipercent;	/*

				 * 100th of 1% of memory to use, -1 if blocks

				 * already set

 count of contexts in the pool */

 block size of the pool */

 context size, in blocks */

/*

 * Convert a pool wildcard to a valid pool index.  The wildcards

 * start at -1 and increase negatively.  Map them as:

 *	-1 => 0

 *	-2 => 1

 *	etc.

 *

 * Return -1 on non-wildcard input, otherwise convert to a pool number.

 non-wildcard */

/*

 * Read the send context memory pool configuration and send context

 * size configuration.  Replace any wildcards and come up with final

 * counts and sizes for the send context types.

 centipercent total */

 absolute block total */

	/*

	 * When SDMA is enabled, kernel context pio packet size is capped by

	 * "piothreshold". Reduce pio buffer allocation for kernel context by

	 * setting it to a fixed size. The allocation allows 3-deep buffering

	 * of the largest pio packets plus up to 128 bytes header, sufficient

	 * to maintain verbs performance.

	 *

	 * When SDMA is disabled, keep the default pooling allocation.

	/*

	 * Step 0:

	 *	- copy the centipercents/absolute sizes from the pool config

	 *	- sanity check these values

	 *	- add up centipercents, then later check for full value

	 *	- add up absolute blocks, then later check for over-commit

		/*

		 * A negative value is "unused" or "invalid".  Both *can*

		 * be valid, but centipercent wins, so check that first

 centipercent valid */

 absolute blocks valid */

 neither valid */

 do not use both % and absolute blocks for different pools */

 if any percentages are present, they must add up to 100% x 100 */

 the absolute pool total cannot be more than the mem total */

	/*

	 * Step 2:

	 *	- copy from the context size config

	 *	- replace context type wildcard counts with real values

	 *	- add up non-memory pool block sizes

	 *	- add up memory pool user counts

		/*

		 * Sanity check count: Either a positive value or

		 * one of the expected wildcards is valid.  The positive

		 * value is checked later when we compare against total

		 * memory available.

		/*

		 * Sanity check pool: The conversion will return a pool

		 * number or -1 if a fixed (non-negative) value.  The fixed

		 * value is checked later when we compare against

		 * total memory available.

 non-wildcard */

 valid wildcard */

 invalid wildcard */

 step 3: calculate the blocks in the pools, and pool context sizes */

 subtract off the fixed pool blocks */

 % beats absolute blocks */

 warn about wasted blocks */

 step 4: fill in the context type sizes from the pool sizes */

 make sure we are not larger than what is allowed by the HW */

 calculate our total usage */

 hardware context map starts with invalid send context indices */

	/*

	 * All send contexts have their credit sizes.  Allocate credits

	 * for each context one after another from the global space.

/*

 * Allocate a software index and hardware context of the given type.

 *

 * Must be called with dd->sc_lock held.

 use a 1:1 mapping, but make them non-equal */

 success */

/*

 * Free the send context given by its software index.

 *

 * Must be called with dd->sc_lock held.

 return the base context of a context in a group */

 return the size of a group */

/*

 * Obtain the credit return addresses, kernel virtual and bus, for the

 * given sc.

 *

 * To understand this routine:

 * o va and dma are arrays of struct credit_return.  One for each physical

 *   send context, per NUMA.

 * o Each send context always looks in its relative location in a struct

 *   credit_return for its credit return.

 * o Each send context in a group must have its return address CSR programmed

 *   with the same value.  Use the address of the first send context in the

 *   group.

/*

 * Work queue function triggered in error interrupt routine for

 * kernel contexts.

/*

 * Calculate PIO block threshold for this send context using the given MTU.

 * Trigger a return when one MTU plus optional header of credits remain.

 *

 * Parameter mtu is in bytes.

 * Parameter hdrqentsize is in DWORDs.

 *

 * Return value is what to write into the CSR: trigger return when

 * unreturned credits pass this count.

 add in the header size, then divide by the PIO block size */

 check against this context's credits */

/*

 * Calculate credit threshold in terms of percent of the allocated credits.

 * Trigger when unreturned credits equal or exceed the percentage of the whole.

 *

 * Return value is what to write into the CSR: trigger return when

 * unreturned credits pass this count.

/*

 * Set the credit return threshold.

 force a credit return on change to avoid a possible stall */

/*

 * set_pio_integrity

 *

 * Set the CHECK_ENABLE register for the send context 'sc'.

/*

 * Allocate a NUMA relative send context structure of the given type along

 * with a HW context.

 do not allocate while frozen */

 grouping is always single context for now */

 PIO Send Memory Address details */

 set base and credits */

 unmask all errors */

 set the default partition key */

 per context type checks */

 set the send context check opcode mask and value */

 set up credit return */

	/*

	 * Calculate the initial credit return threshold.

	 *

	 * For Ack contexts, set a threshold for half the credits.

	 * For User contexts use the given percentage.  This has been

	 * sanitized on driver start-up.

	 * For Kernel contexts, use the default MTU plus a header

	 * or half the credits, whichever is smaller. This should

	 * work for both the 3-deep buffering allocation and the

	 * pooling allocation.

 kernel */

 add in early return */

 kernel, ack */

 set up write-through credit_ctrl */

 User send contexts should not allow sending on VL15 */

	/*

	 * Allocate shadow ring to track outstanding PIO buffers _after_

	 * unlocking.  We don't know the size until the lock is held and

	 * we can't allocate while the lock is held.  No one is using

	 * the context yet, so allocate it now.

	 *

	 * User contexts do not get a shadow ring.

		/*

		 * Size the shadow ring 1 larger than the number of credits

		 * so head == tail can mean empty.

 free a per-NUMA send context structure */

 ensure no restarts */

 make sure the HW is disabled */

 clear/disable all registers set in sc_alloc */

 release the index and context for re-use */

 disable the context */

 do all steps, even if already disabled */

	/*

	 * Flush any waiters.  Once the context is disabled,

	 * credit return interrupts are stopped (although there

	 * could be one in-process when the context is disabled).

	 * Wait one microsecond for any lingering interrupts, then

	 * proceed with the flush.

 this context has a shadow ring */

 return SendEgressCtxtStatus.PacketOccupancy */

 is egress halted on the context? */

 is the send context halted? */

/**

 * sc_wait_for_packet_egress - wait for packet

 * @sc: valid send context

 * @pause: wait for credit return

 *

 * Wait for packet egress, optionally pause for credit return

 *

 * Egress halt and Context halt are not necessarily the same thing, so

 * check for both.

 *

 * NOTE: The context halt bit may not be set immediately.  Because of this,

 * it is necessary to check the SW SFC_HALTED bit (set in the IRQ) and the HW

 * context bit to determine if the context is halted.

 done if any halt bits, SW or HW are set */

 counter is reset if occupancy count changes */

 timed out - bounce the link */

 Add additional delay to ensure chip returns all credits */

/*

 * Restart a context after it has been halted due to error.

 *

 * If the first step fails - wait for the halt to be asserted, return early.

 * Otherwise complain about timeouts but keep going.

 *

 * It is expected that allocations (enabled flag bit) have been shut off

 * already (only applies to kernel contexts).

 bounce off if not halted, or being free'd */

	/*

	 * Step 1: Wait for the context to actually halt.

	 *

	 * The error interrupt is asynchronous to actually setting halt

	 * on the context.

	/*

	 * Step 2: Ensure no users are still trying to write to PIO.

	 *

	 * For kernel contexts, we have already turned off buffer allocation.

	 * Now wait for the buffer count to go to zero.

	 *

	 * For user contexts, the user handling code has cut off write access

	 * to the context's PIO pages before calling this routine and will

	 * restore write access after this routine returns.

 kernel context */

	/*

	 * Step 3: Wait for all packets to egress.

	 * This is done while disabling the send context

	 *

	 * Step 4: Disable the context

	 *

	 * This is a superset of the halt.  After the disable, the

	 * errors can be cleared.

	/*

	 * Step 5: Enable the context

	 *

	 * This enable will clear the halted flag and per-send context

	 * error flags.

/*

 * PIO freeze processing.  To be called after the TXE block is fully frozen.

 * Go through all frozen send contexts and disable them.  The contexts are

 * already stopped by the freeze.

		/*

		 * Don't disable unallocated, unfrozen, or user send contexts.

		 * User send contexts will be disabled when the process

		 * calls into the driver to reset its context.

 only need to disable, the context is already stopped */

/*

 * Unfreeze PIO for kernel send contexts.  The precondition for calling this

 * is that all PIO send contexts have been disabled and the SPC freeze has

 * been cleared.  Now perform the last step and re-enable each kernel context.

 * User (PSM) processing will occur when PSM calls into the kernel to

 * acknowledge the freeze.

 will clear the sc frozen flag */

/**

 * pio_kernel_linkup() - Re-enable send contexts after linkup event

 * @dd: valid devive data

 *

 * When the link goes down, the freeze path is taken.  However, a link down

 * event is different from a freeze because if the send context is re-enabled

 * whowever is sending data will start sending data again, which will hang

 * any QP that is sending data.

 *

 * The freeze path now looks at the type of event that occurs and takes this

 * path for link down event.

 will clear the sc link down flag */

/*

 * Wait for the SendPioInitCtxt.PioInitInProgress bit to clear.

 * Returns:

 *	-ETIMEDOUT - if we wait too long

 *	-EIO	   - if there was an error

 max is the longest possible HW init time / delay */

/*

 * Reset all of the send contexts to their power-on state.  Used

 * only during manual init - no lock against sc_enable needed.

 make sure the init engine is not busy */

 ignore any timeout */

 clear the error */

 reset init all */

 enable the context */

	/*

	 * Obtain the allocator lock to guard against any allocation

	 * attempts (which should not happen prior to context being

	 * enabled). On the release/disable side we don't need to

	 * worry about locking since the releaser will not do anything

	 * if the context accounting values have not changed.

 already enabled */

 IMPORTANT: only clear free and fill if transitioning 0 -> 1 */

 the alloc lock insures no fast path allocation */

	/*

	 * Clear all per-context errors.  Some of these will be set when

	 * we are re-enabling after a context halt.  Now that the context

	 * is disabled, the halt will not clear until after the PIO init

	 * engine runs below.

	/*

	 * The HW PIO initialization engine can handle only one init

	 * request at a time. Serialize access to each device's engine.

	/*

	 * Since access to this code block is serialized and

	 * each access waits for the initialization to complete

	 * before releasing the lock, the PIO initialization engine

	 * should not be in use, so we don't have to wait for the

	 * InProgress bit to go down.

	/*

	 * Wait until the engine is done.  Give the chip the required time

	 * so, hopefully, we read the register just once.

	/*

	 * All is well. Enable the context.

	/*

	 * Read SendCtxtCtrl to force the write out and prevent a timing

	 * hazard where a PIO write may reach the context before the enable.

 force a credit return on the context */

 a 0->1 transition schedules a credit return */

	/*

	 * Ensure that the write is flushed and the credit return is

	 * scheduled. We care more about the 0 -> 1 transition.

 set back to 0 for next time */

 allow all in-flight packets to drain on the context */

 drop all packets on the context, no waiting until they are sent */

/*

 * Start the software reaction to a context halt or SPC freeze:

 *	- mark the context as halted or frozen

 *	- stop buffer allocations

 *

 * Called from the error interrupt.  Other work is deferred until

 * out of the interrupt.

 stop buffer allocations */

 mark the context */

/*

 * The send context buffer "allocator".

 *

 * @sc: the PIO send context we are allocating from

 * @len: length of whole packet - including PBC - in dwords

 * @cb: optional callback to call when the buffer is finished sending

 * @arg: argument for cb

 *

 * Return a pointer to a PIO buffer, NULL if not enough room, -ECOMM

 * when link is down.

 not enough room */

 already tried to get more room */

 copy from receiver cache line and recalculate */

 still no room, actively update */

 there is enough room */

 read this once */

 "allocate" the buffer */

	/*

	 * Fill the parts that the releaser looks at before moving the head.

	 * The only necessary piece is the sent_at field.  The credits

	 * we have just allocated cannot have been returned yet, so the

	 * cb and arg will not be looked at for a "while".  Put them

	 * on this side of the memory barrier anyway.

 could be filled in at sc->sr init time */

 make sure this is in memory before updating the head */

 calculate next head index, do not store */

	/*

	 * update the head - must be last! - the releaser can look at fields

	 * in pbuf once we move the head

 finish filling in the buffer outside the lock */

/*

 * There are at least two entities that can turn on credit return

 * interrupts and they can overlap.  Avoid problems by implementing

 * a count scheme that is enforced by a lock.  The lock is needed because

 * the count and CSR write must be paired.

/*

 * Start credit return interrupts.  This is managed by a count.  If already

 * on, just increment the count.

 lock must surround both the count change and the CSR update */

/*

 * Stop credit return interrupts.  This is managed by a count.  Decrement the

 * count, if the last user, then turn the credit interrupts off.

 lock must surround both the count change and the CSR update */

/*

 * The caller must be careful when calling this.  All needint calls

 * must be paired with !needint.

/**

 * sc_piobufavail - callback when a PIO buffer is available

 * @sc: the send context

 *

 * This is called from the interrupt handler when a PIO buffer is

 * available after hfi1_verbs_send() returned an error that no buffers were

 * available. Disable the interrupt if there are no more QPs waiting.

	/*

	 * Note: checking that the piowait list is empty and clearing

	 * the buffer available interrupt needs to be atomic or we

	 * could end up with QPs on the wait list with the interrupt

	 * disabled.

 refcount held until actual wake up */

	/*

	 * If there had been waiters and there are more

	 * insure that we redo the force to avoid a potential hang.

 Wake up the top-priority one first */

 translate a send credit update to a bit code of reasons */

 use the jiffies compare to get the wrap right */

 a < b */

/*

 * The send context buffer "releaser".

 update free */

 volatile read */

 call sent buffer callbacks */

 code not yet set */

 snapshot the head */

 not sent yet */

 fill in code on first user */

 make sure tail is updated before free */

/*

 * Send context group releaser.  Argument is the send context that caused

 * the interrupt.  Called from the send context interrupt handler.

 *

 * Call release on all contexts in the group.

 *

 * This routine takes the sc_lock without an irqsave because it is only

 * called from an interrupt handler.  Adjust if that changes.

/*

 * pio_select_send_context_vl() - select send context

 * @dd: devdata

 * @selector: a spreading factor

 * @vl: this vl

 *

 * This function returns a send context based on the selector and a vl.

 * The mapping fields are protected by RCU

	/*

	 * NOTE This should only happen if SC->VL changed after the initial

	 * checks on the QP/AH

	 * Default will return VL0's send context below

/*

 * pio_select_send_context_sc() - select send context

 * @dd: devdata

 * @selector: a spreading factor

 * @sc5: the 5 bit sc

 *

 * This function returns an send context based on the selector and an sc

/*

 * Free the indicated map struct

/*

 * Handle RCU callback

/*

 * Set credit return threshold for the kernel send context

/*

 * pio_map_init - called when #vls change

 * @dd: hfi1_devdata

 * @port: port number

 * @num_vls: number of vls

 * @vl_scontexts: per vl send context mapping (optional)

 *

 * This routine changes the mapping based on the number of vls.

 *

 * vl_scontexts is used to specify a non-uniform vl/send context

 * loading. NULL implies auto computing the loading and giving each

 * VL an uniform distribution of send contexts per VL.

 *

 * The auto algorithm computers the sc_per_vl and the number of extra

 * send contexts. Any extra send contexts are added from the last VL

 * on down

 *

 * rcu locking is used here to control access to the mapping fields.

 *

 * If either the num_vls or num_send_contexts are non-power of 2, the

 * array sizes in the struct pio_vl_map and the struct pio_map_elem are

 * rounded up to the next highest power of 2 and the first entry is

 * reused in a round robin fashion.

 *

 * If an error occurs the map change is not done and the mapping is not

 * chaged.

 *

 truncate divide */

 extras */

 add extras from last vl down */

 build new map */

 save for wrap around */

 only allocate once */

			/*

			 * assign send contexts and

			 * adjust credit return threshold

 wrap back to first send context */

 just re-use entry without allocating */

 newmap in hand, save old map */

 publish newmap */

 success, free any old map after grace period */

 free any partial allocation */

 Free PIO map if allocated */

 VLs 0-7, 15 */

 VLs 0-7 */

		/*

		 * Since this function does not deal with a specific

		 * receive context but we need the RcvHdrQ entry size,

		 * use the size from rcd[0]. It is guaranteed to be

		 * valid at this point and will remain the same for all

		 * receive contexts.

 non VL15 start with the max MTU */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2020 Cornelis Networks, Inc.

 * Copyright(c) 2015-2018 Intel Corporation.

/*

 * Initialize context and file private data needed for Expected

 * receive caching. This needs to be done after the context has

 * been configured with the eager/expected RcvEntry counts.

	/*

	 * PSM does not have a good way to separate, count, and

	 * effectively enforce a limit on RcvArray entries used by

	 * subctxts (when context sharing is used) when TID caching

	 * is enabled. To help with that, we calculate a per-process

	 * RcvArray entry share and enforce that.

	 * If TID caching is not in use, PSM deals with usage on its

	 * own. In that case, we allow any subctxt to take all of the

	 * entries.

	 *

	 * Make sure that we set the tid counts only after successful

	 * init.

/*

 * Release pinned receive buffer pages.

 *

 * @mapped: true if the pages have been DMA mapped. false otherwise.

 * @idx: Index of the first page to unpin.

 * @npages: No of pages to unpin.

 *

 * If the pages have been DMA mapped (indicated by mapped parameter), their

 * info will be passed via a struct tid_rb_node. If they haven't been mapped,

 * their info will be passed via a struct tid_user_buf.

/*

 * Pin receive buffer pages.

 Get the number of pages the user buffer spans */

 Allocate the array of struct page pointers needed for pinning */

	/*

	 * Pin all the pages of the user buffer. If we can't pin all the

	 * pages, accept the amount pinned so far and program only that.

	 * User space knows how to deal with partially programmed buffers.

/*

 * RcvArray entry allocation for Expected Receives is done by the

 * following algorithm:

 *

 * The context keeps 3 lists of groups of RcvArray entries:

 *   1. List of empty groups - tid_group_list

 *      This list is created during user context creation and

 *      contains elements which describe sets (of 8) of empty

 *      RcvArray entries.

 *   2. List of partially used groups - tid_used_list

 *      This list contains sets of RcvArray entries which are

 *      not completely used up. Another mapping request could

 *      use some of all of the remaining entries.

 *   3. List of full groups - tid_full_list

 *      This is the list where sets that are completely used

 *      up go.

 *

 * An attempt to optimize the usage of RcvArray entries is

 * made by finding all sets of physically contiguous pages in a

 * user's buffer.

 * These physically contiguous sets are further split into

 * sizes supported by the receive engine of the HFI. The

 * resulting sets of pages are stored in struct tid_pageset,

 * which describes the sets as:

 *    * .count - number of pages in this set

 *    * .idx - starting index into struct page ** array

 *                    of this set

 *

 * From this point on, the algorithm deals with the page sets

 * described above. The number of pagesets is divided by the

 * RcvArray group size to produce the number of full groups

 * needed.

 *

 * Groups from the 3 lists are manipulated using the following

 * rules:

 *   1. For each set of 8 pagesets, a complete group from

 *      tid_group_list is taken, programmed, and moved to

 *      the tid_full_list list.

 *   2. For all remaining pagesets:

 *      2.1 If the tid_used_list is empty and the tid_group_list

 *          is empty, stop processing pageset and return only

 *          what has been programmed up to this point.

 *      2.2 If the tid_used_list is empty and the tid_group_list

 *          is not empty, move a group from tid_group_list to

 *          tid_used_list.

 *      2.3 For each group is tid_used_group, program as much as

 *          can fit into the group. If the group becomes fully

 *          used, move it to tid_full_list.

 Find sets of physically contiguous pages */

	/*

	 * We don't need to access this under a lock since tid_used is per

	 * process and the same process cannot be in hfi1_user_exp_rcv_clear()

	 * and hfi1_user_exp_rcv_setup() at the same time.

	/*

	 * From this point on, we are going to be using shared (between master

	 * and subcontexts) context resources. We need to take the lock.

	/*

	 * The first step is to program the RcvArray entries which are complete

	 * groups.

		/*

		 * If there was a failure to program the RcvArray

		 * entries for the entire group, reset the grp fields

		 * and add the grp back to the free group list.

		/*

		 * If we don't have any partially used tid groups, check

		 * if we have empty groups. If so, take one from there and

		 * put in the partially used list.

		/*

		 * There is an optimization opportunity here - instead of

		 * fitting as many page sets as we can, check for a group

		 * later on in the list that could fit all of them.

 Check if we are done so we break out early */

				/*

				 * If ret is 0, we did not program any entries

				 * into this group, which can only happen if

				 * we've screwed up the accounting somewhere.

				 * Warn and try to continue.

			/*

			 * On failure to copy to the user level, we need to undo

			 * everything done so far so we don't leak resources.

	/*

	 * If not everything was mapped (due to insufficient RcvArray entries,

	 * for example), unpin all unmapped pages so we can pin them nex time.

	/*

	 * copy_to_user() can sleep, which will leave the invalid_lock

	 * locked and cause the MMU notifier to be blocked on the lock

	 * for a long time.

	 * Copy the data to a local buffer so we can release the lock.

		/*

		 * Reset the user flag while still holding the lock.

		 * Otherwise, PSM can miss events.

	/*

	 * Look for sets of physically contiguous pages in the user buffer.

	 * This will allow us to optimize Expected RcvArray entry usage by

	 * using the bigger supported sizes.

		/*

		 * If the pfn's are not sequential, pages are not physically

		 * contiguous.

			/*

			 * At this point we have to loop over the set of

			 * physically contiguous pages and break them down it

			 * sizes supported by the HW.

			 * There are two main constraints:

			 *     1. The max buffer size is MAX_EXPECTED_BUFFER.

			 *        If the total set size is bigger than that

			 *        program only a MAX_EXPECTED_BUFFER chunk.

			 *     2. The buffer size has to be a power of two. If

			 *        it is not, round down to the closes power of

			 *        2 and program that size.

/**

 * program_rcvarray() - program an RcvArray group with receive buffers

 * @fd: filedata pointer

 * @tbuf: pointer to struct tid_user_buf that has the user buffer starting

 *	  virtual address, buffer length, page pointers, pagesets (array of

 *	  struct tid_pageset holding information on physically contiguous

 *	  chunks from the user buffer), and other fields.

 * @grp: RcvArray group

 * @start: starting index into sets array

 * @count: number of struct tid_pageset's to program

 * @tidlist: the array of u32 elements when the information about the

 *           programmed RcvArray entries is to be encoded.

 * @tididx: starting offset into tidlist

 * @pmapped: (output parameter) number of pages programmed into the RcvArray

 *           entries.

 *

 * This function will program up to 'count' number of RcvArray entries from the

 * group 'grp'. To make best use of write-combining writes, the function will

 * perform writes to the unused RcvArray entries which will be ignored by the

 * HW. Each RcvArray entry will be programmed with a physically contiguous

 * buffer chunk from the user's virtual buffer.

 *

 * Return:

 * -EINVAL if the requested count is larger than the size of the group,

 * -ENOMEM or -EFAULT on error from set_rcvarray_entry(), or

 * number of RcvArray entries programmed.

 Count should never be larger than the group size */

 Find the first unused entry in the group */

		/*

		 * If this entry in the group is used, move to the next one.

		 * If we go past the end of the group, exit the loop.

 Fill the rest of the group with "blank" writes */

	/*

	 * Allocate the node first so we can handle a potential

	 * failure before we've programmed anything.

		/*

		 * FIXME: This is in the wrong order, the notifier should be

		 * established before the pages are pinned by pin_rcv_pages.

	/*

	 * Make sure device has seen the write before we unpin the

	 * pages.

/*

 * As a simple helper for hfi1_user_exp_rcv_free, this function deals with

 * clearing nodes in the non-cached case.

			/*

			 * hfi1_set_uevent_bits() sets a user event flag

			 * for all processes. Because calling into the

			 * driver to process TID cache invalidations is

			 * expensive and TID cache invalidations are

			 * handled on a per-process basis, we can

			 * optimize this to set the flag only for the

			 * process in question.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2017 - 2020 Intel Corporation.

/*

 * This file contains HFI1 support for VNIC functionality

 hfi1_vnic_update_stats - update statistics */

 add tx counters on different queues */

 add rx counters on different queues */

 update_len_counters - update pkt's len histogram counters */

 account for 4 byte FCS */

 hfi1_vnic_update_tx_counters - update transmit counters */

 rest of the counts are for good packets only */

 hfi1_vnic_update_rx_counters - update receive counters */

 rest of the counts are for good packets only */

 This function is overloaded for opa_vnic specific implementation */

 hfi1_vnic_maybe_stop_tx - stop tx queue if required */

 take out meta data */

 add tail padding (for 8 bytes size alignment) and icrc */

	/*

	 * pkt_len is how much data we have to write, includes header and data.

	 * total_len is length of the packet in Dwords plus the PBC should not

	 * include the CRC.

 PBC + packet */

 remove the header before updating tx counters */

 update tx counters */

 hfi1_vnic_decap_skb - strip OPA header from the skb (ethernet) packet */

 Validate Packet length */

		/*

		 * In case of invalid vesw id, count the error on

		 * the first available vport.

 update rx counters */

 ensure virtual eth switch id is valid */

	/*

	 * If vesw_id is being changed, and if the vnic port is up,

	 * reset the vnic port to ensure new vesw_id gets picked up

 netdev ops */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015-2018 Intel Corporation.

 wrappers to enforce srcu in seq file */

 nothing allocated */

 stop calls rcu_read_unlock */

 read the per-device counters */

 read the per-device counters */

/*

 * Could use file_inode(file)->i_ino to figure out which file,

 * instead of separate routine for each, but for now, this works...

 read the per-port names (same for each port) */

 read the per-port counters */

 check permanent flag */

 check each dynamic flag on each HFI */

 zero terminate and read the expected integer */

 obtain exclusive access */

 force write to be visible to other HFI on another OS */

 return the number of bytes written */

 read the dc8051 memory */

 the checks below expect the position to be positive */

	/*

	 * Fill in the requested portion of the temporary buffer from the

	 * 8051 memory.  The 8051 memory read is done in terms of 8 bytes.

	 * Adjust start and end to fit.  Skip reading anything if out of

	 * range.

 round down */

 round up */

 only read 8 byte quantities */

 offset must be 8-byte aligned */

 do nothing if out of range or zero count */

 reduce count if needed */

 failed */

 only write 8 byte quantities */

 offset must be 8-byte aligned */

 do nothing if out of range or zero count */

 reduce count if needed */

 failed */

/*

 * read the per-port QSFP data for ppd

 Do an i2c write operation on the chain for the given HFI. */

 byte offset format: [offsetSize][i2cAddr][offsetHigh][offsetLow] */

 explicitly reject invalid address 0 to catch cp and cat */

 Do an i2c write operation on chain for HFI 0. */

 Do an i2c write operation on chain for HFI 1. */

 Do an i2c read operation on the chain for the given HFI. */

 byte offset format: [offsetSize][i2cAddr][offsetHigh][offsetLow] */

 explicitly reject invalid address 0 to catch cp and cat */

 Do an i2c read operation on chain for HFI 0. */

 Do an i2c read operation on chain for HFI 1. */

 Do a QSFP write operation on the i2c chain for the given HFI. */

 base page + page00-page03 */

 Do a QSFP write operation on i2c chain for HFI 0. */

 Do a QSFP write operation on i2c chain for HFI 1. */

 Do a QSFP read operation on the i2c chain for the given HFI. */

 base page + page00-page03 */

 Do a QSFP read operation on i2c chain for HFI 0. */

 Do a QSFP read operation on i2c chain for HFI 1. */

 nothing allocated */

 dev counter files */

 per port files */

/*

 * driver stats field names, one line per stat, single string.  Used by

 * programs like hfistats to print the stats in a way which works for

 * different versions of drivers, without changing program source.

 * if hfi1_ib_stats changes, this needs to change.  Names need to be

 * 12 chars or less (w/o newline), for proper display by hfistats utility.

 must be element 0*/

 special case for interrupts */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2019 Intel Corporation.

 We support only two types - 9B and 16B for now */

/**

 * ud_loopback - handle send on loopback QPs

 * @sqp: the sending QP

 * @swqe: the send work request

 *

 * This is called from hfi1_make_ud_req() to forward a WQE addressed

 * to the same HFI.

 * Note that the receive interrupt handler may be calling hfi1_ud_rcv()

 * while this is being called.

	/*

	 * Check that the qkey matches (except for QP0, see 9.6.1.4.1).

	 * Qkeys with the high order bit set mean use the

	 * qkey from the QP context instead of the WR (see 10.2.5).

 silently drop per IBTA spec */

	/*

	 * A GRH is expected to precede the data even if not

	 * present on the wire.

	/*

	 * Get the next work request entry to find where to put the data.

 Silently drop packets which are too big. */

		/*

		 * For loopback packets with extended LIDs, the

		 * sgid_index in the GRH is 0 and the dgid is

		 * OPA GID of the sender. While creating a response

		 * to the loopback packet, IB core creates the new

		 * sgid_index from the DGID and that will be the

		 * OPA_GID_INDEX. The new dgid is from the sgid

		 * index and that will be in the IB GID format.

		 *

		 * We now have a case where the sent packet had a

		 * different sgid_index and dgid compared to the

		 * one that was received in response.

		 *

		 * Fix this inconsistency.

 Check for loopback when the port lid is not set */

 Signal completion event if the solicited bit is set. */

	/*

	 * Qkeys with the high order bit set mean use the

	 * qkey from the QP context instead of the WR (see 10.2.5).

 header size in dwords LRH+BTH+DETH = (8+12+8)/4. */

 Set VL (see ch. 13.5.3.1) */

 Setup the packet */

	/*

	 * Build 16B Management Packet if either the destination

	 * or source queue pair number is 0 or 1.

 header size in dwords 16B LRH+L4_FM = (16+8)/4. */

 header size in dwords 16B LRH+BTH+DETH = (16+12+8)/4. */

 SW provides space for CRC and LT for bypass packets. */

		/*

		 * Ensure OPA GIDs are transformed to IB gids

		 * before creating the GRH.

 Convert dwords to flits */

 Setup the packet */

/**

 * hfi1_make_ud_req - construct a UD request packet

 * @qp: the QP

 * @ps: the current packet state

 *

 * Assume s_lock is held.

 *

 * Return 1 if constructed; otherwise, return 0.

 We are in the error state, flush the work request. */

 If DMAs are in progress, we can't flush immediately. */

 see post_one_send() */

 Construct the header. */

			/*

			 * If DMAs are in progress, we can't generate

			 * a completion for the loopback packet since

			 * it would be out of order.

			 * Instead of waiting, we could queue a

			 * zero length descriptor so we get a callback.

 Make the appropriate header */

 disarm any ahg */

/*

 * Hardware can't check this so we do it here.

 *

 * This is a slightly different algorithm than the standard pkey check.  It

 * special cases the management keys and allows for 0x7fff and 0xffff to be in

 * the table at the same time.

 *

 * @returns the index found or -1 if not found

 here we look for an exact match */

 did not find 0xffff return 0x7fff idx if found */

 no match...  */

 remove limited/full membership bit */

	/*

	 * Should not get here, this means hardware failed to validate pkeys.

 Populate length */

 BIT 16 to 19 is TVER. Bit 20 to 22 is pad cnt */

 PSN 0 */

 Convert dwords to flits */

 PBC */ + hwords + nwords;

 PSN 0 */

 PBC */ + hwords;

/*

 * opa_smp_check() - Do the regular pkey checking, and the additional

 * checks for SMPs specified in OPAv1 rev 1.0, 9/19/2016 update, section

 * 9.10.25 ("SMA Packet Checks").

 *

 * Note that:

 *   - Checks are done using the pkey directly from the packet's BTH,

 *     and specifically _not_ the pkey that we attach to the completion,

 *     which may be different.

 *   - These checks are specifically for "non-local" SMPs (i.e., SMPs

 *     which originated on another node). SMPs which are sent from, and

 *     destined to this node are checked in opa_local_smp_check().

 *

 * At the point where opa_smp_check() is called, we know:

 *   - destination QP is QP0

 *

 * opa_smp_check() returns 0 if all checks succeed, 1 otherwise.

	/*

	 * I don't think it's possible for us to get here with sc != 0xf,

	 * but check it to be certain.

	/*

	 * At this point we know (and so don't need to check again) that

	 * the pkey is either LIM_MGMT_P_KEY, or FULL_MGMT_P_KEY

	 * (see ingress_pkey_check).

	/*

	 * SMPs fall into one of four (disjoint) categories:

	 * SMA request, SMA response, SMA trap, or SMA trap repress.

	 * Our response depends, in part, on which type of SMP we're

	 * processing.

	 *

	 * If this is an SMA response, skip the check here.

	 *

	 * If this is an SMA request or SMA trap repress:

	 *   - pkey != FULL_MGMT_P_KEY =>

	 *       increment port recv constraint errors, drop MAD

	 *

	 * Otherwise:

	 *    - accept if the port is running an SM

	 *    - drop MAD if it's an SMA trap

	 *    - pkey == FULL_MGMT_P_KEY =>

	 *        reply with unsupported method

	 *    - pkey != FULL_MGMT_P_KEY =>

	 *	  increment port recv constraint errors, drop MAD

/**

 * hfi1_ud_rcv - receive an incoming UD packet

 * @packet: the packet structure

 *

 * This is called from qp_rcv() to process an incoming UD packet

 * for the given QP.

 * Called at interrupt level.

	/*

	 * Get the number of bytes the message was padded by

	 * and drop incomplete packets.

	/*

	 * Check that the permissive LID is only used on QP0

	 * and the QKEY matches (see 9.6.1.4.1 and 9.6.1.5.1).

				/*

				 * Traps will not be sent for packets dropped

				 * by the HW. This is fine, as sending trap

				 * for invalid pkeys is optional according to

				 * IB spec (release 1.3, section 10.9.4)

 GSI packet */

 Silent drop */

 Drop invalid MAD packets (see 13.5.3.1). */

 Received on QP0, and so by definition, this is an SMP */

 look up SMI pkey */

	/*

	 * A GRH is expected to precede the data even if not

	 * present on the wire.

	/*

	 * Get the next work request entry to find where to put the data.

 Silently drop packets which are too big. */

		/*

		 * Assuming we only created 16B on the send side

		 * if we want to use large LIDs, since GRH was stripped

		 * out when creating 16B, add back the GRH here.

	/*

	 * Save the LMC lower bits if the destination LID is a unicast LID.

 Signal completion event if the solicited bit is set. */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2020 Intel Corporation.

 * Copyright(c) 2021 Cornelis Networks.

/*

 * min buffers we want to have per context, after driver

 4KB */

 256KB */

/*

 * Number of user receive contexts we are configured to use (to allow for more

 * pio buffers per ctxt, etc.)  Zero means use one user context per CPU.

 computed based on above array */

 8MB */

 2x the max eager buffer count */

 default is 33% */

 Control context has to be always 0 */

	/*

	 * Set up the kernel context flags here and now because they use

	 * default values for all receive side memories.  User contexts will

	 * be handled as they are created.

 Control context must use DMA_RTAIL */

/*

 * Create the receive context array and one or more kernel contexts

 All the contexts should be freed, free the array */

/*

 * Helper routines for the receive context reference count (rcd and uctxt).

/**

 * hfi1_rcd_free - When reference is zero clean up.

 * @kref: pointer to an initialized rcd data structure

 *

/**

 * hfi1_rcd_put - decrement reference for rcd

 * @rcd: pointer to an initialized rcd data structure

 *

 * Use this to put a reference after the init.

/**

 * hfi1_rcd_get - increment reference for rcd

 * @rcd: pointer to an initialized rcd data structure

 *

 * Use this to get a reference after the init.

 *

 * Return : reflect kref_get_unless_zero(), which returns non-zero on

 * increment, otherwise 0.

/**

 * allocate_rcd_index - allocate an rcd index from the rcd array

 * @dd: pointer to a valid devdata structure

 * @rcd: rcd data structure to assign

 * @index: pointer to index that is allocated

 *

 * Find an empty index in the rcd array, and assign the given rcd to it.

 * If the array is full, we are EBUSY.

 *

/**

 * hfi1_rcd_get_by_index_safe - validate the ctxt index before accessing the

 * array

 * @dd: pointer to a valid devdata structure

 * @ctxt: the index of an possilbe rcd

 *

 * This is a wrapper for hfi1_rcd_get_by_index() to validate that the given

 * ctxt index is valid.

 *

 * The caller is responsible for making the _put().

 *

/**

 * hfi1_rcd_get_by_index - get by index

 * @dd: pointer to a valid devdata structure

 * @ctxt: the index of an possilbe rcd

 *

 * We need to protect access to the rcd array.  If access is needed to

 * one or more index, get the protecting spinlock and then increment the

 * kref.

 *

 * The caller is responsible for making the _put().

 *

/*

 * Common code for user and kernel context create and setup.

 * NOTE: the initial kref is done here (hf1_rcd_init()).

		/*

		 * Calculate the context's RcvArray entry starting point.

		 * We do this here because we have to take into account all

		 * the RcvArray entries that previous context would have

		 * taken and we have to account for any extra groups assigned

		 * to the static (kernel) or dynamic (vnic/user) contexts.

		/*

		 * Simple Eager buffer allocation: we have already pre-allocated

		 * the number of RcvArray entry groups. Each ctxtdata structure

		 * holds the number of groups for that context.

		 *

		 * To follow CSR requirements and maintain cacheline alignment,

		 * make sure all sizes and bases are multiples of group_size.

		 *

		 * The expected entry count is what is left after assigning

		 * eager.

		/*

		 * Allocate array that will hold the eager buffer accounting

		 * data.

		 * This will allocate the maximum possible buffer count based

		 * on the value of the RcvArray split parameter.

		 * The resulting value will be rounded down to the closest

		 * multiple of dd->rcv_entries.group_size.

		/*

		 * The size of the buffers programmed into the RcvArray

		 * entries needs to be big enough to handle the highest

		 * MTU supported.

 Applicable only for statically created kernel contexts */

 Initialize TID flow generations for the context */

/**

 * hfi1_free_ctxt - free context

 * @rcd: pointer to an initialized rcd data structure

 *

 * This wrapper is the free function that matches hfi1_create_ctxtdata().

 * When a context is done being used (kernel or user), this function is called

 * for the "final" put to match the kref init from hf1i_create_ctxtdata().

 * Other users of the context do a get/put sequence to make sure that the

 * structure isn't removed while in use.

/*

 * Select the largest ccti value over all SLs to determine the intra-

 * packet gap for the link.

 *

 * called with cca_timer_lock held (to protect access to cca_timer

 * array), and rcu_read_lock() (to protect access to cc_state).

 Mbits /sec */

	/*

	 * max_pkt_time is the maximum packet egress time in units

	 * of the fabric clock period 1/(805 MHz).

		/*

		 * This should _never_ happen - rcu_read_lock() is held,

		 * and set_link_ipg() should not be called if cc_state

		 * is NULL.

	/*

	 * 1) decrement ccti for SL

	 * 2) calculate IPG for link (set_link_ipg())

	 * 3) restart timer, unless ccti is at min value

 ccti_timer is in units of 1.024 usec */

/*

 * Common code for initializing the physical port structure.

 IB port number, not index */

	/*

	 * There are C_VL_COUNT number of PortVLXmitWait counters.

	 * Adding 1 to C_VL_COUNT to include the PortXmitWait counter.

/*

 * Do initialization for device that is only needed on

 * first detect, not on resets.

/**

 * init_after_reset - re-initialize after a reset

 * @dd: the hfi1_ib device

 *

 * sanity check at least some of the values after reset, and

 * ensure no receive or transmit (explicitly, in case reset

 * failed

	/*

	 * Ensure chip does no sends or receives, tail updates, or

	 * pioavail updates while we re-initialize.  This is mostly

	 * for the driver data structures, not chip registers.

 enable PIO send */

	/*

	 * Enable kernel ctxts' receive and receive interrupt.

	 * Other ctxts done as user opens and initializes them.

/**

 * create_workqueues - create per port workqueues

 * @dd: the hfi1_ib device

			/*

			 * Make the link workqueue single-threaded to enforce

			 * serialization.

 max_active */

/**

 * destroy_workqueues - destroy per port workqueues

 * @dd: the hfi1_ib device

/**

 * enable_general_intr() - Enable the IRQs that will be handled by the

 * general interrupt handler.

 * @dd: valid devdata

 *

/**

 * hfi1_init - do the actual initialization sequence on the chip

 * @dd: the hfi1_ib device

 * @reinit: re-initializing, so don't allocate new memory

 *

 * Do the actual initialization sequence on the chip.  This is done

 * both from the init routine called from the PCI infrastructure, and

 * when we reset the chip, or detect that it was reset internally,

 * or it's administratively re-enabled.

 *

 * Memory allocation here and in called routines is only done in

 * the first case (reinit == 0).  We have to be careful, because even

 * without memory allocation, we need to re-write all the chip registers

 * TIDs, etc. after the reset or enable has completed.

 Set up send low level handlers */

 make sure the link is not "up" */

 allocate dummy tail memory for all receive contexts */

 dd->rcd can be NULL if early initialization failed */

		/*

		 * Set up the (kernel) rcvhdr queue and egr TIDs.  If doing

		 * re-init, the simplest way to handle this is to free

		 * existing, and re-allocate.

		 * Need to re-create rest of ctxt 0 ctxtdata as well.

 enable IRQ */

 Allocate enough memory for user event notification. */

	/*

	 * Allocate a page for device and port status.

	 * Page will be shared amongst all user processes.

 Currently, we only have one port */

 enable chip even if we have an error, so we can debug cause */

	/*

	 * Set status even if port serdes is not initialized

	 * so that diags will work.

 enable all interrupts from the chip */

 chip is OK for user apps; mark it as initialized */

			/*

			 * start the serdes - must be after interrupts are

			 * enabled so we are notified when the link goes up

			/*

			 * Set status even if port serdes is not initialized

			 * so that diags will work.

 if ret is non-zero, we probably should do some cleanup here... */

/*

 * Stop the timers during unit shutdown, or after an error late

 * in initialization.

/**

 * shutdown_device - shut down a device

 * @dd: the hfi1_ib device

 *

 * This is called to make the device quiet when we are about to

 * unload the driver, and also when the device is administratively

 * disabled.   It does not free any data structures.

 * Everything it does has to be setup again by hfi1_init(dd, 1)

 mask and clean up interrupts */

		/*

		 * Gracefully stop all sends allowing any in progress to

		 * trickle out first.

	/*

	 * Enough for anything that's going to trickle out to have actually

	 * done so.

 disable all contexts */

 disable the send device */

		/*

		 * Clear SerdesEnable.

		 * We can't count on interrupts since we are stopping.

/**

 * hfi1_free_ctxtdata - free a context's allocated data

 * @dd: the hfi1_ib device

 * @rcd: the ctxtdata structure

 *

 * free up any allocated data for a context

 * It should never change any chip state, or global driver state.

 all the RcvArray entries should have been cleared by now */

/*

 * Release our hold on the shared asic data.  If we are the last one,

 * return the structure to be finalized outside the lock.  Must be

 * holding hfi1_dev_table lock.

 return NULL if the other dd still has a link */

/**

 * hfi1_free_devdata - cleans up and frees per-unit data structure

 * @dd: pointer to a valid devdata structure

 *

 * It cleans up and frees all data structures set up by

 * by hfi1_alloc_devdata().

 wait for rcu callbacks to complete */

/**

 * hfi1_alloc_devdata - Allocate our primary per-unit data structure.

 * @pdev: Valid PCI device

 * @extra: How many bytes to alloc past the default

 *

 * Must be done via verbs allocator, because the verbs cleanup process

 * both does cleanup and free of the data structure.

 * "extra" is for chip-specific data.

 extra is * number of ports */

	/*

	 * If the BIOS does not have the NUMA node information set, select

	 * NUMA 0 so we get consistent performance.

	/*

	 * Initialize all locks for the device. This needs to be as early as

	 * possible so locks are usable.

/*

 * Called from freeze mode handlers, and from PCI error

 * reporting code.  Should be paranoid about state of

 * system and data structures.

	/*

	 * Mark as having had an error for driver, and also

	 * for /sys and status word mapped to user programs.

	 * This marks unit as not usable, until reset.

/*

 * Do all the generic driver unit- and chip-independent memory

 * allocation and initialization.

 validate max MTU before any devices start */

 valid CUs run from 1-128 in powers of 2 */

 valid credit return threshold is 0-100, variable is unsigned */

	/*

	 * sanitize receive interrupt count, time must wait until after

	 * the hardware type is known

 reject invalid combinations */

		/*

		 * Avoid indefinite packet delivery by requiring a timeout

		 * if count is > 1.

		/*

		 * The dynamic algorithm expects a non-zero timeout

		 * and a count > 1.

 sanitize link CRC options */

	/*

	 * These must be called before the driver is registered with

	 * the PCI subsystem.

 all OK */

/*

 * Do the non-unit driver cleanup, memory free, etc. at unload.

 asymmetric with obtain_firmware() */

 this can only be called after a successful initialization */

 users can't do anything more with chip */

	/*

	 * Free any resources still in use (usually just kernel contexts)

	 * at unload; we do for ctxtcnt, because that's what we allocate.

 must follow rcv context free - need to remove rcv's hooks */

/*

 * Clean up on unit shutdown, or error during unit load after

 * successful initialization.

 First, lock the non-writable module parameters */

 Validate dev ids */

 Allocate the dd so we can get to work */

 Validate some global module parameters */

 use the encoding function as a sanitization check */

	/* The receive eager buffer size must be set before the receive

	 * contexts are created.

	 *

	 * Set the eager buffer size.  Validate that it falls in a range

	 * allowed by the hardware - all powers of 2 between the min and

	 * max.  The maximum valid MTU is within the eager buffer range

	 * so we do not need to cap the max_mtu by an eager buffer size

	 * setting.

 restrict value of hfi1_rcvarr_split */

	/*

	 * Do device-specific initialization, function table setup, dd

	 * allocation, etc.

 error already printed */

 do the generic initialization */

	/*

	 * Now ready for use.  this should be cleared whenever we

	 * detect a reset, or initiate one.  If earlier failure,

	 * we still create devices, so diags, etc. can be used

	 * to determine cause of problem.

 create debufs files after init and ib register */

 everything already cleaned */

	/*

	 * Remove the device init value and complete the device if there is

	 * no clients or wait for active clients to finish.

 close debugfs files before ib unregister */

 remove the /dev hfi1 interface */

 wait for existing user space clients to finish */

 unregister from IB core */

 free netdev data */

	/*

	 * Disable the IB link, disable interrupts on the device,

	 * clear dma engines, etc.

 wait until all of our (qsfp) queue_work() calls complete */

/**

 * hfi1_create_rcvhdrq - create a receive header queue

 * @dd: the hfi1_ib device

 * @rcd: the context data

 *

 * This must be contiguous memory (from an i/o perspective), and must be

 * DMA'able (which means for some systems, it will go through an IOMMU,

 * or be forced into a low address range).

/**

 * hfi1_setup_eagerbufs - llocate eager buffers, both kernel and user

 * contexts.

 * @rcd: the context we are setting up.

 *

 * Allocate the eager TID buffers and program them into hip.

 * They are no longer completely contiguous, we do multiple allocation

 * calls.  Otherwise we get the OOM code involved, by asking for too

 * much per call, with disastrous results on some kernels.

	/*

	 * GFP_USER, but without GFP_FS, so buffer cache can be

	 * coalesced (we hope); otherwise, even at order 4,

	 * heavy filesystem activity makes these fail, and we can

	 * use compound pages.

	/*

	 * The minimum size of the eager buffers is a groups of MTU-sized

	 * buffers.

	 * The global eager_buffer_size parameter is checked against the

	 * theoretical lower limit of the value. Here, we check against the

	 * MTU.

	/*

	 * If using one-pkt-per-egr-buffer, lower the eager buffer

	 * size to the max MTU (page-aligned).

	/*

	 * Eager buffers sizes of 1MB or less require smaller TID sizes

	 * to satisfy the "multiple of 8 RcvArray entries" requirement.

			/*

			 * Fail the eager buffer allocation if:

			 *   - we are already using the lowest acceptable size

			 *   - we are using one-pkt-per-egr-buffer (this implies

			 *     that we are accepting only one size)

			/*

			 * If the first attempt to allocate memory failed, don't

			 * fail everything but continue with the next lower

			 * size.

			/*

			 * Re-partition already allocated buffers to a smaller

			 * size.

	/*

	 * Set the contexts rcv array head update threshold to the closest

	 * power of 2 (so we can use a mask instead of modulo) below half

	 * the allocated entries.

	/*

	 * Compute the expected RcvArray entry base. This is done after

	 * allocating the eager buffers in order to maximize the

	 * expected RcvArray entries for the context.

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2020 Intel Corporation.

 *

	/*

	 * For smaller(4k + skb overhead) allocations we will go using

	 * napi cache. Otherwise we will try to use napi frag cache.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2020 Intel Corporation.

 Name of IRQ types, indexed by enum irq_type */

 Per NUMA node count of HFI devices */

 Increment generation of CPU set if needed */

		/*

		 * We've used up all the CPUs, bump up the generation

		 * and reset the 'used' map

 Get the first CPU from the list of unused CPUs in a CPU set data structure */

 Find out CPUs left in CPU mask */

 empty */

 Initialize non-HT cpu cores mask */

 Start with cpu online mask as the real cpu mask */

	/*

	 * Remove HT cores from the real cpu mask.  Do this in two steps below.

	/*

	 * Step 1.  Skip over the first N HT siblings and use them as the

	 * "real" cores.  Assumes that HT cores are not enumerated in

	 * succession (except in the single core case).

	/*

	 * Step 2.  Remove the remaining HT siblings.  Use cpumask_next() to

	 * skip any gaps.

	/*

	 * The real cpu mask is part of the affinity struct but it has to be

	 * initialized early. It is needed to calculate the number of user

	 * contexts in set_up_context_variables().

	/*

	 * Invalid PCI NUMA node information found, note it, and populate

	 * our database 1:1.

/*

 * It appends an entry to the list.

 * It *must* be called with node_affinity.lock held.

 It must be called with node_affinity.lock held */

/*

 * Non-interrupt CPUs are used first, then interrupt CPUs.

 * Two already allocated cpu masks must be passed.

 Available CPUs for pinning completion vectors */

 Available CPUs without SDMA engine interrupts */

 If there are non-interrupt CPUs available, use them first */

 Otherwise, use interrupt CPUs */

 empty */

 _dev_comp_vect_mappings_destroy() is reentrant */

/*

 * This function creates the table for looking up CPUs for completion vectors.

 * num_comp_vectors needs to have been initilized before calling this function.

/*

 * It assumes dd->comp_vect_possible_cpus is available.

	/*

	 * If there's only one CPU available for completion vectors, then

	 * there will only be one completion vector available. Othewise,

	 * the number of completion vector available will be the number of

	 * available CPUs divide it by the number of devices in the

	 * local NUMA node.

		/*

		 * If the completion vector CPUs available doesn't divide

		 * evenly among devices, then the first device device to be

		 * initialized gets an extra CPU.

 Reserving CPUs for device completion vector */

/*

 * It assumes dd->comp_vect_possible_cpus is available.

 Clearing CPU in device completion vector cpu mask */

/*

 * Interrupt affinity.

 *

 * non-rcv avail gets a default mask that

 * starts as possible cpus with threads reset

 * and each rcv avail reset.

 *

 * rcv avail gets node relative 1 wrapping back

 * to the node relative 1 as necessary.

 *

	/*

	 * If this is the first time this NUMA node's affinity is used,

	 * create an entry in the global affinity structure and initialize it.

 Use the "real" cpu mask of this node as the default */

 fill in the receive list */

 only one CPU, everyone will use it */

			/*

			 * The general/control context will be the first CPU in

			 * the default list, so it is removed from the default

			 * list and added to the general interrupt list.

			/*

			 * Remove the remaining kernel receive queues from

			 * the default list and add them to the receive list.

			/*

			 * If there ends up being 0 CPU cores leftover for SDMA

			 * engines, use the same CPU cores as general/control

			 * context.

 Determine completion vector CPUs for the entire node */

		/*

		 * If there ends up being 0 CPU cores leftover for completion

		 * vectors, use the same CPU core as the general/control

		 * context.

	/*

	 * Free device completion vector CPUs to be used by future

	 * completion vectors

/*

 * Function updates the irq affinity hint for msix after it has been changed

 * by the user using the /proc/irq interface. This function only accepts

 * one cpu in the mask.

	/*

	 * Set the new cpu in the hfi1_affinity_node and clean

	 * the old cpu if it is not used by any other IRQ

 Only one CPU configuration supported currently */

	/*

	 * This is required by affinity notifier. We don't have anything to

	 * free here.

/*

 * Function sets the irq affinity for msix.

 * It *must* be called with node_affinity.lock held.

	/*

	 * The general and control contexts are placed on a particular

	 * CPU, which is set above. Skip accounting for it. Everything else

	 * finds its CPU here.

 Don't do accounting for general contexts */

 Don't do accounting for control contexts */

 This should be called with node_affinity.lock held */

 Removing other siblings not needed for now */

 Identifying correct HW threads within physical cores */

	/*

	 * check whether process/context affinity has already

	 * been set

		/*

		 * Mark the pre-set CPU as used. This is atomic so we don't

		 * need the lock

	/*

	 * The process does not have a preset CPU affinity so find one to

	 * recommend using the following algorithm:

	 *

	 * For each user process that is opening a context on HFI Y:

	 *  a) If all cores are filled, reinitialize the bitmask

	 *  b) Fill real cores first, then HT cores (First set of HT

	 *     cores on all physical cores, then second set of HT core,

	 *     and, so on) in the following order:

	 *

	 *     1. Same NUMA node as HFI Y and not running an IRQ

	 *        handler

	 *     2. Same NUMA node as HFI Y and running an IRQ handler

	 *     3. Different NUMA node to HFI Y and not running an IRQ

	 *        handler

	 *     4. Different NUMA node to HFI Y and running an IRQ

	 *        handler

	 *  c) Mark core as filled in the bitmask. As user processes are

	 *     done, clear cores from the bitmask.

	/*

	 * If we've used all available HW threads, clear the mask and start

	 * overloading.

	/*

	 * If NUMA node has CPUs used by interrupt handlers, include them in the

	 * interrupt handler mask.

	/*

	 * If HT cores are enabled, identify which HW threads within the

	 * physical cores should be used.

			/*

			 * If there's at least one available core for this HW

			 * thread number, stop looking for a core.

			 *

			 * diff will always be not empty at least once in this

			 * loop as the used mask gets reset when

			 * (set->mask == set->used) before this loop.

 Get cpumask of available CPUs on preferred NUMA */

	/*

	 * At first, we don't want to place processes on the same

	 * CPUs as interrupt handlers. Then, CPUs running interrupt

	 * handlers are used.

	 *

	 * 1) If diff is not empty, then there are CPUs not running

	 *    non-interrupt handlers available, so diff gets copied

	 *    over to available_mask.

	 * 2) If diff is empty, then all CPUs not running interrupt

	 *    handlers are taken, so available_mask contains all

	 *    available CPUs running interrupt handlers.

	 * 3) If available_mask is empty, then all CPUs on the

	 *    preferred NUMA node are taken, so other NUMA nodes are

	 *    used for process assignments using the same method as

	 *    the preferred NUMA node.

 If we don't have CPUs on the preferred node, use other NUMA nodes */

 Excluding preferred NUMA cores */

		/*

		 * At first, we don't want to place processes on the same

		 * CPUs as interrupt handlers.

 empty */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2020 Cornelis Networks, Inc.

 * Copyright(c) 2015-2020 Intel Corporation.

 msecs */

/*

 * File operation functions

/*

 * Types of memories mapped into user processes' space

/*

 * Masks and offsets defining the mmap tokens

 The real work is performed later in assign_ctxt() */

 no cpu affinity by default */

 chip pio base */

 64K PIO space / ctxt */

 sop? */

		/*

		 * Map only the amount allocated to the context, not the

		 * entire available context's PIO space.

		/*

		 * The credit return location for this context could be on the

		 * second or third page allocated for credit returns (if number

		 * of enabled contexts > 64 and 128 respectively).

		/*

		 * The driver has already allocated memory for credit

		 * returns and programmed it into the chip. Has that

		 * memory been flagged as non-cached?

 vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot); */

		/*

		 * The RcvEgr buffer need to be handled differently

		 * as multiple non-contiguous pages need to be mapped

		 * into the user process.

				/*

				 * virt_to_pfn() does the same, but

				 * it's not available on x86_64

				 * when CONFIG_MMU is enabled.

		/*

		 * Map only the page that contains this context's user

		 * registers.

		/*

		 * TidFlow table is on the same page as the rest of the

		 * user registers.

		/*

		 * Use the page where this context's flags are. User level

		 * knows where it's own bitmap is within the page.

		/*

		 * v3.7 removes VM_RESERVED but the effect is kept by

		 * using VM_IO.

			/*

			 * If the memory allocation failed, the context alloc

			 * also would have failed, so we would never get here

/*

 * Local (non-chip) user memory is not mapped right away but as it is

 * accessed by the user-level code.

 invalid */

 drain user sdma queue */

 release the cpu */

 clean up rcv side */

	/*

	 * fdata->uctxt is used in the above cleanup.  It is not ready to be

	 * removed until here.

	/*

	 * Clear any left over, unhandled events so the next process that

	 * gets this context doesn't get confused.

	/*

	 * Disable receive context and interrupt available, reset all

	 * RcvCtxtCtrl bits to default values.

 Clear the context's J_KEY */

	/*

	 * If a send context is allocated, reset context integrity

	 * checks to default and disable the send context.

/*

 * Convert kernel *virtual* addresses to physical addresses.

 * This is used to vmalloc'ed addresses.

/**

 * complete_subctxt - complete sub-context info

 * @fd: valid filedata pointer

 *

 * Sub-context info can only be set up after the base context

 * has been completed.  This is indicated by the clearing of the

 * HFI1_CTXT_BASE_UINIT bit.

 *

 * Wait for the bit to be cleared, and then complete the subcontext

 * initialization.

 *

	/*

	 * sub-context info can only be set up after the base context

	 * has been completed.

 Finish the sub-context init */

	/*

	 * Acquire the mutex to protect against multiple creations of what

	 * could be a shared base context.

	/*

	 * Get a sub context if available  (fd->uctxt will be set).

	 * ret < 0 error, 0 no context, 1 sub-context found

	/*

	 * Allocate a base context if context sharing is not required or a

	 * sub context wasn't found.

 Depending on the context type, finish the appropriate init */

/**

 * match_ctxt - match context

 * @fd: valid filedata pointer

 * @uinfo: user info to compare base context with

 * @uctxt: context to compare uinfo to.

 *

 * Compare the given context with the given information to see if it

 * can be used for a sub context.

 Skip dynamically allocated kernel contexts */

 Skip ctxt if it doesn't match the requested one */

 Verify the sharing process matches the base */

 Find an unused sub context */

 context is being closed, do not use */

/**

 * find_sub_ctxt - fund sub-context

 * @fd: valid filedata pointer

 * @uinfo: matching info to use to find a possible context to share.

 *

 * The hfi1_mutex must be held when this function is called.  It is

 * necessary to ensure serialized creation of shared contexts.

 *

 * Return:

 *    0      No sub-context found

 *    1      Subcontext found and allocated

 *    errno  EINVAL (incorrect parameters)

 *           EBUSY (all sub contexts in use)

 value of != 0 will return */

		/*

		 * Pick an error that is unique from all other errors

		 * that are returned so the user process knows that

		 * it tried to allocate while the SPC was frozen.  It

		 * it should be able to retry with success in a short

		 * while.

	/*

	 * If we don't have a NUMA node requested, preference is towards

	 * device NUMA node.

	/*

	 * Allocate and enable a PIO send context.

	/*

	 * Setup sub context information if the user-level has requested

	 * sub contexts.

	 * This has to be done here so the rest of the sub-contexts find the

	 * proper base context.

	 * NOTE: _set_bit() can be used here because the context creation is

	 * protected by the mutex (rather than the spin_lock), and will be the

	 * very first instance of this context.

 save current flag state */

	/*

	 * Disable ASPM when there are open user/PSM contexts to avoid

	 * issues with ASPM L1 exit latency

 We can take the size of the RcvHdr Queue from the master */

 initialize poll variables... */

	/*

	 * Now enable the ctxt for receive.

	 * For chips that are set to DMA the tail register to memory

	 * when they change (and when the update bit transitions from

	 * 0 to 1.  So for those chips, we turn it off and then back on.

	 * This will (very briefly) affect any other open ctxts, but the

	 * duration is very short, and therefore isn't an issue.  We

	 * explicitly set the in-memory tail copy to 0 beforehand, so we

	 * don't have to wait to be sure the DMA update has happened

	 * (chip resets head/tail to 0 on transition to enable).

 Setup J_KEY before enabling the context */

	/*

	 * Ignore the bit in the flags for now until proper

	 * support for multiple packet per rcv array entry is

	 * added.

	/*

	 * The RcvCtxtCtrl.TailUpd bit has to be explicitly written.

	 * We can't rely on the correct value to be set from prior

	 * uses of the chip or ctxt. Therefore, add the rcvctrl op

	 * for both cases.

 adjust flag if this fd is not able to cache */

 no caching */

 Now allocate the RcvHdr queue and eager buffers. */

 If sub-contexts are enabled, do the appropriate setup */

 Now that the context is set up, the fd can get a reference. */

		/*

		 * On error, set the failed bit so sub-contexts will clean up

		 * correctly.

		/*

		 * Base context is done (successfully or not), notify anybody

		 * using a sub-context that is waiting for this completion.

	/*

	 * If more than 64 contexts are enabled the allocated credit

	 * return will span two or three contiguous pages. Since we only

	 * map the page containing the context's credit return address,

	 * we need to calculate the offset in the proper page.

	/*

	 * user regs are at

	 * (RXE_PER_CONTEXT_USER + (ctxt * RXE_PER_CONTEXT_SIZE))

/**

 * user_exp_rcv_setup - Set up the given tid rcv list

 * @fd: file data of the current driver instance

 * @arg: ioctl argumnent for user space information

 * @len: length of data structure associated with ioctl command

 *

 * Wrapper to validate ioctl information before doing _rcv_setup.

 *

		/*

		 * Copy the number of tidlist entries we used

		 * and the length of the buffer we registered.

/**

 * user_exp_rcv_clear - Clear the given tid rcv list

 * @fd: file data of the current driver instance

 * @arg: ioctl argumnent for user space information

 * @len: length of data structure associated with ioctl command

 *

 * The hfi1_user_exp_rcv_clear() can be called from the error path.  Because

 * of this, we need to use this wrapper to copy the user space information

 * before doing the clear.

/**

 * user_exp_rcv_invalid - Invalidate the given tid rcv list

 * @fd: file data of the current driver instance

 * @arg: ioctl argumnent for user space information

 * @len: length of data structure associated with ioctl command

 *

 * Wrapper to validate ioctl information before doing _rcv_invalid.

 *

/*

 * Find all user contexts in use, and set the specified bit in their

 * event mask.

 * See also find_ctxt() for a similar use, that is specific to send buffers.

			/*

			 * subctxt_cnt is 0 if not shared, so do base

			 * separately, first, then remaining subctxt, if any

/**

 * manage_rcvq - manage a context's receive queue

 * @uctxt: the context

 * @subctxt: the sub-context

 * @arg: start/stop action to carry out

 *

 * start_stop == 0 disables receive on the context, for use in queue

 * overflow conditions.  start_stop==1 re-enables, to be used to

 * re-init the software copy of the head register

 atomically clear receive enable ctxt. */

		/*

		 * On enable, force in-memory copy of the tail register to

		 * 0, so that protocol code doesn't have to worry about

		 * whether or not the chip has yet updated the in-memory

		 * copy or not on return from the system call. The chip

		 * always resets it's tail register back to 0 on a

		 * transition from disabled to enabled.

 always; new head should be equal to new tail; see above */

/*

 * clear the event notifier events for this context.

 * User process then performs actions appropriate to bit having been

 * set, if desired, and checks again in future.

/**

 * ctxt_reset - Reset the user context

 * @uctxt: valid user context

	/*

	 * There is no protection here. User level has to guarantee that

	 * no one will be writing to the send context while it is being

	 * re-initialized.  If user level breaks that guarantee, it will

	 * break it's own context and no one else's.

	/*

	 * Wait until the interrupt handler has marked the context as

	 * halted or frozen. Report error if we time out.

	/*

	 * If the send context was halted due to a Freeze, wait until the

	 * device has been "unfrozen" before resetting the context.

			/*

			 * Don't allow context reset if we are into

			 * forced freeze

/*

 * Create per-unit files in /dev

/*

 * Remove per-unit files in /dev

 * void, core kernel returns no errors for this stuff

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015, 2016 Intel Corporation.

 in microseconds */

/*

 * Our neighbor has indicated that we are allowed to act as a fabric

 * manager, so place the full management partition key in the second

 * (0-based) pkey array position. Note that we should already have

 * the limited management partition key in array element 1, and also

 * that the port is not yet up when add_full_mgmt_pkey() is invoked.

 Sanity check - ppd->pkeys[2] should be 0, or already initialized */

/**

 * format_hwmsg - format a single hwerror message

 * @msg: message buffer

 * @msgl: length of message buffer

 * @hwmsg: message to add to message buffer

/**

 * hfi1_format_hwerrors - format hardware error messages for display

 * @hwerrs: hardware errors bit vector

 * @hwerrmsgs: hardware error descriptions

 * @nhwerrmsgs: number of hwerrmsgs

 * @msg: message buffer

 * @msgl: message buffer length

	/*

	 * Only call ib_dispatch_event() if the IB device has been

	 * registered.  HFI1_INITED is set iff the driver has successfully

	 * registered with the IB core.

/**

 * handle_linkup_change - finish linkup/down state changes

 * @dd: valid device

 * @linkup: link state information

 *

 * Handle a linkup or link down notification.

 * The HW needs time to finish its link up state change. Give it that chance.

 *

 * This is called outside an interrupt.

 *

 no change, nothing to do */

		/*

		 * Quick linkup and all link up on the simulator does not

		 * trigger or implement:

		 *	- VerifyCap interrupt

		 *	- VerifyCap frames

		 * But rather moves directly to LinkUp.

		 *

		 * Do the work of the VerifyCap interrupt handler,

		 * handle_verify_cap(), but do not try moving the state to

		 * LinkUp as we are already there.

		 *

		 * NOTE: This uses this device's vAU, vCU, and vl15_init for

		 * the remote values.  Both sides must be using the values.

 HW needs LINK_UP_DELAY to settle, give it that chance */

		/*

		 * 'MgmtAllowed' information, which is exchanged during

		 * LNI, is available at this point.

 physical link went up */

 link widths are not available until the link is fully up */

 physical link went down */

 clear HW details of the previous connection */

 freeze after a link down to guarantee a clean egress */

 if we are down, the neighbor is down */

 notify IB of the link change */

/*

 * Handle receive or urgent interrupts for user contexts.  This means a user

 * process was waiting for a packet to arrive, and didn't want to poll.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2020 Intel Corporation.

 Length of buffer to create verbs txreq cache name */

/*

 * Translate ib_wr_opcode into ib_wc_opcode.

/*

 * Length of header by opcode, 0 --> not supported

 RC */

 UC */

 UD */

 RC */

 TID RDMA has separate handlers for different opcodes.*/

 UC */

 UD */

 CNP */

 RC */

 UC */

/*

 * System image GUID.

/*

 * Make sure the QP is ready and able to accept the given opcode.

		/*

		 * In order to drop non-IB traffic we

		 * set PbcInsertHrc to NONE (0x2).

		 * The packet will still be delivered

		 * to the receiving node but a

		 * KHdrHCRCErr (KDETH packet with a bad

		 * HCRC) will be triggered and the

		 * packet will not be delivered to the

		 * correct context.

		/*

		 * In order to drop regular verbs

		 * traffic we set the PbcTestEbp

		 * flag. The packet will still be

		 * delivered to the receiving node but

		 * a 'late ebp error' will be

		 * triggered and will be dropped.

 DW == LRH (2) + BTH (3) + KDETH (9) + CRC (1) */

 verbs_qp can be picked up from any tid_rdma header struct */

 DW == LRH (2) + BTH (3) + KDETH (9) + CRC (1) */

 verbs_qp can be picked up from any tid_rdma header struct */

 Pkey check needed only for bypass packets */

 Perform pkey check */

		/*

		 * Notify rvt_multicast_detach() if it is waiting for us

		 * to finish.

 Get the destination QP number. */

/**

 * hfi1_ib_rcv - process an incoming packet

 * @packet: data packet information

 *

 * This is called to process an incoming packet at interrupt level.

/*

 * This is called from a timer to check for QPs

 * which need kernel memory in order to send a packet.

 refcount held until actual wake up */

/*

 * This is called with progress side lock held.

 New API */

/*

 * This routine calls txadds for each sg entry.

 *

 * Add failures will revert the sge cursor

 unwind cursor */

/**

 * update_tx_opstats - record stats by opcode

 * @qp: the qp

 * @ps: transmit packet state

 * @plen: the plen in dwords

 *

 * This is a routine to record the tx opstats after a

 * packet has been presented to the egress mechanism.

/*

 * Build the number of DMA descriptors needed to send length bytes of data.

 *

 * NOTE: DMA mapping is held in the tx until completed in the ring or

 *       the tx desc is freed without having been submitted to the ring

 *

 * This routine ensures all the helper routine calls succeed.

 New API */

		/*

		 * hdrbytes accounts for PBC. Need to subtract 8 bytes

		 * before calculating padding.

 add the ulp payload - if any. tx->ss can be NULL for acks */

 add icrc, lt byte, and padding to flit */

 No vl15 here */

 set PBC_DC_INFO bit (aka SC[4]) in pbc */

 Update HCRC based on packet opcode */

 The current one got "sent" */

 free txreq - bad state */

/*

 * If we are now in the error state, return zero to flush the

 * send work request.

	/*

	 * Note that as soon as want_buffer() is called and

	 * possibly before it returns, sc_piobufavail()

	 * could be called. Therefore, put QP on the I/O wait list before

	 * enabling the PIO avail interrupt.

 counting: only call wantpiobuf_intr if first user */

 only RC/UC use complete */

 vl15 special case taken care of in ud.c */

 set PBC_DC_INFO bit (aka SC[4]) in pbc */

 Update HCRC based on packet opcode */

			/*

			 * If we have filled the PIO buffers to capacity and are

			 * not in an active state this request is not going to

			 * go out to so just complete it with an error or else a

			 * ULP or the core may be stuck waiting.

			/*

			 * This is a normal occurrence. The PIO buffs are full

			 * up but we are still happily sending, well we could be

			 * so lets continue to queue the request.

 txreq not queued - free */

 tx consumed in wait */

 add icrc, lt byte, and padding to flit */

/*

 * egress_pkey_matches_entry - return 1 if the pkey matches ent (ent

 * being an entry from the partition key table), return 0

 * otherwise. Use the matching criteria for egress partition keys

 * specified in the OPAv1 spec., section 9.1l.7.

		/*

		 * If pkey[15] is set (full partition member),

		 * is bit 15 in the corresponding table element

		 * clear (limited member)?

/**

 * egress_pkey_check - check P_KEY of a packet

 * @ppd:  Physical IB port data

 * @slid: SLID for packet

 * @pkey: PKEY for header

 * @sc5:  SC for packet

 * @s_pkey_index: It will be used for look up optimization for kernel contexts

 * only. If it is negative value, then it means user contexts is calling this

 * function.

 *

 * It checks if hdr's pkey is valid.

 *

 * Return: 0 on success, otherwise, 1

 If SC15, pkey[0:14] must be 0x7fff */

 Is the pkey = 0x0, or 0x8000? */

	/*

	 * For the kernel contexts only, if a qp is passed into the function,

	 * the most likely matching pkey has index qp->s_pkey_index

	/*

	 * For the user-context mechanism, the P_KEY check would only happen

	 * once per SDMA request, not once per packet.  Therefore, there's no

	 * need to increment the counter for the user-context mechanism.

/*

 * get_send_routine - choose an egress routine

 *

 * Choose an egress routine based on QP type

 * and size

/**

 * hfi1_verbs_send - send a packet

 * @qp: the QP to send on

 * @ps: the state of the packet to send

 *

 * Return zero if packet is sent or queued OK.

 * Return non-zero and clear qp->s_flags RVT_S_BUSY otherwise.

 locate the pkey within the headers */

		/*

		 * The value we are returning here does not get propagated to

		 * the verbs caller. Thus we need to complete the request with

		 * error otherwise the caller could be sitting waiting on the

		 * completion event. Only do this for PIO. SDMA has its own

		 * mechanism for handling the errors. So for SDMA we can just

		 * return.

/**

 * hfi1_fill_device_attr - Fill in rvt dev info device attributes.

 * @dd: the device data structure

/*

 * Convert a single OPA link width (no multiple flags) to an IB value.

 * A zero OPA link width means link down, which means the IB width value

 * is a don't care.

 map 2x and 3x to 1x as they don't exist in IB */

 link down or unknown, return our largest width */

 props being zeroed by the caller, avoid zeroing it here */

 OPA logical states match IB logical states */

 see rate_show() in ib core/sysfs.c */

	/* Once we are a "first class" citizen and have added the OPA MTUs to

	 * the core we can advertise the larger MTU enum to the ULPs, for now

	 * advertise only 4K.

	 *

	 * Those applications which are either OPA aware or pass the MTU enum

	 * from the Path Records to us will get the new 8k MTU.  Those that

	 * attempt to process the MTU enum may fail in various ways.

/*

 * convert ah port,sl to sc

 test the mapping for validity */

	/*

	 * Do not trust reading anything from rvt_ah at this point as it is not

	 * done being setup. We can however modify things which we need to set.

/**

 * hfi1_get_npkeys - return the size of the PKEY table for context 0

 * @dd: the hfi1_ib device

 Set the prefix to the default value (see ch. 4.1.1) */

	/*

	 * Below should only set bits defined in OPA PortInfo.CapabilityMask

	 * and PortInfo.CapabilityMask3

 must be element 0*/

 protects the *_cntr_names bufers */

/*

 * Convert a list of names separated by '\n' into an array of NULL terminated

 * strings. Optionally some entries can be reserved in the array to hold extra

 * external strings.

 keep process mad in the driver */

/**

 * hfi1_register_ib_device - register our device with the infiniband core

 * @dd: the device data structure

 * Return 0 if successful, errno if unsuccessful.

 Only need to initialize non-zero fields. */

 Use first-port GUID as node guid */

	/*

	 * The system image GUID is supposed to be the same for all

	 * HFIs in a single system but since there can be other

	 * device types in the system, we can't be sure this is unique.

	/*

	 * Fill in rvt info object.

	/*

	 * Fill in rvt info device attributes.

 queue pair */

 completeion queue */

 misc settings */

 Let rdmavt handle it all */

 post send table */

 opcode translation table */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2017 Intel Corporation.

/*

 * Make it easy to toggle firmware file name and if it gets loaded by

 * editing the following. This may be something we do while in development

 * but not necessarily something a user would ever need to use.

 Firmware file names get set in hfi1_firmware_init() based on the above */

/*

 * Firmware security header.

 BCD yyyymmdd */

 in DWORDs */

 in DWORDs */

 in DWORDs */

 in DWORDs */

 expected field values */

 size of platform configuration partition */

 size of file of plaform configuration encoded in format version 4 */

 the file itself */

 augmented file size difference */

 Linux core piece */

 pointer to binary data */

 length in bytes */

 pointer to the modulus */

 pointer to the exponent */

 pointer to the signature */

 pointer to r2 */

 pointer to mu */

/*

 * The mutex protects fw_state, fw_err, and all of the firmware_details

 * variables.

 flags for turn_off_spicos() */

 security block commands */

 security block status */

 RSA engine timeout, in ms */

 ms */

 hardware mutex timeout, in ms */

 ms */

 8051 memory access timeout, in us */

 us */

 the number of fabric SerDes on the SBus */

 ASIC_STS_SBUS_RESULT.RESULT_CODE value */

 SBus fabric SerDes addresses, one set per HFI */

 SBus PCIe SerDes addresses, one set per HFI */

 SBus PCIe PCS addresses, one set per HFI */

 SBus fabric SerDes broadcast addresses, one per HFI */

 SBus PCIe SerDes broadcast addresses, one per HFI */

 forwards */

/*

 * Read a single 64-bit value from 8051 data memory.

 *

 * Expects:

 * o caller to have already set up data read, no auto increment

 * o caller to turn off read enable when finished

 *

 * The address argument is a byte offset.  Bits 0:2 in the address are

 * ignored - i.e. the hardware will always do aligned 8-byte reads as if

 * the lower bits are zero.

 *

 * Return 0 on success, -ENXIO on a read error (timeout).

 step 1: set the address, clear enable */

 step 2: enable */

 wait until ACCESS_COMPLETED is set */

 gather the data */

/*

 * Read 8051 data starting at addr, for len bytes.  Will read in 8-byte chunks.

 * Return 0 on success, -errno on error.

 data read set-up, no auto-increment */

 turn off read enable */

/*

 * Write data or code to the 8051 code or data RAM.

 check alignment */

 write set-up */

 write */

 wait until ACCESS_COMPLETED is set */

 turn off write access, auto increment (also sets to data access) */

 return 0 if values match, non-zero and complain otherwise */

/*

 * Verify that the static fields in the CSS header match.

 verify CSS header fields (most sizes are in DW, so add /4) */

/*

 * Make sure there are at least some bytes after the prefix.

 make sure we have some payload */

/*

 * Request the firmware from the system.  Extract the pieces and fill in

 * fdet.  If successful, the caller will need to call dispose_one_firmware().

 * Returns 0 on success, -ERRNO on error.

 verify the firmware */

	/*

	 * If the file does not have a valid CSS header, fail.

	 * Otherwise, check the CSS size field for an expected size.

	 * The augmented file has r2 and mu inserted after the header

	 * was generated, so there will be a known difference between

	 * the CSS header size and the actual file size.  Use this

	 * difference to identify an augmented file.

	 *

	 * Note: css->size is in DWORDs, multiply by 4 to get bytes.

 non-augmented firmware file */

 make sure there are bytes in the payload */

 use dummy space */

 use dummy space */

			/*

			 * Header does not include r2 and mu - generate here.

			 * For now, fail.

 augmented firmware file */

 make sure there are bytes in the payload */

 css->size check failed */

 if returning an error, clean up after ourselves */

 erase all previous information */

/*

 * Obtain the 4 firmwares from the OS.  All must be obtained at once or not

 * at all.  If called with the firmware state in FW_TRY, use alternate names.

 * On exit, this routine will have set the firmware state to one of FW_TRY,

 * FW_FINAL, or FW_ERR.

 *

 * Must be holding fw_mutex.

 nothing more to obtain */

 already in error */

 fw_state is FW_EMPTY or FW_TRY */

		/*

		 * We tried the original and it failed.  Move to the

		 * alternate.

		/*

		 * Let others run.  Some systems, when missing firmware, does

		 * something that holds for 30 seconds.  If we do that twice

		 * in a row it triggers task blocked warning.

		/*

		 * Add a delay before obtaining and loading debug firmware.

		 * Authorization will fail if the delay between firmware

		 * authorization events is shorter than 50us. Add 100us to

		 * make a delay time safe.

 oops, had problems obtaining a firmware */

 retry with alternate (RTL only) */

 success */

 may retry later */

 cannot try again */

/*

 * Called by all HFIs when loading their firmware - i.e. device probe time.

 * The first one will do the actual firmware load.  Use a mutex to resolve

 * any possible race condition.

 *

 * The call to this routine cannot be moved to driver load because the kernel

 * call request_firmware() requires a device which is only available after

 * the first device probe.

 40s delay due to long delay on missing firmware on some systems */

		/*

		 * Another device is trying the firmware.  Wait until it

		 * decides what works (or not).

 waited too long */

 arbitrary delay */

 not in FW_TRY state */

 set fw_state to FW_TRY, FW_FINAL, or FW_ERR, and fw_err */

/*

 * Called when the driver unloads.  The timing is asymmetric with its

 * counterpart, obtain_firmware().  If called at device remove time,

 * then it is conceivable that another device could probe while the

 * firmware is being disposed.  The mutexes can be moved to do that

 * safely, but then the firmware would be requested from the OS multiple

 * times.

 *

 * No mutex is needed as the driver is unloading and there cannot be any

 * other callers.

 retain the error state, otherwise revert to empty */

/*

 * Called with the result of a firmware download.

 *

 * Return 1 to retry loading the firmware, 0 to stop.

		/*

		 * The load succeeded, so expect all others to do the same.

		 * Do not retry again.

 do NOT retry */

 load failed, obtain alternate firmware */

 else in FW_FINAL or FW_ERR, no retry in either case */

/*

 * Write a block of data to a given array CSR.  All calls will be in

 * multiples of 8 bytes.

 aligned */

 not aligned */

/*

 * Write a block of data to a given CSR as a stream of writes.  All calls will

 * be in multiples of 8 bytes.

/*

 * Download the signature and start the RSA mechanism.  Wait for

 * RSA_ENGINE_TIMEOUT before giving up.

 write the signature */

 initialize RSA */

	/*

	 * Make sure the engine is idle and insert a delay between the two

	 * writes to MISC_CFG_RSA_CMD.

 start RSA */

	/*

	 * Look for the result.

	 *

	 * The RSA engine is hooked up to two MISC errors.  The driver

	 * masks these errors as they do not respond to the standard

	 * error "clear down" mechanism.  Look for these errors here and

	 * clear them when possible.  This routine will exit with the

	 * errors of the current run still set.

	 *

	 * MISC_FW_AUTH_FAILED_ERR

	 *	Firmware authorization failed.  This can be cleared by

	 *	re-initializing the RSA engine, then clearing the status bit.

	 *	Do not re-init the RSA angine immediately after a successful

	 *	run - this will reset the current authorization.

	 *

	 * MISC_KEY_MISMATCH_ERR

	 *	Key does not match.  The only way to clear this is to load

	 *	a matching key then clear the status bit.  If this error

	 *	is raised, it will persist outside of this routine until a

	 *	matching key is loaded.

 should not happen */

 finished successfully */

 finished unsuccessfully */

 else still active */

			/*

			 * Timed out while active.  We can't reset the engine

			 * if it is stuck active, but run through the

			 * error code to see what error bits are set.

	/*

	 * Arrive here on success or failure.  Clear all RSA engine

	 * errors.  All current errors will stick - the RSA logic is keeping

	 * error high.  All previous errors will clear - the RSA logic

	 * is not keeping the error high.

	/*

	 * All that is left are the current errors.  Print warnings on

	 * authorization failure details, if any.  Firmware authorization

	 * can be retried, so these are only warnings.

 Security variables a.  Write the modulus */

 Security variables b.  Write the r2 */

 Security variables c.  Write the mu */

 Security variables d.  Write the header */

 return the 8051 firmware state */

/*

 * Wait until the firmware is up and ready to take host requests.

 * Return 0 on success, -ETIMEDOUT on timeout.

 in the simulator, the fake 8051 is always ready */

 ready */

 timed out */

 sleep 2ms-ish */

/*

 * Load the 8051 firmware.

	/*

	 * DC Reset sequence

	 * Load DC 8051 firmware

	/*

	 * DC reset step 1: Reset DC8051

	/*

	 * DC reset step 2 (optional): Load 8051 data memory with link

	 * configuration

	/*

	 * DC reset step 3: Load DC8051 firmware

 release all but the core reset */

 Firmware load step 1 */

	/*

	 * Firmware load step 2.  Clear MISC_CFG_FW_CTRL.FW_8051_LOADED

 Firmware load steps 3-5 */

code*/, 0, fdet->firmware_ptr,

	/*

	 * DC reset step 4. Host starts the DC8051 firmware

	/*

	 * Firmware load step 6.  Set MISC_CFG_FW_CTRL.FW_8051_LOADED

 Firmware load steps 7-10 */

 clear all reset bits, releasing the 8051 */

	/*

	 * DC reset step 5. Wait for firmware to be ready to accept host

	 * requests.

 timed out */

/*

 * Write the SBus request register

 *

 * No need for masking - the arguments are sized exactly.

/*

 * Read a value from the SBus.

 *

 * Requires the caller to be in fast mode

 arbitrary */

/*

 * Turn off the SBus and fabric serdes spicos.

 *

 * + Must be called with Sbus fast mode turned on.

 * + Must be called after fabric serdes broadcast is set up.

 * + Must be called before the 8051 is loaded - assumes 8051 is not loaded

 *   when using MISC_CFG_FW_CTRL.

 only needed on A0 */

 disable SBus spico */

 disable the fabric serdes spicos */

/*

 * Reset all of the fabric serdes for this HFI in preparation to take the

 * link to Polling.

 *

 * To do a reset, we need to write to to the serdes registers.  Unfortunately,

 * the fabric serdes download to the other HFI on the ASIC will have turned

 * off the firmware validation on this HFI.  This means we can't write to the

 * registers to reset the serdes.  Work around this by performing a complete

 * re-download and validation of the fabric serdes firmware.  This, as a

 * by-product, will reset the serdes.  NOTE: the re-download requires that

 * the 8051 be in the Offline state.  I.e. not actively trying to use the

 * serdes.  This routine is called at the point where the link is Offline and

 * is getting ready to go to Polling.

 A0 serdes do not work with a re-download */

 place SerDes in reset and disable SPICO */

 wait 100 refclk cycles @ 156.25MHz => 640ns */

 remove SerDes reset */

 turn SPICO enable on */

		/*

		 * No need for firmware retry - what to download has already

		 * been decided.

		 * No need to pay attention to the load return - the only

		 * failure is a validation failure, which has already been

		 * checked by the initial download.

 Access to the SBus in this routine should probably be serialized */

 make sure fast mode is clear */

 Wait for both DONE and RCV_DATA_VALID to go high */

			/*

			 * If the loop has timed out, we are OK if DONE bit

			 * is set and RCV_DATA_VALID and EXECUTE counters

			 * are the same. If not, we cannot proceed.

 Wait for DONE to clear after EXECUTE is cleared */

 receiver addr */

 step 1: load security variables */

 step 2: place SerDes in reset and disable SPICO */

 wait 100 refclk cycles @ 156.25MHz => 640ns */

 step 3:  remove SerDes reset */

 step 4: assert IMEM override */

 step 5: download SerDes machine code */

 step 6: IMEM override off */

 step 7: turn ECC on */

 steps 8-11: run the RSA engine */

 step 12: turn SPICO enable on */

 step 13: enable core hardware interrupts */

 receiver address */

 step 1: load security variables */

 step 2: place SPICO into reset and enable off */

 step 3: remove reset, enable off, IMEM_CNTRL_EN on */

 step 4: set starting IMEM address for burst download */

 step 5: download the SBus Master machine code */

 step 6: set IMEM_CNTL_EN off */

 step 7: turn ECC on */

 steps 8-11: run the RSA engine */

 step 12: set SPICO_ENABLE on */

 receiver address */

 step 1: load security variables */

 step 2: assert single step (halts the SBus Master spico) */

 step 3: enable XDMEM access */

 step 4: load firmware into SBus Master XDMEM */

	/*

	 * NOTE: the dmem address, write_en, and wdata are all pre-packed,

	 * we only need to pick up the bytes and write them

 step 5: disable XDMEM access */

 step 6: allow SBus Spico to run */

	/*

	 * steps 7-11: run RSA, if it succeeds, firmware is available to

	 * be swapped

/*

 * Set the given broadcast values on the given list of devices.

		/*

		 * Set BROADCAST_GROUP_1 and BROADCAST_GROUP_2, leave

		 * defaults for everything else.  Do not read-modify-write,

		 * per instruction from the manufacturer.

		 *

		 * Register 0xfd:

		 *	bits    what

		 *	-----	---------------------------------

		 *	  0	IGNORE_BROADCAST  (default 0)

		 *	11:4	BROADCAST_GROUP_1 (default 0xff)

		 *	23:16	BROADCAST_GROUP_2 (default 0xff)

 success */

 timed out */

 timed out */

 break mutex and retry */

 return the given resource bit(s) as a mask for the given HFI */

/*

 * Acquire access to a chip resource.

 *

 * Return 0 on success, -EBUSY if resource busy, -EIO if mutex acquire failed.

 a dynamic resource is in use if either HFI has set the bit */

 discrete devices must serialize across both chains */

 non-dynamic resources are not split between HFIs */

 lock against other callers within the driver wanting a resource */

 force write to be visible to other HFI on another OS */

/*

 * Acquire access to a chip resource, wait up to mswait milliseconds for

 * the resource to become available.

 *

 * Return 0 on success, -EBUSY if busy (even after wait), -EIO if mutex

 * acquire failed.

 resource is busy, check our timeout */

 arbitrary delay */

/*

 * Release access to a chip resource

 only dynamic resources should ever be cleared */

 lock against other callers within the driver wanting a resource */

 force write to be visible to other HFI on another OS */

/*

 * Return true if resource is set, false otherwise.  Print a warning

 * if not set and a function is supplied.

 lock against other callers within the driver wanting a resource */

 clear all dynamic access bits for this HFI */

 force write to be visible to other HFI on another OS */

 clear any holds left by us */

 clear any holds left by us */

 only RTL can use these */

 no 8051 or QSFP on simulator */

/*

 * This function is a helper function for parse_platform_config(...) and

 * does not check for validity of the platform configuration cache

 * (because we know it is invalid as we are building up the cache).

 * As such, this should not be called from anywhere other than

 * parse_platform_config

 assume failure */

	/*

	 * For integrated devices that did not fall back to the default file,

	 * the SI tuning information for active channels is acquired from the

	 * scratch register bitmap, thus there is no platform config to parse.

	 * Skip parsing in these situations.

 Field is file size in DWORDs */

	/*

	 * Length can't be larger than partition size. Assume platform

	 * config format version 4 is being used. Interpret the file size

	 * field as header instead by not moving the pointer.

 exactly equal, perfection */

	/*

	 * In both cases where we proceed, using the self-reported file length

	 * is the safer option. In case of old format a predefined value is

	 * being used.

 Done with this set of headers */

 data table */

 We don't trust this file now */

 metadata table */

 We don't trust this file now */

 Calculate and check table crc */

 Jump the table */

 Jump the CRC DWORD */

/* This is the central interface to getting data out of the platform config

 * file. It depends on parse_platform_config() having populated the

 * platform_config_cache in hfi1_devdata, and checks the cache_valid member to

 * validate the sanity of the cache.

 *

 * The non-obvious parameters:

 * @table_index: Acts as a look up key into which instance of the tables the

 * relevant field is fetched from.

 *

 * This applies to the data tables that have multiple instances. The port table

 * is an exception to this rule as each HFI only has one port and thus the

 * relevant table can be distinguished by hfi_id.

 *

 * @data: pointer to memory that will be populated with the field requested.

 * @len: length of memory pointed by @data in bytes.

		/*

		 * Use saved configuration from ppd for integrated platforms

 Convert length to bits */

 Our metadata function checked cache_valid and field_index for us */

			/*

			 * We expect the field to be byte aligned and whole byte

			 * lengths if we are here

 Port table is 4 DWORDS */

/*

 * Download the firmware needed for the Gen3 PCIe SerDes.  An update

 * to the SBus firmware is needed before updating the PCIe firmware.

 *

 * Note: caller must be holding the SBus resource.

 both firmware loads below use the SBus */

/*

 * Read the GUID from the hardware, store it in dd.

 Take the DC out of reset to get a valid GUID value */

 read and display firmware version info */

 set fast mode */

 read version for SBus Master */

 wait for interrupt to be processed */

 read version for PCIe SerDes */

 wait for interrupt to be processed */

 read version for fabric SerDes */

 wait for interrupt to be processed */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2018 Intel Corporation.

 1280 = 256 opcodes * 4 chars/opcode + 255 commas + NULL */

 Check the inputs */

 see fault_opcodes_write() */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2018 Intel Corporation.

 cut down ridiculously long IB macro names */

/**

 * hfi1_make_uc_req - construct a request packet (SEND, RDMA write)

 * @qp: a pointer to the QP

 * @ps: the current packet state

 *

 * Assume s_lock is held.

 *

 * Return 1 if constructed; otherwise, return 0.

 We are in the error state, flush the work request. */

 If DMAs are in progress, we can't flush immediately. */

 header size in 32-bit words LRH+BTH = (8+12)/4. */

 header size in 32-bit words 16B LRH+BTH = (16+12)/4. */

 Get the next send request. */

 Check if send work queue is empty. */

		/*

		 * Local operations are processed immediately

		 * after all prior requests have completed.

		/*

		 * Start a new request.

 Immediate data comes after the BTH */

 Immediate data comes after the RETH */

 Immediate data comes after the BTH */

 Immediate data comes after the BTH */

/**

 * hfi1_uc_rcv - handle an incoming UC packet

 * @packet: the packet structure

 *

 * This is called from qp_rcv() to process an incoming UC packet

 * for the given QP.

 * Called at interrupt level.

 Compare the PSN verses the expected PSN. */

		/*

		 * Handle a sequence error.

		 * Silently drop any current message.

 Check for opcode sequence errors. */

 OK, process the packet. */

			/*

			 * qp->s_rdma_read_sge will be the owner

			 * of the mr references.

 Check for invalid length PMTU or posted rwqe len. */

		/*

		 * There will be no padding for 9B packet but 16B packets

		 * will come in with some padding since we always add

		 * CRC and LT bytes which will need to be flit aligned

 Check for invalid length. */

 LAST len should be >= 1 */

 Don't count the CRC. */

		/*

		 * It seems that IB mandates the presence of an SL in a

		 * work completion only for the UD transport (see section

		 * 11.4.2 of IBTA Vol. 1).

		 *

		 * However, the way the SL is chosen below is consistent

		 * with the way that IB/qib works and is trying avoid

		 * introducing incompatibilities.

		 *

		 * See also OPA Vol. 1, section 9.7.6, and table 9-17.

 zero fields that are N/A */

 Signal completion event if the solicited bit is set. */

 consume RWQE */

 Check rkey */

 Check for invalid length PMTU or posted rwqe len. */

 Check for invalid length. */

 LAST len should be >= 1 */

 Don't count the CRC. */

 Check for invalid length. */

 LAST len should be >= 1 */

 Don't count the CRC. */

 Drop packet for unknown opcodes. */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2018 Intel Corporation.

 *

 1 priority == 16 starve_cnt */

/*

 * iowait_init() - initialize wait structure

 * @wait: wait struct to initialize

 * @tx_limit: limit for overflow queuing

 * @func: restart function for workqueue

 * @sleep: sleep function for no space

 * @resume: wakeup function for no space

 *

 * This function initializes the iowait

 * structure embedded in the QP or PQ.

 *

/**

 * iowait_cancel_work - cancel all work in iowait

 * @w: the iowait struct

 Make sure that the iowork for TID RDMA is used */

/**

 * iowait_set_work_flag - set work flag based on leg

 * @w: the iowait work struct

/**

 * iowait_priority_update_top - update the top priority entry

 * @w: the iowait struct

 * @top: a pointer to the top priority entry

 * @idx: the index of the current iowait in an array

 * @top_idx: the array index for the iowait entry that has the top priority

 *

 * This function is called to compare the priority of a given

 * iowait with the given top priority entry. The top index will

 * be returned.

 Convert priority into starve_cnt and compare the total.*/

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015, 2016 Intel Corporation.

 Prevent power on default of all zeroes from passing checksum */

	/*

	 * ASIC scratch 0 only contains the checksum and bitmap version as

	 * fields of interest, both of which are handled separately from the

	 * loop below, so skip it

 success */

	/*

	 * Allocate separate memory block to store data and free firmware

	 * structure. This allows free_platform_config to treat EPROM and

	 * fallback configs in the same manner.

 Release memory allocated for eprom or fallback file read. */

 we expected 1, so consider 0 an error */

 SFF 8679 rev 1.7 LPMode Deassert time */

 RX CDR present, bypass supported */

 Power class <= 3, ignore config & turn RX CDR on */

 Expand cdr setting to all 4 lanes */

 Preserve current TX CDR status */

 TX CDR present, bypass supported */

 Power class <= 3, ignore config & turn TX CDR on */

 Expand cdr setting to all 4 lanes */

 Preserve current/determined RX CDR status */

 Disable adaptive TX EQ if present */

 no point going on w/o a page 3 */

 no point going on w/o a page 3 */

	/*

	 * Verify that preferred RX amplitude is not just a

	 * fall through of the default

/*

 * Return a special SerDes setting for low power AOC cables.  The power class

 * threshold and setting being used were all found by empirical testing.

 *

 * Summary of the logic:

 *

 * if (QSFP and QSFP_TYPE == AOC and QSFP_POWER_CLASS < 4)

 *     return 0xe

 * return 0; // leave at default

 QSFP only */

 leave at default */

 active optical cables only */

 active AOC */

 leave at default */

 Pass tuning method to 8051 */

 Set same channel loss for both TX and RX */

 Inform 8051 of cable capabilities */

 Clear, then set the external device config field */

 Following for limiting active channels only */

	/*

	 * NOTES:

	 * o The aoc_low_power_setting is applied to all lanes even

	 *   though only lane 0's value is examined by the firmware.

	 * o A lingering low power setting after a cable swap does

	 *   not occur.  On cable unplug the 8051 is reset and

	 *   restarted on cable insert.  This resets all settings to

	 *   their default, erasing any previous low power setting.

 Must be holding the QSFP i2c resource */

	/*

	 * We'll change the QSFP memory contents from here on out, thus we set a

	 * flag here to remind ourselves to reset the QSFP module. This prevents

	 * reuse of stale settings established in our previous pass through.

 Fallback to configured attenuation if cable memory is bad */

/*

 * This function communicates its success or failure via ppd->driver_link_ready

 * Thus, it depends on its association with start_link(...) which checks

 * driver_link_ready before proceeding with the link negotiation and

 * initialization process.

 the link defaults to enabled */

 the driver link ready state defaults to not ready */

 Skip the tuning for testing (loopback != none) and simulations */

 platform_atten, remote_atten pre-zeroed to catch error */

			/*

			 * platform_atten, remote_atten pre-zeroed to

			 * catch error

				/*

				 * We may have modified the QSFP memory, so

				 * update the cache to reflect the changes

 a fail indication */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015-2017 Intel Corporation.

/*

 * Start of per-port congestion control structures and support code

/*

 * Congestion control table size followed by table entries

/*

 * Congestion settings: port control, control map and an array of 16

 * entries for the congestion entries - increase, timer, event log

 * trigger threshold and the minimum injection rate delay.

 Start sc2vl */

 End sc2vl */

 Start sl2sc */

 End sl2sc */

 Start vl2mtu */

 end of per-port file structures and support code */

/*

 * Start of per-unit (or driver, in some cases, but replicated

 * per unit) functions (these get a device *)

 The string printed here is already newline-terminated. */

	/*

	 * Return the smaller of send and receive contexts.

	 * Normally, user level applications would require both a send

	 * and a receive context, so returning the smaller of the two counts

	 * give a more accurate picture of total contexts available.

 Return the number of free user ports (contexts) available. */

 dd->serial is already newline terminated in chip.c */

/*

 * Convert the reported temperature from an integer (reported in

 * units of 0.25C) to a floating point number.

/*

 * Dump tempsense values, in decimal, to ease shell-scripts.

/*

 * end of per-unit (or driver, in some cases, but replicated

 * per unit) functions

 start of per-unit file structures and support code */

/*

 * Register and create our files in /sys/class/infiniband.

	/*

	 * The function kobject_put() will call kobject_del() if the kobject

	 * has been added successfully. The sysfs files created under the

	 * kobject directory will also be removed during the process.

/*

 * Unregister and remove our files in /sys/class/infiniband.

 Unwind operations in hfi1_verbs_register_sysfs() */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2018 - 2020 Intel Corporation.

 *

/**

 * DOC: TID RDMA READ protocol

 *

 * This is an end-to-end protocol at the hfi1 level between two nodes that

 * improves performance by avoiding data copy on the requester side. It

 * converts a qualified RDMA READ request into a TID RDMA READ request on

 * the requester side and thereafter handles the request and response

 * differently. To be qualified, the RDMA READ request should meet the

 * following:

 * -- The total data length should be greater than 256K;

 * -- The total data length should be a multiple of 4K page size;

 * -- Each local scatter-gather entry should be 4K page aligned;

 * -- Each local scatter-gather entry should be a multiple of 4K page size;

 Maximum number of packets within a flow generation. */

 Reserved generation value to set to unused flows for kernel contexts */

/*

 * J_KEY for kernel contexts when TID RDMA is used.

 * See generate_jkey() in hfi.h for more information.

 Maximum number of segments in flight per QP request. */

/*

 * OPFN TID layout

 *

 * 63               47               31               15

 * NNNNNNNNKKKKKKKK MMMMMMMMMMMTTTTT DDDDDDUVVVJJJJJJ RRRRRRWWWWWWCCCC

 * 3210987654321098 7654321098765432 1098765432109876 5432109876543210

 * N - the context Number

 * K - the Kdeth_qp

 * M - Max_len

 * T - Timeout

 * D - reserveD

 * V - version

 * U - Urg capable

 * J - Jkey

 * R - max_Read

 * W - max_Write

 * C - Capcode

	/*

	 * If data passed in is zero, return true so as not to continue the

	 * negotiation process

	/*

	 * If kzalloc fails, return false. This will result in:

	 * * at the requester a new OPFN request being generated to retry

	 *   the negotiation

	 * * at the responder, 0 being returned to the requester so as to

	 *   disable TID RDMA at both the requester and the responder

	/*

	 * A TID RDMA READ request's segment size is not equal to

	 * remote->max_len only when the request's data length is smaller

	 * than remote->max_len. In that case, there will be only one segment.

	 * Therefore, when priv->pkts_ps is used to calculate req->cur_seg

	 * during retry, it will lead to req->cur_seg = 0, which is exactly

	 * what is expected.

	/*

	 * If tid_rdma_conn_reply() returns error, set *data as 0 to indicate

	 * TID RDMA could not be enabled. This will result in TID RDMA being

	 * disabled at the requester too.

 This is called at context initialization time */

/**

 * qp_to_rcd - determine the receive context used by a qp

 * @rdi: rvt dev struct

 * @qp: the qp

 *

 * This routine returns the receive context associated

 * with a a qp's qpn.

 *

 * Returns the context.

 Flow and tid waiter functions */

/**

 * DOC: lock ordering

 *

 * There are two locks involved with the queuing

 * routines: the qp s_lock and the exp_lock.

 *

 * Since the tid space allocation is called from

 * the send engine, the qp s_lock is already held.

 *

 * The allocation routines will get the exp_lock.

 *

 * The first_qp() call is provided to allow the head of

 * the rcd wait queue to be fetched under the exp_lock and

 * followed by a drop of the exp_lock.

 *

 * Any qp in the wait list will have the qp reference count held

 * to hold the qp in memory.

/*

 * return head of rcd wait list

 *

 * Must hold the exp_lock.

 *

 * Get a reference to the QP to hold the QP in memory.

 *

 * The caller must release the reference when the local

 * is no longer being used.

/**

 * kernel_tid_waiters - determine rcd wait

 * @rcd: the receive context

 * @queue: the queue to operate on

 * @qp: the head of the qp being processed

 *

 * This routine will return false IFF

 * the list is NULL or the head of the

 * list is the indicated qp.

 *

 * Must hold the qp s_lock and the exp_lock.

 *

 * Return:

 * false if either of the conditions below are satisfied:

 * 1. The list is empty or

 * 2. The indicated qp is at the head of the list and the

 *    HFI1_S_WAIT_TID_SPACE bit is set in qp->s_flags.

 * true is returned otherwise.

/**

 * dequeue_tid_waiter - dequeue the qp from the list

 * @rcd: the receive context

 * @queue: the queue to operate on

 * @qp: the qp to remove the wait list

 *

 * This routine removes the indicated qp from the

 * wait list if it is there.

 *

 * This should be done after the hardware flow and

 * tid array resources have been allocated.

 *

 * Must hold the qp s_lock and the rcd exp_lock.

 *

 * It assumes the s_lock to protect the s_flags

 * field and to reliably test the HFI1_S_WAIT_TID_SPACE flag.

/**

 * queue_qp_for_tid_wait - suspend QP on tid space

 * @rcd: the receive context

 * @queue: the queue to operate on

 * @qp: the qp

 *

 * The qp is inserted at the tail of the rcd

 * wait queue and the HFI1_S_WAIT_TID_SPACE s_flag is set.

 *

 * Must hold the qp s_lock and the exp_lock.

/**

 * __trigger_tid_waiter - trigger tid waiter

 * @qp: the qp

 *

 * This is a private entrance to schedule the qp

 * assuming the caller is holding the qp->s_lock.

/**

 * tid_rdma_schedule_tid_wakeup - schedule wakeup for a qp

 * @qp: the qp

 *

 * trigger a schedule or a waiting qp in a deadlock

 * safe manner.  The qp reference is held prior

 * to this call via first_qp().

 *

 * If the qp trigger was already scheduled (!rval)

 * the reference is dropped, otherwise the resume

 * or the destroy cancel will dispatch the reference.

/**

 * tid_rdma_trigger_resume - field a trigger work request

 * @work: the work item

 *

 * Complete the off qp trigger processing by directly

 * calling the progress routine.

/*

 * tid_rdma_flush_wait - unwind any tid space wait

 *

 * This is called when resetting a qp to

 * allow a destroy or reset to get rid

 * of any tid space linkage and reference counts.

 Flow functions */

/**

 * kern_reserve_flow - allocate a hardware flow

 * @rcd: the context to use for allocation

 * @last: the index of the preferred flow. Use RXE_NUM_TID_FLOWS to

 *         signify "don't care".

 *

 * Use a bit mask based allocation to reserve a hardware

 * flow for use in receiving KDETH data packets. If a preferred flow is

 * specified the function will attempt to reserve that flow again, if

 * available.

 *

 * The exp_lock must be held.

 *

 * Return:

 * On success: a value postive value between 0 and RXE_NUM_TID_FLOWS - 1

 * On failure: -EAGAIN

 Attempt to reserve the preferred flow index */

 The QP already has an allocated flow */

 Generation received in a RESYNC overrides default flow generation */

 get head before dropping lock */

 get head before dropping lock */

 TID allocation functions */

/**

 * tid_rdma_find_phys_blocks_4k - get groups base on mr info

 * @flow: overall info for a TID RDMA segment

 * @pages: pointer to an array of page structs

 * @npages: number of pages

 * @list: page set array to return

 *

 * This routine returns the number of groups associated with

 * the current sge information.  This implementation is based

 * on the expected receive find_phys_blocks() adjusted to

 * use the MR information vs. the pfn.

 *

 * Return:

 * the number of RcvArray entries

	/*

	 * Look for sets of physically contiguous pages in the user buffer.

	 * This will allow us to optimize Expected RcvArray entry usage by

	 * using the bigger supported sizes.

		/*

		 * If the vaddr's are not sequential, pages are not physically

		 * contiguous.

			/*

			 * At this point we have to loop over the set of

			 * physically contiguous pages and break them down it

			 * sizes supported by the HW.

			 * There are two main constraints:

			 *     1. The max buffer size is MAX_EXPECTED_BUFFER.

			 *        If the total set size is bigger than that

			 *        program only a MAX_EXPECTED_BUFFER chunk.

			 *     2. The buffer size has to be a power of two. If

			 *        it is not, round down to the closes power of

			 *        2 and program that size.

 insure we always return an even number of sets */

/**

 * tid_flush_pages - dump out pages into pagesets

 * @list: list of pagesets

 * @idx: pointer to current page index

 * @pages: number of pages to dump

 * @sets: current number of pagesset

 *

 * This routine flushes out accumuated pages.

 *

 * To insure an even number of sets the

 * code may add a filler.

 *

 * This can happen with when pages is not

 * a power of 2 or pages is a power of 2

 * less than the maximum pages.

 *

 * Return:

 * The new number of sets

 might need a filler */

/**

 * tid_rdma_find_phys_blocks_8k - get groups base on mr info

 * @flow: overall info for a TID RDMA segment

 * @pages: pointer to an array of page structs

 * @npages: number of pages

 * @list: page set array to return

 *

 * This routine parses an array of pages to compute pagesets

 * in an 8k compatible way.

 *

 * pages are tested two at a time, i, i + 1 for contiguous

 * pages and i - 1 and i contiguous pages.

 *

 * If any condition is false, any accumlated pages are flushed and

 * v0,v1 are emitted as separate PAGE_SIZE pagesets

 *

 * Otherwise, the current 8k is totaled for a future flush.

 *

 * Return:

 * The number of pagesets

 * list set with the returned number of pagesets

 *

 get a new v0 */

 compare i, i + 1 vaddr */

 flush out pages */

 output v0,v1 as two pagesets */

 i,i+1 consecutive, look at i-1,i */

 flush out pages */

 pages will always be a multiple of 8k */

 save i-1 */

 move to next pair */

 dump residual pages at end */

 by design cannot be odd sets */

/*

 * Find pages for one segment of a sge array represented by @ss. The function

 * does not check the sge, the sge must have been checked for alignment with a

 * prior call to hfi1_kern_trdma_ok. Other sge checking is done as part of

 * rvt_lkey_ok and rvt_rkey_ok. Also, the function only modifies the local sge

 * copy maintained in @ss->sge, the original sge is not modified.

 *

 * Unlike IB RDMA WRITE, we can't decrement ss->num_sge here because we are not

 * releasing the MR reference count at the same time. Otherwise, we'll "leak"

 * references to the MR. This difference requires that we keep track of progress

 * into the sg_list. This is done by the cur_seg cursor in the tid_rdma_request

 * structure.

/*

 * Get pages pointers and identify contiguous physical memory chunks for a

 * segment. All segments are of length flow->req->seg_len.

 Reuse previously computed pagesets, if any */

/*

 * Try to allocate pageset_count TID's from TID groups for a context

 *

 * This function allocates TID's without moving groups between lists or

 * modifying grp->map. This is done as follows, being cogizant of the lists

 * between which the TID groups will move:

 * 1. First allocate complete groups of 8 TID's since this is more efficient,

 *    these groups will move from group->full without affecting used

 * 2. If more TID's are needed allocate from used (will move from used->full or

 *    stay in used)

 * 3. If we still don't have the required number of TID's go back and look again

 *    at a complete group (will move from group->used)

 First look at complete groups */

 Now look at partially used groups */

	/*

	 * Look again at a complete group, continuing from where we left.

	 * However, if we are at the head, we have reached the end of the

	 * complete groups list from the first loop above

		/*

		 * A single TID entry will be used to use a rcvarr pair (with

		 * tidctrl 0x3), if ALL these are true (a) the bit pos is even

		 * (b) the group map shows current and the next bits as free

		 * indicating two consecutive rcvarry entries are available (c)

		 * we actually need 2 more entries

 entry */

 Efficient DIV_ROUND_UP(npages, pmtu_pg) */

/**

 * hfi1_kern_exp_rcv_setup() - setup TID's and flow for one segment of a

 * TID RDMA request

 *

 * @req: TID RDMA request for which the segment/flow is being set up

 * @ss: sge state, maintains state across successive segments of a sge

 * @last: set to true after the last sge segment has been processed

 *

 * This function

 * (1) finds a free flow entry in the flow circular buffer

 * (2) finds pages and continuous physical chunks constituing one segment

 *     of an sge

 * (3) allocates TID group entries for those chunks

 * (4) programs rcvarray entries in the hardware corresponding to those

 *     TID's

 * (5) computes a tidarray with formatted TID entries which can be sent

 *     to the sender

 * (6) Reserves and programs HW flows.

 * (7) It also manages queing the QP when TID/flow resources are not

 *     available.

 *

 * @req points to struct tid_rdma_request of which the segments are a part. The

 * function uses qp, rcd and seg_len members of @req. In the absence of errors,

 * req->flow_idx is the index of the flow which has been prepared in this

 * invocation of function call. With flow = &req->flows[req->flow_idx],

 * flow->tid_entry contains the TID array which the sender can use for TID RDMA

 * sends and flow->npkts contains number of packets required to send the

 * segment.

 *

 * hfi1_check_sge_align should be called prior to calling this function and if

 * it signals error TID RDMA cannot be used for this sge and this function

 * should not be called.

 *

 * For the queuing, caller must hold the flow->req->qp s_lock from the send

 * engine and the function will procure the exp_lock.

 *

 * Return:

 * The function returns -EAGAIN if sufficient number of TID/flow resources to

 * map the segment could not be allocated. In this case the function should be

 * called again with previous arguments to retry the TID allocation. There are

 * no other error returns. The function returns 0 on success.

	/*

	 * We return error if either (a) we don't have space in the flow

	 * circular buffer, or (b) we already have max entries in the buffer.

	 * Max entries depend on the type of request we are processing and the

	 * negotiated TID RDMA parameters.

	/*

	 * Get pages, identify contiguous physical memory chunks for the segment

	 * If we can not determine a DMA address mapping we will treat it just

	 * like if we ran out of space above.

	/*

	 * At this point we know the number of pagesets and hence the number of

	 * TID's to map the segment. Allocate the TID's from the TID groups. If

	 * we cannot allocate the required number we exit and try again later

	/*

	 * Finally program the TID entries with the pagesets, compute the

	 * tidarray and enable the HW flow

	/*

	 * Setup the flow state with relevant information.

	 * This information is used for tracking the sequence of data packets

	 * for the segment.

	 * The flow is setup here as this is the most accurate time and place

	 * to do so. Doing at a later time runs the risk of the flow data in

	 * qpriv getting out of sync.

 get head before dropping lock */

/*

 * This function is called after one segment has been successfully sent to

 * release the flow and TID HW/SW resources for that segment. The segments for a

 * TID RDMA request are setup and cleared in FIFO order which is managed using a

 * circular buffer.

 Exit if we have nothing in the flow circular buffer */

 To prevent double unprogramming */

 get head before dropping lock */

/*

 * This function is called to release all the tid entries for

 * a request.

 Use memory barrier for proper ordering */

/**

 * hfi1_kern_exp_rcv_free_flows - free priviously allocated flow information

 * @req: the tid rdma request to be cleaned

/**

 * __trdma_clean_swqe - clean up for large sized QPs

 * @qp: the queue patch

 * @wqe: the send wqe

/*

 * This can be called at QP create time or in the data path.

 mini init */

	/*

	 * Initialize various TID RDMA request variables.

	 * These variables are "static", which is why they

	 * can be pre-initialized here before the WRs has

	 * even been submitted.

	 * However, non-NULL values for these variables do not

	 * imply that this WQE has been enabled for TID RDMA.

	 * Drivers should check the WQE's opcode to determine

	 * if a request is a TID RDMA one or not.

 TID RDMA READ functions */

 This is the IB psn used to send the request */

 TID Entries for TID RDMA READ payload */

	/*

	 * We can safely zero these out. Since the first SGE covers the

	 * entire packet, nothing else should even look at the MR.

 Construct the TID RDMA READ REQ packet header */

 We are done with this segment */

 Set the TID RDMA READ request payload size */

/*

 * @len: contains the data length to read upon entry and the read request

 *       payload length upon exit.

	/*

	 * Check sync conditions. Make sure that there are no pending

	 * segments before freeing the flow.

	/*

	 * If the request for this segment is resent, the tid resources should

	 * have been allocated before. In this case, req->flow_idx should

	 * fall behind req->setup_head.

			/*

			 * This is the first new segment for a request whose

			 * earlier segments have been re-sent. We need to

			 * set up the sge pointer correctly.

		/*

		 * Check sync. The last PSN of each generation is reserved for

		 * RESYNC.

 Allocate the flow if not yet */

		/*

		 * The following call will advance req->setup_head after

		 * allocating the tid entries.

			/*

			 * We don't have resources for this segment. The QP has

			 * already been queued.

 req->flow_idx should only be one slot behind req->setup_head */

 Set the first and last IB PSN for the flow in use.*/

 Calculate the next segment start psn.*/

 Build the packet header */

/*

 * Validate and accept the TID RDMA READ request parameters.

 * Return 0 if the request is accepted successfully;

 * Return 1 otherwise.

 Validate the payload first */

 payload length = packet length - (header length + ICRC length) */

	/*

	 * Walk the TID_ENTRY list to make sure we have enough space for a

	 * complete segment. Also calculate the number of required packets.

		/*

		 * For tid pair (tidctr == 3), the buffer size of the pair

		 * should be the sum of the buffer size described by each

		 * tid entry. However, only the first entry needs to be

		 * specified in the request (see WFR HAS Section 8.5.7.1).

 Empty the flow array */

 Set the initial flow index to the current flow. */

 advance circular buffer head */

	/*

	 * Compute last PSN for request.

 sequence error */

		/*

		 * The requester always restarts from the start of the original

		 * request.

		/*

		 * If all the response packets for the current request have

		 * been sent out and this request is complete (old_request

		 * == false) and the TID flow may be unusable (the

		 * req->clear_tail is advanced). However, when an earlier

		 * request is received, this request will not be complete any

		 * more (qp->s_tail_ack_queue is moved back, see below).

		 * Consequently, we need to update the TID flow info everytime

		 * a duplicate request is received.

		/*

		 * True if the request is already scheduled (between

		 * qp->s_tail_ack_queue and qp->r_head_ack_queue);

		/*

		 * True if the request is already scheduled (between

		 * qp->s_tail_ack_queue and qp->r_head_ack_queue).

		 * Also, don't change requests, which are at the SYNC

		 * point and haven't generated any responses yet.

		 * There is nothing to retransmit for them yet.

			/*

			 * If the state of the request has been changed,

			 * the first leg needs to get scheduled in order to

			 * pick up the change. Otherwise, normal response

			 * processing should take care of it.

		/*

		 * If there is no more allocated segment, just schedule the qp

		 * without changing any state.

		/*

		 * If this request has sent responses for segments, which have

		 * not received data yet (flow_idx != clear_tail), the flow_idx

		 * pointer needs to be adjusted so the same responses can be

		 * re-sent.

			/*

			 * When flow_idx == setup_head, we've gotten a duplicate

			 * request for a segment, which has not been allocated

			 * yet. In that case, don't adjust this request.

			 * However, we still want to go through the loop below

			 * to adjust all subsequent requests.

			/*

			 * Look at everything up to and including

			 * s_tail_ack_queue

 Re-process old requests.*/

	/*

	 * Since the qp->s_tail_ack_queue is modified, the

	 * qp->s_ack_state must be changed to re-initialize

	 * qp->s_ack_rdma_sge; Otherwise, we will end up in

	 * wrong memory region.

	/*

	 * It's possible to receive a retry psn that is earlier than an RNRNAK

	 * psn. In this case, the rnrnak state should be cleared.

 HANDLER FOR TID RDMA READ REQUEST packet (Responder side)*/

	/*

	 * 1. Verify TID RDMA READ REQ as per IB_OPCODE_RC_RDMA_READ

	 *    (see hfi1_rc_rcv())

	 * 2. Put TID RDMA READ REQ into the response queueu (s_ack_queue)

	 *     - Setup struct tid_rdma_req with request info

	 *     - Initialize struct tid_rdma_flow info;

	 *     - Copy TID entries;

	 * 3. Set the qp->s_ack_state.

	 * 4. Set RVT_S_RESP_PENDING in s_flags.

	 * 5. Kick the send engine (hfi1_schedule_send())

 The length needs to be in multiples of PAGE_SIZE */

 We've verified the request, insert it into the ack queue. */

 Accept the request parameters */

	/*

	 * We need to increment the MSN here instead of when we

	 * finish sending the result since a duplicate request would

	 * increment it more than once.

	/*

	 * For all requests other than TID WRITE which are added to the ack

	 * queue, qpriv->r_tid_alloc follows qp->r_head_ack_queue. It is ok to

	 * do this because of interlocks between these and TID WRITE

	 * requests. The same change has also been made in hfi1_rc_rcv().

 Schedule the send tasklet. */

 Queue NAK for later */

 Advance to next flow */

 HANDLER FOR TID RDMA READ RESPONSE packet (Requestor side */

	/*

	 * 1. Find matching SWQE

	 * 2. Check that the entire segment has been read.

	 * 3. Remove HFI1_S_WAIT_TID_RESP from s_flags.

	 * 4. Free the TID flow resources.

	 * 5. Kick the send engine (hfi1_schedule_send())

 When header suppression is disabled */

		/*

		 * Copy the payload to destination buffer if this packet is

		 * delivered as an eager packet due to RSM rule and FECN.

		 * The RSM rule selects FECN bit in BTH and SH bit in

		 * KDETH header and therefore will not match the last

		 * packet of each segment that has SH bit cleared.

 Raise the sw sequence check flag for next packet */

 Release the tid resources */

 If not done yet, build next read request */

	/*

	 * Clear the hw flow under two conditions:

	 * 1. This request is a sync point and it is complete;

	 * 2. Current request is completed and there are no more requests.

	/*

	 * The test indicates that the send engine has finished its cleanup

	 * after sending the request and it's now safe to put the QP into error

	 * state. However, if the wqe queue is empty (qp->s_acked == qp->s_tail

	 * == qp->s_head), it would be unsafe to complete the wqe pointed by

	 * qp->s_acked here. Putting the qp into error state will safely flush

	 * all remaining requests.

 Free any TID entries */

 Free flow */

	/*

	 * We've ran out of space in the eager buffer.

	 * Eagerly received KDETH packets which require space in the

	 * Eager buffer (packet that have payload) are TID RDMA WRITE

	 * response packets. In this case, we have to re-transmit the

	 * TID RDMA WRITE request.

 Since no payload is delivered, just drop the packet */

 Start from the right segment */

/*

 * Handle the KDETH eflags for TID RDMA READ response.

 *

 * Return true if the last packet for a segment has been received and it is

 * time to process the response normally; otherwise, return true.

 *

 * The caller must hold the packet->qp->r_lock and the rcu_read_lock.

 If the psn is out of valid range, drop the packet */

	/*

	 * Note that NAKs implicitly ACK outstanding SEND and RDMA write

	 * requests and implicitly NAK RDMA read and atomic requests issued

	 * before the NAK'ed request.

 Complete WQEs that the PSN finishes. */

		/*

		 * If this request is a RDMA read or atomic, and the NACK is

		 * for a later operation, this NACK NAKs the RDMA read or

		 * atomic.

 Retry this request. */

 wait */

			/*

			 * No need to process the NAK since we are

			 * restarting an earlier request.

 Handle the eflags for the request */

			/*

			 * On the first occurrence of a Flow Sequence error,

			 * the flag TID_FLOW_SW_PSN is set.

			 *

			 * After that, the flow is *not* reprogrammed and the

			 * protocol falls back to SW PSN checking. This is done

			 * to prevent continuous Flow Sequence errors for any

			 * packets that could be still in the fabric.

 Drop the packet.*/

					/*

					 * If a response packet for a restarted

					 * request has come back, reset the

					 * restart flag.

 Drop the packet.*/

				/*

				 * If SW PSN verification is successful and

				 * this is the last packet in the segment, tell

				 * the caller to process it as a normal packet.

				/*

				 * If no request has been restarted yet,

				 * restart the current one.

			/*

			 * Since the TID flow is able to ride through

			 * generation mismatch, drop this stale packet.

 Get the destination QP number. */

 Check for valid receive state. */

 For TIDERR and RC QPs preemptively schedule a NAK */

 in bytes */

 Sanity check packet */

		/*

		 * Check for GRH. We should never get packets with GRH in this

		 * path.

 handle TID RDMA READ */

	/*

	 * qp->s_tail_ack_queue points to the rvt_ack_entry currently being

	 * processed. These a completed sequentially so we can be sure that

	 * the pointer will not change until the entire request has completed.

				/*

				 * If the received PSN does not match the next

				 * expected PSN, NAK the packet.

				 * However, only do that if we know that the a

				 * NAK has already been sent. Otherwise, this

				 * mismatch could be due to packets that were

				 * already in flight.

				/*

				 * If SW PSN verification is successful and this

				 * is the last packet in the segment, tell the

				 * caller to process it as a normal packet.

 We are NAK'ing the next expected PSN */

/*

 * "Rewind" the TID request information.

 * This means that we reset the state back to ACTIVE,

 * find the proper flow, set the flow index to that flow,

 * and reset the flow information.

 msg */

		/*

		 * Packet PSN is based on flow_state.spsn + flow->pkt. However,

		 * during a RESYNC, the generation is incremented and the

		 * sequence is reset to 0. Since we've adjusted the npkts in the

		 * flow and the SGE has been sufficiently advanced, we have to

		 * adjust flow->pkt in order to calculate the correct PSN.

 Move flow_idx to correct index */

 Reset all the flows that we are going to resend */

 Pull req->clear_tail back */

	/*

	 * First, clear the flow to help prevent any delayed packets from

	 * being delivered.

 Free only locally allocated TID entries */

 Free only locally allocated TID entries */

 Does @sge meet the alignment requirements for tid rdma? */

	/*

	 * If TID RDMA is disabled by the negotiation, don't

	 * use it.

		/*

		 * TID RDMA is enabled for this RDMA WRITE request iff:

		 *   1. The remote address is page-aligned,

		 *   2. The length is larger than the minimum segment size,

		 *   3. The length is page-multiple.

 Compute the last PSN of the request */

		/*

		 * Reset acked_tail.

		 * TID RDMA READ does not have ACKs so it does not

		 * update the pointer. We have to reset it so TID RDMA

		 * WRITE does not get confused.

 TID RDMA WRITE functions */

	/*

	 * Set the number of flow to be used based on negotiated

	 * parameters.

	/*

	 * Heuristic for computing the RNR timeout when waiting on the flow

	 * queue. Rather than a computationaly expensive exact estimate of when

	 * a flow will be available, we assume that if a QP is at position N in

	 * the flow queue it has to wait approximately (N + 1) * (number of

	 * segments between two sync points). The rationale for this is that

	 * flows are released and recycled at each sync point.

/*

 * @qp: points to rvt_qp context.

 * @to_seg: desired RNR timeout in segments.

 * Return: index of the next highest timeout in the ib_hfi1_rnr_table[]

	/*

	 * Find the next highest value in the RNR table to the required

	 * timeout. This gives the responder some padding.

/*

 * Central place for resource allocation at TID write responder,

 * is called from write_req and write_data interrupt handlers as

 * well as the send thread when a queued QP is scheduled for

 * resource allocation.

 *

 * Iterates over (a) segments of a request and then (b) queued requests

 * themselves to allocate resources for up to local->max_write

 * segments across multiple requests. Stop allocating when we

 * hit a sync point, resume allocating after data packets at

 * sync point have been received.

 *

 * Resource allocation and sending of responses is decoupled. The

 * request/segment which are being allocated and sent are as follows.

 * Resources are allocated for:

 *     [request: qpriv->r_tid_alloc, segment: req->alloc_seg]

 * The send thread sends:

 *     [request: qp->s_tail_ack_queue, segment:req->cur_seg]

		/*

		 * Don't allocate more segments if a RNR NAK has already been

		 * scheduled to avoid messing up qp->r_psn: the RNR NAK will

		 * be sent only when all allocated segments have been sent.

		 * However, if more segments are allocated before that, TID RDMA

		 * WRITE RESP packets will be sent out for these new segments

		 * before the RNR NAK packet. When the requester receives the

		 * RNR NAK packet, it will restart with qp->s_last_psn + 1,

		 * which does not match qp->r_psn and will be dropped.

		 * Consequently, the requester will exhaust its retries and

		 * put the qp into error state.

 No requests left to process */

 If all data has been received, clear the flow */

 Finished allocating for all segments of this request */

 Can allocate only a maximum of local->max_write for a QP */

 Don't allocate at a sync point with data packets pending */

 All data received at the sync point, continue */

 Allocate flow if we don't have one */

		/*

		 * We are at a sync point if we run out of KDETH PSN space.

		 * Last PSN of every generation is reserved for RESYNC.

		/*

		 * If overtaking req->acked_tail, send an RNR NAK. Because the

		 * QP is not queued in this case, and the issue can only be

		 * caused by a delay in scheduling the second leg which we

		 * cannot estimate, we use a rather arbitrary RNR timeout of

		 * (MAX_FLOWS / 2) segments

 Try to allocate rcv array / TID entries */

 Begin processing the next request */

	/*

	 * Schedule an RNR NAK to be sent if (a) flow or rcv array allocation

	 * has failed (b) we are called from the rcv handler interrupt context

	 * (c) an RNR NAK has not already been scheduled

 Set r_nak_state to prevent unrelated events from generating NAK's */

 Pull back r_psn to the segment being RNR NAK'd */

	/*

	 * Pull back r_head_ack_queue to the ack entry following the request

	 * being RNR NAK'd. This allows resources to be allocated to the request

	 * if the queued QP is scheduled.

	/*

	 * These send side fields are used in make_rc_ack(). They are set in

	 * hfi1_send_rc_ack() but must be set here before dropping qp->s_lock

	 * for consistency

	/*

	 * Clear the ACK PENDING flag to prevent unwanted ACK because we

	 * have modified qp->s_ack_psn here.

	/*

	 * qpriv->rnr_nak_state is used to determine when the scheduled RNR NAK

	 * has actually been sent. qp->s_flags RVT_S_ACK_PENDING bit cannot be

	 * used for this because qp->s_lock is dropped before calling

	 * hfi1_send_rc_ack() leading to inconsistency between the receive

	 * interrupt handlers and the send thread in make_rc_ack()

	/*

	 * Schedule RNR NAK to be sent. RNR NAK's are scheduled from the receive

	 * interrupt handlers but will be sent from the send engine behind any

	 * previous responses that may have been scheduled

 HANDLER FOR TID RDMA WRITE REQUEST packet (Responder side)*/

	/*

	 * 1. Verify TID RDMA WRITE REQ as per IB_OPCODE_RC_RDMA_WRITE_FIRST

	 *    (see hfi1_rc_rcv())

	 *     - Don't allow 0-length requests.

	 * 2. Put TID RDMA WRITE REQ into the response queueu (s_ack_queue)

	 *     - Setup struct tid_rdma_req with request info

	 *     - Prepare struct tid_rdma_flow array?

	 * 3. Set the qp->s_ack_state as state diagram in design doc.

	 * 4. Set RVT_S_RESP_PENDING in s_flags.

	 * 5. Kick the send engine (hfi1_schedule_send())

	/*

	 * The resent request which was previously RNR NAK'd is inserted at the

	 * location of the original request, which is one entry behind

	 * r_head_ack_queue

 We've verified the request, insert it into the ack queue. */

 Bring previously RNR NAK'd request back to life */

 The length needs to be in multiples of PAGE_SIZE */

	/*

	 * We need to increment the MSN here instead of when we

	 * finish sending the result since a duplicate request would

	 * increment it more than once.

 Schedule the send tasklet. */

 Queue NAK for later */

		/*

		 * Try to allocate resources here in case QP was queued and was

		 * later scheduled when resources became available

 We've already sent everything which is ready */

		/*

		 * Resources can be assigned but responses cannot be sent in

		 * rnr_nak state, till the resent request is received

	/*

	 * We can safely zero these out. Since the first SGE covers the

	 * entire packet, nothing else should even look at the MR.

 Construct the TID RDMA WRITE RESP packet header */

 msg */

		/*

		 * Go though the entire ack queue and clear any outstanding

		 * HW flow and RcvArray resources.

 HANDLER FOR TID RDMA WRITE RESPONSE packet (Requestor side */

	/*

	 * 1. Find matching SWQE

	 * 2. Check that TIDENTRY array has enough space for a complete

	 *    segment. If not, put QP in error state.

	 * 3. Save response data in struct tid_rdma_req and struct tid_rdma_flow

	 * 4. Remove HFI1_S_WAIT_TID_RESP from s_flags.

	 * 5. Set qp->s_state

	 * 6. Kick the send engine (hfi1_schedule_send())

 Ignore invalid responses */

 Ignore duplicate responses. */

	/*

	 * If we are waiting for a particular packet sequence number

	 * due to a request being resent, check for it. Otherwise,

	 * ensure that we haven't missed anything.

	/*

	 * If we've lost ACKs and our acked_tail pointer is too far

	 * behind, don't overwrite segments. Just drop the packet and

	 * let the reliability protocol take care of it.

	/*

	 * The call to do_rc_ack() should be last in the chain of

	 * packet checks because it will end up updating the QP state.

	 * Therefore, anything that would prevent the packet from

	 * being accepted as a successful response should be prior

	 * to it.

 payload length = packet length - (header length + ICRC length) */

	/*

	 * Walk the TID_ENTRY list to make sure we have enough space for a

	 * complete segment.

 entry */

	/*

	 * If this is the first response for this request, set the initial

	 * flow index to the current flow.

 Set acked flow index to head index */

 advance circular buffer head */

	/*

	 * If all responses for this TID RDMA WRITE request have been received

	 * advance the pointer to the next one.

	 * Since TID RDMA requests could be mixed in with regular IB requests,

	 * they might not appear sequentially in the queue. Therefore, the

	 * next request needs to be "found".

 PSNs are zero-based, so +1 to count number of packets */

	/*

	 * All error handling should be done by now. If we are here, the packet

	 * is either good or been accepted by the error handler.

		/*

		 * Copy the payload to destination buffer if this packet is

		 * delivered as an eager packet due to RSM rule and FECN.

		 * The RSM rule selects FECN bit in BTH and SH bit in

		 * KDETH header and therefore will not match the last

		 * packet of each segment that has SH bit cleared.

			/*

			 * The e->rdma_sge field is set when TID RDMA WRITE REQ

			 * is first received and is never modified thereafter.

 Raise the sw sequence check flag for next packet */

	/*

	 * Release the flow if one of the following conditions has been met:

	 *  - The request has reached a sync point AND all outstanding

	 *    segments have been completed, or

	 *  - The entire request is complete and there are no more requests

	 *    (of any kind) in the queue.

	/*

	 * If we need to generate more responses, schedule the

	 * send engine.

		/*

		 * If the PSN before the current expect KDETH PSN is the

		 * RESYNC PSN, then we never received a good TID RDMA WRITE

		 * DATA packet after a previous RESYNC.

		 * In this case, the next expected KDETH PSN stays the same.

			/*

			 * Because the KDETH PSNs jump during a RESYNC, it's

			 * not possible to infer (or compute) the previous value

			 * of r_next_psn_kdeth in the case of back-to-back

			 * RESYNC packets. Therefore, we save it.

 If we are waiting for an ACK to RESYNC, drop any other packets */

 Drop stale ACK/NAK */

 advance acked segment pointer */

 ACK */

 Check if there is any pending TID ACK */

 ACK(RESYNC) */

 Allow new requests (see hfi1_make_tid_rdma_pkt) */

			/*

			 * Clear RVT_S_SEND_ONE flag in case that the TID RDMA

			 * ACK is received after the TID retry timer is fired

			 * again. In this case, do not send any more TID

			 * RESYNC request or wait for any more TID ACK packet.

			/*

			 * The PSN to start with is the next PSN after the

			 * RESYNC PSN.

			/*

			 * Update to the correct WQE when we get an ACK(RESYNC)

			 * in the middle of a request.

			/*

			 * RESYNC re-numbers the PSN ranges of all remaining

			 * segments. Also, PSN's start from 0 in the middle of a

			 * segment and the first segment size is less than the

			 * default number of packets. flow->resync_npkts is used

			 * to track the number of packets from the start of the

			 * real segment to the point of 0 PSN after the RESYNC

			 * in order to later correctly rewind the SGE.

			/*

			 * If resync_psn points to the last flow PSN for a

			 * segment and the new segment (likely from a new

			 * request) starts with a new generation number, we

			 * need to adjust resync_psn accordingly.

			/*

			 * Renumber all packet sequence number ranges

			 * based on the new generation.

 start from last acked segment */

 NAK */

 PSN sequence error */

 msg */

 req */

 Only send one packet (the RESYNC) */

			/*

			 * No additional request shall be made by this QP until

			 * the RESYNC has been complete.

	/*

	 * RESYNC packet contains the "next" generation and can only be

	 * from the current or previous generations

 Already processing a resync */

		/*

		 * If we don't have a flow, save the generation so it can be

		 * applied when a new flow is allocated

 Reprogram the QP flow with new generation */

	/*

	 * Disable SW PSN checking since a RESYNC is equivalent to a

	 * sync point and the flow has/will be reprogrammed

	/*

	 * Reset all TID flow information with the new generation.

	 * This is done for all requests and segments after the

	 * last received segment

 start from last unacked segment */

 RESYNC request always gets a TID RDMA ACK. */

/*

 * Call this function when the last TID RDMA WRITE DATA packet for a request

 * is built.

 Can't move beyond s_tid_cur */

	/*

	 * Prioritize the sending of the requests and responses over the

	 * sending of the TID RDMA data packets.

	/*

	 * Bail out if we can't send data.

	 * Be reminded that this check must been done after the call to

	 * make_tid_rdma_ack() because the responding QP could be in

	 * RTR state where it can send TID RDMA ACK, not TID RDMA WRITE DATA.

 Check whether there is anything to do. */

		/*

		 * 1. Check whether TID RDMA WRITE RESP available.

		 * 2. If no:

		 *    2.1 If have more segments and no TID RDMA WRITE RESP,

		 *        set HFI1_S_WAIT_TID_RESP

		 *    2.2 Return indicating no progress made.

		 * 3. If yes:

		 *    3.1 Build TID RDMA WRITE DATA packet.

		 *    3.2 If last packet in segment:

		 *        3.2.1 Change KDETH header bits

		 *        3.2.2 Advance RESP pointers.

		 *    3.3 Return indicating progress made.

 move pointer to next flow */

 Advance the s_tid_tail now */

 Use generation from the most recently received response */

 If no responses for this WQE look at the previous one */

	/*

	 * If we didn't get a txreq, the QP will be woken up later to try

	 * again, set the flags to the wake up which work item to wake

	 * up.

	 * (A better algorithm should be found to do this and generalize the

	 * sleep/wakeup flags.)

 Don't send an ACK if we aren't supposed to. */

 header size in 32-bit words LRH+BTH = (8+12)/4. */

	/*

	 * In the RESYNC case, we are exactly one segment past the

	 * previously sent ack or at the previously sent NAK. So to send

	 * the resync ack, we go back one segment (which might be part of

	 * the previous request) and let the do-while loop execute again.

	 * The advantage of executing the do-while loop is that any data

	 * received after the previous ack is automatically acked in the

	 * RESYNC ack. It turns out that for the do-while loop we only need

	 * to pull back qpriv->r_tid_ack, not the segment

	 * indices/counters. The scheme works even if the previous request

	 * was not a TID WRITE request.

	/*

	 * If we've sent all the ACKs that we can, we are done

	 * until we get more segments...

		/*

		 * To deal with coalesced ACKs, the acked_tail pointer

		 * into the flow array is used. The distance between it

		 * and the clear_tail is the number of flows that are

		 * being ACK'ed.

 Get up-to-date value */

 Advance acked index */

		/*

		 * req->clear_tail points to the segment currently being

		 * received. So, when sending an ACK, the previous

		 * segment is being ACK'ed.

 Move to the next ack entry now */

	/*

	 * At this point qpriv->r_tid_ack == qpriv->r_tid_tail but e and

	 * req could be pointing at the previous ack queue entry

		/*

		 * A NAK will implicitly acknowledge all previous TID RDMA

		 * requests. Therefore, we NAK with the req->acked_tail

		 * segment for the request at qpriv->r_tid_ack (same at

		 * this point as the req->clear_tail segment for the

		 * qpriv->r_tid_tail request)

	/*

	 * Ensure s_rdma_ack_cnt changes are committed prior to resetting

	 * RVT_S_RESP_PENDING

 Return if we are already busy processing a work request. */

 insure a pre-built packet is handled  */

 Check for a constructed packet to be sent. */

			/*

			 * If the packet cannot be sent now, return and

			 * the send tasklet will be woken up later.

 allow other tasks to run */

/**

 * hfi1_schedule_tid_send - schedule progress on TID RDMA state machine

 * @qp: the QP

 *

 * This schedules qp progress on the TID RDMA state machine. Caller

 * should hold the s_lock.

 * Unlike hfi1_schedule_send(), this cannot use hfi1_send_ok() because

 * the two state machines can step on each other with respect to the

 * RVT_S_BUSY flag.

 * Therefore, a modified test is used.

 * @return true if the second leg is scheduled;

 *  false if the second leg is not scheduled.

		/*

		 * The following call returns true if the qp is not on the

		 * queue and false if the qp is already on the queue before

		 * this call. Either way, the qp will be on the queue when the

		 * call returns.

	/*

	 * The only sane way to get the amount of

	 * progress is to read the HW flow state.

	/*

	 * If a start/middle packet is delivered here due to

	 * RSM rule and FECN, we need to update the r_next_psn.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015, 2016 Intel Corporation.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015, 2016 Intel Corporation.

 for the given bus number, return the CSR for reading an i2c line */

 for the given bus number, return the CSR for writing an i2c line */

	/*

	 * The OE bit value is inverted and connected to the pin.  When

	 * OE is 0 the pin is left to be pulled up, when the OE is 1

	 * the pin is driven low.  This matches the "open drain" or "open

	 * collector" convention.

 do a read to force the write into the chip */

	/*

	 * The OE bit value is inverted and connected to the pin.  When

	 * OE is 0 the pin is left to be pulled up, when the OE is 1

	 * the pin is driven low.  This matches the "open drain" or "open

	 * collector" convention.

 do a read to force the write into the chip */

 clear OE so we do not pull line down */

 1us pull up + 250ns hold */

 clear OE so we do not pull line down */

 1us pull up + 250ns hold */

/*

 * Allocate and initialize the given i2c bus number.

 * Returns NULL on failure.

 our bus number */

/*

 * Initialize i2c buses.

 * Return 0 on success, -errno on error.

/*

 * Raw i2c write.  No set-up or lock checking.

 *

 * Return 0 on success, -errno on error.

 convert to 7-bit addr */

/*

 * Caller must hold the i2c chain resource.

 *

 * Return number of bytes written, or -errno.

/*

 * Raw i2c read.  No set-up or lock checking.

 *

 * Return 0 on success, -errno on error.

 convert to 7-bit addr */

/*

 * Caller must hold the i2c chain resource.

 *

 * Return number of bytes read, or -errno.

/*

 * Write page n, offset m of QSFP memory as defined by SFF 8636

 * by writing @addr = ((256 * n) + m)

 *

 * Caller must hold the i2c chain resource.

 *

 * Return number of bytes written or -errno.

		/*

		 * Set the qsfp page based on a zero-based address

		 * and a page size of QSFP_PAGESIZE bytes.

 QSFPs require a 5-10msec delay after write operations */

 truncate write to boundary if crossing boundary */

 QSFPs require a 5-10msec delay after write operations */

 stop on error */

/*

 * Perform a stand-alone single QSFP write.  Acquire the resource, do the

 * write, then release the resource.

/*

 * Access page n, offset m of QSFP memory as defined by SFF 8636

 * by reading @addr = ((256 * n) + m)

 *

 * Caller must hold the i2c chain resource.

 *

 * Return the number of bytes read or -errno.

		/*

		 * Set the qsfp page based on a zero-based address

		 * and a page size of QSFP_PAGESIZE bytes.

 QSFPs require a 5-10msec delay after write operations */

 truncate read to boundary if crossing boundary */

 stop on error */

/*

 * Perform a stand-alone single QSFP read.  Acquire the resource, do the

 * read, then release the resource.

/*

 * This function caches the QSFP memory range in 128 byte chunks.

 * As an example, the next byte after address 255 is byte 128 from

 * upper page 01H (if existing) rather than byte 0 from lower page 00H.

 * Access page n, offset m of QSFP memory as defined by SFF 8636

 * in the cache by reading byte ((128 * n) + m)

 * The calls to qsfp_{read,write} in this function correctly handle the

 * address map difference between this mapping and the mapping implemented

 * by those functions

 *

 * The caller must be holding the QSFP i2c chain resource.

 ensure sane contents on invalid reads, for cable swaps */

 Is paging enabled? */

 Paging enabled, page 03 required */

 all */

 only page 2 and 3 */

 only page 1 and 3 */

 only page 3 */

 Holds longest string */

 For use with QSFP_HIGH_PWR macro */

 Bits [1:0] = 00 implies low power module */

/*

 * Takes power class byte [Page 00 Byte 129] in SFF 8636

 * Returns power class as integer (1 through 7, per SFF 8636 rev 2.4)

 power classes count from 1, their bit encodings from 0 */

	/*

	 * 00 in the high power classes stands for unused, bringing

	 * balance to the off-by-1 offset above, we add 4 here to

	 * account for the difference between the low and high power

	 * groups

/*

 * This function maps QSFP memory addresses in 128 byte chunks in the following

 * fashion per the CableInfo SMA query definition in the IBA 1.3 spec/OPA Gen 1

 * spec

 * For addr 000-127, lower page 00h

 * For addr 128-255, upper page 00h

 * For addr 256-383, upper page 01h

 * For addr 384-511, upper page 02h

 * For addr 512-639, upper page 03h

 *

 * For addresses beyond this range, it returns the invalid range of data buffer

 * set to 0.

 * For upper pages that are optional, if they are not valid, returns the

 * particular range of bytes in the data buffer set to 0.

 Overlap with the dynamic channel monitor range */

 Refresh the values of the dynamic monitors from the cable */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2020 - Cornelis Networks, Inc.

 * Copyright(c) 2015 - 2018 Intel Corporation.

 for the headers */

 for struct hfi1_tid_info */

	/*

	 * We are assuming that if the list is enqueued somewhere, it

	 * is to the dmawait list since that is the only place where

	 * it is supposed to be enqueued.

 at this point there can be no more new requests */

 Wait until all requests have been freed. */

/**

 * hfi1_user_sdma_process_request() - Process and start a user sdma request

 * @fd: valid file descriptor

 * @iovec: array of io vectors to process

 * @dim: overall iovec array size

 * @count: number of io vector array entries processed

	/*

	 * Sanity check the header io vector count.  Need at least 1 vector

	 * (header) and cannot be larger than the actual io vector count.

 Try to claim the request. */

	/*

	 * All safety checks have been done and this request has been claimed.

 subtract header vector */

 The request is initialized, count it */

 expected must have a TID info and at least one data vector */

 Copy the header from the user buffer */

 If Static rate control is not enabled, sanitize the header. */

 Validate the opcode. Do not trust packets from user space blindly. */

	/*

	 * Validate the vl. Do not trust packets from user space blindly.

	 * VL comes from PBC, SC comes from LRH, and the VL needs to

	 * match the SC look up.

 Checking P_KEY for requests from user-space */

	/*

	 * Also should check the BTH.lnh. If it says the next header is GRH then

	 * the RXE parsing will be off and will land in the middle of the KDETH

	 * or miss it entirely.

	/*

	 * Calculate the initial TID offset based on the values of

	 * KDETH.OFFSET and KDETH.OM that are passed in.

 Save all the IO vector structures */

	/*

	 * Copy any TID info

	 * User space will provide the TID info only when the

	 * request type is EXPECTED. This is true even if there is

	 * only one packet in the request and the header is already

	 * setup. The reason for the singular TID case is that the

	 * driver needs to perform safety checks.

		/*

		 * We have to copy all of the tids because they may vary

		 * in size and, therefore, the TID count might not be

		 * equal to the pkt count. However, there is no way to

		 * tell at this point.

 We don't need an AHG entry if the request contains only one packet */

	/*

	 * This is a somewhat blocking send implementation.

	 * The driver will block the caller until all packets of the

	 * request have been submitted to the SDMA engine. However, it

	 * will not wait for send completions.

	/*

	 * If the submitted seqsubmitted == npkts, the completion routine

	 * controls the final state.  If sequbmitted < npkts, wait for any

	 * outstanding packets to finish before cleaning up.

	/*

	 * Determine the proper size of the packet data.

	 * The size of the data of the first packet is in the header

	 * template. However, it includes the header and ICRC, which need

	 * to be subtracted.

	 * The minimum representable packet data length in a header is 4 bytes,

	 * therefore, when the data length request is less than 4 bytes, there's

	 * only one packet, and the packet data length is equal to that of the

	 * request data length.

	 * The size of the remaining packets is the minimum of the frag

	 * size (MTU) or remaining data in the request.

		/*

		 * Get the data length based on the remaining space in the

		 * TID pair.

 If we've filled up the TID pair, move to the next one. */

		/*

		 * Since the TID pairs map entire pages, make sure that we

		 * are not going to try to send more data that we have

		 * remaining.

 (Size of complete header - size of PBC) + 4B ICRC + data length */

	/*

	 * Copy the request header into the tx header

	 * because the HW needs a cacheline-aligned

	 * address.

	 * This copy can be optimized out if the hdr

	 * member of user_sdma_request were also

	 * cacheline aligned.

 If tx completion has reported an error, we are done. */

	/*

	 * Check if we might have sent the entire request already

		/*

		 * Check whether any of the completions have come back

		 * with errors. If so, we are not going to process any

		 * more packets from this request.

		/*

		 * For the last packet set the ACK request

		 * and disable header suppression.

		/*

		 * Calculate the payload size - this is min of the fragment

		 * (MTU) size or the remaining bytes in the request but only

		 * if we have payload data.

			/*

			 * Disable header suppression for the payload <= 8DWS.

			 * If there is an uncorrectable error in the receive

			 * data FIFO when the received payload size is less than

			 * or equal to 8DWS then the RxDmaDataFifoRdUncErr is

			 * not reported.There is set RHF.EccErr if the header

			 * is not suppressed.

			/*

			 * Modify the header for this packet. This only needs

			 * to be done if we are not going to use AHG. Otherwise,

			 * the HW will do it based on the changes we gave it

			 * during sdma_txinit_ahg().

		/*

		 * If the request contains any data vectors, add up to

		 * fragsize bytes to the descriptor.

		/*

		 * The txreq was submitted successfully so we can update

		 * the counters.

		/*

		 * It is important to increment this here as it is used to

		 * generate the BTH.PSN and, therefore, can't be bulk-updated

		 * outside of the loop.

		/*

		 * The txreq has already been submitted to the HW queue

		 * so we can free the AHG entry now. Corruption will not

		 * happen due to the sequential manner in which

		 * descriptors are processed.

	/*

	 * Perform safety checks for any type of packet:

	 *    - transfer size is multiple of 64bytes

	 *    - packet length is multiple of 4 bytes

	 *    - packet length is not larger than MTU size

	 *

	 * These checks are only done for the first packet of the

	 * transfer since the header is "given" to us by user space.

	 * For the remainder of the packets we compute the values.

		/*

		 * The header is checked only on the first packet. Furthermore,

		 * we ensure that at least one TID entry is copied when the

		 * request is submitted. Therefore, we don't have to verify that

		 * tididx points to something sane.

		/*

		 * Expected receive packets have the following

		 * additional checks:

		 *     - offset is not larger than the TID size

		 *     - TIDCtrl values match between header and TID array

		 *     - TID indexes match between header and TID array

/*

 * Correctly set the BTH.PSN field based on type of

 * transfer - eager packets can just increment the PSN but

 * expected packets encode generation and sequence in the

 * BTH.PSN field so just incrementing will result in errors.

 KDETH.OM */

 Copy the header template to the request before modification */

	/*

	 * Check if the PBC and LRH length are mismatched. If so

	 * adjust both in the header.

		/*

		 * Third packet

		 * This is the first packet in the sequence that has

		 * a "static" size that can be used for the rest of

		 * the packets (besides the last one).

			/*

			 * From this point on the lengths in both the

			 * PBC and LRH are the same until the last

			 * packet.

			 * Adjust the template so we don't have to update

			 * every packet

	/*

	 * We only have to modify the header if this is not the

	 * first packet in the request. Otherwise, we use the

	 * header given to us.

 Set ACK request on last packet */

 Set the new offset */

 Expected packets have to fill in the new TID information */

		/*

		 * If the offset puts us at the end of the current TID,

		 * advance everything.

			/*

			 * Since we don't copy all the TIDs, all at once,

			 * we have to check again.

 Set KDETH.TIDCtrl based on value for this TID. */

 Set KDETH.TID based on value for this TID */

 Clear KDETH.SH when DISABLE_SH flag is set */

		/*

		 * Set the KDETH.OFFSET and KDETH.OM based on size of

		 * transfer.

 KDETH.OM */

 PBC.PbcLengthDWs */

 LRH.PktLen (we need the full 16 bits due to byte swap) */

	/*

	 * Do the common updates

 BTH.PSN and BTH.A */

 KDETH.Offset */

		/*

		 * If the offset puts us at the end of the current TID,

		 * advance everything.

			/*

			 * Since we don't copy all the TIDs, all at once,

			 * we have to check again.

 KDETH.OM and KDETH.OFFSET (TID) */

 KDETH.TIDCtrl, KDETH.TID, KDETH.Intr, KDETH.SH */

/**

 * user_sdma_txreq_cb() - SDMA tx request completion callback.

 * @txreq: valid sdma tx request

 * @status: success/failure of request

 *

 * Called when the SDMA progress state machine gets notification that

 * the SDMA descriptors for this tx request have been processed by the

 * DMA engine. Called in interrupt context.

 * Only do work on completed sequences.

 sequence isn't complete?  We are done */

 make sure errcode is visible first */

/*

 * Return 1 to remove the node from the rb tree and call the remove op.

 *

 * Called with the rb tree lock held.

 is this node still being used? */

 keep this node */

 this node will be evicted, add its pages to our count */

 have enough pages been cleared? */

 remove this node */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2018 Intel Corporation.

 *

	/*

	 * Exit if the extended bit is not set, or if nothing is requested, or

	 * if we have completed all requests, or if a previous request is in

	 * progress

		/*

		 * Either there is no handler for this capability or the request

		 * packet could not be generated. Either way, mark it as done so

		 * we don't keep attempting to complete it.

 A new request is now in progress */

 Drop opfn.lock before calling ib_post_send() */

	/*

	 * In case of an unexpected error return from ib_post_send

	 * clear opfn.curr and reschedule to try again

/*

 * When QP s_lock is held in the caller, the OPFN request must be scheduled

 * to a different workqueue to avoid double locking QP s_lock in call to

 * ib_post_send in opfn_conn_request

		/*

		 * We are receiving a request for a feature that has already

		 * been negotiated. This may mean that the other side has reset

	/*

	 * Either there is no previous request or the reply is not for the

	 * current request

	/*

	 * Clear opfn.curr to indicate that the previous request is no longer in

	 * progress

	/*

	 * The QP has gone into the Error state. We have to invalidate all

	 * negotiated feature, including the one in progress (if any). The RC

	 * QP handling will clean the WQE for the connection request.

			/*

			 * We only want to set the OPFN requested bit when the

			 * QP transitions to RTS.

				/*

				 * If the QP is transitioning to RTS and the

				 * opfn.completed for TID RDMA has already been

				 * set, the QP is being moved *back* into RTS.

				 * We can now renegotiate the TID RDMA

				 * parameters.

					/*

					 * Since the opfn.completed bit was

					 * already set, it is safe to assume

					 * that the opfn.extended is also set.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2018 Intel Corporation.

/*

 *

 * This should be called with the QP r_lock held.

 *

 * The s_lock will be acquired around the hfi1_migrate_qp() call.

 Validate the SLID. See Ch. 9.6.1.5 and 17.2.8 */

 Validate the SLID. See Ch. 9.6.1.5 */

/**

 * hfi1_make_grh - construct a GRH header

 * @ibp: a pointer to the IB port

 * @hdr: a pointer to the GRH header being constructed

 * @grh: the global route address to send to

 * @hwords: size of header after grh being sent in dwords

 * @nwords: the number of 32 bit words of data being sent

 *

 * Return the size of the header in 32 bit words.

 next_hdr is defined by C8-7 in ch. 8.4.1 */

 The SGID is 32-bit aligned. */

 GRH header size in 32-bit words. */

/**

 * build_ahg - create ahg in s_ahg

 * @qp: a pointer to QP

 * @npsn: the next PSN for the request/response

 *

 * This routine handles the AHG by allocating an ahg entry and causing the

 * copy of the first middle.

 *

 * Subsequent middles use the copied entry, editing the

 * PSN with 1 or 2 edits.

 first middle that needs copy  */

 save to protect a change in another thread */

 subsequent middle after valid */

/**

 * hfi1_make_ruc_header_16B - build a 16B header

 * @qp: the queue pair

 * @ohdr: a pointer to the destination header memory

 * @bth0: bth0 passed in from the RC/UC builder

 * @bth1: bth1 passed in from the RC/UC builder

 * @bth2: bth2 passed in from the RC/UC builder

 * @middle: non zero implies indicates ahg "could" be used

 * @ps: the current packet state

 *

 * This routine may disarm ahg under these situations:

 * - packet needs a GRH

 * - BECN needed

 * - migration state not IB_MIG_MIGRATED

		/*

		 * Ensure OPA GIDs are transformed to IB gids

		 * before creating the GRH.

 we recently received a FECN, so return a BECN */

/**

 * hfi1_make_ruc_header_9B - build a 9B header

 * @qp: the queue pair

 * @ohdr: a pointer to the destination header memory

 * @bth0: bth0 passed in from the RC/UC builder

 * @bth1: bth1 passed in from the RC/UC builder

 * @bth2: bth2 passed in from the RC/UC builder

 * @middle: non zero implies indicates ahg "could" be used

 * @ps: the current packet state

 *

 * This routine may disarm ahg under these situations:

 * - packet needs a GRH

 * - BECN needed

 * - migration state not IB_MIG_MIGRATED

 we recently received a FECN, so return a BECN */

 We support only two types - 9B and 16B for now */

	/*

	 * reset s_ahg/AHG fields

	 *

	 * This insures that the ahgentry/ahgcount

	 * are at a non-AHG default to protect

	 * build_verbs_tx_desc() from using

	 * an include ahgidx.

	 *

	 * build_ahg() will modify as appropriate

	 * to use the AHG feature.

 Make the appropriate header */

 when sending, force a reschedule every one of these periods */

 5s in jiffies */

/**

 * hfi1_schedule_send_yield - test for a yield required for QP

 * send engine

 * @qp: a pointer to QP

 * @ps: a pointer to a structure with commonly lookup values for

 *      the send engine progress

 * @tid: true if it is the tid leg

 *

 * This routine checks if the time slice for the QP has expired

 * for RC QPs, if so an additional work entry is queued. At this

 * point, other QPs have an opportunity to be scheduled. It

 * returns true if a yield is required, otherwise, false

 * is returned.

/**

 * hfi1_do_send - perform a send on a QP

 * @qp: a pointer to the QP

 * @in_thread: true if in a workqueue thread

 *

 * Process entries in the send work queue until credit or queue is

 * exhausted.  Only allow one CPU to send a packet per QP.

 * Otherwise, two threads could send packets out of order.

 Return if we are already busy processing a work request. */

 insure a pre-built packet is handled  */

 Check for a constructed packet to be sent. */

			/*

			 * If the packet cannot be sent now, return and

			 * the send engine will be woken up later.

 allow other tasks to run */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2018 - 2020 Intel Corporation.

/**

 * msix_initialize() - Calculate, request and configure MSIx IRQs

 * @dd: valid hfi1 devdata

 *

	/*

	 * MSIx interrupt count:

	 *	one for the general, "slow path" interrupt

	 *	one per used SDMA engine

	 *	one per kernel receive context

	 *	one for each VNIC context

	 *      ...any new IRQs should be added here.

/**

 * msix_request_irq() - Allocate a free MSIx IRQ

 * @dd: valid devdata

 * @arg: context information for the IRQ

 * @handler: IRQ handler

 * @thread: IRQ thread handler (could be NULL)

 * @type: affinty IRQ type

 * @name: IRQ name

 *

 * Allocated an MSIx vector if available, and then create the appropriate

 * meta data needed to keep track of the pci IRQ request.

 *

 * Return:

 *   < 0   Error

 *   >= 0  MSIx vector

 *

 Allocate an MSIx vector */

	/*

	 * assign arg after pci_request_irq call, so it will be

	 * cleaned up

 This is a request, so a failure is not fatal */

	/*

	 * Set the interrupt register and mask for this

	 * context's interrupt.

/**

 * msix_request_rcd_irq() - Helper function for RCVAVAIL IRQs

 * @rcd: valid rcd context

 *

/**

 * msix_netdev_request_rcd_irq  - Helper function for RCVAVAIL IRQs

 * for netdev context

 * @rcd: valid netdev contexti

/**

 * msix_request_sdma_irq  - Helper for getting SDMA IRQ resources

 * @sde: valid sdma engine

 *

/**

 * msix_request_general_irq - Helper for getting general IRQ

 * resources

 * @dd: valid device data

 general interrupt must be MSIx vector 0 */

/**

 * enable_sdma_srcs - Helper to enable SDMA IRQ srcs

 * @dd: valid devdata structure

 * @i: index of SDMA engine

/**

 * msix_request_irqs() - Allocate all MSIx IRQs

 * @dd: valid devdata structure

 *

 * Helper function to request the used MSIx IRQs.

 *

/**

 * msix_free_irq() - Free the specified MSIx resources and IRQ

 * @dd: valid devdata

 * @msix_intr: MSIx vector to free.

 *

 => no irq, no affinity */

/**

 * msix_clean_up_interrupts  - Free all MSIx IRQ resources

 * @dd: valid device data data structure

 *

 * Free the MSIx and associated PCI resources, if they have been allocated.

 remove irqs - must happen before disabling/turning off */

 clean structures */

/**

 * msix_netdev_synchronize_irq - netdev IRQ synchronize

 * @dd: valid devdata

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015, 2016 Intel Corporation.

 GUID for HFI1 variables in EFI */

 largest EFI data size we expect */

/*

 * Read the named EFI variable.  Return the size of the actual data in *size

 * and a kmalloc'ed buffer in *return_data.  The caller must free the

 * data.  It is guaranteed that *return_data will be NULL and *size = 0

 * if this routine fails.

 *

 * Return 0 on success, -errno on failure.

 set failure return values */

 input: the size of the buffer */

 convert ASCII to unicode - it is a 1:1 mapping */

 need a variable for our GUID */

 call into EFI runtime services */

	/*

	 * It would be nice to call efi_status_to_err() here, but that

	 * is in the EFIVAR_FS code and may not be compiled in.

	 * However, even that is insufficient since it does not cover

	 * EFI_BUFFER_TOO_SMALL which could be an important return.

	 * For now, just split out succces or not found.

	/*

	 * We have successfully read the EFI variable into our

	 * temporary buffer.  Now allocate a correctly sized

	 * buffer.

/*

 * Read an HFI1 EFI variable of the form:

 *	<PCIe address>-<kind>

 * Return an kalloc'ed array and size of the data.

 *

 * Returns 0 on success, -errno on failure.

 create a common prefix */

	/*

	 * If reading the lowercase EFI variable fail, read the uppercase

	 * variable.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015-2017 Intel Corporation.

/*

 * Determine whether the caller can pin pages.

 *

 * This function should be used in the implementation of buffer caches.

 * The cache implementation should call this function prior to attempting

 * to pin buffer pages in order to determine whether they should do so.

 * The function computes cache limits based on the configured ulimit and

 * cache size. Use of this function is especially important for caches

 * which are not limited in any other way (e.g. by HW resources) and, thus,

 * could keeping caching buffers.

 *

 convert to bytes */

	/*

	 * Calculate per-cache size. The calculation below uses only a quarter

	 * of the available per-context limit. This leaves space for other

	 * pinning. Should we worry about shared ctxts?

 If ulimit isn't set to "unlimited" and is smaller than cache_size. */

 Convert to number of pages */

 First, check the absolute limit against all pinned pages. */

 during close after signal, mm can be NULL */

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2020 Intel Corporation.

 No BTH */

 imm */

 reth + imm */

 reth */

 aeth */

 aeth */

 aeth */

 aeth + atomicacketh */

 atomiceth */

 deth */

 ieth */

 SPDX-License-Identifier: (GPL-2.0 OR BSD-3-Clause)

/*

 * Copyright(c) 2020 Intel Corporation.

 *

/*

 * This file contains HFI1 support for IPOIB SDMA functionality

 Add a convenience helper */

 If shutting down just return as queue state is irrelevant */

	/*

	 * When the queue has been drained to less than half full it will be

	 * restarted.

	 * The size of the txreq ring is fixed at initialization.

	 * The tx queue len can be adjusted upward while the interface is

	 * running.

	 * The tx queue len can be large enough to overflow the txreq_ring.

	 * Use the minimum of the current tx_queue_len or the rings max txreqs

	 * to protect against ring overflow.

 See hfi1_ipoib_sdma_complete() */

 Finished freeing tx items so store the head value. */

 see hfi1_ipoib_poll_tx_ring */

 add pbc + headers */

 add the ulp payload */

 Includes ICRC */

 header size in dwords LRH+BTH+DETH = (8+12+8)/4. */

 Includes ICRC */

 Build the lrh */

 Build the bth */

 Build the deth */

 Construct the pbc. */

 This shouldn't happen with a stopped queue */

 See hfi1_ipoib_poll_tx_ring() */

 so that we can test if the sdma descriptors are there */

 Flush the current list */

 consume tx */

 mark complete and kick napi tx */

 Has the flow change ? */

 consume tx */

/*

 * hfi1_ipoib_sdma_sleep - ipoib sdma sleep function

 *

 * This function gets called from sdma_send_txreq() when there are not enough

 * sdma descriptors available to send the packet. It adds Tx queue's wait

 * structure to sdma engine's dmawait list to be woken up when descriptors

 * become available.

 came from non-list submit */

/*

 * hfi1_ipoib_sdma_wakeup - ipoib sdma wakeup function

 *

 * This function gets called when SDMA descriptors becomes available and Tx

 * queue's wait structure was previously added to sdma engine's dmawait list.

	/*

	 * Ring holds 1 less than tx_ring_size

	 * Round up to next power of 2 in order to hold at least tx_queue_len

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015-2018 Intel Corporation.

 the reset value from the FM is supposed to be 0xffff, handle both */

	/*

	 * The verbs framework will handle the directed/LID route

	 * packet changes.

/*

 * If the port is down, clean up all pending traps.  We need to be careful

 * with the given trap, because it may be queued.

		/*

		 * Remove all items from the list, freeing all the non-given

		 * traps.

	/*

	 * If this wasn't on one of the lists it would not be freed.  If it

	 * was on the list, it is now safe to free.

	/*

	 * Since the retry (handle timeout) does not remove a trap request

	 * from the list, all we have to do is compare the node.

 If it is not on the list, add it, limited to RVT-MAX_TRAP_LEN. */

	/*

	 * Next check to see if there is a timer pending.  If not, set it up

	 * and get the first trap from the list.

		/*

		 * o14-2

		 * If the time out is set we have to wait until it expires

		 * before the trap can be sent.

		 * This should be > RVT_TRAP_TIMEOUT

 o14-3.2.1 */

 Add the trap to the list if necessary and see if we can send it */

 Only update the transaction ID for new traps (o13-5). */

 make sure that tid != 0 */

 o14-1: smp->mkey = 0; */

	/*

	 * If the trap was repressed while things were getting set up, don't

	 * bother sending it. This could happen for a retry.

 Find the trap with the highest priority */

/*

 * Send a bad P_Key trap (ch. 14.3.8).

 Send violation trap */

/*

 * Send a bad M_Key trap (ch. 14.3.9).

 Send violation trap */

/*

 * Send a Port Capability Mask Changed trap (ch. 14.3.11).

/*

 * Send a System Image GUID Changed trap (ch. 14.3.12).

/*

 * Send a Node Description Changed trap (ch. 14.3.13).

 IB number port from 1, hw from 0 */

 GUID 0 is illegal */

 channel adapter */

 This is already in network order */

 IB number port from 1, hw from 0 */

 GUID 0 is illegal */

 channel adapter */

 This is already in network order */

 Is the mkey in the process of expiring? */

 Clear timeout and mkey protection field. */

 Unset lease timeout on any valid Get/Set/TrapRepress */

 Bad mkey not a violation below level 2 */

 Generate a trap notice. */

/*

 * The SMA caches reads from LCB registers in case the LCB is unavailable.

 * (The LCB is unavailable in certain link states, for example.)

 IB numbers ports from 1, hw from 0 */

 Only return the mkey if the protection field allows it. */

	/*

	 * This pairs with the memory barrier in hfi1_start_led_override to

	 * ensure that we read the correct state of LED beaconing represented

	 * by led_override_timer_active

 don't forget VL 15 */

 P_KeyViolations are counted by hardware. */

	/* flit_control.interleave is (OPA V1, version .76):

	 * bits		use

	 * ----		---

	 * 2		res

	 * 2		DistanceSupported

	 * 2		DistanceEnabled

	 * 5		MaxNextLevelTxEnabled

	 * 5		MaxNestLevelRxSupported

	 *

	 * HFI supports only "distance mode 1" (see OPA V1, version .76,

	 * section 9.6.2), so set DistanceSupported, DistanceEnabled

	 * to 0x1.

 32.768 usec. response time (guessing) */

 buffer info for FM */

	/* HFIs shall always return VL15 credits to their

	 * neighbor in a timely manner, without any credit return pacing.

 HFI supports a replay buffer 128 LTPs in size */

 read the cached value of DC_LCB_STS_ROUND_TRIP_LTP_CNT */

	/*

	 * this counter is 16 bits wide, but the replay_depth.wire

	 * variable is only 8 bits

/**

 * get_pkeys - return the PKEY table

 * @dd: the hfi1_ib device

 * @port: the IB port number

 * @pkeys: the pkey table is placed here

 get the real pkeys if we are requesting the first block */

/*

 * Use shortened names to improve readability of

 * {logical,physical}_state_transitions

/*

 * IB_PORTPHYSSTATE_POLLING (2) through OPA_PORTPHYSSTATE_MAX (11) are

 * represented in physical_state_transitions.

/*

 * Within physical_state_transitions, rows represent "old" states,

 * columns "new" states, and physical_state_transitions.allowed[old][new]

 * indicates if the transition from old state to new state is legal (see

 * OPAg1v1, Table 6-4).

 2    3    4    5    6    7    8    9   10   11 */

 2 */	{ __A, __A, __D, __D, __D, __D, __D, __D, __D, __D },

 3 */	{ __A, __I, __D, __D, __D, __D, __D, __D, __D, __A },

 4 */	{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },

 5 */	{ __A, __A, __D, __I, __D, __D, __D, __D, __D, __D },

 6 */	{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },

 7 */	{ __D, __A, __D, __D, __D, __I, __D, __D, __D, __D },

 8 */	{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },

 9 */	{ __I, __A, __D, __D, __D, __D, __D, __I, __D, __D },

10 */	{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },

11 */	{ __D, __A, __D, __D, __D, __D, __D, __D, __D, __I },

/*

 * IB_PORT_DOWN (1) through IB_PORT_ACTIVE_DEFER (5) are represented

 * logical_state_transitions

/*

 * Within logical_state_transitions rows represent "old" states,

 * columns "new" states, and logical_state_transitions.allowed[old][new]

 * indicates if the transition from old state to new state is legal (see

 * OPAg1v1, Table 9-12).

 1    2    3    4    5 */

 1 */	{ __I, __D, __D, __D, __U},

 2 */	{ __D, __I, __A, __D, __U},

 3 */	{ __D, __D, __I, __A, __U},

 4 */	{ __D, __D, __I, __I, __U},

 5 */	{ __U, __U, __U, __U, __U},

 always allowed */

 adjust states for indexing into logical_state_transitions */

 always allowed */

 adjust states for indexing into physical_state_transitions */

	/*

	 * A change request of Physical Port State from

	 * 'Offline' to 'Polling' should be ignored.

	/*

	 * Either physical_allowed or logical_allowed is

	 * HFI_TRANSITION_ALLOWED.

 error message emitted above */

	/*

	 * Logical state changes are summarized in OPAv1g1 spec.,

	 * Table 9-12; physical state changes are summarized in

	 * OPAv1g1 spec., Table 6.4.

			/*

			 * Going to poll.  No matter what the current state,

			 * always move offline first, then tune and start the

			 * link.  This correctly handles a FM link bounce and

			 * a link enable.  Going offline is a no-op if already

			 * offline.

		/*

		 * Don't send a reply if the response would be sent

		 * through the disabled port.

/*

 * subn_set_opa_portinfo - set port information

 * @smp: the incoming SM packet

 * @ibdev: the infiniband device

 * @port: the port on the device

 *

 IB numbers ports from 1, hw from 0 */

 Must be a valid unicast LID address. */

			/* Manufacture GID from LID to support extended

			 * addresses

 Must be a valid unicast LID address. */

 LWD.E is always applied - 0 means "disabled" */

 only set and apply if something changed */

 use a valid MTU */

	/* As per OPAV1 spec: VL15 must support and be configured

	 * for operation with a 2048 or larger MTU.

 Set operational VLs */

 Handle CLIENT_REREGISTER event b/c SM asked us for it */

	/*

	 * Do the port state change now that the other link parameters

	 * have been set.

	 * Changing the port physical state only makes sense if the link

	 * is down or is being set to down.

 restore re-reg bit per o14-12.2.1 */

	/*

	 * Apply the new link downgrade policy.  This may result in a link

	 * bounce.  Do this after everything else so things are settled.

	 * Possible problem: if setting the port state above fails, then

	 * the policy change is not applied.

/**

 * set_pkeys - set the PKEY table for ctxt 0

 * @dd: the hfi1_ib device

 * @port: the IB port number

 * @pkeys: the PKEY table

	/*

	 * IB port one/two always maps to context zero/one,

	 * always a kernel context, no locking needed

	 * If we get here with ppd setup, no need to check

	 * that rcd is valid.

	/*

	 * If the update does not include the management pkey, don't do it.

		/*

		 * The SM gives us the complete PKey table. We have

		 * to ensure that we put the PKeys in the matching

		 * slots.

/*

 * filter_sc2vlt changes mappings to VL15 to ILLEGAL_VL (except

 * for SC15, which must map to VL15). If we don't remap things this

 * way it is possible for VL15 counters to increment when we try to

 * send on a SC which is mapped to an invalid VL.

 * When getting the table convert ILLEGAL_VL back to VL15.

 == 32 */

 Put all stale qps into error state */

 == 32 */

	/*

	 * set_sc2vlt_tables writes the information contained in *data

	 * to four 64-bit registers SendSC2VLt[0-3]. We need to make

	 * sure *max_len is not greater than the total size of the four

	 * SendSC2VLt[0-3] registers.

 IB numbers ports from 1, hw from 0 */

	/*

	 * it's known that async_update is 0 by this point, but include

	 * the explicit check for clarity

 IB numbers ports from 1, hw from 0 */

 128 bytes */

	/*

	 * check that addr is within spec, and

	 * addr and (addr + len - 1) are on the same "page"

	/* The address range for the CableInfo SMA query is wider than the

	 * memory available on the QSFP cable. We want to return a valid

	 * response, albeit zeroed out, for address ranges beyond available

	 * memory but that are within the CableInfo query spec

	/*

	 * neither OPA_VLARB_PREEMPT_ELEMENTS, or OPA_VLARB_PREEMPT_MATRIX

	 * can be changed from the default values

 Data counters */

 Error counters */

 5res, 3bit */

 per-VL Data counters */

 real array size defined by # bits set in vl_select_mask */

 1 bit, 8 res, 7 bit */

 Request contains first three fields, response contains those plus the rest */

 Response fields follow */

 29res, 3bit */

 Data counters */

 Sum of error counts/port */

 per-VL Data counters */

 array size defined by #bits set in vl_select_mask*/

 array size defined by  #ports in attribute modifier */

	/*

	 * Request contains first two fields, response contains the

	 * whole magilla

 Response-only fields follow */

 array size defined by #bits set in vl_select_mask */

 array size defined by #ports in attribute modifier */

 PortRcvErrorInfo */

 EI1to12 format */

 ExcessiveBufferOverrunInfo */

 PortXmitConstraintErrorInfo */

 PortRcvConstraintErrorInfo */

 PortRcvSwitchRelayErrorInfo */

 UncorrectableErrorInfo */

 FMConfigErrorInfo */

 actual array size defined by #ports in attr modifier */

 opa_port_error_info_msg error_info_select_mask bit definitions */

	/*

	 * Expected response time is 4.096 usec. * 2^18 == 1.073741824 sec.

 we wrapped */

/**

 * tx_link_width - convert link width bitmask to integer

 * value representing actual link width.

 * @link_width: width of active link

 * @return: return index of the bit set in link_width var

 *

 * The function convert and return the index of bit set

 * that indicate the current link width.

/**

 * get_xmit_wait_counters - Convert HFI 's SendWaitCnt/SendWaitVlCnt

 * counter in unit of TXE cycle times to flit times.

 * @ppd: info of physical Hfi port

 * @link_width: width of active link

 * @link_speed: speed of active link

 * @vl: represent VL0-VL7, VL15 for PortVLXmitWait counters request

 * and if vl value is C_VL_COUNT, it represent SendWaitCnt

 * counter request

 * @return: return SendWaitCnt/SendWaitVlCnt counter value per vl.

 *

 * Convert SendWaitCnt/SendWaitVlCnt counter from TXE cycle times to

 * flit times. Call this function to samples these counters. This

 * function will calculate for previous state transition and update

 * current state at end of function using ppd->prev_link_width and

 * ppd->port_vl_xmit_wait_last to port_vl_xmit_wait_curr and link_width.

	/*

	 * Convert PortXmitWait counter from TXE cycle times

	 * to flit times.

 overflow/wrapped */

 rsp->uncorrectable_errors is 8 bits wide, and it pegs at 0xff */

	/* The vl_select_mask has been checked above, and we know

	 * that it contains only entries which represent valid VLs.

	 * So in the for_each_set_bit() loop below, we don't need

	 * any additional checks for vl.

		/*

		 * Convert PortVlXmitWait counter from TXE cycle

		 * times to flit times.

 port_rcv_switch_relay_errors is 0 for HFIs */

 local link integrity must be right-shifted by the lli resolution */

 link error recovery must b right-shifted by the ler resolution */

 ppd->link_downed is a 32-bit value */

 this is an 8-bit quantity */

 we wrapped */

 Sanity check */

	/*

	 * The bit set in the mask needs to be consistent with the

	 * port the request came in on.

	/*

	 * Note that link_quality_indicator is a 32 bit quantity in

	 * 'datacounters' queries (as opposed to 'portinfo' queries,

	 * where it's a byte).

	/*

	 * Convert PortXmitWait counter from TXE

	 * cycle times to flit times.

	/* The vl_select_mask has been checked above, and we know

	 * that it contains only entries which represent valid VLs.

	 * So in the for_each_set_bit() loop below, we don't need

	 * any additional checks for vl.

		/*

		 * Convert PortVlXmitWait counter from TXE

		 * cycle times to flit times.

 rsp->port_vl_xmit_time_cong is 0 for HFIs */

 rsp->port_vl_xmit_wasted_bw ??? */

		/* port_vl_xmit_wait_data - TXE (table 13-9 HFI spec) ???

		 * does this differ from rsp->vls[vfi].port_vl_xmit_wait

		/*rsp->vls[vfi].port_vl_mark_fecn =

		 *	cpu_to_be64(read_csr(dd, DCC_PRF_PORT_VL_MARK_FECN_CNT

		 *		+ offset));

 overflow/wrapped */

	/*

	 * The bit set in the mask needs to be consistent with the

	 * port the request came in on.

 N/A for OPA */

 LocalLink: 7:4, BufferOverrun: 3:0 */

 N/A for OPA */

 Sanity check */

	/*

	 * The bit set in the mask needs to be consistent with the port

	 * the request came in on.

 PortRcvErrorInfo */

 ExcessiverBufferOverrunInfo */

		/*

		 * if the RcvExcessBufferOverrun bit is set, save SC of

		 * first pkt that encountered an excess buffer overrun

 set the status bit */

 UncorrectableErrorInfo */

 FMConfigErrorInfo */

 clear all per-vl cnts */

	/*

	 * only counters returned by pma_get_opa_portstatus() are

	 * handled, so when pma_get_opa_portstatus() gets a fix,

	 * the corresponding change should be made here as well.

 ignore cs_sw_portCongestion for HFIs */

 ignore cs_port_xmit_time_cong for HFIs */

 ignore cs_port_xmit_wasted_bw for now */

 ignore cs_port_xmit_wait_data for now */

 Only applicable for switch */

	/* if (counter_select & CS_PORT_MARK_FECN)

	 *	write_csr(dd, DCC_PRF_PORT_MARK_FECN_CNT, 0);

 ignore cs_port_rcv_switch_relay_errors for HFIs */

 sw_port_vl_congestion is 0 for HFIs */

 port_vl_xmit_time_cong is 0 for HFIs */

 port_vl_xmit_wasted_bw ??? */

 port_vl_xmit_wait_data - TXE (table 13-9 HFI spec) ??? */

		/* if (counter_select & CS_PORT_MARK_FECN)

		 *     write_csr(dd, DCC_PRF_PORT_VL_MARK_FECN_CNT + offset, 0);

	/*

	 * The bit set in the mask needs to be consistent with the port

	 * the request came in on.

 PortRcvErrorInfo */

 turn off status bit */

 ExcessiverBufferOverrunInfo */

		/*

		 * status bit is essentially kept in the h/w - bit 5 of

		 * RCV_ERR_INFO

 UncorrectableErrorInfo */

 turn off status bit */

 FMConfigErrorInfo */

 turn off status bit */

 Multiple of 64 entry unit CCTs */

/*

 * Apply congestion control information stored in the ppd to the

 * active structure.

	/*

	 * Hold the lock for updating *and* to prevent ppd information

	 * from changing during the update.

 never active, or shutting down */

	/*

	 * Save details from packet into the ppd.  Hold the cc_state_lock so

	 * our information is consistent with anyone trying to apply the state.

 now apply the information */

 keep timestamp in units of 1.024 usec */

		/*

		 * Entries which are older than twice the time

		 * required to wrap the counter are supposed to

		 * be zeroed (CA10-49 IBTA, release 1.2.1, V1).

	/*

	 * Reset threshold_cong_event_map, and threshold_event_counter

	 * to 0 when log is read.

 sanity check n_blocks, start_block */

 return n_blocks, though the last block may not be full */

 sanity check n_blocks, start_block */

 sanity check ccti_limit */

	/*

	 * Save details from packet into the ppd.  Hold the cc_state_lock so

	 * our information is consistent with anyone trying to apply the state.

 now apply the information */

	/*

	 * This pairs with the memory barrier in hfi1_start_led_override to

	 * ensure that we read the correct state of LED beaconing represented

	 * by led_override_timer_active

 zero the payload for this segment */

/*

 * OPAv1 specifies that, on the transition to link up, these counters

 * are cleared:

 *   PortRcvErrors [*]

 *   LinkErrorRecovery

 *   LocalLinkIntegrityErrors

 *   ExcessiveBufferOverruns [*]

 *

 * [*] Error info associated with these counters is retained, but the

 * error info status is reset to 0.

 PortRcvErrors */

 LinkErrorRecovery */

 LocalLinkIntegrityErrors */

 ExcessiveBufferOverruns */

/*

 * is_local_mad() returns 1 if 'mad' is sent from, and destined to the

 * local node, 0 otherwise.

/*

 * opa_local_smp_check() should only be called on MADs for which

 * is_local_mad() returns true. It applies the SMP checks that are

 * specific to SMPs which are sent from, and destined to this node.

 * opa_local_smp_check() returns 0 if the SMP passes its checks, 1

 * otherwise.

 *

 * SMPs which arrive from other nodes are instead checked by

 * opa_smp_check().

	/*

	 * We need to do the "node-local" checks specified in OPAv1,

	 * rev 0.90, section 9.10.26, which are:

	 *   - pkey is 0x7fff, or 0xffff

	 *   - Source QPN == 0 || Destination QPN == 0

	 *   - the MAD header's management class is either

	 *     IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE or

	 *     IB_MGMT_CLASS_SUBN_LID_ROUTED

	 *   - SLID != 0

	 *

	 * However, we know (and so don't need to check again) that,

	 * for local SMPs, the MAD stack passes MADs with:

	 *   - Source QPN of 0

	 *   - MAD mgmt_class is IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE

	 *   - SLID is either: OPA_LID_PERMISSIVE (0xFFFFFFFF), or

	 *     our own port's lid

	 *

/**

 * hfi1_pkey_validation_pma - It validates PKEYs for incoming PMA MAD packets.

 * @ibp: IB port data

 * @in_mad: MAD packet with header and data

 * @in_wc: Work completion data such as source LID, port number, etc.

 *

 * These are all the possible logic rules for validating a pkey:

 *

 * a) If pkey neither FULL_MGMT_P_KEY nor LIM_MGMT_P_KEY,

 *    and NOT self-originated packet:

 *     Drop MAD packet as it should always be part of the

 *     management partition unless it's a self-originated packet.

 *

 * b) If pkey_index -> FULL_MGMT_P_KEY, and LIM_MGMT_P_KEY in pkey table:

 *     The packet is coming from a management node and the receiving node

 *     is also a management node, so it is safe for the packet to go through.

 *

 * c) If pkey_index -> FULL_MGMT_P_KEY, and LIM_MGMT_P_KEY is NOT in pkey table:

 *     Drop the packet as LIM_MGMT_P_KEY should always be in the pkey table.

 *     It could be an FM misconfiguration.

 *

 * d) If pkey_index -> LIM_MGMT_P_KEY and FULL_MGMT_P_KEY is NOT in pkey table:

 *     It is safe for the packet to go through since a non-management node is

 *     talking to another non-management node.

 *

 * e) If pkey_index -> LIM_MGMT_P_KEY and FULL_MGMT_P_KEY in pkey table:

 *     Drop the packet because a non-management node is talking to a

 *     management node, and it could be an attack.

 *

 * For the implementation, these rules can be simplied to only checking

 * for (a) and (e). There's no need to check for rule (b) as

 * the packet doesn't need to be dropped. Rule (c) is not possible in

 * the driver as LIM_MGMT_P_KEY is always in the pkey table.

 *

 * Return:

 * 0 - pkey is okay, -EINVAL it's a bad pkey

 Rule (a) from above */

 Rule (e) from above */

		/*

		 * If this is a get/set portinfo, we already check the

		 * M_Key if the MAD is for another port and the M_Key

		 * is OK on the receiving port. This check is needed

		 * to increment the error counters when the M_Key

		 * fails to match on *both* ports.

		/*

		 * The ib_mad module will call us to process responses

		 * before checking for other consumers.

		 * Just tell the caller to process it normally.

 Always successful */

		/*

		 * If this is a get/set portinfo, we already check the

		 * M_Key if the MAD is for another port and the M_Key

		 * is OK on the receiving port. This check is needed

		 * to increment the error counters when the M_Key

		 * fails to match on *both* ports.

		/*

		 * The ib_mad module will call us to process responses

		 * before checking for other consumers.

		 * Just tell the caller to process it normally.

		/*

		 * The ib_mad module will call us to process responses

		 * before checking for other consumers.

		 * Just tell the caller to process it normally.

/**

 * hfi1_process_mad - process an incoming MAD packet

 * @ibdev: the infiniband device this packet came in on

 * @mad_flags: MAD flags

 * @port: the port number this packet came in on

 * @in_wc: the work completion entry for this packet

 * @in_grh: the global route header for this packet

 * @in_mad: the incoming MAD

 * @out_mad: any outgoing MAD reply

 * @out_mad_size: size of the outgoing MAD reply

 * @out_mad_pkey_index: used to apss back the packet key index

 *

 * Returns IB_MAD_RESULT_SUCCESS if this is a MAD that we are not

 * interested in processing.

 *

 * Note that the verbs framework has already done the MAD sanity checks,

 * and hop count/pointer updating for IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE

 * MADs.

 *

 * This is called by the ib_mad module.

 SPDX-License-Identifier: GPL-2.0 or BSD-3-Clause

/*

 * Copyright(c) 2015 - 2019 Intel Corporation.

/*

 * This file contains PCIe utility routines.

/*

 * Do all the common PCIe setup and initialization.

		/*

		 * This can happen (in theory) iff:

		 * We did a chip reset, and then failed to reprogram the

		 * BAR, or the chip reset due to an internal error.  We then

		 * unloaded the driver and reloaded it.

		 *

		 * Both reset cases set the BAR back to initial state.  For

		 * the latter case, the AER sticky error bit at offset 0x718

		 * should be set, but the Linux kernel doesn't yet know

		 * about that, it appears.  If the original BAR was retained

		 * in the kernel data structures, this may be OK.

		/*

		 * If the 64 bit setup fails, try 32 bit.  Some systems

		 * do not setup 64 bit maps on systems with 2GB or less

		 * memory installed.

/*

 * Clean what was done in hfi1_pcie_init()

	/*

	 * Release regions should be called after the disable. OK to

	 * call if request regions has not been called or failed.

/*

 * Do remaining PCIe setup, once dd is allocated, and save away

 * fields required to re-initialize after a chip reset, or for

 * various other purposes

	/*

	 * The TXE PIO buffers are at the tail end of the chip space.

	 * Cut them off and map them separately.

 sanity check vs expectations */

 verify that reads actually work, save revision for reset check */

 used for io_remap, etc. */

	/*

	 * Map the chip's RcvArray as write-combining to allow us

	 * to write an entire cacheline worth of entries in one shot.

 chip.c CSR routines now work */

/*

 * Do PCIe cleanup related to dd, after chip-specific cleanup, etc.  Just prior

 * to releasing the dd memory.

 * Void because all of the core pcie cleanup functions are void.

 return the PCIe link speed from the given link status */

 not defined, assume Gen1 */

 Gen 1, 2.5GHz */

 Gen 2, 5GHz */

 Gen 3, 8GHz */

 return the PCIe link speed from the given link status */

 read the link status and set dd->{lbus_width,lbus_speed,lbus_info} */

/*

 * Read in the current PCIe link width and speed.  Find if the link is

 * Gen3 capable.

 find if our max speed is Gen3 and parent supports Gen3 speeds */

	/*

	 * bus->max_bus_speed is set from the bridge's linkcap Max Link Speed

 obtain the link width and current speed */

/*

 * Restore command and BARs after a reset has wiped them out

 *

 * Returns 0 on success, otherwise a negative error value

/*

 * Save BARs and command to rewrite after device reset

 *

 * Returns 0 on success, otherwise a negative error value

/*

 * BIOS may not set PCIe bus-utilization parameters for best performance.

 * Check and optionally adjust them to maximize our throughput.

/**

 * tune_pcie_caps() - Code to adjust PCIe capabilities.

 * @dd: Valid device data structure

 *

	/*

	 * Turn on extended tags in DevCtl in case the BIOS has turned it off

	 * to improve WFR SDMA bandwidth

 Find out supported and configured values for parent (root) */

	/*

	 * The driver cannot perform the tuning if it does not have

	 * access to the upstream component.

 Find out supported and configured values for endpoint (us) */

 Find max payload supported by root, endpoint */

 If Supported greater than limit in module param, limit it */

 If less than (allowed, supported), bump root payload */

 If less than (allowed, supported), bump endpoint payload */

	/*

	 * Now the Read Request size.

	 * No field for max supported, but PCIe spec limits it to 4096,

	 * which is code '5' (log2(4096) - 7)

 End of PCIe capability tuning */

/*

 * From here through hfi1_pci_err_handler definition is invoked via

 * PCI error infrastructure, registered via pci

 no more register accesses! */

 else early, or other problem */

 shouldn't happen */

	/*

	 * Running jobs will fail, since it's asynchronous

	 * unlike sysfs-requested reset.   Better than

	 * doing nothing.

 same as re-init after reset */

============================================================================*/

 PCIe Gen3 support */

/*

 * This code is separated out because it is expected to be removed in the

 * final shipping product.  If not, then it will be revisited and items

 * will be moved to more standard locations.

 ASIC_PCI_SD_HOST_STATUS.FW_DNLD_STS field values */

 hfi0 firmware download complete */

 hfi1 firmware download complete */

 hfi0 and hfi1 firmware download complete */

 ASIC_PCI_SD_HOST_STATUS.FW_DNLD_ERR field values */

 no error */

 parity error in SerDes interrupt */

   or response data */

 hfi disabled */

 security check failed */

 SBus status error */

 parity error during ROM transfer*/

 gasket block secondary bus reset delay */

 200ms */

 discrete HFI */

 MCP HFI */

 discrete on, integrated on */

 equalization columns */

 discrete silicon preliminary equalization values */

 prec   attn   post */

 p0 */

 p1 */

 p2 */

 p3 */

 p4 */

 p5 */

 p6 */

 p7 */

 p8 */

 p9 */

 p10 */

 integrated silicon preliminary equalization values */

 prec   attn   post */

 p0 */

 p1 */

 p2 */

 p3 */

 p4 */

 p5 */

 p6 */

 p7 */

 p8 */

 p9 */

 p10 */

 DC     LF     HF     BW */

 p0 */

 p1 */

 p2 */

 p3 */

 p4 */

 p5 */

 p6 */

 p7 */

 p8 */

 p9 */

 p10 */

 DC     LF     HF     BW */

 p0 */

 p1 */

 p2 */

 p3 */

 p4 */

 p5 */

 p6 */

 p7 */

 p8 */

 p9 */

 p10 */

 helper to format the value to write to hardware */

/*

 * Load the given EQ preset table into the PCIe hardware.

 set index */

 write the value */

 check if these coefficients violate EQ rules */

/*

 * Steps to be done after the PCIe firmware is downloaded and

 * before the SBR for the Pcie Gen3.

 * The SBus resource is already being held.

	/*

	 * Write to the PCIe PCSes to set the G3_LOCKED_NEXT bits to 1.

	 * This avoids a spurious framing error that can otherwise be

	 * generated by the MAC layer.

	 *

	 * Use individual addresses since no broadcast is set up.

/*

 * Trigger a secondary bus reset (SBR) on ourselves using our parent.

 *

 * Based on pci_parent_bus_reset() which is not exported by the

 * kernel core.

 need a parent */

 should not be anyone else on the bus */

	/*

	 * This is an end around to do an SBR during probe time. A new API needs

	 * to be implemented to have cleaner interface but this fixes the

	 * current brokenness

/*

 * Write the given gasket interrupt register.

/*

 * Tell the gasket logic how to react to the reset.

 read back to push the write */

/*

 * CCE_PCIE_CTRL long name helpers

 * We redefine these shorter macros to use in the code while leaving

 * chip_registers.h to be autogenerated from the hardware spec.

 /*

  * Write xmt_margin for full-swing (WFR-B) or half-swing (WFR-C).

	/*

	 * For Discrete, use full-swing.

	 *  - PCIe TX defaults to full-swing.

	 *    Leave this register as default.

	 * For Integrated, use half-swing

	 *  - Copy xmt_margin and xmt_margin_oe

	 *    from Gen1/Gen2 to Gen3.

 integrated */

 extract initial fields */

		/*

		 * For A0, EFUSE values are not set.  Override with the

		 * correct values.

			/*

			 * xmt_margin and OverwiteEnabel should be the

			 * same for Gen1/Gen2 and Gen3

 Delay 240ns. */

 Set to 1 lane. */

 overwrite existing values */

/*

 * Do all the steps needed to transition the PCIe link to Gen3 speed.

 PCIe Gen3 is for the ASIC only */

 target Gen1 */

 target Gen2 */

 target Gen3 */

 off or invalid target - skip */

 if already at target speed, done (unless forced) */

	/*

	 * The driver cannot do the transition if it has no access to the

	 * upstream component

 Previous Gen1/Gen2 bus width */

	/*

	 * Do the Gen3 transition.  Steps are those of the PCIe Gen3

	 * recipe.

 step 1: pcie link working in gen1/gen2 */

 step 2: if either side is not capable of Gen3, done */

 hold the SBus resource across the firmware download and SBR */

 make sure thermal polling is not causing interrupts */

 the SBus download will reset the spico for thermal */

 step 3: download SBus Master firmware */

 step 4: download PCIe Gen3 SerDes firmware */

 do not proceed if the firmware cannot be downloaded */

 step 5: set up device parameter settings */

	/*

	 * PcieCfgSpcie1 - Link Control 3

	 * Leave at reset value.  No need to set PerfEq - link equalization

	 * will be performed automatically after the SBR when the target

	 * speed is 8GT/s.

 clear all 16 per-lane error bits (PCIe: Lane Error Status) */

 step 5a: Set Synopsys Port Logic registers */

	/*

	 * PcieCfgRegPl2 - Port Force Link

	 *

	 * Set the low power field to 0x10 to avoid unnecessary power

	 * management messages.  All other fields are zero.

	/*

	 * PcieCfgRegPl100 - Gen3 Control

	 *

	 * turn off PcieCfgRegPl100.Gen3ZRxDcNonCompl

	 * turn on PcieCfgRegPl100.EqEieosCnt

	 * Everything else zero.

	/*

	 * PcieCfgRegPl101 - Gen3 EQ FS and LF

	 * PcieCfgRegPl102 - Gen3 EQ Presets to Coefficients Mapping

	 * PcieCfgRegPl103 - Gen3 EQ Preset Index

	 * PcieCfgRegPl105 - Gen3 EQ Status

	 *

	 * Give initial EQ settings.

 discrete */

 1000mV, FS=24, LF = 8 */

 bit 0 - discrete on/off */

 400mV, FS=29, LF = 9 */

 bit 1 - integrated on/off */

	/*

	 * PcieCfgRegPl106 - Gen3 EQ Control

	 *

	 * Set Gen3EqPsetReqVec, leave other fields 0.

 valid range is 0-10, inclusive */

	/*

	 * step 5b: Do post firmware download steps via SBus

	/*

	 * step 5c: Program gasket interrupts

 set the Rx Bit Rate to REFCLK ratio */

 disable pCal for PCIe Gen3 RX equalization */

 select adaptive or static CTLE */

	/*

	 * Enable iCal for PCIe Gen3 RX equalization, and set which

	 * evaluation of RX_EQ_EVAL will launch the iCal procedure.

 apply static CTLE tunings */

 terminate list */

	/*

	 * step 5d: program XMT margin

	/*

	 * step 5e: disable active state power management (ASPM). It

	 * will be enabled if required later

	/*

	 * step 5f: clear DirectSpeedChange

	 * PcieCfgRegPl67.DirectSpeedChange must be zero to prevent the

	 * change in the speed target from starting before we are ready.

	 * This field defaults to 0 and we are not changing it, so nothing

	 * needs to be done.

 step 5g: Set target link speed */

	/*

	 * Set target link speed to be target on both device and parent.

	 * On setting the parent: Some system BIOSs "helpfully" set the

	 * parent target speed to Gen2 to match the ASIC's initial speed.

	 * We can set the target Gen3 because we have already checked

	 * that it is Gen3 capable earlier.

 only write to parent if target is not as high as ours */

 step 5h: arm gasket logic */

 hold DC in reset across the SBR */

 DC reset hold */

 save firmware control across the SBR */

	/*

	 * step 6: quiesce PCIe link

	 * The chip has already been reset, so there will be no traffic

	 * from the chip.  Linux has no easy way to enforce that it will

	 * not try to access the device, so we just need to hope it doesn't

	 * do it while we are doing the reset.

	/*

	 * step 7: initiate the secondary bus reset (SBR)

	 * step 8: hardware brings the links back up

	 * step 9: wait for link speed transition to be complete

 step 10: decide what to do next */

 check if we can read PCI space */

 restore PCI space registers we know were reset */

 restore firmware control */

	/*

	 * Check the gasket block status.

	 *

	 * This is the first CSR read after the SBR.  If the read returns

	 * all 1s (fails), the link did not make it back.

	 *

	 * Once we're sure we can read and write, clear the DC reset after

	 * the SBR.  Then check for any per-lane errors. Then look over

	 * the status.

 PCIe read failed/timeout */

 clear the DC reset */

 Set the LED off */

 check for any per-lane errors */

 extract status, look for our HFI */

 extract error */

 update our link information cache */

 not target */

 maybe retry */

 allow time to settle */

 return no error if it is OK to be at current speed */

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 * Copyright (c) 2005, 2006 Cisco Systems.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2004 Voltaire, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 props being zeroed by the caller, avoid zeroing it here */

 Don't support raw QPs */

 nothing */

		/*

		 * Be friendly to write_mtt and pass it chunks

		 * of appropriate size.

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 * Copyright (c) 2005, 2006 Cisco Systems, Inc. All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2004 Voltaire, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Must be packed because start is 64 bits but only aligned to 32 bits.

 Tavor only */

 Arbel only */

 Arbel only */

 avoid warning if mthca_dbg compiled away... */

/*

 * incr is ignored in native Arbel (mem-free) mode, so cq->cons_index

 * should be correct before calling update_cons_index().

	/*

	 * First we need to find the current producer index, so we

	 * know where to start cleaning from.  It doesn't matter if HW

	 * adds new entries after this loop -- the QP we're worried

	 * about is already in RESET, so the new entries won't come

	 * from our QP and therefore don't need to be checked.

	/*

	 * Now sweep backwards through the CQ, removing CQ entries

	 * that match our QP by copying older entries on top of them.

	/*

	 * In Tavor mode, the hardware keeps the consumer and producer

	 * indices mod the CQ size.  Since we might be making the CQ

	 * bigger, we need to deal with the case where the producer

	 * index wrapped around before the CQ was resized.

	/*

	 * For completions in error, only work request ID, status, vendor error

	 * (and freed resource count for RD) have to be set.

	/*

	 * Mem-free HCAs always generate one CQE per WQE, even in the

	 * error case, so we don't have to check the doorbell count, etc.

	/*

	 * If we're at the end of the WQE chain, or we've used up our

	 * doorbell count, free the CQE.  Otherwise just update it for

	 * the next poll operation.

	/*

	 * Make sure we read CQ entry contents after we've checked the

	 * ownership bit.

		/*

		 * We do not have to take the QP table lock here,

		 * because CQs will be locked while QPs are removed

		 * from the table.

		/*

		 * WQE addr == base - 1 might be reported in receive completion

		 * with error instead of (rq size - 1) by Sinai FW 1.0.800 and

		 * Arbel FW 5.1.400.  This bug should be fixed in later FW revs.

	/*

	 * If a CQ resize is in progress and we discovered that the

	 * old buffer is empty, then peek in the new buffer, and if

	 * it's not empty, switch to the new buffer and continue

	 * polling there.

		/*

		 * In Tavor mode, the hardware keeps the producer

		 * index modulo the CQ size.  Since we might be making

		 * the CQ bigger, we need to mask our consumer index

		 * using the size of the old CQ buffer before looking

		 * in the new CQ buffer.

	/*

	 * Make sure that the doorbell record in host memory is

	 * written before ringing the doorbell via PCI MMIO.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Trivial bitmap-based allocator */

 num must be a power of 2 */

/*

 * Array of pointers with lazy allocation of leaf pages.  Callers of

 * _get, _set and _clear methods must use a lock or otherwise

 * serialize access to the array.

 Allocate with GFP_ATOMIC because we'll be called with locks held. */

/*

 * Handling for queue buffers -- we allocate a bunch of memory and

 * register it in a memory region at HCA virtual address 0.  If the

 * requested size is > max_direct, we split the allocation into

 * multiple pages, so we don't require too much contiguous memory.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2004 Voltaire, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Snoop SM MADs for port info and P_Key table sets, so we can

 * synthesize LID change and P_Key change events.

		/*

		 * We rely here on the fact that MLX QPs don't use the

		 * address handle after the send is posted (this is

		 * wrong following the IB spec strictly, but we know

		 * it's OK for our devices).

 Forward locally generated traps to the SM */

	/*

	 * Only handle SM gets, sets and trap represses for SM class

	 *

	 * Only handle PMA and Mellanox vendor-specific class gets and

	 * sets for other classes.

		/*

		 * Don't process SMInfo queries or vendor-specific

		 * MADs -- the SMA can't handle them.

 set return bit in status of directed route responses */

 no response for trap repress */

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Must be packed because mtt_seg is 64 bits but only aligned to 32 bits.

 Arbel only */

/*

 * Buddy allocator for MTT segments (currently not very efficient

 * since it doesn't keep a free list and just searches linearly

 * through the bitmaps)

		/*

		 * If we have an odd number of entries to write, add

		 * one more dummy entry for firmware efficiency.

		/*

		 * Be friendly to WRITE_MTT command

		 * and leave two empty slots for the

		 * index and reserved fields of the

		 * mailbox.

 For Arbel, all MTTs must fit in the same page. */

 For Arbel, all MTTs must fit in the same page. */

 Require full segments */

 Free mr */

 Prevent regular MRs from using FMR keys */

 FMR table is always the first, take reserved MTTs out of there */

 XXX check if any MRs are still allocated? */

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Cisco Systems.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * We allocate in as big chunks as we can, up to a maximum of 256 KB

 * per chunk.

	/*

	 * Use __GFP_ZERO because buggy firmware assumes ICM pages are

	 * cleared, and subtle failures are seen if they aren't.

 We use sg_set_buf for coherent allocs, which assumes low memory */

			/* DMA mapping can merge pages but not split them,

			 * so if we found the page, dma_handle has already

		/*

		 * Add a reference to this ICM chunk so that it never

		 * gets freed (since it contains reserved firmware objects).

	/*

	 * To make our bookkeeping simpler, we don't unmap DB

	 * pages until we clean up the whole db table.

 XXX may be able to unmap more pages now */

	/*

	 * Because we don't always free our UARC pages when they

	 * become empty to make mthca_free_db() simpler we need to

	 * make a sweep through the doorbell pages and free any

	 * leftover pages now.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * Reset the chip.  This is somewhat ugly because we have to

	 * save off the PCI header before reset and then restore it

	 * after the chip reboots.  We skip config space offsets 22

	 * and 23 since those have a special meaning.

	 *

	 * To make matters worse, for Tavor (PCI-X HCA) we have to

	 * find the associated bridge device and save off its PCI

	 * header as well.

		/* Look for the bridge -- its device ID will be 2 more

			/*

			 * Didn't find a bridge for a Tavor device --

			 * assume we're in no-bridge mode and hope for

			 * the best.

 For Arbel do we need to save off the full 4K PCI Express header?? */

 actually hit reset */

 Docs say to wait one second before accessing device */

 Now wait for PCI device to start responding again */

 Now restore the PCI headers */

		/*

		 * Bridge control register is at 0x3e, so we'll

		 * naturally restore it last in this loop.

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 CONFIG_INFINIBAND_MTHCA_DEBUG */

 CONFIG_PCI_MSI */

 CONFIG_PCI_MSI */

 Tavor only */

 Tavor only */

 Arbel only */

 First try to max out Read Byte Count */

	/*

	 * Need to allow for worst case send WQE overhead and check

	 * whether max_desc_sz imposes a lower limit than max_sg; UD

	 * send has the biggest overhead.

	/*

	 * Subtract 1 from the limit because we need to allocate a

	 * spare CQE so the HCA HW can tell the difference between an

	 * empty CQ and a full CQ.

	/*

	 * For old FW that doesn't return static rate support, use a

	 * value of 0x3 (only static rate values of 0 or 1 are handled),

	 * except on Sinai, where even old FW can handle static rate

	 * values of 2 and 3.

	/* IB_DEVICE_RESIZE_MAX_WR not supported by driver.

	   May be doable since hardware supports it for SRQ.



	   IB_DEVICE_N_NOTIFY_CQ is supported by hardware but not by driver.



	   IB_DEVICE_SRQ_RESIZE is supported by hardware but SRQ is not

 FIXME: use HCA-attached memory for FW if present */

 CPU writes to non-reserved MTTs, while HCA might DMA to reserved mtts */

	/*

	 * It's not strictly required, but for simplicity just map the

	 * whole multicast group table now.  The table isn't very big

	 * and it's a lot easier than trying to track ref counts.

 Types of supported HCA */

 MT23108                        */

 MT25208 in Tavor compat mode   */

 MT25208 with extended features */

 MT25204 */

	/*

	 * Check for BARs.  We expect 0: 1MB, 2: 8MB, 4: DDR (may not

	 * be present)

 We can handle large RDMA requests, so allow larger segments. */

	/*

	 * Now reset the HCA before we touch the PCI capabilities or

	 * attempt a firmware command, since a boot ROM may have left

	 * the HCA in an undefined state.

 value must be positive and power of 2 */

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Must be packed because start is 64 bits but only aligned to 32 bits.

 reserved for Arbel */

 lost_count for Tavor */

	/*

	 * This barrier makes sure that all updates to ownership bits

	 * done by set_eqe_hw() hit memory before the consumer index

	 * is updated.  set_eq_ci() allows the HCA to possibly write

	 * more EQ entries, and we want to avoid the exceedingly

	 * unlikely possibility of the HCA writing an entry and then

	 * having set_eqe_hw() overwrite the owner field.

 See comment in tavor_set_eq_ci() above. */

 We still want ordering, just not swabbing, so add a barrier */

		/*

		 * Make sure we read EQ entry contents after we've

		 * checked the ownership bit.

		/*

		 * The HCA will think the queue has overflowed if we

		 * don't tell it we've been processing events.  We

		 * create our EQs with MTHCA_NUM_SPARE_EQE extra

		 * entries, so we must update our consumer index at

		 * least that often.

			/*

			 * Conditional on hca_type is OK here because

			 * this is a rare case, not the fast path.

	/*

	 * Rely on caller to set consumer index so that we don't have

	 * to test hca_type in our interrupt handling fast path.

 MSI-X vectors always belong to us */

 MSI-X vectors always belong to us */

		/*

		 * We assume that the EQ arm and EQ set CI registers

		 * fall within the first BAR.  We can't trust the

		 * values firmware gives us, since those addresses are

		 * valid on the HCA's side of the PCI bus but not

		 * necessarily the host side.

		/*

		 * Add 4 because we limit ourselves to EQs 0 ... 31,

		 * so we only need the low word of the register.

	/*

	 * We assume that mapping one page is enough for the whole EQ

	 * context table.  This is fine with all current HCAs, because

	 * we only use 32 EQs and each EQ uses 32 bytes of context

	 * memory, or 1 KB total.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 automatically initialized to 0 */

/*

 * Caller must hold MCG table semaphore.  gid and mgm parameters must

 * be properly aligned for command interface.

 *

 *  Returns 0 unless a firmware command error occurs.

 *

 * If GID is found in MGM or MGM is empty, *index = *hash, *prev = -1

 * and *mgm holds MGM entry.

 *

 * if GID is found in AMGM, *index = index in AMGM, *prev = index of

 * previous entry in hash chain and *mgm holds AMGM entry.

 *

 * If no AMGM exists for given gid, *index = -1, *prev = index of last

 * entry in hash chain and *mgm holds end of hash chain.

 Remove entry from MGM */

 Remove entry from AMGM */

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Cisco Systems. All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2004 Voltaire, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 largest UD header possible */

 data segment overhead for inline */

 inline data segment chunk */

 qp_context flags */

 params1 */

 params2 */

 Reserved on Arbel */

 Reserved on Tavor */

 Reserved on Tavor */

 Reserved on Tavor */

 Next send WQE on Tavor */

 (debugging only entries) */

 Next recv WQE on Tavor */

 (debugging only entries) */

 reserved on Tavor */

 reserved on Tavor */

 qp_attr->en_sqd_async_notify is only applicable in modify qp */

 leave tavor_sched_queue as 0 */

 leave arbel_sched_queue as 0 */

 leave rdd as 0 */

 leave wqe_base as 0 (we always create an MR based at 0 for WQs) */

	/*

	 * If we moved QP0 to RTR, bring the IB link up; if we moved

	 * QP0 to RESET or ERROR, bring the link back down.

	/*

	 * If we moved a kernel QP to RESET, clean up all old CQ

	 * entries and reinitialize the QP.

	/*

	 * Calculate the maximum size of WQE s/g segments, excluding

	 * the next segment and other non-data segments.

 We don't support inline data for kernel QPs (yet). */

/*

 * Allocate and register buffer for WQEs.  qp->rq.max, sq.max,

 * rq.max_gs and sq.max_gs must all be assigned.

 * mthca_alloc_wqe_buf will calculate rq.wqe_shift and

 * sq.wqe_shift (as well as send_wqe_offset, is_direct, and

 * queue)

 nothing */

		/*

		 * An atomic op will require an atomic segment, a

		 * remote address segment and one scatter entry.

 Make sure that we have enough space for a bind request */

 nothing */

	/*

	 * If this is a userspace QP, we don't actually have to

	 * allocate anything.  All we need is to calculate the WQE

	 * sizes and the send_wqe_offset, so we're done now.

	/*

	 * If this is a userspace QP, we're done now.  The doorbells

	 * will be allocated and buffers will be initialized in

	 * userspace.

 Sanity check QP size before proceeding */

	/*

	 * For MLX transport we need 2 extra send gather entries:

	 * one for the header and one for the checksum at the end

 initialize port to zero for error-catching. */

	/*

	 * Lock CQs here, so that CQ polling code can do QP lookup

	 * without taking a lock.

	/*

	 * Lock CQs here, so that CQ polling code can do QP lookup

	 * without taking a lock.

	/*

	 * If this is a userspace QP, the buffers, MR, CQs and so on

	 * will be cleaned up in userspace, so all we have to do is

	 * unref the mem-free tables and free the QPN in our table.

 Create UD header for an MLX send and build a data segment for it */

 assume a MAD */ 1, 0, 0,

	/*

	 * f0 and size0 are only used if nreq != 0, and they will

	 * always be initialized the first time through the main loop

	 * before nreq is incremented.  So nreq cannot become non-zero

	 * without initializing f0 and size0, and they are in fact

	 * never used uninitialized.

 XXX check that state is OK to post send */

 No extra segments required for sends */

 No extra segments required for sends */

 Add one more inline data segment for ICRC */

	/*

	 * size0 is only used if nreq != 0, and it will always be

	 * initialized the first time through the main loop before

	 * nreq is incremented.  So nreq cannot become non-zero

	 * without initializing size0, and it is in fact never used

	 * uninitialized.

 XXX check that state is OK to post receive */

	/*

	 * f0 and size0 are only used if nreq != 0, and they will

	 * always be initialized the first time through the main loop

	 * before nreq is incremented.  So nreq cannot become non-zero

	 * without initializing f0 and size0, and they are in fact

	 * never used uninitialized.

 XXX check that state is OK to post send */

			/*

			 * Make sure that descriptors are written before

			 * doorbell record.

			/*

			 * Make sure doorbell record is written before we

			 * write MMIO send doorbell.

 No extra segments required for sends */

 No extra segments required for sends */

 Add one more inline data segment for ICRC */

		/*

		 * Make sure that descriptors are written before

		 * doorbell record.

		/*

		 * Make sure doorbell record is written before we

		 * write MMIO send doorbell.

 XXX check that state is OK to post receive */

		/*

		 * Make sure that descriptors are written before

		 * doorbell record.

	/*

	 * For SRQs, all receive WQEs generate a CQE, so we're always

	 * at the end of the doorbell chain.

	/*

	 * We reserve 2 extra QPs per port for the special QPs.  The

	 * special QP for port 1 has to be even, so round up.

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Handle old Arbel FW */

	/*

	 * Inter-packet delay (IPD) to get from rate X down to a rate

	 * no more than Y is (X - 1) / Y.

 fall back to allocate in host memory */

 2K message */

 Arbel workaround -- low byte of GID must be 2 */

 Only implement for MAD and memfree ah for now. */

/*

 * Copyright (c) 2004 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Cisco Systems.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 XXX check if any PDs are still allocated? */

/*

 * Copyright (c) 2005 Cisco Systems. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 low 6 bits is descriptor size */

/*

 * Return a pointer to the location within a WQE that we're using as a

 * link when the WQE is in the free list.  We use the imm field

 * because in the Tavor case, posting a WQE may overwrite the next

 * segment of the previous WQE, but a receive WQE will never touch the

 * imm field.  This avoids corrupting our free list if the previous

 * WQE has already completed and been put on the free list when we

 * post the next WQE.

	/*

	 * Put max in a temporary variable to work around gcc bug

	 * triggered by ilog2() on sparc64.

	/*

	 * Now initialize the SRQ buffer so that all of the WQEs are

	 * linked into the list of free WQEs.  In addition, set the

	 * scatter list L_Keys to the sentry value of 0x100.

 Sanity check SRQ size before proceeding */

 We don't support resizing SRQs (yet?) */

/*

 * This function must be called with IRQs disabled.

 flags field will always remain 0 */

			/*

			 * Make sure that descriptors are written

			 * before doorbell is rung.

		/*

		 * Make sure that descriptors are written before

		 * doorbell is rung.

 flags field will always remain 0 */

		/*

		 * Make sure that descriptors are written before

		 * we write doorbell record.

	/*

	 * SRQ allocations are based on powers of 2 for Tavor,

	 * (although they only need to be multiples of 16 bytes).

	 *

	 * Therefore, we need to base the max number of sg entries on

	 * the largest power of 2 descriptor size that is <= to the

	 * actual max WQE descriptor size, rather than return the

	 * max_sg value given by the firmware (which is based on WQE

	 * sizes as multiples of 16, not powers of 2).

	 *

	 * If SRQ implementation is changed for Tavor to be based on

	 * multiples of 16, the calculation below can be deleted and

	 * the FW max_sg value returned.

/*

 * Copyright (c) 2005 Cisco Systems.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 'dev' now is not valid */

/*

 * Copyright (c) 2005 Topspin Communications.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 PAGE_SHIFT */

 XXX check if any UARs are still allocated? */

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * Sort the resources in decreasing order of size.  Since they

	 * all have sizes that are powers of 2, we'll be able to keep

	 * resources aligned to their size and pack them without gaps

	 * using the sorted order.

 nothing */

	/*

	 * PDs don't take any HCA memory, but we assign them as part

	 * of the HCA profile anyway.

	/*

	 * For Tavor, FMRs use ioremapped PCI memory. For 32 bit

	 * systems it may use too much vmalloc space to map all MTT

	 * memory, so we reserve some MTTs for FMR access, taking them

	 * out of the MR pool. They don't use additional memory, but

	 * we assign them as part of the HCA profile anyway.

/*

 * Copyright (c) 2004, 2005 Topspin Communications.  All rights reserved.

 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.

 * Copyright (c) 2005, 2006 Cisco Systems.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 initialization and general commands */

 TPT commands */

 EQ commands */

 CQ commands */

 SRQ commands */

 QP/EE commands */

 special QPs and management commands */

 multicast commands */

 miscellaneous commands */

 debug commands */

/*

 * According to Mellanox code, FW may be starved and never complete

 * commands.  So we can't use strict timeouts described in PRM -- we

 * just arbitrarily select 60 seconds for now.

/*

 * Round up and add 1 to make sure we get the full wait time (since we

 * will be starting in the middle of a jiffy)

	/*

	 * We use writel (instead of something like memcpy_toio)

	 * because writes of less than 32 bits to the HCR don't work

	 * (and some architectures such as ia64 implement memcpy_toio

	 * in terms of writeb).

 __raw_writel may not order writes. */

 previously timed out command completing at long last */

 Invoke a command with an output mailbox */

 Invoke a command with no output parameter */

/*

 * Invoke a command with an immediate output parameter (and copy the

 * output into the caller's out_param pointer after the command

 * executes).

/*

 * Switch to using events to issue FW commands (should be called after

 * event queue to command events has been initialized).

 nothing */

/*

 * Switch back to polling (used when shutting down the device)

		/*

		 * We have to pass pages that are aligned to their

		 * size, so find the least significant 1 in the

		 * address or size and use that as our log2 size.

	/*

	 * FW subminor version is at more significant bits than minor

	 * version, so swap here.

		/*

		 * Round up number of system pages needed in case

		 * MTHCA_ICM_PAGE_SIZE < PAGE_SIZE.

		/*

		 * The board ID is a string but the firmware byte

		 * swaps each 4-byte word before passing it back to

		 * us.  Therefore we need to swab it before printing.

 Check port for UD address vector: */

 Enable IPoIB checksumming if we can: */

 We leave wqe_quota, responder_exu, etc as 0 (default) */

 QPC/EEC/CQC/EQC/RDB attributes */

 UD AV attributes */

 multicast attributes */

 TPT attributes */

 UAR attributes */

	/*

	 * Round up number of system pages needed in case

	 * MTHCA_ICM_PAGE_SIZE < PAGE_SIZE.

	/*

	 * Leave start address fields zeroed out -- mthca assumes that

	 * MRs for CQs always start at virtual address 0.

 don't write outbox, any->reset */

 For debugging */

 write outbox, any->reset */

	/*

	 * Key check traps can't be generated unless we have in_wc to

	 * tell us where to send the trap.

/*

 * Copyright (c) 2009 QLogic Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/**

 * qib_pio_copy - copy data to MMIO space, in multiples of 32-bits

 * @to: destination, in MMIO space (must be 64-bit aligned)

 * @from: source (must be 64-bit aligned)

 * @count: number of 32-bit quantities to copy

 *

 * Copy data from kernel space to MMIO space, in multiples of 32 bits at a

 * time.  Order of access is not guaranteed, nor is a memory barrier

 * performed afterwards.

/*

 * Copyright (c) 2006, 2007, 2008, 2009 QLogic Corporation. All rights reserved.

 * Copyright (c) 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Switch to alternate path.

 * The QP s_lock should be held and interrupts disabled.

/*

 *

 * This should be called with the QP r_lock held.

 *

 * The s_lock will be acquired around the qib_migrate_qp() call.

 Validate the SLID. See Ch. 9.6.1.5 and 17.2.8 */

 Validate the SLID. See Ch. 9.6.1.5 */

/**

 * qib_make_grh - construct a GRH header

 * @ibp: a pointer to the IB port

 * @hdr: a pointer to the GRH header being constructed

 * @grh: the global route address to send to

 * @hwords: the number of 32 bit words of header being sent

 * @nwords: the number of 32 bit words of data being sent

 *

 * Return the size of the header in 32 bit words.

 next_hdr is defined by C8-7 in ch. 8.4.1 */

 The SGID is 32-bit aligned. */

 GRH header size in 32-bit words. */

 Construct the header. */

/**

 * qib_do_send - perform a send on a QP

 * @qp: pointer to the QP

 *

 * Process entries in the send work queue until credit or queue is

 * exhausted.  Only allow one CPU to send a packet per QP (tasklet).

 * Otherwise, two threads could send packets out of order.

 Return if we are already busy processing a work request. */

 Check for a constructed packet to be sent. */

			/*

			 * If the packet cannot be sent now, return and

			 * the send tasklet will be woken up later.

 Record that s_hdr is empty. */

/*

 * Copyright (c) 2006, 2007, 2008 QLogic Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file is conditionally built on PowerPC only.  Otherwise weak symbol

 * versions of the functions exported from here are used.

/**

 * qib_enable_wc - enable write combining for MMIO writes to the device

 * @dd: qlogic_ib device

 *

 * Nothing to do on PowerPC, so just return without error.

/**

 * qib_unordered_wc - indicate whether write combining is unordered

 *

 * Because our performance depends on our ability to do write

 * combining mmio writes in the most efficient way, we need to

 * know if we are on a processor that may reorder stores when

 * write combining.

/*

 * Copyright (c) 2021 Cornelis Networks. All rights reserved.

 * Copyright (c) 2013 Intel Corporation. All rights reserved.

 * Copyright (c) 2006, 2007, 2008, 2009 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * The size has to be longer than this string, so we can append

 * board/chip information to it in the init code.

 general driver use */

/*

 * QIB_PIO_MAXIBHDR is the max IB header size allowed for in our

 * PIO send buffers.  This is well beyond anything currently

 * defined in the InfiniBand spec.

/*

 * QIB_MAX_PKT_RCV is the max # if packets processed per receive interrupt.

/*

 * Return count of units with at least one port ACTIVE.

/*

 * Return count of all units, optionally return in arguments

 * the number of usable (present) units, and the number of

 * ports that are up.

/**

 * qib_wait_linkstate - wait for an IB link state change to occur

 * @ppd: the qlogic_ib device

 * @state: the state to wait for

 * @msecs: the number of milliseconds to wait

 *

 * wait up to msecs milliseconds for IB link state change to occur for

 * now, take the easy polling route.  Currently used only by

 * qib_set_linkstate.  Returns 0 if state reached, otherwise

 * -ETIMEDOUT state can have multiple states set, for any of several

 * transitions.

 don't wait */

 don't wait */

 don't wait */

 don't wait */

		/*

		 * Since the port can be ACTIVE when we ask for ARMED,

		 * clear QIBL_LINKV so we can wait for a transition.

		 * If the link isn't ARMED, then something else happened

		 * and there is no point waiting for ARMED.

/*

 * Get address of eager buffer from it's index (allocated in chunks, not

 * contiguous).

/*

 * Returns 1 if error was a CRC, else 0.

 * Needed for some chip's synthesized error counters.

 For TIDERR and RC QPs premptively schedule a NAK */

 Sanity check packet */

 Check for GRH */

 Get opcode and PSN from packet */

 Get the destination QP number. */

			/*

			 * Handle only RC QPs - for other QP types drop error

			 * packet.

 Check for valid receive state. */

 Only deal with RDMA Writes for now */

 Use the expected PSN. */

						/*

						 * Wait to send the sequence

						 * NAK until all packets

						 * in the receive queue have

						 * been processed.

						 * Otherwise, we end up

						 * propagating congestion.

 Out of sequence NAK */

 QP Request NAKs */

 For now don't handle any other QP types */

 Unicast QP */

 Valid packet with TIDErr */

/*

 * qib_kreceive - receive a packet

 * @rcd: the qlogic_ib context

 * @llic: gets count of good packets needed to clear lli,

 *          (used with chips that need need to track crcs for lli)

 *

 * called from interrupt handler for errors or receive interrupt

 * Returns number of CRC error packets, needed by some chips for

 * local link integrity tracking.   crcs are adjusted down by following

 * good packets, if any, and count of good packets is also tracked.

 words */

 words */

 prevent speculative reads of dma'ed hdrq */

 total length */

		/*

		 * Both tiderr and qibhdrerr are set for all plain IB

		 * packets; only qibhdrerr should be set.

		/*

		 * Update head regs etc., every 16 packets, if not last pkt,

		 * to help prevent rcvhdrq overflows, when many packets

		 * are processed and queue is nearly full.

		 * Don't request an interrupt for intermediate updates.

	/*

	 * Iterate over all QPs waiting to respond.

	 * The list won't change since the IRQ is only run on one CPU.

 Report number of packets consumed */

	/*

	 * Always write head at end, and setup rcv interrupt, even

	 * if no packets were processed.

/**

 * qib_set_mtu - set the MTU

 * @ppd: the perport data

 * @arg: the new MTU

 *

 * We can handle "any" incoming size, the issue here is whether we

 * need to restrict our outgoing size.   For now, we don't do any

 * sanity checking on this, and we don't deal with what happens to

 * programs that are already running when the size changes.

 * NOTE: changing the MTU will usually cause the IBC to go back to

 * link INIT state...

 Only if it's not the initial value (or reset to it) */

/*

 * Following deal with the "obviously simple" task of overriding the state

 * of the LEDS, which normally indicate link physical and logical status.

 * The complications arise in dealing with different hardware mappings

 * and the board-dependent routine being called from interrupts.

 * and then there's the requirement to _flash_ them.

 Below is "non-zero" to force override, but both actual LEDs are off */

	/*

	 * don't re-fire the timer if user asked for it to be off; we let

	 * it fire one more time after they turn it off to simplify

 First check if we are blinking. If not, use 1HZ polling */

 For blink, set each phase from one nybble of val */

 Non-blink set both phases the same. */

	/*

	 * If the timer has not already been started, do so. Use a "quick"

	 * timeout so the function will be called soon, to look at our request.

 Need to start timer */

/**

 * qib_reset_device - reset the chip if possible

 * @unit: the device to reset

 *

 * Whether or not reset is successful, we attempt to re-initialize the chip

 * (that is, much like a driver unload/reload).  We clear the INITTED flag

 * so that the various entry points will fail until we reinitialize.  For

 * now, we only allow this if no user contexts are open that use chip resources

 Need to stop LED timer, _then_ shut off LEDs */

 Shut off LEDs after we are sure timer is not running */

/*

 * Copyright (c) 2012 Intel Corporation. All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file contains support for diagnostic functions.  It is accessed by

 * opening the qib_diag device, normally minor number 129.  Diagnostic use

 * of the QLogic_IB chip may render the chip or board unusable until the

 * driver is unloaded, or in some cases, until the system is rebooted.

 *

 * Accesses to the chip through this interface are not similar to going

 * through the /sys/bus/pci resource mmap interface.

/*

 * Each client that opens the diag device must read then write

 * offset 0, to prevent lossage from random cat or od. diag_state

 * sequences this "handshake".

 State for an individual client. PID so children cannot abuse handshake */

/*

 * Get a client struct. Recycled if possible, else kmalloc.

 * Must be called with qib_mutex held

 got from pool remove it and use */

 None in pool, alloc and init */

/*

 * Return to pool. Must be called with qib_mutex held

	/*

	 * Return all diag_clients of this device. There should be none,

	 * as we are "guaranteed" that no clients are still open

 Now clean up all unused client structs */

 Clean up observer list */

/* qib_remap_ioaddr32 - remap an offset into chip address space to __iomem *

 *

 * @dd: the qlogic_ib device

 * @offs: the offset in chip-space

 * @cntp: Pointer to max (byte) count for transfer starting at offset

 * This returns a u32 __iomem * so it can be used for both 64 and 32-bit

 * mapping. It is needed because with the use of PAT for control of

 * write-combining, the logically contiguous address-space of the chip

 * may be split into virtually non-contiguous spaces, with different

 * attributes, which are them mapped to contiguous physical space

 * based from the first BAR.

 *

 * The code below makes the same assumptions as were made in

 * init_chip_wc_pat() (qib_init.c), copied here:

 * Assumes chip address space looks like:

 *		- kregs + sregs + cregs + uregs (in any order)

 *		- piobufs (2K and 4K bufs in either order)

 *	or:

 *		- kregs + sregs + cregs (in any order)

 *		- piobufs (2K and 4K bufs in either order)

 *		- uregs

 *

 * If cntp is non-NULL, returns how many bytes from offset can be accessed

 * Returns 0 if the offset is not mapped.

 First, simplest case, offset is within the first map. */

	/*

	 * Next check for user regs, the next most common case,

	 * and a cheap check because if they are not in the first map

	 * they are last in chip.

 If user regs mapped, they are after send, so set limit. */

	/*

	 * Lastly, check for offset within Send Buffers.

	 * This is gnarly because struct devdata is deliberately vague

	 * about things like 7322 VL15 buffers, and we are not in

	 * chip-specific code here, so should not make many assumptions.

	 * The one we _do_ make is that the only chip that has more sndbufs

	 * than we admit is the 7322, and it has userregs above that, so

	 * we know the snd_lim.

 Assume 2K buffers are first. */

	/* If 4k buffers exist, account for them by bumping

	 * appropriate limit.

 4k above 2k. Bump snd_lim, if needed*/

	/*

	 * Judgement call: can we ignore the space between SendBuffs and

	 * UserRegs, where we would like to see vl15 buffs, but not more?

/*

 * qib_read_umem64 - read a 64-bit quantity from the chip into user space

 * @dd: the qlogic_ib device

 * @uaddr: the location to store the data in user memory

 * @regoffs: the offset from BAR0 (_NOT_ full pointer, anymore)

 * @count: number of bytes to copy (multiple of 32 bits)

 *

 * This function also localizes all chip memory accesses.

 * The copy should be written such that we read full cacheline packets

 * from the chip.  This is usually used for a single qword

 *

 * NOTE:  This assumes the chip address is 64-bit aligned.

 not very efficient, but it works for now */

/*

 * qib_write_umem64 - write a 64-bit quantity to the chip from user space

 * @dd: the qlogic_ib device

 * @regoffs: the offset from BAR0 (_NOT_ full pointer, anymore)

 * @uaddr: the source of the data in user memory

 * @count: the number of bytes to copy (multiple of 32 bits)

 *

 * This is usually used for a single qword

 * NOTE:  This assumes the chip address is 64-bit aligned.

 not very efficient, but it works for now */

/*

 * qib_read_umem32 - read a 32-bit quantity from the chip into user space

 * @dd: the qlogic_ib device

 * @uaddr: the location to store the data in user memory

 * @regoffs: the offset from BAR0 (_NOT_ full pointer, anymore)

 * @count: number of bytes to copy

 *

 * read 32 bit values, not 64 bit; for memories that only

 * support 32 bit reads; usually a single dword.

 not very efficient, but it works for now */

/*

 * qib_write_umem32 - write a 32-bit quantity to the chip from user space

 * @dd: the qlogic_ib device

 * @regoffs: the offset from BAR0 (_NOT_ full pointer, anymore)

 * @uaddr: the source of the data in user memory

 * @count: number of bytes to copy

 *

 * write 32 bit values, not 64 bit; for memories that only

 * support 32 bit write; usually a single dword.

/**

 * qib_diagpkt_write - write an IB packet

 * @fp: the diag data device file pointer

 * @data: qib_diag_pkt structure saying where to get the packet

 * @count: size of data to write

 * @off: unused by this code

 no hardware, freeze, etc. */

 send count must be an exact number of dwords */

	/*

	 * need total length before first word written, plus 2 Dwords. One Dword

	 * is for padding so we get the full user data when not aligned on

	 * a word boundary. The other Dword is to make sure we have room for the

	 * ICRC which gets tacked on later.

 in dwords */

 disarm it just to be extra sure */

 disable header check on pbufn for this packet */

	/*

	 * Copy all but the trigger word, then flush, so it's written

	 * to chip before trigger word, then write trigger word, then

	 * flush again, so packet is sent.

	/*

	 * Ensure buffer is written to the chip, then re-enable

	 * header checks (if supported by chip).  The txchk

	 * code will ensure seen by chip before returning.

/*

 * Chip-specific code calls to register its interest in

 * a specific range.

 Remove all registered observers when device is closed */

 Pop one observer, let go of lock */

 try again. */

/*

 * Find the observer, if any, for the specified address. Initial implementation

 * is simple stack of observers. This must be called with diag transaction

 * lock held.

 address or length is not 32-bit aligned, hence invalid */

 prevent cat /dev/qib_diag* */

		/*

		 * Check for observer on this address range.

		 * we only support a single 32 or 64-bit read

		 * via observer, currently.

		/*

		 * We need to release lock before any copy_to_user(),

		 * whether implicit in qib_read_umem* or explicit below.

				/*

				 * Address or length is not 64-bit aligned;

				 * do 32-bit rd

 Below finishes case where observer existed */

 address or length is not 32-bit aligned, hence invalid */

 No writes except second-step of init seq */

 before any other write allowed */

		/*

		 * Check for observer on this address range.

		 * We only support a single 32 or 64-bit write

		 * via observer, currently. This helps, because

		 * we would otherwise have to jump through hoops

		 * to make "diag transaction" meaningful when we

		 * cannot do a copy_from_user while holding the lock.

				/*

				 * Address or length is not 64-bit aligned;

				 * do 32-bit write

 all read/write OK now */

/*

 * Copyright (c) 2006, 2007, 2008, 2009 QLogic Corporation. All rights reserved.

 * Copyright (c) 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 cut down ridiculously long IB macro names */

/**

 * qib_make_rc_ack - construct a response packet (ACK, NAK, or RDMA read)

 * @dev: the device for this QP

 * @qp: a pointer to the QP

 * @ohdr: a pointer to the IB header being constructed

 * @pmtu: the path MTU

 *

 * Return 1 if constructed; otherwise, return 0.

 * Note that we are in the responder's side of the QP context.

 * Note the QP s_lock must be held.

 Don't send an ACK if we aren't supposed to. */

 header size in 32-bit words LRH+BTH = (8+12)/4. */

		/*

		 * We can increment the tail pointer now that the last

		 * response has been sent instead of only being

		 * constructed.

 Check for no next entry in the queue. */

			/*

			 * If a RDMA read response is being resent and

			 * we haven't seen the duplicate request yet,

			 * then stop sending the remaining responses the

			 * responder has seen until the requester resends it.

 Copy SGE state in case we need to resend */

 COMPARE_SWAP or FETCH_ADD */

		/*

		 * Send a regular ACK.

		 * Set the s_ack_state so we wait until after sending

		 * the ACK before setting s_ack_state to ACKNOWLEDGE

		 * (see above).

/**

 * qib_make_rc_req - construct a request packet (SEND, RDMA r/w, ATOMIC)

 * @qp: a pointer to the QP

 * @flags: unused

 *

 * Assumes the s_lock is held.

 *

 * Return 1 if constructed; otherwise, return 0.

 Sending responses has higher priority over sending requests. */

 We are in the error state, flush the work request. */

 If DMAs are in progress, we can't flush immediately. */

 will get called again */

 header size in 32-bit words LRH+BTH = (8+12)/4. */

 Send a request. */

		/*

		 * Resend an old request or start a new one.

		 *

		 * We keep track of the current SWQE so that

		 * we don't reset the "furthest progress" state

		 * if we need to back up.

 Check if send work queue is empty. */

			/*

			 * If a fence is requested, wait for previous

			 * RDMA read and atomic operations to finish.

		/*

		 * Note that we have to be careful not to modify the

		 * original work request since we may need to resend

		 * it.

 If no credit, return. */

 Immediate data comes after the BTH */

 If no credit, return. */

 Immediate data comes after RETH */

			/*

			 * Don't allow more operations to be started

			 * than the QP limits allow.

			/*

			 * Don't allow more operations to be started

			 * than the QP limits allow.

		/*

		 * qp->s_state is normally set to the opcode of the

		 * last packet constructed for new requests and therefore

		 * is never set to RDMA read response.

		 * RDMA_READ_RESPONSE_FIRST is used by the ACK processing

		 * thread to indicate a SEND needs to be restarted from an

		 * earlier PSN without interferring with the sending thread.

		 * See qib_restart_rc().

 Immediate data comes after the BTH */

		/*

		 * qp->s_state is normally set to the opcode of the

		 * last packet constructed for new requests and therefore

		 * is never set to RDMA read response.

		 * RDMA_READ_RESPONSE_LAST is used by the ACK processing

		 * thread to indicate a RDMA write needs to be restarted from

		 * an earlier PSN without interferring with the sending thread.

		 * See qib_restart_rc().

 Immediate data comes after the BTH */

		/*

		 * qp->s_state is normally set to the opcode of the

		 * last packet constructed for new requests and therefore

		 * is never set to RDMA read response.

		 * RDMA_READ_RESPONSE_MIDDLE is used by the ACK processing

		 * thread to indicate a RDMA read needs to be restarted from

		 * an earlier PSN without interferring with the sending thread.

		 * See qib_restart_rc().

/**

 * qib_send_rc_ack - Construct an ACK packet and send it

 * @qp: a pointer to the QP

 *

 * This is called from qib_rc_rcv() and qib_kreceive().

 * Note that RDMA reads and atomics are handled in the

 * send side QP state and tasklet.

 Don't send ACK or NAK if a RDMA read or atomic is pending. */

 Construct the header with s_lock held so APM doesn't change it. */

 header size in 32-bit words LRH+BTH+AETH = (8+12+4)/4. */

 read pkey_index w/o lock (its atomic) */

 Don't try to send ACKs if the link isn't ACTIVE */

 length is + 1 for the control dword */

		/*

		 * We are out of PIO buffers at the moment.

		 * Pass responsibility for sending the ACK to the

		 * send tasklet so that when a PIO buffer becomes

		 * available, the ACK is sent ahead of other outgoing

		 * packets.

	/*

	 * Write the pbc.

	 * We have to flush after the PBC for correctness

	 * on some cpus or WC buffer can be written out of order.

 Schedule the send tasklet. */

/**

 * reset_psn - reset the QP state to send starting from PSN

 * @qp: the QP

 * @psn: the packet sequence number to restart at

 *

 * This is called from qib_rc_rcv() to process an incoming RC ACK

 * for the given QP.

 * Called at interrupt level with the QP s_lock held.

	/*

	 * If we are starting the request from the beginning,

	 * let the normal send code handle initialization.

 Find the work request opcode corresponding to the given PSN. */

		/*

		 * If we are starting the request from the beginning,

		 * let the normal send code handle initialization.

	/*

	 * Set the state to restart in the middle of a request.

	 * Don't change the s_sge, s_cur_sge, or s_cur_size.

	 * See qib_make_rc_req().

		/*

		 * This case shouldn't happen since its only

		 * one PSN per req.

	/*

	 * Set RVT_S_WAIT_PSN as qib_rc_complete() may start the timer

	 * asynchronously before the send tasklet can get scheduled.

	 * Doing it in qib_make_rc_req() is too late.

/*

 * Back up requester to resend the last un-ACKed request.

 * The QP r_lock and s_lock should be held and interrupts disabled.

 XXX need to handle delayed completion */

/*

 * Set qp->s_sending_psn to the next PSN after the given one.

 * This would be psn+1 except when RDMA reads are present.

 Find the work request corresponding to the given PSN. */

/*

 * This should be called with the QP s_lock held and interrupts disabled.

 Find out where the BTH is */

	/*

	 * Start timer after a packet requesting an ACK has been sent and

	 * there are still requests that haven't been acked.

	/*

	 * If we were waiting for sends to complete before resending,

	 * and they are now complete, restart sending.

/*

 * Generate a SWQE completion.

 * This is similar to qib_send_complete but has to check to be sure

 * that the SGEs are not being referenced if the SWQE is being resent.

	/*

	 * Don't decrement refcount and don't generate a

	 * completion if the SWQE is being resent until the send

	 * is finished.

	/*

	 * If we are completing a request which is in the process of

	 * being resent, we can stop resending it since we know the

	 * responder has already seen it.

/*

 * do_rc_ack - process an incoming RC ACK

 * @qp: the QP the ACK came in on

 * @psn: the packet sequence number of the ACK

 * @opcode: the opcode of the request that resulted in the ACK

 *

 * This is called from qib_rc_rcv_resp() to process an incoming RC ACK

 * for the given QP.

 * Called at interrupt level with the QP s_lock held.

 * Returns 1 if OK, 0 if current operation should be aborted (NAK).

	/*

	 * Note that NAKs implicitly ACK outstanding SEND and RDMA write

	 * requests and implicitly NAK RDMA read and atomic requests issued

	 * before the NAK'ed request.  The MSN won't include the NAK'ed

	 * request but will include an ACK'ed request(s).

	/*

	 * The MSN might be for a later WQE than the PSN indicates so

	 * only complete WQEs that the PSN finishes.

		/*

		 * RDMA_READ_RESPONSE_ONLY is a special case since

		 * we want to generate completion events for everything

		 * before the RDMA read, copy the data, then generate

		 * the completion for the read.

		/*

		 * If this request is a RDMA read or atomic, and the ACK is

		 * for a later operation, this ACK NAKs the RDMA read or

		 * atomic.  In other words, only a RDMA_READ_LAST or ONLY

		 * can ACK a RDMA read and likewise for atomic ops.  Note

		 * that the NAK case can only happen if relaxed ordering is

		 * used and requests are sent after an RDMA read or atomic

		 * is sent but before the response is received.

 Retry this request. */

			/*

			 * No need to process the ACK/NAK since we are

			 * restarting an earlier request.

 Restart sending task if fence is complete */

 ACK */

			/*

			 * We are expecting more ACKs so

			 * reset the retransmit timer.

			/*

			 * We can stop resending the earlier packets and

			 * continue with the next packet the receiver wants.

 No more acks - kill all timers */

 RNR NAK */

 The last valid PSN is the previous PSN. */

 NAK */

 The last valid PSN is the previous PSN. */

 PSN sequence error */

			/*

			 * Back up to the responder's expected PSN.

			 * Note that we might get a NAK in the middle of an

			 * RDMA READ response which terminates the RDMA

			 * READ.

 Invalid Request */

 Remote Access Error */

 Remote Operation Error */

 Ignore other reserved NAK error codes */

 2: reserved */

 Ignore reserved NAK codes. */

/*

 * We have seen an out of sequence RDMA read middle or last packet.

 * This ACKs SENDs and RDMA writes up to the first RDMA read or atomic SWQE.

 Remove QP from retry timer */

/**

 * qib_rc_rcv_resp - process an incoming RC response packet

 * @ibp: the port this packet came in on

 * @ohdr: the other headers for this packet

 * @data: the packet data

 * @tlen: the packet length

 * @qp: the QP for this packet

 * @opcode: the opcode for this packet

 * @psn: the packet sequence number for this packet

 * @hdrsize: the header length

 * @pmtu: the path MTU

 * @rcd: the context pointer

 *

 * This is called from qib_rc_rcv() to process an incoming RC response

 * packet for the given QP.

 * Called at interrupt level.

		/*

		 * If ACK'd PSN on SDMA busy list try to make progress to

		 * reclaim SDMA credits.

			/*

			 * If send tasklet not running attempt to progress

			 * SDMA queue.

 Acquire SDMA Lock */

 Invoke sdma make progress */

 Release SDMA Lock */

 Ignore invalid responses. */

 Ignore duplicate responses. */

 Update credits for "ghost" ACKs */

	/*

	 * Skip everything other than the PSN we expect, if we are waiting

	 * for a reply to a restarted RDMA read or atomic op.

		/*

		 * If this is a response to a resent RDMA read, we

		 * have to be careful to copy the data to the right

		 * location.

 no AETH, no ACK */

		/*

		 * We got a response so update the timeout.

		 * 4.096 usec. * (1 << qp->timeout)

		/*

		 * Update the RDMA receive state but do the copy w/o

		 * holding the locks and blocking interrupts.

 Get the number of bytes the message was padded by. */

		/*

		 * Check that the data size is >= 0 && <= pmtu.

		 * Remember to account for the AETH header (4) and

		 * ICRC (4).

		/*

		 * If this is a response to a resent RDMA read, we

		 * have to be careful to copy the data to the right

		 * location.

 ACKs READ req. */

 Get the number of bytes the message was padded by. */

		/*

		 * Check that the data size is >= 1 && <= pmtu.

		 * Remember to account for the AETH header (4) and

		 * ICRC (4).

/**

 * qib_rc_rcv_error - process an incoming duplicate or error RC packet

 * @ohdr: the other headers for this packet

 * @data: the packet data

 * @qp: the QP for this packet

 * @opcode: the opcode for this packet

 * @psn: the packet sequence number for this packet

 * @diff: the difference between the PSN and the expected PSN

 * @rcd: the context pointer

 *

 * This is called from qib_rc_rcv() to process an unexpected

 * incoming RC packet for the given QP.

 * Called at interrupt level.

 * Return 1 if no more processing is needed; otherwise return 0 to

 * schedule a response to be sent.

		/*

		 * Packet sequence error.

		 * A NAK will ACK earlier sends and RDMA writes.

		 * Don't queue the NAK if we already sent one.

 Use the expected PSN. */

			/*

			 * Wait to send the sequence NAK until all packets

			 * in the receive queue have been processed.

			 * Otherwise, we end up propagating congestion.

	/*

	 * Handle a duplicate request.  Don't re-execute SEND, RDMA

	 * write or atomic op.  Don't NAK errors, just silently drop

	 * the duplicate request.  Note that r_sge, r_len, and

	 * r_rcv_len may be in use so don't modify them.

	 *

	 * We are supposed to ACK the earliest duplicate PSN but we

	 * can coalesce an outstanding duplicate ACK.  We have to

	 * send the earliest so that RDMA reads can be restarted at

	 * the requester's expected PSN.

	 *

	 * First, find where this duplicate PSN falls within the

	 * ACKs previously sent.

	 * old_req is true if there is an older response that is scheduled

	 * to be sent before sending this one.

		/*

		 * If we didn't find the RDMA read request in the ack queue,

		 * we can ignore this request.

 RETH comes after BTH */

		/*

		 * Address range must be a subset of the original

		 * request and start on pmtu boundaries.

		 * We reuse the old ack_queue slot since the requester

		 * should not back up and request an earlier PSN for the

		 * same request.

		/*

		 * If we didn't find the atomic request in the ack queue

		 * or the send tasklet is already backed up to send an

		 * earlier entry, we can ignore this request.

		/*

		 * Ignore this operation if it doesn't request an ACK

		 * or an earlier RDMA read or atomic is going to be resent.

		/*

		 * Resend the most recent ACK if this request is

		 * after all the previous RDMA reads and atomics.

		/*

		 * Try to send a simple ACK to work around a Mellanox bug

		 * which doesn't accept a RDMA read response or atomic

		 * response as an ACK for earlier SENDs or RDMA writes.

		/*

		 * Resend the RDMA read or atomic op which

		 * ACKs this duplicate request.

/**

 * qib_rc_rcv - process an incoming RC packet

 * @rcd: the context pointer

 * @hdr: the header of this packet

 * @has_grh: true if the header has a GRH

 * @data: the packet data

 * @tlen: the packet length

 * @qp: the QP for this packet

 *

 * This is called from qib_qp_rcv() to process an incoming RC packet

 * for the given QP.

 * Called at interrupt level.

 Check for GRH */

 LRH + BTH */

 LRH + GRH + BTH */

	/*

	 * Process responses (ACKs) before anything else.  Note that the

	 * packet sequence number will be for something in the send work

	 * queue rather than the expected receive packet sequence number.

	 * In other words, this QP is the requester.

 Compute 24 bits worth of difference. */

 Check for opcode sequence errors. */

		/*

		 * Note that it is up to the requester to not send a new

		 * RDMA read or atomic operation before receiving an ACK

		 * for the previous operation.

 OK, process the packet. */

 Check for invalid length PMTU or posted rwqe len. */

 consume RWQE */

 for SEND_ONLY_WITH_IMMEDIATE */

 Get the number of bytes the message was padded by. */

 Check for invalid length. */

 XXX LAST len should be >= 1 */

 Don't count the CRC. */

 zero fields that are N/A */

 Signal completion event if the solicited bit is set. */

 consume RWQE */

 Check rkey & NAK */

 s_ack_queue is size QIB_MAX_RDMA_ATOMIC+1 so use > not >= */

 Check rkey & NAK */

			/*

			 * Update the next expected PSN.  We add 1 later

			 * below, so only add the remainder here.

		/*

		 * We need to increment the MSN here instead of when we

		 * finish sending the result since a duplicate request would

		 * increment it more than once.

 Schedule the send tasklet. */

 Check rkey & NAK */

 Perform atomic OP and save result. */

 Schedule the send tasklet. */

 NAK unknown opcodes. */

 Send an ACK if requested or required. */

 Queue RNR NAK for later */

 Queue NAK for later */

 Queue NAK for later */

/*

 * Copyright (c) 2013 - 2017 Intel Corporation.  All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 nothing allocated */

 nothing allocated */

 stop calls rcu_read_unlock */

/*

 * Copyright (c) 2012 Intel Corporation.  All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * The verbs framework will handle the directed/LID route

	 * packet changes.

	/*

	 * The verbs framework will handle the directed/LID route

	 * packet changes.

 o14-3.2.1 */

 o14-2 */

 o14-1: smp->mkey = 0; */

 4.096 usec. */

/*

 * Send a bad P_Key trap (ch. 14.3.8).

 Send violation trap */

/*

 * Send a bad M_Key trap (ch. 14.3.9).

 Send violation trap */

/*

 * Send a Port Capability Mask Changed trap (ch. 14.3.11).

/*

 * Send a System Image GUID Changed trap (ch. 14.3.12).

/*

 * Send a Node Description Changed trap (ch. 14.3.13).

 IB number port from 1, hdw from 0 */

 GUID 0 is illegal */

 channel adapter */

 This is already in network order */

 Use first-port GUID as node */

 IB number port from 1, hdw from 0 */

 32 blocks of 8 64-bit GUIDs per block */

 GUID 0 is illegal */

 The first is a copy of the read-only HW GUID. */

/**

 * set_overrunthreshold - set the overrun threshold

 * @ppd: the physical port data

 * @n: the new threshold

 *

 * Note that this will only take effect when the link state changes.

/**

 * set_phyerrthreshold - set the physical error threshold

 * @ppd: the physical port data

 * @n: the new threshold

 *

 * Note that this will only take effect when the link state changes.

/**

 * get_linkdowndefaultstate - get the default linkdown state

 * @ppd: the physical port data

 *

 * Returns zero if the default is POLL, 1 if the default is SLEEP.

 Is the mkey in the process of expiring? */

 Clear timeout and mkey protection field. */

 Unset lease timeout on any valid Get/Set/TrapRepress */

 Bad mkey not a violation below level 2 */

 Generate a trap notice. */

 IB numbers ports from 1, hdw from 0 */

 Clear all fields.  Only set the non-zero fields. */

 Only return the mkey if the protection field allows it. */

 pip->diag_code; */

 something is wrong; fall through */

 InitType = 0 */

 InitTypeReply = 0 */

 HCAs ignore VLStallCount and HOQLife */

 pip->vlstallcnt_hoqlife; */

 P_KeyViolations are counted by hardware. */

 Only the hardware GUID is supported for now */

 32.768 usec. response time (guessing) */

 pip->max_credit_hint; */

/**

 * get_pkeys - return the PKEY table

 * @dd: the qlogic_ib device

 * @port: the IB port number

 * @pkeys: the pkey table is placed here

	/*

	 * always a kernel context, no locking needed.

	 * If we get here with ppd setup, no need to check

	 * that pd is valid.

 64 blocks of 32 16-bit P_Key entries */

 IB number port from 1, hdw from 0 */

 32 blocks of 8 64-bit GUIDs per block */

 The first entry is read-only. */

 The only GUID we support is the first read-only entry. */

/**

 * subn_set_portinfo - set port information

 * @smp: the incoming SM packet

 * @ibdev: the infiniband device

 * @port: the port on the device

 *

 * Set Portinfo (see ch. 14.2.5.6).

 Port attributes can only be set on the receiving port */

 IB numbers ports from 1, hdw from 0 */

 Must be a valid unicast LID address. */

 Must be a valid unicast LID address. */

 Allow 1x or 4x to be set (see 14.2.6.6). */

		/*

		 * The IB 1.2 spec. only allows link speed values

		 * 1, 3, 5, 7, 15.  1.2.1 extended to allow specific

		 * speeds.

 Set link down default state. */

 NOP */

 SLEEP */

 POLL */

 Set operational VLs */

	/*

	 * Do the port state change now that the other link parameters

	 * have been set.

	 * Changing the port physical state only makes sense if the link

	 * is down or is being set to down.

	/*

	 * Only state changes of DOWN, ARM, and ACTIVE are valid

	 * and must be in the correct state to take effect (see 7.2.6).

		/*

		 * Don't send a reply if the response would be sent

		 * through the disabled port.

 restore re-reg bit per o14-12.2.1 */

/**

 * rm_pkey - decrecment the reference count for the given PKEY

 * @ppd: the qlogic_ib device

 * @key: the PKEY index

 *

 * Return true if this was the last reference and the hardware table entry

 * needs to be changed.

/**

 * add_pkey - add the given PKEY to the hardware table

 * @ppd: the qlogic_ib device

 * @key: the PKEY

 *

 * Return an error code if unable to add the entry, zero if no change,

 * or 1 if the hardware PKEY register needs to be updated.

 Look for an empty slot or a matching PKEY. */

 If it matches exactly, try to increment the ref count */

 Lost the race. Look for an empty slot below. */

		/*

		 * It makes no sense to have both the limited and unlimited

		 * PKEY set at the same time since the unlimited one will

		 * disable the limited one.

 for qibstats, etc. */

/**

 * set_pkeys - set the PKEY table for ctxt 0

 * @dd: the qlogic_ib device

 * @port: the IB port number

 * @pkeys: the PKEY table

	/*

	 * IB port one/two always maps to context zero/one,

	 * always a kernel context, no locking needed

	 * If we get here with ppd setup, no need to check

	 * that rcd is valid.

		/*

		 * The value of this PKEY table entry is changing.

		 * Remove the old entry in the hardware's array of PKEYs.

	/*

	 * For now, we only send the trap once so no need to process this.

	 * o13-6, o13-7,

	 * o14-3.a4 The SMA shall not send any message in response to a valid

	 * SubnTrapRepress() message.

 Note that AllPortSelect is not valid */

	/*

	 * Set the most significant bit of CM2 to indicate support for

	 * congestion statistics

	/*

	 * Expected response time is 4.096 usec. * 2^18 == 1.073741824 sec.

 32 bit counters */

 Port Sampling code owns the PS* HW counters */

 This function assumes that the xmit_wait lock is already held */

 Port Sampling code owns the PS* HW counters */

 64 bits */

 Adjust counters for any resets done. */

 Congestion PMA packets start at offset 24 not 64 */

	/*

	 * This check is performed only in the GET method because the

	 * SET method ends up calling this anyway.

 Adjust counters for any resets done. */

	/*

	 * Set top 3 bits to indicate interval in picoseconds in

	 * remaining bits.

 Adjust counters for any resets done. */

	/*

	 * Since the HW doesn't support clearing counters, we save the

	 * current count and subtract it from future responses.

 Get counter values before we save them */

		/*

		 * If this is a get/set portinfo, we already check the

		 * M_Key if the MAD is for another port and the M_Key

		 * is OK on the receiving port. This check is needed

		 * to increment the error counters when the M_Key

		 * fails to match on *both* ports.

		/*

		 * The ib_mad module will call us to process responses

		 * before checking for other consumers.

		 * Just tell the caller to process it normally.

		/*

		 * The ib_mad module will call us to process responses

		 * before checking for other consumers.

		 * Just tell the caller to process it normally.

	/*

	 * Expected response time is 4.096 usec. * 2^18 == 1.073741824 sec.

 Is the table index more than what is supported? */

 Is the table index more than what is supported? */

	/* If this packet is the first in the sequence then

	 * zero the total table entry count.

 ccti_limit is 0 to 63 */

		/*

		 * The ib_mad module will call us to process responses

		 * before checking for other consumers.

		 * Just tell the caller to process it normally.

 method is unsupported */

/**

 * qib_process_mad - process an incoming MAD packet

 * @ibdev: the infiniband device this packet came in on

 * @mad_flags: MAD flags

 * @port: the port number this packet came in on

 * @in_wc: the work completion entry for this packet

 * @in_grh: the global route header for this packet

 * @in: the incoming MAD

 * @out: any outgoing MAD reply

 * @out_mad_size: size of the outgoing MAD reply

 * @out_mad_pkey_index: unused

 *

 * Returns IB_MAD_RESULT_SUCCESS if this is a MAD that we are not

 * interested in processing.

 *

 * Note that the verbs framework has already done the MAD sanity checks,

 * and hop count/pointer updating for IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE

 * MADs.

 *

 * This is called by the ib_mad module.

 save counter cache */

 Initialize xmit_wait structure */

/*

 * Copyright (c) 2012 - 2019 Intel Corporation.  All rights reserved.

 * Copyright (c) 2006, 2007, 2008, 2009 QLogic Corporation. All rights reserved.

 * Copyright (c) 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/**

 * qib_ud_loopback - handle send on loopback QPs

 * @sqp: the sending QP

 * @swqe: the send work request

 *

 * This is called from qib_make_ud_req() to forward a WQE addressed

 * to the same HCA.

 * Note that the receive interrupt handler may be calling qib_ud_rcv()

 * while this is being called.

	/*

	 * Check that the qkey matches (except for QP0, see 9.6.1.4.1).

	 * Qkeys with the high order bit set mean use the

	 * qkey from the QP context instead of the WR (see 10.2.5).

	/*

	 * A GRH is expected to precede the data even if not

	 * present on the wire.

	/*

	 * Get the next work request entry to find where to put the data.

 Silently drop packets which are too big. */

 Signal completion event if the solicited bit is set. */

/**

 * qib_make_ud_req - construct a UD request packet

 * @qp: the QP

 * @flags: flags to modify and pass back to caller

 *

 * Assumes the s_lock is held.

 *

 * Return 1 if constructed; otherwise, return 0.

 We are in the error state, flush the work request. */

 If DMAs are in progress, we can't flush immediately. */

 see post_one_send() */

 Construct the header. */

			/*

			 * If DMAs are in progress, we can't generate

			 * a completion for the loopback packet since

			 * it would be out of order.

			 * XXX Instead of waiting, we could queue a

			 * zero length descriptor so we get a callback.

 header size in 32-bit words LRH+BTH+DETH = (8+12+8)/4. */

 Header size in 32-bit words. */

		/*

		 * Don't worry about sending to locally attached multicast

		 * QPs.  It is unspecified by the spec. what happens.

 Header size in 32-bit words. */

 Set VL (see ch. 13.5.3.1) */

 DEST LID */

	/*

	 * Use the multicast QP if the destination LID is a multicast LID.

	/*

	 * Qkeys with the high order bit set mean use the

	 * qkey from the QP context instead of the WR (see 10.2.5).

 remove limited/full membership bit */

	/*

	 * Should not get here, this means hardware failed to validate pkeys.

	 * Punt and return index 0.

/**

 * qib_ud_rcv - receive an incoming UD packet

 * @ibp: the port the packet came in on

 * @hdr: the packet header

 * @has_grh: true if the packet has a GRH

 * @data: the packet data

 * @tlen: the packet length

 * @qp: the QP the packet came on

 *

 * This is called from qib_qp_rcv() to process an incoming UD packet

 * for the given QP.

 * Called at interrupt level.

 Check for GRH */

 LRH + BTH + DETH */

 LRH + GRH + BTH + DETH */

	/*

	 * Get the number of bytes the message was padded by

	 * and drop incomplete packets.

	/*

	 * Check that the permissive LID is only used on QP0

	 * and the QKEY matches (see 9.6.1.4.1 and 9.6.1.5.1).

 Drop invalid MAD packets (see 13.5.3.1). */

 Drop invalid MAD packets (see 13.5.3.1). */

	/*

	 * The opcode is in the low byte when its in network order

	 * (top byte when in host order).

	/*

	 * A GRH is expected to precede the data even if not

	 * present on the wire.

	/*

	 * Get the next work request entry to find where to put the data.

 Silently drop packets which are too big. */

	/*

	 * Save the LMC lower bits if the destination LID is a unicast LID.

 Signal completion event if the solicited bit is set. */

/*

 * Copyright (c) 2007, 2008, 2009 QLogic Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 minimum size of header */

 expected size of headers (for dma_pool) */

 attempt to drain the queue for 5secs */

/*

 * track how many times a process open this driver.

 list element */

 if this is NEW tid-sdma */

 this is large pkt from kmalloc */

 frag size used by PSM */

 last header index or push index */

 dimension of addr (1..3) ... */

 addr array size */

 current tidsm index */

 tidsm array item count */

 payload size so far for header */

 bytes for processing */

 sdma pkts queued counter for this entry */

 tid session member array */

 which pq this pkt belongs to */

 global descq number of entries */

 offset for kvaddr, addr */

 length in page */

 first desc */

 last desc */

 should we put_page? */

 is page dma_mapped? */

 for dma_unmap_page() */

 may be NULL (coherent mem) */

 FIXME: only for pio hack */

 max pages, any more and we coalesce */

	/*

	 * pkts sent to dma engine are queued on this

	 * list head.  the type of the elements of this

	 * list are struct qib_user_sdma_pkt...

	/*

	 * Because above list will be accessed by both process and

	 * signal handler, we need a spinlock for it.

 headers with expected length are allocated from here... */

 packets are allocated from the slab cache... */

 as packets go on the queued queue, they are counted... */

 pending packets, not sending yet */

 sending packets, not complete yet */

 global descq number of entry of last sending packet */

 dma page table */

 protect everything above... */

		/*

		 * dma mapping error, pkt has not managed

		 * this page yet, return the page here so

		 * the caller can ignore this page.

 coalesce case */

	/*

	 * In tid-sdma, the transfer length is restricted by

	 * receiver side current tid page length.

	/*

	 * Then the transfer length is restricted by MTU.

	 * the last descriptor flag is determined by:

	 * 1. the current packet is at frag size length.

	 * 2. the current tid page is done if tid-sdma.

	 * 3. there is no more byte togo if sdma.

 fill the next fragment in this page */

 index */

 offset, len */

 first last desc */

 put page, dma mapped */

 struct page, virt addr */

 dma addr, dma length */

 If there is no more byte togo. (lastdesc==1) */

		/* The packet is done, header is not dma mapped yet.

 If tid-sdma, advance tid info. */

	/*

	 * If this is NOT the last descriptor. (newlen==len)

	 * the current packet is not done yet, but the current

	 * send side page is done.

	/*

	 * If running this driver under PSM with message size

	 * fitting into one transfer unit, it is not possible

	 * to pass this line. otherwise, it is a buggggg.

	/*

	 * Since the current packet is done, and there are more

	 * bytes togo, we need to create a new sdma header, copying

	 * from previous sdma header and modify both.

 Copy the previous sdma header to new sdma header */

 Modify the previous sdma header */

 New pbc length */

 New packet length */

 turn on the header suppression */

 turn off ACK_REQ: 0x04 and EXPECTED_DONE: 0x20 */

 turn off extra bytes: 20-21 bits */

 turn off ACK_REQ: 0x04 */

 New kdeth checksum */

	/* The packet is done, header is not dma mapped yet.

 Modify the new sdma header */

 New pbc length */

 New packet length */

 Set new tid and offset for new sdma header */

 Middle protocol new packet offset */

 New kdeth checksum */

 Next sequence number in new sdma header */

 Init new sdma header. */

 index */

 offset, len */

 first last desc */

 put page, dma mapped */

 struct page, virt addr */

 dma addr, dma length */

 Prepare for next fragment in this page */

 we've too many pages in the iovec, coalesce to a single page */

/*

 * How many pages in this iovec element?

 only user data has page */

 for headers */

 from kmalloc & dma mapped */

 free coherent mem from cache... */

 from kmalloc but not dma mapped */

 return number of pages pinned... */

 map the pages... */

				/* current page has beed taken

				 * care of inside above call.

 if error, return all pages not managed by pkt */

 we need to ignore the first entry here */

	/* need to dma unmap the first entry, this is to restore to

	 * the original state so that caller can free the memory in

 free a packet list -- return counter value of last packet */

/*

 * copy headers, coalesce etc -- pq->lock must be held

 *

 * we queue all the packets to list, returning the

 * number of bytes total.  list must be empty initially,

 * as, if there is an error we clean it...

		/*

		 * This assignment is a bit strange.  it's because the

		 * the pbc counts the number of 32 bit words in the full

		 * packet _except_ the first word of the pbc itself...

		/*

		 * pktnw computation yields the number of 32 bit words

		 * that the caller has indicated in the PBC.  note that

		 * this is one less than the total number of words that

		 * goes to the send DMA engine as the first 32 bit word

		 * of the PBC itself is not counted.  Armed with this count,

		 * we can verify that the packet is consistent with the

		 * iovec lengths.

			/*

			 * Determine if this is tid-sdma or just sdma.

			/*

			 * pbc 'fill1' field is borrowed to pass frag size,

			 * we need to clear it after picking frag size, the

			 * hardware requires this field to be zero.

 setup the first header */

 index */

 offset, len */

 first last desc */

 put page, dma mapped */

 struct page, virt addr */

 dma addr, dma length */

			/* since there is no payload, mark the

				/*

				 * the header is not dma mapped yet.

				 * it should be from kmalloc.

 reset index for push on hw */

 try to clean out queue -- needs pq->lock */

	/*

	 * We need this spin lock here because interrupt handler

	 * might modify this list in qib_user_sdma_send_desc(), also

	 * we can not get interrupted, otherwise it is a deadlock.

 one more packet cleaned */

 clean descriptor queue, returns > 0 if some elements cleaned */

 we're in close, drain packets so that we can cleanup successfully... */

		/*

		 * Since we hold sdma_lock, it is safe without sent_lock.

 SDmaPhyAddr[31:0] */

 SDmaGeneration[1:0] */

 SDmaDwordCount[10:0] */

 SDmaBufOffset[12:2] */

 last */  
 SDmaPhyAddr[47:32] */

			/*

			 * If the packet is >= 2KB mtu equivalent, we

			 * have to use the large buffers, and have to

			 * mark each descriptor as part of a large

			 * buffer packet.

 index for next first */

 reset for next packet */

 advance the tail on the chip if necessary */

 pq->lock must be held, get packets on the wire... */

 non-blocking mode */

	/* In this case, descriptors from this process are not

	 * linked to ppd pending queue, interrupt handler

	 * won't update this process, it is OK to directly

	 * modify without sdma lock.

	/*

	 * Blocking mode for single rail process, we must

	 * release/regain sdma_lock to give other process

	 * chance to make progress. This is important for

	 * performance.

 why not -ECOMM like qib_user_sdma_push_pkts() below? */

 if I have packets not complete yet */

 if I have complete packets to be freed */

 force packets onto the sdma hw queue... */

			/*

			 * Lazily clean hw queue.

/*

 * Copyright (c) 2012 Intel Corporation. All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * QLogic_IB "Two Wire Serial Interface" driver.

 * Originally written for a not-quite-i2c serial eeprom, which is

 * still used on some supported boards. Later boards have added a

 * variety of other uses, most board-specific, so the bit-boffing

 * part has been split off to this file, while the other parts

 * have been moved to chip-specific files.

 *

 * We have also dropped all pretense of fully generic (e.g. pretend

 * we don't know whether '1' is the higher voltage) interface, as

 * the restrictions of the generic i2c interface (e.g. no access from

 * driver itself) make it unsuitable for this use.

/**

 * i2c_wait_for_writes - wait for a write

 * @dd: the qlogic_ib device

 *

 * We use this instead of udelay directly, so we can make sure

 * that previous register writes have been flushed all the way

 * to the chip.  Since we are delaying anyway, the cost doesn't

 * hurt, and makes the bit twiddling more regular

	/*

	 * implicit read of EXTStatus is as good as explicit

	 * read of scratch, if all we want to do is flush

	 * writes.

 inlined, so prevent compiler reordering */

/*

 * QSFP modules are allowed to hold SCL low for 500uSec. Allow twice that

 * for "almost compliant" modules

/* BUF_WAIT is time bus must be free between STOP or ACK and to next START.

 * Should be 20, but some chips need more.

 SCL is meant to be bare-drain, so never set "OUT", just DIR */

	/*

	 * Allow for slow slaves by simple

	 * delay for falling edge, sampling on rise.

 SDA is meant to be bare-drain, so never set "OUT", just DIR */

 SDA is meant to be bare-drain, so never set "OUT", just DIR */

/**

 * i2c_ackrcv - see if ack following write is true

 * @dd: the qlogic_ib device

 AT ENTRY SCL = LOW */

 change direction, ignore data */

/**

 * rd_byte - read a byte, sending STOP on last, else ACK

 * @dd: the qlogic_ib device

 * @last: identifies the last read

 *

 * Returns byte shifted out of device

/**

 * wr_byte - write a byte, one bit at a time

 * @dd: the qlogic_ib device

 * @data: the byte to write

 *

 * Returns 0 if we got the following ack, otherwise 1

/*

 * issue TWSI start sequence:

 * (both clock/data high, clock high, data low while clock is high)

/**

 * stop_seq - transmit the stop sequence

 * @dd: the qlogic_ib device

 *

 * (both clock/data low, clock high, data high while clock is high)

/**

 * stop_cmd - transmit the stop condition

 * @dd: the qlogic_ib device

 *

 * (both clock/data low, clock high, data high while clock is high)

/**

 * qib_twsi_reset - reset I2C communication

 * @dd: the qlogic_ib device

	/* Both SCL and SDA should be high. If not, there

	 * is something wrong.

	/*

	 * Force pins to desired innocuous state.

	 * This is the default power-on state with out=0 and dir=0,

	 * So tri-stated and should be floating high (barring HW problems)

	/*

	 * Clock nine times to get all listeners into a sane state.

	 * If SDA does not go high at any point, we are wedged.

	 * One vendor recommends then issuing START followed by STOP.

	 * we cannot use our "normal" functions to do that, because

	 * if SCL drops between them, another vendor's part will

	 * wedge, dropping SDA and keeping it low forever, at the end of

	 * the next transaction (even if it was not the device addressed).

	 * So our START and STOP take place with SCL held high.

 Note if SDA is high, but keep clocking to sync slave */

		/*

		 * We saw a high, which we hope means the slave is sync'd.

		 * Issue START, STOP, pause for T_BUF.

 Drop SDA to issue START */

 Guarantee .6 uSec setup */

 Guarantee .6 uSec hold */

 At this point, SCL is high, SDA low. Raise SDA for STOP */

/* Write byte to TWSI, optionally prefixed with START or suffixed with

 * STOP.

 * returns 0 if OK (ACK received), else != 0

 Leaves SCL low (from i2c_ackrcv()) */

 Added functionality for IBA7220-based cards */

/*

 * qib_twsi_blk_rd

 * Formerly called qib_eeprom_internal_read, and only used for eeprom,

 * but now the general interface for data transfer from twsi devices.

 * One vestige of its former role is that it recognizes a device

 * QIB_TWSI_NO_DEV and does the correct operation for the legacy part,

 * which responded to all TWSI device codes, interpreting them as

 * address within device. On all other devices found on board handled by

 * this driver, the device is followed by a one-byte "address" which selects

 * the "register" or "offset" within the device from which data should

 * be read.

 legacy not-really-I2C */

 Actual I2C */

		/*

		 * SFF spec claims we do _not_ stop after the addr

		 * but simply issue a start with the "read" dev-addr.

		 * Since we are implicitely waiting for ACK here,

		 * we need t_buf (nominally 20uSec) before that start,

		 * and cannot rely on the delay built in to the STOP

	/*

	 * block devices keeps clocking data out as long as we ack,

	 * automatically incrementing the address. Some have "pages"

	 * whose boundaries will not be crossed, but the handling

	 * of these is left to the caller, who is in a better

	 * position to know.

		/*

		 * Get and store data, sending ACK if length remaining,

		 * else STOP

/*

 * qib_twsi_blk_wr

 * Formerly called qib_eeprom_internal_write, and only used for eeprom,

 * but now the general interface for data transfer to twsi devices.

 * One vestige of its former role is that it recognizes a device

 * QIB_TWSI_NO_DEV and does the correct operation for the legacy part,

 * which responded to all TWSI device codes, interpreting them as

 * address within device. On all other devices found on board handled by

 * this driver, the device is followed by a one-byte "address" which selects

 * the "register" or "offset" within the device to which data should

 * be written.

 Real I2C */

		/*

		 * Wait for write complete by waiting for a successful

		 * read (the chip replies with a zero after the write

		 * cmd completes, and before it writes to the eeprom.

		 * The startcmd for the read will fail the ack until

		 * the writes have completed.   We do this inline to avoid

		 * the debug prints that are in the real read routine

		 * if the startcmd fails.

		 * We also use the proper device address, so it doesn't matter

		 * whether we have real eeprom_dev. Legacy likes any address.

 now read (and ignore) the resulting byte */

/*

 * Copyright (c) 2012 Intel Corporation. All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * driver stats field names, one line per stat, single string.  Used by

 * programs like ipathstats to print the stats in a way which works for

 * different versions of drivers, without changing program source.

 * if qlogic_ib_stats changes, this needs to change.  Names need to be

 * 12 chars or less (w/o newline), for proper display by ipathstats utility.

 no null */

 read the per-device counters */

 read the per-device counters */

/*

 * Could use file_inode(file)->i_ino to figure out which file,

 * instead of separate routine for each, but for now, this works...

 read the per-port names (same for each port) */

 read the per-port counters for port 1 (pidx 0) */

 read the per-port counters for port 2 (pidx 1) */

/*

 * read the per-port QSFP data for port 1 (pidx 0)

/*

 * read the per-port QSFP data for port 2 (pidx 1)

 create the per-unit directory */

 create the files in the new directory */

 create the files in the new directory */

/*

 * This fills everything in when the fs is mounted, to handle umount/mount

 * after device init.  The direct add_cntr_files() call handles adding

 * them from the init code, when the fs is already mounted.

	/*

	 * On first unit initialized, qib_super will not yet exist

	 * because nobody has yet tried to mount the filesystem, so

	 * we can't consider that to be an error; if an error occurs

	 * during the mount, that will get a complaint, so this is OK.

	 * add_cntr_files() for all units is done at mount from

	 * qibfs_fill_super(), so one way or another, everything works.

/*

 * Copyright (c) 2012, 2013 Intel Corporation. All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This is really, really weird shit - write() and writev() here

 * have completely unrelated semantics.  Sucky userland ABI,

 * film at 11.

/*

 * Convert kernel virtual addresses to physical addresses so they don't

 * potentially conflict with the chip addresses used as mmap offsets.

 * It doesn't really matter what mmap offset we use as long as we can

 * interpret it correctly.

 If context sharing is not requested, allow the old size structure */

	/*

	 * have to mmap whole thing

	/*

	 * for this use, may be cfgctxts summed over all chips that

	 * are are configured and present

 unit (chip/board) our context is on */

 for now, only a single page */

	/*

	 * Doing this per context, and based on the skip value, etc.  This has

	 * to be the actual buffer size, since the protocol code treats it

	 * as an array.

	 *

	 * These have to be set to user addresses in the user code via mmap.

	 * These values are used on return to user code for the mmap target

	 * addresses only.  For 32 bit, same 44 bit address problem, so use

	 * the physical address, not virtual.  Before 2.6.11, using the

	 * page_address() macro worked, but in 2.6.11, even that returns the

	 * full 64 bit address (upper bits all 1's).  So far, using the

	 * physical addresses (or chip offsets, for chip mapping) works, but

	 * no doubt some future kernel release will change that, and we'll be

	 * on to yet another method of dealing with this.

	 * Normally only one of rcvhdr_tailaddr or rhf_offset is useful

	 * since the chips with non-zero rhf_offset don't normally

	 * enable tail register updates to host memory, but for testing,

	 * both can be enabled and used.

 setup per-unit (not port) status area for user programs */

 Master's PIO buffers are after all the slave's */

 only spi_subctxt_* fields should be set in this block! */

	/*

	 * All user buffers are 2KB buffers.  If we ever support

	 * giving 4KB buffers to user processes, this will need some

	 * work.  Can't use piobufbase directly, because it has

	 * both 2K and 4K buffer base values.

	/*

	 * user mode PIO buffers are always 2KB, even when 4KB can

	 * be received, and sent via the kernel; this is ibmaxlen

	 * for 2K MTU.

 maxlen, not ibmtu */

 QLogic-built, not kernel.org */

/**

 * qib_tid_update - update a context TID

 * @rcd: the context

 * @fp: the qib device file

 * @ti: the TID information

 *

 * The new implementation as of Oct 2004 is that the driver assigns

 * the tid and returns it to the caller.   To reduce search time, we

 * keep a cursor for each context, walking the shadow tid array to find

 * one that's not in use.

 *

 * For now, if we can't allocate the full list, we fail, although

 * in the long run, we'll allocate as many as we can, and the

 * caller will deal with that by trying the remaining pages later.

 * That means that when we fail, we have to mark the tids as not in

 * use again, in our shadow copy.

 *

 * It's up to the caller to free the tids when they are done.

 * We'll unlock the pages as they free them.

 *

 * Also, right now we are locking one page at a time, but since

 * the intended use of this routine is for a single group of

 * virtually contiguous pages, that should change to improve

 * performance.

 make sure it all fits in tid_pg_list */

 before decrement; chip actual # */

 virtual address of first page in transfer */

		/*

		 * if (ret == -EBUSY)

		 * We can't continue because the pagep array won't be

		 * initialized. This should never happen,

		 * unless perhaps the user has mpin'ed the pages

		 * themselves.

			/*

			 * Oops, wrapped all the way through their TIDs,

			 * and didn't have enough free; see comments at

			 * start of routine

 last tidlist[i] not filled in */

 we "know" system pages and TID pages are same size */

		/*

		 * don't need atomic or it's overhead

 PERFORMANCE: below should almost certainly be cached */

		/*

		 * don't check this tid in qib_ctxtshadow, since we

		 * just filled it in; start with the next one.

 jump here if copy out of updated info failed... */

 same code that's in qib_free_tid() */

 just in case size changes in future */

				/* PERFORMANCE: below should almost certainly

				 * be cached

		/*

		 * Copy the updated array, with qib_tid's filled in, back

		 * to user.  Since we did the copy in already, this "should

		 * never fail" If it does, we have to clean up...

/**

 * qib_tid_free - free a context TID

 * @rcd: the context

 * @subctxt: the subcontext

 * @ti: the TID info

 *

 * right now we are unlocking one page at a time, but since

 * the intended use of this routine is for a single group of

 * virtually contiguous pages, that should change to improve

 * performance.  We check that the TID is in range for this context

 * but otherwise don't check validity; if user has an error and

 * frees the wrong tid, it's only their own data that can thereby

 * be corrupted.  We do check that the TID was in use, for sanity

 * We always use our idea of the saved address, not the address that

 * they pass in to us.

 just in case size changes in future */

		/*

		 * small optimization; if we detect a run of 3 or so without

		 * any set, use find_first_bit again.  That's mainly to

		 * accelerate the case where we wrapped, so we have some at

		 * the beginning, and some at the end, and a big gap

		 * in the middle.

			/* PERFORMANCE: below should almost certainly be

			 * cached

/**

 * qib_set_part_key - set a partition key

 * @rcd: the context

 * @key: the key

 *

 * We can have up to 4 active at a time (other than the default, which is

 * always allowed).  This is somewhat tricky, since multiple contexts may set

 * the same key, so we reference count them, and clean up at exit.  All 4

 * partition keys are packed into a single qlogic_ib register.  It's an

 * error for a process to set the same pkey multiple times.  We provide no

 * mechanism to de-allocate a pkey at this time, we may eventually need to

 * do that.  I've used the atomic operations, and no locking, and only make

 * a single pass through what's available.  This should be more than

 * adequate for some time. I'll think about spinlocks or the like if and as

 * it's necessary.

 nothing to do; this key always valid */

	/*

	 * Set the full membership bit, because it has to be

	 * set in the register or the packet, and it seems

	 * cleaner to set in the register than to force all

	 * callers to set it.

			/*

			 * lost race, decrement count, catch below

			/*

			 * It makes no sense to have both the limited and

			 * full membership PKEY set at the same time since

			 * the unlimited one will disable the limited one.

/**

 * qib_manage_rcvq - manage a context's receive queue

 * @rcd: the context

 * @subctxt: the subcontext

 * @start_stop: action to carry out

 *

 * start_stop == 0 disables receive on the context, for use in queue

 * overflow conditions.  start_stop==1 re-enables, to be used to

 * re-init the software copy of the head register

 atomically clear receive enable ctxt. */

		/*

		 * On enable, force in-memory copy of the tail register to

		 * 0, so that protocol code doesn't have to worry about

		 * whether or not the chip has yet updated the in-memory

		 * copy or not on return from the system call. The chip

		 * always resets it's tail register back to 0 on a

		 * transition from disabled to enabled.

 always; new head should be equal to new tail; see above */

 check for match independent of the global bit */

 common code for the mappings on dma_alloc_coherent mem */

	/*

	 * shared context user code requires rcvhdrq mapped r/w, others

	 * only allowed readonly mapping.

 don't allow them to later change with mprotect */

	/*

	 * This is real hardware, so use io_remap.  This is the mechanism

	 * for the user process to update the head registers for their ctxt

	 * in the chip.

	/*

	 * When we map the PIO buffers in the chip, we want to map them as

	 * writeonly, no read possible; unfortunately, x86 doesn't allow

	 * for this in hardware, but we still prevent users from asking

	 * for it.

	/*

	 * don't allow them to later change to readable with mprotect (for when

	 * not initially mapped readable, as is normally the case)

 We used PAT if wc_cookie == 0 */

 don't allow them to later change to writeable with mprotect */

/*

 * qib_file_vma_fault - handle a VMA page fault.

	/*

	 * Each process has all the subctxt uregbase, rcvhdrq, and

	 * rcvegrbufs mmapped - as an array for all the processes,

	 * and also separately for this process.

 rcvegrbufs are read-only on the slave */

		/*

		 * Don't allow permission to later change to writeable

		 * with mprotect.

/**

 * qib_mmapf - mmap various structures into user space

 * @fp: the file pointer

 * @vma: the VM area

 *

 * We use this to have a shared buffer between the kernel and the user code

 * for the rcvhdr queue, egr buffers, and the per-context user regs and pio

 * buffers in the chip.  We have the open and close entries so we can bump

 * the ref count and keep the driver from being unloaded while still mapped.

	/*

	 * This is the qib_do_user_init() code, mapping the shared buffers

	 * and per-context user registers into the user process. The address

	 * referred to by vm_pgoff is the file offset passed via mmap().

	 * For shared contexts, this is the kernel vmalloc() address of the

	 * pages to share with the master.

	 * For non-shared or master ctxts, this is a physical address.

	 * We only do one mmap for each space mapped.

	/*

	 * Check for 0 in case one of the allocations failed, but user

	 * called mmap anyway.

	/*

	 * Physical addresses must fit in 40 bits for our hardware.

	 * Check for kernel virtual addresses first, anything else must

	 * match a HW or memory address.

 ctxt is not shared */

 caller is the master */

 caller is a slave */

 in-memory copy of pioavail registers */

		/*

		 * The rcvhdrq itself; multiple pages, contiguous

		 * from an i/o perspective.  Shared contexts need

		 * to map r/w, so we allow writing.

 in-memory copy of rcvhdrq tail register */

 invalid */

	/*

	 * If process has NOT already set it's affinity, select and

	 * reserve a processor for it on the local NUMA node.

	/*

	 * If process has NOT already set it's affinity, select and

	 * reserve a processor for it, as a rendevous for all

	 * users of the driver.  If they don't actually later

	 * set affinity to this cpu, or set it to some other cpu,

	 * it just means that sooner or later we don't recommend

	 * a cpu, and let the scheduler do it's best.

/*

 * Check that userland and driver are compatible for subcontexts.

 this code is written long-hand for clarity */

 no promise of compatibility if major mismatch */

 no subctxt implementation so cannot be compatible */

 3 is only compatible with itself */

 >= 4 are compatible (or are expected to be) */

 make no promises yet for future major versions */

	/*

	 * If the user is requesting zero subctxts,

	 * skip the subctxt allocation.

 Check for subctxt compatibility */

 Note: rcd->rcvhdrq_size isn't initialized yet. */

	/*

	 * Allocate memory for use in qib_tid_update() at open to

	 * reduce cost of expected send setup per message segment

/*

 * Select a context on the given device, either using a requested port

 * or the port based on the context number.

 find device (with ACTIVE ports) with fewest ctxts in use */

 device portion of usable() */

 Skip ctxts which are not yet open */

 Skip ctxt if it doesn't match the requested one */

 Verify the sharing process matches the master */

 The real work is performed later in qib_assign_ctxt() */

 no cpu affinity by default */

/*

 * Get ctxt early, so can set affinity prior to memory allocation.

 Check to be sure we haven't already initialized this file */

 for now, if major version is different, bail */

 Subctxts don't need to initialize anything since master did it. */

 some ctxts may get extra buffers, calculate that here */

	/*

	 * All user buffers are 2KB buffers.  If we ever support

	 * giving 4KB buffers to user processes, this will need some

	 * work.  Can't use piobufbase directly, because it has

	 * both 2K and 4K buffer base values.  So check and handle.

	/*

	 * try to ensure that processes start up with consistent avail update

	 * for their own range, at least.   If system very quiet, it might

	 * have the in-memory copy out of date at startup for this range of

	 * buffers, when a context gets re-used.  Do after the chg_pioavail

	 * and before the rest of setup, so it's "almost certain" the dma

	 * will have occurred (can't 100% guarantee, but should be many

	 * decimals of 9s, with this ordering), given how much else happens

	 * after this.

	/*

	 * Now allocate the rcvhdr Q and eager TIDs; skip the TID

	 * array for time being.  If rcd->ctxt > chip-supported,

	 * we need to do extra stuff here to handle by handling overflow

	 * through ctxt 0, someday

 start at beginning after open */

 initialize poll variables... */

	/*

	 * Now enable the ctxt for receive.

	 * For chips that are set to DMA the tail register to memory

	 * when they change (and when the update bit transitions from

	 * 0 to 1.  So for those chips, we turn it off and then back on.

	 * This will (very briefly) affect any other open ctxts, but the

	 * duration is very short, and therefore isn't an issue.  We

	 * explicitly set the in-memory tail copy to 0 beforehand, so we

	 * don't have to wait to be sure the DMA update has happened

	 * (chip resets head/tail to 0 on transition to enable).

 Notify any waiting slaves */

/**

 * unlock_expected_tids - unlock any expected TID entries context still had

 * in use

 * @rcd: ctxt

 *

 * We don't actually update the chip here, because we do a bulk update

 * below, using f_clear_tids.

 ensure all pio buffer writes in progress are flushed */

 drain user sdma queue */

		/*

		 * XXX If the master closes the context before the slave(s),

		 * revoke the mmap for the eager receive queue so

		 * the slave(s) don't wait for receive data forever.

 early; no interrupt users after this */

 atomically clear receive enable ctxt and intr avail. */

 clean up the pkeys for this ctxt user */

 after releasing the mutex */

 Number of user ctxts available for this device. */

		/*

		 * if link is down, or otherwise not usable, delay

		 * the caller up to 30 seconds, so we don't thrash

		 * in trying to get the chip back to ACTIVE, and

		 * set flag so they make the call again.

			/*

			 * subctxt_cnt is 0 if not shared, so do base

			 * separately, first, then remaining subctxt, if any

/*

 * Find all user contexts in use, and set the specified bit in their

 * event mask.

 * See also find_ctxt() for a similar use, that is specific to send buffers.

			/*

			 * subctxt_cnt is 0 if not shared, so do base

			 * separately, first, then remaining subctxt, if any

/*

 * clear the event notifier events for this context.

 * For the DISARM_BUFS case, we also take action (this obsoletes

 * the older QIB_CMD_DISARM_BUFS, but we keep it for backwards

 * compatibility.

 * Other bits don't currently require actions, just atomically clear.

 * User process then performs actions appropriate to bit having been

 * set, if desired, and checks again in future.

 force an update of PIOAvail reg */

/*

 * Create per-unit files in /dev

/*

 * Remove per-unit files in /dev

 * void, core kernel returns no errors for this stuff

/*

 * Copyright (c) 2008, 2009, 2010 QLogic Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/**

 * qib_disarm_piobufs - cancel a range of PIO buffers

 * @dd: the qlogic_ib device

 * @first: the first PIO buffer to cancel

 * @cnt: the number of PIO buffers to cancel

 *

 * Cancel a range of PIO buffers. Used at user process close,

 * in case it died while writing to a PIO buffer.

/*

 * This is called by a user process when it sees the DISARM_BUFS event

 * bit is set.

	/*

	 * Don't need uctxt_lock here, since user has called in to us.

	 * Clear at start in case more interrupts set bits while we

	 * are disarming

		/*

		 * subctxt_cnt is 0 if not shared, so do base

		 * separately, first, then remaining subctxt, if any

/*

 * Return true if send buffer is being used by a user context.

 * Sets  _QIB_EVENT_DISARM_BUFS_BIT in user_event_mask as a side effect

			/*

			 * subctxt_cnt is 0 if not shared, so do base

			 * separately, first, then remaining subctxt, if any

/*

 * Disarm a set of send buffers.  If the buffer might be actively being

 * written to, mark the buffer to be disarmed later when it is not being

 * written to.

 *

 * This should only be called from the IRQ error handler.

		/*

		 * If the buffer is owned by the DMA hardware,

		 * reset the DMA engine.

		/*

		 * If the kernel is writing the buffer or the buffer is

		 * owned by a user process, we can't clear it yet.

 do cancel_sends once per port that had sdma piobufs in error */

/**

 * update_send_bufs - update shadow copy of the PIO availability map

 * @dd: the qlogic_ib device

 *

 * called whenever our local copy indicates we have run out of send buffers

	/*

	 * If the generation (check) bits have changed, then we update the

	 * busy bit for the corresponding PIO buffer.  This algorithm will

	 * modify positions to the value they already have in some cases

	 * (i.e., no change), but it's faster than changing only the bits

	 * that have changed.

	 *

	 * We would like to do this atomicly, to avoid spinlocks in the

	 * critical send path, but that's not really possible, given the

	 * type of changes, and that this routine could be called on

	 * multiple cpu's simultaneously, so we lock in this routine only,

	 * to avoid conflicting updates; all we change is the shadow, and

	 * it's a single 64 bit memory location, so by definition the update

	 * is atomic in terms of what other cpu's can see in testing the

	 * bits.  The spin_lock overhead isn't too bad, since it only

	 * happens when all buffers are in use, so only cpu overhead, not

	 * latency or bandwidth is affected.

/*

 * Debugging code and stats updates if no pio buffers available.

 not atomic, but if we lose a stat count in a while, that's OK */

/*

 * Common code for normal driver send buffer allocation, and reserved

 * allocation.

 *

 * Do appropriate marking as busy, etc.

 * Returns buffer pointer if one is found, otherwise NULL.

 number in range to check */

		/*

		 * Minor optimization.  If we had no buffers on last call,

		 * start out by doing the update; continue and do scan even

		 * if no buffers were updated, to be paranoid.

	/*

	 * While test_and_set_bit() is atomic, we do that and then the

	 * change_bit(), and the pair is not.  See if this is the cause

	 * of the remaining armlaunch errors.

 adjust to min possible  */

 flip generation bit */

 remember that the buffer can be written to now */

 first == last on VL15, avoid */

			/*

			 * First time through; shadow exhausted, but may be

			 * buffers available, try an update and then rescan.

/*

 * Record that the caller is finished writing to the buffer so we don't

 * disarm it while it is being written and disarm it now if needed.

/**

 * qib_chg_pioavailkernel - change which send buffers are available for kernel

 * @dd: the qlogic_ib device

 * @start: the starting send buffer number

 * @len: the number of send buffers

 * @avail: true if the buffers are available for kernel use, false otherwise

 * @rcd: the context pointer

 There are two bits per send buffer (busy and generation) */

 Set or clear the busy bit in the shadow. */

			/*

			 * The BUSY bit will never be set, because we disarm

			 * the user buffers before we hand them back to the

			 * kernel.  We do have to make sure the generation

			 * bit is set correctly in shadow, since it could

			 * have changed many times while allocated to user.

			 * We can't use the bitmap functions on the full

			 * dma array because it is always little-endian, so

			 * we have to flip to host-order first.

			 * BITS_PER_LONG is slightly wrong, since it's

			 * always 64 bits per register in chip...

			 * We only work on 64 bit kernels, so that's OK.

/*

 * Flush all sends that might be in the ready to send state, as well as any

 * that are in the process of being sent.  Used whenever we need to be

 * sure the send side is idle.  Cleans up all buffer state by canceling

 * all pio buffers, and issuing an abort, which cleans up anything in the

 * launch fifo.  The cancel is superfluous on some chip versions, but

 * it's safer to always do it.

 * PIOAvail bits are updated by the chip as if a normal send had happened.

	/*

	 * Tell PSM to disarm buffers again before trying to reuse them.

	 * We need to be sure the rcd doesn't change out from under us

	 * while we do so.  We hold the two locks sequentially.  We might

	 * needlessly set some need_disarm bits as a result, if the

	 * context is closed after we release the uctxt_lock, but that's

	 * fairly benign, and safer than nesting the locks.

				/*

				 * subctxt_cnt is 0 if not shared, so do base

				 * separately, first, then remaining subctxt,

				 * if any

/*

 * Force an update of in-memory copy of the pioavail registers, when

 * needed for any of a variety of reasons.

 * If already off, this routine is a nop, on the assumption that the

 * caller (or set of callers) will "do the right thing".

 * This is a per-device operation, so just the first port.

	/*

	 * Cancel sends when the link goes DOWN so that we aren't doing it

	 * at INIT when we might be trying to send SMI packets.

/*

 * Link is at INIT.

 * We start the HoL timer so we can detect stuck packets blocking SMP replies.

 * Timer may already be running, so use mod_timer, not add_timer.

/*

 * Link is up, continue any user processes, and ensure timer

 * is a nop, if running.  Let timer keep running, if set; it

 * will nop when it sees the link is up.

/*

 * This is only called via the timer.

 If hardware error, etc, skip. */

		/*

		 * Try to flush sends in case a stuck packet is blocking

		 * SMP replies.

/*

 * Copyright (c) 2006, 2007, 2008, 2009 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * QSFP support for ib_qib driver, using "Two Wire Serial Interface" driver

 * in qib_twsi.c

	/*

	 * We presume, if we are called at all, that this board has

	 * QSFP. This is on the same i2c chain as the legacy parts,

	 * but only responds if the module is selected via GPIO pins.

	 * Further, there are very long setup and hold requirements

	 * on MODSEL.

	/*

	 * Module could take up to 2 Msec to respond to MOD_SEL, and there

	 * is no way to tell if it is ready, so we must wait.

 Make sure TWSI bus is in sane state. */

 All QSFP modules are at A0 */

 Some QSFP's fail first try. Retry as experiment */

 qib_twsi_blk_rd() 1 for error, else 0 */

	/*

	 * Module could take up to 10 uSec after transfer before

	 * ready to respond to MOD_SEL negation, and there is no way

	 * to tell if it is ready, so we must wait.

 set QSFP MODSEL, RST. LP all high */

	/*

	 * Module could take up to 2 Msec to respond to MOD_SEL

	 * going away, and there is no way to tell if it is ready.

	 * so we must wait.

/*

 * qsfp_write

 * We do not ordinarily write the QSFP, but this is needed to select

 * the page on non-flat QSFPs, and possibly later unusual cases

	/*

	 * We presume, if we are called at all, that this board has

	 * QSFP. This is on the same i2c chain as the legacy parts,

	 * but only responds if the module is selected via GPIO pins.

	 * Further, there are very long setup and hold requirements

	 * on MODSEL.

	/*

	 * Module could take up to 2 Msec to respond to MOD_SEL,

	 * and there is no way to tell if it is ready, so we must wait.

 Make sure TWSI bus is in sane state. */

 All QSFP modules are at A0 */

 qib_twsi_blk_wr() 1 for error, else 0 */

	/*

	 * Module could take up to 10 uSec after transfer before

	 * ready to respond to MOD_SEL negation, and there is no way

	 * to tell if it is ready, so we must wait.

 set QSFP MODSEL, RST, LP high */

	/*

	 * Module could take up to 2 Msec to respond to MOD_SEL

	 * going away, and there is no way to tell if it is ready.

	 * so we must wait.

/*

 * For validation, we want to check the checksums, even of the

 * fields we do not otherwise use. This function reads the bytes from

 * <first> to <next-1> and returns the 8lsbs of the sum, or <0 for errors

 ensure sane contents on invalid reads, for cable swaps */

		/*

		 * If cable is paged, rather than "flat memory", we need to

		 * set the page to zero, Even if it already appears to be zero.

 Second checksum covers 192 to (serial, date, lot) */

 Holds longest string */

/*

 * Initialize structures that control access to QSFP. Called once per port

 * on cards that support QSFP.

 Initialize work struct for later QSFP events */

	/*

	 * Later, we may want more validation. For now, just set up pins and

	 * blip reset. If module is present, call qib_refresh_qsfp_cache(),

	 * to do further init.

 Generous RST dwell */

/*

 * Copyright (c) 2012 Intel Corporation. All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Functions specific to the serial EEPROM on cards handled by ib_qib.

 * The actual serail interface code is in qib_twsi.c. This file is a client

/**

 * qib_eeprom_read - receives bytes from the eeprom via I2C

 * @dd: the qlogic_ib device

 * @eeprom_offset: address to read from

 * @buff: where to store result

 * @len: number of bytes to receive

/*

 * Actually update the eeprom, first doing write enable if

 * needed, then restoring write enable state.

 * Must be called with eep_lock held

/**

 * qib_eeprom_write - writes data to the eeprom via I2C

 * @dd: the qlogic_ib device

 * @eeprom_offset: where to place data

 * @buff: data to write

 * @len: number of bytes to write

	/*

	 * Limit length checksummed to max length of actual data.

	 * Checksum of erased eeprom will still be bad, but we avoid

	 * reading past the end of the buffer we were passed.

/**

 * qib_get_eeprom_info- get the GUID et al. from the TSWI EEPROM device

 * @dd: the qlogic_ib device

 *

 * We have the capability to use the nguid field, and get

 * the guid from the first chip's flash, to use for all of them.

	/*

	 * Read full flash, not just currently used part, since it may have

	 * been written with a newer definition.

	/*

	 * Use "public" eeprom read function, which does locking and

	 * figures out device. This will migrate to chip-specific.

 don't allow GUID if all 0 or all 1's */

 complain, but allow it */

		/*

		 * Original incorrect GUID format in flash; fix in

		 * core copy, by shifting up 2 octets; don't need to

		 * change top octet, since both it and shifted are 0.

	/*

	 * Things are slightly complicated by the desire to transparently

	 * support both the Pathscale 10-digit serial number and the QLogic

	 * 13-character version.

		/*

		 * This board has a Serial-prefix, which is stored

		 * elsewhere for backward-compatibility.

/*

 * Copyright (c) 2012 Intel Corporation. All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file is conditionally built on x86_64 only.  Otherwise weak symbol

 * versions of the functions exported from here are used.

/**

 * qib_enable_wc - enable write combining for MMIO writes to the device

 * @dd: qlogic_ib device

 *

 * This routine is x86_64-specific; it twiddles the CPU's MTRRs to enable

 * write combining.

	/*

	 * Set the PIO buffers to be WCCOMB, so we get HT bursts to the

	 * chip.  Linux (possibly the hardware) requires it to be on a power

	 * of 2 address matching the length (which has to be a power of 2).

	 * For rev1, that means the base address, for rev2, it will be just

	 * the PIO buffers themselves.

	 * For chips with two sets of buffers, the calculations are

	 * somewhat more complicated; we need to sum, and the piobufbase

	 * register has both offsets, 2K in low 32 bits, 4K in high 32 bits.

	 * The buffers are still packed, so a single range covers both.

 2 sizes for chip */

 all current chips */

 single buffer size (2K, currently) */

 do nothing */

 use error from routine */

/**

 * qib_disable_wc - disable write combining for MMIO writes to the device

 * @dd: qlogic_ib device

/**

 * qib_unordered_wc - indicate whether write combining is ordered

 *

 * Because our performance depends on our ability to do write combining mmio

 * writes in the most efficient way, we need to know if we are on an Intel

 * or AMD x86_64 processor.  AMD x86_64 processors flush WC buffers out in

 * the order completed, and so no special flushing is required to get

 * correct ordering.  Intel processors, however, will flush write buffers

 * out in "random" orders, and so explicit ordering is needed at times.

/*

 * Copyright (c) 2012 - 2018 Intel Corporation.  All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Translate ib_wr_opcode into ib_wc_opcode.

/*

 * System image GUID.

/*

 * Count the number of DMA descriptors needed to send length bytes of data.

 * Don't modify the qib_sge_state to get the count.

 * Return zero if any of the segments is not aligned.

 count the header */

/*

 * Copy from the SGEs to the data buffer.

/**

 * qib_qp_rcv - processing an incoming packet on a QP

 * @rcd: the context pointer

 * @hdr: the packet header

 * @has_grh: true if the packet has a GRH

 * @data: the packet data

 * @tlen: the packet length

 * @qp: the QP the packet came on

 *

 * This is called from qib_ib_rcv() to process an incoming packet

 * for the given QP.

 * Called at interrupt level.

 Check for valid receive state. */

/**

 * qib_ib_rcv - process an incoming packet

 * @rcd: the context pointer

 * @rhdr: the header of the packet

 * @data: the packet payload

 * @tlen: the packet length

 *

 * This is called from qib_kreceive() to process an incoming packet at

 * interrupt level. Tlen is the length of the header + data + CRC in bytes.

 24 == LRH+BTH+CRC */

 Check for a valid destination LID (see ch. 7.11.1). */

 Check for GRH */

 Get the destination QP number. */

		/*

		 * Notify rvt_multicast_detach() if it is waiting for us

		 * to finish.

/*

 * This is called from a timer to check for QPs

 * which need kernel memory in order to send a packet.

 If the source address is not aligned, try to align it. */

 Clear unused upper bytes */

 Source address is aligned. */

			/*

			 * We still have 'extra' number of bytes leftover.

 Clear unused upper bytes */

			/*

			 * Need to round up for the last dword in the

			 * packet.

 Clear unused upper bytes */

 Update address before sending packet. */

 must flush early everything before trigger word */

 be sure trigger word is written */

 assume the list non empty */

 call slow path to get the extra lock */

 Put struct back on free list */

 Wake up first QP wanting a free struct */

/*

 * This is called when there are send DMA descriptors that might be

 * available.

 *

 * This is called with ppd->sdma_lock held.

 Search wait list for first QP wanting DMA descriptors. */

/*

 * This is called with ppd->sdma_lock held.

 resend previously constructed packet */

		/*

		 * Don't try to DMA if it takes more descriptors than

		 * the queue holds.

 add PBC length */

 Allocate a buffer and copy the header and payload to it. */

/*

 * If we are now in the error state, return zero to flush the

 * send work request.

	/*

	 * Note that as soon as want_buffer() is called and

	 * possibly before it returns, qib_ib_piobufavail()

	 * could be called. Therefore, put QP on the I/O wait list before

	 * enabling the PIO avail interrupt.

	/*

	 * Write the pbc.

	 * We have to flush after the PBC for correctness on some cpus

	 * or WC buffer can be written out of order.

		/*

		 * If there is just the header portion, must flush before

		 * writing last word of header for correctness, and after

		 * the last header word (trigger word).

 The common case is aligned and contained in one segment. */

 Update address before sending packet. */

 must flush early everything before trigger word */

 be sure trigger word is written */

/**

 * qib_verbs_send - send a packet

 * @qp: the QP to send on

 * @hdr: the packet header

 * @hdrwords: the number of 32-bit words in the header

 * @ss: the SGE to send

 * @len: the length of the packet in bytes

 *

 * Return zero if packet is sent or queued OK.

 * Return non-zero and clear qp->s_flags RVT_S_BUSY otherwise.

	/*

	 * Calculate the send buffer trigger address.

	 * The +1 counts for the pbc control dword following the pbc length.

	/*

	 * VL15 packets (IB_QPT_SMI) will always use PIO, so we

	 * can defer SDMA restart until link goes ACTIVE without

	 * worrying about just how we got there.

 no hardware, freeze, etc. */

/**

 * qib_get_counters - get various chip counters

 * @ppd: the qlogic_ib device

 * @cntrs: counters are placed here

 *

 * Return the counters needed by recv_pma_get_portcounters().

 no hardware, freeze, etc. */

	/*

	 * The link downed counter counts when the other side downs the

	 * connection.  We add in the number of times we downed the link

	 * due to local link integrity errors to compensate.

/**

 * qib_ib_piobufavail - callback when a PIO buffer is available

 * @dd: the device pointer

 *

 * This is called from qib_intr() at interrupt level when a PIO buffer is

 * available after qib_verbs_send() returned an error that no buffers were

 * available. Disable the interrupt if there are no more QPs waiting.

	/*

	 * Note: checking that the piowait list is empty and clearing

	 * the buffer available interrupt needs to be atomic or we

	 * could end up with QPs on the wait list with the interrupt

	 * disabled.

 Notify qib_destroy_qp() if it is waiting. */

 props being zeroed by the caller, avoid zeroing it here */

 See rate_show() */

	/*

	 * Do not trust reading anything from rvt_ah at this point as it is not

	 * done being setup. We can however modify things which we need to set.

/**

 * qib_get_npkeys - return the size of the PKEY table for context 0

 * @dd: the qlogic_ib device

/*

 * Return the indexed PKEY from the port PKEY table.

 * No need to validate rcd[ctxt]; the port is setup if we are here.

 dd->rcd null if mini_init or some init failures */

 Set the prefix to the default value (see ch. 4.1.1) */

 Snapshot current HW counters to "clear" them. */

/**

 * qib_fill_device_attr - Fill in rvt dev info device attributes.

 * @dd: the device data structure

 post send table */

 opcode translation table */

/**

 * qib_register_ib_device - register our device with the infiniband core

 * @dd: the device data structure

 * Return the allocated qib_ibdev pointer or NULL on error.

 Only need to initialize non-zero fields. */

	/*

	 * The system image GUID is supposed to be the same for all

	 * IB HCAs in a single system but since there can be other

	 * device types in the system, we can't be sure this is unique.

	/*

	 * Fill in rvt info object.

 Reserve one QP */

/**

 * _qib_schedule_send - schedule progress

 * @qp: the qp

 *

 * This schedules progress w/o regard to the s_flags.

 *

 * It is only used in post send, which doesn't hold

 * the s_lock.

/**

 * qib_schedule_send - schedule progress

 * @qp: the qp

 *

 * This schedules qp progress.  The s_lock

 * should be held.

/*

 * Copyright (c) 2012 - 2019 Intel Corporation.  All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation.  * All rights reserved.

 * Copyright (c) 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/*

	 * Free the page if someone raced with us installing it.

/*

 * Allocate the next available QPN or

 * zero/one for QP type IB_QPT_SMI/IB_QPT_GSI.

			/*

			 * This test differs from alloc_pidmap().

			 * If find_next_offset() does find a zero

			 * bit, we don't need to check for QPN

			 * wrapping around past our starting QPN.

			 * We just need to be sure we don't loop

			 * forever.

		/*

		 * In order to keep the number of pages allocated to a

		 * minimum, we scan the all existing pages before increasing

		 * the size of the bitmap table.

/*

 * qib_free_all_qps - check for QPs still in use

/**

 * qib_check_send_wqe - validate wr/wqe

 * @qp: The qp

 * @wqe: The built wqe

 * @call_send: Determine if the send should be posted or scheduled

 *

 * Returns 0 on success, -EINVAL on failure

 progress hint */

/**

 * qib_qp_iter_print - print information to seq_file

 * @s: the seq_file

 * @iter: the iterator

/*

 * Copyright (c) 2012 Intel Corporation. All rights reserved.

 * Copyright (c) 2007 - 2012 QLogic Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 default pio off, sdma on */

/*

 * Bits defined in the send DMA descriptor.

 declare all statics here rather than keep sorting */

/*

 * Complete all the sdma requests on the active list, in the correct

 * order, and with appropriate processing.   Called when cleaning up

 * after sdma shutdown, and when new sdma requests are submitted for

 * a link that is down.   This matches what is done for requests

 * that complete normally, it's just the full list.

 *

 * Must be called with sdma_lock held

	/*

	 * At this point, the following should always be true:

	 * - We are halted, so no more descriptors are getting retired.

	 * - We are not running, so no one is submitting new work.

	 * - Only we can send the e40_sw_cleaned, so we can't start

	 *   running again until we say so.  So, the active list and

	 *   descq are ours to play with.

 Process all retired requests. */

	/*

	 * Resync count of added and removed.  It is VERY important that

	 * sdma_descq_removed NEVER decrement - user_sdma depends on it.

	/*

	 * Reset our notion of head and tail.

	 * Note that the HW registers will be reset when switching states

	 * due to calling __qib_sdma_process_event() below.

/*

 * This is called when changing to state qib_sdma_state_s10_hw_start_up_wait

 * as a result of send buffer errors or send DMA descriptor errors.

 * We want to disarm the buffers in these cases.

 Releasing this reference means the state machine has stopped. */

 debugging bookkeeping */

 Allocate memory for SendDMA descriptor FIFO */

 Allocate memory for DMA of head register to memory */

 SDmaPhyAddr[47:32] */

 SDmaPhyAddr[31:0] */

 SDmaGeneration[1:0] */

 SDmaDwordCount[10:0] */

 SDmaBufOffset[12:2] */

 sdma_lock must be held */

	/* The reason for some of the complexity of this code is that

	 * not all descriptors have corresponding txps.  So, we have to

	 * be able to skip over descs until we wander into the range of

	 * the next txp on the list.

 if desc is part of this txp, unmap if needed */

 increment dequed desc count */

 advance head, wrap if needed */

 if now past this txp's descs, do the callback */

 remove from active list */

 see if there is another txp */

/*

 * This is called from interrupt context.

 set consistent sdma state */

 set up reference counting */

	/*

	 * This waits for the state machine to exit so it is not

	 * necessary to kill the sdma_sw_clean_up_task to make sure

	 * it is not running.

/*

 * Complete a request when sdma not running; likely only request

 * but to simplify the code, always queue it, then process the full

 * activelist.  We process the entire list to ensure that this particular

 * request does get it's callback, but in the correct order.

 * Must be called with sdma_lock held

 no sdma descriptors, so no unmap_desc */

/*

 * This function queues one IB packet onto the send DMA queue per call.

 * The caller is responsible for checking:

 * 1) The number of send DMA descriptor entries is less than the size of

 *    the descriptor queue.

 * 2) The IB SGE addresses and lengths are 32-bit aligned

 *    (except possibly the last SGE's length)

 * 3) The SGE addresses are suitable for passing to dma_map_single().

 write to the descq */

 increment the tail */

 SDmaUseLargeBuf has to be set in every descriptor */

 write to the descq */

 increment the tail */

 XXX what about error sending RDMA read responses? */

 return zero to process the next send work request */

		/*

		 * If we couldn't queue the DMA request, save the info

		 * and try again later rather than destroying the

		 * buffer and undoing the side effects of the copy.

/*

 * sdma_lock should be acquired before calling this routine

 print info for each entry in the descriptor queue */

 print dma descriptor indices from the TX requests */

			/*

			 * If down, but running requested (usually result

			 * of link up, then we need to start up.

			 * This can happen when hw down is requested while

			 * bringing the link up with traffic active on

 and start dma engine */

 This reference means the state machine is started */

/*

 * Copyright (c) 2006, 2007, 2008, 2009 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * qib_map_page - a safety wrapper around pci_map_page()

 *

 * A dma_addr of all 0's is interpreted by the chip as "disabled".

 * Unfortunately, it can also be a valid dma_addr returned on some

 * architectures.

 *

 * The powerpc iommu assigns dma_addrs in ascending order, so we don't

 * have to bother with retries or mapping a dummy page to insure we

 * don't just get the same mapping again.

 *

 * I'm sure we won't be so lucky with other iommu's, so FIXME.

		/*

		 * FIXME: If we get 0 again, we should keep this page,

		 * map another, then free the 0 page.

/**

 * qib_get_user_pages - lock user pages into memory

 * @start_page: the start page

 * @num_pages: the number of pages

 * @p: the output page structures

 *

 * This function takes a given start page (page aligned user virtual

 * address) and pins it and the following specified number of pages.  For

 * now, num_pages is always 1, but that will probably change at some point

 * (because caller is doing expected sends on a single virtually contiguous

 * buffer, so we can do all pages at once).

 during close after signal, mm can be NULL */

/*

 * Copyright (c) 2012, 2013 Intel Corporation.  All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * min buffers we want to have per context, after driver

/*

 * Number of ctxts we are configured to use (to allow for more pio

 * buffers per ctxt, etc.)  Zero means use chip value.

/*

 * If set, do not write to any regs if avoidable, hack to allow

 * check for deranged default register values.

 set number of contexts we'll actually use */

/*

 * Common code for creating the receive context array.

	/*

	 * Allocate full ctxtcnt array, rather than just cfgctxts, because

	 * cleanup iterates across all possible ctxts.

 create (one or more) kctxt */

/*

 * Common code for user and kernel context setup.

 N/A for PSM contexts */

		/*

		 * To avoid wasting a lot of memory, we allocate 32KB chunks

		 * of physically contiguous memory, advance through it until

		 * used up and then allocate more.  Of course, we need

		 * memory to store those extra pointers, now.  32KB seems to

		 * be the most that is "safe" under memory pressure

		 * (creating large files and then copying them over

		 * NFS while doing lots of MPI jobs).  The OOM killer can

		 * get invoked, even though we say we can sleep and this can

		 * cause significant system problems....

/*

 * Common code for initializing the physical port structure.

 IB port number, not index */

 User is intentionally disabling the congestion control agent */

	/*

	 * We really want L2 cache aligned, but for current CPUs of

	 * interest, they are the same.

 device status comes first, for backwards compatibility */

	/*

	 * Setup buffer to hold freeze and other messages, accessible to

	 * apps, following statusp.  This is per-unit, not per port.

 length of msg buffer is "whatever is left" */

/**

 * init_shadow_tids - allocate the shadow TID array

 * @dd: the qlogic_ib device

 *

 * allocate the shadow TID array, so we can qib_munlock previous

 * entries.  It may make more sense to move the pageshadow to the

 * ctxt data structure, so we only allocate memory for ctxts actually

 * in use, since we at 8k per ctxt, now.

 * We don't want failures here to prevent use of the driver/chip,

 * so no return value.

/*

 * Do initialization for device that is only needed on

 * first detect, not on resets.

 setup time (don't start yet) to verify we got interrupt */

/**

 * init_after_reset - re-initialize after a reset

 * @dd: the qlogic_ib device

 *

 * sanity check at least some of the values after reset, and

 * ensure no receive or transmit (explicitly, in case reset

 * failed

	/*

	 * Ensure chip does no sends or receives, tail updates, or

	 * pioavail updates while we re-initialize.  This is mostly

	 * for the driver data structures, not chip registers.

		/*

		 * ctxt == -1 means "all contexts". Only really safe for

		 * _dis_abling things, as here.

 Redundant across ports for some, but no big deal.  */

	/*

	 * Enable PIO send, and update of PIOavail regs to memory.

	/*

	 * Enable kernel ctxts' receive and receive interrupt.

	 * Other ctxts done as user opens and inits them.

 being torn down */

	/*

	 * If we don't have a lid or any interrupts, let the user know and

	 * don't bother checking again.

 re-arm the timer to see if fallback works */

	/*

	 * Ensure all buffers are free, and fifos empty.  Buffers

	 * are common, so only do once for port 0.

	 *

	 * After enable and qib_chg_pioavailkernel so we can safely

	 * enable pioavail updates and PIOENABLE.  After this, packets

	 * are ready and able to go out.

	/*

	 * If not all sendbufs are used, add the one to each of the lower

	 * numbered contexts.  pbufsctxt and lastctxt_piobuf are

	 * calculated in chip-specific code because it may cause some

	 * chip-specific adjustments to be made.

	/*

	 * Set up the shadow copies of the piobufavail registers,

	 * which we compare against the chip registers for now, and

	 * the in memory DMA'ed copies of the registers.

	 * By now pioavail updates to memory should have occurred, so

	 * copy them into our working/shadow registers; this is in

	 * case something went wrong with abort, but mostly to get the

	 * initial values of the generation bit correct.

		/*

		 * Don't need to worry about pioavailkernel here

		 * because we will call qib_chg_pioavailkernel() later

		 * in initialization, to busy out buffers as needed.

 for debugging sanity */

 after pioavailshadow is setup */

/**

 * qib_create_workqueues - create per port workqueues

 * @dd: the qlogic_ib device

 3 + 2 + 1 + 1 + 1 */

/**

 * qib_init - do the actual initialization sequence on the chip

 * @dd: the qlogic_ib device

 * @reinit: reinitializing, so don't allocate new memory

 *

 * Do the actual initialization sequence on the chip.  This is done

 * both from the init routine called from the PCI infrastructure, and

 * when we reset the chip, or detect that it was reset internally,

 * or it's administratively re-enabled.

 *

 * Memory allocation here and in called routines is only done in

 * the first case (reinit == 0).  We have to be careful, because even

 * without memory allocation, we need to re-write all the chip registers

 * TIDs, etc. after the reset or enable has completed.

 Set linkstate to unknown, so we can watch for a transition. */

 Bypass most chip-init, to get to device creation */

 dd->rcd can be NULL if early init failed */

		/*

		 * Set up the (kernel) rcvhdr queue and egr TIDs.  If doing

		 * re-init, the simplest way to handle this is to free

		 * existing, and re-allocate.

		 * Need to re-create rest of ctxt 0 ctxtdata as well.

 don't leave invalid value */

 set max we can ever have for this driver load */

		/*

		 * Have to initialize ibmaxlen, but this will normally

		 * change immediately in qib_set_mtu().

 none of the ports initialized */

 but continue on, so we can debug cause */

 chip is OK for user apps; mark it as initialized */

			/*

			 * Set status even if port serdes is not initialized

			 * so that diags will work.

 now we can enable all interrupts from the chip */

		/*

		 * Setup to verify we get an interrupt, and fallback

		 * to an alternate if necessary and possible.

 start stats retrieval timer */

 if ret is non-zero, we probably should do some cleanup here... */

/*

 * These next two routines are placeholders in case we don't have per-arch

 * code for controlling write combining.  If explicit control of write

 * combining is not available, performance will probably be awful.

/*

 * Stop the timers during unit shutdown, or after an error late

 * in initialization.

/**

 * qib_shutdown_device - shut down a device

 * @dd: the qlogic_ib device

 *

 * This is called to make the device quiet when we are about to

 * unload the driver, and also when the device is administratively

 * disabled.   It does not free any data structures.

 * Everything it does has to be setup again by qib_init(dd, 1)

 mask interrupts, but not errors */

		/*

		 * Gracefully stop all sends allowing any in progress to

		 * trickle out first.

	/*

	 * Enough for anything that's going to trickle out to have actually

	 * done so.

 make sure LEDs are off */

		/*

		 * Clear SerdesEnable.

		 * We can't count on interrupts since we are stopping.

/**

 * qib_free_ctxtdata - free a context's allocated data

 * @dd: the qlogic_ib device

 * @rcd: the ctxtdata structure

 *

 * free up any allocated data for a context

 * This should not touch anything that would affect a simultaneous

 * re-allocation of context data, because it is called after qib_mutex

 * is released (and can be called from reinit as well).

 * It should never change any chip state, or global driver state.

/*

 * Perform a PIO buffer bandwidth write test, to verify proper system

 * configuration.  Even when all the setup calls work, occasionally

 * BIOS or other issues can prevent write combining from working, or

 * can cause other bandwidth problems to the chip.

 *

 * This test simply writes the same buffer over and over again, and

 * measures close to the peak bandwidth to the chip (not testing

 * data bandwidth to the wire).   On chips that use an address-based

 * trigger to send packets to the wire, this is easy.  On chips that

 * use a count to trigger, we want to make sure that the packet doesn't

 * go out on the wire, or trigger flow control checks.

	/*

	 * Enough to give us a reasonable test, less than piobuf size, and

	 * likely multiple of store buffer length.

 we want reasonably accurate elapsed time */

 wait until we cross msec boundary */

	/*

	 * length 0, no dwords actually sent

	/*

	 * This is only roughly accurate, since even with preempt we

	 * still take interrupts that could take a while.   Running for

	 * >= 5 msec seems to get us "close enough" to accurate values.

 1 GiB/sec, slightly over IB SDR line rate */

 disarm piobuf, so it's available again */

/*

 * Allocate our primary per-unit data structure.  Must be done via verbs

 * allocator, because the verbs cleanup process both does cleanup and

 * free of the data structure.

 * "extra" is for chip-specific data.

 extra is * number of ports */

/*

 * Called from freeze mode handlers, and from PCI error

 * reporting code.  Should be paranoid about state of

 * system and data structures.

	/*

	 * Mark as having had an error for driver, and also

	 * for /sys and status word mapped to user programs.

	 * This marks unit as not usable, until reset.

/*

 * Do all the generic driver unit- and chip-independent memory

 * allocation and initialization.

	/*

	 * These must be called before the driver is registered with

	 * the PCI subsystem.

 not fatal if it doesn't work */

 all OK */

/*

 * Do the non-unit driver cleanup, memory free, etc. at unload.

 this can only be called after a successful initialization */

 users can't do anything more with chip */

	/*

	 * Free any resources still in use (usually just kernel contexts)

	 * at unload; we do for ctxtcnt, because that's what we allocate.

	 * We acquire lock to be really paranoid that rcd isn't being

	 * accessed from some interrupt-related code (that should not happen,

	 * but best to be sure).

 debugging paranoia */

/*

 * Clean up on unit shutdown, or error during unit load after

 * successful initialization.

	/*

	 * Clean up chip-specific stuff.

	 * We check for NULL here, because it's outside

	 * the kregbase check, and we need to call it

	 * after the free_irq.  Thus it's possible that

	 * the function pointers were never initialized.

	/*

	 * Do device-specific initialiation, function table setup, dd

	 * allocation, etc.

 error already printed */

 do the generic initialization */

	/*

	 * Now ready for use.  this should be cleared whenever we

	 * detect a reset, or initiate one.  If earlier failure,

	 * we still create devices, so diags, etc. can be used

	 * to determine cause of problem.

 unregister from IB core */

	/*

	 * Disable the IB link, disable interrupts on the device,

	 * clear dma engines, etc.

 wait until all of our (qsfp) queue_work() calls complete */

/**

 * qib_create_rcvhdrq - create a receive header queue

 * @dd: the qlogic_ib device

 * @rcd: the context data

 *

 * This must be contiguous memory (from an i/o perspective), and must be

 * DMA'able (which means for some systems, it will go through an IOMMU,

 * or be forced into a low address range).

 clear for security and sanity on each use */

/**

 * qib_setup_eagerbufs - allocate eager buffers, both kernel and user contexts.

 * @rcd: the context we are setting up.

 *

 * Allocate the eager TID buffers and program them into hip.

 * They are no longer completely contiguous, we do multiple allocation

 * calls.  Otherwise we get the OOM code involved, by asking for too

 * much per call, with disastrous results on some kernels.

	/*

	 * GFP_USER, but without GFP_FS, so buffer cache can be

	 * coalesced (we hope); otherwise, even at order 4,

	 * heavy filesystem activity makes these fail, and we can

	 * use compound pages.

 clear for security and sanity on each use */

 don't hog the cpu */

/*

 * Note: Changes to this routine should be mirrored

 * for the diagnostics routine qib_remap_ioaddr32().

 * There is also related code for VL15 buffers in qib_init_7322_variables().

 * The teardown code that unmaps is in qib_pcie_ddcleanup()

	/*

	 * Free the old mapping because the kernel will try to reuse the

	 * old mapping and not create a new mapping with the

	 * write combining attribute.

	/*

	 * Assumes chip address space looks like:

	 *	- kregs + sregs + cregs + uregs (in any order)

	 *	- piobufs (2K and 4K bufs in either order)

	 * or:

	 *	- kregs + sregs + cregs (in any order)

	 *	- piobufs (2K and 4K bufs in either order)

	 *	- uregs

 Map just the configured ports (not all hw ports) */

 Sanity checks passed, now create the new mappings */

 ureg will now be accessed relative to dd->userbase */

/*

 * Copyright (c) 2012 Intel Corporation.  All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Get/Set heartbeat enable. OR of 1=enabled, 2=auto

	/*

	 * Set the "intentional" heartbeat enable per either of

	 * "Enable" and "Auto", as these are normally set together.

	 * This bit is consulted when leaving loopback mode,

	 * because entering loopback mode overrides it and automatically

	 * disables heartbeat.

/*

 * For userland compatibility, these offsets must remain fixed.

 * They are strings for QIB_STATUS_*

 if overflow */

 end of per-port functions */

/*

 * Start of per-port congestion control structures and support code

/*

 * Congestion control table size followed by table entries

/*

 * Congestion settings: port control, control map and an array of 16

 * entries for the congestion entries - increase, timer, event log

 * trigger threshold and the minimum injection rate delay.

 Start sl2vl */

 End sl2vl */

 Start diag_counters */

 End diag_counters */

 end of per-port file structures and support code */

/*

 * Start of per-unit (or driver, in some cases, but replicated

 * per unit) functions (these get a device *)

 The string printed here is already newline-terminated. */

 The string printed here is already newline-terminated. */

 The string printed here is already newline-terminated. */

 Return the number of user ports (contexts) available. */

	/* The calculation below deals with a special case where

 Return the number of free user ports (contexts) available. */

/*

 * Dump tempsense regs. in decimal, to ease shell-scripts.

 return error on bad read */

/*

 * end of per-unit (or driver, in some cases, but replicated

 * per unit) functions

 start of per-unit file structures and support code */

/*

 * Copyright (c) 2010 - 2017 Intel Corporation.  All rights reserved.

 * Copyright (c) 2008, 2009 QLogic Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file contains PCIe utility routines that are common to the

 * various QLogic InfiniPath adapters

/*

 * Code to adjust PCIe capabilities.

 * To minimize the change footprint, we call it

 * from qib_pcie_params, which every chip-specific

 * file calls, even though this violates some

 * expectations of harmlessness.

/*

 * Do all the common PCIe setup and initialization.

 * devdata is not yet allocated, and is not allocated until after this

 * routine returns success.  Therefore qib_dev_err() can't be used for error

 * printing.

		/*

		 * This can happen (in theory) iff:

		 * We did a chip reset, and then failed to reprogram the

		 * BAR, or the chip reset due to an internal error.  We then

		 * unloaded the driver and reloaded it.

		 *

		 * Both reset cases set the BAR back to initial state.  For

		 * the latter case, the AER sticky error bit at offset 0x718

		 * should be set, but the Linux kernel doesn't yet know

		 * about that, it appears.  If the original BAR was retained

		 * in the kernel data structures, this may be OK.

		/*

		 * If the 64 bit setup fails, try 32 bit.  Some systems

		 * do not setup 64 bit maps on systems with 2GB or less

		 * memory installed.

/*

 * Do remaining PCIe setup, once dd is allocated, and save away

 * fields required to re-initialize after a chip reset, or for

 * various other purposes

 used for io_remap, etc. */

	/*

	 * Save BARs to rewrite after device reset.  Save all 64 bits of

	 * BAR, just in case.

 save for later use */

/*

 * Do PCIe cleanup, after chip-specific cleanup, etc.  Just prior

 * to releasing the dd memory.

 * void because none of the core pcie cleanup returns are void

/*

 * We save the msi lo and hi values, so we can restore them after

 * chip reset (the kernel PCI infrastructure doesn't yet handle that

 * correctly.

 now save the data (vector) info */

 set up something... */

 Gen1, 2.5GHz */

	/*

	 * If nent exists, make sure to record how many vectors were allocated.

	 * If msix_enabled is false, return 0 so the fallback code works

	 * correctly.

	/*

	 * speed is bits 0-3, linkwidth is bits 4-8

	 * no defines for them in headers

 Gen1, 2.5GHz */

 Gen1, 5GHz */

 not defined, assume gen1 */

	/*

	 * Check against expected pcie width and complain if "wrong"

	 * on first initialization, not afterwards (i.e., reset).

 fill in string, even on errors */

/**

 * qib_free_irq - Cleanup INTx and MSI interrupts

 * @dd: valid pointer to qib dev data

 *

 * Since cleanup for INTx and MSI interrupts is trivial, have a common

 * routine.

 *

/*

 * Setup pcie interrupt stuff again after a reset.  I'd like to just call

 * pci_enable_msi() again for msi, but when I do that,

 * the MSI enable bit doesn't get set in the command word, and

 * we switch to to a different interrupt vector, which is confusing,

 * so I instead just do it all inline.  Perhaps somehow can tie this

 * into the PCIe hotplug support at some point

 If we aren't using MSI, don't restore it */

 nothing special for MSIx, just MSI */

 now rewrite the data (vector) info */

 and now set the pci master bit again */

/*

 * These two routines are helper routines for the device reset code

 * to move all the pcie code out of the chip-specific driver code.

 now re-enable memory access, and restore cosmetic settings */

/*

 * Enable PCIe completion and data coalescing, on Intel 5x00 and 7300

 * chipsets.   This is known to be unsafe for some revisions of some

 * of these chipsets, with some BIOS settings, and enabling it on those

 * systems may result in the system crashing, and/or data corruption.

 Find out supported and configured values for parent (root) */

	/*

	 *  - bit 12: Max_rdcmp_Imt_EN: need to set to 1

	 *  - bit 11: COALESCE_FORCE: need to set to 0

	 *  - bit 10: COALESCE_EN: need to set to 1

	 *  (but limitations on some on some chipsets)

	 *

	 *  On the Intel 5000, 5100, and 7300 chipsets, there is

	 *  also: - bit 25:24: COALESCE_MODE, need to set to 0

 5000 P/V/X/Z */

 5100 */

 5400 */

 7300 */

 not one of the chipsets that we know about */

/*

 * BIOS may not set PCIe bus-utilization parameters for best performance.

 * Check and optionally adjust them to maximize our throughput.

 Find out supported and configured values for parent (root) */

 Find out supported and configured values for endpoint (us) */

 Find max payload supported by root, endpoint */

 If Supported greater than limit in module param, limit it */

 If less than (allowed, supported), bump root payload */

 If less than (allowed, supported), bump endpoint payload */

	/*

	 * Now the Read Request size.

	 * No field for max supported, but PCIe spec limits it to 4096,

	 * which is code '5' (log2(4096) - 7)

 End of PCIe capability tuning */

/*

 * From here through qib_pci_err_handler definition is invoked via

 * PCI error infrastructure, registered via pci

 no more register accesses! */

 else early, or other problem */

 shouldn't happen */

	/*

	 * Running jobs will fail, since it's asynchronous

	 * unlike sysfs-requested reset.   Better than

	 * doing nothing.

 same as re-init after reset */

/*

 * Copyright (c) 2006, 2007, 2008, 2009, 2010 QLogic Corporation.

 * All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/**

 * qib_format_hwmsg - format a single hwerror message

 * @msg: message buffer

 * @msgl: length of message buffer

 * @hwmsg: message to add to message buffer

/**

 * qib_format_hwerrors - format hardware error messages for display

 * @hwerrs: hardware errors bit vector

 * @hwerrmsgs: hardware error descriptions

 * @nhwerrmsgs: number of hwerrmsgs

 * @msg: message buffer

 * @msgl: message buffer length

 linkstate */

	/*

	 * If linkstate transitions into INIT from any of the various down

	 * states, or if it transitions from any of the up (INIT or better)

	 * states into any of the down states (except link recovery), then

	 * call the chip-specific code to take appropriate actions.

	 *

	 * ppd->lflags could be 0 if this is the first time the interrupt

	 * handlers has been called but the link is already up.

 transitioned to UP */

 chip-code handled */

 chip-code handled */

 lstate is INIT, ARMED, or ACTIVE */

 start a 75msec timer to clear symbol errors */

 active, but not active defered */

 useful only for 6120 now */

 down */

/*

 * Handle receive interrupts for user ctxts; this means a user

 * process was waiting for a packet to arrive, and didn't want

 * to poll.

 separate routine, for better optimization of qib_intr() */

	/*

	 * We print the message and disable interrupts, in hope of

	 * having a better chance of debugging the problem.

 disable interrupt delivery, something is very wrong */

/*

 * Copyright (c) 2011 - 2017 Intel Corporation.  All rights reserved.

 * Copyright (c) 2006, 2007, 2008, 2009, 2010 QLogic Corporation.

 * All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file contains all of the code that is specific to the

 * QLogic_IB 7220 chip (except that specific to the SerDes)

/*

 * This file contains almost all the chip-specific register information and

 * access functions for the QLogic QLogic_IB 7220 PCI-Express chip, with the

 * exception of SerDes support, which in in qib_sd7220.c.

 Below uses machine-generated qib_chipnum_regs.h file */

 Use defines to tie machine-generated names to lower-case names */

 These must only be written via qib_write_kreg_ctxt() */

 ibcctrl bits */

 cycle through TS1/TS2 till OK */

 wait for TS1, then go on */

 move to 0x11 */

 move to 0x21 */

 move to 0x31 */

/*

 * We could have a single register get/put routine, that takes a group type,

 * but this is somewhat clearer and cleaner.  It also gives us some error

 * checking.  64 bit register reads should always work, but are inefficient

 * on opteron (the northbridge always generates 2 separate HT 32 bit reads),

 * so we use kreg32 wherever possible.  User register and counter register

 * reads are always 32 bit reads, so only one form of those routines.

/**

 * qib_read_ureg32 - read 32-bit virtualized per-context register

 * @dd: device

 * @regno: register number

 * @ctxt: context number

 *

 * Return the contents of a register that is virtualized to be per context.

 * Returns -1 on errors (not distinguishable from valid contents at

 * runtime; we may add a separate error variable at some point).

/**

 * qib_write_ureg - write 32-bit virtualized per-context register

 * @dd: device

 * @regno: register number

 * @value: value

 * @ctxt: context

 *

 * Write the contents of a register that is virtualized to be per context.

/**

 * qib_write_kreg_ctxt - write a device's per-ctxt 64-bit kernel register

 * @dd: the qlogic_ib device

 * @regno: the register number to write

 * @ctxt: the context containing the register

 * @value: the value to write

 kr_revision bits */

 kr_control bits */

 kr_intstatus, kr_intclear, kr_intmask bits */

 variables for sanity checking interrupt and errors */

 kr_hwerrclear, kr_hwerrmask, kr_hwerrstatus, bits */

 specific to this chip */

 kr_ibcddrctrl bits */

 kr_ibcddrstatus */

 link latency shift is 0, don't bother defining */

 kr_extstatus bits */

 kr_xgxsconfig bits */

 kr_rcvpktledcnt */

 4ns period on after packet */

 4ns period off before next on */

 All Production 7220 cards. */

 HW counter clock is at 4nsec */

 interrupt cnt in upper 32 bits */

/*

 * the size bits give us 2^N, in KB units.  0 marks as invalid,

 * and 7 is reserved.  We currently use only 2KB and 4KB

 shift to 3bit size selector */

 2KB */

 4KB */

 TID addr in chip stored w/o low bits */

 pbc; VL15, no credit check */

 control version of same */

 sequential retries to negotiate DDR */

 packet rate matching delay multiplier */

 1x, 4x */

 SDR */

 DDR */

 link training states, from IBC */

 link state machine states from IBC */

 7220 specific hardware errors... */

 generic hardware errors */

 chip-specific hardware errors */

	/*

	 * In practice, it's unlikely wthat we'll see PCIe PLL, or bus

	 * parity or memory parity error failures, because most likely we

	 * won't be able to talk to the core of the chip.  Nonetheless, we

	 * might see them, if they are in parts of the PCIe core that aren't

	 * essential.

 Convenience for decoding Send DMA errors */

 These are all rcv-related errors which we want to count for stats */

 These are all send-related errors which we want to count for stats */

/*

 * this is similar to E_SUM_ERRS, but can't ignore armlaunch, don't ignore

 * errors not related to freeze and cancelling buffers.  Can't ignore

 * armlaunch because could get more while still cleaning up, and need

 * to cancel those as they happen.

/*

 * these are errors that can occur when the link changes state while

 * a packet is being sent or received.  This doesn't cover things

 * like EBP or VCRC that can be the result of a sending having the

 * link change state, so we receive a "known bad" packet.

/*

 * Called when we might have an error that is specific to a particular

 * PIO buffer, and may need to cancel that buffer, so it can be re-used.

 * because we don't need to force the update of pioavail.

	/*

	 * It's possible that sendbuffererror could have bits set; might

	 * have already done this as a result of hardware error handling.

 read these before writing errorclear */

/*

 * This is called with interrupts disabled and sdma_lock held.

/*

 * This is called as part of link down clean up so disarm and flush

 * all send buffers so that SMP packets can be sent.

 This will trigger the Abort interrupt */

 update our idea of what's busy */

	/*

	 * Set SendDmaLenGen and clear and set

	 * the MSB of the generation count to enable generation checking

	 * and load the internal generation counter.

 Set SendDmaTail */

 not expecting any interrupts */

 handled in intr path */

 not expecting any interrupts */

 not expecting any interrupts */

 handled in intr path */

/*

 * Decode the error status into strings, deciding whether to always

 * print * it or not depending on "normal packet errors" vs everything

 * else.   Return 1 if "real" errors, otherwise 0 if only packet

 * errors, so caller can decide what to print with the string.

	/*

	 * Detect and handle the state chase issue, where we can

	 * get stuck if we are unlucky on timing on both sides of

	 * the link.   If we are, we disable, set a timer, and

	 * then re-enable.

 don't report errors that are masked */

 do these first, they are most important */

			/*

			 * This can happen when trying to bring the link

			 * up, but the IB link changes state at the "wrong"

			 * time. The IB logic then complains that the packet

			 * isn't valid.  We don't want to confuse people, so

			 * we just don't print them, except at debug

		/*

		 * This can happen when SMA is trying to bring the link

		 * up, but the IB link changes state at the "wrong" time.

		 * The IB logic then complains that the packet isn't

		 * valid.  We don't want to confuse people, so we just

		 * don't print them, except at debug

	/*

	 * The ones we mask off are handled specially below

	 * or above.  Also mask SDMADISABLED by default as it

	 * is too chatty.

 Update our picture of width and speed from chip */

		/*

		 * Since going into a recovery state causes the link state

		 * to go down and since recovery is transitory, it is better

		 * if we "miss" ever seeing the link training state go into

		 * recovery (i.e., ignore this transition for link state

		 * special handling purposes) without updating lastibcstat.

 needs re-init */

 mark as having had error */

	/*

	 * If there were hdrq or egrfull errors, wake up any processes

	 * waiting in poll.  We used to try to check which contexts had

	 * the overflow, but given the cost of that and the chip reads

	 * to support it, it's better to just wake everybody up if we

	 * get an overflow; waiters can poll again if it's not them.

 enable/disable chip from delivering interrupts */

 force re-interrupt of any pending interrupts. */

/*

 * Try to cleanup as much as possible for anything that might have gone

 * wrong while in freeze mode, such as pio buffers being written by user

 * processes (causing armlaunch), send errors due to going into freeze mode,

 * etc., and try to avoid causing extra interrupts while doing so.

 * Forcibly update the in-memory pioavail register copies after cleanup

 * because the chip won't do it while in freeze mode (the register values

 * themselves are kept correct).

 * Make sure that we don't lose any important interrupts by using the chip

 * feature that says that writing 0 to a bit in *clear that is set in

 * *status will cause an interrupt to be generated again (if allowed by

 * the *mask value).

 * This is in chip-specific code because of all of the register accesses,

 * even though the details are similar on most chips.

 disable error interrupts, to avoid confusion */

 also disable interrupts; errormask is sometimes overwritten */

 clear the freeze, and be sure chip saw it */

 force in-memory update now we are out of freeze */

	/*

	 * force new interrupt if any hwerr, error or interrupt bits are

	 * still set, and clear "safe" send packet errors related to freeze

	 * and cancelling sends.  Re-enable error interrupts before possible

	 * force of re-interrupt on pending interrupts.

/**

 * qib_7220_handle_hwerrors - display hardware errors.

 * @dd: the qlogic_ib device

 * @msg: the output buffer

 * @msgl: the size of the output buffer

 *

 * Use same msg buffer as regular errors to avoid excessive stack

 * use.  Most hardware errors are catastrophic, but for right now,

 * we'll print them and continue.  We reuse the same message buffer as

 * handle_7220_errors() to avoid excessive stack usage.

	/*

	 * Always clear the error status register, except MEMBISTFAIL,

	 * regardless of whether we continue or stop using the chip.

	 * We want that set so we know it failed, even across driver reload.

	 * We'll still ignore it in the hwerrmask.  We do this partly for

	 * diagnostics, but also for support.

		/*

		 * Parity errors in send memory are recoverable by h/w

		 * just do housekeeping, exit freeze mode and continue.

 ignore from now on, so disable until driver reloaded */

 ignore from now on, so disable until driver reloaded */

		/*

		 * If it occurs, it is left masked since the eternal

		 * interface is unused.

		/*

		 * For /sys status file and user programs to print; if no

		 * trailing brace is copied, we'll know it was truncated.

/**

 * qib_7220_init_hwerrors - enable hardware errors

 * @dd: the qlogic_ib device

 *

 * now that we have finished initializing everything that might reasonably

 * cause a hardware error, and cleared those errors bits as they occur,

 * we can enable hardware errors in the mask (potentially enabling

 * freeze mode), and enable hardware errors as errors (along with

 * everything else) in errormask

 default to all hwerrors become interrupts, */

 clear all */

 enable errors that are masked, at least this first time. */

 clear any interrupts up to this point (ints still not enabled) */

/*

 * Disable and enable the armlaunch error.  Used for PIO bandwidth testing

 * on chips that are count-based, rather than trigger-based.  There is no

 * reference counting, but that's also fine, given the intended use.

 * Only chip-specific because it's all register accesses

/*

 * Formerly took parameter <which> in pre-shifted,

 * pre-merged form with LinkCmd and LinkInitCmd

 * together, and assuming the zero was NOP.

		/*

		 * If we are told to disable, note that so link-recovery

		 * code does not attempt to bring us back up.

		/*

		 * Any other linkinitcmd will lead to LINKDOWN and then

		 * to INIT (if all is well), so clear flag to let

		 * link-recovery code attempt to bring us back up.

 write to chip to prevent back-to-back writes of ibc reg */

/*

 * All detailed interaction with the SerDes has been moved to qib_sd7220.c

 *

 * The portion of IBA7220-specific bringup_serdes() that actually deals with

 * registers and memory within the SerDes itself is qib_sd7220_init().

/**

 * qib_7220_bringup_serdes - bring up the serdes

 * @ppd: physical port on the qlogic_ib device

 Put IBC in reset, sends disabled */

 flowcontrolwatermark is in units of KBytes */

	/*

	 * How often flowctrl sent.  More or less in usecs; balance against

	 * watermark value, so that in theory senders always get a flow

	 * control update in time to not let the IB link go idle.

 max error tolerance */

 use "real" buffer space for */

 IB credit flow control. */

	/*

	 * set initial max size pkt IBC will send, including ICRC; it's the

	 * PIO buffer size in dwords, less 1; also see qib_set_mtu()

 without linkcmd or linkinitcmd! */

 initially come up waiting for TS1, without sending anything. */

 not on re-init after reset */

 always enable these on driver reload, not sticky */

 enable automatic lane reversal detection for receive */

 write to chip to prevent back-to-back writes of ibc reg */

 first time through, set port guid */

 write to chip to prevent back-to-back writes of ibc reg */

/**

 * qib_7220_quiet_serdes - set serdes to txidle

 * @ppd: physical port of the qlogic_ib device

 * Called when driver is being unloaded

 disable IBC */

 if initted */

 enable counter writes */

 and disable counter writes */

/**

 * qib_setup_7220_setextled - set the state of the two external LEDs

 * @ppd: the qlogic_ib device

 * @on: whether the link is up or not

 *

 * The exact combo of LEDs if on is true is determined by looking

 * at the ibcstatus.

 *

 * These LEDs indicate the physical and logical state of IB link.

 * For this chip (at least with recommended board pinouts), LED1

 * is Yellow (logical state) and LED2 is Green (physical state),

 *

 * Note:  We try to match the Mellanox HCA LED behavior as best

 * we can.  Green indicates physical link state is OK (something is

 * plugged in, and we can train).

 * Amber indicates the link is logically up (ACTIVE).

 * Mellanox further blinks the amber LED to indicate data packet

 * activity, but we have no hardware support for that, so it would

 * require waking up every 10-20 msecs and checking the counters

 * on the chip, and then turning the LED off if appropriate.  That's

 * visible overhead, so not something we will do.

 *

	/*

	 * The diags use the LED to indicate diag info, so we leave

	 * the external LED alone when the diags are running.

		/*

		 * counts are in chip clock (4ns) periods.

		 * This is 1/16 sec (66.6ms) on,

		 * 3/16 sec (187.5 ms) off, with packets rcvd

 blink the LED on packet receive */

/*

 * qib_setup_7220_cleanup - clean up any per-chip chip-specific stuff

 * @dd: the qlogic_ib device

 *

 * This is called during driver unload.

 *

/*

 * This is only called for SDmaInt.

 * SDmaDisabled is handled on the error path.

 too chatty to print here */

		/*

		 * blip the availupd off, next write will be on, so

		 * we ensure an avail update, regardless of threshold or

		 * buffers becoming free, whenever we want an interrupt

/*

 * Handle errors and unusual events first, separate function

 * to improve cache hits for fast path interrupt handling.

		/*

		 * Boards for this chip currently don't use GPIO interrupts,

		 * so clear by writing GPIOstatus to GPIOclear, and complain

		 * to alert developer. To avoid endless repeats, clear

		 * the bits in the mask, since there is some kind of

		 * programming error or chip problem.

		/*

		 * In theory, writing GPIOstatus to GPIOclear could

		 * have a bad side-effect on some diagnostic that wanted

		 * to poll for a status-change, but the various shadows

		 * make that problematic at best. Diags will just suppress

		 * all GPIO interrupts during such tests.

			/*

			 * A bit set in status and (chip) Mask register

			 * would cause an interrupt. Since we are not

			 * expecting any, report it. Also check that the

			 * chip reflects our shadow, report issues,

			 * and refresh from the shadow.

			/*

			 * Clear any troublemakers, and update chip

			 * from shadow

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 not our interrupt, or already handled */

 don't know if it was our interrupt or not */

	/*

	 * Clear the interrupt bits we found set, relatively early, so we

	 * "know" know the chip will have seen this by the time we process

	 * the queue, and will re-interrupt if necessary.  The processor

	 * itself won't take the interrupt again until we return.

	/*

	 * Handle kernel receive queues before checking for pio buffers

	 * available since receives can overflow; piobuf waiters can afford

	 * a few extra cycles, since they were waiting anyway.

 only call for SDmaInt */

/*

 * Set up our chip-specific interrupt handler.

 * The interrupt type has already been setup, so

 * we just need to do the registration and error checking.

 * If we are using MSI interrupts, we may fall back to

 * INTx later, if the interrupt handler doesn't get called

 * within 1/2 second (see verify_interrupt()).

/**

 * qib_7220_boardname - fill in the board name

 * @dd: the qlogic_ib device

 *

 * info is based on the board revision register

/*

 * This routine sleeps, so it can only be called from user context, not

 * from interrupt context.

 Use dev_err so it shows up in logs, etc. */

 no interrupts till re-initted */

	/*

	 * Keep chip from being accessed until we are ready.  Use

	 * writeq() directly, to allow the write even though QIB_PRESENT

	 * isn't set.

 so we check interrupts work again */

 prevent compiler reordering around actual reset */

		/*

		 * Allow MBIST, etc. to complete; longer on each retry.

		 * We sometimes get machine checks from bus timeout if no

		 * response, so for now, make it *really* long.

		/*

		 * Use readq directly, so we don't need to mark it as PRESENT

		 * until we get a successful indication that all is well.

 it's back */

 failed */

 hold IBC in reset, no sends, etc till later */

 clear the reset error, init error/hwerror mask */

 do setup similar to speed or link-width changes */

/**

 * qib_7220_put_tid - write a TID to the chip

 * @dd: the qlogic_ib device

 * @tidptr: pointer to the expected TID (in chip) to update

 * @type: 0 for eager, 1 for expected

 * @pa: physical address of in memory buffer; tidinvalid if freeing

 paranoia checks */

 for now, always full 4KB page */

/**

 * qib_7220_clear_tids - clear all TID entries for a ctxt, expected and eager

 * @dd: the qlogic_ib device

 * @rcd: the ctxt

 *

 * clear all TID entries for a ctxt, expected and eager.

 * Used from qib_close().  On this chip, TIDs are only 32 bits,

 * not 64, but they are still on 64 bit boundaries, so tidbase

 * is declared as u64 * for the pointer math, even though we write 32 bits

/**

 * qib_7220_tidtemplate - setup constants for TID updates

 * @dd: the qlogic_ib device

 *

 * We setup stuff that we use a lot, to avoid calculating each time

/**

 * qib_7220_get_base_info - set chip-specific flags for user code

 * @rcd: the qlogic_ib ctxt

 * @kinfo: qib_base_info pointer

 *

 * We set the PCIE flag because the lower bandwidth on PCIe vs

 * HyperTransport can affect some user packet algorithims.

 none of the above, set to max */

	/*

	 * Chip can be configured for 5, 9, or 17 ctxts, and choice

	 * affects number of eager TIDs per ctxt (1K, 2K, 4K).

	 * Lock to be paranoid about later motion, etc.

 else configure for default 5 receive ctxts */

 kr_rcvegrcnt changes based on the number of contexts enabled */

 right-justified mask */

 Get allowed Link-width */

 Get currently active Link-width */

 Get allowed Link speeds */

 Get current Link spd */

 Get Auto-RX-polarity enable */

 Get Auto-Lane-reversal enable */

 IB overrun threshold */

 IB PHY error threshold */

 IB link default (sleep/poll) */

 will only take effect when the link state changes */

 Get Heartbeat off/enable/auto */

		/*

		 * 0x00 = 10x link transfer rate or 4 nsec. for 2.5Gbs

		 * Since the clock is always 250MHz, the value is 1 or 0.

 right-justified mask */

		/*

		 * Set LID and LMC. Combined to avoid possible hazard

		 * caller puts LMC in 16MSbits, DLID in 16LSbits of val

 set allowed Link-width */

		/*

		 * As with speed, only write the actual register if

		 * the link is currently down, otherwise takes effect

		 * on next link change.

		/*

		 * We set the QIBL_IB_FORCE_NOTIFY bit so updown

		 * will get called because we want update

		 * link_width_active, and the change may not take

		 * effect for some time (if we are in POLL), so this

		 * flag will force the updown routine to be called

		 * on the next ibstatuschange down interrupt, even

		 * if it's not an down->up transition.

 convert from IB to chip */

 set allowed Link speeds */

		/*

		 * If we turn off IB1.2, need to preset SerDes defaults,

		 * but not right now. Set a flag for the next time

		 * we command the link down.  As with width, only write the

		 * actual register if the link is currently down, otherwise

		 * takes effect on next link change.  Since setting is being

		 * explicitly requested (via MAD or sysfs), clear autoneg

		 * failure status if speed autoneg is enabled.

		/*

		 * We set the QIBL_IB_FORCE_NOTIFY bit so updown

		 * will get called because we want update

		 * link_speed_active, and the change may not take

		 * effect for some time (if we are in POLL), so this

		 * flag will force the updown routine to be called

		 * on the next ibstatuschange down interrupt, even

		 * if it's not an down->up transition.

 IBTA 1.2 mode + speed bits are contiguous */

 set Auto-RX-polarity enable */

 set Auto-Lane-reversal enable */

 IB overrun threshold */

 IB PHY error threshold */

 update pkeys */

 IB link default (sleep/poll) */

 will only take effect when the link state changes */

 SLEEP */

 update the MTU in IBC */

		/*

		 * Update our housekeeping variables, and set IBC max

		 * size, same as init code; max IBC is max we allow in

		 * buffer, less the qword pbc, plus 1 for ICRC, in dwords

		 * Set even if it's unchanged, print debug message only

		 * on changes.

 set the IB link state */

			/*

			 * stop state chase counter and timer, if running.

			 * wait forpending timer, but don't clear .data (ppd)!

		/* If the width active on the chip does not match the

		 * width in the shadow register, write the new active

		 * width to the chip.

		 * We don't have to worry about speed as the speed is taken

		 * care of by set_7220_ibspeed_fast called by ib_updown.

 set Heartbeat off/enable/auto */

 disable heart beat, so link will come up */

 enable heart beat again */

/*

 * Modify the RCVCTRL register in chip-specific way. This

 * is a function because bit positions and (future) register

 * location is chip-specifc, but the needed operations are

 * generic. <op> is a bit-mask because we often want to

 * do multiple modifications.

 always done for specific ctxt */

 Write these registers before the context is enabled. */

 arm rcv interrupt */

		/*

		 * Init the context registers also; if we were

		 * disabled, tail and head should both be zero

		 * already from the enable, but since we don't

		 * know, we have to do it explicitly.

 If kctxt, interrupt on next receive. */

/*

 * Modify the SENDCTRL register in chip-specific way. This

 * is a function there may be multiple such registers with

 * slightly different layouts. To start, we assume the

 * "canonical" register layout of the first chips.

 * Chip requires no back-back sendctrl writes, so write

 * scratch register after writing sendctrl

 First the ones that are "sticky", saved in shadow */

		/*

		 * disarm any that are not yet launched, disabling sends

		 * and updates until done.

		/*

		 * ensure writes have hit chip, then do a few

		 * more reads, to allow DMA of pioavail registers

		 * to occur, so in-memory copy is in sync with

		 * the chip.  Not always safe to sleep.

/**

 * qib_portcntr_7220 - read a per-port counter

 * @ppd: the qlogic_ib device

 * @reg: the counter to snapshot

 0xffff for unimplemented or synthesized counters */

 sum over all kernel contexts */

	/*

	 * only fast incrementing counters are 64bit; use 32 bit reads to

	 * avoid two independent reads when on opteron

/*

 * Device counter names (not port-specific), one line per stat,

 * single string.  Used by utilities like ipathstats to print the stats

 * in a way which works for different versions of drivers, without changing

 * the utility.  Names need to be 12 chars or less (w/o newline), for proper

 * display by utility.

 * Non-error counters are first.

 * Start of "error" conters is indicated by a leading "E " on the first

 * "error" counter, and doesn't count in label length.

 * The EgrOvfl list needs to be last so we truncate them at the configured

 * context count for the device.

 * cntr7220indices contains the corresponding register indices.

/*

 * same as cntr7220names and cntr7220indices, but for port-specific counters.

 * portcntr7220indices is somewhat complicated by some registers needing

 * adjustments of various kinds, and those are ORed with _PORT_VIRT_FLAG

 7220 and 7322-only */

 7220 and 7322-only */

 7220 and 7322-only */

 7220 and 7322-only */

 7220 and 7322-only */

 7220 and 7322-only */

 "virtual", need adjustments */

 do all the setup to make the counter reads efficient later */

 we always have at least one counter before the egrovfl */

 full list; size is without terminating null */

 final read after getting everything */

 everything read, or couldn't get memory */

 final read after getting everything */

 everything read, or couldn't get memory */

/**

 * qib_get_7220_faststats - get word counters from chip before they overflow

 * @t: contains a pointer to the qlogic_ib device qib_devdata

 *

 * This needs more work; in particular, decision on whether we really

 * need traffic_wds done the way it is

 * called from add_timer

	/*

	 * don't access the chip while running diags, or memory diags can

	 * fail

 but re-arm the timer, for diags case; won't hurt other */

	/*

	 * We now try to maintain an activity timer, based on traffic

	 * exceeding a threshold, so we need to check the word-counts

	 * even if they are 64-bit.

/*

 * If we are using MSI, try to fallback to INTx.

/*

 * Reset the XGXS (between serdes and IBC).  Slightly less intrusive

 * than resetting the IBC or external link state, and useful in some

 * cases to cause some retraining.  To do this right, we reset IBC

 * as well.

 be sure */

/*

 * For this chip, we want to use the same buffer every time

 * when we are trying to bring the link up (they are always VL15

 * packets).  At that link state the packet should always go out immediately

 * (or at least be discarded at the tx interface if the link is down).

 * If it doesn't, and the buffer isn't available, that means some other

 * sender has gotten ahead of us, and is preventing our packet from going

 * out.  In that case, we flush all packets, and try again.  If that still

 * fails, we fail the request, and hope things work the next time around.

 *

 * We don't need very complicated heuristics on whether the packet had

 * time to go out or not, since even at SDR 1X, it goes out in very short

 * time periods, covered by the chip reads done here and as part of the

 * flush.

	/*

	 * always blip to get avail list updated, since it's almost

	 * always needed, and is fairly cheap.

 extra chip flush */

 extra chip flush */

/*

 * This code for non-IBTA-compliant IB speed negotiation is only known to

 * work for the SDR to DDR transition, and only between an HCA and a switch

 * with recent firmware.  It is based on observed heuristics, rather than

 * actual knowledge of the non-compliant speed negotiation.

 * It has a number of hard-coded fields, since the hope is to rewrite this

 * when a spec is available on how the negoation is intended to work.

 7 dword header, dword data, icrc */

/*

 * _start packet gets sent twice at start, _done gets sent twice at end

 rest 0's */

 rest 0's */

 for maintainability, do it at runtime */

/*

 * Do the absolute minimum to cause an IB speed change, and make it

 * ready, but don't actually trigger the change.   The caller will

 * do that when ready (if link is in Polling training state, it will

 * happen immediately, otherwise when link next goes down)

 *

 * This routine should only be used as part of the DDR autonegotation

 * code for devices that are not compliant with IB 1.2 (or code that

 * fixes things up for same).

 *

 * When link has gone down, and autoneg enabled, or autoneg has

 * failed and we give up until next time we set both speeds, and

 * then we want IBTA enabled as well as "use max enabled speed.

/*

 * This routine is only used when we are not talking to another

 * IB 1.2-compliant device that we think can do DDR.

 * (This includes all existing switch chips as of Oct 2007.)

 * 1.2-compliant devices go directly to DDR prior to reaching INIT

	/*

	 * Required for older non-IB1.2 DDR switches.  Newer

	 * non-IB-compliant switches don't need it, but so far,

	 * aren't bothered by it either.  "Magic constant"

 2 msec is minimum length of a poll cycle */

/*

 * Handle the empirically determined mechanism for auto-negotiation

 * of DDR speed with switches.

	/*

	 * Busy wait for this first part, it should be at most a

	 * few hundred usec, since we scheduled ourselves for 2msec.

 we got there early or told to stop */

 we expect this to timeout */

 we expect this to timeout */

	/*

	 * Wait up to 250 msec for link to train and get to INIT at DDR;

	 * this should terminate early.

 returns the IBTA port state, rather than the IBC link training state */

		/*

		 * When the link goes down we don't want AEQ running, so it

		 * won't interfere with IBC training, etc., and we need

		 * to go back to the static SerDes preset values.

 initial disarm, etc. */

 this might better in qib_sd7220_presets() */

 we are SDR, and DDR auto-negotiation enabled */

 no other IB status change processing */

 no other IB status change processing */

 re-enable SDR, for next link down */

				/*

				 * Clear autoneg failure flag, and do setup

				 * so we'll try next time link goes down and

				 * back to INIT (possibly connected to a

				 * different device).

			/*

			 * Unlike 7322, the 7220 needs this, due to lack of

			 * interrupt in some cases when we have sdma active

			 * when the link goes down.

/*

 * Does read/modify/write to appropriate registers to

 * set output and direction bits selected by mask.

 * these are in their canonical postions (e.g. lsb of

 * dir will end up in D48 of extctrl on existing chips).

 * returns contents of GP Inputs.

 some bits being written, lock access to GPIO */

	/*

	 * It is unlikely that a read at this time would get valid

	 * data on a pin whose direction line was set in the same

	 * call to this function. We include the read here because

	 * that allows us to potentially combine a change on one pin with

	 * a read on another, and because the old code did something like

	 * this.

/*

 * Read fundamental info we need to use the chip.  These are

 * the registers that describe chip capabilities, and are

 * saved in shadow registers.

 these may be adjusted in init_chip_wc_pat() */

		/*

		 * 4K buffers take 2 pages; we use roundup just to be

		 * paranoid; we calculate it once here, rather than on

		 * ever buf allocate

/*

 * The chip base addresses in cspec and cpspec have to be set

 * after possible init_chip_wc_pat(), rather than in

 * qib_get_7220_chip_params(), so split out as separate function

 init after possible re-map in init_chip_wc_pat() */

		/*

		 * At least some mask bits are zero, so we need

		 * to read. The judgement call is whether from

		 * reg or shadow. First-cut: read reg, and complain

		 * if any bits which should be shadowed are different

		 * from their shadowed value.

		/*

		 * At least some mask bits are one, so we need

		 * to write, but only shadow some bits.

 Shadowed, transient */

		/*

		 * New shadow val is bits we don't want to touch,

		 * ORed with bits we do, that are intended for shadow.

/*

 * write the final few registers that depend on some of the

 * init setup.  Done late in init, just before bringing up

 * the serdes.

 we haven't yet set QIB_PRESENT, so use read directly */

 now register routines work */

	/*

	 * GPIO bits for TWSI data and clock,

	 * used for serial EEPROM.

	/*

	 * Set the initial values to reasonable default, will be set

	 * for real when link is up.

 if any 7220's, only one VL */

 we always allocate at least 2048 bytes for eager buffers */

	/*

	 * We can request a receive interrupt for 1 or

	 * more packets from current offset.  For now, we set this

	 * up for a single packet.

 setup the stats timer; the add_timer is done at end of init */

	/*

	 * Control[4] has been added to change the arbitration within

	 * the SDMA engine between favoring data fetches over descriptor

	 * fetches.  qib_sdma_fetch_arb==0 gives data fetches priority.

 64KB alignment */

 needed for PAT setup */

 set chip access pointers now */

	/* use all of 4KB buffers for the kernel SDMA, zero if !SDMA.

	 * reserve the update threshold amount for other kernel use, such

	 * as sending SMI, MAD, and ACKs, or 3, whichever is greater,

	 * unless we aren't enabling SDMA, in which case we want to use

	 * all the 4k bufs for the kernel.

	 * if this was less than the update threshold, we could wait

	 * a long time for an update.  Coded this way because we

	 * sometimes change the update threshold for various reasons,

	 * and we want this to remain robust.

 update threshold */

 range is <= , not < */

	/*

	 * if we are at 16 user contexts, we will have one 7 sbufs

	 * per context, so drop the update threshold to match.  We

	 * want to update before we actually run out, at low pbufs/ctxt

	 * so give ourselves some margin

 before full enable, no interrupts, no locking needed */

 try 4k if all 2k busy, so same last for both sizes */

 these 2 "counters" are really control registers, and are always RW */

/*

 * NOTE: no real attempt is made to generalize the SDMA stuff.

 * At some point "soon" we will have a new more generalized

 * set of sdma interface, and then we'll clean this up.

 Must be called with sdma_lock held, or before init finished */

 Commit writes to memory and advance the tail on the chip */

 Set SendDmaBase */

 Set SendDmaTail */

 Set SendDmaHeadAddr */

	/*

	 * Reserve all the former "kernel" piobufs, using high number range

	 * so we get as many 4K buffers as possible

 sdma_lock must be held */

 not wrapped */

 wrapped around */

 empty */

 try one more time, directly from the register */

 assume no progress */

/*

 * Compute the amount of delay before sending the next packet if the

 * port's send rate differs from the static rate set for the QP.

 * Since the delay affects this packet but the amount of the delay is

 * based on the length of the previous packet, use the last delay computed

 * and save the delay count for this packet to be used next time

 * we get here.

 Indicate VL15, if necessary */

 see if we need to raise avail update threshold */

/**

 * qib_7220_tempsense_rd - read register of temp sensor via TWSI

 * @dd: the qlogic_ib device

 * @regnum: register to read from

 *

 * returns reg contents (0..255) or < 0 for error

 return a bogus value for (the one) register we do not have */

	/*

	 * There are three possibilities here:

	 * ret is actual value (0..255)

	 * ret is -ENXIO or -EINVAL from twsi code or this file

	 * ret is -EINTR from mutex_lock_interruptible.

 Dummy function, as 7220 boards never disable EEPROM Write */

/**

 * qib_init_iba7220_funcs - set up the chip-specific function pointers

 * @pdev: the pci_dev for qlogic_ib device

 * @ent: pci_device_id struct for this dev

 *

 * This is global, and is called directly at init to set up the

 * chip-specific function pointers for later use.

	/*

	 * Do remaining pcie setup and save pcie values in dd.

	 * Any error printing is already done by the init code.

	 * On return, we have the chip mapped, but chip registers

	 * are not set up until start of qib_init_7220_variables.

 initialize chip-specific variables */

 x16 capable boards */

 x8 capable boards */

 setup interrupt handler (interrupt type handled above) */

 clear diagctrl register, in case diags were running and crashed */

/*

 * Copyright (c) 2012 - 2017 Intel Corporation.  All rights reserved.

 * Copyright (c) 2008 - 2012 QLogic Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file contains all of the code that is specific to the

 * InfiniPath 7322 chip

 LE2 serdes values for different cases */

 Below is special-purpose, so only really works for the IB SerDes blocks. */

 these are variables for documentation and experimentation purposes */

 Time to stop altering Rx Equalization parameters, after link up. */

/*

 * Number of VLs we are configured to use (to allow for more

 * credits per vl, etc.)

 10 dB ~= 5m length */

/*

 * Receive header queue sizes

 plenty for any real system */

 for read back, default index is ~5m copper cable */

 useful for things like LaFifoEmpty_0...7, TxCreditOK_0...7, etc. */

 Below because most, but not all, fields of IntMask have that full suffix */

/*

 * the size bits give us 2^N, in KB units.  0 marks as invalid,

 * and 7 is reserved.  We currently use only 2KB and 4KB

 2KB */

 4KB */

 TID addr in chip stored w/o low bits */

 All Production 7322 cards. */

 HW counter clock is at 4nsec */

 full speed IB port 1 only */

 full speed featuremask, both ports */

/*

 * This file contains almost all the chip-specific register information and

 * access functions for the FAKED QLogic InfiniPath 7322 PCI-Express chip.

 Use defines to tie machine-generated names to lower-case names */

 Common, but chip also has per-port */

 and base for 1 and 2 */

 and 1, 2 */

 and 1, 2 */

 and 1, 2 */

/*

 * per-port kernel registers.  Access only with qib_read_kreg_port()

 * or qib_write_kreg_port()

/*

 * Per-context kernel registers.  Access only with qib_read_kreg_ctxt()

 * or qib_write_kreg_ctxt()

/*

 * TID Flow table, per context.  Reduces

 * number of hdrq updates to one per flow (or on errors).

 * context 0 and 1 share same memory, but have distinct

 * addresses.  Since for now, we never use expected sends

 * on kernel contexts, we don't worry about that (we initialize

 * those entries for ctxt 0/1 on driver load twice, for example).

 0x20 per context; have to hardcode */

 these are the error bits in the tid flows, and are W1C */

/* Most (not all) Counters are per-IBport.

 * Requires LBIntCnt is at offset 0 in the group

 these are the (few) counters that are not port-specific */

 no chip register for # of IB ports supported, so define */

 1 VL15 buffer per hardware IB port, no register for this, so define */

/*

 * context 0 and 1 are special, and there is no chip register that

 * defines this value, so we have to define it here.

 * These are all allocated to either 0 or 1 for single port

 * hardware configuration, otherwise each gets half

 values for vl and port fields in PBC, 7322-specific */

 pbc; VL15, no credit check */

 control version of same */

 link training states, from IBC */

 link state machine states from IBC */

 protect rcvctrl shadow changes */

 RMW of shadows/regs for ExtCtrl and GPIO */

 clear bits which have dedicated handlers */

 for per port interrupts in single port mode */

 shadow of kr_gpio_out, for rmw ops */

 shadow the gpio mask register */

 shadow the gpio output enable, etc... */

 current AvailUpdThld */

 default AvailUpdThld */

 B, C, D, E, F */

 for device error interrupt msg buffer */

 Table of entries in "human readable" form Tx Emphasis. */

 number of entries per speed in onchip table */

 number of extra tx settings entries */

 number of mfg tx settings entries */

 yes, it's obvious, but one less magic number */

  may be overridden via setup_txselect() */

  may be overridden via setup_txselect() */

 The static and dynamic registers are paired, and the pairs indexed by spd */

 msec after LINKUP */

 link down, H1-H4 QDR adapts */

 r1 link down, H1-H4 QDR adapts */

 up, disable H0,H1-8, LE */

 r1 up, disable H0,H1-8 */

	/*

	 * these 5 fields are used to establish deltas for IB symbol

	 * errors and linkrecovery errors.  They can be reported on

	 * some chips during link negotiation prior to INIT, and with

	 * DDR when faking DDR negotiations with non-IBTA switches.

	 * The chip counters are adjusted at driver unload if there is

	 * a non-zero delta.

 krp_ibcctrl_a shadow */

 krp_ibcctrl_b shadow */

	/*

	 * Per-bay per-channel rcv QMH H1 values and Tx values for QDR.

	 * entry zero is unused, to simplify indexing

 txselect table index to use if no qsfp info */

 for port error interrupt msg buffer */

 for per-port sdma error messages */

 0 if not port-specific, else port # */

 ibcctrl bits */

 cycle through TS1/TS2 till OK */

 wait for TS1, then go on */

 move to 0x11 */

 move to 0x21 */

 move to 0x31 */

/**

 * qib_read_ureg32 - read 32-bit virtualized per-context register

 * @dd: device

 * @regno: register number

 * @ctxt: context number

 *

 * Return the contents of a register that is virtualized to be per context.

 * Returns -1 on errors (not distinguishable from valid contents at

 * runtime; we may add a separate error variable at some point).

/**

 * qib_write_ureg - write virtualized per-context register

 * @dd: device

 * @regno: register number

 * @value: value

 * @ctxt: context

 *

 * Write the contents of a register that is virtualized to be per context.

/*

 * not many sanity checks for the port-specific kernel register routines,

 * since they are only used when it's known to be safe.

/**

 * qib_write_kreg_ctxt - write a device's per-ctxt 64-bit kernel register

 * @dd: the qlogic_ib device

 * @regno: the register number to write

 * @ctxt: the context containing the register

 * @value: the value to write

 bits in Control register */

 bits in general interrupt regs */

 Interrupt bits that are "per port" */

 Interrupt bits that are common to a device */

 currently unused: QIB_I_SPIOSENT */

/*

 * Error bits that are "per port".

 Error bits that are common to a device */

/*

 * Per chip (rather than per-port) errors.  Most either do

 * nothing but trigger a print (because they self-recover, or

 * always occur in tandem with other errors that handle the

 * issue), or because they indicate errors with no recovery,

 * but we want to know that they happened.

/* SDMA chip errors (not per port)

 * QIB_E_SDMA_BUF_DUP needs no special handling, because we will also get

 * the SDMAHALT error immediately, so we just print the dup error via the

 * E_AUTO mechanism.  This is true of most of the per-port fatal errors

 * as well, but since this is port-independent, by definition, it's

 * handled a bit differently.  SDMA_VL15 and SDMA_WRONG_PORT are per

 * packet send errors, and so are handled in the same manner as other

 * per-packet errors.

/*

 * Below functionally equivalent to legacy QLOGIC_IB_E_PKTERRS

 * it is used to print "common" packet errors.

 Error Bits that Packet-related (Receive, per-port) */

/*

 * Error bits that are Send-related (per port)

 * (ARMLAUNCH excluded from E_SPKTERRS because it gets special handling).

 * All of these potentially need to have a buffer disarmed

/*

 * This sets some bits more than once, but makes it more obvious which

 * bits are not handled under other categories, and the repeat definition

 * is not a problem.

/*

 * These are errors that can occur when the link

 * changes state while a packet is being sent or received.  This doesn't

 * cover things like EBP or VCRC that can be the result of a sending

 * having the link change state, so we receive a "known bad" packet.

 * All of these are "per port", so renamed:

/*

 * This sets some bits more than once, but makes it more obvious which

 * bits are not handled under other categories (such as QIB_E_SPKTERRS),

 * and the repeat definition is not a problem.

 Likewise Neuter E_SPKT_ERRS_IGNORE */

/*

 * IBTA_1_2 is set when multiple speeds are enabled (normal),

 * and also if forced QDR (only QDR enabled).  It's enabled for the

 * forced QDR case so that scrambling will be enabled by the TS3

 * exchange, when supported by both sides of the link.

 sequential retries to negotiate DDR */

	/*

	 * SDmaHaltErr is not really an error, make it clearer;

/*

 * Below generates "auto-message" for interrupts not specific to any port or

 * context

 Below generates "auto-message" for interrupts specific to a port */

 For some reason, the SerDesTrimDone bits are reversed */

/*

 * Below generates "auto-message" for interrupts specific to a context,

 * with ctxt-number appended

 interrupt cnt in upper 32 bits */

/*

 * Called when we might have an error that is specific to a particular

 * PIO buffer, and may need to cancel that buffer, so it can be re-used,

 * because we don't need to force the update of pioavail

	/*

	 * It's possible that sendbuffererror could have bits set; might

	 * have already done this as a result of hardware error handling.

 No txe_recover yet, if ever */

 No decode__errors yet */

 separate the strings */

 msp->sz counts the nul */

 More than one bit this mask */

 If some bits are left, show in hex. */

 only called if r1 set */

	/*

	 * Send a dummy VL15 packet to flush the launch FIFO.

	 * This will not actually be sent since the TxeBypassIbc bit is set.

/*

 * This is called with interrupts disabled and sdma_lock held.

 If we are draining everything, block sends first */

	/*

	 * Set SendDmaLenGen and clear and set

	 * the MSB of the generation count to enable generation checking

	 * and load the internal generation counter.

/*

 * Must be called with sdma_lock held, or before init finished.

 Commit writes to memory and advance the tail on the chip */

/*

 * This is called with interrupts disabled and sdma_lock held.

	/*

	 * Drain all FIFOs.

	 * The hardware doesn't require this but we do it so that verbs

	 * and user applications don't wait for link active to send stale

	 * data.

 Set SendDmaTail */

 SDMA errors have QIB_E_P_SDMAHALT and another bit set */

/*

 * handle per-device errors (not per-port errors)

 don't report errors that are masked */

 do these first, they are most important */

	/*

	 * The ones we mask off are handled specially below

	 * or above.  Also mask SDMADISABLED by default as it

	 * is too chatty.

	/*

	 * Getting reset is a tragedy for all ports. Mark the device

	 * _and_ the ports as "offline" in way meaningful to each.

 needs re-init */

 mark as having had error */

	/*

	 * If there were hdrq or egrfull errors, wake up any processes

	 * waiting in poll.  We used to try to check which contexts had

	 * the overflow, but given the cost of that and the chip reads

	 * to support it, it's better to just wake everybody up if we

	 * get an overflow; waiters can poll again if it's not them.

	/*

	 * Detect and handle the state chase issue, where we can

	 * get stuck if we are unlucky on timing on both sides of

	 * the link.   If we are, we disable, set a timer, and

	 * then re-enable.

			/* If the link went down (but no into recovery,

 On link down, reenable QDR adaptation */

/*

 * This is per-pport error handling.

 * will likely get it's own MSIx interrupt (one for each port,

 * although just a single handler).

 do this as soon as possible */

 determine cause, then write to clear */

 senderrbuf cleared in SPKTERRS below */

			/*

			 * This can happen when trying to bring the link

			 * up, but the IB link changes state at the "wrong"

			 * time. The IB logic then complains that the packet

			 * isn't valid.  We don't want to confuse people, so

			 * we just don't print them, except at debug

		/*

		 * This can happen when SMA is trying to bring the link

		 * up, but the IB link changes state at the "wrong" time.

		 * The IB logic then complains that the packet isn't

		 * valid.  We don't want to confuse people, so we just

		 * don't print them, except at debug

			/*

			 * We got our interrupt, so init code should be

			 * happy and not try alternatives. Now squelch

			 * other "chatter" from link-negotiation (pre Init)

 Update our picture of width and speed from chip */

			/*

			 * Since going into a recovery state causes the link

			 * state to go down and since recovery is transitory,

			 * it is better if we "miss" ever seeing the link

			 * training state go into recovery (i.e., ignore this

			 * transition for link state special handling purposes)

			 * without updating lastibcstat.

 enable/disable chip from delivering interrupts */

 cause any pending enabled interrupts to be re-delivered */

 and same for MSIx */

/*

 * Try to cleanup as much as possible for anything that might have gone

 * wrong while in freeze mode, such as pio buffers being written by user

 * processes (causing armlaunch), send errors due to going into freeze mode,

 * etc., and try to avoid causing extra interrupts while doing so.

 * Forcibly update the in-memory pioavail register copies after cleanup

 * because the chip won't do it while in freeze mode (the register values

 * themselves are kept correct).

 * Make sure that we don't lose any important interrupts by using the chip

 * feature that says that writing 0 to a bit in *clear that is set in

 * *status will cause an interrupt to be generated again (if allowed by

 * the *mask value).

 * This is in chip-specific code because of all of the register accesses,

 * even though the details are similar on most chips.

 disable error interrupts, to avoid confusion */

 also disable interrupts; errormask is sometimes overwritten */

 clear the freeze, and be sure chip saw it */

	/*

	 * Force new interrupt if any hwerr, error or interrupt bits are

	 * still set, and clear "safe" send packet errors related to freeze

	 * and cancelling sends.  Re-enable error interrupts before possible

	 * force of re-interrupt on pending interrupts.

 We need to purge per-port errs and reset mask, too */

 no error handling to speak of */

/**

 * qib_7322_handle_hwerrors - display hardware errors.

 * @dd: the qlogic_ib device

 * @msg: the output buffer

 * @msgl: the size of the output buffer

 *

 * Use same msg buffer as regular errors to avoid excessive stack

 * use.  Most hardware errors are catastrophic, but for right now,

 * we'll print them and continue.  We reuse the same message buffer as

 * qib_handle_errors() to avoid excessive stack usage.

 Always clear the error status register, except BIST fail */

 no EEPROM logging, yet */

		/*

		 * No recovery yet...

			/*

			 * If any set that we aren't ignoring only make the

			 * complaint once, in case it's stuck or recurring,

			 * and we get here multiple times

			 * Force link down, so switch knows, and

			 * LEDs are turned off.

 ignore from now on, so disable until driver reloaded */

 Ignore esoteric PLL failures et al. */

		/*

		 * for /sys status file and user programs to print; if no

		 * trailing brace is copied, we'll know it was truncated.

/**

 * qib_7322_init_hwerrors - enable hardware errors

 * @dd: the qlogic_ib device

 *

 * now that we have finished initializing everything that might reasonably

 * cause a hardware error, and cleared those errors bits as they occur,

 * we can enable hardware errors in the mask (potentially enabling

 * freeze mode), and enable hardware errors as errors (along with

 * everything else) in errormask

 never clear BIST failure, so reported on each driver load */

 clear all */

 enable errors that are masked, at least this first time. */

/*

 * Disable and enable the armlaunch error.  Used for PIO bandwidth testing

 * on chips that are count-based, rather than trigger-based.  There is no

 * reference counting, but that's also fine, given the intended use.

 * Only chip-specific because it's all register accesses

/*

 * Formerly took parameter <which> in pre-shifted,

 * pre-merged form with LinkCmd and LinkInitCmd

 * together, and assuming the zero was NOP.

		/*

		 * If we are told to disable, note that so link-recovery

		 * code does not attempt to bring us back up.

		 * Also reset everything that we can, so we start

		 * completely clean when re-enabled (before we

		 * actually issue the disable to the IBC)

		/*

		 * Any other linkinitcmd will lead to LINKDOWN and then

		 * to INIT (if all is well), so clear flag to let

		 * link-recovery code attempt to bring us back up.

		/*

		 * Clear status change interrupt reduction so the

		 * new state is seen.

 write to chip to prevent back-to-back writes of ibc reg */

/*

 * The total RCV buffer memory is 64KB, used for both ports, and is

 * in units of 64 bytes (same as IB flow control credit unit).

 * The consumedVL unit in the same registers are in 32 byte units!

 * So, a VL15 packet needs 4.50 IB credits, and 9 rx buffer chunks,

 * and we can therefore allocate just 9 IB credits for 2 VL15 packets

 * in krp_rxcreditvl15, rather than 10.

	/*

	 * Set up per-VL credits. Below is kluge based on these assumptions:

	 * 1) port is disabled at the time early_init is called.

	 * 2) give VL15 17 credits, for two max-plausible packets.

	 * 3) Give VL0-N the rest, with any rounding excess used for VL0

 2 VL15 packets @ 288 bytes each (including IB headers) */

 no buffer space for other VLs */

 Notify IBC that credits need to be recalculated */

 Change the number of operational VLs */

/*

 * The code that deals with actual SerDes is in serdes_7322_init().

 * Compared to the code for iba7220, it is minimal.

/**

 * qib_7322_bringup_serdes - bring up the serdes

 * @ppd: physical port on the qlogic_ib device

	/*

	 * SerDes model not in Pd, but still need to

	 * set up much of IBCCtrl and IBCDDRCtrl; move elsewhere

	 * eventually.

 Put IBC in reset, sends disabled (should be in reset already) */

 ensure previous Tx parameters are not still forced */

 flowcontrolwatermark is in units of KBytes */

	/*

	 * Flow control is sent this often, even if no changes in

	 * buffer space occur.  Units are 128ns for this chip.

	 * Set to 3usec.

 max error tolerance */

 IB credit flow control. */

	/*

	 * set initial max size pkt IBC will send, including ICRC; it's the

	 * PIO buffer size in dwords, less 1; also see qib_set_mtu()

 without linkcmd or linkinitcmd! */

	/*

	 * Reset the PCS interface to the serdes (and also ibc, which is still

	 * in reset from above).  Writes new value of ibcctrl_a as last step.

		/*

		 * Not on re-init after reset, establish shadow

		 * and force initial config.

 Muliple speeds enabled */

 always enable these on driver reload, not sticky */

 setup so we have more time at CFGTEST to change H1 */

 write to chip to prevent back-to-back writes of ibc reg */

 Enable port */

 initially come up DISABLED, without sending anything. */

 clear the linkinit cmds */

 be paranoid against later code motion, etc. */

 Also enable IBSTATUSCHG interrupt.  */

 Always zero until we start messing with SerDes for real */

/**

 * qib_7322_mini_quiet_serdes - set serdes to txidle

 * @ppd: the qlogic_ib device

 * Called when driver is being unloaded

 if initted */

	/*

	 * Despite the name, actually disables IBC as well. Do it when

	 * we are as sure as possible that no more packets can be

	 * received, following the down and the PCS reset.

	 * The actual disabling happens in qib_7322_mini_pci_reset(),

	 * along with the PCS being reset.

	/*

	 * Update the adjusted counters so the adjustment persists

	 * across driver reload.

 enable counter writes */

		/*

		 * No need to save ibmalfdelta since IB perfcounters

		 * are cleared on driver reload.

 and disable counter writes */

/**

 * qib_setup_7322_setextled - set the state of the two external LEDs

 * @ppd: physical port on the qlogic_ib device

 * @on: whether the link is up or not

 *

 * The exact combo of LEDs if on is true is determined by looking

 * at the ibcstatus.

 *

 * These LEDs indicate the physical and logical state of IB link.

 * For this chip (at least with recommended board pinouts), LED1

 * is Yellow (logical state) and LED2 is Green (physical state),

 *

 * Note:  We try to match the Mellanox HCA LED behavior as best

 * we can.  Green indicates physical link state is OK (something is

 * plugged in, and we can train).

 * Amber indicates the link is logically up (ACTIVE).

 * Mellanox further blinks the amber LED to indicate data packet

 * activity, but we have no hardware support for that, so it would

 * require waking up every 10-20 msecs and checking the counters

 * on the chip, and then turning the LED off if appropriate.  That's

 * visible overhead, so not something we will do.

	/*

	 * The diags use the LED to indicate diag info, so we leave

	 * the external LED alone when the diags are running.

 Allow override of LED display for, e.g. Locating system in rack */

		/*

		 * Counts are in chip clock (4ns) periods.

		 * This is 1/16 sec (66.6ms) on,

		 * 3/16 sec (187.5 ms) off, with packets rcvd.

 blink the LED on packet receive */

 only free IRQs that were allocated */

 If num_msix_entries was 0, disable the INTx IRQ */

 make sure no MSIx interrupts are left pending */

 handle SDMA interrupts */

/*

 * Set or clear the Send buffer available interrupt enable bit.

/*

 * Somehow got an interrupt with reserved bits set in interrupt status.

 * Print a message so we know it happened, then clear them.

 * keep mainline interrupt handler cache-friendly

 keep mainline interrupt handler cache-friendly */

	/*

	 * Boards for this chip currently don't use GPIO interrupts,

	 * so clear by writing GPIOstatus to GPIOclear, and complain

	 * to developer.  To avoid endless repeats, clear

	 * the bits in the mask, since there is some kind of

	 * programming error or chip problem.

	/*

	 * In theory, writing GPIOstatus to GPIOclear could

	 * have a bad side-effect on some diagnostic that wanted

	 * to poll for a status-change, but the various shadows

	 * make that problematic at best. Diags will just suppress

	 * all GPIO interrupts during such tests.

	/*

	 * Check for QSFP MOD_PRS changes

	 * only works for single port if IB1 != pidx1

		/*

		 * Clear any troublemakers, and update chip from shadow

/*

 * Handle errors and unusual events first, separate function

 * to improve cache hits for fast path interrupt handling.

/*

 * Dynamically adjust the rcv int timeout for a context based on incoming

 * packet rate.

	/*

	 * Dynamically adjust idle timeout on chip

	 * based on number of packets processed.

/*

 * This is the main interrupt handler.

 * It will normally only be used for low frequency interrupts but may

 * have to handle all interrupts if INTx is enabled or fewer than normal

 * MSIx interrupts were allocated.

 * This routine should ignore the interrupt bits for any of the

 * dedicated MSIx handlers.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 don't know if it was our interrupt or not */

 already handled, or shared and not us */

 handle "errors" of various kinds first, device ahead of port */

	/*

	 * Clear the interrupt bits we found set, relatively early, so we

	 * "know" know the chip will have seen this by the time we process

	 * the queue, and will re-interrupt if necessary.  The processor

	 * itself won't take the interrupt again until we return.

	/*

	 * Handle kernel receive queues before checking for pio buffers

	 * available since receives can overflow; piobuf waiters can afford

	 * a few extra cycles, since they were waiting anyway.

/*

 * Dedicated receive packet available interrupt handler.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 Clear the interrupt bit we expect to be set. */

/*

 * Dedicated Send buffer available interrupt handler.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 Clear the interrupt bit we expect to be set. */

 qib_ib_piobufavail() will clear the want PIO interrupt if needed */

/*

 * Dedicated Send DMA interrupt handler.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 Clear the interrupt bit we expect to be set. */

/*

 * Dedicated Send DMA idle interrupt handler.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 Clear the interrupt bit we expect to be set. */

/*

 * Dedicated Send DMA progress interrupt handler.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 Clear the interrupt bit we expect to be set. */

/*

 * Dedicated Send DMA cleanup interrupt handler.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 Clear the interrupt bit we expect to be set. */

/*

 * Set up our chip-specific interrupt handler.

 * The interrupt type has already been setup, so

 * we just need to do the registration and error checking.

 * If we are using MSIx interrupts, we may fall back to

 * INTx later, if the interrupt handler doesn't get called

 * within 1/2 second (see verify_interrupt()).

		/*

		 * if not switching interrupt types, be sure interrupts are

		 * disabled, and then clear anything pending at this point,

		 * because we are starting clean.

 clear the reset error, init error/hwerror mask */

 clear any interrupt bits that might be set */

 make sure no pending MSIx intr, and clear diag reg */

 Try to get INTx interrupt */

 Try to get MSIx interrupts */

 skip if for a non-configured port */

 per krcvq context receive interrupt */

			/*

			 * Shouldn't happen since the enable said we could

			 * have as many as we are trying to setup here.

 Initialize the vector mapping */

/**

 * qib_7322_boardname - fill in the board name and note features

 * @dd: the qlogic_ib device

 *

 * info will be based on the board revision register

 Will need enumeration of board-types here */

 index into txdds_Xdr */

/*

 * This routine sleeps, so it can only be called from user context, not

 * from interrupt context.

 Use dev_err so it shows up in logs, etc. */

 no interrupts till re-initted */

 can be up to 512 bytes, too big for stack */

	/*

	 * Core PCI (as of 2.6.18) doesn't save or rewrite the full vector

	 * info that is set up by the BIOS, so we have to save and restore

	 * it ourselves.   There is some risk something could change it,

	 * after we save it, but since we have disabled the MSIx, it

	 * shouldn't be touched...

 save it without the masked bit set */

 so we check interrupts work again */

	/*

	 * Keep chip from being accessed until we are ready.  Use

	 * writeq() directly, to allow the write even though QIB_PRESENT

	 * isn't set.

		/*

		 * Allow MBIST, etc. to complete; longer on each retry.

		 * We sometimes get machine checks from bus timeout if no

		 * response, so for now, make it *really* long.

		/*

		 * Use readq directly, so we don't need to mark it as PRESENT

		 * until we get a successful indication that all is well.

 it's back */

 restore the MSIx vector address and data if saved above */

 initialize the remaining registers.  */

 OK or not, no longer resetting */

/**

 * qib_7322_put_tid - write a TID to the chip

 * @dd: the qlogic_ib device

 * @tidptr: pointer to the expected TID (in chip) to update

 * @type: 0 for eager, 1 for expected

 * @pa: physical address of in memory buffer; tidinvalid if freeing

 paranoia checks */

 for now, always full 4KB page */

/**

 * qib_7322_clear_tids - clear all TID entries for a ctxt, expected and eager

 * @dd: the qlogic_ib device

 * @rcd: the ctxt

 *

 * clear all TID entries for a ctxt, expected and eager.

 * Used from qib_close().

/**

 * qib_7322_tidtemplate - setup constants for TID updates

 * @dd: the qlogic_ib device

 *

 * We setup stuff that we use a lot, to avoid calculating each time

	/*

	 * For now, we always allocate 4KB buffers (at init) so we can

	 * receive max size packets.  We may want a module parameter to

	 * specify 2KB or 4KB and/or make it per port instead of per device

	 * for those who want to reduce memory footprint.  Note that the

	 * rcvhdrentsize size must be large enough to hold the largest

	 * IB header (currently 96 bytes) that we expect to handle (plus of

	 * course the 2 dwords of RHF).

/**

 * qib_7322_get_base_info - set chip-specific flags for user code

 * @rcd: the qlogic_ib ctxt

 * @kinfo: qib_base_info pointer

 *

 * We set the PCIE flag because the lower bandwidth on PCIe vs

 * HyperTransport can affect some user packet algorithims.

/*

 * Configure number of contexts.

 none of the above, set to max */

	/*

	 * Chip can be configured for 6, 10, or 18 ctxts, and choice

	 * affects number of eager TIDs per ctxt (1K, 2K, 4K).

	 * Lock to be paranoid about later motion, etc.

 else configure for default 6 receive ctxts */

 The XRC opcode is 5. */

	/*

	 * RcvCtrl *must* be written here so that the

	 * chip understands how to change rcvegrcnt below.

 kr_rcvegrcnt changes based on the number of contexts enabled */

 right-justified mask */

 Get allowed Link-width */

 Get currently active Link-width */

 Get allowed Link speeds */

 Get current Link spd */

 Get Auto-RX-polarity enable */

 Get Auto-Lane-reversal enable */

 IB overrun threshold */

 IB PHY error threshold */

 IB link default (sleep/poll) */

 will only take effect when the link state changes */

 Get Heartbeat off/enable/auto */

 OR of AUTO and ENB */

		/*

		 * 0x00 = 10x link transfer rate or 4 nsec. for 2.5Gbs

		 * Since the clock is always 250MHz, the value is 3, 1 or 0.

/*

 * Below again cribbed liberally from older version. Do not lean

 * heavily on it.

 right-justified mask */

		/*

		 * Set LID and LMC. Combined to avoid possible hazard

		 * caller puts LMC in 16MSbits, DLID in 16LSbits of val

		/*

		 * For header-checking, the SLID in the packet will

		 * be masked with SendIBSLMCMask, and compared

		 * with SendIBSLIDAssignMask. Make sure we do not

		 * set any bits not covered by the mask, or we get

		 * false-positives.

 set allowed Link-width */

 convert IB value to chip register value */

 set allowed Link speeds */

		/*

		 * As with width, only write the actual register if the

		 * link is currently down, otherwise takes effect on next

		 * link change.  Since setting is being explicitly requested

		 * (via MAD or sysfs), clear autoneg failure status if speed

		 * autoneg is enabled.

 Muliple speeds enabled */

 IBTA 1.2 mode + min/max + speed bits are contiguous */

 set Auto-RX-polarity enable */

 set Auto-Lane-reversal enable */

 IB overrun threshold */

 IB PHY error threshold */

 update pkeys */

 IB link default (sleep/poll) */

 will only take effect when the link state changes */

 SLEEP */

 update the MTU in IBC */

		/*

		 * Update our housekeeping variables, and set IBC max

		 * size, same as init code; max IBC is max we allow in

		 * buffer, less the qword pbc, plus 1 for ICRC, in dwords

		 * Set even if it's unchanged, print debug message only

		 * on changes.

 set the IB link state */

			/*

			 * stop state chase counter and timer, if running.

			 * wait forpending timer, but don't clear .data (ppd)!

 set Heartbeat off/enable/auto */

 OR of AUTO and ENB */

 val is the port number of the switch we are connected to. */

 only IBC loopback, may add serdes and xgxs loopbacks later */

 disable heart beat, so link will come up */

 enable heart beat again */

	/*

	 * Need to write timeout register before updating rcvhdrhead to ensure

	 * that the timer is enabled on reception of a packet.

/*

 * Modify the RCVCTRL register in chip-specific way. This

 * is a function because bit positions and (future) register

 * location is chip-specifc, but the needed operations are

 * generic. <op> is a bit-mask because we often want to

 * do multiple modifications.

 need reg write */

 Write these registers before the context is enabled. */

	/*

	 * Decide which registers to write depending on the ops enabled.

	 * Special case is "flush" (no bits set at all)

	 * which needs to write both.

		/*

		 * Init the context registers also; if we were

		 * disabled, tail and head should both be zero

		 * already from the enable, but since we don't

		 * know, we have to do it explicitly.

 be sure enabling write seen; hd/tl should be 0 */

 If kctxt, interrupt on next receive. */

 arm rcv interrupt */

 Now that the context is disabled, clear these registers. */

/*

 * Modify the SENDCTRL register in chip-specific way. This

 * is a function where there are multiple such registers with

 * slightly different layouts.

 * The chip doesn't allow back-to-back sendctrl writes, so write

 * the scratch register after writing sendctrl.

 *

 * Which register is written depends on the operation.

 * Most operate on the common register, while

 * SEND_ENB and SEND_DIS operate on the per-port ones.

 * SEND_ENB is included in common because it can change SPCL_TRIG

 First the dd ones that are "sticky", saved in shadow */

 Then the ppd ones that are "sticky", saved in shadow */

		/*

		 * Disarm any buffers that are not yet launched,

		 * disabling updates until done.

		/*

		 * Now drain all the fifos.  The Abort bit should never be

		 * needed, so for now, at least, we don't use it.

		/*

		 * ensure writes have hit chip, then do a few

		 * more reads, to allow DMA of pioavail registers

		 * to occur, so in-memory copy is in sync with

		 * the chip.  Not always safe to sleep.

 "virtual", need adjustments */

 not "virtual", but 64bit */

 mask off flags above */

/**

 * qib_portcntr_7322 - read a per-port chip counter

 * @ppd: the qlogic_ib pport

 * @reg: the counter to read (not a chip offset)

 0xffff for unimplemented or synthesized counters */

 not needed  for 7322 */

		/*

		 * the next 3 aren't really counters, but were implemented

		 * as counters in older chips, so still get accessed as

		 * though they were counters from this code.

 pseudo-counter, summed for all ports */

 handle non-counters and special cases first */

 sum over all kernel contexts (skip if mini_init) */

		/*

		 * Used as part of the synthesis of port_rcv_errors

		 * in the verbs code for IBTA counters.  Not needed for 7322,

		 * because all the errors are already counted by other cntrs.

 were counters in older chips, now per-port kernel regs */

	/*

	 * Only fast increment counters are 64 bits; use 32 bit reads to

	 * avoid two independent reads when on Opteron.

/*

 * Device counter names (not port-specific), one line per stat,

 * single string.  Used by utilities like ipathstats to print the stats

 * in a way which works for different versions of drivers, without changing

 * the utility.  Names need to be 12 chars or less (w/o newline), for proper

 * display by utility.

 * Non-error counters are first.

 * Start of "error" conters is indicated by a leading "E " on the first

 * "error" counter, and doesn't count in label length.

 * The EgrOvfl list needs to be last so we truncate them at the configured

 * context count for the device.

 * cntr7322indices contains the corresponding register indices.

 7322 only */

/*

 * same as cntr7322names and cntr7322indices, but for port-specific counters.

 * portcntr7322indices is somewhat complicated by some registers needing

 * adjustments of various kinds, and those are ORed with _PORT_VIRT_FLAG

 7220 and 7322-only */

 7220 and 7322-only */

 7220 and 7322-only from here down */

 7322-only from here down */

 do all the setup to make the counter reads efficient later */

 we always have at least one counter before the egrovfl */

 full list; size is without terminating null */

 final read after getting everything */

 everything read, or couldn't get memory */

 final read after getting everything */

 everything read, or couldn't get memory */

/**

 * qib_get_7322_faststats - get word counters from chip before they overflow

 * @t: contains a pointer to the qlogic_ib device qib_devdata

 *

 * VESTIGIAL IBA7322 has no "small fast counters", so the only

 * real purpose of this function is to maintain the notion of

 * "active time", which in turn is only logged into the eeprom,

 * which we don;t have, yet, for 7322-based boards.

 *

 * called from add_timer

		/*

		 * If port isn't enabled or not operational ports, or

		 * diags is running (can cause memory diags to fail)

		 * skip this port this time.

		/*

		 * Maintain an activity timer, based on traffic

		 * exceeding a threshold, so we need to check the word-counts

		 * even if they are 64-bit.

/*

 * If we were using MSIx, try to fallback to INTx.

 already using INTx */

/*

 * Reset the XGXS (between serdes and IBC).  Slightly less intrusive

 * than resetting the IBC or external link state, and useful in some

 * cases to cause some retraining.  To do this right, we reset IBC

 * as well, then return to previous state (which may be still in reset)

 * NOTE: some callers of this "know" this writes the current value

 * of cpspec->ibcctrl_a as part of it's operation, so if that changes,

 * check all callers.

/*

 * This code for non-IBTA-compliant IB speed negotiation is only known to

 * work for the SDR to DDR transition, and only between an HCA and a switch

 * with recent firmware.  It is based on observed heuristics, rather than

 * actual knowledge of the non-compliant speed negotiation.

 * It has a number of hard-coded fields, since the hope is to rewrite this

 * when a spec is available on how the negoation is intended to work.

 7 dword header, dword data, icrc */

 disable header check on this packet, since it can't be valid */

 and re-enable hdr check */

/*

 * _start packet gets sent twice at start, _done gets sent twice at end

 rest 0's */

 rest 0's */

 for maintainability, do it at runtime */

/*

 * Do the absolute minimum to cause an IB speed change, and make it

 * ready, but don't actually trigger the change.   The caller will

 * do that when ready (if link is in Polling training state, it will

 * happen immediately, otherwise when link next goes down)

 *

 * This routine should only be used as part of the DDR autonegotation

 * code for devices that are not compliant with IB 1.2 (or code that

 * fixes things up for same).

 *

 * When link has gone down, and autoneg enabled, or autoneg has

 * failed and we give up until next time we set both speeds, and

 * then we want IBTA enabled as well as "use max enabled speed.

 multiple speeds */

/*

 * This routine is only used when we are not talking to another

 * IB 1.2-compliant device that we think can do DDR.

 * (This includes all existing switch chips as of Oct 2007.)

 * 1.2-compliant devices go directly to DDR prior to reaching INIT

 2 msec is minimum length of a poll cycle */

/*

 * Handle the empirically determined mechanism for auto-negotiation

 * of DDR speed with switches.

	/*

	 * Busy wait for this first part, it should be at most a

	 * few hundred usec, since we scheduled ourselves for 2msec.

 we got there early or told to stop */

 we expect this to timeout */

 we expect this to timeout */

	/*

	 * Wait up to 250 msec for link to train and get to INIT at DDR;

	 * this should terminate early.

/*

 * This routine is used to request IPG set in the QLogic switch.

 * Only called if r1.

/*

 * Timeout handler for setting IPG.

 * Only called if r1.

 returns the IBTA port state, rather than the IBC link training state */

 Update our picture of width and speed from chip */

 Link went down. */

 do IPG MAD again after linkdown, even if last time failed */

 unlock the Tx settings, speed may change */

 on link down, ensure sane pcs state */

			/* schedule the qsfp refresh which should turn the link

 we are SDR, and auto-negotiation enabled */

 no other IB status change processing */

 no other IB status change processing */

 re-enable SDR, for next link down */

			/*

			 * Clear autoneg failure flag, and do setup

			 * so we'll try next time link goes down and

			 * back to INIT (possibly connected to a

			 * different device).

/*

 * Does read/modify/write to appropriate registers to

 * set output and direction bits selected by mask.

 * these are in their canonical postions (e.g. lsb of

 * dir will end up in D48 of extctrl on existing chips).

 * returns contents of GP Inputs.

 some bits being written, lock access to GPIO */

	/*

	 * It is unlikely that a read at this time would get valid

	 * data on a pin whose direction line was set in the same

	 * call to this function. We include the read here because

	 * that allows us to potentially combine a change on one pin with

	 * a read on another, and because the old code did something like

	 * this.

 Enable writes to config EEPROM, if possible. Returns previous state */

/*

 * Read fundamental info we need to use the chip.  These are

 * the registers that describe chip capabilities, and are

 * saved in shadow registers.

 these may be adjusted in init_chip_wc_pat() */

	/*

	 * 4K buffers take 2 pages; we use roundup just to be

	 * paranoid; we calculate it once here, rather than on

	 * ever buf allocate

/*

 * The chip base addresses in cspec and cpspec have to be set

 * after possible init_chip_wc_pat(), rather than in

 * get_7322_chip_params(), so split out as separate function

 port registers are defined as relative to base of chip */

/*

 * This is a fairly special-purpose observer, so we only support

 * the port-specific parts of SendCtrl

	/*

	 * The fixed correspondence between Physical ports and pports is

	 * severed. We need to hunt for the ppd that corresponds

	 * to the offset we got. And we have to do that without admitting

	 * we know the stride, apparently.

 If pport is not being managed by driver, just avoid shadows. */

 In any case, "idx" is flat index in kreg space */

		/*

		 * At least some mask bits are zero, so we need

		 * to read. The judgement call is whether from

		 * reg or shadow. First-cut: read reg, and complain

		 * if any bits which should be shadowed are different

		 * from their shadowed value.

		/*

		 * At least some mask bits are one, so we need

		 * to write, but only shadow some bits.

 Shadowed, transient */

		/*

		 * New shadow val is bits we don't want to touch,

		 * ORed with bits we do, that are intended for shadow.

 Besides logging QSFP events, we set appropriate TxDDS values */

 Delay for 20 msecs to allow ModPrs resistor to setup */

 Set the physical link to disabled */

		/*

		 * Some QSFP's not only do not respond until the full power-up

		 * time, but may behave badly if we try. So hold off responding

		 * to insertion.

		/*

		 * Need to change LE2 back to defaults if we couldn't

		 * read the cable type (to handle cable swaps), so do this

		 * even on failure to read cable information.  We don't

		 * get here for QME, so IS_QME check not needed here.

		/*

		 * We always change parameteters, since we can choose

		 * values for cables without eeproms, and the cable may have

		 * changed from a cable with full or partial eeprom content

		 * to one with partial or no content.

		/* The physical link is being re-enabled only when the

		 * previous state was DISABLED and the VALID bit is not

		 * set. This should only happen when  the cable has been

/*

 * There is little we can do but complain to the user if QSFP

 * initialization fails.

/*

 * called at device initialization time, and also if the txselect

 * module parameter is changed.  This is used for cables that don't

 * have valid QSFP EEPROMs (not present, or attenuation is zero).

 * We initialize to the default, then if there is a specific

 * unit,port match, we use that (and set it immediately, for the

 * current speed, if the link is at INIT or better).

 * String format is "default# unit#,port#=# ... u,p=#", separators must

 * be a SPACE character.  A newline terminates.  The u,p=# tuples may

 * optionally have "u,p=#,#", where the final # is the H1 value

 * The last specific match is used (actually, all are used, but last

 * one is the one that winds up set); if none at all, fall back on default.

 default number is validated in setup_txselect() */

 skip to next, if any */

 skip to next, if any */

 skip to next, if any */

 gcc thinks it might be used uninitted */

 skip */

 now change the IBC and serdes, overriding generic */

			/* Re-enable the physical state machine on mezz boards

			 * now that the correct settings have been set.

 done */

		/* no specific setting, use the default.

		 * Change the IBC and serdes, but since it's

		 * general, don't override specific settings.

 handle the txselect parameter changing */

/*

 * Write the final few registers that depend on some of the

 * init setup.  Done late in init, just before bringing up

 * the serdes.

 driver sends get pkey, lid, etc. checking also, to catch bugs */

	/*

	 * Set SendDmaFetchPriority and init Tx params, including

	 * QSFP handler on boards that have QSFP.

	 * First set our default attenuation entry for cables that

	 * don't have valid attenuation.

 Initialize qsfp if present on board. */

 per IB port errors.  */

/*

 * Write the initialization per-port registers that need to be done at

 * driver load and after reset completes (i.e., that aren't done as part

 * of other init procedures called from qib_init.c).

 * Some of these should be redundant on reset, but play safe.

 no buffer credits for this port */

	/*

	 * Set the number of supported virtual lanes in IBC,

	 * for flow control packet handling on unsupported VLs

 enable tx header checking */

	/*

	 * Unconditionally clear the bufmask bits.  If SDMA is

	 * enabled, we'll set them appropriately later.

/*

 * Write the initialization per-device registers that need to be done at

 * driver load and after reset completes (i.e., that aren't done as part

 * of other init procedures called from qib_init.c).  Also write per-port

 * registers that are affected by overall device config, such as QP mapping

 * Some of these should be redundant on reset, but play safe.

 Set Multicast QPs received by port 2 to map to context one. */

 be paranoid against later code motion, etc. */

 Initialize QP to context mapping */

	/*

	 * Setup up interrupt mitigation for kernel contexts, but

	 * not user contexts (user contexts use interrupts when

	 * stalled waiting for any packet, so want those interrupts

	 * right away).

	/*

	 * Initialize  as (disabled) rcvflow tables.  Application code

	 * will setup each flow as it uses the flow.

	 * Doesn't clear any of the error bits that might be set.

 these are W1C */

	/*

	 * dual cards init to dual port recovery, single port cards to

	 * the one port.  Dual port cards may later adjust to 1 port,

	 * and then back to dual port if both ports are connected

 pport structs are contiguous, allocated after devdata */

 for autoneg_7322_work() */

 for autoneg_7322_work() */

 we haven't yet set QIB_PRESENT, so use read directly */

 now register routines work */

 now that piobcnt2k and 4k set, we can allocate these */

	/*

	 * GPIO bits for TWSI data and clock,

	 * used for serial EEPROM.

	/*

	 * Setup initial values.  These may change when PAT is enabled, but

	 * we need these to do initial chip register accesses.

 all hwerrors become interrupts, unless special purposed */

	/*  link_recovery setup causes these errors, so ignore them,

 single port mode (7340, or configured) */

 Make sure port is disabled. */

 Make sure port is disabled. */

		/*

		 * Set the initial values to reasonable default, will be set

		 * for real when link is up.

		/*

		 * For Mez and similar cards, no qsfp info, so do

		 * the "cable info" setup here.  Can be overridden

		 * in adapter-specific routines.

			/*

			 * Choose center value as default tx serdes setting

			 * until changed through module parameter.

 Avoid writes to chip for mini_init */

 we always allocate at least 2048 bytes for eager buffers */

	/*

	 * We can request a receive interrupt for 1 or

	 * more packets from current offset.

 setup the stats timer; the add_timer is done at end of init */

 64KB alignment */

	/*

	 * We do not set WC on the VL15 buffers to avoid

	 * a rare problem with unaligned writes from

	 * interrupt-flushed store buffers, so we need

	 * to map those separately here.  We can't solve

	 * this for the rarely used mtrr case.

 vl15 buffers start just after the 4k buffers */

 set chip access pointers now */

 no error, so can still figure out why err */

 update threshold */

	/* use all of 4KB buffers for the kernel SDMA, zero if !SDMA.

	 * reserve the update threshold amount for other kernel use, such

	 * as sending SMI, MAD, and ACKs, or 3, whichever is greater,

	 * unless we aren't enabling SDMA, in which case we want to use

	 * all the 4k bufs for the kernel.

	 * if this was less than the update threshold, we could wait

	 * a long time for an update.  Coded this way because we

	 * sometimes change the update threshold for various reasons,

	 * and we want this to remain robust.

 range is <= , not < */

	/*

	 * If we have 16 user contexts, we will have 7 sbufs

	 * per context, so reduce the update threshold to match.  We

	 * want to update before we actually run out, at low pbufs/ctxt

	 * so give ourselves some margin.

 before full enable, no interrupts, no locking needed */

 for other initialization code */

 last is same for 2k and 4k, because we use 4k if all 2k busy */

/*

 * Must be called with sdma_lock held, or before init finished.

/*

 * sdma_lock should be acquired before calling this routine

 get bufuse bits, clear them, and print them again if non-zero */

 0 and 1 should always be zero, so print as short form */

 0 and 1 should always be zero, so print as short form */

 Set SendDmaTail */

 no remainder */

 failsafe for init */

 sdma_lock must be held */

 not wrapped */

 wrapped around */

 empty */

 try one more time, directly from the register */

 proceed as if no progress */

/*

 * Compute the amount of delay before sending the next packet if the

 * port's send rate differs from the static rate set for the QP.

 * The delay affects the next packet and the amount of the delay is

 * based on the length of the this packet.

 Indicate VL15, else set the VL in the control word */

/*

 * Enable the per-port VL15 send buffers for use.

 * They follow the rest of the buffers, without a config parameter.

 * This was in initregs, but that is done before the shadow

 * is set up, and this has to be done after the shadow is

 * set up.

		/*

		 * when flipping from kernel to user, we can't change

		 * the checking type if the buffer is allocated to the

		 * driver.   It's OK the other direction, because it's

		 * from close, and we have just disarm'ed all the

		 * buffers.  All the kernel to kernel changes are also

		 * OK.

 make sure we see an updated copy next time around */

		/*

		 * disable checking on a range; used by diags; just

		 * one buffer, but still written generically

		/*

		 * (re)enable checking on a range; used by diags; just

		 * one buffer, but still written generically; read

		 * scratch to be sure buffer actually triggered, not

		 * just flushed from processor.

 usable by kernel */

 see if we need to raise avail update threshold */

 for user process */

	/*

	 * Be sure whatever we did was seen by the chip and acted upon,

	 * before we return.  Mostly important for which >= 2.

 useful for trigger analyzers, etc. */

 Dummy for now, use chip regs soon */

/**

 * qib_init_iba7322_funcs - set up the chip-specific function pointers

 * @pdev: the pci_dev for qlogic_ib device

 * @ent: pci_device_id struct for this dev

 *

 * Also allocates, inits, and returns the devdata struct for this

 * device instance

 *

 * This is global, and is called directly at init to set up the

 * chip-specific function pointers for later use.

	/*

	 * Do remaining PCIe setup and save PCIe values in dd.

	 * Any error printing is already done by the init code.

	 * On return, we have the chip mapped, but chip registers

	 * are not set up until start of qib_init_7322_variables.

 initialize chip-specific variables */

	/*

	 * Determine number of vectors we want; depends on port count

	 * and number of configured kernel receive queues actually used.

	 * Should also depend on whether sdma is enabled or not, but

	 * that's such a rare testing case it's not worth worrying about.

 reduce by ctxt's < 2 */

 may be less than we wanted, if not enough available */

 setup interrupt handler */

 clear diagctrl register, in case diags were running and crashed */

/*

 * Set the table entry at the specified index from the table specifed.

 * There are 3 * TXDDS_TABLE_SZ entries in all per port, with the first

 * TXDDS_TABLE_SZ for SDR, the next for DDR, and the last for QDR.

 * 'idx' below addresses the correct entry, while its 4 LSBs select the

 * corresponding entry (one of TXDDS_TABLE_SZ) from the selected table.

/*

 * Set one entry in the TxDDS table for spec'd port

 * ridx picks one of the entries, while tp points

 * to the appropriate table entry.

 Get correct offset in chip-space, and in source table */

	/*

	 * We do not use qib_write_kreg_port() because it was intended

	 * only for registers in the lower "port specific" pages.

	 * So do index calculation  by hand.

 Prevent back-to-back writes by hitting scratch */

 Amphenol 1m 30awg NoEq */

 Amphenol 3m 28awg NoEq */

 Finisar 3m OM2 Optical */

 Finisar 30m OM2 Optical */

 Finisar Default OM2 Optical */

 Gore 1m 30awg NoEq */

 Gore 2m 30awg NoEq */

 Gore 1m 28awg NoEq */

 Gore 3m 28awg NoEq */

 Gore 5m 24awg Eq */

 Gore 7m 24awg Eq */

 Gore 5m 26awg Eq */

 Gore 7m 26awg Eq */

 Intersil 12m 24awg Active */

 Intersil 10m 28awg Active */

 Intersil 7m 30awg Active */

 Intersil 5m 32awg Active */

 Intersil Default Active */

 Luxtera 20m Active Optical */

 Molex 1M Cu loopback */

 Molex 2m 28awg NoEq */

 amp, pre, main, post */

 Loopback */

  2 dB */

  3 dB */

  4 dB */

  5 dB */

  6 dB */

  7 dB */

  8 dB */

  9 dB */

 10 dB */

 11 dB */

 12 dB */

 13 dB */

 14 dB */

 15 dB */

 16 dB */

 amp, pre, main, post */

 Loopback */

  2 dB */

  3 dB */

  4 dB */

  5 dB */

  6 dB */

  7 dB */

  8 dB */

  9 dB */

 10 dB */

 11 dB */

 12 dB */

 13 dB */

 14 dB */

 15 dB */

 16 dB */

 amp, pre, main, post */

 Loopback */

  2 dB (also QMH7342) */

  3 dB (also QMH7342) */

  4 dB */

  5 dB */

  6 dB */

  7 dB */

  8 dB */

  9 dB */

 10 dB */

 11 dB */

 12 dB */

 13 dB */

 14 dB */

 15 dB */

 16 dB */

/*

 * extra entries for use with txselect, for indices >= TXDDS_TABLE_SZ.

 * These are mostly used for mez cards going through connectors

 * and backplane traces, but can be used to add other "unusual"

 * table values as well.

 amp, pre, main, post */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 amp, pre, main, post */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 amp, pre, main, post */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QMH7342 backplane settings */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.0 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 QME7342 backplane settings 1.1 */

 amp, pre, main, post */

 QME7342 mfg settings */

 QME7342 P2 mfg settings */

	/*

	 * The attenuation table starts at 2dB for entry 1,

	 * with entry 0 being the loopback entry.

/*

 * if override is set, the module parameter txselect has a value

 * for this specific port, so use it, rather than our normal mechanism.

 Search table of known cables */

	/* Active cables don't have attenuation so we only set SERDES

		/*

		 * If we have no (or incomplete) data from the cable

		 * EEPROM, or no QSFP, or override is set, use the

		 * module parameter value to index into the attentuation

		 * table.

 similar to above, but index into the "extra" table. */

 this shouldn't happen, it's range checked */

 for mez cards or override, use the selected value for all entries */

 Fill in the first entry with the best entry found. */

 Fill in the remaining entries with the default table values. */

/*

 * The chan argument is 0=chan0, 1=chan1, 2=pll, 3=chan2, 4=chan4,

 * 5=subsystem which is why most calls have "chan + chan >> 1"

 * for the channel argument.

 From this point on, make sure we return access */

	/* If mask is not all 1s, we need to read, but different SerDes

	 * entities have different sizes

 Re-read in case host split reads and read data first */

 If mask is not zero, we need to write. */

	/*

	 * Initialize the Tx DDS tables.  Also done every QSFP event,

	 * for adapters with QSFP

 ensure no tx overrides from earlier driver loads */

 Patch some SerDes defaults to "Better for IB" */

 Timing Loop Bandwidth: cdr_timing[11:9] = 0 */

 Termination: rxtermctrl_r2d addr 11 bits [12:11] = 1 */

 Enable LE2: rxle2en_r2a addr 13 bit [6] = 1 */

 May be overridden in qsfp_7322_event */

 enable LE1 adaptation for all but QME, which is disabled */

 Clear cmode-override, may be set from older driver */

 Timing Recovery: rxtapsel addr 5 bits [9:8] = 0 */

 setup LoS params; these are subsystem, so chan == 5 */

 LoS filter threshold_count on, ch 0-3, set to 8 */

 LoS filter threshold_count off, ch 0-3, set to 4 */

 LoS filter select enabled */

 LoS target data:  SDR=4, DDR=2, QDR=1 */

 QDR */

 DDR */

 SDR */

 rxbistena; set 0 to avoid effects of it switch later */

 Configure 4 DFE taps, and only they adapt */

 gain hi stop 32 (22) (6:1) lo stop 7 (10:7) target 22 (13) (15:11) */

	/*

	 * Set receive adaptation mode.  SDR and DDR adaptation are

	 * always on, and QDR is initially enabled; later disabled.

 FLoop LOS gate: PPM filter  enabled */

 rx offset center enabled */

 Set the frequency loop bandwidth to 15 */

 Clear cmode-override, may be set from older driver */

 ensure no tx overrides from earlier driver loads */

 START OF LSI SUGGESTED SERDES BRINGUP */

 Reset - Calibration Setup */

       Stop DFE adaptaion */

       Disable LE1 */

       Disable autoadapt for LE1 */

       Disable LE2 */

       Disable VGA */

       Disable AFE Offset Cancel */

       Disable Timing Loop */

       Disable Frequency Loop */

       Disable Baseline Wander Correction */

       Disable RX Calibration */

       Disable RX Offset Calibration */

       Select BB CDR */

       CDR Step Size */

       Enable phase Calibration */

       DFE Bandwidth [2:14-12] */

       DFE Config (4 taps only) */

       Gain Loop Bandwidth */

       Baseline Wander Correction Gain [13:4-0] (leave as default) */

       Baseline Wander Correction Gain [3:7-5] (leave as default) */

       Data Rate Select [5:7-6] (leave as default) */

       RX Parallel Word Width [3:10-8] (leave as default) */

 RX REST */

       Single- or Multi-channel reset */

       RX Analog reset */

       RX Digital reset */

       RX Analog reset */

       RX Digital reset */

 setup LoS params; these are subsystem, so chan == 5 */

 LoS filter threshold_count on, ch 0-3, set to 8 */

 LoS filter threshold_count off, ch 0-3, set to 4 */

 LoS filter select enabled */

 LoS target data:  SDR=4, DDR=2, QDR=1 */

 QDR */

 DDR */

 SDR */

 Turn on LOS on initial SERDES init */

 FLoop LOS gate: PPM filter  enabled */

 RX LATCH CALIBRATION */

       Enable Eyefinder Phase Calibration latch */

       Enable RX Offset Calibration latch */

       Start Calibration */

       Turn off Calibration */

 BRING RX UP */

       Set LE2 value (May be overridden in qsfp_7322_event) */

       Set LE2 Loop bandwidth */

       Enable LE2 */

       Enable H0 only */

 gain hi stop 32 (22) (6:1) lo stop 7 (10:7) target 22 (13) (15:11) */

       Enable VGA */

       Set Frequency Loop Bandwidth */

       Enable Frequency Loop */

       Set Timing Loop Bandwidth */

       Enable Timing Loop */

	/*       Enable DFE

	 *       Set receive adaptation mode.  SDR and DDR adaptation are

	 *       always on, and QDR is initially enabled; later disabled.

       Disable LE1  */

       Disable auto adapt for LE1 */

       Enable AFE Offset Cancel */

       Enable Baseline Wander Correction */

 Termination: rxtermctrl_r2d addr 11 bits [12:11] = 1 */

 VGA output common mode */

	/*

	 * Initialize the Tx DDS tables.  Also done every QSFP event,

	 * for adapters with QSFP

 start adjust QMH serdes parameters */

 Set clock to 1, 0, 1, 0 */

/*

 * write the current Tx serdes pre,post,main,amp settings into the serdes.

 * The caller must pass the settings appropriate for the current speed,

 * or not care if they are correct for the current speed.

 field names for amp, main, post, pre, respectively */

/*

 * Set the parameters for mez cards on link bounce, so they are

 * always exactly what was requested.  Similar logic to init_txdds

 * but does just the serdes.

 set QDR forced value for H1, if needed */

/* qib_r_wait_for_rdy() not only waits for the ready bit, it

 * returns the current state of R_TDO

 Restore to NOP between operations. */

 these are common for all IB port use cases. */

 used for IB1 or IB2, only one in use */

 used when both IB1 and IB2 are in use */

 used when only IB1 is in use */

 used when only IB2 is in use */

 used when both IB1 and IB2 are in use */

/*

 * Do setup to properly handle IB link recovery; if port is zero, we

 * are initializing to cover both ports; otherwise we are initializing

 * to cover a single port card, or the port has reached INIT and we may

 * need to switch coverage types.

 rest doesn't apply to dualport */

 ibcreset asserted 400ns, be sure that's over */

		/*

		 * require a powercycle before we'll work again, and make

		 * sure we get no more interrupts, and don't turn off

		 * freeze.

 eventually reset */

 don't do the full clear_freeze(), not needed for this */

 take IBC out of reset */

/*

 * Copyright (c) 2013 - 2017 Intel Corporation. All rights reserved.

 * Copyright (c) 2006, 2007, 2008, 2009, 2010 QLogic Corporation.

 * All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file contains all of the code that is specific to the

 * QLogic_IB 6120 PCIe chip.

/*

 * This file contains all the chip-specific register information and

 * access functions for the Intel Intel_IB PCI-Express chip.

 *

 KREG_IDX uses machine-generated #defines */

 Use defines to tie machine-generated names to lower-case names */

 These must only be written via qib_write_kreg_ctxt() */

 link training states, from IBC */

 link state machine states from IBC */

 used after ctxt close */

 no back to back kernel TID writes */

 no back to back user TID writes */

 protect rcvctrl shadow changes */

 RMW of shadows/regs for ExtCtrl and GPIO */

 shadow of kr_gpio_out, for rmw ops */

 shadow the gpio mask register */

 shadow the gpio output enable, etc... */

	/*

	 * these 5 fields are used to establish deltas for IB symbol

	 * errors and linkrecovery errors.  They can be reported on

	 * some chips during link negotiation prior to INIT, and with

	 * DDR when faking DDR negotiations with non-IBTA switches.

	 * The chip counters are adjusted at driver unload if there is

	 * a non-zero delta.

 shadow for kr_ibcctrl */

 link recovery issue */

 used with gpio interrupts to implement IB counters */

	/*

	 * these count only cases where _successive_ LocalLinkIntegrity

	 * errors were seen in the receive headers of IB standard packets

 total dwords sent (sample result) */

 total dwords received (sample result) */

 total packets sent (sample result) */

 total packets received (sample result) */

 # of ticks no data sent (sample result) */

 ibcctrl bits */

 cycle through TS1/TS2 till OK */

 wait for TS1, then go on */

 move to 0x11 */

 move to 0x21 */

 move to 0x31 */

/*

 * We could have a single register get/put routine, that takes a group type,

 * but this is somewhat clearer and cleaner.  It also gives us some error

 * checking.  64 bit register reads should always work, but are inefficient

 * on opteron (the northbridge always generates 2 separate HT 32 bit reads),

 * so we use kreg32 wherever possible.  User register and counter register

 * reads are always 32 bit reads, so only one form of those routines.

/**

 * qib_read_ureg32 - read 32-bit virtualized per-context register

 * @dd: device

 * @regno: register number

 * @ctxt: context number

 *

 * Return the contents of a register that is virtualized to be per context.

 * Returns -1 on errors (not distinguishable from valid contents at

 * runtime; we may add a separate error variable at some point).

/**

 * qib_write_ureg - write 32-bit virtualized per-context register

 * @dd: device

 * @regno: register number

 * @value: value

 * @ctxt: context

 *

 * Write the contents of a register that is virtualized to be per context.

/**

 * qib_write_kreg_ctxt - write a device's per-ctxt 64-bit kernel register

 * @dd: the qlogic_ib device

 * @regno: the register number to write

 * @ctxt: the context containing the register

 * @value: the value to write

 kr_control bits */

 kr_intstatus, kr_intclear, kr_intmask bits */

 kr_hwerrclear, kr_hwerrmask, kr_hwerrstatus, bits */

 kr_extstatus bits */

 kr_xgxsconfig bits */

 Bits in GPIO for the added IB link interrupts */

 29 bits valid */

 pbc; VL15; link_buf only */

 6120 specific hardware errors... */

 generic hardware errors */

 chip-specific hardware errors */

	/*

	 * In practice, it's unlikely wthat we'll see PCIe PLL, or bus

	 * parity or memory parity error failures, because most likely we

	 * won't be able to talk to the core of the chip.  Nonetheless, we

	 * might see them, if they are in parts of the PCIe core that aren't

	 * essential.

 variables for sanity checking interrupt and errors */

 These are all rcv-related errors which we want to count for stats */

 These are all send-related errors which we want to count for stats */

/*

 * this is similar to E_SUM_ERRS, but can't ignore armlaunch, don't ignore

 * errors not related to freeze and cancelling buffers.  Can't ignore

 * armlaunch because could get more while still cleaning up, and need

 * to cancel those as they happen.

/*

 * these are errors that can occur when the link changes state while

 * a packet is being sent or received.  This doesn't cover things

 * like EBP or VCRC that can be the result of a sending having the

 * link change state, so we receive a "known bad" packet.

/*

 * On platforms using this chip, and not having ordered WC stores, we

 * can get TXE parity errors due to speculative reads to the PIO buffers,

 * and this, due to a chip issue can result in (many) false parity error

 * reports.  So it's a debug print on those, and an info print on systems

 * where the speculative reads don't occur.

 enable/disable chip from delivering interrupts */

 force re-interrupt of any pending interrupts. */

/*

 * Try to cleanup as much as possible for anything that might have gone

 * wrong while in freeze mode, such as pio buffers being written by user

 * processes (causing armlaunch), send errors due to going into freeze mode,

 * etc., and try to avoid causing extra interrupts while doing so.

 * Forcibly update the in-memory pioavail register copies after cleanup

 * because the chip won't do it while in freeze mode (the register values

 * themselves are kept correct).

 * Make sure that we don't lose any important interrupts by using the chip

 * feature that says that writing 0 to a bit in *clear that is set in

 * *status will cause an interrupt to be generated again (if allowed by

 * the *mask value).

 * This is in chip-specific code because of all of the register accesses,

 * even though the details are similar on most chips

 disable error interrupts, to avoid confusion */

 also disable interrupts; errormask is sometimes overwritten */

 clear the freeze, and be sure chip saw it */

 force in-memory update now we are out of freeze */

	/*

	 * force new interrupt if any hwerr, error or interrupt bits are

	 * still set, and clear "safe" send packet errors related to freeze

	 * and cancelling sends.  Re-enable error interrupts before possible

	 * force of re-interrupt on pending interrupts.

/**

 * qib_handle_6120_hwerrors - display hardware errors.

 * @dd: the qlogic_ib device

 * @msg: the output buffer

 * @msgl: the size of the output buffer

 *

 * Use same msg buffer as regular errors to avoid excessive stack

 * use.  Most hardware errors are catastrophic, but for right now,

 * we'll print them and continue.  Reuse the same message buffer as

 * handle_6120_errors() to avoid excessive stack usage.

	/* Always clear the error status register, except MEMBISTFAIL,

	 * regardless of whether we continue or stop using the chip.

	 * We want that set so we know it failed, even across driver reload.

	 * We'll still ignore it in the hwerrmask.  We do this partly for

	/*

	 * Make sure we get this much out, unless told to be quiet,

	 * or it's occurred within the last 5 seconds.

		/*

		 * Parity errors in send memory are recoverable,

		 * just cancel the send (if indicated in * sendbuffererror),

		 * count the occurrence, unfreeze (if no other handled

		 * hardware error bits are set), and continue. They can

		 * occur if a processor speculative read is done to the PIO

		 * buffer while we are sending a packet, for example.

 ignore from now on, so disable until driver reloaded */

 ignore from now on, so disable until driver reloaded */

		/*

		 * If it occurs, it is left masked since the external

		 * interface is unused

		/*

		 * if any set that we aren't ignoring; only

		 * make the complaint once, in case it's stuck

		 * or recurring, and we get here multiple

		 * times.

 recovered from all of them */

		/*

		 * for /sys status file and user programs to print; if no

		 * trailing brace is copied, we'll know it was truncated.

/*

 * Decode the error status into strings, deciding whether to always

 * print * it or not depending on "normal packet errors" vs everything

 * else.   Return 1 if "real" errors, otherwise 0 if only packet

 * errors, so caller can decide what to print with the string.

/*

 * Called when we might have an error that is specific to a particular

 * PIO buffer, and may need to cancel that buffer, so it can be re-used.

	/*

	 * It's possible that sendbuffererror could have bits set; might

	 * have already done this as a result of hardware error handling.

 and no more until active again */

 don't report errors that are masked */

 do these first, they are most important */

			/*

			 * This can happen when trying to bring the link

			 * up, but the IB link changes state at the "wrong"

			 * time. The IB logic then complains that the packet

			 * isn't valid.  We don't want to confuse people, so

			 * we just don't print them, except at debug

		/*

		 * This can happen when SMA is trying to bring the link

		 * up, but the IB link changes state at the "wrong" time.

		 * The IB logic then complains that the packet isn't

		 * valid.  We don't want to confuse people, so we just

		 * don't print them, except at debug

	/*

	 * The ones we mask off are handled specially below

	 * or above.

		/*

		 * Since going into a recovery state causes the link state

		 * to go down and since recovery is transitory, it is better

		 * if we "miss" ever seeing the link training state go into

		 * recovery (i.e., ignore this transition for link state

		 * special handling purposes) without updating lastibcstat.

 needs re-init */

 mark as having had error */

	/*

	 * If there were hdrq or egrfull errors, wake up any processes

	 * waiting in poll.  We used to try to check which contexts had

	 * the overflow, but given the cost of that and the chip reads

	 * to support it, it's better to just wake everybody up if we

	 * get an overflow; waiters can poll again if it's not them.

/**

 * qib_6120_init_hwerrors - enable hardware errors

 * @dd: the qlogic_ib device

 *

 * now that we have finished initializing everything that might reasonably

 * cause a hardware error, and cleared those errors bits as they occur,

 * we can enable hardware errors in the mask (potentially enabling

 * freeze mode), and enable hardware errors as errors (along with

 * everything else) in errormask

 init so all hwerrors interrupt, and enter freeze, ajdust below */

		/*

		 * Avoid problem with internal interface bus parity

		 * checking. Fixed in Rev2.

 avoid some intel cpu's speculative read freeze mode issue */

 clear all */

 enable errors that are masked, at least this first time. */

 clear any interrupts up to this point (ints still not enabled) */

/*

 * Disable and enable the armlaunch error.  Used for PIO bandwidth testing

 * on chips that are count-based, rather than trigger-based.  There is no

 * reference counting, but that's also fine, given the intended use.

 * Only chip-specific because it's all register accesses

/*

 * Formerly took parameter <which> in pre-shifted,

 * pre-merged form with LinkCmd and LinkInitCmd

 * together, and assuming the zero was NOP.

		/*

		 * If we are told to disable, note that so link-recovery

		 * code does not attempt to bring us back up.

		/*

		 * Any other linkinitcmd will lead to LINKDOWN and then

		 * to INIT (if all is well), so clear flag to let

		 * link-recovery code attempt to bring us back up.

 write to chip to prevent back-to-back writes of control reg */

/**

 * qib_6120_bringup_serdes - bring up the serdes

 * @ppd: the qlogic_ib device

 Put IBC in reset, sends disabled */

 flowcontrolwatermark is in units of KBytes */

	/*

	 * How often flowctrl sent.  More or less in usecs; balance against

	 * watermark value, so that in theory senders always get a flow

	 * control update in time to not let the IB link go idle.

 max error tolerance */

 use "real" buffer space for */

 IB credit flow control. */

	/*

	 * set initial max size pkt IBC will send, including ICRC; it's the

	 * PIO buffer size in dwords, less 1; also see qib_set_mtu()

 without linkcmd or linkinitcmd! */

 initially come up waiting for TS1, without sending anything. */

	/*

	 * Force reset on, also set rxdetect enable.  Must do before reading

	 * serdesstatus at least for simulation, or some of the bits in

	 * serdes status will come back as undefined and cause simulation

	 * failures

 be sure chip saw it */

 need pll reset set at least for a bit */

	/*

	 * after PLL is reset, set the per-lane Resets and TxIdle and

	 * clear the PLL reset and rxdetect (to get falling edge).

	 * Leave L1PWR bits set (permanently)

 be sure chip saw it */

	/* need PLL reset clear for at least 11 usec before lane

 be sure chip saw it */

 need to compensate for Tx inversion in partner */

 clear current and de-emphasis bits */

 set current to 20ma */

 set de-emphasis to -5.68dB */

 base and port guid same for single port */

	/*

	 * the process of setting and un-resetting the serdes normally

	 * causes a serdes PLL error, so check for that and clear it

	 * here.  Also clearr hwerr bit in errstatus, but not others.

 should just have PLL, clear all set, in an case */

/**

 * qib_6120_quiet_serdes - set serdes to txidle

 * @ppd: physical port of the qlogic_ib device

 * Called when driver is being unloaded

 disable IBC */

 enable counter writes */

 and disable counter writes */

/**

 * qib_6120_setup_setextled - set the state of the two external LEDs

 * @ppd: the qlogic_ib device

 * @on: whether the link is up or not

 *

 * The exact combo of LEDs if on is true is determined by looking

 * at the ibcstatus.

 * These LEDs indicate the physical and logical state of IB link.

 * For this chip (at least with recommended board pinouts), LED1

 * is Yellow (logical state) and LED2 is Green (physical state),

 *

 * Note:  We try to match the Mellanox HCA LED behavior as best

 * we can.  Green indicates physical link state is OK (something is

 * plugged in, and we can train).

 * Amber indicates the link is logically up (ACTIVE).

 * Mellanox further blinks the amber LED to indicate data packet

 * activity, but we have no hardware support for that, so it would

 * require waking up every 10-20 msecs and checking the counters

 * on the chip, and then turning the LED off if appropriate.  That's

 * visible overhead, so not something we will do.

 *

	/*

	 * The diags use the LED to indicate diag info, so we leave

	 * the external LED alone when the diags are running.

 Allow override of LED display for, e.g. Locating system in rack */

/**

 * qib_6120_setup_cleanup - clean up any per-chip chip-specific stuff

 * @dd: the qlogic_ib device

 *

 * This is called during driver unload.

/*

 * handle errors and unusual events first, separate function

 * to improve cache hits for fast path interrupt handling

		/*

		 * GPIO_3..5 on IBA6120 Rev2 chips indicate

		 * errors that we need to count.

 First the error-counter case. */

 want to clear the bits we see asserted. */

			/*

			 * Count appropriately, clear bits out of our copy,

			 * as they have been "handled".

			/*

			 * Some unexpected bits remain. If they could have

			 * caused the interrupt, complain and clear.

			 * To avoid repetition of this condition, also clear

			 * the mask. It is almost certainly due to error.

			/*

			 * Also check that the chip reflects our shadow,

			 * and report issues, If they caused the interrupt.

			 * we will suppress by refreshing from the shadow.

		/*

		 * This return value is not great, but we do not want the

		 * interrupt core code to remove our interrupt handler

		 * because we don't appear to be handling an interrupt

		 * during a chip reset.

 not our interrupt, or already handled */

 don't know if it was our interrupt or not */

	/*

	 * Clear the interrupt bits we found set, relatively early, so we

	 * "know" know the chip will have seen this by the time we process

	 * the queue, and will re-interrupt if necessary.  The processor

	 * itself won't take the interrupt again until we return.

	/*

	 * Handle kernel receive queues before checking for pio buffers

	 * available since receives can overflow; piobuf waiters can afford

	 * a few extra cycles, since they were waiting anyway.

/*

 * Set up our chip-specific interrupt handler

 * The interrupt type has already been setup, so

 * we just need to do the registration and error checking.

	/*

	 * If the chip supports added error indication via GPIO pins,

	 * enable interrupts on those bits so the interrupt routine

	 * can count the events. Also set flag so interrupt routine

	 * can know they are expected.

 Rev2+ reports extra errors via internal GPIO pins */

/**

 * pe_boardname - fill in the board name

 * @dd: the qlogic_ib device

 *

 * info is based on the board revision register

/*

 * This routine sleeps, so it can only be called from user context, not

 * from interrupt context.  If we need interrupt context, we can split

 * it into two routines.

 Use ERROR so it shows up in logs, etc. */

 no interrupts till re-initted */

	/*

	 * Keep chip from being accessed until we are ready.  Use

	 * writeq() directly, to allow the write even though QIB_PRESENT

	 * isn't set.

 so we check interrupts work again */

 prevent compiler re-ordering around actual reset */

		/*

		 * Allow MBIST, etc. to complete; longer on each retry.

		 * We sometimes get machine checks from bus timeout if no

		 * response, so for now, make it *really* long.

		/*

		 * Use readq directly, so we don't need to mark it as PRESENT

		 * until we get a successful indication that all is well.

 it's back */

 failed */

 clear the reset error, init error/hwerror mask */

 for Rev2 error interrupts; nop for rev 1 */

 clear the reset error, init error/hwerror mask */

/**

 * qib_6120_put_tid - write a TID in chip

 * @dd: the qlogic_ib device

 * @tidptr: pointer to the expected TID (in chip) to update

 * @type: RCVHQ_RCV_TYPE_EAGER (1) for eager, RCVHQ_RCV_TYPE_EXPECTED (0)

 * for expected

 * @pa: physical address of in memory buffer; tidinvalid if freeing

 *

 * This exists as a separate routine to allow for special locking etc.

 * It's used for both the full cleanup on exit, as well as the normal

 * setup and teardown.

 select appropriate spinlock */

 for now, always full 4KB page */

	/*

	 * Avoid chip issue by writing the scratch register

	 * before and after the TID, and with an io write barrier.

	 * We use a spinlock around the writes, so they can't intermix

	 * with other TID (eager or expected) writes (the chip problem

	 * is triggered by back to back TID writes). Unfortunately, this

	 * call can be done from interrupt level for the ctxt 0 eager TIDs,

	 * so we have to use irqsave locks.

	/*

	 * Assumes tidptr always > egrtidbase

	 * if type == RCVHQ_RCV_TYPE_EAGER.

/**

 * qib_6120_put_tid_2 - write a TID in chip, Revision 2 or higher

 * @dd: the qlogic_ib device

 * @tidptr: pointer to the expected TID (in chip) to update

 * @type: RCVHQ_RCV_TYPE_EAGER (1) for eager, RCVHQ_RCV_TYPE_EXPECTED (0)

 * for expected

 * @pa: physical address of in memory buffer; tidinvalid if freeing

 *

 * This exists as a separate routine to allow for selection of the

 * appropriate "flavor". The static calls in cleanup just use the

 * revision-agnostic form, as they are not performance critical.

 for now, always full 4KB page */

/**

 * qib_6120_clear_tids - clear all TID entries for a context, expected and eager

 * @dd: the qlogic_ib device

 * @rcd: the context

 *

 * clear all TID entries for a context, expected and eager.

 * Used from qib_close().  On this chip, TIDs are only 32 bits,

 * not 64, but they are still on 64 bit boundaries, so tidbase

 * is declared as u64 * for the pointer math, even though we write 32 bits

 use func pointer because could be one of two funcs */

 use func pointer because could be one of two funcs */

/**

 * qib_6120_tidtemplate - setup constants for TID updates

 * @dd: the qlogic_ib device

 *

 * We setup stuff that we use a lot, to avoid calculating each time

	/*

	 * For now, we always allocate 4KB buffers (at init) so we can

	 * receive max size packets.  We may want a module parameter to

	 * specify 2KB or 4KB and/or make be per ctxt instead of per device

	 * for those who want to reduce memory footprint.  Note that the

	 * rcvhdrentsize size must be large enough to hold the largest

	 * IB header (currently 96 bytes) that we expect to handle (plus of

	 * course the 2 dwords of RHF).

/**

 * qib_6120_get_base_info - set chip-specific flags for user code

 * @rcd: the qlogic_ib ctxt

 * @kinfo: qib_base_info pointer

 *

 * We set the PCIE flag because the lower bandwidth on PCIe vs

 * HyperTransport can affect some user packet algorithms.

/*

 * Used when we close any ctxt, for DMA already in flight

 * at close.  Can't be done until we know hdrq size, so not

 * early in chip init.

 fallback to just 0'ing */

/*

 * Modify the RCVCTRL register in chip-specific way. This

 * is a function because bit positions and (future) register

 * location is chip-specific, but the needed operations are

 * generic. <op> is a bit-mask because we often want to

 * do multiple modifications.

 always done for specific ctxt */

 Write these registers before the context is enabled. */

 arm rcv interrupt */

		/*

		 * Init the context registers also; if we were

		 * disabled, tail and head should both be zero

		 * already from the enable, but since we don't

		 * know, we have to do it explicitly.

 If kctxt, interrupt on next receive. */

		/*

		 * Be paranoid, and never write 0's to these, just use an

		 * unused page.  Of course,

		 * rcvhdraddr points to a large chunk of memory, so this

		 * could still trash things, but at least it won't trash

		 * page 0, and by disabling the ctxt, it should stop "soon",

		 * even if a packet or two is in already in flight after we

		 * disabled the ctxt.  Only 6120 has this issue.

/*

 * Modify the SENDCTRL register in chip-specific way. This

 * is a function there may be multiple such registers with

 * slightly different layouts. Only operations actually used

 * are implemented yet.

 * Chip requires no back-back sendctrl writes, so write

 * scratch register after writing sendctrl

 First the ones that are "sticky", saved in shadow */

		/*

		 * disarm any that are not yet launched, disabling sends

		 * and updates until done.

		/*

		 * ensure writes have hit chip, then do a few

		 * more reads, to allow DMA of pioavail registers

		 * to occur, so in-memory copy is in sync with

		 * the chip.  Not always safe to sleep.

/**

 * qib_portcntr_6120 - read a per-port counter

 * @ppd: the qlogic_ib device

 * @reg: the counter to snapshot

 0xffff for unimplemented or synthesized counters */

 handle counters requests not implemented as chip counters */

 sum over all kernel contexts */

	/*

	 * only fast incrementing counters are 64bit; use 32 bit reads to

	 * avoid two independent reads when on opteron

 add special cased count */

/*

 * Device counter names (not port-specific), one line per stat,

 * single string.  Used by utilities like ipathstats to print the stats

 * in a way which works for different versions of drivers, without changing

 * the utility.  Names need to be 12 chars or less (w/o newline), for proper

 * display by utility.

 * Non-error counters are first.

 * Start of "error" conters is indicated by a leading "E " on the first

 * "error" counter, and doesn't count in label length.

 * The EgrOvfl list needs to be last so we truncate them at the configured

 * context count for the device.

 * cntr6120indices contains the corresponding register indices.

/*

 * same as cntr6120names and cntr6120indices, but for port-specific counters.

 * portcntr6120indices is somewhat complicated by some registers needing

 * adjustments of various kinds, and those are ORed with _PORT_VIRT_FLAG

 "virtual", need adjustments */

 do all the setup to make the counter reads efficient later */

 we always have at least one counter before the egrovfl */

 full list; size is without terminating null */

 final read after getting everything */

 everything read, or couldn't get memory */

 final read after getting everything */

 final read after getting everything */

 everything read, or couldn't get memory */

 force re-interrupt of pending events, just in case */

/**

 * qib_get_6120_faststats - get word counters from chip before they overflow

 * @t: contains a pointer to the qlogic_ib device qib_devdata

 *

 * This needs more work; in particular, decision on whether we really

 * need traffic_wds done the way it is

 * called from add_timer

	/*

	 * don't access the chip while running diags, or memory diags can

	 * fail

 but re-arm the timer, for diags case; won't hurt other */

	/*

	 * We now try to maintain an activity timer, based on traffic

	 * exceeding a threshold, so we need to check the word-counts

	 * even if they are 64-bit.

 no interrupt fallback for these chips */

/*

 * reset the XGXS (between serdes and IBC).  Slightly less intrusive

 * than resetting the IBC or external link state, and useful in some

 * cases to cause some retraining.  To do this right, we reset IBC

 * as well.

 be sure */

 IB overrun threshold */

 IB PHY error threshold */

 IB link default (sleep/poll) */

 will only take effect when the link state changes */

 Get Heartbeat off/enable/auto */

 no heartbeat on this chip */

 1 usec. */

/*

 * We assume range checking is already done, if needed.

 IB overrun threshold */

 IB PHY error threshold */

 update pkeys */

 IB link default (sleep/poll) */

 will only take effect when the link state changes */

 SLEEP */

 update the MTU in IBC */

		/*

		 * Update our housekeeping variables, and set IBC max

		 * size, same as init code; max IBC is max we allow in

		 * buffer, less the qword pbc, plus 1 for ICRC, in dwords

		 * Set even if it's unchanged, print debug message only

		 * on changes.

 set the IB link state */

/*

 * Note that the caller has the ibp->rvp.lock held.

 returns the IBTA port state, rather than the IBC link training state */

/* Does read/modify/write to appropriate registers to

 * set output and direction bits selected by mask.

 * these are in their canonical postions (e.g. lsb of

 * dir will end up in D48 of extctrl on existing chips).

 * returns contents of GP Inputs.

 some bits being written, lock access to GPIO */

	/*

	 * It is unlikely that a read at this time would get valid

	 * data on a pin whose direction line was set in the same

	 * call to this function. We include the read here because

	 * that allows us to potentially combine a change on one pin with

	 * a read on another, and because the old code did something like

	 * this.

/*

 * Read fundamental info we need to use the chip.  These are

 * the registers that describe chip capabilities, and are

 * saved in shadow registers.

 these may be adjusted in init_chip_wc_pat() */

		/*

		 * 4K buffers take 2 pages; we use roundup just to be

		 * paranoid; we calculate it once here, rather than on

		 * ever buf allocate

/*

 * The chip base addresses in cspec and cpspec have to be set

 * after possible init_chip_wc_pat(), rather than in

 * get_6120_chip_params(), so split out as separate function

/*

 * Write the final few registers that depend on some of the

 * init setup.  Done late in init, just before bringing up

 * the serdes.

 not used in this chip */

 we haven't yet set QIB_PRESENT, so use read directly */

 now register routines work */

 fill in boardname */

	/*

	 * GPIO bits for TWSI data and clock,

	 * used for serial EEPROM.

 these can't change for this chip, so set once */

 we always allocate at least 2048 bytes for eager buffers */

	/*

	 * We can request a receive interrupt for 1 or

	 * more packets from current offset.  For now, we set this

	 * up for a single packet.

 setup the stats timer; the add_timer is done at end of init */

 set chip access pointers now */

 if any 6120's, only one VL */

 use all of 4KB buffers for the kernel, otherwise 16 */

/*

 * For this chip, we want to use the same buffer every time

 * when we are trying to bring the link up (they are always VL15

 * packets).  At that link state the packet should always go out immediately

 * (or at least be discarded at the tx interface if the link is down).

 * If it doesn't, and the buffer isn't available, that means some other

 * sender has gotten ahead of us, and is preventing our packet from going

 * out.  In that case, we flush all packets, and try again.  If that still

 * fails, we fail the request, and hope things work the next time around.

 *

 * We don't need very complicated heuristics on whether the packet had

 * time to go out or not, since even at SDR 1X, it goes out in very short

 * time periods, covered by the chip reads done here and as part of the

 * flush.

	/*

	 * always blip to get avail list updated, since it's almost

	 * always needed, and is fairly cheap.

 extra chip flush */

 update our idea of what's busy */

 extra chip flush */

 try 4k if all 2k busy, so same last for both sizes */

/*

 * the pbc doesn't need a VL15 indicator, but we need it for link_buf.

 * The chip ignores the bit if set.

 Dummy function, as 6120 boards never disable EEPROM Write */

/**

 * qib_init_iba6120_funcs - set up the chip-specific function pointers

 * @pdev: pci_dev of the qlogic_ib device

 * @ent: pci_device_id matching this chip

 *

 * This is global, and is called directly at init to set up the

 * chip-specific function pointers for later use.

 *

 * It also allocates/partially-inits the qib_devdata struct for

 * this device.

	/*

	 * Do remaining pcie setup and save pcie values in dd.

	 * Any error printing is already done by the init code.

	 * On return, we have the chip mapped and accessible,

	 * but chip registers are not set up until start of

	 * init_6120_variables.

 initialize chip-specific variables */

 clear diagctrl register, in case diags were running and crashed */

 setup interrupt handler (interrupt type handled above) */

 Note that qpn_mask is set by qib_6120_config_ctxts() first */

/*

 * Copyright (c) 2006, 2007, 2008, 2009, 2010 QLogic Corporation.

 * All rights reserved.

 * Copyright (c) 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 cut down ridiculously long IB macro names */

/**

 * qib_make_uc_req - construct a request packet (SEND, RDMA write)

 * @qp: a pointer to the QP

 * @flags: unused

 *

 * Assumes the s_lock is held.

 *

 * Return 1 if constructed; otherwise, return 0.

 We are in the error state, flush the work request. */

 If DMAs are in progress, we can't flush immediately. */

 header size in 32-bit words LRH+BTH = (8+12)/4. */

 Get the next send request. */

 Check if send work queue is empty. */

		/*

		 * Start a new request.

 Immediate data comes after the BTH */

 Immediate data comes after the RETH */

 Immediate data comes after the BTH */

 Immediate data comes after the BTH */

/**

 * qib_uc_rcv - handle an incoming UC packet

 * @ibp: the port the packet came in on

 * @hdr: the header of the packet

 * @has_grh: true if the packet has a GRH

 * @data: the packet data

 * @tlen: the length of the packet

 * @qp: the QP for this packet.

 *

 * This is called from qib_qp_rcv() to process an incoming UC packet

 * for the given QP.

 * Called at interrupt level.

 Check for GRH */

 LRH + BTH */

 LRH + GRH + BTH */

 Compare the PSN verses the expected PSN. */

		/*

		 * Handle a sequence error.

		 * Silently drop any current message.

 Check for opcode sequence errors. */

 OK, process the packet. */

			/*

			 * qp->s_rdma_read_sge will be the owner

			 * of the mr references.

 Check for invalid length PMTU or posted rwqe len. */

 Get the number of bytes the message was padded by. */

 Check for invalid length. */

 XXX LAST len should be >= 1 */

 Don't count the CRC. */

 zero fields that are N/A */

 Signal completion event if the solicited bit is set. */

 consume RWQE */

 Check rkey */

 Check for invalid length PMTU or posted rwqe len. */

 Get the number of bytes the message was padded by. */

 Check for invalid length. */

 XXX LAST len should be >= 1 */

 Don't count the CRC. */

 Get the number of bytes the message was padded by. */

 Check for invalid length. */

 XXX LAST len should be >= 1 */

 Don't count the CRC. */

 Drop packet for unknown opcodes. */

/*

 * Copyright (c) 2013 Intel Corporation. All rights reserved.

 * Copyright (c) 2006 - 2012 QLogic Corporation. All rights reserved.

 * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * This file contains all of the code that is specific to the SerDes

 * on the QLogic_IB 7220 chip.

/*

 * Same as in qib_iba7220.c, but just the registers needed here.

 * Could move whole set to qib_7220.h, but decided better to keep

 * local.

 these are used only here, not in qib_iba7220.c */

/*

 * The IBSerDesMappTable is a memory that holds values to be stored in

 * various SerDes registers by IBC.

/*

 * Below used for sdnum parameter, selecting one of the two sections

 * used for PCIe, or the single SerDes used for IB.

/*

 * The EPB requires addressing in a particular form. EPB_LOC() is intended

 * to make #definitions a little more readable.

 Forward declarations. */

 Tweak the register (CMUCTRL5) that contains the TRIMSELF controls */

/*

 * Below keeps track of whether the "once per power-on" initialization has

 * been done, because uC code Version 1.32.17 or higher allows the uC to

 * be reset at will, and Automatic Equalization may require it. So the

 * state of the reset "pin", is no longer valid. Instead, we check for the

 * actual uC code having been loaded.

 repeat #define for local use. "Real" #define is in qib_iba7220.c */

 clear, then re-enable parity errs */

/*

 * After a reset or other unusual event, the epb interface may need

 * to be re-synchronized, between the host and the uC.

 * returns <0 for failure to resync within IBSD_RESYNC_TRIES (not expected)

 alternate F0 and 55 */

 Success */

/*

 * Localize the stuff that should be done to change IB uC reset

 * returns <0 for errors.

		/*

		 * Vendor recommends "interrupting" uC before reset, to

		 * minimize possible glitches.

 Squelch possible parity error from _asserting_ reset */

 flush write, delay to ensure it took effect */

 once it's reset, can remove interrupt */

		/*

		 * Before we de-assert reset, we need to deal with

		 * possible glitch on the Parity-error line.

		 * Suppress it around the reset, both in chip-level

		 * hwerrmask and in IB uC control reg. uC will allow

		 * it again during startup.

 set uC control regs to suppress parity errs */

 IB uC code past Version 1.32.17 allow suppression of wdog */

 flush write, delay for startup */

 clear, then re-enable parity errs */

 give time for reset to settle out in EPB */

 Do "sacrificial read" to get EPB in sane state after reset */

 Check/show "summary" Trim-done bit in IBCStatus */

	/*

	 * Do "dummy read/mod/wr" to get EPB in sane state after reset

	 * The default value for MPREG6 is 0.

 Read CTRL reg for each channel to check TRIMDONE */

 Read CTRL reg for each channel to check TRIMDONE */

/*

 * Below is portion of IBA7220-specific bringup_serdes() that actually

 * deals with registers and memory within the SerDes itself.

 * Post IB uC code version 1.32.17, was_reset being 1 is not really

 * informative, so we double-check.

 default to failure */

 SERDES MPU reset recorded in D0 */

 entered with reset not asserted, we need to do it */

 Substitute our deduced value for was_reset */

 First reset if IBSD uCode not yet loaded */

	/*

	 * Alter some regs per vendor latest doc, reset-defaults

	 * are not right for IB.

	/*

	 * Set DAC manual trim IB.

	 * We only do this once after chip has been reset (usually

	 * same as once per system boot).

	/*

	 * Set various registers (DDS and RXEQ) that will be

	 * controlled by IBC (in 1.2 mode) to reasonable preset values

	 * Calling the "internal" version avoids the "check for needed"

	 * and "trimdone monitor" that might be counter-productive.

 Load image, then try to verify */

 Assume success */

 Loaded image, try to verify */

 end if verified */

 end if loaded */

		/*

		 * Loaded and verified. Almost good...

		 * hold "success" in ret

		/*

		 * Prev steps all worked, continue bringup

		 * De-assert RESET to uC, only in first reset, to allow

		 * trimming.

		 *

		 * Since our default setup sets START_EQ1 to

		 * PRESET, we need to clear that for this very first run.

		/*

		 * If this is not the first reset, trimdone should be set

		 * already. We may need to check about this.

		/*

		 * Whether or not trimdone succeeded, we need to put the

		 * uC back into reset to avoid a possible fight with the

		 * IBC state-machine.

		/*

		 * DEBUG: check each time we reset if trimdone bits have

		 * gotten cleared, and re-set them.

 Remember so we do not re-do the load, dactrim, etc. */

	/*

	 * setup for channel training and load values for

	 * RxEq and DDS in tables used by IBC in IB1.2 mode

 start relock timer regardless, but start at 1 second */

/*

 * query, claim, release ownership of the EPB (External Parallel Bus)

 * for a specified SERDES.

 * the "claim" parameter is >0 to claim, <0 to release, 0 to query.

 * Returns <0 for errors, >0 if we had ownership, else 0.

		/*

		 * The IB SERDES "ownership" is fairly simple. A single each

		 * request/grant.

 PCIe SERDES has two "octants", need to select which */

 Make sure any outstanding transaction was seen */

 Need to release */

		/*

		 * The only writeable bits are the request and CS.

		 * Both should be clear

 First read after write is not trustworthy */

 Need to claim */

 First read after write is not trustworthy */

/*

 * Lemma to deal with race condition of write..read to epb regs

 Throw away first read, as RDY bit may be stale */

/**

 * qib_sd7220_reg_mod - modify SERDES register

 * @dd: the qlogic_ib device

 * @sdnum: which SERDES to access

 * @loc: location - channel, element, register, as packed by EPB_LOC() macro.

 * @wd: Write Data - value to set in register

 * @mask: ones where data should be spliced into reg.

 *

 * Basic register read/modify/write, with un-needed acesses elided. That is,

 * a mask of zero will prevent write, while a mask of 0xFF will prevent read.

 * returns current (presumed, if a write was done) contents of selected

 * register, or <0 if errors.

	/*

	 * All access is locked in software (vs other host threads) and

	 * hardware (vs uC access).

 to make read-skip work */

			/*

			 * Not a pure write, so need to read.

			 * loc encodes chip-select as well as address

			/*

			 * Not a pure read, so need to write.

 else, failed to see ready, what error-handling? */

	/*

	 * Release bus. Failure is an error.

/*

 * Below, all uC-related, use appropriate UC_CS, depending

 * on which SerDes is used.

 Transfer date to/from uC Program RAM of IB or PCIe SerDes */

 Pick appropriate transaction reg and "Chip select" for this serdes */

 PCIe SERDES has uC "chip select" in different bit, too */

	/*

	 * In future code, we may need to distinguish several address ranges,

	 * and select various memories based on this. For now, just trim

	 * "loc" (location including address and memory select) to

	 * "addr" (address within memory). we will only support PRAM

	 * The memory is 8KB.

		/*

		 * Every "memory" access is doubly-indirect.

		 * We set two bytes of address, then read/write

		 * one or mores bytes of data.

 First, we set control to "Read" or "Write" */

 Only set address at start of chunk */

 Finally, clear control-bit for Read or Write */

 Release bus. Failure is an error */

 failed in read itself */

/*

 * IRQ not set up at this point in init, so we poll.

	/*

	 * Default to failure, so IBC will not start

	 * without IB_SERDES_TRIM_DONE.

/*

 * Set the "negotiation" values for SERDES. These are used by the IB1.2

 * link negotiation. Macros below are attempt to keep the values a

 * little more human-editable.

 * First, values related to Drive De-emphasis Settings.

 LSB-first list of regs (in elt 9) to mod */

       DDR(FDR)       SDR(HDR)   */

 Vendor recommends below for 3m cable */

 Vendor recommends below for 1m cable */

/*

 * Now the RXEQ section of the table.

 Hardware packs an element number and register address thus: */

 in form used in SerDesDDSRXEQ */

 Set Rcv Eq. to Preset node */

 Set DFELTHFDR/HDR thresholds */

 FDR, was 0, 1, 2, 3 */

 HDR */

 Set TLTHFDR/HDR theshold */

 FDR, was 0, 2, 4, 6 */

 HDR, was  0, 1, 2, 3 */

 Set Preamp setting 2 (ZFR/ZCNT) */

 FDR, was 12, 16, 20, 24 */

 HDR, was 12, 16, 20, 24 */

 Set Preamp DC gain and Setting 1 (GFR/GHR) */

 FDR, was 16, 17, 18, 20 */

 HDR, was 16, 17, 18, 20 */

 Toggle RELOCK (in VCDL_CTRL0) to lock to data */

 Set D5 High */

 Set D5 Low */

 There are 17 values from vendor, but IBC only accesses the first 16 */

 Minimum index for this portion of table */

	/*

	 * Init the DDS section of the table.

	 * Each "row" of the table provokes NUM_DDS_REG writes, to the

	 * registers indicated in DDS_REG_MAP.

	/*

	 * Iterate down table within loop for each register to store.

 End inner for (vals for this reg, each row) */

 end outer for (regs to be stored) */

	/*

	 * Init the RXEQ section of the table.

	 * This runs in a different order, as the pattern of

	 * register references is more complex, but there are only

	 * four "data" values per register.

 RXEQ indices pick up where DDS left off */

 RXEQ data is in second half of table */

 Iterate through RXEQ register addresses */

 "destination" */

 didx is offset by min_idx to address RXEQ range of regs */

 Store the next RXEQ register address */

 Iterate through RXEQ values */

 end outer for (Reg-writes for RXEQ) */

/*

 * Repeat a "store" across all channels of the IB SerDes.

 * Although nominally it inherits the "read value" of the last

 * channel it modified, the only really useful return is <0 for

 * failure, >= 0 for success. The parameter 'loc' is assumed to

 * be the location in some channel of the register to be modified

 * The caller can specify use of the "gang write" option of EPB,

 * in which case we use the specified channel data for any fields

 * not explicitely written.

		/*

		 * Our caller has assured us that we can set all four

		 * channels at once. Trust that. If mask is not 0xFF,

		 * we will read the _specified_ channel for our starting

		 * value.

 Clear "channel" and set CS so we can simply iterate */

/*

 * Set the Tx values normally modified by IBC in IB1.2 mode to default

 * values, as gotten from first row of init table.

 Vendor says RMW not needed for these regs, use 0xFF mask */

/*

 * Set the Rx values normally modified by IBC in IB1.2 mode to default

 * values, as gotten from selected column of init table.

 mask of 0xFF, because hardware does full-byte store. */

/*

 * Set the default values (row 0) for DDR Driver Demphasis.

 * we do this initially and whenever we turn off IB-1.2

 *

 * The "default" values for Rx equalization are also stored to

 * SerDes registers. Formerly (and still default), we used set 2.

 * For experimenting with cables and link-partners, we allow changing

 * that via a module parameter.

 Assert uC reset, so we don't clash with it. */

 more fine-tuning of what will be default */

	/*

	 * Delay for max possible number of steps, with slop.

	 * Each step is about 4usec.

 And again for good measure */

 Now reset xgxs and IBC to complete the recovery */

/*

 * Shut down the timer that polls for relock occasions, if needed

 * this is "hooked" from qib_7220_quiet_serdes(), which is called

 * just before qib_shutdown_device() in qib_driver.c shuts down all

 * the other timers

	/*

	 * Check link-training state for "stuck" state, when down.

	 * if found, try relock and schedule another try at

	 * exponentially growing delay, maxed at one second.

	 * if not stuck, our work is done.

 re-set timer for next check */

 We are now up, relax timer to 1 second interval */

 Transition to down, (re-)set timer to short interval. */

 If timer has not yet been started, do so. */

/* QLogic qedr NIC Driver

 * Copyright (c) 2015-2016  QLogic Corporation

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and /or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Unsupported */

 *attr being zeroed by the caller, avoid zeroing it here */

	/* Two-Layer PBLs, if we have more than one pbl we need to initialize

	 * the first one with physical pointers to all of the rest

 calculate required pbl page size */

 One for the layer0 ( points to the pbls) */

 One layered PBL */

	/* If we have a two layered pbl, the first pbl points to the rest

	 * of the pbls and the first entry lays on the second pbl in the table

		/* If the given pbl is full storing the pbes, move to next pbl.

	/* Ignore return code as there is not much we can do about it. Error

	 * log will be printed inside.

 We allocate an extra entry that we don't report to the FW. */

 Aborting for non doorbell userqueue (SRQ) or non-supporting lib */

 Allocate a page for doorbell recovery, add to mmap */

 mmap the user address used to store doorbell data for recovery */

 calc db offset. user will add DPI base, kernel will add db addr */

 Generate doorbell address. */

 point to the very last element, passing it we will toggle */

 GSIs CQs are handled by driver, so they don't exist in the FW */

	/* We don't want the IRQ handler to handle a non-existing CQ so we

	 * wait until all CNQ interrupts, if any, are received. This will always

	 * happen and will always happen very fast. If not, then a serious error

	 * has occured. That is why we can use a long delay.

	 * We spin for a short time so we dont lose time on context switching

	 * in case all the completions are handled in that span. Otherwise

	 * we sleep for a while and check again. Since the CNQ may be

	 * associated with (only) the current CPU we use msleep to allow the

	 * current CPU to be freed.

	 * The CNQ notification is increased in qedr_irq_handler().

	/* Note that we don't need to have explicit code to wait for the

	 * completion of the event handler because it is invoked from the EQ.

	 * Since the destroy CQ ramrod has also been received on the EQ we can

	 * be certain that there's no event handler in process.

 QP0... attrs->qp_type == IB_QPT_GSI */

	/* verify consumer QPs are not trying to use GSI QP's CQ.

	 * TGT QP isn't associated with RQ/SQ

 iWARP requires two doorbells per RQ. */

 iWARP uses the same cid for rq and sq */

 QP handle to be written in an async event */

 SQ - read access only (0) */

 RQ - read access only (0) */

 db offset was calculated in copy_qp_uresp, now set in the user q */

		/* calculate the db_rec_db2 data since it is constant so no

		 * need to reflect from user

 Now we allocate the chain */

 GSI qp is not registered to db mechanism so no need to delete */

	/* A single work request may take up to QEDR_MAX_SQ_WQE_SIZE elements in

	 * the ring. The ring should allow at least a single WR, even if the

	 * user requested none, due to allocation issues.

	 * We should add an extra WR since the prod and cons indices of

	 * wqe_wr_id are managed in such a way that the WQ is considered full

	 * when (prod+1)%max_wr==cons. We currently don't do that because we

	 * double the number of entries due an iSER issue that pushes far more

	 * WRs than indicated. If we decline its ib_post_send() then we get

	 * error prints in the dmesg we'd like to avoid.

 QP handle to be written in CQE */

	/* A single work request may take up to QEDR_MAX_RQ_WQE_SIZE elements in

	 * the ring. There ring should allow at least a single WR, even if the

	 * user requested none, due to allocation issues.

 Allocate driver internal RQ array */

			/* Update doorbell (in case post_recv was

			 * done before move to RTR)

 Invalid state change. */

 RTR->XXX */

 Invalid state change. */

 RTS->XXX */

 Invalid state change. */

 SQD->XXX */

 Invalid state change. */

 ERR->XXX */

 Translate the masks... */

 Stay with current MTU */

		/* The received timeout value is an exponent used like this:

		 *    "12.7.34 LOCAL ACK TIMEOUT

		 *    Value representing the transport (ACK) timeout for use by

		 *    the remote, expressed as: 4.096 * 2^timeout [usec]"

		 * The FW expects timeout in msec so we need to divide the usec

		 * result by 1000. We'll approximate 1000~2^10, and 4.096 ~ 2^2,

		 * so we get: 2^2 * 2^timeout / 2^10 = 2^(timeout - 8).

		 * The value of zero means infinite so we use a 'max_t' to make

		 * sure that sub 1 msec values will be configured as 1 msec.

	/* Update the QP state before the actual ramrod to prevent a race with

	 * fast path. Modifying the QP state to error will cause the device to

	 * flush the CQEs and while polling the flushed CQEs will considered as

	 * a potential issue if the QP isn't in error state.

 Change the QP state to ERROR */

		/* If connection establishment started the WAIT_FOR_CONNECT

		 * bit will be on and we need to Wait for the establishment

		 * to complete before destroying the qp.

		/* If graceful disconnect started, the WAIT_FOR_DISCONNECT

		 * bit will be on, and we need to wait for the disconnect to

		 * complete before continuing. We can use the same completion,

		 * iwarp_cm_comp, since this is the only place that waits for

		 * this completion and it is sequential. In addition,

		 * disconnect can't occur before the connection is fully

		 * established, therefore if WAIT_FOR_DISCONNECT is on it

		 * means WAIT_FOR_CONNECT is also on and the completion for

		 * CONNECT already occurred.

	/* We need to remove the entry from the xarray before we release the

	 * qp_id to avoid a race of the qp_id being reallocated and failing

	 * on xa_insert

	/* in usual case we use 2 PBLs, so we add one to free

	 * list and allocating another one

 Index only, 18 bit long, lkey = itid << 8 | key */

 it could be user registered memory. */

 Index only, 18 bit long, lkey = itid << 8 | key */

		/* Free all the page list that are possible to be freed

		 * (all the ones that were invalidated), under the assumption

		 * that if an FMR was completed successfully that means that

		 * if there was an invalidate operation before it also ended

 index only, 18 bit long, lkey = itid << 8 | key */

 Copy data inline */

 New segment required */

 Calculate currently allowed length */

 Update segment variables */

 Update sge variables */

 Swap fully-completed segments */

 swap last not completed segment */

 prevent SQ overflow and/or processing of a bad WR */

 same is identical to RDMA READ */

		/* Restore prod to its position before

		 * this WR was processed

 Restore prev_wqe_size */

	/* Trigger doorbell

	 * If there was a failure in the first WR then it will be triggered in

	 * vane. However this is not harmful (as long as the producer value is

	 * unchanged). For performance reasons we avoid checking for this

	 * redundant doorbell.

	 *

	 * qp->wqe_wr_id is accessed during qedr_poll_cq, as

	 * soon as we give the doorbell, we could get a completion

	 * for this wr, therefore we need to make sure that the

	 * memory is updated before giving the doorbell.

	 * During qedr_poll_cq, rmb is called before accessing the

	 * cqe. This covers for the smp_rmb as well.

	/* Calculate number of elements used based on producer

	 * count and consumer count and subtract it from max

	 * work request supported so that we get elements left.

 Set number of sge and work request id in header */

 Set SGE length, lkey and address */

		/* Update WQE and SGE information before

		 * updating producer.

		/* SRQ producer is 8 bytes. Need to update SGE producer index

		 * in first 4 bytes and need to update WQE producer in

		 * next 4 bytes.

 Make sure sge producer is updated first */

			/* First one must include the number

			 * of SGE in the list

		/* Special case of no sges. FW requires between 1-4 sges...

		 * in this case we need to post 1 sge with length zero. this is

		 * because rdma write with immediate consumes an RQ.

			/* First one must include the number

			 * of SGE in the list

		/* qp->rqe_wr_id is accessed during qedr_poll_cq, as

		 * soon as we give the doorbell, we could get a completion

		 * for this wr, therefore we need to make sure that the

		 * memory is update before giving the doorbell.

		 * During qedr_poll_cq, rmb is called before accessing the

		 * cqe. This covers for the smp_rmb as well.

 Return latest CQE (needs processing) */

/* In fmr we need to increase the number of fmr completed counter for the fmr

 * algorithm determining whether we can free a pbl or not.

 * we need to perform this whether the work request was signaled or not. for

 * this purpose we call this function from the condition that checks if a wr

 * should be skipped, to make sure we don't miss it ( possibly this fmr

 * operation was not signalted)

 skip WC */

 fill WC */

 process all WQE before the cosumer */

 if we have extra WC fill it with actual error info */

 Must fill fields before qedr_set_ok_cqe_resp_wc() */

 Fill the rest of the WC */

 fill WC */

 prevent speculative reads of any field of CQE */

		/* doorbell notifies abount latest VALID entry,

		 * but chain already point to the next INVALID one

/* QLogic qedr NIC Driver

 * Copyright (c) 2015-2017  QLogic Corporation

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and /or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

		/* Only connect_request and reply have valid private data

		 * the rest of the events this may be left overs from

		 * connection establishment. CONNECT_REQUEST is issued via

		 * qedr_iw_mpa_request

	/* The qp won't be released until we release the ep.

	 * the ep's refcnt was increased before calling this

	 * function, therefore it is safe to access qp

	/* Success means graceful disconnect was requested. modifying

	 * to SQD is translated to graceful disconnect. O/w reset is sent

	/* We can't get a close event before disconnect, but since

	 * we're scheduling a work queue we need to make sure close

	 * won't delete the ep, so we increase the refcnt

	/* We will only reach the following state if MPA_REJECT was called on

	 * passive. In this case there will be no associated QP.

 QP already being destroyed */

 QP already destroyed */

/* QLogic qedr NIC Driver

 * Copyright (c) 2015-2016  QLogic Corporation

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and /or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 note: length stands for data length i.e. GRH is excluded */

 Do nothing... */

 if a dedicated recv_cq was used, delete it too */

 hdr */  + pkt->n_seg;

 tx header */

 TX failed while posting header - release resources */

 tx payload */

			/* if failed not much to do here, partial packet has

			 * been posted we can't free memory, will need to wait

			 * for completion

 remove LL2 MAC address filter */

 configure and start LL2 */

 create QP */

 the GSI CQ is handled by the driver so remove it from the FW */

 RoCE v1 */

 RoCE v2 IPv4 */

 RoCE v2 IPv6 */

 ENET + VLAN headers */

 BTH */

 DETH */

 GRH / IPv6 header */

 IPv4 header */

 note: checksum is calculated by the device */

 UDP */

 UDP length is untouched hence is zero */

 cookie */,

 notify_fw */);

 0 - currently only one recv sg is supported */

/* QLogic qedr NIC Driver

 * Copyright (c) 2015-2016  QLogic Corporation

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and /or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 QEDR sysfs interface */

 This function allocates fast-path status block memory */

 Allocate Status blocks for CNQ */

 Allocate CNQ PBLs */

 Align protocol-index and chain reads */

		/* The CQ's CNQ notification counter is checked before

		 * destroying the CQ in a busy-wait loop that waits for all of

		 * the CQ's CNQ interrupts to be processed. It is increased

		 * here, only after the completion handler, to ensure that the

		 * the handler is not running when the CQ is destroyed.

 Learn Interrupt configuration */

 Part 1 - query core capabilities */

 Part 2 - check capabilities */

 Part 3 - copy and update capabilities */

	/* First unregister with stack to stop all the active traffic

	 * of the registered clients.

 Update SGID */

 Update LL2 */

/* event handling via NIC driver ensures that all the NIC specific

 * initialization done before RoCE driver notifies

 * event to stack.

/*

 * Broadcom NetXtreme-E RoCE driver.

 *

 * Copyright (c) 2016 - 2017, Broadcom. All rights reserved.  The term

 * Broadcom refers to Broadcom Limited and/or its subsidiaries.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS''

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,

 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR

 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS

 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE

 * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN

 * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Description: IB Verbs interpreter

 Device */

 Port */

 Ignore port_num */

 Ignore port_num */

 Delete the entry from the hardware */

		/* DEL_GID is called in WQ context(netdevice_event_work_handler)

		 * or via the ib_unregister_device path. In the former case QP1

		 * may not be destroyed yet, in which case just return as FW

		 * needs that entry to be present and will fail it's deletion.

		 * We could get invoked again after QP1 is destroyed OR get an

		 * ADD_GID call with a different GID value for the same index

		 * where we issue MODIFY_GID cmd to update the GID entry -- TBD

	/* Save the initial rkey in fence structure for now;

	 * wqe->bind.r_key will be set at (re)bind time.

 Allocate a MR */

 Register MR */

 Create a fence MW only for kernel consumers */

 Protection Domains */

			/* Allocate DPI in alloc_pd to avoid failing of

			 * ibv_devinfo and family of application when DPIs

			 * are depleted.

 Still allow mapping this DBR to the new user PD. */

 Address Handles */

 Supply the configuration for the HW */

	/* Get the HW context of the GID. The reference

	 * of GID table entry is already taken by the caller.

 Get network header type for this GID */

 Write AVID to shared page. */

 make sure cache is updated. */

 remove from active qp list */

 Queue Pairs */

	/* For gen p4 and gen p5 backward compatibility mode

	 * wqe size is fixed to 128 bytes

 Consider mapping PSN search memory only for RC QPs. */

 supply the dgid data same as sgid */

 Have DMAC same as SMAC */

 Initialize the shadow QP structure from the QP1 values */

 Shadow QP SQ depth should be same as QP1 RQ depth */

 Q full delta can be 1 since it is internal QP */

 Q full delta can be 1 since it is internal QP */

		/* Allocate 1 more than what's provided so posting max doesn't

		 * mean empty.

 Allocate 128 + 1 more than what's provided */

	/*

	 * Reserving one slot for Phantom WQE. Application can

	 * post one extra entry in this case. But allowing this to avoid

	 * unexpected Queue full condition

 Need one extra sge to put UD header */

 Setup misc params */

 Doorbell page */

 Setup CQs */

 Setup RQ/SRQ */

 Setup SQ */

 This will update DPI and qp_handle */

 Create a shadow QP to handle the QP1 traffic */

 Shared Receive Queues */

	/* Allocate 1 more than what's provided so posting max doesn't

	 * mean empty

 128 byte wqe size for SRQ . So use max sges */

 SRQ resize is not supported */

 Change the SRQ threshold */

 On success, update the shadow */

 No need to Build and send response back to udata */

 Get live SRQ attr */

 Transcribe each ib_recv_wr to qplib_swqe */

 Using a Random  QKEY */

 LOCAL_WRITE access must be set to allow RC receive */

 Temp: Set all params on QP as of now */

		/* Get the HW context of the GID. The reference

		 * of GID table entry is already taken by the caller.

 Cap the max_rd_atomic to device max */

		/*

		 * Reserving one slot for Phantom WQE. Some application can

		 * post one extra entry in this case. Allowing this to avoid

		 * unexpected Queue full condition

 SRQ was used prior, just ignore the RQ caps */

/* Routine for sending QP1 packets for RoCE V1 an V2

 Get network header type for this GID */

 ETH */

 For vlan, check the sgid for vlan existence */

 BTH */

 pad_count */

 P_key for QP1 is for all members */

 DETH */

 Use the priviledged Q_Key for QP1 */

 Pack the QP1 to the transmit buffer */

		/*

		 * Max Header buf size for IPV6 RoCE V2 is 86,

		 * which is same as the QP1 SQ header buffer.

		 * Header buf size for IPV4 RoCE V2 can be 66.

		 * ETH(14) + VLAN(4)+ IP(20) + UDP (8) + BTH(20).

		 * Subtract 20 bytes from QP1 SQ header buf size

		/*

		 * Max Header buf size for RoCE V1 is 78.

		 * ETH(14) + VLAN(4) + GRH(40) + BTH(20).

		 * Subtract 8 bytes from QP1 SQ header buf size

 Subtract 4 bytes for non vlan packets */

/* For the MAD layer, it only provides the recv SGE the size of

 * ib_grh + MAD datagram.  No Ethernet headers, Ethertype, BTH, DETH,

 * nor RoCE iCRC.  The Cu+ solution must provide buffer for the entire

 * receive packet (334 bytes) with no VLAN and then copy the GRH

 * and the MAD datagram out to the provided SGE.

	/* Create 1 SGE to receive the entire

	 * ethernet packet

 Save the reference from ULP */

 SGE 1 */

 Store the wrid for reporting completion */

 change the wqe->wrid to table index */

	/* Need unconditional fence for local invalidate

	 * opcode to work as expected.

	/* Need unconditional fence for reg_mr

	 * opcode to function as expected.

  Copy the inline data to the data  field */

 Common */

 House keeping */

 Common */

 Unsupported WRs */

 House keeping */

 Common */

 House keeping */

 Common */

 Ring DB if the RQEs posted reaches a threshold value */

 Completion Queues */

 Validate CQ fields */

	/*

	 * Allocating the NQ in a round robin fashion. nq_alloc_cnt is a

	 * used for getting the NQ index.

 raweth_qp1_flags Bit 9-6 indicates itype */

 raweth_qp1_flags2 Bit 8 indicates ip_type. 0-v4 1 - v6 */

	/*

	 * If dest mac is not same as I/F mac, this could be a

	 * loopback address or multicast address, check whether

	 * it is a loopback packet

 Check the  ether type */

 Shadow QP header buffer */

 Store this cqe */

 Find packet type from the cqe */

 Adjust the offset for the user buffer and post in the rq */

	/*

	 * QP1 loopback packet has 4 bytes of internal header before

	 * ether header. Skip these four bytes.

 First send SGE . Skip the ether header*/

 Second Send SGE */

 First recv SGE */

 Create receive work request */

 post data received  in the send queue */

	/*

	 * Check if the vlan is configured in the host.  If not configured, it

	 * can be a transparent VLAN. So dont report the vlan id.

 report only on GSI QP for Thor */

 Mark only if vlan_id is non zero */

 Transcribe each qplib_wqe back to ib_wc */

					/* Handle this completion with

					 * the stored completion

				/* Errors need not be looped back.

				 * But change the wr_id to the one

				 * stored in the table

					/* Handle this completion with

					 * the stored completion

 Trigger on the very next completion */

 Trigger on the next solicited completion */

 Poll to see if there are missed events */

 Memory Regions */

 Allocate and register 0 as the address */

 Infinte length */

 uverbs */

 The fixed portion of the rkey is the same as the lkey */

Temp, Use xa_alloc instead */

		/* Free DPI only if this is the first PD allocated by the

		 * application and mark the context dpi as NULL

 Helper function to mmap the virtual memory from user app */

/*

 * Broadcom NetXtreme-E RoCE driver.

 *

 * Copyright (c) 2016 - 2017, Broadcom. All rights reserved.  The term

 * Broadcom refers to Broadcom Limited and/or its subsidiaries.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS''

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,

 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR

 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS

 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE

 * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN

 * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Description: Slow Path Operators

 Device */

 Extract the context from the side buffer */

 max_qp value reported by FW for PF doesn't include the QP1 for PF */

	/*

	 * 128 WQEs needs to be reserved for the HW (8916). Prevent

	 * reporting the max number

	/*

	 * Some versions of FW reports more than 0xFFFF.

	 * Restrict it for now to 0xFFFF to avoid

	 * reporting trucated value

 ib_port_attr::pkey_tbl_len is u16 */

 SGID */

 Do we need a sgid_lock here? */

 Remove GID from the SGID table */

 unlock */

 Do we need a sgid_lock here? */

		/*

		 * driver should ensure that all RoCE traffic is always VLAN

		 * tagged if RoCE traffic is running on non-zero VLAN ID or

		 * RoCE traffic is running on non-zero Priority.

 MAC in network format */

 Add GID to the sgid_tbl */

 unlock */

 MAC in network format */

 pkeys */

 Do we need a pkey_lock here? */

 unlock */

 Do we need a pkey_lock here? */

 Add PKEY to the pkey_tbl */

 unlock */

 AH */

 MAC in network format */

 Clean up the AH table in the device */

 MRW */

 Free the qplib's MRW memory */

 Free the qplib's MR memory */

		/* Allocate memory for the non-leaf pages to store buf ptrs.

		 * Non-leaf pages always uses system PAGE_SIZE

 Free the hwq if it already exist, must be a rereg */

 Use system PAGE_SIZE */

 Configure the request */

 No PBL provided, just use system PAGE_SIZE */

 Re-calculate the max to fit the HWQ allocation model */

 Extract the context from the side buffer */

/*

 * Broadcom NetXtreme-E RoCE driver.

 *

 * Copyright (c) 2016 - 2017, Broadcom. All rights reserved.  The term

 * Broadcom refers to Broadcom Limited and/or its subsidiaries.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS''

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,

 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR

 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS

 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE

 * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN

 * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Description: Statistics

 *

/*

 * Broadcom NetXtreme-E RoCE driver.

 *

 * Copyright (c) 2016 - 2017, Broadcom. All rights reserved.  The term

 * Broadcom refers to Broadcom Limited and/or its subsidiaries.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS''

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,

 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR

 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS

 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE

 * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN

 * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Description: RDMA Controller HW interface

 Hardware communication channel */

	/* Cmdq are in 16-byte units, each request can consume 1 or more

	 * cmdqe

	/* change the cmd_size to the number of 16byte cmdq unit.

	 * req->cmd_size is modified here

 Locate the next cmdq slot */

 Copy a segment of the req cmd to the cmdq */

		/* The very first doorbell write

		 * is required to set this flag

		 * which prompts the FW to reset

		 * its internal pointers

 ring CMDQ DB */

 Return the CREQ response pointer */

 Prevent posting if f/w is not in a state to process */

 send failed */

 timed out */

 failed with status */

 Completions */

		/* SRQ ctx error, call srq_handler??

		 * But there's no SRQ handle!

		/*

		 * Command Response

		 * cmdq->lock needs to be acquired to synchronie

		 * the command send and completion reaping. This function

		 * is always called with creq->lock held. Using

		 * the nested variant of spin_lock.

		 *

 SP - CREQ Completion handlers */

 Service the CREQ until budget is over */

		/* The valid test of the entry must be done first before

		 * reading any further.

 Prefetch the CREQ element */

 RCFW */

	/* Supply (log-base-2-of-host-page-size - base-page-shift)

	 * to bono to adjust the doorbell page sizes.

	/*

	 * Gen P5 devices doesn't require this allocation

	 * as the L2 driver does the same for RoCE also.

	 * Also, VFs need not setup the HW context area, PF

	 * shall setup this area for VF. Skipping the

	 * HW programming

 Allocate one extra to hold the QP1 entries */

 Mask h/w interrupts */

 Sync with last running IRQ-handler */

 Make sure the HW channel is stopped! */

 Unconditionally map 8 bytes to support 57500 series */

 Write to the Bono mailbox register */

 Clear to defaults */

/*

 * Broadcom NetXtreme-E RoCE driver.

 *

 * Copyright (c) 2016 - 2017, Broadcom. All rights reserved.  The term

 * Broadcom refers to Broadcom Limited and/or its subsidiaries.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS''

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,

 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR

 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS

 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE

 * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN

 * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Description: QPLib resource manager

 PBL */

 page ptr arrays */

 HWQ */

 All HWQs are power of 2 in size */

 This request is Level 0, map PTE */

 2 levels of indirection */

 Alloc PDE pages */

 Alloc PBL pages */

 Fill PDL with PBL page pointers */

			/* For MR it is expected that we supply only 1 contigous

			 * page i.e only 1 entry in the PDL that will contain

			 * all the PBLs for the user supplied memory region

 Alloc or init PTEs */

 Fill PBLs with PTE pointers */

 Find the last pg of the size */

 pages < 512 npbl = 1, npde = 0 */

 1 level of indirection */

 Alloc PBL page */

 Alloc or init  PTEs */

 Fill PBL with PTE pointers */

 Find the last pg of the size */

 For direct access to the elements */

 Context Tables */

 restore original pde level before destroy */

 Alloc pdl buffer */

 Save original pdl level */

 first non-zero index */

 update pde level as per page table programming */

/*

 * Routine: bnxt_qplib_alloc_ctx

 * Description:

 *     Context tables are memories which are used by the chip fw.

 *     The 6 tables defined are:

 *             QPC ctx - holds QP states

 *             MRW ctx - holds memory region and window

 *             SRQ ctx - holds shared RQ states

 *             CQ ctx - holds completion queue states

 *             TQM ctx - holds Tx Queue Manager context

 *             TIM ctx - holds timer context

 *     Depending on the size of the tbl requested, either a 1 Page Buffer List

 *     or a 1-to-2-stage indirection Page Directory List + 1 PBL is used

 *     instead.

 *     Table might be employed as follows:

 *             For 0      < ctx size <= 1 PAGE, 0 level of ind is used

 *             For 1 PAGE < ctx size <= 512 entries size, 1 level of ind is used

 *             For 512    < ctx size <= MAX, 2 levels of ind is used

 * Returns:

 *     0 if success, else -ERRORS

 QPC Tables */

 MRW Tables */

 SRQ Tables */

 CQ Tables */

 TQM Buffer */

 TIM Buffer */

 Stats */

 PDs */

 Found unused PD */

 DPIs */

 Found unused DPI */

 PKEYs */

 pkey default = 0xFFFF */

 Stats */

/*

 * Broadcom NetXtreme-E RoCE driver.

 *

 * Copyright (c) 2016 - 2017, Broadcom. All rights reserved.  The term

 * Broadcom refers to Broadcom Limited and/or its subsidiaries.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS''

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,

 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR

 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS

 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE

 * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN

 * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Description: Fast Path Operators

 Flush list */

 Service the NQ until empty */

		/*

		 * The valid test of the entry must be done first before

		 * reading any further.

/* Wait for receiving all NQEs for this CQ and clean the NQEs associated with

 * this CQ.

 Service the NQ until empty */

		/*

		 * The valid test of the entry must be done first before

		 * reading any further.

 Prefetch the NQ element */

 Fan out to CPU affinitized kthreads? */

 Mask h/w interrupt */

 Sync with last running IRQ handler */

 Make sure the HW is stopped! */

 Unconditionally map 8 bytes to support 57500 series */

 Have a task to schedule CQ notifiers in post send case */

 SRQ */

 Configure the request */

 Configure the request */

 Deferred arming */

 Configure the request */

 Calculate wqe_size16 and data_len */

	/* retaining srq_hwq->cons for this logic

	 * actually the lock is only required to

	 * read srq_hwq->cons.

 Ring DB */

 QP */

 Make it circular */

 General */

 SQ */

 RQ */

 Header buffer - allow hdr_buf pass in */

 First psn entry */

 General */

 SQ */

 RQ */

 SRQ */

 ORRQ and IRRQ */

		/* INIT->RTR, configure the path_mtu to the default

		 * 2048 if not being requested

 Bono FW require the max_dest_rd_atomic to be >= 1 */

 Bono FW 20.6.5 requires SGID_INDEX configuration */

 Bono FW requires the max_rd_atomic to be >= 1 */

		/* Bono FW does not allow PKEY_INDEX,

		 * DGID, FLOW_LABEL, SGID_INDEX, HOP_LIMIT,

		 * TRAFFIC_CLASS, DEST_MAC, PATH_MTU, RQ_PSN,

		 * MIN_RNR_TIMER, MAX_DEST_RD_ATOMIC, DEST_QP_ID

		 * modification

 Filter out the qp_attr_mask based on the state->new transition */

 Extract the context from the side buffer */

		/*

		 * The valid test of the entry must be done first before

		 * reading any further.

 Adding sq_send_hdr is a misnomer, for rq also hdr size is same. */

 Copy the inline data */

 Specifics */

 Assemble info for Raw Ethertype QPs */

 Bad wqe, return error */

 CQ */

 Now complete all outstanding SQEs with FLUSHED_ERR */

 Skip the FENCE WQE completions */

 Out of budget */

 Flush the rest of the RQ */

 Out of budget */

 Must block new posting of SQ and RQ */

/* Note: SQE is valid from sw_sq_cons up to cqe_sq_cons (exclusive)

 *       CQE is track from sw_cq_cons to max_element but valid only if VALID=1

 Normal mode */

 Check for the psn_search marking before completing */

 Unmark */

 TODO: Only ARM if the previous SQE is ARMALL */

 Peek at the completions */

 If the next hwcqe is VALID */

			/*

			 * The valid test of the entry must be done first before

			 * reading any further.

 If the next hwcqe is a REQ */

 If the hwcqe's sq's wr_id matches */

						/*

						 *  Unbreak only if the phantom

						 *  comes back

 Valid but not the phantom, so keep looping */

 Not valid yet, just exit and wait */

	/* Require to walk the sq's swq to fabricate CQEs for all previously

	 * signaled SWQEs due to CQE aggregation from the current sq cons

	 * to the cqe_sq_cons

 Done */

		/* For the last CQE, check for status.  For errors, regardless

		 * of the request being signaled or not, it must complete with

		 * the hwcqe error status

 Add qp to flush list of the CQ */

 Before we complete, do WA 9060 */

 Out of budget */

	/*

	 * Back to normal completion mode only after it has completed all of

	 * the WC for this CQE

 Support for SRQE counter */

 Add qp to flush list of the CQ */

FIXME: Endianness fix needed for smace */

 Add qp to flush list of the CQ */

 Check for Valid bit. If the CQE is valid, return false */

 Add workaround for the length misdetection */

 Add qp to flush list of the CQ */

 Check the Status */

 Must block new posting of SQ and RQ */

	/* Terminal CQE can also include aggregated successful CQEs prior.

	 * So we must complete all CQEs from the current sq's cons to the

	 * cq_cons with status OK

 Out of budget */

	/* Terminal CQE requires all posted RQEs to complete with FLUSHED_ERR

	 * from the current rq->cons to the rq->prod regardless what the

	 * rq->cons the terminal CQE indicates

 Add qp to flush list of the CQ */

 Check the Status */

 Check for Valid bit */

		/*

		 * The valid test of the entry must be done first before

		 * reading any further.

 From the device's respective CQE format to qplib_wc*/

 Done processing this CQ */

			/* Error while processing the CQE, just skip to the

			 * next one

 Using cq->arm_state variable to track whether to issue cq handler */

/*

 * Broadcom NetXtreme-E RoCE driver.

 *

 * Copyright (c) 2016 - 2017, Broadcom. All rights reserved.  The term

 * Broadcom refers to Broadcom Limited and/or its subsidiaries.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * BSD license below:

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 *

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 * 2. Redistributions in binary form must reproduce the above copyright

 *    notice, this list of conditions and the following disclaimer in

 *    the documentation and/or other materials provided with the

 *    distribution.

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS''

 * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,

 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR

 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS

 * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR

 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF

 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR

 * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,

 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE

 * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN

 * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * Description: Main component of the bnxt_re driver

 globals */

 Mutex to protect the list of bnxt_re devices added */

 rest members to follow eventually */

 SR-IOV helper functions */

/* Set the maximum number of each resource that the driver actually wants

 * to allocate. This may be up to the maximum number the firmware has

 * reserved for the function. The driver may choose to allocate fewer

 * resources than the firmware maximum.

 Use max_mr from fw since max_mrw does not get set */

	/*

	 * Reserve a set of resources for the PF. Divide the remaining

	 * resources among the VFs

	/*

	 * The driver allows many more MRs than other resources. If the

	 * firmware does also, then reserve a fixed amount for the PF and

	 * divide the rest among VFs. VFs may use many MRs for NFS

	 * mounts, ISER, NVME applications, etc. If the firmware severely

	 * restricts the number of MRs, then let PF have half and divide

	 * the rest among VFs, as for the other resource types.

 for handling bnxt_en callbacks later */

	/* L2 driver invokes this callback during device error/crash or device

	 * reset. Current RoCE driver doesn't recover the device in case of

	 * error. Handle the error by dispatching fatal events to all qps

	 * ie. by calling bnxt_re_dev_stop and release the MSIx vectors as

	 * L2 driver want to modify the MSIx table.

	/* Check the current device state from L2 structure and move the

	 * device to detached state if FW_FATAL_COND is set.

	 * This prevents more commands to HW during clean-up,

	 * in case the device is already in error.

	/* Move the device states to detached and  avoid sending any more

	 * commands to HW

 Release the MSIx vectors before queuing unregister */

		/* Not setting the f/w timeout bit in rcfw.

		 * During the driver unload the first command

		 * to f/w will timeout and that will set the

		 * timeout bit.

	/* Vectors may change after restart, so update with new vectors

	 * in device sctructure.

 RoCE -> Net driver */

/* Driver registration routines used to let the networking driver (bnxt_en)

 * to know that the RoCE driver is now installed

 Page size is in log2 units */

 Association of ring index with doorbell index and MSIX number */

 Device */

 ib device init */

 Allocate bnxt_re_dev instance here */

 Default values */

 QP was already dead, still return success */

 Lock event_handler? */

 Lock comp_handler? */

 Configure and allocate resources for qplib */

 Modify the state of all QPs except QP1/Shadow QP */

		/* need to modify the VLAN enable setting of non VLAN GID only

		 * as setting is done for VLAN GID while adding GID

 Max 2 tcs supported */

 Get priority for roce */

 Get cosq id for this priority */

 Parse CoS IDs for app priority */

 Config BONO. */

	/* Actual priorities are not programmed as they are already

	 * done by L2 driver; just enable or disable priority vlan tagging

 Register ib dev */

 worker thread for polling periodic events. Now used for QoS programming*/

 Registered a new RoCE device instance to netdev */

 Check whether VF or PF */

	/* Establish RCFW Communication Channel to initialize the context

	 * memory for the function and all child VFs

 Resources based on the 'new' device caps */

 Handle all deferred netevents tasks */

/*

 * "Notifier chain callback can be invoked for the same chain from

 * different CPUs at the same time".

 *

 * For cases when the netdev is already present, our call to the

 * register_netdevice_notifier() will actually get the rtnl_lock()

 * before sending NETDEV_REGISTER and (if up) NETDEV_UP

 * events.

 *

 * But for cases when the netdev is not already present, the notifier

 * chain is subjected to be invoked from different CPUs simultaneously.

 *

 * This is protected by the netdev_mutex.

 Allocate for the deferred task */

		/* VF device removal should be called before the removal

		 * of PF device. Queue VFs unregister first, so that VFs

		 * shall be removed before the PF during the call of

		 * ib_unregister_driver.

 SPDX-License-Identifier: GPL-2.0 OR BSD-2-Clause

/*

 * Copyright 2018-2021 Amazon.com, Inc. or its affiliates. All rights reserved.

 This handler will called for unknown event group or unimplemented handlers */

 Safe to load as we're in irq and removal calls synchronize_irq() */

 Failures in host info set shall not disturb probe */

 Try to enable all the available aenq groups */

	/*

	 * Reserve the max msix vectors we might need, one vector is reserved

	 * for admin.

 SPDX-License-Identifier: GPL-2.0 OR BSD-2-Clause

/*

 * Copyright 2018-2021 Amazon.com, Inc. or its affiliates. All rights reserved.

 usecs */

 usecs */

 msecs */

 trash DMA req_id to identify when hardware is done */

	/*

	 * Init cons_db to mark that all entries in the queue

	 * are initially available

 ID to be used with efa_com_get_comp_ctx */

 cmd_id LSBs are the ctx_id and MSBs are entropy bits from pc */

 barrier not needed in case of writel */

 Go over all the completions */

		/*

		 * Do not read the rest of the completion entry before the

		 * phase bit was validated

 EFA didn't have any completion */

	/*

	 * In case the command wasn't completed find out the root cause.

	 * There might be 2 kinds of errors

	 * 1) No completion (timeout reached)

	 * 2) There is completion but the device didn't get any msi-x interrupt.

/*

 * There are two types to wait for completion.

 * Polling mode - wait until the completion is available.

 * Async mode - wait on wait queue until the completion is ready

 * (or the timeout expired).

 * It is expected that the IRQ called efa_com_handle_admin_completion

 * to mark the completions.

/**

 * efa_com_cmd_exec - Execute admin command

 * @aq: admin queue.

 * @cmd: the admin command to execute.

 * @cmd_size: the command size.

 * @comp: command completion return entry.

 * @comp_size: command completion size.

 * Submit an admin command and then wait until the device will return a

 * completion.

 * The completion will be copied into comp.

 *

 * @return - 0 on success, negative value on failure.

 In case of queue FULL */

/**

 * efa_com_admin_destroy - Destroy the admin and the async events queues.

 * @edev: EFA communication layer struct

/**

 * efa_com_set_admin_polling_mode - Set the admin completion queue polling mode

 * @edev: EFA communication layer struct

 * @polling: Enable/Disable polling mode

 *

 * Set the admin completion mode.

/**

 * efa_com_admin_init - Init the admin and the async queues

 * @edev: EFA communication layer struct

 * @aenq_handlers: Those handlers to be called upon event.

 *

 * Initialize the admin submission and completion queues.

 * Initialize the asynchronous events notification queues.

 *

 * @return - 0 on success, negative value on failure.

 the resolution of timeout reg is 100ms */

/**

 * efa_com_admin_q_comp_intr_handler - admin queue interrupt handler

 * @edev: EFA communication layer struct

 *

 * This method goes over the admin completion queue and wakes up

 * all the pending threads that wait on the commands wait event.

 *

 * Note: Should be called after MSI-X interrupt.

/*

 * efa_handle_specific_aenq_event:

 * return the handler that is relevant to the specific event group

/**

 * efa_com_aenq_intr_handler - AENQ interrupt handler

 * @edev: EFA communication layer struct

 * @data: Data of interrupt handler.

 *

 * Go over the async event notification queue and call the proper aenq handler.

 Get first entry */

 Go over all the events */

		/*

		 * Do not read the rest of the completion entry before the

		 * phase bit was validated

 Handle specific event*/

 call the actual event handler*/

 Get next event entry */

 Don't update aenq doorbell if there weren't any processed events */

 barrier not needed in case of writel */

 dma_addr_bits is unknown at this point */

	/*

	 * Make sure the EFA version and the controller version are at least

	 * as the driver expects

 Validate the ctrl version without the implementation ID */

/**

 * efa_com_get_dma_width - Retrieve physical dma address width the device

 * supports.

 * @edev: EFA communication layer struct

 *

 * Retrieve the maximum physical address bits the device can handle.

 *

 * @return: > 0 on Success and negative value otherwise.

/**

 * efa_com_dev_reset - Perform device FLR to the device.

 * @edev: EFA communication layer struct

 * @reset_reason: Specify what is the trigger for the reset in case of an error.

 *

 * @return - 0 on success, negative value on failure.

 start reset */

 reset clears the mmio readless address, restore it */

 reset done */

 the resolution of timeout reg is 100ms */

 Go over all the events */

		/*

		 * Do not read the rest of the completion entry before the

		 * phase bit was validated

 Get next event entry */

 SPDX-License-Identifier: GPL-2.0 OR BSD-2-Clause

/*

 * Copyright 2018-2021 Amazon.com, Inc. or its affiliates. All rights reserved.

 Device attributes is always supported */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright 2018-2021 Amazon.com, Inc. or its affiliates. All rights reserved.

/*

 * create a chunk list of physical pages dma addresses from the supplied

 * scatter gather list

 allocate a chunk list that consists of 4KB chunks */

 allocate chunk buffers: */

 fill the dma addresses of sg list pages to chunks: */

 map chunks to dma and fill chunks next ptrs */

 initialize pbl continuous mode: map pbl buffer to a dma address. */

/*

 * initialize pbl indirect mode:

 * create a chunk list out of the dma addresses of the physical pages of

 * pbl buffer.

 create a page buffer list from a mapped user memory region */

	/*

	 * it's fine if the driver does not know all request fields,

	 * we will ack input fields in our response.

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 raw_qp_set_mask_map */

/**

 * mlx5_ib_read_user_wqe_common() - Copy a WQE (or part of) from user WQ

 * to kernel buffer

 *

 * @umem: User space memory where the WQ is

 * @buffer: buffer to copy to

 * @buflen: buffer length

 * @wqe_index: index of WQE to copy from

 * @wq_offset: offset to start of WQ

 * @wq_wqe_cnt: number of WQEs in WQ

 * @wq_wqe_shift: log2 of WQE size

 * @bcnt: number of bytes to copy

 * @bytes_copied: number of bytes to copy (return value)

 *

 * Copies from start of WQE bcnt or less bytes.

 * Does not gurantee to copy the entire WQE.

 *

 * Return: zero on success, or an error code.

	/* don't copy more than requested, more than buffer length or

	 * beyond WQ end

 read the control segment first */

 read rest of WQE if it spreads over more than one stride */

 at first read as much as possible */

 we need at least control segment size to proceed */

 if we copied enough then we are done */

	/* otherwise this a wrapped around wqe

	 * so read the remaining bytes starting

	 * from  wqe_index 0

 This event is only valid for trans_qps */

 Sanity check RQ size before proceeding */

	/* this is the first blue flame register in the array of bfregs assigned

	 * to a processes. Since we do not use it for blue flame but rather

	 * regular 64 bit doorbells, we do not need a lock for maintaiing

	 * "odd/even" order

 User QP */

		/*

		 * Free only the BFREGs which are handled by the kernel.

		 * BFREGs of UARs allocated dynamically are handled by user.

 Kernel QP */

	/* We need to divide by two since each register is comprised of

	 * two buffers of identical size, namely odd and even

 Set "fast registration enabled" for all kernel QPs */

 special case when this TIR serves as steering entry without hashing */

 If none of IPV4 & IPV6 SRC/DST was set - this bit field is ignored */

 Check that only one l4 protocol is set */

 If none of TCP & UDP SRC/DST was set - this bit field is ignored */

 qpn is reserved for that QP */

	/* driver does not support atomic_size > 256B

	 * and does not know how to translate bigger sizes

 0xffffff means we ask to work with cqe version 0 */

 Special case to clean flag */

 Set default resources */

 0xffffff means we ask to work with cqe version 0 */

 Special case to clean flag */

	/* Maintain device to QPs access, needed for further handling via reset

	 * flow

	/* Maintain CQ to QPs access, needed for further handling via reset flow

 Set default resources */

 0xffffff means we ask to work with cqe version 0 */

 Special case to clean flag */

	/* Maintain device to QPs access, needed for further handling via reset

	 * flow

	/* Maintain CQ to QPs access, needed for further handling via reset flow

 0xffffff means we ask to work with cqe version 0 */

 we use IB_QP_CREATE_IPOIB_UD_LSO to indicates ipoib qp */

	/* Maintain device to QPs access, needed for further handling via reset

	 * flow

	/* Maintain CQ to QPs access, needed for further handling via reset flow

 del from lists under both locks above to protect reset flow paths */

 Kernel create_qp callers */

 Userspace create_qp callers */

	/*

	 * We don't need to see this warning, it means that kernel code

	 * missing ib_pd. Placed here to catch developer's mistakes.

		/*

			 * We don't return error if these flags were provided,

			 * and mlx5 doesn't have right capability.

		/*

		 * It is IB_QPT_DRIVER and or no subtype or

		 * wrong subtype were provided.

		/*

		 * Special case, if condition didn't meet, it won't be error,

		 * just different in-kernel flow.

 User has old rdma-core, which doesn't support ECE */

		/*

		 * We will check in check_ucmd_data() that user

		 * cleared everything after inlen.

 RSS RAW QP */

		/*

		 * These QPs don't have "reserved" field in their

		 * create_qp input struct, so their data is always valid.

	/*

	 * User provides different create_qp structures based on the

	 * flow and we need to know if he cleared memory after our

	 * struct create_qp ends.

		/*

		 * It is safe to copy response for all user create QP flows,

		 * including MLX5_IB_QPT_DCT, which doesn't need it.

		 * In that case, resp will be filled with zeros.

 index 0 means no limit */

 Remove new rate from table if failed */

 Only remove the old rate after new rate was set */

 todo implement counter_index functionality */

 Underlay port should be used - index 0 function per port */

 For the kernel flows, the resp will stay zero */

	/*

	 * If we moved a kernel QP to RESET, clean up all old CQ

	 * entries and reinitialize the QP.

/* check valid transition for driver QP types

 * for now the only QP type that this function supports is DCI

/* mlx5_ib_modify_dct: modify a DCT QP

 * valid transitions are:

 * RESET to INIT: must set access_flags, pkey_index and port

 * INIT  to RTR : must set min_rnr_timer, tclass, flow_label,

 *			   mtu, gid_index and hop_limit

 * Other transitions and attributes are illegal

		/*

		 * DCT doesn't initialize QP till modify command is executed,

		 * so we need to overwrite previously set ECE field if user

		 * provided any value except zero, which means not set/not

		 * valid.

		/*

		 * If we don't have enough space for the ECE options,

		 * simply indicate it with resp.response_length.

 Internal QP used for wc testing, with NOPs in wq */

 resp.response_length is set in ECE supported flows only */

 Return -EFAULT to the user and expect him to destroy QP. */

 Not all of output fields are applicable, make sure to zero them */

		/*

		 * In Firmware number of strides in each WQE is:

		 *   "512 * 2^single_wqe_log_num_of_strides"

		 * Values 3 to 8 are accepted as 10 to 15, 9 to 18 are

		 * accepted as 0 to 9

 Sanity check RQ size before proceeding */

 This function returns only once the drained WR was completed */

 Make sure that the CQ handler won't run if wasn't run yet */

 Wait for any scheduled/running task to be ended */

		/* Run the CQ handler - this makes sure that the drain WR will

		 * be processed if wasn't processed yet.

/*

 * Bind a qp to a counter. If @counter is NULL then bind the qp to

 * the default counter

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2013-2018, Mellanox Technologies inc.  All rights reserved.

 Sanity check SRQ size before proceeding */

 We don't support resizing SRQs yet */

 always called with interrupts disabled. */

		/* Make sure that descriptors are written before

		 * doorbell record.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2020, Mellanox Technologies inc. All rights reserved.

/* handle_post_send_edge - Check if we get to SQ edge. If yes, update to the

 * next nearby edge and get new address translation for current WQE position.

 * @sq - SQ buffer.

 * @seg: Current WQE position (16B aligned).

 * @wqe_sz: Total current WQE size [16B].

 * @cur_edge: Updated current edge.

/* memcpy_send_wqe - copy data from src to WQE and update the relevant WQ's

 * pointers. At the end @seg is aligned to 16B regardless the copied size.

 * @sq - SQ buffer.

 * @cur_edge: Updated current edge.

 * @seg: Current WQE position (16B aligned).

 * @wqe_sz: Total current WQE size [16B].

 * @src: Pointer to copy from.

 * @n: Number of bytes to copy.

		/* memcpy_send_wqe should get a 16B align address. Hence, we

		 * first copy up to the current edge and then, if needed,

		 * continue to memcpy_send_wqe.

 fail if free */

 fail if not free */

 KLMs take twice the size of MTTs */

 Valid inline section and allow BSF refresh */

 repeating block */

 Basic + Extended + Inline */

 Input domain check byte mask */

 Memory domain */

 Wire domain */

 Same block structure */

		/**

		 * Source domain doesn't contain signature information

		 * or data and protection are interleaved in memory.

		 * So need construct:

		 *                  ------------------

		 *                 |     data_klm     |

		 *                  ------------------

		 *                 |       BSF        |

		 *                  ------------------

		/**

		 * Source domain contains signature information

		 * So need construct a strided block format:

		 *               ---------------------------

		 *              |     stride_block_ctrl     |

		 *               ---------------------------

		 *              |          data_klm         |

		 *               ---------------------------

		 *              |          prot_klm         |

		 *               ---------------------------

		 *              |             BSF           |

		 *               ---------------------------

 length of the protected region, data + protection */

	/**

	 * KLM octoword size - if protection was provided

	 * then we use strided block format (3 octowords),

	 * else we use single KLM (1 octoword)

	/* Matches access in mlx5_set_umr_free_mkey().

	 * Relaxed Ordering is set implicitly in mlx5_set_umr_free_mkey() and

	 * kernel ULPs are not aware of it, so we don't set it here.

	/* We save the edge which was possibly updated during the WQE

	 * construction, into SQ's cache.

	/*

	 * SET_PSV WQEs are not signaled and solicited on error.

 UMR for data + prot registration */

 No UMR, use local_dma_lkey */

 UMR for sig MR */

 handle qp that supports ud offload */

 compiler warning */

		/* Make sure that descriptors are written before

		 * updating doorbell record and ringing the doorbell

		/* Make sure doorbell record is visible to the HCA before

		 * we hit doorbell.

		/* Make sure doorbells don't leak out of SQ spinlock

		 * and reach the HCA out of order.

		/* Make sure that descriptors are written before

		 * doorbell record.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2013-2020, Mellanox Technologies inc. All rights reserved.

 2RST & 2ERR */

 MODIFY with QPC */

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2018, Mellanox Technologies inc.  All rights reserved.

 Don't override existing ip protocol */

 Field is the last supported field */

 Currently only AES_GCM keymat is supported by the driver */

 for now support only one counters spec per flow */

/* If a flow could catch both multicast and unicast packets,

 * it won't fall into the multicast flow steering table and this rule

 * could steal other multicast packets.

	/*

	 * Currently only crypto is supported in egress, when regular egress

	 * rules would be supported, always return VALID_SPEC_NA.

 We curretly only support ipsec egress flow */

 Validate that ethertype is correct */

 currently supports only one counters data */

	/* We current only support a subset of the standard features. Only a

	 * keymat of type AES_GCM, with icv_len == 16, iv_algo == SEQ and esn

	 * (with overlap). Full offload mode isn't supported.

	/* Only the ESN value or the MLX5_ACCEL_ESP_FLAGS_ESN_STATE_OVERLAP can

	 * be modified.

		/*

		 * We only support aes_gcm by now, so we implicitly know this is

		 * the underline crypto.

 data is priority */

 Both flags are not allowed */

 Allow only DEVX object, drop as dest for FDB */

 Allow only DEVX object or QP as dest when inserting to RDMA_RX */

		/* Verify that the given DEVX object is a flow

		 * steering destination.

 Allow only flow table as dest when inserting to FDB or RDMA_RX */

	/* New users should use MLX5_IB_ATTR_FLOW_MATCHER_FT_TYPE and older

	 * users should switch to it. We leave this to not break userspace

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Contains the details of a pagefault. */

 Initiator or send message responder pagefault details. */

 Received packet size, only valid for responders. */

			/*

			 * Number of resource holding WQE, depends on type.

			/*

			 * WQE index. Refers to either the send queue or

			 * receive queue, according to event_subtype.

 RDMA responder pagefault details */

			/*

			 * Received packet size, minimal size page fault

			 * resolution required for forward progress.

/* Timeout in ms to wait for an active mmu notifier to complete when handling

	/*

	 * The locking here is pretty subtle. Ideally the implicit_children

	 * xarray would be protected by the umem_mutex, however that is not

	 * possible. Instead this uses a weaker update-then-lock pattern:

	 *

	 *    xa_store()

	 *    mutex_lock(umem_mutex)

	 *     mlx5_ib_update_xlt()

	 *    mutex_unlock(umem_mutex)

	 *    destroy lkey

	 *

	 * ie any change the xarray must be followed by the locked update_xlt

	 * before destroying.

	 *

	 * The umem_mutex provides the acquire/release semantic needed to make

	 * the xa_store() visible to a racing thread.

/*

 * This must be called after the mr has been removed from implicit_children.

 * NOTE: The MR does not necessarily have to be

 * empty here, parallel page faults could have raced with the free process and

 * added pages to it.

 Freeing a MR is a sleeping operation, so bounce to a work queue */

	/*

	 * If npages is zero then umem_odp->private may not be setup yet. This

	 * does not complete until after the first page is mapped for DMA.

	/*

	 * Iteration one - zap the HW's MTTs. The notifiers_count ensures that

	 * while we are doing the invalidation, no page fault will attempt to

	 * overwrite the same MTTs.  Concurent invalidations might race us,

	 * but they will write 0s as well, so no difference in the end result.

		/*

		 * Strive to write the MTTs in chunks, but avoid overwriting

		 * non-existing MTTs. The huristic here can be improved to

		 * estimate the cost of another UMR vs. the cost of bigger

		 * UMR.

 Count page invalidations */

	/*

	 * We are now sure that the device will not access the

	 * memory. We can safely unmap it, and mark it as dirty if

	 * needed.

	/*

	 * First refcount is owned by the xarray and second refconut

	 * is returned to the caller.

		/*

		 * Another thread beat us to creating the child mr, use

		 * theirs.

	/*

	 * If this is an implicit MR it is already invalidated so we can just

	 * delete the children mkeys.

	/*

	 * No need to check whether the MTTs really belong to this MR, since

	 * ib_umem_odp_map_dma_and_lock already checks this.

 Fault each child mr that intersects with our interval. */

	/*

	 * Any time the implicit_children are changed we must perform an

	 * update of the xlt before exiting to ensure the HW and the

	 * implicit_children remains synchronized.

	/*

	 * Notice this is not strictly ordered right, the KSM is updated after

	 * the implicit_children is updated, so a parallel page fault could

	 * see a MR that is not yet visible in the KSM.  This is similar to a

	 * parallel page fault seeing a MR that is being concurrently removed

	 * from the KSM. Both of these improbable situations are resolved

	 * safely by resuming the HW and then taking another page fault. The

	 * next pagefault handler will see the new information.

/*

 * Returns:

 *  -EFAULT: The io_virt->bcnt is not within the MR, it covers pages that are

 *           not accessible, or the MR is no longer valid.

 *  -EAGAIN/-ENOMEM: The operation should be retried

 *

 *  -EINVAL/others: General internal malfunction

 *  >0: Number of pages mapped

/*

 * Handle a single data segment in a page-fault WQE or RDMA region.

 *

 * Returns number of OS pages retrieved on success. The caller may continue to

 * the next data segment.

 * Can return the following error codes:

 * -EAGAIN to designate a temporary error. The caller will abort handling the

 *  page fault and resolve it.

 * -EFAULT when there's an error mapping the requested pages. The caller will

 *  abort the page fault handling.

		/*

		 * The user could specify a SGL with multiple lkeys and only

		 * some of them are ODP. Treat the non-ODP ones as fully

		 * faulted.

/*

 * Parse a series of data segments for page fault handling.

 *

 * @dev:  Pointer to mlx5 IB device

 * @pfault: contains page fault information.

 * @wqe: points at the first data segment in the WQE.

 * @wqe_end: points after the end of the WQE.

 * @bytes_mapped: receives the number of bytes that the function was able to

 *                map. This allows the caller to decide intelligently whether

 *                enough memory was mapped to resolve the page fault

 *                successfully (e.g. enough for the next MTU, or the entire

 *                WQE).

 * @total_wqe_bytes: receives the total data size of this WQE in bytes (minus

 *                   the committed bytes).

 * @receive_queue: receive WQE end of sg list

 *

 * Returns the number of pages loaded if positive, zero for an empty WQE, or a

 * negative error code.

 receive WQE end of sg list. */

 A zero length data segment designates a length of 2GB. */

/*

 * Parse initiator WQE. Advances the wqe pointer to point at the

 * scatter-gather list, and set wqe_end to the end of the WQE.

/*

 * Parse responder WQE and set wqe_end to the end of the WQE.

	/* The RDMA responder handler handles the page fault in two parts.

	 * First it brings the necessary pages for the current packet

	 * (and uses the pfault context), and then (after resuming the QP)

	 * prefetches more pages. The second operation cannot use the pfault

	 * context and therefore uses the dummy_pfault context allocated on

	/* For some operations, the hardware cannot tell the exact message

	 * length, and in those cases it reports zero. Use prefetch

 We're racing with an invalidation, don't prefetch */

	/* At this point, there might be a new pagefault already arriving in

	 * the eq, switch to the dummy pagefault for the rest of the

	 * processing. We're still OK with the objects being alive as the

 RDMA based event */

 WQE based event */

			/* Unsupported page faults should still be

			 * resolved by the page fault handler

/* mempool_refill() was proposed but unfortunately wasn't accepted

 * http://lkml.iu.edu/hypermail/linux/kernel/1512.1/05073.html

 * Cheap workaround.

 prefetch with write-access must be supported by the MR */

 We rely on IB/core that work is executed if we have num_sge != 0 only. */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2017-2020, Mellanox Technologies inc. All rights reserved.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2019-2020, Mellanox Technologies Ltd. All rights reserved.

/*

 * Copyright (c) 2016, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2020, Mellanox Technologies inc.  All rights reserved.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2018 Mellanox Technologies. All rights reserved.

 Only 1 ib port is the representor for both uplinks */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2020, Mellanox Technologies inc.  All rights reserved.

 The allocated entry can be used only by a DEVX context */

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * Fill in a physical address list. ib_umem_num_dma_blocks() entries will be

 * filled in the pas array.

/*

 * Compute the page shift and page_offset for mailboxes that use a quantized

 * page_offset. The granulatity of the page offset scales according to page

 * size.

	/*

	 * page size is the largest possible page size.

	 *

	 * Reduce the page_size, and thus the page_offset and quanta, until the

	 * page_offset fits into the mailbox field. Once page_size < scale this

	 * loop is guaranteed to terminate.

	/*

	 * The address is not aligned, or otherwise cannot be represented by the

	 * page_offset.

	/* Make sure that descriptors are written before

	 * updating doorbell record and ringing the doorbell

	/* Make sure doorbell record is visible to the HCA before

	 * we hit doorbell

/*

 * Copyright (c) 2016, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Call with gsi->lock locked */

 Call with gsi->lock locked */

 Call with gsi->lock locked */

 Call with gsi->lock locked */

 Undo the effect of adding the outstanding wr */

/*

 * Copyright (c) 2013-2017, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Takes a 1-based port number */

 Takes a 1-based port number */

 Takes a 1-based port number */

	/*

	 * We don't want to fail driver if debugfs failed to initialize,

	 * so we are not forwarding error to the user.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2013-2020, Mellanox Technologies inc. All rights reserved.

	/* do the pass over the counters data array to assign according to the

	 * descriptions and indexing pairs

/**

 * mlx5_ib_get_counters_id - Returns counters id to use for device+port

 * @dev:	Pointer to mlx5 IB device

 * @port_num:	Zero based port number

 *

 * mlx5_ib_get_counters_id() Returns counters set id to use for given

 * device port combination in switchdev and non switchdev mode of the

 * parent device.

 q_counters are per IB device, query the master mdev */

			/* If port is not affiliated yet, its in down state

			 * which doesn't have any counters yet, so it would be

			 * zero. So no need to read from the HCA.

 flow counters currently expose two counters packets and bytes */

 init the fields for the object */

 each counter entry have both description and index pair */

 counters already bound to at least one flow */

 counters not bound yet, must have udata passed */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2021, Mellanox Technologies inc. All rights reserved.

	/* mlx5 device sets alignment as 64*2^driver_value

	 * so normalizing is needed.

 From this point, entry will be freed by mmap_free */

	/* Allocation size must a multiple of the basic block size

	 * and a power of 2.

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 Find uncompleted WQEs belonging to that cq and return mmics ones */

	/* Make sure we read CQ entry contents after we've checked the

	 * ownership bit.

		/* We do not have to take the QP table lock here,

		 * because CQs will be locked while QPs are removed

		 * from the table.

 make sure no soft wqe's are waiting */

	/* First we need to find the current producer index, so we

	 * know where to start cleaning from.  It doesn't matter if HW

	 * adds new entries after this loop -- the QP we're worried

	 * about is already in RESET, so the new entries won't come

	 * from our QP and therefore don't need to be checked.

	/* Now sweep backwards through the CQ, removing CQ entries

	 * that match our QP by copying older entries on top of them.

		/* Make sure update of buffer contents is done before

		 * updating consumer index.

 check multiplication overflow */

 Called from atomic context */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2018, Mellanox Technologies inc.  All rights reserved.

 must be last field in this structure */

 headed in ev_file->event_list */

 first level XA value data structure */

 second XA level, Key = object id */

 second level XA value data structure */

	struct list_head file_list; /* headed in ev_file->

				     * subscribed_events_list

	struct list_head xa_list; /* headed in devx_event->unaffiliated_list or

				   * devx_obj_event->obj_sub_list

 headed in devx_object */

	struct list_head event_list; /* headed in ev_file->event_list or in

				      * temp list via subscription

 Head of events that are subscribed to this FD */

 0 means not supported */

/*

 * As the obj_id in the firmware is not globally unique the object type

 * must be considered upon checking for a valid object id.

 * For that the opcode of the creator command is encoded as part of the obj_id.

 The entry must match to one of the devx_is_obj_create_cmd */

 Pass all cmds for vhca_tunnel as general, tracking is done in FW */

/*

 *Security note:

 * The hardware protection mechanism works like this: Each device object that

 * is subject to UAR doorbells (QP/SQ/CQ) gets a UAR ID (called uar_page in

 * the device specification manual) upon its creation. Then upon doorbell,

 * hardware fetches the object context for which the doorbell was rang, and

 * validates that the UAR through which the DB was rang matches the UAR ID

 * of the object.

 * If no match the doorbell is silently ignored by the hardware. Of course,

 * the user cannot ring a doorbell on a UAR that was not mapped to it.

 * Now in devx, as the devx kernel does not manipulate the QP/SQ/CQ command

 * mailboxes (except tagging them with UID), we expose to the user its UAR

 * ID, so it can embed it in these objects in the expected specification

 * format. So the only thing the user can do is hurt itself by creating a

 * QP/SQ/CQ with a UAR ID other than his, and then in this case other users

 * may ring a doorbell on its objects.

 * The consequence of that will be that another user can schedule a QP/SQ

 * of the buggy user for execution (just insert it to the hardware schedule

 * queue or arm its CQ for event generation), no further harm is expected.

 Only white list of some general HCA commands are allowed for this method. */

 The entry must match to one of the devx_is_obj_create_cmd */

 check whether key level 1 for this obj_sub_list is empty */

		/*

		 * The pagefault_single_data_segment() does commands against

		 * the mmkey, we must wait for that to stop before freeing the

		 * mkey, as another allocation could get the same mkey #.

	/*

	 * Note that if the struct devx_async_cmd_event_file uobj begins to be

	 * destroyed it will block at mlx5_cmd_cleanup_async_ctx() until this

	 * routine returns, ensuring that it always remains valid here.

 1MB */

 Level 1 is valid for future use, no need to free */

 Level1 is valid for future use, no need to free */

 CQ completion */

	/* Protect from concurrent subscriptions to same XA entries to allow

	 * both to succeed

 May be needed upon cleanup the devx object/subscription */

	/* Once all the allocations and the XA data insertions were done we

	 * can go ahead and add all the subscriptions to the relevant lists

	 * without concern of a failure.

	/* Don't bother checking larger page sizes as offset must be zero and

	 * total DEVX umem length must be equal to total umem length.

	/* If the page_size is less than the CPU page size then we can use the

	 * offset and create a umem which is a subset of the page list.

	 * For larger page sizes we can't be sure the DMA  list reflects the

	 * VA so we must ensure that the umem extent is exactly equal to the

	 * page list. Reduce the page size until one of these cases is true.

	/*

	 * If the user does not pass in pgsz_bitmap then the user promises not

	 * to use umem_offset!=0 in any commands that allocate on top of the

	 * umem.

	 *

	 * If the user wants to use a umem_offset then it must pass in

	 * pgsz_bitmap which guides the maximum page size and thus maximum

	 * object alignment inside the umem. See the PRM.

	 *

	 * Users are not allowed to use IOVA here, mkeys are not supported on

	 * umem.

 Explicit filtering to kernel events which may occur frequently */

 This points to an application issue, not a kernel concern */

 free the pending events allocation */

 delete the subscriptions which are related to this FD */

 subscription may not be used by the read API any more */

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 * Copyright (c) 2020, Intel Corporation. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

/*

 * We can't use an array for xlt_emergency_page because dma_map_single doesn't

 * work on kernel modules memory

 If we are doing fill_to_high_water then keep going. */

 Asynchronously schedule new MRs to be populated in the cache. */

 Synchronously create a MR in the cache */

	/*

	 * Target is the new value of total_mrs the user requests, however we

	 * cannot free MRs that are in use. Compute the target value for

	 * available_mrs.

	/*

	 * Upon set we immediately fill the cache to high water mark implied by

	 * the limit.

/*

 * Check if the bucket is outside the high/low water mark and schedule an async

 * update. The cache refill has hysteresis, once the low water mark is hit it is

 * refilled up to the high mark.

		/*

		 * Once we start populating due to hitting a low water mark

		 * continue until we pass the high water mark.

 Queue deletion of excess entries */

			/*

			 * EAGAIN only happens if pending is positive, so we

			 * will be rescheduled from reg_mr_callback(). The only

			 * failure path here is ENOMEM.

		/*

		 * The remove_cache_mr() logic is performed as garbage

		 * collection task. Such task is intended to be run when no

		 * other active processes are running.

		 *

		 * The need_resched() will return TRUE if there are user tasks

		 * to be activated in near future.

		 *

		 * In such case, we don't execute remove_cache_mr() and postpone

		 * the garbage collection work to try to run in next cycle, in

		 * order to free CPU resources to other tasks.

 Allocate a special entry from the cache */

 Matches access in alloc_cache_mr() */

 Return a MR already available in the cache */

	/*

	 * The alignment of iova has already been checked upon entering

	 * UVERBS_METHOD_REG_DMABUF_MR

	/*

	 * Matches access in alloc_cache_mr(). If the MR can't come from the

	 * cache then synchronously create an uncached one.

		/*

		 * The above already tried to do the same stuff as reg_create(),

		 * no reason to try it again.

/*

 * Allocate a temporary buffer to hold the per-page information to transfer to

 * HW. For efficiency this should be as large as it can be, but buffer

 * allocation failure is not allowed, so try smaller sizes.

	/*

	 * MLX5_IB_UPD_XLT_ATOMIC doesn't signal an atomic context just that the

	 * allocation can't trigger any kind of reclaim.

	/*

	 * If the system already has a suitable high order page then just use

	 * that, but don't try hard to create one. This max is about 1M, so a

	 * free x86 huge page will satisfy it.

/*

 * Create a MLX5_IB_SEND_UMR_UPDATE_XLT work request and XLT buffer ready for

 * submission.

	/* UMR copies MTTs in units of MLX5_UMR_MTT_ALIGNMENT bytes,

	 * so we need to align the offset and length accordingly

/*

 * Send the DMA list to the HW for a normal MR using UMR.

 * Dmabuf MR is handled in a similar way, except that the MLX5_IB_UPD_XLT_ZAP

 * flag may be used.

/*

 * If ibmr is NULL it will be allocated by reg_create.

 * Else, the given ibmr will be used.

	/* The pg_access bit allows setting the access flags

		/*

		 * If the MR was created with reg_create then it will be

		 * configured properly but left disabled. It is safe to go ahead

		 * and configure it again via UMR while enabling it.

 ODP requires xlt update via umr to work. */

 dmabuf requires xlt update via umr to work. */

/**

 * revoke_mr - Fence all DMA on the MR

 * @mr: The MR to fence

 *

 * Upon return the NIC will not be doing any DMA to the pages under the MR,

 * and any DMA in progress will be completed. Failure of this function

 * indicates the HW has failed catastrophically.

/*

 * True if the change in access flags can be done via UMR, only some access

 * flags can be updated.

 We only track the allocated sizes of MRs from the cache */

	/*

	 * To keep everything simple the MR is revoked before we start to mess

	 * with it. This ensure the change is atomic relative to any use of the

	 * MR.

		/*

		 * The MR is revoked at this point so there is no issue to free

		 * new_umem.

 Fast path for PD/access change */

 DM or ODP MR's don't have a normal umem so we can't re-use it */

		/*

		 * Only one active MR can refer to a umem at one time, revoke

		 * the old MR before assigning the umem to the new one.

	/*

	 * DM doesn't have a PAS list so we can't re-use it, odp/dmabuf does

	 * but the logic around releasing the umem is different

 Fast path for PAS change */

	/*

	 * Everything else has no state we can preserve, just create a new MR

	 * from scratch

	/*

	 * Any async use of the mr must hold the refcount, once the refcount

	 * goes to zero no other thread, such as ODP page faults, prefetch, any

	 * UMR activity, etc can touch the mkey. Thus it is safe to destroy it.

 Stop DMA */

 This is only used from the kernel, so setting the PD is OK. */

 create mem & wire PSVs */

 Next UMR, Arm SIGERR */

 Set bsf descriptors for mkey */

		/*

		 * pagefault_single_data_segment() may be accessing mmw

		 * if the user bound an ODP MR to this MW.

		/*

		 * PI address for the HW is the offset of the metadata address

		 * relative to the first data page address.

		 * It equals to first data page address + size of data pages +

		 * metadata offset at the first metadata page

		/*

		 * In order to use one MTT MR for data and metadata, we register

		 * also the gaps between the end of the data and the start of

		 * the metadata (the sig MR will verify that the HW will access

		 * to right addresses). This mapping is safe because we use

		 * internal mkey for the registration.

 This is zero-based memory region */

	/*

	 * As a performance optimization, if possible, there is no need to

	 * perform UMR operation to register the data/metadata buffers.

	 * First try to map the sg lists to PA descriptors with local_dma_lkey.

	 * Fallback to UMR only in case of a failure.

	/*

	 * As a performance optimization, if possible, there is no need to map

	 * the sg lists to KLM descriptors. First try to map the sg lists to MTT

	 * descriptors and fallback to KLM only in case of a failure.

	 * It's more efficient for the HW to work with MTT descriptors

	 * (especially in high load).

	 * Use KLM (indirect access) only if it's mandatory.

 This is zero-based memory region */

/*

 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

	/* Key check traps can't be generated unless we have in_wc to

	 * tell us where to send the trap.

	/* Traffic counters will be reported in

	 * their 64bit form via ib_pma_portcounters_ext by default.

		/* Fail to get the native port, likely due to 2nd port is still

		 * unaffiliated. In such case default to 1st port and attached

		 * PF device.

 Declaring support of extended counters */

		/* Don't process SMInfo queries -- the SMA can't handle them.

 set return bit in status of directed route responses */

 no response for trap repress */

 props being zeroed by the caller, avoid zeroing it here */

 Check if extended speeds (EDR/FDR/...) are supported */

 FDR */

 EDR */

 If reported active speed is QDR, check if is FDR-10 */

 Checking LinkSpeedActive for FDR-10 */

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2013-2018, Mellanox Technologies inc.  All rights reserved.

 Delete entry, but leave index occupied */

		/*

		 * We don't need to check returned result for an error,

		 * because  we are storing in pre-allocated space xarray

		 * entry and it can't fail at this stage.

 SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB

/*

 * Copyright (c) 2013-2020, Mellanox Technologies inc. All rights reserved.

 * Copyright (c) 2020, Intel Corporation. All rights reserved.

/*

 * This mutex should be held when accessing either of the above lists

 Should already be registered during the load */

 In case of reps, ib device goes away before the netdevs */

	/* Ensure ndev does not disappear before we invoke dev_hold()

		/* If it's the master no need to refcount, it'll exist

		 * as long as the ib_dev exists.

		/* This means the port isn't affiliated yet. Get the

		 * info for the master port instead.

	/* Possible bad flows are checked before filling out props so in case

	 * of an error it will still be zeroed out.

	 * Use native port in case of reps

 If this is a stub query for an unaffiliated port stop here */

	/* Check if HW supports 8 bytes standard atomic operations and capable

	 * of host endianness respond

 We support 'Gappy' memory registration too */

 IB_WR_REG_MR always requires changing the entity size with UMR */

 At this stage no support for signature handover */

 Legacy bit to support old userspace libraries */

 Legacy bit to support old userspace libraries */

			/* ODP for kernel QPs is not implemented for receive

			 * WQEs and SRQ WQEs

 props being zeroed by the caller, avoid zeroing it here */

			/* If the port isn't affiliated yet query the master.

			 * The master and slave will have the same values.

	/* Default special Pkey for representor device port as per the

	 * IB specification 1.3 section 10.9.1.2.

		/* The port isn't affiliated yet, get the PKey from the master

		 * port. For RoCE the PKey tables will be the same.

	/*

	 * If possible, pass node desc to FW, so it can generate

	 * a 144 trap.  If cmd fails, just ignore.

	/* CM layer calls ib_modify_port() regardless of the link layer. For

	 * Ethernet ports, qkey violation and Port capabilities are meaningless.

 Large page with non 4k uar support might limit the dynamic size */

 This holds the required static allocation asked by the user */

 MLX5_USER_ALLOC_UCONTEXT_FLOW_ACTION_FLAGS_ESP_AES_GCM_FULL_OFFLOAD is currently always 0 */

	/*

	 * We don't want to expose information from the PCI bar that is located

	 * after 4096 bytes, so if the arch only supports larger pages, let's

	 * pretend we don't support reading the HCA's core clock. This is also

	 * forced by mmap function.

 updates req->total_num_bfregs */

 Index resides in an extra byte to enable larger values than 255 */

 For MLX5_IB_MMAP_REGULAR_PAGE do the best effort to get WC */

		/* Fail if uar already allocated, first bfreg index of each

		 * page holds its count.

 Don't expose to user-space information it shouldn't have */

		/*

		 * We got this event before device was fully configured

		 * and MAD registration code wasn't called/finished yet.

 Go over qp list reside on that ibdev, sync with create/destroy qp.*/

 no handling is needed for SRQ */

	/*At that point all inflight post send were put to be executed as of we

	 * lock/unlock above locks Now need to arm all involved CQs.

 do nothing */

		/* In RoCE, port up/down events are handled in

		 * mlx5_netdev_event().

	/*

	 * Make sure no change P_Key work items are still executing.

	 *

	 * At this stage, the mlx5_ib_event should be unregistered

	 * and it ensures that no new works are added.

	/* Log an error, still needed to cleanup the pointers and add

	 * it back to the list.

 build a stub multiport info struct for the native port. */

 Destroy the native port stub */

 not supported for now */;

 Register only for native ports */

 Number of stages to cleanup */

 Clean up stages which were initialized */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, Linaro Limited

/**

 * struct segdist_code - Segment Distributions code from

 *	Table 20 of SLIMbus Specs Version 2.0

 *

 * @ratem: Channel Rate Multipler(Segments per Superframe)

 * @seg_interval: Number of slots between the first Slot of Segment

 *		and the first slot of the next  consecutive Segment.

 * @segdist_code: Segment Distribution Code SD[11:0]

 * @seg_offset_mask: Segment offset mask in SD[11:0]

 * @segdist_codes: List of all possible Segmet Distribution codes.

/*

 * Presence Rate table for all Natural Frequencies

 * The Presence rate of a constant bitrate stream is mean flow rate of the

 * stream expressed in occupied Segments of that Data Channel per second.

 * Table 66 from SLIMbus 2.0 Specs

 *

 * Index of the table corresponds to Presence rate code for the respective rate

 * in the table.

 Not Indicated */

 Reserved */

/**

 * slim_stream_allocate() - Allocate a new SLIMbus Stream

 * @dev:Slim device to be associated with

 * @name: name of the stream

 *

 * This is very first call for SLIMbus streaming, this API will allocate

 * a new SLIMbus stream and return a valid stream runtime pointer for client

 * to use it in subsequent stream apis. state of stream is set to ALLOCATED

 *

 * Return: valid pointer on success and error code on failure.

 * From ASoC DPCM framework, this state is linked to startup() operation.

/**

 * slim_stream_prepare() - Prepare a SLIMbus Stream

 *

 * @rt: instance of slim stream runtime to configure

 * @cfg: new configuration for the stream

 *

 * This API will configure SLIMbus stream with config parameters from cfg.

 * return zero on success and error code on failure. From ASoC DPCM framework,

 * this state is linked to hw_params() operation.

		/*

		 * data rate not exactly multiple of super frame,

		 * use PUSH/PULL protocol

 Frequency Locked for ISO Protocol */

/**

 * slim_stream_enable() - Enable a prepared SLIMbus Stream

 *

 * @stream: instance of slim stream runtime to enable

 *

 * This API will enable all the ports and channels associated with

 * SLIMbus stream

 *

 * Return: zero on success and error code on failure. From ASoC DPCM framework,

 * this state is linked to trigger() start operation.

 define channels first before activating them */

/**

 * slim_stream_disable() - Disable a SLIMbus Stream

 *

 * @stream: instance of slim stream runtime to disable

 *

 * This API will disable all the ports and channels associated with

 * SLIMbus stream

 *

 * Return: zero on success and error code on failure. From ASoC DPCM framework,

 * this state is linked to trigger() pause operation.

/**

 * slim_stream_unprepare() - Un-prepare a SLIMbus Stream

 *

 * @stream: instance of slim stream runtime to unprepare

 *

 * This API will un allocate all the ports and channels associated with

 * SLIMbus stream

 *

 * Return: zero on success and error code on failure. From ASoC DPCM framework,

 * this state is linked to trigger() stop operation.

/**

 * slim_stream_free() - Free a SLIMbus Stream

 *

 * @stream: instance of slim stream runtime to free

 *

 * This API will un allocate all the memory associated with

 * slim stream runtime, user is not allowed to make an dereference

 * to stream after this call.

 *

 * Return: zero on success and error code on failure. From ASoC DPCM framework,

 * this state is linked to shutdown() operation.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2011-2017, The Linux Foundation

/**

 * slim_ctrl_clk_pause() - Called by slimbus controller to enter/exit

 *			   'clock pause'

 * @ctrl: controller requesting bus to be paused or woken up

 * @wakeup: Wakeup this controller from clock pause.

 * @restart: Restart time value per spec used for clock pause. This value

 *	isn't used when controller is to be woken up.

 *

 * Slimbus specification needs this sequence to turn-off clocks for the bus.

 * The sequence involves sending 3 broadcast messages (reconfiguration

 * sequence) to inform all devices on the bus.

 * To exit clock-pause, controller typically wakes up active framer device.

 * This API executes clock pause reconfiguration sequence if wakeup is false.

 * If wakeup is true, controller's wakeup is called.

 * For entering clock-pause, -EBUSY is returned if a message txn in pending.

		/*

		 * Fine-tune calculation based on clock gear,

		 * message-bandwidth after bandwidth management

		/*

		 * Slimbus framework will call controller wakeup

		 * Controller should make sure that it sets active framer

		 * out of clock pause

 already paused */

 Pending response for a message */

 clock pause sequence */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2011-2017, The Linux Foundation. All rights reserved.

 Copyright (c) 2018, Linaro Limited

 NGD (Non-ported Generic Device) registers */

 Slimbus QMI service */

 QMI response timeout of 500ms */

 User defined commands */

 Per spec.max 40 bytes per received message */

 To force a 32 bit signed enum. Do not change or use*/

 To force a 32 bit signed enum. Do not change or use*/

 Check the response */

 Check the response */

 Instance is 0 based */

 Mode indicates the role of the ADSP */

 Add descriptor back to the queue */

 HW expects length field to be excluded */

 Data channel segment interval not multiple of 3 */

 By default enable message queues */

 Enable NGD if it's not already enabled*/

 Version info in 16 MSbits */

		/*

		 * external MDM restart case where ADSP itself was active framer

		 * For example, modem restarted when playback was active

 Did SSR cause this power up failure */

 controller state should be in sync with framework state */

 Make sure qmi service is up before continuing */

 Make sure the last dma xfer is finished */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2011-2017, The Linux Foundation

/**

 * slim_msg_response() - Deliver Message response received from a device to the

 *			framework.

 *

 * @ctrl: Controller handle

 * @reply: Reply received from the device

 * @len: Length of the reply

 * @tid: Transaction ID received with which framework can associate reply.

 *

 * Called by controller to inform framework about the response received.

 * This helps in making the API asynchronous, and controller-driver doesn't need

 * to manage 1 more table other than the one managed by framework mapping TID

 * with buffers

 Remove runtime-pm vote now that response was received for TID txn */

/**

 * slim_alloc_txn_tid() - Allocate a tid to txn

 *

 * @ctrl: Controller handle

 * @txn: transaction to be allocated with tid.

 *

 * Return: zero on success with valid txn->tid and error code on failures.

/**

 * slim_free_txn_tid() - Freee tid of txn

 *

 * @ctrl: Controller handle

 * @txn: transaction whose tid should be freed

/**

 * slim_do_transfer() - Process a SLIMbus-messaging transaction

 *

 * @ctrl: Controller handle

 * @txn: Transaction to be sent over SLIMbus

 *

 * Called by controller to transmit messaging transactions not dealing with

 * Interface/Value elements. (e.g. transmittting a message to assign logical

 * address to a slave device

 *

 * Return: -ETIMEDOUT: If transmission of this message timed out

 *	(e.g. due to bus lines not being clocked or driven by controller)

	/*

	 * do not vote for runtime-PM if the transactions are part of clock

	 * pause sequence

 Initialize tid to invalid value */

		/*

		 * remove runtime-pm vote if this was TX only, or

		 * if there was error during this transaction

/**

 * slim_xfer_msg() - Transfer a value info message on slim device

 *

 * @sbdev: slim device to which this msg has to be transfered

 * @msg: value info message pointer

 * @mc: message code of the message

 *

 * Called by drivers which want to transfer a vlaue or info elements.

 *

 * Return: -ETIMEDOUT: If transmission of this message timed out

/**

 * slim_read() - Read SLIMbus value element

 *

 * @sdev: client handle.

 * @addr:  address of value element to read.

 * @count: number of bytes to read. Maximum bytes allowed are 16.

 * @val: will return what the value element value was

 *

 * Return: -EINVAL for Invalid parameters, -ETIMEDOUT If transmission of

 * this message timed out (e.g. due to bus lines not being clocked

 * or driven by controller)

/**

 * slim_readb() - Read byte from SLIMbus value element

 *

 * @sdev: client handle.

 * @addr:  address in the value element to read.

 *

 * Return: byte value of value element.

/**

 * slim_write() - Write SLIMbus value element

 *

 * @sdev: client handle.

 * @addr:  address in the value element to write.

 * @count: number of bytes to write. Maximum bytes allowed are 16.

 * @val: value to write to value element

 *

 * Return: -EINVAL for Invalid parameters, -ETIMEDOUT If transmission of

 * this message timed out (e.g. due to bus lines not being clocked

 * or driven by controller)

/**

 * slim_writeb() - Write byte to SLIMbus value element

 *

 * @sdev: client handle.

 * @addr:  address of value element to write.

 * @value: value to write to value element

 *

 * Return: -EINVAL for Invalid parameters, -ETIMEDOUT If transmission of

 * this message timed out (e.g. due to bus lines not being clocked

 * or driven by controller)

 *

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2011-2017, The Linux Foundation

 Attempt an OF style match first */

 try getting the logical address after probe */

/*

 * __slim_driver_register() - Client driver registration with SLIMbus

 *

 * @drv:Client driver to be associated with client-device.

 * @owner: owning module/driver

 *

 * This API will register the client driver with the SLIMbus

 * It is called from the driver's module-init function.

 ID table and probe are mandatory */

/*

 * slim_driver_unregister() - Undo effect of slim_driver_register

 *

 * @drv: Client driver to be unregistered

/*

 * slim_register_controller() - Controller bring-up and registration.

 *

 * @ctrl: Controller to be registered.

 *

 * A controller is registered with the framework using this API.

 * If devices on a controller were registered before controller,

 * this will make sure that they get probed when controller is up

 slim_remove_device: Remove the effect of slim_add_device() */

/**

 * slim_unregister_controller() - Controller tear-down.

 *

 * @ctrl: Controller to tear-down.

 Remove all clients */

/**

 * slim_report_absent() - Controller calls this function when a device

 *	reports absent, OR when the device cannot be communicated with

 *

 * @sbdev: Device that cannot be reached, or sent report absent

 invalidate logical addresses */

/**

 * slim_get_device() - get handle to a device.

 *

 * @ctrl: Controller on which this device will be added/queried

 * @e_addr: Enumeration address of the device to be queried

 *

 * Return: pointer to a device if it has already reported. Creates a new

 * device and returns pointer to it if the device has not yet enumerated.

/**

 * of_slim_get_device() - get handle to a device using dt node.

 *

 * @ctrl: Controller on which this device will be added/queried

 * @np: node pointer to device

 *

 * Return: pointer to a device if it has already reported. Creates a new

 * device and returns pointer to it if the device has not yet enumerated.

/**

 * slim_device_report_present() - Report enumerated device.

 *

 * @ctrl: Controller with which device is enumerated.

 * @e_addr: Enumeration address of the device.

 * @laddr: Return logical address (if valid flag is false)

 *

 * Called by controller in response to REPORT_PRESENT. Framework will assign

 * a logical address to this enumeration address.

 * Function returns -EXFULL to indicate that all logical addresses are already

 * taken.

/**

 * slim_get_logical_addr() - get/allocate logical address of a SLIMbus device.

 *

 * @sbdev: client handle requesting the address.

 *

 * Return: zero if a logical address is valid or a new logical address

 * has been assigned. error code in case of error.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2011-2017, The Linux Foundation

 Manager registers */

 Framer registers */

 Interface registers */

 Interrupt status bits */

 Framer config register settings */

 MAX message size over control channel */

 V2 Component registers */

 V1 Component registers */

 Resource group info for manager, and non-ported generic device-components */

 Ensure Oder of subsequent writes */

	/*

	 * this message cannot be handled by ISR, so

	 * let work-queue handle it

 Make sure framer wakeup write goes through before ISR fires */

	/*

	 * HW Workaround: Currently, slave is reporting lost-sync messages

	 * after SLIMbus comes out of clock pause.

	 * Transaction with slave fail before slave reports that message

	 * Give some time for that report to come

	 * SLIMbus wakes up in clock gear 10 at 24.576MHz. With each superframe

	 * being 250 usecs, we wait for 5-10 superframes here to ensure

	 * we get the message

 HW expects length field to be excluded */

 spin till buffer is made available */

 SLEW RATE register for this SLIMbus */

 Make sure SLIMbus-slew rate enabling goes through */

 Register with framework before enabling frame, clock */

 Version info in 16 MSbits */

 Component register initialization */

 Framer register initialization */

/*

 * If PM_RUNTIME is not defined, these 2 functions become helper

 * functions to be called from system suspend/resume.

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * eisa.c - provide support for EISA adapters in PA-RISC machines

 *

 * Copyright (c) 2001 Matthew Wilcox for Hewlett Packard

 * Copyright (c) 2001 Daniel Engstrom <5116@telia.com>

 *

 * There are two distinct EISA adapters.  Mongoose is found in machines

 * before the 712; then the Wax ASIC is used.  To complicate matters, the

 * Wax ASIC also includes a PS/2 and RS-232 controller, but those are

 * dealt with elsewhere; this file is concerned only with the EISA portions

 * of Wax.

 *

 * HINT:

 * -----

 * To allow an ISA card to work properly in the EISA slot you need to

 * set an edge trigger level. This may be done on the palo command line

 * by adding the kernel parameter "eisa_irq_edge=n,n2,[...]]", with

 * n and n2 as the irq levels you want to use.

 *

 * Example: "eisa_irq_edge=10,11" allows ISA cards to operate at

 * irq levels 10 and 11.

/* We can only have one EISA adapter in the system because neither

 * implementation can be flexed.

 Port ops */

 We call these directly without PCI.  See asm/io.h. */

 Interrupt handling */

 cached interrupt mask registers */

/* the trig level can be set with the

 * eisa_irq_edge=n,n,n commandline parameter

 * We should really read this from the EEPROM

 * in the furure.

 irq 13,8,2,1,0 must be edge */

 default to edge triggered */

 called by free irq */

 just mask for now */

 called by request irq */

 EISA supports 16 irqs */

 read IRR command */

 read ISR command */

 mask irq and write eoi */

 'Specific EOI' to slave */

 'Specific EOI' to master-IRQ2 */

 'Specific EOI' to master */

 unmask */

 mask during init */

 mask during init */

 master pic */

 ICW1 */

 ICW2 */

 ICW3 */

 ICW4 */

 OCW2 */

 slave pic */

 ICW1 */

 ICW2 */

 ICW3 */

 ICW4 */

 OCW2 */

 OCW1 */

 OCW1 */

 setup trig level */

 Set all irq's to edge  */

 Device initialisation */

 Reserve IRQ2 */

 newer firmware hand out the eeprom address */

 old firmware, need to figure out the box */

 FIXME : Don't enumerate the bus twice. */

 wild guess */

 Mongoose */

 Wax EISA */

 set the corresponding bit */

 set the corresponding bit */

 clear the corresponding bit */

 set the corresponding bit */

 clear the corresponding bit */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *    Chassis LCD/LED driver for HP-PARISC workstations

 *

 *      (c) Copyright 2000 Red Hat Software

 *      (c) Copyright 2000 Helge Deller <hdeller@redhat.com>

 *      (c) Copyright 2001-2009 Helge Deller <deller@gmx.de>

 *      (c) Copyright 2001 Randolph Chung <tausq@debian.org>

 *

 * TODO:

 *	- speed-up calculations with inlined assembler

 *	- interface to write to second row of LCD from /proc (if technically possible)

 *

 * Changes:

 *      - Audit copy_from_user in led_proc_write.

 *                                Daniele Bellucci <bellucda@tiscali.it>

 *	- Switch from using a tasklet to a work queue, so the led_LCD_driver

 *	  	can sleep.

 *	  			  David Pye <dmp@davidmpye.dyndns.org>

 for offsetof() */

 HZ */

/* The control of the LEDs and LCDs on PARISC-machines have to be done 

   completely in software. The necessary calculations are done in a work queue

   task which is scheduled regularly, and since the calculations may consume a 

   relatively large amount of CPU time, some of the calculations can be 

 LED state from most recent update */

 KittyHawk doesn't support LED on its LCD */

 stores the command byte      */

 value for turning LED on     */

 value for turning LED off    */

 Structure returned by PDC_RETURN_CHASSIS_INFO */

/* NOTE: we use unsigned long:16 two times, since the following member 

 DISPLAY_MODEL_XXXX */

 width of the LCD in chars (DISPLAY_MODEL_LCD only) */

 ptr to LCD cmd-register & data ptr for LED */

 ptr to LCD data-register (LCD only) */

 delay in uS after cmd-write (LCD only) */

 command #1 for writing LCD string (LCD only) */

 command #2 for writing LCD string (LCD only) */

 0 = no activity (LCD only) */

 LCD_CMD and LCD_DATA for KittyHawk machines */

 64bit-ready */

/* lcd_info is pre-initialized to the values needed to program KittyHawk LCD's 

 direct access to some of the lcd_info variables */

 LASI & ASP only */

 The workqueue must be created at init-time */

 Display the default text now */

 KittyHawk has no LED support on its LCD */

 Create the work queue and queue the LED task */

 ptr to LCD/LED-specific function */

 LED */

 LCD */

/*

   ** 

   ** led_ASP_driver()

   ** 

 data to shift (0:on 1:off) */

 strobe to clock data */

/*

   ** 

   ** led_LASI_driver()

   ** 

/*

   ** 

   ** led_LCD_driver()

   **   

 Convert min_cmd_delay to milliseconds */

/*

   ** 

   ** led_get_net_activity()

   ** 

   ** calculate if there was TX- or RX-throughput on the network interfaces

   ** (analog to dev_get_info() from net/core/dev.c)

   **   

 we are running as a workqueue task, so we can use an RCU lookup */

/*

   ** 

   ** led_get_diskio_activity()

   ** 

   ** calculate if there was disk-io in the system

   **   

	/* Just use a very simple calculation here. Do not care about overflow,

/*

   ** led_work_func()

   ** 

   ** manages when and which chassis LCD/LED gets updated



    TODO:

    - display load average (older machines like 715/64 have 4 "free" LED's for that)

    - optimizations

 counter in range 0..HZ */

 stores current value of the LEDs */

 exit if not initialized */

 increment the heartbeat timekeeper */

		/* flash heartbeat-LED like a real heart

		 * (2 x short then a long delay)

 blink LEDs if we got an Oops (HPMC) */

			/* newer machines don't have loadavg. LEDs, so we

 old machines: blink loadavg. LEDs twice per second */

 Update the LCD/LEDs */

/*

   ** led_halt()

   ** 

   ** called by the reboot notifier chain at shutdown and stops all

   ** LED/LCD activities.

   ** 

 Cancel the work item and delete the queue */

 turn all LEDs ON */

/*

   ** register_led_driver()

   ** 

   ** registers an external LED or LCD for usage by this driver.

   ** currently only LCD-, LASI- and ASP-style LCD/LED's are supported.

   ** 

 store the values */

 Skip to register LED in QEMU */

	/* mark the LCD/LED driver now as initialized and 

 Ensure the work is queued */

/*

   ** register_led_regions()

   ** 

   ** register_led_regions() registers the LCD/LED regions for /procfs.

   ** At bootup - where the initialisation of the LCD/LED normally happens - 

   ** not all internal structures of request_region() are properly set up,

   ** so that we delay the led-registration until after busdevices_init() 

   ** has been executed.

   **

/*

   ** 

   ** lcd_print()

   ** 

   ** Displays the given string on the LCD-Display of newer machines.

   ** lcd_print() disables/enables the timer-based led work queue to

   ** avoid a race condition while writing the CMD/DATA register pair.

   **

 temporarily disable the led work task */

 copy display string to buffer for procfs */

 Set LCD Cursor to 1st character */

 Print the string */

 re-queue the work */

/*

   ** led_init()

   ** 

   ** led_init() is called very early in the bootup-process from setup.c 

   ** and asks the PDC for an usable chassis LCD or LED.

   ** If the PDC doesn't return any info, then the LED

   ** is detected by lasi.c or asp.c and registered with the

   ** above functions lasi_led_init() or asp_led_init().

   ** KittyHawk machines have often a buggy PDC, so that

   ** we explicitly check for those machines here.

 Work around the buggy PDC of KittyHawk-machines */

 KittyHawk DC2-100 (K100) */

 KittyHawk DC3-120 (K210) */

 KittyHawk DC3 100 (K400) */

 KittyHawk DC3 120 (K410) */

 KittyHawk DC2 100 (K200) */

 use the preinitialized values of lcd_info */

 initialize the struct, so that we can check for valid return values */

 check the results. Some machines have a buggy PDC */

 LCD display */

 no LED or LCD available */

 Lasi style 8 bit LED display */

 switch() */

 register the LCD/LED driver */

 if() */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

** ccio-dma.c:

**	DMA management routines for first generation cache-coherent machines.

**	Program U2/Uturn in "Virtual Mode" and use the I/O MMU.

**

**	(c) Copyright 2000 Grant Grundler

**	(c) Copyright 2000 Ryan Bradetich

**	(c) Copyright 2000 Hewlett-Packard Company

**

**

**

**  "Real Mode" operation refers to U2/Uturn chip operation.

**  U2/Uturn were designed to perform coherency checks w/o using

**  the I/O MMU - basically what x86 does.

**

**  Philipp Rumpf has a "Real Mode" driver for PCX-W machines at:

**      CVSROOT=:pserver:anonymous@198.186.203.37:/cvsroot/linux-parisc

**      cvs -z3 co linux/arch/parisc/kernel/dma-rm.c

**

**  I've rewritten his code to work under TPG's tree. See ccio-rm-dma.c.

**

**  Drawbacks of using Real Mode are:

**	o outbound DMA is slower - U2 won't prefetch data (GSC+ XQL signal).

**      o Inbound DMA less efficient - U2 can't use DMA_FAST attribute.

**	o Ability to do scatter/gather in HW is lost.

**	o Doesn't work under PCX-U/U+ machines since they didn't follow

**        the coherency design originally worked out. Only PCX-W does.

 for L1_CACHE_BYTES */

 for register_module() */

/* 

** Choose "ccio" since that's what HP-UX calls it.

** Make it easier for folks to migrate from one to the other :^)

 depends on proc fs support. But costs CPU performance. */

 for proc_runway_root */

 IO_CONTROL to turn on CCIO        */

 IO_COMMAND for I/O TLB Writes     */

 IO_COMMAND to Purge I/O TLB entry */

 Runway Supervisory Set */

 Offset 12 */

 Offset 13 */

 Offset 14 */

 Runway Auxiliary Register Set */

 Offset  0 */

 Offset  1 */

 Offset  2 */

 Offset  3 */

 Offset  4 */

 Offset  5 */

 Offset  7 */

 Offset  8 */

 Offset  9 */

 Offset 11 */

 Offset 14 */

 Offset 15 */

/*

** IOA Registers

** -------------

**

** Runway IO_CONTROL Register (+0x38)

** 

** The Runway IO_CONTROL register controls the forwarding of transactions.

**

** | 0  ...  13  |  14 15 | 16 ... 21 | 22 | 23 24 |  25 ... 31 |

** |    HV       |   TLB  |  reserved | HV | mode  |  reserved  |

**

** o mode field indicates the address translation of transactions

**   forwarded from Runway to GSC+:

**       Mode Name     Value        Definition

**       Off (default)   0          Opaque to matching addresses.

**       Include         1          Transparent for matching addresses.

**       Peek            3          Map matching addresses.

**

**       + "Off" mode: Runway transactions which match the I/O range

**         specified by the IO_IO_LOW/IO_IO_HIGH registers will be ignored.

**       + "Include" mode: all addresses within the I/O range specified

**         by the IO_IO_LOW and IO_IO_HIGH registers are transparently

**         forwarded. This is the I/O Adapter's normal operating mode.

**       + "Peek" mode: used during system configuration to initialize the

**         GSC+ bus. Runway Write_Shorts in the address range specified by

**         IO_IO_LOW and IO_IO_HIGH are forwarded through the I/O Adapter

**         *AND* the GSC+ address is remapped to the Broadcast Physical

**         Address space by setting the 14 high order address bits of the

**         32 bit GSC+ address to ones.

**

** o TLB field affects transactions which are forwarded from GSC+ to Runway.

**   "Real" mode is the poweron default.

** 

**   TLB Mode  Value  Description

**   Real        0    No TLB translation. Address is directly mapped and the

**                    virtual address is composed of selected physical bits.

**   Error       1    Software fills the TLB manually.

**   Normal      2    IOA fetches IO TLB misses from IO PDIR (in host memory).

**

**

** IO_IO_LOW_HV	  +0x60 (HV dependent)

** IO_IO_HIGH_HV  +0x64 (HV dependent)

** IO_IO_LOW      +0x78	(Architected register)

** IO_IO_HIGH     +0x7c	(Architected register)

**

** IO_IO_LOW and IO_IO_HIGH set the lower and upper bounds of the

** I/O Adapter address space, respectively.

**

** 0  ... 7 | 8 ... 15 |  16   ...   31 |

** 11111111 | 11111111 |      address   |

**

** Each LOW/HIGH pair describes a disjoint address space region.

** (2 per GSC+ port). Each incoming Runway transaction address is compared

** with both sets of LOW/HIGH registers. If the address is in the range

** greater than or equal to IO_IO_LOW and less than IO_IO_HIGH the transaction

** for forwarded to the respective GSC+ bus.

** Specify IO_IO_LOW equal to or greater than IO_IO_HIGH to avoid specifying

** an address space region.

**

** In order for a Runway address to reside within GSC+ extended address space:

**	Runway Address [0:7]    must identically compare to 8'b11111111

**	Runway Address [8:11]   must be equal to IO_IO_LOW(_HV)[16:19]

**	Runway Address [12:23]  must be greater than or equal to

**	           IO_IO_LOW(_HV)[20:31] and less than IO_IO_HIGH(_HV)[20:31].

**	Runway Address [24:39]  is not used in the comparison.

**

** When the Runway transaction is forwarded to GSC+, the GSC+ address is

** as follows:

**	GSC+ Address[0:3]	4'b1111

**	GSC+ Address[4:29]	Runway Address[12:37]

**	GSC+ Address[30:31]	2'b00

**

** All 4 Low/High registers must be initialized (by PDC) once the lower bus

** is interrogated and address space is defined. The operating system will

** modify the architectural IO_IO_LOW and IO_IO_HIGH registers following

** the PDC initialization.  However, the hardware version dependent IO_IO_LOW

** and IO_IO_HIGH registers should not be subsequently altered by the OS.

** 

** Writes to both sets of registers will take effect immediately, bypassing

** the queues, which ensures that subsequent Runway transactions are checked

** against the updated bounds values. However reads are queued, introducing

** the possibility of a read being bypassed by a subsequent write to the same

** register. This sequence can be avoided by having software wait for read

** returns before issuing subsequent writes.

 I/O MMU base address */

 resource map, bit == pdir entry */

 physical base address */

 bytes, function of IOV Space size */

	u32 res_hint;			/* next available IOVP -

 size of resource map in bytes */

 current index into avg_search */

 STUFF We don't need in performance path */

 specify bit location of chain_id */

 Linked list of discovered iocs */

 device name from firmware */

 the hardware path this ioc is associatd with */

 the fake pci_dev for non-pci devs */

 The "routed" MMIO regions */

/**************************************************************

*

*   I/O Pdir Resource Management

*

*   Bits set in the resource map are in use.

*   Each bit can represent a number of pages.

*   LSbs represent lower addresses (IOVA's).

*

*   This was was copied from sba_iommu.c. Don't try to unify

*   the two resource managers unless a way to have different

*   allocation policies is also adjusted. We'd like to avoid

*   I/O TLB thrashing by having resource allocation policy

*   match the I/O TLB replacement policy.

*

 Convert from IOVP to IOVA and vice versa. */

/*

** Don't worry about the 150% average search length on a miss.

** If the search wraps around, and passes the res_hint, it will

** cause the kernel to panic anyhow.

/*

** Find available bit in this ioa's resource map.

** Use a "circular" search:

**   o Most IOVA's are "temporary" - avg search time should be small.

** o keep a history of what happened for debugging

** o KISS.

**

** Perf optimizations:

** o search for log2(size) bits at a time.

** o search for available resource bits using byte/word/whatever.

** o use different search for "large" (eg > 4 pages) or "very large"

**   (eg > 16 pages) mappings.

/**

 * ccio_alloc_range - Allocate pages in the ioc's resource map.

 * @ioc: The I/O Controller.

 * @pages_needed: The requested number of pages to be mapped into the

 * I/O Pdir...

 *

 * This function searches the resource map of the ioc to locate a range

 * of available pages for the requested size.

	/*

	** "seek and ye shall find"...praying never hurts either...

	** ggg sacrifices another 710 to the computer gods.

		/*

		 * LAN traffic will not thrash the TLB IFF the same NIC

		 * uses 8 adjacent pages to map separate payload data.

		 * ie the same byte in the resource bit map.

		/* FIXME: bit search should shift it's way through

		 * an unsigned long - not byte at a time. As it is now,

		 * we effectively allocate this byte to this mapping.

 check for roll over */

	/* 

	** return the bit address.

/**

 * ccio_free_range - Free pages from the ioc's resource map.

 * @ioc: The I/O Controller.

 * @iova: The I/O Virtual Address.

 * @pages_mapped: The requested number of pages to be freed from the

 * I/O Pdir.

 *

 * This function frees the resouces allocated for the iova.

 see matching comments in alloc_range */

/****************************************************************

**

**          CCIO dma_ops support routines

**

/*

** DMA "Page Type" and Hints 

** o if SAFE_DMA isn't set, mapping is for FAST_DMA. SAFE_DMA should be

**   set for subcacheline DMA transfers since we don't want to damage the

**   other part of a cacheline.

** o SAFE_DMA must be set for "memory" allocated via pci_alloc_consistent().

**   This bit tells U2 to do R/M/W for partial cachelines. "Streaming"

**   data can avoid this if the mapping covers full cache lines.

** o STOP_MOST is needed for atomicity across cachelines.

**   Apparently only "some EISA devices" need this.

**   Using CONFIG_ISA is hack. Only the IOA with EISA under it needs

**   to use this hint iff the EISA devices needs this feature.

**   According to the U2 ERS, STOP_MOST enabled pages hurt performance.

** o PREFETCH should *not* be set for cases like Multiple PCI devices

**   behind GSCtoPCI (dino) bus converter. Only one cacheline per GSC

**   device can be fetched and multiply DMA streams will thrash the

**   prefetch buffer and burn memory bandwidth. See 6.7.3 "Prefetch Rules

**   and Invalidation of Prefetch Entries".

**

** FIXME: the default hints need to be per GSC device - not global.

** 

** HP-UX dorks: linux device driver programming model is totally different

**    than HP-UX's. HP-UX always sets HINT_PREFETCH since it's drivers

**    do special things to work on non-coherent platforms...linux has to

**    be much more careful with this.

 used for pci_alloc_consistent() pages */

 LSL support */

 only needed for "some EISA devices" */

 not used/supported by U2 */

 for outbound pages which are not SAFE */

/*

** Use direction (ie PCI_DMA_TODEVICE) to pick hint.

** ccio_alloc_consistent() depends on this to get SAFE_DMA

** when it passes in BIDIRECTIONAL flag.

/**

 * ccio_io_pdir_entry - Initialize an I/O Pdir.

 * @pdir_ptr: A pointer into I/O Pdir.

 * @sid: The Space Identifier.

 * @vba: The virtual address.

 * @hints: The DMA Hint.

 *

 * Given a virtual address (vba, arg2) and space id, (sid, arg1),

 * load the I/O PDIR entry pointed to by pdir_ptr (arg0). Each IO Pdir

 * entry consists of 8 bytes as shown below (MSB == bit 0):

 *

 *

 * WORD 0:

 * +------+----------------+-----------------------------------------------+

 * | Phys | Virtual Index  |               Phys                            |

 * | 0:3  |     0:11       |               4:19                            |

 * |4 bits|   12 bits      |              16 bits                          |

 * +------+----------------+-----------------------------------------------+

 * WORD 1:

 * +-----------------------+-----------------------------------------------+

 * |      Phys    |  Rsvd  | Prefetch |Update |Rsvd  |Lock  |Safe  |Valid  |

 * |     20:39    |        | Enable   |Enable |      |Enable|DMA   |       |

 * |    20 bits   | 5 bits | 1 bit    |1 bit  |2 bits|1 bit |1 bit |1 bit  |

 * +-----------------------+-----------------------------------------------+

 *

 * The virtual index field is filled with the results of the LCI

 * (Load Coherence Index) instruction.  The 8 bits used for the virtual

 * index are bits 12:19 of the value returned by LCI.

 coherent index */

 We currently only support kernel addresses */

	/*

	** WORD 1 - low order word

	** "hints" parm includes the VALID bit!

	** "dep" clobbers the physical address offset bits as well.

	/*

	** WORD 0 - high order word

	/*

	** get bits 12:15 of physical address

	** shift bits 16:31 of physical address

	** and deposit them

	/*

	** get CPU coherency index bits

	** Grab virtual index [0:11]

	** Deposit virt_idx bits into I/O PDIR word

	/* FIXME: PCX_W platforms don't need FDC/SYNC. (eg C360)

	**        PCX-U/U+ do. (eg C200/C240)

	**        PCX-T'? Don't know. (eg C110 or similar K-class)

	**

	** See PDC_MODEL/option 0/SW_CAP word for "Non-coherent IO-PDIR bit".

	**

	** "Since PCX-U employs an offset hash that is incompatible with

	** the real mode coherence index generation of U2, the PDIR entry

	** must be flushed to memory to retain coherence."

/**

 * ccio_clear_io_tlb - Remove stale entries from the I/O TLB.

 * @ioc: The I/O Controller.

 * @iovp: The I/O Virtual Page.

 * @byte_cnt: The requested number of bytes to be freed from the I/O Pdir.

 *

 * Purge invalid I/O PDIR entries from the I/O TLB.

 *

 * FIXME: Can we change the byte_cnt to pages_mapped?

 clear offset bits, just want pagenum */

/**

 * ccio_mark_invalid - Mark the I/O Pdir entries invalid.

 * @ioc: The I/O Controller.

 * @iova: The I/O Virtual Address.

 * @byte_cnt: The requested number of bytes to be freed from the I/O Pdir.

 *

 * Mark the I/O Pdir entries invalid and blow away the corresponding I/O

 * TLB entries.

 *

 * FIXME: at some threshold it might be "cheaper" to just blow

 *        away the entire I/O TLB instead of individual entries.

 *

 * FIXME: Uturn has 256 TLB entries. We don't need to purge every

 *        PDIR entry - just once for each possible TLB entry.

 *        (We do need to maker I/O PDIR entries invalid regardless).

 *

 * FIXME: Can we change byte_cnt to pages_mapped?

 round up to nearest page size */

 invalidate one page at a time */

 clear only VALID bit */ 

		/*

		** FIXME: PCX_W platforms don't need FDC/SYNC. (eg C360)

		**   PCX-U/U+ do. (eg C200/C240)

		** See PDC_MODEL/option 0/SW_CAP for "Non-coherent IO-PDIR bit".

/****************************************************************

**

**          CCIO dma_ops

**

/**

 * ccio_dma_supported - Verify the IOMMU supports the DMA address range.

 * @dev: The PCI device.

 * @mask: A bit mask describing the DMA address range of the device.

 only support 32-bit or better devices (ie PCI/GSC) */

/**

 * ccio_map_single - Map an address range into the IOMMU.

 * @dev: The PCI device.

 * @addr: The start address of the DMA region.

 * @size: The length of the DMA region.

 * @direction: The direction of the DMA transaction (to/from device).

 *

 * This function implements the pci_map_single function.

 save offset bits */

 round up to nearest IOVP_SIZE */

 If not cacheline aligned, force SAFE_DMA on the whole mess */

 form complete address */

/**

 * ccio_unmap_page - Unmap an address range from the IOMMU.

 * @dev: The PCI device.

 * @addr: The start address of the DMA region.

 * @size: The length of the DMA region.

 * @direction: The direction of the DMA transaction (to/from device).

 clear offset bits */

/**

 * ccio_alloc - Allocate a consistent DMA mapping.

 * @dev: The PCI device.

 * @size: The length of the DMA region.

 * @dma_handle: The DMA address handed back to the device (not the cpu).

 *

 * This function implements the pci_alloc_consistent function.

/* GRANT Need to establish hierarchy for non-PCI devs as well

** and then provide matching gsc_map_xxx() functions for them as well.

 only support PCI */

/**

 * ccio_free - Free a consistent DMA mapping.

 * @dev: The PCI device.

 * @size: The length of the DMA region.

 * @cpu_addr: The cpu address returned from the ccio_alloc_consistent.

 * @dma_handle: The device address returned from the ccio_alloc_consistent.

 *

 * This function implements the pci_free_consistent function.

/*

** Since 0 is a valid pdir_base index value, can't use that

** to determine if a value is valid or not. Use a flag to indicate

** the SG list entry contains a valid pdir index.

/**

 * ccio_map_sg - Map the scatter/gather list into the IOMMU.

 * @dev: The PCI device.

 * @sglist: The scatter/gather list to be mapped in the IOMMU.

 * @nents: The number of entries in the scatter/gather list.

 * @direction: The direction of the DMA transaction (to/from device).

 *

 * This function implements the pci_map_sg function.

 Fast path single entry scatterlists. */

	/*

	** First coalesce the chunks and allocate I/O pdir space

	**

	** If this is one DMA stream, we can properly map using the

	** correct virtual address associated with each DMA page.

	** w/o this association, we wouldn't have coherent DMA!

	** Access to the virtual address is what forces a two pass algorithm.

	/*

	** Program the I/O Pdir

	**

	** map the virtual addresses to the I/O Pdir

	** o dma_address will contain the pdir index

	** o dma_len will contain the number of bytes to map 

	** o page/offset contain the virtual address.

/**

 * ccio_unmap_sg - Unmap the scatter/gather list from the IOMMU.

 * @dev: The PCI device.

 * @sglist: The scatter/gather list to be unmapped from the IOMMU.

 * @nents: The number of entries in the scatter/gather list.

 * @direction: The direction of the DMA transaction (to/from device).

 *

 * This function implements the pci_unmap_sg function.

 KLUGE - unmap_sg calls unmap_page for each mapped page */

 CCIO_COLLECT_STATS */

 XXX - remove me */

 CONFIG_PROC_FS */

/**

 * ccio_find_ioc - Find the ioc in the ioc_list

 * @hw_path: The hardware path of the ioc.

 *

 * This function searches the ioc_list for an ioc that matches

 * the provide hardware path.

/**

 * ccio_get_iommu - Find the iommu which controls this device

 * @dev: The parisc device.

 *

 * This function searches through the registered IOMMU's and returns

 * the appropriate IOMMU for the device based on its hardware path.

 inc upper nibble */

/* Cujo 2.0 has a bug which will silently corrupt data being transferred

 * to/from certain pages.  To avoid this happening, we mark these pages

 * as `used', and ensure that nothing will try to allocate from them.

 GRANT -  is this needed for U2 or not? */

/*

** Get the size of the I/O TLB for this I/O MMU.

**

** If spa_shift is non-zero (ie probably U2),

** then calculate the I/O TLB size using spa_shift.

**

** Otherwise we are supposed to get the IODC entry point ENTRY TLB

** and execute it. However, both U2 and Uturn firmware supplies spa_shift.

** I think only Java (K/D/R-class too?) systems don't do this.

 Uturn supports 256 TLB entries */

 0 */

 We *can't* support JAVA (T600). Venture there at your own risk. */

 U2 */

 UTurn */

/**

 * ccio_ioc_init - Initialize the I/O Controller

 * @ioc: The I/O Controller.

 *

 * Initialize the I/O Controller which includes setting up the

 * I/O Page Directory, the resource map, and initalizing the

 * U2/Uturn chip into virtual mode.

	/*

	** Determine IOVA Space size from memory size.

	**

	** Ideally, PCI drivers would register the maximum number

	** of DMA they can have outstanding for each device they

	** own.  Next best thing would be to guess how much DMA

	** can be outstanding based on PCI Class/sub-class. Both

	** methods still require some "extra" to support PCI

	** Hot-Plug/Removal of PCI cards. (aka PCI OLARD).

 limit IOVA space size to 1MB-1GB */

	/*

	** iova space must be log2() in size.

	** thus, pdir/res_map will also be log2().

	/* We could use larger page sizes in order to *decrease* the number

	** of mappings needed.  (ie 8k pages means 1/2 the mappings).

	**

	** Note: Grant Grunder says "Using 8k I/O pages isn't trivial either

	**   since the pages must also be physically contiguous - typically

	**   this is the case under linux."

 iova_space_size is now bytes, not pages */

 max pdir size <= 8MB */

 Verify it's a power of two */

 resource map size dictated by pdir_size */

 Initialize the res_hint to 16 */

 Initialize the spinlock */

	/*

	** Chainid is the upper most bits of an IOVP used to determine

	** which TLB entry an IOVP will use.

	/*

	** Initialize IOA hardware

	/*

	** Go to "Virtual Mode"

	/*

	** Initialize all I/O TLB entries to 0 (Valid bit off).

	/*

	 * bracing ((signed) ...) are required for 64bit kernel because

	 * we only want to sign extend the lower 16 bits of the register.

	 * The upper 16-bits of range registers are hardcoded to 0xffff.

	/*

	 * Check if this MMIO range is disable

	/* On some platforms (e.g. K-Class), we have already registered

	 * resources for devices reported by firmware. Some are children

	 * of ccio.

	 * "insert" ccio ranges in the mmio hierarchy (/proc/iomem).

	/* We might be trying to expand the MMIO range to include

	 * a child device that has already registered it's MMIO space.

	 * Use "insert" instead of request_resource().

/*

 * Dino calls this function.  Beware that we may get called on systems

 * which have no IOC (725, B180, C160L, etc) but do have a Dino.

 * So it's legal to find no parent IOC.

 *

 * Some other issues: one of the resources in the ioc may be unassigned.

	/* "transparent" bus bridges need to register MMIO resources

	 * firmware assigned them. e.g. children of hppb.c (e.g. K-class)

	 * registered their resources in the PDC "bus walk" (See

	 * arch/parisc/kernel/inventory.c).

/**

 * ccio_probe - Determine if ccio should claim this device.

 * @dev: The device which has been found

 *

 * Determine if ccio should claim this chip (return 0) or not (return 1).

 * If so, initialize the chip and tell other partners in crime they

 * have work to do.

 if this fails, no I/O cards will work, so may as well bug */

/**

 * ccio_init - ccio initialization procedure.

 *

 * Register this driver.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	WAX Device Driver

 *

 *	(c) Copyright 2000 The Puffin Group Inc.

 *

 *	by Helge Deller <deller@gmx.de>

 Hardcoded Interrupt for GSC */

 i8042 General */

 Serial */

 EISA */

 Unknown */

 i8042 High-priority */

 EISA NMI */

 No secondary IRQ */

 Wax-off */

 clear pending interrupts */

	/* We're not really convinced we want to reset the onboard

         * devices. Firmware does it for us...

 Resets */

	gsc_writel(0xFFFFFFFF, base+0x1000); /* HIL */

	gsc_writel(0xFFFFFFFF, base+0x2000); /* RS232-B on Wax */

 gsc_readb(wax->hpa+WAX_VER); */

 Stop wax hissing for a bit */

 the IRQ wax should use */

 enable IRQ's for devices below WAX */

 Done init'ing, register this driver */

 On 715-class machines, Wax EISA is a sibling of Wax, not a child. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

**	DINO manager

**

**	(c) Copyright 1999 Red Hat Software

**	(c) Copyright 1999 SuSE GmbH

**	(c) Copyright 1999,2000 Hewlett-Packard Company

**	(c) Copyright 2000 Grant Grundler

**	(c) Copyright 2006-2019 Helge Deller

**

**

**	This module provides access to Dino PCI bus (config/IOport spaces)

**	and helps manage Dino IRQ lines.

**

**	Dino interrupt handling is a bit complicated.

**	Dino always writes to the broadcast EIR via irr0 for now.

**	(BIG WARNING: using broadcast EIR is a really bad thing for SMP!)

**	Only one processor interrupt is used for the 11 IRQ line 

**	inputs to dino.

**

**	The different between Built-in Dino and Card-Mode

**	dino is in chip initialization and pci device initialization.

**

**	Linux drivers can only use Card-Mode Dino if pci devices I/O port

**	BARs are configured and used by the driver. Programming MMIO address 

**	requires substantial knowledge of available Host I/O address ranges

**	is currently not supported.  Port/Config accessor functions are the

**	same. "BIOS" differences are handled within the existing routines.

/*	Changes :

**	2001-06-14 : Clement Moyroud (moyroudc@esiee.fr)

**		- added support for the integrated RS232. 	

/*

** TODO: create a virtual address for each Dino HPA.

**       GSC code might be able to do this since IODC data tells us

**       how many pages are used. PCI subsystem could (must?) do this

**       for PCI drivers devices which implement/use MMIO registers.

 for struct irqaction */

 for spinlock_t and prototypes */

/*

** Config accessor functions only pass in the 8-bit bus number

** and not the 8-bit "PCI Segment" number. Each Dino will be

** assigned a PCI bus number based on "when" it's discovered.

**

** The "secondary" bus number is set to this before calling

** pci_scan_bus(). If any PPB's are present, the scan will

** discover them and update the "secondary" and "subordinate"

** fields in Dino's pci_bus structure.

**

** Changes in the configuration *will* result in a different

** bus number for each dino.

 Dino 3.x only */

 bits 0-10 are architected */

 only 10 bits are implemented */

 #define xxx       0x080 - bit 7 is "default" */

 #define xxx    0x100 - bit 8 not used */

 #define xxx    0x200 - bit 9 not used */

 'C' inheritance - must be first */

 EIR addr to generate interrupt */ 

 EIR data assign to each dino */ 

 IRQ's which are enabled */ 

 map IMR bit to global irq */

 save most recent IRQ line stat */

/*

 * Dino Configuration Space Accessor Functions

/*

 * keep the current highest bus count to assist in allocating busses.  This

 * tries to keep a global bus count total so that when we discover an 

 * entirely new bus, it can be given a unique bus number.

 tell HW which CFG address */

 generate cfg read cycle */

/*

 * Dino address stepping "feature":

 * When address stepping, Dino attempts to drive the bus one cycle too soon

 * even though the type of cycle (config vs. MMIO) might be different. 

 * The read of Ven/Prod ID is harmless and avoids Dino's address stepping.

 avoid address stepping feature */

 tell HW which CFG address */

 generate cfg read cycle */

/*

 * Dino "I/O Port" Space Accessor Functions

 *

 * Many PCI devices don't require use of I/O port space (eg Tulip,

 * NCR720) since they export the same registers to both MMIO and

 * I/O port space.  Performance is going to stink if drivers use

 * I/O port instead of MMIO.

 tell HW which IO Port address */ \

 generate I/O PORT read cycle */ \

 tell HW which IO port address */ \

 generate cfg write cycle */ \

 Clear the matching bit in the IMR register */

	/*

	** clear pending IRQ bits

	**

	** This does NOT change ILR state!

	** See comment below for ILR usage.

 set the matching bit in the IMR register */

 used in dino_isr() */

	/* Emulate "Level Triggered" Interrupt

	** Basically, a driver is blowing it if the IRQ line is asserted

	** while the IRQ is disabled.  But tulip.c seems to do that....

	** Give 'em a kluge award and a nice round of applause!

	**

	** The gsc_write will generate an interrupt which invokes dino_isr().

	** dino_isr() will read IPR and find nothing. But then catch this

	** when it also checks ILR.

/*

 * Handle a Processor interrupt generated by Dino.

 *

 * ilr_loop counter is a kluge to prevent a "stuck" IRQ line from

 * wedging the CPU. Could be removed or made optional at some point.

 read and acknowledge pending interrupts */

	/* Support for level triggered IRQ lines.

	** 

	** Dropping this support would make this routine *much* faster.

	** But since PCI requires level triggered IRQ line to share lines...

	** device drivers may assume lines are level triggered (and not

	** edge triggered like EISA/ISA can be).

 PS/2 */

 RS232 */

 PS/2 */

 Unknown */

/*

 * Cirrus 6832 Cardbus reports wrong irq on RDI Tadpole PARISC Laptop (deller@gmx.de)

 * (the irqs are off-by-one, not sure yet if this is a cirrus, dino-hardware or dino-driver problem...)

 Check if PCI device is behind a Card-mode Dino. */

 Disable this card by zeroing the PCI resources */

 CONFIG_TULIP */

/*

 * dino_card_setup - Set up the memory space for a Dino in card mode.

 * @bus: the bus under this dino

 *

 * Claim an 8MB chunk of unused IO space and call the generic PCI routines

 * to set up the addresses of the devices on this bus.

 kill the bus, we can't do anything with it */

 Now tell dino what range it has */

	/*

	** REVISIT: card-mode PCI-PCI expansion chassis do exist.

	**         Not sure they were ever productized.

	**         Die here since we'll die later in dino_inb() anyway.

	/*

	** Set Latency Timer to 0xff (not a shared bus)

	** Set CACHELINE_SIZE.

	/*

	** Program INT_LINE for card-mode devices.

	** The cards are hardwired according to this algorithm.

	** And it doesn't matter if PPB's are present or not since

	** the IRQ lines bypass the PPB.

	**

	** "-1" converts INTA-D (1-4) to PCIINTA-D (0-3) range.

	** The additional "-1" adjusts for skewing the IRQ<->slot.

	/* Shouldn't really need to do this but it's in case someone tries

	** to bypass PCI services and look at the card themselves.

 The alignment contraints for PCI bridges under dino */

 Firmware doesn't set up card-mode dino, so we have to */

				/* There's a quirk to alignment of

				 * bridge memory resources: the start

				 * is the alignment and start-end is

				 * the size.  However, firmware will

				 * have assigned start and end, so we

		/*

		** P2PB's only have 2 BARs, no IRQs.

		** I'd like to just ignore them for now.

		/* null out the ROM resource if there is one (we don't

		 * care about an expansion rom on parisc, since it

			/* This code tries to assign an unassigned

			 * interrupt.  Leave it disabled unless you

			 * *really* know what you're doing since the

			 * pin<->interrupt line mapping varies by bus

 Adjust INT_LINE for that busses region */

/*

 *	Initialise a DINO controller chip

 REVISIT - should be a runtime check (eg if (CPU_IS_PCX_L) ...) */

	/*

	** PCX-L processors don't support XQL like Dino wants it.

	** PCX-L2 ignore XQL signal and it doesn't matter.

 UXQL */

	/*

	** Don't enable address decoding until we know which I/O range

	** currently is available from the host. Only affects MMIO

	** and not I/O port space.

 Disable PAMR before writing PAPR */

	/*

	** Dino ERS encourages enabling FBB (0x6f).

	** We can't until we know *all* devices below us can support it.

	** (Something in device configuration header tells us).

	/* Somewhere, the PCI spec says give devices 1 second

	** to recover from the #RESET being de-asserted.

	** Experience shows most devices only need 10ms.

	** This short-cut speeds up booting significantly.

	/*

	 * Decoding IO_ADDR_EN only works for Built-in Dino

	 * since PDC has already initialized this.

 used by pci_scan_bus() */

	/*

	** Note: SMP systems can make use of IRR1/IAR1 registers

	**   But it won't buy much performance except in very

	**   specific applications/configurations. Note Dino

	**   still only has 11 IRQ input lines - just map some of them

	**   to a different processor.

	/* 

	** Dino needs a PA "IRQ" to get a processor's attention.

	** arch/parisc/kernel/irq.c returns an EIRR bit.

	/* Support the serial port which is sometimes attached on built-in

	 * Dino / Cujo chips.

	/*

	** This enables DINO to generate interrupts when it sees

	** any of its inputs *change*. Just asserting an IRQ

	** before it's enabled (ie unmasked) isn't good enough.

	/*

	** Some platforms don't clear Dino's IRR0 register at boot time.

	** Reading will clear it now.

 allocate I/O Port resource region */

 do not mark it busy ! */

/*

** Determine if dino should claim this chip (return 0) or not (return 1).

** If so, initialize the chip appropriately (card-mode vs bridge mode).

** Much of the initialization is common though.

 Dino specific control struct

 Check for bugs */

/* REVISIT: why are C200/C240 listed in the README table but not

**   "Models affected"? Could be an omission in the original literature.

	/*

	** It's not used to avoid chicken/egg problems

	** with configuration accessor functions.

 increment the bus number in case of duplicates */

	/* This code *depends* on scanning being single threaded

	 * if it isn't, this global bus number count will fail

/*

 * Normally, we would just test sversion.  But the Elroy PCI adapter has

 * the same sversion as Dino, so we have to check hversion as well.

 * Unfortunately, the J2240 PDC reports the wrong hversion for the first

 * Dino, so we have to test for Dino, Cujo and Dino-in-a-J2240.

 * For card-mode Dino, most machines report an sversion of 9D.  But 715

 * and 725 firmware misreport it as 0x08080 for no adequately explained

 * reason.

 Card-mode Dino */

 XXX */

 Bridge-mode Dino */

 Bridge-mode Cujo */

 Dino in a J2240 */

/*

 * One time initialization to let the world know Dino is here.

 * This is the only routine which is NOT static.

 * Must be called exactly once before pci_init().

 SPDX-License-Identifier: GPL-2.0-or-later

/* 

 *    EISA "eeprom" support routines

 *

 *    Copyright (C) 2001 Thomas Bogendoerfer <tsbogend at parisc-linux.org>

/*

 *	The various file operations we support.

 SPDX-License-Identifier: GPL-2.0-or-later

/*      National Semiconductor NS87560UBD Super I/O controller used in

 *      HP [BCJ]x000 workstations.

 *

 *      This chip is a horrid piece of engineering, and National

 *      denies any knowledge of its existence. Thus no datasheet is

 *      available off www.national.com. 

 *

 *	(C) Copyright 2000 Linuxcare, Inc.

 * 	(C) Copyright 2000 Linuxcare Canada, Inc.

 *	(C) Copyright 2000 Martin K. Petersen <mkp@linuxcare.com>

 * 	(C) Copyright 2000 Alex deVries <alex@onefishtwo.ca>

 *      (C) Copyright 2001 John Marvin <jsm fc hp com>

 *      (C) Copyright 2003 Grant Grundler <grundler parisc-linux org>

 *	(C) Copyright 2005 Kyle McMartin <kyle@parisc-linux.org>

 *	(C) Copyright 2006 Helge Deller <deller@gmx.de>

 *

 *	The initial version of this is by Martin Peterson.  Alex deVries

 *	has spent a bit of time trying to coax it into working.

 *

 *      Major changes to get basic interrupt infrastructure working to

 *      hopefully be able to support all SuperIO devices. Currently

 *      works with serial. -- John Marvin <jsm@fc.hp.com>

 *

 *	Converted superio_init() to be a PCI_FIXUP_FINAL callee.

 *         -- Kyle McMartin <kyle@parisc-linux.org>

/* NOTES:

 * 

 * Function 0 is an IDE controller. It is identical to a PC87415 IDE

 * controller (and identifies itself as such).

 *

 * Function 1 is a "Legacy I/O" controller. Under this function is a

 * whole mess of legacy I/O peripherals. Of course, HP hasn't enabled

 * all the functionality in hardware, but the following is available:

 *

 *      Two 16550A compatible serial controllers

 *      An IEEE 1284 compatible parallel port

 *      A floppy disk controller

 *

 * Function 2 is a USB controller.

 *

 * We must be incredibly careful during initialization.  Since all

 * interrupts are routed through function 1 (which is not allowed by

 * the PCI spec), we need to program the PICs on the legacy I/O port

 * *before* we attempt to set up IDE and USB.  @#$!&

 *

 * According to HP, devices are only enabled by firmware if they have

 * a physical device connected.

 *

 * Configuration register bits:

 *     0x5A: FDC, SP1, IDE1, SP2, IDE2, PAR, Reserved, P92

 *     0x5B: RTC, 8259, 8254, DMA1, DMA2, KBC, P61, APM

 *

 Poll the 8259 to see if there's an interrupt. */

	/*

	 * Bit    7:	1 = active Interrupt; 0 = no Interrupt pending

	 * Bits 6-3:	zero

	 * Bits 2-0:	highest priority, active requesting interrupt ID (0-7)

		/* I suspect "spurious" interrupts are from unmasking an IRQ.

		 * We don't know if an interrupt was/is pending and thus

		 * just call the handler for that IRQ as if it were pending.

 Check to see which device is interrupting */

 Could be spurious. Check in service bits */

 if ISR7 not set: spurious */

 Call the appropriate device's interrupt */

	/* set EOI - forces a new interrupt if a lower priority device

	 * still needs service.

 Initialize Super I/O device */

 use the IRQ iosapic found for USB INT D... */

 ...then properly fixup the USB to point at suckyio PIC */

 Enable the legacy I/O function */

 not too much we can do about this... */

	/*

	 * Next project is programming the onboard interrupt controllers.

	 * PDC hasn't done this for us, since it's using polled I/O.

	 *

	 * XXX Use dword writes to avoid bugs in Elroy or Suckyio Config

	 *     space access.  PCI is by nature a 32-bit bus and config

	 *     space can be sensitive to that.

	/* 0x64 - 0x67 :

		DMA Rtg 2

		DMA Rtg 3

		DMA Chan Ctl

		TRIGGER_1    == 0x82   USB & IDE level triggered, rest to edge

	/* 0x68 - 0x6b :

		TRIGGER_2    == 0x00   all edge triggered (not used)

		CFG_IR_SER   == 0x43   SerPort1 = IRQ3, SerPort2 = IRQ4

		CFG_IR_PF    == 0x65   ParPort  = IRQ5, FloppyCtlr = IRQ6

		CFG_IR_IDE   == 0x07   IDE1 = IRQ7, reserved

	/* 0x6c - 0x6f :

		CFG_IR_INTAB == 0x00

		CFG_IR_INTCD == 0x10   USB = IRQ1

		CFG_IR_PS2   == 0x00

		CFG_IR_FXBUS == 0x00

	/* 0x70 - 0x73 :

		CFG_IR_USB   == 0x00  not used. USB is connected to INTD.

		CFG_IR_ACPI  == 0x00  not used.

		DMA Priority == 0x4c88  Power on default value. NFC.

 PIC1 Initialization Command Word register programming */

 ICW1: ICW4 write req | ICW1 */

 ICW2: interrupt vector table - not used */

 ICW3: Cascade */

 ICW4: x86 mode */

 PIC1 Program Operational Control Words */

 OCW1: Mask all interrupts */

 OCW2: priority (3-7,0-2) */

 PIC2 Initialization Command Word register programming */

 ICW1: ICW4 write req | ICW1 */

 ICW2: N/A */

 ICW3: Slave ID code */

 ICW4: x86 mode */

 Program Operational Control Words */

 OCW1: Mask all interrupts */

 OCW3: OCW3 select | ESMM | SMM */

 Write master mask reg */

 Setup USB power regulation */

 Mask interrupt */

 Unmask interrupt */

 Verify the function number matches the expected device id. */

	/*

	 * We don't allocate a SuperIO irq for the legacy IO function,

	 * since it is a "bridge". Instead, we will allocate irq's for

	 * each legacy device as they are initialized.

 Function 0 */

 Function 1 */

 save for superio_init() */

 Function 2 */

 save for superio_init() */

 serial port #1 */

 serial port #2 */

 CONFIG_SERIAL_8250 */

base_hi*/,

 dma */,

struct pci_dev* */,

 shared irq flags */))

 CONFIG_PARPORT_PC */

	/*

	** superio_probe(00:0e.0) ven 0x100b dev 0x2 sv 0x0 sd 0x0 class 0x1018a

	** superio_probe(00:0e.1) ven 0x100b dev 0xe sv 0x0 sd 0x0 class 0x68000

	** superio_probe(00:0e.2) ven 0x100b dev 0x12 sv 0x0 sd 0x0 class 0xc0310

 Enabled by PCI_FIXUP_FINAL */

 Function 1 */

 REVISIT XXX : superio_fdc_init() ? */

 Function 0 */

 Function 2 */

 Let appropriate other driver claim this device. */

/*

 * linux/drivers/parisc/power.c

 * HP PARISC soft power switch support driver

 *

 * Copyright (c) 2001-2007 Helge Deller <deller@gmx.de>

 * All rights reserved.

 *

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions

 * are met:

 * 1. Redistributions of source code must retain the above copyright

 *    notice, this list of conditions, and the following disclaimer,

 *    without modification.

 * 2. The name of the author may not be used to endorse or promote products

 *    derived from this software without specific prior written permission.

 *

 * Alternatively, this software may be distributed under the terms of the

 * GNU General Public License ("GPL").

 *

 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND

 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE

 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE

 * ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR

 * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL

 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS

 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)

 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT

 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY

 *

 *

 *  HINT:

 *  Support of the soft power switch button may be enabled or disabled at

 *  runtime through the "/proc/sys/kernel/power" procfs entry.

 how often should the power button be polled ? */

 how long does the power button needs to be down until we react ? */

 assembly code to access special registers */

 taken from PCXL ERS page 82 */

 move value of gr to dr[dr] */

 for dr0 and dr8 only ! */

 all dr except dr0 and dr8 */

 local shutdown counter */

 check, give feedback and start shutdown after one second */

 wait until the button was pressed for 1 second */

 send kill signal */

 just in case killing init process failed */

 main power switch task struct */

 filename in /proc which can be used to enable/disable the power switch */

 soft power switch enabled/disabled */

 main kernel thread worker. It polls the button state */

			/*

			 * Non-Gecko-style machines:

			 * Check the power switch status which is read from the

			 * real I/O location at soft_power_reg.

			 * Bit 31 ("the lowest bit) is the status of the power switch.

			 * This bit is "1" if the button is NOT pressed.

			/*

			 * On gecko style machines (e.g. 712/xx and 715/xx) 

			 * the power switch status is stored in Bit 0 ("the highest bit")

			 * of CPU diagnose register 25.

			 * Warning: Some machines never reset the DIAG flag, even if

			 * the button has been released again.

 avoid writing if not necessary */

/*

 * powerfail interruption handler (irq IRQ_FROM_REGION(CPU_IRQ_REGION)+2) 

/* parisc_panic_event() is called by the panic handler.

 * As soon as a panic occurs, our tasklets above will not be

 * executed any longer. This function then re-enables the 

 * soft-power switch and allows the user to switch off the system

 re-enable the soft-power switch */

 enable the soft power switch if possible */

 Register a call for panic conditions. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Interrupt management for most GSC and related devices.

 *

 * (c) Copyright 1999 Alex deVries for The Puffin Group

 * (c) Copyright 1999 Grant Grundler for Hewlett-Packard

 * (c) Copyright 1999 Matthew Wilcox

 * (c) Copyright 2000 Helge Deller

 * (c) Copyright 2001 Matthew Wilcox for Hewlett-Packard

 virtualize the IRQ first */

 Common interrupt demultiplexer used by Asp, Lasi & Wax.  */

 Disable the IRQ line by clearing the bit in the IMR */

 Enable the IRQ line by setting the bit in the IMR */

	/*

	 * FIXME: read IPR to make sure the IRQ isn't already pending.

	 *   If so, we need to read IRR and manually call do_irq().

	/* work-around for 715/64 and others which have parent

 Initialise local irq -> global irq mapping */

 allocate resource region */

 do not mark it busy ! */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

** I/O Sapic Driver - PCI interrupt line support

**

**      (c) Copyright 1999 Grant Grundler

**      (c) Copyright 1999 Hewlett-Packard Company

**

**

** The I/O sapic driver manages the Interrupt Redirection Table which is

** the control logic to convert PCI line based interrupts into a Message

** Signaled Interrupt (aka Transaction Based Interrupt, TBI).

**

** Acronyms

** --------

** HPA  Hard Physical Address (aka MMIO address)

** IRQ  Interrupt ReQuest. Implies Line based interrupt.

** IRT	Interrupt Routing Table (provided by PAT firmware)

** IRdT Interrupt Redirection Table. IRQ line to TXN ADDR/DATA

**      table which is implemented in I/O SAPIC.

** ISR  Interrupt Service Routine. aka Interrupt handler.

** MSI	Message Signaled Interrupt. PCI 2.2 functionality.

**      aka Transaction Based Interrupt (or TBI).

** PA   Precision Architecture. HP's RISC architecture.

** RISC Reduced Instruction Set Computer.

**

**

** What's a Message Signalled Interrupt?

** -------------------------------------

** MSI is a write transaction which targets a processor and is similar

** to a processor write to memory or MMIO. MSIs can be generated by I/O

** devices as well as processors and require *architecture* to work.

**

** PA only supports MSI. So I/O subsystems must either natively generate

** MSIs (e.g. GSC or HP-PB) or convert line based interrupts into MSIs

** (e.g. PCI and EISA).  IA64 supports MSIs via a "local SAPIC" which

** acts on behalf of a processor.

**

** MSI allows any I/O device to interrupt any processor. This makes

** load balancing of the interrupt processing possible on an SMP platform.

** Interrupts are also ordered WRT to DMA data.  It's possible on I/O

** coherent systems to completely eliminate PIO reads from the interrupt

** path. The device and driver must be designed and implemented to

** guarantee all DMA has been issued (issues about atomicity here)

** before the MSI is issued. I/O status can then safely be read from

** DMA'd data by the ISR.

**

**

** PA Firmware

** -----------

** PA-RISC platforms have two fundamentally different types of firmware.

** For PCI devices, "Legacy" PDC initializes the "INTERRUPT_LINE" register

** and BARs similar to a traditional PC BIOS.

** The newer "PAT" firmware supports PDC calls which return tables.

** PAT firmware only initializes the PCI Console and Boot interface.

** With these tables, the OS can program all other PCI devices.

**

** One such PAT PDC call returns the "Interrupt Routing Table" (IRT).

** The IRT maps each PCI slot's INTA-D "output" line to an I/O SAPIC

** input line.  If the IRT is not available, this driver assumes

** INTERRUPT_LINE register has been programmed by firmware. The latter

** case also means online addition of PCI cards can NOT be supported

** even if HW support is present.

**

** All platforms with PAT firmware to date (Oct 1999) use one Interrupt

** Routing Table for the entire platform.

**

** Where's the iosapic?

** --------------------

** I/O sapic is part of the "Core Electronics Complex". And on HP platforms

** it's integrated as part of the PCI bus adapter, "lba".  So no bus walk

** will discover I/O Sapic. I/O Sapic driver learns about each device

** when lba driver advertises the presence of the I/O sapic by calling

** iosapic_register().

**

**

** IRQ handling notes

** ------------------

** The IO-SAPIC can indicate to the CPU which interrupt was asserted.

** So, unlike the GSC-ASIC and Dino, we allocate one CPU interrupt per

** IO-SAPIC interrupt and call the device driver's handler directly.

** The IO-SAPIC driver hijacks the CPU interrupt handler so it can

** issue the End Of Interrupt command to the IO-SAPIC.

**

** Overview of exported iosapic functions

** --------------------------------------

** (caveat: code isn't finished yet - this is just the plan)

**

** iosapic_init:

**   o initialize globals (lock, etc)

**   o try to read IRT. Presence of IRT determines if this is

**     a PAT platform or not.

**

** iosapic_register():

**   o create iosapic_info instance data structure

**   o allocate vector_info array for this iosapic

**   o initialize vector_info - read corresponding IRdT?

**

** iosapic_xlate_pin: (only called by fixup_irq for PAT platform)

**   o intr_pin = read cfg (INTERRUPT_PIN);

**   o if (device under PCI-PCI bridge)

**               translate slot/pin

**

** iosapic_fixup_irq:

**   o if PAT platform (IRT present)

**	   intr_pin = iosapic_xlate_pin(isi,pcidev):

**         intr_line = find IRT entry(isi, PCI_SLOT(pcidev), intr_pin)

**         save IRT entry into vector_info later

**         write cfg INTERRUPT_LINE (with intr_line)?

**     else

**         intr_line = pcidev->irq

**         IRT pointer = NULL

**     endif

**   o locate vector_info (needs: isi, intr_line)

**   o allocate processor "irq" and get txn_addr/data

**   o request_irq(processor_irq,  iosapic_interrupt, vector_info,...)

**

** iosapic_enable_irq:

**   o clear any pending IRQ on that line

**   o enable IRdT - call enable_irq(vector[line]->processor_irq)

**   o write EOI in case line is already asserted.

**

** iosapic_disable_irq:

**   o disable IRdT - call disable_irq(vector[line]->processor_irq)

 "local" compile flags */

 DEBUG_IOSAPIC */

 DEBUG_IOSAPIC */

 bits in the "low" I/O Sapic IRdT entry */

 bits in the "high" I/O Sapic IRdT entry */

/*

** REVISIT: future platforms may have more than one IRT.

** If so, the following three fields form a structure which

** then be linked into a list. Names are chosen to make searching

** for them easy - not necessarily accurate (eg "cell").

**

** Alternative: iosapic_info could point to the IRT it's in.

** iosapic_register() could search a list of IRT's.

	/* The IRT needs to be 8-byte aligned for the PDC call. 

	 * Normally kmalloc would guarantee larger alignment, but

	 * if CONFIG_DEBUG_SLAB is enabled, then we can get only

	 * 4-byte alignment on 32-bit kernels

/**

 * iosapic_load_irt - Fill in the interrupt routing table

 * @cell_num: The cell number of the CPU we're currently executing on

 * @irt: The address to place the new IRT at

 * @return The number of entries found

 *

 * The "Get PCI INT Routing Table Size" option returns the number of 

 * entries in the PCI interrupt routing table for the cell specified 

 * in the cell_number argument.  The cell number must be for a cell 

 * within the caller's protection domain.

 *

 * The "Get PCI INT Routing Table" option returns, for the cell 

 * specified in the cell_number argument, the PCI interrupt routing 

 * table in the caller allocated memory pointed to by mem_addr.

 * We assume the IRT only contains entries for I/O SAPIC and

 * calculate the size based on the size of I/O sapic entries.

 *

 * The PCI interrupt routing table entry format is derived from the

 * IA64 SAL Specification 2.4.   The PCI interrupt routing table defines

 * the routing of PCI interrupt signals between the PCI device output

 * "pins" and the IO SAPICs' input "lines" (including core I/O PCI

 * devices).  This table does NOT include information for devices/slots

 * behind PCI to PCI bridges. See PCI to PCI Bridge Architecture Spec.

 * for the architected method of routing of IRQ's behind PPB's.

 PDC return value status */

 start of interrupt routing tbl */

 Use pat pdc routine to get interrupt routing table size */

		/*

		** allocate memory for interrupt routing table

		** This interface isn't really right. We are assuming

		** the contents of the table are exclusively

		** for I/O sapic devices.

 get PCI INT routing table */

		/*

		** C3000/J5000 (and similar) platforms with Sprockets PDC

		** will return exactly one IRT for all iosapics.

		** So if we have one, don't need to get it again.

 Should be using the Elroy's HPA, but it's ignored anyway */

 Not a "legacy" system with I/O SAPIC either */

 HPA ignored by this call too. */

 return interrupt table address */

 DEBUG_IOSAPIC_IRT */

 get interrupt routing table for this cell */

 old PDC w/o iosapic */

/*

** Return the IRT entry in case we need to look something else up.

 track how many entries we've looked at */

		/*

		** Validate: entry_type, entry_length, interrupt_type

		**

		** Difference between validate vs compare is the former

		** should print debug info and is not expected to "fail"

		** on current platforms.

		/*

		** Ignore: src_bus_id and rc_seg_id correlate with

		**         iosapic_info->isi_hpa on HP platforms.

		**         If needed, pass in "PFA" (aka config space addr)

		**         instead of slot.

 Found it! */

/*

** xlate_pin() supports the skewing of IRQ lines done by subsidiary bridges.

** Legacy PDC already does this translation for us and stores it in INTR_LINE.

**

** PAT PDC needs to basically do what legacy PDC does:

** o read PIN

** o adjust PIN in case device is "behind" a PPB

**     (eg 4-port 100BT and SCSI/LAN "Combo Card")

** o convert slot/pin to I/O SAPIC input line.

**

** HP platforms only support:

** o one level of skewing for any number of PPBs

** o only support PCI-PCI Bridges.

 The device does NOT support/use IRQ lines.  */

 Check if pcidev behind a PPB */

		/* Convert pcidev INTR_PIN into something we

		** can lookup in the IRT.

		/*

		** Proposal #1:

		**

		** call implementation specific translation function

		** This is architecturally "cleaner". HP-UX doesn't

		** support other secondary bus types (eg. E/ISA) directly.

		** May be needed for other processor (eg IA64) architectures

		** or by some ambitous soul who wants to watch TV.

 PCI_BRIDGE_FUNCS */

		/*

		** Proposal #2:

		** The "pin" is skewed ((pin + dev - 1) % 4).

		**

		** This isn't very clean since I/O SAPIC must assume:

		**   - all platforms only have PCI busses.

		**   - only PCI-PCI bridge (eg not PCI-EISA, PCI-PCMCIA)

		**   - IRQ routing is only skewed once regardless of

		**     the number of PPB's between iosapic and device.

		**     (Bit3 expansion chassis follows this rule)

		**

		** Advantage is it's really easy to implement.

 PCI_BRIDGE_FUNCS */

		/*

		 * Locate the host slot of the PPB.

 Read the window register to flush the writes down to HW  */

 Read the window register to flush the writes down to HW  */

/*

** set_irt prepares the data (dp0, dp1) according to the vector_info

** and target cpu (id_eid).  dp0/dp1 are then used to program I/O SAPIC

** IRdT for the given "vector" (aka IRQ line).

	/*

	** IA64 REVISIT

	** PA doesn't support EXTINT or LPRIO bits.

	/*

	** Extracting id_eid isn't a real clean way of getting it.

	** But the encoding is the same for both PA and IA64 platforms.

		/*

		** PAT PDC just hands it to us "right".

		** txn_addr comes from cpu_data[x].txn_addr.

		/* 

		** eg if base_addr == 0xfffa0000),

		**    we want to get 0xa0ff0000.

		**

		** eid	0x0ff00000 -> 0x00ff0000

		** id	0x000ff000 -> 0xff000000

 data is initialized by fixup_irq */

	/*

	 * Issuing I/O SAPIC an EOI causes an interrupt IFF IRQ line is

	 * asserted.  IRQ generally should not be asserted when a driver

	 * enables their IRQ. It can lead to "interesting" race conditions

	 * in the driver initialization sequence.

	/* d1 contains the destination CPU, so only want to set that

 only used if PAT PDC */

 line used by device */

	/*

	 * HACK ALERT! (non-compliant PCI device support)

	 *

	 * All SuckyIO interrupts are routed through the PIC's on function 1.

	 * But SuckyIO OHCI USB controller gets an IRT entry anyway because

	 * it advertises INT D for INT_PIN.  Use that IRT entry to get the

	 * SuckyIO interrupt routing for PICs on function 1 (*BLEECCHH*).

 We must call superio_fixup_irq() to register the pdev */

 Don't return if need to program the IOSAPIC's IRT... */

 CONFIG_SUPERIO */

 lookup IRT entry for isi/slot/pin set */

 get vector info for this input line */

 If this IRQ line has already been setup, skip it */

	/*

	 * Allocate processor IRQ

	 *

	 * XXX/FIXME The txn_alloc_irq() code and related code should be

	 * moved to enable_irq(). That way we only allocate processor IRQ

	 * bits for devices that actually have drivers claiming them.

	 * Right now we assign an IRQ to every PCI device present,

	 * regardless of whether it's used or not.

 enable_irq() will use txn_* to program IRdT */

 lookup IRT entry for isi/slot/pin set */

 no irq found, force polling */

 search for iosapic */

 no iosapic found, force polling */

 get vector info for this input line */

 If this IRQ line has already been setup, skip it */

	/*

	 * Allocate processor IRQ

	 *

	 * XXX/FIXME The txn_alloc_irq() code and related code should be

	 * moved to enable_irq(). That way we only allocate processor IRQ

	 * bits for devices that actually have drivers claiming them.

	 * Right now we assign an IRQ to every PCI device present,

	 * regardless of whether it's used or not.

 enable_irq() will use txn_* to program IRdT */

/*

** squirrel away the I/O Sapic Version

/*

** iosapic_register() is called by "drivers" with an integrated I/O SAPIC.

** Caller must be certain they have an I/O SAPIC and know its MMIO address.

**

**	o allocate iosapic_info and add it to the list

**	o read iosapic version and squirrel that away

**	o read size of IRdT.

**	o allocate and initialize isi_vector[]

**	o allocate irq region

 track how many entries we've looked at */

	/*

	 * Astro based platforms can only support PCI OLARD if they implement

	 * PAT PDC.  Legacy PDC omits LBAs with no PCI devices from the IRT.

	 * Search the IRT and ignore iosapic's which aren't in the IRT.

 DEBUG_IOSAPIC */

 SPDX-License-Identifier: GPL-2.0-only

/* 

 *    Interfaces to retrieve and set PDC Stable options (firmware)

 *

 *    Copyright (C) 2005-2006 Thibaut VARENE <varenet@parisc-linux.org>

 *

 *    DEV NOTE: the PDC Procedures reference states that:

 *    "A minimum of 96 bytes of Stable Storage is required. Providing more than

 *    96 bytes of Stable Storage is optional [...]. Failure to provide the

 *    optional locations from 96 to 192 results in the loss of certain

 *    functionality during boot."

 *

 *    Since locations between 96 and 192 are the various paths, most (if not

 *    all) PA-RISC machines should have them. Anyway, for safety reasons, the

 *    following code can deal with just 96 bytes of Stable Storage, and all

 *    sizes between 96 and 192 bytes (provided they are multiple of struct

 *    device_path size, eg: 128, 160 and 192) to provide full information.

 *    One last word: there's one path we can always count on: the primary path.

 *    Anything above 224 bytes is used for 'osdep2' OS-dependent storage area.

 *

 *    The first OS-dependent area should always be available. Obviously, this is

 *    not true for the other one. Also bear in mind that reading/writing from/to

 *    osdep2 is much more expensive than from/to osdep1.

 *    NOTE: We do not handle the 2 bytes OS-dep area at 0x5D, nor the first

 *    2 bytes of storage available right after OSID. That's a total of 4 bytes

 *    sacrificed: -ETOOLAZY :P

 *

 *    The current policy wrt file permissions is:

 *	- write: root only

 *	- read: (reading triggers PDC calls) ? root only : everyone

 *    The rationale is that PDC calls could hog (DoS) the machine.

 *

 *	TODO:

 *	- timer/fastsize write calls

 holds Stable Storage size. Initialized once and for all, no lock needed */

 holds OS ID. Initialized once and for all, hopefully to 0x0006 */

 This struct defines what we need to deal with a parisc pdc path entry */

 to protect path entry access */

 entry record is valid if != 0 */

 entry address in stable storage */

 entry name */

 device path in parisc representation */

 corresponding device */

/**

 * pdcspath_fetch - This function populates the path entry structs.

 * @entry: A pointer to an allocated pdcspath_entry.

 * 

 * The general idea is that you don't read from the Stable Storage every time

 * you access the files provided by the facilities. We store a copy of the

 * content of the stable storage WRT various paths in these structs. We read

 * these structs when reading the files, and we will write to these structs when

 * writing to the files, and only then write them back to the Stable Storage.

 *

 * This function expects to be called with @entry->rw_lock write-hold.

 addr, devpath and count must be word aligned */

	/* Find the matching device.

	   NOTE: hardware_path overlays with device_path, so the nice cast can

/**

 * pdcspath_store - This function writes a path to stable storage.

 * @entry: A pointer to an allocated pdcspath_entry.

 * 

 * It can be used in two ways: either by passing it a preset devpath struct

 * containing an already computed hardware path, or by passing it a device

 * pointer, from which it'll find out the corresponding hardware path.

 * For now we do not handle the case where there's an error in writing to the

 * Stable Storage area, so you'd better not mess up the data :P

 *

 * This function expects to be called with @entry->rw_lock write-hold.

	/* We expect the caller to set the ready flag to 0 if the hardware

	   path struct provided is invalid, so that we know we have to fill it.

 ...but we have a device, map it */

 else, we expect the provided hwpath to be valid. */

 addr, devpath and count must be word aligned */

 kobject is already registered */

/**

 * pdcspath_hwpath_read - This function handles hardware path pretty printing.

 * @entry: An allocated and populated pdscpath_entry struct.

 * @buf: The output buffer to write to.

 * 

 * We will call this function to format the output of the hwpath attribute file.

 entry is not ready */

/**

 * pdcspath_hwpath_write - This function handles hardware path modifying.

 * @entry: An allocated and populated pdscpath_entry struct.

 * @buf: The input buffer to read from.

 * @count: The number of bytes to be read.

 * 

 * We will call this function to change the current hardware path.

 * Hardware paths are to be given '/'-delimited, without brackets.

 * We make sure that the provided path actually maps to an existing

 * device, BUT nothing would prevent some foolish user to set the path to some

 * PCI bridge or even a CPU...

 * A better work around would be to make sure we are at the end of a device tree

 * for instance, but it would be IMHO beyond the simple scope of that driver.

 * The aim is to provide a facility. Data correctness is left to userland.

 We'll use a local copy of buf */

 Let's clean up the target. 0xff is a blank pattern */

 First, pick the mod field (the last one of the input string) */

 truncate the remaining string. just precaution */

	/* Then, loop for each delimiter, making sure we don't have too many.

	   we write the bc fields in a down-top way. No matter what, we stop

	   before writing the last field. If there are too many fields anyway,

	   then the user is a moron and it'll be caught up later when we'll

 Store the final field */		

 Now we check that the user isn't trying to lure us */

 So far so good, let's get in deep */

 Now, dive in. Write back to the hardware */

 Update the symlink to the real device */

/**

 * pdcspath_layer_read - Extended layer (eg. SCSI ids) pretty printing.

 * @entry: An allocated and populated pdscpath_entry struct.

 * @buf: The output buffer to write to.

 * 

 * We will call this function to format the output of the layer attribute file.

 entry is not ready */

/**

 * pdcspath_layer_write - This function handles extended layer modifying.

 * @entry: An allocated and populated pdscpath_entry struct.

 * @buf: The input buffer to read from.

 * @count: The number of bytes to be read.

 * 

 * We will call this function to change the current layer value.

 * Layers are to be given '.'-delimited, without brackets.

 * XXX beware we are far less checky WRT input data provided than for hwpath.

 * Potential harm can be done, since there's no way to check the validity of

 * the layer fields.

 device-specific info (ctlr#, unit#, ...) */

 We'll use a local copy of buf */

 Let's clean up the target. 0 is a blank pattern */

 First, pick the first layer */

 So far so good, let's get in deep */

	/* First, overwrite the current layers with the new ones, not touching

 Now, dive in. Write back to the hardware */

/**

 * pdcspath_attr_show - Generic read function call wrapper.

 * @kobj: The kobject to get info from.

 * @attr: The attribute looked upon.

 * @buf: The output buffer.

/**

 * pdcspath_attr_store - Generic write function call wrapper.

 * @kobj: The kobject to write info to.

 * @attr: The attribute to be modified.

 * @buf: The input buffer.

 * @count: The size of the buffer.

 These are the two attributes of any PDC path. */

 Specific kobject type for our PDC paths */

 We hard define the 4 types of path we expect to find */

 An array containing all PDC paths we will deal with */

/* For more insight of what's going on here, refer to PDC Procedures doc,

/**

 * pdcs_size_read - Stable Storage size output.

 * @buf: The output buffer to write to.

 show the size of the stable storage */

/**

 * pdcs_auto_read - Stable Storage autoboot/search flag output.

 * @buf: The output buffer to write to.

 * @knob: The PF_AUTOBOOT or PF_AUTOSEARCH flag

 Current flags are stored in primary boot path entry */

/**

 * pdcs_autoboot_read - Stable Storage autoboot flag output.

 * @buf: The output buffer to write to.

/**

 * pdcs_autosearch_read - Stable Storage autoboot flag output.

 * @buf: The output buffer to write to.

/**

 * pdcs_timer_read - Stable Storage timer count output (in seconds).

 * @buf: The output buffer to write to.

 *

 * The value of the timer field correponds to a number of seconds in powers of 2.

 Current flags are stored in primary boot path entry */

 print the timer value in seconds */

/**

 * pdcs_osid_read - Stable Storage OS ID register output.

 * @buf: The output buffer to write to.

/**

 * pdcs_osdep1_read - Stable Storage OS-Dependent data area 1 output.

 * @buf: The output buffer to write to.

 *

 * This can hold 16 bytes of OS-Dependent data.

/**

 * pdcs_diagnostic_read - Stable Storage Diagnostic register output.

 * @buf: The output buffer to write to.

 *

 * I have NFC how to interpret the content of that register ;-).

 get diagnostic */

/**

 * pdcs_fastsize_read - Stable Storage FastSize register output.

 * @buf: The output buffer to write to.

 *

 * This register holds the amount of system RAM to be tested during boot sequence.

 get fast-size */

/**

 * pdcs_osdep2_read - Stable Storage OS-Dependent data area 2 output.

 * @buf: The output buffer to write to.

 *

 * This can hold pdcs_size - 224 bytes of OS-Dependent data, when available.

/**

 * pdcs_auto_write - This function handles autoboot/search flag modifying.

 * @buf: The input buffer to read from.

 * @count: The number of bytes to be read.

 * @knob: The PF_AUTOBOOT or PF_AUTOSEARCH flag

 * 

 * We will call this function to change the current autoboot flag.

 * We expect a precise syntax:

 *	\"n\" (n == 0 or 1) to toggle AutoBoot Off or On

 We'll use a local copy of buf */

 Current flags are stored in primary boot path entry */

 Be nice to the existing flag record */

 So far so good, let's get in deep */

 Change the path entry flags first */

 Now, dive in. Write back to the hardware */

/**

 * pdcs_autoboot_write - This function handles autoboot flag modifying.

 * @buf: The input buffer to read from.

 * @count: The number of bytes to be read.

 *

 * We will call this function to change the current boot flags.

 * We expect a precise syntax:

 *	\"n\" (n == 0 or 1) to toggle AutoSearch Off or On

/**

 * pdcs_autosearch_write - This function handles autosearch flag modifying.

 * @buf: The input buffer to read from.

 * @count: The number of bytes to be read.

 *

 * We will call this function to change the current boot flags.

 * We expect a precise syntax:

 *	\"n\" (n == 0 or 1) to toggle AutoSearch Off or On

/**

 * pdcs_osdep1_write - Stable Storage OS-Dependent data area 1 input.

 * @buf: The input buffer to read from.

 * @count: The number of bytes to be read.

 *

 * This can store 16 bytes of OS-Dependent data. We use a byte-by-byte

 * write approach. It's up to userspace to deal with it when constructing

 * its input buffer.

 We'll use a local copy of buf */

/**

 * pdcs_osdep2_write - Stable Storage OS-Dependent data area 2 input.

 * @buf: The input buffer to read from.

 * @count: The number of bytes to be read.

 *

 * This can store pdcs_size - 224 bytes of OS-Dependent data. We use a

 * byte-by-byte write approach. It's up to userspace to deal with it when

 * constructing its input buffer.

 We'll use a local copy of buf */

 The remaining attributes. */

/**

 * pdcs_register_pathentries - Prepares path entries kobjects for sysfs usage.

 * 

 * It creates kobjects corresponding to each path entry with nice sysfs

 * links to the real device. This is where the magic takes place: when

 * registering the subsystem attributes during module init, each kobject hereby

 * created will show in the sysfs tree as a folder containing files as defined

 * by path_subsys_attr[].

 Initialize the entries rw_lock before anything else */

 kobject is now registered */

 Add a nice symlink to the real device */

/**

 * pdcs_unregister_pathentries - Routine called when unregistering the module.

/*

 * For now we register the stable subsystem with the firmware subsystem

 * and the paths subsystem with the stable subsystem

 find the size of the stable storage */

 make sure we have enough data */

 get OSID */

 the actual result is 16 bits away */

 For now we'll register the directory at /sys/firmware/stable */

 Don't forget the root entries */

 register the paths kset as a child of the stable kset */

 now we create all "files" for the paths kset */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

** hppb.c:

**      HP-PB bus driver for the NOVA and K-Class systems.

**

**      (c) Copyright 2002 Ryan Bradetich

**      (c) Copyright 2002 Hewlett-Packard Company

**

**

/**

 * hppb_probe - Determine if the hppb driver should claim this device.

 * @dev: The device which has been found

 *

 * Determine if hppb driver should claim this chip (return 0) or not 

 * (return 1). If so, initialize the chip and tell other partners in crime 

 * they have work to do.

 E25 and K */

 E35 */

 E45 */

 E55 */

/**

 * hppb_init - HP-PB bus initialization procedure.

 *

 * Register this driver.   

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	LASI Device Driver

 *

 *	(c) Copyright 1999 Red Hat Software

 *	Portions (c) Copyright 1999 The Puffin Group Inc.

 *	Portions (c) Copyright 1999 Hewlett-Packard

 *

 *	by Alan Cox <alan@redhat.com> and 

 * 	   Alex deVries <alex@onefishtwo.ca>

 LASI Version */

 LASI primary configuration register */

 LASI secondary configuration register */

 Centronics */

 Audio */

 Lasi itself */

 SCSI */

 Floppy */

 PS/2 Keyboard */

 ISDN */

 LAN */

 RS232 */

 Telephone */

 unknown */

 Stop LASI barking for a bit */

 clear pending interrupts */

	/* We're not really convinced we want to reset the onboard

         * devices. Firmware does it for us...

 Resets */

 gsc_writel(0xFFFFFFFF, lasi_base+0x2000);*/	
 Audio */

 gsc_writel(0xFFFFFFFF, lasi_base+0x5000);*/	
 gsc_writel(0xFFFFFFFF, lasi_base+0x6000);*/	
 LAN */

 Keyboard */

 FDC */

	/* Ok we hit it on the head with a hammer, our Dog is now

	** comatose and muzzled.  Devices will now unmask LASI

	** interrupts as they are registered as irq's in the LASI range.

	/* XXX: I thought it was `awks that got `it on the `ead with an

	 * `ammer.  -- willy

/*

   ** lasi_led_init()

   ** 

   ** lasi_led_init() initializes the LED controller on the LASI.

   **

   ** Since Mirage and Electra machines use a different LED

   ** address register, we need to check for these machines 

   ** explicitly.

 nothing */

	/* Gecko machines have only one single LED, which can be permanently 

 Gecko (712/60) */

 Gecko (712/80) */

 Gecko (712/100) */

 Anole 64 (743/64) */

 Anole 100 (743/100) */

 Gecko (712/120) */

 no need to register the LED interrupt-function */  

 Mirage and Electra machines need special offsets */

 Mirage Jr (715/64) */

 Mirage 100 */

 Mirage 100+ */

 Electra 100 */

 Electra 120 */

/*

 * lasi_power_off

 *

 * Function for lasi to turn off the power.  This is accomplished by setting a

 * 1 to PWR_ON_L in the Power Control Register

 * 

 calculate addr of the Power Control Register */

 Power down the machine */

 Check the 4-bit (yes, only 4) version register */

 initialize the chassis LEDs really early */ 

 Stop LASI barking for a bit */

 the IRQ lasi should use */

 enable IRQ's for devices below LASI */

 Done init'ing, register this driver */

 initialize the power off function */

	/* FIXME: Record the LASI HPA for the power off function.  This should

	 * ensure that only the first LASI (the one controlling the power off)

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	ASP Device Driver

 *

 *	(c) Copyright 2000 The Puffin Group Inc.

 *

 *	by Helge Deller <deller@gmx.de>

 hardcoded interrupt for GSC */

 offset of ASP version */

 addr of viper interrupt word */

 SCSI */

 LAN */

 HIL */

 Centronics */

 RS232 */

 EISA BA */

 Graphics1 */

 Audio (Bushmaster) */

 Audio (Scorpio) */

 FW SCSI */

 FDDI */

 Audio (Outfield) */

 Unknown */

 i8042 High-priority */

 EISA BA */

 Other */

/* There are two register ranges we're interested in.  Interrupt /

 * Status / LED are at 0xf080xxxx and Asp special registers are at

 * 0xf082fxxx.  PDC only tells us that Asp is at 0xf082f000, so for

 * the purposes of interrupt handling, we have to tell other bits of

 * the kernel to look at the other registers.

 the IRQ ASP should use */

 Program VIPER to interrupt on the ASP irq */

 Done init'ing, register this driver */

 Mongoose is a sibling of Asp, not a child... */

 initialize the chassis LEDs */ 

 SPDX-License-Identifier: GPL-2.0-or-later

/*

**  System Bus Adapter (SBA) I/O MMU manager

**

**	(c) Copyright 2000-2004 Grant Grundler <grundler @ parisc-linux x org>

**	(c) Copyright 2004 Naresh Kumar Inna <knaresh at india x hp x com>

**	(c) Copyright 2000-2004 Hewlett-Packard Company

**

**	Portions (c) 1999 Dave S. Miller (from sparc64 I/O MMU code)

**

**

**

** This module initializes the IOC (I/O Controller) found on B1000/C3000/

** J5000/J7000/N-class/L-class machines and their successors.

**

** FIXME: add DMA hint support programming in both sba and lba modules.

 for DMA_CHUNK_SIZE */

 for register_parisc_driver() stuff */

 for proc_mckinley_root */

 for proc_runway_root */

 for PAGE0 */

 for PDC_MODEL_* */

 for is_pdc_pat() */

/*

** The number of debug flags is a clue - this code is fragile.

** Don't even think about messing with it unless you have

** plenty of 710's to sacrifice to the computer gods. :^)

 global count of IOMMUs in the system */

 PA8700 (Piranha 2.2) bug workaround */

 Looks nice and keeps the compiler happy */

CONFIG_AGP_PARISC*/

/************************************

** SBA register read and write support

**

** BE WARNED: register writes are posted.

**  (ie follow writes which must reach HW with a read)

**

** Superdome (in particular, REO) allows only 64-bit CSR accesses.

 NOTE: When CONFIG_64BIT isn't defined, READ_REG64() is two 32-bit reads */

/**

 * sba_dump_ranges - debugging only - print ranges assigned to this IOA

 * @hpa: base address of the sba

 *

 * Print the MMIO and IO Port address ranges forwarded by an Astro/Ike/RIO

 * IO Adapter (aka Bus Converter).

/**

 * sba_dump_tlb - debugging only - print IOMMU operating parameters

 * @hpa: base address of the IOMMU

 *

 * Print the size/location of the IO MMU PDIR.

 DEBUG_SBA_INIT */

/**

 * sba_dump_pdir_entry - debugging only - print one IOMMU PDIR entry

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @msg: text to print ont the output line.

 * @pide: pdir index.

 *

 * Print one entry of the IO MMU PDIR in human readable form.

 start printing from lowest pde in rval */

/**

 * sba_check_pdir - debugging only - consistency checker

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @msg: text to print ont the output line.

 *

 * Verify the resource map and pdir state is consistent

 resource map ptr */

 pdir ptr */

 number of bits we might check */

 Get last byte and highest bit from that */

				/*

				** BUMMER!  -- res_map != pdir --

				** Dump rval and matching pdir entries

 try the next bit */

 look at next word of res_map */

 It'd be nice if we always got here :^) */

/**

 * sba_dump_sg - debugging only - print Scatter-Gather list

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @startsg: head of the SG list

 * @nents: number of entries in SG list

 *

 * print the SG list so we can verify it's correct by hand.

 ASSERT_PDIR_SANITY */

/**************************************************************

*

*   I/O Pdir Resource Management

*

*   Bits set in the resource map are in use.

*   Each bit can represent a number of pages.

*   LSbs represent lower addresses (IOVA's).

*

 could increase this to 4 or 8 if needed */

 Convert from IOVP to IOVA and vice versa. */

 Pluto (aka ZX1) boxes need to set or clear the ibase bits appropriately */

 only support Astro and ancestors. Saves a few cycles in key places */

/**

 * sba_search_bitmap - find free space in IO PDIR resource bitmap

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @bits_wanted: number of entries we need.

 *

 * Find consecutive free bits in resource bitmap.

 * Each bit represents one entry in the IO Pdir.

 * Cool perf optimization: search for log2(size) bits at a time.

 Search word at a time - no mask needed */

 point to the next word on next pass */

		/*

		** Search the resource bit map on well-aligned values.

		** "o" is the alignment.

		** We need the alignment to invalidate I/O TLB using

		** SBA HW features in the unmap path.

 mark resources busy! */

 look in the same word on the next pass */

 wrapped ? */

/**

 * sba_alloc_range - find free bits and mark them in IO PDIR resource bitmap

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @size: number of bytes to create a mapping for

 *

 * Given a size, find consecutive unmarked and then mark those bits in the

 * resource bit map.

 verify the first enable bit is clear */

 check for roll over */

/**

 * sba_free_range - unmark bits in IO PDIR resource bitmap

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @iova: IO virtual address which was previously allocated.

 * @size: number of bytes to create a mapping for

 *

 * clear bits in the ioc's resource map

 convert bit to byte address */

 3-bits "bit" address plus 2 (or 3) bits for "byte" == bit in word */

/**************************************************************

*

*   "Dynamic DMA Mapping" support (aka "Coherent I/O")

*

/**

 * sba_io_pdir_entry - fill in one IO PDIR entry

 * @pdir_ptr:  pointer to IO PDIR entry

 * @sid: process Space ID - currently only support KERNEL_SPACE

 * @vba: Virtual CPU address of buffer to map

 * @hint: DMA hint set to use for this mapping

 *

 * SBA Mapping Routine

 *

 * Given a virtual address (vba, arg2) and space id, (sid, arg1)

 * sba_io_pdir_entry() loads the I/O PDIR entry pointed to by

 * pdir_ptr (arg0). 

 * Using the bass-ackwards HP bit numbering, Each IO Pdir entry

 * for Astro/Ike looks like:

 *

 *

 *  0                    19                                 51   55       63

 * +-+---------------------+----------------------------------+----+--------+

 * |V|        U            |            PPN[43:12]            | U  |   VI   |

 * +-+---------------------+----------------------------------+----+--------+

 *

 * Pluto is basically identical, supports fewer physical address bits:

 *

 *  0                       23                              51   55       63

 * +-+------------------------+-------------------------------+----+--------+

 * |V|        U               |         PPN[39:12]            | U  |   VI   |

 * +-+------------------------+-------------------------------+----+--------+

 *

 *  V  == Valid Bit  (Most Significant Bit is bit 0)

 *  U  == Unused

 * PPN == Physical Page Number

 * VI  == Virtual Index (aka Coherent Index)

 *

 * LPA instruction output is put into PPN field.

 * LCI (Load Coherence Index) instruction provides the "VI" bits.

 *

 * We pre-swap the bytes since PCX-W is Big Endian and the

 * IOMMU uses little endian for the pdir.

 physical address */

 coherent index */

 move CI (8 bits) into lowest byte */

 set "valid" bit */

 swap and store into I/O Pdir */

	/*

	 * If the PDC_MODEL capabilities has Non-coherent IO-PDIR bit set

	 * (bit #61, big endian), we have to flush and sync every time

	 * IO-PDIR is changed in Ike/Astro.

/**

 * sba_mark_invalid - invalidate one or more IO PDIR entries

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @iova:  IO Virtual Address mapped earlier

 * @byte_cnt:  number of bytes this mapping covers.

 *

 * Marking the IO PDIR entry(ies) as Invalid and invalidate

 * corresponding IO TLB entry. The Ike PCOM (Purge Command Register)

 * is to purge stale entries in the IO TLB when unmapping entries.

 *

 * The PCOM register supports purging of multiple pages, with a minium

 * of 1 page and a maximum of 2GB. Hardware requires the address be

 * aligned to the size of the range being purged. The size of the range

 * must be a power of 2. The "Cool perf optimization" in the

 * allocation routine helps keep that true.

	/* Assert first pdir entry is set.

	**

	** Even though this is a big-endian machine, the entries

	** in the iopdir are little endian. That's why we look at

	** the byte at +7 instead of at +0.

 set "size" field for PCOM */

 clear I/O Pdir entry "valid" bit first */

 set "size" field for PCOM */

	/*

	** clear I/O PDIR entry "valid" bit.

	** We have to R/M/W the cacheline regardless how much of the

	** pdir entry that we clobber.

	** The rest of the entry would be useful for debugging if we

	** could dump core on HPMC.

/**

 * sba_dma_supported - PCI driver can query DMA support

 * @dev: instance of PCI owned by the driver that's asking

 * @mask:  number of address bits this PCI device can handle

 *

 * See Documentation/core-api/dma-api-howto.rst

	/*

	 * check if mask is >= than the current max IO Virt Address

	 * The max IO Virt address will *always* < 30 bits.

/**

 * sba_map_single - map one buffer and return IOVA for DMA

 * @dev: instance of PCI owned by the driver that's asking.

 * @addr:  driver buffer to map.

 * @size:  number of bytes to map in driver buffer.

 * @direction:  R/W or both.

 *

 * See Documentation/core-api/dma-api-howto.rst

 save offset bits */

 round up to nearest IOVP_SIZE */

 force FDC ops in io_pdir_entry() to be visible to IOMMU */

 form complete address */

/**

 * sba_unmap_page - unmap one IOVA and free resources

 * @dev: instance of PCI owned by the driver that's asking.

 * @iova:  IOVA of driver buffer previously mapped.

 * @size:  number of bytes mapped in driver buffer.

 * @direction:  R/W or both.

 *

 * See Documentation/core-api/dma-api-howto.rst

 clear offset bits */

	/* Delaying when we re-use a IO Pdir entry reduces the number

	 * of MMIO reads needed to flush writes to the PCOM register.

 flush purges */

 DELAYED_RESOURCE_CNT == 0 */

 If fdc's were issued, force fdc's to be visible now */

 flush purges */

 DELAYED_RESOURCE_CNT == 0 */

	/* XXX REVISIT for 2.5 Linux - need syncdma for zero-copy support.

	** For Astro based systems this isn't a big deal WRT performance.

	** As long as 2.4 kernels copyin/copyout data from/to userspace,

	** we don't need the syncdma. The issue here is I/O MMU cachelines

	** are *not* coherent in all cases.  May be hwrev dependent.

	** Need to investigate more.

	asm volatile("syncdma");	

/**

 * sba_alloc - allocate/map shared mem for DMA

 * @hwdev: instance of PCI owned by the driver that's asking.

 * @size:  number of bytes mapped in driver buffer.

 * @dma_handle:  IOVA of new buffer.

 *

 * See Documentation/core-api/dma-api-howto.rst

 only support PCI */

/**

 * sba_free - free/unmap shared mem for DMA

 * @hwdev: instance of PCI owned by the driver that's asking.

 * @size:  number of bytes mapped in driver buffer.

 * @vaddr:  virtual address IOVA of "consistent" buffer.

 * @dma_handler:  IO virtual address of "consistent" buffer.

 *

 * See Documentation/core-api/dma-api-howto.rst

/*

** Since 0 is a valid pdir_base index value, can't use that

** to determine if a value is valid or not. Use a flag to indicate

** the SG list entry contains a valid pdir index.

/**

 * sba_map_sg - map Scatter/Gather list

 * @dev: instance of PCI owned by the driver that's asking.

 * @sglist:  array of buffer/length pairs

 * @nents:  number of entries in list

 * @direction:  R/W or both.

 *

 * See Documentation/core-api/dma-api-howto.rst

 Fast path single entry scatterlists. */

	/*

	** First coalesce the chunks and allocate I/O pdir space

	**

	** If this is one DMA stream, we can properly map using the

	** correct virtual address associated with each DMA page.

	** w/o this association, we wouldn't have coherent DMA!

	** Access to the virtual address is what forces a two pass algorithm.

	/*

	** Program the I/O Pdir

	**

	** map the virtual addresses to the I/O Pdir

	** o dma_address will contain the pdir index

	** o dma_len will contain the number of bytes to map 

	** o address contains the virtual address.

 force FDC ops in io_pdir_entry() to be visible to IOMMU */

/**

 * sba_unmap_sg - unmap Scatter/Gather list

 * @dev: instance of PCI owned by the driver that's asking.

 * @sglist:  array of buffer/length pairs

 * @nents:  number of entries in list

 * @direction:  R/W or both.

 *

 * See Documentation/core-api/dma-api-howto.rst

 kluge since call is unmap_sg() */

/**************************************************************************

**

**   SBA PAT PDC support

**

**   o call pdc_pat_cell_module()

**   o store ranges in PCI "resource" structures

**

/*

** TODO/REVISIT/FIXME: support for directed ranges requires calls to

**      PAT PDC to program the SBA/LBA directed range registers...this

**      burden may fall on the LBA code since it directly supports the

**      PCI subsystem. It's not clear yet. - ggg

/**************************************************************

*

*   Initialization and claim

*

 bit 17,18,20 */

 bit 17,18 on */

	/* If this is not PA8700 (PCX-W2)

	**	OR newer than ver 2.2

	**	OR in a system that doesn't need VINDEX bits from SBA,

	**

	** then we aren't exposed to the HW bug.

	/*

	 * PA8700 (PCX-W2, aka piranha) silent data corruption fix

	 *

	 * An interaction between PA8700 CPU (Ver 2.2 or older) and

	 * Ike/Astro can cause silent data corruption. This is only

	 * a problem if the I/O PDIR is located in memory such that

	 * (little-endian)  bits 17 and 18 are on and bit 20 is off.

	 *

	 * Since the max IO Pdir size is 2MB, by cleverly allocating the

	 * right physical address, we can either avoid (IOPDIR <= 1MB)

	 * or minimize (2MB IO Pdir) the problem if we restrict the

	 * IO Pdir to a maximum size of 2MB-128K (1902K).

	 *

	 * Because we always allocate 2^N sized IO pdirs, either of the

	 * "bad" regions will be the last 128K if at all. That's easy

	 * to test for.

	 * 

 allocate a new one on 512k alignment */

 release original */

 release excess */

		/*

		** 1MB or 2MB Pdir

		** Needs to be aligned on an "odd" 1MB boundary.

 2 or 4MB */

 release original */

 release first 1MB */

			/*

			** 2MB Pdir.

			**

			** Flag tells init_bitmap() to mark bad 128k as used

			** and to reduce the size by 128k.

 release last 1MB */

 release unusable 128KB */

 lba_set_iregs() is in drivers/parisc/lba_pci.c */

 setup Mercury or Elroy IBASE/IMASK registers. */

	/*

	** Firmware programs the base and size of a "safe IOVA space"

	** (one that doesn't overlap memory or LMMIO space) in the

	** IBASE and IMASK registers.

	/*

	** iov_order is always based on a 1GB IOVA space since we want to

	** turn on the other half for AGP GART.

 build IMASK for IOC and Elroy */

	/*

	** Setting the upper bits makes checking for bypass addresses

	** a little faster later on.

 Set I/O PDIR Page size to system page size */

  4K */

  8K */

 16K */

 64K */

	/*

	** Program the IOC's ibase and enable IOVA translation

	** Bit zero == enable bit.

	/*

	** Clear I/O TLB of any possible entries.

	** (Yes. This is a bit paranoid...but so what)

	/*

	** If an AGP device is present, only use half of the IOV space

	** for PCI DMA.  Unfortunately we can't know ahead of time

	** whether GART support will actually be used, for now we

	** can just key on any AGP device found in the system.

	** We program the next pdir index after we stop w/ a key for

	** the GART code to handshake on.

SBA_AGP_SUPPORT*/

	/*

	** Determine IOVA Space size from memory size.

	**

	** Ideally, PCI drivers would register the maximum number

	** of DMA they can have outstanding for each device they

	** own.  Next best thing would be to guess how much DMA

	** can be outstanding based on PCI Class/sub-class. Both

	** methods still require some "extra" to support PCI

	** Hot-Plug/Removal of PCI cards. (aka PCI OLARD).

	**

	** While we have 32-bits "IOVA" space, top two 2 bits are used

	** for DMA hints - ergo only 30 bits max.

 limit IOVA space size to 1MB-1GB */

	/*

	** iova space must be log2() in size.

	** thus, pdir/res_map will also be log2().

	** PIRANHA BUG: Exception is when IO Pdir is 2MB (gets reduced)

 iova_space_size is now bytes, not pages */

 FIXME : DMA HINTs not used */

 build IMASK for IOC and Elroy */

	/*

	** On C3000 w/512MB mem, HP-UX 10.20 reports:

	**     ibase=0, imask=0xFE000000, size=0x2000000.

 save it */

	/*

	** FIXME: Hint registers are programmed with default hint

	** values during boot, so hints should be sane even if we

	** can't reprogram them the way drivers want.

	/*

	** Program the IOC's ibase and enable IOVA translation

 Set I/O PDIR Page size to system page size */

  4K */

  8K */

 16K */

 64K */

 Set I/O PDIR Page size to PAGE_SIZE (4k/16k/...) */

	/*

	** Clear I/O TLB of any possible entries.

	** (Yes. This is a bit paranoid...but so what)

 used by SBA_IOVA and related macros */	

/**************************************************************************

**

**   SBA initialization code (HW and SW)

**

**   o identify SBA chip itself

**   o initialize SBA chip modes (HardFail)

**   o initialize SBA chip modes (HardFail)

**   o FIXME: initialize DMA hints for reasonable defaults

**

		/* Shutdown the USB controller on Astro-based workstations.

		** Once we reprogram the IOMMU, the next DMA performed by

		** USB will HPMC the box. USB is only enabled if a

		** keyboard is present and found.

		**

		** With serial console, j6k v5.0 firmware says:

		**   mem_kbd hpa 0xfee003f8 sba 0x0 pad 0x0 cl_class 0x7

		**

		** FIXME: Using GFX+USB console at power up but direct

		**	linux to serial console is still broken.

		**	USB could generate DMA so we must reset USB.

		**	The proper sequence would be:

		**	o block console output

		**	o reset USB device

		**	o reprogram serial port

		**	o unblock console output

	/*

	** Need to deal with DMA from LAN.

	**	Maybe use page zero boot device as a handle to talk

	**	to PDC about which device to shutdown.

	**

	** Netbooting, j6k v5.0 firmware says:

	** 	mem_boot hpa 0xf4008000 sba 0x0 pad 0x0 cl_class 0x1002

	** ARGH! invalid class.

 j6700 v1.6 firmware sets 0x294f */

 A500 firmware sets 0x4d */

 if !PLUTO */

 IKE, REO */

 TODO - LOOKUP Ike/Stretch chipset mem map */

 XXX: What about Reo Grande? */

			/*

			 * Clear ROPE(N)_CONFIG AO bit.

			 * Disables "NT Ordering" (~= !"Relaxed Ordering")

			 * Overrides bit 1 in DMA Hint Sets.

			 * Improves netperf UDP_STREAM by ~10% for bcm5701.

			/*

			** Make sure the box crashes on rope errors.

 flush out the last writes */

	/* add this one to the head of the list (order doesn't matter)

	** This will be useful for debugging - especially if we get coredumps

 resource map size dictated by pdir_size */

 entries */

 Second part of PIRANHA BUG */

 convert bit count to byte count */

 next available IOVP - circular search */

 Mark first bit busy - ie no IOVA 0 */

 Third (and last) part of PIRANHA BUG */

 region from +1408K to +1536 is un-usable. */

 mark that part of the io pdir busy */

	/*

	 * If the PDC_MODEL capabilities has Non-coherent IO-PDIR bit set

	 * (bit #61, big endian), we have to flush and sync every time

	 * IO-PDIR is changed in Ike/Astro.

 FIXME: Multi-IOC support! */

 8 bits per byte */

 8 bits/byte */

 8 bits per byte */

 KLUGE - unmap_sg calls unmap_single for each mapped page */

 FIXME: Multi-IOC support! */

 CONFIG_PROC_FS */

/*

** Determine if sba should claim this chip (return 0) or not (return 1).

** If so, initialize the chip and tell other partners in crime they

** have work to do.

 Read HW Rev First */

 Astro is broken...Read HW Rev First */

 Astro and Pluto have one IOC per SBA */

/*

** One time initialization to let the world know the SBA was found.

** This is the only routine which is NOT static.

** Must be called exactly once before pci_init().

/**

 * sba_get_iommu - Assign the iommu pointer for the pci bus controller.

 * @dev: The parisc device.

 *

 * Returns the appropriate IOMMU data for the given parisc PCI controller.

 * This is cached and used later for PCI DMA Mapping.

 rope # */

/**

 * sba_directed_lmmio - return first directed LMMIO range routed to rope

 * @pa_dev: The parisc device.

 * @r: resource PCI host controller wants start/end fields assigned.

 *

 * For the given parisc PCI controller, determine if any direct ranges

 * are routed down the corresponding rope.

 rope # */

 Astro has 4 directed ranges. Not sure about Ike/Pluto/et al */

 not enabled */

 directed down different rope */

/**

 * sba_distributed_lmmio - return portion of distributed LMMIO range

 * @pa_dev: The parisc device.

 * @r: resource PCI host controller wants start/end fields assigned.

 *

 * For the given parisc PCI controller, return portion of distributed LMMIO

 * range. The distributed LMMIO is always present and it's just a question

 * of the base address and size of the range.

 rope # */

 Gah! Distr Range wasn't enabled! */

 adjust base for this rope */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

**

**  PCI Lower Bus Adapter (LBA) manager

**

**	(c) Copyright 1999,2000 Grant Grundler

**	(c) Copyright 1999,2000 Hewlett-Packard Company

**

**

**

** This module primarily provides access to PCI bus (config/IOport

** spaces) on platforms with an SBA/LBA chipset. A/B/C/J/L/N-class

** with 4 digit model numbers - eg C3000 (and A400...sigh).

**

** LBA driver isn't as simple as the Dino driver because:

**   (a) this chip has substantial bug fixes between revisions

**       (Only one Dino bug has a software workaround :^(  )

**   (b) has more options which we don't (yet) support (DMA hints, OLARD)

**   (c) IRQ support lives in the I/O SAPIC driver (not with PCI driver)

**   (d) play nicely with both PAT and "Legacy" PA-RISC firmware (PDC).

**       (dino only deals with "Legacy" PDC)

**

** LBA driver passes the I/O SAPIC HPA to the I/O SAPIC driver.

** (I/O SAPIC is integratd in the LBA chip).

**

** FIXME: Add support to SBA and LBA drivers for DMA hint sets

** FIXME: Add support for PCI card hot-plug (OLARD).

 for __init */

 for register_parisc_driver() stuff */

 read/write stuff */

 general stuff */

 debug I/O Port access */

 debug Config Space Access (ie PCI Bus walk) */

 debug PCI Resource Mgt code - PDC PAT only */

 Fast Back-Back xfers - NOT READY YET */

/*

** Config accessor functions only pass in the 8-bit bus number and not

** the 8-bit "PCI Segment" number. Each LBA will be assigned a PCI bus

** number based on what firmware wrote into the scratch register.

**

** The "secondary" bus number is set to this before calling

** pci_register_ops(). If any PPB's are present, the scan will

** discover them and update the "secondary" and "subordinate"

** fields in the pci_bus structure.

**

** Changes in the configuration *may* result in a different

** bus number for each LBA depending on what firmware does.

 non-postable I/O port space, densely packed */

 lba flags */

/*

** Only allow 8 subsidiary busses per LBA

** Problem is the PCI bus numbering is globally shared.

/************************************

 * LBA register read and write support

 *

 * BE WARNED: register writes are posted.

 *  (ie follow writes which must reach HW with a read)

/*

** Extract LBA (Rope) number from HPA

** REVISIT: 16 ropes for Stretch/Ike?

/*

** LBA rev 2.0, 2.1, 2.2, and 3.0 bus walks require a complex

** workaround for cfg cycles:

**	-- preserve  LBA state

**	-- prevent any DMA from occurring

**	-- turn on smart mode

**	-- probe with config writes before doing config reads

**	-- check ERROR_STATUS

**	-- clear ERROR_STATUS

**	-- restore LBA state

**

** The workaround is only used for device discovery.

 Save contents of error config register.  */			\

 Save contents of status control register.  */			\

    /* For LBA rev 2.0, 2.1, 2.2, and 3.0, we must disable DMA		\

    ** arbitration for full bus walks.					\

 Save contents of arb mask register. */			\

	/*								\

	 * Turn off all device arbitration bits (i.e. everything	\

	 * except arbitration enable bit).				\

    /*									\

     * Set the smart mode bit so that master aborts don't cause		\

     * LBA to go into PCI fatal mode (required).			\

    /*									\

     * Setup Vendor ID write and read back the address register		\

     * to make sure that LBA is the bus master.				\

    /*									\

     * Read address register to ensure that LBA is the bus master,	\

     * which implies that DMA traffic has stopped when DMA arb is off.	\

    /*									\

     * Generate a cfg write cycle (will have no affect on		\

     * Vendor ID register since read-only).				\

    /*									\

     * Make sure write has completed before proceeding further,		\

     * i.e. before setting clear enable.				\

/*

 * HPREVISIT:

 *   -- Can't tell if config cycle got the error.

 *

 *		OV bit is broken until rev 4.0, so can't use OV bit and

 *		LBA_ERROR_LOG_ADDR to tell if error belongs to config cycle.

 *

 *		As of rev 4.0, no longer need the error check.

 *

 *   -- Even if we could tell, we still want to return -1

 *	for **ANY** error (not just master abort).

 *

 *   -- Only clear non-fatal errors (we don't want to bring

 *	LBA out of pci-fatal mode).

 *

 *		Actually, there is still a race in which

 *		we could be clearing a fatal error.  We will

 *		live with this during our initial bus walk

 *		until rev 4.0 (no driver activity during

 *		initial bus walk).  The initial bus walk

 *		has race conditions concerning the use of

 *		smart mode as well.

    /*									\

     * Set clear enable (CE) bit. Unset by HW when new			\

     * errors are logged -- LBA HW ERS section 14.3.3).		\

	/*								\

	 * Fail the config read request.				\

	    /*								\

	     * Clear error status (if fatal bit not set) by setting	\

	     * clear error log bit (CL).				\

    /*									\

     * Read address register to ensure that LBA is the bus master,	\

     * which implies that DMA traffic has stopped when DMA arb is off.	\

    /*									\

     * Restore status control register (turn off clear enable).		\

    /*									\

     * Restore error config register (turn off smart mode).		\

	/*								\

	 * Restore arb mask register (reenables DMA arbitration).	\

 used by LBA_CFG_SETUP/RESTORE */

 used by LBA_CFG_SETUP/RESTORE */

 used by LBA_CFG_SETUP/RESTORE */

 FIXME: B2K/C3600 workaround is always use old method... */

 if (!LBA_SKIP_PROBE(d)) */ {

		/* original - Generate config cycle on broken elroy

 either don't want to look or know device isn't present. */

	/* Basic Algorithm

	** Should only get here on fully working LBA rev.

	** This is how simple the code should have been.

/*

 * LBA 4.0 config write code implements non-postable semantics

 * by doing a read of CONFIG ADDR after the write.

 Original Workaround */

 New Workaround */

 Basic Algorithm */

 flush posted write */

/*

 * The mercury_cfg_ops are slightly misnamed; they're also used for Elroy

 * TR4.0 as no additional bugs were found in this areea between Elroy and

 * Mercury

/*

 * LBA 4.0 config write code implements non-postable semantics

 * by doing a read of CONFIG ADDR after the write.

 flush posted write */

/*

 * truncate_pat_collision:  Deal with overlaps or outright collisions

 *			between PAT PDC reported ranges.

 *

 *   Broken PA8800 firmware will report lmmio range that

 *   overlaps with CPU HPA. Just truncate the lmmio range.

 *

 *   BEWARE: conflicts with this lmmio range may be an

 *   elmmio range which is pointing down another rope.

 *

 *  FIXME: only deals with one collision per range...theoretically we

 *  could have several. Supporting more than one collision will get messy.

 find first overlap */

 no entries overlap */

	/* found one that starts behind the new one

	** Don't need to do anything.

 "front" of new one overlaps */

 AACCKK! totally overlaps! drop this range. */

 "end" of new one overlaps */

 truncation successful */

/*

 * extend_lmmio_len: extend lmmio range to maximum length

 *

 * This is needed at least on C8000 systems to get the ATI FireGL card

 * working. On other systems we will currently not extend the lmmio space.

 exit if not a C8000 */

 limit to 256 MB */

 fix overflow */

 first overlap */

 ignore ourself */

 return new end */

 Already allocated */

			/*

			 * Something is wrong with the region.

			 * Invalidate the resource to prevent

			 * child resource allocations in this

			 * range.

 Depth-First Search on bus tree */

/*

** The algorithm is generic code.

** But it needs to access local data structures to get the IRQ base.

** Could make this a "pci_fixup_irq(bus, region)" but not sure

** it's worth it.

**

** Called by do_pci_scan_bus() immediately after each PCI bus is walked.

** Resources aren't allocated until recursive buswalk below HBA is completed.

	/*

	** Properly Setup MMIO resources for this bus.

	** pci_alloc_primary_bus() mangles this.

 PCI-PCI Bridge */

 check and allocate bridge resources */

 Host-PCI Bridge */

 lba_dump_res(&iomem_resource, 2); */

 BUG(); */

 GMMIO is  distributed range. Every LBA/Rope gets part it. */

 Virtualize Device/Bridge Resources. */

 If resource not allocated - skip it */

			/*

			** FIXME: this will result in whinging for devices

			** that share expansion ROMs (think quad tulip), but

			** isn't harmful.

		/*

		** If one device does not support FBB transfers,

		** No one on the bus can be allowed to use them.

                /*

		** P2PB's have no IRQs. ignore them.

 Adjust INTERRUPT_LINE for this dev */

/* FIXME/REVISIT - finish figuring out to set FBB on both

** pci_setup_bridge() clobbers PCI_BRIDGE_CONTROL.

** Can't fixup here anyway....garr...

 enable on PPB */

 enable on LBA */

 Lastly enable FBB/PERR/SERR on all devices too */

/*******************************************************

**

** LBA Sprockets "I/O Port" Space Accessor Functions

**

** This set of accessor functions is intended for use with

** "legacy firmware" (ie Sprockets on Allegro/Forte boxes).

**

** Many PCI devices don't require use of I/O port space (eg Tulip,

** NCR720) since they export the same registers to both MMIO and

** I/O port space. In general I/O port space is slower than

** MMIO since drivers are designed so PIO writes can be posted.

**

/*

** BUG X4107:  Ordering broken - DMA RD return can bypass PIO WR

**

** Fixed in Elroy 2.2. The READ_U32(..., LBA_FUNC_ID) below is

** guarantee non-postable completion semantics - not avoid X4107.

** The READ_U32 only guarantees the write data gets to elroy but

** out to the PCI bus. We can't read stuff from I/O port space

** since we don't know what has side-effects. Attempting to read

** from configuration space would be suicidal given the number of

** bugs in that elroy functionality.

**

**      Description:

**          DMA read results can improperly pass PIO writes (X4107).  The

**          result of this bug is that if a processor modifies a location in

**          memory after having issued PIO writes, the PIO writes are not

**          guaranteed to be completed before a PCI device is allowed to see

**          the modified data in a DMA read.

**

**          Note that IKE bug X3719 in TR1 IKEs will result in the same

**          symptom.

**

**      Workaround:

**          The workaround for this bug is to always follow a PIO write with

**          a PIO read to the same bus before starting DMA on that PCI bus.

**

/*******************************************************

**

** LBA PAT "I/O Port" Space Accessor Functions

**

** This set of accessor functions is intended for use with

** "PAT PDC" firmware (ie Prelude/Rhapsody/Piranha boxes).

**

** This uses the PIOP space located in the first 64MB of GMMIO.

** Each rope gets a full 64*KB* (ie 4 bytes per page) this way.

** bits 1:0 stay the same.  bits 15:2 become 25:12.

** Then add the base and we can generate an I/O Port cycle.

 flush the I/O down to the elroy at least */ \

/*

** make range information from PDC available to PCI subsystem.

** We make the PDC call here in order to get the PCI bus range

** numbers. The rest will get forwarded in pcibios_fixup_bus().

** We don't have a struct pci_bus assigned to us yet.

 PDC return status */

 PA_VIEW */

 IO_VIEW */

 return cell module (IO view) */

 We've already done this once for device discovery...*/

	/*

	** Inspect the resources PAT tells us about

 aka finish */

 Convert the PAT range data to PCI "struct resource" */

 used to fix up pre-initialized MEM BARs */

 MMIO space > 4GB phys addr; for 64-bit BAR */

			/*

			** Postable I/O port space is per PCI host adapter.

			** base of 64MB PIOP region

 keep compiler from complaining about missing declarations */

 CONFIG_64BIT */

	/*

	** With "legacy" firmware, the lowest byte of FW_SCRATCH

	** represents bus->secondary and the second byte represents

	** bus->subsidiary (i.e. highest PPB programmed by firmware).

	** PCI bus walk *should* end up with the same result.

	** FIXME: But we don't have sanity checks in PCI or LBA.

	/* Set up local PCI Bus resources - we don't need them for

	** Legacy boxes but it's nice to see in /proc/iomem.

	/* We want the CPU -> IO routing of addresses.

	 * The SBA BASE/MASK registers control CPU -> IO routing.

	 * Ask SBA what is routed to this rope/LBA.

	/*

	 * The LBA BASE/MASK registers control IO -> System routing.

	 *

	 * The following code works but doesn't get us what we want.

	 * Well, only because firmware (v5.0) on C3000 doesn't program

	 * the LBA BASE/MASE registers to be the exact inverse of 

	 * the corresponding SBA registers. Other Astro/Pluto

	 * based platform firmware may do it right.

	 *

	 * Should someone want to mess with MSI, they may need to

	 * reprogram LBA BASE/MASK registers. Thus preserve the code

	 * below until MSI is known to work on C3000/A500/N4000/RP3440.

	 *

	 * Using the code below, /proc/iomem shows:

	 * ...

	 * f0000000-f0ffffff : PCI00 LMMIO

	 *   f05d0000-f05d0000 : lcd_data

	 *   f05d0008-f05d0008 : lcd_cmd

	 * f1000000-f1ffffff : PCI01 LMMIO

	 * f4000000-f4ffffff : PCI02 LMMIO

	 *   f4000000-f4001fff : sym53c8xx

	 *   f4002000-f4003fff : sym53c8xx

	 *   f4004000-f40043ff : sym53c8xx

	 *   f4005000-f40053ff : sym53c8xx

	 *   f4007000-f4007fff : ohci_hcd

	 *   f4008000-f40083ff : tulip

	 * f6000000-f6ffffff : PCI03 LMMIO

	 * f8000000-fbffffff : PCI00 ELMMIO

	 *   fa100000-fa4fffff : stifb mmio

	 *   fb000000-fb1fffff : stifb fb

	 *

	 * But everything listed under PCI02 actually lives under PCI00.

	 * This is clearly wrong.

	 *

	 * Asking SBA how things are routed tells the correct story:

	 * LMMIO_BASE/MASK/ROUTE f4000001 fc000000 00000000

	 * DIR0_BASE/MASK/ROUTE fa000001 fe000000 00000006

	 * DIR1_BASE/MASK/ROUTE f9000001 ff000000 00000004

	 * DIR2_BASE/MASK/ROUTE f0000000 fc000000 00000000

	 * DIR3_BASE/MASK/ROUTE f0000000 fc000000 00000000

	 *

	 * Which looks like this in /proc/iomem:

	 * f4000000-f47fffff : PCI00 LMMIO

	 *   f4000000-f4001fff : sym53c8xx

	 *   ...[deteled core devices - same as above]...

	 *   f4008000-f40083ff : tulip

	 * f4800000-f4ffffff : PCI01 LMMIO

	 * f6000000-f67fffff : PCI02 LMMIO

	 * f7000000-f77fffff : PCI03 LMMIO

	 * f9000000-f9ffffff : PCI02 ELMMIO

	 * fa000000-fbffffff : PCI03 ELMMIO

	 *   fa100000-fa4fffff : stifb mmio

	 *   fb000000-fb1fffff : stifb fb

	 *

	 * ie all Built-in core are under now correctly under PCI00.

	 * The "PCI02 ELMMIO" directed range is for:

	 *  +-[02]---03.0  3Dfx Interactive, Inc. Voodoo 2

	 *

	 * All is well now.

 mmio_mask also clears Enable bit */

		/*

		** Each rope only gets part of the distributed range.

		** Adjust "window" for this rope.

 Not enabled. */

	/*

	** "Directed" ranges are used when the "distributed range" isn't

	** sufficient for all devices below a given LBA.  Typically devices

	** like graphics cards or X25 may need a directed range when the

	** bus has multiple slots (ie multiple devices) or the device

	** needs more than the typical 4 or 8MB a distributed range offers.

	**

	** The main reason for ignoring it now frigging complications.

	** Directed ranges may overlap (and have precedence) over

	** distributed ranges. Or a distributed range assigned to a unused

	** rope may be used by a directed range on a different rope.

	** Support for graphics devices may require fixing this

	** since they may be assigned a directed range which overlaps

	** an existing (but unused portion of) distributed range.

 See comment which precedes call to sba_directed_lmmio() */

 mmio_mask also clears Enable bit */

 Virtualize the I/O Port space ranges */

/**************************************************************************

**

**   LBA initialization code (HW and SW)

**

**   o identify LBA chip itself

**   o initialize LBA chip modes (HardFail)

**   o FIXME: initialize DMA hints for reasonable defaults

**   o enable configuration functions

**   o call pci_register_ops() to discover devs (fixup/fixup_bus get invoked)

**

 PDC_PAT_BUG */

 DEBUG_LBA_PAT */

/*

 * FIXME add support for PDC_PAT_IO "Get slot status" - OLAR support

 * Only N-Class and up can really make use of Get slot status.

 * maybe L-class too but I've never played with it there.

 PDC_PAT_BUG: exhibited in rev 40.48  on L2000 */

	/*

	 * Hard Fail vs. Soft Fail on PCI "Master Abort".

	 *

	 * "Master Abort" means the MMIO transaction timed out - usually due to

	 * the device not responding to an MMIO read. We would like HF to be

	 * enabled to find driver problems, though it means the system will

	 * crash with a HPMC.

	 *

	 * In SoftFail mode "~0L" is returned as a result of a timeout on the

	 * pci bus. This is like how PCI busses on x86 and most other

	 * architectures behave.  In order to increase compatibility with

	 * existing (x86) PCI hardware and existing Linux drivers we enable

	 * Soft Faul mode on PA-RISC now too.

	/*

	** Writing a zero to STAT_CTL.rf (bit 0) will clear reset signal

	** if it's not already set. If we just cleared the PCI Bus Reset

	** signal, wait a bit for the PCI devices to recover and setup.

		/*

		** PDC_PAT_BUG: PDC rev 40.48 on L2000.

		** B2000/C3600/J6000 also have this problem?

		** 

		** Elroys with hot pluggable slots don't get configured

		** correctly if the slot is empty.  ARB_MASK is set to 0

		** and we can't master transactions on the bus if it's

		** not at least one. 0x3 enables elroy and first slot.

	/*

	** FIXME: Hint registers are programmed with default hint

	** values by firmware. Hints should be sane even if we

	** can't reprogram them the way drivers want.

/*

 * Unfortunately, when firmware numbers busses, it doesn't take into account

 * Cardbus bridges.  So we have to renumber the busses to suit ourselves.

 * Elroy/Mercury don't actually know what bus number they're attached to;

 * we use bus 0 to indicate the directly attached bus and any other bus

 * number will be taken care of by the PCI-PCI bridge.

/*

 * Determine if lba should claim this chip (return 0) or not (return 1).

 * If so, initialize the chip and tell other partners in crime they

 * have work to do.

 Read HW Rev First */

/* Elroy TR4.0 should work with simple algorithm.

   But it doesn't.  Still missing something. *sigh*

		/* We could use one printk for both Elroy and Mercury,

                 * but for the mask for func_class.

 Tell I/O SAPIC driver we have a IRQ handler/region. */

	/* NOTE: PCI devices (e.g. 103c:1005 graphics card) which don't

	**	have an IRT entry will get NULL back from iosapic code.

 ---------- First : initialize data we already have --------- */

 save interrupt handle */

 get iommu data */

 ------------ Second : initialize common stuff ---------- */

 ---------- Third : setup I/O Port and MMIO resources  --------- */

 PDC PAT firmware uses PIOP region of GMMIO space. */

 Go ask PDC PAT what resources this LBA has */

 Sprockets PDC uses NPIOP region */

 Poke the chip a bit for /proc output */

	/*   Overlaps with elmmio can (and should) fail here.

	 *   We will prune (or ignore) the distributed range.

	 *

	 *   FIXME: SBA code should register all elmmio ranges first.

	 *      that would take care of elmmio ranges routed

	 *	to a different rope (already discovered) from

	 *	getting registered *after* LBA code has already

	 *	registered it's distributed lmmio range.

		/* Not registering GMMIO space - according to docs it's not

 pci_add_resource(&resources, &lba_dev->hba.gmmio_space); */

 This is in lieu of calling pci_assign_unassigned_resources() */

 assign resources to un-initialized devices */

	/*

	** Once PCI register ops has walked the bus, access to config

	** space is restricted. Avoids master aborts on config cycles.

	** Early LBA revs go fatal on *any* master abort.

 Whew! Finally done! Tell services we got this one covered. */

/*

** One time initialization to let the world know the LBA was found.

** Must be called exactly once before pci_init().

/*

** Initialize the IBASE/IMASK registers for LBA (Elroy).

** Only called from sba_iommu.c in order to route ranges (MMIO vs DMA).

** sba_iommu is responsible for locking (none needed at init time).

 adjust for hints - 2 more bits */

 Make sure we aren't trying to set bits that aren't writeable. */

/*

 * The design of the Diva management card in rp34x0 machines (rp3410, rp3440)

 * seems rushed, so that many built-in components simply don't work.

 * The following quirks disable the serial AUX port and the built-in ATI RV100

 * Radeon 7000 graphics card which both don't have any external connectors and

 * thus are useless, and even worse, e.g. the AUX port occupies ttyS0 and as

 * such makes those machines the only PARISC machines on which we can't use

 * ttyS0 as boot console.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * eisa_enumerator.c - provide support for EISA adapters in PA-RISC machines

 *

 * Copyright (c) 2002 Daniel Engstrom <5116@telia.com>

/*

 * Todo:

 * 

 * PORT init with MASK attr and other size than byte

 * MEMORY with other decode than 20 bit

 * CRC stuff

 * FREEFORM stuff

/* macros to handle unaligned accesses and 

 * byte swapping. The data in the EEPROM is

		/* hpux seems to allow for

		 * two bytes of irq data but only defines one of

 fixme: maybe initialize the dma channel withthe timing ? */

/* byte 1 and 2 is the port number to write

 * and at byte 3 the value to write starts.

 * I assume that there are and- and or- masks

 * here when HPEE_PORT_INIT_MASK is set but I have 

	/* theis record contain the value of the functions

	 * configuration choises and an info byte which 

	 * describes which other records to expect in this 

 just skip past the type field */

	/* the init field seems to be a two-byte field

	 * which is non-zero if there are an other function following

	 * I think it is the length of the function def 

 function disabled, skip silently */

 I have no idea how to handle this */

		/* the ordering of the sections need

		 * more investigation.

		 * Currently I think that memory comaed before IRQ

		 * I assume the order is LSB to MSB in the 

		 * info flags 

		 * eg type, memory, irq, dma, port, HPEE_PORT_init 

 try to read the id of the board in the slot */

 Maybe we didn't expect a card to be here... */

			/* this board is not here or it does not 

			 * support readid 

	/* now: we need to enable the board if 

	 * it supports enabling and run through

	 * the port init sction if present

	 * and finally record any interrupt polarity

 enable board */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * A devfreq driver for NVIDIA Tegra SoCs

 *

 * Copyright (c) 2014 NVIDIA CORPORATION. All rights reserved.

 * Copyright (C) 2014 Google, Inc

/*

 * ACTMON_AVERAGE_WINDOW_LOG2: default value for @DEV_CTRL_K_VAL, which

 * translates to 2 ^ (K_VAL + 1). ex: 2 ^ (6 + 1) = 128

 ms */

 1/10 of % */

 Assume that the bus is saturated if the utilization is 25% */

/**

 * struct tegra_devfreq_device_config - configuration specific to an ACTMON

 * device

 *

 * Coefficients and thresholds are percentages unless otherwise noted

 Factors applied to boost_freq every consecutive watermark breach */

 Define the watermark bounds when applied to the current avg */

	/*

	 * Threshold of activity (cycles translated to kHz) below which the

	 * CPU frequency isn't to be taken into account. This is to avoid

	 * increasing the EMC frequency when the CPU is very busy but not

	 * accessing the bus often.

 MCALL: All memory accesses (including from the CPUs) */

 MCCPU: memory accesses from the CPUs */

 16MHz in kHz units */

 MCALL: All memory accesses (including from the CPUs) */

 MCCPU: memory accesses from the CPUs */

 16MHz in kHz units */

/**

 * struct tegra_devfreq_device - state specific to an ACTMON device

 *

 * Frequencies are in kHz.

 Average event count sampled in the last interrupt */

	/*

	 * Extra frequency to increase the target by due to consecutive

	 * watermark breaches.

 Optimal frequency calculated from the stats for this device */

 Weight value for count measurements */

	/*

	 * High freq + high boosting percent + large polling interval are

	 * resulting in integer overflow when watermarks are calculated.

		/*

		 * new_boost = min(old_boost * up_coef + step, max_freq)

		/*

		 * new_boost = old_boost * down_coef

		 * or 0 if (old_boost * down_coef < step / 2)

 check whether CPU's freq is taken into account at all */

	/*

	 * Quickly check whether CPU frequency should be taken into account

	 * at all, without blocking CPUFreq's core.

		/*

		 * If CPU's frequency shouldn't be taken into account at

		 * the moment, then there is no need to update the devfreq's

		 * state because ISR will re-check CPU's frequency on the

		 * next interrupt.

	/*

	 * CPUFreq driver should support CPUFREQ_ASYNC_NOTIFICATION in order

	 * to allow asynchronous notifications. This means we can't block

	 * here for too long, otherwise CPUFreq's core will complain with a

	 * warning splat.

 reset boosting on governor's restart */

	/*

	 * CLK notifications are needed in order to reconfigure the upper

	 * consecutive watermark in accordance to the actual clock rate

	 * to avoid unnecessary upper interrupts.

	/*

	 * We are estimating CPU's memory bandwidth requirement based on

	 * amount of memory accesses and system's load, judging by CPU's

	 * frequency. We also don't want to receive events about CPU's

	 * frequency transaction when governor is stopped, hence notifier

	 * is registered dynamically.

 To be used by the tegra governor */

 The below are to be used by the other governors */

 Number of cycles spent on memory access */

 The bus can be considered to be saturated way before 100% */

 Number of cycles in a sampling period */

	/*

	 * tegra-devfreq driver operates with KHz units, while OPP table

	 * entries use Hz units. Hence we need to convert the units for the

	 * devfreq core.

	/*

	 * Couple devfreq-device with the governor early because it is

	 * needed at the moment of governor's start (used by ISR).

		/*

		 * ACTMON hardware supports up to 256 milliseconds for the

		 * sampling period.

	/*

	 * Activity counter is incremented every 256 memory transactions,

	 * and each transaction takes 4 EMC clocks.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/devfreq/governor_performance.c

 *

 *  Copyright (C) 2011 Samsung Electronics

 *	MyungJoo Ham <myungjoo.ham@samsung.com>

	/*

	 * target callback should be able to get floor value as

	 * said in devfreq.h

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/drivers/devfreq/governor_passive.c

 *

 * Copyright (C) 2016 Samsung Electronics

 * Author: Chanwoo Choi <cw00.choi@samsung.com>

 * Author: MyungJoo Ham <myungjoo.ham@samsung.com>

	/*

	 * If the devfreq device with passive governor has the specific method

	 * to determine the next frequency, should use the get_target_freq()

	 * of struct devfreq_passive_data.

	/*

	 * If the parent and passive devfreq device uses the OPP table,

	 * get the next frequency by using the OPP table.

	/*

	 * - parent devfreq device uses the governors except for passive.

	 * - passive devfreq device uses the passive governor.

	 *

	 * Each devfreq has the OPP table. After deciding the new frequency

	 * from the governor of parent devfreq device, the passive governor

	 * need to get the index of new frequency on OPP table of parent

	 * device. And then the index is used for getting the suitable

	 * new frequency for passive devfreq device.

	/*

	 * The passive governor have to get the correct frequency from OPP

	 * list of parent device. Because in this case, *freq is temporary

	 * value which is decided by ondemand governor.

	/*

	 * Get the OPP table's index of decided frequency by governor

	 * of parent device.

 Get the suitable frequency by using index of parent device. */

 Return the suitable frequency for passive device. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/devfreq/governor_userspace.c

 *

 *  Copyright (C) 2011 Samsung Electronics

 *	MyungJoo Ham <myungjoo.ham@samsung.com>

 No user freq specified yet */

	/*

	 * Remove the sysfs entry, unless this is being called after

	 * device_del(), which should have done this already via kobject_del().

 SPDX-License-Identifier: GPL-2.0-only

/*

 * devfreq: Generic Dynamic Voltage and Frequency Scaling (DVFS) Framework

 *	    for Non-CPU Devices.

 *

 * Copyright (C) 2011 Samsung Electronics

 *	MyungJoo Ham <myungjoo.ham@samsung.com>

/*

 * devfreq core provides delayed work based load monitoring helper

 * functions. Governors can use these or can implement their own

 * monitoring mechanism.

 The list of all device-devfreq governors */

 The list of all device-devfreq */

/**

 * find_device_devfreq() - find devfreq struct using device pointer

 * @dev:	device pointer used to lookup device devfreq.

 *

 * Search the list of device devfreqs and return the matched device's

 * devfreq info. devfreq_list_lock should be held by the caller.

/**

 * get_freq_range() - Get the current freq range

 * @devfreq:	the devfreq instance

 * @min_freq:	the min frequency

 * @max_freq:	the max frequency

 *

 * This takes into consideration all constraints.

	/*

	 * Initialize minimum/maximum frequency from freq table.

	 * The devfreq drivers can initialize this in either ascending or

	 * descending order and devfreq core supports both.

 Apply constraints from PM QoS */

 Apply constraints from OPP interface */

/**

 * devfreq_get_freq_level() - Lookup freq_table for the frequency

 * @devfreq:	the devfreq instance

 * @freq:	the target frequency

 Initialize the freq_table from OPP table */

/**

 * devfreq_update_status() - Update statistics of devfreq behavior

 * @devfreq:	the devfreq instance

 * @freq:	the update target frequency

 Immediately exit if previous_freq is not initialized yet. */

/**

 * find_devfreq_governor() - find devfreq governor from name

 * @name:	name of the governor

 *

 * Search the list of devfreq governors and return the matched

 * governor's pointer. devfreq_list_lock should be held by the caller.

/**

 * try_then_request_governor() - Try to find the governor and request the

 *                               module if is not found.

 * @name:	name of the governor

 *

 * Search the list of devfreq governors and request the module and try again

 * if is not found. This can happen when both drivers (the governor driver

 * and the driver that call devfreq_add_device) are built as modules.

 * devfreq_list_lock should be held by the caller. Returns the matched

 * governor's pointer or an error pointer.

 Restore previous state before return */

	/*

	 * Print devfreq_frequency trace information between DEVFREQ_PRECHANGE

	 * and DEVFREQ_POSTCHANGE because for showing the correct frequency

	 * change order of between devfreq device and passive devfreq device.

/**

 * devfreq_update_target() - Reevaluate the device and configure frequency

 *			   on the final stage.

 * @devfreq:	the devfreq instance.

 * @freq:	the new frequency of parent device. This argument

 *		is only used for devfreq device using passive governor.

 *

 * Note: Lock devfreq->lock before calling devfreq_update_target. This function

 *	 should be only used by both update_devfreq() and devfreq governors.

 Reevaluate the proper frequency */

 Use GLB */

 Use LUB */

 Load monitoring helper functions for governors use */

/**

 * update_devfreq() - Reevaluate the device and configure frequency.

 * @devfreq:	the devfreq instance.

 *

 * Note: Lock devfreq->lock before calling update_devfreq

 *	 This function is exported for governors.

/**

 * devfreq_monitor() - Periodically poll devfreq objects.

 * @work:	the work struct used to run devfreq_monitor periodically.

 *

/**

 * devfreq_monitor_start() - Start load monitoring of devfreq instance

 * @devfreq:	the devfreq instance.

 *

 * Helper function for starting devfreq device load monitoring. By

 * default delayed work based monitoring is supported. Function

 * to be called from governor in response to DEVFREQ_GOV_START

 * event when device is added to devfreq framework.

/**

 * devfreq_monitor_stop() - Stop load monitoring of a devfreq instance

 * @devfreq:	the devfreq instance.

 *

 * Helper function to stop devfreq device load monitoring. Function

 * to be called from governor in response to DEVFREQ_GOV_STOP

 * event when device is removed from devfreq framework.

/**

 * devfreq_monitor_suspend() - Suspend load monitoring of a devfreq instance

 * @devfreq:	the devfreq instance.

 *

 * Helper function to suspend devfreq device load monitoring. Function

 * to be called from governor in response to DEVFREQ_GOV_SUSPEND

 * event or when polling interval is set to zero.

 *

 * Note: Though this function is same as devfreq_monitor_stop(),

 * intentionally kept separate to provide hooks for collecting

 * transition statistics.

/**

 * devfreq_monitor_resume() - Resume load monitoring of a devfreq instance

 * @devfreq:    the devfreq instance.

 *

 * Helper function to resume devfreq device load monitoring. Function

 * to be called from governor in response to DEVFREQ_GOV_RESUME

 * event or when polling interval is set to non-zero.

/**

 * devfreq_update_interval() - Update device devfreq monitoring interval

 * @devfreq:    the devfreq instance.

 * @delay:      new polling interval to be set.

 *

 * Helper function to set new load monitoring polling interval. Function

 * to be called from governor in response to DEVFREQ_GOV_UPDATE_INTERVAL event.

 if new delay is zero, stop polling */

 if current delay is zero, start polling with new delay */

 if current delay is greater than new delay, restart polling */

/**

 * devfreq_notifier_call() - Notify that the device frequency requirements

 *			     has been changed out of devfreq framework.

 * @nb:		the notifier_block (supposed to be devfreq->nb)

 * @type:	not used

 * @devp:	not used

 *

 * Called by a notifier that uses devfreq->nb.

/**

 * qos_notifier_call() - Common handler for QoS constraints.

 * @devfreq:    the devfreq instance.

/**

 * qos_min_notifier_call() - Callback for QoS min_freq changes.

 * @nb:		Should be devfreq->nb_min

/**

 * qos_max_notifier_call() - Callback for QoS max_freq changes.

 * @nb:		Should be devfreq->nb_max

/**

 * devfreq_dev_release() - Callback for struct device to release the device.

 * @dev:	the devfreq device

 *

 * Remove devfreq from the list and release its resources.

/**

 * devfreq_add_device() - Add devfreq feature to the device

 * @dev:	the device to add devfreq feature.

 * @profile:	device-specific profile to run devfreq.

 * @governor_name:	name of the policy to choose frequency.

 * @data:	private data for the governor. The devfreq framework does not

 *		touch this value.

/**

 * devfreq_remove_device() - Remove devfreq feature from a device.

 * @devfreq:	the devfreq instance to be removed

 *

 * The opposite of devfreq_add_device().

/**

 * devm_devfreq_add_device() - Resource-managed devfreq_add_device()

 * @dev:	the device to add devfreq feature.

 * @profile:	device-specific profile to run devfreq.

 * @governor_name:	name of the policy to choose frequency.

 * @data:	private data for the governor. The devfreq framework does not

 *		touch this value.

 *

 * This function manages automatically the memory of devfreq device using device

 * resource management and simplify the free operation for memory of devfreq

 * device.

/*

 * devfreq_get_devfreq_by_node - Get the devfreq device from devicetree

 * @node - pointer to device_node

 *

 * return the instance of devfreq device

/*

 * devfreq_get_devfreq_by_phandle - Get the devfreq device from devicetree

 * @dev - instance to the given device

 * @phandle_name - name of property holding a phandle value

 * @index - index into list of devfreq

 *

 * return the instance of devfreq device

 CONFIG_OF */

/**

 * devm_devfreq_remove_device() - Resource-managed devfreq_remove_device()

 * @dev:	the device from which to remove devfreq feature.

 * @devfreq:	the devfreq instance to be removed

/**

 * devfreq_suspend_device() - Suspend devfreq of a device.

 * @devfreq: the devfreq instance to be suspended

 *

 * This function is intended to be called by the pm callbacks

 * (e.g., runtime_suspend, suspend) of the device driver that

 * holds the devfreq.

/**

 * devfreq_resume_device() - Resume devfreq of a device.

 * @devfreq: the devfreq instance to be resumed

 *

 * This function is intended to be called by the pm callbacks

 * (e.g., runtime_resume, resume) of the device driver that

 * holds the devfreq.

/**

 * devfreq_suspend() - Suspend devfreq governors and devices

 *

 * Called during system wide Suspend/Hibernate cycles for suspending governors

 * and devices preserving the state for resume. On some platforms the devfreq

 * device must have precise state (frequency) after resume in order to provide

 * fully operating setup.

/**

 * devfreq_resume() - Resume devfreq governors and devices

 *

 * Called during system wide Suspend/Hibernate cycle for resuming governors and

 * devices that are suspended with devfreq_suspend().

/**

 * devfreq_add_governor() - Add devfreq governor

 * @governor:	the devfreq governor to be added

 The following should never occur */

 Fall through */

/**

 * devm_devfreq_add_governor() - Add devfreq governor

 * @dev:	device which adds devfreq governor

 * @governor:	the devfreq governor to be added

 *

 * This is a resource-managed variant of devfreq_add_governor().

/**

 * devfreq_remove_governor() - Remove devfreq feature from a device.

 * @governor:	the devfreq governor to be removed

 we should have a devfreq governor! */

 Fall through */

	/*

	 * Stop the current governor and remove the specific sysfs files

	 * which depend on current governor.

	/*

	 * Start the new governor and create the specific sysfs files

	 * which depend on the new governor.

 Restore previous governor */

	/*

	 * Create the sysfs files for the new governor. But if failed to start

	 * the new governor, restore the sysfs files of previous governor.

	/*

	 * The devfreq with immutable governor (e.g., passive) shows

	 * only own governor.

	/*

	 * The devfreq device shows the registered governor except for

	 * immutable governors such as passive governor .

 Truncate the trailing space */

	/*

	 * Protect against theoretical sysfs writes between

	 * device_add and dev_pm_qos_add_request

 Round down to kHz for PM QoS */

	/*

	 * Protect against theoretical sysfs writes between

	 * device_add and dev_pm_qos_add_request

	/*

	 * PM QoS frequencies are in kHz so we need to convert. Convert by

	 * rounding upwards so that the acceptable interval never shrinks.

	 *

	 * For example if the user writes "666666666" to sysfs this value will

	 * be converted to 666667 kHz and back to 666667000 Hz before an OPP

	 * lookup, this ensures that an OPP of 666666666Hz is still accepted.

	 *

	 * A value of zero means "no limit".

 Truncate the trailing space */

 Create the specific sysfs files which depend on each governor. */

 Remove the specific sysfs files which depend on each governor. */

/**

 * devfreq_summary_show() - Show the summary of the devfreq devices

 * @s:		seq_file instance to show the summary of devfreq devices

 * @data:	not used

 *

 * Show the summary of the devfreq devices via 'devfreq_summary' debugfs file.

 * It helps that user can know the detailed information of the devfreq devices.

 *

 * Return 0 always because it shows the information without any data change.

/*

 * The following are helper functions for devfreq user device drivers with

 * OPP framework.

/**

 * devfreq_recommended_opp() - Helper function to get proper OPP for the

 *			     freq value given to target callback.

 * @dev:	The devfreq user device. (parent of devfreq)

 * @freq:	The frequency given to target function

 * @flags:	Flags handed from devfreq framework.

 *

 * The callers are required to call dev_pm_opp_put() for the returned OPP after

 * use.

 The freq is an upper bound. opp should be lower */

 If not available, use the closest opp */

 The freq is an lower bound. opp should be higher */

 If not available, use the closest opp */

/**

 * devfreq_register_opp_notifier() - Helper function to get devfreq notified

 *				     for any changes in the OPP availability

 *				     changes

 * @dev:	The devfreq user device. (parent of devfreq)

 * @devfreq:	The devfreq object.

/**

 * devfreq_unregister_opp_notifier() - Helper function to stop getting devfreq

 *				       notified for any changes in the OPP

 *				       availability changes anymore.

 * @dev:	The devfreq user device. (parent of devfreq)

 * @devfreq:	The devfreq object.

 *

 * At exit() callback of devfreq_dev_profile, this must be included if

 * devfreq_recommended_opp is used.

/**

 * devm_devfreq_register_opp_notifier() - Resource-managed

 *					  devfreq_register_opp_notifier()

 * @dev:	The devfreq user device. (parent of devfreq)

 * @devfreq:	The devfreq object.

/**

 * devm_devfreq_unregister_opp_notifier() - Resource-managed

 *					    devfreq_unregister_opp_notifier()

 * @dev:	The devfreq user device. (parent of devfreq)

 * @devfreq:	The devfreq object.

/**

 * devfreq_register_notifier() - Register a driver with devfreq

 * @devfreq:	The devfreq object.

 * @nb:		The notifier block to register.

 * @list:	DEVFREQ_TRANSITION_NOTIFIER.

/*

 * devfreq_unregister_notifier() - Unregister a driver with devfreq

 * @devfreq:	The devfreq object.

 * @nb:		The notifier block to be unregistered.

 * @list:	DEVFREQ_TRANSITION_NOTIFIER.

/**

 * devm_devfreq_register_notifier()

 *	- Resource-managed devfreq_register_notifier()

 * @dev:	The devfreq user device. (parent of devfreq)

 * @devfreq:	The devfreq object.

 * @nb:		The notifier block to be unregistered.

 * @list:	DEVFREQ_TRANSITION_NOTIFIER.

/**

 * devm_devfreq_unregister_notifier()

 *	- Resource-managed devfreq_unregister_notifier()

 * @dev:	The devfreq user device. (parent of devfreq)

 * @devfreq:	The devfreq object.

 * @nb:		The notifier block to be unregistered.

 * @list:	DEVFREQ_TRANSITION_NOTIFIER.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 NXP

 imx_bus_init_icc() - register matching icc provider if required */

	/*

	 * Fetch the clock to adjust but don't explicitly enable.

	 *

	 * For imx bus clock clk_set_rate is safe no matter if the clock is on

	 * or off and some peripheral side-buses might be off unless enabled by

	 * drivers for devices on those specific buses.

	 *

	 * Rate adjustment on a disabled bus clock just takes effect later.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Generic Exynos Bus frequency driver with DEVFREQ Framework

 *

 * Copyright (c) 2016 Samsung Electronics Co., Ltd.

 * Author : Chanwoo Choi <cw00.choi@samsung.com>

 *

 * This driver support Exynos Bus frequency feature by using

 * DEVFREQ framework and is based on drivers/devfreq/exynos/exynos4_bus.c.

/*

 * Control the devfreq-event device to get the current state of bus

/*

 * devfreq function for both simple-ondemand and passive governor

 Get correct frequency for bus. */

 Change voltage and frequency according to new OPP level */

	/*

	 * Get the devfreq-event devices to get the current utilization of

	 * buses. This raw data will be used in devfreq ondemand governor.

	/*

	 * Optionally, Get the saturation ratio according to Exynos SoC

	 * When measuring the utilization of each AXI bus with devfreq-event

	 * devices, the measured real cycle might be much lower than the

	 * total cycle of bus during sampling rate. In result, the devfreq

	 * simple-ondemand governor might not decide to change the current

	 * frequency due to too utilization (= real cycle/total cycle).

	 * So, this property is used to adjust the utilization when calculating

	 * the busy_time in exynos_bus_get_dev_status().

 Get the clock to provide each bus with source clock */

 Get the freq and voltage from OPP table to scale the bus freq */

 Initialize the struct profile and governor data for parent device */

 Add devfreq device to monitor and handle the exynos bus */

 Register opp_notifier to catch the change of OPP  */

	/*

	 * Enable devfreq-event to get raw data which is used to determine

	 * current bus load.

 Initialize the struct profile and governor data for passive device */

 Get the instance of parent devfreq device */

 Add devfreq device for exynos bus with passive governor */

 Parse the device-tree to get the resource information */

 Create child platform device for the interconnect provider */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * devfreq-event: a framework to provide raw data and events of devfreq devices

 *

 * Copyright (C) 2015 Samsung Electronics

 * Author: Chanwoo Choi <cw00.choi@samsung.com>

 *

 * This driver is based on drivers/devfreq/devfreq.c.

 The list of all devfreq event list */

/**

 * devfreq_event_enable_edev() - Enable the devfreq-event dev and increase

 *				 the enable_count of devfreq-event dev.

 * @edev	: the devfreq-event device

 *

 * Note that this function increase the enable_count and enable the

 * devfreq-event device. The devfreq-event device should be enabled before

 * using it by devfreq device.

/**

 * devfreq_event_disable_edev() - Disable the devfreq-event dev and decrease

 *				  the enable_count of the devfreq-event dev.

 * @edev	: the devfreq-event device

 *

 * Note that this function decrease the enable_count and disable the

 * devfreq-event device. After the devfreq-event device is disabled,

 * devfreq device can't use the devfreq-event device for get/set/reset

 * operations.

/**

 * devfreq_event_is_enabled() - Check whether devfreq-event dev is enabled or

 *				not.

 * @edev	: the devfreq-event device

 *

 * Note that this function check whether devfreq-event dev is enabled or not.

 * If return true, the devfreq-event dev is enabeld. If return false, the

 * devfreq-event dev is disabled.

/**

 * devfreq_event_set_event() - Set event to devfreq-event dev to start.

 * @edev	: the devfreq-event device

 *

 * Note that this function set the event to the devfreq-event device to start

 * for getting the event data which could be various event type.

/**

 * devfreq_event_get_event() - Get {load|total}_count from devfreq-event dev.

 * @edev	: the devfreq-event device

 * @edata	: the calculated data of devfreq-event device

 *

 * Note that this function get the calculated event data from devfreq-event dev

 * after stoping the progress of whole sequence of devfreq-event dev.

/**

 * devfreq_event_reset_event() - Reset all opeations of devfreq-event dev.

 * @edev	: the devfreq-event device

 *

 * Note that this function stop all operations of devfreq-event dev and reset

 * the current event data to make the devfreq-event device into initial state.

/**

 * devfreq_event_get_edev_by_phandle() - Get the devfreq-event dev from

 *					 devicetree.

 * @dev		: the pointer to the given device

 * @phandle_name: name of property holding a phandle value

 * @index	: the index into list of devfreq-event device

 *

 * Note that this function return the pointer of devfreq-event device.

/**

 * devfreq_event_get_edev_count() - Get the count of devfreq-event dev

 * @dev		: the pointer to the given device

 * @phandle_name: name of property holding a phandle value

 *

 * Note that this function return the count of devfreq-event devices.

/**

 * devfreq_event_add_edev() - Add new devfreq-event device.

 * @dev		: the device owning the devfreq-event device being created

 * @desc	: the devfreq-event device's descriptor which include essential

 *		  data for devfreq-event device.

 *

 * Note that this function add new devfreq-event device to devfreq-event class

 * list and register the device of the devfreq-event device.

/**

 * devfreq_event_remove_edev() - Remove the devfreq-event device registered.

 * @edev	: the devfreq-event device

 *

 * Note that this function removes the registered devfreq-event device.

/**

 * devm_devfreq_event_add_edev() - Resource-managed devfreq_event_add_edev()

 * @dev		: the device owning the devfreq-event device being created

 * @desc	: the devfreq-event device's descriptor which include essential

 *		  data for devfreq-event device.

 *

 * Note that this function manages automatically the memory of devfreq-event

 * device using device resource management and simplify the free operation

 * for memory of devfreq-event device.

/**

 * devm_devfreq_event_remove_edev()- Resource-managed devfreq_event_remove_edev()

 * @dev		: the device owning the devfreq-event device being created

 * @edev	: the devfreq-event device

 *

 * Note that this function manages automatically the memory of devfreq-event

 * device using device resource management.

/*

 * Device attributes for devfreq-event class.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/devfreq/governor_simpleondemand.c

 *

 *  Copyright (C) 2011 Samsung Electronics

 *	MyungJoo Ham <myungjoo.ham@samsung.com>

 Default constants for DevFreq-Simple-Ondemand (DFSO) */

 Assume MAX if it is going to be divided by zero */

 Prevent overflow */

 Set MAX if it's busy enough */

 Set MAX if we do not know the initial frequency */

 Keep the current frequency */

 Set the desired frequency based on the load */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/devfreq/governor_powersave.c

 *

 *  Copyright (C) 2011 Samsung Electronics

 *	MyungJoo Ham <myungjoo.ham@samsung.com>

	/*

	 * target callback should be able to get ceiling value as

	 * said in devfreq.h

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 NXP

 Query available frequencies. */

/*

 * This should be in a 1:1 mapping with devicetree OPPs but

 * firmware provides additional info.

 Hardware limitation */

/*

 * i.MX8M DRAM Controller clocks have the following structure (abridged):

 *

 * +----------+       |\            +------+

 * | dram_pll |-------|M| dram_core |      |

 * +----------+       |U|---------->| D    |

 *                 /--|X|           |  D   |

 *   dram_alt_root |  |/            |   R  |

 *                 |                |    C |

 *            +---------+           |      |

 *            |FIX DIV/4|           |      |

 *            +---------+           |      |

 *  composite:     |                |      |

 * +----------+    |                |      |

 * | dram_alt |----/                |      |

 * +----------+                     |      |

 * | dram_apb |-------------------->|      |

 * +----------+                     +------+

 *

 * The dram_pll is used for higher rates and dram_alt is used for lower rates.

 *

 * Frequency switching is implemented in TF-A (via SMC call) and can change the

 * configuration of the clocks, including mux parents. The dram_alt and

 * dram_apb clocks are "imx composite" and their parent can change too.

 *

 * We need to prepare/enable the new mux parents head of switching and update

 * their information afterwards.

 For frequency switching: */

	/*

	 * Firmware reports values in MT/s, so we round-down from Hz

	 * Rounding is extra generous to ensure a match.

 change the ddr freqency */

	/*

	 * Fetch new parents

	 *

	 * new_dram_alt_parent and new_dram_apb_parent are optional but

	 * new_dram_core_parent is not.

 increase reference counts and ensure clks are ON before switch */

 update parents in clk tree after switch. */

	/*

	 * Explicitly refresh dram PLL rate.

	 *

	 * Even if it's marked with CLK_GET_RATE_NOCACHE the rate will not be

	 * automatically refreshed when clk_get_rate is called on children.

	/*

	 * clk_set_parent transfer the reference count from old parent.

	 * now we drop extra reference counts used during the switch

	/*

	 * Read back the clk rate to verify switch was correct and so that

	 * we can report it on all error paths.

 An error here means DDR DVFS API not supported by firmware */

 Result should be strictly positive */

 dram_core has 2 options: dram_pll or dram_alt_root */

 dram_apb and dram_alt have exactly 8 possible parents */

 dram_core from alt requires explicit dram_alt parent */

 Enumerate DT OPPs and disable those not supported by firmware */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016, Fuzhou Rockchip Electronics Co., Ltd.

 * Author: Lin Huang <hl@rock-chips.com>

		/*

		 * This makes a SMC call to the TF-A to set the DDR PD

		 * (power-down) timings and to enable or disable the

		 * ODT (on-die termination) resistors.

	/*

	 * If frequency scaling from low to high, adjust voltage first.

	 * If frequency scaling from high to low, adjust frequency first.

	/*

	 * Check the dpll rate,

	 * There only two result we will get,

	 * 1. Ddr frequency scaling fail, we still get the old rate.

	 * 2. Ddr frequency scaling sucessful, we get the rate we set.

 If get the incorrect rate, set voltage to old value. */

	/*

	 * Get dram timing and pass it to arm trust firmware,

	 * the dram driver in arm trust firmware will get these

	 * timing and to do dram initial.

	/*

	 * In TF-A there is a platform SIP call to set the PD (power-down)

	 * timings and to enable or disable the ODT (on-die termination).

	 * This call needs three arguments as follows:

	 *

	 * arg0:

	 *     bit[0-7]   : sr_idle

	 *     bit[8-15]  : sr_mc_gate_idle

	 *     bit[16-31] : standby idle

	 * arg1:

	 *     bit[0-11]  : pd_idle

	 *     bit[16-27] : srpd_lite_idle

	 * arg2:

	 *     bit[0]     : odt enable

	/*

	 * We add a devfreq driver to our parent since it has a device tree node

	 * with operating points.

	/*

	 * Before remove the opp table we need to unregister the opp notifier.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * exynos_ppmu.c - Exynos PPMU (Platform Performance Monitoring Unit) support

 *

 * Copyright (c) 2014-2015 Samsung Electronics Co., Ltd.

 * Author : Chanwoo Choi <cw00.choi@samsung.com>

 *

 * This driver is based on drivers/devfreq/exynos/exynos_ppmu.c

 For Exynos3250, Exynos4 and Exynos5260 */

 For Exynos4 SoCs and Exynos3250 */

 Only for Exynos3250 and Exynos5260 */

 Only for Exynos4 SoCs */

 Only for Exynos5260 SoCs */

 Only for Exynos5433 SoCs */

 For Exynos5422 SoC, deprecated (backwards compatible) */

 For Exynos5422 SoC */

/*

 * The devfreq-event ops structure for PPMU v1.1

 Disable all counters */

 Disable PPMU */

 Enable specific counter */

 Set the event of proper data type monitoring */

 Reset cycle counter/performance counter and enable PPMU */

 Disable PPMU */

 Read cycle count */

 Read performance count */

 Disable specific counter */

/*

 * The devfreq-event ops structure for PPMU v2.0

 Disable all counters */

 Disable PPMU */

 Enable all counters */

 Set the event of proper data type monitoring */

 Reset cycle counter/performance counter and enable PPMU */

 Disable PPMU */

 Read cycle count and performance count */

 Disable all counters */

 sentinel */ },

			/* Set the event of proper data type counting.

			 * Check if the data type has been defined in DT,

			 * use default if not.

				/* Not all registers take the same value for

				 * read+write data count.

 Maps the memory mapped IO to control PPMU register */

 Parse dt data to get resource */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * exynos-nocp.c - Exynos NoC (Network On Chip) Probe support

 *

 * Copyright (c) 2016 Samsung Electronics Co., Ltd.

 * Author : Chanwoo Choi <cw00.choi@samsung.com>

/*

 * The devfreq-event ops structure for nocp probe.

 Disable NoC probe */

 Set a statistics dump period to 0 */

 Set the IntEvent fields of *_SRC */

 Set an alarm with a max/min value of 0 to generate StatALARM */

 Set AlarmMode */

 Enable the measurements by setting AlarmEn and StatEn */

 Set GlobalEN */

 Enable NoC probe */

 Reset NoC probe */

 Read cycle count */

 sentinel */ },

 Maps the memory mapped IO to control nocp register */

 Parse dt data to get resource */

 Add devfreq-event device to measure the bandwidth of NoC */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016, Fuzhou Rockchip Electronics Co., Ltd

 * Author: Lin Huang <hl@rock-chips.com>

 DDRMON_CTRL */

/*

 * The dfi controller can monitor DDR load. It has an upper and lower threshold

 * for the operating points. Whenever the usage leaves these bounds an event is

 * generated to indicate the DDR frequency should be changed.

 get ddr type */

 clear DDRMON_CTRL setting */

 set ddr type to dfi */

 enable count, use software mode */

 Find out which channel is busier */

 try to find the optional reference to the pmu syscon */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * The Industrial I/O core, software trigger functions

 *

 * Copyright (c) 2015 Intel Corporation

 SPDX-License-Identifier: GPL-2.0-only

/* The industrial I/O core, trigger handling functions

 *

 * Copyright (c) 2008 Jonathan Cameron

/* RFC - Question of approach

 * Make the common case (single sensor single trigger)

 * simple by starting trigger capture from when first sensors

 * is added.

 *

 * Complex simultaneous start requires use of 'hold' functionality

 * of the trigger. (not implemented)

 *

 * Any other suggestions?

 Single list of all available triggers */

/**

 * iio_trigger_read_name() - retrieve useful identifying name

 * @dev:	device associated with the iio_trigger

 * @attr:	pointer to the device_attribute structure that is

 *		being processed

 * @buf:	buffer to print the name into

 *

 * Return: a negative number on failure or the number of written

 *	   characters on success.

 Set the name used for the sysfs directory etc */

 Add to list of available triggers held by the IIO core */

 Possible issue in here */

 Search for trigger by name, assuming iio_trigger_list_lock held */

 Trigger Consumer related functions */

/* Complexity in here.  With certain triggers (datardy) an acknowledgement

 * may be needed if the pollfuncs do not include the data read for the

 * triggering device.

 * This is not currently handled.  Alternative of not enabling trigger unless

 * the relevant function is in there may be the best option.

 Worth protecting against double additions? */

 Prevent the module from being removed whilst attached to a trigger */

 Get irq number */

 Request irq */

 Enable trigger in driver */

	/*

	 * Check if we just registered to our own trigger: we determine that

	 * this is the case if the IIO device and the trigger device share the

	 * same parent device.

/**

 * iio_trigger_read_current() - trigger consumer sysfs query current trigger

 * @dev:	device associated with an industrial I/O device

 * @attr:	pointer to the device_attribute structure that

 *		is being processed

 * @buf:	buffer where the current trigger name will be printed into

 *

 * For trigger consumers the current_trigger interface allows the trigger

 * used by the device to be queried.

 *

 * Return: a negative number on failure, the number of characters written

 *	   on success or 0 if no trigger is available

/**

 * iio_trigger_write_current() - trigger consumer sysfs set current trigger

 * @dev:	device associated with an industrial I/O device

 * @attr:	device attribute that is being processed

 * @buf:	string buffer that holds the name of the trigger

 * @len:	length of the trigger name held by buf

 *

 * For trigger consumers the current_trigger interface allows the trigger

 * used for this device to be specified at run time based on the trigger's

 * name.

 *

 * Return: negative error code on failure or length of the buffer

 *	   on success

/**

 * iio_trigger_alloc - Allocate a trigger

 * @parent:		Device to allocate iio_trigger for

 * @fmt:		trigger name format. If it includes format

 *			specifiers, the additional arguments following

 *			format are formatted and inserted in the resulting

 *			string replacing their respective specifiers.

 * RETURNS:

 * Pointer to allocated iio_trigger on success, NULL on failure.

/**

 * devm_iio_trigger_alloc - Resource-managed iio_trigger_alloc()

 * Managed iio_trigger_alloc.  iio_trigger allocated with this function is

 * automatically freed on driver detach.

 * @parent:		Device to allocate iio_trigger for

 * @fmt:		trigger name format. If it includes format

 *			specifiers, the additional arguments following

 *			format are formatted and inserted in the resulting

 *			string replacing their respective specifiers.

 *

 *

 * RETURNS:

 * Pointer to allocated iio_trigger on success, NULL on failure.

 use raw alloc_dr for kmalloc caller tracing */

/**

 * __devm_iio_trigger_register - Resource-managed iio_trigger_register()

 * @dev:	device this trigger was allocated for

 * @trig_info:	trigger to register

 * @this_mod:   module registering the trigger

 *

 * Managed iio_trigger_register().  The IIO trigger registered with this

 * function is automatically unregistered on driver detach. This function

 * calls iio_trigger_register() internally. Refer to that function for more

 * information.

 *

 * RETURNS:

 * 0 on success, negative error number on failure.

/**

 * iio_trigger_validate_own_device - Check if a trigger and IIO device belong to

 *  the same device

 * @trig: The IIO trigger to check

 * @indio_dev: the IIO device to check

 *

 * This function can be used as the validate_device callback for triggers that

 * can only be attached to their own device.

 *

 * Return: 0 if both the trigger and the IIO device belong to the same

 * device, -EINVAL otherwise.

 Clean up an associated but not attached trigger reference */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2015 Cogent Embedded, Inc.

/**

 * iio_triggered_event_setup() - Setup pollfunc_event for triggered event

 * @indio_dev:	IIO device structure

 * @h:		Function which will be used as pollfunc_event top half

 * @thread:	Function which will be used as pollfunc_event bottom half

 *

 * This function combines some common tasks which will normally be performed

 * when setting up a triggered event. It will allocate the pollfunc_event and

 * set mode to use it for triggered event.

 *

 * Before calling this function the indio_dev structure should already be

 * completely initialized, but not yet registered. In practice this means that

 * this function should be called right before iio_device_register().

 *

 * To free the resources allocated by this function call

 * iio_triggered_event_cleanup().

 Flag that events polling is possible */

/**

 * iio_triggered_event_cleanup() - Free resources allocated by iio_triggered_event_setup()

 * @indio_dev: IIO device structure

 SPDX-License-Identifier: GPL-2.0-only

/* The industrial I/O core in kernel channel mapping

 *

 * Copyright (c) 2011 Jonathan Cameron

/*

 * Remove all map entries associated with the given iio device

/**

 * __of_iio_simple_xlate - translate iiospec to the IIO channel index

 * @indio_dev:	pointer to the iio_dev structure

 * @iiospec:	IIO specifier as found in the device tree

 *

 * This is simple translation function, suitable for the most 1:1 mapped

 * channels in IIO chips. This function performs only one sanity check:

 * whether IIO index is less than num_channels (that is specified in the

 * iio_dev).

 Walk up the tree of devices looking for a matching iio channel */

		/*

		 * For named iio channels, first look up the name in the

		 * "io-channel-names" property.  If it cannot be found, the

		 * index will be an error code, and of_iio_channel_get()

		 * will fail.

		/*

		 * No matching IIO channel found on this node.

		 * If the parent node has a "io-channel-ranges" property,

		 * then we can try one of its channels.

 no error, return NULL to search map table */

 NULL terminated array to save passing size */

 Search for OF matches */

 CONFIG_OF */

 CONFIG_OF */

 first find matching entry the channel map */

 first count the matching maps */

 NULL terminated array to save passing size */

 for each map fill in the chans element */

		/*

		 * Just pass raw values as processed if no scaling is

		 * available.

 This is just a special case with scale factor 1 */

 raw values are assumed to be IIO_VAL_INT */

 FIXME: learn about max for other iio values */

 Need to verify underlying driver has not gone away */

 SPDX-License-Identifier: GPL-2.0-only

/* Industrial I/O event handling

 *

 * Copyright (c) 2008 Jonathan Cameron

 *

 * Based on elements of hwmon and input subsystems.

/**

 * struct iio_event_interface - chrdev interface for an event line

 * @wait:		wait queue to allow blocking reads of events

 * @det_events:		list of detected events

 * @dev_attr_list:	list of event interface sysfs attribute

 * @flags:		file operations related flags including busy flag.

 * @group:		event interface sysfs attribute group

 * @read_lock:		lock to protect kfifo read operations

 * @ioctl_handler:	handler for event ioctl() calls

/**

 * iio_push_event() - try to add event to the list for userspace reading

 * @indio_dev:		IIO device structure

 * @ev_code:		What event

 * @timestamp:		When the event occurred

 *

 * Note: The caller must make sure that this function is not running

 * concurrently for the same indio_dev more than once.

 *

 * This function may be safely used as soon as a valid reference to iio_dev has

 * been obtained via iio_device_alloc(), but any events that are submitted

 * before iio_device_register() has successfully completed will be silently

 * discarded.

 Does anyone care? */

/**

 * iio_event_poll() - poll the event queue to find out if it has data

 * @filep:	File structure pointer to identify the device

 * @wait:	Poll table pointer to add the wait queue on

 *

 * Return: (EPOLLIN | EPOLLRDNORM) if data is available for reading

 *	   or a negative error code on failure

		/*

		 * If we couldn't read anything from the fifo (a different

		 * thread might have been faster) we either return -EAGAIN if

		 * the file descriptor is non-blocking, otherwise we go back to

		 * sleep and wait for more data to arrive.

 Dynamically created from the channels array */

 Add all elements from the list. */

/**

 * iio_device_wakeup_eventset - Wakes up the event waitqueue

 * @indio_dev: The IIO device

 *

 * Wakes up the event waitqueue used for poll() and blocking read().

 * Should usually be called when the device is unregistered.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * The Industrial I/O core, software IIO devices functions

 *

 * Copyright (c) 2016 Intel Corporation

 SPDX-License-Identifier: GPL-2.0-only

/* The industrial I/O core

 *

 * Copyright (c) 2008 Jonathan Cameron

 *

 * Handling of buffer allocation / resizing.

 *

 * Things to look at here.

 * - Better memory allocation techniques?

 * - Alternative access techniques?

 wakeup if the device was unregistered */

 drain the buffer if it was disabled */

 force a flush for non-blocking reads */

/**

 * iio_buffer_read() - chrdev read for buffer access

 * @filp:	File structure pointer for the char device

 * @buf:	Destination buffer for iio buffer read

 * @n:		First n bytes to read

 * @f_ps:	Long offset provided by the user as a seek position

 *

 * This function relies on all buffer implementations having an

 * iio_buffer as their first element.

 *

 * Return: negative values corresponding to error codes or ret != 0

 *	   for ending the reading activity

	/*

	 * If datum_size is 0 there will never be anything to read from the

	 * buffer, so signal end of file now.

/**

 * iio_buffer_poll() - poll the buffer to find out if it has data

 * @filp:	File structure pointer for device access

 * @wait:	Poll table structure pointer for which the driver adds

 *		a wait queue

 *

 * Return: (EPOLLIN | EPOLLRDNORM) if data is available for reading

 *	   or 0 for other cases

 check if buffer was opened through new API */

 check if buffer was opened through new API */

 check if buffer was opened through new API */

/**

 * iio_buffer_wakeup_poll - Wakes up the buffer waitqueue

 * @indio_dev: The IIO device

 *

 * Wakes up the event waitqueue used for poll(). Should usually

 * be called when the device is unregistered.

 Ensure ret is 0 or 1. */

 Note NULL used as error indicator as it doesn't make sense. */

/**

 * iio_scan_mask_set() - set particular bit in the scan mask

 * @indio_dev: the iio device

 * @buffer: the buffer whose scan mask we are interested in

 * @bit: the bit to be set.

 *

 * Note that at this point we have no way of knowing what other

 * buffers might request, hence this code only verifies that the

 * individual buffers request is plausible.

 Ensure return value is 0 or 1. */

 How much space will the demuxed element take? */

 If the mask is dynamically allocated free it, otherwise do nothing */

	/*

	 * If there is just one buffer and we are removing it there is nothing

	 * to verify.

 Definitely possible for devices to support both of these. */

		/*

		 * Keep things simple for now and only allow a single buffer to

		 * be connected in hardware mode.

 Can only occur on first buffer */

 What scan mask do we actually have? */

/**

 * struct iio_demux_table - table describing demux memcpy ops

 * @from:	index to copy from

 * @to:		index to copy to

 * @length:	how many bytes to copy

 * @l:		list head used for management

 Clear out any old demux */

 First work out which scan mode we will actually have */

 Now we have the two masks, work from least sig and build up sizes */

 Make sure we are aligned */

 Relies on scan_timestamp being last */

 Wind up again */

 Wind down existing buffers - iff there are any */

	/*

	 * If things go wrong at some step in disable we still need to continue

	 * to perform the other steps, otherwise we leave the device in a

	 * inconsistent state. We return the error code for the first error we

	 * encountered.

 If no buffers in list, we are done */

	/*

	 * We've already verified that the config is valid earlier. If things go

	 * wrong in either enable or disable the most likely reason is an IO

	 * error from the device. In this case there is no good recovery

	 * strategy. Just make sure to disable everything and leave the device

	 * in a sane state.  With a bit of luck the device might come back to

	 * life again later and userspace can try again.

 Find out if it is in the list */

 Already in desired state */

/*

 * When adding new attributes here, put the at the end, at least until

 * the code that handles the length/length_ro & watermark/watermark_ro

 * assignments gets cleaned up. Otherwise these can create some weird

 * duplicate attributes errors under some setups.

 new magic */

 we only need to register the legacy groups for the first buffer */

/**

 * iio_validate_scan_mask_onehot() - Validates that exactly one channel is selected

 * @indio_dev: the iio device

 * @mask: scan mask to be checked

 *

 * Return true if exactly one bit is set in the scan mask, false otherwise. It

 * can be used for devices where only one channel can be active for sampling at

 * a time.

	/*

	 * We can't just test for watermark to decide if we wake the poll queue

	 * because read may request less samples than the watermark.

/**

 * iio_push_to_buffers() - push to a registered buffer.

 * @indio_dev:		iio_dev structure for device.

 * @data:		Full scan.

/**

 * iio_push_to_buffers_with_ts_unaligned() - push to registered buffer,

 *    no alignment or space requirements.

 * @indio_dev:		iio_dev structure for device.

 * @data:		channel data excluding the timestamp.

 * @data_sz:		size of data.

 * @timestamp:		timestamp for the sample data.

 *

 * This special variant of iio_push_to_buffers_with_timestamp() does

 * not require space for the timestamp, or 8 byte alignment of data.

 * It does however require an allocation on first call and additional

 * copies on all calls, so should be avoided if possible.

	/*

	 * Conservative estimate - we can always safely copy the minimum

	 * of either the data provided or the length of the destination buffer.

	 * This relaxed limit allows the calling drivers to be lax about

	 * tracking the size of the data they are pushing, at the cost of

	 * unnecessary copying of padding.

/**

 * iio_buffer_release() - Free a buffer's resources

 * @ref: Pointer to the kref embedded in the iio_buffer struct

 *

 * This function is called when the last reference to the buffer has been

 * dropped. It will typically free all resources allocated by the buffer. Do not

 * call this function manually, always use iio_buffer_put() when done using a

 * buffer.

/**

 * iio_buffer_get() - Grab a reference to the buffer

 * @buffer: The buffer to grab a reference for, may be NULL

 *

 * Returns the pointer to the buffer that was passed into the function.

/**

 * iio_buffer_put() - Release the reference to the buffer

 * @buffer: The buffer to release the reference for, may be NULL

/**

 * iio_device_attach_buffer - Attach a buffer to a IIO device

 * @indio_dev: The device the buffer should be attached to

 * @buffer: The buffer to attach to the device

 *

 * Return 0 if successful, negative if error.

 *

 * This function attaches a buffer to a IIO device. The buffer stays attached to

 * the device until the device is freed. For legacy reasons, the first attached

 * buffer will also be assigned to 'indio_dev->buffer'.

 * The array allocated here, will be free'd via the iio_device_detach_buffers()

 * call which is handled by the iio_device_free().

 first buffer is legacy; attach it to the IIO device directly */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Industrial I/O configfs bits

 *

 * Copyright (c) 2015 Intel Corporation

 SPDX-License-Identifier: GPL-2.0-only

/* The industrial I/O core

 *

 * Copyright (c) 2008 Jonathan Cameron

 *

 * Based on elements of hwmon and input subsystems.

 IDA to assign each registered device a unique id */

 relies on pairs of these shared then separate */

/**

 * iio_device_id() - query the unique ID for the device

 * @indio_dev:		Device structure whose ID is being queried

 *

 * The IIO device ID is a unique index used for example for the naming

 * of the character device /dev/iio\:device[ID]

/**

 * iio_sysfs_match_string_with_gaps - matches given string in an array with gaps

 * @array: array of strings

 * @n: number of strings in the array

 * @str: string to match with

 *

 * Returns index of @str in the @array or -EINVAL, similar to match_string().

 * Uses sysfs_streq instead of strcmp for matching.

 *

 * This routine will look for a string in an array of strings.

 * The search will continue until the element is found or the n-th element

 * is reached, regardless of any NULL elements in the array.

/*

 * There's also a CONFIG_DEBUG_FS guard in include/linux/iio/iio.h for

 * iio_get_debugfs_dentry() to make it inline if CONFIG_DEBUG_FS is undefined

/**

 * iio_find_channel_from_si() - get channel from its scan index

 * @indio_dev:		device

 * @si:			scan index to match

 This turns up an awful lot */

/**

 * iio_device_set_clock() - Set current timestamping clock for the device

 * @indio_dev: IIO device structure containing the device

 * @clock_id: timestamping clock posix identifier to set.

/**

 * iio_device_get_clock() - Retrieve current timestamping clock for the device

 * @indio_dev: IIO device structure containing the device

/**

 * iio_get_time_ns() - utility function to get a time stamp for events etc

 * @indio_dev: device

/**

 * iio_get_time_res() - utility function to get time stamp clock resolution in

 *                      nano seconds.

 * @indio_dev: device

 Register sysfs bus */

 CONFIG_DEBUG_FS */

 replace last space with a newline */

/**

 * iio_read_mount_matrix() - retrieve iio device mounting matrix from

 *                           device "mount-matrix" property

 * @dev:	device the mounting matrix property is assigned to

 * @matrix:	where to store retrieved matrix

 *

 * If device is assigned no mounting matrix property, a default 3x3 identity

 * matrix will be filled in.

 *

 * Return: 0 if success, or a negative error code on failure.

 Invalid number of matrix entries. */

 Invalid matrix declaration format. */

 Matrix was not declared at all: fallback to identity. */

/**

 * iio_format_value() - Formats a IIO value into its string representation

 * @buf:	The buffer to which the formatted value gets written

 *		which is assumed to be big enough (i.e. PAGE_SIZE).

 * @type:	One of the IIO_VAL_* constants. This decides how the val

 *		and val2 parameters are formatted.

 * @size:	Number of IIO value entries contained in vals

 * @vals:	Pointer to the values, exact meaning depends on the

 *		type parameter.

 *

 * Return: 0 by default, a negative number on failure or the

 *	   total number of characters written for a type that belongs

 *	   to the IIO_VAL_* constant.

/**

 * __iio_str_to_fixpoint() - Parse a fixed-point number from a string

 * @str: The string to parse

 * @fract_mult: Multiplier for the first decimal place, should be a power of 10

 * @integer: The integer part of the number

 * @fract: The fractional part of the number

 * @scale_db: True if this should parse as dB

 *

 * Returns 0 on success, or a negative error code if the string could not be

 * parsed.

 Ignore the dB suffix */

 Ignore the dB suffix */

/**

 * iio_str_to_fixpoint() - Parse a fixed-point number from a string

 * @str: The string to parse

 * @fract_mult: Multiplier for the first decimal place, should be a power of 10

 * @integer: The integer part of the number

 * @fract: The fractional part of the number

 *

 * Returns 0 on success, or a negative error code if the string could not be

 * parsed.

 Assumes decimal - precision based on number of digits */

 Build up postfix of <extend_name>_<modifier>_postfix */

 Differential can not have modifier */

 Single ended */

/**

 * iio_free_chan_devattr_list() - Free a list of IIO device attributes

 * @attr_list: List of IIO device attributes

 *

 * This function frees the memory allocated for each of the IIO device

 * attributes in the list.

 First count elements in any existing group */

	/*

	 * New channel registration method - relies on the fact a group does

	 * not need to be initialized if its name is NULL.

 Copy across original attributes */

 Add all elements from the list. */

/**

 * iio_device_alloc() - allocate an iio_dev from a driver

 * @parent:		Parent device.

 * @sizeof_priv:	Space to allocate for private structure.

 cannot use a dev_err as the name isn't available */

/**

 * iio_device_free() - free an iio_dev from a driver

 * @dev:		the iio_dev associated with the device

/**

 * devm_iio_device_alloc - Resource-managed iio_device_alloc()

 * @parent:		Device to allocate iio_dev for, and parent for this IIO device

 * @sizeof_priv:	Space to allocate for private structure.

 *

 * Managed iio_device_alloc. iio_dev allocated with this function is

 * automatically freed on driver detach.

 *

 * RETURNS:

 * Pointer to allocated iio_dev on success, NULL on failure.

/**

 * iio_chrdev_open() - chrdev file open for buffer access and ioctls

 * @inode:	Inode structure for identifying the device in the file system

 * @filp:	File structure for iio device used to keep and later access

 *		private data

 *

 * Return: 0 on success or -EBUSY if the device is already opened

/**

 * iio_chrdev_release() - chrdev file close buffer access and ioctls

 * @inode:	Inode structure pointer for the char device

 * @filp:	File structure pointer for the char device

 *

 * Return: 0 for successful release

	/**

	 * The NULL check here is required to prevent crashing when a device

	 * is being removed while userspace would still have open file handles

	 * to try to access this device.

 If the calling driver did not initialize of_node, do it here */

 assign device groups now; they should be all registered now */

/**

 * iio_device_unregister() - unregister a device from the IIO subsystem

 * @indio_dev:		Device structure representing the device.

/**

 * iio_device_claim_direct_mode - Keep device in direct mode

 * @indio_dev:	the iio_dev associated with the device

 *

 * If the device is in direct mode it is guaranteed to stay

 * that way until iio_device_release_direct_mode() is called.

 *

 * Use with iio_device_release_direct_mode()

 *

 * Returns: 0 on success, -EBUSY on failure

/**

 * iio_device_release_direct_mode - releases claim on direct mode

 * @indio_dev:	the iio_dev associated with the device

 *

 * Release the claim. Device is no longer guaranteed to stay

 * in direct mode.

 *

 * Use with iio_device_claim_direct_mode()

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2014, Samsung Electronics Co. Ltd. All Rights Reserved.

/*

 * SSP -> AP Instruction

 * They tell what packet type can be expected. In the future there will

 * be less of them. BYPASS means common sensor packets with accel, gyro,

 * hrm etc. data. LIBRARY and META are mock-up's for now.

/*

 * It is a bit heavy to do it this way but often the function is used to compose

 * the message from smaller chunks which are placed on the stack.  Often the

 * chunks are small so memcpy should be optimalized.

/*

 * It was designed that way - additional lines to some kind of handshake,

 * please do not ask why - only the firmware guy can know it.

	/*

	 * check if this is a short one way message or the whole transfer has

	 * second part after an interrupt

 mock-up, it will be changed with adding another sensor types */

 threaded irq */

		/*

		 * this is a small list, a few elements - the packets can be

		 * received with no order

			/*

			 * here can be implemented dead messages handling

			 * but the slave should not send such ones - it is to

			 * check but let's handle this

 got dead packet so it is always an error */

 just fail */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2014, Samsung Electronics Co. Ltd. All Rights Reserved.

 It is possible that it is max clk rate for version 1.0 of bootcode */

/*

 * These fields can look enigmatic but this structure is used mainly to flat

 * some values and depends on command type.

/*

 * This function is the first one which communicates with the mcu so it is

 * possible that the first attempt will fail

/**

 * ssp_get_sensor_delay() - gets sensor data acquisition period

 * @data:	sensorhub structure

 * @type:	SSP sensor type

 *

 * Returns acquisition period in ms

/**

 * ssp_enable_sensor() - enables data acquisition for sensor

 * @data:	sensorhub structure

 * @type:	SSP sensor type

 * @delay:	delay in ms

 *

 * Returns 0 or negative value in case of error

 do calibration step, now just enable */

/**

 * ssp_change_delay() - changes data acquisition for sensor

 * @data:	sensorhub structure

 * @type:	SSP sensor type

 * @delay:	delay in ms

 *

 * Returns 0 or negative value in case of error

/**

 * ssp_disable_sensor() - disables sensor

 *

 * @data:	sensorhub structure

 * @type:	SSP sensor type

 *

 * Returns 0 or negative value in case of error

	/*

	 * This wrapper is done to preserve error path for ssp_irq_msg, also

	 * it is defined in different file.

	/*

	 * needs clarification, for now do not want to export all transfer

	 * methods to sensors' drivers

/*

 * sensorhub can request its reinitialization as some brutal and rare error

 * handling. It can be requested from the MCU.

/**

 * ssp_register_consumer() - registers iio consumer in ssp framework

 *

 * @indio_dev:	consumer iio device

 * @type:	ssp sensor type

 Let's start with enabled one so irq balance could be ok */

 just to avoid unbalanced irq set wake up */

 timesyncing is set by MCU */

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2014, Samsung Electronics Co. Ltd. All Rights Reserved.

/**

 * ssp_common_buffer_postenable() - generic postenable callback for ssp buffer

 *

 * @indio_dev:		iio device

 *

 * Returns 0 or negative value in case of error

	/* the allocation is made in post because scan size is known in this

	 * moment

/**

 * ssp_common_buffer_postdisable() - generic postdisable callback for ssp buffer

 *

 * @indio_dev:		iio device

 *

 * Returns 0 or negative value in case of error

/**

 * ssp_common_process_data() - Common process data callback for ssp sensors

 *

 * @indio_dev:		iio device

 * @buf:		source buffer

 * @len:		sensor data length

 * @timestamp:		system timestamp

 *

 * Returns 0 or negative value in case of error

	/*

	 * it always sends full set of samples, remember about available masks

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Measurements Specialties driver common i2c functions

 *

 * Copyright (c) 2015 Measurement-Specialties

 Conversion times in us */

/**

 * ms_sensors_reset() - Reset function

 * @cli:	pointer to device client

 * @cmd:	reset cmd. Depends on device in use

 * @delay:	usleep minimal delay after reset command is issued

 *

 * Generic I2C reset function for Measurement Specialties devices.

 *

 * Return: 0 on success, negative errno otherwise.

/**

 * ms_sensors_read_prom_word() - PROM word read function

 * @cli:	pointer to device client

 * @cmd:	PROM read cmd. Depends on device and prom id

 * @word:	pointer to word destination value

 *

 * Generic i2c prom word read function for Measurement Specialties devices.

 *

 * Return: 0 on success, negative errno otherwise.

/**

 * ms_sensors_convert_and_read() - ADC conversion & read function

 * @cli:	pointer to device client

 * @conv:	ADC conversion command. Depends on device in use

 * @rd:		ADC read command. Depends on device in use

 * @delay:	usleep minimal delay after conversion command is issued

 * @adc:	pointer to ADC destination value

 *

 * Generic ADC conversion & read function for Measurement Specialties

 * devices.

 * The function will issue conversion command, sleep appopriate delay, and

 * issue command to read ADC.

 *

 * Return: 0 on success, negative errno otherwise.

 Trigger conversion */

 Retrieve ADC value */

/**

 * ms_sensors_crc_valid() - CRC check function

 * @value:	input and CRC compare value

 *

 * Cyclic Redundancy Check function used in TSYS02D, HTU21, MS8607.

 * This function performs a x^8 + x^5 + x^4 + 1 polynomial CRC.

 * The argument contains CRC value in LSB byte while the bytes 1 and 2

 * are used for CRC computation.

 *

 * Return: 1 if CRC is valid, 0 otherwise.

 x^8 + x^5 + x^4 + 1 */

/**

 * ms_sensors_read_serial() - Serial number read function

 * @client:	pointer to i2c client

 * @sn:		pointer to 64-bits destination value

 *

 * Generic i2c serial number read function for Measurement Specialties devices.

 * This function is used for TSYS02d, HTU21, MS8607 chipset.

 * Refer to datasheet:

 *	http://www.meas-spec.com/downloads/HTU2X_Serial_Number_Reading.pdf

 *

 * Sensor raw MSB serial number format is the following :

 *	[ SNB3, CRC, SNB2, CRC, SNB1, CRC, SNB0, CRC]

 * Sensor raw LSB serial number format is the following :

 *	[ X, X, SNC1, SNC0, CRC, SNA1, SNA0, CRC]

 * The resulting serial number is following :

 *	[ SNA1, SNA0, SNB3, SNB2, SNB1, SNB0, SNC1, SNC0]

 *

 * Return: 0 on success, negative errno otherwise.

 Read MSB part of serial number */

 Read LSB part of serial number */

/**

 * ms_sensors_write_resolution() - Set resolution function

 * @dev_data:	pointer to temperature/humidity device data

 * @i:		resolution index to set

 *

 * This function will program the appropriate resolution based on the index

 * provided when user space will set samp_freq channel.

 * This function is used for TSYS02D, HTU21 and MS8607 chipsets.

 *

 * Return: 0 on success, negative errno otherwise.

/**

 * ms_sensors_show_battery_low() - Show device battery low indicator

 * @dev_data:	pointer to temperature/humidity device data

 * @buf:	pointer to char buffer to write result

 *

 * This function will read battery indicator value in the device and

 * return 1 if the device voltage is below 2.25V.

 * This function is used for TSYS02D, HTU21 and MS8607 chipsets.

 *

 * Return: length of sprintf on success, negative errno otherwise.

/**

 * ms_sensors_show_heater() - Show device heater

 * @dev_data:	pointer to temperature/humidity device data

 * @buf:	pointer to char buffer to write result

 *

 * This function will read heater enable value in the device and

 * return 1 if the heater is enabled.

 * This function is used for HTU21 and MS8607 chipsets.

 *

 * Return: length of sprintf on success, negative errno otherwise.

/**

 * ms_sensors_write_heater() - Write device heater

 * @dev_data:	pointer to temperature/humidity device data

 * @buf:	pointer to char buffer from user space

 * @len:	length of buf

 *

 * This function will write 1 or 0 value in the device

 * to enable or disable heater.

 * This function is used for HTU21 and MS8607 chipsets.

 *

 * Return: length of buffer, negative errno otherwise.

/**

 * ms_sensors_ht_read_temperature() - Read temperature

 * @dev_data:	pointer to temperature/humidity device data

 * @temperature:pointer to temperature destination value

 *

 * This function will get temperature ADC value from the device,

 * check the CRC and compute the temperature value.

 * This function is used for TSYS02D, HTU21 and MS8607 chipsets.

 *

 * Return: 0 on success, negative errno otherwise.

 Temperature algorithm */

/**

 * ms_sensors_ht_read_humidity() - Read humidity

 * @dev_data:	pointer to temperature/humidity device data

 * @humidity:	pointer to humidity destination value

 *

 * This function will get humidity ADC value from the device,

 * check the CRC and compute the temperature value.

 * This function is used for HTU21 and MS8607 chipsets.

 *

 * Return: 0 on success, negative errno otherwise.

 Humidity algorithm */

/**

 * ms_sensors_tp_crc4() - Calculate PROM CRC for

 *     Temperature and pressure devices.

 *     This function is only used when reading PROM coefficients

 *

 * @prom:	pointer to PROM coefficients array

 *

 * Return: CRC.

/**

 * ms_sensors_tp_crc_valid_112() - CRC check function for

 *     Temperature and pressure devices for 112bit PROM.

 *     This function is only used when reading PROM coefficients

 *

 * @prom:	pointer to PROM coefficients array

 *

 * Return: True if CRC is ok.

 Clear the CRC computation part */

/**

 * ms_sensors_tp_crc_valid_128() - CRC check function for

 *     Temperature and pressure devices for 128bit PROM.

 *     This function is only used when reading PROM coefficients

 *

 * @prom:	pointer to PROM coefficients array

 *

 * Return: True if CRC is ok.

 Clear the CRC and LSB part */

/**

 * ms_sensors_tp_read_prom() - prom coeff read function

 * @dev_data:	pointer to temperature/pressure device data

 *

 * This function will read prom coefficients and check CRC.

 * This function is used for MS5637 and MS8607 chipsets.

 *

 * Return: 0 on success, negative errno otherwise.

/**

 * ms_sensors_read_temp_and_pressure() - read temp and pressure

 * @dev_data:	pointer to temperature/pressure device data

 * @temperature:pointer to temperature destination value

 * @pressure:	pointer to pressure destination value

 *

 * This function will read ADC and compute pressure and temperature value.

 * This function is used for MS5637 and MS8607 chipsets.

 *

 * Return: 0 on success, negative errno otherwise.

 Actual temperature = 2000 + dT * TEMPSENS */

 Second order temperature compensation */

 OFF = OFF_T1 + TCO * dT */

 Sensitivity at actual temperature = SENS_T1 + TCS * dT */

 Temperature compensated pressure = D1 * SENS - OFF */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics sensors buffer library driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 Advance the buffer pointer */

	/*

	 * If we do timestamping here, do it before reading the values, because

	 * once we've read the values, new interrupts can occur (when using

	 * the hardware trigger) and the hw_timestamp may get updated.

	 * By storing it in a local variable first, we are safe.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics sensors core library driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 Regulators not mandatory, but if requested we should enable them. */

 Sensor does not support interrupts */

/**

 * st_sensors_dev_name_probe() - device probe for ST sensor name

 * @dev: driver model representation of the device.

 * @name: device name buffer reference.

 * @len: device name buffer length.

 *

 * In effect this function matches an ID to an internal kernel

 * name for a certain sensor device, so that the rest of the autodetection can

 * rely on that name from this point on. I2C/SPI devices will be renamed

 * to match the internal kernel convention.

 The name from the match takes precedence if present */

 If OF/DT pdata exists, it will take precedence of anything else */

 Disable DRDY, this might be still be enabled after reboot. */

 set BDU */

 set DAS */

		/*

		 * there are some devices (e.g. LIS3MDL) where drdy line is

		 * routed to a given pin and it is not possible to select a

		 * different one. Take into account irq status register

		 * to understand if irq trigger can be properly supported

 Enable/Disable the interrupt generator 1. */

 Flag to the poll function that the hardware trigger is in use */

 Enable/Disable the interrupt generator for data ready. */

/*

 * st_sensors_get_settings_index() - get index of the sensor settings for a

 *				     specific device from list of settings

 * @name: device name buffer reference.

 * @list: sensor settings list.

 * @list_length: length of sensor settings list.

 *

 * Return: non negative number on success (valid index),

 *	   negative error code otherwise.

/*

 * st_sensors_verify_id() - verify sensor ID (WhoAmI) is matching with the

 *			    expected value

 * @indio_dev: IIO device reference.

 *

 * Return: 0 on success (valid sensor ID), else a negative error code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics sensors i2c library driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

/*

 * st_sensors_i2c_configure() - configure I2C interface

 * @indio_dev: IIO device reference.

 * @client: i2c client reference.

 *

 * Return: 0 on success, else a negative error code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics sensors spi library driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

/*

 * st_sensors_is_spi_3_wire() - check if SPI 3-wire mode has been selected

 * @spi: spi device reference.

 *

 * Return: true if SPI 3-wire mode is selected, false otherwise.

/*

 * st_sensors_configure_spi_3_wire() - configure SPI 3-wire if needed

 * @spi: spi device reference.

 * @settings: sensor specific settings reference.

 *

 * Return: 0 on success, else a negative error code.

/*

 * st_sensors_spi_configure() - configure SPI interface

 * @indio_dev: IIO device reference.

 * @spi: spi device reference.

 *

 * Return: 0 on success, else a negative error code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics sensors trigger library driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

/**

 * st_sensors_new_samples_available() - check if more samples came in

 * @indio_dev: IIO device reference.

 * @sdata: Sensor data.

 *

 * returns:

 * false - no new samples available or read error

 * true - new samples available

 How would I know if I can't check it? */

 No scan mask, no interrupt */

/**

 * st_sensors_irq_handler() - top half of the IRQ-based triggers

 * @irq: irq number

 * @p: private handler data

 Get the time stamp as close in time as possible */

/**

 * st_sensors_irq_thread() - bottom half of the IRQ-based triggers

 * @irq: irq number

 * @p: private handler data

	/*

	 * If this trigger is backed by a hardware interrupt and we have a

	 * status register, check if this IRQ came from us. Notice that

	 * we will process also if st_sensors_new_samples_available()

	 * returns negative: if we can't check status, then poll

	 * unconditionally.

	/*

	 * If we have proper level IRQs the handler will be re-entered if

	 * the line is still active, so return here and come back in through

	 * the top half if need be.

	/*

	 * If we are using edge IRQs, new samples arrived while processing

	 * the IRQ and those may be missed unless we pick them here, so poll

	 * again. If the sensor delivery frequency is very high, this thread

	 * turns into a polled loop handler.

	/*

	 * If the IRQ is triggered on falling edge, we need to mark the

	 * interrupt as active low, if the hardware supports this.

 Set up INT active low i.e. falling edge */

 This is the most preferred mode, if possible */

 Tell the interrupt handler that we're dealing with edges */

		/*

		 * If we're not using edges (i.e. level interrupts) we

		 * just mask off the IRQ, handle one interrupt, then

		 * if the line is still low, we return to the

		 * interrupt handler top half again and start over.

	/*

	 * If the interrupt pin is Open Drain, by definition this

	 * means that the interrupt line may be shared with other

	 * peripherals. But to do this we also need to have a status

	 * register and mask to figure out if this sensor was firing

	 * the IRQ or not, so we can tell the interrupt handle that

	 * it was "our" interrupt.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2012, Intel Corporation.

 Default to 3 seconds, but can be changed from sysfs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2012, Intel Corporation.

 0 for default others from HID sensor spec */

 scale, whole number */

 scale, fraction in nanos */

/*

VTF format uses exponent and variable size format.

For example if the size is 2 bytes

0x0067 with VTF16E14 format -> +1.03

To convert just change to 0x67 to decimal and use two decimal as E14 stands

for 10^-2.

Negative numbers are 2's complement

/*

 * This fuction applies the unit exponent to the scale.

 * For example:

 * 9.806650000 ->exp:2-> val0[980]val1[665000000]

 * 9.000806000 ->exp:2-> val0[900]val1[80600000]

 * 0.174535293 ->exp:2-> val0[17]val1[453529300]

 * 1.001745329 ->exp:0-> val0[1]val1[1745329]

 * 1.001745329 ->exp:2-> val0[100]val1[174532900]

 * 1.001745329 ->exp:4-> val0[10017]val1[453290000]

 * 9.806650000 ->exp:-2-> val0[0]val1[98066500]

 Default unit of measure is milliseconds */

	/*

	 * Set Sensitivity field ids, when there is no individual modifier, will

	 * check absolute sensitivity and relative sensitivity of data field

 SPDX-License-Identifier: GPL-2.0

/*

 * System Control and Management Interface(SCMI) based IIO sensor driver

 *

 * Copyright (C) 2021 Google LLC

 adding one additional channel for timestamp */

		/*

		 *  All the axes are supposed to have the same value for timestamp.

		 *  We are just using the values from the Axis 0 here.

		/*

		 *  Timestamp returned by SCMI is in seconds and is equal to

		 *  time * power-of-10 multiplier(tstamp_scale) seconds.

		 *  Converting the timestamp to nanoseconds below.

	/*

	 * The seconds field in the sensor interval in SCMI is 16 bits long

	 * Therefore seconds  = 1/Hz <= 0xFFFF. As floating point calculations are

	 * discouraged in the kernel driver code, to calculate the scale factor (sf)

	 * (1* 1000000 * sf)/uHz <= 0xFFFF. Therefore, sf <= (uHz * 0xFFFF)/1000000

	 * To calculate the multiplier,we convert the sf into char string  and

	 * count the number of characters

	/*

	 * All the axes are supposed to have the same value for range and resolution.

	 * We are just using the values from the Axis 0 here.

		/*

		 * To provide the raw value for the resolution to the userspace,

		 * need to divide the resolution exponent by the sensor scale

 adding one additional channel for timestamp */

 This driver only supports 3-axis accel and gyro, skipping other sensors */

 This driver only supports 3-axis accel and gyro, skipping other sensors */

 SPDX-License-Identifier: GPL-2.0

/*

 * cros_ec_sensors_core - Common function for Chrome OS EC sensor driver.

 *

 * Copyright (C) 2016 Google, Inc

/*

 * Hard coded to the first device to support sensor fifo.  The EC has a 2048

 * byte fifo and will trigger an interrupt when fifo is 2/3 full.

	/*

	 * We don't know fifo size, set to size previously used by older

	 * hardware.

 EC rate is in ms. */

	/*

	 * Ignore samples if the buffer is not set: it is needed if the ODR is

	 * set but the buffer is not enabled yet.

/**

 * cros_ec_sensors_core_init() - basic initialization of the core structure

 * @pdev:		platform device created for the sensors

 * @indio_dev:		iio device structure of the device

 * @physical_device:	true if the device refers to a physical device

 * @trigger_capture:    function pointer to call buffer is triggered,

 *    for backward compatibility.

 * @push_data:          function to call when cros_ec_sensorhub receives

 *    a sample for that sensor.

 *

 * Return: 0 on success, -errno on failure.

 Set up the host command structure. */

 Set sign vector, only used for backward compatibility. */

 0 is a correct value used to stop the device */

			/*

			 * Create a software buffer, feed by the EC FIFO.

			 * We can not use trigger here, as events are generated

			 * as soon as sample_frequency is set.

 Timestamp coming from FIFO are in ns since boot. */

			/*

			 * The only way to get samples in buffer is to set a

			 * software trigger (systrig, hrtimer).

/**

 * cros_ec_motion_send_host_cmd() - send motion sense host command

 * @state:		pointer to state information for device

 * @opt_length:	optional length to reduce the response size, useful on the data

 *		path. Otherwise, the maximal allowed response size is used

 *

 * When called, the sub-command is assumed to be set in param->cmd.

 *

 * Return: 0 on success, -errno on failure.

 Save values */

/**

 * cros_ec_sensors_idx_to_reg - convert index into offset in shared memory

 * @st:		pointer to state information for device

 * @idx:	sensor index (should be element of enum sensor_index)

 *

 * Return:	address to read at

	/*

	 * When using LPC interface, only space for 2 Accel and one Gyro.

	 * First halfword of MOTIONSENSE_TYPE_ACCEL is used by angle.

/**

 * cros_ec_sensors_read_until_not_busy() - read until is not busy

 *

 * @st:	pointer to state information for device

 *

 * Read from EC status byte until it reads not busy.

 * Return: 8-bit status if ok, -errno on failure.

 Give up after enough attempts, return error. */

 Small delay every so often. */

/**

 * cros_ec_sensors_read_data_unsafe() - read acceleration data from EC shared memory

 * @indio_dev:	pointer to IIO device

 * @scan_mask:	bitmap of the sensor indices to scan

 * @data:	location to store data

 *

 * This is the unsafe function for reading the EC data. It does not guarantee

 * that the EC will not modify the data as it is being read in.

 *

 * Return: 0 on success, -errno on failure.

 Read all sensors enabled in scan_mask. Each value is 2 bytes. */

/**

 * cros_ec_sensors_read_lpc() - read acceleration data from EC shared memory.

 * @indio_dev: pointer to IIO device.

 * @scan_mask: bitmap of the sensor indices to scan.

 * @data: location to store data.

 *

 * Note: this is the safe function for reading the EC data. It guarantees

 * that the data sampled was not modified by the EC while being read.

 *

 * Return: 0 on success, -errno on failure.

	/*

	 * Continually read all data from EC until the status byte after

	 * all reads reflects that the EC is not busy and the sample id

	 * matches the sample id from before all reads. This guarantees

	 * that data read in was not modified by the EC while reading.

 If we have tried to read too many times, return error. */

 Read status byte until EC is not busy. */

		/*

		 * Store the current sample id so that we can compare to the

		 * sample id after reading the data.

 Read all EC data, format it, and store it into data. */

 Read status byte. */

/**

 * cros_ec_sensors_read_cmd() - retrieve data using the EC command protocol

 * @indio_dev:	pointer to IIO device

 * @scan_mask:	bitmap of the sensor indices to scan

 * @data:	location to store data

 *

 * Return: 0 on success, -errno on failure.

 Read all sensor data through a command. */

/**

 * cros_ec_sensors_capture() - the trigger handler function

 * @irq:	the interrupt number.

 * @p:		a pointer to the poll function.

 *

 * On a trigger event occurring, if the pollfunc is attached then this

 * handler is called as a threaded interrupt (and hence may sleep). It

 * is responsible for grabbing data from the device and pushing it into

 * the associated buffer.

 *

 * Return: IRQ_HANDLED

 Clear capture data. */

 Read data based on which channels are enabled in scan mask. */

	/*

	 * Tell the core we are done with this trigger and ready for the

	 * next one.

/**

 * cros_ec_sensors_core_read() - function to request a value from the sensor

 * @st:		pointer to state information for device

 * @chan:	channel specification structure table

 * @val:	will contain one element making up the returned value

 * @val2:	will contain another element making up the returned value

 * @mask:	specifies which values to be requested

 *

 * Return:	the type of value returned by the device

/**

 * cros_ec_sensors_core_read_avail() - get available values

 * @indio_dev:		pointer to state information for device

 * @chan:	channel specification structure table

 * @vals:	list of available values

 * @type:	type of data returned

 * @length:	number of data returned in the array

 * @mask:	specifies which values to be requested

 *

 * Return:	an error code, IIO_AVAIL_RANGE or IIO_AVAIL_LIST

/**

 * cros_ec_sensors_core_write() - function to write a value to the sensor

 * @st:		pointer to state information for device

 * @chan:	channel specification structure table

 * @val:	first part of value to write

 * @val2:	second part of value to write

 * @mask:	specifies which values to write

 *

 * Return:	the type of value returned by the device

 Always roundup, so caller gets at least what it asks for. */

 SPDX-License-Identifier: GPL-2.0

/*

 * cros_ec_lid_angle - Driver for CrOS EC lid angle sensor.

 *

 * Copyright 2018 Google, Inc

 *

 * This driver uses the cros-ec interface to communicate with the Chrome OS

 * EC about counter sensors. Counters are presented through

 * iio sysfs.

/*

 * One channel for the lid angle, the other for timestamp.

 State data for ec_sensors iio driver. */

 Shared by all sensors */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * cros_ec_sensors - Driver for Chrome OS Embedded Controller sensors.

 *

 * Copyright (C) 2016 Google, Inc

 *

 * This driver uses the cros-ec interface to communicate with the Chrome OS

 * EC about sensors data. Data access is presented through iio sysfs.

 State data for ec_sensors iio driver. */

 Shared by all sensors */

 Save values */

 Reading calibscale is not supported on older EC. */

 Save values */

			/*

			 * EC returns data in g, iio exepects m/s^2.

			 * Do not use IIO_G_TO_M_S_2 to avoid precision loss.

			/*

			 * EC returns data in dps, iio expects rad/s.

			 * Do not use IIO_DEGREE_TO_RAD to avoid precision

			 * loss. Round to the nearest integer.

			/*

			 * EC returns data in 16LSB / uT,

			 * iio expects Gauss

 Send to EC for each axis, even if not complete */

 Send to EC for each axis, even if not complete */

 Always roundup, so caller gets at least what it asks for. */

 Common part */

 Sensor specific */

 Timestamp */

 There is only enough room for accel and gyro in the io space */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * AD7150 capacitive sensor driver supporting AD7150/1/6

 *

 * Copyright 2010-2011 Analog Devices Inc.

 * Copyright 2021 Jonathan Cameron <Jonathan.Cameron@huawei.com>

/**

 * struct ad7150_chip_info - instance specific chip data

 * @client: i2c client for this device

 * @threshold: thresholds for simple capacitance value events

 * @thresh_sensitivity: threshold for simple capacitance offset

 *	from 'average' value.

 * @thresh_timeout: a timeout, in samples from the moment an

 *	adaptive threshold event occurs to when the average

 *	value jumps to current value.  Note made up of two fields,

 *      3:0 are for timeout receding - applies if below lower threshold

 *      7:4 are for timeout approaching - applies if above upper threshold

 * @state_lock: ensure consistent state of this structure wrt the

 *	hardware.

 * @interrupts: one or two interrupt numbers depending on device type.

 * @int_enabled: is a given interrupt currently enabled.

 * @type: threshold type

 * @dir: threshold direction

		/*

		 * Base units for capacitance are nano farads and the value

		 * calculated from the datasheet formula is in picofarad

		 * so multiply by 1000

 To match shift in _RAW */

 To match shift in _RAW */

 Strangely same for both 1 and 2 chan parts */

check if threshold mode is fixed or adaptive*/

 state_lock should be held to ensure consistent state */

 Only update value live, if parameter is in use */

 Note completely different from the adaptive versions */

		/*

		 * Single timeout register contains timeouts for both

		 * directions.

	/*

	 * There is only a single shared control and no on chip

	 * interrupt disables for the two interrupt lines.

	 * So, enabling will switch the events configured to enable

	 * whatever was most recently requested and if necessary enable_irq()

	 * the interrupt and any disable will disable_irq() for that

	 * channels interrupt.

		/*

		 * Need to temporarily disable both interrupts if

		 * enabled - this is to avoid races around changing

		 * config and thresholds.

		 * Note enable/disable_irq() are reference counted so

		 * no need to check if already enabled.

		/*

		 * There is a potential race condition here, but not easy

		 * to close given we can't disable the interrupt at the

		 * chip side of things. Rely on the status bit.

 update control attributes */

 reenable any irq's we disabled whilst changing mode */

 Complex register sharing going on here */

		/*

		 * Raw timeout is in cycles of 10 msecs as long as both

		 * channels are enabled.

		 * In terms of INT_PLUS_MICRO, that is in units of 10,000

 write back if active */

 SPDX-License-Identifier: GPL-2.0+

/*

 * tpl0102.c - Support for Texas Instruments digital potentiometers

 *

 * Copyright (C) 2016, 2018

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 *

 * TODO: enable/disable hi-z output control

 on-semiconductor parts */

 ti parts */

 SPDX-License-Identifier: GPL-2.0

/*

 * Industrial I/O driver for Microchip digital potentiometers

 * Copyright (c) 2015  Axentia Technologies AB

 * Author: Peter Rosin <peda@axentia.se>

 *

 * Datasheet: http://www.microchip.com/downloads/en/DeviceDoc/22096b.pdf

 *

 * DEVID	#Wipers	#Positions	Resistor Opts (kOhm)	i2c address

 * mcp4531	1	129		5, 10, 50, 100          010111x

 * mcp4532	1	129		5, 10, 50, 100          01011xx

 * mcp4541	1	129		5, 10, 50, 100          010111x

 * mcp4542	1	129		5, 10, 50, 100          01011xx

 * mcp4551	1	257		5, 10, 50, 100          010111x

 * mcp4552	1	257		5, 10, 50, 100          01011xx

 * mcp4561	1	257		5, 10, 50, 100          010111x

 * mcp4562	1	257		5, 10, 50, 100          01011xx

 * mcp4631	2	129		5, 10, 50, 100          0101xxx

 * mcp4632	2	129		5, 10, 50, 100          01011xx

 * mcp4641	2	129		5, 10, 50, 100          0101xxx

 * mcp4642	2	129		5, 10, 50, 100          01011xx

 * mcp4651	2	257		5, 10, 50, 100          0101xxx

 * mcp4652	2	257		5, 10, 50, 100          01011xx

 * mcp4661	2	257		5, 10, 50, 100          0101xxx

 * mcp4662	2	257		5, 10, 50, 100          01011xx

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Maxim Integrated DS1803 digital potentiometer driver

 * Copyright (c) 2016 Slawomir Stepien

 *

 * Datasheet: https://datasheets.maximintegrated.com/en/ds/DS1803.pdf

 *

 * DEVID	#Wipers	#Positions	Resistor Opts (kOhm)	i2c address

 * ds1803	2	256		10, 50, 100		0101xxx

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Maxim Integrated MAX5432-MAX5435 digital potentiometer driver

 * Copyright (C) 2019 Martin Kaiser <martin@kaiser.cx>

 *

 * Datasheet:

 * https://datasheets.maximintegrated.com/en/ds/MAX5432-MAX5435.pdf

 All chip variants have 32 wiper positions. */

 Update the volatile (currently active) setting. */

 Wiper position is in bits D7-D3. (D2-D0 are don't care bits.) */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * Analog Devices AD5110 digital potentiometer driver

 *

 * Copyright (C) 2021 Mugilraj Dhavachelvan <dmugil2000@gmail.com>

 *

 * Datasheet: https://www.analog.com/media/en/technical-documentation/data-sheets/AD5110_5112_5114.pdf

 AD5110 commands */

 AD5110_EEPROM_RD data */

 resistor tolerance */

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

 The storing of EEPROM data takes approximately 18 ms. */

 refresh RDAC register with EEPROM */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Analog Devices AD5272 digital potentiometer driver

 * Copyright (C) 2018 Phil Reid <preid@electromag.com.au>

 *

 * Datasheet: https://www.analog.com/media/en/technical-documentation/data-sheets/AD5272_5274.pdf

 *

 * DEVID	#Wipers	#Positions	Resistor Opts (kOhm)	i2c address

 * ad5272	1	1024		20, 50, 100		01011xx

 * ad5274	1	256		20, 100			01011xx

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Industrial I/O driver for Microchip digital potentiometers

 *

 * Copyright (c) 2016 Slawomir Stepien

 * Based on: Peter Rosin's code from mcp4531.c

 *

 * Datasheet: https://ww1.microchip.com/downloads/en/DeviceDoc/22060b.pdf

 *

 * DEVID	#Wipers	#Positions	Resistor Opts (kOhm)

 * mcp4131	1	129		5, 10, 50, 100

 * mcp4132	1	129		5, 10, 50, 100

 * mcp4141	1	129		5, 10, 50, 100

 * mcp4142	1	129		5, 10, 50, 100

 * mcp4151	1	257		5, 10, 50, 100

 * mcp4152	1	257		5, 10, 50, 100

 * mcp4161	1	257		5, 10, 50, 100

 * mcp4162	1	257		5, 10, 50, 100

 * mcp4231	2	129		5, 10, 50, 100

 * mcp4232	2	129		5, 10, 50, 100

 * mcp4241	2	129		5, 10, 50, 100

 * mcp4242	2	129		5, 10, 50, 100

 * mcp4251	2	257		5, 10, 50, 100

 * mcp4252	2	257		5, 10, 50, 100

 * mcp4261	2	257		5, 10, 50, 100

 * mcp4262	2	257		5, 10, 50, 100

/*

 * TODO:

 * 1. Write wiper setting to EEPROM for EEPROM capable models.

 We need to send addr, cmd and 12 bits */

 Error, bad address/command combination */

 8 bits here */

 SPDX-License-Identifier: GPL-2.0

/*

 * Industrial I/O driver for Microchip digital potentiometers

 *

 * Copyright (c) 2018 Chris Coffey <cmc@babblebit.net>

 * Based on: Slawomir Stepien's code from mcp4131.c

 *

 * Datasheet: https://ww1.microchip.com/downloads/en/devicedoc/11195c.pdf

 *

 * DEVID	#Wipers	#Positions	Resistance (kOhm)

 * mcp41010	1	256		10

 * mcp41050	1	256		50

 * mcp41100	1	256		100

 * mcp42010	2	256		10

 * mcp42050	2	256		50

 * mcp42100	2	256		100

 Protect write sequences */

 Cache wiper values */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Maxim Integrated MAX5481-MAX5484 digital potentiometer driver

 * Copyright 2016 Rockwell Collins

 *

 * Datasheet:

 * https://datasheets.maximintegrated.com/en/ds/MAX5481-MAX5484.pdf

 write wiper reg */

 copy wiper reg to NV reg */

 copy NV reg to wiper reg */

 variant specific configuration */

 restore wiper from NV */

 SPDX-License-Identifier: GPL-2.0

/*

 * Industrial I/O driver for Microchip digital potentiometers

 * Copyright (c) 2018  Axentia Technologies AB

 * Author: Peter Rosin <peda@axentia.se>

 *

 * Datasheet: http://www.microchip.com/downloads/en/DeviceDoc/22147a.pdf

 *

 * DEVID	#Wipers	#Positions	Resistor Opts (kOhm)

 * mcp4017	1	128		5, 10, 50, 100

 * mcp4018	1	128		5, 10, 50, 100

 * mcp4019	1	128		5, 10, 50, 100

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * max5487.c - Support for MAX5487, MAX5488, MAX5489 digital potentiometers

 *

 * Copyright (C) 2016 Cristina-Gabriela Moraru <cristina.moraru09@gmail.com>

 copy both wiper regs to NV regs */

 copy both NV regs to wiper regs */

 restore both wiper regs from NV regs */

 save both wiper regs to NV regs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2017, Intel Corporation.

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Real storage bits will change based on the report desc. */

 Maximum size of a sample to capture is s32 */

 Callback handler to send event after all samples are received and captured */

 Capture samples in local storage */

 Parse report which is specific to an usage id */

 Function to initialize the processing for usage id */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics hts221 spi driver

 *

 * Copyright 2016 STMicroelectronics Inc.

 *

 * Lorenzo Bianconi <lorenzo.bianconi@st.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * htu21.c - Support for Measurement-Specialties

 *           htu21 temperature & humidity sensor

 *	     and humidity part of MS8607 sensor

 *

 * Copyright (c) 2014 Measurement-Specialties

 *

 * (7-bit I2C slave address 0x40)

 *

 * Datasheet:

 *  http://www.meas-spec.com/downloads/HTU21D.pdf

 * Datasheet:

 *  http://www.meas-spec.com/downloads/MS8607-02BA01.pdf

 String copy of the above const for readability purpose */

 in milli C */

 in milli %RH */

/*

 * Meas Spec recommendation is to not read temperature

 * on this driver part for MS8607

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics hts221 sensor driver

 *

 * Copyright 2016 STMicroelectronics Inc.

 *

 * Lorenzo Bianconi <lorenzo.bianconi@st.com>

 calibration registers */

 1Hz */

 7Hz */

 12.5Hz */

 0.4 %RH */

 0.3 %RH */

 0.2 %RH */

 0.15 %RH */

 0.1 %RH */

 0.07 %RH */

 0.05 %RH */

 0.03 %RH */

 0.08 degC */

 0.05 degC */

 0.04 degC */

 0.03 degC */

 0.02 degC */

 0.015 degC */

 0.01 degC */

 0.007 degC */

 enable Block Data Update */

 configure humidity sensor */

 configure temperature sensor */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DHT11/DHT22 bit banging GPIO driver

 *

 * Copyright (c) Harald Geyer <harald@ccbib.org>

 2s in ns */

/*

 * Note that when reading the sensor actually 84 edges are detected, but

 * since the last edge is not significant, we only store 83:

/*

 * Data transmission timing:

 * Data bits are encoded as pulse length (high time) on the data line.

 * 0-bit: 22-30uS -- typically 26uS (AM2302)

 * 1-bit: 68-75uS -- typically 70uS (AM2302)

 * The acutal timings also depend on the properties of the cable, with

 * longer cables typically making pulses shorter.

 *

 * Our decoding depends on the time resolution of the system:

 * timeres > 34uS ... don't know what a 1-tick pulse is

 * 34uS > timeres > 30uS ... no problem (30kHz and 32kHz clocks)

 * 30uS > timeres > 23uS ... don't know what a 2-tick pulse is

 * timeres < 23uS ... no problem

 *

 * Luckily clocks in the 33-44kHz range are quite uncommon, so we can

 * support most systems if the threshold for decoding a pulse as 1-bit

 * is chosen carefully. If somebody really wants to support clocks around

 * 40kHz, where this driver is most unreliable, there are two options.

 * a) select an implementation using busy loop polling on those systems

 * b) use the checksum to do some probabilistic decoding

 us */

 us */

 ns */

 ns */

 ns */

 ns */

 The iio sysfs interface doesn't prevent concurrent reads: */

 num_edges: -1 means "no transmission in progress" */

/*

 * dht11_edges_print: show the data as actually received by the

 *                    driver.

 CONFIG_DYNAMIC_DEBUG */

 DHT22: 100000 = (3*256+232)*100 */

 DHT11 */

/*

 * IRQ handler called on GPIO edges

			/* In theory a better clock could become available

			 * at some point ... and there is no error code

			 * that really fits better.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * si7020.c - Silicon Labs Si7013/20/21 Relative Humidity and Temp Sensors

 * Copyright (c) 2013,2014  Uplogix, Inc.

 * David Barksdale <dbarksdale@uplogix.com>

/*

 * The Silicon Labs Si7013/20/21 Relative Humidity and Temperature Sensors

 * are i2c devices which have an identical programming interface for

 * measuring relative humidity and temperature. The Si7013 has an additional

 * temperature input which this driver does not support.

 *

 * Data Sheets:

 *   Si7013: http://www.silabs.com/Support%20Documents/TechnicalDocs/Si7013.pdf

 *   Si7020: http://www.silabs.com/Support%20Documents/TechnicalDocs/Si7020.pdf

 *   Si7021: http://www.silabs.com/Support%20Documents/TechnicalDocs/Si7021.pdf

 Measure Relative Humidity, Hold Master Mode */

 Measure Temperature, Hold Master Mode */

 Software Reset */

		/*

		 * Humidity values can slightly exceed the 0-100%RH

		 * range and should be corrected by software

 = 175.72 * 1000 */

		/*

		 * Since iio_convert_raw_to_processed_unlocked assumes offset

		 * is an integer we have to round these values and lose

		 * accuracy.

		 * Relative humidity will be 0.0032959% too high and

		 * temperature will be 0.00277344 degrees too high.

		 * This is no big deal because it's within the accuracy of the

		 * sensor.

 = -46.85 * (65536 >> 2) / 175.72 */

 = -6 * (65536 >> 2) / 125 */

 Reset device, loads default settings. */

 Wait the maximum power-up time after software reset. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * si7005.c - Support for Silabs Si7005 humidity and temperature sensor

 *

 * Copyright (c) 2014 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * (7-bit I2C slave address 0x40)

 *

 * TODO: heater, fast mode, processed mode (temp. / linearity compensation)

 16-bit, MSB */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Aosong AM2315 relative humidity and temperature

 *

 * Copyright (c) 2016, Intel Corporation.

 *

 * 7-bit I2C address: 0x5C.

 Ensure timestamp is naturally aligned */

 CRC calculation algorithm, as specified in the datasheet (page 13). */

 Simple function that sends a few bytes to the device to wake it up. */

 tx_buf format: <function code> <start addr> <nr of regs to read> */

	/*

	 * rx_buf format:

	 * <function code> <number of registers read>

	 * <humidity MSB> <humidity LSB> <temp MSB> <temp LSB>

	 * <CRC LSB> <CRC MSB>

 First wake up the device. */

 Wait 2-3 ms, then read back the data sent by the device. */

 Do a bulk data read, then pick out what we need. */

	/*

	 * Do a CRC check on the data and compare it to the value

	 * calculated by the device.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics hts221 sensor driver

 *

 * Copyright 2016 STMicroelectronics Inc.

 *

 * Lorenzo Bianconi <lorenzo.bianconi@st.com>

	/*

	 * H_DA bit (humidity data available) is routed to DRDY line.

	 * Humidity sample is computed after temperature one.

	 * Here we can assume data channels are both available if H_DA bit

	 * is set in status register

 humidity data */

 temperature data */

 SPDX-License-Identifier: GPL-2.0+

/*

 * hdc2010.c - Support for the TI HDC2010 and HDC2080

 * temperature + relative humidity sensors

 *

 * Copyright (C) 2020 Norphonic AS

 * Author: Eugene Zaikonnikov <ez@norphonic.com>

 *

 * Datasheet: https://www.ti.com/product/HDC2010/datasheet

 * Datasheet: https://www.ti.com/product/HDC2080/datasheet

 Scaling up the value so we can use same offset as RAW */

	/*

	 * As DEVICE ID register does not differentiate between

	 * HDC2010 and HDC2080, we have the name hardcoded

 Enable Automatic Measurement Mode at 5Hz */

	/*

	 * We enable both temp and humidity measurement.

	 * However the measurement won't start even in AMM until triggered.

 Disable Automatic Measurement Mode */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics hts221 i2c driver

 *

 * Copyright 2016 STMicroelectronics Inc.

 *

 * Lorenzo Bianconi <lorenzo.bianconi@st.com>

 SPDX-License-Identifier: GPL-2.0+

/*

 * hdc100x.c - Support for the TI HDC100x temperature + humidity sensors

 *

 * Copyright (C) 2015, 2018

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 *

 * Datasheets:

 * https://www.ti.com/product/HDC1000/datasheet

 * https://www.ti.com/product/HDC1008/datasheet

 * https://www.ti.com/product/HDC1010/datasheet

 * https://www.ti.com/product/HDC1050/datasheet

 * https://www.ti.com/product/HDC1080/datasheet

 integration time of the sensor */

 Ensure natural alignment of timestamp */

 integration time in us */

 IIO_TEMP channel*/

 IIO_HUMIDITYRELATIVE channel */

 HDC100X_REG_CONFIG shift and mask values */

 IIO_TEMP channel */

 IIO_HUMIDITYRELATIVE channel */

 start measurement */

 wait for integration time to pass */

 read measurement */

 Buffer is enabled. First set ACQ Mode, then attach poll func */

 dual read starts at temp register */

 be sure we are in a known state */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MPU3050 gyroscope driver

 *

 * Copyright (C) 2016 Linaro Ltd.

 * Author: Linus Walleij <linus.walleij@linaro.org>

 *

 * Based on the input subsystem driver, Copyright (C) 2011 Wistron Co.Ltd

 * Joseph Lai <joseph_lai@wistron.com> and trimmed down by

 * Alan Cox <alan@linux.intel.com> in turn based on bma023.c.

 * Device behaviour based on a misc driver posted by Nathan Royer in 2011.

 *

 * TODO: add support for setting up the low pass 3dB frequency.

/*

 * Register map: anything suffixed *_H is a big-endian high byte and always

 * followed by the corresponding low byte (*_L) even though these are not

 * explicitly included in the register definitions.

 MPU memory bank read options */

 Bits 8-11 select memory bank */

 Register bits */

 FIFO Enable */

/*

 * Digital Low Pass filter (DLPF)

 * Full Scale (FS)

 * and Synchronization

 Interrupt config */

 Interrupt status */

 USR_CTRL */

 PWR_MGM */

/*

 * Fullscale precision is (for finest precision) +/- 250 deg/s, so the full

 * scale is actually 500 deg/s. All 16 bits are then used to cover this scale,

 * in two's complement.

/*

 * Regulator names

 Reset */

 Turn on the Z-axis PLL */

 Write calibration offset registers */

 Set low pass filter (sample rate), sync and full scale */

 Set up sampling frequency */

	/*

	 * Max 50 ms start-up time after setting DLPF_FS_SYNC

	 * according to the data sheet, then wait for the next sample

	 * at this frequency T = 1000/f ms.

 8 kHz base frequency */

 Divide by 1 */

			/*

			 * The temperature scaling is (x+23000)/280 Celsius

			 * for the "best fit straight line" temperature range

			 * of -30C..85C.  The 23000 includes room temperature

			 * offset of +35C, 280 is the precision scale and x is

			 * the 16-bit signed integer reported by hardware.

			 *

			 * Temperature value itself represents temperature of

			 * the sensor die.

 Millidegrees, see about temperature scaling above */

			/*

			 * Convert to the corresponding full scale in

			 * radians. All 16 bits are used with sign to

			 * span the available scale: to account for the one

			 * missing value if we multiply by 1/S16_MAX, instead

			 * multiply with 2/U16_MAX.

 Resume device */

	/*

	 * Couldn't figure out a way to precalculate these at compile time.

		/*

		 * The max samplerate is 8000 Hz, the minimum

		 * 1000 / 256 ~= 4 Hz

		/*

		 * Above 1000 Hz we must turn off the digital low pass filter

		 * so we get a base frequency of 8kHz to the divider

		/*

		 * We support +/-250, +/-500, +/-1000 and +/2000 deg/s

		 * which means we need to round to the closest radians

		 * which will be roughly +/-4.3, +/-8.7, +/-17.5, +/-35

		 * rad/s. The scale is then for the 16 bits used to cover

		 * it 2/(2^16) of that.

 Just too large, set the max range */

		/*

		 * Now we're dealing with fractions below zero in millirad/s

		 * do some integer interpolation and match with the closest

		 * fullscale in the table.

 Catch-all */

	/*

	 * If we're using the hardware trigger, get the precise timestamp from

	 * the top half of the threaded IRQ handler. Otherwise get the

	 * timestamp here so it will be close in time to the actual values

	 * read from the registers.

 Using the hardware IRQ trigger? Check the buffer then. */

 X, Y, Z + temperature */

 Reset and enable the FIFO */

			/*

			 * If there is a FIFO footer in the pipe, first clear

			 * that out. This follows the complex algorithm in the

			 * datasheet that states that you may never leave the

			 * FIFO empty after the first reading: you have to

			 * always leave two footer bytes in it. The footer is

			 * in practice just two zero bytes.

 Put in some dummy value */

 Index past the footer (fifo_values[0]) and push */

			/*

			 * If we're emptying the FIFO, just make sure to

			 * check if something new appeared.

			/*

			 * At this point, the timestamp that triggered the

			 * hardware interrupt is no longer valid for what

			 * we are reading (the interrupt likely fired for

			 * the value on the top of the FIFO), so set the

			 * timestamp to zero and let userspace deal with it.

	/*

	 * If we picked some datums from the FIFO that's enough, else

	 * fall through and just read from the current value registers.

	 * This happens in two cases:

	 *

	 * - We are using some other trigger (external, like an HRTimer)

	 *   than the sensor's own sample generator. In this case the

	 *   sensor is just set to the max sampling frequency and we give

	 *   the trigger a copy of the latest value every time we get here.

	 *

	 * - The hardware trigger is active but unused and we actually use

	 *   another trigger which calls here with a frequency higher

	 *   than what the device provides data. We will then just read

	 *   duplicate values directly from the hardware registers.

 Unless we have OUR trigger active, run at full speed */

 Four channels apart from timestamp, scan mask = 0x0f */

/*

 * These are just the hardcoded factors resulting from the more elaborate

 * calculations done with fractions in the scale raw get/set functions.

/**

 * mpu3050_read_mem() - read MPU-3050 internal memory

 * @mpu3050: device to read from

 * @bank: target bank

 * @addr: target address

 * @len: number of bytes

 * @buf: the buffer to store the read bytes in

 Reset */

 Turn on the PLL */

 Disable IRQs */

 Read out the 8 bytes of OTP (one-time-programmable) memory */

 This is device-unique data so it goes into the entropy pool */

 Die ID, bits 0-12 */

 Wafer ID, bits 13-17 */

 A lot ID, bits 18-33 */

 W lot ID, bits 34-45 */

 WP ID, bits 47-49 */

 rev ID, bits 50-55 */

	/*

	 * 20-100 ms start-up time for register read/write according to

	 * the datasheet, be on the safe side and wait 200 ms.

 Take device out of sleep mode */

	/*

	 * Put MPU-3050 into sleep mode before cutting regulators.

	 * This is important, because we may not be the sole user

	 * of the regulator so the power may stay on after this, and

	 * then we would be wasting power unless we go to sleep mode

	 * first.

 Get the time stamp as close in time as possible */

 ACK IRQ and check if it was from us */

/**

 * mpu3050_drdy_trigger_set_state() - set data ready interrupt state

 * @trig: trigger instance

 * @enable: true if trigger should be enabled, false to disable

 Disabling trigger: disable interrupt and return */

 Disable all interrupts */

 Clear IRQ flag */

 Disable all things in the FIFO and reset it */

 Else we're enabling the trigger from this point */

 Disable all things in the FIFO */

 Reset and enable the FIFO */

 Turn on the FIFO for temp+X+Y+Z */

 Configure the sample engine */

 Clear IRQ flag */

 Give us interrupts whenever there is new data ready */

 Check if IRQ is open drain */

	/*

	 * Configure the interrupt generator hardware to supply whatever

	 * the interrupt is configured for, edges low/high level low/high,

	 * we can provide it all.

		/*

		 * With level IRQs, we mask the IRQ until it is processed,

		 * but with edge IRQs (pulses) we can queue several interrupts

		 * in the top half.

 This is the most preferred mode, if possible */

 An open drain line can be shared with several devices */

 Default fullscale: 2000 degrees per second */

 1 kHz, divide by 100, default frequency = 10 Hz */

 Read the mounting matrix, if present */

 Fetch and turn on regulators */

 Check if we have an assigned IRQ to use as trigger */

 Enable runtime PM */

	/*

	 * Set autosuspend to two orders of magnitude larger than the

	 * start-up time. 100ms start-up time means 10000ms autosuspend,

	 * i.e. 10 seconds.

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2014, Samsung Electronics Co. Ltd. All Rights Reserved.

 ssp registering should be done after all iio setup */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ADIS16080/100 Yaw Rate Gyroscope with SPI driver

 *

 * Copyright 2010 Analog Devices Inc.

 Gyroscope output */

 Temperature output */

/*

 * 1: Write contents on DIN to control register.

 * 0: No changes to control register.

/**

 * struct adis16080_state - device instance specific data

 * @us:			actual spi_device to write data

 * @info:		chip specific parameters

 * @buf:		transmit or receive buffer

 * @lock:		lock to protect buffer during reads

 VREF = 5V, 12 bits */

 85 C = 585, 25 C = 0 */

 2.5 V = 0 */

 85 C = 585, 25 C = 0 */

 80 degree = 819, 819 rad = 46925 degree */

 300 degree = 1230, 1230 rad = 70474 degree */

 setup the industrialio driver allocated elements */

 Allocate the comms buffers */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics gyroscopes driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for NXP Fxas21002c Gyroscope - SPI

 *

 * Copyright (C) 2019 Linaro Ltd.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2012, Intel Corporation.

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Real storage bits will change based on the report desc. */

 Maximum size of a sample to capture is u32 */

 Channel read_raw handler */

 Channel write_raw handler */

 Callback handler to send event after all samples are received and captured */

 Capture samples in local storage */

 Parse report which is specific to an usage id*/

 Function to initialize the processing for usage id */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for NXP FXAS21002C Gyroscope - I2C

 *

 * Copyright (C) 2018 Linaro Ltd.

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for NXP FXAS21002C Gyroscope - Core

 *

 * Copyright (C) 2019 Linaro Ltd.

/*

 * These values are taken from the low-pass filter cutoff frequency calculated

 * ODR * 0.lpf_values. So, for ODR = 800Hz with a lpf value = 0.32

 * => LPF cutoff frequency = 800 * 0.32 = 256 Hz

/*

 * These values are taken from the high-pass filter cutoff frequency calculated

 * ODR * 0.0hpf_values. So, for ODR = 800Hz with a hpf value = 0.018750

 * => HPF cutoff frequency = 800 * 0.018750 = 15 Hz

 serialize data access */

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

 We need to check if FS_DOUBLE is enabled to offset the value */

 if going to active wait the setup times */

	/*

	 * From table 33 of the device spec, for ODR = 25Hz and 12.5 value 0.08

	 * is not allowed and for ODR = 12.5 value 0.16 is also not allowed

 Set ODR to 200HZ as default */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics gyroscopes driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

/*

 * For new single-chip sensors use <device_name> as compatible string.

 * For old single-chip devices keep <device_name>-gyro to maintain

 * compatibility

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ADXRS290 SPI Gyroscope Driver

 *

 * Copyright (C) 2020 Nishant Malpani <nish.malpani25@gmail.com>

 * Copyright (C) 2020 Analog Devices, Inc.

 Serial Number Registers, 4 bytes */

 Roll Rate o/p Data Regs, 2 bytes */

 Pitch Rate o/p Data Regs, 2 bytes */

 Serialize reads and their subsequent processing */

 Ensure correct alignment of timestamp when present */

/*

 * Available cut-off frequencies of the low pass filter in Hz.

 * The integer part and fractional part are represented separately.

/*

 * Available cut-off frequencies of the high pass filter in Hz.

 * The integer part and fractional part are represented separately.

 extract lower 12 bits temperature reading */

 update cached mode */

 1 LSB = 0.005 degrees/sec */

 1 LSB = 0.1 degrees Celsius */

 caching the updated state of the low-pass filter */

 retrieving the current state of the high-pass filter */

 caching the updated state of the high-pass filter */

 retrieving the current state of the low-pass filter */

 Values are stored in a 2D matrix */

 Values are stored in a 2D matrix */

	/*

	 * Data ready interrupt is reset after a read of the data registers.

	 * Here, we only read the 16b DATAY registers as that marks the end of

	 * a read of the data registers and initiates a reset for the interrupt

	 * line.

 exercise a bulk data capture starting from reg DATAX0... */

 default mode the gyroscope starts in */

 switch to measurement mode and switch on the temperature sensor */

 max transition time to measurement mode */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ADIS16133/ADIS16135/ADIS16136 gyroscope driver

 *

 * Copyright 2012 Analog Devices Inc.

 *   Author: Lars-Peter Clausen <lars@metafoo.de>

 Special case */

 Not a valid setting */

 0.010697 degree Celsius */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * itg3200_core.c -- support InvenSense ITG3200

 *                   Digital 3-Axis Gyroscope driver

 *

 * Copyright (c) 2011 Christian Strobel <christian.strobel@iis.fraunhofer.de>

 * Copyright (c) 2011 Manuel Stahl <manuel.stahl@iis.fraunhofer.de>

 * Copyright (c) 2012 Thorsten Nowak <thorsten.nowak@iis.fraunhofer.de>

 *

 * TODO:

 * - Support digital low pass filter

 * - Support power management

 (1 / 14,375) * (PI / 180) */

 Only the temperature channel has an offset */

/*

 * Reset device and internal registers to the power-up-default settings

 * Use the gyro clock as reference, as suggested by the datasheet

 Wait for PLL (1ms according to datasheet) */

 itg3200_enable_full_scale() - Disables the digital low pass filter */

 SPDX-License-Identifier: GPL-2.0-only

 Just power up the device, that is all that is needed */

 The main driver is up, now register the I2C mux */

 Just fail the mux, there is no point in killing the driver */

 Ignore failure, not critical */

/*

 * device id table is used to identify what device can be

 * supported by this driver

 Deprecated vendor ID from the Input driver */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ADXRS450/ADXRS453 Digital Output Gyroscope Driver

 *

 * Copyright 2011 Analog Devices Inc.

 ms */

 The MSB for the spi commands */

 Rate Registers */

 Temperature Registers */

 Low CST Memory Registers */

 High CST Memory Registers */

 Quad Memory Registers */

 Fault Registers */

 Part ID Register 1 */

 Serial Number Registers, 4 bytes */

 Dynamic Null Correction Registers */

 Check bits */

/**

 * struct adxrs450_state - device instance specific data

 * @us:			actual spi_device

 * @buf_lock:		mutex to protect tx and rx

 * @tx:			transmit buffer

 * @rx:			receive buffer

/**

 * adxrs450_spi_read_reg_16() - read 2 bytes from a register pair

 * @indio_dev: device associated with child of actual iio_dev

 * @reg_address: the address of the lower of the two registers, which should be

 *	an even address, the second register's address is reg_address + 1.

 * @val: somewhere to pass back the value read

/**

 * adxrs450_spi_write_reg_16() - write 2 bytes data to a register pair

 * @indio_dev: device associated with child of actual actual iio_dev

 * @reg_address: the address of the lower of the two registers,which should be

 *	an even address, the second register's address is reg_address + 1.

 * @val: value to be written.

 enforce sequential transfer delay 0.1ms */

/**

 * adxrs450_spi_sensor_data() - read 2 bytes sensor data

 * @indio_dev: device associated with child of actual iio_dev

 * @val: somewhere to pass back the value read

/**

 * adxrs450_spi_initial() - use for initializing procedure.

 * @st: device instance specific data

 * @val: somewhere to pass back the value read

 * @chk: Whether to perform fault check

 Recommended Startup Sequence by spec */

 setup the industrialio driver allocated elements */

 This is only used for removal purposes */

 Get the device into a sane initial state */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ADIS16260/ADIS16265 Programmable Digital Gyroscope Sensor Driver

 *

 * Copyright 2010 Analog Devices Inc.

 ms */

 Flash memory write count */

 Power supply measurement */

 X-axis gyroscope output */

 analog input channel measurement */

 internal temperature measurement */

 angle displacement */

 Calibration, offset/bias adjustment */

 Calibration, scale adjustment */

 Alarm 1 magnitude/polarity setting */

 Alarm 2 magnitude/polarity setting */

 Alarm 1 dynamic rate of change setting */

 Alarm 2 dynamic rate of change setting */

 Alarm control */

 Auxiliary DAC data */

 Control, digital I/O line */

 Control, data ready, self-test settings */

 Control, internal sample rate */

 Control, dynamic range, filtering */

 Control, sleep mode initiation */

 Diagnostic, error flags */

 Control, global commands */

 Lot Identification Code 1 */

 Lot Identification Code 2 */

#define ADIS16260_PROD_ID    0x56 /* Product identifier;

 Serial number */

 MSC_CTRL */

 Internal self-test enable */

 SMPL_PRD */

 Time base (tB): 0 = 1.953 ms, 1 = 60.54 ms */

 SLP_CNT */

 DIAG_STAT */

 GLOB_CMD */

/* At the moment triggers are only used for ring buffer

 * filling. This may change!

 Power down the device */

 1.8315 mV */

 610.5 uV */

 0.1453 C */

 25 C = 0x00 */

 If an adis16251 */

 setup the industrialio driver allocated elements */

 this is only used for removal purposes */

 Get the device into a sane initial state */

/*

 * These parts do not need to be differentiated until someone adds

 * support for the on chip filtering.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * itg3200_buffer.c -- support InvenSense ITG3200

 *                     Digital 3-Axis Gyroscope driver

 *

 * Copyright (c) 2011 Christian Strobel <christian.strobel@iis.fraunhofer.de>

 * Copyright (c) 2011 Manuel Stahl <manuel.stahl@iis.fraunhofer.de>

 * Copyright (c) 2012 Thorsten Nowak <thorsten.nowak@iis.fraunhofer.de>

	/*

	 * Ensure correct alignment and padding including for the

	 * timestamp that may be inserted.

 select default trigger */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics gyroscopes driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * BMG160 Gyro Sensor driver

 * Copyright (c) 2014, Intel Corporation.

 Ensure naturally aligned timestamp */

 Ignore the readonly reserved bit. */

	/*

	 * Reset chip to get it in a known good state. A delay of 30ms after

	 * reset is required according to the datasheet.

 Wait upto 500 ms to be ready after changing mode */

 Set Bandwidth */

 Set Default Range */

 Set default interrupt mode */

 Enable/Disable INT_MAP0 mapping */

 Enable/Disable slope interrupts */

 Update slope thres */

		/*

		 * New data interrupt is always non-latched,

		 * which will have higher priority, so no need

		 * to set latched mode, we will be flooded anyway with INTR

 Enable/Disable INT_MAP1 mapping */

 Restore interrupt mode */

 Ignore the readonly reserved bit. */

		/*

		 * Section 4.2 of spec

		 * In suspend mode, the only supported operations are reading

		 * registers as well as writing to the (0x14) softreset

		 * register. Since we will be in suspend mode by default, change

		 * mode to power on for other writes.

 Refer to comments above for the suspend mode ops */

	/*

	 * We will expect the enable and disable to do operation in

	 * in reverse order. This will happen here anyway as our

	 * resume operation uses sync mode runtime pm calls, the

	 * suspend operation will be delayed by autosuspend delay

	 * So the disable operation will still happen in reverse of

	 * enable operation. When runtime pm is disabled the mode

	 * is always on so sequence doesn't matter

 new data interrupts don't need ack */

 Set latched mode interrupt and clear any latched interrupt */

	/*

	 * Refer to comment in bmg160_write_event_config for

	 * enable/disable operation order

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics gyroscopes driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 DEFAULT VALUE FOR SENSORS */

 FULLSCALE */

			/*

			 * The sensor has IHL (active low) and open

			 * drain settings, but only for INT1 and not

			 * for the DRDY line on INT2.

			/*

			 * The sensor has IHL (active low) and open

			 * drain settings, but only for INT1 and not

			 * for the DRDY line on INT2.

			/*

			 * The sensor has IHL (active low) and open

			 * drain settings, but only for INT1 and not

			 * for the DRDY line on INT2.

			/*

			 * The sensor has IHL (active low) and open

			 * drain settings, but only for INT1 and not

			 * for the DRDY line on INT2.

 DRDY on gyros is available only on INT2 pin */

/*

 * st_gyro_get_settings() - get sensor settings from device name

 * @name: device name buffer reference.

 *

 * Return: valid reference on success, NULL otherwise.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ADIS16130 Digital Output, High Precision Angular Rate Sensor driver

 *

 * Copyright 2010 Analog Devices Inc.

 1 = data-ready signal low when unread data on all channels; */

 1 = synchronization enabled */

 Gyroscope output, rate of rotation */

 Temperature output */

 Gyroscope channel setup */

 1 = channel enable; */

 Temperature channel setup */

 1 = 24-bit resolution; */

/**

 * struct adis16130_state - device instance specific data

 * @us:			actual spi_device to write data

 * @buf_lock:		mutex to protect tx and rx

 * @buf:		unified tx/rx buffer

 Take the iio_dev status lock */

 0 degree = 838860, 250 degree = 14260608 */

 RAD_TO_DEGREE(14260608 - 8388608) */

 0C = 8036283, 105C = 9516048 */

 setup the industrialio driver allocated elements */

 this is only used for removal purposes */

 SPDX-License-Identifier: GPL-2.0+

/*

 * lmp91000.c - Support for Texas Instruments digital potentiostats

 *

 * Copyright (C) 2016, 2018

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 *

 * TODO: bias voltage + polarity control, and multiple chip support

 64-bit data + 64-bit naturally aligned timestamp */

 chemical channel mV */

 temperature channel mV */

 delay till first temperature reading is complete */

 SPDX-License-Identifier: GPL-2.0

/*

 * HMC425A and similar Gain Amplifiers

 *

 * Copyright 2020 Analog Devices Inc.

 protect sensor state */

 Match table for of_platform binding */

 set default gain -31.5db*/

 SPDX-License-Identifier: GPL-2.0

/*

 * AD8366 and similar Gain Amplifiers

 * This driver supports the following gain amplifiers:

 *   AD8366 Dual-Digital Variable Gain Amplifier (VGA)

 *   ADA4961 BiCMOS RF Digital Gain Amplifier (DGA)

 *   ADL5240 Digitally controlled variable gain amplifier (VGA)

 *   HMC1119 0.25 dB LSB, 7-Bit, Silicon Digital Attenuator

 *

 * Copyright 2012-2019 Analog Devices Inc.

 protect sensor state */

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

 Values in dB */

 Values in dB */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2013, Intel Corporation.

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Real storage bits will change based on the report desc. */

 Maximum size of a sample to capture is u32 */

 Channel read_raw handler */

 Channel write_raw handler */

 Callback handler to send event after all samples are received and captured */

 Capture samples in local storage */

 Parse report which is specific to an usage id*/

 Function to initialize the processing for usage id */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2014, Intel Corporation.

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Real storage bits will change based on the report desc. */

 Maximum size of a sample to capture is u32 */

 Channel read_raw handler */

 Channel write_raw handler */

 Callback handler to send event after all samples are received and captured */

 Capture samples in local storage */

 Parse report which is specific to an usage id*/

 Function to initialize the processing for usage id */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 Relative orientation(AG) sensor */

 Geomagnetic orientation(AM) sensor */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/* Unit tests for IIO formatting functions

 *

 * Copyright (c) 2020 Lars-Peter Clausen <lars@metafoo.de>

 positive >= 1 */

 positive < 1 */

 negative <= -1 */

 negative > -1 */

 positive < 1 */

 positive >= 1 */

 negative > -1 */

 negative <= -1 */

 Zero */

 positive < 1 */

 positive >= 1 */

 negative > -1 */

 negative <= -1 */

 Zero */

 SPDX-License-Identifier: GPL-2.0

/*

 * Support for PNI RM3100 3-axis geomagnetic sensor on a i2c bus.

 *

 * Copyright (C) 2018 Song Qiang <songqiang1304521@gmail.com>

 *

 * i2c slave address: 0x20 + SA1 << 1 + SA0.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Asahi Kasei EMD Corporation AK8974

 * and Aichi Steel AMI305 magnetometer chips.

 * Based on a patch from Samu Onkalo and the AK8975 IIO driver.

 *

 * Copyright (C) 2010 Nokia Corporation and/or its subsidiary(-ies).

 * Copyright (c) 2010 NVIDIA Corporation.

 * Copyright (C) 2016 Linaro Ltd.

 *

 * Author: Samu Onkalo <samu.p.onkalo@nokia.com>

 * Author: Linus Walleij <linus.walleij@linaro.org>

 For irq_get_irq_data() */

/*

 * 16-bit registers are little-endian. LSB is at the address defined below

 * and MSB is at the next higher address.

 These registers are common for AK8974 and AMI30x */

 Absolute any axis value threshold */

 AK8974-specific offsets */

 AMI305-specific offsets */

 Different temperature registers */

 AMI306-specific control register */

 AMI306 factory calibration data */

 fine axis sensitivity */

 axis sensitivity */

 axis cross-interference */

 offset at ZERO magnetic field */

 Axis over +threshold  */

 Axis below -threshold	*/

 Range overflow (any axis) */

 Data ready */

 Data overrun */

 Interrupt occurred */

 0 = standby; 1 = active */

 0 = 10 Hz; 1 = 20 Hz	 */

 0 = normal; 1 = force	 */

 0 */

 1 = enable interrupts	      */

 1 = enable data ready signal */

 1 = data ready active high   */

 Software reset		  */

 Start forced measurement */

 Set selftest register	  */

 Enable interrupt for this axis */

 0 = active low; 1 = active high */

 0 = latched; 1 = pulse (50 usec) */

 HSCDTD008A-specific control register */

 must be set to 1 */

 0 = 14-bit output; 1 = 15-bit output */

 The AMI305 has elaborate FW version and serial number registers */

/*

 * Set the autosuspend to two orders of magnitude larger than the poweron

 * delay to make sane reasonable power tradeoff savings (5 seconds in

 * this case).

/**

 * struct ak8974 - state container for the AK8974 driver

 * @i2c: parent I2C client

 * @orientation: mounting matrix, flipped axis etc

 * @map: regmap to access the AK8974 registers over I2C

 * @regs: the avdd and dvdd power regulators

 * @name: the name of the part

 * @variant: the whoami ID value (for selecting code paths)

 * @lock: locks the magnetometer for exclusive use during a measurement

 * @drdy_irq: uses the DRDY IRQ line

 * @drdy_complete: completion for DRDY

 * @drdy_active_low: the DRDY IRQ is active low

 * @scan: timestamps

 Ensure timestamp is naturally aligned */

 Power on to get register access. Sets CTRL1 reg to reset state */

 After reset, power off is default state */

 magic from datasheet: set high-speed measurement mode */

 Clear any previous measurement overflow status */

 If we have a DRDY IRQ line, use it */

 Force a measurement */

 Default delay-based poll loop */

 Out of range overflow! Strong magnet close? */

 TODO: timestamp here to get good measurement stamps */

 Check if this was a DRDY from us */

 Yes this was our IRQ */

 We may be on a shared IRQ, let the next client check */

 Trigger self-test */

 only bits 0 thru 6 valid */

	/*

	 * We read all axes and discard all but one, for optimized

	 * reading, use the triggered buffer.

	/*

	 * This explicit cast to (s16) is necessary as the measurement

	 * is done in 2's complement with positive and negative values.

	 * The follwing assignment to *val will then convert the signed

	 * s16 value to a signed int value.

			/*

			 * The datasheet for AMI305 and AMI306, page 6

			 * specifies the range of the sensor to be

			 * +/- 12 Gauss.

			/*

			 * 12 bits are used, +/- 2^11

			 * [ -2048 .. 2047 ] (manual page 20)

			 * [ 0xf800 .. 0x07ff ]

			/*

			 * The datasheet for HSCDTF008A, page 3 specifies the

			 * range of the sensor as +/- 2.4 mT per axis, which

			 * corresponds to +/- 2400 uT = +/- 24 Gauss.

			/*

			 * 15 bits are used (set up in CTRL4), +/- 2^14

			 * [ -16384 .. 16383 ] (manual page 24)

			 * [ 0xc000 .. 0x3fff ]

 GUESSING +/- 12 Gauss */

 GUESSING 12 bits ADC +/- 2^11 */

 Unknown request */

/*

 * We have no datasheet for the AK8974 but we guess that its

 * ADC is 12 bits. The AMI305 and AMI306 certainly has 12bit

 * ADC.

/*

 * The HSCDTD008A has 15 bits resolution the way we set it up

 * in CTRL4.

 Register with IIO */

 Take runtime PM online */

 If we have a valid DRDY IRQ, make use of it */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 3-axis magnetometer driver support following SPI Bosch-Sensortec chips:

 *  - BMC150

 *  - BMC156

 *  - BMM150

 *

 * Copyright (c) 2016, Intel Corporation.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * i2c driver for hmc5843/5843/5883/5883l/5983

 *

 * Split from hmc5843.c

 * Copyright (C) Josef Gajdusek <atx@atx.name>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2012, Intel Corporation.

 dynamically sized array to hold sensor values */

 array of pointers to sensor value */

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Real storage bits will change based on the report desc. */

 Maximum size of a sample to capture is u32 */

 Channel read_raw handler */

 Channel write_raw handler */

 Callback handler to send event after all samples are received and captured */

 Capture samples in local storage */

 Parse report which is specific to an usage id*/

 Scan for each usage attribute supported */

 Check if usage attribute exists in the sensor hub device */

 Setup IIO channel array */

 attr_count include timestamp channel, and the iio_vals should be aligned to 8byte */

 Setup IIO channel struct */

 Set magn_val_addr to iio value address */

 Function to initialize the processing for usage id */

 sensitivity of rot_attribute is not the same as magn_flux_attributes */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics magnetometers driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

/*

 * For new single-chip sensors use <device_name> as compatible string.

 * For old single-chip devices keep <device_name>-magn to maintain

 * compatibility

 * For multi-chip devices, use <device_name>-magn to distinguish which

 * capability is being used

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI driver for hmc5983

 *

 * Copyright (C) Josef Gajdusek <atx@atx.name>

 Autoincrement address pointer */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Bosch BMC150 three-axis magnetic field sensor driver

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * This code is based on bmm050_api.c authored by contact@bosch.sensortec.com:

 *

 * (C) Copyright 2011~2014 Bosch Sensortec GmbH All Rights Reserved

 Time from SUSPEND to SLEEP */

	/*

	 * 1. Protect this structure.

	 * 2. Serialize sequences that power on/off the device and access HW.

 Ensure timestamp is naturally aligned */

 the maximum selectable read-out frequency from datasheet */

		/*

		 * The API/driver performs an off-chip temperature

		 * compensation and outputs x/y/z magnetic field data in

		 * 16 LSB/uT to the upper application layer.

 replace last space with a newline */

	/*

	 * 3ms power-on time according to datasheet, let's better

	 * be safe than sorry and set this delay to 5ms.

	/*

	 * Data Ready (DRDY) is always cleared after

	 * readout of data registers ends.

/*

 * Should be called with data->mutex held.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * A sensor driver for the magnetometer AK8975.

 *

 * Magnetic compass sensor driver for monitoring magnetic flux information.

 *

 * Copyright (c) 2010, NVIDIA Corporation.

/*

 * Register definitions, as well as various shifts and masks to get at the

 * individual fields of the registers.

/*

 * AK09912 Register definitions

/*

 * Miscellaneous values.

/*

 * Precalculate scale factor (in Gauss units) for each axis and

 * store in the device data.

 *

 * This scale factor is axis-dependent, and is derived from 3 calibration

 * factors ASA(x), ASA(y), and ASA(z).

 *

 * These ASA values are read from the sensor device at start of day, and

 * cached in the device context struct.

 *

 * Adjusting the flux value with the sensitivity adjustment value should be

 * done via the following formula:

 *

 * Hadj = H * ( ( ( (ASA-128)*0.5 ) / 128 ) + 1 )

 * where H is the raw value, ASA is the sensitivity adjustment, and Hadj

 * is the resultant adjusted value.

 *

 * We reduce the formula to:

 *

 * Hadj = H * (ASA + 128) / 256

 *

 * H is in the range of -4096 to 4095.  The magnetometer has a range of

 * +-1229uT.  To go from the raw value to uT is:

 *

 * HuT = H * 1229/4096, or roughly, 3/10.

 *

 * Since 1uT = 0.01 gauss, our final scale factor becomes:

 *

 * Hadj = H * ((ASA + 128) / 256) * 3/10 * 1/100

 * Hadj = H * ((ASA + 128) * 0.003) / 256

 *

 * Since ASA doesn't change, we cache the resultant scale factor into the

 * device context in ak8975_setup().

 *

 * Given we use IIO_VAL_INT_PLUS_MICRO bit when displaying the scale, we

 * multiply the stored scale value by 1e6.

/*

 * For AK8963 and AK09911, same calculation, but the device is less sensitive:

 *

 * H is in the range of +-8190.  The magnetometer has a range of

 * +-4912uT.  To go from the raw value to uT is:

 *

 * HuT = H * 4912/8190, or roughly, 6/10, instead of 3/10.

/*

 * For AK09912, same calculation, except the device is more sensitive:

 *

 * H is in the range of -32752 to 32752.  The magnetometer has a range of

 * +-4912uT.  To go from the raw value to uT is:

 *

 * HuT = H * 4912/32752, or roughly, 3/20, instead of 3/10.

 Compatible Asahi Kasei Compass parts */

/*

 * Per-instance context data for the device.

 Ensure natural alignment of timestamp */

 Enable attached power regulator if any. */

	/*

	 * According to the datasheet the power supply rise time is 200us

	 * and the minimum wait time before mode setting is 100us, in

	 * total 300us. Add some margin and say minimum 500us here.

 Disable attached power regulator if any. */

/*

 * Return 0 if the i2c device is the one we expect.

 * return a negative error number otherwise

	/*

	 * Signature for each device:

	 * Device   |  WIA1      |  WIA2

	 * AK09916  |  DEVICE_ID_|  AK09916_DEVICE_ID

	 * AK09912  |  DEVICE_ID |  AK09912_DEVICE_ID

	 * AK09911  |  DEVICE_ID |  AK09911_DEVICE_ID

	 * AK8975   |  DEVICE_ID |  NA

	 * AK8963   |  DEVICE_ID |  NA

/*

 * Helper function to write to CNTL register.

 After mode change wait atleast 100us */

/*

 * Handle data ready irq

/*

 * Install data ready interrupt handler

/*

 * Perform some start-of-day setup, including reading the asa calibration

 * values and caching them.

 Write the fused rom access mode. */

 Get asa data and store in the device data. */

 After reading fuse ROM data set power-down mode */

 Wait for the conversion to complete. */

 Wait for the conversion to complete. */

 Returns 0 if the end of conversion interrupt occured or -ETIME otherwise */

 Set up the device for taking a sample. */

 Wait for the conversion to complete. */

 This will be executed only for non-interrupt based waiting case */

 Retrieve raw flux value for one of the x, y, or z axis.  */

 Swap bytes and convert to valid range. */

	/*

	 * For each axis, read the flux value from the appropriate register

	 * (the register is specified in the iio device attributes).

 Clamp to valid range. */

	/*

	 * Grab and set up the supplied GPIO.

	 * We may not have a GPIO based IRQ to scan, that is fine, we will

	 * poll if so.

	/*

	 * According to AK09911 datasheet, if reset GPIO is provided then

	 * deassert reset on ak8975_power_on() and assert reset on

	 * ak8975_power_off().

 Register with IIO */

 id will be NULL when enumerated via ACPI */

 Fetch the regulators */

 Perform some basic start-of-day setup of the device. */

 Enable runtime PM */

	/*

	 * The device comes online in 500us, so add two orders of magnitude

	 * of delay before autosuspending: 50 ms.

 Set the device in power down if it wasn't already */

 Next cut the regulators */

 Take up the regulators */

	/*

	 * We come up in powered down mode, the reading routines will

	 * put us in the mode to read values later.

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 3-axis magnetometer driver supporting following I2C Bosch-Sensortec chips:

 *  - BMC150

 *  - BMC156

 *  - BMM150

 *

 * Copyright (c) 2016, Intel Corporation.

 deprecated compatible */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics magnetometers driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * mag3110.c - Support for Freescale MAG3110 magnetometer sensor

 *

 * Copyright (c) 2013 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * (7-bit I2C slave address 0x0e)

 *

 * TODO: irq, user offset, oversampling, continuous mode

 MSB first */

 MSB first */

 trigger single measurement */

 continuous measurements */

 magnetic auto-reset */

 measurements not user-offset corrected */

 Each client has this additional data */

 Ensure natural alignment of timestamp */

 trigger measurement */

 wait for data ready */

 replace trailing space by newline */

	/*

	 * Takes up to 1/ODR to come out of active mode into stby

	 * Longest expected period is 12.5seconds.

	 * We'll sleep for 500ms between checks

 wait for standby */

 returns >0 if active, 0 if in standby and <0 on error */

 config can only be changed when in standby */

	/*

	 * After coming out of active we must wait for the part

	 * to transition to STBY. This can take up to 1 /ODR to occur

 in 0.1 uT / LSB */

 in 1 C / LSB */

 SPDX-License-Identifier: GPL-2.0

/*

 * Support for PNI RM3100 3-axis geomagnetic sensor on a spi bus.

 *

 * Copyright (C) 2018 Song Qiang <songqiang1304521@gmail.com>

 Actually this device supports both mode 0 and mode 3. */

 Data rates cannot exceed 1Mbits. */

 SPDX-License-Identifier: GPL-2.0

/*

 * PNI RM3100 3-axis geomagnetic sensor driver core.

 *

 * Copyright (C) 2018 Song Qiang <songqiang1304521@gmail.com>

 *

 * User Manual available at

 * <https://www.pnicorp.com/download/rm3100-user-manual/>

 *

 * TODO: event generation, pm.

 Cycle Count Registers. */

 Poll Measurement Mode register. */

 Continuous Measurement Mode register. */

 TiMe Rate Configuration register. */

 Result Status register. */

 Measurement result registers. */

/*

 * This is computed by hand, is the sum of channel storage bits and padding

 * bits, which is 4+4+4+12=24 in here.

 Ensure naturally aligned timestamp */

	/*

	 * This lock is for protecting the consistency of series of i2c

	 * operations, that is, to make sure a measurement process will

	 * not be interrupted by a set frequency operation, which should

	 * be taken where a series of i2c operation starts, released where

	 * the operation ends.

	/*

	 * Write operation to any register or read operation

	 * to first byte of results will clear the interrupt.

	/*

	 * A read cycle of 400kbits i2c bus is about 20us, plus the time

	 * used for scheduling, a read cycle of fast mode of this device

	 * can reach 1.7ms, it may be possible for data to arrive just

	 * after we check the RM3100_REG_STATUS. In this case, irq_handler is

	 * called before measuring_done is reinitialized, it will wait

	 * forever for data that has already been ready.

	 * Reinitialize measuring_done before looking up makes sure we

	 * will always capture interrupt no matter when it happens.

/*

 * Frequency : rm3100_samp_rates[][0].rm3100_samp_rates[][1]Hz.

 * Time between reading: rm3100_sam_rates[][2]ms.

 * The first one is actually 1.7ms.

	/*

	 * The scale of this sensor depends on the cycle count value, these

	 * three values are corresponding to the cycle count value 50, 100,

	 * 200. scale = output / gain * 10^4.

	/*

	 * case 200:

	 * This function will never be called by users' code, so here we

	 * assume that it will never get a wrong parameter.

 All cycle count registers use the same value. */

 Checking if cycle count registers need changing. */

 Writing TMRC registers requires CMM reset. */

 Starting channels enabled. */

 Convert XXXYYYZZZxxx to XXXxYYYxZZZx. x for paddings. */

	/*

	 * Always using the same buffer so that we wouldn't need to set the

	 * paddings to 0 in case of leaking any data.

 Initializing max wait time, which is double conversion time. */

 Cycle count values may not be what we want. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Yamaha YAS magnetic sensors, often used in Samsung

 * mobile phones. While all are not yet handled because of lacking

 * hardware, expand this driver to handle the different variants:

 *

 * YAS530 MS-3E (2011 Samsung Galaxy S Advance)

 * YAS532 MS-3R (2011 Samsung Galaxy S4)

 * YAS533 MS-3F (Vivo 1633, 1707, V3, Y21L)

 * (YAS534 is a magnetic switch, not handled)

 * YAS535 MS-6C

 * YAS536 MS-3W

 * YAS537 MS-3T (2015 Samsung Galaxy S6, Note 5, Xiaomi)

 * YAS539 MS-3S (2018 Samsung Galaxy A7 SM-A750FN)

 *

 * Code functions found in the MPU3050 YAS530 and YAS532 drivers

 * named "inv_compass" in the Tegra Android kernel tree.

 * Copyright (C) 2012 InvenSense Corporation

 *

 * Author: Linus Walleij <linus.walleij@linaro.org>

 This register map covers YAS530 and YAS532 but differs in YAS 537 and YAS539 */

 [-31 .. 31] */

 [-31 .. 31] */

 [-31 .. 31] */

 Bits in the YAS5xx config register */

 Interrupt on? */

 Interrupt active high? */

 Bits in the measure command register */

 Bits in the measure data register */

 YAS530 (MS-3E) */

 YAS530 (MS-3E A) */

 YAS530B (MS-3E B) */

 YAS532/YAS533 (MS-3R/F) */

 YAS532/533 AB (MS-3R/F AB) */

 YAS532/533 AC (MS-3R/F AC) */

 Looks like Kelvin */

 These variant IDs are known from code dumps */

 YAS537 (MS-3T) */

 YAS539 (MS-3S) */

 Turn off device regulators etc after 5 seconds of inactivity */

 Linearization calibration x, y1, y2 */

 Temperature compensation calibration */

 Misc calibration coefficients */

 clock divider */

/**

 * struct yas5xx - state container for the YAS5xx driver

 * @dev: parent device pointer

 * @devid: device ID number

 * @version: device version

 * @name: device name

 * @calibration: calibration settings from the OTP storage

 * @hard_offsets: offsets for each axis measured with initcoil actuated

 * @orientation: mounting matrix, flipped axis etc

 * @map: regmap to access the YAX5xx registers over I2C

 * @regs: the vdd and vddio power regulators

 * @reset: optional GPIO line used for handling RESET

 * @lock: locks the magnetometer for exclusive use during a measurement (which

 * involves several register transactions so the regmap lock is not enough)

 * so that measurements get serialized in a first-come-first serve manner

 * @scan: naturally aligned measurements

	/*

	 * The scanout is 4 x 32 bits in CPU endianness.

	 * Ensure timestamp is naturally aligned

 On YAS530 the x, y1 and y2 values are 12 bits */

	/*

	 * These are the bits used in a 16bit word:

	 * 15 14 13 12 11 10 9  8  7  6  5  4  3  2  1  0

	 *    x  x  x  x  x  x  x  x  x  x  x  x

 On YAS532 the x, y1 and y2 values are 13 bits */

	/*

	 * These are the bits used in a 16bit word:

	 * 15 14 13 12 11 10 9  8  7  6  5  4  3  2  1  0

	 *    x  x  x  x  x  x  x  x  x  x  x  x  x

/**

 * yas5xx_measure() - Make a measure from the hardware

 * @yas5xx: The device state

 * @t: the raw temperature measurement

 * @x: the raw x axis measurement

 * @y1: the y1 axis measurement

 * @y2: the y2 axis measurement

 * @return: 0 on success or error code

	/*

	 * Typical time to measure 1500 us, max 2000 us so wait min 500 us

	 * and at most 20000 us (one magnitude more than the datsheet max)

	 * before timeout.

		/*

		 * The t value is 9 bits in big endian format

		 * These are the bits used in a 16bit word:

		 * 15 14 13 12 11 10 9  8  7  6  5  4  3  2  1  0

		 *    x  x  x  x  x  x  x  x  x

		/*

		 * The t value is 10 bits in big endian format

		 * These are the bits used in a 16bit word:

		 * 15 14 13 12 11 10 9  8  7  6  5  4  3  2  1  0

		 *    x  x  x  x  x  x  x  x  x  x

 Select coefficients */

 Elaborate coefficients */

	/*

	 * Linearization formula:

	 *

	 * x' = x - (3721 + 50 * f) + (xoffset - r) * c

	 *

	 * Where f and r are calibration values, c is a per-device

	 * and sometimes per-axis coefficient.

/**

 * yas5xx_get_measure() - Measure a sample of all axis and process

 * @yas5xx: The device state

 * @to: Temperature out

 * @xo: X axis out

 * @yo: Y axis out

 * @zo: Z axis out

 * @return: 0 on success or error code

 *

 * Returned values are in nanotesla according to some code.

 These are "signed x, signed y1 etc */

 We first get raw data that needs to be translated to [x,y,z] */

 Do some linearization if available */

	/*

	 * Temperature compensation for x, y1, y2 respectively:

	 *

	 *          Cx * t

	 * x' = x - ------

	 *           100

	/*

	 * Break y1 and y2 into y and z, y1 and y2 are apparently encoding

	 * y and z.

	/*

	 * FIXME: convert to Celsius? Just guessing this is given

	 * as 1/10:s of degrees so multiply by 100 to get millicentigrades.

	/*

	 * Calibrate [x,y,z] with some formulas like this:

	 *

	 *            100 * x + a_2 * y + a_3 * z

	 *  x' = k *  ---------------------------

	 *                        10

	 *

	 *           a_4 * x + a_5 * y + a_6 * z

	 *  y' = k * ---------------------------

	 *                        10

	 *

	 *           a_7 * x + a_8 * y + a_9 * z

	 *  z' = k * ---------------------------

	 *                        10

 Temperature is unscaled */

		/*

		 * The axis values are in nanotesla according to the vendor

		 * drivers, but is clearly in microtesla according to

		 * experiments. Since 1 uT = 0.01 Gauss, we need to divide

		 * by 100000000 (10^8) to get to Gauss from the raw value.

 Unknown request */

 TODO: enable regmap cache, using mark dirty and sync at runtime resume */

/**

 * yas53x_extract_calibration() - extracts the a2-a9 and k calibration

 * @data: the bitfield to use

 * @c: the calibration to populate

	/*

	 * Bitfield layout for the axis calibration data, for factor

	 * a2 = 2 etc, k = k, c = clock divider

	 *

	 * n   7 6 5 4 3 2 1 0

	 * 0 [ 2 2 2 2 2 2 3 3 ] bits 63 .. 56

	 * 1 [ 3 3 4 4 4 4 4 4 ] bits 55 .. 48

	 * 2 [ 5 5 5 5 5 5 6 6 ] bits 47 .. 40

	 * 3 [ 6 6 6 6 7 7 7 7 ] bits 39 .. 32

	 * 4 [ 7 7 7 8 8 8 8 8 ] bits 31 .. 24

	 * 5 [ 8 9 9 9 9 9 9 9 ] bits 23 .. 16

	 * 6 [ 9 k k k k k c c ] bits 15 .. 8

	 * 7 [ c x x x x x x x ] bits  7 .. 0

 Dummy read, first read is ALWAYS wrong */

 Actual calibration readout */

 Extract the calibration from the bitfield */

	/*

	 * Extract linearization:

	 * Linearization layout in the 32 bits at byte 11:

	 * The r factors are 6 bit values where bit 5 is the sign

	 *

	 * n    7  6  5  4  3  2  1  0

	 * 0 [ xx xx xx r0 r0 r0 r0 r0 ] bits 31 .. 24

	 * 1 [ r0 f0 f0 r1 r1 r1 r1 r1 ] bits 23 .. 16

	 * 2 [ r1 f1 f1 r2 r2 r2 r2 r2 ] bits 15 .. 8

	 * 3 [ r2 f2 f2 xx xx xx xx xx ] bits  7 .. 0

 Dummy read, first read is ALWAYS wrong */

 Actual calibration readout */

 Sanity check, is this all zeroes? */

 Only one bit of version info reserved here as far as we know */

 Extract calibration from the bitfield */

	/*

	 * Extract linearization:

	 * Linearization layout in the 32 bits at byte 10:

	 * The r factors are 6 bit values where bit 5 is the sign

	 *

	 * n    7  6  5  4  3  2  1  0

	 * 0 [ xx r0 r0 r0 r0 r0 r0 f0 ] bits 31 .. 24

	 * 1 [ f0 r1 r1 r1 r1 r1 r1 f1 ] bits 23 .. 16

	 * 2 [ f1 r2 r2 r2 r2 r2 r2 f2 ] bits 15 .. 8

	 * 3 [ f2 xx xx xx xx xx xx xx ] bits  7 .. 0

 Actuate the init coil and measure offsets */

 When the initcoil is active this should be around the center */

	/*

	 * We set offsets in the interval +-31 by iterating

	 * +-16, +-8, +-4, +-2, +-1 adjusting the offsets each

	 * time, then writing the final offsets into the

	 * registers.

	 *

	 * NOTE: these offsets are NOT in the same unit or magnitude

	 * as the values for [x, y1, y2]. The value is +/-31

	 * but the effect on the raw values is much larger.

	 * The effect of the offset is to bring the measure

	 * rougly to the center.

 Needed for calibration algorithm */

 Zero the test registers */

 Set up for no interrupts, calibrated clock divider */

 Measure interval 0 (back-to-back?)  */

 See comment in runtime resume callback */

 This will take the device out of reset if need be */

 Take runtime PM online */

	/*

	 * Now we can't get any more reads from the device, which would

	 * also call pm_runtime* functions and race with our disable

	 * code. Disable PM runtime in orderly fashion and power down.

	/*

	 * The YAS530 datasheet says TVSKW is up to 30 ms, after that 1 ms

	 * for all voltages to settle. The YAS532 is 10ms then 4ms for the

	 * I2C to come online. Let's keep it safe and put this at 31ms.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics magnetometers driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Device driver for the the HMC5843 multi-chip module designed

 * for low field magnetic sensing.

 *

 * Copyright (C) 2010 Texas Instruments

 *

 * Author: Shubhrajyoti Datta <shubhrajyoti@ti.com>

 * Acknowledgment: Jonathan Cameron <jic23@kernel.org> for valuable inputs.

 * Support for HMC5883 and HMC5883L by Peter Meerwald <pmeerw@pmeerw.net>.

 * Split to multiple files by Josef Gajdusek <atx@atx.name> - 2014

/*

 * Range gain settings in (+-)Ga

 * Beware: HMC5843 and HMC5883 have different recommended sensor field

 * ranges; default corresponds to +-1.0 Ga and +-1.3 Ga, respectively

 Device status */

 Mode register configuration */

/*

 * HMC5843: Minimum data output rate

 * HMC5883: Typical data output rate

 Device measurement configuration */

/*

 * API for setting the measurement configuration to

 * Normal, Positive bias and Negative bias

 *

 * From the datasheet:

 * 0 - Normal measurement configuration (default): In normal measurement

 *     configuration the device follows normal measurement flow. Pins BP

 *     and BN are left floating and high impedance.

 *

 * 1 - Positive bias configuration: In positive bias configuration, a

 *     positive current is forced across the resistive load on pins BP

 *     and BN.

 *

 * 2 - Negative bias configuration. In negative bias configuration, a

 *     negative current is forced across the resistive load on pins BP

 *     and BN.

 *

 * 3 - Only available on HMC5983. Magnetic sensor is disabled.

 *     Temperature sensor is enabled.

 Scaling factors: 10000000/Gain */

/*

 * From the datasheet:

 * Value	| HMC5843		| HMC5883/HMC5883L

 *		| Data output rate (Hz)	| Data output rate (Hz)

 * 0		| 0.5			| 0.75

 * 1		| 1			| 1.5

 * 2		| 2			| 3

 * 3		| 5			| 7.5

 * 4		| 10 (default)		| 15

 * 5		| 20			| 30

 * 6		| 50			| 75

 * 7		| Not used		| Not used

 Describe chip variants */

 The lower two bits contain the current conversion mode */

 Return the measurement value from the specified channel */

 replace trailing space by newline */

 replace trailing space by newline */

 Beware: Y and Z are exchanged on HMC5883 and 5983 */

 default settings at probe */

  sleep mode to save power */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics magnetometers driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 DEFAULT VALUE FOR SENSORS */

 FULLSCALE */

 Special L addresses for Sensor 2 */

 Special L addresses for sensor 3 */

 Special L addresses for sensor 4 */

 This sensor has no valid WhoAmI report 0 */

 220 Hz, 0x07 reportedly exist */

 drdy line is routed drdy pin */

 Default magn DRDY is available on INT2 pin */

/*

 * st_magn_get_settings() - get sensor settings from device name

 * @name: device name buffer reference.

 *

 * Return: valid reference on success, NULL otherwise.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MMC35240 - MEMSIC 3-axis Magnetic Sensor

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * IIO driver for MMC35240 (7-bit I2C slave address 0x30).

 *

 * TODO: offset, ACPI, continuous measurement mode, PM

 output resolution bits */

 us */

 us */

/*

 * Memsic OTP process code piece is put here for reference:

 *

 * #define OTP_CONVERT(REG)  ((float)((REG) >=32 ? (32 - (REG)) : (REG)) * 0.006

 * 1) For X axis, the COEFFICIENT is always 1.

 * 2) For Y axis, the COEFFICIENT is as below:

 *    f_OTP_matrix[4] = OTP_CONVERT(((reg_data[1] & 0x03) << 4) |

 *                                   (reg_data[2] >> 4)) + 1.0;

 * 3) For Z axis, the COEFFICIENT is as below:

 *    f_OTP_matrix[8] = (OTP_CONVERT(reg_data[3] & 0x3f) + 1) * 1.35;

 * We implemented the OTP logic into driver.

 scale = 1000 here for Y otp */

 0.6 * 1.35 = 0.81, scale 10000 for Z otp */

 7.92 ms */

 4.08 ms */

 2.16 ms */

 1.20 ms */

 sensitivity per X, Y, Z axis */

 null field output */

 16 bits, 125Hz ODR */

 16 bits, 250Hz ODR */

 14 bits, 450Hz ODR */

 12 bits, 800Hz ODR */

 OTP compensation */

	/*

	 * Recharge the capacitor at VCAP pin, requested to be issued

	 * before a SET/RESET command.

	/*

	 * make sure we restore sensor characteristics, by doing

	 * a SET/RESET sequence, the axis polarity being naturally

	 * aligned after RESET

 set default sampling frequency */

 minimum wait time to complete measurement is 10 ms */

/**

 * mmc35240_raw_to_mgauss - convert raw readings to milli gauss. Also apply

 *			    compensation for output value.

 *

 * @data: device private data

 * @index: axis index for which we want the conversion

 * @buf: raw data to be converted, 2 bytes in little endian format

 * @val: compensated output reading (unit is milli gauss)

 *

 * Returns: 0 in case of success, -EINVAL when @index is not valid

 apply OTP compensation */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AFE4404 Heart Rate Monitors and Low-Cost Pulse Oximeters

 *

 * Copyright (C) 2015-2016 Texas Instruments Incorporated - https://www.ti.com/

 *	Andrew F. Davis <afd@ti.com>

 AFE4404 registers */

 AFE4404 CONTROL2 register fields */

 Gains */

 LED Current */

 Offset DAC */

 sentinel */

 Gains */

 LED Current */

 Offset DAC */

/**

 * struct afe4404_data - AFE4404 device instance data

 * @dev: Device structure

 * @regmap: Register map of the device

 * @fields: Register fields of the device

 * @regulator: Pointer to the regulator for the IC

 * @trig: IIO trigger for this device

 * @irq: ADC_RDY line interrupt number

 * @buffer: Used to construct a scan to push to the iio buffer.

 ADC values */

 LED current */

 Default timings from data-sheet */

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * max30102.c - Support for MAX30102 heart rate and pulse oximeter sensor

 *

 * Copyright (C) 2017 Matt Ranostay <matt.ranostay@konsulko.com>

 *

 * Support for MAX30105 optical particle sensor

 * Copyright (C) 2017 Peter Meerwald-Stadler <pmeerw@pmeerw.net>

 *

 * 7-bit I2C chip address: 0x57

 * TODO: proximity power saving feature

 red LED */

 red + IR LED */

 multi-LED mode */

 multi-LED control */

 3 x 18-bit (padded to 32-bits) */

 FIFO has one sample slot left */

 each step is 0.200 mA */

 Default to 7 mA RED LED */

 Default to 7 mA green LED */

 Default to 7 mA IR LED */

 setup LED current settings */

 configure 18-bit HR + SpO2 readings at 400Hz */

 average 4 samples + generate FIFO interrupt */

 enable FIFO interrupt */

 start acquisition */

		/*

		 * Temperature reading can only be acquired when not in

		 * shutdown; leave shutdown briefly when buffer not running

 62.5 */

 check part ID */

 show revision ID */

 clear mode setting, chip shutdown */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AFE4403 Heart Rate Monitors and Low-Cost Pulse Oximeters

 *

 * Copyright (C) 2015-2016 Texas Instruments Incorporated - https://www.ti.com/

 *	Andrew F. Davis <afd@ti.com>

 AFE4403 Registers */

 Gains */

 LED Current */

 sentinel */

 Gains */

 LED Current */

/**

 * struct afe4403_data - AFE4403 device instance data

 * @dev: Device structure

 * @spi: SPI device handle

 * @regmap: Register map of the device

 * @fields: Register fields of the device

 * @regulator: Pointer to the regulator for the IC

 * @trig: IIO trigger for this device

 * @irq: ADC_RDY line interrupt number

 * @buffer: Used to construct data layout to push into IIO buffer.

 Ensure suitable alignment for timestamp */

 ADC values */

 LED current */

 Enable reading from the device */

 Disable reading from the device */

 Enable reading from the device */

 Disable reading from the device */

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * max30100.c - Support for MAX30100 heart rate and pulse oximeter sensor

 *

 * Copyright (C) 2015, 2018

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 *

 * TODO: enable pulse length controls via device tree properties

 2 16-bit channels */

 FIFO is almost full */

 LED turned off */

 Default to 24 mA RED LED, 50 mA IR LED */

 RED LED current */

 IR LED current */

 setup LED current settings */

 enable hi-res SPO2 readings at 100Hz */

 enable SPO2 mode */

 enable FIFO interrupt */

 start acquisition */

		/*

		 * Temperature reading can only be acquired while engine

		 * is running

 0.0625 */

 SPDX-License-Identifier: GPL-2.0

/*

 * IIO multiplexer driver

 *

 * Copyright (C) 2017 Axentia Technologies AB

 *

 * Author: Peter Rosin <peda@axentia.se>

/*

 * Same as of_property_for_each_string(), but also keeps track of the

 * index of each string.

 one extra entry for the sentinel */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * JSA1212 Ambient Light & Proximity Sensor Driver

 *

 * Copyright (c) 2014, Intel Corporation.

 *

 * JSA1212 I2C slave address: 0x44(ADDR tied to GND), 0x45(ADDR tied to VDD)

 *

 * TODO: Interrupt support, thresholds, range support.

 JSA1212 reg address */

 JSA1212 reg masks */

 JSA1212 CONF REG bits */

 Proxmity sensing IRDR current sink settings */

 JSA1212 INT REG bits */

 JSA1212 ALS RNG REG bits */

 JSA1212 INT threshold range */

 ALS enable status */

 proximity enable status */

 ALS range idx to val mapping */

 Enables or disables ALS function based on status */

 Enables or disables PXS function based on status */

 Delay for data output */

 Read 12 bit data */

 Delay for data output */

 Read out all data */

 Max 12 bit value */

 power off the device */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 Samsung Electronics Co., Ltd.

 * Author: Jacek Anaszewski <j.anaszewski@samsung.com>

 *

 * IIO features supported by the driver:

 *

 * Read-only raw channels:

 *   - illuminance_clear [lux]

 *   - illuminance_ir

 *   - proximity

 *

 * Triggered buffer:

 *   - illuminance_clear

 *   - illuminance_ir

 *   - proximity

 *

 * Events:

 *   - illuminance_clear (rising and falling)

 *   - proximity (rising and falling)

 *     - both falling and rising thresholds for the proximity events

 *       must be set to the values greater than 0.

 *

 * The driver supports triggered buffers for all the three

 * channels as well as high and low threshold events for the

 * illuminance_clear and proxmimity channels. Triggers

 * can be enabled simultaneously with both illuminance_clear

 * events. Proximity events cannot be enabled simultaneously

 * with any triggers or illuminance events. Enabling/disabling

 * one of the proximity events automatically enables/disables

 * the other one.

 Registers */

 Basic operations */

 ALS related settings */

 PS related settings */

 LED reg */

 ALS: Threshold low LSB */

 ALS: Threshold low MSB */

 ALS: Threshold high LSB */

 ALS: Threshold high MSB */

 PS: Threshold low LSB */

 PS: Threshold low MSB */

 PS: Threshold high LSB */

 PS: Threshold high MSB */

 ALS result: Clear/Illuminance LSB */

 ALS result: Clear/Illuminance MSB */

 ALS result: IR LSB */

 ALS result: IR LSB */

 PS result LSB */

 PS result MSB */

 Number of registers */

 OP_REG bits */

 Software shutdown */

 Auto shutdown/Continuous mode */

 Operating mode selection  */

 PS: detection/non-detection */

 PS: interrupt result  */

 ALS: interrupt result  */

 Output data type selection */

 ALS_REG bits */

 Number of measurement cycles */

 ALS: Resolution */

 ALS: Max measurable range */

 PS_REG bits */

 Auto light cancel */

 Interrupt type setting */

 PS: Resolution */

 PS: Max measurable range */

 LED reg bits */

 Intermittent operating */

 ILED drive peak current */

 INT terminal setting */

 LED modulation frequency */

 Software reset */

		/*

		 * Shutdown the device if the operation being executed entails

		 * mode transition.

 set shutdown mode */

 Set OP_REG and apply operation mode (power on / off) */

		/*

		 * For the high lux mode ALS threshold has to be scaled down

		 * to allow for proper comparison with the output value.

		/* Clear als threshold registers to avoid spurious

		 * events caused by lux mode transition.

 Change lux mode */

 Adjust als threshold register values to the new lux mode */

 Read interrupt flags */

 Read interrupt flags */

 Clear interrupt flags (if not in INTTYPE_PULSE mode) */

		/* Check D0 register to assess if the lux mode

		 * transition is required.

		/*

		 * We need to check output value to distinguish

		 * between high and low ambient light threshold event.

 This fires off the trigger. */

	/*

	 * In order to enable proximity detection feature in the device

	 * both high and low threshold registers have to be written

	 * with different values, greater than zero.

	/*

	 * Enable triggers according to the scan_mask. Enabling either

	 * LIGHT_CLEAR or LIGHT_IR scan mode results in enabling ALS

	 * module in the device, which generates samples in both D0 (clear)

	 * and D1 (ir) registers. As the two registers are bound to the

	 * two separate IIO channels they are treated in the driver logic

	 * as if they were controlled independently.

 Initialize device registers */

 Allocate buffer */

 Allocate trigger */

 This needs to be requested here for read_raw calls to work. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics uvis25 spi driver

 *

 * Copyright 2017 STMicroelectronics Inc.

 *

 * Lorenzo Bianconi <lorenzo.bianconi83@gmail.com>

 SPDX-License-Identifier: GPL-2.0+

/*

 * lv0104cs.c: LV0104CS Ambient Light Sensor Driver

 *

 * Copyright (C) 2018

 * Author: Jeff LaBundy <jeff@labundy.com>

 *

 * 7-bit I2C slave address: 0x13

 *

 * Link to data sheet: https://www.onsemi.com/pub/Collateral/LV0104CS-D.PDF

 wait for integration time to pass (with margin) */

 convert ADC output to lux */

 round to nearest quantized calibscale (sensitivity) */

 round down */

 round up */

 set calibscale (sensitivity) */

 hard matching */

 hard matching */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CM3605 Ambient Light and Proximity Sensor

 *

 * Copyright (C) 2016 Linaro Ltd.

 * Author: Linus Walleij <linus.walleij@linaro.org>

 *

 * This hardware was found in the very first Nexus One handset from Google/HTC

 * and an early endavour into mobile light and proximity sensors.

 To get our ADC channel */

 To deal with our ADC channel */

 It should not go above 1.650V according to the data sheet */

/**

 * struct cm3605 - CM3605 state

 * @dev: pointer to parent device

 * @vdd: regulator controlling VDD

 * @aset: sleep enable GPIO, high = sleep

 * @aout: IIO ADC channel to convert the AOUT signal

 * @als_max: maximum LUX detection (depends on RSET)

 * @dir: proximity direction: start as FALLING

 * @led: trigger for the infrared LED used by the proximity sensor

 Invert the edge for each event */

	/*

	 * AOUT has an offset of ~30mV then linear at dark

	 * then goes from 2.54 up to 650 LUX yielding 1.55V

	 * (1550 mV) so scale the returned value to this interval

	 * using simple linear interpolation.

 Remove bias */

 Linear interpolation between 0 and ALS typ max */

 Just name the trigger the same as the driver */

 SPDX-License-Identifier: GPL-2.0+

/*

 * VEML6030 Ambient Light Sensor

 *

 * Copyright (c) 2019, Rishi Gupta <gupt21@gmail.com>

 *

 * Datasheet: https://www.vishay.com/docs/84366/veml6030.pdf

 * Appnote-84367: https://www.vishay.com/docs/84367/designingveml6030.pdf

 Device registers */

 Bit masks for specific functionality */

/*

 * The resolution depends on both gain and integration time. The

 * cur_resolution stores one of the resolution mentioned in the

 * table during startup and gets updated whenever integration time

 * or gain is changed.

 *

 * Table 'resolution and maximum detection range' in appnote 84367

 * is visualized as a 2D array. The cur_gain stores index of gain

 * in this table (0-3) while the cur_integration_time holds index

 * of integration time (0-5).

 Integration time available in seconds */

/*

 * Scale is 1/gain. Value 0.125 is ALS gain x (1/8), 0.25 is

 * ALS gain x (1/4), 1.0 = ALS gain x 1 and 2.0 is ALS gain x 2.

/*

 * Persistence = 1/2/4/8 x integration time

 * Minimum time for which light readings must stay above configured

 * threshold to assert the interrupt.

/*

 * Return list of valid period values in seconds corresponding to

 * the currently active integration time.

 Channel number */

	/*

	 * Cache current integration time and update resolution. For every

	 * increase in integration time to next level, resolution is halved

	 * and vice-versa.

 integration time multiplied by 1/2/4/8 */

 0x02 << 11 */

	/*

	 * Cache currently set gain & update resolution. For every

	 * increase in the gain to next level, resolution is halved

	 * and vice-versa.

/*

 * Provide both raw as well as light reading in lux.

 * light (in lux) = resolution * raw reading

/*

 * Sensor should not be measuring light when interrupt is configured.

 * Therefore correct sequence to configure interrupt functionality is:

 * shut down -> enable/disable interrupt -> power on

 *

 * state = 1 enables interrupt, state = 0 disables interrupt

 enable interrupt + power on */

 Spurious interrupt handling */

/*

 * Set ALS gain to 1/8, integration time to 100 ms, PSM to mode 2,

 * persistence to 1 x integration time and the threshold

 * interrupt disabled by default. First shutdown the sensor,

 * update registers and then power on the sensor.

 Wait 4 ms to let processor & oscillator start correctly */

 Clear stale interrupt status bits if any during start */

 Cache currently active measurement parameters */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * tcs3414.c - Support for TAOS TCS3414 digital color sensor

 *

 * Copyright (c) 2014 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * Digital color sensor with 16-bit channels for red, green, blue, clear);

 * 7-bit I2C slave address 0x39 (TCS3414) or 0x29, 0x49, 0x59 (TCS3413,

 * TCS3415, TCS3416, resp.)

 *

 * TODO: sync, interrupt support, thresholds, prescaler

 Ensure timestamp is naturally aligned */

 scale factors: 1/gain */

 integration time in ms */

 free running */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for AMS AS73211 JENCOLOR(R) Digital XYZ Sensor

 *

 * Author: Christian Eggers <ceggers@arri.de>

 *

 * Copyright (c) 2020 ARRI Lighting

 *

 * Color light sensor with 16-bit channels for x, y, z and temperature);

 * 7-bit I2C slave address 0x74 .. 0x77.

 *

 * Datasheet: https://ams.com/documents/20143/36005/AS73211_DS000556_3-01.pdf

 AS73211 configuration registers */

 AS73211 output register bank */

 Available sample frequencies are 1.024MHz multiplied by powers of two. */

/**

 * struct as73211_data - Instance data for one AS73211

 * @client: I2C client.

 * @osr:    Cached Operational State Register.

 * @creg1:  Cached Configuration Register 1.

 * @creg2:  Cached Configuration Register 2.

 * @creg3:  Cached Configuration Register 3.

 * @mutex:  Keeps cached registers in sync with the device.

 * @completion: Completion to wait for interrupt.

 * @int_time_avail: Available integration times (depend on sampling frequency).

 nW/m^2 */

 nW/m^2 */

 nW/m^2 */

 Channel order MUST match devices result register order */

	/*

	 * Return integration time in units of 1024 clock cycles. Integration time

	 * in CREG1 is in powers of 2 (x 1024 cycles).

	/*

	 * f_samp is configured in CREG3 in powers of 2 (x 1.024 MHz)

	 * t_cycl is configured in CREG1 in powers of 2 (x 1024 cycles)

	 * t_int_us = 1 / (f_samp) * t_cycl * US_PER_SEC

	 *          = 1 / (2^CREG3_CCLK * 1,024,000) * 2^CREG1_CYCLES * 1,024 * US_PER_SEC

	 *          = 2^(-CREG3_CCLK) * 2^CREG1_CYCLES * 1,000

	 * In order to get rid of negative exponents, we extend the "fraction"

	 * by 2^3 (CREG3_CCLK,max = 3)

	 * t_int_us = 2^(3-CREG3_CCLK) * 2^CREG1_CYCLES * 125

 gain can be calculated from CREG1 as 2^(11 - CREG1_GAIN) */

 must be called with as73211_data::mutex held. */

	/*

	 * During measurement, there should be no traffic on the i2c bus as the

	 * electrical noise would disturb the measurement process.

	/*

	 * Reset AS73211_OSR_SS (is self clearing) in order to avoid unintentional

	 * triggering of further measurements later.

	/*

	 * Add 33% extra margin for the timeout. fclk,min = fclk,typ - 27%.

 Wait integration time */

 f_samp is configured in CREG3 in powers of 2 (x 1.024 MHz) */

 1024, 2048, ... */

 val must be 1024 * 2^x */

 f_samp is configured in CREG3 in powers of 2 (x 1.024 MHz (=2^10)) */

 gain can be calculated from CREG1 as 2^(11 - CREG1_GAIN) */

 f_samp is configured in CREG3 in powers of 2 (x 1.024 MHz) */

		/*

		 * time_ms = time_us * US_PER_MS * f_samp_1_024mhz / MHZ_PER_HZ

		 *         = time_us * f_samp_1_024mhz / 1000

 1 ms, 2 ms, ... (power of two) */

 not possible due to previous tests */

 Need to switch to config mode ... */

 don't push any data for errors other than EOVERFLOW */

 Optimization for reading all (color + temperature) channels */

 Optimization for reading only color channels */

 AS73211 starts reading at address 2 */

		/*

		 * Saturate all channels (in case of overflows). Temperature channel

		 * is not affected by overflows.

 reset device */

	/*

	 * Reading AGEN is only possible after reset (AGEN is not available if

	 * device is in measurement mode).

 At the time of writing this driver, only DEVID 2 and MUT 1 are known. */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Device driver for monitoring ambient light intensity in (lux) and proximity

 * detection (prox) within the TAOS TSL2571, TSL2671, TMD2671, TSL2771, TMD2771,

 * TSL2572, TSL2672, TMD2672, TSL2772, and TMD2772 devices.

 *

 * Copyright (c) 2012, TAOS Corporation.

 * Copyright (c) 2017-2018 Brian Masney <masneyb@onstation.org>

 Cal defs */

 TSL2772 Device ID */

 Lux calculation constants */

/*

 * TAOS Register definitions - Note: depending on device, some of these register

 * are not used and the register address is benign.

 Register offsets */

 Device Registers and Masks */

 tsl2772 cmd reg masks */

 tsl2772 cntrl reg masks */

 tsl2772 status reg masks */

 tsl2772 cntrl reg masks */

 Device family members */

 Per-device data */

	/*

	 * This structure is intentionally large to accommodate

	 * updates via sysfs.

	 * Sized to 9 = max 8 segments + 1 termination segment

/*

 * Different devices require different coefficents, and these numbers were

 * derived from the 'Lux Equation' section of the various device datasheets.

 * All of these coefficients assume a Glass Attenuation (GA) factor of 1.

 * The coefficients are multiplied by 1000 to avoid floating point operations.

 * The two rows in each table correspond to the Lux1 and Lux2 equations from

 * the datasheets.

 2.72 / 2.73 ms */

 2.72 / 2.73 ms */

 Channel variations */

/**

 * tsl2772_get_lux() - Reads and calculates current lux value.

 * @indio_dev:	pointer to IIO device

 *

 * The raw ch0 and ch1 values of the ambient light sensed in the last

 * integration cycle are read from the device. The raw values are multiplied

 * by a device-specific scale factor, and divided by the integration time and

 * device gain. The code supports multiple lux equations through the lux table

 * coefficients. A lux gain trim is applied to each lux equation, and then the

 * maximum lux within the interval 0..65535 is selected.

 return LAST VALUE */

 have no data, so return LAST VALUE */

		/*

		 * The als_gain_trim can have a value within the range 250..4000

		 * and is a multiplier for the lux. A trim of 1000 makes no

		 * changes to the lux, less than 1000 scales it down, and

		 * greater than 1000 scales it up.

/**

 * tsl2772_get_prox() - Reads proximity data registers and updates

 *                      chip->prox_data.

 *

 * @indio_dev:	pointer to IIO device

/**

 * tsl2772_defaults() - Populates the device nominal operating parameters

 *                      with those provided by a 'platform' data struct or

 *                      with prefined defaults.

 *

 * @chip:               pointer to device structure.

 If Operational settings defined elsewhere.. */

 Load up the proper lux table. */

/**

 * tsl2772_als_calibrate() -	Obtain single reading and calculate

 *                              the als_gain_trim.

 *

 * @indio_dev:	pointer to IIO device

 Non calculated parameters */

 and make sure we're not already on */

 if forcing a register update - turn off, then on */

 Set the gain based on tsl2772_settings struct */

 set chip time scaling and saturation */

 75% of full scale */

	/*

	 * TSL2772 Specific power-on / adc enable sequence

	 * Power on the device 1st.

	/*

	 * Use the following shadow copy for our delay before enabling ADC.

	 * Write all the registers.

 Power-on settling time */

 turn device off */

/**

 * tsl2772_invoke_change - power cycle the device to implement the user

 *                         parameters

 * @indio_dev:	pointer to IIO device

 *

 * Obtain and lock both ALS and PROX resources, determine and save device state

 * (On/Off), cycle device to implement updated parameter, put device back into

 * proper state, and unlock resource.

			/*

			 * We just printed the first "0" entry.

			 * Now get rid of the extra "," and break.

	/*

	 * We now have an array of ints starting at value[1], and

	 * enumerated by value[0].

	 * We expect each group of two ints to be one table entry,

	 * and the last table entry is all 0.

 Zero out the table */

 ALS filter values are 1, 2, 3, 5, 10, 15, ..., 60 */

 ALS filter values are 1, 2, 3, 5, 10, 15, ..., 60 */

 Use the default register values to identify the Taos device */

 What type of interrupt do we need to process */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO driver for the light sensor ISL29028.

 * ISL29028 is Concurrent Ambient Light and Proximity Sensor

 *

 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 * Copyright (c) 2016-2017 Brian Masney <masneyb@onstation.org>

 *

 * Datasheets:

 *  - http://www.intersil.com/content/dam/Intersil/documents/isl2/isl29028.pdf

 *  - http://www.intersil.com/content/dam/Intersil/documents/isl2/isl29030.pdf

	{  80,      0,  13 }, /*

			       * Note: Data sheet lists 12.5 ms sleep time.

			       * Round up a half millisecond for msleep().

 Wait for conversion to be complete for first sample */

 Enable the ALS/IR */

 Need to wait for conversion time if ALS/IR mode enabled */

	/*

	 * convert als data count to lux.

	 * if lux_scale = 125,  lux = count * 0.031

	 * if lux_scale = 2000, lux = count * 0.49

 Channel IO */

	/**

	 * Preserve the ret variable if the call to

	 * isl29028_set_pm_runtime_busy() is successful so the reading

	 * (if applicable) is returned to user space.

	/**

	 * The specific component (ALS/IR or proximity) will enable itself as

	 * needed the next time that the user requests a reading. This is done

	 * above in isl29028_set_als_ir_mode() and isl29028_enable_proximity().

 for backward compat., don't use */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 Capella Microsystems Inc.

 * Author: Kevin Tsai <ktsai@capellamicro.com>

 Registers Address */

 Number of Configurable Registers */

 CMD register */

 ALS_SM=01 IT=800ms */

 Based on IT=800ms */

 CPM0 Index 0: device-id (3218 or 32181), 1: Unknown, 2: init_regs_bitmap */

 CPM1 Index 0: lux_per_bit, 1: calibscale, 2: resolution (100000) */

 CM3218 Family */

 CM32181 Family */

/**

 * cm32181_acpi_get_cpm() - Get CPM object from ACPI

 * @dev:	pointer of struct device.

 * @obj_name:	pointer of ACPI object name.

 * @values:	pointer of array for return elements.

 * @count:	maximum size of return array.

 *

 * Convert ACPI CPM table to array.

 *

 * Return: -ENODEV for fail.  Otherwise is number of elements.

 Check for uncalibrated devices */

 CPM1 lux_per_bit is for the current it value */

 CONFIG_ACPI */

/**

 * cm32181_reg_init() - Initialize CM32181 registers

 * @cm32181:	pointer of struct cm32181.

 *

 * Initialize CM32181 ambient light sensor register to default values.

 *

 * Return: 0 for success; otherwise for error code.

 check device ID */

 CM3218 */

 CM32181 */

 CM32182, fully compat. with CM32181 */

 Default Values */

 Initialize registers*/

/**

 *  cm32181_read_als_it() - Get sensor integration time (ms)

 *  @cm32181:	pointer of struct cm32181

 *  @val2:	pointer of int to load the als_it value.

 *

 *  Report the current integration time in milliseconds.

 *

 *  Return: IIO_VAL_INT_PLUS_MICRO for success, otherwise -EINVAL.

/**

 * cm32181_write_als_it() - Write sensor integration time

 * @cm32181:	pointer of struct cm32181.

 * @val:	integration time by millisecond.

 *

 * Convert integration time (ms) to sensor value.

 *

 * Return: i2c_smbus_write_word_data command return value.

/**

 * cm32181_get_lux() - report current lux value

 * @cm32181:	pointer of struct cm32181.

 *

 * Convert sensor raw data to lux.  It depends on integration

 * time and calibscale variable.

 *

 * Return: Positive value is lux, otherwise is error code.

/**

 * cm32181_get_it_available() - Get available ALS IT value

 * @dev:	pointer of struct device.

 * @attr:	pointer of struct device_attribute.

 * @buf:	pointer of return string buffer.

 *

 * Display the available integration time values by millisecond.

 *

 * Return: string length.

	/*

	 * Some ACPI systems list 2 I2C resources for the CM3218 sensor, the

	 * SMBus Alert Response Address (ARA, 0x0c) and the actual I2C address.

	 * Detect this and take the following step to deal with it:

	 * 1. When a SMBus Alert capable sensor has an Alert asserted, it will

	 *    not respond on its actual I2C address. Read a byte from the ARA

	 *    to clear any pending Alerts.

	 * 2. Create a "dummy" client for the actual I2C address and

	 *    use that client to communicate with the sensor.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * vl6180.c - Support for STMicroelectronics VL6180 ALS, range and proximity

 * sensor

 *

 * Copyright 2017 Peter Meerwald-Stadler <pmeerw@pmeerw.net>

 * Copyright 2017 Manivannan Sadhasivam <manivannanece23@gmail.com>

 *

 * IIO driver for VL6180 (7-bit I2C slave address 0x29)

 *

 * Range: 0 to 100mm

 * ALS: < 1 Lux up to 100 kLux

 * IR: 850nm

 *

 * TODO: irq, threshold events, continuous mode, hardware buffer

 Device identification register and value */

 Configuration registers */

 Status registers */

 Result value registers */

 bits of the RANGE_START and ALS_START register */

 continuous mode */

 start measurement, auto-reset */

 bits of the INTR_STATUS and INTR_CONFIG register */

 bits of the INTR_CLEAR register */

 bits of the HOLD register */

 default value for the ALS_IT register */

 100 ms */

 values for the ALS_GAIN register */

/**

 * struct vl6180_chan_regs - Registers for accessing channels

 * @drdy_mask:			Data ready bit in status register

 * @start_reg:			Conversion start register

 * @value_reg:			Result value register

 * @word:			Register word length

 Start single shot measurement */

 Read result value from appropriate registers */

 Clear the interrupt flag after data read */

/*

 * Available Ambient Light Sensor gain settings, 1/1000th, and

 * corresponding setting for the VL6180_ALS_GAIN register

 one ALS count is 0.32 Lux @ gain 1, IT 100 ms */

 0.32 * 1000 * 100 */

 sensor reports mm, scale to meter */

 HOLD is needed before updating any config registers */

 round to ms */

	/*

	 * Detect false reset condition here. This bit is always set when the

	 * system comes out of reset.

 Enable ALS and Range ready interrupts */

 ALS integration time: 100ms */

 ALS gain: 1 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * apds9300.c - IIO driver for Avago APDS9300 ambient light sensor

 *

 * Copyright 2013 Oleksandr Kravchenko <o.v.kravchenko@globallogic.com>

 Command register bits */

 Select command register. Must write as 1 */

 I2C write/read: if 1 word, if 0 byte */

 Interrupt clear. Clears pending interrupt */

 Register set */

 Control of basic functions */

 Low byte of low interrupt threshold */

 Low byte of high interrupt threshold */

 Interrupt control */

 Low byte of ADC channel 0 */

 Low byte of ADC channel 1 */

 Power on/off value for APDS9300_CONTROL register */

 Interrupts */

 Interrupt Persist Function: Any value outside of threshold range */

 Max threshold value */

 Lux calculation */

 Calculated values 1000 * (CH1/CH0)^1.4 for CH1/CH0 from 0 to 0.52 */

 avoid division by zero */

 Select ADC0 or ADC1 data register */

 Need to set power off to ensure that the chip is off */

	/*

	 * Probe the chip. To do so we try to power up the device and then to

	 * read back the 0x03 code

	/*

	 * Disable interrupt to ensure thai it is doesn't enable

	 * i.e. after device soft reset

 Ensure that power off in case of error */

 Ensure that power off and interrupts are disabled */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Intel Corporation

 *

 * Driver for TXC PA12203001 Proximity and Ambient Light Sensor.

 *

 * To do: Interrupt support.

 als range 31000, ps, als disabled */

 led current: 100 mA */

 ps mode: normal, interrupts not active */

 available scales: corresponding to [500, 4000, 7000, 31000]  lux */

 protect device states */

			/*

			 * ALS ADC value is stored in registers

			 * PA12203001_REG_ADL and in PA12203001_REG_ADL + 1.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Intel Corporation

 *

 * Driver for UPISEMI us5182d Proximity and Ambient Light Sensor.

 *

 * To do: Interrupt support.

/*

 * Registers for tuning the auto dark current cancelling feature.

 * DARK_TH(reg 0x27,0x28) - threshold (counts) for auto dark cancelling.

 * when ALS  > DARK_TH --> ALS_Code = ALS - Upper(0x2A) * Dark

 * when ALS < DARK_TH --> ALS_Code = ALS - Lower(0x29) * Dark

 Thresholds for events: px low (0x08-l, 0x09-h), px high (0x0a-l 0x0b-h) */

 ms */

 ms */

 Available ranges: [12354, 7065, 3998, 2202, 1285, 498, 256, 138] lux */

/*

 * Experimental thresholds that work with US5182D sensor on evaluation board

 * roughly between 12-32 lux

 Glass attenuation factor */

 Dark gain tuning */

	/*

	 * In oneshot mode the chip will power itself down after taking the

	 * required measurement.

 update mode */

	/*

	 * After updating the operating mode, the chip requires that

	 * the operation is stored, by writing 1 in the STORE_MODE

	 * register (auto-clearing).

/**

 * us5182d_update_dark_th - update Darh_Th registers

 * @data:	us5182d_data structure

 * @index:	index in us5182d_dark_ths array to use for the updated value

 *

 * Function needs to be called with a lock held because it needs two i2c write

 * byte operations as these registers (0x27 0x28) don't work in word mode

 * accessing.

/**

 * us5182d_apply_scale - update the ALS scale

 * @data:	us5182d_data structure

 * @index:	index in us5182d_scales array to use for the updated value

 *

 * Function needs to be called with a lock held as we're having more than one

 * i2c operation.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * opt3001.c - Texas Instruments OPT3001 Light Sensor

 *

 * Copyright (C) 2014 Texas Instruments Incorporated - https://www.ti.com

 *

 * Author: Andreas Dannenberg <dannenberg@ti.com>

 * Based on previous work from: Felipe Balbi <balbi@ti.com>

 also 3 << 9 */

 The end-of-conversion enable is located in the low-limit register */

/*

 * Time to wait for conversion result to be ready. The device datasheet

 * sect. 6.5 states results are ready after total integration time plus 3ms.

 * This results in worst-case max values of 113ms or 883ms, respectively.

 * Add some slack to be on the safe side.

		/*

		 * Combine the integer and micro parts for comparison

		 * purposes. Use milli lux precision to avoid 32-bit integer

		 * overflows.

		/*

		 * Enable the end-of-conversion interrupt mechanism. Note that

		 * doing so will overwrite the low-level limit value however we

		 * will restore this value later on.

 Allow IRQ to access the device despite lock being set */

 Reset data-ready indicator flag */

 Configure for single-conversion mode and start a new conversion */

 Wait for the IRQ to indicate the conversion is complete */

 Sleep for result ready time */

 Check result ready flag */

 Obtain value */

 Disallow IRQ to access the device while lock is active */

		/*

		 * Disable the end-of-conversion interrupt mechanism by

		 * restoring the low-level limit value (clearing

		 * OPT3001_LOW_LIMIT_EOC_ENABLE). Note that selectively clearing

		 * those enable bits would affect the actual limit value due to

		 * bit-overlap and therefore can't be done.

 Enable automatic full-scale setting mode */

 Reflect status of the device's integration time setting */

 Ensure device is in shutdown initially */

 Configure for latched window-style comparison operation */

 Make use of INT pin only if valid IRQ no. is given */

 Terminating Entry */

 SPDX-License-Identifier: GPL-2.0+

/*

 * si1133.c - Support for Silabs SI1133 combined ambient

 * light and UV index sensors

 *

 * Copyright 2018 Maxime Roussin-Belanger <maxime.roussinbelanger@gmail.com>

 A.K.A. HW_GAIN in datasheet */

 Integration time in milliseconds, nanoseconds */

 Lock protecting one command at a time can be processed */

/*

 * The algorithm is from:

 * https://siliconlabs.github.io/Gecko_SDK_Doc/efm32zg/html/si1133_8c_source.html#l00716

 wait for irq */

 channel list already set, no need to reprogram */

 mux already set to correct value */

 Deactivate lux measurements if they were active */

 Activate lux channels */

/*

 * si1133_init_lux_channels - Configure 3 different channels(adc) (1,2 and 3)

 * The channel configuration for the lux measurement was taken from :

 * https://siliconlabs.github.io/Gecko_SDK_Doc/efm32zg/html/si1133_8c_source.html#l00578

 *

 * Reserved the channel 0 for the other raw measurements

 Turn off autonomous mode */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Support for ON Semiconductor NOA1305 ambient light sensor

 *

 * Copyright (C) 2016 Emcraft Systems

 * Copyright (C) 2019 Collabora Ltd.

	/*

	 * Lux = count / (<Integration Constant> * <Integration Time>)

	 *

	 * Integration Constant = 7.7

	 * Integration Time in Seconds

 SPDX-License-Identifier: GPL-2.0-only

/*

 * vcnl4000.c - Support for Vishay VCNL4000/4010/4020/4040/4200 combined ambient

 * light and proximity sensor

 *

 * Copyright 2012 Peter Meerwald <pmeerw@pmeerw.net>

 * Copyright 2019 Pursim SPC

 * Copyright 2020 Mathieu Othacehe <m.othacehe@gmail.com>

 *

 * IIO driver for:

 *   VCNL4000/10/20 (7-bit I2C slave address 0x13)

 *   VCNL4040 (7-bit I2C slave address 0x60)

 *   VCNL4200 (7-bit I2C slave address 0x51)

 *

 * TODO:

 *   allow to adjust IR current

 *   interrupts (VCNL4040, VCNL4200)

 for VCNL4020, VCNL4010 */

 Command register */

 Product ID and Revision ID */

 Proximity rate */

 IR LED current for proximity mode */

 Ambient light parameter register */

 ALS rate */

 Ambient light result register, MSB */

 Ambient light result register, LSB */

 Proximity result register, MSB */

 Proximity result register, LSB */

 Proximity test signal frequency */

 Interrupt control */

 Proximity modulator timing adjustment */

 Low threshold, MSB */

 Low threshold, LSB */

 High threshold, MSB */

 High threshold, LSB */

 Interrupt status */

 Ambient light configuration */

 Proximity configuration */

 Proximity data */

 Ambient light data */

 Device ID, slave address and version */

 Device ID and version */

 Bit masks for COMMAND register */

 ALS data ready? */

 proximity data ready? */

 start on-demand ALS measurement */

 start on-demand proximity measurement */

 start ALS measurement */

 start proximity measurement */

 start self-timed measurement */

 Bit masks for interrupt registers. */

 Select threshold interrupt source */

 Threshold interrupt type */

 Enable on ALS data ready */

 Enable on proximity data ready */

 High threshold exceeded */

 Low threshold exceeded */

 ALS data ready */

 Proximity data ready */

 before we enter pm_runtime_suspend */

 no suspend op */

 power on */ : 1 
 Wait at least one integration cycle before fetching data */

 Default wait time is 50ms, add 20% tolerance. */

 Default wait time is 4.8ms, add 20% tolerance. */

 Default wait time is 80ms, add 20% tolerance. */

 Default wait time is 5ms, add 20% tolerance. */

 wait for data to become ready */

 measurement takes up to 100 ms */

 Protect against event capture. */

 Protect against event capture. */

 Enable periodic measurement of proximity data. */

		/*

		 * Enable interrupts on threshold, for proximity data by

		 * default.

 sentinel */ }

 1x16-bit + naturally aligned ts */

 Do not enable the buffer if we are already capturing events. */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Azoteq IQS621/622 Ambient Light Sensors

 *

 * Copyright (C) 2019 Jeff LaBundy <jeff@labundy.com>

 IQS621 only */

 IQS621 and IQS622 */

 IQS622 only */

		/*

		 * The IQS622 supports two detection thresholds, both measured

		 * in the same arbitrary units reported by read_raw: proximity

		 * (0 through 255 in steps of 1), and touch (0 through 1020 in

		 * steps of 4).

		 *

		 * Based on the single detection threshold chosen by the user,

		 * select the hardware threshold that gives the best trade-off

		 * between range and resolution.

		 *

		 * By default, the close-range (but coarse) touch threshold is

		 * chosen during probe.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AL3320A - Dyna Image Ambient Light Sensor

 *

 * Copyright (c) 2014, Intel Corporation.

 *

 * IIO driver for AL3320A (7-bit I2C slave address 0x1C).

 *

 * TODO: interrupt support, thresholds

 * When the driver will get support for interrupt handling, then interrupt

 * will need to be disabled before turning sensor OFF in order to avoid

 * potential races with the interrupt handling.

 chip params default values */

 no waiting */

 33.28 Klx */

 8.32 Klx  */

 2.08 Klx  */

 0.65 Klx  */

		/*

		 * ALS ADC value is stored in two adjacent registers:

		 * - low byte of output is stored at AL3320A_REG_DATA_LOW

		 * - high byte of output is stored at AL3320A_REG_DATA_LOW + 1

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * A iio driver for the light sensor ISL 29018/29023/29035.

 *

 * IIO driver for monitoring ambient light intensity in luxi, proximity

 * sensing and infrared sensing.

 *

 * Copyright (c) 2010, NVIDIA Corporation.

 Keep the same range when integration time changes */

 Set mode */

 Do proximity sensing with required scheme */

/*

 * From ISL29018 Data Sheet (FN6619.4, Oct 8, 2012) regarding the

 * infrared suppression:

 *

 *   Proximity Sensing Scheme: Bit 7. This bit programs the function

 * of the proximity detection. Logic 0 of this bit, Scheme 0, makes

 * full n (4, 8, 12, 16) bits (unsigned) proximity detection. The range

 * of Scheme 0 proximity count is from 0 to 2^n. Logic 1 of this bit,

 * Scheme 1, makes n-1 (3, 7, 11, 15) bits (2's complementary)

 * proximity_less_ambient detection. The range of Scheme 1

 * proximity count is from -2^(n-1) to 2^(n-1) . The sign bit is extended

 * for resolutions less than 16. While Scheme 0 has wider dynamic

 * range, Scheme 1 proximity detection is less affected by the

 * ambient IR noise variation.

 *

 * 0 Sensing IR from LED and ambient

 * 1 Sensing IR from LED with ambient IR rejection

	/*

	 * Return the "proximity scheme" i.e. if the chip does on chip

	 * infrared suppression (1 means perform on chip suppression)

	/*

	 * Get the "proximity scheme" i.e. if the chip does on chip

	 * infrared suppression (1 means perform on chip suppression)

 Clear brownout bit */

	/*

	 * Code added per Intersil Application Note 1534:

	 *     When VDD sinks to approximately 1.8V or below, some of

	 * the part's registers may change their state. When VDD

	 * recovers to 2.25V (or greater), the part may thus be in an

	 * unknown mode of operation. The user can return the part to

	 * a known mode of operation either by (a) setting VDD = 0V for

	 * 1 second or more and then powering back up with a slew rate

	 * of 0.5V/ms or greater, or (b) via I2C disable all ALS/PROX

	 * conversions, clear the test registers, and then rewrite all

	 * registers to the desired values.

	 * ...

	 * For ISL29011, ISL29018, ISL29021, ISL29023

	 * 1. Write 0x00 to register 0x08 (TEST)

	 * 2. Write 0x00 to register 0x00 (CMD1)

	 * 3. Rewrite all registers to the desired values

	 *

	 * ISL29018 Data Sheet (FN6619.1, Feb 11, 2010) essentially says

	 * the same thing EXCEPT the data sheet asks for a 1ms delay after

	 * writing the CMD1 register.

	/*

	 * See Intersil AN1534 comments above.

	 * "Operating Mode" (COMMAND1) register is reprogrammed when

	 * data is read from the device.

 per data sheet, page 10 */

 Set defaults */

	/*

	 * Since this driver uses only polling commands, we are by default in

	 * auto shutdown (ie, power-down) mode.

	 * So we do not have much to do here.

 SPDX-License-Identifier: GPL-2.0+

/*

 * adux1020.c - Support for Analog Devices ADUX1020 photometric sensor

 *

 * Copyright (C) 2019 Linaro Ltd.

 * Author: Manivannan Sadhasivam <manivannan.sadhasivam@linaro.org>

 *

 * TODO: Triggered buffer support

 System registers */

 Chip ID bits */

 Operating modes */

 Force Idle mode */

 Flush FIFO */

 Enable 32MHz clock */

 Set 32MHz clock to be controlled by internal state machine */

 Switch to standby mode before changing the mode */

 Set data out and switch to the desired mode */

 Disable INT pin as polling is going to be used */

 Enable mode interrupt */

 Clear mode interrupt */

 Disable mode interrupts */

		/*

		 * Trigger proximity interrupt when the intensity is above

		 * or below threshold

 Set proximity mode */

 Full scale threshold value is 0-65535  */

 Load default configuration */

 Use LED_IREF for proximity mode */

 Mask all interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 * ROHM BH1710/BH1715/BH1721/BH1750/BH1751 ambient light sensor driver

 *

 * Copyright (c) Tomasz Duszynski <tduszyns@gmail.com>

 *

 * Data sheets:

 *  http://rohmfs.rohm.com/en/products/databook/datasheet/ic/sensor/light/bh1710fvc-e.pdf

 *  http://rohmfs.rohm.com/en/products/databook/datasheet/ic/sensor/light/bh1715fvc-e.pdf

 *  http://rohmfs.rohm.com/en/products/databook/datasheet/ic/sensor/light/bh1721fvc-e.pdf

 *  http://rohmfs.rohm.com/en/products/databook/datasheet/ic/sensor/light/bh1750fvi-e.pdf

 *  http://rohmfs.rohm.com/en/products/databook/datasheet/ic/sensor/light/bh1751fvi-e.pdf

 *

 * 7-bit I2C slave addresses:

 *  0x23 (ADDR pin low)

 *  0x5C (ADDR pin high)

 *

 auto-mode for BH1721 */

	/*

	 * For BH1710/BH1721 all possible integration time values won't fit

	 * into one page so displaying is limited to every second one.

	 * Note, that user can still write proper values which were not

	 * listed.

	/*

	 * BH1721 will enter continuous mode on receiving this command.

	 * Note, that this eliminates need for bh1750_resume().

	/*

	 * This is mainly for BH1721 which doesn't enter power down

	 * mode automatically.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ACPI Ambient Light Sensor Driver

 *

 * Based on ALS driver:

 * Copyright (C) 2009 Zhang Rui <rui.zhang@intel.com>

 *

 * Rework for IIO subsystem:

 * Copyright (C) 2012-2013 Martin Liska <marxin.liska@gmail.com>

 *

 * Final cleanup and debugging:

 * Copyright (C) 2013-2014 Marek Vasut <marex@denx.de>

 * Copyright (C) 2015 Gabriele Mazzotta <gabriele.mzt@gmail.com>

/*

 * So far, there's only one channel in here, but the specification for

 * ACPI0008 says there can be more to what the block can report. Like

 * chromaticity and such. We are ready for incoming additions!

 _RAW is here for backward ABI compatibility */

/*

 * The event buffer contains timestamp and all the data from

 * the ACPI0008 block. There are multiple, but so far we only

 * support _ALI (illuminance): One channel, padding and timestamp.

/*

 * All types of properties the ACPI0008 block can report. The ALI, ALC, ALT

 * and ALP can all be handled by acpi_als_read_value() below, while the ALR is

 * special.

 *

 * The _ALR property returns tables that can be used to fine-tune the values

 * reported by the other props based on the particular hardware type and it's

 * location (it contains tables for "rainy", "bright inhouse lighting" etc.).

 *

 * So far, we support only ALI (illuminance).

 Unhandled event */

 we support only illumination (_ALI) so far. */

	/*

	 * When coming from own trigger via polls, set polling function

	 * timestamp here. Given ACPI notifier is already in a thread and call

	 * function directly, there is no need to set the timestamp in the

	 * notify function.

	 *

	 * If the timestamp was actually 0, the timestamp is set one more time.

	/*

	 * Set hardware trigger by default to let events flow when

	 * BIOS support notification.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AL3010 - Dyna Image Ambient Light Sensor

 *

 * Copyright (c) 2014, Intel Corporation.

 * Copyright (c) 2016, Dyna-Image Corp.

 * Copyright (c) 2020, David Heidelberg, Micha Mirosaw, Dmitry Osipenko

 *

 * IIO driver for AL3010 (7-bit I2C slave address 0x1C).

 *

 * TODO: interrupt support, thresholds

 * When the driver will get support for interrupt handling, then interrupt

 * will need to be disabled before turning sensor OFF in order to avoid

 * potential races with the interrupt handling.

 77806 lx */

 19542 lx */

  4863 lx */

  1216 lx */

		/*

		 * ALS ADC value is stored in two adjacent registers:

		 * - low byte of output is stored at AL3010_REG_DATA_LOW

		 * - high byte of output is stored at AL3010_REG_DATA_LOW + 1

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CM3232 Ambient Light Sensor

 *

 * Copyright (C) 2014-2015 Capella Microsystems Inc.

 * Author: Kevin Tsai <ktsai@capellamicro.com>

 *

 * IIO driver for CM3232 (7-bit I2C slave address 0x10).

 Registers Address */

 0.100000 */

 0.200000 */

 0.400000 */

 0.800000 */

 1.600000 */

 3.200000 */

/**

 * cm3232_reg_init() - Initialize CM3232

 * @chip:	pointer of struct cm3232_chip.

 *

 * Check and initialize CM3232 ambient light sensor.

 *

 * Return: 0 for success; otherwise for error code.

 Identify device */

 Disable and reset device */

 Register default value */

 Configure register */

/**

 *  cm3232_read_als_it() - Get sensor integration time

 *  @chip:	pointer of struct cm3232_chip

 *  @val:	pointer of int to load the integration (sec).

 *  @val2:	pointer of int to load the integration time (microsecond).

 *

 *  Report the current integration time.

 *

 *  Return: IIO_VAL_INT_PLUS_MICRO for success, otherwise -EINVAL.

/**

 * cm3232_write_als_it() - Write sensor integration time

 * @chip:	pointer of struct cm3232_chip.

 * @val:	integration time in second.

 * @val2:	integration time in microsecond.

 *

 * Convert integration time to sensor value.

 *

 * Return: i2c_smbus_write_byte_data command return value.

/**

 * cm3232_get_lux() - report current lux value

 * @chip:	pointer of struct cm3232_chip.

 *

 * Convert sensor data to lux.  It depends on integration

 * time and calibscale variable.

 *

 * Return: Zero or positive value is lux, otherwise error code.

 Calculate mlux per bit based on als_it */

/**

 * cm3232_get_it_available() - Get available ALS IT value

 * @dev:	pointer of struct device.

 * @attr:	pointer of struct device_attribute.

 * @buf:	pointer of return string buffer.

 *

 * Display the available integration time in second.

 *

 * Return: string length.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * lm3533-als.c -- LM3533 Ambient Light Sensor driver

 *

 * Copyright (C) 2011-2012 Texas Instruments

 *

 * Author: Johan Hovold <jhovold@gmail.com>

/*

 * channel	output channel 0..2

 * zone		zone 0..4

 Clear interrupt by reading the ALS zone register. */

	/*

	 * This device does not allow negative hysteresis (in fact, it uses

	 * whichever value is smaller as the lower bound) so we need to make

	 * sure that thresh_falling <= thresh_raising.

/*

 * ALS output current values (ALS mapper targets)

 *

 * out_current[0-2]_current[0-4]_raw		0-255

/*

 * ALS Zone thresholds (boundaries)

 *

 * in_illuminance0_thresh[0-3]_falling_value	0-255

 * in_illuminance0_thresh[0-3]_raising_value	0-255

/*

 * ALS Zone threshold hysteresis

 *

 * threshY_hysteresis = threshY_raising - threshY_falling

 *

 * in_illuminance0_thresh[0-3]_hysteresis	0-255

 * in_illuminance0_thresh[0-3]_hysteresis	0-255

/*

 * ALS Zone threshold-event enable

 *

 * in_illuminance0_thresh_either_en		0,1

/*

 * ALS Current Zone

 *

 * in_illuminance0_zone		0-4

 pwm input */

 analog input */

 ALS input is always high impedance in PWM-mode. */

 Make sure interrupts are disabled. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * isl29125.c - Support for Intersil ISL29125 RGB light sensor

 *

 * Copyright (c) 2014 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * RGB light sensor with 16-bit channels for red, green, blue);

 * 7-bit I2C slave address 0x44

 *

 * TODO: interrupt support, IR compensation, thresholds, 12bit

 375 lux full range */

 10k lux full range */

 Ensure timestamp is naturally aligned */

10k lux full range*/

375 lux full range*/

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2021 Joe Sandom <joe.g.sandom@gmail.com>

 *

 * Datasheet: https://ams.com/tsl25911#tab/documents

 *

 * Device driver for the TAOS TSL2591. This is a very-high sensitivity

 * light-to-digital converter that transforms light intensity into a digital

 * signal.

 ADC integration time, field value to time in ms */

 ADC integration time, field value to time in seconds */

 ADC integration time, time in seconds to field value */

 TSL2591 register set */

 TSL2591 command register definitions */

 TSL2591 enable register definitions */

 TSL2591 control register definitions */

 TSL2591 persist register definitions */

 TSL2591 PID register mask */

 TSL2591 ID register mask */

 TSL2591 status register masks */

 TSL2591 constant values */

 Power off suspend delay time MS */

 TSL2591 default values */

 TSL2591 number of data registers */

 TSL2591 number of valid status reads on ADC complete */

 TSL2591 delay period between polls when checking for ALS valid flag */

 TSL2591 maximum values */

/*

 * LUX calculations;

 * AGAIN values from Adafruit's TSL2591 Arduino library

 * https://github.com/adafruit/Adafruit_TSL2591_Library

	/*

	 * Keep als_settings in sync with hardware state

	 * and ensure multiple readers are serialized.

/*

 * Period table is ALS persist cycle x integration time setting

 * Integration times: 100ms, 200ms, 300ms, 400ms, 500ms, 600ms

 * ALS cycles: 1, 2, 3, 5, 10, 20, 25, 30, 35, 40, 45, 50, 55, 60

	/*

	 * Sleep for ALS integration time to allow enough time or an ADC read

	 * cycle to complete. Check status after delay for ALS valid.

 Check for status ALS valid flag for up to 100ms */

/*

 * tsl2591_read_channel_data - Reads raw channel data and calculates lux

 *

 * Formula for lux calculation;

 * Derived from Adafruit's TSL2591 library

 * Link: https://github.com/adafruit/Adafruit_TSL2591_Library

 * Counts Per Lux (CPL) = (ATIME_ms * AGAIN) / LUX DF

 * lux = ((C0DATA - C1DATA) * (1 - (C1DATA / C0DATA))) / CPL

 *

 * Scale values to get more representative value of lux i.e.

 * lux = ((C0DATA - C1DATA) * (1000 - ((C1DATA * 1000) / C0DATA))) / CPL

 *

 * Channel 0 = IR + Visible

 * Channel 1 = IR only

 Calculate counts per lux value */

 Calculate lux value */

 Divide by 1000 to get real lux value before scaling */

 Get the decimal part of lux reading */

	/*

	 * Lower threshold should not be greater or equal to upper.

	 * If this is the case, then assert upper threshold to new lower

	 * threshold + 1 to avoid ordering issues when setting thresholds.

	/*

	 * Upper threshold should not be less than lower. If this

	 * is the case, then assert lower threshold to new upper

	 * threshold - 1 to avoid ordering issues when setting thresholds.

 Clear ALS irq */

	/*

	 * Add chip off to automatically managed path and disable runtime

	 * power management. This ensures that the chip power management

	 * is handled correctly on driver remove. tsl2591_chip_off() must be

	 * added to the managed path after pm runtime is enabled and before

	 * any error exit paths are met to ensure we're not left in a state

	 * of pm runtime not being disabled properly.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Sensortek STK3310/STK3311 Ambient Light and Proximity Sensor

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * IIO driver for STK3310/STK3311. 7-bit I2C address: 0x48.

 Estimate maximum proximity values with regard to measurement scale. */

 Integration time in seconds, microseconds */

 Proximity event */

 Out-of-proximity event */

 Only proximity interrupts are implemented at the moment. */

 Set INT_PS value */

 3-bit state; 0b100 is not supported. */

 Don't reset the 'enabled' flags if we're going in standby */

 Enable PS interrupts */

 Read FLAG_NF to figure out what threshold has been met. */

 Reset the interrupt flag */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * These are the two Sharp GP2AP002 variants supported by this driver:

 * GP2AP002A00F Ambient Light and Proximity Sensor

 * GP2AP002S00F Proximity Sensor

 *

 * Copyright (C) 2020 Linaro Ltd.

 * Author: Linus Walleij <linus.walleij@linaro.org>

 *

 * Based partly on the code in Sony Ericssons GP2AP00200F driver by

 * Courtney Cavin and Oskar Andero in drivers/input/misc/gp2ap002a00f.c

 * Based partly on a Samsung misc driver submitted by

 * Donggeun Kim & Minkyu Kang in 2011:

 * https://lore.kernel.org/lkml/1315556546-7445-1-git-send-email-dg77.kim@samsung.com/

 * Based partly on a submission by

 * Jonathan Bakker and Pawe Chmiel in january 2019:

 * https://lore.kernel.org/linux-input/20190125175045.22576-1-pawel.mikolaj.chmiel@gmail.com/

 * Based partly on code from the Samsung GT-S7710 by <mjchen@sta.samsung.com>

 * Based partly on the code in LG Electronics GP2AP00200F driver by

 * Kenobi Lee <sungyoung.lee@lge.com> and EunYoung Cho <ey.cho@lge.com>

 To get our ADC channel */

 To deal with our ADC channel */

 ------------------------------------------------------------------------ */

 ADDRESS SYMBOL             DATA                                 Init R/W */

                   D7    D6    D5    D4    D3    D2    D1    D0           */

 ------------------------------------------------------------------------ */

    0      PROX     X     X     X     X     X     X     X    VO  H'00   R */

    1      GAIN     X     X     X     X  LED0     X     X     X  H'00   W */

    2       HYS  HYSD HYSC1 HYSC0     X HYSF3 HYSF2 HYSF1 HYSF0  H'00   W */

    3     CYCLE     X     X CYCL2 CYCL1 CYCL0  OSC2     X     X  H'00   W */

    4     OPMOD     X     X     X   ASD     X     X  VCON   SSD  H'00   W */

    6       CON     X     X     X OCON1 OCON0     X     X     X  H'00   W */

 ------------------------------------------------------------------------ */

 VO   :Proximity sensing result(0: no detection, 1: detection)            */

 LED0 :Select switch for LED driver's On-registence(0:2x higher, 1:normal)*/

 HYSD/HYSF :Adjusts the receiver sensitivity                              */

 OSC  :Select switch internal clocl frequency hoppling(0:effective)       */

 CYCL :Determine the detection cycle(typically 8ms, up to 128x)           */

 SSD  :Software Shutdown function(0:shutdown, 1:operating)                */

 VCON :VOUT output method control(0:normal, 1:interrupt)                  */

 ASD  :Select switch for analog sleep function(0:ineffective, 1:effective)*/

 OCON :Select switch for enabling/disabling VOUT (00:enable, 11:disable)  */

 Setting this bit to 0 means 2x higher LED resistance */

/*

 * These bits adjusts the proximity sensitivity, determining characteristics

 * of the detection distance and its hysteresis.

/*

 * These values determine the detection cycle response time

 * 0: 8ms, 1: 16ms, 2: 32ms, 3: 64ms, 4: 128ms,

 * 5: 256ms, 6: 512ms, 7: 1024ms

/*

 * Select switch for internal clock frequency hopping

 *	0: effective,

 *	1: ineffective

 Analog sleep effective */

 Enable chip */

 IRQ mode */

/*

 * Select switch for enabling/disabling Vout pin

 * 0: enable

 * 2: force to go Low

 * 3: force to go High

/**

 * struct gp2ap002 - GP2AP002 state

 * @map: regmap pointer for the i2c regmap

 * @dev: pointer to parent device

 * @vdd: regulator controlling VDD

 * @vio: regulator controlling VIO

 * @alsout: IIO ADC channel to convert the ALSOUT signal

 * @hys_far: hysteresis control from device tree

 * @hys_close: hysteresis control from device tree

 * @is_gp2ap002s00f: this is the GP2AP002F variant of the chip

 * @irq: the IRQ line used by this device

 * @enabled: we cannot read the status of the hardware so we need to

 * keep track of whether the event is enabled using this state variable

 Close */

 Far */

	/*

	 * After changing hysteresis, we need to wait for one detection

	 * cycle to see if anything changed, or we will just trigger the

	 * previous interrupt again. A detection cycle depends on the CYCLE

	 * register, we are hard-coding ~8 ms in probe() so wait some more

	 * than this, 20-30 ms.

/*

 * This array maps current and lux.

 *

 * Ambient light sensing range is 3 to 55000 lux.

 *

 * This mapping is based on the following formula.

 * illuminance = 10 ^ (current[mA] / 10)

 *

 * When the ADC measures 0, return 0 lux.

 ensure we don't under/overflow */

 Set up the IR LED resistance */

 Disable internal frequency hopping */

 Enable chip and IRQ, disable analog sleep */

 Interrupt on VOUT enabled */

	/*

	 * We just keep track of this internally, as it is not possible to

	 * query the hardware.

		/*

		 * This will bring the regulators up (unless they are on

		 * already) and reintialize the sensor by using runtime_pm

		 * callbacks.

/*

 * We need a special regmap because this hardware expects to

 * write single bytes to registers but read a 16bit word on some

 * variants and discard the lower 8 bits so combine

 * i2c_smbus_read_word_data() with i2c_smbus_write_byte_data()

 * selectively like this.

	/*

	 * Check the device compatible like this makes it possible to use

	 * ACPI PRP0001 for registering the sensor using device tree

	 * properties.

	/*

	 * The hysteresis settings are coded into the device tree as values

	 * to be written into the hysteresis register. The datasheet defines

	 * modes "A", "B1" and "B2" with fixed values to be use but vendor

	 * code trees for actual devices are tweaking these values and refer to

	 * modes named things like "B1.5". To be able to support any devices,

	 * we allow passing an arbitrary hysteresis setting for "near" and

	 * "far".

 Check the device tree for the IR LED hysteresis */

 The GP2AP002A00F has a light sensor too */

 Operating voltage 2.4V .. 3.6V according to datasheet */

 VIO should be between 1.65V and VDD */

	/*

	 * Initialize the device and signal to runtime PM that now we are

	 * definitely up and using power.

	/*

	 * As the device takes 20 ms + regulator delay to come up with a fresh

	 * measurement after power-on, do not shut it down unnecessarily.

	 * Set autosuspend to a one second.

 Skip light channel for the proximity-only sensor */

 Deactivate the IRQ */

 Disable chip and IRQ, everything off */

	/*

	 * As these regulators may be shared, at least we are now in

	 * sleep even if the regulators aren't really turned off.

 Re-activate the IRQ */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * tsl4531.c - Support for TAOS TSL4531 ambient light sensor

 *

 * Copyright 2013 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * IIO driver for the TSL4531x family

 *   TSL45311/TSL45313: 7-bit I2C slave address 0x39

 *   TSL45315/TSL45317: 7-bit I2C slave address 0x29

 *

 * TODO: single cycle measurement

 operating modes in control register */

 integration time control in config register */

 part number in id register */

 0.. 1x, 1 .. 2x, 2 .. 4x */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * tcs3472.c - Support for TAOS TCS3472 color light-to-digital converter

 *

 * Copyright (c) 2013 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * Color light sensor with 16-bit channels for red, green, blue, clear);

 * 7-bit I2C slave address 0x39 (TCS34721, TCS34723) or 0x29 (TCS34725,

 * TCS34727)

 *

 * Datasheet: http://ams.com/eng/content/download/319364/1117183/file/TCS3472_Datasheet_EN_v2.pdf

 *

 * TODO: wait time

 Ensure timestamp is naturally aligned */

/*

 * Translation from APERS field value to the number of consecutive out-of-range

 * clear channel values before an interrupt is generated

 replace trailing space by newline */

 enable device */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * RPR-0521 ROHM Ambient Light and Proximity Sensor

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * IIO driver for RPR-0521RS (7-bit I2C slave address 0x38).

 *

 * TODO: illuminance channel

 16-bit, little endian */

 16-bit, little endian */

 16-bit, little endian */

 ALS - 100ms, PXS - 100ms */

 x1 */

 x2 */

 x64 */

 x128 */

 x1 */

 x2 */

 x4 */

	{ALS, PXS},		   W==currently writable option */

 W0000, 0=standby */

  0001 */

  0010 */

  0011 */

  0100 */

  0101 */

 W0110 */

  0111 */

  1000, measurement 100ms, sleep 300ms */

  1001, measurement 100ms, sleep 300ms */

  1010, high sensitivity mode */

 W1011, high sensitivity mode */

 1100, ALS_data x 0.5, see specification P.18 */

 protect device params updates (e.g state, gain) */

 device active status */

 optimize runtime pm ops - enable/disable device only if needed */

	/*

	 * Ensure correct naturally aligned timestamp.

	 * Note that the read will put garbage data into

	 * the padding but this should not be a problem

/*

 * Start with easy freq first, whole table of freq combinations is more

 * complicated.

 Order of the channel data in buffer */

/**

 * rpr0521_set_power_state - handles runtime PM state and sensors enabled status

 *

 * @data: rpr0521 device private data

 * @on: state to be set for devices in @device_mask

 * @device_mask: bitmask specifying for which device we need to update @on state

 *

 * Calls for this function must be balanced so that each ON should have matching

 * OFF. Otherwise pm usage_count gets out of sync.

	/*

	 * On: _resume() is called only when we are suspended

	 * Off: _suspend() is called after delay if _resume() is not

	 * called before that.

	 * Note: If either measurement is re-enabled before _suspend(),

	 * both stay enabled until _suspend().

 If _resume() was not called, enable measurement now. */

 Interrupt register tells if this sensor caused the interrupt or not. */

 Reg read failed. */

 Int not from this sensor. */

 IRQ to trigger handler */

	/*

	 * We need to wake the thread to read the interrupt reg. It

	 * is not possible to do that here because regmap_read takes a

	 * mutex.

 Other trigger polls store time here. */

 Use irq timestamp when reasonable. */

 Other chained trigger polls get timestamp only here. */

 3 * 16-bit + (discarded) int clear reg. */

 Interrupt after each measurement */

 Ignore latch and mode because of drdy */

 Don't care of clearing mode, assert and latch. */

/*

 * Trigger producer enable / disable. Note that there will be trigs only when

 * measurement data is ready to be read.

 get gain index */

	/*

	 * Ignore channel

	 * both pxs and als are setup only to same freq because of simplicity

 set default measurement time - 100 ms for both ALS and PS */

	/*

	 * Int pin keeps state after power off. Set pin to high impedance

	 * mode to prevent power drain.

	/*

	 * If sensor write/read is needed in _probe after _use_autosuspend,

	 * sensor needs to be _resumed first using rpr0521_set_power_state().

 IRQ to trigger setup */

 Trigger0 producer setup */

 Ties irq to trigger producer handler. */

		/*

		 * Now whole pipe from physical interrupt (irq defined by

		 * devicetree to device) to trigger0 output is set up.

 Trigger consumer setup */

 If measurements are enabled, enable them on resume */

 disable channels and sets {als,pxs}_dev_en to false */

wait for first measurement result

 SPDX-License-Identifier: GPL-2.0

/*

 * VCNL4035 Ambient Light and Proximity Sensor - 7-bit I2C slave address 0x60

 *

 * Copyright (c) 2018, DENX Software Engineering GmbH

 * Author: Parthiban Nallathambi <pn@denx.de>

 *

 * TODO: Proximity

 Device registers */

 Register masks */

 Default values */

 Triggered buffer */

 Ensure naturally aligned timestamp */

/*

 *	Device IT	INT Time (ms)	Scale (lux/step)

 *	000		50		0.064

 *	001		100		0.032

 *	010		200		0.016

 *	100		400		0.008

 *	101 - 111	800		0.004

 * Values are proportional, so ALS INT is selected for input due to

 * simplicity reason. Integration time value and scaling is

 * calculated based on device INT value

 *

 * Raw value needs to be scaled using ALS steps

 No direct ABI for persistence and threshold, so eventing */

 16 bit threshold range 0 - 65535 */

 allow only 1 2 4 8 as persistence value */

 ALS white channel enable */

 set default integration time - 100 ms for ALS */

 set default persistence time - 1 for ALS */

 set default HIGH threshold for ALS */

 set default LOW threshold for ALS */

 Trigger setup */

 IRQ to trigger mapping */

 wait for 1 ALS integration cycle */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2014, Intel Corporation.

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Real storage bits will change based on the report desc. */

 Maximum size of a sample to capture is u32 */

 Channel read_raw handler */

 Channel write_raw handler */

 Function to push data to buffer */

 Callback handler to send event after all samples are received and captured */

 Capture samples in local storage */

 Parse report which is specific to an usage id*/

 Function to initialize the processing for usage id */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * si1145.c - Support for Silabs SI1132 and SI1141/2/3/5/6/7 combined ambient

 * light, UV index and proximity sensors

 *

 * Copyright 2014-16 Peter Meerwald-Stadler <pmeerw@pmeerw.net>

 * Copyright 2016 Crestez Dan Leonard <leonard.crestez@intel.com>

 *

 * SI1132 (7-bit I2C slave address 0x60)

 * SI1141/2/3 (7-bit I2C slave address 0x5a)

 * SI1145/6/6 (7-bit I2C slave address 0x60)

 Helper to figure out PS_LED register / shift per channel */

 Parameter offsets */

 Channel enable masks for CHLIST parameter */

 Proximity measurement mode for ADC_MISC parameter */

 Signal range mask for ADC_MISC parameter */

 Commands for REG_COMMAND */

 Minimum sleep after each command to ensure it's received */

 Return -ETIMEDOUT after this long */

 Interrupt configuration masks for INT_CFG register */

 enable interrupt */

 auto reset interrupt pin */

 Interrupt enable masks for IRQ_ENABLE register */

 Proximity LED current; see Table 2 in datasheet */

/**

 * struct si1145_data - si1145 chip state data

 * @client:	I2C client

 * @lock:	mutex to protect shared state.

 * @cmdlock:	Low-level mutex to protect command execution only

 * @rsp_seq:	Next expected response number or -1 if counter reset required

 * @scan_mask:	Saved scan mask to avoid duplicate set_chlist

 * @autonomous: If automatic measurements are active (for buffer support)

 * @part_info:	Part information

 * @trig:	Pointer to iio trigger

 * @meas_rate:	Value of MEAS_RATE register. Only set in HW in auto mode

 * @buffer:	Used to pack data read from sensor.

	/*

	 * Ensure timestamp will be naturally aligned if present.

	 * Maximum buffer size (may be only partly used if not all

	 * channels are enabled):

	 *   6*2 bytes channels data + 4 bytes alignment +

	 *   8 bytes timestamp

/*

 * __si1145_command_reset() - Send CMD_NOP and wait for response 0

 *

 * Does not modify data->rsp_seq

 *

 * Return: 0 on success and -errno on error.

/*

 * si1145_command() - Execute a command and poll the response register

 *

 * All conversion overflows are reported as -EOVERFLOW

 * INVALID_SETTING is reported as -EINVAL

 * Timeouts are reported as -ETIMEDOUT

 *

 * Return: 0 on success or -errno on failure

 Sleep a little to ensure the command is received */

 All overflows are treated identically */

 Force a counter reset next time */

 Set param. Returns negative errno or current value */

 Expand 8 bit compressed value to 16 bit, see Silabs AN498 */

 Compress 16 bit value to 8 bit, see Silabs AN498 */

 Write meas_rate in hardware */

 Set the samp freq in driver private data */

 channel list already set, no need to reprogram */

/*

 * Conversion between iio scale and ADC_GAIN values

 * These could be further adjusted but proximity/intensity are dimensionless

			/*

			 * -ADC offset - ADC counts @ 25C -

			 *   35 * ADC counts / C

			/*

			 * All ADC measurements have are by default offset

			 * by -256

			 * See AN498 5.6.3

 Set recovery period to one's complement of gain */

 Hardware key, magic value */

 Turn off autonomous mode */

 Initialize sampling freq to 10 Hz */

 Set LED currents to 45 mA; have 4 bits, see Table 2 in datasheet */

 Set normal proximity measurement mode */

 ADC_COUNTER should be one complement of ADC_GAIN */

 Set ALS visible measurement mode */

 Set ALS IR measurement mode */

	/*

	 * Initialize UCOEF to default values in datasheet

	 * These registers are normally zero on reset

/*

 * Program the channels we want to measure with CMD_PSALS_AUTO. No need for

 * _postdisable as we stop with CMD_PSALS_PAUSE; single measurement (direct)

 * mode reprograms the channels list anyway...

 Check that at most one AUX channel is enabled */

/*

 * si1145_trigger_set_state() - Set trigger state

 *

 * When not using triggers interrupts are disabled and measurement rate is

 * set to zero in order to minimize power consumption.

 Disable as much as possible skipping errors */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2012, Intel Corporation.

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Real storage bits will change based on the report desc. */

 Maximum size of a sample to capture is u32 */

 Channel read_raw handler */

 Channel write_raw handler */

 Callback handler to send event after all samples are received and captured */

 Capture samples in local storage */

 Parse report which is specific to an usage id*/

 Function to initialize the processing for usage id */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MAX44000 Ambient and Infrared Proximity Sensor

 *

 * Copyright (c) 2016, Intel Corporation.

 *

 * Data sheet: https://datasheets.maximintegrated.com/en/ds/MAX44000.pdf

 *

 * 7-bit I2C slave address 0x4a

 Registers in datasheet order */

 REG_CFG bits */

/*

 * Upper 4 bits are not documented but start as 1 on powerup

 * Setting them to 0 causes proximity to misbehave so set them to 1

 REG_RX bits */

 REG_TX bits */

 Ensure naturally aligned timestamp */

 Default scale is set to the minimum of 0.03125 or 1 / (1 << 5) lux */

 Scale can be multiplied by up to 128x via ALSPGA for measurement gain */

/*

 * Scale can be multiplied by up to 64x via ALSTIM because of lost resolution

 *

 * This scaling factor is hidden from userspace and instead accounted for when

 * reading raw values from the device.

 *

 * This makes it possible to cleanly expose ALSPGA as IIO_CHAN_INFO_SCALE and

 * ALSTIM as IIO_CHAN_INFO_INT_TIME without the values affecting each other.

 *

 * Handling this internally is also required for buffer support because the

 * channel's scan_type can't be modified dynamically.

 Available integration times with pretty manual alignment: */

 Available scales (internal to ulux) with pretty manual alignment: */

	/*

	 * Overflow is explained on datasheet page 17.

	 *

	 * It's a warning that either the G or IR channel has become saturated

	 * and that the value in the register is likely incorrect.

	 *

	 * The recommendation is to change the scale (ALSPGA).

	 * The driver just returns the max representable value.

 Maybe we should clamp the value instead? */

 Output register is in 10s of miliamps */

 Avoid negative shifts */

	/*

	 * The device doesn't have a reset function so we just clear some

	 * important bits at probe time to ensure sane operation.

	 *

	 * Since we don't support interrupts/events the threshold values are

	 * not important. We also don't touch trim values.

 Reset ALS scaling bits */

	/*

	 * By default the LED pulse used for the proximity sensor is disabled.

	 * Set a middle value so that we get some sort of valid data by default.

 Reset CFG bits to ALS_PRX mode which allows easy reading of both values. */

 Read status at least once to clear any stale interrupt bits. */

 SPDX-License-Identifier: GPL-2.0+

/*

 * apds9960.c - Support for Avago APDS9960 gesture/RGB/ALS/proximity sensor

 *

 * Copyright (C) 2015, 2018

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 *

 * TODO: gesture + proximity calib offsets

 regmap fields */

 state */

 gain values */

 integration time value in us */

 gesture buffer */

 4 8-bit channels */

 Default ALS integration time = 2.48ms */

 Gesture Sensor */

 ALS */

 RGB Sensor */

 integration time in us */

 gain mapping */

 pxs + gesture gains are mirrored */

 Allow one integration cycle before allowing a reading */

 RGB + ALS sensors only have integration time */

 RGB + ALS sensors only have int time */

 Default IT for ALS of 28 ms */

 Ensure gesture interrupt is OFF */

 Disable gesture sensor, since polling is useless from user-space */

 Ensure proximity interrupt is OFF */

 Enable proximity sensor for polling */

 Ensure ALS interrupt is OFF */

 Enable ALS sensor for polling */

	/*

	 * When enabled trigger an interrupt after 3 readings

	 * outside threshold for ALS + PXS

	/*

	 * Wait for 4 event outside gesture threshold to prevent interrupt

	 * flooding.

 Default ENTER and EXIT thresholds for the GESTURE engine. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 Samsung Electronics Co., Ltd.

 * Author: Beomho Seo <beomho.seo@samsung.com>

 Slave address 0x19 for PS of 7 bit addressing protocol for I2C */

 Alert Response Address */

 Ambient light sensor */

 Proximity sensor */

 CS_CONF1 command code */

 CS_CONF2 command code */

 CS_CONF3 channel integration time */

 Integration time 80 msec */

 Integration time 160 msec */

 Integration time 320 msec */

 Integration time 640 msec */

 PS_CONF1 command code */

 PS_CONF1 command code: integration time */

 Integration time 0.32 msec */

 Integration time 0.42 msec */

 Integration time 0.52 msec */

 Integration time 0.64 msec */

 PS_CONF1 command code: duty ratio */

 Duty ratio 1/80 */

 Duty ratio 1/160 */

 Duty ratio 1/320 */

 Duty ratio 1/640 */

 PS_THD command code */

 PS_CANC command code */

 PS_CONF2 command code */

 CS initialization */

 PS initialization */

 Set shutdown mode */

	/*

	 * The PS INT pin is an active low signal that PS INT move logic low

	 * when the object is detect. Once the MCU host received the PS INT

	 * "LOW" signal, the Host needs to read the data at Alert Response

	 * Address(ARA) to clear the PS INT signal. After clearing the PS

	 * INT pin, the PS INT signal toggles from low to high.

 Delay for work after enable operation */

 SPDX-License-Identifier: GPL-2.0

/*

 * max44009.c - Support for MAX44009 Ambient Light Sensor

 *

 * Copyright (c) 2019 Robert Eshleman <bobbyeshleman@gmail.com>

 *

 * Datasheet: https://datasheets.maximintegrated.com/en/ds/MAX44009.pdf

 *

 * TODO: Support continuous mode and configuring from manual mode to

 *	 automatic mode.

 *

 * Default I2C address: 0x4a

 Registers in datasheet order */

 The maximum rising threshold for the max44009 */

 The max44009 always scales raw readings by 0.045 and is non-configurable */

 The fixed-point fractional multiplier for de-scaling threshold values */

 Manual mode only */

 Manual mode only */

 Manual mode only */

 Manual mode only */

	/*

	 * To set the integration time, the device must also be in manual

	 * mode.

	/*

	 * The mantissa consists of the low nibble of the Lux High Byte

	 * and the low nibble of the Lux Low Byte.

 The exponent byte is just the upper nibble of the Lux High Byte */

	/*

	 * The exponent value is base 2 to the power of the raw exponent byte.

	/*

	 * Use i2c_transfer instead of smbus read because i2c_transfer

	 * does NOT use a stop bit between address write and data read.

	 * Using a stop bit causes disjoint upper/lower byte reads and

	 * reduces accuracy.

 Reverse scaling of fixed-point integral */

 Reverse scaling of fixed-point fractional */

	/*

	 * To get the upper threshold, always adds the minimum upper threshold

	 * value to the shifted byte value (see datasheet).

	/*

	 * Exponent is base 2 to the power of the threshold exponent byte

	 * value

	/*

	 * Set device to trigger interrupt immediately upon exceeding

	 * the threshold limit.

 Clear any stale interrupt bit */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CM3323 - Capella Color Light Sensor

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * IIO driver for CM3323 (7-bit I2C slave address 0x10)

 *

 * TODO: calibscale to correct the lens factor

 sensor disable */

 auto/manual force mode */

 40 ms */

 80 ms */

 160 ms */

 320 ms */

 640 ms */

 1280 ms */

 enable sensor and set auto force mode */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ltr501.c - Support for Lite-On LTR501 ambient light and proximity sensor

 *

 * Copyright 2014 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * 7-bit I2C slave address 0x23

 *

 * TODO: IR LED characteristics

 ALS operation mode, SW reset */

 PS operation mode */

 measurement rate*/

 ALS integ time, measurement rate*/

 16-bit, little endian */

 upper 8 bits of LTR501_ALS_DATA1 */

 16-bit, little endian */

 upper 8 bits of LTR501_ALS_DATA0 */

 16-bit, little endian */

 upper 8 bits of LTR501_PS_DATA */

 output mode, polarity, mode */

 11 bit, ps upper threshold */

 11 bit, ps lower threshold */

 16 bit, ALS upper threshold */

 16 bit, ALS lower threshold */

 ps thresh, als thresh */

 repetition frequency in micro HZ*/

 repetition rate in micro seconds */

 x16 gain */

 x32 gain */

 bits X1 are for x64 gain */

 period in micro seconds */

 IR and visible spectrum coeff's are given in data sheet */

 multiply numerator by 100 to avoid handling ratio < 1 */

 Make sure integ time index is valid */

		/*

		 * 200 ms and 400 ms integ time can only be

		 * used in dynamic range 1

 50 ms integ time can only be used in dynamic range 2 */

 read int time in micro seconds */

 Make sure integ time index is valid */

 always read both ALS channels in given order */

 period in microseconds */

 period should be atleast equal to sampling period */

 period should be atleast equal to rate */

 update persistence count when changing frequency */

 update persistence count when changing frequency */

 only 1 and 0 are valid inputs */

 figure out which data needs to be ready */

 SPDX-License-Identifier: GPL-2.0

/*

 * cros_ec_light_prox - Driver for light and prox sensors behing CrosEC.

 *

 * Copyright (C) 2017 Google, Inc

/*

 * We only represent one entry for light or proximity. EC is merging different

 * light sensors to return the what the eye would see. For proximity, we

 * currently support only one light source.

 State data for ec_sensors iio driver. */

 Shared by all sensors */

			/*

			 * The data coming from the light sensor is

			 * pre-processed and represents the ambient light

			 * illuminance reading expressed in lux.

 Save values */

		/*

		 * RANGE is used for calibration

		 * scale is a number x.y, where x is coded on 16 bits,

		 * y coded on 16 bits, between 0 and 9999.

 Send to EC for each axis, even if not complete */

 Common part */

 Sensor specific */

 Timestamp */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/iio/light/tsl2563.c

 *

 * Copyright (C) 2008 Nokia Corporation

 *

 * Written by Timo O. Karjalainen <timo.o.karjalainen@nokia.com>

 * Contact: Amit Kucheria <amit.kucheria@verdurent.com>

 *

 * Converted to IIO driver

 * Amit Kucheria <amit.kucheria@verdurent.com>

 Use this many bits for fraction part. */

 Given number of 1/10000's in ADC_FRAC_BITS precision. */

 Bits used for fraction in calibration coefficients.*/

 0.5 in CALIB_FRAC_BITS precision */

 Make a fraction from a number n that was multiplied with b. */

 Decimal 10^(digits in sysfs presentation) */

 data0 low threshold, 2 bytes */

 data0 high threshold, 2 bytes */

 broadband sensor value, 2 bytes */

 infrared sensor value, 2 bytes */

 Remember state for suspend and resume functions */

 Calibration coefficients */

 Cache current values, to be returned while suspended */

/*

 * Return value is 0 for off, 1 for on, or a negative error

 * code if reading failed.

/*

 * Interrupt register is automatically written anyway if it is relevant

 * so is not here.

/*

 * "Normalized" ADC value is one obtained with 400ms of integration time and

 * 16x gain. This function returns the number of bits of shift needed to

 * convert between normalized values and HW values obtained using given

 * timing and gain settings.

 no-op */

 Convert a HW ADC value to normalized scale. */

	/*

	 * TODO: Make sure that we wait at least required delay but why we

	 * have to extend it one tick more?

/*

 * Conversions between lux and ADC values.

 *

 * The basic formula is lux = c0 * adc0 - c1 * adc1, where c0 and c1 are

 * appropriate constants. Different constants are needed for different

 * kinds of light, determined by the ratio adc1/adc0 (basically the ratio

 * of the intensities in infrared and visible wavelengths). lux_table below

 * lists the upper threshold of the adc1/adc0 ratio and the corresponding

 * constants.

 Convert normalized, scaled ADC values to lux. */

 Apply calibration coefficient to ADC count. */

 clear the interrupt and push the event */

 ensure the chip is actually on */

 now the interrupt is not enabled, we can go to sleep */

 Default values used until userspace says otherwise */

 The interrupt cannot yet be enabled so this is fine without lock */

 Ensure that interrupts are disabled - then flush any bottom halves */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Device driver for monitoring ambient light intensity (lux)

 * within the TAOS tsl258x family of devices (tsl2580, tsl2581, tsl2583).

 *

 * Copyright (c) 2011, TAOS Corporation.

 * Copyright (c) 2016-2017 Brian Masney <masneyb@onstation.org>

 Device Registers and Masks */

 tsl2583 cmd reg masks */

 tsl2583 cntrl reg masks */

 tsl2583 status reg masks */

 Lux calculation constants */

 Per-device data */

 Termination segment */

	/*

	 * This structure is intentionally large to accommodate updates via

	 * sysfs. Sized to 11 = max 10 segments + 1 termination segment.

	 * Assumption is that one and only one type of glass used.

 Index = (0 - 3) Used to validate the gain selection index */

/*

 * Provides initial operational parameter defaults.

 * These defaults may be changed through the device's sysfs files.

	/*

	 * The integration time must be a multiple of 50ms and within the

	 * range [50, 600] ms.

	/*

	 * This is an index into the gainadj table. Assume clear glass as the

	 * default.

 Default gain trim to account for aperture effects */

 Known external ALS reading used for calibration */

 Default lux table. */

/*

 * Reads and calculates current lux value.

 * The raw ch0 and ch1 values of the ambient light sensed in the last

 * integration cycle are read from the device.

 * Time scale factor array values are adjusted based on the integration time.

 * The raw values are multiplied by a scale factor, and device gain is obtained

 * using gain index. Limit checks are done next, then the ratio of a multiple

 * of ch1 value, to the ch0 value, is calculated. The array als_device_lux[]

 * declared above is then scanned to find the first ratio value that is just

 * above the ratio we just calculated. The ch0 and ch1 multiplier constants in

 * the array are then used along with the time scale factor array values, to

 * calculate the lux.

 separated ch0/ch1 data from device */

 raw lux calculated from device data */

 is data new & valid */

 return LAST VALUE */

	/*

	 * Clear the pending interrupt status bit on the chip to allow the next

	 * integration cycle to start. This has to be done even though this

	 * driver currently does not support interrupts.

 have no data, so return failure */

 extract ALS/lux data */

		/*

		 * The sensor appears to be in total darkness so set the

		 * calculated lux to 0 and return early to avoid a division by

		 * zero below when calculating the ratio.

 calculate ratio */

 convert to unscaled lux using the pointer to the table */

 note: lux is 31 bit max at this point */

 adjust for active time scale */

	/*

	 * Adjust for active gain scale.

	 * The tsl2583_default_lux tables above have a factor of 8192 built in,

	 * so we need to shift right.

	 * User-specified gain provides a multiplier.

	 * Apply user-specified gain before shifting right to retain precision.

	 * Use 64 bits to avoid overflow on multiplication.

	 * Then go back to 32 bits before division to avoid using div_u64().

 check for overflow */

 Update the structure with the latest VALID lux. */

/*

 * Obtain single reading and calculate the als_gain_trim (later used

 * to derive actual lux).

 * Return updated gain_trim value.

 Avoid division by zero of lux_value later on */

 determine als integration register */

 ensure at least one cycle */

 convert back to time (encompasses overrides) */

 set chip struct re scaling and saturation */

 90% of full scale */

 Set the gain based on als_settings struct */

/*

 * Turn the device on.

 * Configuration must be set before calling this function.

 Power on the device; ADC off. */

 Sysfs Interface Functions */

			/*

			 * We just printed the first "0" entry.

			 * Now get rid of the extra "," and break.

	/*

	 * We now have an array of ints starting at value[1], and

	 * enumerated by value[0].

	 * We expect each group of three ints is one table entry,

	 * and the last table entry is all 0.

			/*

			 * From page 20 of the TSL2581, TSL2583 data

			 * sheet (TAOS134  MARCH 2011):

			 *

			 * One of the photodiodes (channel 0) is

			 * sensitive to both visible and infrared light,

			 * while the second photodiode (channel 1) is

			 * sensitive primarily to infrared light.

	/*

	 * Preserve the ret variable if the call to

	 * tsl2583_set_pm_runtime_busy() is successful so the reading

	 * (if applicable) is returned to user space.

 Load up the V2 defaults (these are hard coded defaults for now) */

 Driver definition */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics uvis25 sensor driver

 *

 * Copyright 2017 STMicroelectronics Inc.

 *

 * Lorenzo Bianconi <lorenzo.bianconi83@gmail.com>

	/*

	 * in order to avoid possible race conditions with interrupt

	 * generation, disable the sensor first and then poll output

	 * register. That sequence guarantees the interrupt will be reset

	 * when irq line is unmasked

		/*

		 * mask irq line during oneshot read since the sensor

		 * does not export the capability to disable data-ready line

		 * in the register map and it is enabled by default.

		 * If the line is unmasked during read_raw() it will be set

		 * active and never reset since the trigger is disabled

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ROHM 1780GLI Ambient Light Sensor Driver

 *

 * Copyright (C) 2016 Linaro Ltd.

 * Author: Linus Walleij <linus.walleij@linaro.org>

 * Loosely based on the previous BH1780 ALS misc driver

 * Copyright (C) 2010 Texas Instruments

 * Author: Hemanth V <hemanthv@ti.com>

 power on settling time in ms */

 max time before value available in ms */

 Power up the device */

	/*

	 * As the device takes 250 ms to even come up with a fresh

	 * measurement after power-on, do not shut it down unnecessarily.

	 * Set autosuspend to a five seconds.

 Wait for power on, then for a value to be available */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * zopt2201.c - Support for IDT ZOPT2201 ambient light and UV B sensor

 *

 * Copyright 2017 Peter Meerwald-Stadler <pmeerw@pmeerw.net>

 *

 * Datasheet: https://www.idt.com/document/dst/zopt2201-datasheet

 * 7-bit I2C slave addresses 0x53 (default) or 0x52 (programmed)

 *

 * TODO: interrupt support, ALS/UVB raw mode

 Registers */

 LSB first, 13 to 20 bits */

 LSB first, 13 to 20 bits */

 LSB first, 13 to 20 bits */

 LSB first, 13 to 20 bits */

 0 .. ALS, 1 .. UV B */

 Values for ZOPT2201_LS_MEAS_RATE resolution / bit width */

 takes 400 ms */

 takes 200 ms */

 takes 100 ms, default */

 takes 50 ms */

 takes 25 ms */

 takes 3.125 ms */

 Values for ZOPT2201_LS_MEAS_RATE measurement rate */

 default */

 Values for ZOPT2201_LS_GAIN */

 Values for ZOPT2201_MAIN_STATUS */

 gain factor */

 micro lux per count */

 gain factor */

 micro W/m2 per count */

 sensor resolution in bits */

 measurement time in micro seconds */

 scale factor as integer + micro */

 gain register value */

 resolution register value */

 scale factor as integer + micro */

 gain register value */

 resolution register value */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * adjd_s311.c - Support for ADJD-S311-CR999 digital color sensor

 *

 * Copyright (C) 2012 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * driver for ADJD-S311-CR999 digital color sensor (10-bit channels for

 * red, green, blue, clear); 7-bit I2C slave address 0x74

 *

 * limitations: no calibration, no offset mode, no sleep mode

		/*

		 * not documented, based on measurement:

		 * 4095 LSBs correspond to roughly 4 ms

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics uvis25 i2c driver

 *

 * Copyright 2017 STMicroelectronics Inc.

 *

 * Lorenzo Bianconi <lorenzo.bianconi83@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * veml6070.c - Support for Vishay VEML6070 UV A light sensor

 *

 * Copyright 2016 Peter Meerwald-Stadler <pmeerw@pmeerw.net>

 *

 * IIO driver for VEML6070 (7-bit I2C slave addresses 0x38 and 0x39)

 *

 * TODO: integration time, ACK signal

 read: MSB data, write: config */

 LSB data */

 raise interrupt when over threshold */

 bit mask integration time */

 reserved, set to 1 */

 shutdown mode when set */

 integration time 1x */

 disable shutdown */

 measurement takes up to 125 ms for IT 1x */

 read MSB, address 0x39 */

 read LSB, address 0x38 */

 shutdown again */

	/*

	 * conversion of raw UV intensity values to UV index depends on

	 * integration time (IT) and value of the resistor connected to

	 * the RSET pin (default: 270 KOhm)

 low */

 moderate */

 high */

 very high */

 extreme */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2017 Analog Devices Inc.

 *  Author: Lars-Peter Clausen <lars@metafoo.de>

/**

 * struct iio_hw_consumer - IIO hw consumer block

 * @buffers: hardware buffers list head.

 * @channels: IIO provider channels.

/**

 * iio_hw_consumer_alloc() - Allocate IIO hardware consumer

 * @dev: Pointer to consumer device.

 *

 * Returns a valid iio_hw_consumer on success or a ERR_PTR() on failure.

/**

 * iio_hw_consumer_free() - Free IIO hardware consumer

 * @hwc: hw consumer to free.

/**

 * devm_iio_hw_consumer_alloc - Resource-managed iio_hw_consumer_alloc()

 * @dev: Pointer to consumer device.

 *

 * Managed iio_hw_consumer_alloc. iio_hw_consumer allocated with this function

 * is automatically freed on driver detach.

 *

 * returns pointer to allocated iio_hw_consumer on success, NULL on failure.

/**

 * iio_hw_consumer_enable() - Enable IIO hardware consumer

 * @hwc: iio_hw_consumer to enable.

 *

 * Returns 0 on success.

/**

 * iio_hw_consumer_disable() - Disable IIO hardware consumer

 * @hwc: iio_hw_consumer to disable.

 SPDX-License-Identifier: GPL-2.0-only

/* The industrial I/O callback buffer

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2013-2015 Analog Devices Inc.

 *  Author: Lars-Peter Clausen <lars@metafoo.de>

/*

 * For DMA buffers the storage is sub-divided into so called blocks. Each block

 * has its own memory buffer. The size of the block is the granularity at which

 * memory is exchanged between the hardware and the application. Increasing the

 * basic unit of data exchange from one sample to one block decreases the

 * management overhead that is associated with each sample. E.g. if we say the

 * management overhead for one exchange is x and the unit of exchange is one

 * sample the overhead will be x for each sample. Whereas when using a block

 * which contains n samples the overhead per sample is reduced to x/n. This

 * allows to achieve much higher samplerates than what can be sustained with

 * the one sample approach.

 *

 * Blocks are exchanged between the DMA controller and the application via the

 * means of two queues. The incoming queue and the outgoing queue. Blocks on the

 * incoming queue are waiting for the DMA controller to pick them up and fill

 * them with data. Block on the outgoing queue have been filled with data and

 * are waiting for the application to dequeue them and read the data.

 *

 * A block can be in one of the following states:

 *  * Owned by the application. In this state the application can read data from

 *    the block.

 *  * On the incoming list: Blocks on the incoming list are queued up to be

 *    processed by the DMA controller.

 *  * Owned by the DMA controller: The DMA controller is processing the block

 *    and filling it with data.

 *  * On the outgoing list: Blocks on the outgoing list have been successfully

 *    processed by the DMA controller and contain data. They can be dequeued by

 *    the application.

 *  * Dead: A block that is dead has been marked as to be freed. It might still

 *    be owned by either the application or the DMA controller at the moment.

 *    But once they are done processing it instead of going to either the

 *    incoming or outgoing queue the block will be freed.

 *

 * In addition to this blocks are reference counted and the memory associated

 * with both the block structure as well as the storage memory for the block

 * will be freed when the last reference to the block is dropped. This means a

 * block must not be accessed without holding a reference.

 *

 * The iio_dma_buffer implementation provides a generic infrastructure for

 * managing the blocks.

 *

 * A driver for a specific piece of hardware that has DMA capabilities need to

 * implement the submit() callback from the iio_dma_buffer_ops structure. This

 * callback is supposed to initiate the DMA transfer copying data from the

 * converter to the memory region of the block. Once the DMA transfer has been

 * completed the driver must call iio_dma_buffer_block_done() for the completed

 * block.

 *

 * Prior to this it must set the bytes_used field of the block contains

 * the actual number of bytes in the buffer. Typically this will be equal to the

 * size of the block, but if the DMA hardware has certain alignment requirements

 * for the transfer length it might choose to use less than the full size. In

 * either case it is expected that bytes_used is a multiple of the bytes per

 * datum, i.e. the block must not contain partial samples.

 *

 * The driver must call iio_dma_buffer_block_done() for each block it has

 * received through its submit_block() callback, even if it does not actually

 * perform a DMA transfer for the block, e.g. because the buffer was disabled

 * before the block transfer was started. In this case it should set bytes_used

 * to 0.

 *

 * In addition it is recommended that a driver implements the abort() callback.

 * It will be called when the buffer is disabled and can be used to cancel

 * pending and stop active transfers.

 *

 * The specific driver implementation should use the default callback

 * implementations provided by this module for the iio_buffer_access_funcs

 * struct. It may overload some callbacks with custom variants if the hardware

 * has special requirements that are not handled by the generic functions. If a

 * driver chooses to overload a callback it has to ensure that the generic

 * callback is called from within the custom callback.

/*

 * dma_free_coherent can sleep, hence we need to take some special care to be

 * able to drop a reference from an atomic context.

/*

 * Version of iio_buffer_block_put() that can be called from atomic context

	/*

	 * The buffer has already been freed by the application, just drop the

	 * reference.

/**

 * iio_dma_buffer_block_done() - Indicate that a block has been completed

 * @block: The completed block

 *

 * Should be called when the DMA controller has finished handling the block to

 * pass back ownership of the block to the queue.

/**

 * iio_dma_buffer_block_list_abort() - Indicate that a list block has been

 *   aborted

 * @queue: Queue for which to complete blocks.

 * @list: List of aborted blocks. All blocks in this list must be from @queue.

 *

 * Typically called from the abort() callback after the DMA controller has been

 * stopped. This will set bytes_used to 0 for each block in the list and then

 * hand the blocks back to the queue.

	/*

	 * If the core owns the block it can be re-used. This should be the

	 * default case when enabling the buffer, unless the DMA controller does

	 * not support abort and has not given back the block yet.

/**

 * iio_dma_buffer_request_update() - DMA buffer request_update callback

 * @buffer: The buffer which to request an update

 *

 * Should be used as the iio_dma_buffer_request_update() callback for

 * iio_buffer_access_ops struct for DMA buffers.

	/*

	 * Split the buffer into two even parts. This is used as a double

	 * buffering scheme with usually one block at a time being used by the

	 * DMA and the other one by the application.

 Allocations are page aligned */

 If we can't re-use it free it */

	/*

	 * At this point all blocks are either owned by the core or marked as

	 * dead. This means we can reset the lists without having to fear

	 * corrution.

 Could not reuse it */

	/*

	 * If the hardware has already been removed we put the block into

	 * limbo. It will neither be on the incoming nor outgoing list, nor will

	 * it ever complete. It will just wait to be freed eventually.

		/*

		 * This is a bit of a problem and there is not much we can do

		 * other then wait for the buffer to be disabled and re-enabled

		 * and try again. But it should not really happen unless we run

		 * out of memory or something similar.

		 *

		 * TODO: Implement support in the IIO core to allow buffers to

		 * notify consumers that something went wrong and the buffer

		 * should be disabled.

/**

 * iio_dma_buffer_enable() - Enable DMA buffer

 * @buffer: IIO buffer to enable

 * @indio_dev: IIO device the buffer is attached to

 *

 * Needs to be called when the device that the buffer is attached to starts

 * sampling. Typically should be the iio_buffer_access_ops enable callback.

 *

 * This will allocate the DMA buffers and start the DMA transfers.

/**

 * iio_dma_buffer_disable() - Disable DMA buffer

 * @buffer: IIO DMA buffer to disable

 * @indio_dev: IIO device the buffer is attached to

 *

 * Needs to be called when the device that the buffer is attached to stops

 * sampling. Typically should be the iio_buffer_access_ops disable callback.

/**

 * iio_dma_buffer_read() - DMA buffer read callback

 * @buffer: Buffer to read form

 * @n: Number of bytes to read

 * @user_buffer: Userspace buffer to copy the data to

 *

 * Should be used as the read callback for iio_buffer_access_ops

 * struct for DMA buffers.

/**

 * iio_dma_buffer_data_available() - DMA buffer data_available callback

 * @buf: Buffer to check for data availability

 *

 * Should be used as the data_available callback for iio_buffer_access_ops

 * struct for DMA buffers.

	/*

	 * For counting the available bytes we'll use the size of the block not

	 * the number of actual bytes available in the block. Otherwise it is

	 * possible that we end up with a value that is lower than the watermark

	 * but won't increase since all blocks are in use.

/**

 * iio_dma_buffer_set_bytes_per_datum() - DMA buffer set_bytes_per_datum callback

 * @buffer: Buffer to set the bytes-per-datum for

 * @bpd: The new bytes-per-datum value

 *

 * Should be used as the set_bytes_per_datum callback for iio_buffer_access_ops

 * struct for DMA buffers.

/**

 * iio_dma_buffer_set_length - DMA buffer set_length callback

 * @buffer: Buffer to set the length for

 * @length: The new buffer length

 *

 * Should be used as the set_length callback for iio_buffer_access_ops

 * struct for DMA buffers.

 Avoid an invalid state */

/**

 * iio_dma_buffer_init() - Initialize DMA buffer queue

 * @queue: Buffer to initialize

 * @dev: DMA device

 * @ops: DMA buffer queue callback operations

 *

 * The DMA device will be used by the queue to do DMA memory allocations. So it

 * should refer to the device that will perform the DMA to ensure that

 * allocations are done from a memory region that can be accessed by the device.

/**

 * iio_dma_buffer_exit() - Cleanup DMA buffer queue

 * @queue: Buffer to cleanup

 *

 * After this function has completed it is safe to free any resources that are

 * associated with the buffer and are accessed inside the callback operations.

/**

 * iio_dma_buffer_release() - Release final buffer resources

 * @queue: Buffer to release

 *

 * Frees resources that can't yet be freed in iio_dma_buffer_exit(). Should be

 * called in the buffers release callback implementation right before freeing

 * the memory associated with the buffer.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2014-2015 Analog Devices Inc.

 *  Author: Lars-Peter Clausen <lars@metafoo.de>

/*

 * The IIO DMAengine buffer combines the generic IIO DMA buffer infrastructure

 * with the DMAengine framework. The generic IIO DMA buffer infrastructure is

 * used to manage the buffer memory and implement the IIO buffer operations

 * while the DMAengine framework is used to perform the DMA transfers. Combined

 * this results in a device independent fully functional DMA buffer

 * implementation that can be used by device drivers for peripherals which are

 * connected to a DMA controller which has a DMAengine driver implementation.

/**

 * iio_dmaengine_buffer_alloc() - Allocate new buffer which uses DMAengine

 * @dev: Parent device for the buffer

 * @channel: DMA channel name, typically "rx".

 *

 * This allocates a new IIO buffer which internally uses the DMAengine framework

 * to perform its transfers. The parent device will be used to request the DMA

 * channel.

 *

 * Once done using the buffer iio_dmaengine_buffer_free() should be used to

 * release it.

 Needs to be aligned to the maximum of the minimums */

/**

 * iio_dmaengine_buffer_free() - Free dmaengine buffer

 * @buffer: Buffer to free

 *

 * Frees a buffer previously allocated with iio_dmaengine_buffer_alloc().

/**

 * devm_iio_dmaengine_buffer_alloc() - Resource-managed iio_dmaengine_buffer_alloc()

 * @dev: Parent device for the buffer

 * @channel: DMA channel name, typically "rx".

 *

 * This allocates a new IIO buffer which internally uses the DMAengine framework

 * to perform its transfers. The parent device will be used to request the DMA

 * channel.

 *

 * The buffer will be automatically de-allocated once the device gets destroyed.

/**

 * devm_iio_dmaengine_buffer_setup() - Setup a DMA buffer for an IIO device

 * @dev: Parent device for the buffer

 * @indio_dev: IIO device to which to attach this buffer.

 * @channel: DMA channel name, typically "rx".

 *

 * This allocates a new IIO buffer with devm_iio_dmaengine_buffer_alloc()

 * and attaches it to an IIO device with iio_device_attach_buffer().

 * It also appends the INDIO_BUFFER_HARDWARE mode to the supported modes of the

 * IIO device.

 SPDX-License-Identifier: GPL-2.0-only

	/*

	 * Make sure we don't overflow an unsigned int after kfifo rounds up to

	 * the next power of 2.

 Avoid an invalid state */

/**

 * devm_iio_kfifo_allocate - Resource-managed iio_kfifo_allocate()

 * @dev:		Device to allocate kfifo buffer for

 *

 * RETURNS:

 * Pointer to allocated iio_buffer on success, NULL on failure.

/**

 * devm_iio_kfifo_buffer_setup_ext - Allocate a kfifo buffer & attach it to an IIO device

 * @dev: Device object to which to attach the life-time of this kfifo buffer

 * @indio_dev: The device the buffer should be attached to

 * @mode_flags: The mode flags for this buffer (INDIO_BUFFER_SOFTWARE and/or

 *		INDIO_BUFFER_TRIGGERED).

 * @setup_ops: The setup_ops required to configure the HW part of the buffer (optional)

 * @buffer_attrs: Extra sysfs buffer attributes for this IIO buffer

 *

 * This function allocates a kfifo buffer via devm_iio_kfifo_allocate() and

 * attaches it to the IIO device via iio_device_attach_buffer().

 * This is meant to be a bit of a short-hand/helper function as there are a few

 * drivers that seem to do this.

 SPDX-License-Identifier: GPL-2.0-only

 /*

 * Copyright (c) 2012 Analog Devices, Inc.

 *  Author: Lars-Peter Clausen <lars@metafoo.de>

/**

 * iio_triggered_buffer_setup_ext() - Setup triggered buffer and pollfunc

 * @indio_dev:		IIO device structure

 * @h:			Function which will be used as pollfunc top half

 * @thread:		Function which will be used as pollfunc bottom half

 * @direction:		Direction of the data stream (in/out).

 * @setup_ops:		Buffer setup functions to use for this device.

 *			If NULL the default setup functions for triggered

 *			buffers will be used.

 * @buffer_attrs:	Extra sysfs buffer attributes for this IIO buffer

 *

 * This function combines some common tasks which will normally be performed

 * when setting up a triggered buffer. It will allocate the buffer and the

 * pollfunc.

 *

 * Before calling this function the indio_dev structure should already be

 * completely initialized, but not yet registered. In practice this means that

 * this function should be called right before iio_device_register().

 *

 * To free the resources allocated by this function call

 * iio_triggered_buffer_cleanup().

 Ring buffer functions - here trigger setup related */

 Flag that polled ring buffering is possible */

/**

 * iio_triggered_buffer_cleanup() - Free resources allocated by iio_triggered_buffer_setup_ext()

 * @indio_dev: IIO device structure

 SPDX-License-Identifier: GPL-2.0+

/*

 * Azoteq IQS624/625 Angular Position Sensors

 *

 * Copyright (C) 2019 Jeff LaBundy <jeff@labundy.com>

	/*

	 * The IQS625 reports angular position in the form of coarse intervals,

	 * so only interval change events are unmasked. Conversely, the IQS624

	 * reports angular position down to one degree of resolution, so wheel

	 * movement events are unmasked instead.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensors Driver

 * Copyright (c) 2020, Intel Corporation.

 Channel definitions */

 Adjust channel real bits based on report descriptor */

 Channel read_raw handler */

 Channel write_raw handler */

/*

 * Callback handler to send event after all samples are received

 * and captured.

 Capture samples in local storage */

 Parse report which is specific to an usage id */

 Function to initialize the processing for usage id */

 Function to deinitialize the processing for usage id */

 Format: HID-SENSOR-INT-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * vz89x.c - Support for SGX Sensortech MiCS VZ89X VOC sensors

 *

 * Copyright (C) 2015-2018

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

/*

 * Chipset sometime updates in the middle of a reading causing it to reset the

 * data pointer, and causing invalid reading of previous data.

 * We can check for this by reading MSB of the resistance reading that is

 * always zero, and by also confirming the VOC_short isn't zero.

 VZ89TE device has a modified CRC-8 two complement check */

 sensor can only be polled once a second max per datasheet */

 SPDX-License-Identifier: GPL-2.0

/*

 * Bosch BME680 - Temperature, Pressure, Humidity & Gas Sensor

 *

 * Copyright (C) 2017 - 2018 Bosch Sensortec GmbH

 * Copyright (C) 2018 Himanshu Jha <himanshujha199640@gmail.com>

 *

 * Datasheet:

 * https://ae-bst.resource.bosch.com/media/_tech/media/datasheets/BST-BME680-DS001-00.pdf

	/*

	 * Carryover value from temperature conversion, used in pressure

	 * and humidity compensation calculations.

 Temperature related coefficients */

 Pressure related coefficients */

 Humidity related coefficients */

 Gas heater related coefficients */

 Other coefficients */

/*

 * Taken from Bosch BME680 API:

 * https://github.com/BoschSensortec/BME680_driver/blob/63bb5336/bme680.c#L876

 *

 * Returns temperature measurement in DegC, resolutions is 0.01 DegC. Therefore,

 * output value of "3233" represents 32.33 DegC.

 If the calibration is invalid, attempt to reload it */

/*

 * Taken from Bosch BME680 API:

 * https://github.com/BoschSensortec/BME680_driver/blob/63bb5336/bme680.c#L896

 *

 * Returns pressure measurement in Pa. Output value of "97356" represents

 * 97356 Pa = 973.56 hPa.

/*

 * Taken from Bosch BME680 API:

 * https://github.com/BoschSensortec/BME680_driver/blob/63bb5336/bme680.c#L937

 *

 * Returns humidity measurement in percent, resolution is 0.001 percent. Output

 * value of "43215" represents 43.215 %rH.

 clamp between 0-100 %rH */

/*

 * Taken from Bosch BME680 API:

 * https://github.com/BoschSensortec/BME680_driver/blob/63bb5336/bme680.c#L973

 *

 * Returns gas measurement in Ohm. Output value of "82986" represent 82986 ohms.

 Look up table for the possible gas range values */

/*

 * Taken from Bosch BME680 API:

 * https://github.com/BoschSensortec/BME680_driver/blob/63bb5336/bme680.c#L1002

 Cap temperature */

/*

 * Taken from Bosch BME680 API:

 * https://github.com/BoschSensortec/BME680_driver/blob/63bb5336/bme680.c#L1188

 Max duration */

	/*

	 * Highly recommended to set oversampling of humidity before

	 * temperature/pressure oversampling.

 IIR filter settings */

 set target heater temperature */

 set target heating duration */

 Enable the gas sensor and select heater profile set-point 0 */

 set forced mode to trigger measurement */

 reading was skipped */

	/*

	 * val might be NULL if we're called by the read_press/read_humid

	 * routine which is callled to get t_fine value used in

	 * compensate_press/compensate_humid to get compensated

	 * pressure/humidity readings.

 Centidegrees to millidegrees */

 Read and compensate temperature to get a reading of t_fine */

 reading was skipped */

 Read and compensate temperature to get a reading of t_fine */

 reading was skipped */

 Set heater settings */

 set forced mode to trigger measurement */

	/*

	 * occurs if either the gas heating duration was insuffient

	 * to reach the target heater temperature or the target

	 * heater temperature was too high for the heater sink to

	 * reach.

 default values for the sensor */

 2X oversampling rate */

 4X oversampling rate */

 8X oversampling rate */

 degree Celsius */

 milliseconds */

 SPDX-License-Identifier: GPL-2.0

/*

 * Sensirion SPS30 particulate matter sensor driver

 *

 * Copyright (c) Tomasz Duszynski <tduszyns@gmail.com>

 sensor measures reliably up to 3000 ug / m3 */

 minimum and maximum self cleaning periods in seconds */

 this is fine since passed float is always non-negative */

 special case 0 */

 return values ranging from 1 to 99 */

 return values ranging from 100 to 300000 */

 PM1, PM2P5, PM4, PM10 */

 read up to the number of bytes actually needed */

	/*

	 * sensor requires reset in order to return up to date self cleaning

	 * period

 SPDX-License-Identifier: GPL-2.0+

/*

 * sgp40.c - Support for Sensirion SGP40 Gas Sensor

 *

 * Copyright (C) 2021 Andreas Klinger <ak@it-klinger.de>

 *

 * I2C slave address: 0x59

 *

 * Datasheet can be found here:

 * https://www.sensirion.com/file/datasheet_sgp40

 *

 * There are two functionalities supported:

 *

 * 1) read raw logarithmic resistance value from sensor

 *    --> useful to pass it to the algorithm of the sensor vendor for

 *    measuring deteriorations and improvements of air quality.

 *

 * 2) calculate an estimated absolute voc index (0 - 500 index points) for

 *    measuring the air quality.

 *    For this purpose the value of the resistance for which the voc index

 *    will be 250 can be set up using calibbias.

 *

 * Compensation values of relative humidity and temperature can be set up

 * by writing to the out values of temp and humidityrelative.

/*

 * floating point calculation of voc is done as integer

 * where numbers are multiplied by 1 << SGP40_CALC_POWER

 Prevent concurrent access to rht, tmp, calibbias */

/*

 * taylor approximation of e^x:

 * y = 1 + x + x^2 / 2 + x^3 / 6 + x^4 / 24 + ... + x^n / n!

 *

 * Because we are calculating x real value multiplied by 2^power we get

 * an additional 2^power^n to divide for every element. For a reasonable

 * precision this would overflow after a few iterations. Therefore we

 * divide the x^n part whenever its about to overflow (xmax).

 divide when next multiplication would overflow */

 we calculate as a multiple of 16384 (2^14) */

 voc = 500 / (1 + e^x) */

 clamp between 0 .. 100 %rH */

 clamp between -45 .. +130 C */

		/*

		 * calculation should fit into integer, where:

		 * voc <= (500 * 2^SGP40_CALC_POWER) = 8192000

		 * (with SGP40_CALC_POWER = 14)

 set default values */

 50 % */

 25 C */

 resistance raw value for voc index of 250 */

 SPDX-License-Identifier: GPL-2.0

/*

 * Sensirion SPS30 particulate matter sensor serial driver

 *

 * Copyright (c) 2021 Tomasz Duszynski <tomasz.duszynski@octakon.com>

 SOF isn't checksummed */

 SOF, checksum and EOF are not checksummed */

 just in case device put some unexpected data on the bus */

 wait for the start of frame */

 remove stuffed bytes on-the-fly */

 EOF received */

 request BE IEEE754 formatted data */

 measurements are ready within a second */

 if measurements aren't ready sensor returns empty frame */

	/*

	 * tell device do return serial number and add extra nul byte just in case

	 * serial number isn't a valid string

 SPDX-License-Identifier: GPL-2.0+

/*

 * atlas-sensor.c - Support for Atlas Scientific OEM SM sensors

 *

 * Copyright (C) 2015-2019 Konsulko Group

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 96-bit data + 32-bit pad + 64-bit timestamp */

 0.001 */

 0.00001 */

 0.000000001 */

 0.1 */

 interrupt pin toggles on new conversion */

 SPDX-License-Identifier: GPL-2.0

/*

 * BME680 - SPI Driver

 *

 * Copyright (C) 2018 Himanshu Jha <himanshujha199640@gmail.com>

/*

 * In SPI mode there are only 7 address bits, a "page" register determines

 * which part of the 8-bit range is active. This function looks at the address

 * and writes the page selection bit if needed

 Page "1" is low range */

	/*

	 * Data sheet claims we're only allowed to change bit 4, so we must do

	 * a read-modify-write on each and every page select

	/*

	 * The SPI register address (= full register address without bit 7)

	 * and the write command (bit7 = RW = '0')

 bit7 = RW = '1' */

 Undefined on warm boot */

 SPDX-License-Identifier: GPL-2.0

/*

 * Sensirion SCD4X carbon dioxide sensor i2c driver

 *

 * Copyright (C) 2021 Protonic Holland

 * Author: Roan van Dijk <roan@protonic.nl>

 *

 * I2C slave address: 0x62

 *

 * Datasheets:

 * https://www.sensirion.com/file/datasheet_scd4x

Commands SCD4X*/

 maintain access to device, to prevent concurrent reads/writes */

	/*

	 * Measurement needs to be stopped before sending commands.

	 * Except stop and start command.

 execution time for stopping measurement */

	/*

	 * Measurement needs to be stopped before sending commands.

	 * Except for reading measurement and data ready command.

 execution time for stopping measurement */

 CRC byte for every 2 bytes of data */

 start measurement */

 measurement needs to be stopped before sending commands */

 execution time */

 start measurement, except for forced calibration command */

 execution time */

 CRC byte for every 2 bytes of data */

	/*

	 * on error try to start the measurement,

	 * puts sensor back into continuous measurement

 new measurement available */

 try to start sensor on timeout */

 execution time */

 SPDX-License-Identifier: GPL-2.0+

/*

 * atlas-ezo-sensor.c - Support for Atlas Scientific EZO sensors

 *

 * Copyright (C) 2020 Konsulko Group

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 lock to avoid multiple concurrent read calls */

 removing floating point for fixed number representation */

 IIO_CONCENTRATION modifiers */

 0.0001 */

 SPDX-License-Identifier: GPL-2.0

/*

 * Plantower PMS7003 particulate matter sensor driver

 *

 * Copyright (c) Tomasz Duszynski <tduszyns@gmail.com>

 last 2 data bytes hold frame checksum */

/*

 * commands have following format:

 *

 * +------+------+-----+------+-----+-----------+-----------+

 * | 0x42 | 0x4d | cmd | 0x00 | arg | cksum msb | cksum lsb |

 * +------+------+-----+------+-----+-----------+-----------+

 must be held whenever state gets touched */

 Used to construct scan to push to the IIO buffer */

 PM1, PM2P5, PM10 */

 wait for SOF and data length */

 SPDX-License-Identifier: GPL-2.0+

/*

 * ams-iaq-core.c - Support for AMS iAQ-Core VOC sensors

 *

 * Copyright (C) 2015, 2018

 * Author: Matt Ranostay <matt.ranostay@konsulko.com>

 sensor can only be polled once a second max per datasheet */

 so initial reading will complete */

 SPDX-License-Identifier: GPL-2.0

/*

 * Sensirion SCD30 carbon dioxide sensor core driver

 *

 * Copyright (c) 2020 Tomasz Duszynski <tomasz.duszynski@octakon.com>

 sensor boots up within 2 secs */

	/*

	 * Power-on-reset causes sensor to produce some glitch on i2c bus and

	 * some controllers end up in error state. Try to recover by placing

	 * any data on the bus.

 simplified float to fixed point conversion with a scaling factor of 0.01 */

 special case 0 */

 return values ranging from 1 to 99 */

 return values starting at 100 */

	/*

	 * co2 is left unprocessed while temperature and humidity are scaled

	 * to milli deg C and milli percent respectively.

 new measurement available */

		/*

		 * Manufacturer does not explicitly specify min/max sensible

		 * values hence check is omitted for simplicity.

		/*

		 * Not all values fit PAGE_SIZE buffer hence print every 6th

		 * (each frequency differs by 6s in time domain from the

		 * adjacent). Unlisted but valid ones are still accepted.

		/*

		 * this channel is special in a sense we are pretending that

		 * sensor is able to change measurement chamber pressure but in

		 * fact we're just setting pressure compensation value

	/*

	 * Interrupt is enabled just before taking a fresh measurement

	 * and disabled afterwards. This means we need to ensure it is not

	 * enabled here to keep calls to enable/disable balanced.

 SPDX-License-Identifier: GPL-2.0

/*

 * Sensirion SPS30 particulate matter sensor i2c driver

 *

 * Copyright (c) 2020 Tomasz Duszynski <tomasz.duszynski@octakon.com>

 *

 * I2C slave address: 0x69

 max number of bytes needed to store PM measurements or serial string */

	/*

	 * Sensor does not support repeated start so instead of

	 * sending two i2c messages in a row we just send one by one.

	/*

	 * Internally sensor stores measurements in a following manner:

	 *

	 * PM1: upper two bytes, crc8, lower two bytes, crc8

	 * PM2P5: upper two bytes, crc8, lower two bytes, crc8

	 * PM4: upper two bytes, crc8, lower two bytes, crc8

	 * PM10: upper two bytes, crc8, lower two bytes, crc8

	 *

	 * What follows next are number concentration measurements and

	 * typical particle size measurement which we omit.

 each two bytes are followed by a crc8 */

 validate received data and strip off crc bytes */

 request BE IEEE754 formatted data */

	/*

	 * Power-on-reset causes sensor to produce some glitch on i2c bus and

	 * some controllers end up in error state. Recover simply by placing

	 * some data on the bus, for example STOP_MEAS command, which

	 * is NOP in this case.

 measurements are ready within a second */

 extra nul just in case */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ccs811.c - Support for AMS CCS811 VOC Sensor

 *

 * Copyright (C) 2017 Narcisa Vasile <narcisaanamaria12@gmail.com>

 *

 * Datasheet: ams.com/content/download/951091/2269479/CCS811_DS000459_3-00.pdf

 *

 * IIO driver for AMS CCS811 (I2C address 0x5A/0x5B set by ADDR Low/High)

 *

 * TODO:

 * 1. Make the drive mode selectable form userspace

 * 2. Add support for interrupts

 * 3. Adjust time to wait for data to be ready based on selected operation mode

 * 4. Read error register and put the information in logs

 Used to transition from boot to application mode */

 Status register flags */

/*

 * Value of FW_MODE bit of STATUS register describes the sensor's state:

 * 0: Firmware is in boot mode, this allows new firmware to be loaded

 * 1: Firmware is in application mode. CCS811 is ready to take ADC measurements

 Measurement modes */

 Protect readings */

 Ensures correct alignment of timestamp if present */

/*

 * The CCS811 powers-up in boot mode. A setup write to CCS811_APP_START will

 * transition the sensor to application mode.

 Maximum waiting time: 1s, as measurements are made every second */

 Try to reset using nRESET pin if available else do SW reset */

		/*

		 * As per the datasheet, this sequence of values needs to be

		 * written to the SW_RESET register for triggering the soft

		 * reset in the device and placing it in boot mode.

 tSTART delay required after reset */

 Check hardware id (should be 0x81 for this family of devices) */

 SPDX-License-Identifier: GPL-2.0

/*

 * Senseair Sunrise 006-0-0007 CO2 sensor driver.

 *

 * Copyright (C) 2021 Jacopo Mondi

 *

 * List of features not yet supported by the driver:

 * - controllable EN pin

 * - single-shot operations using the nDRY pin.

 * - ABC/target calibration

/*

 * The calibration timeout is not characterized in the datasheet.

 * Use 30 seconds as a reasonable upper limit.

 Protects access to IIO attributes. */

 Custom regmap read/write operations: perform unlocked access to the i2c bus. */

	/*

	 * Wake up sensor by sending sensor address: START, sensor address,

	 * STOP. Sensor will not ACK this byte.

	 *

	 * The chip enters a low power state after 15ms without

	 * communications or after a complete read/write sequence.

 Discard reg address from values count. */

/*

 * Sunrise i2c read/write operations: lock the i2c segment to avoid losing the

 * wake up session. Use custom regmap operations that perform unlocked access to

 * the i2c bus.

 Trigger a calibration cycle. */

 Reset the calibration status reg. */

 Write a calibration command and poll the calibration status bit. */

	/*

	 * Calibration takes several seconds, so the sleep time between reads

	 * can be pretty relaxed.

 Enumerate and retrieve the chip error status. */

 Calibration triggers. */

 Error statuses. */

			/*

			 * 1 / 10^4 to comply with IIO scale for CO2

			 * (percentage). The chip CO2 reading range is [400 -

			 * 5000] ppm which corresponds to [0,004 - 0,5] %.

 x10 to comply with IIO scale (millidegrees celsius). */

	/*

	 * The chip nacks the wake up message. If the adapter does not support

	 * protocol mangling do not set the I2C_M_IGNORE_NAK flag at the expense

	 * of possible cruft in the logs.

 SPDX-License-Identifier: GPL-2.0

/*

 * Sensirion SCD30 carbon dioxide sensor i2c driver

 *

 * Copyright (c) 2020 Tomasz Duszynski <tomasz.duszynski@octakon.com>

 *

 * I2C slave address: 0x61

	/*

	 * repeated start is not supported hence instead of sending two i2c

	 * messages in a row we send one by one

 each two bytes are followed by a crc8 */

 commands below don't take an argument */

 validate received data and strip off crc bytes */

 SPDX-License-Identifier: GPL-2.0

/*

 * sgp30.c - Support for Sensirion SGP Gas Sensors

 *

 * Copyright (C) 2018 Andreas Brauchli <andreas.brauchli@sensirion.com>

 *

 * I2C slave address: 0x58

 *

 * Datasheets:

 * https://www.sensirion.com/file/datasheet_sgp30

 * https://www.sensirion.com/file/datasheet_sgpc3

 *

 * TODO:

 * - baseline support

 * - humidity compensation

 * - power mode switching (SGPC3)

/**

 * sgp_verify_buffer() - verify the checksums of the data buffer words

 *

 * @data:       SGP data

 * @buf:        Raw data buffer

 * @word_count: Num data words stored in the buffer, excluding CRC bytes

 *

 * Return:      0 on success, negative error otherwise.

/**

 * sgp_read_cmd() - reads data from sensor after issuing a command

 * The caller must hold data->data_lock for the duration of the call.

 * @data:        SGP data

 * @cmd:         SGP Command to issue

 * @buf:         Raw data buffer to use

 * @word_count:  Num words to read, excluding CRC bytes

 * @duration_us: Time taken to sensor to take a reading and data to be ready.

 *

 * Return:       0 on success, negative error otherwise.

/**

 * sgp_measure_iaq() - measure and retrieve IAQ values from sensor

 * The caller must hold data->data_lock for the duration of the call.

 * @data:       SGP data

 *

 * Return:      0 on success, -EBUSY on default values, negative error

 *              otherwise.

 data contains default values */

 driver does not match product */

 engineering samples are not supported: no interface guarantees */

 get feature set version and write it to client data */

 SPDX-License-Identifier: GPL-2.0

/*

 * BME680 - I2C Driver

 *

 * Copyright (C) 2018 Himanshu Jha <himanshujha199640@gmail.com>

 *

 * 7-Bit I2C slave address is:

 *	- 0x76 if SDO is pulled to GND

 *	- 0x77 if SDO is pulled to VDDIO

 *

 * Note: SDO pin cannot be left floating otherwise I2C address

 *	 will be undefined.

 SPDX-License-Identifier: GPL-2.0

/*

 * Sensirion SCD30 carbon dioxide sensor serial driver

 *

 * Copyright (c) 2020 Tomasz Duszynski <tomasz.duszynski@octakon.com>

	/*

	 * Communication over serial line is based on modbus protocol (or rather

	 * its variation called modbus over serial to be precise). Upon

	 * receiving a request device should reply with response.

	 *

	 * Frame below represents a request message. Each field takes

	 * exactly one byte.

	 *

	 * +------+------+-----+-----+-------+-------+-----+-----+

	 * | dev  | op   | reg | reg | byte1 | byte0 | crc | crc |

	 * | addr | code | msb | lsb |       |       | lsb | msb |

	 * +------+------+-----+-----+-------+-------+-----+-----+

	 *

	 * The message device replies with depends on the 'op code' field from

	 * the request. In case it was set to SCD30_SERDEV_WRITE sensor should

	 * reply with unchanged request. Otherwise 'op code' was set to

	 * SCD30_SERDEV_READ and response looks like the one below. As with

	 * request, each field takes one byte.

	 *

	 * +------+------+--------+-------+-----+-------+-----+-----+

	 * | dev  | op   | num of | byte0 | ... | byteN | crc | crc |

	 * | addr | code | bytes  |       |     |       | lsb | msb |

	 * +------+------+--------+-------+-----+-------+-----+-----+

 number of u16 words to read */

 just in case sensor puts some unexpected bytes on the bus */

 SPDX-License-Identifier: GPL-2.0

/*

 * AD5338R, AD5671R, AD5673R, AD5675R, AD5677R, AD5691R, AD5692R, AD5693,

 * AD5693R, AD5694, AD5694R, AD5695R, AD5696, AD5696R

 * Digital to analog converters driver

 *

 * Copyright 2018 Analog Devices Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO driver for the Measurement Computing CIO-DAC

 * Copyright (C) 2016 William Breathitt Gray

 *

 * This driver supports the following Measurement Computing devices: CIO-DAC16,

 * CIO-DAC06, and PC104-DAC06.

/**

 * struct cio_dac_iio - IIO device private data structure

 * @chan_out_states:	channels' output states

 * @base:		base port address of the IIO device

 DAC can only accept up to a 16-bit value */

 initialize DAC outputs to 0V */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5592R Digital <-> Analog converters driver

 *

 * Copyright 2015-2016 Analog Devices Inc.

 * Author: Paul Cercueil <paul.cercueil@analog.com>

 NOP */

	/*

	 * Invalid data:

	 * See Figure 40. Single-Channel ADC Conversion Sequence

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Maxim Integrated

 * 7-bit, Multi-Channel Sink/Source Current DAC Driver

 * Copyright (C) 2017 Maxim Integrated

/*

 * DS4424 DAC control register 8 bits

 * [7]		0: to sink; 1: to source

 * [6:0]	steps to sink/source

 * bit[7] looks like a sign bit, but the value of the register is

 * not a two's complement code considering the bit[6:0] is a absolute

 * distance from the zero point.

 SPDX-License-Identifier: GPL-2.0-only

 /*

  * iio/dac/max5821.c

  * Copyright (C) 2014 Philippe Reynes

 command bytes */

 max5821 start in powerdown mode 100Kohm to ground */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5721, AD5721R, AD5761, AD5761R, Voltage Output Digital to Analog Converter

 *

 * Copyright 2016 Qtechnology A/S

 * 2016 Ricardo Ribalda <ribalda@kernel.org>

/**

 * struct ad5761_chip_info - chip specific information

 * @int_vref:	Value of the internal reference voltage in mV - 0 if external

 *		reference voltage is used

 * @channel:	channel specification

/**

 * struct ad5761_state - driver instance specific data

 * @spi:		spi_device

 * @vref_reg:		reference voltage regulator

 * @use_intref:		true when the internal voltage reference is used

 * @vref:		actual voltage reference in mVolts

 * @range:		output range mode used

 * @lock:		lock to protect the data buffer during SPI ops

 * @data:		cache aligned spi buffer

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

 Use Internal regulator */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5760, AD5780, AD5781, AD5790, AD5791 Voltage Output Digital to Analog

 * Converter

 *

 * Copyright 2011 Analog Devices Inc.

 Registers */

 Control Register */

 Software Control Register */

/**

 * struct ad5791_chip_info - chip specific information

 * @get_lin_comp:	function pointer to the device specific function

/**

 * struct ad5791_state - driver instance specific data

 * @spi:			spi_device

 * @reg_vdd:		positive supply regulator

 * @reg_vss:		negative supply regulator

 * @chip_info:		chip model specific constants

 * @vref_mv:		actual reference voltage used

 * @vref_neg_mv:	voltage of the negative supply

 * @ctrl:		control register cache

 * @pwr_down_mode:	current power down mode

 * @pwr_down:		true if device is powered down

 * @data:		spi transfer buffers

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  m62332.c - Support for Mitsubishi m62332 DAC

 *

 *  Copyright (c) 2014 Dmitry Eremin-Solenikov

 *

 *  Based on max517 driver:

 *  Copyright (C) 2010, 2011 Roland Stigge <stigge@antcom.de>

 Corresponds to Vref / 2^(bits) */

 mV */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * AD5446 SPI DAC driver

 *

 * Copyright 2010 Analog Devices Inc.

/**

 * struct ad5446_state - driver instance specific data

 * @dev:		this device

 * @chip_info:		chip model specific constants, available modes etc

 * @reg:		supply regulator

 * @vref_mv:		actual reference voltage used

 * @cached_val:		store/retrieve values during power down

 * @pwr_down_mode:	power down mode (1k, 100k or tristate)

 * @pwr_down:		true if the device is in power down

 * @lock:		lock to protect the data buffer during write ops

/**

 * struct ad5446_chip_info - chip specific information

 * @channel:		channel spec for the DAC

 * @int_vref_mv:	AD5620/40/60: the internal reference voltage

 * @write:		chip specific helper function to write to the register

/*

 * ad5446_supported_spi_device_ids:

 * The AD5620/40/60 parts are available in different fixed internal reference

 * voltage options. The actual part numbers may look differently

 * (and a bit cryptic), however this style is used to make clear which

 * parts are supported here.

 ad5452 is compatible to the ad5444 */

 ad5453 is compatible to the ad5446 */

 ad5541a and ad5542a are compatible */

 ad5541a and ad5543 are compatible */

 AD5620/40/60: */

 part numbers may look differently */

 compatible Texas Instruments chips */

/*

 * ad5446_supported_i2c_device_ids:

 * The AD5620/40/60 parts are available in different fixed internal reference

 * voltage options. The actual part numbers may look differently

 * (and a bit cryptic), however this style is used to make clear which

 * parts are supported here.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  max517.c - Support for Maxim MAX517, MAX518 and MAX519

 *

 *  Copyright (C) 2010, 2011 Roland Stigge <stigge@antcom.de>

 Commands */

 for MAX518 and MAX519 */

 Power Down */

/*

 * channel: bit 0: channel 1

 *          bit 1: channel 2

 * (this way, it's possible to set both channels at once)

 Corresponds to Vref / 2^(bits) */

 single channel for MAX517 */

	/*

	 * Reference voltage on MAX518 and default is 5V, else take vref_mv

	 * from platform_data

 mV */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * mcp4725.c - Support for Microchip MCP4725/6

 *

 * Copyright (C) 2012 Peter Meerwald <pmeerw@pmeerw.net>

 *

 * Based on max517 by Roland Stigge <stigge@antcom.de>

 *

 * driver for the Microchip I2C 12-bit digital-to-analog converter (DAC)

 * (7-bit I2C slave address 0x60, the three LSBs can be configured in

 * hardware)

 restore previous DAC value */

 write EEPROM */

 wait for write complete, takes up to 50ms */

 check if is the vref-supply defined */

 read current DAC value and settings */

 largest resistor to gnd */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5755, AD5755-1, AD5757, AD5735, AD5737 Digital to analog converters driver

 *

 * Copyright 2012 Analog Devices Inc.

/**

 * struct ad5755_chip_info - chip specific information

 * @channel_template:	channel specification

 * @calib_shift:	shift for the calibration data registers

 * @has_voltage_out:	whether the chip has voltage outputs

/**

 * struct ad5755_state - driver instance specific data

 * @spi:	spi device the driver is attached to

 * @chip_info:	chip model specific constants, available modes etc

 * @pwr_down:	bitmask which contains  hether a channel is powered down or not

 * @ctrl:	software shadow of the channel ctrl registers

 * @channels:	iio channel spec for the device

 * @lock:	lock to protect the data buffer during SPI ops

 * @data:	spi transfer buffers

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5624R, AD5644R, AD5664R Digital to analog convertors spi driver

 *

 * Copyright 2010-2011 Analog Devices Inc.

	/*

	 * The input shift register is 24 bits wide. The first two bits are

	 * don't care bits. The next three are the command bits, C2 to C0,

	 * followed by the 3-bit DAC address, A2 to A0, and then the

	 * 16-, 14-, 12-bit data-word. The data-word comprises the 16-,

	 * 14-, 12-bit input code followed by 0, 2, or 4 don't care bits,

	 * for the AD5664R, AD5644R, and AD5624R, respectively.

 Backwards compatibility. This naming is not correct */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5504, AD5501 High Voltage Digital to Analog Converter

 *

 * Copyright 2011 Analog Devices Inc.

 Registers */

 Control Register */

/**

 * struct ad5504_state - driver instance specific data

 * @spi:			spi_device

 * @reg:		supply regulator

 * @vref_mv:		actual reference voltage used

 * @pwr_down_mask:	power down mask

 * @pwr_down_mode:	current power down mode

 * @data:		transfer buffer

/*

 * ad5504_supported_device_ids:

 writes to the CTRL register must be followed by a NOOP */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5415, AD5426, AD5429, AD5432, AD5439, AD5443, AD5449 Digital to Analog

 * Converter driver.

 *

 * Copyright 2012 Analog Devices Inc.

 *  Author: Lars-Peter Clausen <lars@metafoo.de>

/**

 * struct ad5449_chip_info - chip specific information

 * @channels:		Channel specification

 * @num_channels:	Number of channels

 * @has_ctrl:		Chip has a control register

/**

 * struct ad5449 - driver instance specific data

 * @spi:		the SPI device for this driver instance

 * @chip_info:		chip model specific constants, available modes etc

 * @vref_reg:		vref supply regulators

 * @has_sdo:		whether the SDO line is connected

 * @dac_cache:		Cache for the DAC values

 * @data:		spi transfer buffers

 * @lock:		lock to protect the data buffer during SPI ops

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO DAC driver for NXP LPC18xx DAC

 *

 * Copyright (C) 2016 Joachim Eastwood <manabian@gmail.com>

 *

 * UNSUPPORTED hardware features:

 *  - Interrupts

 *  - DMA

 LPC18XX DAC registers and bits */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * DAC7612 Dual, 12-Bit Serial input Digital-to-Analog Converter

 *

 * Copyright 2019 Qtechnology A/S

 * 2019 Ricardo Ribalda <ribalda@kernel.org>

 *

 * Licensed under the GPL-2.

	/*

	 * Lock to protect the state of the device from potential concurrent

	 * write accesses from userspace. The write operation requires an

	 * SPI write, then toggling of a GPIO, so the lock aims to protect

	 * the sanity of the entire sequence of operation.

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

	/*

	 * LOADDACS pin can be controlled by the driver or externally.

	 * When controlled by the driver, the DAC value is updated after

	 * every write.

	 * When the driver does not control the PIN, the user or an external

	 * event can change the value of all DACs by pulsing down the LOADDACs

	 * pin.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5421 Digital to analog converters  driver

 *

 * Copyright 2011 Analog Devices Inc.

/* load dac and fault shared the same register number. Writing to it will cause

 These bits will cause the fault pin to go high */

/**

 * struct ad5421_state - driver instance specific data

 * @spi:		spi_device

 * @ctrl:		control register cache

 * @current_range:	current range which the device is configured for

 * @data:		spi transfer buffers

 * @fault_mask:		software masking of events

 * @lock:		lock to protect the data buffer during SPI ops

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

	/* If we had a fault, this might mean that the DAC has lost its state

	 * and has been reset. Make sure that the control register actually

	 * contains what we expect it to contain. Otherwise the watchdog might

	 * be enabled and we get watchdog timeout faults, which will render the

	/* The fault pin stays high as long as a fault condition is present and

	 * it is not possible to mask fault conditions. For certain fault

	 * conditions for example like over-temperature it takes some time

	 * until the fault condition disappears. If we would exit the interrupt

	 * handler immediately after handling the event it would be entered

	 * again instantly. Thus we fall back to polling in case we detect that

	 * a interrupt condition is still present.

		/* 0xffff is a invalid value for the register and will only be

 we are only interested in new events */

 still active? go to sleep for some time */

	/* The current range is configured using external pins, which are

 write initial ctrl register value */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5024, AD5025, AD5044, AD5045, AD5064, AD5064-1, AD5065, AD5625, AD5625R,

 * AD5627, AD5627R, AD5628, AD5629R, AD5645R, AD5647R, AD5648, AD5665, AD5665R,

 * AD5666, AD5667, AD5667R, AD5668, AD5669R, LTC2606, LTC2607, LTC2609, LTC2616,

 * LTC2617, LTC2619, LTC2626, LTC2627, LTC2629, LTC2631, LTC2633, LTC2635

 * Digital to analog converters driver

 *

 * Copyright 2011 Analog Devices Inc.

/**

 * enum ad5064_regmap_type - Register layout variant

 * @AD5064_REGMAP_ADI: Old Analog Devices register map layout

 * @AD5064_REGMAP_ADI2: New Analog Devices register map layout

 * @AD5064_REGMAP_LTC: LTC register map layout

/**

 * struct ad5064_chip_info - chip specific information

 * @shared_vref:	whether the vref supply is shared between channels

 * @internal_vref:	internal reference voltage. 0 if the chip has no

 *			internal vref.

 * @channels:		channel specification

 * @num_channels:	number of channels

 * @regmap_type:	register map layout variant

/**

 * struct ad5064_state - driver instance specific data

 * @dev:		the device for this driver instance

 * @chip_info:		chip model specific constants, available modes etc

 * @vref_reg:		vref supply regulators

 * @pwr_down:		whether channel is powered down

 * @pwr_down_mode:	channel's current power down mode

 * @dac_cache:		current DAC raw value (chip does not support readback)

 * @use_internal_vref:	set to true if the internal reference voltage should be

 *			used.

 * @write:		register write callback

 * @lock:		maintain consistency between cached and dev state

 * @data:		i2c/spi transfer buffers

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

	/*

	 * This assumes that when the regulator has an internal VREF

	 * there is only one external VREF connection, which is

	 * currently the case for all supported devices.

 If no external regulator was supplied use the internal VREF */

 similar enough to ad5668-2 */

 similar enough to ad5629-2 */

 similar enough to ad5669-2 */

 SPDX-License-Identifier: GPL-2.0

/*

 * This file is part of STM32 DAC driver

 *

 * Copyright (C) 2017, STMicroelectronics - All Rights Reserved

 * Author: Fabrice Gasnier <fabrice.gasnier@st.com>.

 *

/**

 * struct stm32_dac_priv - stm32 DAC core private data

 * @pclk:		peripheral clock common for all DACs

 * @vref:		regulator reference

 * @common:		Common data for all DAC instances

/**

 * struct stm32_dac_cfg - DAC configuration

 * @has_hfsel: DAC has high frequency control

 When clock speed is higher than 80MHz, set HFSEL */

 restore hfsel (maybe lost under low power state) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD7303 Digital to analog converters driver

 *

 * Copyright 2013 Analog Devices Inc.

/**

 * struct ad7303_state - driver instance specific data

 * @spi:		the device for this driver instance

 * @config:		cached config register value

 * @dac_cache:		current DAC raw value (chip does not support readback)

 * @vdd_reg:		reference to VDD regulator

 * @vref_reg:		reference to VREF regulator

 * @lock:		protect writes and cache updates

 * @data:		spi transfer buffer

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

	/* There is no noop cmd which allows us to only update the powerdown

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO DAC driver for Analog Devices AD8801 DAC

 *

 * Copyright (C) 2016 Gwenhael Goavec-Merou

 Value write on each channel */

 SPDX-License-Identifier: GPL-2.0

/*

 * IIO DAC emulation driver using a digital potentiometer

 *

 * Copyright (C) 2016 Axentia Technologies AB

 *

 * Author: Peter Rosin <peda@axentia.se>

/*

 * It is assumed that the dpot is used as a voltage divider between the

 * current dpot wiper setting and the maximum resistance of the dpot. The

 * divided voltage is provided by a vref regulator.

 *

 *                   .------.

 *    .-----------.  |      |

 *    | vref      |--'    .---.

 *    | regulator |--.    |   |

 *    '-----------'  |    | d |

 *                   |    | p |

 *                   |    | o |  wiper

 *                   |    | t |<---------+

 *                   |    |   |

 *                   |    '---'       dac output voltage

 *                   |      |

 *                   '------+------------+

			/*

			 * Convert integer scale to fractional scale by

			 * setting the denominator (val2) to one...

 ...and fall through. Say it again for GCC. */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * AD5672R, AD5674R, AD5676, AD5676R, AD5679R,

 * AD5681R, AD5682R, AD5683, AD5683R, AD5684,

 * AD5684R, AD5685R, AD5686, AD5686R

 * Digital to analog converters driver

 *

 * Copyright 2018 Analog Devices Inc.

 Does not exist */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Analog Devices AD5766, AD5767

 * Digital to Analog Converters driver

 * Copyright 2019-2020 Analog Devices Inc.

/**

 * struct ad5766_chip_info - chip specific information

 * @num_channels:	number of channels

 * @channels:	        channel specification

/*

 * Dither signal can also be scaled.

 * Available dither scale strings corresponding to "dither_scale" field in

 * "struct ad5766_state".

/**

 * struct ad5766_state - driver instance specific data

 * @spi:		SPI device

 * @lock:		Lock used to restrict concurrent access to SPI device

 * @chip_info:		Chip model specific constants

 * @gpio_reset:		Reset GPIO, used to reset the device

 * @crt_range:		Current selected output range

 * @dither_enable:	Power enable bit for each channel dither block (for

 *			example, D15 = DAC 15,D8 = DAC 8, and D0 = DAC 0)

 *			0 - Normal operation, 1 - Power down

 * @dither_invert:	Inverts the dither signal applied to the selected DAC

 *			outputs

 * @dither_source:	Selects between 2 possible sources:

 *			1: N0, 2: N1

 *			Two bits are used for each channel

 * @dither_scale:	Two bits are used for each of the 16 channels:

 *			0: 1 SCALING, 1: 0.75 SCALING, 2: 0.5 SCALING,

 *			3: 0.25 SCALING.

 * @data:		SPI transfer buffers

 t_reset >= 100ns */

	/*

	 * Minimum time between a reset and the subsequent successful write is

	 * typically 25 ns

 Always issue a reset before writing to the span register. */

 Dither power down */

 Configure trigger buffer */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ti-dac5571.c - Texas Instruments 8/10/12-bit 1/4-channel DAC driver

 *

 * Copyright (C) 2018 Prevas A/S

 *

 * https://www.ti.com/lit/ds/symlink/dac5571.pdf

 * https://www.ti.com/lit/ds/symlink/dac6571.pdf

 * https://www.ti.com/lit/ds/symlink/dac7571.pdf

 * https://www.ti.com/lit/ds/symlink/dac5574.pdf

 * https://www.ti.com/lit/ds/symlink/dac6574.pdf

 * https://www.ti.com/lit/ds/symlink/dac7574.pdf

 * https://www.ti.com/lit/ds/symlink/dac5573.pdf

 * https://www.ti.com/lit/ds/symlink/dac6573.pdf

 * https://www.ti.com/lit/ds/symlink/dac7573.pdf

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * mcp4922.c

 *

 * Driver for Microchip Digital to Analog Converters.

 * Supports MCP4902, MCP4912, and MCP4922.

 *

 * Copyright (c) 2014 EMAC Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * AD5686R, AD5685R, AD5684R Digital to analog converters  driver

 *

 * Copyright 2011 Analog Devices Inc.

 AD5674R/AD5679R have 16 channels and 2 powerdown registers */

 Set all the power down mode for all channels to 1K pulldown */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Analog devices AD5360, AD5361, AD5362, AD5363, AD5370, AD5371, AD5373

 * multi-channel Digital to Analog Converters driver

 *

 * Copyright 2011 Analog Devices Inc.

 Special function register addresses */

/**

 * struct ad5360_chip_info - chip specific information

 * @channel_template:	channel specification template

 * @num_channels:	number of channels

 * @channels_per_group:	number of channels per group

 * @num_vrefs:		number of vref supplies for the chip

/**

 * struct ad5360_state - driver instance specific data

 * @spi:		spi_device

 * @chip_info:		chip model specific constants, available modes etc

 * @vref_reg:		vref supply regulators

 * @ctrl:		control register cache

 * @lock:		lock to protect the data buffer during SPI ops

 * @data:		spi transfer buffers

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

	/* The first groups have their own vref, while the remaining groups

		/* offset is supposed to have the same scale as raw, but it

		 * is always 14bits wide, so on a chip where the raw value has

		/* There is one DAC offset register per vref. Changing one

		 * channels offset will also change the offset for all other

 vout = 4 * vref * dac_code */

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for Linear Technology LTC1665/LTC1660, 8 channels DAC

 *

 * Copyright (C) 2018 Marcus Folkesson <marcus.folkesson@gmail.com>

 Convert to mV */

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ti-dac082s085.c - Texas Instruments 8/10/12-bit 2/4-channel DAC driver

 *

 * Copyright (C) 2017 KUNBUS GmbH

 *

 * https://www.ti.com/lit/ds/symlink/dac082s085.pdf

 * https://www.ti.com/lit/ds/symlink/dac102s085.pdf

 * https://www.ti.com/lit/ds/symlink/dac122s085.pdf

 * https://www.ti.com/lit/ds/symlink/dac084s085.pdf

 * https://www.ti.com/lit/ds/symlink/dac104s085.pdf

 * https://www.ti.com/lit/ds/symlink/dac124s085.pdf

/**

 * struct ti_dac_chip - TI DAC chip

 * @lock: protects write sequences

 * @vref: regulator generating Vref

 * @mesg: SPI message to perform a write

 * @xfer: SPI transfer used by @mesg

 * @val: cached value of each output

 * @powerdown: whether the chip is powered down

 * @powerdown_mode: selected by the user

 * @resolution: resolution of the chip

 * @buf: buffer for @xfer

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale Vybrid vf610 DAC driver

 *

 * Copyright 2016 Toradex AG

		/*

		 * DACRFS is always 1 for valid reference and typical

		 * reference voltage as per Vybrid datasheet is 3.3V

		 * from section 9.1.2.1 of Vybrid datasheet

 mV */;

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * LTC2632 Digital to analog convertors spi driver

 *

 * Copyright 2017 Maxime Roussin-Blanger

 * expanded by Silvan Murer <silvan.murer@gmail.com>

/**

 * struct ltc2632_chip_info - chip specific information

 * @channels:		channel spec for the DAC

 * @num_channels:	DAC channel count of the chip

 * @vref_mv:		internal reference voltage

/**

 * struct ltc2632_state - driver instance specific data

 * @spi_dev:			pointer to the spi_device struct

 * @powerdown_cache_mask:	used to show current channel powerdown state

 * @vref_mv:			used reference voltage (internal or external)

 * @vref_reg:		regulator for the reference voltage

	/*

	 * The input shift register is 24 bits wide.

	 * The next four are the command bits, C3 to C0,

	 * followed by the 4-bit DAC address, A3 to A0, and then the

	 * 12-, 10-, 8-bit data-word. The data-word comprises the 12-,

	 * 10-, 8-bit input code followed by 4, 6, or 8 don't care bits.

 use internal reference voltage */

 use external reference voltage */

 SPDX-License-Identifier: GPL-2.0

/* ti-dac7311.c - Texas Instruments 8/10/12-bit 1-channel DAC driver

 *

 * Copyright (C) 2018 CMC NV

 *

 * https://www.ti.com/lit/ds/symlink/dac7311.pdf

/**

 * struct ti_dac_chip - TI DAC chip

 * @lock: protects write sequences

 * @vref: regulator generating Vref

 * @spi: SPI device to send data to the device

 * @val: cached value

 * @powerdown: whether the chip is powered down

 * @powerdown_mode: selected by the user

 * @resolution: resolution of the chip

 * @buf: buffer for transfer data

 SPDX-License-Identifier: GPL-2.0+

/*

 * AD5770R Digital to analog converters driver

 *

 * Copyright 2018 Analog Devices Inc.

 ADI_SPI_IF_CONFIG_A */

 ADI_SPI_IF_CONFIG_B */

 ADI_SPI_IF_CONFIG_C */

 AD5770R configuration registers */

 AD5770R_CHANNEL_CONFIG */

 AD5770R_OUTPUT_RANGE */

 AD5770R_REFERENCE */

 AD5770R_CH_ENABLE */

/**

 * struct ad5770r_state - driver instance specific data

 * @spi:		spi_device

 * @regmap:		regmap

 * @vref_reg:		fixed regulator for reference configuration

 * @gpio_reset:		gpio descriptor

 * @output_mode:	array contains channels output ranges

 * @vref:		reference value

 * @ch_pwr_down:	powerdown flags

 * @internal_ref:	internal reference flag

 * @external_res:	external 2.5k resistor flag

 * @transf_buf:		cache aligned buffer for spi read/write

 Perform software reset if no GPIO provided */

 data must not be written during reset timeframe */

		/* There is no sign bit. (negative current is mapped from 0)

		 * (sourced/sinked) current = raw * scale + offset

		 * where offset in case of CH0 can be negative.

 Perform a reset */

 Set output range */

 Set outputs off */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Analog devices AD5764, AD5764R, AD5744, AD5744R quad-channel

 * Digital to Analog Converters driver

 *

 * Copyright 2011 Analog Devices Inc.

/**

 * struct ad5764_chip_info - chip specific information

 * @int_vref:	Value of the internal reference voltage in uV - 0 if external

 *		reference voltage is used

 * @channels:	channel specification

/**

 * struct ad5764_state - driver instance specific data

 * @spi:		spi_device

 * @chip_info:		chip info

 * @vref_reg:		vref supply regulators

 * @lock:		lock to protect the data buffer during SPI ops

 * @data:		spi transfer buffers

	/*

	 * DMA (thus cache coherency maintenance) requires the

	 * transfer buffers to live in their own cache lines.

 vout = 4 * vref + ((dac_code / 65536) - 0.5) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5592R Digital <-> Analog converters driver

 *

 * Copyright 2014-2016 Analog Devices Inc.

 * Author: Paul Cercueil <paul.cercueil@analog.com>

 Writing this magic value resets the device */

 Default to input */

 Pull down unused pins to GND */

 Configure pins that we use */

 Verify that we can read back at least one register */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AD5593R Digital <-> Analog converters driver

 *

 * Copyright 2015-2016 Analog Devices Inc.

 * Author: Paul Cercueil <paul.cercueil@analog.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Analog devices AD5380, AD5381, AD5382, AD5383, AD5390, AD5391, AD5392

 * multi-channel Digital to Analog Converters driver

 *

 * Copyright 2011 Analog Devices Inc.

/**

 * struct ad5380_chip_info - chip specific information

 * @channel_template:	channel specification template

 * @num_channels:	number of channels

 * @int_vref:		internal vref in uV

/**

 * struct ad5380_state - driver instance specific data

 * @regmap:		regmap instance used by the device

 * @chip_info:		chip model specific constants, available modes etc

 * @vref_reg:		vref supply regulator

 * @vref:		actual reference voltage used in uA

 * @pwr_down:		whether the chip is currently in power down mode

 * @lock:		lock to protect the data buffer during regmap ops

 SPDX-License-Identifier: GPL-2.0

/*

 * This file is part of STM32 DAC driver

 *

 * Copyright (C) 2017, STMicroelectronics - All Rights Reserved

 * Authors: Amelie Delaunay <amelie.delaunay@st.com>

 *	    Fabrice Gasnier <fabrice.gasnier@st.com>

/**

 * struct stm32_dac - private data of DAC driver

 * @common:		reference to DAC common data

 * @lock:		lock to protect against potential races when reading

 *			and update CR, to keep it in sync with pm_runtime

 already enabled / disabled ? */

	/*

	 * When HFSEL is set, it is not allowed to write the DHRx register

	 * during 8 clock cycles after the ENx bit is set. It is not allowed

	 * to make software/hardware trigger during this period either.

 scan_index is always 0 as num_channels is 1 */ \

	/*

	 * Expose only one channel here, as they can be used independently,

	 * with separate trigger. Then separate IIO devices are instantiated

	 * to manage this.

 Get stm32-dac-core PM online */

 Ensure DAC is disabled before suspend */

 SPDX-License-Identifier: GPL-2.0

/*

 * AD5758 Digital to analog converters driver

 *

 * Copyright 2018 Analog Devices Inc.

 *

 * TODO: Currently CRC is not supported in this driver

 AD5758 registers definition */

 AD5758_DAC_CONFIG */

 AD5758_KEY */

 AD5758_DCDC_CONFIG1 */

 AD5758_DCDC_CONFIG2 */

 AD5758_DIGITAL_DIAG_RESULTS */

 AD5758_ADC_CONFIG */

/**

 * struct ad5758_state - driver instance specific data

 * @spi:	spi_device

 * @lock:	mutex lock

 * @gpio_reset:	gpio descriptor for the reset line

 * @out_range:	struct which stores the output range

 * @dc_dc_mode:	variable which stores the mode of operation

 * @dc_dc_ilim:	variable which stores the dc-to-dc converter current limit

 * @slew_time:	variable which stores the target slew time

 * @pwr_down:	variable which contains whether a channel is powered down or not

 * @d32:	spi transfer buffers

/*

 * Output ranges corresponding to bits [3:0] from DAC_CONFIG register

 * 0000: 0 V to 5 V voltage range

 * 0001: 0 V to 10 V voltage range

 * 0010: 5 V voltage range

 * 0011: 10 V voltage range

 * 1000: 0 mA to 20 mA current range

 * 1001: 0 mA to 24 mA current range

 * 1010: 4 mA to 20 mA current range

 * 1011: 20 mA current range

 * 1100: 24 mA current range

 * 1101: -1 mA to +22 mA current range

 Wait to allow time for the internal calibrations to complete */

 Perform a software reset and wait at least 100us */

	/*

	 * The ENABLE_PPC_BUFFERS bit must be set prior to enabling PPC current

	 * mode.

	/*

	 * Poll the BUSY_3WI bit in the DCDC_CONFIG2 register until it is 0.

	 * This allows the 3-wire interface communication to complete.

	/*

	 * Poll the BUSY_3WI bit in the DCDC_CONFIG2 register until it is 0.

	 * This allows the 3-wire interface communication to complete.

 Wait to allow time for the internal calibrations to complete */

	/*

	 * The slew time can be determined by using the formula:

	 * Slew Time = (Full Scale Out / (Step Size x Update Clk Freq))

	 * where Slew time is expressed in microseconds

	 * Given the desired slew time, the following algorithm determines the

	 * best match for the step size and the update clock frequency.

		/*

		 * Go through each valid update clock freq and determine a raw

		 * value for the step size by using the formula:

		 * Step Size = Full Scale Out / (Update Clk Freq * Slew Time)

		/*

		 * After a raw value for step size was determined, find the

		 * closest valid match

 Calculate the slew time */

		/*

		 * Determine with how many microseconds the calculated slew time

		 * is different from the desired slew time and store the diff

		 * for the next iteration

 Wait to allow time for the internal calibrations to complete */

 Wait to allow time for the internal calibrations to complete */

 Perform a software reset */

 Disable CRC checks */

 Perform a reset */

 Disable CRC checks */

 Perform a calibration memory refresh */

 Clear all the error flags */

 Set the dc-to-dc current limit */

 Configure the dc-to-dc controller mode */

 Configure the output range */

 Enable Slew Rate Control, set the slew rate clock and step */

 Power up the DAC and internal (INT) amplifiers */

 Enable VIOUT */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ADXL355 3-Axis Digital Accelerometer I2C driver

 *

 * Copyright (c) 2021 Puranjay Mohan <puranjay12@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Sensortek STK8BA50 3-Axis Accelerometer

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * STK8BA50 7-bit I2C address: 0x18.

/*

 * The accelerometer has four measurement ranges:

 * +/-2g; +/-4g; +/-8g; +/-16g

 *

 * Acceleration values are 10-bit, 2's complement.

 * Scales are calculated as following:

 *

 * scale1 = (2 + 2) * 9.81 / (2^10 - 1)   = 0.0384

 * scale2 = (4 + 4) * 9.81 / (2^10 - 1)   = 0.0767

 * etc.

 *

 * Scales are stored in this format:

 * { <register value>, <scale value> }

 *

 * Locally, the range is stored as a table index.

 Sample rates are stored as { <register value>, <Hz value> } */

 Used to map scan mask bits to their corresponding channel register. */

 Ensure timestamp is naturally aligned */

	/*

	 * Do a bulk read if all channels are requested,

	 * from 0x02 (XOUT1) to 0x07 (ZOUT2)

 Reset all registers on startup */

 The default range is +/-2g */

 The default sampling rate is 1792 Hz (maximum) */

 Set up interrupts */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * 3-axis accelerometer driver supporting SPI Bosch-Sensortec accelerometer chip

 * Copyright  2015 Pengutronix, Markus Pargmann <mpa@pengutronix.de>

 SPDX-License-Identifier: GPL-2.0

/*

 * NXP FXLS8962AF/FXLS8964AF Accelerometer SPI Driver

 *

 * Copyright 2021 Connected Cars A/S

 SPDX-License-Identifier: GPL-2.0

/*

 * NXP FXLS8962AF/FXLS8964AF Accelerometer I2C Driver

 *

 * Copyright 2021 Connected Cars A/S

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ADXL345 3-Axis Digital Accelerometer IIO core driver

 *

 * Copyright (c) 2017 Eva Rachel Retuya <eraretuya@gmail.com>

 *

 * Datasheet: https://www.analog.com/media/en/technical-documentation/data-sheets/ADXL345.pdf

 Up to 13-bits resolution */

/*

 * In full-resolution mode, scale factor is maintained at ~4 mg/LSB

 * in all g ranges.

 *

 * At +/- 16g with 13-bit resolution, scale is computed as:

 * (16 + 16) * 9.81 / (2^13 - 1) = 0.0383

/*

 * The Datasheet lists a resolution of Resolution is ~49 mg per LSB. That's

 * ~480mm/s**2 per LSB.

		/*

		 * Data is stored in adjacent registers:

		 * ADXL345_REG_DATA(X0/Y0/Z0) contain the least significant byte

		 * and ADXL345_REG_DATA(X0/Y0/Z0) + 1 the most significant byte

		/*

		 * 8-bit resolution at +/- 2g, that is 4x accel data scale

		 * factor

		/*

		 * 8-bit resolution at +/- 2g, that is 4x accel data scale

		 * factor

 Enable full-resolution mode */

 Enable measurement mode */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO driver for Domintech DMARD06 accelerometer

 *

 * Copyright (C) 2016 Aleksei Mamlin <mamlinav@gmail.com>

 Device data registers */

 Device ID value */

 Device values */

 Device power modes */

 Device channels */

 SPDX-License-Identifier: GPL-2.0

/*

 * NXP FXLS8962AF/FXLS8964AF Accelerometer Core Driver

 *

 * Copyright 2021 Connected Cars A/S

 *

 * Datasheet:

 * https://www.nxp.com/docs/en/data-sheet/FXLS8962AF.pdf

 * https://www.nxp.com/docs/en/data-sheet/FXLS8964AF.pdf

 *

 * Errata:

 * https://www.nxp.com/docs/en/errata/ES_FXLS8962AF.pdf

 Raw temp channel offset */

 Only used in hw fifo mode. */

 Enable wakeup interrupt */

 Enable events */

	/*

	 * Enable update of SDCD_REF_X/Y/Z values with the current decimated and

	 * trimmed X/Y/Z acceleration input data. This allows for acceleration

	 * slope detection with Data(n) to Data(n1) always used as the input

	 * to the window comparator.

 Not in buffered mode so disable power */

 TBOOT1, TBOOT2, specifies we have to wait between 1 - 17.7ms */

 Enable watermark at max fifo size */

 Enable buffer interrupt */

 Disable buffer interrupt */

		/*

		 * Due to errata bug:

		 * E3: FIFO burst read operation error using I2C interface

		 * We have to avoid burst reads on I2C..

	/*

	 * Approximate timestamps for each of the sample based on the sampling,

	 * frequency, timestamp for last sample and number of samples.

 Demux hw FIFO into kfifo. */

		/*

		 * Disable buffer, as the buffer is so small the device will wake

		 * almost immediately.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Freescale MMA7660FC 3-Axis Accelerometer

 *

 * Copyright (c) 2016, Intel Corporation.

 *

 * IIO driver for Freescale MMA7660FC; 7-bit I2C address: 0x4c.

/*

 * The accelerometer has one measurement range:

 *

 * -1.5g - +1.5g (6-bit, signed)

 *

 * scale = (1.5 + 1.5) * 9.81 / (2^6 - 1)	= 0.467142857

	/*

	 * Read data. If the Alert bit is set, the register was read at

	 * the same time as the device was attempting to update the content.

	 * The solution is to read the register again. Do this only

	 * MMA7660_I2C_READ_RETRIES times to avoid spending too much time

	 * in the kernel.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * kxsd9.c	simple support for the Kionix KXSD9 3D

 *		accelerometer.

 *

 * Copyright (c) 2008-2009 Jonathan Cameron <jic23@kernel.org>

 *

 * The i2c interface is very similar, so shouldn't be a problem once

 * I have a suitable wire made up.

 *

 * TODO:	Support the motion detector

 Self-test */

/**

 * struct kxsd9_state - device related storage

 * @dev: pointer to the parent device

 * @map: regmap to the device

 * @orientation: mounting matrix, flipped axis etc

 * @regs: regulators for this device, VDD and IOVDD

 * @scale: the current scaling setting

 reverse order */

/*

 * Regulator names

 Cached scale when the sensor is powered down */

 Check no integer component */

 Only 12 bits are valid */

 This has a bias of -2048 */

	/*

	 * Ensure correct positioning and alignment of timestamp.

	 * No need to zero initialize as all elements written.

 Enable the regulators */

 Power up */

	/*

	 * Set 1000Hz LPF, 2g fullscale, motion wakeup threshold 1g,

	 * latched wakeup

	/*

	 * Power-up time depends on the LPF setting, but typ 15.9 ms, let's

	 * set 20 ms to allow for some slack.

	/*

	 * Set into low power mode - since there may be more users of the

	 * regulators this is the first step of the power saving: it will

	 * make sure we conserve power even if there are others users on the

	 * regulators.

 Disable the regulators */

 Four channels apart from timestamp, scan mask = 0x0f */

 Read the mounting matrix, if present */

 Fetch and turn on regulators */

 Default scaling */

 Enable runtime PM */

	/*

	 * Set autosuspend to two orders of magnitude larger than the

	 * start-up time. 20ms start-up time means 2000ms autosuspend,

	 * i.e. 2 seconds.

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Sensortek STK8312 3-Axis Accelerometer

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * IIO driver for STK8312; 7-bit I2C address: 0x3D.

 active-high, push-pull */

/*

 * The accelerometer has two measurement ranges:

 *

 * -6g - +6g (8-bit, signed)

 * -16g - +16g (8-bit, signed)

 *

 * scale1 = (6 + 6) * 9.81 / (2^8 - 1)     = 0.4616

 * scale2 = (16 + 16) * 9.81 / (2^8 - 1)   = 1.2311

 Ensure timestamp is naturally aligned */

 Need to run OTP sequence before entering active mode */

 We need to go in standby mode to modify registers */

 We need to go in standby mode to modify registers */

 We need to go in standby mode to modify registers */

	/*

	 * Do a bulk read if all channels are requested,

	 * from 0x00 (XOUT) to 0x02 (ZOUT)

 A software reset is recommended at power-on */

 Deprecated in favour of lowercase form */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * mCube MC3230 3-Axis Accelerometer

 *

 * Copyright (c) 2016 Hans de Goede <hdegoede@redhat.com>

 *

 * IIO driver for mCube MC3230; 7-bit I2C address: 0x4c.

/*

 * The accelerometer has one measurement range:

 *

 * -1.5g - +1.5g (8-bit, signed)

 *

 * scale = (1.5 + 1.5) * 9.81 / (2^8 - 1)	= 0.115411765

 First check chip-id and product-id */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * KXCJK-1013 3-axis accelerometer driver

 * Copyright (c) 2014, Intel Corporation.

/*

 * From low byte X axis register, all the other addresses of Y and Z can be

 * obtained by just applying axis offset. The following axis defines are just

 * provide clarity, but not used.

 Everything up to 0x11 is equal to KXCJK1013/KXTF9 above */

 KXTF9 */

 KXTF9 */

 KXTF9 */

 KXCJK: INT_SOURCE2: motion detect, KXTF9: INT_SRC_REG1: tap detect */

 KX023 interrupt routing to INT1. INT2 can be configured with INC6 */

 this must be last */

 .int_src1 was moved to INT_SRC2 on KXTF9 */

 .int_src2 is not available */

 The registers have totally different names but the bits are compatible */

 Ensure timestamp naturally aligned */

 Refer to section 4 of the specification */

 KXCJK-1013 */

 KXCJ9-1008 */

 KXCTJ2-1009 */

 KXTF9 */

 KX023-1025 */

 First 4 are not in datasheet, taken from KXCTJ2-1009 */

 Make sure the kbd and touchpad on 2-in-1s using 2 KXCJ91008-s work */

 Set 12 bit mode */

 Setting range to 4G */

 Set up INT polarity */

 On KX023, route all used interrupts to INT1 for now */

 This is requirement by spec to change state to STANDBY */

 This is requirement by spec to change state to STANDBY */

 To change ODR, the chip must be set to STANDBY as per spec */

	/*

	 * We will expect the enable and disable to do operation in

	 * in reverse order. This will happen here anyway as our

	 * resume operation uses sync mode runtime pm calls, the

	 * suspend operation will be delayed by autosuspend delay

	 * So the disable operation will still happen in reverse of

	 * enable operation. When runtime pm is disabled the mode

	 * is always on so sequence doesn't matter

 default polarity */

	/*

	 * A typical delay of 10ms is required for powering up

	 * according to the data sheets of supported chips.

	 * Hence double that to play safe.

 KXCJ91008 in the display of a yoga 2-in-1 */

 KXCJ91008 in the base of a yoga 2-in-1 */

 SPDX-License-Identifier: GPL-2.0

/*

 * 3-axis accelerometer driver supporting following Bosch-Sensortec chips:

 *  - BMI088

 *

 * Copyright (c) 2018-2020, Topic Embedded Products

 Write register is same as generic SPI */

 Set RW = '1' */

 Read requires a dummy byte transfer */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics accelerometers driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 An older compatible */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics accelerometers driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

/*

 * For new single-chip sensors use <device_name> as compatible string.

 * For old single-chip devices keep <device_name>-accel to maintain

 * compatibility

 An older compatible */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO accel SPI driver for Freescale MMA7455L 3-axis 10-bit accelerometer

 * Copyright 2015 Joachim Eastwood <manabian@gmail.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * ADIS16201 Dual-Axis Digital Inclinometer and Accelerometer

 *

 * Copyright 2010 Analog Devices Inc.

 Data Output Register Information */

 Calibration Register Definition */

 Alarm Register Definition */

 Operation, filter configuration */

 Miscellaneous Control Register Definition */

 Data-ready enable: 1 = enabled, 0 = disabled */

 Data-ready polarity: 1 = active high, 0 = active low */

 Data-ready line selection: 1 = DIO1, 0 = DIO0 */

 Diagnostics System Status Register Definition */

 Power supply above 3.625 V */

 Power supply below 2.975 V */

 System Command Register Definition */

 Voltage base units are mV hence 1.22 mV */

 Voltage base units are mV hence 0.61 mV */

			/*

			 * IIO base unit for sensitivity of accelerometer

			 * is milli g.

			 * 1 LSB represents 0.244 mg.

		/*

		 * The raw ADC value is 1278 when the temperature

		 * is 25 degrees and the scale factor per milli

		 * degree celcius is -470.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ADXL313 3-Axis Digital Accelerometer

 *

 * Copyright (c) 2021 Lucas Stankus <lucas.p.stankus@gmail.com>

 *

 * Datasheet: https://www.analog.com/media/en/technical-documentation/data-sheets/ADXL313.pdf

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ADXL355 3-Axis Digital Accelerometer SPI driver

 *

 * Copyright (c) 2021 Puranjay Mohan <puranjay12@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Freescale MMA9551L Intelligent Motion-Sensing Platform driver

 * Copyright (c) 2014, Intel Corporation.

 Tilt application (inclination in IIO terms). */

 Hz */

 Tilt events are mapped to the first three GPIO pins. */

 IIO counts axes from 1, because IIO_NO_MOD is 0. */

 IIO counts axes from 1, because IIO_NO_MOD is 0. */

 Bit 7 of each angle register holds the angle flag. */

 IRQ was triggered on 4th line, which we don't use. */

	/*

	 * Read the angle even though we don't use it, otherwise we

	 * won't get any further interrupts.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ADXL313 3-Axis Digital Accelerometer

 *

 * Copyright (c) 2021 Lucas Stankus <lucas.p.stankus@gmail.com>

 *

 * Datasheet: https://www.analog.com/media/en/technical-documentation/data-sheets/ADXL313.pdf

 lock to protect transf_buf */

		/*

		 * Scale for any g range is given in datasheet as

		 * 1024 LSB/g = 0.0009765625 * 9.80665 = 0.009576806640625 m/s^2

		/*

		 * 8-bit resolution at +/- 0.5g, that is 4x accel data scale

		 * factor at full resolution

		/*

		 * 8-bit resolution at +/- 0.5g, that is 4x accel data scale

		 * factor at full resolution

 Ensures the device is in a consistent state after start up */

 Sets the range to +/- 4g */

 Enables full resolution */

 Enables measurement mode */

/**

 * adxl313_core_probe() - probe and setup for adxl313 accelerometer

 * @dev:	Driver model representation of the device

 * @regmap:	Register map of the device

 * @name:	Device name buffer reference

 * @setup:	Setup routine to be executed right before the standard device

 *		setup, can also be set to NULL if not required

 *

 * Return: 0 on success, negative errno on error cases

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 3-axis accelerometer driver supporting many Bosch-Sensortec chips

 * Copyright (c) 2014, Intel Corporation.

 Default BW: 125Hz */

 Slope duration in terms of number of samples */

 in terms of multiples of g's/LSB, based on range */

 Sleep Duration values */

/*

 * Support for getting accelerometer information from BOSC0200 ACPI nodes.

 *

 * There are 2 variants of the BOSC0200 ACPI node. Some 2-in-1s with 360 degree

 * hinges declare 2 I2C ACPI-resources for 2 accelerometers, 1 in the display

 * and 1 in the base of the 2-in-1. On these 2-in-1s the ROMS ACPI object

 * contains the mount-matrix for the sensor in the display and ROMK contains

 * the mount-matrix for the sensor in the base. On devices using a single

 * sensor there is a ROTM ACPI object which contains the mount-matrix.

 *

 * Here is an incomplete list of devices known to use 1 of these setups:

 *

 * Yoga devices with 2 accelerometers using ROMS + ROMK for the mount-matrices:

 * Lenovo Thinkpad Yoga 11e 3th gen

 * Lenovo Thinkpad Yoga 11e 4th gen

 *

 * Tablets using a single accelerometer using ROTM for the mount-matrix:

 * Chuwi Hi8 Pro (CWI513)

 * Chuwi Vi8 Plus (CWI519)

 * Chuwi Hi13

 * Irbis TW90

 * Jumper EZpad mini 3

 * Onda V80 plus

 * Predia Basic Tablet

 DUAL250E fwnodes have no mount matrix info */

 data ready interrupt */

 motion interrupt */

 fifo watermark interrupt */

 data ready interrupt */

 motion interrupt */

 fifo watermark interrupt */

	/*

	 * For now we map all interrupts to the same output pin.

	 * However, some boards may have just INT2 (and not INT1) connected,

	 * so we try to detect which IRQ it is based on the interrupt-names.

	 * Without interrupt-names, we assume the irq belongs to INT1.

	/*

	 * We will expect the enable and disable to do operation in reverse

	 * order. This will happen here anyway, as our resume operation uses

	 * sync mode runtime pm calls. The suspend operation will be delayed

	 * by autosuspend delay.

	 * So the disable operation will still happen in reverse order of

	 * enable operation. When runtime pm is disabled the mode is always on,

	 * so sequence doesn't matter.

 map the interrupt to the appropriate pins */

 enable/disable the interrupt */

/*

 * We must read at least one full frame in one burst, otherwise the rest of the

 * frame data is discarded.

	/*

	 * If we getting called from IRQ handler we know the stored timestamp is

	 * fairly accurate for the last stored sample. Otherwise, if we are

	 * called as a result of a read operation from userspace and hence

	 * before the watermark interrupt was triggered, take a timestamp

	 * now. We can fall anywhere in between two samples so the error in this

	 * case is at most one sample period.

	/*

	 * Approximate timestamps for each of the sample based on the sampling

	 * frequency, timestamp for last sample and number of samples.

	 *

	 * Note that we can't use the current bandwidth settings to compute the

	 * sample period because the sample rate varies with the device

	 * (e.g. between 31.70ms to 32.20ms for a bandwidth of 15.63HZ). That

	 * small variation adds when we store a large number of samples and

	 * creates significant jitter between the last and first samples in

	 * different batches (e.g. 32ms vs 21ms).

	 *

	 * To avoid this issue we compute the actual sample period ourselves

	 * based on the timestamp delta between the last two flush operations.

	/*

	 * Ideally we want the IIO core to handle the demux when running in fifo

	 * mode but not when running in triggered buffer mode. Unfortunately

	 * this does not seem to be possible, so stick with driver demux for

	 * now.

/*

 * The range for the Bosch sensors is typically +-2g/4g/8g/16g, distributed

 * over the amount of bits (see above). The scale table can be calculated using

 *     (range / 2^bits) * g = (range / 2^bits) * 9.80665 m/s^2

 * e.g. for +-2g and 12 bits: (4 / 2^12) * 9.80665 m/s^2 = 0.0095768... m/s^2

 * Multiply 10^6 and round to get the values listed below.

 new data interrupts don't need ack */

 clear any latched interrupt */

	/*

	 * Reset chip to get it in a known good state. A delay of 1.8ms after

	 * reset is required according to the data sheets of supported chips.

 Set Bandwidth */

 Set Default Range */

 Set default slope duration and thresholds */

 Set default as latched interrupts */

	/*

	 * VDD   is the analog and digital domain voltage supply

	 * VDDIO is the digital I/O voltage supply

	/*

	 * 2ms or 3ms power-on time according to datasheets, let's better

	 * be safe than sorry and set this delay to 5ms.

		/*

		 * Set latched mode interrupt. While certain interrupts are

		 * non-latched regardless of this settings (e.g. new data) we

		 * want to use latch mode when we can to prevent interrupt

		 * flooding.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * bma180.c - IIO driver for Bosch BMA180 triaxial acceleration sensor

 *

 * Copyright 2013 Oleksandr Kravchenko <x0199363@ti.com>

 *

 * Support for BMA250 (c) Peter Meerwald <pmeerw@pmeerw.net>

 *

 * SPI is not supported by driver

 * BMA023/BMA150/SMB380: 7-bit I2C slave address 0x38

 * BMA180: 7-bit I2C slave address 0x40 or 0x41

 * BMA250: 7-bit I2C slave address 0x18 or 0x19

 Register set */

 Range of accel values */

 Accel bandwidth */

 Intr every new accel data is ready */

 Need to distinguish BMA180 from other */

 First of 6 registers of accel data */

 BMA180_CTRL_REG0 bits */

 Disable wake up mode */

 1 - chip will sleep */

 Unlock writing to addr from 0x20 */

 Reset pending interrupts */

 BMA180_CTRL_REG3 bits */

 Intr every new accel data is ready */

 BMA180_OFFSET_LSB1 skipping mode bit */

 Bit masks for registers bit fields */

 Range of measured accel values */

 Accel bandwidth */

 Config operation modes */

 We have to write this value in reset register to do soft reset */

 Chip power modes */

 Range of accel values */

 Accel bandwidth */

 chip will sleep */

 Reset pending interrupts */

 Ensure timestamp is naturally aligned */

 Hz */

 Hz */

 Hz */

 Try to read chip_id register. It must return 0x03. */

	/*

	 * No serial transaction should occur within minimum 10 us

	 * after soft_reset command

 50 Hz */

 2 G */

 20 Hz */

 2 G */

 16 Hz */

 2 G */

	/*

	 * This enables dataready interrupt on the INT1 pin

	 * FIXME: support using the INT2 pin

 No temperature channel */

 No power mode on bma023 */

 0 LSB @ -30 degree C */

 No power mode on bma150 */

 0 LSB @ 24 degree C */

 0 LSB @ 24 degree C */

 Typical voltage 2.4V these are min and max */

 Wait to make sure we started up properly (3 ms at least) */

 SPDX-License-Identifier: GPL-2.0+

/*

 * ADXL372 3-Axis Digital Accelerometer SPI driver

 *

 * Copyright 2018 Analog Devices Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO driver for the MiraMEMS DA311 3-axis accelerometer

 *

 * Copyright (c) 2016 Hans de Goede <hdegoede@redhat.com>

 * Copyright (c) 2011-2013 MiraMEMS Sensing Technology Co., Ltd.

/*

 * Note register addressed go from 0 - 0x3f and then wrap.

 * For some reason there are 2 banks with 0 - 0x3f addresses,

 * rather then a single 0-0x7f bank.

 Bank 0 regs */

 Bank 1 regs */

/*

 * a value of + or -1024 corresponds to + or - 1G

 * scale = 9.81 / 1024 = 0.009580078

 | 0x80 comes from the android driver */

 Select bank 1 */

 Back to bank 0 */

 Init sequence taken from the android driver */

 Reset */

		/*

		 * Values are 12 bits, stored as 16 bits with the 4

		 * least significant bits always 0.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI IIO driver for Bosch BMA400 triaxial acceleration sensor.

 *

 * Copyright 2020 Dan Robertson <dan@dlrobertson.com>

 *

	/*

	 * From the BMA400 datasheet:

	 *

	 * > For a basic read operation two bytes have to be read and the first

	 * > has to be dropped and the second byte must be interpreted.

	/*

	 * Per the bma400 datasheet, the first SPI read may

	 * return garbage. As the datasheet recommends, the

	 * chip ID register will be read here and checked

	 * again in the following probe.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IIO driver for the MiraMEMS DA280 3-axis accelerometer and

 * IIO driver for the MiraMEMS DA226 2-axis accelerometer

 *

 * Copyright (c) 2016 Hans de Goede <hdegoede@redhat.com>

/*

 * a value of + or -4096 corresponds to + or - 1G

 * scale = 9.81 / 4096 = 0.002395019

		/*

		 * Values are 14 bits, stored as 16 bits with the 2

		 * least significant bits always 0.

 SPDX-License-Identifier: GPL-2.0+

/*

 * ADXL372 3-Axis Digital Accelerometer core driver

 *

 * Copyright 2018 Analog Devices Inc.

 ADXL372 registers definition */

 ADXL372_POWER_CTL */

 ADXL372_MEASURE */

 ADXL372_TIMING */

 ADXL372_FIFO_CTL */

 ADXL372_STATUS_1 */

 ADXL372_STATUS_2 */

 ADXL372_INT1_MAP */

 ADX372_THRESH */

 The ADXL372 includes a deep, 512 sample FIFO buffer */

/*

 * At +/- 200g with 12-bit resolution, scale is computed as:

 * (200 + 200) * 9.81 / (2^12 - 1) = 0.958241

 lock for threshold */

 scale factor is 100 mg/code */

	/*

	 * 3.3 ms per code is the scale factor of the TIME_ACT register for

	 * ODR = 6400 Hz. It is 6.6 ms per code for ODR = 3200 Hz and below.

 TIME_ACT register is 8 bits wide */

	/*

	 * 13 ms per code is the scale factor of the TIME_INACT register for

	 * ODR = 6400 Hz. It is 26 ms per code for ODR = 3200 Hz and below.

 FIFO must be configured while in standby mode */

	/*

	 * watermark stores the number of sets; we need to write the FIFO

	 * registers with the number of samples

 STATUS1, STATUS2, FIFO_ENTRIES2 and FIFO_ENTRIES are adjacent regs */

	/*

	 * FIFO_ENTRIES contains the least significant byte, and FIFO_ENTRIES2

	 * contains the two most significant bits

		/*

		 * When reading data from multiple axes from the FIFO,

		 * to ensure that data is not overwritten and stored out

		 * of order at least one sample set must be left in the

		 * FIFO after every read.

 Read data from the FIFO */

 Each sample is 2 bytes */

 filter peak detection data */

	/*

	 * Perform a software reset to make sure the device is in a consistent

	 * state after start up.

 Set threshold for activity detection to 1g */

 Set threshold for inactivity detection to 100mg */

 Set activity processing in Looped mode */

 Set activity timer to 1ms */

 Set inactivity timer to 10s */

 Set the mode of operation to full bandwidth measurement mode */

		/*

		 * The timer period depends on the ODR selected.

		 * At 3200 Hz and below, it is 6.6 ms; at 6400 Hz, it is 3.3 ms

		/*

		 * The timer period depends on the ODR selected.

		 * At 3200 Hz and below, it is 26 ms; at 6400 Hz, it is 13 ms

		/*

		 * The maximum bandwidth is constrained to at most half of

		 * the ODR to ensure that the Nyquist criteria is not violated

 Configure the FIFO to store sets of impact event peak. */

	/*

	 * The 512 FIFO samples can be allotted in several ways, such as:

	 * 170 sample sets of concurrent 3-axis data

	 * 256 sample sets of concurrent 2-axis data (user selectable)

	 * 512 sample sets of single-axis data

	 * 170 sets of impact event peak (x, y, z)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * 3-axis accelerometer driver for MXC4005XC Memsic sensor

 *

 * Copyright (c) 2014, Intel Corporation.

 Ensure timestamp is naturally aligned */

/*

 * MXC4005 can operate in the following ranges:

 * +/- 2G, 4G, 8G (the default +/-2G)

 *

 * (2 + 2) * 9.81 / (2^12 - 1) = 0.009582

 * (4 + 4) * 9.81 / (2^12 - 1) = 0.019164

 * (8 + 8) * 9.81 / (2^12 - 1) = 0.038329

 clear interrupt */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MXC6255 - MEMSIC orientation sensing accelerometer

 *

 * Copyright (c) 2015, Intel Corporation.

 *

 * IIO driver for MXC6255 (7-bit I2C slave address 0x15).

/*

 * MXC6255 has only one measurement range: +/- 2G.

 * The acceleration output is an 8-bit value.

 *

 * Scale is calculated as follows:

 * (2 + 2) * 9.80665 / (2^8 - 1) = 0.153829

 *

 * Scale value for +/- 2G measurement range

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STMicroelectronics accelerometers driver

 *

 * Copyright 2012-2013 STMicroelectronics Inc.

 *

 * Denis Ciocca <denis.ciocca@st.com>

 DEFAULT VALUE FOR SENSORS */

 FULLSCALE */

 DF1 and DF0 */

		/*

		 * Data Alignment Setting - needs to be set to get

		 * left-justified data like all other sensors.

 guess */

			/*

			 * TODO: check these resulting gain settings, these are

			 * not in the datsheet

 guess */

 No WAI register present */

		/*

		 * The part has a BDU bit but if set the data is never

		 * updated so don't set it.

 just ODR = 1100Hz available */

 Default accel DRDY is available on INT1 pin */

/* Read ST-specific _ONT orientation data from ACPI and generate an

 * appropriate mount matrix.

	/* For some reason, ST's _ONT translation does not apply directly

	 * to the data read from the sensor. Another translation must be

	 * performed first, as described by the matrix below. Perhaps

	 * ST required this specific translation for the first product

	 * where the device was mounted?

 Read _ONT data, which should be a package of 6 integers. */

	/* The first 3 integers provide axis order information.

	 * e.g. 0 1 2 would indicate normal X,Y,Z ordering.

	 * e.g. 1 0 2 indicates that data arrives in order Y,X,Z.

		/* Avoiding full matrix multiplication, we simply reorder the

		 * columns in the default_ont matrix according to the

		 * ordering provided by _ONT.

	/* The final 3 integers provide sign flip information.

	 * 0 means no change, 1 means flip.

	 * e.g. 0 0 1 means that Z data should be sign-flipped.

	 * This is applied after the axis reordering from above.

 Flip the values in the indicated column */

 Convert our integer matrix to a string-based iio_mount_matrix */

 !CONFIG_ACPI */

/*

 * st_accel_get_settings() - get sensor settings from device name

 * @name: device name buffer reference.

 *

 * Return: valid reference on success, NULL otherwise.

	/*

	 * First try specific ACPI methods to retrieve orientation then try the

	 * generic function.

