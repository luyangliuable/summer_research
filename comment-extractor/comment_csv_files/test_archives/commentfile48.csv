 SPDX-License-Identifier: LGPL-2.1+

/*

 * Advance a date by one day.

/*

 * Checks every day in a 160000 years interval starting on 1970-01-01

 * against the expected result.

	/*

	 * 160000 years	= (160000 / 400) * 400 years

	 *		= (160000 / 400) * 146097 days

	 *		= (160000 / 400) * 146097 * 86400 seconds

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2011 Zhao Zhang <zhzhl555@gmail.com>

 *

 * Derived from driver/rtc/rtc-au1xxx.c

RTC programmable counters 0 and 1*/

 Programmable Counter 0 Registers */

 Programmable Counter 1 Registers */

 add timeout check counter, for more safe */

 set to 1 HZ if needed */

 this loop coundn't be endless */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Faraday Technology FTRTC010 driver

 *

 *  Copyright (C) 2009 Janos Laube <janos.dev@gmail.com>

 *

 * Original code for older kernel 2.6.15 are from Stormlinksemi

 * first update from Janos Laube for > 2.6.29 kernels

 *

 * checkpatch fixes and usage of rtc-lib code

 * Hans Ulli Kroll <ulli.kroll@googlemail.com>

/*

 * Looks like the RTC in the Gemini SoC is (totaly) broken

 * We can't read/write directly the time from RTC registers.

 * We must do some "offset" calculation to get the real time

 *

 * This FIX works pretty fine and Stormlinksemi aka Cortina-Networks does

 * the same thing, without the rtc-lib.c calls.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * RTC Driver for X-Powers AC100

 *

 * Copyright (c) 2016 Chen-Yu Tsai

 *

 * Chen-Yu Tsai <wens@csie.org>

 Control register */

 Clock output register bits */

 RTC */

 Alarm (wall clock) */

/*

 * The year parameter passed to the driver is usually an offset relative to

 * the year 1900. This macro is used to convert this offset to another one

 * relative to the minimum year allowed by the hardware.

 *

 * The year range is 1970 - 2069. This range is selected to match Allwinner's

 * driver.

/**

 * Clock controls for 3 clock output pins

 Abuse the fact that one parent is 32768 Hz, and the other is 4 MHz */

 Handle pre-divider first */

		/*

		 * The clock has two parents, one is a fixed clock which is

		 * internally registered by the ac100 driver. The other parent

		 * is a clock from the codec side of the chip, which we

		 * properly declare and reference in the devicetree and is

		 * not implemented in any driver right now.

		 * If the clock core looks for the parent of that second

		 * missing clock, it can't find one that is registered and

		 * returns NULL.

		 * So we end up in a situation where clk_hw_get_num_parents

		 * returns the amount of clocks we can be parented to, but

		 * clk_hw_get_parent_by_index will not return the orphan

		 * clocks.

		 * Thus we need to check if the parent exists before

		 * we get the parent rate, so we could use the RTC

		 * without waiting for the codec to be supported.

/**

 * RTC related bits

 our RTC has a limited year range... */

 convert to BCD */

 trigger write */

 Is it a leap year? */

 our alarm has a limited year range... */

 convert to BCD */

 Do not enable weekday alarm */

 trigger write */

 read status */

 signal rtc framework */

 clear status */

 disable interrupt */

 always use 24 hour mode */

 disable counter alarm interrupt */

 clear counter alarm pending interrupts */

 SPDX-License-Identifier: GPL-2.0+

/*

 * An RTC driver for the NVIDIA Tegra 200 series internal RTC.

 *

 * Copyright (c) 2010-2019, NVIDIA Corporation.

 Set to 1 = busy every eight 32 kHz clocks during copy of sec+msec to AHB. */

 When msec is read, the seconds are buffered into shadow seconds. */

 write 1 bits to clear status bits */

 bits in INTR_MASK */

 bits in INTR_STATUS */

 NULL if not initialized */

 alarm and periodic IRQ */

/*

 * RTC hardware is busy when it is updating its values over AHB once every

 * eight 32 kHz clocks (~250 us). Outside of these updates the CPU is free to

 * write. CPU is always free to read.

/*

 * Wait for hardware to be ready for writing. This function tries to maximize

 * the amount of time before the next update. It does this by waiting for the

 * RTC to become busy with its periodic update, then returning once the RTC

 * first becomes not busy.

 *

 * This periodic update (where the seconds and milliseconds are copied to the

 * AHB side) occurs every eight 32 kHz clocks (~250 us). The behavior of this

 * function allows us to make some assumptions without introducing a race,

 * because 250 us is plenty of time to read/write a value.

 ~490 us is the worst case, ~250 us is best */

	/*

	 * First wait for the RTC to become busy. This is when it posts its

	 * updated seconds+msec registers to AHB side.

 now we have about 250 us to manipulate registers */

	/*

	 * RTC hardware copies seconds to shadow seconds when a read of

	 * milliseconds occurs. use a lock to keep other threads out.

 convert tm to seconds */

 seconds only written if wait succeeded */

 alarm is disabled */

 alarm is enabled */

 read the original value, and OR in the flag */

 set it */

 clear it */

 if successfully written and alarm is enabled ... */

 disable alarm if 0 or write error */

 clear the interrupt masks and status on any IRQ */

 check if alarm */

 check if periodic */

 set context info */

 clear out the hardware */

 only use ALARM0 as a wake source */

 leave the alarms on as a wake source */

 alarms were left on as a wake source, turn them off */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An i2c driver for the Xicor/Intersil X1205 RTC

 * Copyright 2004 Karen Spearel

 * Copyright 2005 Alessandro Zummo

 *

 * please send all reports to:

 *	Karen Spearel <kas111 at gmail dot com>

 *	Alessandro Zummo <a.zummo@towertech.it>

 *

 * based on a lot of other RTC drivers.

 *

 * Information and datasheet:

 * http://www.intersil.com/cda/deviceinfo/0,1477,X1205,00.html

 offsets into CCR area */

 status register */

 Base address of CCR */

 Base address of ALARM0 */

 Clock failure */

 Write Enable Latch */

 Register Write Enable */

 Alarm 0 match */

 Set in ccr.hour for 24 hr mode */

 Alarm 0 enable */

/*

 * In the routines that deal directly with the x1205 hardware, we use

 * rtc_time -- month 0-11, hour 0-23, yr = calendar year-epoch

 * Epoch is initialized as 2000. Time is set to UTC.

 setup read ptr */

 read date */

 read date registers */

 Mask out the enable bits if these are alarm registers */

 hr is 0-23 */

 mon is 0-11 */

 setup read ptr */

 read status */

 read status register */

 set hour and 24hr bit */

 month, 1 - 12 */

 year, since the rtc epoch*/

 If writing alarm registers, set compare bits on registers 0-4 */

 this sequence is required to unlock the chip */

 If we wrote to the nonvolatile region, wait 10msec for write cycle*/

 ...and set or clear the AL0E bit in the INT register */

 Need to set RWEL again as the write has cleared it */

 and wait 10msec again for this write to complete */

 disable further writes */

 setup read ptr */

 read dtr */

 read dtr register */

 setup read ptr */

 read atr */

 read atr register */

	/* atr is a two's complement value on 6 bits,

	 * perform sign extension. The formula is

	 * Catr = (atr * 0.25pF) + 11.00pF.

	/* Probe array. We will read the register at the specified

	 * address and check if the given bits are zero.

 register, mask */

 register, mask, min, max */

 check that registers have bits a 0 where expected */

 check limits (only registers with bcd values) */

 setup read ptr */

 read INT register */

 read interrupt register and status register */

 Check for power failures and eventually enable the osc */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An I2C driver for the Epson RX8581 RTC

 *

 * Author: Martyn Welch <martyn.welch@ge.com>

 * Copyright 2008 GE Intelligent Platforms Embedded Systems, Inc.

 *

 * Based on: rtc-pcf8563.c (An I2C driver for the Philips PCF8563 RTC)

 * Copyright 2005-06 Tower Technologies

 Second in BCD */

 Minute in BCD */

 Hour in BCD */

 Day of Week */

 Day of Month in BCD */

 Month in BCD */

 Year in BCD */

 RAM */

 Alarm Min in BCD*/

 Alarm Hour in BCD */

 Extension Register */

 Flag Register */

 Control Register */

 Flag Register bit definitions */

 Update */

 Timer */

 Alarm */

 Voltage Low */

 Control Register bit definitions */

 Update Interrupt Enable */

 Timer Interrupt Enable */

 Alarm Interrupt Enable */

 STOP bit */

 RESET bit */

/*

 * In the routines that deal directly with the rx8581 hardware, we use

 * rtc_time -- month 0-11, hour 0-23, yr = calendar year-epoch.

	/* First we ensure that the "update flag" is not set, we read the

	 * time and date then re-read the "update flag". If the update flag

	 * has been set, we know that the time has changed during the read so

	 * we repeat the whole process again.

 If update flag set, clear it */

 Now read time and date */

 Check flag register */

 rtc hr 0-23 */

 rtc mn 1-12 */

 hours, minutes and seconds */

 month, 1 - 12 */

 year and century */

 Stop the clock */

 write register's data */

 get VLF and clear it */

 Restart the clock */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An I2C and SPI driver for the NXP PCF2127/29 RTC

 * Copyright 2013 Til-Technologies

 *

 * Author: Renaud Cerrato <r.cerrato@til-technologies.fr>

 *

 * Watchdog and tamper functions

 * Author: Bruno Thomsen <bruno.thomsen@gmail.com>

 *

 * based on the other drivers in this same directory.

 *

 * Datasheet: https://www.nxp.com/docs/en/data-sheet/PCF2127.pdf

 Control register 1 */

 Control register 2 */

 Control register 3 */

 Time and date registers */

 Alarm registers */

 CLKOUT control register */

 Watchdog registers */

 Tamper timestamp registers */

/*

 * RAM registers

 * PCF2127 has 512 bytes general-purpose static RAM (SRAM) that is

 * battery backed and can survive a power outage.

 * PCF2129 doesn't have this feature.

 Watchdog timer value constants */

 Mask for currently enabled interrupts */

/*

 * In the routines that deal directly with the pcf2127 hardware, we use

 * rtc_time -- month 0-11, hour 0-23, yr = calendar year-epoch.

	/*

	 * Avoid reading CTRL2 register as it causes WD_VAL register

	 * value to reset to 0 which means watchdog is stopped.

 Clock integrity is not guaranteed when OSF flag is set. */

		/*

		 * no need clear the flag here,

		 * it will be cleared once the new date is saved

 rtc hr 0-23 */

 rtc mn 1-12 */

 hours, minutes and seconds */

 this will also clear OSF flag */

 month, 1 - 12 */

 year */

 write register's data */

 watchdog driver */

/*

 * Restart watchdog timer if feature is active.

 *

 * Note: Reading CTRL2 register causes watchdog to stop which is unfortunate,

 * since register also contain control/status flags for other features.

 * Always call this function after reading CTRL2 register.

 Test if watchdog timer is started by bootloader */

 Alarm */

 Do not match on week day */

/*

 * This function reads ctrl2 register, caller is responsible for calling

 * pcf2127_wdt_active_ping()

 TS_MO register (month) value range: 1-12 */

 assume we are in 1970...2069 */

 Let userspace read the first timestamp */

 sysfs interface */

 Sets actual start to 1970 */

	/*

	 * The "Power-On Reset Override" facility prevents the RTC to do a reset

	 * after power on. For normal operation the PORO must be disabled.

	/*

	 * Watchdog timer enabled and reset pin /RST activated when timed out.

	 * Select 1Hz clock source for watchdog timer.

	 * Note: Countdown timer disabled and not available.

	 * For pca2129, pcf2129, only bit[7] is for Symbol WD_CD

	 * of register watchdg_tim_ctl. The bit[6] is labeled

	 * as T. Bits labeled as T must always be written with

	 * logic 0.

	/*

	 * Disable battery low/switch-over timestamp and interrupts.

	 * Clear battery interrupt flags which can block new trigger events.

	 * Note: This is the default chip behaviour but added to ensure

	 * correct tamper timestamp and interrupt function.

	/*

	 * Enable timestamp function and store timestamp of first trigger

	 * event until TSF1 and TFS2 interrupt flags are cleared.

	/*

	 * Enable interrupt generation when TSF1 or TSF2 timestamp flags

	 * are set. Interrupt signal is an open-drain output and can be

	 * left floating if unused.

/*

 * The reason we need this custom regmap_bus instead of using regmap_init_i2c()

 * is that the STOP condition is required between set register address and

 * read register data when reading from registers.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RTC driver for the Armada 38x Marvell SoCs

 *

 * Copyright (C) 2015 Marvell

 *

 * Gregory Clement <gregory.clement@free-electrons.com>

 Armada38x SoC registers  */

 Armada 7K/8K registers  */

 Initialize the RTC-MBUS bridge timing */

/*

 * According to the datasheet, the OS should wait 5us after every

 * register write to the RTC hard macro so that the required update

 * can occur without holding off the system bus

 * According to errata RES-3124064, Write to any RTC register

 * may fail. As a workaround, before writing to RTC

 * register, issue a dummy write of 0x0 twice to RTC Status

 * register.

 Update RTC-MBUS bridge timing parameters */

 Maximum value */

 Maximum value */

		/*

		 * If a value already has half of the sample this is the most

		 * frequent one and we can stop the research right now

 If bits [7:0] are non-zero, assume RTC was uninitialized */

 Oscillator startup time */

 disable all the interrupts for alarm*/

 Ack the event */

/*

 * The information given in the Armada 388 functional spec is complex.

 * They give two different formulas for calculating the offset value,

 * but when considering "Offset" as an 8-bit signed integer, they both

 * reduce down to (we shall rename "Offset" as "val" here):

 *

 *   val = (f_ideal / f_measured - 1) / resolution   where f_ideal = 32768

 *

 * Converting to time, f = 1/t:

 *   val = (t_measured / t_ideal - 1) / resolution   where t_ideal = 1/32768

 *

 *   =>  t_measured / t_ideal = val * resolution + 1

 *

 * "offset" in the RTC interface is defined as:

 *   t = t0 * (1 + offset * 1e-9)

 * where t is the desired period, t0 is the measured period with a zero

 * offset, which is t_measured above. With t0 = t_measured and t = t_ideal,

 *   offset = (t_ideal / t_measured - 1) / 1e-9

 *

 *   => t_ideal / t_measured = offset * 1e-9 + 1

 *

 * so:

 *

 *   offset * 1e-9 + 1 = 1 / (val * resolution + 1)

 *

 * We want "resolution" to be an integer, so resolution = R * 1e-9, giving

 *   offset = 1e18 / (val * R + 1e9) - 1e9

 *   val = (1e18 / (offset + 1e9) - 1e9) / R

 * with a common transformation:

 *   f(x) = 1e18 / (x + 1e9) - 1e9

 *   offset = f(val * R)

 *   val = f(offset) / R

 *

 * Armada 38x supports two modes, fine mode (954ppb) and coarse mode (3815ppb).

 ppb_cor + 1000000000L can never be zero */

	/*

	 * The maximum ppb_cor is -128 * 3815 .. 127 * 3815, but we

	 * need to clamp the input.  This equates to -484270 .. 488558.

	 * Not only is this to stop out of range "off" but also to

	 * avoid the division by zero in armada38x_ppb_convert().

	/*

	 * Use low update mode where possible, which gives a better

	 * resolution of correction.

	/*

	 * Armada 388 requires a bit pattern in bits 14..8 depending on

	 * the sign bit: { 0, ~S, S, S, S, S, S }

 Update RTC-MBUS bridge timing parameters */

 Update RTC-MBUS bridge timing parameters */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DS1286 Real Time Clock interface for Linux

 *

 * Copyright (C) 1998, 1999, 2000 Ralf Baechle

 * Copyright (C) 2008 Thomas Bogendoerfer

 *

 * Based on code written by Paul Gortmaker.

 Allow or mask alarm interrupts */

 Mask watchdog int. enab. bit	*/

 Allow watchdog interrupts.	*/

	/*

	 * read RTC once any update in progress is done. The update

	 * can take just over 2ms. We wait 10 to 20ms. There is no need to

	 * to poll-wait (up to 1s - eeccch) for the falling edge of RTC_UIP.

	 * If you need to know *exactly* when a second has started, enable

	 * periodic update complete interrupts, (via ioctl) and then

	 * immediately read /dev/rtc which will block until you get the IRQ.

	 * Once the read clears, read the RTC time (again via ioctl). Easy.

	/*

	 * Only the values that we read from the RTC are set. We leave

	 * tm_wday, tm_yday and tm_isdst untouched. Even though the

	 * RTC has RTC_DAY_OF_WEEK, we ignore it, as it is only updated

	 * by the RTC when initially set to a non-zero value.

	/*

	 * Account for differences between how the RTC uses the values

	 * and how they are defined in a struct rtc_time;

 tm_mon starts at zero */

 They are unsigned */

	/*

	 * Only the values that we read from the RTC are set. That

	 * means only tm_wday, tm_hour, tm_min.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Real Time Clock driver for Marvell 88PM860x PMIC

 *

 * Copyright (c) 2010 Marvell International Ltd.

 * Author:	Haojian Zhuang <haojian.zhuang@marvell.com>

 bit definitions of Measurement Enable Register 2 (0x51) */

 bit definitions of RTC Register 1 (0xA0) */

 10 minutes */

 load 32-bit read-only counter */

 load 32-bit read-only counter */

 convert to mv */

 try higher voltage */

 try lower voltage */

 trigger next calibration since VRTC is updated */

 disable measurement */

 set addresses of 32-bit base value for RTC time */

	/*

	 * enable internal XO instead of internal 3.25MHz clock since it can

	 * free running in PMIC power-down state.

 <00> -- 2.7V, <01> -- 2.9V, <10> -- 3.1V, <11> -- 3.3V */

 calibrate VRTC */

 VRTC_CALIBRATION */

 disable measurement */

 VRTC_CALIBRATION */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An rtc/i2c driver for the EM Microelectronic EM3027

 * Copyright 2011 CompuLab, Ltd.

 *

 * Author: Mike Rapoport <mike@compulab.co.il>

 *

 * Based on rtc-ds1672.c by Alessandro Zummo <a.zummo@towertech.it>

 Registers */

 setup read addr */

 read time/date */

 read time/date registers */

 write time/date */

 write time/date registers */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc-ds1307.c - RTC driver for some mostly-compatible I2C chips.

 *

 *  Copyright (C) 2005 James Chapman (ds1337 core)

 *  Copyright (C) 2006 David Brownell

 *  Copyright (C) 2009 Matthias Fuchs (rx8025 support)

 *  Copyright (C) 2012 Bertrand Achard (nvram access fixes)

/*

 * We can't determine type by probing, but if we expect pre-Linux code

 * to have set the chip up as a clock (turning on the oscillator and

 * setting the date and time), Linux can ignore the non-clock features.

 * That's a natural job for a factory or repair bench.

 always first and 0 */

 always last */

 rs5c372 too?  different address... */

 RTC registers don't differ much, except for the century flag */

 00-59 */

 00-59 */

 00-23, or 1-12{am,pm} */

 in REG_HOUR */

 in REG_HOUR */

 in REG_HOUR */

 in REG_HOUR */

 01-07 */

 01-31 */

 01-12 */

 in REG_MONTH */

 00-99 */

/*

 * Other registers (control, status, alarms, trickle charge, NVRAM, etc)

 * start at 7, and they differ a LOT. Only control and status matter for

 * basic RTC date and time functionality; be careful using them.

 or ds1338 */

 same as BBSQI */

 negative offset step is -2.034ppm */

 positive offset step is +4.068ppm */

 Min and max values supported with 'offset' interface by M41TXX */

 register's offset */

	/* Does the RTC require trickle-resistor-ohms to select the value of

	 * the resistor between Vcc and Vbackup?

	/* Some RTC's batteries and supercaps were charged by default, others

	 * allow charging but were not configured previously to do so.

	 * Remember this behavior to stay backwards compatible.

 read the RTC date and time registers all at once */

 if oscillator fail bit is set, no data can be trusted */

 rx8130 is bit position, not BCD */

 rx8130 is bit position, not BCD */

 assume 20YY not 19YY */

		/*

		 * these bits were cleared when preparing the date/time

		 * values and need to be set again before writing the

		 * regsfer out to the device.

 clear Voltage Loss Flag as data is available now */

 read all ALARM1, ALARM2, and status registers at once */

	/*

	 * report alarm time (ALARM1); assume 24 hour and day-of-month modes,

	 * and that all four fields are checked matches

 ... and status */

 read current status of both alarms and the chip */

 set ALARM1, using 24 hour and day-of-month modes */

 set ALARM2 to non-garbage */

 disable alarms */

 optionally enable ALARM1 */

 only ALARM1 is used */

 make sure that the backup battery is enabled */

 Read control registers. */

 Read alarm registers. */

 Read control registers. */

 Report alarm 0 time assuming 24-hour and day-of-month modes. */

 Read control registers. */

 Hardware alarm precision is 1 minute! */

 Check and clear alarm 0 interrupt flag. */

 Disable alarm 0. */

 Read control and alarm 0 registers. */

 Report alarm 0 time assuming 24-hour and day-of-month modes. */

/*

 * We may have a random RTC weekday, therefore calculate alarm weekday based

 * on current weekday we read from the RTC timekeeping regs

 Read control and alarm 0 registers. */

 Set alarm 0, using 24-hour and day-of-month modes. */

 Clear the alarm 0 interrupt flag. */

 Set alarm match: second, minute, hour, day, date, month. */

 Disable interrupt. We will not enable until completely programmed */

 check if positive */

	/*

	 * watchdog timeouts are measured in seconds. So ignore hundredths of

	 * seconds field.

 this is battery backed SRAM */

 32bit (4 word x 8 bit) */

 this is battery backed SRAM */

 this is battery backed SRAM */

/*

 * The ds1337 and ds1339 both have two alarms, but we only use the first

 * one (with a "seconds" field).  For ds1337 we expect nINTA is our alarm

 * signal; ds1339 chips have only one alarm signal.

----------------------------------------------------------------------*/

----------------------------------------------------------------------*/

----------------------------------------------------------------------*/

	/* aux-voltage-chargeable takes precedence over the deprecated

	 * trickle-diode-disable

----------------------------------------------------------------------*/

/*

 * Temperature sensor support for ds3231 devices.

/*

 * A user-initiated temperature conversion is not started by this function,

 * so the temperature is updated once every 64 seconds.

	/*

	 * Temperature is represented as a 10-bit code with a resolution of

	 * 0.25 degree celsius and encoded in two's complement format.

 CONFIG_RTC_DRV_DS1307_HWMON */

----------------------------------------------------------------------*/

/*

 * Square-wave output support for DS3231

 * Datasheet: https://datasheets.maximintegrated.com/en/ds/DS3231.pdf

 optional override of the clockname */

		/*

		 * Interrupt signal due to alarm conditions and square-wave

		 * output share same pin, so don't initialize both.

 CONFIG_COMMON_CLK */

 CONFIG_WATCHDOG_CORE */

/*

 * For devices with no IRQ directly connected to the SoC, the RTC chip

 * can be forced as a wakeup source by stating that explicitly in

 * the device's .dts file using the "wakeup-source" boolean property.

 * If the "wakeup-source" property is set, don't request an IRQ.

 * This will guarantee the 'wakealarm' sysfs entry is available on the device,

 * if supported by the RTC.

 get registers that the "rtc" read below won't read... */

 oscillator off?  turn it on, so clock can tick. */

		/*

		 * Using IRQ or defined as wakeup-source?

		 * Disable the square wave and both alarms.

		 * For some variants, be sure alarms can trigger when we're

		 * running on Vbackup (BBSQI/BBSQW)

 oscillator fault?  clear flag, and warn */

 oscillator off?  turn it on, so clock can tick. */

 make sure we are running in 24hour mode */

 switch to 24 hour mode */

 correct hour */

 oscillator off?  turn it on, so clock can tick. */

 read RTC registers */

		/*

		 * NOTE: ignores century bits; fix before deploying

		 * systems that will run through year 2100.

		/*

		 * Be sure we're in 24 hour mode.  Multi-master systems

		 * take note...

 We cannot support UIE mode if we do not have an IRQ line */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * RTC driver for Maxim MAX8925

 *

 * Copyright (C) 2009-2010 Marvell International Ltd.

 *	Haojian Zhuang <haojian.zhuang@marvell.com>

 disable ALARM0 except for 1SEC alarm */

 only enable alarm on year/month/day/hour/min/sec */

 XXX - isn't this redundant? */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * An RTC driver for Allwinner A10/A20

 *

 * Copyright (c) 2013, Carlo Caione <carlo.caione@gmail.com>

/*

 * Get date values

/*

 * Get time values

/*

 * Get alarm values

/*

 * Set date values

/*

 * Set time values

/*

 * Set alarm values

/*

 * Time unit conversions

/*

 * The year parameter passed to the driver is usually an offset relative to

 * the year 1900. This macro is used to convert this offset to another one

 * relative to the minimum year allowed by the hardware.

/*

 * min and max year are arbitrary set considering the limited range of the

 * hardware register field

 min year allowed */

 max year allowed */

 mask for the year field */

 bit shift to get the leap year */

	/*

	 * switch from (data_year->min)-relative offset to

	 * a (1900)-relative one

	/*

	 * read again in case it changes

	/*

	 * switch from (data_year->min)-relative offset to

	 * a (1900)-relative one

	/*

	 * the input rtc_tm->tm_year is the offset relative to 1900. We use

	 * the SUNXI_YEAR_OFF macro to rebase it with respect to the min year

	 * allowed by the hardware

	/*

	 * After writing the RTC HH-MM-SS register, the

	 * SUNXI_LOSC_CTRL_RTC_HMS_ACC bit is set and it will not

	 * be cleared until the real writing operation is finished

	/*

	 * After writing the RTC YY-MM-DD register, the

	 * SUNXI_LOSC_CTRL_RTC_YMD_ACC bit is set and it will not

	 * be cleared until the real writing operation is finished

 sentinel */ },

 clear the alarm count value */

 disable alarm, not generate irq pending */

 disable alarm week/cnt irq, unset to cpu */

 clear alarm week/cnt irq pending */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * RTC driver for Maxim MAX8907

 *

 * Copyright (c) 2011-2012, NVIDIA Corporation.

 *

 * Based on drivers/rtc/rtc-max8925.c,

 * Copyright (C) 2009-2010 Marvell International Ltd.

 Disable alarm while we update the target time */

 SPDX-License-Identifier: GPL-2.0+

/*

 *  Copyright (C) 2009-2010, Lars-Peter Clausen <lars@metafoo.de>

 *  Copyright (C) 2010, Paul Cercueil <paul@crapouillou.net>

 *	 JZ4740 SoC RTC driver

 The following are present on the jz4780 */

 Magic value to enable writes on jz4780 */

 Don't clear interrupt flags by accident */

	/* If the seconds register is read while it is updated, it can contain a

	 * bogus value. This can be avoided by making sure that two consecutive

	 * reads have the same value.

 Default: 60ms */

 Default: 100ms */

	/*

	 * Set minimum wakeup pin assertion time: 100 ms.

	 * Range is 0 to 2 sec if RTC is clocked at 32 kHz.

	/*

	 * Set reset pin low-level assertion time after wakeup: 60 ms.

	 * Range is 0 to 125 ms if RTC is clocked at 32 kHz.

 Each 1 Hz pulse should happen after (rate) ticks */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * rtc-efi: RTC Class Driver for EFI-based systems

 *

 * Copyright (C) 2009 Hewlett-Packard Development Company, L.P.

 *

 * Author: dann frazier <dannf@dannf.org>

 * Based on efirtc.c by Stephane Eranian

/*

 * returns day of the year [0-365]

 efi_time_t.month is in the [1-12] so, we need -1 */

/*

 * returns day of the week [0-6] 0=Sunday

	/*

	 * 1/1/0000 may or may not have been a Sunday (if it ever existed at

	 * all) but assuming it was makes this calculation work correctly.

 day in the year [1-365]*/

 day of the week [0-6], Sunday=0 */

	/*

	 * As of EFI v1.10, this call always returns an unsupported status

	/*

	 * XXX Fixme:

	 * As of EFI 0.92 with the firmware I have on my

	 * machine this call does not seem to work quite

	 * right

	 *

	 * As of v1.10, this call always returns an unsupported status

 should never happen */

 XXX fixme: convert to string? */

 XXX fixme: convert to string? */

	/*

	 * now prints the capabilities

 First check if the RTC is usable */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Haoyu HYM8563 RTC driver

 *

 * Copyright (C) 2013 MundoReader S.L.

 * Author: Heiko Stuebner <heiko@sntech.de>

 *

 * based on rtc-HYM8563

 * Copyright (C) 2010 ROCKCHIP, Inc.

 Each alarm check can be disabled by setting this bit in the register */

/*

 * RTC handling

 0 = Sun */

 0 = Jan */

 Years >= 2100 are to far in the future, 19XX is to early */

	/*

	 * While the HYM8563 has a century flag in the month register,

	 * it does not seem to carry it over a subsequent write/read.

	 * So we'll limit ourself to 100 years, starting at 2000 for now.

	/*

	 * CTL1 only contains TEST-mode bits apart from stop,

	 * so no need to read the value first

 The alarm only has a minute accuracy */

	/*

	 * The alarm has no seconds so deal with it

/*

 * Handling of the clkout

 optional override of the clockname */

 register the clock */

/*

 * The alarm interrupt is implemented as a level-low interrupt in the

 * hym8563, while the timer interrupt uses a falling edge.

 * We don't use the timer at all, so the interrupt is requested to

 * use the level-low trigger.

 Clear the alarm flag */

 Clear stop flag if present */

 Disable alarm and timer interrupts */

 Clear any pending alarm and timer flags */

 check state of calendar information */

 the hym8563 alarm only supports a minute accuracy */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Micro Crystal RV-3029 / RV-3049 rtc class driver

 *

 * Author: Gregory Hermant <gregory.hermant@calao-systems.com>

 *         Michael Buesch <m@bues.ch>

 *

 * based on previously existing rtc class drivers

 Register map */

 control section */

 watch section */

 24h/12h mode */

 PM/AM bit in 12h mode */

 alarm section */

 timer section */

 temperature section */

 eeprom data section */

 eeprom control section */

 temp scan interval */

 thermometer enable */

 CLKOUT */

 CLKOUT */

 1.5K resistance */

 5K   resistance */

 20K  resistance */

 80K  resistance */

 XTAL offset */

 Sign: 1->pos, 0->neg */

 XTAL temp drift coef */

 XTAL turnover temp (in *C) */

 XTAL turnover temp mask */

 user ram section */

 Re-enable eeprom refresh */

 Check whether we are in the allowed voltage range. */

		/* We clear the bits and retry once just in case

		 * we had a brown out in early startup.

 Disable eeprom refresh. */

 Wait for any previous eeprom accesses to finish. */

 HR field has a more complex interpretation */

 12h format */

 PM flag set */

 24h format */

 Activate all the alarms with AE_x bit */

 Write the alarm */

 clear PON and VLOW2 bits */

 resistance in ohms */

 trickle config bits */

 Configure the trickle charger. */

 Disable trickle charger. */

 Enable trickle charger. */

 CONFIG_RTC_DRV_RV3029_HWMON */

 CONFIG_RTC_DRV_RV3029_HWMON */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/rtc/rtc-vt8500.c

 *

 *  Copyright (C) 2010 Alexey Charkov <alchark@gmail.com>

 *

 * Based on rtc-pxa.c

/*

 * Register definitions

 Time set */

 Date set */

 Alarm set */

 Control */

 Time read */

 Date read */

 Write status */

 Calibration */

 Interrupt status */

 Status */

 Enable RTC */

 12h time format */

 Enable periodic irqs */

 0: 1Hz/60, 1: 1Hz */

 Enable calibration */

 Alarm interrupt status */

 Protects this structure */

 clear interrupt sources */

 Enable RTC and set it to 24-hour mode */

 Disable alarm matching */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RTC driver for NXP LPC178x/18xx/43xx Real-Time Clock (RTC)

 *

 * Copyright (C) 2011 NXP Semiconductors

 * Copyright (C) 2015 Joachim Eastwood <manabian@gmail.com>

 LPC24xx RTC register offsets and bits */

 Macros to read fields in consolidated time (CT) registers */

 Disable RTC during update */

 Disable alarm irq during update */

 Check interrupt cause */

 Clear interrupt status and report event */

 Clear any pending interrupts */

 Enable RTC count */

 Ensure all interrupt sources are masked */

 SPDX-License-Identifier: GPL-2.0

 RTC driver for ChromeOS Embedded Controller.



 Copyright (C) 2017 Google, Inc.

 Author: Stephen Barber <smbarber@chromium.org>

/**

 * struct cros_ec_rtc - Driver data for EC RTC

 *

 * @cros_ec: Pointer to EC device

 * @rtc: Pointer to RTC device

 * @notifier: Notifier info for responding to EC events

 * @saved_alarm: Alarm to restore when interrupts are reenabled

 Read the current time from the EC. */

 Set the current EC time. */

 Read alarm time from RTC. */

	/*

	 * The EC host command for getting the alarm is relative (i.e. 5

	 * seconds from now) whereas rtc_wkalrm is absolute. Get the current

	 * RTC time first so we can calculate the relative time.

 Set the EC's RTC alarm. */

	/*

	 * The EC host command for setting the alarm is relative

	 * (i.e. 5 seconds from now) whereas rtc_wkalrm is absolute.

	 * Get the current RTC time first so we can calculate the

	 * relative time.

		/*

		 * If the alarm is being disabled, send an alarm

		 * clear command.

 Don't set an alarm in the past. */

 Restore saved alarm if it's still in the future. */

 Disable alarm, saving the old alarm value. */

		/*

		 * If the current EC alarm is already past, we don't want

		 * to set an alarm when we go through the alarm irq enable

		 * path.

 Get initial time */

 Get RTC events from the EC. */

 SPDX-License-Identifier: GPL-2.0+



 RTC driver for Maxim MAX77686 and MAX77802



 Copyright (C) 2012 Samsung Electronics Co.Ltd



  based on rtc-max8997.c

 Define non existing register */

 RTC Control Register */

 RTC Update Register1 */

 RTC Hour register */

 RTC Alarm Enable */

/*

 * MAX77802 has separate register (RTCAE1) for alarm enable instead

 * using 1 bit from registers RTC{SEC,MIN,HOUR,DAY,MONTH,YEAR,DATE}

 * as in done in MAX77686.

 Minimum usecs needed for a RTC update */

 Mask used to read RTC registers value */

 Registers offset to I2C addresses map */

 Has a separate alarm enable register? */

 I2C address for RTC block */

 RTC interrupt via platform resource */

 Pending alarm status register */

 RTC IRQ CHIP for regmap */

 regmap configuration for the chip */

 These are not registers but just offsets that are mapped to addresses */

 Maps RTC registers offset to the MAX77686 register addresses */

 RTC interrupts */

 same masks as 77686 */

 Only a single bit is set in data[], so fls() would be equivalent */

	/*

	 * MAX77686 uses 1 bit from sec/min/hour/etc RTC registers and the

	 * year values are just 0..99 so add 100 to support up to 2099.

 Minimum delay required before RTC update. */

 RTCA1 */

 Set RTC control register : Binary mode, 24hour mdoe */

	/*

	 * If the main IRQ (not virtual) is the parent IRQ, then it must be

	 * disabled during suspend because if it happens while suspended it

	 * will be handled before resuming I2C.

	 *

	 * Since Main IRQ is shared, all its users should disable it to be sure

	 * it won't fire while one of them is still suspended.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * A RTC driver for the Simtek STK17TA8

 *

 * By Thomas Hommel <thomas.hommel@ge.com>

 *

 * Based on the DS1553 driver from

 * Atsushi Nemoto <anemo@mba.ocn.ne.jp>

 Bits in the Calibration register */

 Bits in the Flags register */

 Bits in the Interrupts register */

 give enough time to update RTC in case of continuous read */

 year is 1900 + tm->tm_year */

 clear interrupts */

 read and clear interrupt */

 turn RTC on if it was not on */

 work with hotplug and coldplug */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SPI Driver for Microchip MCP795 RTC

 *

 * Copyright (C) Josef Gajdusek <atx@atx.name>

 *

 * based on other Linux RTC drivers

 *

 * Device datasheet:

 * https://ww1.microchip.com/downloads/en/DeviceDoc/22280A.pdf

 MCP795 Instructions, see datasheet table 3-1 */

 MCP795 RTCC registers, see datasheet table 4-1 */

 wait for the OSCON bit to clear */

 Enable or disable Alarm 0 in RTC */

 clear ALM0IF (Alarm 0 Interrupt Flag) bit */

 enable alarm 0 */

 disable alarm 0 and alarm 1 */

 Stop RTC and store current value of EXTOSC bit */

 Read first, so we can leave config bits untouched */

	/* Always write the date and month using a separate Write command.

	 * This is a workaround for a know silicon issue that some combinations

	 * of date and month values may result in the date being reset to 1.

	/* Start back RTC and restore previous value of EXTOSC bit.

	 * There is no need to clear EXTOSC bit when the previous value was 0

	 * because it was already cleared when stopping the RTC oscillator.

 Assume we are in 20xx */

 Read current time from RTC hardware */

 Get the number of seconds since 1970 */

 make sure alarm fires within the next one year */

 disable alarm */

 Read registers, so we can leave configuration bits untouched */

 set alarm match: seconds, minutes, hour, day, date and month */

 enable alarm if requested */

	/* Disable alarm.

	 * There is no need to clear ALM0IF (Alarm 0 Interrupt Flag) bit,

	 * because it is done every time when alarm is enabled.

 Start the oscillator but don't set the value of EXTOSC bit */

 Clear the 12 hour mode flag*/

		/* Clear any pending alarm (ALM0IF bit) before requesting

		 * the interrupt.

 SPDX-License-Identifier: GPL-2.0-only

/* rtc-max6916.c

 *

 * Driver for MAXIM  max6916 Low Current, SPI Compatible

 * Real Time Clock

 *

 * Author : Venkat Prashanth B U <venkat.prashanth2498@gmail.com>

 Registers in max6916 rtc */

 write the rtc settings */

 spi setup with max6916 in mode 3 and bits per word as 8 */

 RTC Settings */

 Disable the write protect of rtc */

Enable oscillator,disable oscillator stop flag, glitch filter*/

 display the settings */

 SPDX-License-Identifier: GPL-2.0

/*

 * SuperH On-Chip RTC Support

 *

 * Copyright (C) 2006 - 2009  Paul Mundt

 * Copyright (C) 2006  Jamie Lenehan

 * Copyright (C) 2008  Angelo Castello

 *

 * Based on the old arch/sh/kernel/cpu/rtc.c by:

 *

 *  Copyright (C) 2000  Philipp Rumpf <prumpf@tux.org>

 *  Copyright (C) 1999  Tetsuya Okada & Niibe Yutaka

 Default values for RZ/A RTC */

 no chip bugs */

 RTC sec */

 RTC min */

 RTC hour */

 RTC week */

 RTC day */

 RTC month */

 RTC year */

 ALARM sec */

 ALARM min */

 ALARM hour */

 ALARM week */

 ALARM day */

 ALARM month */

 Control */

 Control */

/*

 * Note on RYRAR and RCR3: Up until this point most of the register

 * definitions are consistent across all of the available parts. However,

 * the placement of the optional RYRAR and RCR3 (the RYRAR control

 * register used to control RYRCNT/RYRAR compare) varies considerably

 * across various parts, occasionally being mapped in to a completely

 * unrelated address space. For proper RYRAR support a separate resource

 * would have to be handed off, but as this is purely optional in

 * practice, we simply opt not to support it, thereby keeping the code

 * quite a bit more simplified.

 ALARM Bits - or with BCD encoded value */

 Enable for alarm cmp   */

 Period Bits */

 Enable Half Period to support 8,32,128Hz */

 Half periodic counter */

 Periodic One x Second */

 Kernel or User periodic request 1=kernel */

 RCR1 Bits */

 Carry Flag             */

 Carry Interrupt Enable */

 Alarm Interrupt Enable */

 Alarm Flag             */

 RCR2 Bits */

 PEriodic interrupt Flag */

 Periodic interrupt Set  */

 ENable RTC              */

 ADJustment (30-second)  */

 Reset bit               */

 Start bit               */

 See asm/rtc.h for cap bits */

 Users have requested One x Second IRQ */

 Half period enabled than one skipped and the next notified */

 Clear CF-bit */

 only keep the carry interrupt enabled if UIE is on */

 Reset pre-scaler & stop RTC */

 Start RTC */

 return -1 for ignored values */

 strip the enable bit */

 RTC is 1-12, tm_mon is 0-11 */

 < 0 for a value that is ignored */

 disable alarm interrupt and clear the alarm flag */

 set alarm time */

 get periodic/carry/alarm irqs */

 With a single device, the clock id is still "rtc0" */

		/*

		 * No error handling for rtc->clk intentionally, not all

		 * platforms will have a unique clock for the RTC, and

		 * the clk API can handle the struct clk pointer being

		 * NULL.

		/*

		 * Some CPUs have special capabilities in addition to the

		 * default set. Add those in here.

 register shared periodic/carry/alarm irq */

 register periodic/carry/alarm irqs */

 everything disabled by default */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * rtc-twl.c -- TWL Real Time Clock interface

 *

 * Copyright (C) 2007 MontaVista Software, Inc

 * Author: Alexandre Rusev <source@mvista.com>

 *

 * Based on original TI driver twl4030-rtc.c

 *   Copyright (C) 2006 Texas Instruments, Inc.

 *

 * Based on rtc-omap.c

 *   Copyright (C) 2003 MontaVista Software, Inc.

 *   Author: George G. Davis <gdavis@mvista.com> or <source@mvista.com>

 *   Copyright (C) 2006 David Brownell

/*

 * RTC block register offsets (use TWL_MODULE_RTC)

 RTC_CTRL_REG bitfields */

 RTC_STATUS_REG bitfields */

 RTC_INTERRUPTS_REG bitfields */

 REG_SECONDS_REG through REG_YEARS_REG is how many registers? */

----------------------------------------------------------------------*/

	/*

	 * Cache the value for timer/alarm interrupts register; this is

	 * only changed by callers holding rtc ops lock (or resume).

/*

 * Supports 1 byte read from TWL RTC register.

/*

 * Supports 1 byte write to TWL RTC registers.

/*

 * Enable 1/second update and/or alarm interrupts.

 if the bit is set, return from here */

/*

 * Disable update and/or alarm interrupts.

 if the bit is clear, return from here */

/*

 * Gets current TWL RTC time and date parameters.

 *

 * The RTC's time/alarm representation is not what gmtime(3) requires

 * Linux to use:

 *

 *  - Months are 1..12 vs Linux 0-11

 *  - Years are 0..99 vs Linux 1900..N (we assume 21st century)

 for twl6030/32 make sure BIT_RTC_CTRL_REG_GET_TIME_M is clear */

 Copy RTC counting registers to static registers or latches */

 for twl6030/32 enable read access to static shadowed registers */

 for twl6030 restore original state of rtc control register */

 Stop RTC while updating the TC registers */

 update all the time registers in one shot */

 Start back RTC */

/*

 * Gets current TWL RTC alarm time.

 some of these fields may be wildcard/"match all" */

 report cached alarm enable state */

 update all the alarm registers in one shot */

	/*

	 * Figure out source of interrupt: ALARM or TIMER in RTC_STATUS_REG.

	 * only one (ALARM or RTC) interrupt source may be enabled

	 * at time, we also could check our results

	 * by reading RTS_INTERRUPTS_REGISTER[IT_TIMER,IT_ALARM]

		/* Clear on Read enabled. RTC_IT bit of TWL4030_INT_PWR_ISR1

		 * needs 2 reads to clear the interrupt. One read is done in

		 * do_twl_pwrirq(). Doing the second read, to clear

		 * the bit.

		 *

		 * FIXME the reason PWR_ISR1 needs an extra read is that

		 * RTC_IF retriggered until we cleared REG_ALARM_M above.

		 * But re-reading like this is a bad hack; by doing so we

		 * risk wrongly clearing status for some other IRQ (losing

		 * the interrupt).  Be smarter about handling RTC_UF ...

 Notify RTC core on event */

----------------------------------------------------------------------*/

 Clear RTC Power up reset and pending alarm interrupts */

 ensure interrupts are disabled, bootloaders can be strange */

 init cached IRQ enable bits */

/*

 * Disable all TWL RTC module interrupts.

 * Sets status flag to free.

 leave rtc running, but disable irqs */

	/* mask timer interrupts, but leave alarm interrupts on to enable

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Dallas DS1216 RTC driver

 *

 * Copyright (c) 2007 Thomas Bogendoerfer

 *

/*

 * Read the 64 bit we'd like to have - It a series

 * of 64 bits showing up in the LSB of the base register.

 *

 Reset magic pointer */

 Write 64 bit magic to DS1216 */

 AM/PM mode */

 clear 0.1 and 0.01 seconds */

 dummy read to get clock into a known state */

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC subsystem, base class

 *

 * Copyright (C) 2005 Tower Technologies

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 *

 * class skeleton from drivers/hwmon/hwmon.c

 Result of the last RTC to system clock attempt. */

/* IMPORTANT: the RTC only stores whole seconds. It is arbitrary

 * whether it stores the most close value or the value with partial

 * seconds truncated. However, it is important that we use it to store

 * the truncated value. This is because otherwise it is necessary,

 * in an rtc sync function, to read both xtime.tv_sec and

 * xtime.tv_nsec. On some processors (i.e. ARM), an atomic read

 * of >32bits is not possible. So storing the most close value would

 * slow down the sync API. So here we have the truncated value and

 * the best guess is to add 0.5s.

/*

 * On suspend(), measure the delta between one RTC and the

 * system's wall clock; restore it on resume().

 snapshot the current RTC and system time at suspend*/

	/*

	 * To avoid drift caused by repeated suspend/resumes,

	 * which each can add ~1 second drift error,

	 * try to compensate so the difference in system time

	 * and rtc time stays close to constant.

		/*

		 * if delta_delta is too large, assume time correction

		 * has occurred and set old_delta to the current delta.

 Otherwise try to adjust old_system to compensate */

 snapshot the current rtc and system time at resume */

 calculate the RTC time delta (sleep time)*/

	/*

	 * Since these RTC suspend/resume handlers are not called

	 * at the very end of suspend or the start of resume,

	 * some run-time may pass on either sides of the sleep time

	 * so subtract kernel run-time between rtc_suspend to rtc_resume

	 * to keep things accurate.

 Ensure the caller will set the id before releasing the device */

	/*

	 * Drivers can revise this default after allocating the device.

	 * The default is what most RTCs do: Increment seconds exactly one

	 * second after the write happened. This adds a default transport

	 * time of 5ms which is at least halfways close to reality.

 Init timerqueue */

 Init aie timer */

 Init uie timer */

 Init pie timer */

	/*

	 * If RTC driver did not implement the range of RTC hardware device,

	 * then we can not expand the RTC range by adding or subtracting one

	 * offset.

	/*

	 * If user did not implement the start time for RTC driver, then no

	 * need to expand the RTC range.

	/*

	 * If the start_secs is larger than the maximum seconds (rtc->range_max)

	 * supported by RTC hardware or the maximum seconds of new expanded

	 * range (start_secs + rtc->range_max - rtc->range_min) is less than

	 * rtc->range_min, which means the minimum seconds (rtc->range_min) of

	 * RTC hardware will be mapped to start_secs by adding one offset, so

	 * the offset seconds calculation formula should be:

	 * rtc->offset_secs = rtc->start_secs - rtc->range_min;

	 *

	 * If the start_secs is larger than the minimum seconds (rtc->range_min)

	 * supported by RTC hardware, then there is one region is overlapped

	 * between the original RTC hardware range and the new expanded range,

	 * and this overlapped region do not need to be mapped into the new

	 * expanded range due to it is valid for RTC device. So the minimum

	 * seconds of RTC hardware (rtc->range_min) should be mapped to

	 * rtc->range_max + 1, then the offset seconds formula should be:

	 * rtc->offset_secs = rtc->range_max - rtc->range_min + 1;

	 *

	 * If the start_secs is less than the minimum seconds (rtc->range_min),

	 * which is similar to case 2. So the start_secs should be mapped to

	 * start_secs + rtc->range_max - rtc->range_min + 1, then the

	 * offset seconds formula should be:

	 * rtc->offset_secs = -(rtc->range_max - rtc->range_min + 1);

	 *

	 * Otherwise the offset seconds should be 0.

	/*

	 * Remove innards of this RTC, then disable it, before

	 * letting any rtc_class_open() users access it again

 Check to see if there is an ALARM already set in hw */

/**

 * devm_rtc_device_register - resource managed rtc_device_register()

 * @dev: the device to register

 * @name: the name of the device (unused)

 * @ops: the rtc operations structure

 * @owner: the module owner

 *

 * @return a struct rtc on success, or an ERR_PTR on error

 *

 * Managed rtc_device_register(). The rtc_device returned from this function

 * are automatically freed on driver detach.

 * This function is deprecated, use devm_rtc_allocate_device and

 * rtc_register_device instead

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ST M48T86 / Dallas DS12887 RTC driver

 * Copyright (c) 2006 Tower Technologies

 *

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 *

 * This drivers only supports the clock running in BCD and 24H mode.

 * If it will be ever adapted to binary and 12H mode, care must be taken

 * to not introduce bugs.

 1 = sunday */

 1 - 12 */

 0 - 99 */

 data (binary) mode */

 tm_mon is 0-11 */

 bcd mode */

 tm_mon is 0-11 */

 correct the hour if the clock is in 12h mode */

 update flag and 24h mode */

 data (binary) mode */

 bcd mode */

 update ended */

/*

 * The RTC is an optional feature at purchase time on some Technologic Systems

 * boards. Verify that it actually exists by checking if the last two bytes

 * of the NVRAM can be changed.

 *

 * This is based on the method used in their rtc7800.c example.

 read battery status */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2010

 *

 * Author: Virupax Sadashivpetimath <virupax.sadashivpetimath@stericsson.com>

 *

 * RTC clock driver for the RTC part of the AB8500 Power management chip.

 * Based on RTC clock driver for the AB3100 Analog Baseband Chip by

 * Linus Walleij <linus.walleij@stericsson.com>

 RtcReadRequest bits */

 RtcCtrl bits */

 Request a data read */

 Wait for some cycles after enabling the rtc read in ab8500 */

 Read the Watchtime registers */

 Make the seconds count as per the RTC resolution */

 Request a data write */

 Check if the alarm is enabled or not */

 Set the alarm time */

	/*

	 * Check that the calibration value (which is in units of 0.5

	 * parts-per-million) is in the AB8500's range for RtcCalibration

	 * register. -128 (0x80) is not permitted because the AB8500 uses

	 * a sign-bit rather than two's complement, so 0x80 is just another

	 * representation of zero.

	/*

	 * The AB8500 uses sign (in bit7) and magnitude (in bits0-7)

	 * so need to convert to this sort of representation before writing

	 * into RtcCalibration register...

		/*

		 * The AB8500 uses sign (in bit7) and magnitude (in bits0-7)

		 * so need to convert value from RtcCalibration register into

		 * a two's complement signed value...

 sentinel */ }

 For RTC supply test */

 Wait for reset by the PorRtc */

 Check if the RTC Supply fails */

 24-bit minutes + 59 secs

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Driver for ST M41T93 SPI RTC

 *

 * (c) 2010 Nikolaus Voss, Weinmann Medical GmbH

 MSB must be '1' to write */

 write cmd + 8 data bytes */

 ptr to first data byte */

			/* OF cannot be immediately reset: oscillator has to be

	/* Check status of clock. Two states must be considered:

	   1. halt bit (HT) is set: the clock is running but update of readout

	      registers has been disabled due to power failure. This is normal

	      case after poweron. Time is valid after resetting HT bit.

	   2. oscillator fail bit (OF) is set: time is invalid.

 read actual time/date */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc-ds1305.c -- driver for DS1305 and DS1306 SPI RTC chips

 *

 * Copyright (C) 2008 David Brownell

/*

 * Registers ... mask DS1305_WRITE into register address to write,

 * otherwise you're reading it.  All non-bitmask values are BCD.

/* RTC date/time ... the main special cases are that we:

 *  - Need fancy "hours" encoding in 12hour mode

 *  - Don't rely on the "day-of-week" field (or tm_wday)

 *  - Are a 21st-century clock (2000 <= year < 2100)

 bytes for RTC regs */

 register addresses */

 set == 12 hr mode */

 set == PM (12hr mode) */

/* The two alarms have only sec/min/hour/wday fields (ALM_LEN).

 * DS1305_ALM_DISABLE disables a match field (some combos are bad).

 *

 * NOTE that since we don't use WDAY, we limit ourselves to alarms

 * only one day into the future (vs potentially up to a week).

 *

 * NOTE ALSO that while we could generate once-a-second IRQs (UIE), we

 * don't currently support them.  We'd either need to do it only when

 * no alarm is pending (not the standard model), or to use the second

 * alarm (implying that this is a DS1305 not DS1306, *and* that either

 * it's wired up a second IRQ we know, or that INTCN is set)

 bytes for ALM regs */

 register addresses */

 three control registers */

 bytes of control regs */

 register addresses */

 low enables oscillator */

 write protect */

 clear == only int0 used */

 enable 1Hz output */

 enable ALM1 IRQ */

 enable ALM0 IRQ */

 status has just AEIx bits, mirrored as IRQFx */

 trickle bits are defined in <linux/spi/ds1305.h> */

 a bunch of NVRAM */

 bytes of NVRAM */

 register addresses */

----------------------------------------------------------------------*/

/*

 * Utilities ...  tolerate 12-hour AM/PM notation in case of non-Linux

 * software (like a bootloader) which may require it.

----------------------------------------------------------------------*/

/*

 * Interface to RTC framework

/*

 * Get/set of date and time is pretty normal.

	/* Use write-then-read to get all the date/time registers

	 * since dma from stack is nonportable

 Decode the registers */

 Write registers starting at the first time/date address. */

 use write-then-read since dma from stack is nonportable */

/*

 * Get/set of alarm is a bit funky:

 *

 * - First there's the inherent raciness of getting the (partitioned)

 *   status of an alarm that could trigger while we're reading parts

 *   of that status.

 *

 * - Second there's its limited range (we could increase it a bit by

 *   relying on WDAY), which means it will easily roll over.

 *

 * - Third there's the choice of two alarms and alarm signals.

 *   Here we use ALM0 and expect that nINT0 (open drain) is used;

 *   that's the only real option for DS1306 runtime alarms, and is

 *   natural on DS1305.

 *

 * - Fourth, there's also ALM1, and a second interrupt signal:

 *     + On DS1305 ALM1 uses nINT1 (when INTCN=1) else nINT0;

 *     + On DS1306 ALM1 only uses INT1 (an active high pulse)

 *       and it won't work when VCC1 is active.

 *

 *   So to be most general, we should probably set both alarms to the

 *   same value, letting ALM1 be the wakeup event source on DS1306

 *   and handling several wiring options on DS1305.

 *

 * - Fifth, we support the polled mode (as well as possible; why not?)

 *   even when no interrupt line is wired to an IRQ.

/*

 * Context: caller holds rtc->ops_lock (to protect ds1305->ctrl)

	/* Refresh control register cache BEFORE reading ALM0 registers,

	 * since reading alarm registers acks any pending IRQ.  That

	 * makes returning "pending" status a bit of a lie, but that bit

	 * of EFI status is at best fragile anyway (given IRQ handlers).

 get and check ALM0 registers */

	/* Stuff these values into alm->time and let RTC framework code

	 * fill in the rest ... and also handle rollover to tomorrow when

	 * that's needed.

/*

 * Context: caller holds rtc->ops_lock (to protect ds1305->ctrl)

 convert desired alarm to time_t */

 Read current time as time_t */

 make sure alarm fires within the next 24 hours */

 disable alarm if needed */

 write alarm */

 enable alarm if requested */

 ctrl[2] is treated as read-only; no locking needed */

 lock to protect ds1305->ctrl */

	/* Disable the IRQ, and clear its status ... for now, we "know"

	 * that if more than one alarm is active, they're in sync.

	 * Note that reading ALM data registers also clears IRQ status.

/*

 * This "real" IRQ handler hands off to a workqueue mostly to allow

 * mutex locking for ds1305->ctrl ... unlike I2C, we could issue async

 * I/O requests in IRQ context (to clear the IRQ status).

----------------------------------------------------------------------*/

/*

 * Interface for NVRAM

----------------------------------------------------------------------*/

/*

 * Interface to SPI stack

	/* Sanity check board setup data.  This may be hooked up

	 * in 3wire mode, but we don't care.  Note that unless

	 * there's an inverter in place, this needs SPI_CS_HIGH!

 set up driver data */

 read and cache control registers */

	/* Sanity check register values ... partially compensating for the

	 * fact that SPI has no device handshake.  A pullup on MISO would

	 * make these tests fail; but not all systems will have one.  If

	 * some register is neither 0x00 nor 0xff, a chip is likely there.

	/* enable writes if needed ... if we were paranoid it would

	 * make sense to enable them only when absolutely necessary.

	/* on DS1305, maybe start oscillator; like most low power

	 * oscillators, it may take a second to stabilize

 ack any pending IRQs */

 this may need one-time (re)init */

 maybe enable trickle charge */

 on DS1306, configure 1 Hz signal */

 see if non-Linux software set up AM/PM mode */

 register RTC ... from here on, ds1305->ctrl needs locking */

	/* Maybe set up alarm IRQ; be ready to handle it triggering right

	 * away.  NOTE that we don't share this.  The signal is active low,

	 * and we can't ack it before a SPI message delay.  We temporarily

	 * disable the IRQ until it's acked, which lets us work with more

	 * IRQ trigger modes (not all IRQ controllers can do falling edge).

 carefully shut down irq and workqueue, if present */

 REVISIT add suspend/resume */

 SPDX-License-Identifier: GPL-2.0

/*

 *  pcap rtc code for Motorola EZX phones

 *

 *  Copyright (c) 2008 guiming zhuo <gmzhuo@gmail.com>

 *  Copyright (c) 2009 Daniel Ribeiro <drwyrm@gmail.com>

 *

 *  Based on Motorola's rtc.c Copyright (c) 2003-2005 Motorola

 time of day, seconds since midnight */

 days since 1/1/1970 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2016 Oleksij Rempel <linux@rempel-privat.de>

 Miscellaneous registers */

 Interrupt Location Register */

 Clock Control Register */

 Calibration counter disable */

 Reset internal oscillator divider */

 Clock Enable */

 Counter Increment Interrupt Register */

 Alarm Mask Register */

 Consolidated time registers */

 Time counter registers */

 General purpose registers */

 Alarm register group */

		/*

		 * woops, counter flipped right now. Now we are safe

		 * to reread.

	/*

	 * make sure SEC counter will not flip other counter on write time,

	 * real value will be written at the enf of sequence.

 if dev is not enabled, reset it */

 Disable alarm matching */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2019 BayLibre, SAS

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 * Copyright (C) 2015 Amlogic, Inc. All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * I2C client/driver for the ST M41T80 family of i2c rtc chips.

 *

 * Author: Alexander Bigga <ab@mycable.de>

 *

 * Based on m41t00.c by Mark A. Greer <mgreer@mvista.com>

 *

 * 2006 (c) mycable GmbH

 ST: Stop Bit */

 AFE: AF Enable Bit */

 SQWE: SQW Enable Bit */

 HT: Halt Update Bit */

 OF: Oscillator Failure Bit */

 AF: Alarm Flag Bit */

 BL: Battery Low Bit */

 RB: Watchdog resolution */

 RB: Watchdog resolution */

 RB: Watchdog resolution */

 Halt feature */

 Battery low indicator */

 Squarewave feature */

 Extra watchdog resolution */

 RSx bits are in reg 4 */

 DT compatibility only, do not use compatibles below: */

 assume 20YY not 19YY, and ignore the Century Bit */

 If the square wave output is controlled in the weekday register */

 Clear the OF bit of Flags Register */

 Clear AF and AFE flags */

 Keep SQWE bit value */

 Write the alarm */

 Enable the alarm interrupt */

		/*

		 * skip registering square wave clock when a fixed

		 * clock has been registered. The fixed clock is

		 * registered automatically when being referenced.

 First disable the clock */

 optional override of the clockname */

 register the clock */

/*

 *****************************************************************************

 *

 * Watchdog Driver

 *

 *****************************************************************************

 Default margin */

 1..31 seconds */

/**

 *	wdt_ping - Reload counter one with the watchdog timeout.

 *	We don't bother reloading the cascade counter.

 watchdog register */

 resolution = 4s */

		/*

		 * WDS = 1 (0x80), mulitplier = WD_TIMO, resolution = 1s (0x02)

	/*

	 * M41T65 has three bits for watchdog resolution.  Don't set bit 7, as

	 * that would be an invalid resolution.

/**

 *	wdt_disable - disables watchdog.

/**

 *	wdt_write - write to watchdog.

 *	@file: file handle to the watchdog

 *	@buf: buffer to write (unused as data does not matter here

 *	@count: count of bytes

 *	@ppos: pointer to the position to write. No seeks allowed

 *

 *	A write to a watchdog device is defined as a keepalive signal. Any

 *	write of data will do, as we we don't define content meaning.

/**

 *	wdt_ioctl - ioctl handler to set watchdog.

 *	@file: file handle to the device

 *	@cmd: watchdog command

 *	@arg: argument pointer

 *

 *	The watchdog API defines a common set of functions for all watchdogs

 *	according to their available features. We only actually usefully support

 *	querying capabilities and current status.

 Arbitrary, can't find the card's limits */

/**

 *	wdt_open - open a watchdog.

 *	@inode: inode of device

 *	@file: file handle to device

 *

		/*

		 *	Activate

/**

 *	wdt_release - release a watchdog.

 *	@inode: inode to board

 *	@file: file handle to board

 *

/**

 *	wdt_notify_sys - notify to watchdog.

 *	@this: our notifier block

 *	@code: the event being reported

 *	@unused: unused

 *

 *	Our notifier is called on system shutdowns. We want to turn the card

 *	off at reboot otherwise the machine will reboot again during memory

 *	test or worse yet during the following fsck. This would suck, in fact

 *	trust me - if it happens it does suck.

 Disable Watchdog */

/*

 *	The WDT card needs to learn about soft shutdowns in order to

 *	turn the timebomb registers off.

 CONFIG_RTC_DRV_M41T80_WDT */

/*

 *****************************************************************************

 *

 *	Driver Interface

 *

 *****************************************************************************

 We cannot support UIE mode if we do not have an IRQ line */

 Make sure HT (Halt Update) bit is cleared */

 Make sure ST (stop) bit is cleared */

 SPDX-License-Identifier: GPL-2.0+



 RTC driver for Maxim MAX8998



 Copyright (C) 2010 Samsung Electronics Co.Ltd

 Author: Minkyu Kang <mk7.kang@samsung.com>

 Author: Joonyoung Shim <jy0922.shim@samsung.com>

 LP3974 with delay bug chips has rtc alarm bugs with "MONTH" field */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright © 2014-2017 Broadcom

 Make sure we are actually counting in seconds */

 If enabled as a wakeup-source, arm the timer when powering off */

 Set timer for cold boot */

 Alarm is enabled */

/*

 * Does not do much but keep the RTC class happy. We always support

 * alarms.

	/*

	 * Set wakeup capability before requesting wakeup interrupt, so we can

	 * process boot-time "wakeups" (e.g., from S5 soft-off)

 CONFIG_PM_SLEEP */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An rtc driver for the Dallas DS1742

 *

 * Copyright (C) 2006 Atsushi Nemoto <anemo@mba.ocn.ne.jp>

 *

 * Copyright (C) 2006 Torsten Ertbjerg Rasmussen <tr@newtec.dk>

 *  - nvram size determined from resource

 *  - this ds1742 driver now supports ds1743.

 Bits in the Control/Century register */

 Bits in the Seconds register */

 Bits in the Day register */

 RTC_CENTURY and RTC_CONTROL share same register */

 give enough time to update RTC in case of continuous read */

 year is 1900 + tm->tm_year */

 turn RTC on if it was not on */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Dallas DS1302 RTC Support

 *

 *  Copyright (C) 2002 David McCullough

 *  Copyright (C) 2003 - 2007 Paul Mundt

 Read command */

 Write command */

 Write enable */

 Write disable */

 Address of RAM0 */

 Address of trickle charge register */

 Address of clock burst */

 Size of clock burst */

 Address of control register */

 Address of year register */

 Address of day of week register */

 Address of month register */

 Address of day of month register */

 Address of hour register */

 Address of minute register */

 Address of second register */

 Enable writing */

 Write registers starting at the first time/date address. */

 use write-then-read since dma from stack is nonportable */

	/* Use write-then-read to get all the date/time registers

	 * since dma from stack is nonportable

 Decode the registers */

	/* Sanity check board setup data.  This may be hooked up

	 * in 3wire mode, but we don't care.  Note that unless

	 * there's an inverter in place, this needs SPI_CS_HIGH!

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * Freescale STMP37XX/STMP378X Real Time Clock driver

 *

 * Copyright (c) 2007 Sigmatel, Inc.

 * Peter Hartley, <peter.hartley@sigmatel.com>

 *

 * Copyright 2008 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2008 Embedded Alley Solutions, Inc All Rights Reserved.

 * Copyright 2011 Wolfram Sang, Pengutronix e.K.

 missing bitmask in headers */

/**

 * stmp3xxx_wdt_set_timeout - configure the watchdog inside the STMP3xxx RTC

 * @dev: the parent device of the watchdog (= the RTC)

 * @timeout: the desired value for the timeout register of the watchdog.

 *           0 disables the watchdog

 *

 * The watchdog needs one register and two bits which are in the RTC domain.

 * To handle the resource conflict, the RTC driver will create another

 * platform_device for the watchdog driver as a child of the RTC device.

 * The watchdog driver is passed the below accessor function via platform_data

 * to configure the watchdog. Locking is not needed because accessing SET/CLR

 * registers is atomic.

 CONFIG_STMP3XXX_RTC_WATCHDOG */

 3ms according to i.MX28 Ref Manual */

	/*

	 * The i.MX28 Applications Processor Reference Manual, Rev. 1, 2010

	 * states:

	 * | The order in which registers are updated is

	 * | Persistent 0, 1, 2, 3, 4, 5, Alarm, Seconds.

	 * | (This list is in bitfield order, from LSB to MSB, as they would

	 * | appear in the STALE_REGS and NEW_REGS bitfields of the HW_RTC_STAT

	 * | register. For example, the Seconds register corresponds to

	 * | STALE_REGS or NEW_REGS containing 0x80.)

 Time read/write */

 interrupt(s) handler */

	/*

	 * Resetting the rtc stops the watchdog timer that is potentially

	 * running. So (assuming it is running on purpose) don't reset if the

	 * watchdog is enabled.

	/*

	 * Obviously the rtc needs a clock input to be able to run.

	 * This clock can be provided by an external 32k crystal. If that one is

	 * missing XTAL must not be disabled in suspend which consumes a

	 * lot of power. Normally the presence and exact frequency (supported

	 * are 32000 Hz and 32768 Hz) is detectable from fuses, but as reality

	 * proves these fuses are not blown correctly on all machines, so the

	 * frequency can be overridden in the device tree.

 keep 32kHz crystal running in low-power mode */

 keep 32.768kHz crystal running in low-power mode */

 keep XTAL on in low-power mode */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * Freescale FlexTimer Module (FTM) alarm device driver.

 *

 * Copyright 2014 Freescale Semiconductor, Inc.

 * Copyright 2019-2020 NXP

 *

/*

 * Select Fixed frequency clock (32KHz) as clock source

 * of FlexTimer Module

 Select 128 (2^7) as divider factor */

 Maximum counter value in FlexTimer's CNT registers */

 select and enable counter clock source */

 disable counter clock source */

	/*

	 *Fix errata A-007728 for flextimer

	 *	If the FTM counter reaches the FTM_MOD value between

	 *	the reading of the TOF bit and the writing of 0 to

	 *	the TOF bit, the process of clearing the TOF bit

	 *	does not work as expected when FTMx_CONF[NUMTOF] != 0

	 *	and the current TOF count is less than FTMx_CONF[NUMTOF].

	 *	If the above condition is met, the TOF bit remains set.

	 *	If the TOF interrupt is enabled (FTMx_SC[TOIE] = 1),the

	 *	TOF interrupt also remains asserted.

	 *

	 *	Above is the errata discription

	 *

	 *	In one word: software clearing TOF bit not works when

	 *	FTMx_CONF[NUMTOF] was seted as nonzero and FTM counter

	 *	reaches the FTM_MOD value.

	 *

	 *	The workaround is clearing TOF bit until it works

	 *	(FTM counter doesn't always reache the FTM_MOD anyway),

	 *	which may cost some cycles.

	/*

	 * The CNT register contains the FTM counter value.

	 * Reset clears the CNT register. Writing any value to COUNT

	 * updates the counter with its initial value, CNTIN.

/*

 * Note:

 *	The function is not really getting time from the RTC

 *	since FlexTimer is not a RTC device, but we need to

 *	get time to setup alarm, so we are using system time

 *	for now.

/*

 * 1. Select fixed frequency clock (32KHz) as clock source;

 * 2. Select 128 (2^7) as divider factor;

 * So clock is 250 Hz (32KHz/128).

 *

 * 3. FlexTimer's CNT register is a 32bit register,

 * but the register's 16 bit as counter value,it's other 16 bit

 * is reserved.So minimum counter value is 0x0,maximum counter

 * value is 0xffff.

 * So max alarm value is 262 (65536 / 250) seconds

	/*

	 * The counter increments until the value of MOD is reached,

	 * at which point the counter is reloaded with the value of CNTIN.

	 * The TOF (the overflow flag) bit is set when the FTM counter

	 * changes from MOD to CNTIN. So we should using the cycle - 1.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * rtc-tps65910.c -- TPS65910 Real Time Clock interface

 *

 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 * Author: Venu Byravarasu <vbyravarasu@nvidia.com>

 *

 * Based on original TI driver rtc-twl.c

 *   Copyright (C) 2007 MontaVista Software, Inc

 *   Author: Alexandre Rusev <source@mvista.com>

 Total number of RTC registers needed to set time*/

 Total number of RTC registers needed to set compensation registers */

 Min and max values supported with 'offset' interface (swapped sign) */

 Number of ticks per hour */

 Multiplier for ppb conversions */

/*

 * Gets current tps65910 RTC time and date parameters.

 *

 * The RTC's time/alarm representation is not what gmtime(3) requires

 * Linux to use:

 *

 *  - Months are 1..12 vs Linux 0-11

 *  - Years are 0..99 vs Linux 1900..N (we assume 21st century)

 Copy RTC counting registers to static registers or latches */

 Stop RTC while updating the RTC time registers */

 update all the time registers in one shot */

 Start back RTC */

/*

 * Gets current tps65910 RTC alarm time.

 update all the alarm registers in one shot */

	/*

	 * TPS65910 uses two's complement 16 bit value for compensation for RTC

	 * crystal inaccuracies. One time every hour when seconds counter

	 * increments from 0 to 1 compensation value will be added to internal

	 * RTC counter value.

	 *

	 * Compensation value 0x7FFF is prohibited value.

	 *

	 * Valid range for compensation value: [-32768 .. 32766]

 Update all the compensation registers in one shot */

 Enable automatic compensation */

 If automatic compensation is not enabled report back zero */

 Convert from RTC calibration register format to ppb format */

 Offset value operates in negative way, so swap sign */

 Make sure offset value is within supported range */

 Convert from ppb format to RTC calibration register format */

 Offset value operates in negative way, so swap sign */

 Notify RTC core on event */

 Clear pending interrupts */

 Enable RTC digital power domain */

 SPDX-License-Identifier: GPL-2.0+

/*

 * rtc-dm355evm.c - access battery-backed counter in MSP430 firmware

 *

 * Copyright (c) 2008 by David Brownell

/*

 * The MSP430 firmware on the DM355 EVM uses a watch crystal to feed

 * a 1 Hz counter.  When a backup battery is supplied, that makes a

 * reasonable RTC for applications where alarms and non-NTP drift

 * compensation aren't important.

 *

 * The only real glitch is the inability to read or write all four

 * counter bytes atomically:  the count may increment in the middle

 * of an operation, causing trouble when the LSB rolls over.

 *

 * This driver was tested with firmware revision A4.

		/*

		 * Read LSB(0) to MSB(3) bytes.  Defend against the counter

		 * rolling over by re-reading until the value is stable,

		 * and assuming the four reads take at most a few seconds.

	/*

	 * REVISIT handle non-atomic writes ... maybe just retry until

	 * byte[1] sticks (no rollover)?

----------------------------------------------------------------------*/

/*

 * I2C is used to talk to the MSP430, but this platform device is

 * exposed by an MFD driver that manages I2C communications.

 SPDX-License-Identifier: GPL-2.0

/*

 * An rtc/i2c driver for the Dallas DS1672

 * Copyright 2005-06 Tower Technologies

 *

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 Registers */

/*

 * In the routines that deal directly with the ds1672 hardware, we use

 * rtc_time -- month 0-11, hour 0-23, yr = calendar year-epoch

 * Time is set to UTC.

 setup read ptr */

 read date */

 read control register */

 read date registers */

 set control reg to enable counting */

 SPDX-License-Identifier: GPL-2.0

/*

 * MOXA ART RTC driver.

 *

 * Copyright (C) 2013 Jonas Jensen

 *

 * Jonas Jensen <jonas.jensen@gmail.com>

 *

 * Based on code from

 * Moxa Technology Co., Ltd. <www.moxa.com>

 12-hour mode */

 PM mode */

 24-hour mode */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * An RTC driver for Allwinner A31/A23

 *

 * Copyright (c) 2014, Chen-Yu Tsai <wens@csie.org>

 *

 * based on rtc-sunxi.c

 *

 * An RTC driver for Allwinner A10/A20

 *

 * Copyright (c) 2013, Carlo Caione <carlo.caione@gmail.com>

 Control register */

 RTC */

 Alarm 0 (counter) */

 Alarm 1 (wall clock) */

 Alarm config */

/*

 * Get date values

/*

 * Get time values

/*

 * Set date values

/*

 * Set time values

/*

 * The year parameter passed to the driver is usually an offset relative to

 * the year 1900. This macro is used to convert this offset to another one

 * relative to the minimum year allowed by the hardware.

 *

 * The year range is 1970 - 2033. This range is selected to match Allwinner's

 * driver, even though it is somewhat limited.

/*

 * There are other differences between models, including:

 *

 *   - number of GPIO pins that can be configured to hold a certain level

 *   - crypto-key related registers (H5, H6)

 *   - boot process related (super standby, secondary processor entry address)

 *     registers (R40, H6)

 *   - SYS power domain controls (R40)

 *   - DCXO controls (H6)

 *   - RC oscillator calibration (H6)

 *

 * These functions are not covered by this driver.

 Bypass auto-switch to int osc, on ext losc failure */

 Switch to the external, more precise, oscillator, if present */

 Yes, I know, this is ugly. */

 Only read IOSC name from device tree if it is exported */

 If there is no external oscillator, this will be NULL and ... */

 ... number of clock parents will be 1. */

 datasheet says 600 ~ 700 KHz */

 datasheet says 600 ~ 700 KHz */

 As far as we are concerned, clocks for H5 are the same as H3 */

/*

 * The R40 user manual is self-conflicting on whether the prescaler is

 * fixed or configurable. The clock diagram shows it as fixed, but there

 * is also a configurable divider in the RTC block.

	/*

	 * read again in case it changes

	/*

	 * switch from (data_year->min)-relative offset to

	 * a (1900)-relative one

 Check whether registers are writable */

	/*

	 * After writing the RTC HH-MM-SS register, the

	 * SUN6I_LOSC_CTRL_RTC_HMS_ACC bit is set and it will not

	 * be cleared until the real writing operation is finished

	/*

	 * After writing the RTC YY-MM-DD register, the

	 * SUN6I_LOSC_CTRL_RTC_YMD_ACC bit is set and it will not

	 * be cleared until the real writing operation is finished

 Enable IRQ wake on suspend, to wake up from RTC. */

 Disable IRQ wake on resume. */

 clear the alarm counter value */

 disable counter alarm */

 disable counter alarm interrupt */

 disable week alarm */

 disable week alarm interrupt */

 clear counter alarm pending interrupts */

 clear week alarm pending interrupts */

 disable alarm wakeup */

 2033-12-31 23:59:59 */

/*

 * As far as RTC functionality goes, all models are the same. The

 * datasheets claim that different models have different number of

 * registers available for non-volatile storage, but experiments show

 * that all SoCs have 16 registers available for this purpose.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0+

/*

 * An I2C driver for the Intersil ISL 12026

 *

 * Copyright (c) 2018 Cavium, Inc.

 register offsets */

 military or 24 hour time */

 The EEPROM array responds at i2c address 0x57 */

 Set SR.WEL */

 Set SR.WEL and SR.RWEL */

 Set the CCR registers */

 SC */

 MN */

 HR */

 DT */

 MO */

 YR */

 DW */

 Y2K */

 First, read SR */

 Second, CCR regs */

	/*

	 * offset and bytes checked and limited by nvmem core, so

	 * proceed without further checks.

 2 bytes of address, most significant first */

 page + 2 address bytes */

	/*

	 * offset and bytes checked and limited by nvmem core, so

	 * proceed without further checks.

		/*

		 * 2 bytes of address, most significant first, followed

		 * by page data bytes

	/*

	 * If we can read the of_property, set the specified value.

	 * If there is an error reading the of_property (likely

	 * because it does not exist), keep the current value.

 Check if PWR.BSW and/or PWR.SBIB need specified values */

 else keep current BSW */

 else keep current SBIB */

 SPDX-License-Identifier: GPL-2.0

/*

 * An I2C driver for the PCF85063 RTC

 * Copyright 2014 Rose Technology

 *

 * Author: Søren Andersen <san@rosetechnology.dk>

 * Maintainers: http://www.nslu2-linux.org/

 *

 * Copyright (C) 2019 Micro Crystal AG

 * Author: Alexandre Belloni <alexandre.belloni@bootlin.com>

/*

 * Information for this driver was pulled from the following datasheets.

 *

 *  https://www.nxp.com/docs/en/data-sheet/PCF85063A.pdf

 *  https://www.nxp.com/docs/en/data-sheet/PCF85063TP.pdf

 *

 *  PCF85063A -- Rev. 7 — 30 March 2018

 *  PCF85063TP -- Rev. 4 — 6 May 2015

 *

 *  https://www.microcrystal.com/fileadmin/Media/Products/RTC/App.Manual/RV-8263-C7_App-Manual.pdf

 *  RV8263 -- Rev. 1.0 — January 2019

 status */

 2's complement sign bit */

 frequency mask */

 datetime */

	/*

	 * while reading, the time/date registers are blocked and not updated

	 * anymore until the access is finished. To not lose a second

	 * event, the access must be finished within one second. So, read all

	 * time/date registers in one turn.

 if the clock has lost its power it makes no sense to use its time */

 rtc hr 0-23 */

 rtc mn 1-12 */

	/*

	 * to accurately set the time, reset the divider chain and keep it in

	 * reset state until all time/date registers are written

 hours, minutes and seconds */

 clear OS flag */

 Day of month, 1 - 31 */

 Day, 0 - 6 */

 month, 1 - 12 */

 year and century */

 write all registers at once */

	/*

	 * Write the control register as a separate action since the size of

	 * the register space is different between the PCF85063TP and

	 * PCF85063A devices.  The rollover point can not be used.

 Do not match on week day */

/*

 * Handling of the clkout

		/*

		 * skip registering square wave clock when a fixed

		 * clock has been registered. The fixed clock is

		 * registered automatically when being referenced.

 optional override of the clockname */

 register the clock */

 register clk in common clk framework */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  drivers/rtc/rtc-pcf8583.c

 *

 *  Copyright (C) 2000 Russell King

 *  Copyright (C) 2008 Wolfram Sang & Juergen Beisert, Pengutronix

 *

 *  Driver for PCF8583 RTC & RAM chip

 *

 *  Converted to the generic RTC susbsystem by G. Liakhovetski (2006)

	/*

	 * Ensure that the RTC is running.

	/*

	 * The RTC year holds the LSB two bits of the current

	 * year, which should reflect the LSB two bits of the

	 * CMOS copy of the year.  Any difference indicates

	 * that we have to correct the CMOS version.

		/*

		 * RTC year wrapped.  Adjust it appropriately.

	/*

	 * The RTC's own 2-bit year must reflect the least

	 * significant two bits of the CMOS year.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Real Time Clock driver for Wolfson Microelectronics WM8350

 *

 *	Copyright (C) 2007, 2008 Wolfson Microelectronics PLC.

 *

 *  Author: Liam Girdwood

 *          linux@wolfsonmicro.com

/*

 * Read current time and date in RTC

	/*

	 * Read the time twice and compare.

	 * If time1 == time2, then time is valid else retry.

/*

 * Set current time and date in RTC

 Set RTC_SET to stop the clock */

 Wait until confirmation of stopping */

 Write time to RTC */

 Clear RTC_SET to start the clock */

/*

 * Read alarm time and date in RTC

 Set RTC_SET to stop the clock */

 Wait until confirmation of stopping */

 Wait until confirmation */

 Write time to RTC */

 Make it one shot */

 enable the RTC if it's not already enabled */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * rtc-st-lpc.c - ST's LPC RTC, powered by the Low Power Timer

 *

 * Copyright (C) 2014 STMicroelectronics Limited

 *

 * Author: David Paris <david.paris@st.com> for STMicroelectronics

 *         Lee Jones <lee.jones@linaro.org> for STMicroelectronics

 *

 * Based on the original driver written by Stuart Menefy.

 Low Power Timer */

 Low Power Alarm */

 LPC as WDT */

 Now many secs to fire */

 LPC can either run as a Clocksource or in RTC or WDT mode */

	/*

	 * clean 'rtc->alarm' to allow a new

	 * .set_alarm to the upper RTC layer

 SPDX-License-Identifier: GPL-2.0-or-later

/* NXP PCF50633 RTC Driver

 *

 * (C) 2006-2008 by Openmoko, Inc.

 * Author: Balaji Rao <balajirrao@openmoko.org>

 * All rights reserved.

 *

 * Broken down from monstrous PCF50633 driver mainly by

 * Harald Welte, Andy Green and Werner Almesberger

 Second */

 Minute */

 Hour */

 Weekday */

 Day */

 Month */

 Year */

 Alarm Second */

 Alarm Minute */

 Alarm Hour */

 Alarm Weekday */

 Alarm Day */

 Alarm Month */

 Alarm Year */

 always last */

 Returns 0 on success */

 do like mktime does and ignore tm_wday */

 disable alarm interrupt */

 Returns 0 on success */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TI LP8788 MFD - rtc driver

 *

 * Copyright 2012 Texas Instruments

 *

 * Author: Milo(Woogyom) Kim <milo.kim@ti.com>

 register address */

 mask/shift bits */

 Addr 05h */

 Addr 05h */

 Addr 7Dh or 84h */

 lookup defined weekday from read register value */

 because rtc weekday is a readonly register, do not update */

 even the alarm IRQ number is not specified, rtc time should work */

 SPDX-License-Identifier: GPL-2.0-or-later



 Copyright (C) 2018 ROHM Semiconductors



 RTC driver for ROHM BD71828 and BD71815 PMIC

/*

 * On BD71828 and BD71815 the ALM0 MASK is 14 bytes after the ALM0

 * block start

/*

 * We read regs RTC_SEC => RTC_YEAR

 * this struct is ordered according to chip registers.

 * Keep it u8 only (or packed) to avoid padding issues.

	/*

	 * PM and 24H bits are not used by Wake - thus we clear them

	 * here and not in tmday2rtc() which is also used by wake.

	/*

	 * We do always set time in 24H mode.

	/*

	 * If RTC is in 12H mode, then bit BD70528_MASK_RTC_HOUR_PM

	 * is not BCD value but tells whether it is AM or PM

 read the RTC date and time registers all at once */

		/*

		 * See also BD718XX_ALM_EN_OFFSET:

		 * This works for BD71828 and BD71815 as they have same offset

		 * between ALM0 start and ALM0_MASK. If new ICs are to be

		 * added this requires proper check as ALM0_MASK is not located

		 * at the end of ALM0 block - but after all ALM blocks so if

		 * amount of ALMs differ the offset to enable/disable is likely

		 * to be incorrect and enable/disable must be given as own

		 * reg address here.

 Request alarm IRQ prior to registerig the RTC */

 SPDX-License-Identifier: GPL-2.0

/* rtc-sun4v.c: Hypervisor based RTC for SUN4V systems.

 *

 * Author: David S. Miller

 *

 * Copyright (C) 2008 David S. Miller <davem@davemloft.net>

 SPDX-License-Identifier: GPL-2.0+

/*

 * "RTT as Real Time Clock" driver for AT91SAM9 SoC family

 *

 * (C) 2007 Michel Benoit

 *

 * Based on rtc-at91rm9200.c by Rick Bronson

/*

 * This driver uses two configurable hardware resources that live in the

 * AT91SAM9 backup power domain (intended to be powered at all times)

 * to implement the Real Time Clock interfaces

 *

 *  - A "Real-time Timer" (RTT) counts up in seconds from a base time.

 *    We can't assign the counter value (CRTV) ... but we can reset it.

 *

 *  - One of the "General Purpose Backup Registers" (GPBRs) holds the

 *    base time, normally an offset from the beginning of the POSIX

 *    epoch (1970-Jan-1 00:00:00 UTC).  Some systems also include the

 *    local timezone's offset.

 *

 * The RTC's value is the RTT counter plus that offset.  The RTC's alarm

 * is likewise a base (ALMV) plus that offset.

 *

 * Not all RTTs will be used as RTCs; some systems have multiple RTTs to

 * choose from, or a "real" RTC module.  All systems have multiple GPBR

 * registers available, likewise usable for more than "RTC" support.

 Real-time Mode Register */

 Timer Prescaler Value */

 Alarm Interrupt Enable */

 Increment Interrupt Enable */

 Timer Restart */

 Real-time Alarm Register */

 Alarm Value */

 Real-time Value Register */

 Current Real-time Value */

 Real-time Status Register */

 Alarm Status */

 Timer Increment */

/*

 * We store ALARM_DISABLED in ALMV to record that no alarm is set.

 * It's also the reset value for that field.

/*

 * Read current time and date in RTC

 read current time offset */

 reread the counter to help sync the two clock domains */

/*

 * Set current time and date in RTC

 disable interrupts */

 read current time offset */

 store the new base time in a battery backup register */

 adjust the alarm time for the new base */

 time jumped backwards, increase time until alarm */

 time jumped forwards, decrease time until alarm */

 time jumped past the alarm, disable alarm */

 reset the timer, and re-enable interrupts */

 time is not set */

 alarm in the past? finish and leave disabled */

 else set alarm and maybe enable it */

/*

 * Provide additional RTC information in /proc/driver/rtc

	/* Shared interrupt may be for another device.  Note: reading

	 * SR clears it, so we must only read it in this irq handler!

 alarm status */

 timer update/increment */

/*

 * IRQ handler for the RTC

 We're called in suspended state */

 Mask irqs coming from this peripheral */

 Trigger a system wakeup */

/*

 * Initialize and install RTC driver

 platform setup code should have handled this; sigh */

 unless RTT is counting at 1 Hz, re-initialize it */

 disable all interrupts (same as on shutdown path) */

 register irq handler after we know what name we'll use */

	/* NOTE:  sam9260 rev A silicon has a ROM bug which resets the

	 * RTT on at least some reboots.  If you have that chip, you must

	 * initialize the time from some external source like a GPS, wall

	 * clock, discrete RTC, etc

/*

 * Disable and remove the RTC driver

 disable all interrupts */

 AT91SAM9 RTC Power management control */

	/*

	 * This IRQ is shared with DBGU and other hardware which isn't

	 * necessarily a wakeup event source.

 don't let RTTINC cause wakeups */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/rtc/rtc-spear.c

 *

 * Copyright (C) 2010 ST Microelectronics

 * Rajeev Kumar<rajeev-dlh.kumar@st.com>

 RTC registers */

 TIME_REG & ALARM_TIME_REG */

 seconds units position */

 seconds tens position */

 minutes units position */

 minutes tens position */

 hours units position */

 hours tens position */

 DATE_REG & ALARM_DATE_REG */

 days units position */

 days tens position */

 months units position */

 months tens position */

 years units position */

 years tens position */

 years hundereds position */

 years millenium position */

 MASK SHIFT TIME_REG & ALARM_TIME_REG*/

 seconds units */

 minutes units position */

 hours units position */

 Month day shift */

 Month shift */

 Year shift */

 date reg equal to time reg, for debug only */

 interrupt enable */

 STATUS_REG */

 Assuming BUSY may stay active for 80 msec) */

 check status busy, after each msec */

 epoch == 1900 */

/*

 * spear_rtc_read_time - set the time

 * @dev: rtc device in use

 * @tm: holds date and time

 *

 * This function read time and date. On success it will return 0

 * otherwise -ve error is returned.

 we don't report wday/yday/isdst ... */

/*

 * spear_rtc_set_time - set the time

 * @dev: rtc device in use

 * @tm: holds date and time

 *

 * This function set time and date. On success it will return 0

 * otherwise -ve error is returned.

/*

 * spear_rtc_read_alarm - read the alarm time

 * @dev: rtc device in use

 * @alm: holds alarm date and time

 *

 * This function read alarm time and date. On success it will return 0

 * otherwise -ve error is returned.

/*

 * spear_rtc_set_alarm - set the alarm time

 * @dev: rtc device in use

 * @alm: holds alarm date and time

 *

 * This function set alarm time and date. On success it will return 0

 * otherwise -ve error is returned.

 alarm off */

 alarm on */

 alarm irqs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Avionic Design GmbH

 battery low bit, read-only */

 This will purposely overwrite PCF8523_SECONDS_OS */

		/*

		 * If the time cannot be set, restart the RTC anyway. Note

		 * that errors are ignored if the RTC cannot be started so

		 * that we have a chance to propagate the original error.

 The alarm has no seconds, round up to nearest minute */

 sign extend the 7-bit offset value */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) STMicroelectronics 2017

 * Author:  Amelie Delaunay <amelie.delaunay@st.com>

 STM32_RTC_TR bit fields  */

 STM32_RTC_DR bit fields */

 STM32_RTC_CR bit fields */

 STM32_RTC_ISR/STM32_RTC_ICSR bit fields */

 STM32_RTC_PRER bit fields */

 STM32_RTC_ALRMAR and STM32_RTC_ALRMBR bit fields */

 STM32_RTC_SR/_SCR bit fields */

 STM32_RTC_VERR bit fields */

 STM32_RTC_WPR key constants */

 Max STM32 RTC register offset is 0x3FC */

		/*

		 * It takes around 2 rtc_ck clock cycles to enter in

		 * initialization phase mode (and have INITF flag set). As

		 * slowest rtc_ck frequency may be 32kHz and highest should be

		 * 1MHz, we poll every 10 us with a timeout of 100ms.

	/*

	 * Wait for RSF to be set to ensure the calendar registers are

	 * synchronised, it takes around 2 rtc_ck clock cycles

 Alarm A flag - Alarm interrupt */

 Pass event to the kernel */

 Clear event flags, otherwise new events won't be received */

 Convert rtc_time structure from bin to bcd format */

	/*

	 * Number of days since Sunday

	 * - on kernel side, 0=Sunday...6=Saturday

	 * - on rtc side, 0=invalid,1=Monday...7=Sunday

 Convert rtc_time structure from bcd to bin format */

	/*

	 * Number of days since Sunday

	 * - on kernel side, 0=Sunday...6=Saturday

	 * - on rtc side, 0=invalid,1=Monday...7=Sunday

 Time and Date in BCD format */

 We don't report tm_yday and tm_isdst */

 Time in BCD format */

 Date in BCD format */

		/*

		 * Date/day doesn't matter in Alarm comparison so alarm

		 * triggers every day

 Alarm is set to a day of week */

 Alarm is set to a day of month */

 Hours don't matter in Alarm comparison */

 Minutes don't matter in Alarm comparison */

 Seconds don't matter in Alarm comparison */

 We expose Alarm A to the kernel */

 Clear event flags, otherwise new events won't be received */

	/*

	 * Assuming current date is M-D-Y H:M:S.

	 * RTC alarm can't be set on a specific month and year.

	 * So the valid alarm range is:

	 *	M-D-Y H:M:S < alarm <= (M+1)-D-Y H:M:S

	 * with a specific case for December...

	/*

	 * RTC alarm can't be set on a specific date, unless this date is

	 * up to the same day of month next month.

 tm_year and tm_mon are not used because not supported by RTC */

 24-hour format */

 Disable Alarm */

	/*

	 * Poll Alarm write flag to be sure that Alarm update is allowed: it

	 * takes around 2 rtc_ck clock cycles

 Write to Alarm register */

 Flags are cleared by writing 0 in RTC_ISR */

 set to ISR offset to ease alarm management */

 set to ISR offset to ease alarm management */

 Flags are cleared by writing 1 in RTC_SCR */

 named RTC_ICSR on stm32mp1 */

 Find prediv_a and prediv_s to obtain the 1Hz calendar clock */

	/*

	 * Can't find a 1Hz, so give priority to RTC power consumption

	 * by choosing the higher possible value for prediv_a

 Force 24h time format */

	/*

	 * After a system reset, RTC_ISR.INITS flag can be read to check if

	 * the calendar has been initialized or not. INITS flag is reset by a

	 * power-on reset (no vbat, no power-supply). It is not reset if

	 * rtc_ck parent clock has changed (so RTC prescalers need to be

	 * changed). That's why we cannot rely on this flag to know if RTC

	 * init has to be done.

 Handle RTC alarm interrupts */

	/*

	 * If INITS flag is reset (calendar year field set to 0x00), calendar

	 * must be initialized

 Disable interrupts */

 Enable backup domain write protection if needed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc-palmas.c -- Palmas Real Time Clock driver.



 * RTC driver for TI Palma series devices like TPS65913,

 * TPS65914 power management IC.

 *

 * Copyright (c) 2012, NVIDIA Corporation.

 *

 * Author: Laxman Dewangan <ldewangan@nvidia.com>

 Total number of RTC registers needed to set time*/

 Copy RTC counting registers to static registers or latches */

 Stop RTC while updating the RTC time registers */

 Start back RTC */

 Clear pending interrupts */

 Start RTC */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Seiko Instruments S-35390A RTC Driver

 *

 * Copyright (c) 2007 Byron Bradley

 flags for STATUS1 */

 flag for STATUS2 */

 INT2 pin output mode */

 INT2AE */

 INT2ME */

 INT2FE */

 INT2FE | INT2ME */

	/*

	 * At least one of POC and BLD are set, so reinitialise chip. Keeping

	 * this information in the hardware to know later that the time isn't

	 * valid is unfortunately not possible because POC and BLD are cleared

	 * on read. So the reset is best done now.

	 *

	 * The 24H bit is kept over reset, so set it already here.

 Try up to five times to reset the chip */

/*

 * Returns <0 on error, 0 if rtc is setup fine and 1 if the chip was reset.

 * To keep the information if an irq is pending, pass the value read from

 * STATUS1 to the caller.

		/*

		 * Do not communicate for 0.5 seconds since the power-on

		 * detection circuit is in operation.

	/*

	 * If both POC and BLD are unset everything is fine.

 This chip expects the bits of each byte to be in reverse order */

 This chip returns the bits of each byte in reverse order */

 disable interrupt (which deasserts the irq line) */

 clear pending interrupt (in STATUS1 only), if any */

 set interupt mode*/

		/*

		 * When the alarm isn't enabled, the register to configure

		 * the alarm time isn't accessible.

 This chip returns the bits of each byte in reverse order */

	/*

	 * B0 of the three matching registers is an enable flag. Iff it is set

	 * the configured value is used for matching.

 alarm triggers always at s=0 */

 s35390a_reset set lowvoltage flag and init RTC if needed */

 update flag and clear register */

 This chip uses multiple addresses, use dummy devices for them */

 disable alarm (and maybe test mode) */

 SPDX-License-Identifier: GPL-2.0+

/*

 * APM X-Gene SoC Real Time Clock Driver

 *

 * Copyright (c) 2014, Applied Micro Circuits Corporation

 * Author: Rameshwar Prasad Sahu <rsahu@apm.com>

 *         Loc Ho <lho@apm.com>

 RTC CSR Registers */

	/*

	 * NOTE: After the following write, the RTC_CCVR is only reflected

	 *       after the update cycle of 1 seconds.

 Force a barrier */

 If possible, CMR should be read here */

 Check if interrupt asserted */

 Clear interrupt */

 Turn on the clock and the crystal */

 HW does not support update faster than 1 seconds */

	/*

	 * If this RTC alarm will be used for waking the system up,

	 * don't disable it of course. Else we just disable the alarm

	 * and await suspension.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * RTC client/driver for the Maxim/Dallas DS1374 Real-Time Clock over I2C

 *

 * Based on code by Randy Vinson <rvinson@mvista.com>,

 * which was based on the m41t00.c by Mark Greer <mgreer@mvista.com>.

 *

 * Copyright (C) 2014 Rose Technology

 * Copyright (C) 2006-2007 Freescale Semiconductor

 * Copyright (c) 2005 MontaVista Software, Inc.

/*

 * It would be more efficient to use i2c msgs/i2c_transfer directly but, as

 * recommended in .../Documentation/i2c/writing-clients.rst section

 * "Sending and receiving", using SMBus level communication is preferred.

 Time of Day */

 Watchdog/Alarm */

 Control */

 Alarm Int. Enable */

 1=INT, 0=RST */

 1=Watchdog, 0=Alarm */

 WD/Alarm counter enable */

 Status */

 Oscillator Stop Flag */

 Alarm Flag */

 Trickle Charge */

	/* The mutex protects alarm operations, and prevents a race

	 * between the enable_irq() in the workqueue and the free_irq()

	 * in the remove function.

	/* If the alarm is pending, clear it before requesting

	 * the interrupt, so an interrupt event isn't reported

	 * before everything is initialized.

/* The ds1374 has a decrementer for an alarm, rather than a comparator.

 * If the time of day is changed, then the alarm will need to be

 * reset.

	/* This can happen due to races, in addition to dates that are

	 * truly in the past.  To avoid requiring the caller to check for

	 * races, dates in the past are assumed to be in the recent past

	 * (i.e. not something that we'd rather the caller know about via

	 * an error), and the alarm is set to go off as soon as possible.

	/* Disable any existing alarm before setting the new one

/*

 *****************************************************************************

 *

 * Watchdog Driver

 *

 *****************************************************************************

 Default margin */

 24-bit value */

 Disable any existing watchdog/alarm before setting the new one */

 Set new watchdog time */

 Enable watchdog timer */

 for RST PIN */

/*

 * Reload the watchdog timer.  (ie, pat the watchdog)

 Disable watchdog timer */

CONFIG_RTC_DRV_DS1374_WDT*/

/*

 *****************************************************************************

 *

 *	Driver Interface

 *

 *****************************************************************************

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Oki MSM6242 RTC Driver

 *

 *  Copyright 2009 Geert Uytterhoeven

 *

 *  Based on the A2000 TOD code in arch/m68k/amiga/config.c

 *  Copyright (C) 1993 Hamish Macdonald

 1-second digit register */

 10-second digit register */

 1-minute digit register */

 10-minute digit register */

 1-hour digit register */

 PM/AM, 10-hour digit register */

 1-day digit register */

 10-day digit register */

 1-month digit register */

 10-month digit register */

 1-year digit register */

 10-year digit register */

 Week register */

 Control Register D */

 Control Register E */

 Control Register F */

 30-second adjustment */

 period 1/64 second */

 period 1 second */

 period 1 minute */

 period 1 hour */

 STD.P output control */

 reset */

 SPDX-License-Identifier: GPL-2.0+

/*

 * drivers/rtc/rtc-rc5t619.c

 *

 * Real time clock driver for RICOH RC5T619 power management chip.

 *

 * Copyright (C) 2019 Andreas Kemnade

 disable function */

 clear alarm flag and CTFG */

 things to be done once after power on */

 clear VDET PON */

 0101-1011 */

 0010-0000 */

 clearing RTC Adjust register */

 back to system 0-11 */

 system set 0-11 */

 0-disable, 1-enable */

 clear alarm-D status bits.*/

 disable rtc periodic function */

 set interrupt and enable it */

 enable wake */

 system don't want to using alarm interrupt, so close it */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2013-2014 Samsung Electronics Co., Ltd

	http:


  Copyright (C) 2013 Google, Inc

/*

 * Maximum number of retries for checking changes in UDR field

 * of S5M_RTC_UDR_CON register (to limit possible endless loop).

 *

 * After writing to RTC registers (setting time or alarm) read the UDR field

 * in S5M_RTC_UDR_CON register. UDR is auto-cleared when data have

 * been transferred.

 Make sure this is always the last enum name. */

/*

 * Registers used by the driver which are different between chipsets.

 *

 * Operations like read time and write alarm/time require updating

 * specific fields in UDR register. These fields usually are auto-cleared

 * (with some exceptions).

 *

 * Table of operations per device:

 *

 * Device     | Write time | Read time | Write alarm

 * =================================================

 * S5M8767    | UDR + TIME |           | UDR

 * S2MPS11/14 | WUDR       | RUDR      | WUDR + RUDR

 * S2MPS13    | WUDR       | RUDR      | WUDR + AUDR

 * S2MPS15    | WUDR       | RUDR      | AUDR

 Number of registers used for setting time/alarm0/alarm1 */

 First register for time, seconds */

 RTC control register */

 First register for alarm 0, seconds */

 First register for alarm 1, seconds */

	/*

	 * Register for update flag (UDR). Typically setting UDR field to 1

	 * will enable update of time or alarm register. Then it will be

	 * auto-cleared after successful update.

 Auto-cleared mask in UDR field for writing time and alarm */

	/*

	 * Masks in UDR field for time and alarm operations.

	 * The read time mask can be 0. Rest should not.

 Register map for S5M8763 and S5M8767 */

 Not needed */

 Register map for S2MPS13 */

 Register map for S2MPS11/14 */

/*

 * Register map for S2MPS15 - in comparison to S2MPS14 the WUDR and AUDR bits

 * are swapped.

/*

 * Read RTC_UDR_CON register and wait till UDR field is cleared.

 * This indicates that time/alarm update ended.

 No exceptions needed */

 On S2MPS13 the AUDR is not auto-cleared */

 UDR update time. Default of 7.32 ms is too long. */

 Set RTC control register : Binary mode, 24hour mode */

		/*

		 * Should set WUDR & (RUDR or AUDR) bits to high after writing

		 * RTC_CTRL register like writing Alarm registers. We can't find

		 * the description from datasheet but vendor code does that

		 * really.

 CONFIG_PM_SLEEP */

 Module information */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Intersil ISL1208 rtc class driver

 *

 * Copyright 2005,2006 Hebert Valerio Riedel <hvr@gnu.org>

 Register map */

 rtc section */

 24h/12h mode */

 PM/AM bit in 12h mode */

 control/status section */

 auto reset */

 crystal oscillator */

 write rtc */

 event */

 alarm */

 battery */

 rtc fail */

 alarm enable */

 interrupt/alarm mode */

 event detection enable */

 event in pull-up disable */

 alarm section */

 user section */

 event section */

 ISL1208 various variants */

 Chip capabilities table */

 Device state */

 block read */

 block write */

 simple check to see whether we have a isl1208 */

 check if bits are cleared */

	/* The 6bit value in the ATR register controls the load

	 * capacitance C_load * in steps of 0.25pF

	 *

	 * bit (1<<5) of the ATR register is inverted

	 *

	 * C_load(ATR=0x20) =  4.50pF

	 * C_load(ATR=0x00) = 12.50pF

	 * C_load(ATR=0x1f) = 20.25pF

	 *

 mask out lsb */

 invert 6th bit */

 add offset of 4.5pF; unit[atr] = 0.25pF */

 returns adjustment value + 100 */

 dtr encodes adjustments of {-60,-40,-20,0,20,40,60} ppm */

 HR field has a more complex interpretation */

 24h format */

 12h format */

 PM flag set */

 rtc starts at 1 */

 MSB of each alarm register is an enable bit */

 The alarm doesn't store the year so get it from the rtc section */

 If the alarm time is before the current time disable the alarm */

 Program the alarm and enable it for each setting */

 write ALARM registers */

	/* The clock has an 8 bit wide bcd-coded register (they never learn)

	 * for the year. tm_year is an offset from 1900 and we are interested

	 * in the 2000-2099 range, so any value less than 100 is invalid.

 set WRTC */

 write RTC registers */

 clear WRTC again */

 MSB of each alarm register is an enable bit */

	/*

	 * I2C reads get NAK'ed if we read straight away after an interrupt?

	 * Using a mdelay/msleep didn't seem to help either, so we work around

	 * this by continually trying to read the register for a short time.

 Clear the alarm */

 Disable the alarm */

 sysfs interface */

 nvmem sanitizes offset/count for us, but count==0 is possible */

 nvmem sanitizes off/count for us, but count==0 is possible */

 .size from chip specific config */

 Allocate driver state, point i2c client data to it */

 Determine which chip we have */

 Setup nvmem configuration in driver state struct */

 SPDX-License-Identifier: GPL-2.0-only

/* drivers/rtc/rtc-max6902.c

 *

 * Copyright (C) 2006 8D Technologies inc.

 * Copyright (C) 2004 Compulab Ltd.

 *

 * Driver for MAX6902 spi RTC

 MSB must be '0' to write */

 Set MSB to indicate read */

 Burst read */

	/* The chip sends data in this order:

 Read century */

 Remove write protection */

	/* Compulab used a delay here. However, the datasheet

 delay(2000); */

 Write protect */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for TI BQ32000 RTC.

 *

 * Copyright (C) 2009 Semihalf.

 * Copyright (C) 2014 Pavel Machek <pavel@denx.de>

 *

 * You can get hardware description at

 * https://www.ti.com/lit/ds/symlink/bq32000.pdf

 Seconds register address */

 Mask over seconds value */

 Oscillator Stop flat */

 Minutes register address */

 Mask over minutes value */

 Oscillator Failure flag */

 Mask over hours value */

 Century flag */

 Century flag enable bit */

 CAL_CFG1, calibration and control */

 Trickle charge enable */

 Trickle charger control */

 Trickle charge FET bypass */

#define MAX_LEN			10	/* Maximum number of consecutive

					 * register for this particular RTC.

	/*

	 * In case of oscillator failure, the register contents should be

	 * considered invalid. The flag is cleared the next time the RTC is set.

		/*

		 * TCHE[3:0] == 0x05, TCH2 == 1, TCFE == 0 (charging

		 * over diode and 940ohm resistor)

 diode disabled */

 Check Oscillator Stop flag */

 Check Oscillator Failure flag */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Real Time Clock driver for Conexant Digicolor

 *

 * Copyright (C) 2015 Paradox Innovation Ltd.

 *

 * Author: Baruch Siach <baruch@tkos.co.il>

 Read twice to ensure consistency */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An rtc driver for the Dallas/Maxim DS1685/DS1687 and related real-time

 * chips.

 *

 * Copyright (C) 2011-2014 Joshua Kinard <kumba@gentoo.org>.

 * Copyright (C) 2009 Matthias Fuchs <matthias.fuchs@esd-electronics.com>.

 *

 * References:

 *    DS1685/DS1687 3V/5V Real-Time Clocks, 19-5215, Rev 4/10.

 *    DS17x85/DS17x87 3V/5V Real-Time Clocks, 19-5222, Rev 4/10.

 *    DS1689/DS1693 3V/5V Serialized Real-Time Clocks, Rev 112105.

 *    Application Note 90, Using the Multiplex Bus RTC Extended Features.

 ----------------------------------------------------------------------- */

/*

 *  Standard read/write

 *  all registers are mapped in CPU address space

/**

 * ds1685_read - read a value from an rtc register.

 * @rtc: pointer to the ds1685 rtc structure.

 * @reg: the register address to read.

/**

 * ds1685_write - write a value to an rtc register.

 * @rtc: pointer to the ds1685 rtc structure.

 * @reg: the register address to write.

 * @value: value to write to the register.

 ----------------------------------------------------------------------- */

/*

 * Indirect read/write functions

 * access happens via address and data register mapped in CPU address space

/**

 * ds1685_indirect_read - read a value from an rtc register.

 * @rtc: pointer to the ds1685 rtc structure.

 * @reg: the register address to read.

/**

 * ds1685_indirect_write - write a value to an rtc register.

 * @rtc: pointer to the ds1685 rtc structure.

 * @reg: the register address to write.

 * @value: value to write to the register.

 ----------------------------------------------------------------------- */

 Inlined functions */

/**

 * ds1685_rtc_bcd2bin - bcd2bin wrapper in case platform doesn't support BCD.

 * @rtc: pointer to the ds1685 rtc structure.

 * @val: u8 time value to consider converting.

 * @bcd_mask: u8 mask value if BCD mode is used.

 * @bin_mask: u8 mask value if BIN mode is used.

 *

 * Returns the value, converted to BIN if originally in BCD and bcd_mode TRUE.

/**

 * ds1685_rtc_bin2bcd - bin2bcd wrapper in case platform doesn't support BCD.

 * @rtc: pointer to the ds1685 rtc structure.

 * @val: u8 time value to consider converting.

 * @bin_mask: u8 mask value if BIN mode is used.

 * @bcd_mask: u8 mask value if BCD mode is used.

 *

 * Returns the value, converted to BCD if originally in BIN and bcd_mode TRUE.

/**

 * s1685_rtc_check_mday - check validity of the day of month.

 * @rtc: pointer to the ds1685 rtc structure.

 * @mday: day of month.

 *

 * Returns -EDOM if the day of month is not within 1..31 range.

/**

 * ds1685_rtc_switch_to_bank0 - switch the rtc to bank 0.

 * @rtc: pointer to the ds1685 rtc structure.

/**

 * ds1685_rtc_switch_to_bank1 - switch the rtc to bank 1.

 * @rtc: pointer to the ds1685 rtc structure.

/**

 * ds1685_rtc_begin_data_access - prepare the rtc for data access.

 * @rtc: pointer to the ds1685 rtc structure.

 *

 * This takes several steps to prepare the rtc for access to get/set time

 * and alarm values from the rtc registers:

 *  - Sets the SET bit in Control Register B.

 *  - Reads Ext Control Register 4A and checks the INCR bit.

 *  - If INCR is active, a short delay is added before Ext Control Register 4A

 *    is read again in a loop until INCR is inactive.

 *  - Switches the rtc to bank 1.  This allows access to all relevant

 *    data for normal rtc operation, as bank 0 contains only the nvram.

 Set the SET bit in Ctrl B */

 Switch to Bank 1 */

 Read Ext Ctrl 4A and check the INCR bit to avoid a lockout. */

/**

 * ds1685_rtc_end_data_access - end data access on the rtc.

 * @rtc: pointer to the ds1685 rtc structure.

 *

 * This ends what was started by ds1685_rtc_begin_data_access:

 *  - Switches the rtc back to bank 0.

 *  - Clears the SET bit in Control Register B.

 Switch back to Bank 0 */

 Clear the SET bit in Ctrl B */

/**

 * ds1685_rtc_get_ssn - retrieve the silicon serial number.

 * @rtc: pointer to the ds1685 rtc structure.

 * @ssn: u8 array to hold the bits of the silicon serial number.

 *

 * This number starts at 0x40, and is 8-bytes long, ending at 0x47. The

 * first byte is the model number, the next six bytes are the serial number

 * digits, and the final byte is a CRC check byte.  Together, they form the

 * silicon serial number.

 *

 * These values are stored in bank1, so ds1685_rtc_switch_to_bank1 must be

 * called first before calling this function, else data will be read out of

 * the bank0 NVRAM.  Be sure to call ds1685_rtc_switch_to_bank0 when done.

 ----------------------------------------------------------------------- */

 ----------------------------------------------------------------------- */

 Read/Set Time & Alarm functions */

/**

 * ds1685_rtc_read_time - reads the time registers.

 * @dev: pointer to device structure.

 * @tm: pointer to rtc_time structure.

 Fetch the time info from the RTC registers. */

 bcd2bin if needed, perform fixups, and store to rtc_time. */

 RTC has hardcoded timezone, so don't use. */

/**

 * ds1685_rtc_set_time - sets the time registers.

 * @dev: pointer to device structure.

 * @tm: pointer to rtc_time structure.

 Fetch the time info from rtc_time. */

	/*

	 * Perform Sanity Checks:

	 *   - Months: !> 12, Month Day != 0.

	 *   - Month Day !> Max days in current month.

	 *   - Hours !>= 24, Mins !>= 60, Secs !>= 60, & Weekday !> 7.

	/*

	 * Set the data mode to use and store the time values in the

	 * RTC registers.

/**

 * ds1685_rtc_read_alarm - reads the alarm registers.

 * @dev: pointer to device structure.

 * @alrm: pointer to rtc_wkalrm structure.

 *

 * There are three primary alarm registers: seconds, minutes, and hours.

 * A fourth alarm register for the month date is also available in bank1 for

 * kickstart/wakeup features.  The DS1685/DS1687 manual states that a

 * "don't care" value ranging from 0xc0 to 0xff may be written into one or

 * more of the three alarm bytes to act as a wildcard value.  The fourth

 * byte doesn't support a "don't care" value.

 Fetch the alarm info from the RTC alarm registers. */

 Check the month date for validity. */

	/*

	 * Check the three alarm bytes.

	 *

	 * The Linux RTC system doesn't support the "don't care" capability

	 * of this RTC chip.  We check for it anyways in case support is

	 * added in the future and only assign when we care.

 Write the data to rtc_wkalrm. */

/**

 * ds1685_rtc_set_alarm - sets the alarm in registers.

 * @dev: pointer to device structure.

 * @alrm: pointer to rtc_wkalrm structure.

 Fetch the alarm info and convert to BCD. */

 Check the month date for validity. */

	/*

	 * Check the three alarm bytes.

	 *

	 * The Linux RTC system doesn't support the "don't care" capability

	 * of this RTC chip because rtc_valid_tm tries to validate every

	 * field, and we only support four fields.  We put the support

	 * here anyways for the future.

 Disable the alarm interrupt first. */

 Read ctrlc to clear RTC_CTRL_C_AF. */

	/*

	 * Set the data mode to use and store the time values in the

	 * RTC registers.

 Re-enable the alarm if needed. */

 Done! */

 ----------------------------------------------------------------------- */

 ----------------------------------------------------------------------- */

 /dev/rtcX Interface functions */

/**

 * ds1685_rtc_alarm_irq_enable - replaces ioctl() RTC_AIE on/off.

 * @dev: pointer to device structure.

 * @enabled: flag indicating whether to enable or disable.

 Flip the requisite interrupt-enable bit. */

 Read Control C to clear all the flag bits. */

 ----------------------------------------------------------------------- */

 ----------------------------------------------------------------------- */

 IRQ handler */

/**

 * ds1685_rtc_extended_irq - take care of extended interrupts

 * @rtc: pointer to the ds1685 rtc structure.

 * @pdev: platform device pointer.

	/*

	 * Check for a kickstart interrupt. With Vcc applied, this

	 * typically means that the power button was pressed, so we

	 * begin the shutdown sequence.

 Briefly disable kickstarts to debounce button presses. */

 Clear the kickstart flag. */

		/*

		 * Sleep 500ms before re-enabling kickstarts.  This allows

		 * adequate time to avoid reading signal jitter as additional

		 * button presses.

 Call the platform pre-poweroff function. Else, shutdown. */

	/*

	 * Check for a wake-up interrupt.  With Vcc applied, this is

	 * essentially a second alarm interrupt, except it takes into

	 * account the 'date' register in bank1 in addition to the

	 * standard three alarm registers.

 Call the platform wake_alarm function if defined. */

	/*

	 * Check for a ram-clear interrupt.  This happens if RIE=1 and RF=0

	 * when RCE=1 in 4B.  This clears all NVRAM bytes in bank0 by setting

	 * each byte to a logic 1.  This has no effect on any extended

	 * NV-SRAM that might be present, nor on the time/calendar/alarm

	 * registers.  After a ram-clear is completed, there is a minimum

	 * recovery time of ~150ms in which all reads/writes are locked out.

	 * NOTE: A ram-clear can still occur if RCE=1 and RIE=0.  We cannot

	 * catch this scenario.

 Call the platform post_ram_clear function if defined. */

/**

 * ds1685_rtc_irq_handler - IRQ handler.

 * @irq: IRQ number.

 * @dev_id: platform device pointer.

 Abort early if the device isn't ready yet (i.e., DEBUG_SHIRQ). */

 Ctrlb holds the interrupt-enable bits and ctrlc the flag bits. */

 Is the IRQF bit set? */

		/*

		 * We need to determine if it was one of the standard

		 * events: PF, AF, or UF.  If so, we handle them and

		 * update the RTC core.

 Check for a periodic interrupt. */

 Check for an alarm interrupt. */

 Check for an update interrupt. */

			/*

			 * One of the "extended" interrupts was received that

			 * is not recognized by the RTC core.

 ----------------------------------------------------------------------- */

 ----------------------------------------------------------------------- */

 ProcFS interface */

 Num of control registers. */

 Num bits per register. */

 Num spaces between each bit. */

/*

 * Periodic Interrupt Rates.

/*

 * Square-Wave Output Frequencies.

/**

 * ds1685_rtc_proc - procfs access function.

 * @dev: pointer to device structure.

 * @seq: pointer to seq_file structure.

 Read all the relevant data from the control registers. */

 Determine the RTC model. */

 Print out the information. */

 CONFIG_PROC_FS */

 ----------------------------------------------------------------------- */

 ----------------------------------------------------------------------- */

 RTC Class operations */

 ----------------------------------------------------------------------- */

 Read NVRAM in time and bank0 registers. */

 Enable burst-mode on DS17x85/DS17x87 */

		/* We need one write to RTC_BANK1_RAM_ADDR_LSB to start

 Read NVRAM in bank1 registers. */

			/* DS1685/DS1687 has to write to RTC_BANK1_RAM_ADDR

 Disable burst-mode on DS17x85/DS17x87 */

 !CONFIG_RTC_DRV_DS1689 */

 Write NVRAM in time and bank0 registers. */

 Enable burst-mode on DS17x85/DS17x87 */

		/* We need one write to RTC_BANK1_RAM_ADDR_LSB to start

 Write NVRAM in bank1 registers. */

			/* DS1685/DS1687 has to write to RTC_BANK1_RAM_ADDR

 Disable burst-mode on DS17x85/DS17x87 */

 !CONFIG_RTC_DRV_DS1689 */

 ----------------------------------------------------------------------- */

 SysFS interface */

/**

 * ds1685_rtc_sysfs_battery_show - sysfs file for main battery status.

 * @dev: pointer to device structure.

 * @attr: pointer to device_attribute structure.

 * @buf: pointer to char array to hold the output.

/**

 * ds1685_rtc_sysfs_auxbatt_show - sysfs file for aux battery status.

 * @dev: pointer to device structure.

 * @attr: pointer to device_attribute structure.

 * @buf: pointer to char array to hold the output.

/**

 * ds1685_rtc_sysfs_serial_show - sysfs file for silicon serial number.

 * @dev: pointer to device structure.

 * @attr: pointer to device_attribute structure.

 * @buf: pointer to char array to hold the output.

/*

 * struct ds1685_rtc_sysfs_misc_attrs - list for misc RTC features.

/*

 * struct ds1685_rtc_sysfs_misc_grp - attr group for misc RTC features.

 ----------------------------------------------------------------------- */

 Driver Probe/Removal */

/**

 * ds1685_rtc_probe - initializes rtc driver.

 * @pdev: pointer to platform_device structure.

 Get the platform data. */

 Allocate memory for the rtc device. */

 Setup resources and access functions */

 Get the register step size. */

 Platform pre-shutdown function, if defined. */

 Platform wake_alarm function, if defined. */

 Platform post_ram_clear function, if defined. */

 set the driver data. */

 Turn the oscillator on if is not already on (DV1 = 1). */

 Enable the countdown chain (DV2 = 0) */

 Clear RS3-RS0 in Control A. */

	/*

	 * All done with Control A.  Switch to Bank 1 for the remainder of

	 * the RTC setup so we have access to the extended functions.

 Default to 32768kHz output. */

 Set the SET bit in Control B so we can do some housekeeping. */

 Read Ext Ctrl 4A and check the INCR bit to avoid a lockout. */

	/*

	 * If the platform supports BCD mode, then set DM=0 in Control B.

	 * Otherwise, set DM=1 for BIN mode.

	/*

	 * Disable Daylight Savings Time (DSE = 0).

	 * The RTC has hardcoded timezone information that is rendered

	 * obselete.  We'll let the OS deal with DST settings instead.

 Force 24-hour mode (2412 = 1). */

 Reinitialize the time hours. */

 Enable 24-hour mode. */

 Write back to Control B, including DM & DSE bits. */

 Write the time hours back. */

 Reinitialize the alarm hours. */

 Write the alarm hours back. */

 24-hour mode is already set, so write Control B back. */

 Unset the SET bit in Control B so the RTC can update. */

 Check the main battery. */

 Check the auxillary battery.  It is optional. */

 Read Ctrl B and clear PIE/AIE/UIE. */

 Reading Ctrl C auto-clears PF/AF/UF. */

 Read Ctrl 4B and clear RIE/WIE/KSE. */

 Clear RF/WF/KF in Ctrl 4A. */

	/*

	 * Re-enable KSE to handle power button events.  We do not enable

	 * WIE or RIE by default.

 Century bit is useless because leap year fails in 1900 and 2100 */

 Maximum periodic rate is 8192Hz (0.122070ms). */

 See if the platform doesn't support UIE. */

	/*

	 * Fetch the IRQ and setup the interrupt handler.

	 *

	 * Not all platforms have the IRQF pin tied to something.  If not, the

	 * RTC will still set the *IE / *F flags and raise IRQF in ctrlc, but

	 * there won't be an automatic way of notifying the kernel about it,

	 * unless ctrlc is explicitly polled.

 Request an IRQ. */

 Check to see if something came back. */

 Setup complete. */

/**

 * ds1685_rtc_remove - removes rtc driver.

 * @pdev: pointer to platform_device structure.

 Read Ctrl B and clear PIE/AIE/UIE. */

 Reading Ctrl C auto-clears PF/AF/UF. */

 Read Ctrl 4B and clear RIE/WIE/KSE. */

 Manually clear RF/WF/KF in Ctrl 4A. */

/*

 * ds1685_rtc_driver - rtc driver properties.

 ----------------------------------------------------------------------- */

 ----------------------------------------------------------------------- */

 Poweroff function */

/**

 * ds1685_rtc_poweroff - uses the RTC chip to power the system off.

 * @pdev: pointer to platform_device structure.

 Check for valid RTC data, else, spin forever. */

 Get the rtc data. */

		/*

		 * Disable our IRQ.  We're powering down, so we're not

		 * going to worry about cleaning up.  Most of that should

		 * have been taken care of by the shutdown scripts and this

		 * is the final function call.

 Oscillator must be on and the countdown chain enabled. */

		/*

		 * Read Control 4A and check the status of the auxillary

		 * battery.  This must be present and working (VRT2 = 1)

		 * for wakeup and kickstart functionality to be useful.

 Clear all of the interrupt flags on Control 4A. */

			/*

			 * The auxillary battery is present and working.

			 * Enable extended functions (ABE=1), enable

			 * wake-up (WIE=1), and enable kickstart (KSE=1)

			 * in Control 4B.

 Set PAB to 1 in Control 4A to power the system down. */

 Spin ... we do not switch back to bank0. */

 ----------------------------------------------------------------------- */

 SPDX-License-Identifier: GPL-2.0-only

/* drivers/rtc/rtc-rx4581.c

 *

 * written by Torben Hohn <torbenh@linutronix.de>

 *

 * Based on:

 * drivers/rtc/rtc-max6902.c

 *

 * Copyright (C) 2006 8D Technologies inc.

 * Copyright (C) 2004 Compulab Ltd.

 *

 * Driver for MAX6902 spi RTC

 *

 * and based on:

 * drivers/rtc/rtc-rx8581.c

 *

 * An I2C driver for the Epson RX8581 RTC

 *

 * Author: Martyn Welch <martyn.welch@ge.com>

 * Copyright 2008 GE Intelligent Platforms Embedded Systems, Inc.

 *

 * Based on: rtc-pcf8563.c (An I2C driver for the Philips PCF8563 RTC)

 * Copyright 2005-06 Tower Technologies

 Second in BCD */

 Minute in BCD */

 Hour in BCD */

 Day of Week */

 Day of Month in BCD */

 Month in BCD */

 Year in BCD */

 RAM */

 Alarm Min in BCD*/

 Alarm Hour in BCD */

 Extension Register */

 Flag Register */

 Control Register */

 Flag Register bit definitions */

 Update */

 Timer */

 Alarm */

 Voltage Low */

 Control Register bit definitions */

 Update Interrupt Enable */

 Timer Interrupt Enable */

 Alarm Interrupt Enable */

 STOP bit */

 RESET bit */

 high nibble must be '0' to write */

 Set MSB to indicate read */

/*

 * In the routines that deal directly with the rx8581 hardware, we use

 * rtc_time -- month 0-11, hour 0-23, yr = calendar year-epoch.

	/* First we ensure that the "update flag" is not set, we read the

	 * time and date then re-read the "update flag". If the update flag

	 * has been set, we know that the time has changed during the read so

	 * we repeat the whole process again.

 If update flag set, clear it */

 Now read time and date */

 Check flag register */

 rtc hr 0-23 */

 rtc mn 1-12 */

 assume we are in 1970...2069 */

 hours, minutes and seconds */

 month, 1 - 12 */

 year and century */

 Stop the clock */

 write register's data */

 get VLF and clear it */

 Restart the clock */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for MediaTek SoC based RTC

 *

 * Copyright (C) 2017 Sean Wang <sean.wang@mediatek.com>

/*

 * Ranges from 0x40 to 0x78 provide RTC time setup for year, month,

 * day of month, day of week, hour, minute and second.

/*

 * The offset is used in the translation for the year between in struct

 * rtc_time and in hardware register MTK_RTC_TREG(x,MTK_YEA)

/*

 * The lowest value for the valid tm_year. RTC hardware would take incorrectly

 * tm_year 100 as not a leap year and thus it is also required being excluded

 * from the valid options.

/*

 * The most year the RTC can hold is 99 and the next to 99 in year register

 * would be wraparound to 0, for MT7622.

 The highest value for the valid tm_year */

 Simple macro helps to check whether the hardware supports the tm_year */

 Types of the function the RTC provides are time counter and alarm. */

 Indexes are used for the pointer to relevant registers in MTK_RTC_TREG */

 The setup of the init sequence is for allowing RTC got to work */

	/*

	 * Read again until the field of the second is not changed which

	 * ensures all fields in the consistent state. Note that MTK_SEC must

	 * be read first. In this way, it guarantees the others remain not

	 * changed when the results for two MTK_SEC consecutive reads are same.

 Rebase to the absolute year which userspace queries */

 Rebase to the relative year which RTC hardware requires */

 Stop alarm also implicitly disables the alarm interrupt */

 Ack alarm interrupt status */

 Stop time counter before setting a new one*/

 Restart the time counter */

	/*

	 * Stop the alarm also implicitly including disables interrupt before

	 * setting a new one.

	/*

	 * Avoid contention between mtk_rtc_setalarm and IRQ handler so that

	 * disabling the interrupt and awaiting for pending IRQ handler to

	 * complete.

 Restart the alarm with the new setup */

 CONFIG_PM */

 CONFIG_PM */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for the SGS-Thomson M48T35 Timekeeper RAM chip

 *

 * Copyright (C) 2000 Silicon Graphics, Inc.

 * Written by Ulf Carlsson (ulfc@engr.sgi.com)

 *

 * Copyright (C) 2008 Thomas Bogendoerfer

 *

 * Based on code written by Paul Gortmaker.

 starts at 0x7ff8 */

	/*

	 * Only the values that we read from the RTC are set. We leave

	 * tm_wday, tm_yday and tm_isdst untouched. Even though the

	 * RTC has RTC_DAY_OF_WEEK, we ignore it, as it is only updated

	 * by the RTC when initially set to a non-zero value.

	/*

	 * Account for differences between how the RTC uses the values

	 * and how they are defined in a struct rtc_time;

 tm_mon starts at zero */

 They are unsigned */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An SPI driver for the Philips PCF2123 RTC

 * Copyright 2009 Cyber Switching, Inc.

 *

 * Author: Chris Verges <chrisv@cyberswitching.com>

 * Maintainers: http://www.cyberswitching.com

 *

 * based on the RS5C348 driver in this same directory.

 *

 * Thanks to Christian Pellegrin <chripell@fsfe.org> for

 * the sysfs contributions to this driver.

 *

 * Please note that the CS is active high, so platform data

 * should look something like:

 *

 * static struct spi_board_info ek_spi_devices[] = {

 *	...

 *	{

 *		.modalias		= "rtc-pcf2123",

 *		.chip_select		= 1,

 *		.controller_data	= (void *)AT91_PIN_PA10,

 *		.max_speed_hz		= 1000 * 1000,

 *		.mode			= SPI_CS_HIGH,

 *		.bus_num		= 0,

 *	},

 *	...

 *};

 REGISTERS */

 Control Register 1 */

 Control Register 2 */

 datetime */

 Alarm Registers */

 Clock Rate Offset Register */

 Timer Registers */

 PCF2123_REG_CTRL1 BITS */

 Clear */

 Correction irq enable */

 12 hour time */

 Software reset */

 Stop the clock */

 External clock test mode */

 PCF2123_REG_CTRL2 BITS */

 Countdown timer irq enable */

 Alarm irq enable */

 Countdown timer flag */

 Alarm flag */

 Irq pin generates pulse */

 Minute or second irq flag */

 Second irq enable */

 Minute irq enable */

 PCF2123_REG_SC BITS */

 Clock has been stopped */

 PCF2123_REG_ALRM_XX BITS */

 MN, HR, DM, or DW alarm matching */

 PCF2123_REG_TMR_CLKOUT BITS */

 4096 KHz countdown timer */

 64 Hz countdown timer */

 1 Hz countdown timer */

 60th Hz countdown timer */

 Countdown timer enable */

 PCF2123_REG_OFFSET BITS */

 2's complement sign bit */

 Coarse mode offset */

 Offset step in parts per billion */

 Offset value */

 READ/WRITE ADDRESS BITS */

/*

 * The offset register is a 7 bit signed value with a coarse bit in bit 7.

 * The main difference between the two is normal offset adjusts the first

 * second of n minutes every other hour, with 61, 62 and 63 being shoved

 * into the 60th minute.

 * The coarse adjustment does the same, but every hour.

 * the two overlap, with every even normal offset value corresponding

 * to a coarse offset. Based on this algorithm, it seems that despite the

 * name, coarse offset is a better fit for overlapping values.

 choose fine offset only for odd values in the normal range */

 Normal offset. Clear the coarse bit */

 Coarse offset. Divide by 2 and set the coarse bit */

 rtc hr 0-23 */

 rtc mn 1-12 */

 Stop the counter first */

 Set the new time */

 rtc mn 1-12 */

 Start the counter */

 Disable alarm interrupt */

 Ensure alarm flag is clear */

 Set new alarm */

 Alarm? */

 Clear alarm flag */

 Stop the counter */

 See if the counter was actually stopped */

 Start the counter */

 Finalize the initialization */

 Register alarm irq */

	/* The PCF2123's alarm only has minute accuracy. Must add timer

	 * support to this driver to generate interrupts more than once

	 * per minute.

 Deprecated, do not use */

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+



 Copyright 2004-2008 Freescale Semiconductor, Inc. All Rights Reserved.

  32bit rtc hour/min counter reg */

  32bit rtc seconds counter reg */

  32bit rtc alarm hour/min reg */

  32bit rtc alarm seconds reg */

  32bit rtc control reg */

  32bit rtc interrupt status reg */

  32bit rtc interrupt enable reg */

  32bit rtc stopwatch min reg */

  32bit rtc days counter reg */

  32bit rtc day alarm reg */

  32bit rtc test reg 1 */

  32bit rtc test reg 2 */

  32bit rtc test reg 3 */

/*

 * This function is used to obtain the RTC time or the alarm value in

 * second.

/*

 * This function sets the RTC alarm value or the time value.

 time is within a day now */

 time is within an hour now */

/*

 * This function updates the RTC alarm registers and then clears all the

 * interrupt status bits.

 clear all the interrupt status bits */

 This function is the RTC interrupt service routine. */

 clear interrupt sources */

 update irq data & counter */

 RTC alarm should be one-shot */

/*

 * This function reads the current RTC time into tm in Gregorian date.

 Avoid roll-over from reading the different registers */

/*

 * This function sets the internal RTC time based on tm in Gregorian date.

 Avoid roll-over from reading the different registers */

/*

 * This function reads the current alarm value into the passed in 'alrm'

 * argument. It updates the alrm's pending field value based on the whether

 * an alarm interrupt occurs or not.

/*

 * This function sets the RTC alarm based on passed in alrm.

 RTC layer */

 9bit days + hours minutes seconds */

		/*

		 * Set the start date as beginning of the current year. This can

		 * be overridden using device tree.

 16bit days + hours minutes seconds */

 Configure and enable the RTC */

/*

 * Ricoh RS5C313 RTC device/driver

 *  Copyright (C) 2007 Nobuhiro Iwamatsu

 *

 *  2005-09-19 modifed by kogiidena

 *

 * Based on the old drivers/char/rs5c313_rtc.c  by:

 *  Copyright (C) 2000 Philipp Rumpf <prumpf@tux.org>

 *  Copyright (C) 1999 Tetsuya Okada & Niibe Yutaka

 *

 * Based on code written by Paul Gortmaker.

 *  Copyright (C) 1996 Paul Gortmaker

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Based on other minimal char device drivers, like Alan's

 * watchdog, Ted's random, etc. etc.

 *

 *	1.07	Paul Gortmaker.

 *	1.08	Miquel van Smoorenburg: disallow certain things on the

 *		DEC Alpha as the CMOS clock is also used for other things.

 *	1.09	Nikita Schmidt: epoch support and some Alpha cleanup.

 *	1.09a	Pete Zaitcev: Sun SPARC

 *	1.09b	Jeff Garzik: Modularize, init cleanup

 *	1.09c	Jeff Garzik: SMP cleanup

 *	1.10    Paul Barton-Davis: add support for async I/O

 *	1.10a	Andrea Arcangeli: Alpha updates

 *	1.10b	Andrew Morton: SMP lock fix

 *	1.10c	Cesar Barros: SMP locking fixes and cleanup

 *	1.10d	Paul Gortmaker: delete paranoia check in rtc_exit

 *	1.10e	Maciej W. Rozycki: Handle DECstation's year weirdness.

 *      1.11    Takashi Iwai: Kernel access functions

 *			      rtc_register/rtc_unregister/rtc_control

 *      1.11a   Daniele Bellucci: Audit create_proc_read_entry in rtc_init

 *	1.12	Venkatesh Pallipadi: Hooks for emulating rtc on HPET base-timer

 *		CONFIG_HPET_EMULATE_RTC

 *	1.13	Nobuhiro Iwamatsu: Updata driver.

****************************************************/

 LANDISK dependence part of RS5C313                */

****************************************************/

 RICOH RS5C313 CE port */

 RICOH RS5C313 CE port bit */

 SCSPTR1 data */

 Set SCK as I/O port and Initialize SCSPTR1 data & I/O port. */

 And Initialize SCL for RS5C313 clock */

 SCL:H */

 SCL output enable */

 CE:L */

 SDA:Write Data */

 SDA:output enable */

 SCL:L */

 SCL:H */

 SDA:output disable */

 SDA:Read Data */

 SCL:L */

 SCL:H */

 CONFIG_SH_LANDISK */

****************************************************/

 machine independence part of RS5C313              */

****************************************************/

 RICOH RS5C313 address */

 RICOH RS5C313 control register */

 RICOH RS5C313 test register */

 RICOH RS5C313 control bit */

 CE:H */

 Initialize control reg. 24 hour */

 CE:L */

 CE:L */

 busy check. */

 CE:H */

 Initiatlize control reg. 24 hour */

 CE:L */

 CE:H */

 CE:H */

 INT interval reg. OFF */

 Initialize control reg. 24 hour & adjust */

 busy check. */

 CE:L */

 SPDX-License-Identifier: GPL-2.0

/*

 * A driver for the RTC embedded in the Cirrus Logic EP93XX processors

 * Copyright (c) 2006 Tower Technologies

 *

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Real time clock driver for DA9055

 *

 * Copyright(c) 2012 Dialog Semiconductor Ltd.

 *

 * Author: Dajun Dajun Chen <dajun.chen@diasemi.com>

	/*

	 * Registers are only valid when RTC_READ

	 * status bit is asserted

 Enable RTC and the internal Crystal */

 Enable RTC in Power Down mode */

 Enable RTC in Reset mode */

 Disable the RTC TICK ALM */

 Turn off the alarm if it should not be a wake source. */

 Disable the ALM IRQ */

/* Enable the alarm if it should be enabled (in case it was disabled to

 * prevent use as a wake source).

 Unconditionally disable the alarm */

 SPDX-License-Identifier: GPL-2.0+

/*

 * TI OMAP Real Time Clock interface for Linux

 *

 * Copyright (C) 2003 MontaVista Software, Inc.

 * Author: George G. Davis <gdavis@mvista.com> or <source@mvista.com>

 *

 * Copyright (C) 2006 David Brownell (new RTC framework)

 * Copyright (C) 2014 Johan Hovold <johan@kernel.org>

/*

 * The OMAP RTC is a year/month/day/hours/minutes/seconds BCD clock

 * with century-range alarm matching, driven by the 32kHz clock.

 *

 * The main user-visible ways it differs from PC RTCs are by omitting

 * "don't care" alarm fields and sub-second periodic IRQs, and having

 * an autoadjust mechanism to calibrate to the true oscillator rate.

 *

 * Board-specific wiring options include using split power mode with

 * RTC_OFF_NOFF used as the reset signal (so the RTC won't be reset),

 * and wiring RTC_WAKE_INT (so the RTC alarm can wake the system from

 * low power modes) for OMAP1 boards (OMAP-L138 has this built into

 * the SoC). See the BOARD-SPECIFIC CUSTOMIZATION comment.

 RTC registers */

 OMAP_RTC_CTRL_REG bit fields: */

 OMAP_RTC_STATUS_REG bit fields: */

 OMAP_RTC_INTERRUPTS_REG bit fields: */

 OMAP_RTC_OSC_REG bit fields: */

 OMAP_RTC_IRQWAKEEN bit fields: */

 OMAP_RTC_PMIC bit fields: */

 OMAP_RTC_KICKER values */

/*

 * We rely on the rtc framework to handle locking (rtc->ops_lock),

 * so the only other requirement is that register accesses which

 * require BUSY to be clear are made with IRQs locally disabled

 BUSY may stay active for 1/32768 second (~30 usec) */

 now we have ~15 usec to read/write various registers */

 alarm irq? */

 1/sec periodic/update irq? */

 this hardware doesn't support "don't care" alarm fields */

 epoch == 1900 */

 we don't report wday/yday/isdst ... */

/**

 * omap_rtc_power_off_program: Set the pmic power off sequence. The RTC

 * generates pmic_pwr_enable control, which can be used to control an external

 * PMIC.

 enable pmic_power_en control */

 Clear any existing ALARM2 event */

 set alarm one second from now */

	/*

	 * enable ALARM2 interrupt

	 *

	 * NOTE: this fails on AM3352 if rtc_write (writeb) is used

 Retry in case roll over happened before alarm was armed. */

/*

 * omap_rtc_poweroff: RTC-controlled power off

 *

 * The RTC can be used to control an external PMIC via the pmic_power_en pin,

 * which can be configured to transition to OFF on ALARM2 events.

 *

 * Notes:

 * The one-second alarm offset is the shortest offset possible as the alarm

 * registers must be set before the next timer update and the offset

 * calculation is too heavy for everything to be done within a single access

 * period (~15 us).

 *

 * Called with local interrupts disabled.

 Set PMIC power enable and EXT_WAKEUP in case PB power on is used */

	/*

	 * Wait for alarm to trigger (within one second) and external PMIC to

	 * power off the system. Add a 500 ms margin for external latencies

	 * (e.g. debounce circuits).

 sentinel */

 sentinel */

 active low by default */

 Enable the clock/module so that we can access the registers */

	/*

	 * disable interrupts

	 *

	 * NOTE: ALARM2 is not cleared on AM3352 if rtc_write (writeb) is used

 enable RTC functional clock */

 clear old status */

 On boards with split power, RTC_ON_NOFF won't reset the RTC */

 force to 24 hour mode */

	/*

	 * BOARD-SPECIFIC CUSTOMIZATION CAN GO HERE:

	 *

	 *  - Device wake-up capability setting should come through chip

	 *    init logic. OMAP1 boards should initialize the "wakeup capable"

	 *    flag in the platform device if the board is wired right for

	 *    being woken up by RTC alarm. For OMAP-L138, this capability

	 *    is built into the SoC by the "Deep Sleep" capability.

	 *

	 *  - Boards wired so RTC_ON_nOFF is used as the reset signal,

	 *    rather than nPWRON_RESET, should forcibly enable split

	 *    power mode.  (Some chip errata report that RTC_CTRL_SPLIT

	 *    is write-only, and always reads as zero...)

	/*

	 * If we have the external clock then switch to it so we can keep

	 * ticking across suspend.

 handle periodic and alarm irqs */

 Support ext_wakeup pinconf */

 leave rtc running, but disable irqs */

 Disable the clock/module */

	/*

	 * FIXME: the RTC alarm is not currently acting as a wakeup event

	 * source on some platforms, and in fact this enable() call is just

	 * saving a flag that's never used...

	/*

	 * Keep the ALARM interrupt enabled to allow the system to power up on

	 * alarm events.

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC driver for the Micro Crystal RV8803

 *

 * Copyright (C) 2015 Micro Crystal SA

 * Alexandre Belloni <alexandre.belloni@bootlin.com>

 *

	/*

	 * There is a 61µs window during which the RTC does not acknowledge I2C

	 * transfers. In that case, ensure that there are multiple attempts.

 Stop the clock */

 Restart the clock */

 The alarm has no seconds, round up to nearest minute */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * rtc-as3722.c - Real Time Clock driver for ams AS3722 PMICs

 *

 * Copyright (C) 2013 ams AG

 * Copyright (c) 2013, NVIDIA Corporation. All rights reserved.

 *

 * Author: Florian Lobmaier <florian.lobmaier@ams.com>

 * Author: Laxman Dewangan <ldewangan@nvidia.com>

 Enable the RTC to make sure it is running. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Real Time Clock driver for Marvell 88PM80x PMIC

 *

 * Copyright (c) 2012 Marvell International Ltd.

 *  Wenzeng Chen<wzch@marvell.com>

 *  Qiao Zhou <zhouqiao@marvell.com>

/*

 * Calculate the next alarm time given the requested alarm time mask

 * and the current time.

 Advance one day */

 load 32-bit read-only counter */

 load 32-bit read-only counter */

 load 32-bit read-only counter */

 get new ticks for alarm in 24 hours */

	/*

	 * enable internal XO instead of internal 3.25MHz clock since it can

	 * free running in PMIC power-down state.

 remember whether this power up is caused by PMIC RTC or not */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Real time clock device driver for DA9063

 * Copyright (C) 2013-2015  Dialog Semiconductor Ltd.

 REGS */

 MASKS */

 ALARM CONFIG */

 REGS */

 MASKS */

 ALARM CONFIG */

 REGS */

 MASKS */

 ALARM CONFIG */

 REGS */

 MASKS */

 ALARM CONFIG */

 handle the rtc synchronisation delay */

	/*

	 * TODO: some models have alarms on a minute boundary but still support

	 * real hardware interrupts. Add this once the core supports it.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc class driver for the Maxim MAX6900 chip

 *

 * Copyright (c) 2007 MontaVista, Software, Inc.

 *

 * Author: Dale Farnsworth <dale@farnsworth.org>

 *

 * based on previously existing rtc class drivers

/*

 * register indices

 seconds      00-59 */

 minutes      00-59 */

 hours        00-23 */

 day of month 00-31 */

 month        01-12 */

 day of week   1-7  */

 year         00-99 */

 control */

 register 8 is undocumented */

 century */

 can burst r/w first 8 regs */

 Write Protect */

/*

 * register read/write commands

 specification says 2.5 mS */

 write */

 write */

 write */

 write */

	/*

	 * We have to make separate calls to i2c_transfer because of

	 * the need to delay after each write to the chip.  Also,

	 * we write the century byte first, since we set the write-protect

	 * bit as part of the burst write.

 set write protect */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/drivers/rtc/rtc-pl030.c

 *

 *  Copyright (C) 2000-2001 Deep Blue Solutions Ltd.

/*

 * Set the RTC time.  Unfortunately, we can't accurately set

 * the point at which the counter updates.

 *

 * Also, since RTC_LR is transferred to RTC_CR on next rising

 * edge of the 1Hz clock, we must write the time one second

 * in advance.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2018 NXP.

 pack 2 time parameters into 1 register, 16 bits for each */

 ignore non-rtc irq */

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC subsystem, nvmem interface

 *

 * Copyright (C) 2017 Alexandre Belloni

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC subsystem, dev interface

 *

 * Copyright (C) 2005 Tower Technologies

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 *

 * based on arch/arm/common/rtctime.c

 16 RTCs should be enough for everyone... */

/*

 * Routine to poll RTC seconds field for change as often as possible,

 * after first RTC_UIE use timer to reduce polling

 CONFIG_RTC_INTF_DEV_UIE_EMUL */

	/* check that the calling task has appropriate permissions

	 * for certain ioctls. doing this check here is useful

	 * to avoid duplicate code in each driver.

	/*

	 * Drivers *SHOULD NOT* provide ioctl implementations

	 * for these requests.  Instead, provide methods to

	 * support the following code, so that the RTC's main

	 * features are accessible without using ioctls.

	 *

	 * RTC and alarm times will be in UTC, by preference,

	 * but dual-booting with MS-Windows implies RTCs must

	 * use the local wall clock time.

		/* RTC_ALM_SET alarms may be up to 24 hours in the future.

		 * Rather than expecting every RTC to implement "don't care"

		 * for day/month/year fields, just force the alarm to have

		 * the right values for those fields.

		 *

		 * RTC_WKALM_SET should be used instead.  Not only does it

		 * eliminate the need for a separate RTC_AIE_ON call, it

		 * doesn't have the "alarm 23:59:59 in the future" race.

		 *

		 * NOTE:  some legacy code may have used invalid fields as

		 * wildcards, exposing hardware "periodic alarm" capabilities.

		 * Not supported here.

 alarm may need to wrap into tomorrow */

 Finally try the driver's ioctl interface */

 arg is a plain integer, not pointer */

 arg is a plain integer, not pointer */

	/* We shut down the repeating IRQs that userspace enabled,

	 * since nothing is listening to them.

	 *  - Update (UIE) ... currently only managed through ioctls

	 *  - Periodic (PIE) ... also used through rtc_*() interface calls

	 *

	 * Leave the alarm alone; it may be set to trigger a system wakeup

	 * later, or be used by kernel code, and is a one-shot event anyway.

 Keep ioctl until all drivers are converted */

 insertion/removal hooks */

 SPDX-License-Identifier: GPL-2.0

/*

 * PS3 RTC Driver

 *

 * Copyright 2009 Sony Corporation

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * The Netronix embedded controller is a microcontroller found in some

 * e-book readers designed by the original design manufacturer Netronix, Inc.

 * It contains RTC, battery monitoring, system power management, and PWM

 * functionality.

 *

 * This driver implements access to the RTC time and date.

 *

 * Copyright 2020 Jonathan Neuschäfer <j.neuschaefer@gmx.net>

	/*

	 * Read the minutes/seconds field again. If it changed since the first

	 * read, we can't assume that the values read so far are consistent,

	 * and should start from the beginning.

	/*

	 * To avoid time overflows while we're writing the full date/time,

	 * set the seconds field to zero before doing anything else. For the

	 * next 59 seconds (plus however long it takes until the RTC's next

	 * update of the second field), the seconds field will not overflow

	 * into the other fields.

 2255-12-31 23:59:59 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Real-time clock driver for MPC5121

 *

 * Copyright 2007, Domen Puncer <domen.puncer@telargo.com>

 * Copyright 2008, Freescale Semiconductor, Inc. All rights reserved.

 * Copyright 2011, Dmitry Eremin-Solenikov

 RTC + 0x00 */

 RTC + 0x01 */

 RTC + 0x02 */

 RTC + 0x03 */

 RTC + 0x04 */

 RTC + 0x05 */

 RTC + 0x06 */

 RTC + 0x07 */

 RTC + 0x08 */

 RTC + 0x09 */

 RTC + 0x0a */

 RTC + 0x0c */

 RTC + 0x0d */

 RTC + 0x0e */

 RTC + 0x0f */

 RTC + 0x11 */

 RTC + 0x12 */

 RTC + 0x13 */

 RTC + 0x14 */

 RTC + 0x15 */

 RTC + 0x16 */

 RTC + 0x18 */

 RTC + 0x19 */

 RTC + 0x1a */

 RTC + 0x1b */

 RTC + 0x1c */

 RTC + 0x1d */

 RTC + 0x1e */

 RTC + 0x1f */

	/*

	 * target_time:

	 *	intended to be used for hibernation but hibernation

	 *	does not work on silicon rev 1.5 so use it for non-volatile

	 *	storage of offset between the actual_time register and linux

	 *	time

 RTC + 0x20 */

	/*

	 * actual_time:

	 *	readonly time since VBAT_RTC was last connected

 RTC + 0x24 */

 RTC + 0x28 */

/*

 * Update second/minute/hour registers.

 *

 * This is just so alarm will work.

 set time sequence */

	/*

	 * linux time is actual_time plus the offset saved in target_time

	/*

	 * update second minute hour registers

	 * so alarms will work

	/*

	 * The actual_time register is read only so we write the offset

	 * between it and linux time to the target_time register.

	/*

	 * update second minute hour registers

	 * so alarms will work

 12 hour format? */

 date */

 set date sequence */

	/*

	 * the alarm has no seconds so deal with it

 acknowledge and clear status */

 acknowledge */

 4052-12-31 23:59:59 */

		/*

		 * This is a limitation of the driver that abuses the target

		 * time register, the actual maximum year for the mpc5121 is

		 * also 4052.

 disable interrupt, so there are no nasty surprises */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2008-2009 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2010 Orex Computed Radiography

/*

 * This driver uses the 47-bit 32 kHz counter in the Freescale DryIce block

 * to implement a Linux RTC. Times and alarms are truncated to seconds.

 * Since the RTC framework performs API locking via rtc->ops_lock the

 * only simultaneous accesses we need to deal with is updating DryIce

 * registers while servicing an alarm.

 *

 * Note that reading the DSR (DryIce Status Register) automatically clears

 * the WCF (Write Complete Flag). All DryIce writes are synchronized to the

 * LP (Low Power) domain and set the WCF upon completion. Writes to the

 * DIER (DryIce Interrupt Enable Register) are the only exception. These

 * occur at normal bus speeds and do not set WCF.  Periodic interrupts are

 * not supported by the hardware.

 DryIce Register Definitions */

 Time Counter MSB Reg */

 Time Counter LSB Reg */

 Clock Alarm MSB Reg */

 Clock Alarm LSB Reg */

 doomsday - 1 sec */

 Control Reg */

 Tamper-detect configuration hard lock */

 Tamper-detect configuration soft lock */

 Key-select soft lock */

 Monotonic-counter hard lock */

 Monotonic-counter soft lock */

 Timer-counter hard lock */

 Timer-counter soft lock */

 Failure state hard lock */

 Time Counter Enable */

 Monotonic Counter Enable */

 Status Reg */

 Wire-mesh tamper detected */

 External tamper B detected */

 External tamper A detected */

 External boot detected */

 SCC alarm detected */

 Temperature tamper detected */

 Clock tamper detected */

 Voltage tamper detected */

 Write Busy Flag (synchronous) */

 Write Next Flag (synchronous) */

 Write Complete Flag (synchronous)*/

 Write Error Flag */

 Clock Alarm Flag */

 monotonic counter overflow */

 time counter overflow */

 Non-Valid Flag */

 Security Violation Flag */

 Interrupt Enable Reg (synchronous) */

 Write Next Interrupt Enable */

 Write Complete Interrupt Enable */

 Write Error Interrupt Enable */

 Clock Alarm Interrupt Enable */

 Security-violation Interrupt Enable */

 DryIce Monotonic Counter Reg */

 DryIce Tamper Configuration Reg */

 monotonic overflow enabled */

 time overflow enabled */

 wire-mesh tamper enabled */

 external B tamper enabled */

 external A tamper enabled */

 external boot tamper enabled */

 SCC enabled */

 temperature tamper enabled */

 clock tamper enabled */

 voltage tamper enabled */

 DryIce General Purpose Reg */

/**

 * struct imxdi_dev - private imxdi rtc data

 * @pdev: pointer to platform dev

 * @rtc: pointer to rtc struct

 * @ioaddr: IO registers pointer

 * @clk: input reference clock

 * @dsr: copy of the DSR register

 * @irq_lock: interrupt enable register (DIER) lock

 * @write_wait: registers write complete queue

 * @write_mutex: serialize registers write

 * @work: schedule alarm work

/* Some background:

 *

 * The DryIce unit is a complex security/tamper monitor device. To be able do

 * its job in a useful manner it runs a bigger statemachine to bring it into

 * security/tamper failure state and once again to bring it out of this state.

 *

 * This unit can be in one of three states:

 *

 * - "NON-VALID STATE"

 *   always after the battery power was removed

 * - "FAILURE STATE"

 *   if one of the enabled security events has happened

 * - "VALID STATE"

 *   if the unit works as expected

 *

 * Everything stops when the unit enters the failure state including the RTC

 * counter (to be able to detect the time the security event happened).

 *

 * The following events (when enabled) let the DryIce unit enter the failure

 * state:

 *

 * - wire-mesh-tamper detect

 * - external tamper B detect

 * - external tamper A detect

 * - temperature tamper detect

 * - clock tamper detect

 * - voltage tamper detect

 * - RTC counter overflow

 * - monotonic counter overflow

 * - external boot

 *

 * If we find the DryIce unit in "FAILURE STATE" and the TDCHL cleared, we

 * can only detect this state. In this case the unit is completely locked and

 * must force a second "SYSTEM POR" to bring the DryIce into the

 * "NON-VALID STATE" + "FAILURE STATE" where a recovery is possible.

 * If the TDCHL is set in the "FAILURE STATE" we are out of luck. In this case

 * a battery power cycle is required.

 *

 * In the "NON-VALID STATE" + "FAILURE STATE" we can clear the "FAILURE STATE"

 * and recover the DryIce unit. By clearing the "NON-VALID STATE" as the last

 * task, we bring back this unit into life.

/*

 * Do a write into the unit without interrupt support.

 * We do not need to check the WEF here, because the only reason this kind of

 * write error can happen is if we write to the unit twice within the 122 us

 * interval. This cannot happen, since we are using this function only while

 * setting up the unit.

 do the register write */

	/*

	 * now it takes four 32,768 kHz clock cycles to take

	 * the change into effect = 122 us

 the following flags force a transition into the "FAILURE STATE" */

 report the cause */

 we are out of luck */

	/*

	 * with the next SYSTEM POR we will transit from the "FAILURE STATE"

	 * into the "NON-VALID STATE" + "FAILURE STATE"

 initialize alarm */

 clear alarm flag */

	/*

	 * lets disable all sources which can force the DryIce unit into

	 * the "FAILURE STATE" for now

 and lets protect them at runtime from any change */

	/*

	 * the timer cannot be set/modified if

	 * - the TCHL or TCSL bit is set in DCR

 we are out of luck */

	/*

	 * - the timer counter stops/is stopped if

	 *   - its overflow flag is set (TCO in DSR)

	 *      -> clear overflow bit to make it count again

	 *   - NVF is set in DSR

	 *      -> clear non-valid bit to make it count again

	 *   - its TCE (DCR) is cleared

	 *      -> set TCE to make it count

	 *   - it was never set before

	 *      -> write a time into it (required again if the NVF was set)

 state handled */

 clear overflow flag */

 enable the counter */

 set and trigger it to make it count */

 now prepare for the valid state */

	/*

	 * now we must first remove the tamper sources in order to get the

	 * device out of the "FAILURE STATE"

	 * To disable any of the following sources we need to modify the DTCR

			/*

			 * the tamper register is locked. We cannot disable the

			 * tamper detection. The TDCHL can only be reset by a

			 * DRYICE POR, but we cannot force a DRYICE POR in

			 * software because we are still in "FAILURE STATE".

			 * We need a DRYICE POR via battery power cycling....

			/*

			 * out of luck!

			 * we cannot disable them without a DRYICE POR

 a soft lock can be removed by a SYSTEM POR */

 disable all sources */

 clear the status bits now */

	/*

	 * now we are trying to clear the "Security-violation flag" to

	 * get the DryIce out of this state

 success? */

 last resort */

	/*

	 * now we have left the "FAILURE STATE" and ending up in the

	 * "NON-VALID STATE" time to recover everything

/*

 * enable a dryice interrupt

/*

 * disable a dryice interrupt

/*

 * This function attempts to clear the dryice write-error flag.

 *

 * A dryice write error is similar to a bus fault and should not occur in

 * normal operation.  Clearing the flag requires another write, so the root

 * cause of the problem may need to be fixed before the flag can be cleared.

 clear the write error flag */

 wait for it to take effect */

/*

 * Write a dryice register and wait until it completes.

 *

 * This function uses interrupts to determine when the

 * write has completed.

 serialize register writes */

 enable the write-complete interrupt */

 do the register write */

 wait for the write to finish */

 check for write error */

/*

 * read the seconds portion of the current time from the dryice time counter

/*

 * set the seconds portion of dryice time counter and clear the

 * fractional part.

 we are even more out of luck */

 we are out of luck for now */

 zero the fractional part first */

/*

 * read the seconds portion of the alarm register.

 * the fractional part of the alarm register is always zero.

 alarm is enabled if the interrupt is enabled */

 don't allow the DSR read to mess up DSR_WCF */

 alarm is pending if the alarm flag is set */

/*

 * set the seconds portion of dryice alarm register

 write the new alarm time */

 enable alarm intr */

 disable alarm intr */

/*

 * interrupt handler for dryice "normal" and security violation interrupt

 handle the security violation event */

			/*

			 * Disable the interrupt when this kind of event has

			 * happened.

			 * There cannot be more than one event of this type,

			 * because it needs a complex state change

			 * including a main power cycle to get again out of

			 * this state.

 report the violation */

 handle write complete and write error cases */

		/*If the write wait queue is empty then there is no pending

		  operations. It means the interrupt is for DryIce -Security.

 DSR_WCF clears itself on DSR read */

 mask the interrupt */

 save the dsr value for the wait queue */

 handle the alarm case */

 DSR_WCF clears itself on DSR read */

 mask the interrupt */

 finish alarm in user context */

/*

 * post the alarm event from user context so it can sleep

 * on the write completion.

 dismiss the interrupt (ignore error) */

 pass the alarm event to the rtc framework. */

/*

 * probe for dryice rtc device

	/* the 2nd irq is the security violation irq

	 * make this optional, don't break the device tree ABI

	/*

	 * Initialize dryice hardware

 mask all interrupts */

 this is not an error, see above */

 mask all interrupts */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An rtc driver for the Dallas DS1553

 *

 * Copyright (C) 2006 Atsushi Nemoto <anemo@mba.ocn.ne.jp>

 Bits in the Control/Century register */

 Bits in the Seconds register */

 Bits in the Flags register */

 Bits in the Interrupts register */

 RTC_CENTURY and RTC_CONTROL share same register */

 give enough time to update RTC in case of continuous read */

 year is 1900 + tm->tm_year */

 clear interrupts */

 read and clear interrupt */

 turn RTC on if it was not on */

 work with hotplug and coldplug */

 SPDX-License-Identifier: GPL-2.0

/*

 * Real Time Clock driver for AB-RTCMC-32.768kHz-EOZ9 chip.

 * Copyright (C) 2019 Orolia

 *

 Enable Self Recovery, Clock for Watch and EEPROM refresh functions */

 Enable built-in termometer */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 Cadence

 *

 * Authors:

 *  Jan Kotas <jank@cadence.com>

 Registers */

 Control */

 Status */

 Keep RTC */

 Alarm, Event, Interrupt */

 Time */

 Calendar */

 Reading the register clears it */

 If the RTC is disabled, assume the values are invalid */

 Update registers, check valid flags */

 Update registers, check valid alarm flags */

 The RTC supports 01.01.1900 - 31.12.2999 */

 Always use 24-hour mode and keep the RTC values */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Spreadtrum Communications Inc.

 *

 BIT & MASK definition for SPRD_RTC_INT_* registers */

 second/minute/hour/day values mask definition */

 alarm lock definition for SPRD_RTC_SPG_UPD register */

 SPG values definition for SPRD_RTC_SPG_UPD register */

 power control/status definition */

 timeout of synchronizing time and alarm registers (us) */

/*

 * The Spreadtrum RTC controller has 3 groups registers, including time, normal

 * alarm and auxiliary alarm. The time group registers are used to set RTC time,

 * the normal alarm registers are used to set normal alarm, and the auxiliary

 * alarm registers are used to set auxiliary alarm. Both alarm event and

 * auxiliary alarm event can wake up system from deep sleep, but only alarm

 * event can power up system from power down status.

 wait until the SPG value is updated successfully */

 convert seconds to RTC time format */

	/*

	 * Since the time and normal alarm registers are put in always-power-on

	 * region supplied by VDDRTC, then these registers changing time will

	 * be very long, about 125ms. Thus here we should wait until all

	 * values are updated successfully.

 clear the auxiliary alarm interrupt status */

 Clear RTC power status firstly */

		/*

		 * Set RTC power status to indicate now RTC has valid time

		 * values.

	/*

	 * The RTC core checks to see if there is an alarm already set in RTC

	 * hardware, and we always read the normal alarm at this time.

	/*

	 * We have 2 groups alarms: normal alarm and auxiliary alarm. Since

	 * both normal alarm event and auxiliary alarm event can wake up system

	 * from deep sleep, but only alarm event can power up system from power

	 * down status. Moreover we do not need to poll about 125ms when

	 * updating auxiliary alarm registers. Thus we usually set auxiliary

	 * alarm when wake up system from deep sleep, and for other scenarios,

	 * we should set normal alarm with polling status.

	 *

	 * So here we check if the alarm time is set by aie_timer, if yes, we

	 * should set normal alarm, if not, we should set auxiliary alarm which

	 * means it is just a wake event.

 clear the alarm interrupt status firstly */

 unlock the alarm to enable the alarm function. */

		/*

		 * Lock the alarm function in case fake alarm event will power

		 * up systems.

	/*

	 * If the RTC power status value is SPRD_RTC_POWER_RESET_VALUE, which

	 * means the RTC has been powered down, so the RTC time values are

	 * invalid.

	/*

	 * The SPRD_RTC_INT_EN register is not put in always-power-on region

	 * supplied by VDDRTC, so we should check if we need enable the alarm

	 * interrupt when system booting.

	 *

	 * If we have set SPRD_RTC_POWEROFF_ALM_FLAG which is saved in

	 * always-power-on region, that means we have set one alarm last time,

	 * so we should enable the alarm interrupt to help RTC core to see if

	 * there is an alarm already set in RTC hardware.

 check if we need set the alarm interrupt */

 check if RTC time values are valid */

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC subsystem, sysfs interface

 *

 * Copyright (C) 2005 Tower Technologies

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 device attributes */

/*

 * NOTE:  RTC times displayed in sysfs use the RTC's timezone.  That's

 * ideally UTC.  However, PCs that also boot to MS-Windows normally use

 * the local time and change to match daylight savings time.  That affects

 * attributes including date, time, since_epoch, and wakealarm.

/**

 * hctosys_show - indicate if the given RTC set the system time

 * @dev: The device that the attribute belongs to.

 * @attr: The attribute being read.

 * @buf: The result buffer.

 *

 * buf is "1" if the system clock was set by this RTC at the last

 * boot or resume event.

	/* Don't show disabled alarms.  For uniformity, RTC alarms are

	 * conceptually one-shot, even though some common RTCs (on PCs)

	 * don't actually work that way.

	 *

	 * NOTE: RTC implementations where the alarm doesn't match an

	 * exact YYYY-MM-DD HH:MM[:SS] date *must* disable their RTC

	 * alarms after they trigger, to ensure one-shot semantics.

	/* Only request alarms that trigger in the future.  Disable them

	 * by writing another time, e.g. 0 meaning Jan 1 1970 UTC.

		/* Avoid accidentally clobbering active alarms; we can't

		 * entirely prevent that here, without even the minimal

		 * locking from the /dev/rtcN api.

		/* Provide a valid future alarm time.  Linux isn't EFI,

		 * this time won't be ignored when disabling the alarm.

/* The reason to trigger an alarm with no process watching it (via sysfs)

 * is its side effect:  waking from a system state like suspend-to-RAM or

 * suspend-to-disk.  So: no attribute unless that side effect is possible.

 * (Userspace may disable that mechanism later.)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Epson RTC-9701JE

 *

 * Copyright (C) 2008 Magnus Damm

 *

 * Based on rtc-max6902.c

 *

 * Copyright (C) 2006 8D Technologies inc.

 * Copyright (C) 2004 Compulab Ltd.

 Second Counter */

 Minute Counter */

 Hour Counter */

 Week Counter */

 Day Counter */

 Month Counter */

 Year Counter */

 Y100 Counter */

 Minute Alarm */

 Hour Alarm */

 Week/Day Alarm */

 Interval Timer */

 Extension Register */

 RTC Flag Register */

 RTC Control Register */

 RSECCNT */

 RMINCNT */

 RHRCNT */

 RDAYCNT */

 RMONCNT */

 RYRCNT */

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC driver for the interal RTC block in the Amlogic Meson6, Meson8,

 * Meson8b and Meson8m2 SoCs.

 *

 * The RTC is split in to two parts, the AHB front end and a simple serial

 * connection to the actual registers. This driver manages both parts.

 *

 * Copyright (c) 2018 Martin Blumenstingl <martin.blumenstingl@googlemail.com>

 * Copyright (c) 2015 Ben Dooks <ben.dooks@codethink.co.uk> for Codethink Ltd

 * Based on origin by Carlo Caione <carlo@endlessm.com>

 registers accessed from cpu bus */

 rtc registers accessed via rtc-serial interface */

 number of address bits to send */

 number of data bits to tx/rx */

 rtc device we created */

 device we bound from */

 reset source */

 voltage input */

 peripheral registers */

 serial registers */

 RTC front-end serialiser controls */

 prepare bus for transfers, set all lines low */

 wait for the bus to be ready */

 write the static value and start the auto serializer */

 wait for the auto serializer to complete */

 RTC interface layer functions */

 NVMEM interface layer functions */

	/*

	 * check if we can read RTC counter, if not then the RTC is probably

	 * not functional. If it isn't probably best to not bind.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Real time clocks driver for MStar/SigmaStar ARMv7 SoCs.

 * Based on "Real Time Clock driver for msb252x." that was contained

 * in various MStar kernels.

 *

 * (C) 2019 Daniel Palmer

 * (C) 2021 Romain Perier

 Registers */

 Control bits for REG_RTC_CTRL */

 Control bits for REG_RTC_STATUS_INT */

 Wait for HW latch done */

 Enable load for loading value into internal RTC counter */

 Wait for HW latch done */

 SPDX-License-Identifier: GPL-2.0

/*

 * A driver for the I2C members of the Abracon AB x8xx RTC family,

 * and compatible: AB 1805 and AB 0805

 *

 * Copyright 2014-2015 Macq S.A.

 *

 * Author: Philippe De Muyter <phdm@macqel.be>

 * Author: Alexandre Belloni <alexandre.belloni@bootlin.com>

 *

	/*

	 * Write the configuration key register to enable access to the Trickle

	 * register

 Read the Oscillator Failure only in XT mode */

 Clear the OF bit of Oscillator Status Register */

	/*

	 * It is unclear if we'll get an interrupt before the external

	 * reset kicks in.

 1024 autocalibration is 0x10 */

 512 autocalibration is 0x11 */

 Unlock write access to Oscillator Control Register */

 Unlock write access on Oscillator Control register */

	/*

	 * Writing any timeout to the WDT register resets the watchdog timer.

	 * Writing 0 disables it.

 Configure RV1805 specifics */

		/*

		 * Avoid accidentally entering test mode. This can happen

		 * on the RV1805 in case the reserved bit 5 in control2

		 * register is set. RV-1805-C3 datasheet indicates that

		 * the bit should be cleared in section 11h - Control2.

		/*

		 * Avoid extra power leakage. The RV1805 uses smaller

		 * 10pin package and the EXTI input is not present.

		 * Disable it to avoid leakage.

		/*

		 * Write the configuration key register to enable access to

		 * the config2 register

 part autodetection */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Real Time Clock interface for XScale PXA27x and PXA3xx

 *

 * Copyright (C) 2008 Robert Jarzmik

/*

 * PXA Registers and bits definitions

 Periodic interrupt count enable */

 Periodic interrupt Alarm enable */

 Periodic interrupt detected */

 RTC stopwatch alarm2 enable */

 RTC stopwatch alarm2 detected */

 RTC stopwatch alarm1 enable */

 RTC stopwatch alarm1 detected */

 RTC alarm2 enable */

 RTC alarm2 detected */

 RTC alarm1 enable */

 RTC alarm1 detected */

 HZ interrupt enable */

 RTC alarm interrupt enable */

 HZ rising-edge detected */

 RTC alarm detected */

 Protects this structure */

 clear interrupt sources */

 temporary disable rtc interrupts */

 clear alarm interrupt if it has occurred */

 update irq data & counter */

 enable back rtc interrupts */

 SPDX-License-Identifier: GPL-2.0

/* drivers/rtc/rtc-goldfish.c

 *

 * Copyright (C) 2007 Google, Inc.

 * Copyright (C) 2017 Imagination Technologies Ltd.

 get low bits of current time  */

   and update TIMER_TIME_HIGH  */

 get high bits of time at last */

   TIMER_TIME_LOW read         */

 set low bits of alarm and     */

   activate it                 */

 set high bits of next alarm   */

		/*

		 * if this function was called with enabled=0

		 * then it could mean that the application is

		 * trying to cancel an ongoing alarm

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Motorola CPCAP PMIC RTC driver

 *

 * Based on cpcap-regulator.c from Motorola Linux kernel tree

 * Copyright (C) 2009 Motorola, Inc.

 *

 * Rewritten for mainline kernel

 *  - use DT

 *  - use regmap

 *  - use standard interrupt framework

 *  - use managed device resources

 *  - remove custom "secure clock daemon" helpers

 *

 * Copyright (C) 2017 Sebastian Reichel <sre@kernel.org>

		/* The TOD1 and TOD2 registers MUST be written in this order

		 * for the change to properly set.

		/* Clearing the upper lower 8 bits of the TOD guarantees that

		 * the upper half of TOD (TOD2) will not increment for 0xFF RTC

		 * ticks (255 seconds).  During this time we can safely write

		 * to DAY, TOD2, then TOD1 (in that order) and expect RTC to be

		 * synchronized to the exact time requested upon the final write

		 * to TOD1.

	/* Stock Android uses the 1 Hz interrupt for "secure clock daemon",

	 * which is not supported by the mainline kernel. The mainline kernel

	 * does not use the irq at the moment, but we explicitly request and

	 * disable it, so that its masked and does not wake up the processor

	 * every second.

 ignore error and continue without wakeup support */

 SPDX-License-Identifier: GPL-2.0-only

/*

* Copyright (c) 2014-2015 MediaTek Inc.

* Author: Tianping.Fang <tianping.fang@mediatek.com>

	/* HW register use 7 bits to store year data, minus

	 * RTC_MIN_YEAR_OFFSET before write year data to register, and plus

	 * RTC_MIN_YEAR_OFFSET back after read year from register

 HW register start mon from one, but tm_mon start from zero. */

	/* rtc_tm_to_time64 covert Gregorian date to seconds since

	 * 01-01-1970 00:00:00, and this date is Thursday.

 Time register write to hardware after call trigger function */

	/* All alarm time register write to hardware after calling

	 * mtk_rtc_write_trigger. This can avoid race condition if alarm

	 * occur happen during writing alarm time register.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * drivers/rtc/rtc-pl031.c

 *

 * Real Time Clock interface for ARM AMBA PrimeCell 031 RTC

 *

 * Author: Deepak Saxena <dsaxena@plexity.net>

 *

 * Copyright 2006 (c) MontaVista Software, Inc.

 *

 * Author: Mian Yousaf Kaukab <mian.yousaf.kaukab@stericsson.com>

 * Copyright 2010 (c) ST-Ericsson AB

/*

 * Register definitions

 Data read register */

 Match register */

 Data load register */

 Control register */

 Interrupt mask and set register */

 Raw interrupt status register */

 Masked interrupt status register */

 Interrupt clear register */

 ST variants have additional timer functionality */

 Timer data read register */

 Timer data load register */

 Timer control register */

 Year data read register */

 Year match register */

 Year data load register */

 counter enable bit */

 Clockwatch enable bit */

 Periodic timer enable bit */

 Common bit definitions for Interrupt status and control registers */

 Alarm interrupt bit */

 Periodic interrupt bit. ST variants only. */

 Common bit definations for ST v2 for reading/writing time */

 Second [0-59] */

 Minute [0-59] */

 Hour [0-23] */

 Day of Week [1-7] 1=Sunday */

 Day of Month [1-31] */

 Month [1-12] 1=January */

/**

 * struct pl031_vendor_data - per-vendor variations

 * @ops: the vendor-specific operations used on this silicon version

 * @clockwatch: if this is an ST Microelectronics silicon version with a

 *	clockwatch function

 * @st_weekday: if this is an ST Microelectronics silicon version that need

 *	the weekday fix

 * @irqflags: special IRQ flags per variant

 Clear any pending alarm interrupts. */

/*

 * Convert Gregorian date to ST v2 RTC format.

 wday masking is not working in hardware so wday must be valid */

 wday is not provided, calculate it here */

/*

 * Convert ST v2 RTC format to Gregorian date.

 Enable the clockwatch on ST Variants */

	/*

	 * On ST PL031 variants, the RTC reset value does not provide correct

	 * weekday for 2000-01-01. Correct the erroneous sunday to saturday.

 Operations for the original ARM version */

 The First ST derivative */

 And the second ST derivative */

	/*

	 * This variant shares the IRQ with another block and must not

	 * suspend that IRQ line.

	 * TODO check if it shares with IRQF_NO_SUSPEND user, else we can

	 * remove IRQF_COND_SUSPEND

 ST Micro variants */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An I2C driver for Ricoh RS5C372, R2025S/D and RV5C38[67] RTCs

 *

 * Copyright (C) 2005 Pavel Mironchik <pmironchik@optifacio.net>

 * Copyright (C) 2006 Tower Technologies

 * Copyright (C) 2008 Paul Mundt

/*

 * Ricoh has a family of I2C based RTCs, which differ only slightly from

 * each other.  Differences center on pinout (e.g. how many interrupts,

 * output clock, etc) and how the control registers are used.  The '372

 * is significant only because that's the one this driver first supported.

 or ALARM_W */

 or ALARM_D */

 (ALARM_B only) */

 or WALE */

 or DALE */

 no periodic irq */

 1 Hz level irq */

 only if !R2x2x */

 only if  R2x2x */

 only if  R2x2x */

 only if  R2x2x */

 or WAFG */

 or DAFG */

 to read (style 1) or write registers starting at R */

/* REVISIT:  this assumes that:

 *  - we're in the 21st century, so it's safe to ignore the century

 *    bit for rv5c38[67] (REG_MONTH bit 7);

 *  - we should use ALARM_A not ALARM_B (may be wrong on some boards)

	/* This implements the third reading method from the datasheet, using

	 * an internal address that's reset after each transaction (by STOP)

	 * to 0x0f ... so we read extra registers, and skip the first one.

	 *

	 * The first method doesn't work with the iop3xx adapter driver, on at

	 * least 80219 chips; this works around that bug.

	 *

	 * The third method on the other hand doesn't work for the SMBus-only

	 * configurations, so we use the the first method there, stripping off

	 * the extra register in the process.

 tm->tm_mon is zero-based */

 year is 1900 + tm->tm_year */

 clear rtc warning bits */

/* NOTE:  Since RTC_WKALM_{RD,SET} were originally defined for EFI,

 * which only exposes a polled programming interface; and since

 * these calls map directly to those EFI requests; we don't demand

 * we have an IRQ for this chip when we go through this API.

 *

 * The older x86_pc derived RTC_ALM_{READ,SET} calls require irqs

 * though, managed through RTC_AIE_{ON,OFF} requests.

 report alarm time */

 ... and status */

 only handle up to 24 hours in the future, like RTC_ALM_SET */

 REVISIT: round up tm_sec */

 if needed, disable irq (clears pending status) */

 set alarm */

 any/all days */

 ... and maybe enable its irq */

 nothing */

 SYSFS */

 use 24hr mode */

 impossible */

		/*

		 * If we don't have any master mode adapter, try breaking

		 * it down in to the barest of capabilities.

 Still no good, give up */

 we read registers 0x0f then 0x00-0x0f; skip the first one */

 clock may be set for am/pm or 24 hr time */

		/* alarm uses ALARM_A; and nINTRA on 372a, nINTR on 372b.

		 * so does periodic irq, except some 327a modes.

		/* alarm uses ALARM_W; and nINTRB for alarm and periodic

		 * irq, on both 386 and 387

	/* if the oscillator lost power and no other software (like

	 * the bootloader) set it up, do it here.

	 *

	 * The R2025S/D does this a little differently than the other

	 * parts, so we special case that..

 REVISIT use client->irq to register alarm irq ... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Ricoh RP5C01 RTC Driver

 *

 *  Copyright 2009 Geert Uytterhoeven

 *

 *  Based on the A3000 TOD code in arch/m68k/amiga/config.c

 *  Copyright (C) 1993 Hamish Macdonald

 MODE 00 */

 MODE 00 */

 MODE 00 and MODE 01 */

 MODE 00 and MODE 01 */

 MODE 00 and MODE 01 */

 MODE 00 and MODE 01 */

 MODE 00 and MODE 01 */

 MODE 00 and MODE 01 */

 MODE 00 and MODE 01 */

 MODE 00 */

 MODE 00 */

 MODE 00 */

 MODE 00 */

 MODE 01 */

 MODE 01 */

 all modes */

 all modes */

 all modes */

 timer enable */

 alarm enable */

 time */

 alarm, 12h/24h, leap year */

 RAM 4 bits x 13 */

 RAM 4 bits x 13 */

 reset divider stages for */

 seconds or smaller units */

 reset all alarm registers */

 against concurrent RTC/NVRAM access */

/*

 * The NVRAM is organized as 2 blocks of 13 nibbles of 4 bits.

 * We provide access to them like AmigaOS does: the high nibble of each 8-bit

 * byte is stored in BLOCK10, the low nibble in BLOCK11.

 SPDX-License-Identifier: GPL-2.0

/*

 * Real Time Clock (RTC) Driver for sd3078

 * Copyright (C) 2018 Zoro Li

/*

 * The sd3078 has write protection

 * and we can choose whether or not to use it.

 * Write protection is turned off by default.

/*

 * In order to prevent arbitrary modification of the time register,

 * when modification of the register,

 * the "write" bit needs to be written in a certain order.

 * 1. set WRITE1 bit

 * 2. set WRITE2 bit

 * 3. set WRITE3 bit

/*

 * In order to prevent arbitrary modification of the time register,

 * we should disable the write function.

 * when disable write,

 * the "write" bit needs to be clear in a certain order.

 * 1. clear WRITE2 bit

 * 2. clear WRITE3 bit

 * 3. clear WRITE1 bit

	/*

	 * The sd3078 supports 12/24 hour mode.

	 * When getting time,

	 * we need to convert the 12 hour mode to the 24 hour mode.

 24H MODE */

 12H MODE PM */

 12H MODE AM */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Real time clock driver for DA9052

 *

 * Copyright(c) 2012 Dialog Semiconductor Ltd.

 *

 * Author: Dajun Dajun Chen <dajun.chen@diasemi.com>

 it will cause repeated irqs if not zero */

 DA9052 only has 6 bits for year - to represent 2000-2063 */

 DA9052 only has 6 bits for year - to represent 2000-2063 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * RTC client/driver for the Maxim/Dallas DS3232/DS3234 Real-Time Clock

 *

 * Copyright (C) 2009-2011 Freescale Semiconductor.

 * Author: Jack Lan <jack.lan@freescale.com>

 * Copyright (C) 2008 MIMOMax Wireless Ltd.

 Alarm 1 BASE */

 Alarm 2 BASE */

 Control register */

 control/status register */

	/* If the alarm is pending, clear it before requesting

	 * the interrupt, so an interrupt event isn't reported

	 * before everything is initialized.

 Extract additional information for AM/PM and century */

 Write to rtc_time structure */

 Convert to 24 hr */

 Day of the week in linux range is 0~6 while 1~7 in RTC chip */

 linux tm_mon range:0~11, while month range is 1~12 in RTC chip */

 Extract time from rtc_time and load into ds3232*/

 Day of the week in linux range is 0~6 while 1~7 in RTC chip */

 Date */

 linux tm_mon range:0~11, while month range is 1~12 in RTC chip */

/*

 * DS3232 has two alarm, we only use alarm1

 * According to linux specification, only support one-shot alarm

 * no periodic alarm mode

/*

 * linux rtc-module does not support wday alarm

 * and only 24h time mode supported indeed

 clear alarm interrupt enable bit */

 clear any pending alarm flag */

 enable alarm1 interrupt */

 disable alarm1 interrupt */

/*

 * Temperature sensor support for ds3232/ds3234 devices.

 * A user-initiated temperature conversion is not started by this function,

 * so the temperature is updated once every 64 seconds.

	/*

	 * Temperature is represented as a 10-bit code with a resolution of

	 * 0.25 degree celsius and encoded in two's complement format.

 disable alarm1 interrupt */

 clear the alarm pend flag */

	/* Control settings

	 *

	 * CONTROL_REG

	 * BIT 7	6	5	4	3	2	1	0

	 *     EOSC	BBSQW	CONV	RS2	RS1	INTCN	A2IE	A1IE

	 *

	 *     0	0	0	1	1	1	0	0

	 *

	 * CONTROL_STAT_REG

	 * BIT 7	6	5	4	3	2	1	0

	 *     OSF	BB32kHz	CRATE1	CRATE0	EN32kHz	BSY	A2F	A1F

	 *

	 *     1	0	0	0	1	0	0	0

 Print our settings */

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC subsystem, proc interface

 *

 * Copyright (C) 2005-06 Tower Technologies

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 *

 * based on arch/arm/common/rtctime.c

 SPDX-License-Identifier: GPL-2.0+

/*

 *	Real Time Clock driver for Wolfson Microelectronics WM831x

 *

 *	Copyright (C) 2009 Wolfson Microelectronics PLC.

 *

 *  Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

 *

/*

 * R16416 (0x4020) - RTC Write Counter

 RTC_WR_CNT - [15:0] */

 RTC_WR_CNT - [15:0] */

 RTC_WR_CNT - [15:0] */

/*

 * R16417 (0x4021) - RTC Time 1

 RTC_TIME - [15:0] */

 RTC_TIME - [15:0] */

 RTC_TIME - [15:0] */

/*

 * R16418 (0x4022) - RTC Time 2

 RTC_TIME - [15:0] */

 RTC_TIME - [15:0] */

 RTC_TIME - [15:0] */

/*

 * R16419 (0x4023) - RTC Alarm 1

 RTC_ALM - [15:0] */

 RTC_ALM - [15:0] */

 RTC_ALM - [15:0] */

/*

 * R16420 (0x4024) - RTC Alarm 2

 RTC_ALM - [15:0] */

 RTC_ALM - [15:0] */

 RTC_ALM - [15:0] */

/*

 * R16421 (0x4025) - RTC Control

 RTC_VALID */

 RTC_VALID */

 RTC_VALID */

 RTC_VALID */

 RTC_SYNC_BUSY */

 RTC_SYNC_BUSY */

 RTC_SYNC_BUSY */

 RTC_SYNC_BUSY */

 RTC_ALM_ENA */

 RTC_ALM_ENA */

 RTC_ALM_ENA */

 RTC_ALM_ENA */

 RTC_PINT_FREQ - [6:4] */

 RTC_PINT_FREQ - [6:4] */

 RTC_PINT_FREQ - [6:4] */

/*

 * R16422 (0x4026) - RTC Trim

 RTC_TRIM - [9:0] */

 RTC_TRIM - [9:0] */

 RTC_TRIM - [9:0] */

	/*

	 * The write counter contains a pseudo-random number which is

	 * regenerated every time we set the RTC so it should be a

	 * useful per-system source of entropy.

/*

 * Read current time and date in RTC

 Has the RTC been programmed? */

	/* Read twice to make sure we don't read a corrupt, partially

	 * incremented, value.

/*

 * Set current time and date in RTC

	/* Wait for the update to complete - should happen first time

	 * round but be conservative.

	/* Check that the update was accepted; security features may

	 * have caused the update to be ignored.

 Allow a second of change in case of tick */

/*

 * Read alarm time and date in RTC

 Turn off the alarm if it should not be a wake source. */

/* Enable the alarm if it should be enabled (in case it was disabled to

 * prevent use as a wake source).

 Unconditionally disable the alarm */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Au1xxx counter0 (aka Time-Of-Year counter) RTC interface driver.

 *

 * Copyright (C) 2008 Manuel Lauss <mano@roarinelk.homelinux.net>

/* All current Au1xxx SoCs have 2 counters fed by an external 32.768 kHz

 * crystal. Counter 0, which keeps counting during sleep/powerdown, is

 * used to count seconds since the beginning of the unix epoch.

 *

 * The counters must be configured and enabled by bootloader/board code;

 * no checks as to whether they really get a proper 32.768kHz clock are

 * made as this would take far too long.

 32kHz clock enabled and detected */

	/* wait for the pending register write to succeed.  This can

	 * take up to 6 seconds...

 set counter0 tickrate to 1Hz if necessary */

 wait until hardware gives access to TRIM register */

			/* timed out waiting for register access; assume

			 * counters are unusable.

 set 1Hz TOY tick rate */

 wait until the hardware allows writes to the counter reg */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc-ds1390.c -- driver for the Dallas/Maxim DS1390/93/94 SPI RTC

 *

 * Copyright (C) 2008 Mercury IMC Ltd

 * Written by Mark Jackson <mpfj@mimc.co.uk>

 *

 * NOTE: Currently this driver only supports the bare minimum for read

 * and write the RTC. The extra features provided by the chip family

 * (alarms, trickle charger, different control registers) are unavailable.

 cmd + 8 registers */

 MSB must be '1' to write */

 Clear MSB to indicate read */

 do the i/o */

 Enable charger */

 Resistor select */

 build the message */

 do the i/o */

	/* The chip sends data in this order:

 mask off century bit */

 adjust for century bit */

 build the message */

 do the i/o */

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC interface for Wilco Embedded Controller with R/W abilities

 *

 * Copyright 2018 Google LLC

 *

 * The corresponding platform device is typically registered in

 * drivers/platform/chrome/wilco_ec/core.c

 Message sent to the EC to request the current time. */

/**

 * struct ec_rtc_read_response - Format of RTC returned by EC.

 * @reserved: Unused byte

 * @second: Second value (0..59)

 * @minute: Minute value (0..59)

 * @hour: Hour value (0..23)

 * @day: Day value (1..31)

 * @month: Month value (1..12)

 * @year: Year value (full year % 100)

 * @century: Century value (full year / 100)

 *

 * All values are presented in binary (not BCD).

/**

 * struct ec_rtc_write_request - Format of RTC sent to the EC.

 * @command: Always EC_COMMAND_CMOS

 * @reserved: Unused byte

 * @param: Always EC_CMOS_TOD_WRITE

 * @century: Century value (full year / 100)

 * @year: Year value (full year % 100)

 * @month: Month value (1..12)

 * @day: Day value (1..31)

 * @hour: Hour value (0..23)

 * @minute: Minute value (0..59)

 * @second: Second value (0..59)

 * @weekday: Day of the week (0=Saturday)

 *

 * All values are presented in BCD.

 Ignore other tm fields, man rtc says userspace shouldn't use them. */

	/*

	 * Convert from 0=Sunday to 0=Saturday for the EC

	 * We DO need to set weekday because the EC controls battery charging

	 * schedules that depend on the day of the week.

 EC only supports this century */

 SPDX-License-Identifier: GPL-2.0

/*

 * drivers/rtc/rtc-pcf85363.c

 *

 * Driver for NXP PCF85363 real-time clock.

 *

 * Copyright (C) 2017 Eric Nelson

/*

 * Date/Time registers

/*

 * Alarm registers

/*

 * Time stamp registers

/*

 * control registers

 read the RTC date and time registers all at once */

 adjust for 1900 base of rtc_time */

 clear current flags */

	/*

	 * Disable the alarm interrupt before changing the value to avoid

	 * spurious interrupts

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc-rc5t583.c -- RICOH RC5T583 Real Time Clock

 *

 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.

 * Author: Venu Byravarasu <vbyravarasu@nvidia.com>

 To store the list of enabled interrupts, during system suspend */

 Total number of RTC registers needed to set time*/

 Total number of RTC registers needed to set Y-Alarm*/

 Set Y-Alarm interrupt */

 Get Y-Alarm interrupt status*/

 Set Y-Alarm, based on 'enabled' */

/*

 * Gets current rc5t583 RTC time and date parameters.

 *

 * The RTC's time/alarm representation is not what gmtime(3) requires

 * Linux to use:

 *

 *  - Months are 1..12 vs Linux 0-11

 *  - Years are 0..99 vs Linux 1900..N (we assume 21st century)

 check if YALE is set */

 clear pending Y-alarm interrupt bit */

 Notify RTC core on event */

 Clear pending interrupts */

 clear RTC Adjust register */

/*

 * Disable rc5t583 RTC interrupts.

 * Sets status flag to free.

 Store current list of enabled interrupts*/

 Restore list of enabled interrupts before suspend */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * RTC driver for Rockchip RK808

 *

 * Copyright (c) 2014, Fuzhou Rockchip Electronics Co., Ltd

 *

 * Author: Chris Zhong <zyw@rock-chips.com>

 * Author: Zhang Qing <zhangqing@rock-chips.com>

 RTC_CTRL_REG bitfields */

/* RK808 has a shadowed register for saving a "frozen" RTC time.

 * When user setting "GET_TIME" to 1, the time will save in this shadowed

 * register. If set "READSEL" to 1, user read rtc time register, actually

 * get the time of that moment. If we need the real time, clr this bit.

 REG_SECONDS_REG through REG_YEARS_REG is how many registers? */

/*

 * The Rockchip calendar used by the RK808 counts November with 31 days. We use

 * these translation functions to convert its dates to/from the Gregorian

 * calendar used by the rest of the world. We arbitrarily define Jan 1st, 2016

 * as the day when both calendars were in sync, and treat all other dates

 * relative to that.

 * NOTE: Other system software (e.g. firmware) that reads the same hardware must

 * implement this exact same conversion algorithm, with the same anchor date.

 If it's Nov 31st, rtc_tm_to_time64() will count that like Dec 1st */

 Compensate if we went back over Nov 31st (will work up to 2381) */

 This may result in 31! */

 Read current time and date in RTC */

 Force an update of the shadowed registers right now */

	/*

	 * After we set the GET_TIME bit, the rtc time can't be read

	 * immediately. So we should wait up to 31.25 us, about one cycle of

	 * 32khz. If we clear the GET_TIME bit here, the time of i2c transfer

	 * certainly more than 31.25us: 16 * 2.5us at 400kHz bus frequency.

 Set current time and date in RTC */

 Stop RTC while updating the RTC registers */

 Start RTC again */

 Read alarm time and date in RTC */

/*

 * We will just handle setting the frequency and make use the framework for

 * reading the periodic interupts.

 *

 * @freq: Current periodic IRQ freq:

 * bit 0: every second

 * bit 1: every minute

 * bit 2: every hour

 * bit 3: every day

 Turn off the alarm if it should not be a wake source. */

/* Enable the alarm if it should be enabled (in case it was disabled to

 * prevent use as a wake source).

 start rtc running by default, and use shadowed timer. */

 request alarm irq of rk808 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc-fm3130.c - RTC driver for Ramtron FM3130 I2C chip.

 *

 *  Copyright (C) 2008 Sergey Lapin

 *  Based on ds1307 driver by James Chapman and David Brownell

 Osciallator enabled */

 Low battery */

 Alarm flag */

 Century overflow */

 Power on reset */

 Alarm enable */

 Calibration mode */

 W=1 -> write mode W=0 normal */

 R=1 -> read mode R=0 normal */

		/* We have invalid data in RTC, probably due

		to battery faults or other problems. Return EIO

		for now, it will allow us to set data later instead

 read the RTC date and time registers all at once */

 assume 20YY not 19YY, and ignore CF bit */

 first register addr */

 assume 20YY not 19YY */

 Writing time registers, we don't support multibyte transfers */

 We assume here that data are valid once written */

		/*

		 * We have invalid alarm in RTC, probably due to battery faults

		 * or other problems. Return EIO for now, it will allow us to

		 * set alarm value later instead of error during probing which

		 * disables device

 read the RTC alarm registers all at once */

 RTC is 1-12, tm_mon is 0-11 */

 check if alarm enabled */

 Writing time registers, we don't support multibyte transfers */

 enable or disable alarm */

 We assume here that data is valid once written */

 alarm off */

 alarm on */

 Messages to read time */

 Messages to read alarm */

 Disabling calibration mode */

 Disabling read and write modes */

 oscillator off?  turn it on, so clock can tick. */

 low battery?  clear flag, and warn */

 check if Power On Reset bit is set */

 ACS is controlled by alarm */

 alarm registers sanity check */

 clock registers sanity chek */

	/* We won't bail out here because we just got invalid data.

 SPDX-License-Identifier: GPL-2.0-only

/* rtc-generic: RTC driver using the generic RTC abstraction

 *

 * Copyright (C) 2008 Kyle McMartin <kyle@mcmartin.ca>

 SPDX-License-Identifier: GPL-2.0-only

/* rtc-ds1343.c

 *

 * Driver for Dallas Semiconductor DS1343 Low Current, SPI Compatible

 * Real Time Clock

 *

 * Author : Raghavendra Chandra Ganiga <ravi23ganiga@gmail.com>

 *	    Ankur Srivastava <sankurece@gmail.com> : DS1343 Nvram Support

 RTC DS1343 Registers */

 DS1343 Control Registers bits */

 DS1343 Status Registers bits */

 DS1343 Trickle Charger Registers bits */

 year offset from 1900 */

	/* RTC DS1347 works in spi mode 3 and

	 * its chip select is active high. Active high should be defined as

	 * "inverse polarity" as GPIO-based chip selects can be logically

	 * active high but inverted by the GPIO library.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Epson RTC module RX-8010 SJ

 *

 * Copyright(C) Timesys Corporation 2015

 * Copyright(C) General Electric Company 2015

 0x20 to 0x2F are user registers */

 set STOP bit before changing clock/calendar */

 clear STOP bit after changing clock/calendar */

 Initialize reserved registers as specified in datasheet */

 SPDX-License-Identifier: GPL-2.0-only

/* rtc-ds1347.c

 *

 * Driver for Dallas Semiconductor DS1347 Low Current, SPI Compatible

 * Real Time Clock

 *

 * Author : Raghavendra Chandra Ganiga <ravi23ganiga@gmail.com>

 Registers in ds1347 rtc */

 spi setup with ds1347 in mode 3 and bits per word as 8 */

 Disable the write protect of rtc */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012 Sven Schnelle <svens@stackframe.org>

 enable oscillator */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (C) 2011-2012 Freescale Semiconductor, Inc.

 These register offsets are relative to LP (Low Power) range */

 Read 64 bit timer register, which could be in inconsistent state */

/* Read the secure real time counter, taking care to deal with the cases of the

 * counter updating while being read.

	/* As expected, the registers might update between the read of the LSB

	 * reg and the MSB reg.  It's also possible that one register might be

	 * in partially modified state as well.

 Convert 47-bit counter to 32-bit raw second count */

 Just read the lsb from the counter, dealing with inconsistent state */

 Wait for 3 CKIL cycles, about 61.0-91.5 µs */

 wrap around _is_ handled! */

 Disable RTC first */

 Write 32-bit time to 47-bit timer, leaving 15 LSBs blank */

 Enable RTC again */

 Clear alarm interrupt status bit */

 RTC alarm should be one-shot */

 clear interrupt status */

 Initialize glitch detect */

 Clear interrupt status */

 Enable RTC */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *	Real Time Clock interface for Linux on Atmel AT91RM9200

 *

 *	Copyright (C) 2002 Rick Bronson

 *

 *	Converted to RTC class model by Andrew Victor

 *

 *	Ported to Linux 2.6 by Steven Scholz

 *	Based on s3c2410-rtc.c Simtec Electronics

 *

 *	Based on sa1100-rtc.c by Nils Faerber

 *	Based on rtc.c by Paul Gortmaker

 Control Register */

 Update Request Time Register */

 Update Request Calendar Register */

 Mode Register */

 12/24 hour mode */

 Negative PPM correction */

 Slow clock correction */

 High PPM correction */

 Time Register */

 Current Second */

 Current Minute */

 Current Hour */

 Ante Meridiem Post Meridiem Indicator */

 Calendar Register */

 Current Century */

 Current Year */

 Current Month */

 Current Day */

 Current Date */

 Time Alarm Register */

 Second Alarm Enable */

 Minute Alarm Enable */

 Hour Alarm Enable */

 Calendar Alarm Register */

 Month Alarm Enable */

 Date Alarm Enable */

 Status Register */

 Acknowledge for Update */

 Alarm Flag */

 Second Event */

 Time Event */

 Calendar Event */

 Status Clear Command Register */

 Interrupt Enable Register */

 Interrupt Disable Register */

 Interrupt Mask Register */

 Valid Entry Register */

 Non valid Time */

 Non valid Calendar */

 Non valid Time Alarm */

 Non valid Calendar Alarm */

	/*

	 * Register read back (of any RTC-register) needed to make sure

	 * IDR-register write has reached the peripheral before updating

	 * shadow mask.

	 *

	 * Note that there is still a possibility that the mask is updated

	 * before interrupts have actually been disabled in hardware. The only

	 * way to be certain would be to poll the IMR-register, which is is

	 * the very register we are trying to emulate. The register read back

	 * is a reasonable heuristic.

/*

 * Decode time/date into rtc_time structure

 must read twice in case it changes */

	/*

	 * The Calendar Alarm register does not have a field for

	 * the year - so these will return an invalid value.

 century */

 year */

 day of the week [0-6], Sunday=0 */

/*

 * Read current time and date in RTC

/*

 * Set current time and date in RTC

 Stop Time/Calendar from counting */

 wait for ACKUPD interrupt */

 Restart Time/Calendar */

/*

 * Read alarm time and date in RTC

/*

 * Set alarm time and date in RTC

 offset less than 764 ppb, disable correction*/

	/*

	 * 29208 ppb is the perfect cutoff between low range and high range

	 * low range values are never better than high range value after that.

/*

 * IRQ handler for the RTC

 this interrupt is shared!  Is it ours? */

 clear status reg */

 sentinel */

/*

 * Initialize and install RTC driver

 Disable all interrupts */

	/* cpu init code should really have flagged this device as

	 * being wake-capable; if it didn't, do that here.

	/* enable SECEV interrupt in order to initialize at91_rtc_upd_rdy

	 * completion.

/*

 * Disable and remove the RTC driver

 Disable all interrupts */

 Disable all interrupts */

 AT91RM9200 RTC Power management control */

	/* this IRQ is shared with DBGU and other hardware which isn't

	 * necessarily doing PM like we are...

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Real Time Clock interface for StrongARM SA1x00 and XScale PXA2xx

 *

 * Copyright (c) 2000 Nils Faerber

 *

 * Based on rtc.c by Paul Gortmaker

 *

 * Original Driver by Nils Faerber <nils@kernelconcepts.de>

 *

 * Modifications from:

 *   CIH <cih@coventive.com>

 *   Nicolas Pitre <nico@fluxnic.net>

 *   Andrew Christian <andrew.christian@hp.com>

 *

 * Converted to the RTC subsystem and Driver Model

 *   by Richard Purdie <rpurdie@rpsys.net>

 HZ interrupt enable */

 RTC alarm interrupt enable */

 HZ rising-edge detected */

 RTC alarm detected */

 clear interrupt sources */

	/* Fix for a nasty initialization problem the in SA11xx RTSR register.

		/* This is the original code, before there was the if test

		 * above. This code does not clear interrupts that were not

		/* For some reason, it is possible to enter this routine

		 * without interruptions enabled, it has been tested with

		 * several units (Bug in SA11xx chip?).

		 *

		 * This situation leads to an infinite "loop" of interrupt

		 * routine calling and as a result the processor seems to

 clear alarm interrupt if it has occurred */

 update irq data & counter */

	/*

	 * According to the manual we should be able to let RTTR be zero

	 * and then a default diviser for a 32.768KHz clock is used.

	 * Apparently this doesn't work, at least for my SA1110 rev 5.

	 * If the clock divider is uninitialized then reset it to the

	 * default value to get the 1Hz clock.

 The current RTC value probably doesn't make sense either */

	/* Fix for a nasty initialization problem the in SA11xx RTSR register.

	 * See also the comments in sa1100_rtc_interrupt().

	 *

	 * Sometimes bit 1 of the RTSR (RTSR_HZ) will wake up 1, which means an

	 * interrupt pending, even though interrupts were never enabled.

	 * In this case, this bit it must be reset before enabling

	 * interruptions to avoid a nonexistent interrupt to occur.

	 *

	 * In principle, the same problem would apply to bit 0, although it has

	 * never been observed to happen.

	 *

	 * This issue is addressed both here and in sa1100_rtc_interrupt().

	 * If the issue is not addressed here, in the times when the processor

	 * wakes up with the bit set there will be one spurious interrupt.

	 *

	 * The issue is also dealt with in sa1100_rtc_interrupt() to be on the

	 * safe side, once the condition that lead to this strange

	 * initialization is unknown and could in principle happen during

	 * normal processing.

	 *

	 * Notice that clearing bit 1 and 0 is accomplished by writting ONES to

 SPDX-License-Identifier: GPL-2.0+

/*

 * rtc-ab-b5ze-s3 - Driver for Abracon AB-RTCMC-32.768Khz-B5ZE-S3

 *                  I2C RTC / Alarm chip

 *

 * Copyright (C) 2014, Arnaud EBALARD <arno@natisbad.org>

 *

 * Detailed datasheet of the chip is available here:

 *

 *  https://www.abracon.com/realtimeclock/AB-RTCMC-32.768kHz-B5ZE-S3-Application-Manual.pdf

 *

 * This work is based on ISL12057 driver (drivers/rtc/rtc-isl12057.c).

 *

 Control section */

 Control 1 register */

 Pulse interrupt enable */

 Alarm interrupt enable */

 Second interrupt enable */

 24h/12h mode */

 Software reset */

 RTC circuit enable */

 Control 2 register */

 Countdown timer B int. enable */

 Countdown timer A int. enable */

 Watchdog timer A int. enable */

 Alarm interrupt status */

 Second interrupt status */

 Countdown timer B int. status */

 Countdown timer A int. status */

 Watchdog timer A int. status */

 Control 3 register */

 Power Management bit 2 */

 Power Management bit 1 */

 Power Management bit 0 */

 Battery switchover int. status */

 Battery low int. status */

 Battery switchover int. enable */

 Battery low int. enable */

 RTC section */

 RTC Seconds register */

 Clock integrity status */

 RTC Minutes register */

 RTC Hours register */

 RTC Hours PM bit */

 RTC Date register */

 RTC Day of the week register */

 RTC Month register */

 RTC Year register */

 Alarm section (enable bits are all active low) */

 Alarm - minute register */

 Minute enable */

 Alarm - hours register */

 Hour enable */

 Alarm - date register */

 Date (day of the month) enable */

 Alarm - day of the week reg. */

 Day of the week enable */

 Frequency offset section */

 Frequency offset register */

 Offset mode: 2 hours / minute */

 CLOCKOUT section */

 Timer & Clockout register */

 Permanent/pulsed timer A/int. 2 */

 Permanent/pulsed timer B */

 Clkout Freq bit 2 */

 Clkout Freq bit 1 */

 Clkout Freq bit 0 */

 Timer A: - 01 : countdown */

	       - 10 : timer	*/

 Timer B enable */

 Timer A Section */

 Timer A clock register */

 Freq bit 2 */

 Freq bit 1 */

 Freq bit 0 */

 Timer A register */

 Timer B Section */

 Timer B clock register */

 Timer B register */

 current alarm is via timer A */

/*

 * Try and match register bits w/ fixed null values to see whether we

 * are dealing with an ABB5ZES3.

 check if bits are cleared */

 Clear alarm status bit. */

 Enable or disable alarm (i.e. alarm interrupt generation) */

 Enable or disable timer (watchdog timer A interrupt generation) */

/*

 * Note: we only read, so regmap inner lock protection is sufficient, i.e.

 * we do not need driver's main lock protection.

	/*

	 * As we need to read CTRL1 register anyway to access 24/12h

	 * mode bit, we do a single bulk read of both control and RTC

	 * sections (they are consecutive). This also ease indexing

	 * of register values after bulk read.

 If clock integrity is not guaranteed, do not return a time value */

 12hr mode */

 PM */

 24hr mode */

 starts at 1 */

 MSB=0 clears OSC */

 24-hour format */

/*

 * Set provided TAQ and Timer A registers (TIMA_CLK and TIMA) based on

 * given number of seconds.

 1Hz */

/*

 * Return current number of seconds in Timer A. As we only use

 * timer A with a 1Hz freq, this is what we expect to have.

 1Hz */

/*

 * Read alarm currently configured via a watchdog timer using timer A. This

 * is done by reading current RTC time and adding remaining timer time.

	/*

	 * Instead of doing two separate calls, because they are consecutive,

	 * we grab both clockout register and Timer A section. The latter is

	 * used to decide if timer A is enabled (as a watchdog timer).

 get current time ... */

 ... convert to seconds ... */

 ... add remaining timer A time ... */

 ... and convert back. */

 Read alarm currently configured via a RTC alarm registers. */

	/*

	 * The alarm section does not store year/month. We use the ones in rtc

	 * section as a basis and increment month and then year if needed to get

	 * alarm after current time.

/*

 * As the Alarm mechanism supported by the chip is only accurate to the

 * minute, we use the watchdog timer mechanism provided by timer A

 * (up to 256 seconds w/ a second accuracy) for low alarm values (below

 * 4 minutes). Otherwise, we use the common alarm mechanism provided

 * by the chip. In order for that to work, we keep track of currently

 * configured timer type via 'timer_alarm' flag in our private data

 * structure.

/*

 * Set alarm using chip alarm mechanism. It is only accurate to the

 * minute (not the second). The function expects alarm interrupt to

 * be disabled.

		/*

		 * Chip only support alarms up to one month in the future. Let's

		 * return an error if we get something after that limit.

		 * Comparison is done by incrementing rtc_tm month field by one

		 * and checking alarm value is still below.

 handle year wrapping */

	/*

	 * Program all alarm registers but DW one. For each register, setting

	 * MSB to 0 enables associated alarm.

 do not match day of the week */

 Record currently configured alarm is not a timer */

 Enable or disable alarm interrupt generation */

/*

 * Set alarm using timer watchdog (via timer A) mechanism. The function expects

 * timer A interrupt to be disabled.

 Program given number of seconds to Timer A registers */

 Configure Timer A as a watchdog timer */

 Record currently configured alarm is a timer */

 Enable or disable timer interrupt generation */

/*

 * The chip has an alarm which is only accurate to the minute. In order to

 * handle alarms below that limit, we use the watchdog timer function of

 * timer A. More precisely, the timer method is used for alarms below 240

 * seconds.

 Let's first disable both the alarm and the timer interrupts */

	/*

	 * Let's now configure the alarm; if we are expected to ring in

	 * more than 240s, then we setup an alarm. Otherwise, a timer.

 Enable or disable battery low irq generation */

/*

 * Check current RTC status and enable/disable what needs to be. Return 0 if

 * everything went ok and a negative value upon error.

	/*

	 * By default, the devices generates a 32.768KHz signal on IRQ#1 pin. It

	 * is disabled here to prevent polluting the interrupt line and

	 * uselessly triggering the IRQ handler we install for alarm and battery

	 * low events. Note: this is done before clearing int. status below

	 * in this function.

	 * We also disable all timers and set timer interrupt to permanent (not

	 * pulsed).

	/*

	 * Each component of the alarm (MN, HR, DT, DW) can be enabled/disabled

	 * individually by clearing/setting MSB of each associated register. So,

	 * we set all alarm enable bits to disable current alarm setting.

 Set Control 1 register (RTC enabled, 24hr mode, all int. disabled) */

	/*

	 * Set Control 2 register (timer int. disabled, alarm status cleared).

	 * WTAF is read-only and cleared automatically by reading the register.

	/*

	 * Enable battery low detection function and battery switchover function

	 * (standard mode). Disable associated interrupts. Clear battery

	 * switchover flag but not battery low flag. The latter is checked

	 * later below.

 Check oscillator integrity flag */

	/*

	 * Check battery low flag at startup: this allows reporting battery

	 * is low at startup when IRQ line is not connected. Note: we record

	 * current status to avoid reenabling this interrupt later in probe

	 * function if battery is low.

	/*

	 * Check battery low detection flag and disable battery low interrupt

	 * generation if flag is set (interrupt can only be cleared when

	 * battery is replaced).

 Check alarm flag */

 Acknowledge and disable the alarm */

 Check watchdog Timer A flag */

		/*

		 * Acknowledge and disable the alarm. Note: WTAF

		 * flag had been cleared when reading CTRL2

 Enable battery low detection interrupt if battery not already low */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2019 MediaTek Inc.

 * Author: Ran Bi <ran.bi@mediatek.com>

 Clear interrupt */

 SEC has carried */

 mask day of week */

 Init RTC register */

 necessary before set MT2712_POWERKEY */

 RTC need POWERKEY1/2 match, then goto normal work mode */

 rtc hw init */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for ST M41T94 SPI RTC

 *

 * Copyright (C) 2008 Kim B. Heino

 write cmd + 7 registers */

 write time + date */

 clear halt update bit */

 clear stop bit */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * IBM OPAL RTC driver

 * Copyright (C) 2014 IBM

 Wait 10ms before retry */

 go around again */

 Wait 10ms before retry */

 go around again */

/*

 * TPO	Timed Power-On

 *

 * TPO get/set OPAL calls care about the hour and min and to make it consistent

 * with the rtc utility time conversion functions, we use the 'u64' to store

 * its value and perform bit shift by 32 before use..

 check if no alarm is set */

 Set Timed Power-On */

 if alarm is enabled */

 TPO, we care about hour and minute */

	/*

	 * TPO is automatically enabled when opal_set_tpo_time() is called with

	 * non-zero rtc-time. We only handle disable case which needs to be

	 * explicitly told to opal.

 legacy */))

 SPDX-License-Identifier: GPL-2.0-only

/* drivers/rtc/rtc-v3020.c

 *

 * Copyright (C) 2006 8D Technologies inc.

 * Copyright (C) 2004 Compulab Ltd.

 *

 * Driver for the V3020 RTC

 *

 * Changelog:

 *

 *  10-May-2006: Raphael Assenat <raph@8d.com>

 *				- Converted to platform driver

 *				- Use the generic rtc class

 *

 *  ??-???-2004: Someone at Compulab

 *			- Initial driver creation.

 MMIO access */

 GPIO access */

 Commands dont have data */

 Copy the current time to ram... */

 ...and then read constant values. */

 Write all the values to ram... */

 ...and set the clock. */

	/* Compulab used this delay here. I dont know why,

mdelay(5);*/

	/* Make sure the v3020 expects a communication cycle

	/* Test chip by doing a write/read sequence

	/* Make sure frequency measurement mode, test modes, and lock

 SPDX-License-Identifier: GPL-2.0-only

/*

 * An I2C driver for the Philips PCF8563 RTC

 * Copyright 2005-06 Tower Technologies

 *

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 * Maintainers: http://www.nslu2-linux.org/

 *

 * based on the other drivers in this same directory.

 *

 * https://www.nxp.com/docs/en/data-sheet/PCF8563.pdf

 status */

 datetime */

 alarm */

 clock out */

 clock out enabled */

 frequenc mask */

 timer control */

 timer */

 low voltage */

 century */

	/*

	 * The meaning of MO_C bit varies by the chip type.

	 * From PCF8563 datasheet: this bit is toggled when the years

	 * register overflows from 99 to 00

	 *   0 indicates the century is 20xx

	 *   1 indicates the century is 19xx

	 * From RTC8564 datasheet: this bit indicates change of

	 * century. When the year digit data overflows from 99 to 00,

	 * this bit is set. By presetting it to 0 while still in the

	 * 20th century, it will be set in year 2000, ...

	 * There seems no reliable way to know how the system use this

	 * bit.  So let's do it heuristically, assuming we are live in

	 * 1970...2069.

 0: MO_C=1 means 19xx, otherwise MO_C=1 means 20xx */

 setup read ptr */

/*

 * In the routines that deal directly with the pcf8563 hardware, we use

 * rtc_time -- month 0-11, hour 0-23, yr = calendar year-epoch.

 rtc hr 0-23 */

 rtc mn 1-12 */

 detect the polarity heuristically. see note above. */

 hours, minutes and seconds */

 month, 1 - 12 */

 year and century */

 The alarm has no seconds, round up to nearest minute */

/*

 * Handling of the clkout

 disable the clkout output */

 optional override of the clockname */

 register the clock */

 Set timer to lowest frequency to save power (ref Haoyu datasheet) */

 Clear flags and disable interrupts */

 the pcf8563 alarm only supports a minute accuracy */

 register clk in common clk framework */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2010 NXP Semiconductors

/*

 * Clock and Power control register offsets

 RTC must be disabled during count update */

 Disable alarm during update */

 Disable alarm interrupt */

	/*

	 * Write a large value to the match value so the RTC won't

	 * keep firing the match status

	/*

	 * The RTC is on a separate power domain and can keep it's state

	 * across a chip power cycle. If the RTC has never been previously

	 * setup, then set it up now for the first time.

 Clear latched interrupt states */

 Write key value to RTC so it won't reload on reset */

	/*

	 * IRQ is enabled after device registration in case alarm IRQ

	 * is pending upon suspend exit.

 Unconditionally disable the alarm */

 SPDX-License-Identifier: GPL-2.0

/*

 * An RTC test device/driver

 * Copyright (C) 2005 Tower Technologies

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * rtc-tps6586x.c: RTC driver for TI PMIC TPS6586X

 *

 * Copyright (c) 2012, NVIDIA Corporation.

 *

 * Author: Laxman Dewangan <ldewangan@nvidia.com>

 enables alarm */

 32 KHz buffer enable */

 0=1KHz or 1=32KHz updates */

 start a PMU RTC access by reading the register prior to the RTC_COUNT4 */

only 14-bits width in second*/

 Disable RTC before changing time */

 Enable RTC */

 1 kHz tick mode, enable tick counting */

 30-bit seconds */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Epson RTC module RX-6110 SA

 *

 * Copyright(C) 2015 Pengutronix, Steffen Trumtrar <kernel@pengutronix.de>

 * Copyright(C) SEIKO EPSON CORPORATION 2013. All rights reserved.

 RX-6110 Register definitions */

 Extension Register (1Dh) bit positions */

 Flag Register (1Eh) bit positions */

 Control Register (1Fh) bit positions */

/**

 * rx6110_rtc_tm_to_data - convert rtc_time to native time encoding

 *

 * @tm: holds date and time

 * @data: holds the encoding in rx6110 native form

	/*

	 * The year in the RTC is a value between 0 and 99.

	 * Assume that this represents the current century

	 * and disregard all other values.

/**

 * rx6110_data_to_rtc_tm - convert native time encoding to rtc_time

 *

 * @data: holds the encoding in rx6110 native form

 * @tm: holds date and time

 only 24-hour clock */

	/*

	 * The year in the RTC is a value between 0 and 99.

	 * Assume that this represents the current century

	 * and disregard all other values.

/**

 * rx6110_set_time - set the current time in the rx6110 registers

 *

 * @dev: the rtc device in use

 * @tm: holds date and time

 *

 * BUG: The HW assumes every year that is a multiple of 4 to be a leap

 * year. Next time this is wrong is 2100, which will not be a leap year

 *

 * Note: If STOP is not set/cleared, the clock will start when the seconds

 *       register is written

 *

 set STOP bit before changing clock/calendar */

 The time in the RTC is valid. Be sure to have VLF cleared. */

 clear STOP bit after changing clock/calendar */

/**

 * rx6110_get_time - get the current time from the rx6110 registers

 * @dev: the rtc device in use

 * @tm: holds date and time

 check for VLF Flag (set at power-on) */

 read registers to date */

/**

 * rx6110_init - initialize the rx6110 registers

 *

 * @rx6110: pointer to the rx6110 struct in use

 *

 check for VLF Flag (set at power-on) */

 check for Alarm Flag */

 check for Periodic Timer Flag */

 check for Update Timer Flag */

 clear all flags BUT VLF */

/**

 * rx6110_spi_probe - initialize rtc driver

 * @spi: pointer to spi device

 CONFIG_SPI_MASTER */

 CONFIG_I2C */

 SPDX-License-Identifier: GPL-2.0-only

/* Copyright (c) 2010-2011, Code Aurora Forum. All rights reserved.

 RTC Register offsets from RTC CTRL REG */

 RTC_CTRL register bit fields */

/**

 * struct pm8xxx_rtc_regs - describe RTC registers per PMIC versions

 * @ctrl: base address of control register

 * @write: base address of write register

 * @read: base address of read register

 * @alarm_ctrl: base address of alarm control register

 * @alarm_ctrl2: base address of alarm control2 register

 * @alarm_rw: base address of alarm read-write register

 * @alarm_en: alarm enable mask

/**

 * struct pm8xxx_rtc -  rtc driver internal structure

 * @rtc:		rtc device for this driver.

 * @regmap:		regmap used to access RTC registers

 * @allow_set_time:	indicates whether writing to the RTC is allowed

 * @rtc_alarm_irq:	rtc alarm irq number.

 * @regs:		rtc registers description.

 * @rtc_dev:		device structure.

 * @ctrl_reg_lock:	spinlock protecting access to ctrl_reg.

/*

 * Steps to write the RTC registers.

 * 1. Disable alarm if enabled.

 * 2. Disable rtc if enabled.

 * 3. Write 0x00 to LSB.

 * 4. Write Byte[1], Byte[2], Byte[3] then Byte[0].

 * 5. Enable rtc if disabled in step 2.

 * 6. Enable alarm if disabled in step 1.

 Disable RTC H/w before writing on RTC register */

 Write 0 to Byte[0] */

 Write Byte[1], Byte[2], Byte[3] */

 Write Byte[0] */

 Enable RTC H/w after writing on RTC register */

	/*

	 * Read the LSB again and check if there has been a carry over.

	 * If there is, redo the read operation.

 Clear Alarm register */

 Clear the alarm enable bit */

 Clear RTC alarm register */

 Check if the RTC is on, else turn it on */

/*

 * Hardcoded RTC bases until IORESOURCE_REG mapping is figured out

 Initialise spinlock to protect RTC control register */

 Register the RTC device */

 Request the alarm IRQ */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * A SPI driver for the Ricoh RS5C348 RTC

 *

 * Copyright (C) 2006 Atsushi Nemoto <anemo@mba.ocn.ne.jp>

 *

 * The board specific init code should provide characteristics of this

 * device:

 *     Mode 1 (High-Active, Shift-Then-Sample), High Avtive CS

 REG_HOURS */

 REG_MONTH */

 REG_CTL1 */

 REG_CTL2 */

 REG_CTL2 */

 single write */

 single read */

 burst write */

 burst read */

 Transfer 5 bytes before writing SEC.  This gives 31us for carry. */

 cmd, ctl2 */

 dummy */

 cmd, ctl2 */

 dummy */

 cmd, sec, ... */

 hour 0 is AM12, noon is PM12 */

 write in one transfer to avoid data inconsistency */

 Tcsr 62us */

 Transfer 5 byte befores reading SEC.  This gives 31us for carry. */

 cmd, ctl2 */

 dummy */

 cmd, ctl2 */

 dummy */

 cmd, sec, ... */

 read in one transfer to avoid data inconsistency */

 Tcsr 62us */

 year is 1900 + tm->tm_year */

 Check D7 of SECOND register */

 SPDX-License-Identifier: GPL-2.0

/*

 * RTC subsystem, interface functions

 *

 * Copyright (C) 2005 Tower Technologies

 * Author: Alessandro Zummo <a.zummo@towertech.it>

 *

 * based on arch/arm/common/rtctime.c

	/*

	 * Since the reading time values from RTC device are always in the RTC

	 * original valid range, but we need to skip the overlapped region

	 * between expanded range and original range, which is no need to add

	 * the offset.

	/*

	 * If the setting time values are in the valid range of RTC hardware

	 * device, then no need to subtract the offset when setting time to RTC

	 * device. Otherwise we need to subtract the offset to make the time

	 * values are valid for RTC hardware device.

 A timer might have just expired */

	/* The lower level RTC driver may return -1 in some fields,

	 * creating invalid alarm->time values, for reasons like:

	 *

	 *   - The hardware may not be capable of filling them in;

	 *     many alarms match only on time-of-day fields, not

	 *     day/month/year calendar data.

	 *

	 *   - Some hardware uses illegal values as "wildcard" match

	 *     values, which non-Linux firmware (like a BIOS) may try

	 *     to set up as e.g. "alarm 15 minutes after each hour".

	 *     Linux uses only oneshot alarms.

	 *

	 * When we see that here, we deal with it by using values from

	 * a current RTC timestamp for any missing (-1) values.  The

	 * RTC driver prevents "periodic alarm" modes.

	 *

	 * But this can be racey, because some fields of the RTC timestamp

	 * may have wrapped in the interval since we read the RTC alarm,

	 * which would lead to us inserting inconsistent values in place

	 * of the -1 fields.

	 *

	 * Reading the alarm and timestamp in the reverse sequence

	 * would have the same race condition, and not solve the issue.

	 *

	 * So, we must first read the RTC timestamp,

	 * then read the RTC alarm value,

	 * and then read a second RTC timestamp.

	 *

	 * If any fields of the second timestamp have changed

	 * when compared with the first timestamp, then we know

	 * our timestamp may be inconsistent with that used by

	 * the low-level rtc_read_alarm_internal() function.

	 *

	 * So, when the two timestamps disagree, we just loop and do

	 * the process again to get a fully consistent set of values.

	 *

	 * This could all instead be done in the lower level driver,

	 * but since more than one lower level RTC implementation needs it,

	 * then it's probably best best to do it here instead of there..

 Get the "before" timestamp */

 get the RTC alarm values, which may be incomplete */

 full-function RTCs won't have such missing fields */

 get the "after" timestamp, to detect wrapped fields */

 note that tm_sec is a "don't care" value here: */

	/* Fill in the missing alarm fields using the timestamp; we

	 * know there's at least one since alarm->time is invalid.

 For simplicity, only support date rollover for now */

	/* Can't proceed if alarm is still invalid after replacing

	 * missing fields.

 with luck, no rollover is needed */

	/* 24 hour rollover ... if it's now 10am Monday, an alarm that

	 * that will trigger at 5am will do so at 5am Tuesday, which

	 * could also be in the next month or year.  This is a common

	 * case, especially for PCs.

	/* Month rollover ... if it's the 31th, an alarm on the 3rd will

	 * be next month.  An alarm matching on the 30th, 29th, or 28th

	 * may end up in the month after that!  Many newer PCs support

	 * this type of alarm.

 Year rollover ... easy except for leap years! */

 Make sure we're not setting alarms in the past */

	/*

	 * XXX - We just checked to make sure the alarm time is not

	 * in the past, but there is still a race window where if

	 * the is alarm set for the next second and the second ticks

	 * over right here, before we set the alarm.

	/*

	 * Round down so we never miss a deadline, checking for past deadline is

	 * done in __rtc_set_alarm

 Called once per device from rtc_device_register */

 Alarm has to be enabled & in the future for us to enqueue it */

 nothing */;

 make sure we're changing state */

/**

 * rtc_handle_legacy_irq - AIE, UIE and PIE event hook

 * @rtc: pointer to the rtc device

 * @num: number of occurence of the event

 * @mode: type of the event, RTC_AF, RTC_UF of RTC_PF

 *

 * This function is called when an AIE, UIE or PIE mode interrupt

 * has occurred (or been emulated).

 *

 mark one irq of the appropriate mode */

/**

 * rtc_aie_update_irq - AIE mode rtctimer hook

 * @rtc: pointer to the rtc_device

 *

 * This functions is called when the aie_timer expires.

/**

 * rtc_uie_update_irq - UIE mode rtctimer hook

 * @rtc: pointer to the rtc_device

 *

 * This functions is called when the uie_timer expires.

/**

 * rtc_pie_update_irq - PIE mode hrtimer hook

 * @timer: pointer to the pie mode hrtimer

 *

 * This function is used to emulate PIE mode interrupts

 * using an hrtimer. This function is called when the periodic

 * hrtimer expires.

/**

 * rtc_update_irq - Triggered when a RTC interrupt occurs.

 * @rtc: the rtc device

 * @num: how many irqs are being reported (usually one)

 * @events: mask of RTC_IRQF with one or more of RTC_PF, RTC_AF, RTC_UF

 * Context: any

	/*

	 * We always cancel the timer here first, because otherwise

	 * we could run into BUG_ON(timer->state != HRTIMER_STATE_CALLBACK);

	 * when we manage to start the timer before the callback

	 * returns HRTIMER_RESTART.

	 *

	 * We cannot use hrtimer_cancel() here as a running callback

	 * could be blocked on rtc->irq_task_lock and hrtimer_cancel()

	 * would spin forever.

/**

 * rtc_irq_set_state - enable/disable 2^N Hz periodic IRQs

 * @rtc: the rtc device

 * @enabled: true to enable periodic IRQs

 * Context: any

 *

 * Note that rtc_irq_set_freq() should previously have been used to

 * specify the desired frequency of periodic IRQ.

/**

 * rtc_irq_set_freq - set 2^N Hz periodic IRQ frequency for IRQ

 * @rtc: the rtc device

 * @freq: positive frequency

 * Context: any

 *

 * Note that rtc_irq_set_state() is used to enable or disable the

 * periodic IRQs.

/**

 * rtc_timer_enqueue - Adds a rtc_timer to the rtc_device timerqueue

 * @rtc: rtc device

 * @timer: timer being added.

 *

 * Enqueues a timer onto the rtc devices timerqueue and sets

 * the next alarm event appropriately.

 *

 * Sets the enabled bit on the added timer.

 *

 * Must hold ops_lock for proper serialization of timerqueue

 Skip over expired timers */

/**

 * rtc_timer_remove - Removes a rtc_timer from the rtc_device timerqueue

 * @rtc: rtc device

 * @timer: timer being removed.

 *

 * Removes a timer onto the rtc devices timerqueue and sets

 * the next alarm event appropriately.

 *

 * Clears the enabled bit on the removed timer.

 *

 * Must hold ops_lock for proper serialization of timerqueue

/**

 * rtc_timer_do_work - Expires rtc timers

 * @work: work item

 *

 * Expires rtc timers. Reprograms next alarm event if needed.

 * Called via worktask.

 *

 * Serializes access to timerqueue via ops_lock mutex

 expire timer */

 Re-add/fwd periodic timers */

 Set next alarm */

/* rtc_timer_init - Initializes an rtc_timer

 * @timer: timer to be intiialized

 * @f: function pointer to be called when timer fires

 * @rtc: pointer to the rtc_device

 *

 * Kernel interface to initializing an rtc_timer.

/* rtc_timer_start - Sets an rtc_timer to fire in the future

 * @ rtc: rtc device to be used

 * @ timer: timer being set

 * @ expires: time at which to expire the timer

 * @ period: period that the timer will recur

 *

 * Kernel interface to set an rtc_timer

/* rtc_timer_cancel - Stops an rtc_timer

 * @ rtc: rtc device to be used

 * @ timer: timer being set

 *

 * Kernel interface to cancel an rtc_timer

/**

 * rtc_read_offset - Read the amount of rtc offset in parts per billion

 * @rtc: rtc device to be used

 * @offset: the offset in parts per billion

 *

 * see below for details.

 *

 * Kernel interface to read rtc clock offset

 * Returns 0 on success, or a negative number on error.

 * If read_offset() is not implemented for the rtc, return -EINVAL

/**

 * rtc_set_offset - Adjusts the duration of the average second

 * @rtc: rtc device to be used

 * @offset: the offset in parts per billion

 *

 * Some rtc's allow an adjustment to the average duration of a second

 * to compensate for differences in the actual clock rate due to temperature,

 * the crystal, capacitor, etc.

 *

 * The adjustment applied is as follows:

 *   t = t0 * (1 + offset * 1e-9)

 * where t0 is the measured length of 1 RTC second with offset = 0

 *

 * Kernel interface to adjust an rtc clock offset.

 * Return 0 on success, or a negative number on error.

 * If the rtc offset is not setable (or not implemented), return -EINVAL

 SPDX-License-Identifier: GPL-2.0-only

/*

 * HID Sensor Time Driver

 * Copyright (c) 2012, Alexander Holler.

 Channel names for verbose error messages */

 Callback handler to send event after all samples are received and captured */

 0xff... or -1 to denote an error */

		/*

		 * The draft for HID-sensors (HUTRR39) currently doesn't define

		 * the range for the year attribute. Therefor we support

		 * 8 bit (0-99) and 16 or 32 bits (full) as size for the year.

 assume we are in 1970...2069 */

 sensors are sending the month as 1-12, we need 0-11 */

 small helper, haven't found any other way */

 should never happen */

 Check the (needed) attributes for sanity */

 allow attribute seconds with unit seconds */

 get a report with all values through requesting one value */

 wait for all values (event) */

 no error */

 timeouted */

 killed (-ERESTARTSYS) */

	/*

	 * Enable HID input processing early in order to be able to read the

	 * clock already in devm_rtc_device_register().

 Format: HID-SENSOR-usage_id_in_hex_lowercase */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for Epson's RTC module RX-8025 SA/NB

 *

 * Copyright (C) 2009 Wolfgang Grandegger <wg@grandegger.com>

 *

 * Copyright (C) 2005 by Digi International Inc.

 * All rights reserved.

 *

 * Modified by fengjh at rising.com.cn

 * <lm-sensors@lm-sensors.org>

 * 2006.11

 *

 * Code cleanup by Sergei Poselenov, <sposelenov@emcraft.com>

 * Converted to new style by Wolfgang Grandegger <wg@grandegger.com>

 * Alarm and periodic interrupt added by Dmitry Rakhchev <rda@emcraft.com>

 Register definitions */

 0x0d is reserved */

 1 Hz periodic level irq */

 Clock precision adjustment */

 in ppb */

	/* XSTP bit has different polarity on RX-8025 vs RX-8035.

	 * RX-8025: 0 == oscillator stopped

	 * RX-8035: 1 == oscillator stopped

 periodic */

 alarm */

	/*

	 * Here the read-only bits are written as "0".  I'm not sure if that

	 * is sound.

 Keep test bit zero ! */

 Alarm support */

 Hardware alarms precision is 1 minute! */

/*

 * According to the RX8025 SA/NB application manual the frequency and

 * temperature characteristics can be approximated using the following

 * equation:

 *

 *   df = a * (ut - t)**2

 *

 *   df: Frequency deviation in any temperature

 *   a : Coefficient = (-35 +-5) * 10**-9

 *   ut: Ultimate temperature in degree = +25 +-5 degree

 *   t : Any temperature in degree

 SPDX-License-Identifier: GPL-2.0+

/*

 * Realtek RTD129x RTC

 *

 * Copyright (c) 2017 Andreas Färber

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DaVinci Power Management and Real Time Clock Driver for TI platforms

 *

 * Copyright (C) 2009 Texas Instruments, Inc

 *

 * Author: Miguel Aguilar <miguel.aguilar@ridgerun.com>

/*

 * The DaVinci RTC is a simple RTC with the following

 * Sec: 0 - 59 : BCD count

 * Min: 0 - 59 : BCD count

 * Hour: 0 - 23 : BCD count

 * Day: 0 - 0x7FFF(32767) : Binary count ( Over 89 years )

 PRTC interface registers */

 PRTCIF_CTLR bit fields */

 PRTCIF_INTEN bit fields */

 PRTCIF_INTFLG bit fields */

 PRTC subsystem registers */

 PRTCSS_RTC_INTC_EXTENA1 */

 PRTCSS_RTC_CTRL bit fields */

 PRTCSS_RTC_CCTRL bit fields */

 Enable interrupts */

/* rtc-starfire.c: Starfire platform RTC driver.

 *

 * Author: David S. Miller

 * License: GPL

 *

 * Copyright (C) 2008 David S. Miller <davem@davemloft.net>

 SPDX-License-Identifier: GPL-2.0-only

/* rtc-bq4802.c: TI BQ4802 RTC driver.

 *

 * Copyright (C) 2008 David S. Miller <davem@davemloft.net>

 tm_mon starts at zero */

 work with hotplug and coldplug */

 SPDX-License-Identifier: GPL-2.0-only

 Ensure that the RTC is accessible. Bit 6 must be 0! */

	/*

	 * Check whether there is an update in progress during which the

	 * readout is unspecified. The maximum update time is ~2ms. Poll

	 * every msec for completion.

	 *

	 * Store the second value before checking UIP so a long lasting NMI

	 * which happens to hit after the UIP check cannot make an update

	 * cycle invisible.

 Revalidate the above readout */

	/*

	 * Only the values that we read from the RTC are set. We leave

	 * tm_wday, tm_yday and tm_isdst untouched. Even though the

	 * RTC has RTC_DAY_OF_WEEK, we ignore it, as it is only updated

	 * by the RTC when initially set to a non-zero value.

	/*

	 * Check for the UIP bit again. If it is set now then

	 * the above values may contain garbage.

	/*

	 * A NMI might have interrupted the above sequence so check whether

	 * the seconds value has changed which indicates that the NMI took

	 * longer than the UIP bit was set. Unlikely, but possible and

	 * there is also virt...

	/*

	 * Account for differences between how the RTC uses the values

	 * and how they are defined in a struct rtc_time;

 Set the current date and time in the real time clock. */

 tm_mon starts at zero */

 They are unsigned */

	/*

	 * We want to keep the year set to 73 until March

	 * for non-leap years, so that Feb, 29th is handled

	 * correctly.

	/* These limits and adjustments are independent of

	 * whether the chip is in binary mode or not.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * EPSON TOYOCOM RTC-7301SF/DG Driver

 *

 * Copyright (c) 2016 Akinobu Mita <akinobu.mita@gmail.com>

 *

 * Based on rtc-rp5c01.c

 *

 * Datasheet: http://www5.epsondevice.com/en/products/parallel/rtc7301sf.html

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 and Band 1 */

 Bank 0 */

 Bank 0 */

 Bank 0 */

 Bank 0 */

 Bank 0 */

 Bank 0 */

 Bank 1 */

 Bank 2 */

 All banks */

 Don't care for alarm register */

 SPDX-License-Identifier: GPL-2.0-or-later

 /* Copyright (C) 2004-2006, Advanced Micro Devices, Inc.

 Static structures */

 Write a 128 bit field (either a writable key or IV) */

 Read a 128 bit field (either a writable key or IV) */

 Start the operation */

 Clear the event */

	/* If the source and destination is the same, then

	 * we need to turn on the coherent flags, otherwise

	 * we don't need to worry

 Start the critical section */

 CRYPTO-API Functions */

 not supported at all */

	/*

	 * The requested key size is not supported by HW, do a fallback

 not supported at all */

	/*

	 * The requested key size is not supported by HW, do a fallback

 Clear any pending activity */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 *

 * Support for OMAP AES HW acceleration.

 *

 * Copyright (c) 2010 Nokia Corporation

 * Author: Dmitry Kasatkin <dmitry.kasatkin@nokia.com>

 * Copyright (c) 2011 Texas Instruments Incorporated

 keep registered devices data here */

 RESET the key as previous HASH keys should not get affected*/

 dma_lch_out - completed */

		/* Enable DATAIN interrupt and let it take

 IN */

 No callback necessary */

 OUT */

 start DMA */

 assign new request to device */

 Update IV output */

 ********************** ALG API ************************************ */

 ********************** ALGS ************************************ */

 Clear IRQ status */

 Enable DATA_OUT interrupt */

 Clear IRQ status */

 All bytes read! */

 Enable DATA_IN interrupt for next block */

 Get the base address */

 Only OMAP2/3 can be non-DT */

 HW accelerator only works with buffers > 9 */

	/*

	 * Changing the queue size in fly is safe, if size becomes smaller

	 * than current size, it will just not accept new entries until

	 * it has shrank enough.

 Initialize crypto engine */

 SPDX-License-Identifier: GPL-2.0-only

/* n2_core.c: Niagara2 Stream Processing Unit (SPU) crypto support.

 *

 * Copyright (C) 2010, 2011 David S. Miller <davem@davemloft.net>

/* An async job request records the final tail value it used in

 * n2_request_common->offset, test to see if that offset is in

 * the range old_head, new_head, inclusive.

/* When the HEAD marker is unequal to the actual HEAD, we get

 * a virtual device INO interrupt.  We should process the

 * completed CWQ entries and adjust the HEAD marker to clear

 * the IRQ.

 XXX ... XXX */

 HW limit for all HMAC requests */

	/* The total effective length of the operation may not

	 * exceed 2^16.

	/* XXX can do better, improve this later by doing a by-hand scatterlist

	 * XXX walk, etc.

/* The SPU allows some level of flexibility for partial cipher blocks

 * being specified in a descriptor.

 *

 * It merely requires that every descriptor's length field is at least

 * as large as the cipher block size.  This means that a cipher block

 * can span at most 2 descriptors.  However, this does not allow a

 * partial block to span into the final descriptor as that would

 * violate the rule (since every descriptor's length must be at lest

 * the block size).  So, for example, assuming an 8 byte block size:

 *

 *	0xe --> 0xa --> 0x8

 *

 * is a valid length sequence, whereas:

 *

 *	0xe --> 0xb --> 0x7

 *

 * is not a valid sequence.

 DES: ECB CBC and CFB are supported */

 3DES: ECB CBC and CFB are supported */

 AES: ECB CBC and CTR are supported */

/* To map CWQ queues to interrupt sources, the hypervisor API provides

 * a devino.  This isn't very useful to us because all of the

 * interrupts listed in the device_node have been translated to

 * Linux virtual IRQ cookie numbers.

 *

 * So we have to back-translate, going through the 'intr' and 'ino'

 * property tables of the n2cp MDESC node, matching it with the OF

 * 'interrupts' property entries, in order to to figure out which

 * devino goes to which already-translated IRQ.

/* Walk the backward arcs of a CWQ 'exec-unit' node,

 * gathering cpu membership information.

 Process an 'exec-unit' MDESC node of type 'cwq'.  */

 SPDX-License-Identifier: GPL-2.0

/*

 * Cryptographic API.

 *

 * Support for ATMEL AES HW acceleration.

 *

 * Copyright (c) 2012 Eukréa Electromatique - ATMEL

 * Author: Nicolas Royer <nicolas@eukrea.com>

 *

 * Some ideas are from omap-aes.c driver.

 AES flags */

 Reserve bits [18:16] [14:12] [1:0] for mode (same as for AES_MR) */

 auth_req MUST be place last. */

 VERBOSE_DEBUG */

 Shared functions */

 VERBOSE_DEBUG */

 VERBOSE_DEBUG */

 One AES IP per SoC. */

 Clear all but persistent flags and set request flags. */

	/*

	 * The CTR transfer works in fragments of data of maximum 1 MByte

	 * because of the 16 bit CTR counter embedded in the IP. When reaching

	 * here, ctx->blocks contains the number of blocks of the last fragment

	 * processed, there is no need to explicit cast it to u16.

 MR register must be set before IV registers */

 CPU transfer */

 DMA transfer */

 Set output DMA transfer first */

 Then set input DMA transfer */

 WARNING: ctx->start() MAY change dd->is_async. */

 AES async block ciphers */

 Check for transfer completion. */

 Compute data length. */

 Check 16bit counter overflow. */

 Jump to offset. */

 Configure hardware. */

		/*

		 * Increment the counter manually to cope with the hardware

		 * counter overflow.

	/*

	 * ECB, CBC, CFB, OFB or CTR mode require the plaintext and ciphertext

	 * to have a positve integer length.

 gcm aead functions */

 Set the data length. */

 If needed, overwrite the GCM Intermediate Hash Word Registers */

 Write data into the Input Data Registers. */

 Read the computed hash from GHASHRx. */

 Compute text length. */

	/*

	 * According to tcrypt test suite, the GCM Automatic Tag Generation

	 * fails when both the message and its associated data are empty.

 Write incr32(J0) into IV. */

 Set aad and text lengths. */

 Check whether AAD are present. */

 Copy assoc data and add padding. */

 Write assoc data into the Input Data register. */

 Write AAD first. */

 GMAC only. */

 Prepare src and dst scatter lists to transfer cipher/plain texts */

 Update the Mode Register for DMA transfers. */

 Read the GCM Intermediate Hash Word Registers. */

	/*

	 * Change mode to CTR to complete the tag generation.

	 * Use J0 as Initialization Vector.

 Read the computed tag. */

 xts functions */

 Compute the tweak value from req->iv with ecb(aes). */

 Read the computed ciphered tweak value. */

	/*

	 * Hardware quirk:

	 * the order of the ciphered tweak bytes need to be reversed before

	 * writing them into the ODATARx registers.

 Process the data. */

 authenc aead functions */

 If here, we've got the ownership of the SHA device. */

 Configure the SHA device. */

 Prepare src and dst scatter-lists to transfer cipher/plain texts. */

 Configure the AES device. */

	/*

	 * Here we always set the 2nd parameter of atmel_aes_write_ctrl() to

	 * 'true' even if the data transfer is actually performed by the CPU (so

	 * not by the DMA) because we must force the AES_MR_SMOD bitfield to the

	 * value AES_MR_SMOD_IDATAR0. Indeed, both AES_MR_SMOD and SHA_MR_SMOD

	 * must be set to *_MR_SMOD_IDATAR0.

 Transfer data. */

 atmel_sha_authenc_final() releases the SHA device. */

 Save auth key. */

 Save enc key. */

 Compute text length. */

	/*

	 * Currently, empty messages are not supported yet:

	 * the SHA auto-padding can be used only on non-empty messages.

	 * Hence a special case needs to be implemented for empty message.

 CONFIG_CRYPTO_DEV_ATMEL_AUTHENC */

 Probe functions */

 Try to grab 2 DMA channels */

 i = ARRAY_SIZE(aes_authenc_algs); */

 keep only major version number */

 sentinel */ }

 Get the base address */

 Get the IRQ */

 Initializing the clock */

 SPDX-License-Identifier: GPL-2.0

/*

 * exynos-rng.c - Random Number Generator driver for the Exynos

 *

 * Copyright (c) 2017 Krzysztof Kozlowski <krzk@kernel.org>

 *

 * Loosely based on old driver from drivers/char/hw_random/exynos-rng.c:

 * Copyright (C) 2012 Samsung Electronics

 * Jonghwa Lee <jonghwa3.lee@samsung.com>

 EXYNOS_RNG_CONTROL bit fields */

 EXYNOS_RNG_STATUS bit fields */

 Five seed and output registers, each 4 bytes */

/*

 * Driver re-seeds itself with generated random numbers to hinder

 * backtracking of the original seed.

 *

 * Time for next re-seed in ms.

/*

 * In polling mode, do not wait infinitely for the engine to finish the work.

 Context for crypto */

 Device associated memory */

 Generated numbers stored for seeding during resume */

 Time of last seeding in jiffies */

 Bytes generated since last seeding */

 Round seed length because loop iterates over full register size */

/*

 * Start the engine and poll for finish.  Then read from output registers

 * filling the 'dst' buffer up to 'dlen' bytes or up to size of generated

 * random data (EXYNOS_RNG_SEED_SIZE).

 *

 * On success: return 0 and store number of read bytes under 'read' address.

 * On error: return -ERRNO.

 Clear status bit */

 Re-seed itself from time to time */

 Let others do some of their job. */

 If we were never seeded then after resume it will be the same */

 Get new random numbers and store them for seeding on resume. */

 Never seeded so nothing to do */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 *

 * Support for VIA PadLock hardware crypto engine.

 *

 * Copyright (c) 2006  Michal Ludvig <michal@logix.cz>

 We can't store directly to *out as it may be unaligned. */

	/* BTW Don't reduce the buffer size below 128 Bytes!

 rep xsha1 */

 We can't store directly to *out as it may be unaligned. */

	/* BTW Don't reduce the buffer size below 128 Bytes!

 rep xsha256 */

 Allocate a fallback and abort if it failed. */

/* Add two shash_alg instance for hardware-implemented *

The PHE require the out buffer must 128 bytes and 16-bytes aligned*/

 Append the bytes in state's buffer to a block to handle */

 Process the left bytes from the input data */

 Pad out to 56 mod 64 */

 Append length field bytes */

 Swap to output */

The PHE require the out buffer must 128 bytes and 16-bytes aligned*/

 Append the bytes in state's buffer to a block to handle */

 Process the left bytes from input data*/

 Pad out to 56 mod 64 */

 Append length field bytes */

 Swap to output */

	/* Register the newly added algorithm module if on *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP Crypto driver common support routines.

 *

 * Copyright (c) 2017 Texas Instruments Incorporated

 *   Tero Kristo <t-kristo@ti.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 *

 * Support for SAHARA cryptographic accelerator.

 *

 * Copyright (c) 2014 Steffen Trumtrar <s.trumtrar@pengutronix.de>

 * Copyright (c) 2013 Vista Silicon S.L.

 * Author: Javier Martin <javier.martin@vista-silicon.com>

 *

 * Based on omap-aes.c and tegra-aes.c

 SAHARA can only process one request at a time */

 AES-specific context */

 keep at the end

/*

 * struct sahara_sha_reqctx - private data per request

 * @buf: holds data for requests smaller than block_size

 * @rembuf: used to prepare one block_size-aligned request

 * @context: hw-specific context for request. Digest is extracted from this

 * @mode: specifies what type of hw-descriptor needs to be built

 * @digest_size: length of digest for this request

 * @context_size: length of hw-context for this request.

 *                Always digest_size + 4

 * @buf_cnt: number of bytes saved in buf

 * @sg_in_idx: number of hw links

 * @in_sg: scatterlist for input data

 * @in_sg_chain: scatterlists for chained input data

 * @total: total number of bytes for transfer

 * @last: is this the last block

 * @first: is this the first block

 * @active: inside a transfer

 Copy new key if necessary */

 Create input links */

 Create output links */

 Fill remaining fields of hw_desc[1] */

 Request is ready to be dispatched by the device */

 assign new request to device */

 assign new context to device */

 SAHARA only supports 128bit keys */

	/*

	 * The requested key size is not supported by HW, do a fallback.

 Create initial descriptor: #8*/

 Create hash descriptor: #10. Must follow #6. */

 if len1 is 0, p1 must be 0, too */

 Create input links */

 Save the context for the next operation */

/*

 * Load descriptor aka #6

 *

 * To load a previously saved context back to the MDHA unit

 *

 * p1: Saved Context

 * p2: NULL

 *

 append bytes from previous operation */

 only the last transfer can be padded in hardware */

 to few data, save for next operation */

 add data from previous operation first */

 data must always be a multiple of block_size */

 Save remaining bytes for later use */

 nbytes should now be multiple of blocksize */

 have data from previous operation and current */

 only data from previous operation */

 buf was copied into rembuf above */

 no data from previous operation */

 on next call, we only have the remaining data in the buffer */

 sentinel */ }

 Get the base address */

 Get the IRQ */

 clocks */

 Allocate HW descriptors */

 Allocate space for iv and key */

 Allocate space for context: largest digest + message length field */

 Allocate space for HW links */

 SPDX-License-Identifier: GPL-2.0

/*

 * Microchip / Atmel SHA204A (I2C) driver.

 *

 * Copyright (c) 2019 Linaro, Ltd. <ard.biesheuvel@linaro.org>

 keep maximum 1 asynchronous read in flight at any time */

 sentinel */ }

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0



 Cryptographic API.



 Support for Samsung S5PV210 and Exynos HW acceleration.



 Copyright (C) 2011 NetUP Inc. All rights reserved.

 Copyright (c) 2017 Samsung Electronics Co., Ltd. All rights reserved.



 Hash part based on omap-sham.c driver.

 Feed control registers */

 AES registers */

 HW engine modes */

 HASH registers */

/*

 * HASH bit numbers, used by device, setting in dev->hash_flags with

 * functions set_bit(), clear_bit() or tested with test_bit() or BIT(),

 * to keep HASH state BUSY or FREE, or to signal state from irq_handler

 * to hash_tasklet. SGS keep track of allocated memory for scatterlist

 HASH HW constants */

/**

 * struct samsung_aes_variant - platform specific SSS driver data

 * @aes_offset: AES register offset from SSS module's base.

 * @hash_offset: HASH register offset from SSS module's base.

 * @clk_names: names of clocks needed to run SSS IP

 *

 * Specifies platform specific configuration of SSS module.

 * Note: A structure for driver specific platform data is used for future

 * expansion of its usage.

/**

 * struct s5p_aes_dev - Crypto device state container

 * @dev:	Associated device

 * @clk:	Clock for accessing hardware

 * @pclk:	APB bus clock necessary to access the hardware

 * @ioaddr:	Mapped IO memory region

 * @aes_ioaddr:	Per-varian offset for AES block IO memory

 * @irq_fc:	Feed control interrupt line

 * @req:	Crypto request currently handled by the device

 * @ctx:	Configuration for currently handled crypto request

 * @sg_src:	Scatter list with source data for currently handled block

 *		in device.  This is DMA-mapped into device.

 * @sg_dst:	Scatter list with destination data for currently handled block

 *		in device. This is DMA-mapped into device.

 * @sg_src_cpy:	In case of unaligned access, copied scatter list

 *		with source data.

 * @sg_dst_cpy:	In case of unaligned access, copied scatter list

 *		with destination data.

 * @tasklet:	New request scheduling jib

 * @queue:	Crypto queue

 * @busy:	Indicates whether the device is currently handling some request

 *		thus it uses some of the fields from this state, like:

 *		req, ctx, sg_src/dst (and copies).  This essentially

 *		protects against concurrent access to these fields.

 * @lock:	Lock for protecting both access to device hardware registers

 *		and fields related to current request (including the busy field).

 * @res:	Resources for hash.

 * @io_hash_base: Per-variant offset for HASH block IO memory.

 * @hash_lock:	Lock for protecting hash_req, hash_queue and hash_flags

 *		variable.

 * @hash_flags:	Flags for current HASH op.

 * @hash_queue:	Async hash queue.

 * @hash_tasklet: New HASH request scheduling job.

 * @xmit_buf:	Buffer for current HASH request transfer into SSS block.

 * @hash_req:	Current request sending to SSS HASH block.

 * @hash_sg_iter: Scatterlist transferred through DMA into SSS HASH block.

 * @hash_sg_cnt: Counter for hash_sg_iter.

 *

 * @use_hash:	true if HASH algs enabled

 protect hash_ vars */

/**

 * struct s5p_hash_reqctx - HASH request context

 * @dd:		Associated device

 * @op_update:	Current request operation (OP_UPDATE or OP_FINAL)

 * @digcnt:	Number of bytes processed by HW (without buffer[] ones)

 * @digest:	Digest message or IV for partial result

 * @nregs:	Number of HW registers for digest or IV read/write

 * @engine:	Bits for selecting type of HASH in SSS block

 * @sg:		sg for DMA transfer

 * @sg_len:	Length of sg for DMA transfer

 * @sgl:	sg for joining buffer and req->src scatterlist

 * @skip:	Skip offset in req->src for current op

 * @total:	Total number of bytes for current request

 * @finup:	Keep state for finup or final.

 * @error:	Keep track of error.

 * @bufcnt:	Number of bytes holded in buffer[]

 * @buffer:	For byte(s) from end of req->src in UPDATE op

 digest_size / sizeof(reg) */

/**

 * struct s5p_hash_ctx - HASH transformation context

 * @dd:		Associated device

 * @flags:	Bits for algorithm HASH.

 * @fallback:	Software transformation for zero message or size < BUFLEN.

 Calls the completion. Cannot be called with dev->lock hold. */

/*

 * Returns -ERRNO on error (mapping of new data failed).

 * On success returns:

 *  - 0 if there is no more data,

 *  - 1 if new transmitting (output) data is ready and its address+length

 *     have to be written to device (by calling s5p_set_dma_outdata()).

/*

 * Returns -ERRNO on error (mapping of new data failed).

 * On success returns:

 *  - 0 if there is no more data,

 *  - 1 if new receiving (input) data is ready and its address+length

 *     have to be written to device (by calling s5p_set_dma_indata()).

, bool *set_dma*/)

/**

 * s5p_set_dma_hashdata() - start DMA with sg

 * @dev:	device

 * @sg:		scatterlist ready to DMA transmit

 DMA starts */

/**

 * s5p_hash_rx() - get next hash_sg_iter

 * @dev:	device

 *

 * Return:

 * 2	if there is no more data and it is UPDATE op

 * 1	if new receiving (input) data is ready and can be written to device

 * 0	if there is no more data and it is FINAL op

	/*

	 * Handle rx or tx interrupt. If there is still data (scatterlist did not

	 * reach end), then map next scatterlist entry.

	 * In case of such mapping error, s5p_aes_complete() should be called.

	 *

	 * If there is no more data in tx scatter list, call s5p_aes_complete()

	 * and schedule new tasklet.

	 *

	 * Handle hx interrupt. If there is still data map next entry.

 clear DMA bits */

 clear HASH irq bits */

 cannot have both HPART and HDONE */

 when DONE or PART, do not handle HASH DMA */

 Device is still busy */

		/*

		 * Writing length of DMA block (either receiving or

		 * transmitting) will start the operation immediately, so this

		 * should be done at the end (even after clearing pending

		 * interrupts to not miss the interrupt).

	/*

	 * Note about else if:

	 *   when hash_sg_iter reaches end and its UPDATE op,

	 *   issue SSS_HASH_PAUSE and wait for HPART irq

/**

 * s5p_hash_read_msg() - read message or IV from HW

 * @req:	AHASH request

/**

 * s5p_hash_write_ctx_iv() - write IV for next partial/finup op.

 * @dd:		device

 * @ctx:	request context

/**

 * s5p_hash_write_iv() - write IV for next partial/finup op.

 * @req:	AHASH request

/**

 * s5p_hash_copy_result() - copy digest into req->result

 * @req:	AHASH request

/**

 * s5p_hash_dma_flush() - flush HASH DMA

 * @dev:	secss device

/**

 * s5p_hash_dma_enable() - enable DMA mode for HASH

 * @dev:	secss device

 *

 * enable DMA mode for HASH

/**

 * s5p_hash_irq_disable() - disable irq HASH signals

 * @dev:	secss device

 * @flags:	bitfield with irq's to be disabled

/**

 * s5p_hash_irq_enable() - enable irq signals

 * @dev:	secss device

 * @flags:	bitfield with irq's to be enabled

/**

 * s5p_hash_set_flow() - set flow inside SecSS AES/DES with/without HASH

 * @dev:	secss device

 * @hashflow:	HASH stream flow with/without crypto AES/DES

/**

 * s5p_ahash_dma_init() - enable DMA and set HASH flow inside SecSS

 * @dev:	secss device

 * @hashflow:	HASH stream flow with/without AES/DES

 *

 * flush HASH DMA and enable DMA, set HASH stream flow inside SecSS HW,

 * enable HASH irq's HRDMA, HDONE, HPART

/**

 * s5p_hash_write_ctrl() - prepare HASH block in SecSS for processing

 * @dd:		secss device

 * @length:	length for request

 * @final:	true if final op

 *

 * Prepare SSS HASH block for processing bytes in DMA mode. If it is called

 * after previous updates, fill up IV words. For final, calculate and set

 * lengths for HASH so SecSS can finalize hash. For partial, set SSS HASH

 * length as 2^63 so it will be never reached and set to zero prelow and

 * prehigh.

 *

 * This function does not start DMA transfer.

 number of bytes for last part */

 total number of bits prev hashed */

/**

 * s5p_hash_xmit_dma() - start DMA hash processing

 * @dd:		secss device

 * @length:	length for request

 * @final:	true if final op

 *

 * Update digcnt here, as it is needed for finup/final op.

 catch last interrupt */

 DMA starts */

/**

 * s5p_hash_copy_sgs() - copy request's bytes into new buffer

 * @ctx:	request context

 * @sg:		source scatterlist request

 * @new_len:	number of bytes to process from sg

 *

 * Allocate new buffer, copy data for HASH into it. If there was xmit_buf

 * filled, copy it first, then copy data from sg into it. Prepare one sgl[0]

 * with allocated buffer.

 *

 * Set bit in dd->hash_flag so we can free it after irq ends processing.

/**

 * s5p_hash_copy_sg_lists() - copy sg list and make fixes in copy

 * @ctx:	request context

 * @sg:		source scatterlist request

 * @new_len:	number of bytes to process from sg

 *

 * Allocate new scatterlist table, copy data for HASH into it. If there was

 * xmit_buf filled, prepare it first, then copy page, length and offset from

 * source sg into it, adjusting begin and/or end for skip offset and

 * hash_later value.

 *

 * Resulting sg table will be assigned to ctx->sg. Set flag so we can free

 * it after irq ends processing.

/**

 * s5p_hash_prepare_sgs() - prepare sg for processing

 * @ctx:	request context

 * @sg:		source scatterlist request

 * @new_len:	number of bytes to process from sg

 * @final:	final flag

 *

 * Check two conditions: (1) if buffers in sg have len aligned data, and (2)

 * sg table have good aligned elements (list_ok). If one of this checks fails,

 * then either (1) allocates new buffer for data with s5p_hash_copy_sgs, copy

 * data into this buffer and prepare request in sgl, or (2) allocates new sg

 * table and prepare sg elements.

 *

 * For digest or finup all conditions can be good, and we may not need any

 * fixes.

	/*

	 * Have aligned data from previous operation and/or current

	 * Note: will enter here only if (digest or finup) and aligned

/**

 * s5p_hash_prepare_request() - prepare request for processing

 * @req:	AHASH request

 * @update:	true if UPDATE op

 *

 * Note 1: we can have update flag _and_ final flag at the same time.

 * Note 2: we enter here when digcnt > BUFLEN (=HASH_BLOCK_SIZE) or

 *	   either req->nbytes or ctx->bufcnt + req->nbytes is > BUFLEN or

 *	   we have final op

 bytes left from previous request, so fill up to BUFLEN */

 copy hash_later bytes from end of req->src */

 previous bytes are in xmit_buf, so no overwrite */

 have buffered data only */

 first update didn't fill up buffer */

/**

 * s5p_hash_update_dma_stop() - unmap DMA

 * @dd:		secss device

 *

 * Unmap scatterlist ctx->sg.

/**

 * s5p_hash_finish() - copy calculated digest to crypto layer

 * @req:	AHASH request

/**

 * s5p_hash_finish_req() - finish request

 * @req:	AHASH request

 * @err:	error

/**

 * s5p_hash_handle_queue() - handle hash queue

 * @dd:		device s5p_aes_dev

 * @req:	AHASH request

 *

 * If req!=NULL enqueue it on dd->queue, if FLAGS_BUSY is not set on the

 * device then processes the first request from the dd->queue

 *

 * Returns: see s5p_hash_final below.

 restore hash IV */

 HASH_OP_UPDATE */

 no final() after finup() */

 HASH_OP_FINAL */

 hash_tasklet_cb will not finish it, so do it here */

		/*

		 * Execute next request immediately if there is anything

		 * in queue.

/**

 * s5p_hash_tasklet_cb() - hash tasklet

 * @data:	ptr to s5p_aes_dev

 hash or semi-hash ready */

 finish curent request */

 If we are not busy, process next req */

/**

 * s5p_hash_enqueue() - enqueue request

 * @req:	AHASH request

 * @op:		operation UPDATE (true) or FINAL (false)

 *

 * Returns: see s5p_hash_final below.

/**

 * s5p_hash_update() - process the hash input data

 * @req:	AHASH request

 *

 * If request will fit in buffer, copy it and return immediately

 * else enqueue it with OP_UPDATE.

 *

 * Returns: see s5p_hash_final below.

 HASH_OP_UPDATE */

/**

 * s5p_hash_final() - close up hash and calculate digest

 * @req:	AHASH request

 *

 * Note: in final req->src do not have any data, and req->nbytes can be

 * non-zero.

 *

 * If there were no input data processed yet and the buffered hash data is

 * less than BUFLEN (64) then calculate the final hash immediately by using

 * SW algorithm fallback.

 *

 * Otherwise enqueues the current AHASH request with OP_FINAL operation op

 * and finalize hash message in HW. Note that if digcnt!=0 then there were

 * previous update op, so there are always some buffered bytes in ctx->buffer,

 * which means that ctx->bufcnt!=0

 *

 * Returns:

 * 0 if the request has been processed immediately,

 * -EINPROGRESS if the operation has been queued for later execution or is set

 *		to processing by HW,

 * -EBUSY if queue is full and request should be resubmitted later,

 * other negative values denotes an error.

 uncompleted hash is not needed */

 HASH_OP_FINAL */

/**

 * s5p_hash_finup() - process last req->src and calculate digest

 * @req:	AHASH request containing the last update data

 *

 * Return values: see s5p_hash_final above.

	/*

	 * final() has to be always called to cleanup resources even if

	 * update() failed, except EINPROGRESS or calculate digest for small

	 * size

/**

 * s5p_hash_init() - initialize AHASH request contex

 * @req:	AHASH request

 *

 * Init async hash request context.

/**

 * s5p_hash_digest - calculate digest from req->src

 * @req:	AHASH request

 *

 * Return values: see s5p_hash_final above.

/**

 * s5p_hash_cra_init_alg - init crypto alg transformation

 * @tfm:	crypto transformation

 Allocate a fallback and abort if it failed. */

/**

 * s5p_hash_cra_init - init crypto tfm

 * @tfm:	crypto transformation

/**

 * s5p_hash_cra_exit - exit crypto tfm

 * @tfm:	crypto transformation

 *

 * free allocated fallback

/**

 * s5p_hash_export - export hash state

 * @req:	AHASH request

 * @out:	buffer for exported state

/**

 * s5p_hash_import - import hash state

 * @req:	AHASH request

 * @in:		buffer with state to be imported from

 This sets bit [13:12] to 00, which selects 128-bit counter */

 AES_ECB */

 as a variant it is possible to use byte swapping on DMA side */

	/*

	 * Note: HASH and PRNG uses the same registers in secss, avoid

	 * overwrite each other. This will drop HASH when CONFIG_EXYNOS_RNG

	 * is enabled in config. We need larger size for HASH registers in

	 * secss, current describe only AES/DES

 try AES without HASH */

 SPDX-License-Identifier: GPL-2.0

/*

 * Cryptographic API.

 *

 * Support for ATMEL SHA1/SHA256 HW acceleration.

 *

 * Copyright (c) 2012 Eukréa Electromatique - ATMEL

 * Author: Nicolas Royer <nicolas@eukrea.com>

 *

 * Some ideas are from omap-sham.c drivers.

 SHA flags */

 bits[11:8] are reserved. */

/*

 * .statesize = sizeof(struct atmel_sha_reqctx) must be <= PAGE_SIZE / 8 as

 * tested by the ahash_prepare_alg() function.

 walk state */

 offset in current sg */

 total request */

 VERBOSE_DEBUG */

 VERBOSE_DEBUG */

 VERBOSE_DEBUG */

 handle new request */

			/*

			* Check if count <= 0 because the buffer is full or

			* because the sg length is 0. In the latest case,

			* check if there is another sg in the list, a 0 length

			* sg doesn't necessarily mean the end of the sg list.

/*

 * The purpose of this padding is to ensure that the padded message is a

 * multiple of 512 bits (SHA1/SHA224/SHA256) or 1024 bits (SHA384/SHA512).

 * The bit "1" is appended at the end of the message followed by

 * "padlen-1" zero bits. Then a 64 bits block (SHA1/SHA224/SHA256) or

 * 128 bits block (SHA384/SHA512) equals to the message length in bits

 * is appended.

 *

 * For SHA1/SHA224/SHA256, padlen is calculated as followed:

 *  - if message length < 56 bytes then padlen = 56 - message length

 *  - else padlen = 64 + 56 - message length

 *

 * For SHA384/SHA512, padlen is calculated as followed:

 *  - if message length < 112 bytes then padlen = 112 - message length

 *  - else padlen = 128 + 112 - message length

 Setting CR_FIRST only for the first iteration */

		/*

		 * Restore the hardware context: update the User Initialize

		 * Hash Value (UIHV) with the value saved when the latest

		 * 'update' operation completed on this very same crypto

		 * request.

	/*

	 * WARNING: If the UIHV feature is not available, the hardware CANNOT

	 * process concurrent requests: the internal registers used to store

	 * the hash/digest are still set to the partial digest output values

	 * computed during the latest round.

 should be non-zero before next lines to disable clocks later */

 catch last interrupt */

 should be non-zero before next lines to disable clocks later */

 catch last interrupt */

 Start DMA transfer */

 dma_lch_in - completed - wait DATRDY */

 should be non-zero before next lines to disable clocks later */

 catch last interrupt */

 Start DMA transfer */

 next call does not fail... so no unmap in the case of error */

 size is not ctx->block_size aligned */

 not last sg must be ctx->block_size aligned */

 offset where to start slow */

 Add padding */

 offset where to start slow */

 next call does not fail... so no unmap in the case of error */

 wait for dma completion before can take more data */

 faster to handle last block with cpu */

 Should not happen... */

 atomic operation is not needed here */

 WARNING: ctx->start() MAY change dd->is_async. */

	/*

	 * atmel_sha_update_req() and atmel_sha_final_req() can return either:

	 *  -EINPROGRESS: the hardware is busy and the SHA driver will resume

	 *                its job later in the done_task.

	 *                This is the main path.

	 *

	 * 0: the SHA driver can continue its job then release the hardware

	 *    later, if needed, with atmel_sha_finish_req().

	 *    This is the alternate path.

	 *

	 * < 0: an error has occurred so atmel_sha_complete(dd, err) has already

	 *      been called, hence the hardware has been released.

	 *      The SHA driver must stop its job without calling

	 *      atmel_sha_finish_req(), otherwise atmel_sha_complete() would be

	 *      called a second time.

	 *

	 * Please note that currently, atmel_sha_final_req() never returns 0.

 no final() after finup() */

 done_task will not finish it, so do it here */

 faster to use CPU for short transfers */

 uncompleted hash is not needed */

 copy ready hash (+ finalize hmac) */

	/*

	 * final() has to be always called to cleanup resources

	 * even if udpate() failed, except EINPROGRESS

 hash or semi-hash ready */

 finish curent request */

 DMA transfer functions */

		/*

		 * This is the last sg, the only one that is allowed to

		 * have an unaligned length.

 All other sg lengths MUST be aligned to the block size. */

	/*

	 * dma->nents has already been initialized by

	 * atmel_sha_dma_check_aligned().

 CPU transfer functions */

 Write data into the Input Data Registers. */

		/*

		 * Prepare next block:

		 * Fill ctx->buffer now with the next data to be written into

		 * IDATARx: it gives time for the SHA hardware to process

		 * the current data so the SHA_INT_DATARDY flag might be set

		 * in SHA_ISR when polling this register at the beginning of

		 * the next loop.

 Wait for hardware to be ready again. */

 Not ready yet. */

 Prepare the first block to be written. */

 hmac functions */

 Compute K' from K. */

 Prepare ipad. */

 Prepare ipad. */

 Save d = SHA((K' + ipad) | msg). */

 Restore context to finish computing SHA((K' + opad) | d). */

	/*

	 * req->result might not be sizeof(u32) aligned, so copy the

	 * digest into ctx->digest[] before memcpy() the data into

	 * req->result.

 Special case for empty message. */

 TODO:

 Check DMA threshold and alignment. */

 Write both initial hash values to compute a HMAC. */

 Write the Mode, Message Size, Bytes Count then Control Registers. */

 Process data. */

 authenc functions */

 _init() parameters. */

 _final() parameters. */

	/*

	 * Force atmel_sha_complete() to call req->base.complete(), ie

	 * atmel_sha_authenc_complete(), which in turn calls authctx->cb().

 Reset request context (MUST be done first). */

 Get SHA device. */

 Init request context. */

 Process assoc data. */

 Prevent atmel_sha_complete() from calling req->base.complete(). */

 CONFIG_CRYPTO_DEV_ATMEL_AUTHENC */

i = ARRAY_SIZE(sha_hmac_algs);*/

 keep only major version number */

 sentinel */ }

 Get the base address */

 Get the IRQ */

 Initializing the clock */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 Imagination Technologies

 * Authors:  Will Thomas, James Hartley

 *

 *	Interface structure taken from omap-sham driver

 sg root */

 walk state */

 Zero length buffer must remain last member of struct */

	/*

	 * The hardware block requires two cycles between writing the control

	 * register and writing the first word of data in non DMA mode, to

	 * ensure the first data write is not grouped in burst with the control

	 * register write a read is issued to 'flush' the bus.

	/*

	 * The hash accelerator does not support a data valid mask. This means

	 * that if each dma (i.e. per page) is not a multiple of 4 bytes, the

	 * padding bytes in the last word written by that dma would erroneously

	 * be included in the hash. To avoid this we round down the transfer,

	 * and add the excess to the start of the next dma. It does not matter

	 * that the final dma may not be a multiple of 4 bytes as the hashing

	 * block is programmed to accept the correct number of bytes.

 done_task will not finish so do it here */

 Register bank */

 Write port (DMA or CPU) */

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0

/*

 * Microchip / Atmel ECC (I2C) driver.

 *

 * Copyright (c) 2017, Microchip Technology Inc.

 * Author: Tudor Ambarus <tudor.ambarus@microchip.com>

/**

 * atmel_i2c_checksum() - Generate 16-bit CRC as required by ATMEL ECC.

 * CRC16 verification of the count, opcode, param1, param2 and data bytes.

 * The checksum is saved in little-endian format in the least significant

 * two bytes of the command. CRC polynomial is 0x8005 and the initial register

 * value should be zero.

 *

 * @cmd : structure used for communicating with the device.

	/*

	 * Read the word from Configuration zone that contains the lock bytes

	 * (UserExtra, Selector, LockValue, LockConfig).

 a random private key will be generated and stored in slot keyID */

 private key slot */

	/*

	 * The device only supports NIST P256 ECC keys. The public key size will

	 * always be the same. Use a macro for the key size to avoid unnecessary

	 * computations.

/*

 * After wake and after execution of a command, there will be error, status, or

 * result bytes in the device's output register that can be retrieved by the

 * system. When the length of that group is four bytes, the codes returned are

 * detailed in error_list.

 if err_id is not in the error_list then ignore it */

	/*

	 * The device ignores any levels or transitions on the SCL pin when the

	 * device is idle, asleep or during waking up. Don't check for error

	 * when waking up the device.

	/*

	 * Wait to wake the device. Typical execution times for ecdh and genkey

	 * are around tens of milliseconds. Delta is chosen to 50 microseconds.

/*

 * atmel_i2c_send_receive() - send a command to the device and receive its

 *                            response.

 * @client: i2c client device

 * @cmd   : structure used to communicate with the device

 *

 * After the device receives a Wake token, a watchdog counter starts within the

 * device. After the watchdog timer expires, the device enters sleep mode

 * regardless of whether some I/O transmission or command execution is in

 * progress. If a command is attempted when insufficient time remains prior to

 * watchdog timer execution, the device will return the watchdog timeout error

 * code without attempting to execute the command. There is no way to reset the

 * counter other than to put the device into sleep or idle mode and then

 * wake it up again.

 send the command */

 delay the appropriate amount of time for command to execute */

 receive the response */

 put the device into low-power mode */

 return the size of the wake_token in bytes */

	/*

	 * It is vital that the Configuration, Data and OTP zones be locked

	 * prior to release into the field of the system containing the device.

	 * Failure to lock these zones may permit modification of any secret

	 * keys and may lead to other security problems.

 fall through */

	/*

	 * WAKE_TOKEN_MAX_SIZE was calculated for the maximum bus_clk_rate -

	 * 1MHz. The previous bus_clk_rate check ensures us that wake_token_sz

	 * will always be smaller than or equal to WAKE_TOKEN_MAX_SIZE.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale i.MX23/i.MX28 Data Co-Processor driver

 *

 * Copyright (C) 2013 Marek Vasut <marex@denx.de>

/*

 * Null hashes to align with hw behavior on imx6sl and ull

 * these are flipped for consistency with hw output

 DCP DMA descriptor. */

 Coherent aligned block for bounce buffering. */

 Common context */

 SHA Hash-specific context */

 Crypto-specific context */

 keep at the end

/*

 * There can even be only one instance of the MXS DCP due to the

 * design of Linux Crypto API.

 DCP register layout. */

 DMA descriptor bits. */

 Clear status register. */

 Load the DMA descriptor. */

 Increment the semaphore to start the DMA transfer. */

/*

 * Encryption (AES128)

 Fill in the DMA descriptor. */

 Payload contains the key. */

 Copy the key from the temporary location. */

 Copy the CBC IV just past the key. */

 CBC needs the INIT set. */

			/*

			 * If we filled the buffer or this is the last SG,

			 * submit the buffer.

 Copy the IV for CBC for chaining */

	/*

	 * AES 128 is supposed by the hardware, store key into temporary

	 * buffer and exit. We must use the temporary buffer here, since

	 * there can still be an operation in progress.

	/*

	 * If the requested AES key size is not supported by the hardware,

	 * but is supported by in-kernel software implementation, we use

	 * software fallback.

/*

 * Hashing (SHA1/SHA256)

 Fill in the DMA descriptor. */

	/*

	 * Align driver with hw behavior when generating null hashes

 Set HASH_TERM bit for last transfer block. */

		/*

		 * If we filled the buffer and still have some

		 * more data, submit the buffer.

 Submit whatever is left. */

 For some reason the result is flipped */

	/*

	 * Start hashing session. The code below only inits the

	 * hashing session context, nothing more.

	/*

	 * Ignore requests that have no data in them and are not

	 * the trailing requests in the stream of requests.

 AES 128 ECB and AES 128 CBC */

 SHA1 */

 SHA256 */

 Clear the interrupts. */

 Complete the DMA requests that finished. */

 Allocate coherent helper block. */

 Re-align the structure so it fits the DCP constraints. */

 DCP clock is optional, only used on some SOCs */

 Restart the DCP block. */

 Initialize control register. */

 Enable all DCP DMA channels. */

	/*

	 * We do not enable context switching. Give the context buffer a

	 * pointer to an illegal address so if context switching is

	 * inadvertantly enabled, the DCP will return an error instead of

	 * trashing good memory. The DCP DMA cannot access ROM, so any ROM

	 * address will do.

 Create the SHA and AES handler threads. */

 Register the various crypto algorithms. */

 Failed to register algorithm. */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * talitos - Freescale Integrated Security Engine (SEC) device driver

 *

 * Copyright (c) 2008-2011 Freescale Semiconductor, Inc.

 *

 * Scatterlist Crypto API glue code copied from files with the following:

 * Copyright (c) 2006-2007 Herbert Xu <herbert@gondor.apana.org.au>

 *

 * Crypto algorithm registration code copied from hifn driver:

 * 2007+ Copyright (c) Evgeniy Polyakov <johnpol@2ka.mipt.ru>

 * All rights reserved.

/*

 * map virtual single (contiguous) pointer to h/w descriptor pointer

/*

 * unmap bus single (contiguous) h/w descriptor pointer

 set 36-bit addressing, done writeback enable and done IRQ enable */

 enable chaining descriptors */

 and ICCR writeback, if available */

/*

 * Reset and initialize the device

	/*

	 * Master reset

	 * errata documentation: warning: certain SEC interrupts

	 * are not fully cleared by writing the MCR:SWR bit,

	 * set bit twice to completely reset

 reset channels */

 enable channel done and error interrupts */

 disable parity error check in DEU (erroneous? test vect.) */

 disable integrity check error interrupts (use writeback instead) */

/**

 * talitos_submit - submits a descriptor to the device for processing

 * @dev:	the SEC device to be used

 * @ch:		the SEC device channel to be used

 * @desc:	the descriptor to be processed by the device

 * @callback:	whom to call when processing is complete

 * @context:	a handle for use by caller (optional)

 *

 * desc must contain valid dma-mapped (bus physical) address pointers.

 * callback must check err and feedback in descriptor header

 * for device processing status.

 h/w fifo is full */

 map descriptor and save caller data */

 increment fifo head */

 GO! */

/*

 * process what was done, notify callback of error if not

 descriptors with their done bits set don't get the error */

 copy entries so we can call callback outside lock */

 release request entry in fifo */

 increment fifo tail */

 channel may resume processing in single desc error case */

/*

 * process completed requests for channels that have done status

 At this point, all completed channels have been processed */	\

 Unmask done interrupts for channels completed later on. */	\

 At this point, all completed channels have been processed */	\

 Unmask done interrupts for channels completed later on. */	\

/*

 * locate current (offending) descriptor

/*

 * user diagnostics; report root cause of error based on execution unit status

/*

 * recover from error interrupts

 only SEC2 supports continuation */

 skip channels without errors */

 bits 29, 31, 17, 19 */

 h/w dropped descriptor */

 purge request queues */

 reset and reinitialize the device */

 Acknowledge interrupt */					       \

 mask further done interrupts. */		       \

 done_task will unmask done interrupts at exit */    \

 Acknowledge interrupt */					       \

 mask further done interrupts. */		       \

 done_task will unmask done interrupts at exit */    \

/*

 * hwrng

 rng fifo requires 64-bit accesses */

 start generating */

/*

 * crypto alg

/*

 * Defines a priority for doing AEAD with descriptors type

 * HMAC_SNOOP_NO_AFEA (HSNA) instead of type IPSEC_ESP

 max of AES_BLOCK_SIZE, DES3_EDE_BLOCK_SIZE */

/*

 * ipsec_esp descriptor callbacks

 auth check */

 check ICV auth status */

/*

 * convert scatterlist to SEC h/w link table format

 * stop at cryptlen bytes

 tag end of link table */

 Only one segment now, so no link tbl needed*/

/*

 * fill in and submit ipsec_esp descriptor

 hmac key */

 hmac data */

 cipher iv */

 cipher key */

	/*

	 * cipher in

	 * map and adjust cipher len to aead request cryptlen.

	 * extent is bytes of HMAC postpended to ciphertext,

	 * typically 12 for ipsec

 cipher out */

 Add an entry to the link table for ICV data */

 icv data follows link tables */

 iv out */

/*

 * allocate and map the extended descriptor

 dst && dst != src*/

	/*

	 * allocate space for base edesc plus the link tables,

	 * allowing for two separate entries for AD and generated ICV (+ 2),

	 * and space for two sets of ICVs (stashed and generated)

 if its a ahash, add space for a second desc next to the first one */

 allocate extended descriptor */

 set encrypt */

 allocate extended descriptor */

 decrypt and check the ICV */

 reset integrity check result bits */

 Have to check the ICV with software */

 stash incoming ICV for later cmp with ICV generated by the h/w */

 first DWORD empty */

 cipher iv */

 cipher key */

	/*

	 * cipher in

 cipher out */

 iv out */

 last DWORD empty */

 allocate extended descriptor */

 set encrypt */

 allocate extended descriptor */

 When using hashctx-in, must unmap it. */

 Position any partial block for next update/final/finup */

/*

 * SEC1 doesn't like hashing of 0 sized message, so we do the padding

 * ourself and submit a padded block

 first DWORD empty */

 hash context in */

 Indicate next op is not the first. */

 HMAC key */

	/*

	 * data in

 fifth DWORD empty */

 hash/HMAC out -or- hash context out */

 last DWORD empty */

 Initialize the context */

 first indicates h/w must init its context */

 assume h/w init of context */

/*

 * on h/w without explicit sha224 support, we initialize h/w context

 * manually with sha224 constants, and tell it to run sha256.

 init 64-bit count */

 prevent h/w initting context with sha256 values*/

 Buffer up to one whole block */

 At least (blocksize + 1) bytes are available to hash */

 There is a partial block. Hash the full block(s) now */

 Keep one block buffered */

 Chain in any previously buffered data */

 Allocate extended descriptor */

 On last one, request SEC to pad; otherwise continue */

 request SEC to INIT hash. */

	/* When the tfm context has a keylen, it's an HMAC.

	 * A first or last (ie. not middle) descriptor must request HMAC.

 Keep tfm keylen == 0 during hash of the long key */

 Must get the hash of the long key */

 AEAD algorithms.  These use a single-pass ipsec_esp descriptor */

 SKCIPHER algorithms. */

 AHASH algorithms. */

 update context with ptr to dev */

 assign SEC channel to tfm in round-robin fashion */

 copy descriptor header template value */

 select done notification */

/*

 * given the alg's descriptor header template, determine whether descriptor

 * type and primary/secondary execution units required match the hw

 * capabilities description provided in the device tree node.

 get the primary irq line */

 get the secondary irq line */

 get SEC version capabilities from device tree */

 reset and initialize the h/w */

 register the RNG, if available */

 register crypto algorithms the device supports */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for OMAP DES and Triple DES HW acceleration.

 *

 * Copyright (c) 2013 Texas Instruments Incorporated

 * Author: Joel Fernandes <joelf@ti.com>

	/*

	 * total is used by PIO mode for book keeping so introduce

	 * variable total_save as need it to calc page_order

 Buffers for copying for unaligned cases */

 keep registered devices data here */

	/*

	 * clocks are enabled when request starts and disabled when finished.

	 * It may be long delays between requests.

	 * Device might go to off mode to save power.

 it seems a key should always be set even if it has not changed */

 FIXME: take fist available des core */

 already found before */

 dma_lch_out - completed */

		/* Enable DATAIN interrupt and let it take

 IN */

 No callback necessary */

 OUT */

 start DMA */

 assign new request to device */

 ********************** ALG API ************************************ */

 ********************** ALGS ************************************ */

 Clear IRQ status */

 Enable DATA_OUT interrupt */

 Clear IRQ status */

 All bytes read! */

 Enable DATA_IN interrupt for next block */

 non-DT devices get pdata from pdev */

 Initialize des crypto engine */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 *

 * Support for OMAP AES GCM HW acceleration.

 *

 * Copyright (c) 2016 Texas Instruments Incorporated

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * 2007+ Copyright (c) Evgeniy Polyakov <johnpol@2ka.mipt.ru>

 * All rights reserved.

 I/O region sizes */

 DMA registres */

 DMA Command Ring Address */

 DMA Source Data Ring Address */

 DMA Result Ring Address */

 DMA Destination Data Ring Address */

 DMA Status and Control */

 DMA Interrupt Enable */

 DMA Configuration #1 */

 DMA Configuration #2 */

 Chip ID */

/*

 * Processing Unit Registers (offset from BASEREG0)

 Processing Unit Data */

 Processing Unit Control */

 Processing Unit Interrupt Status */

 Processing Unit Configuration */

 Processing Unit Interrupt Enable */

 Processing Unit Status/Chip ID */

 FIFO Status */

 FIFO Configuration */

 Register space size */

 Processing Unit Control Register (HIFN_0_PUCTRL) */

 clear source fifo */

 stop pu */

 lock ram */

 enable dma */

 Reset processing unit */

 Processing Unit Interrupt Status Register (HIFN_0_PUISR) */

 Invalid command interrupt */

 Data error interrupt */

 Source FIFO ready interrupt */

 Destination FIFO ready interrupt */

 Destination overrun interrupt */

 Source command interrupt */

 Source context interrupt */

 Source data interrupt */

 Destination data interrupt */

 Destination result interrupt */

 Processing Unit Configuration Register (HIFN_0_PUCNFG) */

 DRAM size mask */

 256k dram */

 512k dram */

 1m dram */

 2m dram */

 4m dram */

 8m dram */

 16m dram */

 32m dram */

 DRAM refresh rate mask */

 512 divisor of ECLK */

 256 divisor of ECLK */

 128 divisor of ECLK */

 your guess is as good as mine... */

 your guess is as good as mine... */

 DMA big endian mode */

 Bus width 32bits */

 Bus width 16 bits */

 Allow chipid from PUSTAT */

 Context RAM is DRAM */

 Context RAM is SRAM */

 Enable single compression context */

 Encryption configuration */

 Processing Unit Interrupt Enable Register (HIFN_0_PUIER) */

 Invalid command interrupt */

 Data error interrupt */

 Source FIFO ready interrupt */

 Destination FIFO ready interrupt */

 Destination overrun interrupt */

 Source command interrupt */

 Source context interrupt */

 Source data interrupt */

 Destination data interrupt */

 Destination result interrupt */

 Processing Unit Status Register/Chip ID (HIFN_0_PUSTAT) */

 Invalid command interrupt */

 Data error interrupt */

 Source FIFO ready interrupt */

 Destination FIFO ready interrupt */

 Destination overrun interrupt */

 Source command interrupt */

 Source context interrupt */

 Source data interrupt */

 Destination data interrupt */

 Destination result interrupt */

 Chip revision mask */

 Chip enabled mask */

 Level 2 enabled */

 Level 1 enabled */

 Level 0 enabled */

 7751 PT6/2 */

 7751 PT6/3 */

 FIFO Status Register (HIFN_0_FIFOSTAT) */

 Source FIFO available */

 Destination FIFO available */

 FIFO Configuration Register (HIFN_0_FIFOCNFG) */

 must be written as 1 */

/*

 * DMA Interface Registers (offset from BASEREG1)

 DMA Command Ring Address */

 DMA Source Ring Address */

 DMA Result Ring Address */

 DMA Destination Ring Address */

 DMA Status and Control */

 DMA Interrupt Enable */

 DMA Configuration */

 795x: PLL config */

 7811: rng enable */

 7811: rng config */

 7811: rng data */

 7811: rng status */

 7811: MIPS reset */

 Revision ID */

 Public/RNG Reset */

 Public Base Address */

 Public Operand Length */

 Public Operand */

 Public Status */

 Public Interrupt enable */

 RNG config */

 RNG data */

 start of Public key memory */

 end of Public key memory */

 DMA Status and Control Register (HIFN_1_DMA_CSR) */

 Destinition Ring Control */

 Dest. Control: no-op */

 Dest. Control: disable */

 Dest. Control: enable */

 Destinition Ring PCIAbort */

 Destinition Ring Done */

 Destinition Ring Last */

 Destinition Ring Waiting */

 Destinition Ring Overflow */

 Result Ring Control */

 Result Control: no-op */

 Result Control: disable */

 Result Control: enable */

 Result Ring PCI Abort */

 Result Ring Done */

 Result Ring Last */

 Result Ring Waiting */

 Result Ring Overflow */

 Source Ring Control */

 Source Control: no-op */

 Source Control: disable */

 Source Control: enable */

 Source Ring PCI Abort */

 Source Ring Done */

 Source Ring Last */

 Source Ring Waiting */

 Illegal write (7811 only) */

 Illegal read (7811 only) */

 Command Ring Control */

 Command Control: no-op */

 Command Control: disable */

 Command Control: enable */

 Command Ring PCI Abort */

 Command Ring Done */

 Command Ring Last */

 Command Ring Waiting */

 Public op done (7951 only) */

 Command Ring Engine IRQ */

 DMA Interrupt Enable Register (HIFN_1_DMA_IER) */

 Destination Ring PCIAbort */

 Destination Ring Done */

 Destination Ring Last */

 Destination Ring Waiting */

 Destination Ring Overflow */

 Result Ring PCI Abort */

 Result Ring Done */

 Result Ring Last */

 Result Ring Waiting */

 Result Ring Overflow */

 Source Ring PCI Abort */

 Source Ring Done */

 Source Ring Last */

 Source Ring Waiting */

 Illegal write (7811 only) */

 Illegal read (7811 only) */

 Command Ring PCI Abort */

 Command Ring Done */

 Command Ring Last */

 Command Ring Waiting */

 public op done (7951 only) */

 Engine IRQ */

 DMA Configuration Register (HIFN_1_DMA_CNFG) */

 big endian mode */

 Poll frequency mask */

 Invalid Poll Scalar */

 Host control LAST bit */

 DMA mode */

 DMA Reset # */

 Master Reset # */

 PLL configuration register */

 HBI reference clock */

 PLL reference clock */

 Reference clock bypass */

 PK engine HBI clock */

 PK engine PLL clock */

 PE engine HBI clock */

 PE engine PLL clock */

 Reserved bit, must be 1 */

 Clock multiplier shift */

 PLL clock multiplier 2 */

 PLL clock multiplier 4 */

 PLL clock multiplier 6 */

 PLL clock multiplier 8 */

 PLL clock multiplier 10 */

 PLL clock multiplier 12 */

 charge pump (mult. 1-8) */

 charge pump (mult. 9-12) */

 Maximum PLL frequency */

 Public key reset register (HIFN_1_PUB_RESET) */

 reset public/rng unit */

 Public base address register (HIFN_1_PUB_BASE) */

 base address */

 Public operand length register (HIFN_1_PUB_OPLEN) */

 modulus length mask */

 modulus length shift */

 exponent length mask */

 exponent length shift */

 reducend length mask */

 reducend length shift */

 Public operation register (HIFN_1_PUB_OP) */

 A offset mask */

 A offset shift */

 B offset mask */

 B offset shift */

 M offset mask */

 M offset shift */

 Opcode: */

  NOP */

  ADD */

  ADD w/carry */

  SUB */

  SUB w/carry */

  Modular ADD */

  Modular SUB */

  INC A */

  DEC A */

  MULT */

  Modular MULT */

  Modular RED */

  Modular EXP */

 Public status register (HIFN_1_PUB_STATUS) */

 operation done */

 carry */

 Public interrupt enable register (HIFN_1_PUB_IEN) */

 operation done interrupt */

 Random number generator config register (HIFN_1_RNG_CONFIG) */

 enable rng */

	/*

	 *  Our current positions for insertion and removal from the descriptor

	 *  rings.

 enable compression engine */

 enable padding engine */

 enable MAC engine */

 enable crypt engine */

/*

 * Structure to help build up the command data structure.

 algorithm: */

   DES */

   3DES */

   RC4 */

   AES */

 Encrypt mode: */

   ECB */

   CBC */

   CFB */

   OFB */

 clear context */

 AES key size: */

  128 bit */

  192 bit */

  256 bit */

 expect new key */

 expect new iv */

/*

 * Structure to help build up the command data structure.

/*

 * MAC POS IPsec initiates authentication after encryption on encodes

 * and before decryption on decodes.

 must be one */

 clear history */

 update history */

 LZS: strip zero */

 MPPC: restart */

 compression mode: */

   MPPC */

   LZS */

 15:0 of source count */

 15:0 of dest count */

 destination overrun */

 17:16 of source count */

 17:16 of dest count */

 longitudinal check byte */

 MPPC: restart */

 LZS: end marker seen */

 source expired */

 followed by 0, 6, 8, or 10 u16's of the MAC, then crypt */

 compare failed */

 source expired */

 source expired */

 maximum dma segment len */

 maximum dma length */

	/*

	 * Setting poll frequency and others to 0.

	/*

	 * Reset DMA.

 get the parity */

	/*

	 * We must wait at least 256 Pk_clk cycles between two reads of the rng.

 Enable RNG engine. */

 First value must be discarded */

 Setup LAST descriptors. */

/*

 * Initialize the PLL. We need to know the frequency of the reference clock

 * to calculate the optimal multiplier. For PCI we assume 66MHz, since that

 * allows us to operate without the risk of overclocking the chip. If it

 * actually uses 33MHz, the chip will operate at half the speed, this can be

 * overridden by specifying the frequency as module parameter (pci33).

 *

 * Unfortunately the PCI clock is not very suitable since the HIFN needs a

 * stable clock and the PCI clock frequency may vary, so the default is the

 * external clock. There is no way to find out its frequency, we default to

 * 66MHz since according to Mike Ham of HiFn, almost every board in existence

 * has an external crystal populated at 66MHz.

 Select clock source and enable clock bypass */

 Let the chip lock to the input clock */

 Disable clock bypass */

 Switch the engines to the PLL */

	/*

	 * The Fpk_clk runs at half the total speed. Its frequency is needed to

	 * calculate the minimum time between two reads of the rng. Since 33MHz

	 * is actually 33.333... we overestimate the frequency here, resulting

	 * in slightly larger intervals.

 Initialization magic... */

 write all 4 ring address registers */

	/*

	 * dma->resr[dma->resi].l = __cpu_to_le32(HIFN_MAX_RESULT | HIFN_D_VALID |

	 *					HIFN_D_LAST);

				/*

				 * Destination page does not have enough space

				 * to put there additional blocksized chunk,

				 * so we mark that page as containing only

				 * blocksize aligned chunks:

				 *	t->length = (slen & ~(HIFN_D_DST_DALIGN - 1));

				 * and increase number of bytes to be processed

				 * in next chunk:

				 *	nbytes += diff;

				/*

				 * Temporary of course...

				 * Kick author if you will catch this one.

	/*

	 * HEAVY TODO: needs to kick Herbert XU to write documentation.

	 * HEAVY TODO: needs to kick Herbert XU to write documentation.

	 * HEAVY TODO: needs to kick Herbert XU to write documentation.

/*

 * AES ecryption functions.

/*

 * AES decryption functions.

/*

 * DES ecryption functions.

/*

 * DES decryption functions.

/*

 * 3DES ecryption functions.

 3DES decryption functions. */

	/*

	 * 3DES ECB, CBC, CFB and OFB modes.

	/*

	 * DES ECB, CBC, CFB and OFB modes.

	/*

	 * AES ECB, CBC, CFB and OFB modes.

	/*

	 * This is ok to call this without lock being held,

	 * althogh it modifies some parameters used in parallel,

	 * (like dev->success), but they are used in process

	 * context or update is atomic (like setting dev->sa[i] to NULL).

	/*

	 * For the 7955/7956 the reference clock frequency must be in the

	 * range of 20MHz-100MHz. For the 7954 the upper bound is 66.67MHz,

	 * but this chip is currently not supported.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 *

 * Support for OMAP SHA1/MD5 HW acceleration.

 *

 * Copyright (c) 2010 Nokia Corporation

 * Author: Dmitry Kasatkin <dmitry.kasatkin@nokia.com>

 * Copyright (c) 2011 Texas Instruments Incorporated

 *

 * Some ideas are from old omap-sha1-md5.c driver.

 mostly device flags */

 context flags */

 walk state */

 offset in current sg */

 total request */

 fallback stuff */

 OMAP2 SHA1 is big endian */

	/*

	 * Setting ALGO_CONST only for the first iteration

	 * and CLOSE_HASH only for the last one.

	/*

	 * Setting ALGO_CONST only for the first iteration and

	 * CLOSE_HASH only for the last one. Note that flags mode bits

	 * correspond to algorithm encoding in mode register.

 should be non-zero before next lines to disable clocks later */

 catch last interrupt */

 catch last interrupt */

 wait for dma completion before can take more data */

		/*

		 * faster to handle last block with cpu or

		 * use cpu when dma is not present.

 Re-enqueue the request */

 atomic operation is not needed here */

	/*

	 * If we are running HMAC on limited hardware support, skip

	 * the ipad in the beginning of the buffer if we are going for

	 * software fallback algorithm.

 uncompleted hash is not needed */

	/*

	 * OMAP HW accel works only with buffers >= 9.

	 * HMAC is always >= 9 because ipad == block size.

	 * If buffersize is less than fallback_sz, we use fallback

	 * SW encoding, as using DMA + HW in this case doesn't provide

	 * any benefit.

 copy ready hash (+ finalize hmac) */

	/*

	 * final() has to be always called to cleanup resources

	 * even if udpate() failed, except EINPROGRESS

 Allocate a fallback and abort if it failed. */

 OMAP4 has some algs in addition to what OMAP2 has */

 hash or semi-hash ready */

 finish curent request */

 final -> allow device to go to power-saving mode */

 Get the base address */

 Get the IRQ */

 Only OMAP2/3 can be non-DT */

 HW accelerator only works with buffers > 9 */

	/*

	 * Changing the queue size in fly is safe, if size becomes smaller

	 * than current size, it will just not accept new entries until

	 * it has shrank enough.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel IXP4xx NPE-C crypto driver

 *

 * Copyright (C) 2008 Christian Hohnstaedt <chohnstaedt@innominate.com>

 Intermittent includes, delete this after v5.14-rc1 */

 hash: cfgword + 2 * digestlen; crypt: keylen + cfgword */

/* Space for registering when the first

 NPE_OP_*  operation mode */

 NPE_OP_*  operation mode */

 IV for CBC mode or CTR IV for CTR mode */

 icv or rev aes */

 Authentication start offset */

 Authentication data length */

 Cryption start offset */

 Cryption data length */

 Authentication data length */

 Authentication start offset */

 Cryption data length */

 Cryption start offset */

 Additional Auth Data Addr for CCM mode */

 NPE Crypto Param structure address */

 Used by Host: 4*4 bytes*/

 keep at the end

 used when the hmac is not on one sg entry */

 Locate the NPE and queue manager to use from device tree */

		/*

		 * Hardcoded engine when using platform data, this goes away

		 * when we switch to using DT only.

	/* buffer_pool will also be used to sometimes store the hmac,

	 * so assure it is large enough

 write cfg word to cryptinfo */

 (authsize/4) << 8 */

 change the "byte swap" flags */

 write ICV to cryptinfo */

 write cfg word to cryptinfo */

 write cipher key to cryptinfo */

 NPE wants keylen set to DES3_EDE_KEY_SIZE even for single DES */

 the nonce is stored in bytes at end of key */

		/* This was never tested by Intel

 set up counter block */

 initialize counter portion of counter block */

 req->cryptlen includes the authsize when decrypting */

		/* The 12 hmac bytes are scattered,

 block ciphers */

 authenc */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017-18 Linaro Limited



 Based on msm-rng.c and downstream driver

 Device specific register offsets */

 Device specific register masks and config values */

 read random data from hardware */

 copy only remaining bytes */

 Enable PRNG only if it is not already enabled */

 ACPI systems have clk already on, so skip clk_get */

 SPDX-License-Identifier: GPL-2.0

/*

 * Microchip / Atmel ECC (I2C) driver.

 *

 * Copyright (c) 2017, Microchip Technology Inc.

 * Author: Tudor Ambarus <tudor.ambarus@microchip.com>

/**

 * struct atmel_ecdh_ctx - transformation context

 * @client     : pointer to i2c client device

 * @fallback   : used for unsupported curves or when user wants to use its own

 *               private key.

 * @public_key : generated when calling set_secret(). It's the responsibility

 *               of the user to not call set_secret() while

 *               generate_public_key() or compute_shared_secret() are in flight.

 * @curve_id   : elliptic curve id

 * @do_fallback: true when the device doesn't support the curve or when the user

 *               wants to use its own private key.

 might want less than we've got */

 copy the shared secret */

 fall through */

/*

 * A random private key is generated and stored in the device. The device

 * returns the pair public key.

 free the old public key, if any */

 make sure you don't free the old public key twice */

 fallback to ecdh software implementation */

	/*

	 * The device only supports NIST P256 ECC keys. The public key size will

	 * always be the same. Use a macro for the key size to avoid unnecessary

	 * computations.

 save the public key */

 might want less than we've got */

 public key was saved at private key generation */

 must have exactly two points to be on the curve */

	/*

	 * The device only supports NIST P256 ECC keys. The public key size will

	 * always be the same. Use a macro for the key size to avoid unnecessary

	 * computations.

 Return EBUSY if i2c client already allocated. */

 sentinel */

 SPDX-License-Identifier: GPL-2.0

/*

 * K3 SA2UL crypto accelerator driver

 *

 * Copyright (C) 2018-2020 Texas Instruments Incorporated - http://www.ti.com

 *

 * Authors:	Keerthy

 *		Vitaly Andrianov

 *		Tero Kristo

 Byte offset for key in encryption security context */

 Byte offset for Aux-1 in encryption security context */

 Make 32-bit word from 4 bytes */

 size of SCCTL structure in bytes */

 Max Authentication tag size */

/**

 * struct sa_cmdl_cfg - Command label configuration descriptor

 * @aalg: authentication algorithm ID

 * @enc_eng_id: Encryption Engine ID supported by the SA hardware

 * @auth_eng_id: Authentication Engine ID

 * @iv_size: Initialization Vector size

 * @akey: Authentication key

 * @akey_len: Authentication key length

 * @enc: True, if this is an encode request

/**

 * struct algo_data - Crypto algorithm specific data

 * @enc_eng: Encryption engine info structure

 * @auth_eng: Authentication engine info structure

 * @auth_ctrl: Authentication control word

 * @hash_size: Size of digest

 * @iv_idx: iv index in psdata

 * @iv_out_size: iv out size

 * @ealg_id: Encryption Algorithm ID

 * @aalg_id: Authentication algorithm ID

 * @mci_enc: Mode Control Instruction for Encryption algorithm

 * @mci_dec: Mode Control Instruction for Decryption

 * @inv_key: Whether the encryption algorithm demands key inversion

 * @ctx: Pointer to the algorithm context

 * @keyed_mac: Whether the authentication algorithm has key

 * @prep_iopad: Function pointer to generate intermediate ipad/opad

/**

 * struct sa_alg_tmpl: A generic template encompassing crypto/aead algorithms

 * @type: Type of the crypto algorithm.

 * @alg: Union of crypto algorithm definitions.

 * @registered: Flag indicating if the crypto algorithm is already registered

 CRYPTO_ALG_TYPE from <linux/crypto.h> */

/**

 * struct sa_mapped_sg: scatterlist information for tx and rx

 * @mapped: Set to true if the @sgt is mapped

 * @dir: mapping direction used for @sgt

 * @split_sg: Set if the sg is split and needs to be freed up

 * @static_sg: Static scatterlist entry for overriding data

 * @sgt: scatterlist table for DMA API use

/**

 * struct sa_rx_data: RX Packet miscellaneous data place holder

 * @req: crypto request data pointer

 * @ddev: pointer to the DMA device

 * @tx_in: dma_async_tx_descriptor pointer for rx channel

 * @mapped_sg: Information on tx (0) and rx (1) scatterlist DMA mapping

 * @enc: Flag indicating either encryption or decryption

 * @enc_iv_size: Initialisation vector size

 * @iv_idx: Initialisation vector index

/**

 * struct sa_req: SA request definition

 * @dev: device for the request

 * @size: total data to the xmitted via DMA

 * @enc_offset: offset of cipher data

 * @enc_size: data to be passed to cipher engine

 * @enc_iv: cipher IV

 * @auth_offset: offset of the authentication data

 * @auth_size: size of the authentication data

 * @auth_iv: authentication IV

 * @type: algorithm type for the request

 * @cmdl: command label pointer

 * @base: pointer to the base request

 * @ctx: pointer to the algorithm context data

 * @enc: true if this is an encode request

 * @src: source data

 * @dst: destination data

 * @callback: DMA callback for the request

 * @mdata_size: metadata size passed to DMA

/*

 * Mode Control Instructions for various Key lengths 128, 192, 256

 * For CBC (Cipher Block Chaining) mode for encryption

/*

 * Mode Control Instructions for various Key lengths 128, 192, 256

 * For CBC (Cipher Block Chaining) mode for decryption

/*

 * Mode Control Instructions for various Key lengths 128, 192, 256

 * For CBC (Cipher Block Chaining) mode for encryption

/*

 * Mode Control Instructions for various Key lengths 128, 192, 256

 * For CBC (Cipher Block Chaining) mode for decryption

/*

 * Mode Control Instructions for various Key lengths 128, 192, 256

 * For ECB (Electronic Code Book) mode for encryption

/*

 * Mode Control Instructions for various Key lengths 128, 192, 256

 * For ECB (Electronic Code Book) mode for decryption

/*

 * Mode Control Instructions for DES algorithm

 * For CBC (Cipher Block Chaining) mode and ECB mode

 * encryption and for decryption respectively

/*

 * Perform 16 byte or 128 bit swizzling

 * The SA2UL Expects the security context to

 * be in little Endian and the bus width is 128 bits or 16 bytes

 * Hence swap 16 bytes at a time from higher to lower address

 Prepare the ipad and opad from key as per SHA algorithm step 1*/

 Instead of XOR with 0 */

 Instead of XOR with 0 */

 Derive the inverse key used in AES-CBC decryption operation */

 work around to get the right inverse for AES_KEYSIZE_192 size keys */

 Based crypto_aes_expand_key logic */

 Set Security context for the encryption engine */

 Set Encryption mode selector to crypto processing */

 Set the mode control instructions in security context */

 For AES-CBC decryption get the inverse key */

 For all other cases: key is used */

 Set Security context for the authentication engine */

 Set Authentication mode selector to hash processing */

 Auth SW ctrl word: bit[6]=1 (upload computed hash to TLR section) */

 Copy the keys or ipad/opad */

 basic hash */

 Format general command label */

 Clear the command label */

 Iniialize the command update structure */

 Encryption command label */

 Encryption modes requiring IV */

 Update Command label */

 Format SWINFO words to be sent to SA */

 Dump the security context */

 SCCTL Owner info: 0=host, 1=CP_ACE */

 Prepare context for encryption engine */

 Prepare context for authentication engine */

 Set the ownership of context to CP_ACE */

 swizzle the security context */

 Free the per direction context memory */

 Setup Encryption Security Context & Command label template */

 Setup Decryption Security Context & Command label template */

 Convert the key size (16/24/32) to the key size index (0/1/2) */

 Convert the key size (16/24/32) to the key size index (0/1/2) */

	/*

	 * SA2UL has an interesting feature where the receive DMA channel

	 * is selected based on the data passed to the engine. Within the

	 * transition range, there is also a space where it is impossible

	 * to determine where the data will end up, and this should be

	 * avoided. This will be handled by the SW fallback mechanism by

	 * the individual algorithm implementations.

	/*

	 * Map the packets, first we check if the data fits into a single

	 * sg entry and use that if possible. If it does not fit, we check

	 * if we need to do sg_split to align the scatterlist data on the

	 * actual data size being processed by the crypto engine.

	/*

	 * Prepare metadata for DMA engine. This essentially describes the

	 * crypto algorithm to be used, data sizes, different keys etc.

 Use SW fallback if the data size is not supported */

 Setup Encryption Security Context & Command label template */

 for fallback */

 AEAD algorithm configuration interface function */

 Convert the key size (16/24/32) to the key size index (0/1/2) */

 Setup Encryption Security Context & Command label template */

 Setup Decryption Security Context & Command label template */

 AEAD algorithm encrypt interface function */

 AEAD algorithm decrypt interface function */

 Register the algorithms in crypto framework */

 Skip unsupported algos */

 Unregister the algorithms in crypto framework */

 Setup dma pool for security context buffers */

 SPDX-License-Identifier: GPL-2.0-only

/* 

 * Cryptographic API.

 *

 * Support for VIA PadLock hardware crypto engine.

 *

 * Copyright (c) 2004  Michal Ludvig <michal@logix.cz>

 *

/*

 * Number of data blocks actually fetched for each xcrypt insn.

 * Processors with prefetch errata will fetch extra blocks.

 Control word. */

/* Whenever making any changes to the following

 * structure *make sure* you keep E, d_data

 * and cword aligned on 16 Bytes boundaries and

 * the Hardware can access 16 * 16 bytes of E and d_data

 * (only the first 15 * 16 bytes matter but the HW reads

 * more).

/* Tells whether the ACE is capable to generate

	/* TODO: We should check the actual CPU model/stepping

	         as it's possible that the capability will be

	/*

	 * If the hardware is capable of generating the extended key

	 * itself we must supply the plain key for both encryption

	 * and decryption.

 Prepare control words. */

 Don't generate extended keys if the hardware can do it. */

 ====== Encryption/decryption routines ====== */

 These are the real call to PadLock. */

/*

 * While the padlock instructions don't use FP/SSE registers, they

 * generate a spurious DNA fault when CR0.TS is '1'.  Fortunately,

 * the kernel doesn't use CR0.TS.

 rep xcryptecb */

 rep xcryptcbc */

	/*

	 * Padlock prefetches extra data so we must provide mapped input buffers.

	 * Assume there are at least 16 bytes of stack already in use.

	/*

	 * Padlock prefetches extra data so we must provide mapped input buffers.

	 * Assume there are at least 16 bytes of stack already in use.

	/* Padlock in ECB mode fetches at least ecb_fetch_bytes of data.

	 * We could avoid some copying here but it's probably not worth it.

 Padlock in CBC mode fetches at least cbc_fetch_bytes of data. */

 rep xcryptecb */

 rep xcryptecb */

 rep xcryptcbc */

 rep xcryptcbc */

 SPDX-License-Identifier: GPL-2.0

/*

 * Cryptographic API.

 *

 * Support for ATMEL DES/TDES HW acceleration.

 *

 * Copyright (c) 2012 Eukréa Electromatique - ATMEL

 * Author: Nicolas Royer <nicolas@eukrea.com>

 *

 * Some ideas are from omap-aes.c drivers.

 TDES flags  */

 Reserve bits [17:16], [13:12], [2:0] for AES Mode Register */

 One TDES IP per SoC. */

 dma_lch_out - completed */

 MR register must be set before IV registers */

 copy data */

 MAP here */

 Enable Interrupt */

 Start DMA transfer */

 check for alignment */

 use cache buffers */

 assign new request to device */

 des_task will not finish it, so do it here */

 copy data */

 Try to grab 2 DMA channels */

 DMA started. Not fininishing. */

 keep only major version number */

 sentinel */ }

 Get the base address */

 Get the IRQ */

 Initializing the clock */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * AMCC SoC PPC4xx Crypto Driver

 *

 * Copyright (c) 2008 Applied Micro Circuits Corporation.

 * All rights reserved. James Hsiao <jhsiao@amcc.com>

 *

 * This file implements AMCC crypto offload Linux device driver for use with

 * Linux CryptoAPI.

/*

 * PPC4xx Crypto Engine Initialization Routine

 setup pe dma, include reset sg, pdr and pe, then release reset */

 un reset pe,sg and pdr */

 un reset pe,sg and pdr */

clear all pending interrupt*/

/*

 * alloc memory for the gather ring

 * no need to alloc buf for the ring

 * gdr_tail, gdr_head and gdr_count are initialized by this function

 alloc 256 bytes which is enough for any kind of dynamic sa */

 alloc state record */

/*

 * alloc memory for the gather ring

 * no need to alloc buf for the ring

 * gdr_tail, gdr_head and gdr_count are initialized by this function

/*

 * when this function is called.

 * preemption or interrupt must be disabled

/*

 * alloc memory for the scatter ring

 * need to alloc buf for the ring

 * sdr_tail, sdr_head and sdr_count are initialized by this function

 alloc memory for scatter descriptor ring */

/*

 * when this function is called.

 * preemption or interrupt must be disabled

 the head = tail, or empty case is already take cared */

	/*

	 * Because the scatter buffers are all neatly organized in one

	 * big continuous ringbuffer; scatterwalk_map_and_copy() can

	 * be instructed to copy a range of buffers in one go.

 append icv at the end */

 check icv at the end */

	/*

	 * There's a very subtile/disguised "bug" in the hardware that

	 * gets indirectly mentioned in 18.1.3.5 Encryption/Decryption

	 * of the hardware spec:

	 * *drum roll* the AES/(T)DES OFB and CFB modes are listed as

	 * operation modes for >>> "Block ciphers" <<<.

	 *

	 * To workaround this issue and stop the hardware from causing

	 * "overran dst buffer" on crypttexts that are not a multiple

	 * of 16 (AES_BLOCK_SIZE), we force the driver to use the

	 * scatter buffers.

 figure how many gd are needed */

 figure how many sd are needed */

	/*

	 * The follow section of code needs to be protected

	 * The gather ring and scatter ring needs to be consecutive

	 * In case of run out of any kind of descriptor, the descriptor

	 * already got must be return the original place.

	/*

	 * Let the caller know to slow down, once more than 13/16ths = 81%

	 * of the available data contexts are being used simultaneously.

	 *

	 * With PPC4XX_NUM_PD = 256, this will leave a "backlog queue" for

	 * 31 more contexts. Before new requests have to be rejected.

		/*

		 * To fix contention issues between ipsec (no blacklog) and

		 * dm-crypto (backlog) reserve 32 entries for "no backlog"

		 * data contexts.

 get first gd we are going to use */

 enable gather */

 walk the sg, and setup gather array */

		/*

		 * Disable gather in sa command

		/*

		 * Indicate gather array is not used

		/*

		 * we know application give us dst a whole piece of memory

		 * no need to use scatter ring.

 setup scatter descriptor */

 sd->ptr should be setup by sd_init routine*/

 setup scatter descriptor */

				/*

				 * SD entry can hold PPC4XX_SD_BUFFER_SIZE,

				 * which is more than nbytes, so done.

 write any value to push engine to read a pd */

/*

 * Algorithm Registration Functions

 if tail not done, break */

/*

 * Top Half of isr.

 trigger PRN generation */

 usually 19 iterations are enough */

 copy only remaining bytes */

/*

 * Supported Crypto Algorithms

 Crypto AES modes */

 AEAD */

/*

 * Module Initialization Routine

	/*

	 * Older version of 460EX/GT have a hardware bug.

	 * Hence they do not support H/W based security intr coalescing

 Init tasklet for bottom half processing */

 Register for Crypto isr, Crypto Engine IRQ */

 need to setup pdr, rdr, gdr and sdr before this */

 Register security algorithms with Linux CryptoAPI */

 Un-register with Linux CryptoAPI */

 Free all allocated memory */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * AMCC SoC PPC4xx Crypto Driver

 *

 * Copyright (c) 2008 Applied Micro Circuits Corporation.

 * All rights reserved. James Hsiao <jhsiao@amcc.com>

 *

 * This file implements the Linux crypto algorithms.

/*

 * AES Functions

 Create SA */

 Setup SA */

	/*

	 * SA_OPCODE_ENCRYPT is the same value as SA_OPCODE_DECRYPT.

	 * it's the DIR_(IN|OUT)BOUND that matters

	/*

	 * The hardware uses only the last 32-bits as the counter while the

	 * kernel tests (aes_ctr_enc_tv_template[4] for example) expect that

	 * the whole IV is a counter.  So fallback if the counter is going to

	 * overlow.

 authsize has to be a multiple of 4 */

	/*

	 * hardware does not handle cases where plaintext

	 * is less than a block.

 assoc len needs to be a multiple of 4 and <= 1020 */

 CCM supports only counter field length of 2 and 4 bytes */

/*

 * AES-CCM Functions

 Setup SA */

 CRYPTO_MODE_AES_ICM */

/*

 * AES-GCM Functions

/*

 * HASH SHA1 Functions

 Create SA */

 Need to zero hash digest in SA */

/*

 * SHA1 Algorithm

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Generic PowerPC 44x RNG driver

 *

 * Copyright 2011 IBM Corporation

 Find the TRNG device node and map it */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *   Driver for ARTPEC-6 crypto block using the kernel asynchronous crypto api.

 *

 *    Copyright (C) 2014-2017  Axis Communications AB

 Max length of a line in all cache levels for Artpec SoCs. */

 DMA metadata constants */

 DMA descriptor structures */

 Each descriptor array can hold max 64 entries */

 Hash modes (including HMAC variants) */

 Crypto modes */

/* The PDMA is a DMA-engine tightly coupled with a ciphering engine.

 * It operates on a descriptor array with up to 64 descriptor entries.

 * The arrays must be 64 byte aligned in memory.

 *

 * The ciphering unit has no registers and is completely controlled by

 * a 4-byte metadata that is inserted at the beginning of each dma packet.

 *

 * A dma packet is a sequence of descriptors terminated by setting the .eop

 * field in the final descriptor of the packet.

 *

 * Multiple packets are used for providing context data, key data and

 * the plain/ciphertext.

 *

 *   PDMA Descriptors (Array)

 *  +------+------+------+~~+-------+------+----

 *  |  0   |  1   |  2   |~~| 11 EOP|  12  |  ....

 *  +--+---+--+---+----+-+~~+-------+----+-+----

 *     |      |        |       |         |

 *     |      |        |       |         |

 *   __|__  +-------++-------++-------+ +----+

 *  | MD  | |Payload||Payload||Payload| | MD |

 *  +-----+ +-------++-------++-------+ +----+

	/* buf is aligned to ARTPEC_CACHE_LINE_MAX and

	 * holds up to ARTPEC_CACHE_LINE_MAX bytes data.

 Enough maps for all out/in buffers, and all three descr. arrays */

 waiting for pdma fifo space */

 submitted to pdma fifo */

 cache-aligned block padding buffer */

 The crypto framework makes it hard to avoid this global. */

 Make descriptor content visible to the DMA before starting it. */

/** artpec6_crypto_setup_out_descr_phys - Setup an out channel with a

 *                                        physical address

 *

 * @addr: The physical address of the data buffer

 * @len:  The length of the data buffer

 * @eop:  True if this is the last buffer in the packet

 *

 * @return 0 on success or -ENOSPC if there are no more descriptors available

/** artpec6_crypto_setup_out_descr_short - Setup a short out descriptor

 *

 * @dst: The virtual address of the data

 * @len: The length of the data, must be between 1 to 7 bytes

 * @eop: True if this is the last buffer in the packet

 *

 * @return 0 on success

 *	-ENOSPC if no more descriptors are available

 *	-EINVAL if the data length exceeds 7 bytes

 We only read one stat descriptor */

	/*

	 * DMA_BIDIRECTIONAL since we need our zeroing of the stat descriptor

	 * to be written.

/** artpec6_crypto_setup_out_descr - Setup an out descriptor

 *

 * @dst: The virtual address of the data

 * @len: The length of the data

 * @eop: True if this is the last buffer in the packet

 * @use_short: If this is true and the data length is 7 bytes or less then

 *	a short descriptor will be used

 *

 * @return 0 on success

 *	Any errors from artpec6_crypto_setup_out_descr_short() or

 *	setup_out_descr_phys()

/** artpec6_crypto_setup_in_descr_phys - Setup an in channel with a

 *                                       physical address

 *

 * @addr: The physical address of the data buffer

 * @len:  The length of the data buffer

 * @intr: True if an interrupt should be fired after HW processing of this

 *	  descriptor

 *

/** artpec6_crypto_setup_in_descr - Setup an in channel descriptor

 *

 * @buffer: The virtual address to of the data buffer

 * @len:    The length of the data buffer

 * @last:   If this is the last data buffer in the request (i.e. an interrupt

 *	    is needed

 *

 * Short descriptors are not used for the in channel

		/* When destination buffers are not aligned to the cache line

		 * size we need bounce buffers. The DMA-API requires that the

		 * entire line is owned by the DMA buffer and this holds also

		 * for the case when coherent DMA is used.

/** artpec6_crypto_terminate_out_descrs - Set the EOP on the last out descriptor

 *

 * If the out descriptor list is non-empty, then the eop flag on the

 * last used out descriptor will be set.

 *

 * @return  0 on success

 *	-EINVAL if the out descriptor is empty or has overflown

/** artpec6_crypto_terminate_in_descrs - Set the interrupt flag on the last

 *                                       in descriptor

 *

 * See artpec6_crypto_terminate_out_descrs() for return values

/** create_hash_pad - Create a Secure Hash conformant pad

 *

 * @dst:      The destination buffer to write the pad. Must be at least 64 bytes

 * @dgstlen:  The total length of the hash digest in bytes

 * @bitcount: The total length of the digest in bits

 *

 * @return The total number of padding bytes written to @dst

/*

 * Ciphering functions.

	/*

	 * The hardware uses only the last 32-bits as the counter while the

	 * kernel tests (aes_ctr_enc_tv_template[4] for example) expect that

	 * the whole IV is a counter.  So fallback if the counter is going to

	 * overlow.

/*

 * AEAD functions

 Upload HMAC key, must be first the first packet */

 Copy and pad up the key */

 Restore context */

 If this is the final round, set the final flag */

 If this is the final round, set the final flag */

 Setup up metadata descriptors */

			/* We have a partial buffer and will at least some bytes

			 * to the HW. Empty this partial buffer before tackling

			 * the SG lists

 Reset partial buffer */

 Finalize */

 Write out the partial buffer if present */

 Add the hash pad */

 Descriptor for the final result */

 This is not the final operation for this request */

 Save the result to the context */

 fall through */

/** artpec6_crypto_process_crypto - Prepare an async block cipher crypto request

 *

 * @req: The asynch request to process

 *

 * @return 0 if the dma job was successfully prepared

 *	  <0 on error

 *

 * This function sets up the PDMA descriptors for a block cipher request.

 *

 * The required padding is added for AES-CTR using a statically defined

 * buffer.

 *

 * The PDMA descriptor list will be as follows:

 *

 * OUT: [KEY_MD][KEY][EOP]<CIPHER_MD>[IV]<data_0>...[data_n][AES-CTR_pad]<eop>

 * IN:  <CIPHER_MD><data_0>...[data_n]<intr>

 *

 Same as regk_crypto_key_128 for NULL crypto */

 Metadata */

 Data out */

 Data in */

 CTR-mode padding required by the HW. */

 Key */

 For the decryption, cryptlen includes the tag. */

 Prepare the context buffer */

 The HW omits the initial increment of the counter field.

 Associated data */

 The HW mandates zero padding here */

 Data to crypto */

 The HW mandates zero padding here */

 Data from crypto */

 skip associated data in the output */

 Put padding between the cryptotext and the auth tag */

		/* The authentication tag shall follow immediately after

		 * the output ciphertext. For decryption it is put in a context

		 * buffer for later compare against the input tag.

			/* For encryption the requested tag size may be smaller

			 * than the hardware's generated tag.

	/*

	 * In some cases, the hardware can raise an in_eop_flush interrupt

	 * before actually updating the status, so we have an timer which will

	 * recheck the status on timeout.  Since the cases are expected to be

	 * very rare, we use a relatively large timeout value.  There should be

	 * no noticeable negative effect if we timeout spuriously.

		/* A non-zero final status descriptor indicates

		 * this job has finished.

 Allow testing of timeout handling with fault injection */

	/* Perform the completion callbacks without holding the queue lock

	 * to allow new request submissions from the callbacks.

 Verify GCM hashtag. */

------------------- Hash functions -----------------------------------------*/

	/*

	 * The PDMA unit contains 1984 bytes of internal memory for the OUT

	 * channels and 1024 bytes for the IN channel. This is an elastic

	 * memory used to internally store the descriptors and data. The values

	 * ares specified in 64 byte incremements.  Trustzone buffers are not

	 * used at this stage.

 1024 bytes for data */

 960 bytes for descriptors */

 512 bytes for data */

 256 bytes for descriptors */

 256 bytes for stat descrs */

	/* We get two interrupt notifications from each job.

	 * The in_data means all data was sent to memory and then

	 * we request a status flush command to write the per-job

	 * status to its status vector. This ensures that the

	 * tasklet can detect exactly how many submitted jobs

	 * that have finished.

------------------- Algorithm definitions ----------------------------------*/

 Hashes */

 SHA-1 */

 SHA-256 */

 HMAC SHA-256 */

 Crypto */

 AES - ECB */

 AES - CTR */

 AES - CBC */

 AES - XTS */

 SPDX-License-Identifier: GPL-2.0

/* Marvell OcteonTX CPT driver

 *

 * Copyright (C) 2019 Marvell International Ltd.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 Disable mbox(0) interrupts for all VFs */

 Enable mbox(0) interrupts for all VFs */

 Reset the PF when probed first */

 Check BIST status */

 Get max enabled cores */

 Get max VQs/VFs supported by the device */

 Disable all cores */

 Enable MSI-X */

 Register mailbox interrupt handlers */

 Enable mailbox interrupt */

 MAP PF's configuration registers */

 CPT device HW initialization */

 Register interrupts */

 Initialize engine groups */

 Disable VFs */

 Cleanup engine groups */

 Disable CPT PF interrupts */

 Disengage SE and AE cores from all groups */

 Supported devices */

 end of table */

 SPDX-License-Identifier: GPL-2.0

/* Marvell OcteonTX CPT driver

 *

 * Copyright (C) 2019 Marvell International Ltd.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 Size of salt in AES GCM mode */

 Size of IV in AES GCM mode */

 Size of ICV (Integrity Check Value) in AES GCM mode */

 Offset of IV in AES GCM mode */

 Truncated SHA digest size */

		/*

		 * On OcteonTX platform there is one CPT instruction queue bound

		 * to each VF. We get maximum performance if one CPT queue

		 * is available for each cpu otherwise CPT queues need to be

		 * shared between cpus.

		/*

		 * When selected cipher is NULL we need to manually

		 * verify whether calculated hmac value matches

		 * received hmac value

 Encryption data length */

 Authentication data length */

	/*

	 * Storing  Packet Data Information in offset

	 * Control Word First 8 bytes

	/*

	 * OUTPUT Buffer Processing

	 * AES encryption/decryption output would be

	 * received in the following format

	 *

	 * ------IV--------|------ENCRYPTED/DECRYPTED DATA-----|

	 * [ 16 Bytes/     [   Request Enc/Dec/ DATA Len AES CBC ]

 Validate that request doesn't exceed maximum CPT supported size */

 Clear control words */

	/*

	 * We perform an asynchronous send and once

	 * the request is completed the driver would

	 * intimate through registered call back functions

	/*

	 * Additional memory for skcipher_request is

	 * allocated since the cryptd daemon uses

	 * this memory for request_ctx information

	/*

	 * When selected cipher is NULL we use HMAC opcode instead of

	 * FLEXICRYPTO opcode therefore we don't need to use HASH algorithms

	 * for calculating ipad and opad

/*

 * This is the Integrity Check Value validation (aka the authentication tag

 * length)

	/*

	 * Partial Hash calculated from the software

	 * algorithm is retrieved for IPAD & OPAD

 IPAD Calculation */

 OPAD Calculation */

 Invalid key length */

	/*

	 * For aes gcm we expect to get encryption key (16, 24, 32 bytes)

	 * and salt (4 bytes)

 Invalid key and salt length */

 Store encryption key and salt */

 Copy encryption key to context */

 Copy IV to context */

 Copy encryption key to context */

 Copy salt to context */

 Unknown cipher type */

	/*

	 * Storing Packet Data Information in offset

	 * Control Word First 8 bytes

 Add authentication key */

	/*

	 * If source and destination are different

	 * then copy payload to destination

		/*

		 * In an encryption scenario hmac needs

		 * to be appended after payload

		/*

		 * In a decryption scenario calculated hmac for received

		 * payload needs to be compare with hmac received

 Clear control words */

 Validate that request doesn't exceed maximum CPT supported size */

	/*

	 * We perform an asynchronous send and once

	 * the request is completed the driver would

	 * intimate through registered call back functions

 SPDX-License-Identifier: GPL-2.0

/* Marvell OcteonTX CPT driver

 *

 * Copyright (C) 2019 Marvell International Ltd.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 Writing mbox(1) causes interrupt */

 Interrupt handler to handle mailbox messages from VFs */

	/*

	 * MBOX[0] contains msg

	 * MBOX[1] contains data

 Wait for previous message to be acked, timeout 2sec */

/*

 * Checks if VF is able to comminicate with PF

 * and also gets the CPT number this VF is associated to.

/*

 * Communicate VQs size to PF to program CPT(0)_PF_Q(0-15)_CTL of the VF.

 * Must be ACKed.

/*

 * Communicate VF group required to PF and get the VQ binded to that group

 Convey group of the VF */

/*

 * Communicate VF group required to PF and get the VQ binded to that group

 Convey group of the VF */

/*

 * Communicate to PF that VF is UP and running

/*

 * Communicate to PF that VF is DOWN and running

 SPDX-License-Identifier: GPL-2.0

/* Marvell OcteonTX CPT driver

 *

 * Copyright (C) 2019 Marvell International Ltd.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 Tar archive defines */

 tar header as defined in POSIX 1003.1-1990. */

	/*

	 * Set UCODE_BASE only for the cores which are not used,

	 * other cores should have already valid UCODE_BASE set

 Detach the cores from group */

 Wait for cores to become idle */

 Disable the cores only if they are not used anymore */

 Attach the cores to the group */

 Enable the cores */

	/*

	 * If size is less than microcode header size then don't report

	 * an error because it might not be microcode file, just process

	 * next file from archive

	/*

	 * If microcode version can't be found don't report an error

	 * because it might not be microcode file, just process next file

 Load tar archive */

 Read current file size */

 Check for the end of the archive */

 Read next block from tar archive */

 Validate if a number of requested engines is available */

 Reserve requested engines for this engine group */

  Allocate DMAable space */

 Byte swap 64-bit */

  Ucode needs 16-bit swap */

 Unload ucode used by this engine group */

 Setup fields for engine group which is mirrored */

 Setup fields for mirroring engine group */

		/*

		 * If mirrored group has this type of engines attached then

		 * there are 3 scenarios possible:

		 * 1) mirrored_engs.count == engs[i].count then all engines

		 * from mirrored engine group will be shared with this engine

		 * group

		 * 2) mirrored_engs.count > engs[i].count then only a subset of

		 * engines from mirrored engine group will be shared with this

		 * engine group

		 * 3) mirrored_engs.count < engs[i].count then all engines

		 * from mirrored engine group will be shared with this group

		 * and additional engines will be reserved for exclusively use

		 * by this engine group

 Removing engine group mirroring if enabled */

 Disable engine group */

 Release all engines held by this engine group */

 Verify that ucode loaded supports requested engine types */

 Validate if requested engine types are supported by this device */

 Find engine group which is not used */

 Load ucode */

 Validate scenario where 1 ucode is used */

 Check if this group mirrors another existing engine group */

 Setup mirroring */

		/*

		 * Update count of requested engines because some

		 * of them might be shared with mirrored group

 Reserve engines */

 Update ucode pointers used by engines */

 Update engine masks used by this group */

 Create sysfs entry for engine group info */

 Enable engine group */

	/*

	 * If this engine group mirrors another engine group

	 * then we need to unload ucode as we will use ucode

	 * from mirrored engine group

 Validate input parameters */

 create engine group */

 delete engine group */

	/*

	 * We don't create engine group for kernel crypto if attempt to create

	 * it was already made (when user enabled VFs for the first time)

 We create group for kcrypto only if no groups are configured */

	/*

	 * If device supports SE engines and there is SE microcode in tar

	 * archive try to create engine group with SE engines for kernel

	 * crypto functionality (symmetric crypto)

	/*

	 * If device supports AE engines and there is AE microcode in tar

	 * archive try to create engine group with AE engines for asymmetric

	 * crypto functionality.

 Disengage the cores from groups */

 Disable the cores */

 First delete all mirroring engine groups */

 Delete remaining engine groups */

 Release memory */

 OcteonTX 83XX SE CPT PF has only SE engines attached */

 OcteonTX 83XX AE CPT PF has only AE engines attached */

 SPDX-License-Identifier: GPL-2.0

/* Marvell OcteonTX CPT driver

 *

 * Copyright (C) 2019 Marvell International Ltd.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 Completion code size and initial value */

 SG list header size in bytes */

 Default timeout when waiting for free pending entry in us */

 Default threshold for stopping and resuming sender requests */

 Setup gather (input) components */

	/*

	 * Get buffer for union otx_cpt_res_s response

	 * structure and its physical address

 Create and initialize RPTR */

/*

 * On OcteonTX platform the parameter db_count is used as a count for ringing

 * door bell. The valid values for db_count are:

 * 0 - 1 CPT instruction will be enqueued however CPT will not be informed

 * 1 - 1 CPT instruction will be enqueued and CPT will be informed

	/*

	 * cpt_send_cmd is currently called only from critical section

	 * therefore no locking is required for accessing instruction queue

 make sure all memory stores are done before ringing doorbell */

	/*

	 * Check if we are close to filling in entire pending queue,

	 * if so then tell the sender to stop/sleep by returning -EBUSY

	 * We do it only for context which can sleep (GFP_KERNEL)

 Fill in the command */

 Fill in the CPT_INST_S type command for HW interpretation */

 Print debug info if enabled */

 Send CPT command */

	/*

	 * We allocate and prepare pending queue entry in critical section

	 * together with submitting CPT instruction to CPT instruction queue

	 * to make sure that order of CPT requests is the same in both

	 * pending and instruction queues

 check for timeout */

 Check microcode completion code */

			/*

			 * If requested hmac is truncated and ucode returns

			 * s/g write length error then we report success

			 * because ucode writes as many bytes of calculated

			 * hmac as available in gather buffer and reports

			 * s/g write length error if number of bytes in gather

			 * buffer is less than full hmac size.

 Request has been processed with success */

		/*

		 * Check if we should inform sending side to resume

		 * We do it CPT_IQ_RESUME_MARGIN elements in advance before

		 * pending queue becomes empty

				/*

				 * EINPROGRESS is an indication for sending

				 * side that it can resume sending requests

		/*

		 * Call callback after current pending entry has been

		 * processed, we don't do it if the callback pointer is

		 * invalid.

 SPDX-License-Identifier: GPL-2.0

/* Marvell OcteonTX CPT driver

 *

 * Copyright (C) 2019 Marvell International Ltd.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 Writing mbox(0) causes interrupt */

/*

 * ACKs VF's mailbox message

 * @vf: VF to which ACK to be sent

 NACKs VF's mailbox message that PF is not able to complete the action */

 W1C for the VF */

/*

 * Configure QLEN/Chunk sizes for VF

/*

 * Configure VQ priority

 Interrupt handler to handle mailbox messages from VFs */

	/*

	 * MBOX[0] contains msg

	 * MBOX[1] contains data

 First msg in VF teardown sequence */

 SPDX-License-Identifier: GPL-2.0

/* Marvell OcteonTX CPT driver

 *

 * Copyright (C) 2019 Marvell International Ltd.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 free single queue */

 init queue spin lock */

 clean up for each queue */

 Qsize in dwords, needed for SADDR config, 1-next chunk pointer */

 Qsize in bytes to create space for alignment */

 per queue initialization */

		/*

		 * Make the queue circular, tie back last chunk entry to head

 setup command queues */

 possible cpus */

 Create worker threads for BH processing */

 Num of Instructions * 8 words */

 Enable SWERR interrupts for the requested VF */

 Enable MBOX interrupt for the requested VF */

 Enable DONE interrupt for the requested VF */

 W1C for the VF */

 W1C for the VF */

 W1C for the VF */

 W1C for the VF */

 W1C for the VF */

 Check for MISC interrupt types */

 Clear doorbell count */

 Read the number of completions */

		/*

		 * Acknowledge the number of scheduled completions for

		 * processing

 Disable the VQ */

 Reset the doorbell */

 Clear inflight */

 Write VQ SADDR */

 Configure timerhold / coalescence */

 Enable the VQ */

 Flag the VF ready */

 MAP PF's configuration registers */

 Enable mailbox interrupt */

 Check cpt pf status, gets chip ID / device Id from PF if ready */

 CPT VF software resources initialization */

 Convey VQ LEN to PF */

 CPT VF device initialization */

 Send msg to PF to assign currnet Q to required group */

 Enable done interrupt */

 Set irq affinity masks */

 Initialize algorithms and set ops */

 Convey DOWN to PF */

 Supported devices */

 end of table */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cipher algorithms supported by the CESA: DES, 3DES and AES.

 *

 * Author: Boris Brezillon <boris.brezillon@free-electrons.com>

 * Author: Arnaud Ebalard <arno@natisbad.org>

 *

 * This work is based on an initial version written by

 * Sebastian Andrzej Siewior < sebastian at breakpoint dot cc >

 FIXME: only update enc_len field */

 Add input transfers */

 Add dummy desc to launch the crypto operation */

 Add output transfers */

 Add output data for IV */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for Marvell's Cryptographic Engine and Security Accelerator (CESA)

 * that can be found on the following platform: Orion, Kirkwood, Armada. This

 * driver supports the TDMA engine on platforms on which it is available.

 *

 * Author: Boris Brezillon <boris.brezillon@free-electrons.com>

 * Author: Arnaud Ebalard <arno@natisbad.org>

 *

 * This work is based on an initial version written by

 * Sebastian Andrzej Siewior < sebastian at breakpoint dot cc >

 Limit of the crypto queue before reaching the backlog */

		/*

		 * TODO: avoid clearing the FPGA_INT_STATUS if this not

		 * relevant on some platforms.

 Process fetched requests */

 Launch the next pending request */

 Iterate over the complete queue */

		/*

		 * Not all platforms can gate the CESA clocks: do not complain

		 * if the clock does not exist.

 Set affinity */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hash algorithms supported by the CESA: MD5, SHA1 and SHA256.

 *

 * Author: Boris Brezillon <boris.brezillon@free-electrons.com>

 * Author: Arnaud Ebalard <arno@natisbad.org>

 *

 * This work is based on an initial version written by

 * Sebastian Andrzej Siewior < sebastian at breakpoint dot cc >

 Pad out to 56 mod 64 */

 FIXME: only update enc_len field */

 We must explicitly set the digest state. */

 Set the hash state in the IVDIG regs. */

		/*

		 * Result is already in the correct endianness when the SA is

		 * used

			/*

			 * Hardware's MD5 digest is in little endian format, but

			 * SHA in big endian format

 Set the operation block fragment length. */

 Append dummy desc to launch operation */

	/*

	 * If the transfer is smaller than our maximum length, and we have

	 * some data outstanding, we can ask the engine to finish the hash.

	/*

	 * The request is longer than the engine can handle, or we have

	 * no data outstanding. Manually generate the padding, adding it

	 * as a "mid" fragment.

	/*

	 * Add the cache (left-over data from a previous block) first.

	 * This will never overflow the SRAM size.

		/*

		 * Add all the new data, inserting an operation block and

		 * launch command between each full SRAM block-worth of

		 * data. We intentionally do not add the final op block.

 Account for the data that was in the cache. */

	/*

	 * At this point, frag_len indicates whether we have any data

	 * outstanding which needs an operation.  Queue up the final

	 * operation, which depends whether this is the final request.

	/*

	 * If results are copied via DMA, this means that this

	 * request can be directly processed by the engine,

	 * without partial updates. So we can chain it at the

	 * DMA level with other requests.

 Add dummy desc to wait for crypto operation end */

		/*

		 * Put the CESA_TDMA_SET_STATE flag on the first tdma desc to

		 * let the step logic know that the IVDIG registers should be

		 * explicitly set before launching a TDMA chain.

 Set the memory region to 0 to avoid any leak. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Provide TDMA helper functions used by cipher and hash algorithm

 * implementations.

 *

 * Author: Boris Brezillon <boris.brezillon@free-electrons.com>

 * Author: Arnaud Ebalard <arno@natisbad.org>

 *

 * This work is based on an initial version written by

 * Sebastian Andrzej Siewior < sebastian at breakpoint dot cc >

		/*

		 * Break the DMA chain if the CESA_TDMA_BREAK_CHAIN is set on

		 * the last element of the current chain, or if the request

		 * being queued needs the IV regs to be set before lauching

		 * the request.

			/*

			 * if req is NULL, this means we're processing the

			 * request in engine->req.

 Re-chaining to the next request */

 If this is the last request, clear the chain */

	/*

	 * Save the last request in error to engine->req, so that the core

	 * knows which request was faulty

	/* We re-use an existing op_desc object to retrieve the context

	 * and result instead of allocating a new one.

	 * There is at least one object of this type in a CESA crypto

	 * req, just pick the first one in the chain.

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

 Size of salt in AES GCM mode */

 Size of IV in AES GCM mode */

 Size of ICV (Integrity Check Value) in AES GCM mode */

 Offset of IV in AES GCM mode */

 Truncated SHA digest size */

	/*

	 * On OcteonTX2 platform CPT instruction queue is bound to each

	 * local function LF, in turn LFs can be attached to PF

	 * or VF therefore we always use first device. We get maximum

	 * performance if one CPT queue is available for each cpu

	 * otherwise CPT queues need to be shared between cpus.

			/*

			 * When selected cipher is NULL we need to manually

			 * verify whether calculated hmac value matches

			 * received hmac value

 Encryption data length */

 Authentication data length */

	/*

	 * Storing  Packet Data Information in offset

	 * Control Word First 8 bytes

	/*

	 * OUTPUT Buffer Processing

	 * AES encryption/decryption output would be

	 * received in the following format

	 *

	 * ------IV--------|------ENCRYPTED/DECRYPTED DATA-----|

	 * [ 16 Bytes/     [   Request Enc/Dec/ DATA Len AES CBC ]

 Clear control words */

	/*

	 * We perform an asynchronous send and once

	 * the request is completed the driver would

	 * intimate through registered call back functions

	/*

	 * Additional memory for skcipher_request is

	 * allocated since the cryptd daemon uses

	 * this memory for request_ctx information

	/*

	 * When selected cipher is NULL we use HMAC opcode instead of

	 * FLEXICRYPTO opcode therefore we don't need to use HASH algorithms

	 * for calculating ipad and opad

 Set authsize for fallback case */

	/*

	 * Partial Hash calculated from the software

	 * algorithm is retrieved for IPAD & OPAD

 IPAD Calculation */

 OPAD Calculation */

 Invalid key length */

	/*

	 * For aes gcm we expect to get encryption key (16, 24, 32 bytes)

	 * and salt (4 bytes)

 Invalid key and salt length */

 Store encryption key and salt */

 Copy encryption key to context */

 Copy IV to context */

 Copy encryption key to context */

 Copy salt to context */

 Unknown cipher type */

	/*

	 * Storing Packet Data Information in offset

	 * Control Word First 8 bytes

 Add authentication key */

	/*

	 * If source and destination are different

	 * then copy payload to destination

		/*

		 * In an encryption scenario hmac needs

		 * to be appended after payload

		/*

		 * In a decryption scenario calculated hmac for received

		 * payload needs to be compare with hmac received

 Store the cipher tfm and then use the fallback tfm */

 Clear control words */

	/*

	 * We perform an asynchronous send and once

	 * the request is completed the driver would

	 * intimate through registered call back functions

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

	/*

	 * Overwrite mbox mbase to point to bounce buffer, so that PF/VF

	 * prepare all mbox messages in bounce buffer instead of directly

	 * in hw mbox memory.

 Copy mbox messages from mbox memory to bounce buffer */

 Read the interrupt bits */

 Schedule work queue function to process the MBOX request */

 Clear and ack the interrupt */

 Check if resources were successfully attached */

 Check if resources were successfully detached */

 sync with mbox memory region */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

/*

 * CPT PF driver version, It will be incremented by 1 for every feature

 * addition in CPT mailbox messages.

 Check if msg is valid, if not reply with an invalid msg */

	/*

	 * Check which VF has raised an interrupt and schedule

	 * corresponding work queue to process the messages

 Read the interrupt bits */

 Clear the interrupt */

 sync with mbox memory region */

 Process received mbox messages */

 Set which VF sent this message based on mbox IRQ */

		/*

		 * Behave as the AF, drop the msg if there is

		 * no memory, timeout handling also goes here

 Send mbox responses to VF */

 Read the interrupt bits */

 Schedule work queue function to process the MBOX request */

 Clear and ack the interrupt */

 Handle mailbox messages received from AF */

 Sync mbox data into memory */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2021 Marvell. */

 tar_addr<6:4> = Size of first LMTST - 1 in units of 128b. */

	/*

	 * Make sure memory areas pointed in CPT_INST_S

	 * are flushed before the instruction is sent to CPT

 Copy CPT command to LMTLINE */

 Map VF LMILINE region */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

 Disable instruction queues */

 Set instruction queues base addresses */

 Set instruction queues sizes */

 Set done interrupts time wait */

 Set done interrupts num wait */

 Enable instruction queues */

 Disable instruction queues */

 Enable done interrupts */

 Enable Misc interrupts */

 Acknowledge interrupts */

 Read the number of completed requests */

 Acknowledge the number of completed requests */

 Schedule processing of completed requests */

 Send request to attach LFs */

	/*

	 * Allow each LF to execute requests destined to any of 8 engine

	 * groups and set queue priority of each LF to high

 Cleanup LFs hardware side */

 Send request to detach LFs */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

 Clear any pending interrupts */

 Enable VF interrupts for VFs from 0 to 63 */

 Enable VF interrupts for VFs from 64 to 127 */

 Disable VF-PF interrupts */

 Clear any pending interrupts */

 Clear FLR interrupt if any */

 Enable VF FLR interrupts */

 Clear ME interrupt if any */

 Enable VF ME interrupts */

 Disable VF FLR interrupts */

 Disable VF ME interrupts */

 Clear transaction pending register */

 Clear interrupt */

 Disable the interrupt */

 Clear interrupt */

 Register VF-PF mailbox interrupt handler */

 Register VF FLR interrupt handler */

 Register VF ME interrupt handler */

 Register VF FLR interrupt handler */

 Register VF FLR interrupt handler */

 Map VF-PF mailbox memory */

 Disable AF-PF interrupt */

 Clear interrupt if any */

 Register AF-PF mailbox interrupt handler */

 Clear interrupt if any, to avoid spurious interrupts */

 Enable AF-PF interrupt */

 Map AF-PF mailbox memory */

	/*

	 * Check if AF has setup revision for RVUM block, otherwise

	 * driver probe should be deferred until AF driver comes up

 check if 'implemented' bit is set for block BLKADDR_CPT1 */

 Reset the CPT PF device */

 Get number of SE, IE and AE engines */

 Disable all cores */

 Initialize VF<=>PF mailbox */

 Register VF<=>PF mailbox interrupt */

 Get CPT HW capabilities using LOAD_FVC operation. */

 Map PF's configuration registers */

 Check if AF driver is up, otherwise defer probe */

 Initialize AF-PF mailbox */

 Register mailbox interrupt */

 Initialize CPT PF device */

 Initialize engine groups */

 Delete sysfs entry created for kernel VF limits */

 Cleanup engine groups */

 Disable AF-PF mailbox interrupt */

 Destroy AF-PF mbox */

 Supported devices */

 end of table */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

 SG list header size in bytes */

 Default timeout when waiting for free pending entry in us */

 Default threshold for stopping and resuming sender requests */

 Default command timeout in seconds */

 Setup gather (input) components */

	/*

	 * Get buffer for union otx2_cpt_res_s response

	 * structure and its physical address

	/*

	 * Check if we are close to filling in entire pending queue,

	 * if so then tell the sender to stop/sleep by returning -EBUSY

	 * We do it only for context which can sleep (GFP_KERNEL)

 Fill in the command */

 64-bit swap for microcode data reads, not needed for addresses*/

 Fill in the CPT_INST_S type command for HW interpretation */

 Print debug info if enabled */

 Send CPT command */

	/*

	 * We allocate and prepare pending queue entry in critical section

	 * together with submitting CPT instruction to CPT instruction queue

	 * to make sure that order of CPT requests is the same in both

	 * pending and instruction queues

 check for timeout */

		/*

		 * Check microcode completion code, it is only valid

		 * when completion code is CPT_COMP_E::GOOD

			/*

			 * If requested hmac is truncated and ucode returns

			 * s/g write length error then we report success

			 * because ucode writes as many bytes of calculated

			 * hmac as available in gather buffer and reports

			 * s/g write length error if number of bytes in gather

			 * buffer is less than full hmac size.

 Request has been processed with success */

		/*

		 * Check if we should inform sending side to resume

		 * We do it CPT_IQ_RESUME_MARGIN elements in advance before

		 * pending queue becomes empty

				/*

				 * EINPROGRESS is an indication for sending

				 * side that it can resume sending requests

		/*

		 * Call callback after current pending entry has been

		 * processed, we don't do it if the callback pointer is

		 * invalid.

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

 Set PF number for microcode fetches */

		/*

		 * Set UCODE_BASE only for the cores which are not used,

		 * other cores should have already valid UCODE_BASE set

 Detach the cores from group */

 Wait for cores to become idle */

 Disable the cores only if they are not used anymore */

 Attach the cores to the group */

 Enable the cores */

 Request firmware for each engine type */

 Validate if a number of requested engines are available */

 Reserve requested engines for this engine group */

  Allocate DMAable space */

 Byte swap 64-bit */

  Ucode needs 16-bit swap */

 Point microcode to each core of the group */

 Attach the cores to the group and enable them */

 Disable all engines used by this group */

 Unload ucode used by this engine group */

 Clear UCODE_BASE register for each engine used by this group */

 Setup fields for engine group which is mirrored */

 Setup fields for mirroring engine group */

		/*

		 * If mirrored group has this type of engines attached then

		 * there are 3 scenarios possible:

		 * 1) mirrored_engs.count == engs[i].count then all engines

		 * from mirrored engine group will be shared with this engine

		 * group

		 * 2) mirrored_engs.count > engs[i].count then only a subset of

		 * engines from mirrored engine group will be shared with this

		 * engine group

		 * 3) mirrored_engs.count < engs[i].count then all engines

		 * from mirrored engine group will be shared with this group

		 * and additional engines will be reserved for exclusively use

		 * by this engine group

 Removing engine group mirroring if enabled */

 Disable engine group */

 Release all engines held by this engine group */

 Find engine group which is not used */

 Load ucode */

 Check if this group mirrors another existing engine group */

 Setup mirroring */

		/*

		 * Update count of requested engines because some

		 * of them might be shared with mirrored group

 Update ucode pointers used by engines */

 Update engine masks used by this group */

 Enable engine group */

	/*

	 * If this engine group mirrors another engine group

	 * then we need to unload ucode as we will use ucode

	 * from mirrored engine group

 First delete all mirroring engine groups */

 Delete remaining engine groups */

	/*

	 * We don't create engine groups if it was already

	 * made (when user enabled VFs for the first time)

	/*

	 * Create engine group with SE engines for kernel

	 * crypto functionality (symmetric crypto)

	/*

	 * Create engine group with SE+IE engines for IPSec.

	 * All SE engines will be shared with engine group 0.

	/*

	 * Create engine group with AE engines for asymmetric

	 * crypto functionality.

	/*

	 * Configure engine group mask to allow context prefetching

	 * for the groups.

	/*

	 * Set interval to periodically flush dirty data for the next

	 * CTX cache entry. Set the interval count to maximum supported

	 * value.

 Disengage the cores from groups */

 Wait for cores to become idle */

 Disable the cores */

 Release memory */

/*

 * Get CPT HW capabilities using LOAD_FVC operation.

	/*

	 * We don't get capabilities if it was already done

	 * (when user enabled VFs for the first time)

	/*

	 * Create engine groups for each type to submit LOAD_FVC op and

	 * get engine's capabilities.

 Fill in the command */

 64-bit swap for microcode data reads, not needed for addresses */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

 Clear interrupt if any */

 Enable PF-VF interrupt */

 Disable PF-VF interrupt */

 Clear interrupt if any */

 Enable MSI-X */

 Register VF<=>PF mailbox interrupt handler */

 Enable PF-VF mailbox interrupts */

		/* For cn10k platform, VF mailbox region is in its BAR2

		 * register space

 Map PF-VF mailbox memory */

 Initialize spin lock */

 Remove interrupts affinity */

 Disable instruction queue */

 Unregister crypto algorithms */

 Unregister LFs interrupts */

 Cleanup LFs software side */

 Send request to detach LFs */

 Get engine group number for symmetric crypto */

 Get msix offsets for attached LFs */

 Initialize LFs software side */

 Register LFs interrupts */

 Set interrupts affinity */

 Register crypto algorithms */

 Map VF's configuration registers */

 Initialize PF<=>VF mailbox */

 Register interrupts */

 Initialize CPT LFs */

 Disable PF-VF mailbox interrupt */

 Destroy PF-VF mbox */

 Supported devices */

 end of table */

 SPDX-License-Identifier: GPL-2.0-only

 Copyright (C) 2020 Marvell. */

 SPDX-License-Identifier: GPL-2.0

/*

 * amlogic-cipher.c - hardware cryptographic offloader for Amlogic GXL SoC

 *

 * Copyright (C) 2018-2019 Corentin LABBE <clabbe@baylibre.com>

 *

 * This file add support for AES cipher with 128,192,256 bits keysize in

 * CBC and ECB mode.

 KEY/IV descriptors use 3 desc */

	/*

	 * The hardware expect a list of meson_desc structures.

	 * The 2 first structures store key

	 * The third stores IV

 SPDX-License-Identifier: GPL-2.0

/*

 * amlgoic-core.c - hardware cryptographic offloader for Amlogic GXL SoC

 *

 * Copyright (C) 2018-2019 Corentin Labbe <clabbe@baylibre.com>

 *

 * Core file which registers crypto algorithms supported by the hardware.

/*

 * Allocate the channel list structure

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2020 Intel Corporation */

		/*

		 * If the accelerator is connected to a node with no memory

		 * there is no point in using the accelerator since the remote

		 * memory transaction will be very slow.

	/*

	 * Add accel device to accel table

	 * This should be called before adf_cleanup_accel is called

 Allocate and initialise device hardware meta-data structure */

 Get Accelerators and Accelerators Engines masks */

 If the device has no acceleration engines then ignore it */

 Create dev top level debugfs entry */

 Create device configuration table */

 Enable PCI device */

 Set DMA identifier */

 Get accelerator capabilities mask */

 Find and map all the device's BARS */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2020 Intel Corporation */

 Worker thread to service arbiter mappings */

/*

 * The vector routing table is used to select the MSI-X entry to use for each

 * interrupt source.

 * The first ADF_4XXX_ETR_MAX_BANKS entries correspond to ring interrupts.

 * The final entry corresponds to VF2PF or error interrupts.

 * This vector table could be used to configure one MSI-X entry to be shared

 * between multiple interrupt sources.

 *

 * The default routing is set to have a one to one correspondence between the

 * interrupt source and the MSI-X entry used.

 Read accelerator capabilities mask */

 Enable all in errsou3 except VFLR notification on host */

 Enable bundle interrupts */

 Enable misc interrupts */

 Temporarily mask PM interrupt */

 Set DRV_ACTIVE bit to power up the device */

 Poll status register to make sure the device is powered up */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Add accel device to accel table */

 Allocate and configure device configuration structure */

 Get Accelerators and Accelerators Engines masks */

 Create dev top level debugfs entry */

 Create device configuration table */

 enable PCI device */

 set dma identifier */

 Find and map all the device's BARS */

 Completion for VF2PF request/response message exchange */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2015 - 2020 Intel Corporation */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 convert to uword address */

 Do not free the list head unless we allocated it. */

 set the highest ustore address referenced */

 check if ctx is appropriate for the ctxMode */

 pub key */

 padding */

 exponent */

 signature */

 AE firmware */

 map uof objects */

 map suof objects */

 Parse MOF file chunks */

 All sym_objs uobjs and sobjs should be available */

 Seek specified uof object in MOF */

 load the page starting at appropriate ustore address */

 get fill-pattern from an image -- they are all the same */

 load the buffer */

 copy the buffer to ustore */

	/* load the default page and set assigned CTX PC

 find the slice to which this image is assigned */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Get any started device */

/**

 * qat_crypto_dev_config() - create dev config required to create crypto inst.

 *

 * @accel_dev: Pointer to acceleration device.

 *

 * Function creates device configuration required to create crypto instances

 *

 * Return: 0 on success, error code otherwise.

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2015 - 2020 Intel Corporation */

 lock preventing concurrent acces of CSR */

 Check if the PFVF CSR is in use by remote function */

 Attempt to get ownership of the PFVF CSR */

 Wait for confirmation from remote func it received the message */

 Finished with the PFVF CSR; relinquish it and leave msg in CSR */

/**

 * adf_iov_putmsg() - send PFVF message

 * @accel_dev:  Pointer to acceleration device.

 * @msg:	Message to send

 * @vf_nr:	VF number to which the message will be sent if on PF, ignored

 *		otherwise

 *

 * Function sends a message through the PFVF channel

 *

 * Return: 0 on success, error code otherwise.

/**

 * adf_send_pf2vf_msg() - send PF to VF message

 * @accel_dev:	Pointer to acceleration device

 * @vf_nr:	VF number to which the message will be sent

 * @msg:	Message to send

 *

 * This function allows the PF to send a message to a specific VF.

 *

 * Return: 0 on success, error code otherwise.

/**

 * adf_send_vf2pf_msg() - send VF to PF message

 * @accel_dev:	Pointer to acceleration device

 * @msg:	Message to send

 *

 * This function allows the VF to send a message to the PF.

 *

 * Return: 0 on success, error code otherwise.

/**

 * adf_send_vf2pf_req() - send VF2PF request message

 * @accel_dev:	Pointer to acceleration device.

 * @msg:	Request message to send

 *

 * This function sends a message that requires a response from the VF to the PF

 * and waits for a reply.

 *

 * Return: 0 on success, error code otherwise.

 Send request from VF to PF */

 Wait for response */

 Read message from the VF */

 To ACK, clear the VF2PFINT bit */

 Ignore legacy non-system (non-kernel) VF2PF messages */

 Set legacy major and minor version num */

 re-enable interrupt on PF from this VF */

 Response from PF received, check compatibility */

 VF is newer than PF and decides whether it is compatible */

/**

 * adf_enable_vf2pf_comms() - Function enables communication from vf to pf

 *

 * @accel_dev: Pointer to acceleration device virtual function.

 *

 * Return: 0 on success, error code otherwise.

/**

 * adf_enable_pf2vf_comms() - Function enables communication from pf to vf

 *

 * @accel_dev: Pointer to acceleration device virtual function.

 *

 * This function carries out the necessary steps to setup and start the PFVF

 * communication channel, if any.

 *

 * Return: 0 on success, error code otherwise.

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

/**

 * adf_cfg_dev_add() - Create an acceleration device configuration table.

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function creates a configuration table for the given acceleration device.

 * The table stores device specific config values.

 * To be used by QAT device specific drivers.

 *

 * Return: 0 on success, error code otherwise.

 accel_dev->debugfs_dir should always be non-NULL here */

/**

 * adf_cfg_dev_remove() - Clears acceleration device configuration table.

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function removes configuration table from the given acceleration device

 * and frees all allocated memory.

 * To be used by QAT device specific drivers.

 *

 * Return: void

/**

 * adf_cfg_add_key_value_param() - Add key-value config entry to config table.

 * @accel_dev:  Pointer to acceleration device.

 * @section_name: Name of the section where the param will be added

 * @key: The key string

 * @val: Value pain for the given @key

 * @type: Type - string, int or address

 *

 * Function adds configuration key - value entry in the appropriate section

 * in the given acceleration device

 * To be used by QAT device specific drivers.

 *

 * Return: 0 on success, error code otherwise.

/**

 * adf_cfg_section_add() - Add config section entry to config table.

 * @accel_dev:  Pointer to acceleration device.

 * @name: Name of the section

 *

 * Function adds configuration section where key - value entries

 * will be stored.

 * To be used by QAT device specific drivers.

 *

 * Return: 0 on success, error code otherwise.

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Initialize device id to NO DEVICE as 0 is a valid device id */

 First stop all VFs */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

	/*

	 * If no source is provided use g as base

		/*

		 * src can be of any size in valid range, but HW expects it to

		 * be the same as modulo p so in case it is different we need

		 * to allocate a new buf and copy src data.

		 * In other case we just need to map the user provided buffer.

		 * Also need to make sure that it is in contiguous buffer.

	/*

	 * dst can be of any size in valid range, but HW expects it to be the

	 * same as modulo m so in case it is different we need to allocate a

	 * new buf and copy src data.

	 * In other case we just need to map the user provided buffer.

	 * Also need to make sure that it is in contiguous buffer.

 Mapping in.in.b or in.in_g2.xa is the same */

 If g equals 2 don't copy it */

 Free old secret if any */

	/*

	 * src can be of any size in valid range, but HW expects it to be the

	 * same as modulo n so in case it is different we need to allocate a

	 * new buf and copy src data.

	 * In other case we just need to map the user provided buffer.

	 * Also need to make sure that it is in contiguous buffer.

	/*

	 * src can be of any size in valid range, but HW expects it to be the

	 * same as modulo n so in case it is different we need to allocate a

	 * new buf and copy src data.

	 * In other case we just need to map the user provided buffer.

	 * Also need to make sure that it is in contiguous buffer.

 invalid key size provided */

 p */

 q */

 dp */

 dq */

 qinv */

 Free the old key if any */

 invalid key provided */

 invalid private key provided */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 The base_addr has to be aligned to the size of the buffer */

 Enable HW arbitration for the given ring */

 Enable interrupts if needed */

 Disable interrupts for the given ring */

 Clear PCI config space */

 Disable HW arbitration for the given ring */

 Handle all the responses and reenable IRQs */

 Allocate the rings in the bank */

	/* Enable IRQ coalescing always. This will allow to use

	 * the optimised flag and coalesc register.

/**

 * adf_init_etr_data() - Initialize transport rings for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function is the initializes the communications channels (rings) to the

 * acceleration device accel_dev.

 * To be used by QAT device specific drivers.

 *

 * Return: 0 on success, error code otherwise.

 accel_dev->debugfs_dir should always be non-NULL here */

/**

 * adf_cleanup_etr_data() - Clear transport rings for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function is the clears the communications channels (rings) of the

 * acceleration device accel_dev.

 * To be used by QAT device specific drivers.

 *

 * Return: void

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2020 Intel Corporation */

	/* Convert 64bit WDT timer value into 32bit values for

	 * mmio write to 32bit CSRs.

 Enable WDT for sym and dc */

 Enable WDT for pke */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2015 - 2020 Intel Corporation */

 This ptr will be populated when VFs will be created */

 Set Valid bits in AE Thread to PCIe Function Mapping */

 Enable VF to PF interrupts for all VFs */

	/*

	 * Due to the hardware design, when SR-IOV and the ring arbiter

	 * are enabled all the VFs supported in hardware must be enabled in

	 * order for all the hardware resources (i.e. bundles) to be usable.

	 * When SR-IOV is enabled, each of the VFs will own one bundle.

/**

 * adf_disable_sriov() - Disable SRIOV for the device

 * @accel_dev:  Pointer to accel device.

 *

 * Function disables SRIOV for the accel device.

 *

 * Return: 0 on success, error code otherwise.

 Disable VF to PF interrupts */

 Clear Valid bits in AE Thread to PCIe Function Mapping */

/**

 * adf_sriov_configure() - Enable SRIOV for the device

 * @pdev:  Pointer to PCI device.

 * @numvfs: Number of virtual functions (VFs) to enable.

 *

 * Note that the @numvfs parameter is ignored and all VFs supported by the

 * device are enabled due to the design of the hardware.

 *

 * Function enables SRIOV for the PCI device.

 *

 * Return: number of VFs enabled on success, error code otherwise.

 Allocate memory for VF info structs */

 Workqueue for PF2VF responses */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 protects adf_admin_comms struct */

 Response timeout */

		/* Response received from admin message, we can now

		 * make response data available in "out" parameter.

/**

 * adf_send_admin_init() - Function sends init message to FW

 * @accel_dev: Pointer to acceleration device.

 *

 * Function sends admin init message to the FW

 *

 * Return: 0 on success, error code otherwise.

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 ensure at least 8 time cycles elapsed in wait_cycles */

 Sets the accelaration engine context mode to either four or eight */

 stop the timestamp timers */

 start timestamp timers */

 write to the reset csr */

 enable clock */

 Set undefined power-up/reset states to reasonable default values */

 clear the ecc bits */

 wait for AE to finish */

 create AE objects */

 Set SIGNATURE_ENABLE[0] to 0x1 in order to enable ALU_OUT csr */

 take all AEs out of reset */

 save current context */

 execute micro codes */

 wait for micro codes to finish */

 retore to saved context */

 delay for at least 8 cycles */

	/*

	 * read ALU output

	 * the instruction should have been executed

	 * prior to clearing the ECS in putUwords

 exec micro codes */

 4-ctx mode */

 8-ctx mode */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 If SR-IOV is enabled (vf_info is non-NULL), check for VF->PF ints */

 Get the interrupt sources triggered by VFs */

 Disable VF2PF interrupts for VFs with pending ints */

			/*

			 * Handle VF2PF interrupt unless the VF is malicious and

			 * is attempting to flood the host OS with VF2PF interrupts.

 CONFIG_PCI_IOV */

 Request msix irq for all banks unless SR-IOV enabled */

 Request msix irq for AE */

 If SR-IOV is disabled (vf_info is NULL), add entries for each bank */

/**

 * adf_isr_resource_free() - Free IRQ for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function frees interrupts for acceleration device.

/**

 * adf_isr_resource_alloc() - Allocate IRQ for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function allocates interrupts for acceleration device.

 *

 * Return: 0 on success, error code otherwise.

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 reset dev data */

 The device hanged and we can't restart it so stop here */

 The dev is back alive. Notify the caller if in sync mode */

 If in sync mode wait for the result */

 Maximum device reset time is 10 seconds */

/**

 * adf_enable_aer() - Enable Advance Error Reporting for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function enables PCI Advance Error Reporting for the

 * QAT acceleration device accel_dev.

 * To be used by QAT device specific drivers.

/**

 * adf_disable_aer() - Disable Advance Error Reporting for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function disables PCI Advance Error Reporting for the

 * QAT acceleration device accel_dev.

 * To be used by QAT device specific drivers.

 *

 * Return: void

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

/**

 * adf_clean_vf_map() - Cleans VF id mapings

 *

 * Function cleans internal ids for virtual functions.

 * @vf: flag indicating whether mappings is cleaned

 *	for vfs only or for vfs and pfs

/**

 * adf_devmgr_update_class_index() - Update internal index

 * @hw_data:  Pointer to internal device data.

 *

 * Function updates internal dev index for VFs

/**

 * adf_devmgr_add_dev() - Add accel_dev to the acceleration framework

 * @accel_dev:  Pointer to acceleration device.

 * @pf:		Corresponding PF if the accel_dev is a VF

 *

 * Function adds acceleration device to the acceleration framework.

 * To be used by QAT device specific drivers.

 *

 * Return: 0 on success, error code otherwise.

 PF on host or VF on guest - optimized to remove redundant is_vf */

 VF on host */

/**

 * adf_devmgr_rm_dev() - Remove accel_dev from the acceleration framework.

 * @accel_dev:  Pointer to acceleration device.

 * @pf:		Corresponding PF if the accel_dev is a VF

 *

 * Function removes acceleration device from the acceleration framework.

 * To be used by QAT device specific drivers.

 *

 * Return: void

 PF on host or VF on guest - optimized to remove redundant is_vf */

/**

 * adf_devmgr_pci_to_accel_dev() - Get accel_dev associated with the pci_dev.

 * @pci_dev:  Pointer to PCI device.

 *

 * Function returns acceleration device associated with the given PCI device.

 * To be used by QAT device specific drivers.

 *

 * Return: pointer to accel_dev or NULL if not found.

/**

 * adf_dev_in_use() - Check whether accel_dev is currently in use

 * @accel_dev: Pointer to acceleration device.

 *

 * To be used by QAT device specific drivers.

 *

 * Return: 1 when device is in use, 0 otherwise.

/**

 * adf_dev_get() - Increment accel_dev reference count

 * @accel_dev: Pointer to acceleration device.

 *

 * Increment the accel_dev refcount and if this is the first time

 * incrementing it during this period the accel_dev is in use,

 * increment the module refcount too.

 * To be used by QAT device specific drivers.

 *

 * Return: 0 when successful, EFAULT when fail to bump module refcount

/**

 * adf_dev_put() - Decrement accel_dev reference count

 * @accel_dev: Pointer to acceleration device.

 *

 * Decrement the accel_dev refcount and if this is the last time

 * decrementing it during this period the accel_dev is in use,

 * decrement the module refcount too.

 * To be used by QAT device specific drivers.

 *

 * Return: void

/**

 * adf_devmgr_in_reset() - Check whether device is in reset

 * @accel_dev: Pointer to acceleration device.

 *

 * To be used by QAT device specific drivers.

 *

 * Return: 1 when the device is being reset, 0 otherwise.

/**

 * adf_dev_started() - Check whether device has started

 * @accel_dev: Pointer to acceleration device.

 *

 * To be used by QAT device specific drivers.

 *

 * Return: 1 when the device has started, 0 otherwise

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Common content descriptor */

 Encrypt content desc */

 Decrypt content desc */

 sufficient for SHA-1/SHA-256 as well */

 CD setup */

 Request setup */

 Cipher CD config setup */

 Auth CD config setup */

 CD setup */

 Request setup */

 Cipher CD config setup */

 Auth CD config setup */

		/* Store both XTS keys in CD, only the first key is sent

		 * to the HW, the second key is used for tweak calculation

 Cipher CD config setup */

 AES_KEYSIZE_256 */

 Key reversing not supported, set no convert */

 In-place key reversal */

 If out of place operation dma unmap only data */

 Handle out of place operation */

 Otherwise set the src and dst to the same address */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2020 Intel Corporation */

 Get the interrupt sources triggered by VFs */

	/* To avoid adding duplicate entries to work queue, clear

	 * vf_int_mask_sets bits that are already masked in ERRMSK register.

 Enable VF2PF Messaging Ints - VFs 0 through 15 per vf_mask[15:0] */

 Disable VF2PF interrupts for VFs 0 through 15 per vf_mask[15:0] */

 Enable Accel Engine error detection & correction */

 Enable shared memory error detection & correction */

 Set/Unset Valid bit in AE Thread to PCIe Function Mapping Group A */

 Set/Unset Valid bit in AE Thread to PCIe Function Mapping Group B */

 Read accelerator capabilities mask */

 Configures WDT timers */

 Enable WDT for sym and dc */

 Enable WDT for pke */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

	/* Service arb configured for 32 bytes responses and

 Map worker threads to service arbiters */

	/*

	 * Enable arbitration on a ring only if the TX half of the ring mask

	 * matches the RX part. This results in writes to CSR on both TX and

	 * RX update - only one is necessary, but both are done for

	 * simplicity.

 Reset arbiter configuration */

 Unmap worker threads to service arbiters */

 Disable arbitration on all rings */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Re-enable PF2VF interrupts */

 Read the message from PF */

 Ignore legacy non-system (non-kernel) PF2VF messages */

 To ack, clear the PF2VFINT bit */

 To ack, clear the PF2VFINT bit */

 Re-enable PF2VF interrupts */

 Read VF INT source CSR to determine the source of VF interrupt */

 Read VF INT mask CSR to determine which sources are masked */

	/*

	 * Recompute v_int ignoring sources that are masked. This is to

	 * avoid rescheduling the tasklet for interrupts already handled

 Check for PF2VF interrupt */

 Disable PF to VF interrupt */

 Schedule tasklet to handle interrupt BH */

 Check bundle interrupt */

 Disable Flag and Coalesce Ring Interrupts */

/**

 * adf_vf_isr_resource_free() - Free IRQ for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function frees interrupts for acceleration device virtual function.

/**

 * adf_vf_isr_resource_alloc() - Allocate IRQ for acceleration device

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function allocates interrupts for acceleration device virtual function.

 *

 * Return: 0 on success, error code otherwise.

/**

 * adf_flush_vf_wq() - Flush workqueue for VF

 * @accel_dev:  Pointer to acceleration device.

 *

 * Function disables the PF/VF interrupts on the VF so that no new messages

 * are received and flushes the workqueue 'adf_vf_stop_wq'.

 *

 * Return: void.

/**

 * adf_init_vf_wq() - Init workqueue for VF

 *

 * Function init workqueue 'adf_vf_stop_wq' for VF.

 *

 * Return: 0 on success, error code otherwise.

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

/**

 * adf_dev_init() - Init data structures and services for the given accel device

 * @accel_dev: Pointer to acceleration device.

 *

 * Initialize the ring data structures and the admin comms and arbitration

 * services.

 *

 * Return: 0 on success, error code otherwise.

	/*

	 * Subservice initialisation is divided into two stages: init and start.

	 * This is to facilitate any ordering dependencies between services

	 * prior to starting any of the accelerators.

/**

 * adf_dev_start() - Start acceleration service for the given accel device

 * @accel_dev:    Pointer to acceleration device.

 *

 * Function notifies all the registered services that the acceleration device

 * is ready to be used.

 * To be used by QAT device specific drivers.

 *

 * Return: 0 on success, error code otherwise.

 Set ssm watch dog timer */

/**

 * adf_dev_stop() - Stop acceleration service for the given accel device

 * @accel_dev:    Pointer to acceleration device.

 *

 * Function notifies all the registered services that the acceleration device

 * is shuting down.

 * To be used by QAT device specific drivers.

 *

 * Return: void

/**

 * adf_dev_shutdown() - shutdown acceleration services and data strucutures

 * @accel_dev: Pointer to acceleration device

 *

 * Cleanup the ring data structures and the admin comms and arbitration

 * services.

 Delete configuration only if not restarting */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2015 - 2020 Intel Corporation */

/**

 * adf_vf2pf_notify_init() - send init msg to PF

 * @accel_dev:  Pointer to acceleration VF device.

 *

 * Function sends an init message from the VF to a PF

 *

 * Return: 0 on success, error code otherwise.

/**

 * adf_vf2pf_notify_shutdown() - send shutdown msg to PF

 * @accel_dev:  Pointer to acceleration VF device.

 *

 * Function sends a shutdown message from the VF to a PF

 *

 * Return: void

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Add accel device to accel table */

 Allocate and configure device configuration structure */

 Get Accelerators and Accelerators Engines masks */

 Create dev top level debugfs entry */

 Create device configuration table */

 enable PCI device */

 set dma identifier */

 Find and map all the device's BARS */

 Completion for VF2PF request/response message exchange */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2015 - 2020 Intel Corporation */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

		/* If the accelerator is connected to a node with no memory

		 * there is no point in using the accelerator since the remote

	/* Add accel device to accel table.

 Allocate and configure device configuration structure */

 Get Accelerators and Accelerators Engines masks */

 If the device has no acceleration engines then ignore it. */

 Create dev top level debugfs entry */

 Create device configuration table */

 enable PCI device */

 set dma identifier */

 Get accelerator capabilities mask */

 Find and map all the device's BARS */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Worker thread to service arbiter mappings */

 Read accelerator capabilities mask */

 Enable bundle and misc interrupts */

	/* Get the interrupt sources triggered by VFs, but to avoid duplicates

	 * in the work queue, clear vf_int_mask_sets bits that are already

	 * masked in ERRMSK register.

 Enable VF2PF Messaging Ints - VFs 0 through 15 per vf_mask[15:0] */

 Enable VF2PF Messaging Ints - VFs 16 through 31 per vf_mask[31:16] */

 Disable VF2PF interrupts for VFs 0 through 15 per vf_mask[15:0] */

 Disable VF2PF interrupts for VFs 16 through 31 per vf_mask[31:16] */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Add accel device to accel table */

 Allocate and configure device configuration structure */

 Get Accelerators and Accelerators Engines masks */

 Create dev top level debugfs entry */

 Create device configuration table */

 enable PCI device */

 set dma identifier */

 Find and map all the device's BARS */

 Completion for VF2PF request/response message exchange */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2015 - 2020 Intel Corporation */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

		/* If the accelerator is connected to a node with no memory

		 * there is no point in using the accelerator since the remote

	/* Add accel device to accel table.

 Allocate and configure device configuration structure */

 Get Accelerators and Accelerators Engines masks */

 If the device has no acceleration engines then ignore it. */

 Create dev top level debugfs entry */

 Create device configuration table */

 enable PCI device */

 set dma identifier */

 Get accelerator capabilities mask */

 Find and map all the device's BARS */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Worker thread to service arbiter mappings */

 If an accel is disabled, then disable the corresponding two AEs */

 Enable bundle and misc interrupts */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

		/* If the accelerator is connected to a node with no memory

		 * there is no point in using the accelerator since the remote

	/* Add accel device to accel table.

 Allocate and configure device configuration structure */

 Get Accelerators and Accelerators Engines masks */

 If the device has no acceleration engines then ignore it. */

 Create dev top level debugfs entry */

 Create device configuration table */

 enable PCI device */

 set dma identifier */

 Get accelerator capabilities mask */

 Find and map all the device's BARS */

 SPDX-License-Identifier: (BSD-3-Clause OR GPL-2.0-only)

 Copyright(c) 2014 - 2020 Intel Corporation */

 Worker thread to service arbiter mappings */

 If an accel is disabled, then disable the corresponding two AEs */

 Enable bundle and misc interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 * Xilinx ZynqMP AES Driver.

 * Copyright (c) 2020 Xilinx Inc.

 ZynqMP AES driver supports only one instance */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * One vector for each type of ring

 *  - NPS packet ring, AQMQ ring and ZQMQ ring

 base entry for packet ring/port */

/**

 * nps_pkt_slc_isr - IRQ handler for NPS solicit port

 * @irq: irq number

 * @data: argument

 New packet on SLC output port */

 Write 1 to clear */

 enable the solicit ports */

 enable the input ring */

 if pf mode do queue recovery */

		/**

		 * if VF(s) enabled communicate the error information

		 * to VF(s)

/*

 * nps_core_int_isr - interrupt handler for NITROX errors and

 *   mailbox communication

 Mailbox interrupt */

 If more work callback the ISR, set resend */

 get the vector number */

	/*

	 * PF MSI-X vectors

	 *

	 * Entry 0: NPS PKT ring 0

	 * Entry 1: AQMQ ring 0

	 * Entry 2: ZQM ring 0

	 * Entry 3: NPS PKT ring 1

	 * Entry 4: AQMQ ring 1

	 * Entry 5: ZQM ring 1

	 * ....

	 * Entry 192: NPS_CORE_INT_ACTIVE

 Enable MSI-X */

 request irqs for packet rings/ports */

 get the vector number */

 request irqs for non ring vectors */

 get the vector number */

	/**

	 * only non ring vectors i.e Entry 192 is available

	 * for PF in SR-IOV mode.

 SPDX-License-Identifier: GPL-2.0

/**

 * num_vfs_valid - validate VF count

 * @num_vfs: number of VF(s)

 PF has no queues in SR-IOV mode */

 unregister crypto algorithms */

 cleanup PF resources */

/**

 * nitrox_pf_reinit - re-initialize PF resources once SR-IOV is disabled

 * @ndev: NITROX device

 allocate resources for PF */

 configure the AQM queues */

 configure the packet queues */

 set device to ready state */

 register crypto algorithms */

 unregister interrupts for PF in SR-IOV */

 register interrupts for PF in SR-IOV */

 set bit in flags */

 cleanup PF resources */

 PF SR-IOV mode initialization */

 clear bit in flags */

 reset back to working mode in PF */

 clear bit in flags */

 cleanup PF SR-IOV resources */

 SPDX-License-Identifier: GPL-2.0

/**

 * emu_enable_cores - Enable EMU cluster cores.

 * @ndev: NITROX device

 AE cores 20 per cluster */

 SE cores 16 per cluster */

 enable per cluster cores */

/**

 * nitrox_config_emu_unit - configure EMU unit.

 * @ndev: NITROX device

 enable cores */

 enable general error and watch dog interrupts */

 step 1: disable the ring, clear enable bit */

 step 2: wait to clear [ENB] */

 step 3: clear done counts */

 64-byte instruction size */

 wait for set [ENB] */

/**

 * nitrox_config_pkt_input_rings - configure Packet Input Rings

 * @ndev: NITROX device

		/**

		 * step 4:

		 * configure ring base address 16-byte aligned,

		 * size and interrupt threshold.

 configure ring size */

 set high threshold for pkt input ring interrupts */

 step 5: clear off door bell counts */

 enable the ring */

 step 1: disable slc port */

 step 2 */

 wait to clear [ENB] */

 step 3: clear slc counters */

	/*

	 * 8 trailing 0x00 bytes will be added

	 * to the end of the outgoing packet.

 enable response header */

 wait to set [ENB] */

 step 4: configure interrupt levels */

 time interrupt threshold */

 enable the solicit port */

/**

 * enable_nps_core_interrupts - enable NPS core interrutps

 * @ndev: NITROX device.

 *

 * This includes NPS core interrupts.

 NPS core interrutps */

 endian control information */

 disable ILK interface */

 enable nps core interrupts */

/**

 * enable_nps_pkt_interrupts - enable NPS packet interrutps

 * @ndev: NITROX device.

 *

 * This includes NPS packet in and slc interrupts.

 NPS packet in ring interrupts */

 NPS packet slc port interrupts */

 config input and solicit ports */

 enable nps packet interrupts */

 step 1: disable the queue */

 step 2: wait for AQMQ_ACTIVITY_STATX[QUEUE_ACTIVE] to clear */

 step 3: clear commands completed count */

 steps 1 - 3 */

 step 4: clear doorbell count of ring */

 step 5: configure host ring details */

 set host address for next command of ring */

 set host address of ring base */

 set ring size */

 set command completion threshold */

 step 6: enable the queue */

 clear interrupt enable bits */

 config aqm command queues */

 enable aqm interrupts */

 enable pom interrupts */

 enable perf counters */

/**

 * nitrox_config_rand_unit - enable NITROX random number unit

 * @ndev: NITROX device

 EFL core interrupts */

 no threshold limits for PCIe */

 enable interrupts */

 no threshold limits for PCIe */

 invalidate LBC */

 enable interrupts */

 get core frequency */

 find zip hardware availability */

	/* determine the partname

	 * CNN55<core option>-<freq><pincount>-<feature option>-<rev>

 copy partname */

 Mailbox interrupt low enable set register */

 Mailbox interrupt high enable set register */

 Mailbox interrupt low enable clear register */

 Mailbox interrupt high enable clear register */

 SPDX-License-Identifier: GPL-2.0

 packet inuput ring alignments */

 AQM Queue input alignments */

 AQM Queue Doorbell Counter Register Address */

 AQM Queue Commands Completed Count Register Address */

 packet input ring doorbell address */

 packet solicit port completion count address */

 Crypto context pool, 16 byte aligned */

/*

 * crypto_alloc_context - Allocate crypto context from pool

 * @ndev: NITROX Device

 fill meta data */

/**

 * crypto_free_context - Free crypto context to pool

 * @ctx: context to free

/**

 * nitrox_common_sw_init - allocate software resources.

 * @ndev: NITROX device

 *

 * Allocates crypto context pools and command queues etc.

 *

 * Return: 0 on success, or a negative error code on error.

 per device crypto context pool */

/**

 * nitrox_common_sw_cleanup - free software resources.

 * @ndev: NITROX device

 SPDX-License-Identifier: GPL-2.0

/*

 * supported cipher list

 get the first device */

 allocate nitrox crypto context */

 free the nitrox crypto context */

 fill crypto context */

 copy the key to context */

 Allocate buffer to hold IV and input scatterlist array */

	/* Allocate buffer to hold ORH, COMPLETION and output scatterlist

	 * array

 fill the request */

 param0: length of the data to be encrypted */

 param2: encryption data offset */

 send the crypto request */

 copy KEY2 */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

/*

 * mbx_msg_type - Mailbox message types

/*

 * mbx_msg_opcode - Mailbox message opcodes

 send ACK to VF */

 process the request from VF */

 loop for VF(0..63) */

 get the vfno from ring */

 fill the vf mailbox data */

 clear the corresponding vf bit */

 loop for VF(64..127) */

 get the vfno from ring */

 fill the vf mailbox data */

 clear the corresponding vf bit */

 allocate pf2vf response workqueue */

 enable pf2vf mailbox interrupts */

 disable pf2vf mailbox interrupts */

 destroy workqueue */

 SPDX-License-Identifier: GPL-2.0-only

 SE microcode */

 AE microcode */

/*

 * nitrox_pci_tbl - PCI Device ID Table

 required last entry */

/**

 * struct ucode - Firmware Header

 * @id: microcode ID

 * @version: firmware version

 * @code_size: code section size

 * @raz: alignment

 * @code: code section

/*

 * write_to_ucd_unit - Write Firmware to NITROX UCD unit

	/*

	 * UCD structure

	 *

	 *  -------------

	 *  |    BLK 7  |

	 *  -------------

	 *  |    BLK 6  |

	 *  -------------

	 *  |    ...    |

	 *  -------------

	 *  |    BLK 0  |

	 *  -------------

	 *  Total of 8 blocks, each size 32KB

 set the block number */

 write 8 bytes at a time */

 copy the firmware version */

 Load SE Firmware on UCD Block 0 */

 put all SE cores in DEFAULT_SE_GROUP */

	/* write block number and firmware length

	 * bit:<2:0> block number

	 * bit:3 is set SE uses 32KB microcode

	 * bit:3 is clear SE uses 64KB microcode

 copy the firmware version */

 Load AE Firmware on UCD Block 2 */

 put all AE cores in DEFAULT_AE_GROUP */

	/* write block number and firmware length

	 * bit:<2:0> block number

	 * bit:3 is set AE uses 32KB microcode

	 * bit:3 is clear AE uses 64KB microcode

/**

 * nitrox_add_to_devlist - add NITROX device to global device list

 * @ndev: NITROX device

/**

 * nitrox_remove_from_devlist - remove NITROX device from

 *   global device list

 * @ndev: NITROX device

 barrier to sync with other cpus */

 barrier to sync with other cpus */

/**

 * nitrox_bist_check - Check NITROX BIST registers status

 * @ndev: NITROX device

 get cores information */

 configure IO units */

 configure Local Buffer Cache */

 load firmware on cores */

/**

 * nitrox_probe - NITROX Initialization function.

 * @pdev: PCI device information struct

 * @id: entry in nitrox_pci_tbl

 *

 * Return: 0, if the driver is bound to the device, or

 *         a negative error if there is failure.

 do FLR */

 add to device list */

 command timeout in jiffies */

 allocate command queus based on cpus, max queues are 64 */

 clear the statistics */

 barrier to sync with other cpus */

 barrier to sync with other cpus */

/**

 * nitrox_remove - Unbind the driver from the device.

 * @pdev: PCI device information struct

 barrier to sync with other cpus */

 disable SR-IOV */

 SPDX-License-Identifier: GPL-2.0

 SLC_STORE_INFO */

 PKT_IN_HDR + SLC_STORE_INFO */

 Base destination port for the solicited requests */

/*

 * Response codes from SE microcode

 * 0x00 - Success

 *   Completion with no error

 * 0x43 - ERR_GC_DATA_LEN_INVALID

 *   Invalid Data length if Encryption Data length is

 *   less than 16 bytes for AES-XTS and AES-CTS.

 * 0x45 - ERR_GC_CTX_LEN_INVALID

 *   Invalid context length: CTXL != 23 words.

 * 0x4F - ERR_GC_DOCSIS_CIPHER_INVALID

 *   DOCSIS support is enabled with other than

 *   AES/DES-CBC mode encryption.

 * 0x50 - ERR_GC_DOCSIS_OFFSET_INVALID

 *   Authentication offset is other than 0 with

 *   Encryption IV source = 0.

 *   Authentication offset is other than 8 (DES)/16 (AES)

 *   with Encryption IV source = 1

 * 0x51 - ERR_GC_CRC32_INVALID_SELECTION

 *   CRC32 is enabled for other than DOCSIS encryption.

 * 0x52 - ERR_GC_AES_CCM_FLAG_INVALID

 *   Invalid flag options in AES-CCM IV.

/**

 * create_sg_component - create SG componets for N5 device.

 * @sr: Request structure

 * @sgtbl: SG table

 * @map_nents: number of dma mapped entries

 *

 * Component structure

 *

 *   63     48 47     32 31    16 15      0

 *   --------------------------------------

 *   |   LEN0  |  LEN1  |  LEN2  |  LEN3  |

 *   |-------------------------------------

 *   |               PTR0                 |

 *   --------------------------------------

 *   |               PTR1                 |

 *   --------------------------------------

 *   |               PTR2                 |

 *   --------------------------------------

 *   |               PTR3                 |

 *   --------------------------------------

 *

 *   Returns 0 if success or a negative errno code on error.

 each component holds 4 dma pointers */

 populate device sg component */

 map the device sg component */

/**

 * dma_map_inbufs - DMA map input sglist and creates sglist component

 *                  for N5 device.

 * @sr: Request structure

 * @req: Crypto request structre

 *

 * Returns 0 if successful or a negative errno code on error.

 sync with other cpus */

 sync with other cpus */

/**

 * post_se_instr - Post SE instruction to Packet Input ring

 * @sr: Request structure

 * @cmdq: Command queue structure

 *

 * Returns 0 if successful or a negative error code,

 * if no space in ring.

 copy the instruction */

 flush the command queue updates */

 Ring doorbell with count 1 */

 increment the posted command count */

 submit until space available */

 delete from backlog list */

 sync with other cpus */

 post the command */

 try to post backlog requests */

 increment drop count */

 add to backlog list */

/**

 * nitrox_process_se_request - Send request to SE core

 * @ndev: NITROX device

 * @req: Crypto request

 * @callback: Completion callback

 * @cb_arg: Completion callback arguments

 *

 * Returns 0 on success, or a negative error code.

 get the context handle */

 select the queue */

	/*

	 * 64-Byte Instruction Format

	 *

	 *  ----------------------

	 *  |      DPTR0         | 8 bytes

	 *  ----------------------

	 *  |  PKT_IN_INSTR_HDR  | 8 bytes

	 *  ----------------------

	 *  |    PKT_IN_HDR      | 16 bytes

	 *  ----------------------

	 *  |    SLC_INFO        | 16 bytes

	 *  ----------------------

	 *  |   Front data       | 16 bytes

	 *  ----------------------

 fill the packet instruction */

 word 0 */

 word 1 */

 word 2 */

 context length in 64-bit words */

 offset from solicit base port 256 */

 word 3 */

 word 4 */

 word 5 */

	/*

	 * No conversion for front data,

	 * It goes into payload

	 * put GP Header in front data

/**

 * process_response_list - process completed requests

 * @cmdq: Command queue structure

 *

 * Returns the number of responses processed.

 check all pending requests */

 check orh and completion bytes updates */

 request not completed, check for timeout */

 sync with other cpus */

 remove from response list */

 ORH error code */

/*

 * pkt_slc_resp_tasklet - post processing of SE responses

 read completion count */

 resend the interrupt if more work to do */

	/*

	 * clear the interrupt with resend bit enabled,

	 * MSI-X interrupt generates if Completion count > Threshold

 SPDX-License-Identifier: GPL-2.0

 fill crypto context */

 copy enc key to context */

 IV entry */

 Allocate buffer to hold IV and input scatterlist array */

 IV, ORH, COMPLETION entries */

	/* Allocate buffer to hold ORH, COMPLETION and output scatterlist

	 * array

 send the crypto request */

 send the crypto request */

 get the first device */

 allocate nitrox crypto context */

 ask microcode to calculate ipad/opad */

 free the nitrox crypto context */

 send the crypto request */

 send the crypto request */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Cavium, Inc.

 free single queue */

 init queue spin lock */

 clean up for each queue */

 common cleanup */

 common init */

 Qsize in dwords, needed for SADDR config, 1-next chunk pointer */

 Qsize in bytes to create space for alignment */

 per queue initialization */

 Make the queue circular */

 Tie back last chunk entry to head */

 setup AE command queues */

 possible cpus */

 Create worker threads for BH processing */

 Num of Instructions * 8 words */

 Set mbox(0) interupts for the requested vf */

 Set mbox(0) interupts for the requested vf */

 Set DONE interrupt for the requested vf */

 W1C for the VF */

 W1C for the VF */

 W1C for the VF */

 W1C for the VF */

 W1C for the VF */

Check for MISC interrupt types*/

Clear doorbell count*/

 Read the number of completions */

		/* Acknowledge the number of

		 * scheduled completions for processing

 Disable the VQ */

 Reset the doorbell */

 Clear inflight */

 Write VQ SADDR */

 TODO: for now only one queue, so hard coded */

 Configure timerhold / coalescence */

 Enable the VQ */

 Flag the VF ready */

 Mark as VF driver */

 MAP PF's configuration registers */

 Enable mailbox interrupt */

 Check ready with PF */

 Gets chip ID / device Id from PF if ready */

 CPT VF software resources initialization */

 Convey VQ LEN to PF */

 CPT VF device initialization */

 Send msg to PF to assign currnet Q to required group */

 Enable mailbox interrupt */

 Set irq affinity masks */

 Convey DOWN to PF */

 Supported devices */

 end of table */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Cavium, Inc.

 Writing mbox(1) causes interrupt */

 Interrupt handler to handle mailbox messages from VFs */

	/*

	 * MBOX[0] contains msg

	 * MBOX[1] contains data

 Wait for previous message to be acked, timeout 2sec */

/*

 * Checks if VF is able to comminicate with PF

 * and also gets the CPT number this VF is associated to.

/*

 * Communicate VQs size to PF to program CPT(0)_PF_Q(0-15)_CTL of the VF.

 * Must be ACKed.

/*

 * Communicate VF group required to PF and get the VQ binded to that group

 Convey group of the VF */

/*

 * Communicate VF group required to PF and get the VQ binded to that group

 Convey group of the VF */

/*

 * Communicate to PF that VF is UP and running

/*

 * Communicate to PF that VF is DOWN and running

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Cavium, Inc.

 Default 4 VF enabled */

/*

 * Disable cores specified by coremask

 Disengage the cores from groups */

 Disable the cores */

/*

 * Enable cores specified by coremask

 Clear mbox(0) interupts for all vfs */

 Clear ecc(0) interupts for all vfs */

 Clear exec interupts for all vfs */

 Set mbox(0) interupts for all vfs */

	/* Assumes 0-9 are SE cores for UCODE_BASE registers and

	 * AE core bases follow

 start couting from 10 */

 upto 15 */

 start couting from 0 */

 upto 9 */

 Point to microcode for each core of the group */

 Make device not ready */

 Disable All PF interrupts */

 Calculate mcode group and coremasks */

 Convert requested cores to mask */

 Load microcode for AE engines */

 Configure group mask for the mcode */

 Enable AE cores for the group mask */

 Covert requested cores to mask */

 Load microcode for SE engines */

 Configure group mask for the mcode */

 Enable SE cores for the group mask */

 Enabled PF mailbox interrupts */

 Enabled PF mailbox interrupts */

  Allocate DMAable space */

 Byte swap 64-bit */

  MC needs 16-bit swap */

 Disengage the cores from groups */

 Disable the cores */

/*

 * Ensure all cores are disengaged from all groups by

 * calling cpt_disable_all_cores() before calling this

 * function.

 Free microcode bases and reset group masks */

 Clear UCODE_BASE registers for all engines */

 Reset the PF when probed first */

Check BIST status*/

Get CLK frequency*/

Get max enabled cores */

Disable all cores*/

Reset device parameters*/

 PF is ready */

 Enable MSI-X */

 Register mailbox interrupt handlers */

 Enable mailbox interrupt */

 User requested VFs */

Enabled the available VFs */

 TODO: Optionally enable static VQ priorities feature */

 MAP PF's configuration registers */

 CPT device HW initialization */

 Register interrupts */

 Configure SRIOV */

 Disengage SE and AE cores from all groups*/

 Unload microcodes */

 Supported devices */

 end of table */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Cavium, Inc.

 Writing mbox(0) causes interrupt */

/* ACKs VF's mailbox message

 * @vf: VF to which ACK to be sent

 W1C for the VF */

/*

 *  Configure QLEN/Chunk sizes for VF

/*

 * Configure VQ priority

 Interrupt handler to handle mailbox messages from VFs */

	/*

	 * MBOX[0] contains msg

	 * MBOX[1] contains data

 First msg in VF teardown sequence */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Cavium, Inc.

/**

 * get_free_pending_entry - get free entry from pending queue

 * @q: pending queue

 * @qlen: queue length

 Setup gather (input) components */

 Setup scatter (output) components */

 Create and initialize DPTR */

 Create and initialize RPTR */

 lock commad queue */

 make sure all memory stores are done before ringing doorbell */

 unlock command queue */

 check for timeout */

		/*

		 * Calling callback after we find

		 * that the request has been serviced

	/*

	 * Get buffer for union cpt_res_s response

	 * structure and its physical address

 Fill the VQ command */

 Get Pending Entry to submit command */

 Always queue 0, because 1 queue per VF */

 Send CPT command */

 Create the CPT_INST_S type command for HW intrepretation */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Cavium, Inc.

 Setting the iv information */

 Setting the iv information */

 Encryption Data length */

Auth data length */

	/* Storing  Packet Data Information in offset

	 * Control Word First 8 bytes

	/* OUTPUT Buffer Processing

	 * AES encryption/decryption output would be

	 * received in the following format

	 *

	 * ------IV--------|------ENCRYPTED/DECRYPTED DATA-----|

	 * [ 16 Bytes/     [   Request Enc/Dec/ DATA Len AES CBC ]

 Reading IV information */

	/* We perform an asynchronous send and once

	 * the request is completed the driver would

	 * intimate through  registered call back functions

/***********************license start************************************

 * Copyright (c) 2003-2017 Cavium, Inc.

 * All rights reserved.

 *

 * License: one of 'Cavium License' or 'GNU General Public License Version 2'

 *

 * This file is provided under the terms of the Cavium License (see below)

 * or under the terms of GNU General Public License, Version 2, as

 * published by the Free Software Foundation. When using or redistributing

 * this file, you may do so under either license.

 *

 * Cavium License:  Redistribution and use in source and binary forms, with

 * or without modification, are permitted provided that the following

 * conditions are met:

 *

 *  * Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *

 *  * Redistributions in binary form must reproduce the above

 *    copyright notice, this list of conditions and the following

 *    disclaimer in the documentation and/or other materials provided

 *    with the distribution.

 *

 *  * Neither the name of Cavium Inc. nor the names of its contributors may be

 *    used to endorse or promote products derived from this software without

 *    specific prior written permission.

 *

 * This Software, including technical data, may be subject to U.S. export

 * control laws, including the U.S. Export Administration Act and its

 * associated regulations, and may be subject to export or import

 * regulations in other countries.

 *

 * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"

 * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS

 * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH

 * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY

 * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT

 * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY)

 * WARRANTIES OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A

 * PARTICULAR PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET

 * ENJOYMENT, QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION. THE

 * ENTIRE  RISK ARISING OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES

 * WITH YOU.

/*

 * Allocates new ZIP device structure

 * Returns zip_device pointer or NULL if cannot allocate memory for zip_device

 To ensure that the index is within the limit */

/**

 * zip_get_device - Get ZIP device based on node id of cpu

 *

 * @node: Node id of the current cpu

 * Return: Pointer to Zip device structure

/**

 * zip_get_node_id - Get the node id of the current cpu

 *

 * Return: Node id of the current cpu

 Initializes the ZIP h/w sub-system */

 Enable the ZIP Engine(Core) Clock */

	/*

	 * Program ZIP_QUE(0..7)_SBUF_ADDR and ZIP_QUE(0..7)_SBUF_CTL to

	 * have the correct buffer pointer and size configured for each

	 * instruction queue.

 Initialize tail ptr to head */

 Write the physical addr to register */

	/*

	 * Queue-to-ZIP core mapping

	 * If a queue is not mapped to a particular core, it is equivalent to

	 * the ZIP core being disabled.

 Enabling queues based on ZIP_NUM_QUEUES */

 Mapping each queue to two ZIP cores */

 Higher Priority RR */

 MAP configuration registers */

 Initialize ZIP Hardware */

 Remove zip_dev from zip_device list, free the zip_device memory */

 Forces ZIP cores to do reset */

	/*

	 * Free Command Queue buffers. This free should be called for all

	 * the enabled Queues.

 remove zip device from zip device list */

 PCI Sub-System Interface */

 Kernel Crypto Subsystem Interface */

/*

 * debugfs functions

 Displays ZIP device statistics */

 Get all the pending requests */

 Clears stats data */

 Prints registers' contents */

 Root directory for thunderx_zip debugfs entry */

 Creating files for entries inside thunderx_zip directory */

 debugfs - end */

 Register with the Kernel Crypto Interface */

 comp-decomp statistics are handled with debugfs interface */

 Unregister from the kernel crypto interface */

 Unregister this driver for pci zip devices */

/***********************license start************************************

 * Copyright (c) 2003-2017 Cavium, Inc.

 * All rights reserved.

 *

 * License: one of 'Cavium License' or 'GNU General Public License Version 2'

 *

 * This file is provided under the terms of the Cavium License (see below)

 * or under the terms of GNU General Public License, Version 2, as

 * published by the Free Software Foundation. When using or redistributing

 * this file, you may do so under either license.

 *

 * Cavium License:  Redistribution and use in source and binary forms, with

 * or without modification, are permitted provided that the following

 * conditions are met:

 *

 *  * Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *

 *  * Redistributions in binary form must reproduce the above

 *    copyright notice, this list of conditions and the following

 *    disclaimer in the documentation and/or other materials provided

 *    with the distribution.

 *

 *  * Neither the name of Cavium Inc. nor the names of its contributors may be

 *    used to endorse or promote products derived from this software without

 *    specific prior written permission.

 *

 * This Software, including technical data, may be subject to U.S. export

 * control laws, including the U.S. Export Administration Act and its

 * associated regulations, and may be subject to export or import

 * regulations in other countries.

 *

 * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"

 * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS

 * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH

 * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY

 * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT

 * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY)

 * WARRANTIES OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A

 * PARTICULAR PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET

 * ENJOYMENT, QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION. THE

 * ENTIRE  RISK ARISING OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES

 * WITH YOU.

/**

 * zip_cmd_qbuf_alloc - Allocates a cmd buffer for ZIP Instruction Queue

 * @zip: Pointer to zip device structure

 * @q:   Queue number to allocate bufffer to

 * Return: 0 if successful, -ENOMEM otherwise

/**

 * zip_cmd_qbuf_free - Frees the cmd Queue buffer

 * @zip: Pointer to zip device structure

 * @q:   Queue number to free buffer of

/**

 * zip_data_buf_alloc - Allocates memory for a data bufffer

 * @size:   Size of the buffer to allocate

 * Returns: Pointer to the buffer allocated

/**

 * zip_data_buf_free - Frees the memory of a data buffer

 * @ptr:  Pointer to the buffer

 * @size: Buffer size

/***********************license start************************************

 * Copyright (c) 2003-2017 Cavium, Inc.

 * All rights reserved.

 *

 * License: one of 'Cavium License' or 'GNU General Public License Version 2'

 *

 * This file is provided under the terms of the Cavium License (see below)

 * or under the terms of GNU General Public License, Version 2, as

 * published by the Free Software Foundation. When using or redistributing

 * this file, you may do so under either license.

 *

 * Cavium License:  Redistribution and use in source and binary forms, with

 * or without modification, are permitted provided that the following

 * conditions are met:

 *

 *  * Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *

 *  * Redistributions in binary form must reproduce the above

 *    copyright notice, this list of conditions and the following

 *    disclaimer in the documentation and/or other materials provided

 *    with the distribution.

 *

 *  * Neither the name of Cavium Inc. nor the names of its contributors may be

 *    used to endorse or promote products derived from this software without

 *    specific prior written permission.

 *

 * This Software, including technical data, may be subject to U.S. export

 * control laws, including the U.S. Export Administration Act and its

 * associated regulations, and may be subject to export or import

 * regulations in other countries.

 *

 * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"

 * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS

 * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH

 * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY

 * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT

 * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY)

 * WARRANTIES OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A

 * PARTICULAR PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET

 * ENJOYMENT, QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION. THE

 * ENTIRE  RISK ARISING OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES

 * WITH YOU.

 IWORD#0 */

 Decompression History Gather list - no gather list */

 For decompression, CE must be 0x0. */

 For decompression, SS must be 0x0. */

 For decompression, SF should always be set. */

 Begin File */

 0: for Deflate decompression, 3: for LZS decompression */

 IWORD #1*/

 adler checksum */

	/*

	 * HISTORYLENGTH must be 0x0 for any ZIP decompress operation.

	 * History data is added to a decompression operation via IWORD3.

 IWORD # 8 and 9 - Output pointer */

 Maximum number of output-stream bytes that can be written */

 IWORD # 6 and 7 - input pointer */

 IWORD # 10 and 11 - Result pointer */

 Clearing completion code */

 Returning 0 for time being.*/

/**

 * zip_inflate - API to offload inflate operation to hardware

 * @zip_ops: Pointer to zip operation structure

 * @s:       Pointer to the structure representing zip state

 * @zip_dev: Pointer to zip device structure

 *

 * This function prepares the zip inflate command and submits it to the zip

 * engine for processing.

 *

 * Return: 0 if successful or error code

 Prepare inflate zip command */

 Load inflate command to zip queue and ring the doorbell */

 Decompression requests submitted stats update */

 Wait for completion or error */

 Decompression requests completed stats update */

 Get checksum from engine */

/***********************license start************************************

 * Copyright (c) 2003-2017 Cavium, Inc.

 * All rights reserved.

 *

 * License: one of 'Cavium License' or 'GNU General Public License Version 2'

 *

 * This file is provided under the terms of the Cavium License (see below)

 * or under the terms of GNU General Public License, Version 2, as

 * published by the Free Software Foundation. When using or redistributing

 * this file, you may do so under either license.

 *

 * Cavium License:  Redistribution and use in source and binary forms, with

 * or without modification, are permitted provided that the following

 * conditions are met:

 *

 *  * Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *

 *  * Redistributions in binary form must reproduce the above

 *    copyright notice, this list of conditions and the following

 *    disclaimer in the documentation and/or other materials provided

 *    with the distribution.

 *

 *  * Neither the name of Cavium Inc. nor the names of its contributors may be

 *    used to endorse or promote products derived from this software without

 *    specific prior written permission.

 *

 * This Software, including technical data, may be subject to U.S. export

 * control laws, including the U.S. Export Administration Act and its

 * associated regulations, and may be subject to export or import

 * regulations in other countries.

 *

 * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"

 * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS

 * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH

 * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY

 * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT

 * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY)

 * WARRANTIES OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A

 * PARTICULAR PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET

 * ENJOYMENT, QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION. THE

 * ENTIRE  RISK ARISING OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES

 * WITH YOU.

/**

 * zip_cmd_queue_consumed - Calculates the space consumed in the command queue.

 *

 * @zip_dev: Pointer to zip device structure

 * @queue:   Queue number

 *

 * Return: Bytes consumed in the command queue buffer.

/**

 * zip_load_instr - Submits the instruction into the ZIP command queue

 * @instr:      Pointer to the instruction to be submitted

 * @zip_dev:    Pointer to ZIP device structure to which the instruction is to

 *              be submitted

 *

 * This function copies the ZIP instruction to the command queue and rings the

 * doorbell to notify the engine of the instruction submission. The command

 * queue is maintained in a circular fashion. When there is space for exactly

 * one instruction in the queue, next chunk pointer of the queue is made to

 * point to the head of the queue, thus maintaining a circular queue.

 *

 * Return: Queue number to which the instruction was submitted

	/*

	 * Distribute the instructions between the enabled queues based on

	 * the CPU id.

 Take cmd buffer lock */

	/*

	 * Command Queue implementation

	 * 1. If there is place for new instructions, push the cmd at sw_head.

	 * 2. If there is place for exactly one instruction, push the new cmd

	 *    at the sw_head. Make sw_head point to the sw_tail to make it

	 *    circular. Write sw_head's physical address to the "Next-Chunk

	 *    Buffer Ptr" to make it cmd_hw_tail.

	 * 3. Ring the door bell.

 Check if there is space to push just one cmd */

 Space for one cmd, pust it and make it circular queue */

 16 64_bit words = 128B */

 Now, point the "Next-Chunk Buffer Ptr" to sw_head */

 Using Circular command queue */

 Mark this buffer for free */

 Write new chunk buffer address at "Next-Chunk Buffer Ptr" */

 Push this cmd to cmd queue buffer */

 16 64_bit words = 128B */

 Ring the doorbell */

 Unlock cmd buffer lock */

/**

 * zip_update_cmd_bufs - Updates the queue statistics after posting the

 *                       instruction

 * @zip_dev: Pointer to zip device structure

 * @queue:   Queue number

 Take cmd buffer lock */

 Check if the previous buffer can be freed */

 Reset the free flag */

 Point the hw_tail to start of the new chunk buffer */

 16 64_bit words = 128B */

/***********************license start************************************

 * Copyright (c) 2003-2017 Cavium, Inc.

 * All rights reserved.

 *

 * License: one of 'Cavium License' or 'GNU General Public License Version 2'

 *

 * This file is provided under the terms of the Cavium License (see below)

 * or under the terms of GNU General Public License, Version 2, as

 * published by the Free Software Foundation. When using or redistributing

 * this file, you may do so under either license.

 *

 * Cavium License:  Redistribution and use in source and binary forms, with

 * or without modification, are permitted provided that the following

 * conditions are met:

 *

 *  * Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *

 *  * Redistributions in binary form must reproduce the above

 *    copyright notice, this list of conditions and the following

 *    disclaimer in the documentation and/or other materials provided

 *    with the distribution.

 *

 *  * Neither the name of Cavium Inc. nor the names of its contributors may be

 *    used to endorse or promote products derived from this software without

 *    specific prior written permission.

 *

 * This Software, including technical data, may be subject to U.S. export

 * control laws, including the U.S. Export Administration Act and its

 * associated regulations, and may be subject to export or import

 * regulations in other countries.

 *

 * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"

 * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS

 * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH

 * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY

 * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT

 * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY)

 * WARRANTIES OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A

 * PARTICULAR PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET

 * ENJOYMENT, QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION. THE

 * ENTIRE  RISK ARISING OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES

 * WITH YOU.

 equivalent to level 6 of opensource zlib */

 Auto Huffman */

 LZS Encoding */

 Adler checksum desired */

 Work around for a bug in zlib which needs an extra bytes sometimes */

 Not LZS Encoding */

 Legacy Compress framework start */

 Legacy compress framework end */

 SCOMP framework start */

 SCOMP framework end */

/***********************license start************************************

 * Copyright (c) 2003-2017 Cavium, Inc.

 * All rights reserved.

 *

 * License: one of 'Cavium License' or 'GNU General Public License Version 2'

 *

 * This file is provided under the terms of the Cavium License (see below)

 * or under the terms of GNU General Public License, Version 2, as

 * published by the Free Software Foundation. When using or redistributing

 * this file, you may do so under either license.

 *

 * Cavium License:  Redistribution and use in source and binary forms, with

 * or without modification, are permitted provided that the following

 * conditions are met:

 *

 *  * Redistributions of source code must retain the above copyright

 *    notice, this list of conditions and the following disclaimer.

 *

 *  * Redistributions in binary form must reproduce the above

 *    copyright notice, this list of conditions and the following

 *    disclaimer in the documentation and/or other materials provided

 *    with the distribution.

 *

 *  * Neither the name of Cavium Inc. nor the names of its contributors may be

 *    used to endorse or promote products derived from this software without

 *    specific prior written permission.

 *

 * This Software, including technical data, may be subject to U.S. export

 * control laws, including the U.S. Export Administration Act and its

 * associated regulations, and may be subject to export or import

 * regulations in other countries.

 *

 * TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"

 * AND WITH ALL FAULTS AND CAVIUM INC. MAKES NO PROMISES, REPRESENTATIONS

 * OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH

 * RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY

 * REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT

 * DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY)

 * WARRANTIES OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A

 * PARTICULAR PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET

 * ENJOYMENT, QUIET POSSESSION OR CORRESPONDENCE TO DESCRIPTION. THE

 * ENTIRE  RISK ARISING OUT OF USE OR PERFORMANCE OF THE SOFTWARE LIES

 * WITH YOU.

 Prepares the deflate zip command */

 IWORD #0 */

 History gather */

 compression enable = 1 for deflate */

 sf (sync flush) */

 ef (end of file) */

 ss (compression speed/storage) */

 IWORD #1 */

 adler checksum */

 IWORD # 6 and 7 - compression input/history pointer */

 IWORD # 8 and 9 - Output pointer */

 maximum number of output-stream bytes that can be written */

 IWORD # 10 and 11 - Result pointer */

 Clearing completion code */

/**

 * zip_deflate - API to offload deflate operation to hardware

 * @zip_ops: Pointer to zip operation structure

 * @s:       Pointer to the structure representing zip state

 * @zip_dev: Pointer to zip device structure

 *

 * This function prepares the zip deflate command and submits it to the zip

 * engine for processing.

 *

 * Return: 0 if successful or error code

 Prepares zip command based on the input parameters */

 Loads zip command into command queues and rings door bell */

 Stats update for compression requests submitted */

 Wait for completion or error */

 Stats update for compression requests completed */

 Returning ZIP_ERROR to avoid copy to user */

 Update the CRC depending on the format */

 Get checksum from engine, need to feed it again */

 Update output_len */

 Dynamic stop && strm->output_len < zipconstants[onfsize] */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 use default sgl head size 64B */

/**

 * hisi_acc_create_sgl_pool() - Create a hw sgl pool.

 * @dev: The device which hw sgl pool belongs to.

 * @count: Count of hisi_acc_hw_sgl in pool.

 * @sge_nr: The count of sge in hw_sgl

 *

 * This function creates a hw sgl pool, after this user can get hw sgl memory

 * from it.

	/*

	 * the pool may allocate a block of memory of size PAGE_SIZE * 2^(MAX_ORDER - 1),

	 * block size may exceed 2^31 on ia64, so the max of block size is 2^31

/**

 * hisi_acc_free_sgl_pool() - Free a hw sgl pool.

 * @dev: The device which hw sgl pool belongs to.

 * @pool: Pointer of pool.

 *

 * This function frees memory of a hw sgl pool.

/**

 * hisi_acc_sg_buf_map_to_hw_sgl - Map a scatterlist to a hw sgl.

 * @dev: The device which hw sgl belongs to.

 * @sgl: Scatterlist which will be mapped to hw sgl.

 * @pool: Pool which hw sgl memory will be allocated in.

 * @index: Index of hisi_acc_hw_sgl in pool.

 * @hw_sgl_dma: The dma address of allocated hw sgl.

 *

 * This function builds hw sgl according input sgl, user can use hw_sgl_dma

 * as src/dst in its BD. Only support single hw sgl currently.

/**

 * hisi_acc_sg_buf_unmap() - Unmap allocated hw sgl.

 * @dev: The device which hw sgl belongs to.

 * @sgl: Related scatterlist.

 * @hw_sgl: Virtual address of hw sgl.

 *

 * This function unmaps allocated hw sgl.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 eq/aeq irq enable */

 mailbox */

 sqc shift */

 cqc shift */

 eqc shift */

 interfunction communication */

 sentinel */ }

 return 0 mailbox ready, -ETIMEDOUT hardware timeout */

 128 bit should be written to hardware at one time to trigger a mailbox */

 set c_flag */

 the workqueue created by device driver of QM */

 make sure setup is completed */

/*

 * the formula:

 * IR = X Mbps if ir = 1 means IR = 100 Mbps, if ir = 10000 means = 10Gbps

 *

 *		        IR_b * (2 ^ IR_u) * 8

 * IR(Mbps) * 10 ^ -3 = -------------------------

 *		        Tick * (2 ^ IR_s)

				/** the formula is changed to:

				 *	   IR_b * (2 ^ IR_u) * DIVISOR_CLK

				 * IR(Mbps) = -------------------------

				 *	       768 * (2 ^ IR_s)

 The base number of queue reuse for different alg type */

 The config should be conducted after qm_dev_mem_reset() */

 init default shaper qos val */

	/*

	 * if vfq_num + remain_q_num > max_qp_num, the last VFs,

	 * each with one more queue.

 rd_clr_ctrl 1 enable read clear, otherwise 0 disable it */

 According PF or VF Dev ID to calculation curr_qm_qp_num and store */

 XXX_CNT are reading clear register */

/**

 * hisi_qm_regs_dump() - Dump registers's value.

 * @s: debugfs file handle.

 * @regset: accelerator registers information.

 *

 * Dump accelerator registers.

 Judge if the instance is being reset. */

 clear QM hw residual error source */

 configure error type */

 enable close master ooo when hardware error happened */

 disable close master ooo when hardware error happened */

 read err sts */

 ce error does not need to be reset */

 Check if the error causes the master ooo block */

 All VFs send command to PF, break */

 PF check VFs msg */

 PF clear interrupt to ack VFs */

 if VF respond, PF notifies VF successfully. */

 PF sends command to all VFs by mailbox */

 If all VFs acked, PF notifies VFs successfully. */

 Check which vf respond timeout. */

 Waiting for PF response */

 Use last 64 bits of DUS to reset status. */

/**

 * hisi_qm_create_qp() - Create a queue pair from qm.

 * @qm: The qm we create a qp from.

 * @alg_type: Accelerator specific algorithm type in sqc.

 *

 * return created qp, -EBUSY if all qps in qm allocated, -ENOMEM if allocating

 * qp memory fails.

/**

 * hisi_qm_release_qp() - Release a qp back to its qm.

 * @qp: The qp we want to release.

 *

 * This function releases the resource of a qp.

 rand_qc */

 rand_qc */

/**

 * hisi_qm_start_qp() - Start a qp into running.

 * @qp: The qp we want to start to run.

 * @arg: Accelerator specific argument.

 *

 * After this function, qp can receive request from user. Return 0 if

 * successful, Return -EBUSY if failed.

/**

 * qp_stop_fail_cb() - call request cb.

 * @qp: stopped failed qp.

 *

 * Callback function should be called whether task completed or not.

/**

 * qm_drain_qp() - Drain a qp.

 * @qp: The qp we want to drain.

 *

 * Determine whether the queue is cleared by judging the tail pointers of

 * sq and cq.

 No need to judge if master OOO is blocked. */

 Kunpeng930 supports drain qp by device */

	/*

	 * It is allowed to stop and release qp when reset, If the qp is

	 * stopped when reset but still want to be released then, the

	 * is_resetting flag should be set negative so that this qp will not

	 * be restarted after reset.

/**

 * hisi_qm_stop_qp() - Stop a qp in qm.

 * @qp: The qp we want to stop.

 *

 * This function is reverse of hisi_qm_start_qp. Return 0 if successful.

/**

 * hisi_qp_send() - Queue up a task in the hardware queue.

 * @qp: The qp in which to put the message.

 * @msg: The message.

 *

 * This function will return -EBUSY if qp is currently full, and -EAGAIN

 * if qp related qm is resetting.

 *

 * Note: This function may run with qm_irq_thread and ACC reset at same time.

 *       It has no race with qm_irq_thread. However, during hisi_qp_send, ACC

 *       reset may happen, we have no lock here considering performance. This

 *       causes current qm_db sending fail or can not receive sended sqe. QM

 *       sync/async receive function should handle the error sqe. ACC reset

 *       done function should clear used sqe to 0.

 map sq/cq/doorbell to user space */

		/*

		 * dma_mmap_coherent() requires vm_pgoff as 0

		 * restore vm_pfoff to initial value for mmap()

 make sure to read data from memory */

 only consider sva case */

 Add one more page for device or qp status */

/**

 * qm_frozen() - Try to froze QM to cut continuous queue request. If

 * there is user on the QM, return failure without doing anything.

 * @qm: The qm needed to be fronzen.

 *

 * This function frozes QM, then we can do SRIOV disabling.

 Try to frozen all the VFs as disable SRIOV */

/**

 * hisi_qm_wait_task_finish() - Wait until the task is finished

 * when removing the driver.

 * @qm: The qm needed to wait for the task to finish.

 * @qm_list: The list of all available devices.

/**

 * hisi_qm_get_free_qp_num() - Get free number of qp in qm.

 * @qm: The qm which want to get free qp.

 *

 * This function return free number of qp in qm.

 Clear communication interrupt source */

 Enable pf to vf communication reg. */

/**

 * hisi_qm_uninit() - Uninitialize qm.

 * @qm: The qm needed uninit.

 *

 * This function uninits qm related device resources.

/**

 * hisi_qm_get_vft() - Get vft from a qm.

 * @qm: The qm we want to get its vft.

 * @base: The base number of queue in vft.

 * @number: The number of queues in vft.

 *

 * We can allocate multiple queues to a qm by configuring virtual function

 * table. We get related configures by this function. Normally, we call this

 * function in VF driver to get the queue information.

 *

 * qm hw v1 does not support this interface.

/**

 * hisi_qm_set_vft() - Set vft to a qm.

 * @qm: The qm we want to set its vft.

 * @fun_num: The function number.

 * @base: The base number of queue in vft.

 * @number: The number of queues in vft.

 *

 * This function is alway called in PF driver, it is used to assign queues

 * among PF and VFs.

 *

 * Assign queues A~B to PF: hisi_qm_set_vft(qm, 0, A, B - A + 1)

 * Assign queues A~B to VF: hisi_qm_set_vft(qm, 2, A, B - A + 1)

 * (VF function number 0x2)

/**

 * hisi_qm_start() - start qm

 * @qm: The qm to be started.

 *

 * This function starts a qm, then we can allocate qp from this qm.

 Stop started qps in reset flow */

/**

 * qm_clear_queues() - Clear all queues memory in a qm.

 * @qm: The qm in which the queues will be cleared.

 *

 * This function clears all queues memory in a qm. Reset of accelerator can

 * use this to clear queues.

/**

 * hisi_qm_stop() - Stop a qm.

 * @qm: The qm which will be stopped.

 * @r: The reason to stop qm.

 *

 * This function stops qm and its qps, then qm can not accept request.

 * Related resources are not released at this state, we can use hisi_qm_start

 * to let qm start again.

 Mask eq and aeq irq */

/**

 * hisi_qm_dev_err_init() - Initialize device error configuration.

 * @qm: The qm for which we want to do error initialization.

 *

 * Initialize QM and device error related configuration.

/**

 * hisi_qm_dev_err_uninit() - Uninitialize device error configuration.

 * @qm: The qm for which we want to do error uninitialization.

 *

 * Uninitialize QM and device error related configuration.

/**

 * hisi_qm_free_qps() - free multiple queue pairs.

 * @qps: The queue pairs need to be freed.

 * @qp_num: The num of queue pairs.

/**

 * hisi_qm_alloc_qps_node() - Create multiple queue pairs.

 * @qm_list: The list of all available devices.

 * @qp_num: The number of queue pairs need created.

 * @alg_type: The algorithm type.

 * @node: The numa node.

 * @qps: The queue pairs need created.

 *

 * This function will sort all available device according to numa distance.

 * Then try to create all queue pairs from one device, if all devices do

 * not meet the requirements will return error.

 If vfs_q_num is less than num_vfs, return error. */

		/*

		 * if q_num + remain_q_num > max_qp_num in last vf, divide the

		 * remaining queues equally.

 The base number of queue reuse for different alg type */

 reset mailbox qos val */

 vf ping pf to get function qos */

 Mailbox and reset cannot be operated at the same time */

 Mailbox and reset cannot be operated at the same time */

/**

 * hisi_qm_set_algqos_init() - Initialize function qos debugfs files.

 * @qm: The qm for which we want to add debugfs files.

 *

 * Create function qos debugfs files.

/**

 * hisi_qm_debug_init() - Initialize qm related debugfs files.

 * @qm: The qm for which we want to add debugfs files.

 *

 * Create qm related debugfs files.

 only show this in PF */

/**

 * hisi_qm_debug_regs_clear() - clear qm debug related registers.

 * @qm: The qm for which we want to clear its debug registers.

 clear current_qm */

 clear current_q */

	/*

	 * these registers are reading and clearing, so clear them after

	 * reading them.

 clear clear_enable */

/**

 * hisi_qm_sriov_enable() - enable virtual functions

 * @pdev: the PCIe device

 * @max_vfs: the number of virtual functions to enable

 *

 * Returns the number of enabled VFs. If there are VFs enabled already or

 * max_vfs is more than the total number of device can be enabled, returns

 * failure.

/**

 * hisi_qm_sriov_disable - disable virtual functions

 * @pdev: the PCI device.

 * @is_frozen: true when all the VFs are frozen.

 *

 * Return failure if there are VFs assigned already or VF is in used.

 While VF is in used, SRIOV cannot be disabled. */

 clear vf function shaper configure array */

/**

 * hisi_qm_sriov_configure - configure the number of VFs

 * @pdev: The PCI device

 * @num_vfs: The number of VFs need enabled

 *

 * Enable SR-IOV according to num_vfs, 0 means disable.

 get device hardware error status */

 ce error does not need to be reset */

 log qm error */

 log device error */

/**

 * hisi_qm_dev_err_detected() - Get device and qm error status then log it.

 * @pdev: The PCI device which need report error.

 * @state: The connectivity between CPU and device.

 *

 * We register this function into PCIe AER handlers, It will report device or

 * qm hardware error status when error occur.

 save VFs PCIE BAR configuration */

 Kunpeng930 supports to notify VFs to stop before PF reset */

 All reset requests need to be queued for processing */

	/*

	 * PF and VF on host doesnot support resetting at the

	 * same time on Kunpeng920.

 PF obtains the information of VF by querying the register. */

 Whether VFs stop successfully, soft reset will continue. */

 Kunpeng930 hardware automatically close master ooo when NFE occurs */

 Ensure all doorbells and mailboxes received by QM */

 OOO register set and check */

 If bus lock, reset chip */

 The reset related sub-control registers are not in PCI BAR */

 enable VFs PCIE BAR configuration */

 Kunpeng930 supports to notify VFs to start after PF reset. */

 temporarily close the OOO port used for PEH to write out MSI */

 clear dev ecc 2bit error source if having */

 clear QM ecc mbit error source */

 clear AM Reorder Buffer ecc mbit source */

 open the OOO port for PEH to write out MSI */

/**

 * hisi_qm_dev_slot_reset() - slot reset

 * @pdev: the PCIe device

 *

 * This function offers QM relate PCIe device reset interface. Drivers which

 * use QM can use this function as slot_reset in its struct pci_error_handlers.

 reset pcie device controller */

	/*

	 * Check whether there is an ECC mbit error, If it occurs, need to

	 * wait for soft reset to fix it.

 PF obtains the information of VF by querying the register. */

/**

 * hisi_qm_dev_shutdown() - Shutdown device.

 * @pdev: The device will be shutdown.

 *

 * This function will stop qm when OS shutdown or rebooting.

 reset pcie device controller */

 Wait for reset to finish */

 hardware completion status should be available by this time */

	/*

	 * Whether message is got successfully,

	 * VF needs to ack PF by clearing the interrupt.

 The message is obtained by querying the register during resetting */

	/*

	 * Get the msg from source by sending mailbox. Whether message is got

	 * successfully, destination needs to ack source by clearing the interrupt.

/**

 * hisi_qm_alg_register() - Register alg to crypto and add qm to qm_list.

 * @qm: The qm needs add.

 * @qm_list: The qm list.

 *

 * This function adds qm to qm list, and will register algorithm to

 * crypto when the qm list is empty.

/**

 * hisi_qm_alg_unregister() - Unregister alg from crypto and delete qm from

 * qm list.

 * @qm: The qm needs delete.

 * @qm_list: The qm list.

 *

 * This function deletes qm from qm list, and will unregister algorithm

 * from crypto when the qm list is empty.

 check if qp number is valid */

 one more page for device or qp statuses */

/**

 * hisi_qm_init() - Initialize configures about qm.

 * @qm: The qm needing init.

 *

 * This function init qm, then we can call hisi_qm_start to put qm into work.

 v2 starts to support get vft by mailbox */

/**

 * hisi_qm_get_dfx_access() - Try to get dfx access.

 * @qm: pointer to accelerator device.

 *

 * Try to get dfx access, then user can get message.

 *

 * If device is in suspended, return failure, otherwise

 * bump up the runtime PM usage counter.

/**

 * hisi_qm_put_dfx_access() - Put dfx access.

 * @qm: pointer to accelerator device.

 *

 * Put dfx access, drop runtime PM usage counter.

/**

 * hisi_qm_pm_init() - Initialize qm runtime PM.

 * @qm: pointer to accelerator device.

 *

 * Function that initialize qm runtime PM.

/**

 * hisi_qm_pm_uninit() - Uninitialize qm runtime PM.

 * @qm: pointer to accelerator device.

 *

 * Function that uninitialize qm runtime PM.

 shutdown OOO register */

/**

 * hisi_qm_suspend() - Runtime suspend of given device.

 * @dev: device to suspend.

 *

 * Function that suspend the device.

/**

 * hisi_qm_resume() - Runtime resume of given device.

 * @dev: device to resume.

 *

 * Function that resume the device.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018-2019 HiSilicon Limited. */

 clock gate */

 sentinel */

/*

 * uacce_mode = 0 means hpre only register to crypto,

 * uacce_mode = 1 means hpre both register to crypto and uacce.

	/*

	 * type: 0 - RSA/DH. algorithm supported in V2,

	 *       1 - ECC algorithm in V3.

 Switch over to MSI handling due to non-standard PCI implementation */

 clusters initiating */

/*

 * For Kunpeng 920, we should disable FLR triggered by hardware (BME/PM/SRIOV).

 * Or it may stay in D3 state when we bind and unbind hpre quickly,

 * as it does FLR triggered by hardware.

 Enable prefetch */

 disabel dynamic clock gate before sram init */

 HPRE need more time, we close this interrupt */

 This setting is only needed by Kunpeng 920. */

 Config data buffer pasid needed by Kunpeng 920 */

 clear clusterX/cluster_ctrl */

 clear rdclr_en */

 disable hpre hw error interrupts */

 disable HPRE block master OOO when nfe occurs on Kunpeng930 */

 clear HPRE hw error source if having */

 configure error type */

 enable HPRE block master OOO when nfe occurs on Kunpeng930 */

 enable hpre hw error interrupts */

 Enable shaper type 0 */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 due to nist p521  */

 size in bytes of the n prime */

 size in bytes */

 low address: e--->n */

 low address: d--->n */

 low address: dq->dp->q->p->qinv */

	/*

	 * If base is g we compute the public key

	 *	ya = g^xa mod p; [RFC2631 sec 2.1.1]

	 * else if base if the counterpart public key we

	 * compute the shared secret

	 *	ZZ = yb^xa mod p; [RFC2631 sec 2.1.1]

	 * low address: d--->n, please refer to Hisilicon HPRE UM

 m */

 low address: p->a->k->b */

 low address: x->y */

 low address: p->a->k */

 gx coordinate */

 for ecc algorithms */

 when the data is dh's source, we should format it */

 success */

 If g equals 2 don't copy it */

 Free old secret if any */

 For 512 and 1536 bits key size, use soft tfm instead */

 success */

 For 512 and 1536 bits key size, use soft tfm instead */

 success */

 if invalid key size provided, we use software tfm */

 Using hardware HPRE to do RSA */

 If it is clear all, all the resources of the QP will be cleaned. */

/*

 * we should judge if it is CRT or not,

 * CRT: return true,  N-CRT: return false .

 N-CRT less than 5 parameters */

 For 512 and 1536 bits key size, use soft tfm instead */

 ecdh: p->a->k->b */

 curve25519: p->a->k */

/*

 * The bits of 192/224/256/384/521 are supported by HPRE,

 * and convert the bits like:

 * bits<=256, bits=256; 256<bits<=384, bits=384; 384<bits<=576, bits=576;

 * If the parameter bit width is insufficient, then we fill in the

 * high-order zeros by soft, so TASK_LENGTH1 is 0x3/0x5/0x8;

 Use stdrng to generate private key */

 Src_data include gx and gy. */

 max size is the pub_key_size, include x and y */

	/*

	 * The key from 'buf' is in little-endian, we should preprocess it as

	 * the description in rfc7748: "k[0] &= 248, k[31] &= 127, k[31] |= 64",

	 * then convert it to big endian. Only in this way, the result can be

	 * the same as the software curve-25519 that exists in crypto.

 fill curve parameters */

 p->a->k->gx */

 Free old secret if any */

 The modulus is ptr's last byte minus '0xed'(last byte of p) */

	/*

	 * Src_data(gx) is in little-endian order, MSB in the final byte should

	 * be masked as described in RFC7748, then transform it to big-endian

	 * form, then hisi_hpre can use the data.

	/*

	 * When src_data equals (2^255 - 19) ~  (2^255 - 1), it is out of p,

	 * we get its modulus to p, and then use it.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 clock gating */

/*

 * uacce_mode = 0 means sec only register to crypto,

 * uacce_mode = 1 means sec both register to crypto and uacce.

 Enable prefetch */

 Kunpeng920 needs to close clock gating */

 disable clock gate control before mem init */

 Enable sm4 extra mode, as ctr/ecb */

 Enable sm4 xts mode multiple iv */

 config endian */

 qm user domain */

 qm cache */

 disable FLR triggered by BME(bus master enable) */

 enable sqc,cqc writeback */

 sec_debug_regs_clear() - clear the sec debug regs */

 clear sec dfx regs */

 clear rdclr_en */

 clear SEC hw error source if having */

 enable RAS int */

 enable SEC block master OOO when nfe occurs on Kunpeng930 */

 enable SEC hw error interrupts */

 disable SEC hw error interrupts */

 disable SEC block master OOO when nfe occurs on Kunpeng930 */

 disable RAS int */

		/*

		 * have no way to get qm configure in VM in v1 hardware,

		 * so currently force PF to uses SEC_PF_DEF_Q_NUM, and force

		 * to trigger only one VF in v1 hardware.

		 * v2 hardware has no such problem.

	/*

	 * WQ_HIGHPRI: SEC request must be low delayed,

	 * so need a high priority workqueue.

	 * WQ_UNBOUND: SEC task is likely with long

	 * running CPU intensive workloads.

 enable shaper type 0 */

 Check if iommu is used */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 SEC sqe(bd) bit operational relative MACRO */

 Get an en/de-cipher queue cyclically to balance load over queues of TFM */

 Get DMA memory resources */

/*

 * To improve performance, pbuffer is used for

 * small packets (< 512Bytes) as IOMMU translation using.

	/*

	 * SEC_PBUF_PKG contains data pbuf, iv and

	 * out_mac : <SEC_PBUF|SEC_IV|SEC_MAC>

	 * Every PAGE contains six SEC_PBUF_PKG

	 * The sec_qp_ctx contains QM_Q_DEPTH numbers of SEC_PBUF_PKG

	 * So we need SEC_PBUF_PAGE_NUM numbers of PAGE

	 * for the SEC_TOTAL_PBUF_SZ

 Half of queue depth is taken as fake requests limit in the queue. */

 Copy input mac */

 Set destination and source address type */

 increment counter (128-bit int) */

 IV output at encrypto of CBC/CTR mode */

 the specification has been checked in aead_iv_demension_check() */

 the last 3bit is L' */

 the M' is bit3~bit5, the Flags is bit6 */

	/*

	 * the last 32bit is counter's initial number,

	 * but the nonce uses the first 16bit

	 * the tail 16bit fill with the cipher length

		/*

		 * CCM 16Byte Cipher_IV: {1B_Flage,13B_IV,2B_counter},

		 * the  counter must set to 0x01

 CCM 16Byte Auth_IV: {1B_AFlage,13B_IV,2B_Ptext_length} */

 GCM 12Byte Cipher_IV == Auth_IV */

 C_ICV_Len is MAC size, 0x4 ~ 0x10 */

 mode set to CCM/GCM, don't set {A_Alg, AKey_Len, MAC_Len} */

 C_ICV_Len is MAC size, 0x4 ~ 0x10 */

 mode set to CCM/GCM, don't set {A_Alg, AKey_Len, MAC_Len} */

 Copy output mac */

 To load balance */

 Output IV as decrypto */

 As failing, restore the IV from user */

 software need sync mode to do crypto */

 Support AES or SM4 */

 Kunpeng920 aead mode not support input 0 size */

 To avoid repeat register */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 copy remaining bytes */

 Wait until the task is finished */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 clock gating */

 sentinel */ }

/*

 * One ZIP controller has one PF and multiple VFs, some global configurations

 * which PF has need this structure.

 *

 * Just relevant for PF.

/*

 * uacce_mode = 0 means zip only register to crypto,

 * uacce_mode = 1 means zip both register to crypto and uacce.

 Enable prefetch */

 qm user domain */

 qm cache */

 disable FLR triggered by BME(bus master enable) */

 cache */

 user domain configurations */

 let's open all compression/decompression cores */

 enable sqc,cqc writeback */

 clear ZIP hw error source if having */

 configure error type */

 enable ZIP block master OOO when nfe occurs on Kunpeng930 */

 enable ZIP hw error interrupts */

 disable ZIP hw error interrupts */

 disable ZIP block master OOO when nfe occurs on Kunpeng930 */

 hisi_zip_debug_regs_clear() - clear the zip debug regs */

 enable register read_clear bit */

 disable register read_clear bit */

 Disable ECC Mbit error report. */

 Inject zip ECC Mbit error to block master ooo. */

		/*

		 * have no way to get qm configure in VM in v1 hardware,

		 * so currently force PF to uses HZIP_PF_DEF_Q_NUM, and force

		 * to trigger only one VF in v1 hardware.

		 *

		 * v2 hardware has no such problem.

 enable shaper type 0 */

 ZIP need to enable shaper type 1 */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2019 HiSilicon Limited. */

 hisi_zip_sqe dw3 */

 hisi_zip_sqe dw7 */

 hisi_zip_sqe dw8 */

 hisi_zip_sqe dw9 */

 send command to start a task */

 let's output compression head now */

 alg_type = 0 for compress, 1 for decompress in hw sqe */

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for the HiSilicon SEC units found on Hip06 Hip07

 *

 * Copyright (c) 2016-2017 HiSilicon Limited.

 SEC_ALGSUB registers */

 SEC_SAA registers */

 SEC_COMMON registers */

 W4---W15 */

/*

 * sec_cache_config - configure optimum cache placement

 Check that translation is occurring */

 Always disable write back of normal bd */

 Get the first idle queue in SEC device */

		/*

		 * Must be before callback otherwise blocks adding other chained

		 * elements

 Find which one is least busy and use that first */

/**

 * sec_queue_alloc_start_safe - get a hw queue from appropriate instance

 *

 * This function does extremely simplistic load balancing. It does not take into

 * account NUMA locality of the accelerator, or which cpu has requested the

 * queue.  Future work may focus on optimizing this in order to improve full

 * machine throughput.

/**

 * sec_queue_stop_release() - free up a hw queue for reuse

 * @queue: The queue we are done with.

 *

 * This will stop the current queue, terminanting any transactions

 * that are inflight an return it to the pool of available hw queuess

/**

 * sec_queue_empty() - Is this hardware queue currently empty.

 * @queue: The queue to test

 *

 * We need to know if we have an empty queue for some of the chaining modes

 * as if it is not empty we may need to hold the message in a software queue

 * until the hw queue is drained.

/**

 * sec_queue_send() - queue up a single operation in the hw queue

 * @queue: The queue in which to put the message

 * @msg: The message

 * @ctx: Context to be put in the shadow array and passed back to cb on result.

 *

 * This function will return -EAGAIN if the queue is currently full.

 Ensure content updated before queue advance */

 Enable out of order queue */

 Interrupt after a single complete element */

	/*

	 * Enable all available processing unit clocks.

	 * Only the first cluster is usable with translations.

 32 bit little endian */

 Data axi port write and read outstanding config as per datasheet */

 Enable clock gating */

 Set CNT_CYC register not read clear */

 Enable CNT_CYC */

  do not use debug bd */

 Same QoS for all queues */

 Unexpose as soon as possible, reuse during remove is fine */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2016-2017 HiSilicon Limited. */

/*

 * Mutex used to ensure safe operation of reference count of

 * alg providers

 First one */

 Chained */

 rekeying */

 new key */

 queuelock must be held */

		/*

		 * Add to hardware queue only under following circumstances

		 * 1) Software and hardware queue empty so no chain dependencies

		 * 2) No dependencies as new IV - (check software queue empty

		 *    to maintain order)

		 * 3) No dependencies because the mode does no chaining.

		 *

		 * In other cases first insert onto the software queue which

		 * is then emptied as requests complete

 Wait unti we can send then try again */

 DEAD if here - should not happen */

		/*

		 * We need to muddle on to avoid getting stuck with elements

		 * on the queue. Error will be reported so requester so

		 * it should be able to handle appropriately.

 Put the IV in place for chained cases */

 No need to sync to the device as coherent DMA */

 Do not update */

 We know there is space so this cannot fail */

 Need to verify there is room first */

	/*

	 * Request is done.

	 * The dance is needed as the lock is freed in the completion

 Split into suitable sized blocks */

 output the scatter list before and after this */

/*

 * Reverses the sec_map_and_split_sg call for messages not yet added to

 * the queues.

 Writing whole u32 so no need to take care of masking */

 SGL mapping out here to allow us to break it up as necessary */

 Shared info stored in seq_req - applies to all BDs */

	/*

	 * Future optimization.

	 * In the chaining case we can't use a dma pool bounce buffer

	 * but in the case where we know there is no chaining we can

 Set them all up then queue - cleaner error handling. */

	/*

	 * Only attempt to queue if the whole lot can fit in the queue -

	 * we can't successfully cleanup after a partial queing so this

	 * must succeed or fail atomically.

	 *

	 * Big hammer test of both software and hardware queues - could be

	 * more refined but this is unlikely to happen so no need.

 Grab a big lock for a long time to avoid concurrency issues */

	/*

	 * Can go on to queue if we have space in either:

	 * 1) The hardware queue and no software queue

	 * 2) The software queue

	 * AND there is nothing in the backlog.  If there is backlog we

	 * have to only queue to the backlog queue and return busy.

 Cleanup - all elements in pointer arrays have been copied */

 Unable to find any test vectors so untested */

/*

 * This file is part of the Chelsio T6 Crypto driver for Linux.

 *

 * Copyright (c) 2003-2016 Chelsio Communications, Inc. All rights reserved.

 *

 * This software is available to you under a choice of one of two

 * licenses.  You may choose to be licensed under the terms of the GNU

 * General Public License (GPL) Version 2, available from the file

 * COPYING in the main directory of this source tree, or the

 * OpenIB.org BSD license below:

 *

 *     Redistribution and use in source and binary forms, with or

 *     without modification, are permitted provided that the following

 *     conditions are met:

 *

 *      - Redistributions of source code must retain the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer.

 *

 *      - Redistributions in binary form must reproduce the above

 *        copyright notice, this list of conditions and the following

 *        disclaimer in the documentation and/or other materials

 *        provided with the distribution.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,

 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF

 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND

 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS

 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN

 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN

 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE

 * SOFTWARE.

 *

 * Written and Maintained by:

 *	Manoj Malviya (manojmalviya@chelsio.com)

 *	Atul Gupta (atul.gupta@chelsio.com)

 *	Jitendra Lulla (jlulla@chelsio.com)

 *	Yeshaswi M R Gowda (yeshaswi@chelsio.com)

 *	Harsh Jain (harsh@chelsio.com)

 RotWord(temp) */

 should never get here */

/**

 *	create_cipher_wr - form the WR for cipher operations

 *	@wrparam: Container for create_cipher_wr()'s parameters

 No of block can processed without overflow

	/* For a 192 bit key remove the padded zeroes which was

	 * added in chcr_xts_setkey

Updated before sending last WR*/

/* We need separate function for final iv because in rfc3686  Initial counter

 * starts from 1 and buffer size of iv is 8 byte only which remains constant

 * for subsequent update requests

Already updated for Decrypt*/

CTR mode counter overfloa*/

Min dsgl size*/

 Can be sent as Imm*/

 initialize counter portion of counter block */

	/*RFC3686 initialises IV counter value to 1, rfc3686(ctr(aes))

	 * cannot be used as fallback in chcr_handle_cipher_response

/**

 *	create_hash_wr - Create hash work request

 *	@req: Cipher req base

 *	@param: Container for create_hash_wr()'s parameters

 Request upto max wr size */

	/* Detach state for CHCR means lldi or padap is freed. Increasing

	 * inflight count for dev guarantees that lldi and padap is valid

 Swap buffers */

/*

 *	chcr_handle_resp - Unmap the DMA buffers associated with the request

 *	@req: crypto request

	/* use the key to calculate the ipad and opad. ipad will sent with the

	 * first request's data. opad will be sent with the final hash result

	 * ipad in hmacctx->ipad and opad in hmacctx->opad location

	/* Both keys for xts must be aligned to 16 byte boundary

	 * by padding with zeros. So for 24 byte keys padding 8 zeroes.

 validate key size */

 For IV

	/*

	 * Input order	is AAD,IV and Payload. where IV should be included as

	 * the part of authdata. All other fields should be filled according

	 * to the hardware spec

	/* calculate and handle src and dst sg length separately

	 * for inplace and out-of place operations

	/* calculate and handle src and dst sg length separately

	 * for inplace and out-of place operations

 set m, bits 3-5 */

 set adata, bit 6, if associated data is used */

 2 <= L <= 8, so 1 <= L' <= 7. */

 zero the ctr value */

 For CCM there wil be b0 always. So AAD start will be 1 always */

 For IV and B0

For B0

 For IV

Offset of tag from end

 prepare a 16 byte iv */

 S   A   L  T |  IV | 0x00000001 */

	/*SHA1 authsize in ipsec is 12 instead of 10 i.e maxauthsize / 2 is not

	 * true for sha1. authsize == 12 condition should be before

	 * authsize == (maxauth >> 1)

 nonce/salt is present in the last 4 bytes */

	/* Calculate the H = CIPH(K, 0 repeated 16 times).

	 * It will go in key context

 it contains auth and cipher key both*/

	/* Copy only encryption key. We use authkey to generate h(ipad) and

	 * h(opad) so authkey is not needed again. authkeylen size have the

	 * size of the hash digest size.

 Compute the ipad-digest*/

 Compute the opad-digest */

 convert the ipad and opad digest to network order */

 it contains auth and cipher key both*/

	/* Detach state for CHCR means lldi or padap is freed.

	 * We cannot increment fallback here.

 Form a WR from req */

 AES-CBC */

 SHA */

 HMAC */

 Add AEAD Algorithms */

/*

 *	chcr_unregister_alg - Deregister crypto algorithms with

 *	kernel framework.

/*

 *	chcr_register_alg - Register crypto algorithms with kernel framework.

/*

 *	start_crypto - Register the crypto algorithms.

 *	This should called once when the first device comesup. After this

 *	kernel will start calling driver APIs for crypto operations.

/*

 *	stop_crypto - Deregister all the crypto algorithms with kernel.

 *	This should be called once when the last device goes down. After this

 *	kernel will not call the driver API for crypto operations.

/*

 * This file is part of the Chelsio T4/T5/T6 Ethernet driver for Linux.

 *

 * Copyright (C) 2011-2016 Chelsio Communications.  All rights reserved.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation.

 *

 * Written and Maintained by:

 * Manoj Malviya (manojmalviya@chelsio.com)

 * Atul Gupta (atul.gupta@chelsio.com)

 * Jitendra Lulla (jlulla@chelsio.com)

 * Yeshaswi M R Gowda (yeshaswi@chelsio.com)

 * Harsh Jain (harsh@chelsio.com)

 Max ntxq will be derived from fw config file*/

	/*

	 * When multiple devices are present in system select

	 * device in round-robin fashion for crypto operations

	 * Although One session must use the same device to

	 * maintain request-response ordering.

 call completion callback with failure status */

 Create the device and add it in the device list */

 Create the device and add it in the device list */

 Move u_ctx to inactive_dev list

 ALready Initialised.

 Remove all devices from list */

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright 2015-2016 Freescale Semiconductor Inc.

 * Copyright 2017-2019 NXP

 max key is sum of AES_MAX_KEY_SIZE, max split key size */

/*

 * This is a a cache of buffers, from which the users of CAAM QI driver

 * can allocate short buffers. It's speedier than doing kmalloc on the hotpath.

 * NOTE: A more elegant solution would be to have some headroom in the frames

 *       being processed. This can be added by the dpaa2-eth driver. This would

 *       pose a problem for userspace application processing which cannot

 *       know of this limitation. So for now, this will work.

 * NOTE: The memcache is SMP-safe. No need to handle spinlocks in-here

/**

 * struct caam_ctx - per-session context

 * @flc: Flow Contexts array

 * @key:  [authentication key], encryption key

 * @flc_dma: I/O virtual addresses of the Flow Contexts

 * @key_dma: I/O virtual address of the key

 * @dir: DMA direction for mapping key and Flow Contexts

 * @dev: dpseci device

 * @adata: authentication algorithm details

 * @cdata: encryption algorithm details

 * @authsize: authentication tag (a.k.a. ICV / MAC) size

 * @xts_key_fallback: true if fallback tfm needs to be used due

 *		      to unsupported xts key lengths

 * @fallback: xts fallback tfm

/*

 * qi_cache_zalloc - Allocate buffers from CAAM-QI cache

 *

 * Allocate data on the hotpath. Instead of using kzalloc, one can use the

 * services of the CAAM QI memory cache (backed by kmem_cache). The buffers

 * will have a size of CAAM_QI_MEMCACHE_SIZE, which should be sufficient for

 * hosting 16 SG entries.

 *

 * @flags - flags that would be used for the equivalent kmalloc(..) call

 *

 * Returns a pointer to a retrieved buffer on success or NULL on failure.

/*

 * qi_cache_free - Frees buffers allocated from CAAM-QI cache

 *

 * @obj - buffer previously allocated by qi_cache_zalloc

 *

 * No checking is being done, the call is a passthrough call to

 * kmem_cache_free(...)

	/*

	 * AES-CTR needs to load IV in CONTEXT1 reg

	 * at an offset of 128bits (16bytes)

	 * CONTEXT1[255:128] = IV

	/*

	 * RFC3686 specific:

	 *	CONTEXT1[255:128] = {NONCE, IV, COUNTER}

	/*

	 * In case |user key| > |derived key|, using DKP<imm,imm> would result

	 * in invalid opcodes (last bytes of user key) in the resulting

	 * descriptor. Use DKP<ptr,imm> instead => both virtual and dma key

	 * addresses are needed.

 aead_encrypt shared descriptor */

 SDL */

 aead_decrypt shared descriptor */

 SDL */

 allocate space for base edesc, link tables and IV */

	/*

	 * Create S/G table: req->assoclen, [IV,] req->src [, req->dst].

	 * Input is not contiguous.

	 * HW reads 4 S/G entries at a time; make sure the reads don't go beyond

	 * the end of the table by allocating more S/G entries. Logic:

	 * if (src != dst && output S/G)

	 *      pad output S/G, if needed

	 * else if (src == dst && S/G)

	 *      overlapping S/Gs; pad one of them

	 * else if (input S/G) ...

	 *      pad input S/G, if needed

 Make sure IV is located in a DMAable area */

		/*

		 * The associated data comes already with the IV but we need

		 * to skip it when we authenticate or encrypt...

		/*

		 * crypto engine requires the output entry to be present when

		 * "frame list" FD is used.

		 * Since engine does not support FMT=2'b11 (unused entry type),

		 * leaving out_fle zeroized is the best option.

 SDL */

 SDL */

	/*

	 * AES GCM encrypt shared descriptor

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

 SDL */

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 SDL */

	/*

	 * RFC4106 encrypt shared descriptor

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

 SDL */

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 SDL */

	/*

	 * The last four bytes of the key material are used as the salt value

	 * in the nonce. Update the AES key length.

	/*

	 * RFC4543 encrypt shared descriptor

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

 SDL */

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 SDL */

	/*

	 * The last four bytes of the key material are used as the salt value

	 * in the nonce. Update the AES key length.

 skcipher_encrypt shared descriptor */

 SDL */

 skcipher_decrypt shared descriptor */

 SDL */

	/*

	 * RFC3686 specific:

	 *	| CONTEXT1[255:128] = {NONCE, IV, COUNTER}

	 *	| *key = {KEY, NONCE}

	/*

	 * AES-CTR needs to load IV in CONTEXT1 reg

	 * at an offset of 128bits (16bytes)

	 * CONTEXT1[255:128] = IV

 xts_skcipher_encrypt shared descriptor */

 SDL */

 xts_skcipher_decrypt shared descriptor */

 SDL */

	/*

	 * Input, output HW S/G tables: [IV, src][dst, IV]

	 * IV entries point to the same buffer

	 * If src == dst, S/G entries are reused (S/G tables overlap)

	 *

	 * HW reads 4 S/G entries at a time; make sure the reads don't go beyond

	 * the end of the table by allocating more S/G entries.

 allocate space for base edesc, link tables and IV */

 Make sure IV is located in a DMAable area */

 allocate extended descriptor */

 allocate extended descriptor */

	/*

	 * The crypto API expects us to set the IV (req->iv) to the last

	 * ciphertext block (CBC mode) or last counter (CTR mode).

	 * This is used e.g. by the CTS mode.

	/*

	 * The crypto API expects us to set the IV (req->iv) to the last

	 * ciphertext block (CBC mode) or last counter (CTR mode).

	 * This is used e.g. by the CTS mode.

	/*

	 * XTS is expected to return an error even for input length = 0

	 * Note that the case input length < block size will be caught during

	 * HW offloading and return an error.

 allocate extended descriptor */

	/*

	 * XTS is expected to return an error even for input length = 0

	 * Note that the case input length < block size will be caught during

	 * HW offloading and return an error.

 allocate extended descriptor */

 copy descriptor header template value */

 Galois Counter Mode */

 single-pass ipsec_esp descriptor */

 max hash key is max split key size */

 caam context sizes for hashes: running digest + 8 */

/**

 * struct caam_hash_ctx - ahash per-session context

 * @flc: Flow Contexts array

 * @key: authentication key

 * @flc_dma: I/O virtual addresses of the Flow Contexts

 * @dev: dpseci device

 * @ctx_len: size of Context Register

 * @adata: hashing algorithm details

 ahash state */

 Map current buffer in state (if length > 0) and put it in link table */

 Map state->caam_ctx, and add it to link table */

 ahash_update shared descriptor */

 SDL */

 ahash_update_first shared descriptor */

 SDL */

 ahash_final shared descriptor */

 SDL */

 ahash_digest shared descriptor */

 SDL */

 Digest hash size if it is too large */

 descriptor to perform unkeyed hash on key_in */

 SDL */

 in progress */

	/*

	 * In case |user key| > |derived key|, using DKP<imm,imm> would result

	 * in invalid opcodes (last bytes of user key) in the resulting

	 * descriptor. Use DKP<ptr,imm> instead => both virtual and dma key

	 * addresses are needed.

 allocate space for base edesc and link tables */

 allocate space for base edesc and link tables */

 allocate space for base edesc and link tables */

 allocate space for base edesc and link tables */

 allocate space for base edesc and link tables */

	/*

	 * crypto engine requires the input entry to be present when

	 * "frame list" FD is used.

	 * Since engine does not support FMT=2'b11 (unused entry type), leaving

	 * in_fle zeroized (except for "Final" flag) is the best option.

 allocate space for base edesc and link tables */

 allocate space for base edesc and link tables */

 allocate space for base edesc and link tables */

 ahash descriptors */

 Sizes for MDHA running digests: MD5, SHA1, 224, 256, 384, 512 */

 copy descriptor header template value */

	/*

	 * For keyed hash algorithms shared descriptors

	 * will be created later in setkey() callback

 Register notification callbacks */

			/*

			 * If no affine DPIO for this core, there's probably

			 * none available for next cores either. Signal we want

			 * to retry later, in case the DPIO devices weren't

			 * probed yet.

 Configure Rx queues */

		/*

		 * Rx priority (WQ) doesn't really matter, since we use

		 * pull mode, i.e. volatile dequeues from specific FQs

	/*

	 * FD[ADDR] is guaranteed to be valid, irrespective of errors reported

	 * in FD[ERR] or FD[FRC].

 Retry while portal is busy */

				/*

				 * MUST retry until we get some sort of

				 * valid response token (be it "empty dequeue"

				 * or a valid frame).

 Process FD */

 Try to dequeue some more */

	/*

	 * Congestion group feature supported starting with DPSECI API v5.1

	 * and only when object has been created with this capability.

 Get a handle for the DPSECI this interface is associate with */

		/*

		 * Allow all cores to enqueue, while only some of them

		 * will take part in dequeuing.

	/*

	 * There is no way to get CAAM endianness - there is no direct register

	 * space access and MC f/w does not provide this attribute.

	 * All DPAA2-based SoCs have little endian CAAM, thus hard-code this

	 * property.

 Obtain a MC portal */

 DPSECI initialization */

 DPIO */

 DPSECI binding to DPIO */

 DPSECI enable */

 register crypto algorithms the device supports */

 Skip DES algorithms if not supported by device */

 Skip AES algorithms if not supported by device */

 Skip CHACHA20 algorithms if not supported by device */

 Skip DES algorithms if not supported by device */

 Skip AES algorithms if not supported by device */

 Skip CHACHA20 algorithms if not supported by device */

 Skip POLY1305 algorithms if not supported by device */

		/*

		 * Skip algorithms requiring message digests

		 * if MD not supported by device.

 register hash algorithms the device supports */

	/*

	 * Skip registration of any hashing algorithms if MD block

	 * is not present.

 register hmac version */

 register unkeyed version */

 SPDX-License-Identifier: GPL-2.0+

/*

 * CAAM/SEC 4.x transport/backend driver

 * JobR backend functionality

 *

 * Copyright 2008-2012 Freescale Semiconductor, Inc.

 * Copyright 2019 NXP

 List of Physical JobR's with the Driver */

 jr_list lock */

 Free the resources of crypto-engine */

	/*

	 * mask interrupts since we are going to poll

	 * for reset completion status

 initiate flush (required prior to reset) */

 initiate reset */

 unmask interrupts */

/*

 * Shutdown JobR independent of platform property code

	/*

	 * Return EBUSY if job ring already allocated.

 Unregister JR-based RNG & crypto algorithms */

 Remove the node from Physical JobR list maintained by driver */

 Release ring */

 Main per-ring interrupt handler */

	/*

	 * Check the output ring for ready responses, kick

	 * tasklet if jobs done.

	/*

	 * If JobR error, we got more development work to do

	 * Flag a bug now, but we really need to shut down and

	 * restart the queue (and fix code).

 mask valid interrupts */

 Have valid interrupt at this point, just ACK and trigger */

 Deferred service handler, run as interrupt-fired tasklet */

 found */

 we should never fail to find a matching descriptor */

 Unmap just-run descriptor so we can post-process */

 mark completed, avoid matching on a recycled desc addr */

 Stash callback params */

		/*

		 * Make sure all information from the job has been obtained

		 * before telling CAAM that the job has been removed from the

		 * output ring.

 set done */

		/*

		 * if this job completed out-of-order, do not increment

		 * the tail.  Otherwise, increment tail by 1 plus the

		 * number of subsequent jobs already completed out-of-order

 Finally, execute user's callback */

 reenable / unmask IRQs */

/**

 * caam_jr_alloc() - Alloc a job ring for someone to use as needed.

 *

 * returns :  pointer to the newly allocated physical

 *	      JobR dev can be written to if successful.

/**

 * caam_jr_free() - Free the Job Ring

 * @rdev:      points to the dev that identifies the Job ring to

 *             be released.

/**

 * caam_jr_enqueue() - Enqueue a job descriptor head. Returns -EINPROGRESS

 * if OK, -ENOSPC if the queue is full, -EIO if it cannot map the caller's

 * descriptor.

 * @dev:  struct device of the job ring to be used

 * @desc: points to a job descriptor that execute our request. All

 *        descriptors (and all referenced data) must be in a DMAable

 *        region, and all data references must be physical addresses

 *        accessible to CAAM (i.e. within a PAMU window granted

 *        to it).

 * @cbk:  pointer to a callback function to be invoked upon completion

 *        of this request. This has the form:

 *        callback(struct device *dev, u32 *desc, u32 stat, void *arg)

 *        where:

 *        dev:     contains the job ring device that processed this

 *                 response.

 *        desc:    descriptor that initiated the request, same as

 *                 "desc" being argued to caam_jr_enqueue().

 *        status:  untranslated status received from CAAM. See the

 *                 reference manual for a detailed description of

 *                 error meaning, or see the JRSTA definitions in the

 *                 register header file

 *        areq:    optional pointer to an argument passed with the

 *                 original request

 * @areq: optional pointer to a user argument for use at callback

 *        time.

	/*

	 * Guarantee that the descriptor's DMA address has been written to

	 * the next slot in the ring before the write index is updated, since

	 * other cores may update this index independently.

	/*

	 * Ensure that all job information has been written before

	 * notifying CAAM that a new job was added to the input ring

	 * using a memory barrier. The wr_reg32() uses api iowrite32()

	 * to do the register write. iowrite32() issues a memory barrier

	 * before the write operation.

/*

 * Init JobR independent of platform property detection

 Setup rings */

 Select interrupt coalescing parameters */

 Connect job ring interrupt handler. */

/*

 * Probe routine for each detected JobR subsystem.

 save ring identity relative to detection */

 Get configuration properties from device tree */

 First, get register page */

 Initialize crypto engine */

 Start crypto engine */

 Identify the interrupt */

 Now do the platform independent part */

 now turn on hardware */

 SPDX-License-Identifier: GPL-2.0

/*

 * CAAM/SEC 4.x QI transport/backend driver

 * Queue Interface backend functionality

 *

 * Copyright 2013-2016 Freescale Semiconductor, Inc.

 * Copyright 2016-2017, 2019-2020 NXP

/*

 * Use a reasonable backlog of frames (per CPU) as congestion threshold,

 * so that resources used by the in-flight buffers do not become a memory hog.

/*

 * caam_napi - struct holding CAAM NAPI-related params

 * @irqtask: IRQ task for QI backend

 * @p: QMan portal

/*

 * caam_qi_pcpu_priv - percpu private data structure to main list of pending

 *                     responses expected on each cpu.

 * @caam_napi: CAAM NAPI params

 * @net_dev: netdev used by NAPI

 * @rsp_fq: response FQ from CAAM

/*

 * caam_qi_priv - CAAM QI backend private params

 * @cgr: QMan congestion group

/*

 * This is written by only one core - the one that initialized the CGR - and

 * read by multiple cores (all the others).

/*

 * This is a a cache of buffers, from which the users of CAAM QI driver

 * can allocate short (CAAM_QI_MEMCACHE_SIZE) buffers. It's faster than

 * doing malloc on the hotpath.

 * NOTE: A more elegant solution would be to have some headroom in the frames

 *       being processed. This could be added by the dpaa-ethernet driver.

 *       This would pose a problem for userspace application processing which

 *       cannot know of this limitation. So for now, this will work.

 * NOTE: The memcache is SMP-safe. No need to handle spinlocks in-here

 Async FQ retirement condition */

 Retry till FQ gets in retired state */

 Wait till the older CAAM FQ get empty */

 Wait until pending jobs from this FQ are processed by CAAM */

 Note down older req FQ */

 Create a new req FQ in parked state */

 Hook up new FQ to context so that new requests keep queuing */

 Empty and remove the older FQ */

 We can revert to older FQ */

	/*

	 * Re-initialise pre-header. Set RSLS and SDLEN.

	 * Update the shared descriptor for driver context.

 Put the new FQ in scheduled state */

		/*

		 * We can kill new FQ and revert to old FQ.

		 * Since the desc is already modified, it is success case

	/*

	 * Initialise pre-header - set RSLS and SDLEN - and shared descriptor

	 * and dma-map them.

 If given CPU does not own the portal, choose another one that does */

 Find response FQ hooked with this CPU */

 Attach request FQ */

 init reference counter used to track references to request FQ */

 Remove request FQ */

 Disable QMan IRQ source and invoke NAPI */

Now create response FQs*/

 Initialize the congestion detection */

 Initialise response FQs */

	/*

	 * Enable the NAPI contexts on each of the core which has an affine

	 * portal.

 SPDX-License-Identifier: GPL-2.0+

/*

 * caam - Freescale FSL CAAM support for ahash functions of crypto API

 *

 * Copyright 2011 Freescale Semiconductor, Inc.

 * Copyright 2018-2019 NXP

 *

 * Based on caamalg.c crypto API driver.

 *

 * relationship of digest job descriptor or first job descriptor after init to

 * shared descriptors:

 *

 * ---------------                     ---------------

 * | JobDesc #1  |-------------------->|  ShareDesc  |

 * | *(packet 1) |                     |  (hashKey)  |

 * ---------------                     | (operation) |

 *                                     ---------------

 *

 * relationship of subsequent job descriptors to shared descriptors:

 *

 * ---------------                     ---------------

 * | JobDesc #2  |-------------------->|  ShareDesc  |

 * | *(packet 2) |      |------------->|  (hashKey)  |

 * ---------------      |    |-------->| (operation) |

 *       .              |    |         | (load ctx2) |

 *       .              |    |         ---------------

 * ---------------      |    |

 * | JobDesc #3  |------|    |

 * | *(packet 3) |           |

 * ---------------           |

 *       .                   |

 *       .                   |

 * ---------------           |

 * | JobDesc #4  |------------

 * | *(packet 4) |

 * ---------------

 *

 * The SharedDesc never changes for a connection unless rekeyed, but

 * each packet will likely be in a different place. So all we need

 * to know to process the packet is where the input is, where the

 * output goes, and what context we want to process with. Context is

 * in the SharedDesc, packet references in the JobDesc.

 *

 * So, a job desc looks like:

 *

 * ---------------------

 * | Header            |

 * | ShareDesc Pointer |

 * | SEQ_OUT_PTR       |

 * | (output buffer)   |

 * | (output length)   |

 * | SEQ_IN_PTR        |

 * | (input buffer)    |

 * | (input length)    |

 * ---------------------

 max hash key is max split key size */

 caam context sizes for hashes: running digest + 8 */

 ahash per-session context */

 ahash state */

 Common job descriptor seq in/out ptr routines */

 Map state->caam_ctx, and append seq_out_ptr command that points to it */

 Map current buffer in state (if length > 0) and put it in link table */

 Map state->caam_ctx, and add it to link table */

 ahash_update shared descriptor */

 ahash_update_first shared descriptor */

 ahash_final shared descriptor */

 ahash_digest shared descriptor */

 shared descriptor for ahash_update */

 shared descriptor for ahash_{final,finup} */

 key is immediate data for INIT and INITFINAL states */

 shared descriptor for first invocation of ahash_update */

 shared descriptor for ahash_digest */

 shared descriptor for ahash_update */

 shared descriptor for ahash_{final,finup} */

 shared descriptor for first invocation of ahash_update */

 shared descriptor for ahash_digest */

 Digest hash size if it is too large */

 Job descriptor to perform unkeyed hash on key_in */

 in progress */

	/*

	 * If DKP is supported, use it in the shared descriptor to generate

	 * the split key.

		/*

		 * In case |user key| > |derived key|, using DKP<imm,imm>

		 * would result in invalid opcodes (last bytes of user key) in

		 * the resulting descriptor. Use DKP<ptr,imm> instead => both

		 * virtual and dma key addresses are needed.

 key is immediate data for all cmac shared descriptors */

/*

 * ahash_edesc - s/w-extended ahash descriptor

 * @sec4_sg_dma: physical mapped address of h/w link table

 * @src_nents: number of segments in input scatterlist

 * @sec4_sg_bytes: length of dma mapped sec4_sg space

 * @bklog: stored to determine if the request needs backlog

 * @hw_desc: the h/w job descriptor followed by any referenced link tables

 * @sec4_sg: h/w link table

	/*

	 * If no backlog flag, the completion of the request is done

	 * by CAAM, not crypto engine.

	/*

	 * If no backlog flag, the completion of the request is done

	 * by CAAM, not crypto engine.

/*

 * Allocate an enhanced descriptor, which contains the hardware descriptor

 * and space for hardware scatter table containing sg_num entries.

	/*

	 * Only the backlog request are sent to crypto-engine since the others

	 * can be handled by CAAM, if free, especially since JR has up to 1024

	 * entries (more than the 10 entries from crypto-engine).

 submit update job descriptor */

	/*

	 * For XCBC and CMAC, if to_hash is multiple of block size,

	 * keep last block in internal buffer

		/*

		 * allocate space for base edesc and hw desc commands,

		 * link tables

 allocate space for base edesc and hw desc commands, link tables */

 allocate space for base edesc and hw desc commands, link tables */

 allocate space for base edesc and hw desc commands, link tables */

 submit ahash final if it the first job descriptor */

 allocate space for base edesc and hw desc commands, link tables */

 submit ahash update if it the first job descriptor after update */

	/*

	 * For XCBC and CMAC, if to_hash is multiple of block size,

	 * keep last block in internal buffer

		/*

		 * allocate space for base edesc and hw desc commands,

		 * link tables

 submit ahash finup if it the first job descriptor after update */

 allocate space for base edesc and hw desc commands, link tables */

 submit first update job descriptor after init */

	/*

	 * For XCBC and CMAC, if to_hash is multiple of block size,

	 * keep last block in internal buffer

		/*

		 * allocate space for base edesc and hw desc commands,

		 * link tables

 ahash descriptors */

 Sizes for MDHA running digests: MD5, SHA1, 224, 256, 384, 512 */

	/*

	 * Get a Job ring from Job Ring driver to ensure in-order

	 * crypto request processing per tfm

	/*

	 * For keyed hash algorithms shared descriptors

	 * will be created later in setkey() callback

	/*

	 * Register crypto algorithms the device supports.  First, identify

	 * presence and attributes of MD block.

	/*

	 * Skip registration of any hashing algorithms if MD block

	 * is not present.

 Limit digest size based on LP256 */

 register crypto algorithms the device supports */

 If MD size is not supported by device, skip registration */

 register hmac version */

 register unkeyed version */

 SPDX-License-Identifier: GPL-2.0

/*

 * CAAM/SEC 4.x functions for handling key-generation jobs

 *

 * Copyright 2008-2011 Freescale Semiconductor, Inc.

 *

/*

get a split ipad/opad key



Split key generation-----------------------------------------------



[00] 0xb0810008    jobdesc: stidx=1 share=never len=8

[01] 0x04000014        key: class2->keyreg len=20

			@0xffe01000

[03] 0x84410014  operation: cls2-op sha1 hmac init dec

[04] 0x24940000     fifold: class2 msgdata-last2 len=0 imm

[05] 0xa4000001       jump: class2 local all ->1 [06]

[06] 0x64260028    fifostr: class2 mdsplit-jdk len=40

			@0xffe04000

 Sets MDHA up into an HMAC-INIT */

	/*

	 * do a FIFO_LOAD of zero, this will trigger the internal key expansion

	 * into both pads inside MDHA

	/*

	 * FIFO_STORE with the explicit split-key content store

	 * (0x26 output type)

 in progress */

 SPDX-License-Identifier: GPL-2.0

/*

 * caam - Freescale FSL CAAM support for Public Key Cryptography descriptors

 *

 * Copyright 2016 Freescale Semiconductor, Inc.

 *

 * There is no Shared Descriptor for PKC so that the Job Descriptor must carry

 * all the desired key parameters, input and output pointers.

 Descriptor for RSA Public operation */

 Descriptor for RSA Private operation - Private Key Form #1 */

 Descriptor for RSA Private operation - Private Key Form #2 */

 Descriptor for RSA Private operation - Private Key Form #3 */

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

 Copyright 2019 NXP */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Shared descriptors for aead, skcipher algorithms

 *

 * Copyright 2016-2019 NXP

/*

 * For aead functions, read payload and write payload,

 * both of which are specified in req->src and req->dst

 Set DK bit in class 1 operation if shared */

 DK bit is valid only for AES */

/**

 * cnstr_shdsc_aead_null_encap - IPSec ESP encapsulation shared descriptor

 *                               (non-protocol) with no (null) encryption.

 * @desc: pointer to buffer used for descriptor construction

 * @adata: pointer to authentication transform definitions.

 *         A split key is required for SEC Era < 6; the size of the split key

 *         is specified in this case. Valid algorithm values - one of

 *         OP_ALG_ALGSEL_{MD5, SHA1, SHA224, SHA256, SHA384, SHA512} ANDed

 *         with OP_ALG_AAI_HMAC_PRECOMP.

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @era: SEC Era

 Skip if already shared */

 assoclen + cryptlen = seqinlen */

 Prepare to read and write cryptlen + assoclen bytes */

	/*

	 * MOVE_LEN opcode is not available in all SEC HW revisions,

	 * thus need to do some magic, i.e. self-patch the descriptor

	 * buffer.

 Class 2 operation */

 Read and write cryptlen bytes */

 Write ICV */

/**

 * cnstr_shdsc_aead_null_decap - IPSec ESP decapsulation shared descriptor

 *                               (non-protocol) with no (null) decryption.

 * @desc: pointer to buffer used for descriptor construction

 * @adata: pointer to authentication transform definitions.

 *         A split key is required for SEC Era < 6; the size of the split key

 *         is specified in this case. Valid algorithm values - one of

 *         OP_ALG_ALGSEL_{MD5, SHA1, SHA224, SHA256, SHA384, SHA512} ANDed

 *         with OP_ALG_AAI_HMAC_PRECOMP.

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @era: SEC Era

 Skip if already shared */

 Class 2 operation */

 assoclen + cryptlen = seqoutlen */

 Prepare to read and write cryptlen + assoclen bytes */

	/*

	 * MOVE_LEN opcode is not available in all SEC HW revisions,

	 * thus need to do some magic, i.e. self-patch the descriptor

	 * buffer.

 Read and write cryptlen bytes */

	/*

	 * Insert a NOP here, since we need at least 4 instructions between

	 * code patching the descriptor buffer and the location being patched.

 Load ICV */

 Note: Context registers are saved. */

 Skip if already shared */

	/*

	 * RFC3686 specific:

	 *	| key = {AUTH_KEY, ENC_KEY, NONCE}

	 *	| enckeylen = encryption key size + nonce size

 Load Counter into CONTEXT1 reg */

/**

 * cnstr_shdsc_aead_encap - IPSec ESP encapsulation shared descriptor

 *                          (non-protocol).

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - one of OP_ALG_ALGSEL_{AES, DES, 3DES} ANDed

 *         with OP_ALG_AAI_CBC or OP_ALG_AAI_CTR_MOD128.

 * @adata: pointer to authentication transform definitions.

 *         A split key is required for SEC Era < 6; the size of the split key

 *         is specified in this case. Valid algorithm values - one of

 *         OP_ALG_ALGSEL_{MD5, SHA1, SHA224, SHA256, SHA384, SHA512} ANDed

 *         with OP_ALG_AAI_HMAC_PRECOMP.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_rfc3686: true when ctr(aes) is wrapped by rfc3686 template

 * @nonce: pointer to rfc3686 nonce

 * @ctx1_iv_off: IV offset in CONTEXT1 register

 * @is_qi: true when called from caam/qi

 * @era: SEC Era

 Note: Context registers are saved. */

 Class 2 operation */

 REG3 = assoclen */

 Read and write assoclen bytes */

 Skip assoc data */

 read assoc before reading payload */

 Load Counter into CONTEXT1 reg */

 Class 1 operation */

 Read and write cryptlen bytes */

 Write ICV */

/**

 * cnstr_shdsc_aead_decap - IPSec ESP decapsulation shared descriptor

 *                          (non-protocol).

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - one of OP_ALG_ALGSEL_{AES, DES, 3DES} ANDed

 *         with OP_ALG_AAI_CBC or OP_ALG_AAI_CTR_MOD128.

 * @adata: pointer to authentication transform definitions.

 *         A split key is required for SEC Era < 6; the size of the split key

 *         is specified in this case. Valid algorithm values - one of

 *         OP_ALG_ALGSEL_{MD5, SHA1, SHA224, SHA256, SHA384, SHA512} ANDed

 *         with OP_ALG_AAI_HMAC_PRECOMP.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @geniv: whether to generate Encrypted Chain IV

 * @is_rfc3686: true when ctr(aes) is wrapped by rfc3686 template

 * @nonce: pointer to rfc3686 nonce

 * @ctx1_iv_off: IV offset in CONTEXT1 register

 * @is_qi: true when called from caam/qi

 * @era: SEC Era

 Note: Context registers are saved. */

 Class 2 operation */

 REG3 = assoclen */

 Read and write assoclen bytes */

 Skip assoc data */

 read assoc before reading payload */

 Load Counter into CONTEXT1 reg */

 Choose operation */

 Read and write cryptlen bytes */

 Load ICV */

/**

 * cnstr_shdsc_aead_givencap - IPSec ESP encapsulation shared descriptor

 *                             (non-protocol) with HW-generated initialization

 *                             vector.

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - one of OP_ALG_ALGSEL_{AES, DES, 3DES} ANDed

 *         with OP_ALG_AAI_CBC or OP_ALG_AAI_CTR_MOD128.

 * @adata: pointer to authentication transform definitions.

 *         A split key is required for SEC Era < 6; the size of the split key

 *         is specified in this case. Valid algorithm values - one of

 *         OP_ALG_ALGSEL_{MD5, SHA1, SHA224, SHA256, SHA384, SHA512} ANDed

 *         with OP_ALG_AAI_HMAC_PRECOMP.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_rfc3686: true when ctr(aes) is wrapped by rfc3686 template

 * @nonce: pointer to rfc3686 nonce

 * @ctx1_iv_off: IV offset in CONTEXT1 register

 * @is_qi: true when called from caam/qi

 * @era: SEC Era

 Note: Context registers are saved. */

 REG3 = assoclen */

 Generate IV */

 Copy IV to class 1 context */

 Return to encryption */

 Read and write assoclen bytes */

 Skip assoc data */

 read assoc before reading payload */

 Copy iv from outfifo to class 2 fifo */

 Load Counter into CONTEXT1 reg */

 Class 1 operation */

 Will write ivsize + cryptlen */

 Not need to reload iv */

 Will read cryptlen */

	/*

	 * Wait for IV transfer (ofifo -> class2) to finish before starting

	 * ciphertext transfer (ofifo -> external memory).

 Write ICV */

/**

 * cnstr_shdsc_gcm_encap - gcm encapsulation shared descriptor

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_GCM.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_qi: true when called from caam/qi

 skip key loading if they are loaded due to sharing */

 class 1 operation */

 REG3 = assoclen */

 if assoclen + cryptlen is ZERO, skip to ICV write */

 if assoclen is ZERO, skip reading the assoc data */

 skip assoc data */

 cryptlen = seqinlen - assoclen */

 if cryptlen is ZERO jump to zero-payload commands */

 read assoc data */

 write encrypted data */

 read payload data */

 jump to ICV writing */

 zero-payload commands */

 read assoc data */

 jump to ICV writing */

 There is no input data */

 write ICV */

/**

 * cnstr_shdsc_gcm_decap - gcm decapsulation shared descriptor

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_GCM.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_qi: true when called from caam/qi

 skip key loading if they are loaded due to sharing */

 class 1 operation */

 REG3 = assoclen */

 if assoclen is ZERO, skip reading the assoc data */

 skip assoc data */

 read assoc data */

 cryptlen = seqoutlen - assoclen */

 jump to zero-payload command if cryptlen is zero */

 store encrypted data */

 read payload data */

 zero-payload command */

 read ICV */

/**

 * cnstr_shdsc_rfc4106_encap - IPSec ESP gcm encapsulation shared descriptor

 *                             (non-protocol).

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_GCM.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_qi: true when called from caam/qi

 *

 * Input sequence: AAD | PTXT

 * Output sequence: AAD | CTXT | ICV

 * AAD length (assoclen), which includes the IV length, is available in Math3.

 Skip key loading if it is loaded due to sharing */

 Class 1 operation */

 REG3 = assoclen */

 Read salt and IV */

 Skip AAD */

 Read cryptlen and set this value into VARSEQOUTLEN */

 If cryptlen is ZERO jump to AAD command */

 Read AAD data */

 Workaround for erratum A-005473 (simultaneous SEQ FIFO skips) */

 Skip IV */

 Write encrypted data */

 Read payload data */

 Jump instructions to avoid double reading of AAD */

 There is no input data, cryptlen = 0 */

 Read AAD */

 Write ICV */

/**

 * cnstr_shdsc_rfc4106_decap - IPSec ESP gcm decapsulation shared descriptor

 *                             (non-protocol).

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_GCM.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_qi: true when called from caam/qi

 Skip key loading if it is loaded due to sharing */

 Class 1 operation */

 REG3 = assoclen */

 Read salt and IV */

 Read assoc data */

 Skip IV */

 Will read cryptlen bytes */

 Workaround for erratum A-005473 (simultaneous SEQ FIFO skips) */

 Skip assoc data */

 Will write cryptlen bytes */

 Store payload data */

 Read encrypted data */

 Read ICV */

/**

 * cnstr_shdsc_rfc4543_encap - IPSec ESP gmac encapsulation shared descriptor

 *                             (non-protocol).

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_GCM.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_qi: true when called from caam/qi

 Skip key loading if it is loaded due to sharing */

 Class 1 operation */

 assoclen is not needed, skip it */

 Read salt and IV */

 assoclen + cryptlen = seqinlen */

	/*

	 * MOVE_LEN opcode is not available in all SEC HW revisions,

	 * thus need to do some magic, i.e. self-patch the descriptor

	 * buffer.

 Will read assoclen + cryptlen bytes */

 Will write assoclen + cryptlen bytes */

 Read and write assoclen + cryptlen bytes */

 Move payload data to OFIFO */

 Write ICV */

/**

 * cnstr_shdsc_rfc4543_decap - IPSec ESP gmac decapsulation shared descriptor

 *                             (non-protocol).

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_GCM.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @is_qi: true when called from caam/qi

 Skip key loading if it is loaded due to sharing */

 Class 1 operation */

 assoclen is not needed, skip it */

 Read salt and IV */

 assoclen + cryptlen = seqoutlen */

	/*

	 * MOVE_LEN opcode is not available in all SEC HW revisions,

	 * thus need to do some magic, i.e. self-patch the descriptor

	 * buffer.

 Will read assoclen + cryptlen bytes */

 Will write assoclen + cryptlen bytes */

 Store payload data */

 In-snoop assoclen + cryptlen data */

 Move payload data to OFIFO */

 Read ICV */

/**

 * cnstr_shdsc_chachapoly - Chacha20 + Poly1305 generic AEAD (rfc7539) and

 *                          IPsec ESP (rfc7634, a.k.a. rfc7539esp) shared

 *                          descriptor (non-protocol).

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_CHACHA20 ANDed with

 *         OP_ALG_AAI_AEAD.

 * @adata: pointer to authentication transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_POLY1305 ANDed with

 *         OP_ALG_AAI_AEAD.

 * @ivsize: initialization vector size

 * @icvsize: integrity check value (ICV) size (truncated or full)

 * @encap: true if encapsulation, false if decapsulation

 * @is_qi: true when called from caam/qi

 Note: Context registers are saved. */

 skip key loading if they are loaded due to sharing */

 For IPsec load the salt from keymat in the context register */

 Class 2 and 1 operations: Poly & ChaCha */

 REG3 = assoclen */

	/*

	 * MAGIC with NFIFO

	 * Read associated data from the input and send them to class1 and

	 * class2 alignment blocks. From class1 send data to output fifo and

	 * then write it to memory since we don't need to encrypt AD.

 IPsec - copy IV at the output */

 Read and write cryptlen bytes */

 Write ICV */

 Read and write cryptlen bytes */

 Load ICV for verification */

 For skcipher encrypt and decrypt, read from req->src and write to req->dst */

/**

 * cnstr_shdsc_skcipher_encap - skcipher encapsulation shared descriptor

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - one of OP_ALG_ALGSEL_{AES, DES, 3DES} ANDed

 *         with OP_ALG_AAI_CBC or OP_ALG_AAI_CTR_MOD128

 *                                - OP_ALG_ALGSEL_CHACHA20

 * @ivsize: initialization vector size

 * @is_rfc3686: true when ctr(aes) is wrapped by rfc3686 template

 * @ctx1_iv_off: IV offset in CONTEXT1 register

 Skip if already shared */

 Load class1 key only */

 Load nonce into CONTEXT1 reg */

 Load IV, if there is one */

 Load counter into CONTEXT1 reg */

 Load operation */

 Perform operation */

 Store IV */

/**

 * cnstr_shdsc_skcipher_decap - skcipher decapsulation shared descriptor

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - one of OP_ALG_ALGSEL_{AES, DES, 3DES} ANDed

 *         with OP_ALG_AAI_CBC or OP_ALG_AAI_CTR_MOD128

 *                                - OP_ALG_ALGSEL_CHACHA20

 * @ivsize: initialization vector size

 * @is_rfc3686: true when ctr(aes) is wrapped by rfc3686 template

 * @ctx1_iv_off: IV offset in CONTEXT1 register

 Skip if already shared */

 Load class1 key only */

 Load nonce into CONTEXT1 reg */

 Load IV, if there is one */

 Load counter into CONTEXT1 reg */

 Choose operation */

 Perform operation */

 Store IV */

/**

 * cnstr_shdsc_xts_skcipher_encap - xts skcipher encapsulation shared descriptor

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_XTS.

	/*

	 * Set sector size to a big value, practically disabling

	 * sector size segmentation in xts implementation. We cannot

	 * take full advantage of this HW feature with existing

	 * crypto API / dm-crypt SW architecture.

 Skip if already shared */

 Load class1 keys only */

 Load sector size with index 40 bytes (0x28) */

	/*

	 * create sequence for loading the sector index / 16B tweak value

	 * Lower 8B of IV - sector index / tweak lower half

	 * Upper 8B of IV - upper half of 16B tweak

 Load operation */

 Perform operation */

 Store lower 8B and upper 8B of IV */

/**

 * cnstr_shdsc_xts_skcipher_decap - xts skcipher decapsulation shared descriptor

 * @desc: pointer to buffer used for descriptor construction

 * @cdata: pointer to block cipher transform definitions

 *         Valid algorithm values - OP_ALG_ALGSEL_AES ANDed with OP_ALG_AAI_XTS.

	/*

	 * Set sector size to a big value, practically disabling

	 * sector size segmentation in xts implementation. We cannot

	 * take full advantage of this HW feature with existing

	 * crypto API / dm-crypt SW architecture.

 Skip if already shared */

 Load class1 key only */

 Load sector size with index 40 bytes (0x28) */

	/*

	 * create sequence for loading the sector index / 16B tweak value

	 * Lower 8B of IV - sector index / tweak lower half

	 * Upper 8B of IV - upper half of 16B tweak

 Load operation */

 Perform operation */

 Store lower 8B and upper 8B of IV */

 SPDX-License-Identifier: GPL-2.0+

/* * CAAM control-plane driver backend

 * Controller-level driver, kernel property detection, initialization

 *

 * Copyright 2008-2012 Freescale Semiconductor, Inc.

 * Copyright 2018-2019 NXP

/*

 * Descriptor to instantiate RNG State Handle 0 in normal mode and

 * load the JDKEK, TDKEK and TDSK registers

 INIT RNG in non-test mode */

		/*

		 * For SH0, Secure Keys must be generated as well

 wait for done */

		/*

		 * load 1 to clear written reg:

		 * resets the done interrupt and returns the RNG to idle.

 Initialize State Handle  */

 Descriptor for deinstantiation of State Handle 0 of the RNG block. */

 Uninstantiate State Handle 0 */

/*

 * run_descriptor_deco0 - runs a descriptor on DECO0, under direct control of

 *			  the software (no JR/QI used).

 * @ctrldev - pointer to device

 * @status - descriptor status, after being run

 *

 * Return: - 0 if no error occurred

 *	   - -ENODEV if the DECO couldn't be acquired

 *	   - -EAGAIN if an error occurred while executing the descriptor

	    /*

	     * Apparently on i.MX8M{Q,M,N,P} it doesn't matter if virt_en == 1

	     * and the following steps should be performed regardless

	/*

	 * If the descriptor length is longer than 4 words, then the

	 * FOUR bit in JRCTRL register must be set.

 Instruct the DECO to execute it */

		/*

		 * If an error occurred in the descriptor, then

		 * the DECO status field will be set to 0x0D

 Mark the DECO as free */

/*

 * deinstantiate_rng - builds and executes a descriptor on DECO0,

 *		       which deinitializes the RNG block.

 * @ctrldev - pointer to device

 * @state_handle_mask - bitmask containing the instantiation status

 *			for the RNG4 state handles which exist in

 *			the RNG4 block: 1 if it's been instantiated

 *

 * Return: - 0 if no error occurred

 *	   - -ENOMEM if there isn't enough memory to allocate the descriptor

 *	   - -ENODEV if DECO0 couldn't be acquired

 *	   - -EAGAIN if an error occurred when executing the descriptor

		/*

		 * If the corresponding bit is set, then it means the state

		 * handle was initialized by us, and thus it needs to be

		 * deinitialized as well

			/*

			 * Create the descriptor for deinstantating this state

			 * handle

 Try to run it through DECO0 */

	/*

	 * De-initialize RNG state handles initialized by this driver.

	 * In case of SoCs with Management Complex, RNG is managed by MC f/w.

/*

 * instantiate_rng - builds and executes a descriptor on DECO0,

 *		     which initializes the RNG block.

 * @ctrldev - pointer to device

 * @state_handle_mask - bitmask containing the instantiation status

 *			for the RNG4 state handles which exist in

 *			the RNG4 block: 1 if it's been instantiated

 *			by an external entry, 0 otherwise.

 * @gen_sk  - generate data to be loaded into the JDKEK, TDKEK and TDSK;

 *	      Caution: this can be done only once; if the keys need to be

 *	      regenerated, a POR is required

 *

 * Return: - 0 if no error occurred

 *	   - -ENOMEM if there isn't enough memory to allocate the descriptor

 *	   - -ENODEV if DECO0 couldn't be acquired

 *	   - -EAGAIN if an error occurred when executing the descriptor

 *	      f.i. there was a RNG hardware error due to not "good enough"

 *	      entropy being acquired.

		/*

		 * If the corresponding bit is set, this state handle

		 * was initialized by somebody else, so it's left alone.

 Create the descriptor for instantiating RNG State Handle */

 Try to run it through DECO0 */

		/*

		 * If ret is not 0, or descriptor status is not 0, then

		 * something went wrong. No need to try the next state

		 * handle (if available), bail out here.

		 * Also, if for some reason, the State Handle didn't get

		 * instantiated although the descriptor has finished

		 * without any error (HW optimizations for later

		 * CAAM eras), then try again.

 Clear the contents before recreating the descriptor */

/*

 * kick_trng - sets the various parameters for enabling the initialization

 *	       of the RNG4 block in CAAM

 * @pdev - pointer to the platform device

 * @ent_delay - Defines the length (in system clocks) of each entropy sample.

	/*

	 * Setting both RTMCTL:PRGM and RTMCTL:TRNG_ACC causes TRNG to

	 * properly invalidate the entropy in the entropy register and

	 * force re-generation.

	/*

	 * Performance-wise, it does not make sense to

	 * set the delay to a value that is lower

	 * than the last one that worked (i.e. the state handles

	 * were instantiated properly. Thus, instead of wasting

	 * time trying to set the values controlling the sample

	 * frequency, the function simply returns.

 min. freq. count, equal to 1/4 of the entropy sample length */

 disable maximum frequency count */

 read the control register */

	/*

	 * select raw sampling in both entropy shifter

	 * and statistical checker; ; put RNG4 into run mode

 This is '0' prior to CAAM ERA-6 */

/**

 * caam_get_era() - Return the ERA of the SEC on SoC, based

 * on "sec-era" optional property in the DTS. This property is updated

 * by u-boot.

 * In case this property is not passed an attempt to retrieve the CAAM

 * era via register reads will be made.

 *

 * @ctrl:	controller region

/*

 * ERRATA: imx6 devices (imx6D, imx6Q, imx6DL, imx6S, imx6DP and imx6QP)

 * have an issue wherein AXI bus transactions may not occur in the correct

 * order. This isn't a problem running single descriptors, but can be if

 * running multiple concurrent descriptors. Reworking the driver to throttle

 * to single requests is impractical, thus the workaround is to limit the AXI

 * pipeline to a depth of 1 (from it's default of 4) to preclude this situation

 * from occurring.

 sentinel */ }

 Probe routine for CAAM top (controller) level */

 Get configuration properties from device tree */

 First, get register page */

 If (DPAA 1.x) QI present, check whether dependencies are available */

	/* Allocating the BLOCK_OFFSET based on the supported page size on

	 * the platform

 Get the IRQ of the controller (for security violations only) */

	/*

	 * Enable DECO watchdogs and, if this is a PHYS_ADDR_T_64BIT kernel,

	 * long pointers in master configuration register.

	 * In case of SoCs with Management Complex, MC f/w performs

	 * the configuration.

	/*

	 *  Read the Compile Time parameters and SCFGR to determine

	 * if virtualization is enabled for this platform

		/* VIRT_EN_INCL = 1 & VIRT_EN_POR = 1 or

		 * VIRT_EN_INCL = 1 & VIRT_EN_POR = 0 & SCFGR_VIRT_EN = 1

 VIRT_EN_INCL = 0 && VIRT_EN_POR_VALUE = 1 */

 Check to see if (DPAA 1.x) QI present. If so, enable */

 This is all that's required to physically enable QI */

 If QMAN driver is present, init CAAM-QI backend */

 If no QI and no rings specified, quit and go home */

	/*

	 * If SEC has RNG version >= 4 and RNG state handle has not been

	 * already instantiated, do RNG instantiation

	 * In case of SoCs with Management Complex, RNG is managed by MC f/w.

		/*

		 * If the secure keys (TDKEK, JDKEK, TDSK), were already

		 * generated, signal this to the function that is instantiating

		 * the state handles. An error would occur if RNG4 attempts

		 * to regenerate these keys before the next POR.

			/*

			 * If either SH were instantiated by somebody else

			 * (e.g. u-boot) then it is assumed that the entropy

			 * parameters are properly set and thus the function

			 * setting these (kick_trng(...)) is skipped.

			 * Also, if a handle was instantiated, do not change

			 * the TRNG parameters.

			/*

			 * if instantiate_rng(...) fails, the loop will rerun

			 * and the kick_trng(...) function will modify the

			 * upper and lower limits of the entropy sampling

			 * interval, leading to a successful initialization of

			 * the RNG.

				/*

				 * if here, the loop will rerun,

				 * so don't hog the CPU

		/*

		 * Set handles initialized by this module as the complement of

		 * the already initialized ones

 Enable RDB bit so that RNG works faster */

 NOTE: RTIC detection ought to go here, around Si time */

 Report "alive" for developer to see */

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

 Copyright 2019 NXP */

/*

 * This is a counter for the number of times the congestion group (where all

 * the request and response queueus are) reached congestion. Incremented

 * each time the congestion callback is called with congested == true.

	/*

	 * FIXME: needs better naming distinction, as some amalgamation of

	 * "caam" and nprop->full_name. The OF name isn't distinctive,

	 * but does separate instances

 Controller level - global status values */

 Internal covering keys (useful in non-secure mode only) */

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright 2013-2016 Freescale Semiconductor Inc.

 * Copyright 2017-2018 NXP

/**

 * dpseci_open() - Open a control session for the specified object

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @dpseci_id:	DPSECI unique ID

 * @token:	Returned token; use in subsequent API calls

 *

 * This function can be used to open a control session for an already created

 * object; an object may have been declared statically in the DPL

 * or created dynamically.

 * This function returns a unique authentication token, associated with the

 * specific object ID and the specific MC portal; this token must be used in all

 * subsequent commands for this specific object.

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_close() - Close the control session of the object

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 *

 * After this function is called, no further operations are allowed on the

 * object without opening a new control session.

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_enable() - Enable the DPSECI, allow sending and receiving frames

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_disable() - Disable the DPSECI, stop sending and receiving frames

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_reset() - Reset the DPSECI, returns the object to initial state

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_is_enabled() - Check if the DPSECI is enabled.

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @en:		Returns '1' if object is enabled; '0' otherwise

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_get_attributes() - Retrieve DPSECI attributes

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @attr:	Returned object's attributes

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_set_rx_queue() - Set Rx queue configuration

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @queue:	Select the queue relative to number of priorities configured at

 *		DPSECI creation; use DPSECI_ALL_QUEUES to configure all

 *		Rx queues identically.

 * @cfg:	Rx queue configuration

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_get_rx_queue() - Retrieve Rx queue attributes

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @queue:	Select the queue relative to number of priorities configured at

 *		DPSECI creation

 * @attr:	Returned Rx queue attributes

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_get_tx_queue() - Retrieve Tx queue attributes

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @queue:	Select the queue relative to number of priorities configured at

 *		DPSECI creation

 * @attr:	Returned Tx queue attributes

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_get_sec_attr() - Retrieve SEC accelerator attributes

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @attr:	Returned SEC attributes

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_get_api_version() - Get Data Path SEC Interface API version

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @major_ver:	Major version of data path sec API

 * @minor_ver:	Minor version of data path sec API

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_set_congestion_notification() - Set congestion group

 *	notification configuration

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @cfg:	congestion notification configuration

 *

 * Return:	'0' on success, error code otherwise

/**

 * dpseci_get_congestion_notification() - Get congestion group notification

 *	configuration

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPSECI object

 * @cfg:	congestion notification configuration

 *

 * Return:	'0' on success, error code otherwise

 SPDX-License-Identifier: GPL-2.0

/*

 * CAAM Error Reporting

 *

 * Copyright 2009-2011 Freescale Semiconductor, Inc.

		/*

		 * make sure the scatterlist's page

		 * has a valid virtual memory mapping

 DEBUG */

 RNG-only error */

	/*

	 * CCB ICV check failures are part of normal operation life;

	 * we leave the upper layers to do what they want with them.

	/*

	 * If there is an error handling function, call it to report the error.

	 * Otherwise print the error source name.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Freescale FSL CAAM support for crypto API over QI backend.

 * Based on caamalg.c

 *

 * Copyright 2013-2016 Freescale Semiconductor, Inc.

 * Copyright 2016-2019 NXP

/*

 * crypto alg

 max key is sum of AES_MAX_KEY_SIZE, max split key size */

/*

 * per-session context

 Protects multiple init of driver context */

	/*

	 * AES-CTR needs to load IV in CONTEXT1 reg

	 * at an offset of 128bits (16bytes)

	 * CONTEXT1[255:128] = IV

	/*

	 * RFC3686 specific:

	 *	CONTEXT1[255:128] = {NONCE, IV, COUNTER}

	/*

	 * In case |user key| > |derived key|, using DKP<imm,imm> would result

	 * in invalid opcodes (last bytes of user key) in the resulting

	 * descriptor. Use DKP<ptr,imm> instead => both virtual and dma key

	 * addresses are needed.

 aead_encrypt shared descriptor */

 aead_decrypt shared descriptor */

 aead_givencrypt shared descriptor */

	/*

	 * If DKP is supported, use it in the shared descriptor to generate

	 * the split key.

 postpend encryption key to auth split key */

 Now update the driver contexts with the new shared descriptor */

	/*

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

 Now update the driver contexts with the new shared descriptor */

	/*

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * The last four bytes of the key material are used as the salt value

	 * in the nonce. Update the AES key length.

 Now update the driver contexts with the new shared descriptor */

	/*

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * The last four bytes of the key material are used as the salt value

	 * in the nonce. Update the AES key length.

 Now update the driver contexts with the new shared descriptor */

 skcipher encrypt, decrypt shared descriptors */

 Now update the driver contexts with the new shared descriptor */

	/*

	 * RFC3686 specific:

	 *	| CONTEXT1[255:128] = {NONCE, IV, COUNTER}

	 *	| *key = {KEY, NONCE}

	/*

	 * AES-CTR needs to load IV in CONTEXT1 reg

	 * at an offset of 128bits (16bytes)

	 * CONTEXT1[255:128] = IV

 xts skcipher encrypt, decrypt shared descriptors */

 Now update the driver contexts with the new shared descriptor */

/*

 * aead_edesc - s/w-extended aead descriptor

 * @src_nents: number of segments in input scatterlist

 * @dst_nents: number of segments in output scatterlist

 * @iv_dma: dma address of iv for checking continuity and link table

 * @qm_sg_bytes: length of dma mapped h/w link table

 * @qm_sg_dma: bus physical mapped address of h/w link table

 * @assoclen: associated data length, in CAAM endianness

 * @assoclen_dma: bus physical mapped address of req->assoclen

 * @drv_req: driver-specific request structure

 * @sgt: the h/w link table, followed by IV

/*

 * skcipher_edesc - s/w-extended skcipher descriptor

 * @src_nents: number of segments in input scatterlist

 * @dst_nents: number of segments in output scatterlist

 * @iv_dma: dma address of iv for checking continuity and link table

 * @qm_sg_bytes: length of dma mapped h/w link table

 * @qm_sg_dma: bus physical mapped address of h/w link table

 * @drv_req: driver-specific request structure

 * @sgt: the h/w link table, followed by IV

	/*

	 * This function is called on the fast path with values of 'type'

	 * known at compile time. Invalid arguments are not expected and

	 * thus no checks are made.

 Read again to check if some other core init drv_ctx */

 (type == DECRYPT) */

/*

 * allocate and map the aead extended descriptor

 allocate space for base edesc and hw desc commands, link tables */

	/*

	 * Create S/G table: req->assoclen, [IV,] req->src [, req->dst].

	 * Input is not contiguous.

	 * HW reads 4 S/G entries at a time; make sure the reads don't go beyond

	 * the end of the table by allocating more S/G entries. Logic:

	 * if (src != dst && output S/G)

	 *      pad output S/G, if needed

	 * else if (src == dst && S/G)

	 *      overlapping S/Gs; pad one of them

	 * else if (input S/G) ...

	 *      pad input S/G, if needed

 Make sure IV is located in a DMAable area */

 allocate extended descriptor */

 Create and submit job descriptor */

	/*

	 * The crypto API expects us to set the IV (req->iv) to the last

	 * ciphertext block (CBC mode) or last counter (CTR mode).

	 * This is used e.g. by the CTS mode.

	/*

	 * Input, output HW S/G tables: [IV, src][dst, IV]

	 * IV entries point to the same buffer

	 * If src == dst, S/G entries are reused (S/G tables overlap)

	 *

	 * HW reads 4 S/G entries at a time; make sure the reads don't go beyond

	 * the end of the table by allocating more S/G entries.

 allocate space for base edesc, link tables and IV */

 Make sure IV is located in a DMAable area */

	/*

	 * XTS is expected to return an error even for input length = 0

	 * Note that the case input length < block size will be caught during

	 * HW offloading and return an error.

 allocate extended descriptor */

 Galois Counter Mode */

 single-pass ipsec_esp descriptor */

	/*

	 * distribute tfms across job rings to ensure in-order

	 * crypto request processing per tfm

 copy descriptor header template value */

 Make sure this runs only on (DPAA 1.x) QI */

	/*

	 * Register crypto algorithms the device supports.

	 * First, detect presence and attributes of DES, AES, and MD blocks.

 If MD is present, limit digest size based on LP256 */

 Skip DES algorithms if not supported by device */

 Skip AES algorithms if not supported by device */

 Skip DES algorithms if not supported by device */

 Skip AES algorithms if not supported by device */

		/*

		 * Check support for AES algorithms not available

		 * on LP devices.

		/*

		 * Skip algorithms requiring message digests

		 * if MD or MD size is not supported by device.

 SPDX-License-Identifier: GPL-2.0+

/*

 * caam - Freescale FSL CAAM support for hw_random

 *

 * Copyright 2011 Freescale Semiconductor, Inc.

 * Copyright 2018-2019 NXP

 *

 * Based on caamalg.c crypto API driver.

 *

/*

 * Length of used descriptors, see caam_init_desc()

 rng per-device context */

 + 1 cmd_sz */

 Generate random bytes: + 1 cmd_sz */

 Store bytes: + 1 cmd_sz + caam_ptr_sz  */

	/*

	 * Fill async buffer to have early randomness data for

	 * hw_random

 Check for an instantiated RNG before registration */

 SPDX-License-Identifier: GPL-2.0+

/*

 * caam - Freescale FSL CAAM support for crypto API

 *

 * Copyright 2008-2011 Freescale Semiconductor, Inc.

 * Copyright 2016-2019 NXP

 *

 * Based on talitos crypto API driver.

 *

 * relationship of job descriptors to shared descriptors (SteveC Dec 10 2008):

 *

 * ---------------                     ---------------

 * | JobDesc #1  |-------------------->|  ShareDesc  |

 * | *(packet 1) |                     |   (PDB)     |

 * ---------------      |------------->|  (hashKey)  |

 *       .              |              | (cipherKey) |

 *       .              |    |-------->| (operation) |

 * ---------------      |    |         ---------------

 * | JobDesc #2  |------|    |

 * | *(packet 2) |           |

 * ---------------           |

 *       .                   |

 *       .                   |

 * ---------------           |

 * | JobDesc #3  |------------

 * | *(packet 3) |

 * ---------------

 *

 * The SharedDesc never changes for a connection unless rekeyed, but

 * each packet will likely be in a different place. So all we need

 * to know to process the packet is where the input is, where the

 * output goes, and what context we want to process with. Context is

 * in the SharedDesc, packet references in the JobDesc.

 *

 * So, a job desc looks like:

 *

 * ---------------------

 * | Header            |

 * | ShareDesc Pointer |

 * | SEQ_OUT_PTR       |

 * | (output buffer)   |

 * | (output length)   |

 * | SEQ_IN_PTR        |

 * | (input buffer)    |

 * | (input length)    |

 * ---------------------

/*

 * crypto alg

 max key is sum of AES_MAX_KEY_SIZE, max split key size */

/*

 * per-session context

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 aead_encrypt shared descriptor */

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 aead_decrypt shared descriptor */

 NULL encryption / decryption */

	/*

	 * AES-CTR needs to load IV in CONTEXT1 reg

	 * at an offset of 128bits (16bytes)

	 * CONTEXT1[255:128] = IV

	/*

	 * RFC3686 specific:

	 *	CONTEXT1[255:128] = {NONCE, IV, COUNTER}

	/*

	 * In case |user key| > |derived key|, using DKP<imm,imm>

	 * would result in invalid opcodes (last bytes of user key) in

	 * the resulting descriptor. Use DKP<ptr,imm> instead => both

	 * virtual and dma key addresses are needed.

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 aead_encrypt shared descriptor */

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 aead_decrypt shared descriptor */

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

 aead_givencrypt shared descriptor */

	/*

	 * AES GCM encrypt shared descriptor

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

	/*

	 * RFC4106 encrypt shared descriptor

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

	/*

	 * RFC4543 encrypt shared descriptor

	 * Job Descriptor and Shared Descriptor

	 * must fit into the 64-word Descriptor h/w Buffer

	/*

	 * Job Descriptor and Shared Descriptors

	 * must all fit into the 64-word Descriptor h/w Buffer

	/*

	 * If DKP is supported, use it in the shared descriptor to generate

	 * the split key.

 postpend encryption key to auth split key */

	/*

	 * The last four bytes of the key material are used as the salt value

	 * in the nonce. Update the AES key length.

	/*

	 * The last four bytes of the key material are used as the salt value

	 * in the nonce. Update the AES key length.

 skcipher_encrypt shared descriptor */

 skcipher_decrypt shared descriptor */

	/*

	 * RFC3686 specific:

	 *	| CONTEXT1[255:128] = {NONCE, IV, COUNTER}

	 *	| *key = {KEY, NONCE}

	/*

	 * AES-CTR needs to load IV in CONTEXT1 reg

	 * at an offset of 128bits (16bytes)

	 * CONTEXT1[255:128] = IV

 xts_skcipher_encrypt shared descriptor */

 xts_skcipher_decrypt shared descriptor */

/*

 * aead_edesc - s/w-extended aead descriptor

 * @src_nents: number of segments in input s/w scatterlist

 * @dst_nents: number of segments in output s/w scatterlist

 * @mapped_src_nents: number of segments in input h/w link table

 * @mapped_dst_nents: number of segments in output h/w link table

 * @sec4_sg_bytes: length of dma mapped sec4_sg space

 * @bklog: stored to determine if the request needs backlog

 * @sec4_sg_dma: bus physical mapped address of h/w link table

 * @sec4_sg: pointer to h/w link table

 * @hw_desc: the h/w job descriptor followed by any referenced link tables

/*

 * skcipher_edesc - s/w-extended skcipher descriptor

 * @src_nents: number of segments in input s/w scatterlist

 * @dst_nents: number of segments in output s/w scatterlist

 * @mapped_src_nents: number of segments in input h/w link table

 * @mapped_dst_nents: number of segments in output h/w link table

 * @iv_dma: dma address of iv for checking continuity and link table

 * @sec4_sg_bytes: length of dma mapped sec4_sg space

 * @bklog: stored to determine if the request needs backlog

 * @sec4_sg_dma: bus physical mapped address of h/w link table

 * @sec4_sg: pointer to h/w link table

 * @hw_desc: the h/w job descriptor followed by any referenced link tables

 *	     and IV

	/*

	 * If no backlog flag, the completion of the request is done

	 * by CAAM, not crypto engine.

	/*

	 * The crypto API expects us to set the IV (req->iv) to the last

	 * ciphertext block (CBC mode) or last counter (CTR mode).

	 * This is used e.g. by the CTS mode.

	/*

	 * If no backlog flag, the completion of the request is done

	 * by CAAM, not crypto engine.

/*

 * Fill in aead job descriptor

 BUG This should not be specific to generic GCM. */

 Read GCM IV */

 Append Salt */

 Append IV */

 End of blank commands */

 IPsec specific: CONTEXT1[223:128] = {NONCE, IV} */

		/*

		 * The associated data comes already with the IV but we need

		 * to skip it when we authenticate or encrypt...

	/*

	 * For IPsec load the IV further in the same register.

	 * For RFC7539 simply load the 12 bytes nonce in a single operation

	/*

	 * AES-CTR needs to load IV in CONTEXT1 reg

	 * at an offset of 128bits (16bytes)

	 * CONTEXT1[255:128] = IV

	/*

	 * RFC3686 specific:

	 *	CONTEXT1[255:128] = {NONCE, IV, COUNTER}

	/*

	 * {REG3, DPOVRD} = assoclen, depending on whether MATH command supports

	 * having DPOVRD as destination.

/*

 * Fill in skcipher job descriptor

/*

 * allocate and map the aead extended descriptor

 Cover also the case of null (zero length) input data */

 Cover also the case of null (zero length) output data */

	/*

	 * HW reads 4 S/G entries at a time; make sure the reads don't go beyond

	 * the end of the table by allocating more S/G entries.

 allocate space for base edesc and hw desc commands, link tables */

	/*

	 * Only the backlog request are sent to crypto-engine since the others

	 * can be handled by CAAM, if free, especially since JR has up to 1024

	 * entries (more than the 10 entries from crypto-engine).

 allocate extended descriptor */

 Create and submit job descriptor */

 allocate extended descriptor */

 Create and submit job descriptor */

/*

 * allocate and map the skcipher extended descriptor for skcipher

 no need for an input hw s/g table

	/*

	 * Input, output HW S/G tables: [IV, src][dst, IV]

	 * IV entries point to the same buffer

	 * If src == dst, S/G entries are reused (S/G tables overlap)

	 *

	 * HW reads 4 S/G entries at a time; make sure the reads don't go beyond

	 * the end of the table by allocating more S/G entries. Logic:

	 * if (output S/G)

	 *      pad output S/G, if needed

	 * else if (input S/G) ...

	 *      pad input S/G, if needed

	/*

	 * allocate space for base edesc and hw desc commands, link tables, IV

 Make sure IV is located in a DMAable area */

	/*

	 * XTS is expected to return an error even for input length = 0

	 * Note that the case input length < block size will be caught during

	 * HW offloading and return an error.

 allocate extended descriptor */

 Create and submit job descriptor*/

	/*

	 * Only the backlog request are sent to crypto-engine since the others

	 * can be handled by CAAM, if free, especially since JR has up to 1024

	 * entries (more than the 10 entries from crypto-engine).

 Galois Counter Mode */

 single-pass ipsec_esp descriptor */

 copy descriptor header template value */

	/*

	 * Register crypto algorithms the device supports.

	 * First, detect presence and attributes of DES, AES, and MD blocks.

 If MD is present, limit digest size based on LP256 */

 Skip DES algorithms if not supported by device */

 Skip AES algorithms if not supported by device */

		/*

		 * Check support for AES modes not available

		 * on LP devices.

 Skip DES algorithms if not supported by device */

 Skip AES algorithms if not supported by device */

 Skip CHACHA20 algorithms if not supported by device */

 Skip POLY1305 algorithms if not supported by device */

 Skip GCM algorithms if not supported by device */

		/*

		 * Skip algorithms requiring message digests

		 * if MD or MD size is not supported by device.

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * caam - Freescale FSL CAAM support for Public Key Cryptography

 *

 * Copyright 2016 Freescale Semiconductor, Inc.

 * Copyright 2018-2019 NXP

 *

 * There is no Shared Descriptor for PKC so that the Job Descriptor must carry

 * all the desired key parameters, input and output pointers.

 for a 4096-bit modulus */

 buffer filled with zeros, used for padding */

/*

 * variable used to avoid double free of resources in case

 * algorithm registration was unsuccessful

 RSA Job Completion handler */

	/*

	 * If no backlog flag, the completion of the request is done

	 * by CAAM, not crypto engine.

	/*

	 * If no backlog flag, the completion of the request is done

	 * by CAAM, not crypto engine.

/**

 * caam_rsa_count_leading_zeros - Count leading zeros, need it to strip,

 *                                from a given scatterlist

 *

 * @sgl   : scatterlist to count zeros from

 * @nbytes: number of zeros, in bytes, to strip

 * @flags : operation flags

 do not strip more than given bytes */

		/*

		 * strip leading zeros and

		 * return the number of zeros to skip

		/*

		 * input src is less then n key modulus,

		 * so there will be zero padding

 no need for an input hw s/g table */

 allocate space for base edesc, hw desc commands and link tables */

 Save nents for later use in Job Descriptor */

	/*

	 * Only the backlog request are sent to crypto-engine since the others

	 * can be handled by CAAM, if free, especially since JR has up to 1024

	 * entries (more than the 10 entries from crypto-engine).

 Allocate extended descriptor */

 Set RSA Encrypt Protocol Data Block */

 Initialize Job Descriptor */

 Allocate extended descriptor */

 Set RSA Decrypt Protocol Data Block - Private Key Form #1 */

 Initialize Job Descriptor */

 Allocate extended descriptor */

 Set RSA Decrypt Protocol Data Block - Private Key Form #2 */

 Initialize Job Descriptor */

 Allocate extended descriptor */

 Set RSA Decrypt Protocol Data Block - Private Key Form #3 */

 Initialize Job Descriptor */

/**

 * caam_read_rsa_crt - Used for reading dP, dQ, qInv CRT members.

 * dP, dQ and qInv could decode to less than corresponding p, q length, as the

 * BER-encoding requires that the minimum number of bytes be used to encode the

 * integer. dP, dQ, qInv decoded values have to be zero-padded to appropriate

 * length.

 *

 * @ptr   : pointer to {dP, dQ, qInv} CRT member

 * @nbytes: length in bytes of {dP, dQ, qInv} CRT member

 * @dstlen: length in bytes of corresponding p or q prime factor

/**

 * caam_read_raw_data - Read a raw byte stream as a positive integer.

 * The function skips buffer's leading zeros, copies the remained data

 * to a buffer allocated in the GFP_DMA | GFP_KERNEL zone and returns

 * the address of the new buffer.

 *

 * @buf   : The data to read

 * @nbytes: The amount of data to read

 Free the old RSA key if any */

 Copy key in DMA zone */

	/*

	 * Skip leading zeros and copy the positive integer to a buffer

	 * allocated in the GFP_DMA | GFP_KERNEL zone. The decryption descriptor

	 * expects a positive integer for the RSA modulus and uses its length as

	 * decryption output length.

 Free the old RSA key if any */

 Copy key in DMA zone */

	/*

	 * Skip leading zeros and copy the positive integer to a buffer

	 * allocated in the GFP_DMA | GFP_KERNEL zone. The decryption descriptor

	 * expects a positive integer for the RSA modulus and uses its length as

	 * decryption output length.

 Per session pkc's driver context creation function */

 Per session pkc's driver context cleanup function */

 Public Key Cryptography module initialization handler */

 Determine public key hardware accelerator presence. */

		/*

		 * Newer CAAMs support partially disabled functionality. If this is the

		 * case, the number is non-zero, but this bit is set to indicate that

		 * no encryption or decryption is supported. Only signing and verifying

		 * is supported.

 Do not register algorithms if PKHA is not present. */

 allocate zero buffer, used for padding input */

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Shared descriptors for ahash algorithms

 *

 * Copyright 2017-2019 NXP

/**

 * cnstr_shdsc_ahash - ahash shared descriptor

 * @desc: pointer to buffer used for descriptor construction

 * @adata: pointer to authentication transform definitions.

 *         A split key is required for SEC Era < 6; the size of the split key

 *         is specified in this case.

 *         Valid algorithm values - one of OP_ALG_ALGSEL_{MD5, SHA1, SHA224,

 *         SHA256, SHA384, SHA512}.

 * @state: algorithm state OP_ALG_AS_{INIT, FINALIZE, INITFINALIZE, UPDATE}

 * @digestsize: algorithm's digest size

 * @ctx_len: size of Context Register

 * @import_ctx: true if previous Context Register needs to be restored

 *              must be true for ahash update and final

 *              must be false for for ahash first and digest

 * @era: SEC Era

 Append key if it has been set; ahash update excluded */

 Skip key loading if already shared */

 If needed, import context from software */

 Class 2 operation */

	/*

	 * Load from buf and/or src and write to req->result or state->context

	 * Calculate remaining bytes to read

 Read remaining bytes */

 Store class2 context bytes */

/**

 * cnstr_shdsc_sk_hash - shared descriptor for symmetric key cipher-based

 *                       hash algorithms

 * @desc: pointer to buffer used for descriptor construction

 * @adata: pointer to authentication transform definitions.

 * @state: algorithm state OP_ALG_AS_{INIT, FINALIZE, INITFINALIZE, UPDATE}

 * @digestsize: algorithm's digest size

 * @ctx_len: size of Context Register

 Skip loading of key, context if already shared */

 UPDATE, FINALIZE */

 Load K1 */

 CMAC */

 Restore context */

 Class 1 operation */

	/*

	 * Load from buf and/or src and write to req->result or state->context

	 * Calculate remaining bytes to read

 Read remaining bytes */

	/*

	 * Save context:

	 * - xcbc: partial hash, keys K2 and K3

	 * - cmac: partial hash, constant L = E(K,0)

 Save K1 */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ss-core.c - hardware cryptographic offloader for

 * Allwinner A80/A83T SoC

 *

 * Copyright (C) 2015-2019 Corentin Labbe <clabbe.montjoie@gmail.com>

 *

 * Core file which registers crypto algorithms supported by the SecuritySystem

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

/*

 * sun8i_ss_get_engine_number() get the next channel slot

 * This is a simple round-robin way of getting the next channel

 choose between stream0/stream1 */

/*

 * Allocate the flow list structure

/*

 * Power management strategy: The device is suspended unless a TFM exists for

 * one of the algorithms proposed by this driver.

 enable interrupts for all flows */

 Ignore error of debugfs */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ss-cipher.c - hardware cryptographic offloader for

 * Allwinner A80/A83T SoC

 *

 * Copyright (C) 2016-2019 Corentin LABBE <clabbe.montjoie@gmail.com>

 *

 * This file add support for AES cipher with 128,192,256 bits keysize in

 * CBC and ECB mode.

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

 SS need same numbers of SG (with same length) for source and destination */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ss-hash.c - hardware cryptographic offloader for

 * Allwinner A80/A83T SoC

 *

 * Copyright (C) 2015-2020 Corentin Labbe <clabbe@baylibre.com>

 *

 * This file add support for MD5 and SHA1/SHA224/SHA256.

 *

 * You could find the datasheet in Documentation/arm/sunxi.rst

 FALLBACK */

 choose between stream0/stream1 */

 we need to reserve one SG for the padding one */

		/* SS can operate hash only on full block size

		 * since SS support only MD5,sha1,sha224 and sha256, blocksize

		 * is always 64

		 * TODO: handle request if last SG is not len%64

		 * but this will need to copy data on a new SG of size=64

/* sun8i_ss_hash_run - run an ahash request

 * Send the data of the request to the SS along with an extra SG with padding

 the padding could be up to two block. */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ss-prng.c - hardware cryptographic offloader for

 * Allwinner A80/A83T SoC

 *

 * Copyright (C) 2015-2020 Corentin Labbe <clabbe@baylibre.com>

 *

 * This file handle the PRNG found in the SS

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

	/* The SS does not give an updated seed, so we need to get a new one.

	 * So we will ask for an extra PRNG_SEED_SIZE data.

	 * We want dlen + seedsize rounded up to a multiple of PRNG_DATA_SIZE

 the PRNG act badly (failing rngtest) without SS_KEY_ADR_REG set */

 Be sure all data is written before enabling the task */

	/* Since cipher and hash use the linux/cryptoengine and that we have

	 * a cryptoengine per flow, we are sure that they will issue only one

	 * request per flow.

	 * Since the cryptoengine wait for completion before submitting a new

	 * one, the mlock could be left just after the final writel.

	 * But cryptoengine cannot handle crypto_rng, so we need to be sure

	 * nothing will use our flow.

	 * The easiest way is to grab mlock until the hardware end our requests.

	 * We could have used a per flow lock, but this would increase

	 * complexity.

	 * The drawback is that no request could be handled for the other flow.

 Update seed */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ce-core.c - hardware cryptographic offloader for

 * Allwinner H3/A64/H5/H2+/H6/R40 SoC

 *

 * Copyright (C) 2015-2019 Corentin Labbe <clabbe.montjoie@gmail.com>

 *

 * Core file which registers crypto algorithms supported by the CryptoEngine.

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

/*

 * mod clock is lower on H3 than other SoC due to some DMA timeout occurring

 * with high value.

 * If you want to tune mod clock, loading driver and passing selftest is

 * insufficient, you need to test with some LUKS test (mount and write to it)

/*

 * sun8i_ce_get_engine_number() get the next channel slot

 * This is a simple round-robin way of getting the next channel

 * The flow 3 is reserve for xRNG operations

 Be sure all data is written before enabling the task */

	/* Only H6 needs to write a part of t_common_ctl along with "1", but since it is ignored

	 * on older SoCs, we have no reason to complicate things.

	/* No need to lock for this read, the channel is locked so

	 * nothing could modify the error value for this channel

 Sadly, the error bit is not per flow */

/*

 * Allocate the channel list structure

/*

 * Power management strategy: The device is suspended unless a TFM exists for

 * one of the algorithms proposed by this driver.

 Get Non Secure IRQ */

 Ignore error of debugfs */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ce-hash.c - hardware cryptographic offloader for

 * Allwinner H3/A64/H5/H2+/H6/R40 SoC

 *

 * Copyright (C) 2015-2020 Corentin Labbe <clabbe@baylibre.com>

 *

 * This file add support for MD5 and SHA1/SHA224/SHA256/SHA384/SHA512.

 *

 * You could find the datasheet in Documentation/arm/sunxi.rst

 FALLBACK */

 we need to reserve one SG for padding one */

 the padding could be up to two block. */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ce-trng.c - hardware cryptographic offloader for

 * Allwinner H3/A64/H5/H2+/H6/R40 SoC

 *

 * Copyright (C) 2015-2020 Corentin Labbe <clabbe@baylibre.com>

 *

 * This file handle the TRNG

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

/*

 * Note that according to the algorithm ID, 2 versions of the TRNG exists,

 * The first present in H3/H5/R40/A64 and the second present in H6.

 * This file adds support for both, but only the second is working

 * reliabily according to rngtest.

 round the data length to a multiple of 32*/

 recent CE (H6) need length in bytes, in word otherwise */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ce-cipher.c - hardware cryptographic offloader for

 * Allwinner H3/A64/H5/H2+/H6/R40 SoC

 *

 * Copyright (C) 2016-2019 Corentin LABBE <clabbe.montjoie@gmail.com>

 *

 * This file add support for AES cipher with 128,192,256 bits keysize in

 * CBC and ECB mode.

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

 CTS and recent CE (H6) need length in bytes, in word otherwise */

 SPDX-License-Identifier: GPL-2.0

/*

 * sun8i-ce-prng.c - hardware cryptographic offloader for

 * Allwinner H3/A64/H5/H2+/H6/R40 SoC

 *

 * Copyright (C) 2015-2020 Corentin Labbe <clabbe@baylibre.com>

 *

 * This file handle the PRNG

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

 we want dlen + seedsize rounded up to a multiple of PRNG_DATA_SIZE */

 recent CE (H6) need length in bytes, in word otherwise */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * sun4i-ss-hash.c - hardware cryptographic accelerator for Allwinner A20 SoC

 *

 * Copyright (C) 2013-2015 Corentin LABBE <clabbe.montjoie@gmail.com>

 *

 * This file add support for MD5 and SHA1.

 *

 * You could find the datasheet in Documentation/arm/sunxi.rst

 This is a totally arbitrary value */

 sun4i_hash_init: initialize request context */

/*

 * sun4i_hash_update: update hash engine

 *

 * Could be used for both SHA1 and MD5

 * Write data by step of 32bits and put then in the SS.

 *

 * Since we cannot leave partial data and hash state in the engine,

 * we need to get the hash state at the end of this function.

 * We can get the hash state every 64 bytes

 *

 * So the first work is to get the number of bytes to write to SS modulo 64

 * The extra bytes will go to a temporary buffer op->buf storing op->len bytes

 *

 * So at the begin of update()

 * if op->len + areq->nbytes < 64

 * => all data will be written to wait buffer (op->buf) and end=0

 * if not, write all data from op->buf to the device and position end to

 * complete to 64bytes

 *

 * example 1:

 * update1 60o => op->len=60

 * update2 60o => need one more word to have 64 bytes

 * end=4

 * so write all data from op->buf and one word of SGs

 * write remaining data in op->buf

 * final state op->len=56

	/*

	 * i is the total bytes read from SGs, to be compared to areq->nbytes

	 * i is important because we cannot rely on SG length since the sum of

	 * SG->length could be greater than areq->nbytes

	 *

	 * end is the position when we need to stop writing to the device,

	 * to be compared to i

	 *

	 * in_i: advancement in the current SG

 protect against overflow */

 linearize data to op->buf */

	/*

	 * if some data have been processed before,

	 * we need to restore the partial hash state

 Enable the device */

 start of handling data */

 Since we have the flag final, we can go up to modulo 4 */

 TODO if SGlen % 4 and !op->len then DMA */

		/*

		 * we need to linearize in two case:

		 * - the buffer is already used

		 * - the SG does not have enough byte remaining ( < 4)

			/*

			 * if we have entered here we have two reason to stop

			 * - the buffer is full

			 * - reach the end

 how many bytes we can read from current SG */

 write buf to the device */

 how many bytes we can read from current SG */

 how many bytes we can write in the device*/

	/*

	 * Now we have written to the device all that we can,

	 * store the remaining bytes in op->buf

 how many bytes we can read from current SG */

	/*

	 * End of data process

	 * Now if we have the flag final go to finalize part

	 * If not, store the partial hash

	/*

	 * The datasheet isn't very clear about when to retrieve the digest. The

	 * bit SS_DATA_END is cleared when the engine has processed the data and

	 * when the digest is computed *but* it doesn't mean the digest is

	 * available in the digest registers. Hence the delay to be sure we can

	 * read it.

/*

 * hash_final: finalize hashing operation

 *

 * If we have some remaining bytes, we write them.

 * Then ask the SS for finalizing the hashing operation

 *

 * I do not check RX FIFO size in this function since the size is 32

 * after each enabling and this function neither write more than 32 words.

 * If we come from the update part, we cannot have more than

 * 3 remaining bytes to write and SS is fast enough to not care about it.

 write the remaining words of the wait buffer */

 write the remaining bytes of the nbw buffer */

	/*

	 * number of space to pad to obtain 64o minus 8(size) minus 4 (final 1)

	 * I take the operations from other MD5/SHA1 implementations

 last block size */

 if we can't fill all data, jump to the next 64 block */

 write the length of data */

 Tell the SS to stop the hashing */

	/*

	 * Wait for SS to finish the hash.

	 * The timeout could happen only in case of bad overclocking

	 * or driver bug.

	/*

	 * The datasheet isn't very clear about when to retrieve the digest. The

	 * bit SS_DATA_END is cleared when the engine has processed the data and

	 * when the digest is computed *but* it doesn't mean the digest is

	 * available in the digest registers. Hence the delay to be sure we can

	 * read it.

 Get the hash from the device */

 sun4i_hash_finup: finalize hashing operation after an update */

 combo of init/update/final functions */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * sun4i-ss-core.c - hardware cryptographic accelerator for Allwinner A20 SoC

 *

 * Copyright (C) 2013-2015 Corentin LABBE <clabbe.montjoie@gmail.com>

 *

 * Core file which registers crypto algorithms supported by the SS.

 *

 * You could find a link for the datasheet in Documentation/arm/sunxi.rst

/*

 * Power management strategy: The device is suspended unless a TFM exists for

 * one of the algorithms proposed by this driver.

/*

 * When power management is enabled, this function enables the PM and set the

 * device as suspended

 * When power management is disabled, this function just enables the device

	/*

	 * Check that clock have the correct rates given in the datasheet

	 * Try to set the clock to the maximum allowed

	/*

	 * The only impact on clocks below requirement are bad performance,

	 * so do not print "errors"

	 * warn on Overclocked clocks

	/*

	 * Datasheet named it "Die Bonding ID"

	 * I expect to be a sort of Security System Revision number.

	 * Since the A80 seems to have an other version of SS

	 * this info could be useful

 Ignore error of debugfs */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * sun4i-ss-cipher.c - hardware cryptographic accelerator for Allwinner A20 SoC

 *

 * Copyright (C) 2013-2015 Corentin LABBE <clabbe.montjoie@gmail.com>

 *

 * This file add support for AES cipher with 128,192,256 bits

 * keysize in CBC and ECB mode.

 * Add support also for DES and 3DES in CBC and ECB mode.

 *

 * You could find the datasheet in Documentation/arm/sunxi.rst

 when activating SS, the default FIFO space is SS_RX_DEFAULT(32) */

 progress for in and out */

 offset for in and out */

 Generic function that support SG with size not multiple of 4 */

 when activating SS, the default FIFO space is SS_RX_DEFAULT(32) */

 progress for in and out */

 offset for in and out */

 offset in buf */

 offset in bufo*/

 length of data in bufo */

	/*

	 * if we have only SGs with size multiple of 4,

	 * we can use the SS optimized function

			/*

			 * todo is the number of consecutive 4byte word that we

			 * can read from current SG

				/*

				 * not enough consecutive bytes, so we need to

				 * linearize in buf. todo is in bytes

				 * After that copy, if we have a multiple of 4

				 * we need to be able to write all buf in one

				 * pass, so it is why we min() with rx_cnt

 todo in 4bytes word */

			/*

			 * read obl bytes in bufo, we read at maximum for

			 * emptying the device

				/*

				 * how many bytes we can copy ?

				 * no more than remaining SG size

				 * no more than remaining buffer

				 * no need to test against oleft

 bufo must be fully used here */

 CBC AES */

 ECB AES */

 CBC DES */

 ECB DES */

 CBC 3DES */

 ECB 3DES */

 check and set the AES key, prepare the mode to be used */

 check and set the DES key, prepare the mode to be used */

 check and set the 3DES key, prepare the mode to be used */

 SPDX-License-Identifier: GPL-2.0-or-later

 write the seed */

 Read the random data */

 Update the seed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Crypto acceleration support for Rockchip RK3288

 *

 * Copyright (c) 2015, Fuzhou Rockchip Electronics Co., Ltd

 *

 * Author: Zain Wang <zain.wang@rock-chips.com>

 *

 * Some ideas are from marvell-cesa.c and s5p-sss.c driver.

	/* Store the iv that need to be updated in chain mode.

	 * And update the IV buffer to contain the next IV for decryption mode.

 Update the IV buffer to contain the next IV for encryption mode. */

/* return:

 *	true	some err was occurred

 *	fault	no err, continue

 here show the calculation is over without any err */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Crypto acceleration support for Rockchip RK3288

 *

 * Copyright (c) 2015, Fuzhou Rockchip Electronics Co., Ltd

 *

 * Author: Zain Wang <zain.wang@rock-chips.com>

 *

 * Some ideas are from marvell/cesa.c and s5p-sss.c driver.

/*

 * IC can not process zero message hash,

 * so we put the fixed hash out when met zero message.

		/*

		 * it will take some time to process date after last dma

		 * transmission.

		 *

		 * waiting time is relative with the last date len,

		 * so cannot set a fixed time here.

		 * 10us makes system not call here frequently wasting

		 * efficiency, and make it response quickly when dma

		 * complete.

 for fallback */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Crypto acceleration support for Rockchip RK3288

 *

 * Copyright (c) 2015, Fuzhou Rockchip Electronics Co., Ltd

 *

 * Author: Zain Wang <zain.wang@rock-chips.com>

 *

 * Some ideas are from marvell-cesa.c and s5p-sss.c driver.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) STMicroelectronics SA 2017

 * Author: Fabien Dessenne <fabien.dessenne@st.com>

 Bit [0] encrypt / decrypt */

 Bit [8..1] algo & operation mode */

 Mode mask = bits [15..0] */

 Bit [31..16] status  */

 Registers */

 Registers values */

 Misc */

 protect dev_list */

 Phase 1 : init */

 Wait for end of processing */

 Phase 1 : init. Firstly set the CTR value to 1 (not 0) */

 Build B0 */

 Enable HW */

 Write B0 */

 Wait for end of processing */

 Disable interrupt */

 Set key */

 Set configuration */

 AES ECB/CBC decrypt: run key preparation first */

 Wait for end of processing */

 Apply config and flush (valid when CRYPEN = 0) */

 Phase 1 : init */

 Phase 2 : header (authenticated data) */

 Enable now */

 Phase 4 : output tag */

 Enable interrupt and let the IRQ handler do everything */

		/*

		 * Length of input and output data:

		 * Encryption case:

		 *  INPUT  =   AssocData  ||   PlainText

		 *          <- assoclen ->  <- cryptlen ->

		 *          <------- total_in ----------->

		 *

		 *  OUTPUT =   AssocData  ||  CipherText  ||   AuthTag

		 *          <- assoclen ->  <- cryptlen ->  <- authsize ->

		 *          <---------------- total_out ----------------->

		 *

		 * Decryption case:

		 *  INPUT  =   AssocData  ||  CipherText  ||  AuthTag

		 *          <- assoclen ->  <--------- cryptlen --------->

		 *                                          <- authsize ->

		 *          <---------------- total_in ------------------>

		 *

		 *  OUTPUT =   AssocData  ||   PlainText

		 *          <- assoclen ->  <- crypten - authsize ->

		 *          <---------- total_out ----------------->

 Append auth tag to output */

 No auth tag in output */

 In output, jump after assoc data */

 No input data to process: get tag and finish */

 Update Config */

 GCM: write aad and payload size (in bits) */

 CCM: write CTR0 */

 Wait for output data */

 Get and write tag */

 Read a full u32 */

 Empty fifo out (data from input padding) */

 Read less than an u32 */

 Get and check tag */

 Disable cryp */

 Do no read tag now (if any) */

 Read a full u32 */

 Empty fifo out (data from input padding) */

 Read less than an u32 */

 Do no write tag (if any) */

 Write a full u32 */

 Write padding data */

 Write less than an u32 */

 'Special workaround' procedure described in the datasheet */

 a) disable ip */

 b) Update IV1R */

 c) change mode to CTR */

 a) enable IP */

 b) pad and write the last block */

 c) get and store encrypted data */

 d) change mode back to AES GCM */

 e) change phase to Final */

 f) write padded data */

 g) Empty fifo out */

 h) run the he normal Final phase */

 disable ip, set NPBLB and reneable ip */

 'Special workaround' procedure described in the datasheet */

 a) disable ip */

 b) get IV1 from CRYP_CSGCMCCM7 */

 c) Load CRYP_CSGCMCCMxR */

 d) Write IV1R */

 e) change mode to CTR */

 a) enable IP */

 b) pad and write the last block */

 c) get and store decrypted data */

 d) Load again CRYP_CSGCMCCMxR */

 e) change mode back to AES CCM */

 f) change phase to header */

 g) XOR and write padded data */

 h) wait for completion */

 i) run the he normal Final phase */

 Padding for AES GCM encryption */

 Special case 1 */

 Setting padding bytes (NBBLB) */

 Padding for AES CCM decryption */

 Special case 2 */

 Setting padding bytes (NBBLB) */

 Check if whole header written */

 Write padding if needed */

 Wait for completion */

 Phase 3 : payload */

 Phase 4 : tag */

 Write first u32 of B1 */

 Build the two first u32 of B1 */

 Write next u32 */

 Build an u32 */

 Write padding if needed */

 Wait for completion */

 Phase 3 : payload */

 Phase 4 : tag */

 Output FIFO IRQ: read data */

 All bytes processed, finish */

 Write Header */

 Input FIFO IRQ: write data */

 Write Header */

 Input FIFO IRQ: write data */

 Input FIFO IRQ: write data */

 Initialize crypto engine */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This file is part of STM32 Crypto driver for Linux.

 *

 * Copyright (C) 2017, STMicroelectronics - All Rights Reserved

 * Author(s): Lionel DEBIEVE <lionel.debieve@st.com> for STMicroelectronics.

 Control Register */

 Interrupt */

 Interrupt Mask */

 Context swap register */

 Status Flags */

 STR Register */

 DMA */

 Export Context */

 List protection access */

 done task will not finish it, so do it here */

	/*

	 * final() has to be always called to cleanup resources

	 * even if update() failed, except EINPROGRESS

 Finish current request */

 Disable IT*/

 Initialize crypto engine */

 Register algos */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) STMicroelectronics SA 2017

 * Author: Fabien Dessenne <fabien.dessenne@st.com>

 Registers */

 Registers values */

 protect dev_list */

 crc32c: partial in first 4 bytes of that struct */

 Reset, set key, poly and configure in bit reverse mode */

 Store partial result */

 Hardware is busy, calculate crc32 by software */

	/*

	 * Restore previously calculated CRC for this context as init value

	 * Restore polynomial configuration

	 * Configure in register for word input data,

	 * Configure out register in reversed bit mode data.

 Configure for byte data */

 Configure for word data */

 Configure for byte data */

 Store partial result */

 Digest first bytes not 32bit aligned at first pass in the loop */

 Send computed CRC */

 CRC-32 */

 CRC-32Castagnoli */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2016 Broadcom

 ================= Device Structure ================== */

 ==================== Parameters ===================== */

/*

 * The value of these module parameters is used to set the priority for each

 * algo type when this driver registers algos with the kernel crypto API.

 * To use a priority other than the default, set the priority in the insmod or

 * modprobe. Changing the module priority after init time has no effect.

 *

 * The default priorities are chosen to be lower (less preferred) than ARMv8 CE

 * algos, but more preferred than generic software algos.

/* A type 3 BCM header, expected to precede the SPU header for SPU-M.

 * Bits 3 and 4 in the first byte encode the channel number (the dma ringset).

 * 0x60 - ring 0

 * 0x68 - ring 1

 * 0x70 - ring 2

 * 0x78 - ring 3

/*

 * Some SPU hw does not use BCM header on SPU messages. So BCM_HDR_LEN

 * is set dynamically after reading SPU type from device tree.

 min and max time to sleep before retrying when mbox queue is full. usec */

/**

 * select_channel() - Select a SPU channel to handle a crypto request. Selects

 * channel in round robin order.

 *

 * Return:  channel index

/**

 * spu_skcipher_rx_sg_create() - Build up the scatterlist of buffers used to

 * receive a SPU response message for an skcipher request. Includes buffers to

 * catch SPU message headers and the response data.

 * @mssg:	mailbox message containing the receive sg

 * @rctx:	crypto request context

 * @rx_frag_num: number of scatterlist elements required to hold the

 *		SPU response message

 * @chunksize:	Number of bytes of response data expected

 * @stat_pad_len: Number of bytes required to pad the STAT field to

 *		a 4-byte boundary

 *

 * The scatterlist that gets allocated here is freed in spu_chunk_cleanup()

 * when the request completes, whether the request is handled successfully or

 * there is an error.

 *

 * Returns:

 *   0 if successful

 *   < 0 if an error

 used to build sgs in mbox message */

 Number of bytes of response data expected */

 Space for SPU message header */

 If XTS tweak in payload, add buffer to receive encrypted tweak */

 Copy in each dst sg entry from request, up to chunksize */

/**

 * spu_skcipher_tx_sg_create() - Build up the scatterlist of buffers used to

 * send a SPU request message for an skcipher request. Includes SPU message

 * headers and the request data.

 * @mssg:	mailbox message containing the transmit sg

 * @rctx:	crypto request context

 * @tx_frag_num: number of scatterlist elements required to construct the

 *		SPU request message

 * @chunksize:	Number of bytes of request data

 * @pad_len:	Number of pad bytes

 *

 * The scatterlist that gets allocated here is freed in spu_chunk_cleanup()

 * when the request completes, whether the request is handled successfully or

 * there is an error.

 *

 * Returns:

 *   0 if successful

 *   < 0 if an error

 used to build sgs in mbox message */

 Number of bytes of response data expected */

 if XTS tweak in payload, copy from IV (where crypto API puts it) */

 Copy in each src sg entry from request, up to chunksize */

			/*

			 * Mailbox queue is full. Since MAY_SLEEP is set, assume

			 * not in atomic context and we can wait and try again.

 Check error returned by mailbox controller */

 Signal txdone for mailbox channel */

 Signal txdone for mailbox channel */

/**

 * handle_skcipher_req() - Submit as much of a block cipher request as fits in

 * a single SPU request message, starting at the current position in the request

 * data.

 * @rctx:	Crypto request context

 *

 * This may be called on the crypto API thread, or, when a request is so large

 * it must be broken into multiple SPU messages, on the thread used to invoke

 * the response callback. When requests are broken into multiple SPU

 * messages, we assume subsequent messages depend on previous results, and

 * thus always wait for previous results before submitting the next message.

 * Because requests are submitted in lock step like this, there is no need

 * to synchronize access to request data structures.

 *

 * Return: -EINPROGRESS: request has been accepted and result will be returned

 *			 asynchronously

 *         Any other value indicates an error

 Num bytes of request to submit */

 Bytes of request still to process */

 Beginning of data for current SPU msg */

 IV or ctr value to use in this SPU msg */

 num bytes to align status field */

 total length of all padding */

 mailbox message */

 number of entries in src and dst sg in mailbox message. */

 response header and STATUS */

 request header */

 determine the chunk we are breaking off and update the indexes */

 Count number of sg entries to be included in this request */

		/*

		 * Encrypting non-first first chunk. Copy last block of

		 * previous result to IV for this chunk.

 get our local copy of the iv */

 generate the next IV if possible */

			/*

			 * CBC Decrypt: next IV is the last ciphertext block in

			 * this chunk

			/*

			 * The SPU hardware increments the counter once for

			 * each AES block of 16 bytes. So update the counter

			 * for the next chunk, if there is one. Note that for

			 * this chunk, the counter has already been copied to

			 * local_iv_ctr. We can assume a block size of 16,

			 * because we only support CTR mode for AES, not for

			 * any other cipher alg.

 Copy SPU header template created at setkey time */

	/*

	 * Build mailbox message containing SPU request msg and rx buffers

	 * to catch response message

 Will be returned in response */

 Create rx scatterlist to catch result */

 extra sg to insert tweak */

 Create tx scatterlist containing SPU request message */

 extra sg to insert tweak */

/**

 * handle_skcipher_resp() - Process a block cipher SPU response. Updates the

 * total received count for the request and updates global stats.

 * @rctx:	Crypto request context

 See how much data was returned */

	/*

	 * In XTS mode, the first SPU_XTS_TWEAK_SIZE bytes may be the

	 * encrypted tweak ("i") value; we don't count those.

/**

 * spu_ahash_rx_sg_create() - Build up the scatterlist of buffers used to

 * receive a SPU response message for an ahash request.

 * @mssg:	mailbox message containing the receive sg

 * @rctx:	crypto request context

 * @rx_frag_num: number of scatterlist elements required to hold the

 *		SPU response message

 * @digestsize: length of hash digest, in bytes

 * @stat_pad_len: Number of bytes required to pad the STAT field to

 *		a 4-byte boundary

 *

 * The scatterlist that gets allocated here is freed in spu_chunk_cleanup()

 * when the request completes, whether the request is handled successfully or

 * there is an error.

 *

 * Return:

 *   0 if successful

 *   < 0 if an error

 used to build sgs in mbox message */

 Space for SPU message header */

 Space for digest */

/**

 * spu_ahash_tx_sg_create() -  Build up the scatterlist of buffers used to send

 * a SPU request message for an ahash request. Includes SPU message headers and

 * the request data.

 * @mssg:	mailbox message containing the transmit sg

 * @rctx:	crypto request context

 * @tx_frag_num: number of scatterlist elements required to construct the

 *		SPU request message

 * @spu_hdr_len: length in bytes of SPU message header

 * @hash_carry_len: Number of bytes of data carried over from previous req

 * @new_data_len: Number of bytes of new request data

 * @pad_len:	Number of pad bytes

 *

 * The scatterlist that gets allocated here is freed in spu_chunk_cleanup()

 * when the request completes, whether the request is handled successfully or

 * there is an error.

 *

 * Return:

 *   0 if successful

 *   < 0 if an error

 used to build sgs in mbox message */

 Number of bytes of response data expected */

 Copy in each src sg entry from request, up to chunksize */

/**

 * handle_ahash_req() - Process an asynchronous hash request from the crypto

 * API.

 * @rctx:  Crypto request context

 *

 * Builds a SPU request message embedded in a mailbox message and submits the

 * mailbox message on a selected mailbox channel. The SPU request message is

 * constructed as a scatterlist, including entries from the crypto API's

 * src scatterlist to avoid copying the data to be hashed. This function is

 * called either on the thread from the crypto API, or, in the case that the

 * crypto API request is too large to fit in a single SPU request message,

 * on the thread that invokes the receive callback with a response message.

 * Because some operations require the response from one chunk before the next

 * chunk can be submitted, we always wait for the response for the previous

 * chunk before submitting the next chunk. Because requests are submitted in

 * lock step like this, there is no need to synchronize access to request data

 * structures.

 *

 * Return:

 *   -EINPROGRESS: request has been submitted to SPU and response will be

 *		   returned asynchronously

 *   -EAGAIN:      non-final request included a small amount of data, which for

 *		   efficiency we did not submit to the SPU, but instead stored

 *		   to be submitted to the SPU with the next part of the request

 *   other:        an error code

 number of bytes still to be hashed in this req */

 length of hash carry + new data */

	/*

	 * length of new data, not from hash carry, to be submitted in

	 * this hw request

 Length of data field, incl gcm and hash padding */

 total pad len, including gcm, hash, stat padding */

 length of GCM/CCM padding */

 length of padding to align STATUS word */

 mailbox message */

	/*

	 * number of entries in src and dst sg. Always includes SPU msg header.

	 * rx always includes a buffer to catch digest and STATUS.

	/*

	 * For hash algorithms below assignment looks bit odd but

	 * it's needed for AES-XCBC and AES-CMAC hash algorithms

	 * to differentiate between 128, 192, 256 bit key values.

	 * Based on the key values, hash algorithm is selected.

	 * For example for 128 bit key, hash algorithm is AES-128.

	/*

	 * Compute the amount remaining to hash. This may include data

	 * carried over from previous requests.

	/*

	 * If this is not a final request and the request data is not a multiple

	 * of a full block, then simply park the extra data and prefix it to the

	 * data for the next request.

 len of data to add to hash carry */

 remainder */

 chunksize not a multiple of blocksize */

 Don't have a full block to submit to hw */

 if we have hash carry, then prefix it to the data in this request */

 Count number of sg entries to be used in this request */

 AES hashing keeps key size in type field, so need to copy it here */

 update the indexes */

 if you sent a prebuf then that wasn't from this req->src */

	/*

	 * If a non-first chunk, then include the digest returned from the

	 * previous chunk so that hw can add to it (except for AES types).

 Prepend SPU header with type 3 BCM header */

	/*

	 * Determine total length of padding required. Put all padding in one

	 * buffer.

	/*

	 * Build mailbox message containing SPU request msg and rx buffers

	 * to catch response message

 Will be returned in response */

 Create rx scatterlist to catch result */

 Create tx scatterlist containing SPU request message */

/**

 * spu_hmac_outer_hash() - Request synchonous software compute of the outer hash

 * for an HMAC request.

 * @req:  The HMAC request from the crypto API

 * @ctx:  The session context

 *

 * Return: 0 if synchronous hash operation successful

 *         -EINVAL if the hash algo is unrecognized

 *         any other value indicates an error

/**

 * ahash_req_done() - Process a hash result from the SPU hardware.

 * @rctx: Crypto request context

 *

 * Return: 0 if successful

 *         < 0 if an error

		/* byte swap the output from the UPDT function to network byte

		 * order

 if this an HMAC then do the outer hash */

/**

 * handle_ahash_resp() - Process a SPU response message for a hash request.

 * Checks if the entire crypto API request has been processed, and if so,

 * invokes post processing on the result.

 * @rctx: Crypto request context

	/*

	 * Save hash to use as input to next op if incremental. Might be copying

	 * too much, but that's easier than figuring out actual digest size here

/**

 * spu_aead_rx_sg_create() - Build up the scatterlist of buffers used to receive

 * a SPU response message for an AEAD request. Includes buffers to catch SPU

 * message headers and the response data.

 * @mssg:	mailbox message containing the receive sg

 * @req:	Crypto API request

 * @rctx:	crypto request context

 * @rx_frag_num: number of scatterlist elements required to hold the

 *		SPU response message

 * @assoc_len:	Length of associated data included in the crypto request

 * @ret_iv_len: Length of IV returned in response

 * @resp_len:	Number of bytes of response data expected to be written to

 *              dst buffer from crypto API

 * @digestsize: Length of hash digest, in bytes

 * @stat_pad_len: Number of bytes required to pad the STAT field to

 *		a 4-byte boundary

 *

 * The scatterlist that gets allocated here is freed in spu_chunk_cleanup()

 * when the request completes, whether the request is handled successfully or

 * there is an error.

 *

 * Returns:

 *   0 if successful

 *   < 0 if an error

 used to build sgs in mbox message */

 Number of bytes of response data expected */

 RFC4543: only pad after data, not after AAD */

 ICV (after data) must be in the next 32-bit word for CCM */

 have to catch gcm pad in separate buffer */

 Space for SPU message header */

		/*

		 * Don't write directly to req->dst, because SPU may pad the

		 * assoc data in the response

		/*

		 * Copy in each dst sg entry from request, up to chunksize.

		 * dst sg catches just the data. digest caught in separate buf.

 If GCM/CCM data is padded, catch padding in separate buffer */

 Always catch ICV in separate buffer */

/**

 * spu_aead_tx_sg_create() - Build up the scatterlist of buffers used to send a

 * SPU request message for an AEAD request. Includes SPU message headers and the

 * request data.

 * @mssg:	mailbox message containing the transmit sg

 * @rctx:	crypto request context

 * @tx_frag_num: number of scatterlist elements required to construct the

 *		SPU request message

 * @spu_hdr_len: length of SPU message header in bytes

 * @assoc:	crypto API associated data scatterlist

 * @assoc_len:	length of associated data

 * @assoc_nents: number of scatterlist entries containing assoc data

 * @aead_iv_len: length of AEAD IV, if included

 * @chunksize:	Number of bytes of request data

 * @aad_pad_len: Number of bytes of padding at end of AAD. For GCM/CCM.

 * @pad_len:	Number of pad bytes

 * @incl_icv:	If true, write separate ICV buffer after data and

 *              any padding

 *

 * The scatterlist that gets allocated here is freed in spu_chunk_cleanup()

 * when the request completes, whether the request is handled successfully or

 * there is an error.

 *

 * Return:

 *   0 if successful

 *   < 0 if an error

 used to build sgs in mbox message */

 Number of bytes of data to write */

 Number of bytes of data written */

 Copy in each associated data sg entry from request */

 For aead, a single msg should consume the entire src sg */

/**

 * handle_aead_req() - Submit a SPU request message for the next chunk of the

 * current AEAD request.

 * @rctx:  Crypto request context

 *

 * Unlike other operation types, we assume the length of the request fits in

 * a single SPU request message. aead_enqueue() makes sure this is true.

 * Comments for other op types regarding threads applies here as well.

 *

 * Unlike incremental hash ops, where the spu returns the entire hash for

 * truncated algs like sha-224, the SPU returns just the truncated hash in

 * response to aead requests. So digestsize is always ctx->digestsize here.

 *

 * Return: -EINPROGRESS: crypto request has been accepted and result will be

 *			 returned asynchronously

 *         Any other value indicates an error

 mailbox message */

	/* number of entries in src and dst sg. Always includes SPU msg header.

 and STATUS */

 doing the whole thing at once */

		/*

		 * 8-byte IV is included assoc data in request. SPU2

		 * expects AAD to include just SPI and seqno. So

		 * subtract off the IV len.

	/*

	 * Count number of sg entries from the crypto API request that are to

	 * be included in this mailbox message. For dst sg, don't count space

	 * for digest. Digest gets caught in a separate buffer and copied back

	 * to dst sg when processing response.

 General case AAD padding (CCM and RFC4543 special cases below) */

 General case data padding (CCM decrypt special case below) */

		/*

		 * for CCM, AAD len + 2 (rather than AAD len) needs to be

		 * 128-bit aligned

		/*

		 * And when decrypting CCM, need to pad without including

		 * size of ICV which is tacked on to end of chunk

 CCM also requires software to rewrite portions of IV: */

		/*

		 * RFC4543: data is included in AAD, so don't pad after AAD

		 * and pad data based on both AAD + data size

 Copy ICV from end of src scatterlist to digest buf */

 Prepend SPU header with type 3 BCM header */

 Determine total length of padding. Put all padding in one buffer. */

	/*

	 * Build mailbox message containing SPU request msg and rx buffers

	 * to catch response message

 Will be returned in response */

 Create rx scatterlist to catch result */

	/*

	 * Always catch ICV in separate buffer. Have to for GCM/CCM because of

	 * padding. Have to for SHA-224 and other truncated SHAs because SPU

	 * sends entire digest back.

		/*

		 * Input is ciphertxt plus ICV, but ICV not incl

		 * in output.

 no rx frags to catch output data */

 Create tx scatterlist containing SPU request message */

/**

 * handle_aead_resp() - Process a SPU response message for an AEAD request.

 * @rctx:  Crypto request context

 See how much data was returned */

 only count payload */

	/*

	 * Copy the ICV back to the destination

	 * buffer. In decrypt case, SPU gives us back the digest, but crypto

	 * API doesn't expect ICV in dst buffer.

/**

 * spu_chunk_cleanup() - Do cleanup after processing one chunk of a request

 * @rctx:  request context

 *

 * Mailbox scatterlists are allocated for each chunk. So free them after

 * processing each chunk.

 mailbox message used to tx request */

/**

 * finish_req() - Used to invoke the complete callback from the requester when

 * a request has been handled asynchronously.

 * @rctx:  Request context

 * @err:   Indicates whether the request was successful or not

 *

 * Ensures that cleanup has been done for request

 No harm done if already called */

/**

 * spu_rx_callback() - Callback from mailbox framework with a SPU response.

 * @cl:		mailbox client structure for SPU driver

 * @msg:	mailbox message containing SPU response

 This is fatal */

 process the SPU status */

 Process the SPU response message */

	/*

	 * If this response does not complete the request, then send the next

	 * request chunk.

 Deallocate anything specific to previous chunk */

				/*

				 * we saved data in hash carry, but tell crypto

				 * API we successfully completed request.

 Successfully submitted request for next chunk */

 ==================== Kernel Cryptographic API ==================== */

/**

 * skcipher_enqueue() - Handle skcipher encrypt or decrypt request.

 * @req:	Crypto API request

 * @encrypt:	true if encrypting; false if decrypting

 *

 * Return: -EINPROGRESS if request accepted and result will be returned

 *			asynchronously

 *	   < 0 if an error

 Initialize current position in src and dst scatterlists */

 Choose a SPU to process this request */

 synchronous result */

 XTS includes two keys of equal length */

 SPU needs XTS keys in the reverse order the crypto API presents */

 Prepend SPU request message with BCM header */

 Initialize position in src scatterlist */

 SPU2 hardware does not compute hash of zero length data */

 Choose a SPU to process this request */

 synchronous result */

		/*

		 * we saved data in hash carry, but tell crypto API

		 * we successfully completed request.

 Initialize the context */

 If we add a hash whose digest is larger, catch it here. */

/**

 * spu_no_incr_hash() - Determine whether incremental hashing is supported.

 * @ctx:  Crypto session context

 *

 * SPU-2 does not support incremental hashing (we'll have to revisit and

 * condition based on chip revision or device tree entry if future versions do

 * support incremental hash)

 *

 * SPU-M also doesn't support incremental hashing of AES-XCBC

 *

 * Return: true if incremental hashing is not supported

 *         false otherwise

 Otherwise, incremental hashing is supported */

		/*

		 * If we get an incremental hashing request and it's not

		 * supported by the hardware, we need to handle it in software

		 * by calling synchronous hash functions.

 Set the key using data we already have from setkey */

 Initialize hash w/ this key and other params */

 Otherwise call the internal function which uses SPU hw */

		/*

		 * If we get an incremental hashing request and it's not

		 * supported by the hardware, we need to handle it in software

		 * by calling synchronous hash functions.

 Copy data from req scatterlist to tmp buffer */

 Call synchronous update */

 Otherwise call the internal function which uses SPU hw */

		/*

		 * If we get an incremental hashing request and it's not

		 * supported by the hardware, we need to handle it in software

		 * by calling synchronous hash functions.

 Done with hash, can deallocate it now */

 Otherwise call the internal function which uses SPU hw */

		/*

		 * If we get an incremental hashing request and it's not

		 * supported by the hardware, we need to handle it in software

		 * by calling synchronous hash functions.

 Copy data from req scatterlist to tmp buffer */

 Call synchronous update */

 Otherwise call the internal function which uses SPU hw */

 Done with hash, can deallocate it now */

 whole thing at once */

	/*

	 * Full HMAC operation in SPUM is not verified,

	 * So keeping the generation of IPAD, OPAD and

	 * outer hashing in software.

 init the context as a hash */

 SPU-M can do incr hashing but needs sw for outer HMAC */

 start with a prepended ipad */

 Perform initialization and then call finup */

		/*

		 * SPU2 supports full HMAC implementation in the

		 * hardware, need not to generate IPAD, OPAD and

		 * outer hash in software.

		 * Only for hash key len > hash block size, SPU2

		 * expects to perform hashing on the key, shorten

		 * it to digest size and feed it as hash key.

 start with a prepended ipad */

 aead helpers */

	/*

	 * SPU hardware cannot handle the AES-GCM/CCM case where plaintext

	 * and AAD are both 0 bytes long. So use fallback in this case.

 SPU-M hardware only supports CCM digest size of 8, 12, or 16 bytes */

	/*

	 * SPU-M on NSP has an issue where AES-CCM hash is not correct

	 * when AAD size is 0

	/*

	 * RFC4106 and RFC4543 cannot handle the case where AAD is other than

	 * 16 or 20 bytes long. So use fallback in this case.

 Store the cipher tfm and then use the fallback tfm */

		/*

		 * Save the callback and chain ourselves in, so we can restore

		 * the tfm

			/*

			 * fallback was synchronous (did not return

			 * -EINPROGRESS). So restore request state here.

 assoc data is at start of src sg */

	/*

	 * Init current position in src scatterlist to be after assoc data.

	 * src_skip set to buffer offset where data begins. (Assoc data could

	 * end in the middle of a buffer.)

		/*

		 * Expect req->dst to have room for assoc data followed by

		 * output data and ICV, if encrypt. So initialize dst_sg

		 * to point beyond assoc len offset.

	/*

	 * Do memory allocations for request after fallback check, because if we

	 * do fallback, we won't call finish_req() to dealloc.

 synchronous result */

 May end up padding auth key. So make sure it's zeroed. */

 setkey the fallback just in case we needto use it */

 setkey the fallback just in case we need to use it */

/**

 * aead_gcm_esp_setkey() - setkey() operation for ESP variant of GCM AES.

 * @cipher: AEAD structure

 * @key:    Key followed by 4 bytes of salt

 * @keylen: Length of key plus salt, in bytes

 *

 * Extracts salt from key and stores it to be prepended to IV on each request.

 * Digest is always 16 bytes

 *

 * Return: Value from generic gcm setkey.

/**

 * rfc4543_gcm_esp_setkey() - setkey operation for RFC4543 variant of GCM/GMAC.

 * @cipher: AEAD structure

 * @key:    Key followed by 4 bytes of salt

 * @keylen: Length of key plus salt, in bytes

 *

 * Extracts salt from key and stores it to be prepended to IV on each request.

 * Digest is always 16 bytes

 *

 * Return: Value from generic gcm setkey.

/**

 * aead_ccm_esp_setkey() - setkey() operation for ESP variant of CCM AES.

 * @cipher: AEAD structure

 * @key:    Key followed by 4 bytes of salt

 * @keylen: Length of key plus salt, in bytes

 *

 * Extracts salt from key and stores it to be prepended to IV on each request.

 * Digest is always 16 bytes

 *

 * Return: Value from generic ccm setkey.

 setkey the fallback just in case we needto use it */

 ==================== Supported Cipher Algorithms ==================== */

 SKCIPHER algorithms. */

 AHASH algorithms. */

	/*

	 * export state size has to be < 512 bytes. So don't include msg bufs

	 * in state size.

 random first IV */

/**

 * spu_functions_register() - Specify hardware-specific SPU functions based on

 * SPU type read from device tree.

 * @dev:	device structure

 * @spu_type:	SPU hardware generation

 * @spu_subtype: SPU hardware version

/**

 * spu_mb_init() - Initialize mailbox client. Request ownership of a mailbox

 * channel for the SPU being probed.

 * @dev:  SPU driver device structure

 *

 * Return: 0 if successful

 *	   < 0 otherwise

 Mark alg as having been registered, if successful */

 AES-XCBC is the only AES hash type currently supported on SPU-M */

 SHA3 algorithm variants are not registered for SPU-M or SPU2. */

 Mark alg as having been registered, if successful */

 setkey set in alg initialization */

 Mark alg as having been registered, if successful */

 register crypto algorithms the device supports */

 Skip any algorithm not registered */

 ==================== Kernel Platform API ==================== */

 sentinel */ }

 Count number of mailbox channels */

		/*

		 * Not all algorithms were registered, depending on whether

		 * hardware is SPU or SPU2.  So here we make sure to skip

		 * those algorithms that were not previously registered.

 ===== Kernel Module API ===== */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2016 Broadcom

 Assumes SPU-M messages are in big endian */

 SCTX length in words */

 SCTX payload length in bytes */

 ========== Decode MH ========== */

 skip emh. unused */

 ========== Decode SCTX ========== */

 XTS has two keys */

 ========== Decode BDESC ========== */

 ========== Decode BD ========== */

 Double check sanity */

/**

 * spum_ns2_ctx_max_payload() - Determine the max length of the payload for a

 * SPU message for a given cipher and hash alg context.

 * @cipher_alg:		The cipher algorithm

 * @cipher_mode:	The cipher mode

 * @blocksize:		The size of a block of data for this algo

 *

 * The max payload must be a multiple of the blocksize so that if a request is

 * too large to fit in a single SPU message, the request can be broken into

 * max_payload sized chunks. Each chunk must be a multiple of blocksize.

 *

 * Return: Max payload length in bytes

 In XTS on SPU-M, we'll need to insert tweak before input data */

/**

 * spum_nsp_ctx_max_payload() - Determine the max length of the payload for a

 * SPU message for a given cipher and hash alg context.

 * @cipher_alg:		The cipher algorithm

 * @cipher_mode:	The cipher mode

 * @blocksize:		The size of a block of data for this algo

 *

 * The max payload must be a multiple of the blocksize so that if a request is

 * too large to fit in a single SPU message, the request can be broken into

 * max_payload sized chunks. Each chunk must be a multiple of blocksize.

 *

 * Return: Max payload length in bytes

 In XTS on SPU-M, we'll need to insert tweak before input data */

/** spum_payload_length() - Given a SPU-M message header, extract the payload

 * length.

 * @spu_hdr:	Start of SPU header

 *

 * Assumes just MH, EMH, BD (no SCTX, BDESC. Works for response frames.

 *

 * Return: payload length in bytes

 Find BD header.  skip MH, EMH */

/**

 * spum_response_hdr_len() - Given the length of the hash key and encryption

 * key, determine the expected length of a SPU response header.

 * @auth_key_len:	authentication key length (bytes)

 * @enc_key_len:	encryption key length (bytes)

 * @is_hash:		true if response message is for a hash operation

 *

 * Return: length of SPU response header (bytes)

/**

 * spum_hash_pad_len() - Calculate the length of hash padding required to extend

 * data to a full block size.

 * @hash_alg:   hash algorithm

 * @hash_mode:       hash mode

 * @chunksize:  length of data, in bytes

 * @hash_block_size:  size of a block of data for hash algorithm

 *

 * Reserve space for 1 byte (0x80) start of pad and the total length as u64

 *

 * Return:  length of hash pad in bytes

 AES-XCBC hash requires just padding to next block boundary */

/**

 * spum_gcm_ccm_pad_len() - Determine the required length of GCM or CCM padding.

 * @cipher_mode:	Algo type

 * @data_size:		Length of plaintext (bytes)

 *

 * Return: Length of padding, in bytes

/**

 * spum_assoc_resp_len() - Determine the size of the receive buffer required to

 * catch associated data.

 * @cipher_mode:	cipher mode

 * @assoc_len:		length of associated data (bytes)

 * @iv_len:		length of IV (bytes)

 * @is_encrypt:		true if encrypting. false if decrypting.

 *

 * Return: length of associated data in response message (bytes)

 AAD needs to be padded in responses too */

		/*

		 * AAD needs to be padded in responses too

		 * for CCM, len + 2 needs to be 128-bit aligned.

/**

 * spum_aead_ivlen() - Calculate the length of the AEAD IV to be included

 * in a SPU request after the AAD and before the payload.

 * @cipher_mode:  cipher mode

 * @iv_len:   initialization vector length in bytes

 *

 * In Linux ~4.2 and later, the assoc_data sg includes the IV. So no need

 * to include the IV as a separate field in the SPU request msg.

 *

 * Return: Length of AEAD IV in bytes

/**

 * spum_hash_type() - Determine the type of hash operation.

 * @src_sent:  The number of bytes in the current request that have already

 *             been sent to the SPU to be hashed.

 *

 * We do not use HASH_TYPE_FULL for requests that fit in a single SPU message.

 * Using FULL causes failures (such as when the string to be hashed is empty).

 * For similar reasons, we never use HASH_TYPE_FIN. Instead, submit messages

 * as INIT or UPDT and do the hash padding in sw.

/**

 * spum_digest_size() - Determine the size of a hash digest to expect the SPU to

 * return.

 * @alg_digest_size: Number of bytes in the final digest for the given algo

 * @alg:             The hash algorithm

 * @htype:           Type of hash operation (init, update, full, etc)

 *

 * When doing incremental hashing for an algorithm with a truncated hash

 * (e.g., SHA224), the SPU returns the full digest so that it can be fed back as

 * a partial result for the next chunk.

	/* SPU returns complete digest when doing incremental hash and truncated

	 * hash algo.

/**

 * spum_create_request() - Build a SPU request message header, up to and

 * including the BD header. Construct the message starting at spu_hdr. Caller

 * should allocate this buffer in DMA-able memory at least SPU_HEADER_ALLOC_LEN

 * bytes long.

 * @spu_hdr: Start of buffer where SPU request header is to be written

 * @req_opts: SPU request message options

 * @cipher_parms: Parameters related to cipher algorithm

 * @hash_parms:   Parameters related to hash algorithm

 * @aead_parms:   Parameters related to AEAD operation

 * @data_size:    Length of data to be encrypted or authenticated. If AEAD, does

 *		  not include length of AAD.

 *

 * Return: the length of the SPU header in bytes. 0 if an error occurs.

 size of the cipher payload */

 offset of prebuf or data from end of BD header */

 total size of the DB data (without STAT word padding) */

 size/offset of the auth payload */

 starting out: zero the header (plus some) */

 format master header word */

 Do not set the next bit even though the datasheet says to */

 Format sctx word 0 (protocol_bits) */

 size in words */

 Format sctx word 1 (cipher_bits) */

 Set the crypto parameters in the cipher.flags */

 Set the auth parameters in the cipher.flags */

	/*

	 * Format sctx extensions if required, and update main fields if

	 * required)

 Write the authentication key material if present */

 unpadded length */

 if GCM/CCM we need to write ICV into the payload */

 Inform the SPU of the ICV size (in words) */

 copy the encryption keys in the SAD entry */

		/*

		 * if encrypting then set IV size, use SCTX IV unless no IV

		 * given here

 Use SCTX IV */

 cipher iv provided so put it in here */

	/*

	 * RFC4543 (GMAC/ESP) requires data to be sent as part of AAD

	 * so we need to override the BDESC parameters.

 write in the total sctx length now that we know it */

 Endian adjust the SCTX */

 === create the BDESC section === */

	/*

	 * CCM in SPU-M requires that ICV not be in same 32-bit word as data or

	 * padding.  So account for padding as necessary.

 === no MFM section === */

 === create the BD section === */

 add the BD header */

/**

 * spum_cipher_req_init() - Build a SPU request message header, up to and

 * including the BD header.

 * @spu_hdr:      Start of SPU request header (MH)

 * @cipher_parms: Parameters that describe the cipher request

 *

 * Construct the message starting at spu_hdr. Caller should allocate this buffer

 * in DMA-able memory at least SPU_HEADER_ALLOC_LEN bytes long.

 *

 * Return: the length of the SPU header in bytes. 0 if an error occurs.

 starting out: zero the header (plus some) */

 format master header word */

 Do not set the next bit even though the datasheet says to */

 Format sctx word 0 (protocol_bits) */

 size in words */

 copy the encryption keys in the SAD entry */

		/*

		 * if encrypting then set IV size, use SCTX IV unless no IV

		 * given here

 Use SCTX IV */

 Set the crypto parameters in the cipher.flags */

 copy the encryption keys in the SAD entry */

 write in the total sctx length now that we know it */

 Endian adjust the SCTX */

 Endian adjust the SCTX */

/**

 * spum_cipher_req_finish() - Finish building a SPU request message header for a

 * block cipher request. Assumes much of the header was already filled in at

 * setkey() time in spu_cipher_req_init().

 * @spu_hdr:         Start of the request message header (MH field)

 * @spu_req_hdr_len: Length in bytes of the SPU request header

 * @is_inbound:      0 encrypt, 1 decrypt

 * @cipher_parms:    Parameters describing cipher operation to be performed

 * @data_size:       Length of the data in the BD field

 *

 * Assumes much of the header was already filled in at setkey() time in

 * spum_cipher_req_init().

 * spum_cipher_req_init() fills in the encryption key.

	/*

	 * In XTS mode, API puts "i" parameter (block tweak) in IV.  For

	 * SPU-M, should be in start of the BD; tx_sg_create() copies it there.

	 * IV in SPU msg for SPU-M should be 0, since that's the "j" parameter

	 * (block ctr within larger data unit) - given we can send entire disk

	 * block (<= 4KB) in 1 SPU msg, don't need to use this parameter.

 format master header word */

 Do not set the next bit even though the datasheet says to */

 cipher_bits was initialized at setkey time */

 Format sctx word 1 (cipher_bits) */

 cipher iv provided so put it in here */

 === create the BDESC section === */

 XTS mode, data_size needs to include tweak parameter */

 === no MFM section === */

 === create the BD section === */

 add the BD header */

 XTS mode, data_size needs to include tweak parameter */

/**

 * spum_request_pad() - Create pad bytes at the end of the data.

 * @pad_start:		Start of buffer where pad bytes are to be written

 * @gcm_ccm_padding:	length of GCM/CCM padding, in bytes

 * @hash_pad_len:	Number of bytes of padding extend data to full block

 * @auth_alg:		authentication algorithm

 * @auth_mode:		authentication mode

 * @total_sent:		length inserted at end of hash pad

 * @status_padding:	Number of bytes of padding to align STATUS word

 *

 * There may be three forms of pad:

 *  1. GCM/CCM pad - for GCM/CCM mode ciphers, pad to 16-byte alignment

 *  2. hash pad - pad to a block length, with 0x80 data terminator and

 *                size at the end

 *  3. STAT pad - to ensure the STAT field is 4-byte aligned

 fix data alignent for GCM/CCM */

 clear the padding section */

 AES/XCBC just requires padding to be 0s */

 terminate the data */

 add the size at the end as required per alg */

 SHA1, SHA2-224, SHA2-256 */

 pad to a 4byte alignment for STAT */

/**

 * spum_xts_tweak_in_payload() - Indicate that SPUM DOES place the XTS tweak

 * field in the packet payload (rather than using IV)

 *

 * Return: 1

/**

 * spum_tx_status_len() - Return the length of the STATUS field in a SPU

 * response message.

 *

 * Return: Length of STATUS field in bytes.

/**

 * spum_rx_status_len() - Return the length of the STATUS field in a SPU

 * response message.

 *

 * Return: Length of STATUS field in bytes.

/**

 * spum_status_process() - Process the status from a SPU response message.

 * @statp:  start of STATUS word

 * Return:

 *   0 - if status is good and response should be processed

 *   !0 - status indicates an error and response is invalid

/**

 * spum_ccm_update_iv() - Update the IV as per the requirements for CCM mode.

 *

 * @digestsize:		Digest size of this request

 * @cipher_parms:	(pointer to) cipher parmaeters, includes IV buf & IV len

 * @assoclen:		Length of AAD data

 * @chunksize:		length of input data to be sent in this req

 * @is_encrypt:		true if this is an output/encrypt operation

 * @is_esp:		true if this is an ESP / RFC4309 operation

 *

 L from CCM algorithm, length of plaintext data */

 M' from CCM algo, (M - 2) / 2, where M=authsize */

	/*

	 * IV needs to be formatted as follows:

	 *

	 * |          Byte 0               | Bytes 1 - N | Bytes (N+1) - 15 |

	 * | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 | Bits 7 - 0  |    Bits 7 - 0    |

	 * | 0 |Ad?|(M - 2) / 2|   L - 1   |    Nonce    | Plaintext Length |

	 *

	 * Ad? = 1 if AAD present, 0 if not present

	 * M = size of auth field, 8, 12, or 16 bytes (SPU-M) -or-

	 *                         4, 6, 8, 10, 12, 14, 16 bytes (SPU2)

	 * L = Size of Plaintext Length field; Nonce size = 15 - L

	 *

	 * It appears that the crypto API already expects the L-1 portion

	 * to be set in the first byte of the IV, which implicitly determines

	 * the nonce size, and also fills in the nonce.  But the other bits

	 * in byte 0 as well as the plaintext length need to be filled in.

	 *

	 * In rfc4309/esp mode, L is not already in the supplied IV and

	 * we need to fill it in, as well as move the IV data to be after

	 * the salt

 RFC4309 has fixed L */

 L' = plaintext length - 1 so Plaintext length is L' + 1 */

 M' = (M - 2) / 2 */

 adata = 1 if any associated data */

 Nonce is already filled in by crypto API, and is 15 - L bytes */

 Don't include digest in plaintext size when decrypting */

 Fill in length of plaintext, formatted to be L bytes long */

/**

 * spum_wordalign_padlen() - Given the length of a data field, determine the

 * padding required to align the data following this field on a 4-byte boundary.

 * @data_size: length of data field in bytes

 *

 * Return: length of status field padding, in bytes

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2016 Broadcom

 offset of SPU_OFIFO_CTRL register */

/**

 * spu_sg_at_offset() - Find the scatterlist entry at a given distance from the

 * start of a scatterlist.

 * @sg:         [in]  Start of a scatterlist

 * @skip:       [in]  Distance from the start of the scatterlist, in bytes

 * @sge:        [out] Scatterlist entry at skip bytes from start

 * @sge_offset: [out] Number of bytes from start of sge buffer to get to

 *                    requested distance.

 *

 * Return: 0 if entry found at requested distance

 *         < 0 otherwise

 byte index from start of sg to the end of the previous entry */

 byte index from start of sg to the end of the current entry */

 Copy len bytes of sg data, starting at offset skip, to a dest buffer */

/*

 * Copy data into a scatterlist starting at a specified offset in the

 * scatterlist. Specifically, copy len bytes of data in the buffer src

 * into the scatterlist dest, starting skip bytes into the scatterlist.

/**

 * spu_sg_count() - Determine number of elements in scatterlist to provide a

 * specified number of bytes.

 * @sg_list:  scatterlist to examine

 * @skip:     index of starting point

 * @nbytes:   consider elements of scatterlist until reaching this number of

 *	      bytes

 *

 * Return: the number of sg entries contributing to nbytes of data

/**

 * spu_msg_sg_add() - Copy scatterlist entries from one sg to another, up to a

 * given length.

 * @to_sg:       scatterlist to copy to

 * @from_sg:     scatterlist to copy from

 * @from_skip:   number of bytes to skip in from_sg. Non-zero when previous

 *		 request included part of the buffer in entry in from_sg.

 *		 Assumes from_skip < from_sg->length.

 * @from_nents:  number of entries in from_sg

 * @length:      number of bytes to copy. may reach this limit before exhausting

 *		 from_sg.

 *

 * Copies the entries themselves, not the data in the entries. Assumes to_sg has

 * enough entries. Does not limit the size of an individual buffer in to_sg.

 *

 * to_sg, from_sg, skip are all updated to end of copy

 *

 * Return: Number of bytes copied

 an entry in from_sg */

 length of entry added to to_sg */

 number of bytes copied so far */

 number of bytes in this from entry not yet used */

 used up all of from entry */

 start at beginning of next entry */

 there was a carry from the low 8 bytes */

/**

 * do_shash() - Do a synchronous hash operation in software

 * @name:       The name of the hash algorithm

 * @result:     Buffer where digest is to be written

 * @data1:      First part of data to hash. May be NULL.

 * @data1_len:  Length of data1, in bytes

 * @data2:      Second part of data to hash. May be NULL.

 * @data2_len:  Length of data2, in bytes

 * @key:	Key (if keyed hash)

 * @key_len:	Length of key, in bytes (or 0 if non-keyed hash)

 *

 * Note that the crypto API will not select this driver's own transform because

 * this driver only registers asynchronous algos.

 *

 * Return: 0 if hash successfully stored in result

 *         < 0 otherwise

 Dump len bytes of a scatterlist starting at skip bytes into the sg */

 number of bytes dumped so far */

 Returns the name for a given cipher alg/mode */

/*

 * Create the debug FS directories. If the top-level directory has not yet

 * been created, create it now. Create a stats file in this directory for

 * a SPU.

 Create file with permissions S_IRUSR */

/**

 * format_value_ccm() - Format a value into a buffer, using a specified number

 *			of bytes (i.e. maybe writing value X into a 4 byte

 *			buffer, or maybe into a 12 byte buffer), as per the

 *			SPU CCM spec.

 *

 * @val:		value to write (up to max of unsigned int)

 * @buf:		(pointer to) buffer to write the value

 * @len:		number of bytes to use (0 to 255)

 *

 First clear full output buffer */

 Then, starting from right side, fill in with data */

 Only handle up to 32 bits of 'val' */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2016 Broadcom

/*

 * This file works with the SPU2 version of the SPU. SPU2 has different message

 * formats than the previous version of the SPU. All SPU message format

 * differences should be hidden in the spux.c,h files.

 SPU2 has no STATUS in input packet */

/*

 * Controlled by pkt_stat_cnt field in CRYPTO_SS_SPU0_CORE_SPU2_CONTROL0

 * register. Defaults to 2.

/*

 * Convert from a software cipher mode value to the corresponding value

 * for SPU2.

/**

 * spu2_cipher_xlate() - Convert a cipher {alg/mode/type} triple to a SPU2

 * cipher type and mode.

 * @cipher_alg:  [in]  cipher algorithm value from software enumeration

 * @cipher_mode: [in]  cipher mode value from software enumeration

 * @cipher_type: [in]  cipher type value from software enumeration

 * @spu2_type:   [out] cipher type value used by spu2 hardware

 * @spu2_mode:   [out] cipher mode value used by spu2 hardware

 *

 * Return:  0 if successful

 SPU2 does not support RC4 */

/*

 * Convert from a software hash mode value to the corresponding value

 * for SPU2. Note that HASH_MODE_NONE and HASH_MODE_XCBC have the same value.

/**

 * spu2_hash_xlate() - Convert a hash {alg/mode/type} triple to a SPU2 hash type

 * and mode.

 * @hash_alg:  [in] hash algorithm value from software enumeration

 * @hash_mode: [in] hash mode value from software enumeration

 * @hash_type: [in] hash type value from software enumeration

 * @ciph_type: [in] cipher type value from software enumeration

 * @spu2_type: [out] hash type value used by SPU2 hardware

 * @spu2_mode: [out] hash mode value used by SPU2 hardware

 *

 * Return:  0 if successful

 Dump FMD ctrl0. The ctrl0 input is in host byte order */

 Dump FMD ctrl1. The ctrl1 input is in host byte order */

 Dump FMD ctrl2. The ctrl2 input is in host byte order */

 Dump FMD ctrl3. The ctrl3 input is in host byte order */

 Dump a SPU2 header for debug */

 Double check sanity */

/**

 * spu2_fmd_init() - At setkey time, initialize the fixed meta data for

 * subsequent skcipher requests for this context.

 * @fmd:               Start of FMD field to be written

 * @spu2_type:         Cipher algorithm

 * @spu2_mode:         Cipher mode

 * @cipher_key_len:    Length of cipher key, in bytes

 * @cipher_iv_len:     Length of cipher initialization vector, in bytes

 *

 * Return:  0 (success)

	/*

	 * AAD1 offset is from start of FD. FD length is always 0 for this

	 * driver. So AAD1_offset is always 0.

/**

 * spu2_fmd_ctrl0_write() - Write ctrl0 field in fixed metadata (FMD) field of

 * SPU request packet.

 * @fmd:            Start of FMD field to be written

 * @is_inbound:     true if decrypting. false if encrypting.

 * @auth_first:     true if alg authenticates before encrypting

 * @protocol:       protocol selector

 * @cipher_type:    cipher algorithm

 * @cipher_mode:    cipher mode

 * @auth_type:      authentication type

 * @auth_mode:      authentication mode

/**

 * spu2_fmd_ctrl1_write() - Write ctrl1 field in fixed metadata (FMD) field of

 * SPU request packet.

 * @fmd:            Start of FMD field to be written

 * @is_inbound:     true if decrypting. false if encrypting.

 * @assoc_size:     Length of additional associated data, in bytes

 * @auth_key_len:   Length of authentication key, in bytes

 * @cipher_key_len: Length of cipher key, in bytes

 * @gen_iv:         If true, hw generates IV and returns in response

 * @hash_iv:        IV participates in hash. Used for IPSEC and TLS.

 * @return_iv:      Return IV in output packet before payload

 * @ret_iv_len:     Length of IV returned from SPU, in bytes

 * @ret_iv_offset:  Offset into full IV of start of returned IV

 * @cipher_iv_len:  Length of input cipher IV, in bytes

 * @digest_size:    Length of digest (aka, hash tag or ICV), in bytes

 * @return_payload: Return payload in SPU response

 * @return_md : return metadata in SPU response

 *

 * Packet can have AAD2 w/o AAD1. For algorithms currently supported,

 * associated data goes in AAD2.

 need aad2 for gcm aes esp */

	/* Let's ask for the output pkt to include FMD, but don't need to

	 * get keys and IVs back in OMD.

 Crypto API does not get assoc data back. So no need for AAD2. */

/**

 * spu2_fmd_ctrl2_write() - Set the ctrl2 field in the fixed metadata field of

 * SPU2 header.

 * @fmd:            Start of FMD field to be written

 * @cipher_offset:  Number of bytes from Start of Packet (end of FD field) where

 *                  data to be encrypted or decrypted begins

 * @auth_key_len:   Length of authentication key, in bytes

 * @auth_iv_len:    Length of authentication initialization vector, in bytes

 * @cipher_key_len: Length of cipher key, in bytes

 * @cipher_iv_len:  Length of cipher IV, in bytes

 AAD1 offset is from start of FD. FD length always 0. */

/**

 * spu2_fmd_ctrl3_write() - Set the ctrl3 field in FMD

 * @fmd:          Fixed meta data. First field in SPU2 msg header.

 * @payload_len:  Length of payload, in bytes

/**

 * spu2_ctx_max_payload() - Determine the maximum length of the payload for a

 * SPU message for a given cipher and hash alg context.

 * @cipher_alg:		The cipher algorithm

 * @cipher_mode:	The cipher mode

 * @blocksize:		The size of a block of data for this algo

 *

 * For SPU2, the hardware generally ignores the PayloadLen field in ctrl3 of

 * FMD and just keeps computing until it receives a DMA descriptor with the EOF

 * flag set. So we consider the max payload to be infinite. AES CCM is an

 * exception.

 *

 * Return: Max payload length in bytes

/**

 * spu2_payload_length() -  Given a SPU2 message header, extract the payload

 * length.

 * @spu_hdr:  Start of SPU message header (FMD)

 *

 * Return: payload length, in bytes

/**

 * spu2_response_hdr_len() - Determine the expected length of a SPU response

 * header.

 * @auth_key_len:  Length of authentication key, in bytes

 * @enc_key_len:   Length of encryption key, in bytes

 * @is_hash:       Unused

 *

 * For SPU2, includes just FMD. OMD is never requested.

 *

 * Return: Length of FMD, in bytes

/**

 * spu2_hash_pad_len() - Calculate the length of hash padding required to extend

 * data to a full block size.

 * @hash_alg:        hash algorithm

 * @hash_mode:       hash mode

 * @chunksize:       length of data, in bytes

 * @hash_block_size: size of a hash block, in bytes

 *

 * SPU2 hardware does all hash padding

 *

 * Return:  length of hash pad in bytes

/**

 * spu2_gcm_ccm_pad_len() -  Determine the length of GCM/CCM padding for either

 * the AAD field or the data.

 * @cipher_mode:  Unused

 * @data_size:    Unused

 *

 * Return:  0. Unlike SPU-M, SPU2 hardware does any GCM/CCM padding required.

/**

 * spu2_assoc_resp_len() - Determine the size of the AAD2 buffer needed to catch

 * associated data in a SPU2 output packet.

 * @cipher_mode:   cipher mode

 * @assoc_len:     length of additional associated data, in bytes

 * @iv_len:        length of initialization vector, in bytes

 * @is_encrypt:    true if encrypting. false if decrypt.

 *

 * Return: Length of buffer to catch associated data in response

 gcm aes esp has to write 8-byte IV in response */

/**

 * spu2_aead_ivlen() - Calculate the length of the AEAD IV to be included

 * in a SPU request after the AAD and before the payload.

 * @cipher_mode:  cipher mode

 * @iv_len:   initialization vector length in bytes

 *

 * For SPU2, AEAD IV is included in OMD and does not need to be repeated

 * prior to the payload.

 *

 * Return: Length of AEAD IV in bytes

/**

 * spu2_hash_type() - Determine the type of hash operation.

 * @src_sent:  The number of bytes in the current request that have already

 *             been sent to the SPU to be hashed.

 *

 * SPU2 always does a FULL hash operation

/**

 * spu2_digest_size() - Determine the size of a hash digest to expect the SPU to

 * return.

 * @alg_digest_size: Number of bytes in the final digest for the given algo

 * @alg:             The hash algorithm

 * @htype:           Type of hash operation (init, update, full, etc)

 *

/**

 * spu2_create_request() - Build a SPU2 request message header, includint FMD and

 * OMD.

 * @spu_hdr: Start of buffer where SPU request header is to be written

 * @req_opts: SPU request message options

 * @cipher_parms: Parameters related to cipher algorithm

 * @hash_parms:   Parameters related to hash algorithm

 * @aead_parms:   Parameters related to AEAD operation

 * @data_size:    Length of data to be encrypted or authenticated. If AEAD, does

 *		  not include length of AAD.

 *

 * Construct the message starting at spu_hdr. Caller should allocate this buffer

 * in DMA-able memory at least SPU_HEADER_ALLOC_LEN bytes long.

 *

 * Return: the length of the SPU header in bytes. 0 if an error occurs.

 size of the payload */

 offset of prebuf or data from start of AAD2 */

 total size of the data following OMD (without STAT word padding) */

		/*

		 * On SPU 2, aes gcm cipher first on encrypt, auth first on

		 * decrypt

 and do opposite for ccm (auth 1st on encrypt) */

 Convert to spu2 values for cipher alg, hash alg */

	/* If we are doing GCM hashing only - either via rfc4543 transform

	 * or because we happen to do GCM with AAD only and no payload - we

	 * need to configure hardware to use hash key rather than cipher key

	 * and put data into payload.  This is because unlike SPU-M, running

	 * GCM cipher with 0 size payload is not permitted.

 Use hashing (only) and set up hash key */

 Write OMD */

/**

 * spu2_cipher_req_init() - Build an skcipher SPU2 request message header,

 * including FMD and OMD.

 * @spu_hdr:       Location of start of SPU request (FMD field)

 * @cipher_parms:  Parameters describing cipher request

 *

 * Called at setkey time to initialize a msg header that can be reused for all

 * subsequent skcipher requests. Construct the message starting at spu_hdr.

 * Caller should allocate this buffer in DMA-able memory at least

 * SPU_HEADER_ALLOC_LEN bytes long.

 *

 * Return: the total length of the SPU header (FMD and OMD) in bytes. 0 if an

 * error occurs.

 Convert to spu2 values */

 Construct the FMD header */

 Write cipher key to OMD */

/**

 * spu2_cipher_req_finish() - Finish building a SPU request message header for a

 * block cipher request.

 * @spu_hdr:         Start of the request message header (MH field)

 * @spu_req_hdr_len: Length in bytes of the SPU request header

 * @is_inbound:      0 encrypt, 1 decrypt

 * @cipher_parms:    Parameters describing cipher operation to be performed

 * @data_size:       Length of the data in the BD field

 *

 * Assumes much of the header was already filled in at setkey() time in

 * spu_cipher_req_init().

 * spu_cipher_req_init() fills in the encryption key.

 start of optional metadata */

	/*

	 * FMD ctrl0 was initialized at setkey time. update it to indicate

	 * whether we are encrypting or decrypting.

 decrypt */

 encrypt */

 cipher iv provided so put it in here */

/**

 * spu2_request_pad() - Create pad bytes at the end of the data.

 * @pad_start:      Start of buffer where pad bytes are to be written

 * @gcm_padding:    Length of GCM padding, in bytes

 * @hash_pad_len:   Number of bytes of padding extend data to full block

 * @auth_alg:       Authentication algorithm

 * @auth_mode:      Authentication mode

 * @total_sent:     Length inserted at end of hash pad

 * @status_padding: Number of bytes of padding to align STATUS word

 *

 * There may be three forms of pad:

 *  1. GCM pad - for GCM mode ciphers, pad to 16-byte alignment

 *  2. hash pad - pad to a block length, with 0x80 data terminator and

 *                size at the end

 *  3. STAT pad - to ensure the STAT field is 4-byte aligned

 fix data alignent for GCM */

 clear the padding section */

 terminate the data */

 add the size at the end as required per alg */

 SHA1, SHA2-224, SHA2-256 */

 pad to a 4byte alignment for STAT */

/**

 * spu2_xts_tweak_in_payload() - Indicate that SPU2 does NOT place the XTS

 * tweak field in the packet payload (it uses IV instead)

 *

 * Return: 0

/**

 * spu2_tx_status_len() - Return the length of the STATUS field in a SPU

 * response message.

 *

 * Return: Length of STATUS field in bytes.

/**

 * spu2_rx_status_len() - Return the length of the STATUS field in a SPU

 * response message.

 *

 * Return: Length of STATUS field in bytes.

/**

 * spu2_status_process() - Process the status from a SPU response message.

 * @statp:  start of STATUS word

 *

 * Return:  0 - if status is good and response should be processed

 *         !0 - status indicates an error and response is invalid

 SPU2 status is 2 bytes by default - SPU_RX_STATUS_LEN */

/**

 * spu2_ccm_update_iv() - Update the IV as per the requirements for CCM mode.

 *

 * @digestsize:		Digest size of this request

 * @cipher_parms:	(pointer to) cipher parmaeters, includes IV buf & IV len

 * @assoclen:		Length of AAD data

 * @chunksize:		length of input data to be sent in this req

 * @is_encrypt:		true if this is an output/encrypt operation

 * @is_esp:		true if this is an ESP / RFC4309 operation

 *

 size of length field, in bytes */

	/*

	 * In RFC4309 mode, L is fixed at 4 bytes; otherwise, IV from

	 * testmgr contains (L-1) in bottom 3 bits of first byte,

	 * per RFC 3610.

 SPU2 doesn't want these length bytes nor the first byte... */

/**

 * spu2_wordalign_padlen() - SPU2 does not require padding.

 * @data_size: length of data field in bytes

 *

 * Return: length of status field padding, in bytes (always 0 on SPU2)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SHA-512 routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

	/* 2 cases for total data len:

	 *  1: < SHA512_BLOCK_SIZE: copy into state, return 0

	 *  2: >= SHA512_BLOCK_SIZE: process X blocks, copy in leftover

		/* to_process: SHA512_BLOCK_SIZE aligned chunk to be

		 * processed in this iteration. This value is restricted

		 * by sg list limits and number of sgs we already used

		 * for leftover data. (see above)

		 * In ideal case, we could allow NX_PAGE_SIZE * max_sg_len,

		 * but because data may not be aligned, we need to account

		/*

		 * we've hit the nx chip previously and we're updating

		 * again, so copy over the partial digest.

 copy the leftover back into the state struct */

	/* final is represented by continuing the operation and indicating that

		/* we've hit the nx chip previously, now we're finalizing,

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES XCBC routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

/*

 * Based on RFC 3566, for a zero-length message:

 *

 * n = 1

 * K1 = E(K, 0x01010101010101010101010101010101)

 * K3 = E(K, 0x03030303030303030303030303030303)

 * E[0] = 0x00000000000000000000000000000000

 * M[1] = 0x80000000000000000000000000000000 (0 length message with padding)

 * E[1] = (K1, M[1] ^ E[0] ^ K3)

 * Tag = M[1]

 Change to ECB mode */

 K1 and K3 base patterns */

 Generate K1 and K3 encrypting the patterns */

 XOr K3 with the padding for a 0 length message */

 Encrypt the final result */

 Restore XCBC mode */

	/* 2 cases for total data len:

	 *  1: <= AES_BLOCK_SIZE: copy into state, return 0

	 *  2: > AES_BLOCK_SIZE: process X blocks, copy in leftover

		/* the hardware will not accept a 0 byte operation for this

		 * algorithm and the operation MUST be finalized to be correct.

		 * So if we happen to get an update that falls on a block sized

		 * boundary, we must save off the last block to finalize with

		/* we've hit the nx chip previously and we're updating again,

 everything after the first update is continuation */

 copy the leftover back into the state struct */

		/* we've hit the nx chip previously, now we're finalizing,

		/*

		 * we've never seen an update, so this is a 0 byte op. The

		 * hardware cannot handle a 0 byte op, so just ECB to

		 * generate the hash.

	/* final is represented by continuing the operation and indicating that

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES GCM routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

 page_limit: number of sg entries that fit on one page */

		/*

		 * to_process: the data chunk to process in this update.

		 * This value is bound by sg list limits.

 Set GMAC mode */

 page_limit: number of sg entries that fit on one page */

 Copy IV */

		/*

		 * to_process: the data chunk to process in this update.

		 * This value is bound by sg list limits.

 Restore GCM mode */

	/* For scenarios where the input message is zero length, AES CTR mode

	 * may be used. Set the source data to be a single block (16B) of all

	 * zeros, and set the input IV value to be the same as the GMAC IV

 Change to ECB mode */

 Encrypt the counter/IV */

 Copy out the auth tag */

 Restore XCBC mode */

	/*

	 * ECB key uses the same region that GCM AAD and counter, so it's safe

	 * to just fill it with zeroes.

 initialize the counter */

 Process associated data */

 Set flags for encryption */

 copy out the auth tag */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES ECB routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API for the NX-842 hardware compression.

 *

 * Copyright (C) IBM Corporation, 2011-2015

 *

 * Designer of the Power data compression engine:

 *   Bulent Abali <abali@us.ibm.com>

 *

 * Original Authors: Robert Jennings <rcj@linux.vnet.ibm.com>

 *                   Seth Jennings <sjenning@linux.vnet.ibm.com>

 *

 * Rewrite: Dan Streetman <ddstreet@ieee.org>

 *

 * This is an interface to the NX-842 compression hardware in PowerPC

 * processors.  Most of the complexity of this drvier is due to the fact that

 * the NX-842 compression hardware requires the input and output data buffers

 * to be specifically aligned, to be a specific multiple in length, and within

 * specific minimum and maximum lengths.  Those restrictions, provided by the

 * nx-842 driver via nx842_constraints, mean this driver must use bounce

 * buffers and headers to correct misaligned in or out buffers, and to split

 * input buffers that are too large.

 *

 * This driver will fall back to software decompression if the hardware

 * decompression fails, so this driver's decompression should never fail as

 * long as the provided compressed buffer is valid.  Any compressed buffer

 * created by this driver will have a header (except ones where the input

 * perfectly matches the constraints); so users of this driver cannot simply

 * pass a compressed buffer created by this driver over to the 842 software

 * decompression library.  Instead, users must use this driver to decompress;

 * if the hardware fails or is unavailable, the compressed buffer will be

 * parsed and the header removed, and the raw 842 buffer(s) passed to the 842

 * software decompression library.

 *

 * This does not fall back to software compression, however, since the caller

 * of this function is specifically requesting hardware compression; if the

 * hardware compression fails, the caller can fall back to software

 * compression, and the raw 842 compressed buffer that the software compressor

 * creates can be passed to this driver for hardware decompression; any

 * buffer without our specific header magic is assumed to be a raw 842 buffer

 * and passed directly to the hardware.  Note that the software compression

 * library will produce a compressed buffer that is incompatible with the

 * hardware decompressor if the original input buffer length is not a multiple

 * of 8; if such a compressed buffer is passed to this driver for

 * decompression, the hardware will reject it and this driver will then pass

 * it over to the software library for decompression.

/* The first 5 bits of this magic are 0x1f, which is an invalid 842 5-bit

 * template (see lib/842/842.h), so this magic number will never appear at

 * the start of a raw 842 compressed buffer.  That is important, as any buffer

 * passed to us without this magic is assumed to be a raw 842 compressed

 * buffer, and passed directly to the hardware to decompress.

 bounce buffer size */

 try longer on comp because we can fallback to sw decomp if hw is busy */

 ms */

 ms */

 limit maximum, to always have enough bounce buffer to decompress */

 compress should have added space for header */

 reset dlen, if we're retrying */

		/* possibly we should reduce the slen here, instead of

		 * retrying with the dbounce buffer?

 skip adding header if the buffers meet all constraints */

 header goes before first group */

 ignore indicates the input stream needed to be padded */

		/* we can append padding bytes because the 842 format defines

		 * an "end" template (see lib/842/842_decompress.c) and will

		 * ignore any bytes following it.

 reset dlen, if we're retrying */

 reset everything, sw doesn't have constraints */

 have ignore bytes */

	/* If it doesn't start with our header magic number, assume it's a raw

	 * 842 compressed buffer and pass it directly to the hardware driver

 ignore applies to last group */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES CTR routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES CCM routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

 taken from crypto/ccm.c */

 taken from crypto/ccm.c */

 2 <= L <= 8, so 1 <= L' <= 7. */

 based on code from crypto/ccm.c */

 set m, bits 3-5 */

 set adata, bit 6, if associated data is used */

 zero the ctr value */

	/* page 78 of nx_wb.pdf has,

	 * Note: RFC3610 allows the AAD data to be up to 2^64 -1 bytes

	 * in length. If a full message is used, the AES CCA implementation

	 * restricts the maximum AAD length to 2^32 -1 bytes.

	 * If partial messages are used, the implementation supports

	 * 2^64 -1 bytes maximum AAD length.

	 *

	 * However, in the cryptoapi's aead_request structure,

	 * assoclen is an unsigned int, thus it cannot hold a length

	 * value greater than 2^32 - 1.

	 * Thus the AAD is further constrained by this and is never

	 * greater than 2^32.

		/* if associated data is 14 bytes or less, we do 1 GCM

		 * operation on 2 AES blocks, B0 (stored in the csbcpb) and B1,

		/* if associated data is less than (2^16 - 2^8), we construct

		 * B1 differently and feed in the associated data to a CCA

 generate B0 */

	/* generate B1:

	 * add control info for associated data

	 * RFC 3610 and NIST Special Publication 800-38C

 now copy any remaining AAD to scatterlist and call nx... */

		/* inlen should be negative, indicating to phyp that its a

 page_limit: number of sg entries that fit on one page */

 copy out the auth tag to compare with later */

		/* to_process: the AES_BLOCK_SIZE data chunk to process in this

		 * update. This value is bound by sg list limits.

		/* for partial completion, copy following for next

		 * entry into loop...

 update stats */

		/* to process: the AES_BLOCK_SIZE data chunk to process in this

		 * update. This value is bound by sg list limits.

		/* for partial completion, copy following for next

		 * entry into loop...

 update stats */

 copy out the auth tag */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for IBM PowerNV compression accelerator

 *

 * Copyright (C) 2015 Dan Streetman, IBM Corp

 ms */

 Below fields must be properly aligned */

 CRB_ALIGN align */

 DDE_ALIGN align */

 DDE_ALIGN align */

 Above fields must be properly aligned */

 unused, to allow alignment */

 Can be 842 or GZIP high/normal*/

 Coprocessor instance, used with icswx */

/*

 * Send the request to NX engine on the chip for the corresponding CPU

 * where the process is executing. Use with VAS function.

 no cpu hotplug on powernv, so this list never changes after init */

 used in icswx function */

/*

 * Using same values as in skiboot or coprocessor type representing

 * in NX workbook.

 on P9 and later */

/**

 * setup_indirect_dde - Setup an indirect DDE

 *

 * The DDE is setup with the the DDE count, byte count, and address of

 * first direct DDE in the list.

/**

 * setup_direct_dde - Setup single DDE from buffer

 *

 * The DDE is setup with the buffer and length.  The buffer must be properly

 * aligned.  The used length is returned.

 * Returns:

 *   N    Successfully set up DDE with N bytes

/**

 * setup_ddl - Setup DDL from buffer

 *

 * Returns:

 *   0		Successfully set up DDL

	/* only need to check last mult; since buffer must be

	 * DDE_BUFFER_ALIGN aligned, and that is a multiple of

	 * DDE_BUFFER_SIZE_MULT, and pre-last page DDE buffers

	 * are guaranteed a multiple of DDE_BUFFER_SIZE_MULT.

 use a single direct DDE */

 use the DDL */

/**

 * wait_for_csb

 hw has updated csb and output buffer */

 check CSB flags */

 verify CSB completion sequence is 0 */

 check CSB Completion Code */

 no error */

		/* not an error, but the compressed data is

		 * larger than the uncompressed data :(

 input data errors */

 input and output buffers overlap */

 output buffer too small */

 P9 or later */

		/*

		 * DDE byte count exceeds the limit specified in Maximum

		 * byte count register.

 these should not happen */

 setup_ddl should have detected this */

 setup_ddl should have detected this */

 should not happen, we use physical addrs */

 should not happen, we use physical addrs */

 shouldn't happen, we're in HYP mode */

 shouldn't happen, setup_ddl doesn't use many dde's */

 P9 or later */

 shouldn't happen, we setup CRB correctly */

 P9 or later */

		/*

		 * shouldn't happen, setup_direct/indirect_dde creates

		 * DDE right

 shouldn't happen, setup_ddl creates DDL right */

 shouldn't happen, setup_ddl creates DDL right */

 should not happen with ICSWX */

 should not happen, we don't use chained CRBs */

 should not happen, we don't use chained CRBs */

 hardware errors */

 P9 or later */

 check Completion Extension state */

 successful completion */

 Clear any previous values */

 set up DDLs */

 set up CRB's CSB addr */

 Addrs are phys */

/**

 * nx842_exec_icswx - compress/decompress data using the 842 algorithm

 *

 * (De)compression provided by the NX842 coprocessor on IBM PowerNV systems.

 * This compresses or decompresses the provided input buffer into the provided

 * output buffer.

 *

 * Upon return from this function @outlen contains the length of the

 * output data.  If there is an error then @outlen will be 0 and an

 * error will be specified by the return code from this function.

 *

 * The @workmem buffer should only be used by one function call at a time.

 *

 * @in: input buffer pointer

 * @inlen: input buffer size

 * @out: output buffer pointer

 * @outlenp: output buffer size pointer

 * @workmem: working memory buffer pointer, size determined by

 *           nx842_powernv_driver.workmem_size

 * @fc: function code, see CCW Function Codes in nx-842.h

 *

 * Returns:

 *   0		Success, output of length @outlenp stored in the buffer at @out

 *   -ENODEV	Hardware unavailable

 *   -ENOSPC	Output buffer is to small

 *   -EMSGSIZE	Input buffer too large

 *   -EINVAL	buffer constraints do not fix nx842_constraints

 *   -EPROTO	hardware error during operation

 *   -ETIMEDOUT	hardware did not complete operation in reasonable time

 *   -EINTR	operation was aborted

 shoudn't happen, we don't load without a coproc */

 set up CCW */

 use 0 for hw auto-selection */

 do ICSWX */

	/*

	 * NX842 coprocessor sets 3rd bit in CR register with XER[S0].

	 * XER[S0] is the integer summary overflow bit which is nothing

	 * to do NX. Since this bit can be set with other return values,

	 * mask this bit.

/**

 * nx842_exec_vas - compress/decompress data using the 842 algorithm

 *

 * (De)compression provided by the NX842 coprocessor on IBM PowerNV systems.

 * This compresses or decompresses the provided input buffer into the provided

 * output buffer.

 *

 * Upon return from this function @outlen contains the length of the

 * output data.  If there is an error then @outlen will be 0 and an

 * error will be specified by the return code from this function.

 *

 * The @workmem buffer should only be used by one function call at a time.

 *

 * @in: input buffer pointer

 * @inlen: input buffer size

 * @out: output buffer pointer

 * @outlenp: output buffer size pointer

 * @workmem: working memory buffer pointer, size determined by

 *           nx842_powernv_driver.workmem_size

 * @fc: function code, see CCW Function Codes in nx-842.h

 *

 * Returns:

 *   0		Success, output of length @outlenp stored in the buffer

 *		at @out

 *   -ENODEV	Hardware unavailable

 *   -ENOSPC	Output buffer is to small

 *   -EMSGSIZE	Input buffer too large

 *   -EINVAL	buffer constraints do not fix nx842_constraints

 *   -EPROTO	hardware error during operation

 *   -ETIMEDOUT	hardware did not complete operation in reasonable time

 *   -EINTR	operation was aborted

		/*

		 * VAS copy CRB into L2 cache. Refer <asm/vas.h>.

		 * @crb and @offset.

		/*

		 * VAS paste previously copied CRB to NX.

		 * @txwin, @offset and @last (must be true).

		/*

		 * Retry copy/paste function for VAS failures.

/**

 * nx842_powernv_compress - Compress data using the 842 algorithm

 *

 * Compression provided by the NX842 coprocessor on IBM PowerNV systems.

 * The input buffer is compressed and the result is stored in the

 * provided output buffer.

 *

 * Upon return from this function @outlen contains the length of the

 * compressed data.  If there is an error then @outlen will be 0 and an

 * error will be specified by the return code from this function.

 *

 * @in: input buffer pointer

 * @inlen: input buffer size

 * @out: output buffer pointer

 * @outlenp: output buffer size pointer

 * @workmem: working memory buffer pointer, size determined by

 *           nx842_powernv_driver.workmem_size

 *

 * Returns: see @nx842_powernv_exec()

/**

 * nx842_powernv_decompress - Decompress data using the 842 algorithm

 *

 * Decompression provided by the NX842 coprocessor on IBM PowerNV systems.

 * The input buffer is decompressed and the result is stored in the

 * provided output buffer.

 *

 * Upon return from this function @outlen contains the length of the

 * decompressed data.  If there is an error then @outlen will be 0 and an

 * error will be specified by the return code from this function.

 *

 * @in: input buffer pointer

 * @inlen: input buffer size

 * @out: output buffer pointer

 * @outlenp: output buffer size pointer

 * @wmem: working memory buffer pointer, size determined by

 *        nx842_powernv_driver.workmem_size

 *

 * Returns: see @nx842_powernv_exec()

	/*

	 * Kernel requests will be high priority. So open send

	 * windows only for high priority RxFIFO entries.

 lpid is 0 for kernel requests */

	/*

	 * Open a VAS send window which is used to send request to NX.

/*

 * Identify chip ID for each CPU, open send wndow for the corresponding NX

 * engine and save txwin in percpu cpu_txwin.

 * cpu_txwin is used in copy/paste operation for each compression /

 * decompression request.

			/*

			 * Kernel requests use only high priority FIFOs. So

			 * open send windows for these FIFOs.

			 * GZIP is not supported in kernel right now.

 shouldn't happen, Each chip will have NX engine */

	/*

	 * Maximum RX window credits can not be more than #CRBs in

	 * RxFIFO. Otherwise, can get checkstop if RxFIFO overruns.

	/*

	 * Open a VAS receice window which is used to configure RxFIFO

	 * for NX.

	/*

	 * (lpid, pid, tid) combination has to be unique for each

	 * coprocessor instance in the system. So to make it

	 * unique, skiboot uses coprocessor type such as 842 or

	 * GZIP for pid and provides this value to kernel in pid

	 * device-tree property.

	/*

	 * Initialize NX instance for both high and normal priority FIFOs.

	/*

	 * close percpu txwins that are opened for the corresponding coproc.

 verify workmem size/align restrictions */

 verify buffer size/align restrictions */

		/*

		 * Register VAS user space API for NX GZIP so

		 * that user space can use GZIP engine.

		 * Using high FIFO priority for kernel requests and

		 * normal FIFO priority is assigned for userspace.

		 * 842 compression is supported only in kernel.

		/*

		 * GZIP is not supported in kernel right now.

		 * So open tx windows only for 842.

	/*

	 * GZIP engine is supported only in power9 or later and nx842_ct

	 * is used on power8 (icswx).

	 * VAS API for NX GZIP is registered during init for user space

	 * use. So delete this API use for GZIP engine.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * debugfs routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

/*

 * debugfs

 *

 * For documentation on these attributes, please see:

 *

 * Documentation/ABI/testing/debugfs-pfo-nx-crypto

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Driver for IBM Power 842 compression accelerator

 *

 * Copyright (C) IBM Corporation, 2012

 *

 * Authors: Robert Jennings <rcj@linux.vnet.ibm.com>

 *          Seth Jennings <sjenning@linux.vnet.ibm.com>

 struct nx_csbcpb */

/*

 * Coprocessor type specific capabilities from the hypervisor.

 Max bytes in one GZIP request */

 Min compression size in bytes */

 Min decompression size in bytes */

/*

 * Coprocessor type specific capabilities.

 Max bytes in one GZIP request */

 Min compression in bytes */

 Min decompression in bytes */

 dynamic, max_sync_size */

 I assume we need to align the CSB? */

 scatterlist */

 coprocessor status/parameter block */

 Macros for fields within nx_csbcpb */

 Check the valid bit within the csbcpb valid field */

/* CE macros operate on the completion_extension field bits in the csbcpb.

 * CE0 0=full completion, 1=partial completion

 * CE1 0=CE0 indicates completion, 1=termination (output may be modified)

 The NX unit accepts data only on 4K page boundaries */

 NX unit operation flags */

 No use of DMA mappings within the driver. */

 Real address (use __pa()) */

 pHyp scatterlist entry */

 number of slentries */

 ptr to array of slentries */

 Does not include sizeof(entry_nr) in the size */

 The csb must be valid after returning from vio_h_cop_sync */

 Check return values from the hardware in the CSB */

 Completed without error */

 Compression ok, but output larger than input */

 Output buffer too small */

 Calculated CRC doesn't match the passed value */

 Input data contains an illegal template field */

 Template indicates data past the end of the input stream */

 Hardware sanity check */

/**

 * nx842_pseries_compress - Compress data using the 842 algorithm

 *

 * Compression provide by the NX842 coprocessor on IBM Power systems.

 * The input buffer is compressed and the result is stored in the

 * provided output buffer.

 *

 * Upon return from this function @outlen contains the length of the

 * compressed data.  If there is an error then @outlen will be 0 and an

 * error will be specified by the return code from this function.

 *

 * @in: Pointer to input buffer

 * @inlen: Length of input buffer

 * @out: Pointer to output buffer

 * @outlen: Length of output buffer

 * @wmem: ptr to buffer for working memory, size determined by

 *        nx842_pseries_driver.workmem_size

 *

 * Returns:

 *   0		Success, output of length @outlen stored in the buffer at @out

 *   -ENOMEM	Unable to allocate internal buffers

 *   -ENOSPC	Output buffer is to small

 *   -EIO	Internal error

 *   -ENODEV	Hardware unavailable

 Init scatterlist */

 Init operation */

 Create direct DDE */

 Create indirect DDE (scatterlist) */

 Create direct DDE */

 Create indirect DDE (scatterlist) */

 Send request to pHyp */

 Check for pHyp error */

 Check for hardware error */

/**

 * nx842_pseries_decompress - Decompress data using the 842 algorithm

 *

 * Decompression provide by the NX842 coprocessor on IBM Power systems.

 * The input buffer is decompressed and the result is stored in the

 * provided output buffer.  The size allocated to the output buffer is

 * provided by the caller of this function in @outlen.  Upon return from

 * this function @outlen contains the length of the decompressed data.

 * If there is an error then @outlen will be 0 and an error will be

 * specified by the return code from this function.

 *

 * @in: Pointer to input buffer

 * @inlen: Length of input buffer

 * @out: Pointer to output buffer

 * @outlen: Length of output buffer

 * @wmem: ptr to buffer for working memory, size determined by

 *        nx842_pseries_driver.workmem_size

 *

 * Returns:

 *   0		Success, output of length @outlen stored in the buffer at @out

 *   -ENODEV	Hardware decompression device is unavailable

 *   -ENOMEM	Unable to allocate internal buffers

 *   -ENOSPC	Output buffer is to small

 *   -EINVAL	Bad input data encountered when attempting decompress

 *   -EIO	Internal error

 Ensure page alignment and size */

 Init scatterlist */

 Init operation */

 Create direct DDE */

 Create indirect DDE (scatterlist) */

 Create direct DDE */

 Create indirect DDE (scatterlist) */

 Send request to pHyp */

 Check for pHyp error */

 Check for hardware error */

 decompress fail */

/**

 * nx842_OF_set_defaults -- Set default (disabled) values for devdata

 *

 * @devdata: struct nx842_devdata to update

 *

 * Returns:

 *  0 on success

 *  -ENOENT if @devdata ptr is NULL

/**

 * nx842_OF_upd_status -- Check the device info from OF status prop

 *

 * The status property indicates if the accelerator is enabled.  If the

 * device is in the OF tree it indicates that the hardware is present.

 * The status field indicates if the device is enabled when the status

 * is 'okay'.  Otherwise the device driver will be disabled.

 *

 * @devdata: struct nx842_devdata to use for dev_info

 * @prop: struct property point containing the maxsyncop for the update

 *

 * Returns:

 *  0 - Device is available

 *  -ENODEV - Device is not available

/**

 * nx842_OF_upd_maxsglen -- Update the device info from OF maxsglen prop

 *

 * Definition of the 'ibm,max-sg-len' OF property:

 *  This field indicates the maximum byte length of a scatter list

 *  for the platform facility. It is a single cell encoded as with encode-int.

 *

 * Example:

 *  # od -x ibm,max-sg-len

 *  0000000 0000 0ff0

 *

 *  In this example, the maximum byte length of a scatter list is

 *  0x0ff0 (4,080).

 *

 * @devdata: struct nx842_devdata to update

 * @prop: struct property point containing the maxsyncop for the update

 *

 * Returns:

 *  0 on success

 *  -EINVAL on failure

/**

 * nx842_OF_upd_maxsyncop -- Update the device info from OF maxsyncop prop

 *

 * Definition of the 'ibm,max-sync-cop' OF property:

 *  Two series of cells.  The first series of cells represents the maximums

 *  that can be synchronously compressed. The second series of cells

 *  represents the maximums that can be synchronously decompressed.

 *  1. The first cell in each series contains the count of the number of

 *     data length, scatter list elements pairs that follow – each being

 *     of the form

 *    a. One cell data byte length

 *    b. One cell total number of scatter list elements

 *

 * Example:

 *  # od -x ibm,max-sync-cop

 *  0000000 0000 0001 0000 1000 0000 01fe 0000 0001

 *  0000020 0000 1000 0000 01fe

 *

 *  In this example, compression supports 0x1000 (4,096) data byte length

 *  and 0x1fe (510) total scatter list elements.  Decompression supports

 *  0x1000 (4,096) data byte length and 0x1f3 (510) total scatter list

 *  elements.

 *

 * @devdata: struct nx842_devdata to update

 * @prop: struct property point containing the maxsyncop for the update

 *

 * Returns:

 *  0 on success

 *  -EINVAL on failure

	/* Use one limit rather than separate limits for compression and

	 * decompression. Set a maximum for this so as not to exceed the

	 * size that the header can support and round the value down to

/**

 * nx842_OF_upd -- Handle OF properties updates for the device.

 *

 * Set all properties from the OF tree.  Optionally, a new property

 * can be provided by the @new_prop pointer to overwrite an existing value.

 * The device will remain disabled until all values are valid, this function

 * will return an error for updates unless all values are valid.

 *

 * @new_prop: If not NULL, this property is being updated.  If NULL, update

 *  all properties from the current values in the OF tree.

 *

 * Returns:

 *  0 - Success

 *  -ENOMEM - Could not allocate memory for new devdata structure

 *  -EINVAL - property value not found, new_prop is not a recognized

 *	property for the device or property value is not valid.

 *  -ENODEV - Device is not available

 Set ptrs for existing properties */

	/*

	 * If this is a property update, there are only certain properties that

	 * we care about. Bail if it isn't in the below list

 Perform property updates */

/**

 * nx842_OF_notifier - Process updates to OF properties for the device

 *

 * @np: notifier block

 * @action: notifier action

 * @data: struct of_reconfig_data pointer

 *

 * Returns:

 *	NOTIFY_OK on success

 *	NOTIFY_BAD encoded with error number on failure, use

 *		notifier_to_errno() to decode this value

	/* The last bucket holds everything over

 put in device directory */

/*

 * Get NX capabilities from the hypervisor.

 * Only NXGZIP capabilities are provided by the hypersvisor right

 * now and these values are available to user space with sysfs.

	/*

	 * Get NX overall capabilities with feature type=0

	/*

	 * NX-GZIP feature available

		/*

		 * Get capabilities for NX-GZIP feature

	/*

	 * Get NX capabilities from the hypervisor.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

/**

 * nx_hcall_sync - make an H_COP_OP hcall for the passed in op structure

 *

 * @nx_ctx: the crypto context handle

 * @op: PFO operation struct to pass in

 * @may_sleep: flag indicating the request can sleep

 *

 * Make the hcall, retrying while the hardware is busy. If we cannot yield

 * the thread, limit the number of retries to 10 here.

/**

 * nx_build_sg_list - build an NX scatter list describing a single  buffer

 *

 * @sg_head: pointer to the first scatter list element to build

 * @start_addr: pointer to the linear buffer

 * @len: length of the data at @start_addr

 * @sgmax: the largest number of scatter list elements we're allowed to create

 *

 * This function will start writing nx_sg elements at @sg_head and keep

 * writing them until all of the data from @start_addr is described or

 * until sgmax elements have been written. Scatter list elements will be

 * created such that none of the elements describes a buffer that crosses a 4K

 * boundary.

	/* determine the start and end for this address range - slightly

	/* each iteration will write one struct nx_sg element and add the

	 * length of data described by that element to sg_len. Once @len bytes

	 * have been described (or @sgmax elements have been written), the

	 * loop ends. min_t is used to ensure @end_addr falls on the same page

	 * as sg_addr, if not, we need to create another nx_sg element for the

	 * data on the next page.

	 *

	 * Also when using vmalloc'ed data, every time that a system page

	 * boundary is crossed the physical address needs to be re-calculated.

 return the moved sg_head pointer */

/**

 * nx_walk_and_build - walk a linux scatterlist and build an nx scatterlist

 *

 * @nx_dst: pointer to the first nx_sg element to write

 * @sglen: max number of nx_sg entries we're allowed to write

 * @sg_src: pointer to the source linux scatterlist to walk

 * @start: number of bytes to fast-forward past at the beginning of @sg_src

 * @src_len: number of bytes to walk in @sg_src

 we need to fast forward through @start bytes first */

	/* start - offset is the number of bytes to advance in the scatterlist

			/* In cases where we have scatterlist chain sg_next

 update to_process */

 return the moved destination pointer */

/**

 * trim_sg_list - ensures the bound in sg list.

 * @sg: sg list head

 * @end: sg lisg end

 * @delta:  is the amount we need to crop in order to bound the list.

 * @nbytes: length of data in the scatterlists or data length - whichever

 *          is greater.

	/* There are cases where we need to crop list in order to make it

	 * a block size multiple, but we also need to align data. In order to

	 * that we need to calculate how much we need to put back to be

	 * processed

/**

 * nx_build_sg_lists - walk the input scatterlists and build arrays of NX

 *                     scatterlists based on them.

 *

 * @nx_ctx: NX crypto context for the lists we're building

 * @iv: iv data, if the algorithm requires it

 * @dst: destination scatterlist

 * @src: source scatterlist

 * @nbytes: length of data described in the scatterlists

 * @offset: number of bytes to fast-forward past at the beginning of

 *          scatterlists.

 * @oiv: destination for the iv data, if the algorithm requires it

 *

 * This is common code shared by all the AES algorithms. It uses the crypto

 * scatterlist walk routines to traverse input and output scatterlists, building

 * corresponding NX scatterlists

	/* these lengths should be negative, which will indicate to phyp that

	 * the input and output parameters are scatterlists, not linear

/**

 * nx_ctx_init - initialize an nx_ctx's vio_pfo_op struct

 *

 * @nx_ctx: the nx context to initialize

 * @function: the function code for the op

	/* You can't tell if the data read in for this property is sane by its

	 * size alone. This is because there are sizes embedded in the data

	 * structure. The best we can do is check lengths as we parse and bail

/**

 * nx_of_init - read openFirmware values from the device tree

 *

 * @dev: device handle

 * @props: pointer to struct to hold the properties values

 *

 * Called once at driver probe time, this function will read out the

 * openFirmware properties we use at runtime. If all the OF properties are

 * acceptable, when we exit this function props->flags will indicate that

 * we're ready to register our crypto algorithms.

/**

 * nx_register_algs - register algorithms with the crypto API

 *

 * Called from nx_probe()

 *

 * If all OF properties are in an acceptable state, the driver flags will

 * indicate that we're ready and we'll create our debugfs files and register

 * out crypto algorithms.

/**

 * nx_crypto_ctx_init - create and initialize a crypto api context

 *

 * @nx_ctx: the crypto api context

 * @fc: function code for the context

 * @mode: the function code specific mode for this context

 we need an extra page for csbcpb_aead for these modes */

 the csbcpb and scatterlists must be 4K aligned pages */

	/* give each context a pointer to global stats and their OF

 entry points from the crypto tfm initializers */

/**

 * nx_crypto_ctx_exit - destroy a crypto api context

 *

 * @tfm: the crypto transform pointer for the context

 *

 * As crypto API contexts are destroyed, this exit hook is called to free the

 * memory associated with it.

 module wide initialization/cleanup */

 driver state structure */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES CBC routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SHA-256 routines supporting the Power 7+ Nest Accelerators driver

 *

 * Copyright (C) 2011-2012 International Business Machines Inc.

 *

 * Author: Kent Yoder <yoder1@us.ibm.com>

	/* 2 cases for total data len:

	 *  1: < SHA256_BLOCK_SIZE: copy into state, return 0

	 *  2: >= SHA256_BLOCK_SIZE: process X blocks, copy in leftover

		/* to_process: SHA256_BLOCK_SIZE aligned chunk to be

		 * processed in this iteration. This value is restricted

		 * by sg list limits and number of sgs we already used

		 * for leftover data. (see above)

		 * In ideal case, we could allow NX_PAGE_SIZE * max_sg_len,

		 * but because data may not be aligned, we need to account

		/*

		 * we've hit the nx chip previously and we're updating

		 * again, so copy over the partial digest.

 copy the leftover back into the state struct */

	/* final is represented by continuing the operation and indicating that

		/* we've hit the nx chip previously, now we're finalizing,

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2010-2014, The Linux Foundation. All rights reserved.

 check for buffer from previous updates and append it */

 save the original req structure fields */

	/*

	 * if we have data from previous update copy them on buffer. The old

	 * data will be combined with current request bytes.

 calculate how many bytes will be hashed later */

	/*

	 * At this point, there is more than one block size of data.  If

	 * the available data to transfer is exactly a multiple of block

	 * size, save the last block to be transferred in qce_ahash_final

	 * (with the last block bit set) if this is indeed the end of data

	 * stream. If not this saved block will be transferred as part of

	 * next update. If this block is not held back and if this is

	 * indeed the end of data stream, the digest obtained will be wrong

	 * since qce_ahash_final will see that rctx->buflen is 0 and return

	 * doing nothing which in turn means that a digest will not be

	 * copied to the destination result buffer.  qce_ahash_final cannot

	 * be made to alter this behavior and allowed to proceed if

	 * rctx->buflen is 0 because the crypto engine BAM does not allow

	 * for zero length transfers.

 here nbytes is multiple of blocksize */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012-2014, The Linux Foundation. All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2021, Linaro Limited. All rights reserved.

 Get the dst buffer */

 dst buffer */

 Get the msg */

	/*

	 * Format associated data (RFC3610 and NIST 800-38C)

	 * Even though specification allows for AAD to be up to 2^64 - 1 bytes,

	 * the assoclen field in aead_request is unsigned int and thus limits

	 * the AAD to be up to 2^32 - 1 bytes. So we handle only two scenarios

	 * while forming the header for AAD.

 Copy the associated data */

 Pad associated data to block size */

 Associated Data */

 src msg */

		/*

		 * For decrypt, when src and dst buffers are same, there is already space

		 * in the buffer for padded 0's which is output in lieu of

		 * the MAC that is input. So skip the below.

 Verify that msg len size is valid */

	/*

	 * Clear the msglen bytes in IV.

	 * Else the h/w engine and nonce will use any stray value pending there.

	/*

	 * The crypto framework encodes cryptlen as unsigned int. Thus, even though

	 * spec allows for upto 8 bytes to encode msg_len only 4 bytes are needed.

 CE does not handle 0 length messages */

 If fallback is needed, schedule and exit */

 Reset need_fallback in case the same ctx is used for another transaction */

	/*

	 * CBC algorithms require message lengths to be

	 * multiples of block size.

 RFC4309 supported AAD size 16 bytes/20 bytes */

		/*

		 * The crypto engine does not support any two keys

		 * being the same for triple des algorithms. The

		 * verify_skcipher_des3_key does not check for all the

		 * below conditions. Schedule fallback in this case.

 No random key sizes */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2010-2014, The Linux Foundation. All rights reserved.

 busy, do not dequeue request */

	/*

	 * the driver does not support v5 with minor 0 because it has special

	 * alignment requirements.

	/*

	 * Rx and tx pipes are treated as a pair inside CE.

	 * Pipe pair number depends on the actual BAM dma pipe

	 * that is used for transfers. The BAM dma pipes are passed

	 * from the device tree and used to derive the pipe pair

	 * id in the CE driver as follows.

	 * 	BAM dma pipes(rx, tx)		CE pipe pair id

	 *		0,1				0

	 *		2,3				1

	 *		4,5				2

	 *		6,7				3

	 *		...

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012-2014, The Linux Foundation. All rights reserved.

 get big endianness */

 clear status */

 if not the last, the size has to be on the block boundary */

 get little endianness */

	/* Set data unit size to cryptlen. Anything else causes

	 * crypto engine to return back incorrect results.

 get little endianness */

 Write encryption key */

 Write encryption iv */

 Clear authentication IV and KEY registers of previous values */

 Clear byte count */

 Write authentication key */

 Write initial authentication IV only for HMAC algorithms */

 Write default authentication iv */

 Write nonce for CCM algorithms */

 Set up ENCR_SEG_CFG */

 Set up AUTH_SEG_CFG */

 Set the encryption size and start offset */

 Set the authentication size and start offset */

 Write total length */

 get little endianness */

 Start the process */

	/*

	 * Don't use result dump status. The operation may not be complete.

	 * Instead, use the status we just read from device. In case, we need to

	 * use result_status from result dump the result_status needs to be byte

	 * swapped, since we set the device to little endian.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2010-2014, The Linux Foundation. All rights reserved.

	/*

	 * AES XTS key1 = key2 not supported by crypto engine.

	 * Revisit to request a fallback cipher in this case.

	/*

	 * The crypto engine does not support any two keys

	 * being the same for triple des algorithms. The

	 * verify_skcipher_des3_key does not check for all the

	 * below conditions. Return -ENOKEY in case any two keys

	 * are the same. Revisit to see if a fallback cipher

	 * is needed to handle this condition.

 CE does not handle 0 length messages */

	/*

	 * ECB and CBC algorithms require message lengths to be

	 * multiples of block size.

	/*

	 * Conditions for requesting a fallback cipher

	 * AES-192 (not supported by crypto engine (CE))

	 * AES-XTS request with len <= 512 byte (not recommended to use CE)

	 * AES-XTS request with len > QCE_SECTOR_SIZE and

	 * is not a multiple of it.(Revisit this condition to check if it is

	 * needed in all versions of CE)

 take the size without the fallback skcipher_request at the end */

 SPDX-License-Identifier: GPL-2.0

/*

 * sl3516-ce-rng.c - hardware cryptographic offloader for SL3516 SoC.

 *

 * Copyright (C) 2021 Corentin Labbe <clabbe@baylibre.com>

 *

 * This file handle the RNG found in the SL3516 crypto engine

 SPDX-License-Identifier: GPL-2.0

/*

 * sl3516-ce-cipher.c - hardware cryptographic offloader for Storlink SL3516 SoC

 *

 * Copyright (C) 2021 Corentin LABBE <clabbe@baylibre.com>

 *

 * This file adds support for AES cipher with 128,192,256 bits keysize in

 * ECB mode.

 sl3516_ce_need_fallback - check if a request can be handled by the CE */

	/*

	 * check if we have enough descriptors for TX

	 * Note: TX need one control desc for each SG

 check if we have enough descriptors for RX */

 need same numbers of SG (with same length) for source and destination */

 SPDX-License-Identifier: GPL-2.0

/*

 * sl3516-ce-core.c - hardware cryptographic offloader for Storlink SL3516 SoC

 *

 * Copyright (C) 2021 Corentin Labbe <clabbe@baylibre.com>

 *

 * Core file which registers crypto algorithms supported by the CryptoEngine

/*

 * Power management strategy: The device is suspended unless a TFM exists for

 * one of the algorithms proposed by this driver.

 Ignore error of debugfs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES CBC routines supporting VMX instructions on the Power 8

 *

 * Copyright (C) 2015 International Business Machines Inc.

 *

 * Author: Marcelo Henrique Cerri <mhcerri@br.ibm.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * GHASH routines supporting VMX instructions on the Power 8

 *

 * Copyright (C) 2015, 2019 International Business Machines Inc.

 *

 * Author: Marcelo Henrique Cerri <mhcerri@br.ibm.com>

 *

 * Extended by Daniel Axtens <dja@axtens.net> to replace the fallback

 * mechanism. The new approach is based on arm64 code, which is:

 *   Copyright (C) 2014 - 2018 Linaro Ltd. <ard.biesheuvel@linaro.org>

 key used by vector asm */

 key used by software fallback */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES routines supporting VMX instructions on the Power 8

 *

 * Copyright (C) 2015 International Business Machines Inc.

 *

 * Author: Marcelo Henrique Cerri <mhcerri@br.ibm.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Routines supporting VMX instructions on the Power 8

 *

 * Copyright (C) 2015 International Business Machines Inc.

 *

 * Author: Marcelo Henrique Cerri <mhcerri@br.ibm.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES CTR routines supporting VMX instructions on the Power 8

 *

 * Copyright (C) 2015 International Business Machines Inc.

 *

 * Author: Marcelo Henrique Cerri <mhcerri@br.ibm.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AES XTS routines supporting VMX In-core instructions on Power 8

 *

 * Copyright (C) 2015 International Business Machines Inc.

 *

 * Author: Leonidas S. Barbosa <leosilva@linux.vnet.ibm.com>

 SPDX-License-Identifier: GPL-2.0-or-later

 /* Management for virtio crypto devices (refer to adf_dev_mgr.c)

  *

  * Copyright 2016 HUAWEI TECHNOLOGIES CO., LTD.

 The table_lock protects the above global list and num_devices */

/*

 * virtcrypto_devmgr_add_dev() - Add vcrypto_dev to the acceleration

 * framework.

 * @vcrypto_dev:  Pointer to virtio crypto device.

 *

 * Function adds virtio crypto device to the global list.

 * To be used by virtio crypto device specific drivers.

 *

 * Return: 0 on success, error code othewise.

/*

 * virtcrypto_devmgr_rm_dev() - Remove vcrypto_dev from the acceleration

 * framework.

 * @vcrypto_dev:  Pointer to virtio crypto device.

 *

 * Function removes virtio crypto device from the acceleration framework.

 * To be used by virtio crypto device specific drivers.

 *

 * Return: void

/*

 * virtcrypto_devmgr_get_first()

 *

 * Function returns the first virtio crypto device from the acceleration

 * framework.

 *

 * To be used by virtio crypto device specific drivers.

 *

 * Return: pointer to vcrypto_dev or NULL if not found.

/*

 * virtcrypto_dev_in_use() - Check whether vcrypto_dev is currently in use

 * @vcrypto_dev: Pointer to virtio crypto device.

 *

 * To be used by virtio crypto device specific drivers.

 *

 * Return: 1 when device is in use, 0 otherwise.

/*

 * virtcrypto_dev_get() - Increment vcrypto_dev reference count

 * @vcrypto_dev: Pointer to virtio crypto device.

 *

 * Increment the vcrypto_dev refcount and if this is the first time

 * incrementing it during this period the vcrypto_dev is in use,

 * increment the module refcount too.

 * To be used by virtio crypto device specific drivers.

 *

 * Return: 0 when successful, EFAULT when fail to bump module refcount

/*

 * virtcrypto_dev_put() - Decrement vcrypto_dev reference count

 * @vcrypto_dev: Pointer to virtio crypto device.

 *

 * Decrement the vcrypto_dev refcount and if this is the last time

 * decrementing it during this period the vcrypto_dev is in use,

 * decrement the module refcount too.

 * To be used by virtio crypto device specific drivers.

 *

 * Return: void

/*

 * virtcrypto_dev_started() - Check whether device has started

 * @vcrypto_dev: Pointer to virtio crypto device.

 *

 * To be used by virtio crypto device specific drivers.

 *

 * Return: 1 when the device has started, 0 otherwise

/*

 * virtcrypto_get_dev_node() - Get vcrypto_dev on the node.

 * @node:  Node id the driver works.

 * @service: Crypto service that needs to be supported by the

 *	      dev

 * @algo: The algorithm number that needs to be supported by the

 *	  dev

 *

 * Function returns the virtio crypto device used fewest on the node,

 * and supports the given crypto service and algorithm.

 *

 * To be used by virtio crypto device specific drivers.

 *

 * Return: pointer to vcrypto_dev or NULL if not found.

 Get any started device */

/*

 * virtcrypto_dev_start() - Start virtio crypto device

 * @vcrypto:    Pointer to virtio crypto device.

 *

 * Function notifies all the registered services that the virtio crypto device

 * is ready to be used.

 * To be used by virtio crypto device specific drivers.

 *

 * Return: 0 on success, EFAULT when fail to register algorithms

/*

 * virtcrypto_dev_stop() - Stop virtio crypto device

 * @vcrypto:    Pointer to virtio crypto device.

 *

 * Function notifies all the registered services that the virtio crypto device

 * is ready to be used.

 * To be used by virtio crypto device specific drivers.

 *

 * Return: void

/*

 * vcrypto_algo_is_supported()

 * @vcrypto: Pointer to virtio crypto device.

 * @service: The bit number for service validate.

 *	      See VIRTIO_CRYPTO_SERVICE_*

 * @algo : The bit number for the algorithm to validate.

 *

 *

 * Validate if the virtio crypto device supports a service and

 * algo.

 *

 * Return true if device supports a service and algo.

 SPDX-License-Identifier: GPL-2.0-or-later

 /* Algorithms supported by virtio crypto device

  *

  * Authors: Gonglei <arei.gonglei@huawei.com>

  *

  * Copyright 2016 HUAWEI TECHNOLOGIES CO., LTD.

 Cipher or aead */

 Encryption? */

/*

 * The algs_lock protects the below global virtio_crypto_active_devs

 * and crypto algorithms registion.

 Finish the encrypt or decrypt process */

	/*

	 * Avoid to do DMA from the stack, switch to using

	 * dynamically-allocated for the key

 Pad ctrl header */

 Set the default dataqueue id to 0 */

 Pad cipher's parameters */

 Set key */

 Return status and session id back */

	/*

	 * Trapping into the hypervisor, so the request should be

	 * handled immediately.

 Pad ctrl header */

 Set the default virtqueue id to 0 */

 Return status and session id back */

 Create encryption session */

 Create decryption session */

 Note: kernel crypto API realization */

 New key */

 Rekeying, we should close the created sessions previously */

 Why 3?  outhdr + iv + inhdr */

 Head of operation */

 Outhdr */

 IV */

	/*

	 * Avoid to do DMA from the stack, switch to using

	 * dynamically-allocated for the IV

 Source data */

 Destination data */

 Status */

 Use the first data virtqueue as default */

 Use the first data virtqueue as default */

 SPDX-License-Identifier: GPL-2.0-or-later

 /* Driver for Virtio crypto device.

  *

  * Copyright 2016 HUAWEI TECHNOLOGIES CO., LTD.

	/*

	 * We expect 1 data virtqueue, followed by

	 * possible N-1 data queues used in multiqueue mode,

	 * followed by control vq.

 Allocate space for find_vqs parameters */

 Parameters for control virtqueue */

 Allocate/initialize parameters for data virtqueues */

 Initialize crypto engine */

	/*

	 * In single queue mode, we don't set the cpu affinity.

	/*

	 * In multiqueue mode, we let the queue to be private to one cpu

	 * by setting the affinity hint to eliminate the contention.

	 *

	 * TODO: adds cpu hotplug support by register cpu notifier.

	 *

 Allocate send & receive queues */

	/*

	 * Unknown status bits would be a host error and the driver

	 * should consider the device to be broken.

		/*

		 * If the accelerator is connected to a node with no memory

		 * there is no point in using the accelerator since the remote

		 * memory transaction will be very slow.

 Add virtio crypto device to global table */

 Use single data queue as default */

 none */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) driver

 *

 * Copyright (C) 2016,2019 Advanced Micro Devices, Inc.

 *

 * Author: Gary R Hook <gary.hook@amd.com>

/* Allocate the requested number of contiguous LSB slots

 * from the LSB bitmap. Look in the private range for this

 * queue first; failing that, check the public area.

 * If no space is available, wait around.

 * Return: first slot number

 First look at the map for the queue */

 No joy; try to get an entry from the shared blocks */

 Wait for KSB entries to become available */

/* Free a number of LSB slots from the bitmap, starting at

 * the indicated starting slot number.

 An entry from the private LSB */

 From the shared LSBs */

 CCP version 5: Union to define the function field (cmd_reg1/dword0) */

 Word 0 */

 Word 1 */

 Word 2 */

 Word 3 */

 Words 4/5 */

 Word 6/7 */

 Always one unused spot */

 handle endianness */

 The data used by this command must be flushed to memory */

 Write the new tail address back to the queue register */

 Turn the queue back on using our cached control register */

 Wait for the job to complete */

			/* Log the error and flush the queue by

			 * moving the head pointer

 Zero out all the fields of the command desc */

 Zero out all the fields of the command desc */

 Zero out all the fields of the command desc */

 Zero out all the fields of the command desc */

 Zero out all the fields of the command desc */

 Source is from external memory */

 Destination is in external memory */

 Key (Exponent) is in external memory */

 Length of source data is always 256 bytes */

 Zero out all the fields of the command desc */

	/* Build a bit mask to know which LSBs this queue has access to.

	 * Don't bother with segment 0 as it has special privileges.

	/* For each queue:

	 * If the count of potential LSBs available to a queue matches the

	 * ordinal given to us in lsb_cnt:

	 * Copy the mask of possible LSBs for this queue into "qlsb";

	 * For each bit in qlsb, see if the corresponding bit in the

	 * aggregation mask is set; if so, we have a match.

	 *     If we have a match, clear the bit in the aggregation to

	 *     mark it as no longer available.

	 *     If there is no match, clear the bit in qlsb and keep looking.

					/* We found an available LSB

					 * that this queue can access

/* For each queue, from the most- to least-constrained:

 * find an LSB that can be assigned to the queue. If there are N queues that

 * can only use M LSBs, where N > M, fail; otherwise, every queue will get a

 * dedicated LSB. Remaining LSB regions become a shared resource.

 * If we have fewer LSBs than queues, all LSB regions become shared resources.

 Create an aggregate bitmap to get a total count of available LSBs */

		/* We have enough LSBS to give every queue a private LSB.

		 * Brute force search to start with the queues that are more

		 * constrained in LSB choice. When an LSB is privately

		 * assigned, it is removed from the public mask.

		 * This is an ugly N squared algorithm with some optimization.

	/* What's left of the LSBs, according to the public mask, now become

	 * shared. Any zero bits in the lsb_pub mask represent an LSB region

	 * that can't be used as a shared resource, so mark the LSB slots for

	 * them as "in use".

 On error, only save the first error value */

 Acknowledge the interrupt and wake the kthread */

 Find available queues */

	/*

	 * Check for a access to the registers.  If this read returns

	 * 0xffffffff, it's likely that the system is running a broken

	 * BIOS which disallows access to the device. Stop here and fail

	 * the initialization (but not the load, as the PSP could get

	 * properly initialized).

 Allocate a dma pool for this queue */

 Page alignment satisfies our needs for N <= 128 */

		/* Preset some register values and masks that are queue

		 * number dependent

 Turn off the queues and disable interrupts until ready */

 Start with nothing */

 Clear the interrupt status */

 Request an irq */

 Initialize the ISR tasklet */

 Copy the private LSB mask to the public registers */

 Configure size of each virtual queue accessible to host */

 Find the LSB regions accessible to the queue */

 Unassigned value */

 Optimization: pre-allocate LSB slots for each queue */

 Create a kthread for each queue */

 Put this on the unit list to make it available */

 Register the DMA engine support */

 Set up debugfs entries */

 Unregister the DMA engine */

 Unregister the RNG */

 Remove this device from the list of available units first */

	/* We're in the process of tearing down the entire driver;

	 * when all the devices are gone clean up debugfs

 Disable and clear interrupts */

 Turn off the run bit */

 Clear the interrupt status */

 Stop the queue kthreads */

 Flush the cmd and backlog queue */

 Invoke the callback directly with an error code */

 Invoke the callback directly with an error code */

 Public side */

 We own all of the queues on the NTB CCP */

 Version 5 adds some function, but is essentially the same as v5 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) SHA crypto API support

 *

 * Copyright (C) 2013,2018 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 * Author: Gary R Hook <gary.hook@amd.com>

 Save remaining data to buffer */

 Update result area if supplied */

 CCP can't do zero length final, so keep some data around */

 Initialize the context scatterlist */

		/* Build the data scatterlist table - allocate enough entries

		 * for both data pieces (buffer and input data)

 Total in bits */

 Should never get here */

 Buffer the HMAC key for first update */

 Don't let anything leak to 'out' */

 'out' may not be aligned so memcpy from local variable */

 'in' may not be aligned so memcpy to local variable */

 Set to zero until complete */

	/* Clear key area to provide zero padding for keys smaller

	 * than the block size

 Must hash the input key */

 Copy the base algorithm and only change what's necessary */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Secure Processor driver

 *

 * Copyright (C) 2017-2018 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 * Author: Gary R Hook <gary.hook@amd.com>

 * Author: Brijesh Singh <brijesh.singh@amd.com>

/* List of SPs, SP count, read-write access lock, and access functions

 *

 * Lock structure: get sp_unit_lock for reading whenever we need to

 * examine the SP list.

 Ever-increasing value to produce unique unit numbers */

 Need a common routine to manage all interrupts */

 Each sub-device can manage it's own interrupt */

 Need a common routine to manage all interrupts */

 Each sub-device can manage it's own interrupt */

 Using common routine to manage all interrupts */

 Nothing else using it, so free it */

 Each sub-device can manage it's own interrupt */

 Using common routine to manage all interrupts */

 Nothing else using it, so free it */

 Each sub-device can manage it's own interrupt */

/**

 * sp_alloc_struct - allocate and initialize the sp_device struct

 *

 * @dev: device struct of the SP

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) driver

 *

 * Copyright (C) 2013,2019 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 * Author: Gary R Hook <gary.hook@amd.com>

 Limit CCP use to a specifed number of queues per device */

 Limit the maximum number of configured CCPs */

 Human-readable error strings */

/* List of CCPs, CCP count, read-write access lock, and access functions

 *

 * Lock structure: get ccp_unit_lock for reading whenever we need to

 * examine the CCP list. While holding it for reading we can acquire

 * the RR lock to update the round-robin next-CCP pointer. The unit lock

 * must be acquired before the RR lock.

 *

 * If the unit-lock is acquired for writing, we have total control over

 * the list, so there's no value in getting the RR lock.

 Round-robin counter */

/**

 * ccp_add_device - add a CCP device to the list

 *

 * @ccp: ccp_device struct pointer

 *

 * Put this CCP on the unit list, which makes it available

 * for use.

 *

 * Returns zero if a CCP device is present, -ENODEV otherwise.

		/* We already have the list lock (we're first) so this

		 * pointer can't change on us. Set its initial value.

/**

 * ccp_del_device - remove a CCP device from the list

 *

 * @ccp: ccp_device struct pointer

 *

 * Remove this unit from the list of devices. If the next device

 * up for use is this one, adjust the pointer. If this is the last

 * device, NULL the pointer.

		/* ccp_unit_lock is read/write; any read access

		 * will be suspended while we make changes to the

		 * list and RR pointer.

 Register an RNG */

	/* We round-robin through the unit list.

	 * The (ccp_rr) pointer refers to the next unit to use.

/**

 * ccp_present - check if a CCP device is present

 *

 * Returns zero if a CCP device is present, -ENODEV otherwise.

/**

 * ccp_version - get the version of the CCP device

 *

 * Returns the version from the first unit on the list;

 * otherwise a zero if no CCP device is present

/**

 * ccp_enqueue_cmd - queue an operation for processing by the CCP

 *

 * @cmd: ccp_cmd struct to be processed

 *

 * Queue a cmd to be processed by the CCP. If queueing the cmd

 * would exceed the defined length of the cmd queue the cmd will

 * only be queued if the CCP_CMD_MAY_BACKLOG flag is set and will

 * result in a return code of -EBUSY.

 *

 * The callback routine specified in the ccp_cmd struct will be

 * called to notify the caller of completion (if the cmd was not

 * backlogged) or advancement out of the backlog. If the cmd has

 * advanced out of the backlog the "err" value of the callback

 * will be -EINPROGRESS. Any other "err" value during callback is

 * the result of the operation.

 *

 * The cmd has been successfully queued if:

 *   the return code is -EINPROGRESS or

 *   the return code is -EBUSY and CCP_CMD_MAY_BACKLOG flag is set

 Some commands might need to be sent to a specific device */

 Caller must supply a callback routine */

 Find an idle queue */

 If we found an idle queue, wake it up */

 Find an idle queue */

 If we found an idle queue, wake it up */

/**

 * ccp_cmd_queue_thread - create a kernel thread to manage a CCP queue

 *

 * @data: thread-specific data

 Execute the command */

 Schedule the completion callback */

/**

 * ccp_alloc_struct - allocate and initialize the ccp_device struct

 *

 * @sp: sp_device struct of the CCP

 Initialize the wait queues */

	/* Locking is provided by the caller so we can update device

	 * hwrng-related fields safely

		/* Zero is returned if not data is available or if a

		 * bad-entropy error is present. Assume an error if

		 * we exceed TRNG_RETRIES reads of zero.

 Reset the counter and save the rng value */

 If there's no device there's nothing to do */

 Wake all the queue kthreads to prepare for suspend */

 Wait for all queue kthreads to say they're done */

 If there's no device there's nothing to do */

 Wake up all the kthreads */

	/*

	 * Check how many we have so far, and stop after reaching

	 * that number

 don't fail the load */

		/* A positive number means that the device cannot be initialized,

		 * but no additional message is required.

 An unexpected problem occurred, and should be reported in the log */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) AES crypto API support

 *

 * Copyright (C) 2013-2019 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 Restore the original pointer */

 Initialize the CTR block */

 Point to the new IV */

 Copy the defaults and override as necessary */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Platform Security Processor (PSP) interface

 *

 * Copyright (C) 2016,2019 Advanced Micro Devices, Inc.

 *

 * Author: Brijesh Singh <brijesh.singh@amd.com>

 Read the interrupt status: */

 invoke subdevice interrupt handlers */

 Clear the interrupt status by writing the same value we read. */

	/*

	 * Check for a access to the registers.  If this read returns

	 * 0xffffffff, it's likely that the system is running a broken

	 * BIOS which disallows access to the device. Stop here and

	 * fail the PSP initialization (but not the load, as the CCP

	 * could get properly initialized).

 Check if device supports SEV feature */

 Check if device supports TEE feature */

 Return error if device neither supports SEV nor TEE */

 Disable and clear interrupts until ready */

 Request an irq */

 Enable interrupt */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Secure Processor device driver

 *

 * Copyright (C) 2014,2018 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) crypto API support

 *

 * Copyright (C) 2013,2017 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 List heads for the supported algorithms */

/* For any tfm, requests for that tfm must be returned on the order

 * received.  With multiple queues available, the CCP can process more

 * than one cmd at a time.  Therefore we must maintain a cmd list to insure

 * the proper ordering of requests on a given tfm.

	/* Save the crypto_tfm and crypto_async_request addresses

	 * separately to avoid any reference to a possibly invalid

	 * crypto_async_request structure after invoking the request

	 * callback

 Used for held command processing to determine state */

	/* Held cmds will be after the current cmd in the queue so start

	 * searching for a cmd with a matching tfm for submission.

	/* Process the backlog:

	 *   Because cmds can be executed from any point in the cmd list

	 *   special precautions have to be taken when handling the backlog.

 Skip over this cmd if it is the next backlog cmd */

 Skip over this cmd if it is now the next backlog cmd */

 Remove the cmd entry from the list of cmds */

 Only propagate the -EINPROGRESS if necessary */

	/* Operation has completed - update the queue before invoking

	 * the completion callbacks and retrieve the next cmd (cmd with

	 * a matching tfm) that can be submitted to the CCP.

 Transition the state from -EBUSY to -EINPROGRESS first */

 Completion callbacks */

 Submit the next cmd */

		/* Since we have already queued the cmd, we must indicate that

		 * we can backlog so as not to "lose" this request.

 Error occurred, report it and get the next entry */

 Check if the cmd can/should be queued */

	/* Look for an entry with the same tfm.  If there is a cmd

	 * with the same tfm in the list then the current cmd cannot

	 * be submitted to the CCP yet.

 Error, don't queue it */

/**

 * ccp_crypto_enqueue_request - queue an crypto async request for processing

 *				by the CCP

 *

 * @req: crypto_async_request struct to be processed

 * @cmd: ccp_cmd struct to be sent to the CCP

	/* The tfm pointer must be saved and not referenced from the

	 * crypto_async_request (req) pointer because it is used after

	 * completion callback for the request and the req pointer

	 * might not be valid anymore.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Secure Encrypted Virtualization (SEV) interface

 *

 * Copyright (C) 2016,2019 Advanced Micro Devices, Inc.

 *

 * Author: Brijesh Singh <brijesh.singh@amd.com>

 1st gen EPYC */

 2nd gen EPYC */

 3rd gen EPYC */

/* Trusted Memory Region (TMR):

 *   The TMR is a 1MB area that must be 1MB aligned.  Use the page allocator

 *   to allocate the memory, which will return aligned memory for the specified

 *   allocation order.

 Check if it is command completion: */

 Check if it is SEV command completion: */

	/*

	 * Copy the incoming data to driver's scratch buffer as __pa() will not

	 * work for some memory, e.g. vmalloc'd addresses, and @data may not be

	 * physically contiguous.

 Get the physical address of the command buffer */

 wait for command completion */

	/*

	 * Copy potential output from the PSP back to data.  Do this even on

	 * failure in case the caller wants to glean something from the error.

		/*

		 * Do not include the encryption mask on the physical

		 * address of the TMR (firmware should clear it anyway).

 Prepare for first SEV guest launch after INIT */

	/*

	 * The SEV spec requires that FACTORY_RESET must be issued in

	 * UNINIT state. Before we go further lets check if any guest is

	 * active.

	 *

	 * If FW is in WORKING state then deny the request otherwise issue

	 * SHUTDOWN command do INIT -> UNINIT before issuing the FACTORY_RESET.

	 *

 userspace wants to query CSR length */

 allocate a physically contiguous buffer to store the CSR blob */

 If we query the CSR length, FW responded with expected data. */

 verify that blob length does not exceed our limit */

	/* Check for SEV FW for a particular model.

	 * Ex. amd_sev_fam17h_model00h.sbin for Family 17h Model 00h

	 *

	 * or

	 *

	 * Check for SEV FW common to a subset of models.

	 * Ex. amd_sev_fam17h_model0xh.sbin for

	 *     Family 17h Model 00h -- Family 17h Model 0Fh

	 *

	 * or

	 *

	 * Fall-back to using generic name: sev.fw

 Don't fail if SEV FW couldn't be updated. Continue with existing SEV FW */

	/*

	 * SEV FW expects the physical address given to it to be 32

	 * byte aligned. Memory allocated has structure placed at the

	 * beginning followed by the firmware being passed to the SEV

	 * FW. Allocate enough memory for data structure + alignment

	 * padding + SEV FW.

	/*

	 * Copy firmware data to a kernel allocated contiguous

	 * memory region.

 copy PEK certificate blobs from userspace */

 copy PEK certificate blobs from userspace */

 If platform is not in INIT state then transition it to INIT */

 SEV GET_ID is available from SEV API v0.16 and up */

	/*

	 * Firmware will return the length of the ID value (either the minimum

	 * required length or the actual length written), return it to the user.

 SEV GET_ID available from SEV API v0.16 and up */

	/* SEV FW expects the buffer it fills with the ID to be

	 * 8-byte aligned. Memory allocated should be enough to

	 * hold data structure + alignment padding + memory

	 * where SEV FW writes the ID.

 If platform is not in INIT state then transition it to INIT. */

 Userspace wants to query the certificate length. */

 Allocate a physically contiguous buffer to store the PDH blob. */

 Allocate a physically contiguous buffer to store the cert chain blob. */

 If we query the length, FW responded with expected data. */

	/*

	 * SEV feature support can be detected on multiple devices but the SEV

	 * FW commands must be issued on the master. During probe, we do not

	 * know the master hence we create /dev/sev on the first device probe.

	 * sev_do_cmd() finds the right master device to which to issue the

	 * command to the firmware.

 The TMR area was encrypted, flush it from the cache */

 Obtain the TMR memory area for SEV-ES use */

 Initialize the platform */

		/*

		 * INIT command returned an integrity check failure

		 * status code, meaning that firmware load and

		 * validation of SEV related persistent data has

		 * failed and persistent state has been erased.

		 * Retrying INIT command here should succeed.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) driver

 *

 * Copyright (C) 2017 Advanced Micro Devices, Inc.

 *

 * Author: Gary R Hook <gary.hook@amd.com>

 DebugFS helpers */

/* Return a formatted buffer containing the current

 * statistics across all queues for a CCP.

/* Reset the counters in a queue

/* A value was written to the stats variable, which

 * should be used to reset the queue counters across

 * that device.

/* Return a formatted buffer containing the current information

 * for that queue

/* A value was written to the stats variable for a

 * queue. Reset the queue counters to this value.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Secure Processor device driver

 *

 * Copyright (C) 2013,2019 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 * Author: Gary R Hook <gary.hook@amd.com>

 Couldn't get MSI-X vectors, try MSI */

 Couldn't get MSI interrupt */

 0 */

 1 */

 2 */

 3 */

 4 */

 5 */

 Last entry must be zero */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) AES CMAC crypto API support

 *

 * Copyright (C) 2013,2018 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 Save remaining data to buffer */

 Update result area if supplied */

 CCP can't do zero length final, so keep some data around */

	/* Build the data scatterlist table - allocate enough entries for all

	 * possible data pieces (buffer, input data, padding)

 Initialize the K1/K2 scatterlist */

 Don't let anything leak to 'out' */

 'out' may not be aligned so memcpy from local variable */

 'in' may not be aligned so memcpy to local variable */

 Set to zero until complete */

 Set the key for the AES cipher used to generate the keys */

 Encrypt a block of zeroes - use key area in context */

 Generate K1 and K2 */

 Save the supplied key */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) driver

 *

 * Copyright (C) 2013,2017 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 * Author: Gary R Hook <gary.hook@amd.com>

 Wait for KSB entries to become available */

	/* We could read a status register to see how many free slots

	 * are actually available, but reading that register resets it

	 * and you could lose some error information.

 Start at CMD_REQ1 */

 Write CMD_REQ1 through CMD_REQx first */

 Tell the CCP to start */

 Wait for the job to complete */

 On error delete all related jobs from the queue */

 Delete just head job from the queue on SoC */

 Fill out the register contents for REQ1 through REQ6 */

 Fill out the register contents for REQ1 through REQ6 */

 Fill out the register contents for REQ1 through REQ6 */

 Fill out the register contents for REQ1 through REQ6 */

 Fill out the register contents for REQ1 through REQ6 */

 Fill out the register contents for REQ1 through REQ6 */

 On error, only save the first error value */

 Acknowledge the interrupt and wake the kthread */

 Find available queues */

 Allocate a dma pool for this queue */

 Reserve 2 KSB regions for the queue */

		/* Preset some register values and masks that are queue

		 * number dependent

 Build queue interrupt mask (two interrupts per queue) */

 For arm64 set the recommended queue cache settings */

 Disable and clear interrupts until ready */

 Request an irq */

 Initialize the ISR tasklet? */

 Create a kthread for each queue */

 Enable interrupts */

 Register the DMA engine support */

 Unregister the DMA engine */

 Unregister the RNG */

 Remove this device from the list of available units */

 Disable and clear interrupts */

 Stop the queue kthreads */

 Flush the cmd and backlog queue */

 Invoke the callback directly with an error code */

 Invoke the callback directly with an error code */

 SPDX-License-Identifier: MIT

/*

 * AMD Trusted Execution Environment (TEE) interface

 *

 * Author: Rijo Thomas <Rijo-john.Thomas@amd.com>

 * Author: Devaraj Rangasamy <Devaraj.Rangasamy@amd.com>

 *

 * Copyright (C) 2019,2021 Advanced Micro Devices, Inc.

	/* We need actual physical address instead of DMA address, since

	 * Trusted OS running on AMD Secure Processor will map this region

 ~10ms sleep per loop => nloop = timeout * 100 */

	/* Send command buffer details to Trusted OS by writing to

	 * CPU-PSP message registers

 Loop until empty entry found in ring buffer */

 Get pointer to ring buffer command entry */

		/* Check if ring buffer is full or command entry is waiting

		 * for response from TEE

 Wait if ring buffer is full or TEE is processing data */

	/* Do not submit command if PSP got disabled while processing any

	 * command in another thread

 Write command data into ring buffer */

 Indicate driver is waiting for response */

 Update local copy of write pointer */

 Trigger interrupt to Trusted OS */

	/* The response is provided by Trusted OS in same

	 * location as submitted data entry within ring buffer.

 ~1ms sleep per loop => nloop = timeout * 1000 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) driver

 *

 * Copyright (C) 2013-2019 Advanced Micro Devices, Inc.

 *

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

 * Author: Gary R Hook <gary.hook@amd.com>

 SHA initial context values */

 Advance to the next DMA scatterlist entry */

		/* In the case that the DMA mapped scatterlist has entries

		 * that have been merged, the non-DMA mapped scatterlist

		 * must be advanced multiple times for each merged entry.

		 * This ensures that the current non-DMA mapped entry

		 * corresponds to the current DMA mapped entry.

 Clear the buffer if setting it */

	/* Perform the copy operation

	 *   nbytes will always be <= UINT_MAX because dm_wa->length is

	 *   an unsigned int

 Update the structures and generate the count */

	/* The CCP can only DMA from/to one address each per operation. This

	 * requires that we find the smallest DMA area between the source

	 * and destination. The resulting len values will always be <= UINT_MAX

	 * because the dma length is an unsigned int.

	/* The data operation length will be at least block_size in length

	 * or the smaller of available sg room remaining for the source or

	 * the destination

 Unless we have to buffer data, there's no reason to wait */

		/* Not enough data in the sg element, so it

		 * needs to be buffered into a blocksize chunk

		/* Enough data in the sg element, but we need to

		 * adjust for any previously copied data

			/* Not enough room in the sg element or we're on the

			 * last piece of data (when using padding), so the

			 * output needs to be buffered into a blocksize chunk

			/* Enough room in the sg element, but we need to

			 * adjust for any previously used area

	/* All supported key sizes fit in a single (32-byte) SB entry

	 * and must be in little endian format. Use the 256-bit byte

	 * swap passthru option to convert from big endian to little

	 * endian.

	/* The AES context fits in a single (32-byte) SB entry and

	 * must be in little endian format. Use the 256-bit byte swap

	 * passthru option to convert from big endian to little endian.

 Send data to the CCP AES engine */

 Push the K1/K2 key to the CCP now */

	/* Retrieve the AES context - convert from LE to BE using

	 * 32-byte (256-bit) byteswapping

 ...but we only need AES_BLOCK_SIZE bytes */

 Default value */

 Gotta have a key SGL */

 Zero defaults to 16 bytes, the maximum size */

	/* First, decompose the source buffer into AAD & PT,

	 * and the destination buffer into AAD, CT & tag, or

	 * the input into CT & tag.

	 * It is expected that the input and output SGs will

	 * be valid, even if the AAD and input lengths are 0.

 Input length for decryption includes tag */

 Pre-allocated */

 Pre-allocated */

 Copy the key to the LSB */

	/* Copy the context (IV) to the LSB.

	 * There is an assumption here that the IV is 96 bits in length, plus

	 * a nonce of 32 bits. If no IV is present, use a zeroed buffer.

 Step 1: Run a GHASH over the Additional Authenticated Data */

 Step 2: Run a GCTR over the plaintext */

 Step 3: Update the IV portion of the context with the original IV */

	/* Step 4: Concatenate the lengths of the AAD and source, and

	 * hash that 16 byte buffer.

 Pre-allocated */

 Pre-allocated */

 Put the ciphered tag after the ciphertext. */

 Does this ciphered tag match the input? */

	/* All supported key sizes fit in a single (32-byte) SB entry

	 * and must be in little endian format. Use the 256-bit byte

	 * swap passthru option to convert from big endian to little

	 * endian.

	/* The AES context fits in a single (32-byte) SB entry and

	 * must be in little endian format. Use the 256-bit byte swap

	 * passthru option to convert from big endian to little endian.

 Load the AES context - convert to LE */

 CFB128 only */

	/* Prepare the input and output data workareas. For in-place

	 * operations we need to set the dma direction to BIDIRECTIONAL

	 * and copy the src workarea to the dst workarea.

 Send data to the CCP AES engine */

			/* Since we don't retrieve the AES context in ECB

			 * mode we have to wait for the operation to complete

			 * on the last piece of data

		/* Retrieve the AES context - convert from LE to BE using

		 * 32-byte (256-bit) byteswapping

 ...but we only need AES_BLOCK_SIZE bytes */

	/* A version 3 device only supports 128-bit keys, which fits into a

	 * single SB entry. A version 5 device uses a 512-bit vector, so two

	 * SB entries.

		/* All supported key sizes must be in little endian format.

		 * Use the 256-bit byte swap passthru option to convert from

		 * big endian to little endian.

		/* Version 5 CCPs use a 512-bit space for the key: each portion

		 * occupies 256 bits, or one entire slot, and is zero-padded.

	/* The AES context fits in a single (32-byte) SB entry and

	 * for XTS is already in little endian format so no byte swapping

	 * is needed.

	/* Prepare the input and output data workareas. For in-place

	 * operations we need to set the dma direction to BIDIRECTIONAL

	 * and copy the src workarea to the dst workarea.

 Send data to the CCP AES engine */

	/* Retrieve the AES context - convert from LE to BE using

	 * 32-byte (256-bit) byteswapping

 ...but we only need AES_BLOCK_SIZE bytes */

 Error checks */

 Zero out all the fields of the command desc */

 Set up the Function field */

	/*

	 * All supported key sizes fit in a single (32-byte) KSB entry and

	 * (like AES) must be in little endian format. Use the 256-bit byte

	 * swap passthru option to convert from big endian to little endian.

	/*

	 * The contents of the key triplet are in the reverse order of what

	 * is required by the engine. Copy the 3 pieces individually to put

	 * them where they belong.

 Basic offset */

 Copy the key to the SB */

	/*

	 * The DES3 context fits in a single (32-byte) KSB entry and

	 * must be in little endian format. Use the 256-bit byte swap

	 * passthru option to convert from big endian to little endian.

 Load the context into the LSB */

	/*

	 * Prepare the input and output data workareas. For in-place

	 * operations we need to set the dma direction to BIDIRECTIONAL

	 * and copy the src workarea to the dst workarea.

 Send data to the CCP DES3 engine */

			/* Since we don't retrieve the context in ECB mode

			 * we have to wait for the operation to complete

			 * on the last piece of data

 Retrieve the context and make BE */

 ...but we only need the last DES3_EDE_BLOCK_SIZE bytes */

 The version 3 device can't handle zero-length input */

 Not final, just return */

			/* CCP can't do a zero length sha operation so the

			 * caller must buffer the data.

			/* The CCP cannot perform zero-length sha operations

			 * so the caller is required to buffer data for the

			 * final operation. However, a sha operation for a

			 * message with a total length of zero is valid so

			 * known values are required to supply the result.

 Set variables used throughout */

	/* For zero-length plaintext the src pointer is ignored;

	 * otherwise both parts must be valid

 Pre-allocated */

	/* For SHA1/224/256 the context fits in a single (32-byte) SB entry;

	 * SHA384/512 require 2 adjacent SB slots, with the right half in the

	 * first slot, and the left half in the second. Each portion must then

	 * be in little endian format: use the 256-bit byte swap option.

 Restore the context */

 Send data to the CCP SHA engine; block_size is set above */

	/* Retrieve the SHA context - convert from LE to BE using

	 * 32-byte (256-bit) byteswapping to BE

 Finishing up, so get the digest */

 Stash the context */

 HMAC operation, recursively perform final SHA */

 Check against the maximum allowable size, in bits */

	/* The RSA modulus must precede the message being acted upon, so

	 * it must be copied to a DMA area where the message and the

	 * modulus can be concatenated.  Therefore the input buffer

	 * length required is twice the output buffer length (which

	 * must be a multiple of 256-bits).  Compute o_len, i_len in bytes.

	 * Buffer sizes must be a multiple of 32 bytes; rounding up may be

	 * required.

		/* sb_count is the number of storage block slots required

		 * for the modulus.

		/* A version 5 device allows a modulus size that will not fit

		 * in the LSB, so the command will transfer it from memory.

		 * Set the sb key to the default, even though it's not used.

	/* The RSA exponent must be in little endian format. Reverse its

	 * byte order.

		/* Copy the exponent to the local storage block, using

		 * as many 32-byte blocks as were allocated above. It's

		 * already little endian, so no further change is required.

 The exponent can be retrieved from memory via DMA. */

	/* Concatenate the modulus and the message. Both the modulus and

	 * the operands must be in little endian format.  Since the input

	 * is in big endian format it must be converted.

 Prepare the output area for the operation */

 Load the mask */

	/* Prepare the input and output data workareas. For in-place

	 * operations we need to set the dma direction to BIDIRECTIONAL

	 * and copy the src workarea to the dst workarea.

	/* Send data to the CCP Passthru engine

	 *   Because the CCP engine works on a single source and destination

	 *   dma address at a time, each entry in the source scatterlist

	 *   (after the dma_map_sg call) must be less than or equal to the

	 *   (remaining) length in the destination scatterlist entry and the

	 *   length must be a multiple of CCP_PASSTHRU_BLOCKSIZE

 Load the mask */

 Send data to the CCP Passthru engine */

	/* Concatenate the modulus and the operands. Both the modulus and

	 * the operands must be in little endian format.  Since the input

	 * is in big endian format it must be converted and placed in a

	 * fixed length buffer.

	/* Save the workarea address since it is updated in order to perform

	 * the concatenation

 Copy the ECC modulus */

 Copy the first operand */

 Copy the second operand */

 Restore the workarea address */

 Prepare the output area for the operation */

 Save the ECC result */

	/* Concatenate the modulus and the operands. Both the modulus and

	 * the operands must be in little endian format.  Since the input

	 * is in big endian format it must be converted and placed in a

	 * fixed length buffer.

	/* Save the workarea address since it is updated in order to perform

	 * the concatenation

 Copy the ECC modulus */

 Copy the first point X and Y coordinate */

 Set the first point Z coordinate to 1 */

 Copy the second point X and Y coordinate */

 Set the second point Z coordinate to 1 */

 Copy the Domain "a" parameter */

 Copy the scalar value */

 Restore the workarea address */

 Prepare the output area for the operation */

	/* Save the workarea address since it is updated as we walk through

	 * to copy the point math result

 Save the ECC result X and Y coordinates */

 Restore the workarea address */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) driver

 *

 * Copyright (C) 2016,2019 Advanced Micro Devices, Inc.

 *

 * Author: Gary R Hook <gary.hook@amd.com>

/* The CCP as a DMA provider can be configured for public or private

 * channels. Default is specified in the vdata for the device (PCI ID).

 * This module parameter will override for all channels on all devices:

 *   dma_chan_attr = 0x2 to force all channels public

 *                 = 0x1 to force all channels private

 *                 = 0x0 to defer to the vdata setting

 *                 = any other value: warning, revert to 0x0

 Move current DMA descriptor to the complete list */

 Get the next DMA descriptor on the active list */

 Loop over descriptors until one is found with commands */

 Remove the DMA command from the list and free it */

 No errors, keep going */

 Error, free remaining commands and move on */

 Check for DMA descriptor completion */

 Don't submit cmd if no descriptor or DMA is paused */

 If there was nothing active, start processing */

 Get status from complete chain, if still there */

TODO: Wait for active DMA to complete before returning? */

 Indicate the channel is running again */

 If there was something active, re-start */

TODO: Wait for active DMA to complete before continuing */

TODO: Purge the complete list? */

	/* The DMA channels for this device can be set to public or private,

	 * and overridden by the module parameter dma_chan_attr.

	 * Default: according to the value in vdata (dma_chan_attr=0)

	 * dma_chan_attr=0x1: all channels private (override vdata)

	 * dma_chan_attr=0x2: all channels public (override vdata)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) RSA crypto API support

 *

 * Copyright (C) 2017 Advanced Micro Devices, Inc.

 *

 * Author: Gary R Hook <gary.hook@amd.com>

 in bits */

 In bits */

 Clean up old key data */

 Code borrowed from crypto/rsa.c */

 convert to bits */

	/* Register the RSA algorithm in standard mode

	 * This works for CCP v3 and later

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) AES XTS crypto API support

 *

 * Copyright (C) 2013,2017 Advanced Micro Devices, Inc.

 *

 * Author: Gary R Hook <gary.hook@amd.com>

 * Author: Tom Lendacky <thomas.lendacky@amd.com>

	/* Version 3 devices support 128-bit keys; version 5 devices can

	 * accommodate 128- and 256-bit keys.

	/* Check conditions under which the CCP can fulfill a request. The

	 * device can handle input plaintext of a length that is a multiple

	 * of the unit_size, bug the crypto implementation only supports

	 * the unit_size being equal to the input length. This limits the

	 * number of scenarios we can handle.

	/* The CCP has restrictions on block sizes. Also, a version 3 device

	 * only supports AES-128 operations; version 5 CCPs support both

	 * AES-128 and -256 operations.

		/* Use the fallback to process the request for any

		 * unsupported unit sizes or key sizes

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) AES GCM crypto API support

 *

 * Copyright (C) 2016,2017 Advanced Micro Devices, Inc.

 *

 * Author: Gary R Hook <gary.hook@amd.com>

	/*

	 * 5 parts:

	 *   plaintext/ciphertext input

	 *   AAD

	 *   key

	 *   IV

	 *   Destination+tag buffer

 Prepare the IV: 12 bytes + an integer (counter) */

 Set up a scatterlist for the IV */

 The AAD + plaintext are concatenated in the src buffer */

 The cipher text + the tag are in the dst buffer */

 Copy the defaults and override as necessary */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMD Cryptographic Coprocessor (CCP) DES3 crypto API support

 *

 * Copyright (C) 2016,2017 Advanced Micro Devices, Inc.

 *

 * Author: Gary R Hook <ghook@amd.com>

	/* It's not clear that there is any support for a keysize of 112.

	 * If needed, the caller should make K1 == K3

 Copy the defaults and override as necessary */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Marvell

 *

 * Antoine Tenart <antoine.tenart@free-electrons.com>

 !=0=AEAD, 2=IPSec ESP AEAD, 3=IPsec ESP GMAC */

 0=authenc, 1=GCM, 2 reserved for CCM */

 All the below is AEAD specific */

 Number of result descriptors associated to the request */

 32 bit nonce */

 64 bit IV part */

 32 bit counter, start at 0 or 1 (big endian!) */

 96 bit nonce part */

 32 bit counter */

 No space in cdesc, instruction moves to atoken */

 Everything fits in cdesc */

 Need to pad with NOP */

 _ESP and _ESP_GMAC */

 32 bit nonce */

 64 bit IV part */

 32 bit counter, start at 0 or 1 (big endian!) */

 96 bit IV part */

 32 bit counter, start at 0 or 1 (big endian!) */

 CBC */

 Start with minimum size */

 Always 4 dwords of embedded IV  for AEAD modes */

 Construct IV block B0 for the CBC-MAC */

 Length + nonce */

 Fixup flags byte */

 64 bit IV part */

 Start counter at 0 */

 Message length */

 Variable length IV part */

 Start variable length counter at 0 */

 fixup flags byte */

 insert lower 2 bytes of message length */

 Process AAD data */

 For CCM only, align AAD data towards hash engine */

 Process AAD data */

 For ESP mode (and not GMAC), skip over the IV */

 Poly-chacha decryption needs a dummy NOP here ... */

 According to Op Manual */

 For GCM and CCM, obtain enc(Y0) */

 Fixup stat field for AAD direction instruction */

 Process crypto data */

 Fixup instruction field for AAD dir instruction */

 Do not send to crypt engine in case of GMAC */

 For CCM only, pad crypto data to the hash engine */

 Append ICV */

 Extract ICV */

 Verify ICV */

 Fixup length of the token in the command descriptor */

 Must have at least space for the nonce here */

 last 4 bytes of key are the nonce! */

 exclude the nonce here */

 Encryption key */

 Auth key */

 Now copy the keys into the context */

 Take in account the ipad+opad digests */

 Chacha20-Poly1305 */

	/*

	 * Update IV in req from last crypto output word for CBC modes

 For encrypt take the last output word */

		/*

		 * AEAD has auth tag appended to output for encrypt and

		 * removed from the output for decrypt!

		/*

		 * Save IV from last crypto input word for CBC modes in decrypt

		 * direction. Need to do this first in case of inplace operation

		 * as it will be overwritten.

	/*

	 * Remember actual input length, source buffer length may be

	 * updated in case of inline operation below.

		/*

		 * The EIP97 cannot deal with zero length input packets!

		 * So stuff a dummy command descriptor indicating a 1 byte

		 * (dummy) input packet, using the context record as source.

 No space left in the command descriptor ring */

 command descriptors */

 Do not overflow the request */

 No space left in the command descriptor ring */

 Add context control words and token to first command descriptor */

 result descriptors */

 only allow the part of the buffer we know we need */

 skip over AAD space in buffer - not written */

 No space left in the result descriptor ring */

		/*

		 * Special case: AEAD decrypt with only AAD data.

		 * In this case there is NO output data from the engine,

		 * but the engine still needs a result descriptor!

		 * Create a dummy one just for catching the result token.

 No space left in the result descriptor ring */

		/*

		 * Save input IV in case of CBC decrypt mode

		 * Will be overwritten with output IV prior to use!

 context not allocated, skip invalidation */

 last 4 bytes of key are the nonce! */

 exclude the nonce here */

 Add nonce size */

 if context exits and key changed, need to invalidate it */

 if context exits and key changed, need to invalidate it */

 default */

 default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 override default */

 Check for illegal XTS keys */

 Only half of the key data is cipher key */

 The other half is the tweak key */

 XTS actually uses 2 AES keys glued together */

 Compute hash key by encrypting zeroes with cipher key */

 override default */

 override default */

 Borrowed from crypto/ccm.c */

 ESP variant has nonce appended to key */

	/*

	 * Instead of wasting time detecting umpteen silly corner cases,

	 * just dump all "small" requests to the fallback implementation.

	 * HW would not be faster on such small requests anyway.

 HW cannot do full (AAD+payload) zero length, use fallback */

 ESP variant has nonce appended to the key */

 Allocate fallback implementation */

 Precomputed by HW */

 +1 to put it above HW chacha + SW poly */

 +1 to put it above HW chacha + SW poly */

 Workaround for HW bug: EIP96 4.3 does not report blocksize error */

 Workaround for HW bug: EIP96 4.3 does not report blocksize error */

 last 4 bytes of key are the nonce! */

 exclude the nonce here */

 Add nonce size */

 Workaround for HW bug: EIP96 4.3 does not report blocksize error */

 Workaround for HW bug: EIP96 4.3 does not report blocksize error */

 Keep fallback cipher synchronized */

 Keep fallback cipher synchronized */

 Workaround for HW bug: EIP96 4.3 does not report blocksize error */

 If input length > 0 only */

 HW cannot do full (AAD+payload) zero length, use fallback */

 Workaround for HW bug: EIP96 4.3 does not report blocksize error */

 If input length > 0 only */

 HW cannot do full (AAD+payload) zero length, use fallback */

 last 4 bytes of key are the nonce! */

 First byte of the nonce = L = always 3 for RFC4309 (4 byte ctr) */

 last 3 bytes of key are the nonce! */

 Borrowed from crypto/ccm.c */

 Borrowed from crypto/ccm.c */

 Borrowed from crypto/ccm.c */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Marvell

 *

 * Antoine Tenart <antoine.tenart@free-electrons.com>

 Actual command descriptor ring */

 Command descriptor shadow ring for storing additional token data */

	/*

	 * Populate command descriptors with physical pointers to shadow descs.

	 * Note that we only need to do this once if we don't overwrite them.

 Use shoffset for result token offset here */

 Result token at relative offset shoffset */

		/*

		 * Note that the length here MUST be >0 or else the EIP(1)97

		 * may hang. Newer EIP197 firmware actually incorporates this

		 * fix already, but that doesn't help the EIP97 and we may

		 * also be running older firmware.

 assume error */

 assume error */

 Clear length in result token */

 Assume errors - HW will clear if not the case */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Marvell

 *

 * Antoine Tenart <antoine.tenart@free-electrons.com>

 expected state size, only set once */

 block size, only set once */

 output digest size, only set once */

	/*

	 * Copy the input digest if needed, and setup the context

	 * fields. Do this now as we need it to setup the first command

	 * descriptor.

 First - and possibly only - block of basic hash only */

 ensure its not 0! */

 ensure its not 0! */

 Hash continuation or HMAC, setup (inner) digest from state */

 Compute digest count for hash/HMAC finish operations */

			/* This is a hardware limitation, as the

			 * counter must fit into an u32. This represents

			 * a fairly big amount of input data, so we

			 * shouldn't see this.

 Special case: zero length HMAC */

 PE HW < 4.4 cannot do HMAC continue, fake using hash */

 Basic hash continue operation, need digest + cnt */

 For zero-len HMAC, don't finalize, already padded! */

 Clear zero-length HMAC flag for next operation! */

 HMAC */

 Need outer digest for HMAC finalization */

 Single pass HMAC - no digest count */

 Hash continuation, do not finish yet */

 Faking HMAC using hash - need to do outer hash */

 Not done yet */

 Undo final XOR with 0xffffffff ...*/

		/* If this is not the last request and the queued data does not

		 * fit into full cache blocks, cache it for the next send call.

		/* If this is not the last request and the queued data

		 * is a multiple of a block, cache the last one for now.

			/*

			 * Cache contains less than 1 full block, complete.

 More data follows: borrow bytes */

 10- padding for XCBCMAC & CMAC

 HW will use K2 iso K3 - compensate!

 XCBC continue: XOR previous result into 1st word */

 Add a command descriptor for the cached data, if any */

 Now handle the current ahash request buffer(s) */

 Do not overflow the request */

 Setup the context options */

 Add the token */

 Add a result descriptor */

 create invalidation request */

/* safexcel_ahash_cache: cache data until at least one request can be sent to

 * the engine, aka. when there is at least 1 block size in the pipe.

	/* cache_len: everything accepted by the driver but not sent yet,

	 * tot sz handled by update() - last req sz - tot sz handled by send()

	/*

	 * In case there isn't enough bytes to proceed (less than a

	 * block size), cache the data until we have enough.

 We couldn't cache all the data */

 invalidate for *any* non-XCBC continuation */

 invalidate if (i)digest changed */

 invalidate for HMAC finish with odigest changed */

			/*

			 * We're still setting needs_inv here, even though it is

			 * cleared right away, because the needs_inv flag can be

			 * set in other functions and we want to keep the same

			 * logic.

 If the request is 0 length, do nothing */

 Add request to the cache if it fits */

 Update total request length */

	/* If not all data could fit into the cache, go process the excess.

	 * Also go process immediately for an HMAC IV precompute, which

	 * will never be finished at all, but needs to be processed anyway.

		/*

		 * If we have an overall 0 length *hash* request:

		 * The HW cannot do 0 length hash, so we provide the correct

		 * result directly here.

 Zero length CRC32 */

 Zero length CBC MAC */

 Zero length (X)CBC/CMAC */

 K3 */

 10- padding

		/*

		 * If we have an overall 0 length *HMAC* request:

		 * For HMAC, we need to finalize the inner digest

		 * and then perform the outer hash.

 generate pad block in the cache */

 start with a hash block of all zeroes */

 set the first byte to 0x80 to 'append a 1 bit' */

 add the length in bits in the last 2 bytes */

 Little endian length word (e.g. MD5) */

 Big endian length word (e.g. any SHA) */

 plus 1 hash block */

 Set special zero-length HMAC flag */

 Finalize HMAC */

 Finalize HMAC */

 context not allocated, skip invalidation */

 Start from ipad precompute */

 Already processed the key^ipad part now! */

 Avoid leaking */

 Start from ipad precompute */

 Already processed the key^ipad part now! */

 Start from ipad precompute */

 Already processed the key^ipad part now! */

 Start from ipad precompute */

 Already processed the key^ipad part now! */

 Start from ipad precompute */

 Already processed the key^ipad part now! */

 Start from ipad precompute */

 Already processed the key^ipad part now! */

 MD5 is little endian! ... */

 Default 'key' is all zeroes */

 Start from loaded key */

 Set processed to non-zero to enable invalidation detection */

 Start from loaded keys */

 Set processed to non-zero to enable invalidation detection */

 precompute the XCBC key material */

 precompute the CMAC key material */

 code below borrowed from crypto/cmac.c */

 encrypt the zero block */

 gf(2^128) multiply zero-ciphertext with u and u^2 */

 end of code borrowed from crypto/cmac.c */

 Start from ipad precompute */

 Already processed the key^ipad part now! */

 Set fallback cipher HMAC key */

 Update or ex/import happened or len 0, cannot use the HW */

 HW cannot do zero length hash, use fallback instead */

 return safexcel_ahash_import(req, in);

 Allocate fallback implementation */

 Update statesize from fallback algorithm! */

 HW cannot do zero length hash, use fallback instead */

 HW cannot do zero length hash, use fallback instead */

 HW cannot do zero length hash, use fallback instead */

 Allocate precalc basic digest implementation */

		/*

		 * If the key is larger than the blocksize, then hash it

		 * first using our fallback cipher

		/*

		 * If the digest is larger than half the blocksize, we need to

		 * move the rest to opad due to the way our HMAC infra works.

 Buffers overlap, need to use memmove iso memcpy! */

		/*

		 * Copy the key to our ipad & opad buffers

		 * Note that ipad and opad each contain one half of the key,

		 * to match the existing HMAC driver infrastructure.

 Pad key with zeroes */

 If doing fallback, still need to set the new key! */

 Copy (half of) the key */

 Start of HMAC should have len == processed == blocksize */

 HW cannot do zero length HMAC, use fallback instead */

 Copy (half of) the key */

 Start of HMAC should have len == processed == blocksize */

 HW cannot do zero length HMAC, use fallback instead */

 Copy (half of) the key */

 Start of HMAC should have len == processed == blocksize */

 HW cannot do zero length HMAC, use fallback instead */

 Copy (half of) the key */

 Start of HMAC should have len == processed == blocksize */

 HW cannot do zero length HMAC, use fallback instead */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Marvell

 *

 * Antoine Tenart <antoine.tenart@free-electrons.com>

	/*

	 * Map all interfaces/rings to register index 0

	 * so they can share contexts. Without this, the EIP197 will

	 * assume each interface/ring to be in its own memory domain

	 * i.e. have its own subset of UNIQUE memory addresses.

	 * Which would cause records with the SAME memory address to

	 * use DIFFERENT cache buffers, causing both poor cache utilization

	 * AND serious coherence/invalidation issues.

	/*

	 * Initialize other virtualization regs for cache

	 * These may not be in their reset state ...

	/*

	 * And probe the actual size of the physically attached cache data RAM

	 * Using a binary subdivision algorithm downto 32 byte cache lines.

 write marker to lowest address in top half */

 Unique */

 write invalid markers to possible aliases */

 read back marker from top half */

 read back correct, continue with top half */

 not read back correct, continue with bottom half */

 Clear all records in administration RAM */

 must also initialize the address key due to ECC! */

 Clear the hash table entries */

 Setup (dummy) virtualization for cache */

	/*

	 * Enable the record cache memory access and

	 * probe the bank select width

 Clear all ECC errors */

	/*

	 * Make sure the cache memory is accessible by taking record cache into

	 * reset. Need data memory access here, not admin access.

 Probed data RAM size in bytes */

	/*

	 * Now probe the administration RAM size pretty much the same way

	 * Except that only the lower 30 bits are writable and we don't need

	 * bank selects

 admin access now */

 Probed admin RAM size in admin words */

 Clear any ECC errors detected while probing! */

 Sanity check probing results */

	/*

	 * Determine optimal configuration from RAM sizes

	 * Note that we assume that the physical RAM configuration is sane

	 * Therefore, we don't do any parameter error checking here ...

 For now, just use a single record format covering everything */

	/*

	 * Step #1: How many records will physically fit?

	 * Hard upper limit is 1023!

 Step #2: Need at least 2 words in the admin RAM per record */

 Step #3: Determine log2 of hash table size */

 Step #4: determine current size of hash table in dwords */

 dwords, not admin words */

 Step #5: add back excess words and see if we can fit more records */

 Clear the cache RAMs */

 Disable the record cache memory access */

 Write head and tail pointers of the record free chain */

 Configure the record cache #1 */

 Configure the record cache #2 */

 Configure the token FIFO's */

 Clear the ICE scratchpad memory */

 clear the scratchpad RAM using 32 bit writes only */

 Reset the IFPP engine to make its program mem accessible */

 Reset the IPUE engine to make its program mem accessible */

 Enable access to all IFPP program memories */

 bypass the OCE, if present */

 Write the firmware */

 Exclude final 2 NOPs from size */

/*

 * If FW is actual production firmware, then poll for its initialization

 * to complete and check if it is good for the HW, otherwise just return OK.

 Disable access to all program memory */

 Start IFPP microengines */

 Start IPUE microengines */

 For miniFW startup, there is no initialization, so always succeed */

 Wait until all the firmwares have properly started up */

			/* Fallback to the old firmware location for the

			 * EIP197b.

 Enable access to IPUE program memories */

 Retry with minifw path */

 determine number of CD's we can fetch into the CD FIFO as 1 block */

 EIP197: try to fetch enough in 1 go to keep all pipes busy */

 for the EIP97, just fetch all that fits minus 1 */

	/*

	 * Since we're using command desc's way larger than formally specified,

	 * we need to check whether we can fit even 1 for low-end EIP196's!

 ring base address */

 Configure DMA tx control */

 clear any pending interrupt */

 determine number of RD's we can fetch into the FIFO as one block */

 EIP197: try to fetch enough in 1 go to keep all pipes busy */

 for the EIP97, just fetch all that fits minus 1 */

 ring base address */

 Configure DMA tx control */

 clear any pending interrupt */

 enable ring interrupt */

	/*

	 * For EIP197's only set maximum number of TX commands to 2^5 = 32

	 * Skip for the EIP97 as it does not have this field.

 Configure wr/rd cache values */

 Interrupts reset */

 Disable all global interrupts */

 Clear any pending interrupt */

 Processing Engine configuration */

 Data Fetch Engine configuration */

 Reset all DFE threads */

 Reset HIA input interface arbiter (if present) */

 DMA transfer size to use */

 Leave the DFE threads reset state */

 Configure the processing engine thresholds */

 enable HIA input interface arbiter and rings */

 Data Store Engine configuration */

 Reset all DSE threads */

 Wait for all DSE threads to complete */

 DMA transfer size to use */

		/* FIXME: instability issues can occur for EIP97 but disabling

		 * it impacts performance.

 Leave the DSE threads reset state */

 Configure the processing engine thresholds */

 Processing Engine configuration */

 Token & context configuration */

 H/W capabilities selection: just enable everything */

 Command Descriptor Rings prepare */

 Clear interrupts for this ring */

 Disable external triggering */

 Clear the pending prepared counter */

 Clear the pending processed counter */

 Result Descriptor Ring prepare */

 Disable external triggering*/

 Clear the pending prepared counter */

 Clear the pending processed counter */

 Ring size */

 Enable command descriptor rings */

 Enable result descriptor rings */

 Clear any HIA interrupt */

 Called with ring's lock taken */

 Configure when we want an interrupt */

	/* If a request wasn't properly dequeued because of a lack of resources,

	 * proceeded it first,

		/* In case the send() helper did not issue any command to push

		 * to the engine because the input data was cached, continue to

		 * dequeue other requests as this is valid and not an error.

	/* Not enough resources to handle all the requests. Bail out and save

	 * the request and the backlog for the next dequeue call (per-ring).

 let the RDR know we have pending descriptors */

 let the CDR know we have pending descriptors */

 Rest only valid if last seg! */

 Fatal error (bits 1,2,5,6 & 14) */

		/*

		 * Give priority over authentication fails:

		 * Blocksize, length & overflow errors,

		 * something wrong with the input!

 Authentication failed */

 All other non-fatal errors */

 Acknowledge the command descriptors */

 Prepare command descriptor */

 Prepare result descriptor */

	/* If the number of requests overflowed the counter, try to proceed more

	 * requests.

 RDR interrupts */

			/*

			 * Fatal error, the RDR is unusable and must be

			 * reinitialized. This should not happen under

			 * normal circumstances.

 ACK the interrupts */

 ACK the interrupts */

 "ringX\0" */

 Set affinity */

 Do we have all required base algorithms available? */

 No, so don't register this ciphersuite */

 Do we have all required base algorithms available? */

 No, so don't unregister this ciphersuite */

 Do we have all required base algorithms available? */

 No, so don't unregister this ciphersuite */

 Cannot currently support more rings than we have ring AICs! */

 res token is behind the descr, but ofs must be rounded to buswdth */

 now the size of the descr is this 1st part plus the result struct */

 convert dwords to bytes */

/*

 * Generic part of probe routine, shared by platform and PCI driver

 *

 * Assumes IO resources have been mapped, private data mem has been allocated,

 * clocks have been enabled, device pointer has been assigned etc.

 *

	/*

	 * First try the EIP97 HIA version regs

	 * For the EIP197, this is guaranteed to NOT return any of the test

	 * values

 do not swap */

 read back byte-swapped, so complement byte swap bits */

 So it wasn't an EIP97 ... maybe it's an EIP197? */

 read back byte-swapped, so complement swap bits */

 Now initialize the reg offsets based on the probing info so far */

	/*

	 * If the version was read byte-swapped, we need to flip the device

	 * swapping Keep in mind here, though, that what we write will also be

	 * byte-swapped ...

 toggle byte swap bits */

	/*

	 * We're not done probing yet! We may fall through to here if no HIA

	 * was found at all. So, with the endianness presumably correct now and

	 * the offsets setup, *really* probe for the EIP97/EIP197.

		/*

		 * We did not find the device that matched our initial probing

		 * (or our initial probing failed) Report appropriate error.

 Detect EIP206 processing pipe */

 Detect EIP96 packet engine and version */

 EIP197 */

 Detect ICE EIP207 class. engine and version */

 Detect EIP96PP packet stream editor and version */

 Detect OCE EIP207 class. engine and version */

 If not a full TRC, then assume simple TRC */

 EIP197 always has SOME form of TRC */

 EIP97 */

 by definition */

 Scan for ring AIC's */

 Low-end EIP196 may not have any ring AIC's ... */

 Get supported algorithms from EIP96 transform engine */

 Print single info line describing what we just detected */

		/*

		 * Request MSI vectors for global + 1 per ring -

		 * or just 1 for older dev images

 Register the ring IRQ handlers and configure the rings */

 clear any pending interrupt */

 Reset the CDR base address */

 Reset the RDR base address */

 for Device Tree platform driver */

 The clock isn't mandatory */

 The clock isn't mandatory */

 Generic EIP97/EIP197 device probing */

 For backward compatibility and intended for generic use */

 PCIE devices - i.e. Inside Secure development boards */

 enable the device */

 take ownership of PCI BAR0 */

 Setup MSI identity map mapping */

 Enable all device interrupts */

 HW reset FPGA dev board */

 assert reset */

 maintain strict ordering for accesses here */

 deassert reset */

 maintain strict ordering for accesses here */

 enable bus mastering */

 Generic EIP97/EIP197 device probing */

 Register PCI driver */

 Register platform driver */

 Unregister platform driver */

 Unregister PCI driver if successfully registered before */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Keem Bay OCS AES Crypto Driver.

 *

 * Copyright (C) 2018-2020 Intel Corporation

/**

 * struct ocs_aes_tctx - OCS AES Transform context

 * @engine_ctx:		Engine context.

 * @aes_dev:		The OCS AES device.

 * @key:		AES/SM4 key.

 * @key_len:		The length (in bytes) of @key.

 * @cipher:		OCS cipher to use (either AES or SM4).

 * @sw_cipher:		The cipher to use as fallback.

 * @use_fallback:	Whether or not fallback cipher should be used.

/**

 * struct ocs_aes_rctx - OCS AES Request context.

 * @instruction:	Instruction to be executed (encrypt / decrypt).

 * @mode:		Mode to use (ECB, CBC, CTR, CCm, GCM, CTS)

 * @src_nents:		Number of source SG entries.

 * @dst_nents:		Number of destination SG entries.

 * @src_dma_count:	The number of DMA-mapped entries of the source SG.

 * @dst_dma_count:	The number of DMA-mapped entries of the destination SG.

 * @in_place:		Whether or not this is an in place request, i.e.,

 *			src_sg == dst_sg.

 * @src_dll:		OCS DMA linked list for input data.

 * @dst_dll:		OCS DMA linked list for output data.

 * @last_ct_blk:	Buffer to hold last cipher text block (only used in CBC

 *			mode).

 * @cts_swap:		Whether or not CTS swap must be performed.

 * @aad_src_dll:	OCS DMA linked list for input AAD data.

 * @aad_dst_dll:	OCS DMA linked list for output AAD data.

 * @in_tag:		Buffer to hold input encrypted tag (only used for

 *			CCM/GCM decrypt).

 * @out_tag:		Buffer to hold output encrypted / decrypted tag (only

 *			used for GCM encrypt / decrypt).

 Fields common across all modes. */

 CBC specific */

 CTS specific */

 CCM/GCM specific */

 GCM specific */

 Driver data. */

 Protects dev_list. */

 Only a single OCS device available */

/*

 * Ensure key is 128-bit or 256-bit for AES or 128-bit for SM4 and an actual

 * key is being passed in.

 *

 * Return: 0 if key is valid, -EINVAL otherwise.

 For AES, only 128-byte or 256-byte keys are supported. */

 For SM4, only 128-byte keys are supported. */

 Everything else is unsupported. */

 Save key into transformation context. */

 Set key for symmetric cypher. */

 Fallback is used for AES with 192-bit key. */

 Set key for AEAD cipher. */

 Fallback is used for AES with 192-bit key. */

 Swap two AES blocks in SG lists. */

	/*

	 * No easy way to copy within sg list, so copy both blocks to temporary

	 * buffers first.

 Initialize request context to default values. */

 Zero everything. */

 Set initial value for DMA addresses. */

 Ensure input length is multiple of block size */

 Ensure input length is multiple of block size */

 Ensure IV is present and block size in length */

		/*

		 * NOTE: Since req->cryptlen == 0 case was already handled in

		 * kmb_ocs_sk_common(), the above two conditions also guarantee

		 * that: cryptlen >= iv_size

 Ensure IV is present and block size in length */

 Ensure input length >= block size */

 Ensure IV is present and block size in length */

/*

 * Called by encrypt() / decrypt() skcipher functions.

 *

 * Use fallback if needed, otherwise initialize context and enqueue request

 * into engine.

	/*

	 * If cryptlen == 0, no processing needed for ECB, CBC and CTR.

	 *

	 * For CTS continue: kmb_ocs_sk_validate_input() will return -EINVAL.

 Clean up OCS DMA linked lists */

	/*

	 * For CBC decrypt, save last block (iv) to last_ct_blk buffer.

	 *

	 * Note: if we are here, we already checked that cryptlen >= iv_size

	 * and iv_size == AES_BLOCK_SIZE (i.e., the size of last_ct_blk); see

	 * kmb_ocs_sk_validate_input().

 For CTS decrypt, swap last two blocks, if needed. */

 src and dst buffers are the same, use bidirectional DMA mapping. */

 Create DST linked list */

	/*

	 * If descriptor creation was successful, set the src_dll.dma_addr to

	 * the value of dst_dll.dma_addr, as we do in-place AES operation on

	 * the src.

 Map SRC SG. */

 Create SRC linked list */

 Map DST SG. */

 Create DST linked list */

 If this is not a CTS decrypt operation with swapping, we are done. */

	/*

	 * Otherwise, we have to copy src to dst (as we cannot modify src).

	 * Use OCS AES bypass mode to copy src to dst via DMA.

	 *

	 * NOTE: for anything other than small data sizes this is rather

	 * inefficient.

	/*

	 * Now dst == src, so clean up what we did so far and use in_place

	 * logic.

	/*

	 * If 2 blocks or greater, and multiple of block size swap last two

	 * blocks to be compatible with other crypto API CTS implementations:

	 * OCS mode uses CBC-CS2, whereas other crypto API implementations use

	 * CBC-CS3.

	 * CBC-CS2 and CBC-CS3 defined by:

	 * https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38a-add.pdf

 Clean-up DMA before further processing output. */

 For CTS Encrypt, swap last 2 blocks, if needed. */

 For CBC copy IV to req->IV. */

 CBC encrypt case. */

 CBC decrypt case. */

 For all other modes there's nothing to do. */

 For decrypt crytplen == len(PT) + len(tag). */

 IV is mandatory. */

 Ensure IV is present and block size in length */

/*

 * Called by encrypt() / decrypt() aead functions.

 *

 * Use fallback if needed, otherwise initialize context and enqueue request

 * into engine.

 Clean up OCS DMA linked lists */

/**

 * kmb_ocs_aead_dma_prepare() - Do DMA mapping for AEAD processing.

 * @req:		The AEAD request being processed.

 * @src_dll_size:	Where to store the length of the data mapped into the

 *			src_dll OCS DMA list.

 *

 * Do the following:

 * - DMA map req->src and req->dst

 * - Initialize the following OCS DMA linked lists: rctx->src_dll,

 *   rctx->dst_dll, rctx->aad_src_dll and rxtc->aad_dst_dll.

 *

 * Return: 0 on success, negative error code otherwise.

 The length of the data to be mapped by src_dll. */

 The length of the data to be mapped by dst_dll. */

 The length of the data in dst_sg. */

 Get number of entries in input data SG list. */

		/*

		 * For decrypt:

		 * - src sg list is:		AAD|CT|tag

		 * - dst sg list expects:	AAD|PT

		 *

		 * in_size == len(CT); out_size == len(PT)

 req->cryptlen includes both CT and tag. */

 out_size = PT size == CT size */

 len(dst_sg) == len(AAD) + len(PT) */

		/*

		 * Copy tag from source SG list to 'in_tag' buffer.

		 *

		 * Note: this needs to be done here, before DMA mapping src_sg.

 OCS_ENCRYPT */

		/*

		 * For encrypt:

		 *	src sg list is:		AAD|PT

		 *	dst sg list expects:	AAD|CT|tag

 in_size == len(PT) */

		/*

		 * In CCM mode the OCS engine appends the tag to the ciphertext,

		 * but in GCM mode the tag must be read from the tag registers

		 * and appended manually below

 len(dst_sg) == len(AAD) + len(CT) + len(tag) */

 Get number of entries in output data SG list. */

 Map destination; use bidirectional mapping for in-place case. */

 Create AAD DST list: maps dst[0:AAD_SIZE-1]. */

 Create DST list: maps dst[AAD_SIZE:out_size] */

 If this is not CCM encrypt, we are done. */

			/*

			 * SRC and DST are the same, so re-use the same DMA

			 * addresses (to avoid allocating new DMA lists

			 * identical to the dst ones).

		/*

		 * For CCM encrypt the input and output linked lists contain

		 * different amounts of data, so, we need to create different

		 * SRC and AAD SRC lists, even for the in-place case.

 Not in-place case. */

 Map source SG. */

 Create AAD SRC list. */

 Create SRC list. */

 Copy AAD from src sg to dst sg using OCS DMA. */

 The length of the data mapped by src_dll. */

 For CCM, we just call the OCS processing and we are done. */

 GCM case; invoke OCS processing. */

 For GCM decrypt, we have to compare in_tag with out_tag. */

 For GCM encrypt, we must manually copy out_tag to DST sg. */

 Clean-up must be called before the sg_pcopy_from_buffer() below. */

 Copy tag to destination sg after AAD and CT. */

 Return directly as DMA cleanup already done. */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS */

 set fallback cipher in case it will be needed */

 Zero key registers if set */

 Set fallback cipher in case it will be needed */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS */

	/*

	 * If any algorithm fails to register, all preceding algorithms that

	 * were successfully registered will be automatically unregistered.

 Device tree driver match. */

 Get base register address. */

 Get and request IRQ */

 Initialize crypto engine */

 The OCS driver is a platform device. */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Keem Bay OCS ECC Crypto Driver.

 *

 * Copyright (C) 2019-2021 Intel Corporation

 ECC Instruction : for ECC_COMMAND */

/**

 * struct ocs_ecc_dev - ECC device context

 * @list: List of device contexts

 * @dev: OCS ECC device

 * @base_reg: IO base address of OCS ECC

 * @engine: Crypto engine for the device

 * @irq_done: IRQ done completion.

 * @irq: IRQ number

/**

 * struct ocs_ecc_ctx - Transformation context.

 * @engine_ctx:	 Crypto engine ctx.

 * @ecc_dev:	 The ECC driver associated with this context.

 * @curve:	 The elliptic curve used by this transformation.

 * @private_key: The private key.

 Driver data. */

 Protects dev_list. */

 Global variable holding the list of OCS ECC devices (only one expected). */

 Get OCS ECC tfm context from kpp_request. */

 Converts number of digits to number of bytes. */

/*

 * Wait for ECC idle i.e when an operation (other than write operations)

 * is done.

 Direct write of u32 buffer to ECC engine with associated instruction. */

 MMIO Write src uint32 to dst. */

 Start OCS ECC operation and wait for its completion. */

/**

 * ocs_ecc_read_cx_out() - Read the CX data output buffer.

 * @dev:	The OCS ECC device to read from.

 * @cx_out:	The buffer where to store the CX value. Must be at least

 *		@byte_count byte long.

 * @byte_count:	The amount of data to read.

/**

 * ocs_ecc_read_cy_out() - Read the CX data output buffer.

 * @dev:	The OCS ECC device to read from.

 * @cy_out:	The buffer where to store the CY value. Must be at least

 *		@byte_count byte long.

 * @byte_count:	The amount of data to read.

 Only a single OCS device available. */

 Do point multiplication using OCS ECC HW. */

 Use the maximum data size. */

 Generate random nbytes for Simple and Differential SCA protection. */

 Wait engine to be idle before starting new operation. */

 Send ecc_start pulse as well as indicating operation size. */

 Write ax param; Base point (Gx). */

 Write ay param; Base point (Gy). */

	/*

	 * Write the private key into DATA_IN reg.

	 *

	 * Since DATA_IN register is used to write different values during the

	 * computation private Key value is overwritten with

	 * side-channel-resistance value.

 Write operand by/l. */

 Write p = curve prime(GF modulus). */

 Write a = curve coefficient. */

 Make hardware perform the multiplication. */

 Read result. */

/**

 * kmb_ecc_do_scalar_op() - Perform Scalar operation using OCS ECC HW.

 * @ecc_dev:	The OCS ECC device to use.

 * @scalar_out:	Where to store the output scalar.

 * @scalar_a:	Input scalar operand 'a'.

 * @scalar_b:	Input scalar operand 'b'

 * @curve:	The curve on which the operation is performed.

 * @ndigits:	The size of the operands (in digits).

 * @inst:	The operation to perform (as an OCS ECC instruction).

 *

 * Return:	0 on success, negative error code otherwise.

 Wait engine to be idle before starting new operation. */

 Send ecc_start pulse as well as indicating operation size. */

 Write ax param (Base point (Gx).*/

 Write ay param Base point (Gy).*/

 Write p = curve prime(GF modulus).*/

 Give instruction A.B or A+B to ECC engine. */

 SP800-56A section 5.6.2.3.4 partial verification: ephemeral keys only */

 Check 1: Verify key is not the zero point. */

 Check 2: Verify key is in the range [0, p-1]. */

 Check 3: Verify that y^2 == (x^3 + a·x + b) mod p */

 y^2 */

 Compute y^2 -> store in yy */

 x^3 */

 Assigning w = 3, used for calculating x^3. */

 Load the next stage.*/

 Do a*x -> store in w. */

 Do ax + b == w + b; store in w. */

 x^3 + ax + b == x^3 + w -> store in w. */

 Compare y^2 == x^3 + a·x + b. */

 SP800-56A section 5.6.2.3.3 full verification */

 Checks 1 through 3 */

 Check 4: Verify that nQ is the zero point. */

 Make sure the private key is in the range [2, n-3]. */

/*

 * ECC private keys are generated using the method of extra random bits,

 * equivalent to that described in FIPS 186-4, Appendix B.4.1.

 *

 * d = (c mod(n–1)) + 1    where c is a string of random bits, 64 bits longer

 *                         than requested

 * 0 <= c mod(n-1) <= n-2  and implies that

 * 1 <= d <= n-1

 *

 * This method generates a private key uniformly distributed in the range

 * [1, n-1].

 Check that N is included in Table 1 of FIPS 186-4, section 6.1.1 */

	/*

	 * FIPS 186-4 recommends that the private key should be obtained from a

	 * RBG with a security strength equal to or greater than the security

	 * strength associated with N.

	 *

	 * The maximum security strength identified by NIST SP800-57pt1r4 for

	 * ECC is 256 (N >= 512).

	 *

	 * This condition is met by the default RNG because it selects a favored

	 * DRBG with a security strength of 256.

 Ensure key size is not bigger then expected. */

 Auto-generate private key is not provided. */

 Compute shared secret. */

 Public key is a point, thus it has two coordinates */

 Copy public key from SG list to pubk_buf. */

 Allocate and initialize public key point. */

	/*

	 * Check the public key for following

	 * Check 1: Verify key is not the zero point.

	 * Check 2: Verify key is in the range [1, p-1].

	 * Check 3: Verify that y^2 == (x^3 + a·x + b) mod p

 Allocate point for storing computed shared secret. */

 Calculate the shared secret.*/

 Copy shared secret from point to buffer. */

 Request might ask for less bytes than what we have. */

 Compute public key. */

 Public key is a point, so it has double the digits. */

 Public Key(pk) = priv * G. */

 SP800-56A rev 3 5.6.2.1.3 key check */

 Copy public key from point to buffer. */

 Copy public key to req->dst. */

 Ensure kmb_ocs_ecdh_set_secret() has been successfully called. */

 Ensure dst is present. */

 Check the request dst is big enough to hold the public key. */

 'src' is not supposed to be present when generate pubk is called. */

 Ensure kmb_ocs_ecdh_set_secret() has been successfully called. */

 Ensure dst is present. */

 Ensure src is present. */

	/*

	 * req->src is expected to the (other-side) public key, so its length

	 * must be 2 * coordinate size (in bytes).

 Public key is made of two coordinates, so double the digits. */

	/*

	 * Read the status register and write it back to clear the

	 * DONE_INT_STATUS bit.

 Get base register address. */

 Get and request IRQ */

 Add device to the list of OCS ECC devices. */

 Initialize crypto engine. */

 Register the KPP algo. */

 Device tree driver match. */

 The OCS driver is a platform device. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Keem Bay OCS AES Crypto Driver.

 *

 * Copyright (C) 2018-2020 Intel Corporation

/*

 * AES_A_DMA_DMA_MODE register.

 * Default: 0x00000000.

 * bit[31]	ACTIVE

 *		This bit activates the DMA. When the DMA finishes, it resets

 *		this bit to zero.

 * bit[30:26]	Unused by this driver.

 * bit[25]	SRC_LINK_LIST_EN

 *		Source link list enable bit. When the linked list is terminated

 *		this bit is reset by the DMA.

 * bit[24]	DST_LINK_LIST_EN

 *		Destination link list enable bit. When the linked list is

 *		terminated this bit is reset by the DMA.

 * bit[23:0]	Unused by this driver.

/*

 * AES_ACTIVE register

 * default 0x00000000

 * bit[31:10]	Reserved

 * bit[9]	LAST_ADATA

 * bit[8]	LAST_GCX

 * bit[7:2]	Reserved

 * bit[1]	TERMINATION

 * bit[0]	TRIGGER

/*

 * There is an inconsistency in the documentation. This is documented as a

 * 11-bit value, but it is actually 10-bits.

/*

 * During CCM decrypt, the OCS block needs to finish processing the ciphertext

 * before the tag is written. For 128-bit mode this required delay is 28 OCS

 * clock cycles. For 256-bit mode it is 36 OCS clock cycles.

/*

 * During CCM decrypt there must be a delay of at least 42 OCS clock cycles

 * between setting the TRIGGER bit in AES_ACTIVE and setting the LAST_CCM_GCM

 * bit in the same register (as stated in the OCS databook)

 See RFC3610 section 2.2 */

/*

 * CCM IV format from RFC 3610 section 2.3

 *

 *   Octet Number   Contents

 *   ------------   ---------

 *   0              Flags

 *   1 ... 15-L     Nonce N

 *   16-L ... 15    Counter i

 *

 * Flags = L' = L - 1

/**

 * struct ocs_dma_linked_list - OCS DMA linked list entry.

 * @src_addr:   Source address of the data.

 * @src_len:    Length of data to be fetched.

 * @next:	Next dma_list to fetch.

 * @ll_flags:   Flags (Freeze @ terminate) for the DMA engine.

/*

 * Set endianness of inputs and outputs

 * AES_BYTE_ORDER_CFG

 * default 0x00000000

 * bit [10] - KEY_HI_LO_SWAP

 * bit [9] - KEY_HI_SWAP_DWORDS_IN_OCTWORD

 * bit [8] - KEY_HI_SWAP_BYTES_IN_DWORD

 * bit [7] - KEY_LO_SWAP_DWORDS_IN_OCTWORD

 * bit [6] - KEY_LO_SWAP_BYTES_IN_DWORD

 * bit [5] - IV_SWAP_DWORDS_IN_OCTWORD

 * bit [4] - IV_SWAP_BYTES_IN_DWORD

 * bit [3] - DOUT_SWAP_DWORDS_IN_OCTWORD

 * bit [2] - DOUT_SWAP_BYTES_IN_DWORD

 * bit [1] - DOUT_SWAP_DWORDS_IN_OCTWORD

 * bit [0] - DOUT_SWAP_BYTES_IN_DWORD

 Trigger AES process start. */

 Indicate last bulk of data. */

/*

 * Set LAST_CCM_GCM in AES_ACTIVE register and clear all other bits.

 *

 * Called when DMA is programmed to fetch the last batch of data.

 * - For AES-CCM it is called for the last batch of Payload data and Ciphertext

 *   data.

 * - For AES-GCM, it is called for the last batch of Plaintext data and

 *   Ciphertext data.

 Wait for LAST_CCM_GCM bit to be unset. */

 Wait for 10 bits of input occupancy. */

 /*

  * Set LAST_CCM_GCM and LAST_ADATA bits in AES_ACTIVE register (and clear all

  * other bits).

  *

  * Called when DMA is programmed to fetch the last batch of Associated Data

  * (CCM case) or Additional Authenticated Data (GCM case).

 Set DMA src and dst transfer size to 0 */

 Activate DMA for zero-byte transfer case. */

 Activate DMA and enable src linked list */

 Activate DMA and enable dst linked list */

 Activate DMA and enable src and dst linked lists */

 Reset PERF_CNTR to 0 and activate it */

 Wait until PERF_CNTR is > delay, then deactivate it */

 Disable AES and DMA IRQ. */

 Disable interrupts */

 Clear any pending interrupt */

 Enable AES or DMA IRQ.  IRQ is disabled once fired. */

 Ensure DMA error interrupts are enabled */

		/*

		 * AES_IER

		 * default 0x00000000

		 * bits [31:3] - reserved

		 * bit [2] - EN_SKS_ERR

		 * bit [1] - EN_AES_COMPLETE

		 * bit [0] - reserved

 Ensure AES interrupts are disabled */

		/*

		 * DMA_MSI_IER

		 * default 0x00000000

		 * bits [31:9] - reserved

		 * bit [8] - CPD_ERR_INT_EN

		 * bit [7] - OUTBUF_RD_ERR_INT_EN

		 * bit [6] - OUTBUF_WR_ERR_INT_EN

		 * bit [5] - INBUF_RD_ERR_INT_EN

		 * bit [4] - INBUF_WR_ERR_INT_EN

		 * bit [3] - BAD_COMP_INT_EN

		 * bit [2] - SAI_INT_EN

		 * bit [1] - DST_DONE_INT_EN

		 * bit [0] - SRC_DONE_INT_EN

 Enable and wait for IRQ (either from OCS AES engine or DMA) */

 Configure DMA to OCS, linked list mode */

 Configure DMA from OCS, linked list mode */

 Read DMA ISR status. */

 Disable and clear interrupts. */

 Save DMA error status. */

 Signal IRQ completion. */

/**

 * ocs_aes_set_key() - Write key into OCS AES hardware.

 * @aes_dev:	The OCS AES device to write the key to.

 * @key_size:	The size of the key (in bytes).

 * @key:	The key to write.

 * @cipher:	The cipher the key is for.

 *

 * For AES @key_size must be either 16 or 32. For SM4 @key_size must be 16.

 *

 * Return:	0 on success, negative error code otherwise.

 OCS AES supports 128-bit and 256-bit keys only. */

 OCS SM4 supports 128-bit keys only. */

 Write key to AES_KEY[0-7] registers */

	/*

	 * Write key size

	 * bits [31:1] - reserved

	 * bit [0] - AES_KEY_SIZE

	 *           0 - 128 bit key

	 *           1 - 256 bit key

 Write AES_COMMAND */

	/* AES_COMMAND

	 * default 0x000000CC

	 * bit [14] - CIPHER_SELECT

	 *            0 - AES

	 *            1 - SM4

	 * bits [11:8] - OCS_AES_MODE

	 *               0000 - ECB

	 *               0001 - CBC

	 *               0010 - CTR

	 *               0110 - CCM

	 *               0111 - GCM

	 *               1001 - CTS

	 * bits [7:6] - AES_INSTRUCTION

	 *              00 - ENCRYPT

	 *              01 - DECRYPT

	 *              10 - EXPAND

	 *              11 - BYPASS

	 * bits [3:2] - CTR_M_BITS

	 *              00 - No increment

	 *              01 - Least significant 32 bits are incremented

	 *              10 - Least significant 64 bits are incremented

	 *              11 - Full 128 bits are incremented

 Ensure interrupts are disabled and pending interrupts cleared. */

 Set endianness recommended by data-sheet. */

 Set AES_COMMAND register. */

/*

 * Write the byte length of the last AES/SM4 block of Payload data (without

 * zero padding and without the length of the MAC) in register AES_PLEN.

/*

 * Validate inputs according to mode.

 * If OK return 0; else return -EINVAL.

 Ensure cipher, mode and instruction are valid. */

	/*

	 * When instruction is OCS_BYPASS, OCS simply copies data from source

	 * to destination using DMA.

	 *

	 * AES mode is irrelevant, but both source and destination DMA

	 * linked-list must be defined.

	/*

	 * For performance reasons switch based on mode to limit unnecessary

	 * conditionals for each mode

 Ensure input length is multiple of block size */

 Ensure source and destination linked lists are created */

 Ensure input length is multiple of block size */

 Ensure source and destination linked lists are created */

 Ensure IV is present and block size in length */

 Ensure input length of 1 byte or greater */

 Ensure source and destination linked lists are created */

 Ensure IV is present and block size in length */

 Ensure input length >= block size */

 Ensure source and destination linked lists are created */

 Ensure IV is present and block size in length */

 Ensure IV is present and GCM_AES_IV_SIZE in length */

		/*

		 * If input data present ensure source and destination linked

		 * lists are created

 If aad present ensure aad linked list is created */

 Ensure tag destination is set */

 Just ensure that tag_size doesn't cause overflows. */

 Ensure IV is present and block size in length */

 2 <= L <= 8, so 1 <= L' <= 7 */

 If aad present ensure aad linked list is created */

 Just ensure that tag_size doesn't cause overflows. */

			/*

			 * If input data present ensure source and destination

			 * linked lists are created

 Ensure input tag is present */

 Instruction == OCS_ENCRYPT */

		/*

		 * Destination linked list always required (for tag even if no

		 * input data)

 If input data present ensure src linked list is created */

/**

 * ocs_aes_op() - Perform AES/SM4 operation.

 * @aes_dev:		The OCS AES device to use.

 * @mode:		The mode to use (ECB, CBC, CTR, or CTS).

 * @cipher:		The cipher to use (AES or SM4).

 * @instruction:	The instruction to perform (encrypt or decrypt).

 * @dst_dma_list:	The OCS DMA list mapping output memory.

 * @src_dma_list:	The OCS DMA list mapping input payload data.

 * @src_size:		The amount of data mapped by @src_dma_list.

 * @iv:			The IV vector.

 * @iv_size:		The size (in bytes) of @iv.

 *

 * Return: 0 on success, negative error code otherwise.

	/*

	 * ocs_aes_validate_inputs() is a generic check, now ensure mode is not

	 * GCM or CCM.

 Cast IV to u32 array. */

 Write the byte length of the last data block to engine. */

 ECB is the only mode that doesn't use IV. */

 Set AES_ACTIVE.TRIGGER to start the operation. */

 Configure and activate input / output DMA. */

		/*

		 * For CTS mode, instruct engine to activate ciphertext

		 * stealing if last block of data is incomplete.

 For all other modes, just write the 'termination' bit. */

 Wait for engine to complete processing. */

 Read back IV for streaming mode */

 Compute and write J0 to engine registers. */

	/*

	 * IV must be 12 bytes; Other sizes not supported as Linux crypto API

	 * does only expects/allows 12 byte IV for GCM

 Read GCM tag from engine registers. */

	/*

	 * The Authentication Tag T is stored in Little Endian order in the

	 * registers with the most significant bytes stored from AES_T_MAC[3]

	 * downward.

/**

 * ocs_aes_gcm_op() - Perform GCM operation.

 * @aes_dev:		The OCS AES device to use.

 * @cipher:		The Cipher to use (AES or SM4).

 * @instruction:	The instruction to perform (encrypt or decrypt).

 * @dst_dma_list:	The OCS DMA list mapping output memory.

 * @src_dma_list:	The OCS DMA list mapping input payload data.

 * @src_size:		The amount of data mapped by @src_dma_list.

 * @iv:			The input IV vector.

 * @aad_dma_list:	The OCS DMA list mapping input AAD data.

 * @aad_size:		The amount of data mapped by @aad_dma_list.

 * @out_tag:		Where to store computed tag.

 * @tag_size:		The size (in bytes) of @out_tag.

 *

 * Return: 0 on success, negative error code otherwise.

 Compute and write J0 to OCS HW. */

 Write out_tag byte length */

 Write the byte length of the last plaintext / ciphertext block. */

 Write ciphertext bit length */

 Write aad bit length */

 Set AES_ACTIVE.TRIGGER to start the operation. */

 Process AAD. */

 If aad present, configure DMA to feed it to the engine. */

 Instructs engine to pad last block of aad, if needed. */

 Wait for DMA transfer to complete. */

 Wait until adata (if present) has been processed. */

 Now process payload. */

 Configure and activate DMA for both input and output data. */

 Instruct AES/SMA4 engine payload processing is over. */

 Wait for OCS AES engine to complete processing. */

 Write encrypted tag to AES/SM4 engine. */

 Ensure DMA input buffer is empty */

	/*

	 * During CCM decrypt, the OCS block needs to finish processing the

	 * ciphertext before the tag is written.  So delay needed after DMA has

	 * completed writing the ciphertext

 Write encrypted tag to AES/SM4 engine. */

/*

 * Write B0 CCM block to OCS AES HW.

 *

 * Note: B0 format is documented in NIST Special Publication 800-38C

 * https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38c.pdf

 * (see Section A.2.1)

 CCM B0 block is 16 bytes long. */

 Initialize B0 to 0. */

	/*

	 * B0[0] is the 'Flags Octet' and has the following structure:

	 *   bit 7: Reserved

	 *   bit 6: Adata flag

	 *   bit 5-3: t value encoded as (t-2)/2

	 *   bit 2-0: q value encoded as q - 1

 If there is AAD data, set the Adata flag. */

	/*

	 * t denotes the octet length of T.

	 * t can only be an element of { 4, 6, 8, 10, 12, 14, 16} and is

	 * encoded as (t - 2) / 2

	/*

	 * q is the octet length of Q.

	 * q can only be an element of {2, 3, 4, 5, 6, 7, 8} and is encoded as

	 * q - 1 == iv[0] & 0x7;

	/*

	 * Copy the Nonce N from IV to B0; N is located in iv[1]..iv[15 - q]

	 * and must be copied to b0[1]..b0[15-q].

	 * q == (iv[0] & 0x7) + 1

	/*

	 * The rest of B0 must contain Q, i.e., the message length.

	 * Q is encoded in q octets, in big-endian order, so to write it, we

	 * start from the end of B0 and we move backward.

	/*

	 * If cryptlen is not zero at this point, it means that its original

	 * value was too big.

 Now write B0 to OCS AES input buffer. */

/*

 * Write adata length to OCS AES HW.

 *

 * Note: adata len encoding is documented in NIST Special Publication 800-38C

 * https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38c.pdf

 * (see Section A.2.2)

 Maximum encoded size: 10 octets. */

	/*

	 * adata_len ('a') is encoded as follows:

	 * If 0 < a < 2^16 - 2^8    ==> 'a' encoded as [a]16, i.e., two octets

	 *				(big endian).

	 * If 2^16 - 2^8 ≤ a < 2^32 ==> 'a' encoded as 0xff || 0xfe || [a]32,

	 *				i.e., six octets (big endian).

	 * If 2^32 ≤ a < 2^64       ==> 'a' encoded as 0xff || 0xff || [a]64,

	 *				i.e., ten octets (big endian).

 adata_len >= 2^32 */

 Since no aad the LAST_GCX bit can be set now */

 Adata case. */

	/*

	 * Form the encoding of the Associated data length and write it

	 * to the AES/SM4 input buffer.

 Configure the AES/SM4 DMA to fetch the Associated Data */

 Activate DMA to fetch Associated data. */

 Set LAST_GCX and LAST_ADATA in AES ACTIVE register. */

 Wait for DMA transfer to complete. */

 Wait until adata (if present) has been processed. */

		/*

		 * Configure and activate DMA for both input and output

		 * data.

 Configure and activate DMA for output data only. */

	/*

	 * Set the LAST GCX bit in AES_ACTIVE Register to instruct

	 * AES/SM4 engine to pad the last block of data.

 We are done, wait for IRQ and return. */

 Let engine process 0-length input. */

	/*

	 * Configure and activate DMA for both input and output

	 * data.

	/*

	 * Set the LAST GCX bit in AES_ACTIVE Register; this allows the

	 * AES/SM4 engine to differentiate between encrypted data and

	 * encrypted MAC.

	 /*

	  * Enable DMA DONE interrupt; once DMA transfer is over,

	  * interrupt handler will process the MAC/tag.

/*

 * Compare Tag to Yr.

 *

 * Only used at the end of CCM decrypt. If tag == yr, message authentication

 * has succeeded.

 Read Tag and Yr from AES registers. */

/**

 * ocs_aes_ccm_op() - Perform CCM operation.

 * @aes_dev:		The OCS AES device to use.

 * @cipher:		The Cipher to use (AES or SM4).

 * @instruction:	The instruction to perform (encrypt or decrypt).

 * @dst_dma_list:	The OCS DMA list mapping output memory.

 * @src_dma_list:	The OCS DMA list mapping input payload data.

 * @src_size:		The amount of data mapped by @src_dma_list.

 * @iv:			The input IV vector.

 * @adata_dma_list:	The OCS DMA list mapping input A-data.

 * @adata_size:		The amount of data mapped by @adata_dma_list.

 * @in_tag:		Input tag.

 * @tag_size:		The size (in bytes) of @in_tag.

 *

 * Note: for encrypt the tag is appended to the ciphertext (in the memory

 *	 mapped by @dst_dma_list).

 *

 * Return: 0 on success, negative error code otherwise.

	/*

	 * Note: rfc 3610 and NIST 800-38C require counter of zero to encrypt

	 * auth tag so ensure this is the case

	/*

	 * Nonce is already converted to ctr0 before being passed into this

	 * function as iv.

 Write MAC/tag length in register AES_TLEN */

	/*

	 * Write the byte length of the last AES/SM4 block of Payload data

	 * (without zero padding and without the length of the MAC) in register

	 * AES_PLEN.

 Set AES_ACTIVE.TRIGGER to start the operation. */

 Form block B0 and write it to the AES/SM4 input buffer. */

	/*

	 * Ensure there has been at least CCM_DECRYPT_DELAY_LAST_GCX_CLK_COUNT

	 * clock cycles since TRIGGER bit was set

 Process Adata. */

 For Encrypt case we just process the payload and return. */

 For Decypt we need to process the payload and then the tag. */

 Process MAC/tag directly: feed tag to engine and wait for IRQ. */

/**

 * ocs_create_linked_list_from_sg() - Create OCS DMA linked list from SG list.

 * @aes_dev:	  The OCS AES device the list will be created for.

 * @sg:		  The SG list OCS DMA linked list will be created from. When

 *		  passed to this function, @sg must have been already mapped

 *		  with dma_map_sg().

 * @sg_dma_count: The number of DMA-mapped entries in @sg. This must be the

 *		  value returned by dma_map_sg() when @sg was mapped.

 * @dll_desc:	  The OCS DMA dma_list to use to store information about the

 *		  created linked list.

 * @data_size:	  The size of the data (from the SG list) to be mapped into the

 *		  OCS DMA linked list.

 * @data_offset:  The offset (within the SG list) of the data to be mapped.

 *

 * Return:	0 on success, negative error code otherwise.

 Default values for when no ddl_desc is created. */

 Loop over sg_list until we reach entry at specified offset. */

 If we reach the end of the list, offset was invalid. */

 Compute number of DMA-mapped SG entries to add into OCS DMA list. */

 If we reach the end of the list, data_size was invalid. */

 Allocate the DMA list, one entry for each SG entry. */

 Populate DMA linked list entries. */

 Current element points to the DMA address of the next one. */

 Terminate last element. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Keem Bay OCS HCU Crypto Driver.

 *

 * Copyright (C) 2018-2020 Intel Corporation

 Registers. */

 Register bit definitions. */

/*

 * While polling on a busy HCU, wait maximum 200us between one check and the

 * other.

 Wait on a busy HCU for maximum 1 second. */

/**

 * struct ocs_hcu_dma_entry - An entry in an OCS DMA linked list.

 * @src_addr:  Source address of the data.

 * @src_len:   Length of data to be fetched.

 * @nxt_desc:  Next descriptor to fetch.

 * @ll_flags:  Flags (Freeze @ terminate) for the DMA engine.

/**

 * struct ocs_hcu_dma_list - OCS-specific DMA linked list.

 * @head:	The head of the list (points to the array backing the list).

 * @tail:	The current tail of the list; NULL if the list is empty.

 * @dma_addr:	The DMA address of @head (i.e., the DMA address of the backing

 *		array).

 * @max_nents:	Maximum number of entries in the list (i.e., number of elements

 *		in the backing array).

 *

 * The OCS DMA list is an array-backed list of OCS DMA descriptors. The array

 * backing the list is allocated with dma_alloc_coherent() and pointed by

 * @head.

 SM3 shares the same block size. */

/**

 * ocs_hcu_wait_busy() - Wait for HCU OCS hardware to became usable.

 * @hcu_dev:	OCS HCU device to wait for.

 *

 * Return: 0 if device free, -ETIMEOUT if device busy and internal timeout has

 *	   expired.

 Clear any pending interrupts. */

 Enable error and HCU done interrupts. */

 Clear any pending interrupts. */

 Only operating on DMA source completion and error interrupts. */

 Unmask */

 Unset flag and return error. */

/**

 * ocs_hcu_get_intermediate_data() - Get intermediate data.

 * @hcu_dev:	The target HCU device.

 * @data:	Where to store the intermediate.

 * @algo:	The algorithm being used.

 *

 * This function is used to save the current hashing process state in order to

 * continue it in the future.

 *

 * Note: once all data has been processed, the intermediate data actually

 * contains the hashing result. So this function is also used to retrieve the

 * final result of a hashing process.

 *

 * Return: 0 on success, negative error code otherwise.

 Data not requested. */

 Ensure that the OCS is no longer busy before reading the chains. */

	/*

	 * This loops is safe because data->digest is an array of

	 * SHA512_DIGEST_SIZE bytes and the maximum value returned by

	 * ocs_hcu_num_chains() is OCS_HCU_NUM_CHAINS_SHA384_512 which is equal

	 * to SHA512_DIGEST_SIZE / sizeof(u32).

/**

 * ocs_hcu_set_intermediate_data() - Set intermediate data.

 * @hcu_dev:	The target HCU device.

 * @data:	The intermediate data to be set.

 * @algo:	The algorithm being used.

 *

 * This function is used to continue a previous hashing process.

	/*

	 * This loops is safe because data->digest is an array of

	 * SHA512_DIGEST_SIZE bytes and the maximum value returned by

	 * ocs_hcu_num_chains() is OCS_HCU_NUM_CHAINS_SHA384_512 which is equal

	 * to SHA512_DIGEST_SIZE / sizeof(u32).

 Length of the output buffer must match the algo digest size. */

 Ensure that the OCS is no longer busy before reading the chains. */

/**

 * ocs_hcu_hw_cfg() - Configure the HCU hardware.

 * @hcu_dev:	The HCU device to configure.

 * @algo:	The algorithm to be used by the HCU device.

 * @use_hmac:	Whether or not HW HMAC should be used.

 *

 * Return: 0 on success, negative error code otherwise.

 Ensure interrupts are disabled. */

 Configure endianness, hashing algorithm and HW HMAC (if needed) */

/**

 * ocs_hcu_clear_key() - Clear key stored in OCS HMAC KEY registers.

 * @hcu_dev:	The OCS HCU device whose key registers should be cleared.

 Clear OCS_HCU_KEY_[0..15] */

/**

 * ocs_hcu_write_key() - Write key to OCS HMAC KEY registers.

 * @hcu_dev:	The OCS HCU device the key should be written to.

 * @key:	The key to be written.

 * @len:	The size of the key to write. It must be OCS_HCU_HW_KEY_LEN.

 *

 * Return:	0 on success, negative error code otherwise.

 Copy key into temporary u32 array. */

	/*

	 * Hardware requires all the bytes of the HW Key vector to be

	 * written. So pad with zero until we reach OCS_HCU_HW_KEY_LEN.

	/*

	 * OCS hardware expects the MSB of the key to be written at the highest

	 * address of the HCU Key vector; in other word, the key must be

	 * written in reverse order.

	 *

	 * Therefore, we first enable byte swapping for the HCU key vector;

	 * so that bytes of 32-bit word written to OCS_HCU_KEY_[0..15] will be

	 * swapped:

	 * 3 <---> 0, 2 <---> 1.

	/*

	 * And then we write the 32-bit words composing the key starting from

	 * the end of the key.

/**

 * ocs_hcu_ll_dma_start() - Start OCS HCU hashing via DMA

 * @hcu_dev:	The OCS HCU device to use.

 * @dma_list:	The OCS DMA list mapping the data to hash.

 * @finalize:	Whether or not this is the last hashing operation and therefore

 *		the final hash should be compute even if data is not

 *		block-aligned.

 *

 * Return: 0 on success, negative error code otherwise.

	/*

	 * For final requests we use HCU_DONE IRQ to be notified when all input

	 * data has been processed by the HCU; however, we cannot do so for

	 * non-final requests, because we don't get a HCU_DONE IRQ when we

	 * don't terminate the operation.

	 *

	 * Therefore, for non-final requests, we use the DMA IRQ, which

	 * triggers when DMA has finishing feeding all the input data to the

	 * HCU, but the HCU may still be processing it. This is fine, since we

	 * will wait for the HCU processing to be completed when we try to read

	 * intermediate results, in ocs_hcu_get_intermediate_data().

 Total size of the DMA list to allocate. */

 Add a new DMA entry at the end of the OCS DMA list. */

 Check if list is full. */

	/*

	 * If there was an old tail (i.e., this is not the first element we are

	 * adding), un-terminate the old tail and make it point to the new one.

		/*

		 * The old tail 'nxt_desc' must point to the DMA address of the

		 * new tail.

 Update list tail with new tail. */

/**

 * ocs_hcu_hash_init() - Initialize hash operation context.

 * @ctx:	The context to initialize.

 * @algo:	The hashing algorithm to use.

 *

 * Return:	0 on success, negative error code otherwise.

 No need to set idata.digest to 0. */

/**

 * ocs_hcu_hash_update() - Perform a hashing iteration.

 * @hcu_dev:	The OCS HCU device to use.

 * @ctx:	The OCS HCU hashing context.

 * @dma_list:	The OCS DMA list mapping the input data to process.

 *

 * Return: 0 on success; negative error code otherwise.

 Configure the hardware for the current request. */

 If we already processed some data, idata needs to be set. */

 Start linked-list DMA hashing. */

 Update idata and return. */

/**

 * ocs_hcu_hash_finup() - Update and finalize hash computation.

 * @hcu_dev:	The OCS HCU device to use.

 * @ctx:	The OCS HCU hashing context.

 * @dma_list:	The OCS DMA list mapping the input data to process.

 * @dgst:	The buffer where to save the computed digest.

 * @dgst_len:	The length of @dgst.

 *

 * Return: 0 on success; negative error code otherwise.

 Configure the hardware for the current request. */

 If we already processed some data, idata needs to be set. */

 Start linked-list DMA hashing. */

 Get digest and return. */

/**

 * ocs_hcu_hash_final() - Finalize hash computation.

 * @hcu_dev:		The OCS HCU device to use.

 * @ctx:		The OCS HCU hashing context.

 * @dgst:		The buffer where to save the computed digest.

 * @dgst_len:		The length of @dgst.

 *

 * Return: 0 on success; negative error code otherwise.

 Configure the hardware for the current request. */

 If we already processed some data, idata needs to be set. */

	/*

	 * Enable HCU interrupts, so that HCU_DONE will be triggered once the

	 * final hash is computed.

 Get digest and return. */

/**

 * ocs_hcu_digest() - Compute hash digest.

 * @hcu_dev:		The OCS HCU device to use.

 * @algo:		The hash algorithm to use.

 * @data:		The input data to process.

 * @data_len:		The length of @data.

 * @dgst:		The buffer where to save the computed digest.

 * @dgst_len:		The length of @dgst.

 *

 * Return: 0 on success; negative error code otherwise.

 Configure the hardware for the current request. */

/**

 * ocs_hcu_hmac() - Compute HMAC.

 * @hcu_dev:		The OCS HCU device to use.

 * @algo:		The hash algorithm to use with HMAC.

 * @key:		The key to use.

 * @dma_list:	The OCS DMA list mapping the input data to process.

 * @key_len:		The length of @key.

 * @dgst:		The buffer where to save the computed HMAC.

 * @dgst_len:		The length of @dgst.

 *

 * Return: 0 on success; negative error code otherwise.

 Ensure 'key' is not NULL. */

 Configure the hardware for the current request. */

 Clear HW key before processing return code. */

 Read and clear the HCU interrupt. */

 Read and clear the HCU DMA interrupt. */

 Check for errors. */

 Check for DONE IRQs. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel Keem Bay OCS HCU Crypto Driver.

 *

 * Copyright (C) 2018-2020 Intel Corporation

 Flag marking a final request. */

 Flag marking a HMAC request. */

 Flag set when HW HMAC is being used. */

 Flag set when SW HMAC is being used. */

/**

 * struct ocs_hcu_ctx: OCS HCU Transform context.

 * @engine_ctx:	 Crypto Engine context.

 * @hcu_dev:	 The OCS HCU device used by the transformation.

 * @key:	 The key (used only for HMAC transformations).

 * @key_len:	 The length of the key.

 * @is_sm3_tfm:  Whether or not this is an SM3 transformation.

 * @is_hmac_tfm: Whether or not this is a HMAC transformation.

/**

 * struct ocs_hcu_rctx - Context for the request.

 * @hcu_dev:	    OCS HCU device to be used to service the request.

 * @flags:	    Flags tracking request status.

 * @algo:	    Algorithm to use for the request.

 * @blk_sz:	    Block size of the transformation / request.

 * @dig_sz:	    Digest size of the transformation / request.

 * @dma_list:	    OCS DMA linked list.

 * @hash_ctx:	    OCS HCU hashing context.

 * @buffer:	    Buffer to store: partial block of data and SW HMAC

 *		    artifacts (ipad, opad, etc.).

 * @buf_cnt:	    Number of bytes currently stored in the buffer.

 * @buf_dma_addr:   The DMA address of @buffer (when mapped).

 * @buf_dma_count:  The number of bytes in @buffer currently DMA-mapped.

 * @sg:		    Head of the scatterlist entries containing data.

 * @sg_data_total:  Total data in the SG list at any time.

 * @sg_data_offset: Offset into the data of the current individual SG node.

 * @sg_dma_nents:   Number of sg entries mapped in dma_list.

	/*

	 * Buffer is double the block size because we need space for SW HMAC

	 * artifacts, i.e:

	 * - ipad (1 block) + a possible partial block of data.

	 * - opad (1 block) + digest of H(k ^ ipad || m)

/**

 * struct ocs_hcu_drv - Driver data

 * @dev_list:	The list of HCU devices.

 * @lock:	The lock protecting dev_list.

 Protects dev_list. */

/*

 * Return the total amount of data in the request; that is: the data in the

 * request buffer + the data in the sg list.

 Move remaining content of scatter-gather list to context buffer. */

		/*

		 * If current sg has been fully processed, skip to the next

		 * one.

		/*

		 * Determine the maximum data available to copy from the node.

		 * Minimum of the length left in the sg node, or the total data

		 * in the request.

 Copy from scatter-list entry to context buffer. */

 If the HCU device for the request was previously set, return it. */

	/*

	 * Otherwise, get the first HCU device available (there should be one

	 * and only one device).

 Free OCS DMA linked list and DMA-able context buffer. */

 Unmap rctx->buffer (if mapped). */

 Unmap req->src (if mapped). */

 Free dma_list (if allocated). */

/*

 * Prepare for DMA operation:

 * - DMA-map request context buffer (if needed)

 * - DMA-map SG list (only the entries to be processed, see note below)

 * - Allocate OCS HCU DMA linked list (number of elements =  SG entries to

 *   process + context buffer (if not empty)).

 * - Add DMA-mapped request context buffer to OCS HCU DMA list.

 * - Add SG entries to DMA list.

 *

 * Note: if this is a final request, we process all the data in the SG list,

 * otherwise we can only process up to the maximum amount of block-aligned data

 * (the remainder will be put into the context buffer and processed in the next

 * request).

 This function should be called only when there is data to process. */

	/*

	 * If this is not a final DMA (terminated DMA), the data passed to the

	 * HCU must be aligned to the block size; compute the remainder data to

	 * be processed in the next request.

 Determine the number of scatter gather list entries to process. */

 If there are entries to process, map them. */

		/*

		 * The value returned by dma_map_sg() can be < nents; so update

		 * nents accordingly.

	/*

	 * If context buffer is not empty, map it and add extra DMA entry for

	 * it.

 Increase number of dma entries. */

 Allocate OCS HCU DMA list. */

 Add request context buffer (if previously DMA-mapped) */

 Add the SG nodes to be processed to the DMA linked list. */

		/*

		 * The number of bytes to add to the list entry is the minimum

		 * between:

		 * - The DMA length of the SG entry.

		 * - The data left to be processed.

		/*

		 * Do not create a zero length DMA descriptor. Check in case of

		 * zero length SG node.

 Add sg to HCU DMA list. */

 Update amount of data remaining in SG list. */

		/*

		 * If  remaining data is equal to remainder (note: 'less than'

		 * case should never happen in practice), we are done: update

		 * offset and exit the loop.

		/*

		 * If we get here is because we need to process the next sg in

		 * the list; set offset within the sg to 0.

 Clear buffer of any data. */

	/*

	 * Key length must be equal to block size. If key is shorter,

	 * we pad it with zero (note: key cannot be longer, since

	 * longer keys are hashed by kmb_ocs_hcu_setkey()).

	/*

	 * Prepare IPAD for HMAC. Only done for first block.

	 * HMAC(k,m) = H(k ^ opad || H(k ^ ipad || m))

	 * k ^ ipad will be first hashed block.

	 * k ^ opad will be calculated in the final request.

	 * Only needed if not using HW HMAC.

	/*

	 * If hardware HMAC flag is set, perform HMAC in hardware.

	 *

	 * NOTE: this flag implies REQ_FINAL && kmb_get_total_data(rctx)

 Map input data into the HCU DMA linked list. */

 Unmap data and free DMA list regardless of return code. */

 Process previous return code. */

 Handle update request case. */

 Update should always have input data. */

 Map input data into the HCU DMA linked list. */

 Do hashing step. */

 Unmap data and free DMA list regardless of return code. */

 Process previous return code. */

		/*

		 * Reset request buffer count (data in the buffer was just

		 * processed).

		/*

		 * Move remaining sg data into the request buffer, so that it

		 * will be processed during the next request.

		 *

		 * NOTE: we have remaining data if kmb_get_total_data() was not

		 * a multiple of block size.

 If we get here, this is a final request. */

 If there is data to process, use finup. */

 Map input data into the HCU DMA linked list. */

 Do hashing step. */

 Free DMA list regardless of return code. */

 Process previous return code. */

 Otherwise (if we have no data), use final. */

	/*

	 * If we are finalizing a SW HMAC request, we just computed the result

	 * of: H(k ^ ipad || m).

	 *

	 * We now need to complete the HMAC calculation with the OPAD step,

	 * that is, we need to compute H(k ^ opad || digest), where digest is

	 * the digest we just obtained, i.e., H(k ^ ipad || m).

		/*

		 * Compute k ^ opad and store it in the request buffer (which

		 * is not used anymore at this point).

		 * Note: key has been padded / hashed already (so keylen ==

		 * blksz) .

 Now append the digest to the rest of the buffer. */

 Now hash the buffer to obtain the final HMAC. */

 Perform secure clean-up. */

 Initialize entire request context to zero. */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_HCU_HMAC_SHA224 */

		/*

		 * SHA256 and SM3 have the same digest size: use info from tfm

		 * context to find out which one we should use.

 Initialize intermediate data. */

 If this a HMAC request, set HMAC flag. */

	/*

	 * If we are doing HMAC, then we must use SW-assisted HMAC, since HW

	 * HMAC does not support context switching (there it can only be used

	 * with finup() or digest()).

	/*

	 * If remaining sg_data fits into ctx buffer, just copy it there; we'll

	 * process it at the next update() or final().

 Common logic for kmb_ocs_hcu_final() and kmb_ocs_hcu_finup(). */

	/*

	 * If this is a HMAC request and, so far, we didn't have to switch to

	 * SW HMAC, check if we can use HW HMAC.

		/*

		 * If we are here, it means we never processed any data so far,

		 * so we can use HW HMAC, but only if there is some data to

		 * process (since OCS HW MAC does not support zero-length

		 * messages) and the key length is supported by the hardware

		 * (OCS HCU HW only supports length <= 64); if HW HMAC cannot

		 * be used, fall back to SW-assisted HMAC.

 Intermediate data is always stored and applied per request. */

 Intermediate data is always stored and applied per request. */

	/*

	 * Key length must be equal to block size:

	 * - If key is shorter, we are done for now (the key will be padded

	 *   later on); this is to maximize the use of HW HMAC (which works

	 *   only for keys <= 64 bytes).

	 * - If key is longer, we hash it.

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_HCU_HMAC_SHA224 */

 Set request size and initialize tfm context. */

 Init context to 0. */

 Set engine ops. */

 Function called when 'tfm' is de-initialized. */

 Clear the key. */

 CONFIG_CRYPTO_DEV_KEEMBAY_OCS_HCU_HMAC_SHA224 */

 Device tree driver match. */

 Get the memory address and remap. */

 Get and request IRQ. */

 Initialize crypto engine */

 Security infrastructure guarantees OCS clock is enabled. */

 The OCS driver is a platform device. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cryptographic API.

 * Support for Nomadik hardware crypto engine.



 * Copyright (C) ST-Ericsson SA 2010

 * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson

 * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson

 * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.

 * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.

 * Author: Andreas Westin <andreas.westin@stericsson.com> for ST-Ericsson.

 HMAC-SHA1, no key */

 HMAC-SHA256, no key */

/**

 * struct hash_driver_data - data specific to the driver.

 *

 * @device_list:	A list of registered devices to choose from.

 * @device_allocation:	A semaphore initialized with number of devices.

 Declaration of functions */

/**

 * hash_messagepad - Pads a message and write the nblw bits.

 * @device_data:	Structure for the hash device.

 * @message:		Last word of a message

 * @index_bytes:	The number of bytes in the last message

 *

 * This function manages the final part of the digest calculation, when less

 * than 512 bits (64 bytes) remain in message. This means index_bytes < 64.

 *

/**

 * release_hash_device - Releases a previously allocated hash device.

 * @device_data:	Structure for the hash device.

 *

	/*

	 * The down_interruptible part for this semaphore is called in

	 * cryp_get_device_data.

/**

 * get_empty_message_digest - Returns a pre-calculated digest for

 * the empty message.

 * @device_data:	Structure for the hash device.

 * @zero_hash:		Buffer to return the empty message digest.

 * @zero_hash_size:	Hash size of the empty message digest.

 * @zero_digest:	True if zero_digest returned.

	/**

	 * Caller responsible for ctx != NULL.

/**

 * hash_disable_power - Request to disable power and clock.

 * @device_data:	Structure for the hash device.

 * @save_device_state:	If true, saves the current hw state.

 *

 * This function request for disabling power (regulator) and clock,

 * and could also save current hw state.

/**

 * hash_enable_power - Request to enable power and clock.

 * @device_data:		Structure for the hash device.

 * @restore_device_state:	If true, restores a previous saved hw state.

 *

 * This function request for enabling power (regulator) and clock,

 * and could also restore a previously saved hw state.

/**

 * hash_get_device_data - Checks for an available hash device and return it.

 * @ctx:		Structure for the hash context.

 * @device_data:	Structure for the hash device.

 *

 * This function check for an available hash device and return it to

 * the caller.

 * Note! Caller need to release the device, calling up().

 Wait until a device is available */

 Interrupted */

 Select a device */

 current_ctx allocates a device, NULL = unallocated */

		/**

		 * No free device found.

		 * Since we allocated a device with down_interruptible, this

		 * should not be able to happen.

		 * Number of available devices, which are contained in

		 * device_allocation, is therefore decremented by not doing

		 * an up(device_allocation).

/**

 * hash_hw_write_key - Writes the key to the hardware registries.

 *

 * @device_data:	Structure for the hash device.

 * @key:		Key to be written.

 * @keylen:		The lengt of the key.

 *

 * Note! This function DOES NOT write to the NBLW registry, even though

 * specified in the the hw design spec. Either due to incorrect info in the

 * spec or due to a bug in the hw.

 Take care of the remaining bytes in the last word */

/**

 * init_hash_hw - Initialise the hash hardware for a new calculation.

 * @device_data:	Structure for the hash device.

 * @ctx:		The hash context.

 *

 * This function will enable the bits needed to clear and start a new

 * calculation.

/**

 * hash_get_nents - Return number of entries (nents) in scatterlist (sg).

 *

 * @sg:		Scatterlist.

 * @size:	Size in bytes.

 * @aligned:	True if sg data aligned to work in DMA mode.

 *

 hash_set_dma_transfer will align last nent */

/**

 * hash_dma_valid_data - checks for dma valid sg data.

 * @sg:		Scatterlist.

 * @datasize:	Datasize in bytes.

 *

 * NOTE! This function checks for dma valid sg data, since dma

 * only accept datasizes of even wordsize.

 Need to include at least one nent, else error */

/**

 * ux500_hash_init - Common hash init function for SHA1/SHA2 (SHA256).

 * @req: The hash request for the job.

 *

 * Initialize structures.

 Don't use DMA */

/**

 * hash_processblock - This function processes a single block of 512 bits (64

 *                     bytes), word aligned, starting at message.

 * @device_data:	Structure for the hash device.

 * @message:		Block (512 bits) of message to be written to

 *			the HASH hardware.

 * @length:		Message length

 *

	/*

	 * NBLW bits. Reset the number of bits in last word (NBLW).

	/*

	 * Write message data to the HASH_DIN register.

/**

 * hash_messagepad - Pads a message and write the nblw bits.

 * @device_data:	Structure for the hash device.

 * @message:		Last word of a message.

 * @index_bytes:	The number of bytes in the last message.

 *

 * This function manages the final part of the digest calculation, when less

 * than 512 bits (64 bytes) remain in message. This means index_bytes < 64.

 *

	/*

	 * Clear hash str register, only clear NBLW

	 * since DCAL will be reset by hardware.

 Main loop */

 num_of_bytes == 0 => NBLW <- 0 (32 bits valid in DATAIN) */

/**

 * hash_incrementlength - Increments the length of the current message.

 * @ctx: Hash context

 * @incr: Length of message processed already

 *

 * Overflow cannot occur, because conditions for overflow are checked in

 * hash_hw_update.

 Check for wrap-around */

/**

 * hash_setconfiguration - Sets the required configuration for the hash

 *                         hardware.

 * @device_data:	Structure for the hash device.

 * @config:		Pointer to a configuration structure.

	/*

	 * DATAFORM bits. Set the DATAFORM bits to 0b11, which means the data

	 * to be written to HASH_DIN is considered as 32 bits.

	/*

	 * ALGO bit. Set to 0b1 for SHA-1 and 0b0 for SHA-256

	/*

	 * MODE bit. This bit selects between HASH or HMAC mode for the

	 * selected algorithm. 0b0 = HASH and 0b1 = HMAC.

 Truncate key to blocksize */

 Wrong hash mode */

/**

 * hash_begin - This routine resets some globals and initializes the hash

 *              hardware.

 * @device_data:	Structure for the hash device.

 * @ctx:		Hash context.

 HW and SW initializations */

 Note: there is no need to initialize buffer and digest members */

	/*

	 * INIT bit. Set this bit to 0b1 to reset the HASH processor core and

	 * prepare the initialize the HASH accelerator to compute the message

	 * digest of a new message.

	/*

	 * NBLW bits. Reset the number of bits in last word (NBLW).

			/*

			 * If 'data_buffer' is four byte aligned and

			 * local buffer does not have any data, we can

			 * write data directly from 'data_buffer' to

			 * HW peripheral, otherwise we first copy data

			 * to a local buffer

/**

 * hash_dma_final - The hash dma final function for SHA1/SHA256.

 * @req:	The hash request for the job.

 Enable DMA input */

 Number of bits in last word = (nbytes * 8) % 32 */

 Store the nents in the dma struct. */

	/**

	 * Allocated in setkey, and only used in HMAC.

/**

 * hash_hw_final - The final hash calculation function

 * @req:	The hash request for the job.

		/**

		 * Use a pre-calculated empty message digest

		 * (workaround since hw return zeroes, hw bug!?)

 Return error */

	/**

	 * Allocated in setkey, and only used in HMAC.

/**

 * hash_hw_update - Updates current HASH computation hashing another part of

 *                  the message.

 * @req:	Byte array containing the message to be hashed (caller

 *		allocated).

 Empty message ("") is correct indata */

	/* Check if ctx->state.length + msg_length

 Main loop */

/**

 * hash_resume_state - Function that resumes the state of an calculation.

 * @device_data:	Pointer to the device structure.

 * @device_state:	The state to be restored in the hash hardware

 Check correctness of index and length members */

	/*

	 * INIT bit. Set this bit to 0b1 to reset the HASH processor core and

	 * prepare the initialize the HASH accelerator to compute the message

	 * digest of a new message.

/**

 * hash_save_state - Function that saves the state of hardware.

 * @device_data:	Pointer to the device structure.

 * @device_state:	The strucure where the hardware state should be saved.

	/* Write dummy value to force digest intermediate calculation. This

	 * actually makes sure that there isn't any ongoing calculation in the

	 * hardware.

/**

 * hash_check_hw - This routine checks for peripheral Ids and PCell Ids.

 * @device_data:

 *

 Checking Peripheral Ids  */

/**

 * hash_get_digest - Gets the digest.

 * @device_data:	Pointer to the device structure.

 * @digest:		User allocated byte array for the calculated digest.

 * @algorithm:		The algorithm in use.

 Copy result into digest array */

/**

 * ahash_update - The hash update function for SHA1/SHA2 (SHA256).

 * @req: The hash request for the job.

 Skip update for DMA, all data will be passed to DMA in final */

/**

 * ahash_final - The hash final function for SHA1/SHA2 (SHA256).

 * @req:	The hash request for the job.

	/**

	 * Freed in final.

/**

 * ux500_hash_probe - Function that probes the hash hardware.

 * @pdev: The platform device.

 Enable power for HASH1 hardware block */

 Enable the clock for HASH1 hardware block */

 Enable device power (and clock) */

 Put the new device into the device list... */

 ... and signal that a new device is available. */

/**

 * ux500_hash_remove - Function that removes the hash device from the platform.

 * @pdev: The platform device.

 Try to decrease the number of available devices. */

 Check that the device is free */

 current_ctx allocates a device, NULL = unallocated */

 The device is busy */

 Return the device to the pool. */

 Remove the device from the list */

 If this was the last device, remove the services */

/**

 * ux500_hash_shutdown - Function that shutdown the hash device.

 * @pdev: The platform device

 Check that the device is free */

 current_ctx allocates a device, NULL = unallocated */

		/**

		 * (Allocate the device)

		 * Need to set this to non-null (dummy) value,

		 * to avoid usage if context switching.

 Remove the device from the list */

 If this was the last device, remove the services */

/**

 * ux500_hash_suspend - Function that suspends the hash device.

 * @dev:	Device to suspend.

/**

 * ux500_hash_resume - Function that resume the hash device.

 * @dev:	Device to resume.

/**

 * ux500_hash_mod_init - The kernel module init function.

 Initialize the semaphore to 0 devices (locked state) */

/**

 * ux500_hash_mod_fini - The kernel module exit function.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2010

 * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson.

 * Author: Jonas Linde <jonas.linde@stericsson.com> for ST-Ericsson.

 * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson.

 * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.

 * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2010

 * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson.

 * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson.

 * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.

 * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.

 * Author: Jonas Linde <jonas.linde@stericsson.com> for ST-Ericsson.

 * Author: Andreas Westin <andreas.westin@stericsson.com> for ST-Ericsson.

/**

 * struct cryp_driver_data - data specific to the driver.

 *

 * @device_list: A list of registered devices to choose from.

 * @device_allocation: A semaphore initialized with number of devices.

/**

 * struct cryp_ctx - Crypto context

 * @config: Crypto mode.

 * @key: Key array.

 * @keylen: Length of key.

 * @iv: Pointer to initialization vector.

 * @indata: Pointer to indata.

 * @outdata: Pointer to outdata.

 * @datalen: Length of indata.

 * @outlen: Length of outdata.

 * @blocksize: Size of blocks.

 * @updated: Updated flag.

 * @dev_ctx: Device dependent context.

 * @device: Pointer to the device.

 * @session_id: Atomic session ID.

/**

 * swap_bits_in_byte - mirror the bits in a byte

 * @b: the byte to be mirrored

 *

 * The bits are swapped the following way:

 *  Byte b include bits 0-7, nibble 1 (n1) include bits 0-3 and

 *  nibble 2 (n2) bits 4-7.

 *

 *  Nibble 1 (n1):

 *  (The "old" (moved) bit is replaced with a zero)

 *  1. Move bit 6 and 7, 4 positions to the left.

 *  2. Move bit 3 and 5, 2 positions to the left.

 *  3. Move bit 1-4, 1 position to the left.

 *

 *  Nibble 2 (n2):

 *  1. Move bit 0 and 1, 4 positions to the right.

 *  2. Move bit 2 and 4, 2 positions to the right.

 *  3. Move bit 3-6, 1 position to the right.

 *

 *  Combine the two nibbles to a complete and swapped byte.

 Bits 6 and 7, right shift 4 */

#define R_SHIFT_2_MASK  0x28 /* (After right shift 4) Bits 3 and 5,

#define R_SHIFT_1_MASK  0x1e /* (After right shift 2) Bits 1-4,

 Bits 0 and 1, left shift 4 */

#define L_SHIFT_2_MASK  0x14 /* (After left shift 4) Bits 2 and 4,

#define L_SHIFT_1_MASK  0x78 /* (After left shift 1) Bits 3-6,

 Swap most significant nibble */

 Right shift 4, bits 6 and 7 */

 Right shift 2, bits 3 and 5 */

 Right shift 1, bits 1-4 */

 Swap least significant nibble */

 Left shift 4, bits 0 and 1 */

 Left shift 2, bits 2 and 4 */

 Left shift 1, bits 3-6 */

	/*

	 * We never want 0 to be a valid value, since this is the default value

	 * for the software context.

 The device is coming from the one found in hw_crypt_noxts. */

	/*

	 * Since we loop on num_of_regs we need to have a check in case

	 * someone provides an incorrect blocksize which would force calling

	 * cfg_iv with i greater than 2 which is an error.

 Wait until a device is available */

 Interrupted */

 Select a device */

 current_ctx allocates a device, NULL = unallocated */

		/**

		 * No free device found.

		 * Since we allocated a device with down_interruptible, this

		 * should not be able to happen.

		 * Number of available devices, which are contained in

		 * device_allocation, is therefore decremented by not doing

		 * an up(device_allocation).

		/*

		 * ctx->outlen is decremented in the cryp_interrupt_handler

		 * function. We had to add cpu_relax() (barrier) to make sure

		 * that gcc didn't optimze away this variable.

		/*

		 * The reason for having DMA in this if case is that if we are

		 * running cryp_mode = 2, then we separate DMA routines for

		 * handling cipher/plaintext > blocksize, except when

		 * running the normal CRYPTO_ALG_TYPE_CIPHER, then we still use

		 * the polling mode. Overhead of doing DMA setup eats up the

		 * benefits using it.

 We have the device now, so store the nents in the dma struct. */

 Enable DMA in- and output. */

	/*

	 * The down_interruptible part for this semaphore is called in

	 * cryp_get_device_data.

 Release the device */

	/*

	 * The down_interruptible part for this semaphore is called in

	 * cryp_get_device_data.

	/*

 For everything except DMA, we run the non DMA version. */

 DMA does not work for DES due to a hw bug */

 For everything except DMA, we run the non DMA version. */

/**

 * cryp_algs_register_all -

/**

 * cryp_algs_unregister_all -

 Grab the DMA configuration from platform data. */

 Enable power for CRYP hardware block */

 Enable the clk for CRYP hardware block */

 Enable device power (and clock) */

 Put the new device into the device list... */

 ... and signal that a new device is available. */

 Try to decrease the number of available devices. */

 Check that the device is free */

 current_ctx allocates a device, NULL = unallocated */

 The device is busy */

 Return the device to the pool. */

 Remove the device from the list */

 If this was the last device, remove the services */

 Check that the device is free */

 current_ctx allocates a device, NULL = unallocated */

		/**

		 * (Allocate the device)

		 * Need to set this to non-null (dummy) value,

		 * to avoid usage if context switching.

 Remove the device from the list */

 If this was the last device, remove the services */

 Handle state? */

 Initialize the semaphore to 0 devices (locked state) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2010

 * Author: Shujuan Chen <shujuan.chen@stericsson.com> for ST-Ericsson.

 * Author: Jonas Linde <jonas.linde@stericsson.com> for ST-Ericsson.

 * Author: Niklas Hernaeus <niklas.hernaeus@stericsson.com> for ST-Ericsson.

 * Author: Joakim Bech <joakim.xx.bech@stericsson.com> for ST-Ericsson.

 * Author: Berne Hebark <berne.herbark@stericsson.com> for ST-Ericsson.

/*

 * cryp_wait_until_done - wait until the device logic is not busy

/**

 * cryp_check - This routine checks Peripheral and PCell Id

 * @device_data: Pointer to the device data struct for base address.

 Check Peripheral and Pcell Id Register for CRYP */

/**

 * cryp_activity - This routine enables/disable the cryptography function.

 * @device_data: Pointer to the device data struct for base address.

 * @cryp_crypen: Enable/Disable functionality

/**

 * cryp_flush_inoutfifo - Resets both the input and the output FIFOs

 * @device_data: Pointer to the device data struct for base address.

	/*

	 * We always need to disable the hardware before trying to flush the

	 * FIFO. This is something that isn't written in the design

	 * specification, but we have been informed by the hardware designers

	 * that this must be done.

	/*

	 * CRYP_SR_INFIFO_READY_MASK is the expected value on the status

	 * register when starting a new calculation, which means Input FIFO is

	 * not full and input FIFO is empty.

/**

 * cryp_set_configuration - This routine set the cr CRYP IP

 * @device_data: Pointer to the device data struct for base address.

 * @cryp_config: Pointer to the configuration parameter

 * @control_register: The control register to be written later on.

 Prepare key for decryption in AES_ECB and AES_CBC mode. */

		/*

		 * This seems a bit odd, but it is indeed needed to set this to

		 * encrypt even though it is a decryption that we are doing. It

		 * also mentioned in the design spec that you need to do this.

		 * After the keyprepartion for decrypting is done you should set

		 * algodir back to decryption, which is done outside this if

		 * statement.

		 *

		 * According to design specification we should set mode ECB

		 * during key preparation even though we might be running CBC

		 * when enter this function.

		 *

		 * Writing to KSE_ENABLED will drop CRYPEN when key preparation

		 * is done. Therefore we need to set CRYPEN again outside this

		 * if statement when running decryption.

/**

 * cryp_configure_protection - set the protection bits in the CRYP logic.

 * @device_data: Pointer to the device data struct for base address.

 * @p_protect_config:	Pointer to the protection mode and

 *			secure mode configuration

/**

 * cryp_is_logic_busy - returns the busy status of the CRYP logic

 * @device_data: Pointer to the device data struct for base address.

/**

 * cryp_configure_for_dma - configures the CRYP IP for DMA operation

 * @device_data: Pointer to the device data struct for base address.

 * @dma_req: Specifies the DMA request type value.

/**

 * cryp_configure_key_values - configures the key values for CRYP operations

 * @device_data: Pointer to the device data struct for base address.

 * @key_reg_index: Key value index register

 * @key_value: The key value struct

/**

 * cryp_configure_init_vector - configures the initialization vector register

 * @device_data: Pointer to the device data struct for base address.

 * @init_vector_index: Specifies the index of the init vector.

 * @init_vector_value: Specifies the value for the init vector.

/**

 * cryp_save_device_context -	Store hardware registers and

 *				other device context parameter

 * @device_data: Pointer to the device data struct for base address.

 * @ctx: Crypto device context

 * @cryp_mode: Mode: Polling, Interrupt or DMA

	/*

	 * Always start by disable the hardware and wait for it to finish the

	 * ongoing calculations before trying to reprogram it.

 Save IV for CBC mode for both AES and DES. */

/**

 * cryp_restore_device_context -	Restore hardware registers and

 *					other device context parameter

 * @device_data: Pointer to the device data struct for base address.

 * @ctx: Crypto device context

	/*

	 * Fall through for all items in switch statement. DES is captured in

	 * the default.

 Restore IV for CBC mode for AES and DES. */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

 IPAD, OPAD*/

 K1,K2,K3 */

 used for ctr3686 iv and aes ccm */

 Actual (reduced?) size of the MAC/ICv */

 Unmap enckey buffer */

 XCBC authetication */

 HMAC auth. */

 Initialize modes in instance */

 Allocate key buffer, cache line aligned */

 Set default authlen value */

 XCBC authetication */

 Allocate dma-coherent buffer for XCBC's K1+K2+K3 */

 (and temporary for user key - up to 256b) */

 HMAC authentication */

 Allocate dma-coherent buffer for IPAD + OPAD */

 BACKLOG notification */

 Restore ordinary iv pointer */

			/* In case of payload authentication failure, MUST NOT

			 * revealed the decrypted message --> zero its memory.

ENCRYPT*/

 Load the AES key */

	/* We are using for the source/user key the same buffer

	 * as for the output keys, * because after this key loading it

	 * is not needed anymore

 calc derived HMAC key */

 Load hash initial state */

 Load the hash current length*/

 Prepare ipad key */

 Perform HASH update */

 Get the digset */

 Not authenc (e.g., CCM) - no auth_key) */

 Check cipher key size */

 Default assumed to be AES ciphers */

 All tests of keys sizes passed */

/* This function prepers the user key so it can pass to the hmac processing

 * (copy to intenral buffer or hash in case of key longer than block

 auth_key required and >0 */

 Load hash initial state */

 Load the hash current length*/

 Get hashed key */

 STAT_PHASE_0: Init and sanity checks */

 authenc() alg. */

 the nonce is stored in bytes at end of key */

			/* Copy nonce from last 4 bytes in CTR key to

			 *  first 4 bytes in CTR IV

 Set CTR key size */

 non-authenc - has just one key */

 STAT_PHASE_1: Copy key to ctx */

 Get key material */

 HMAC */

 STAT_PHASE_2: Create sequence */

 non-authenc modes, e.g., CCM */

 No auth. key setup */

 STAT_PHASE_3: Submit sequence to HW */

 For CCM there is no sequence to setup the key */

 Update STAT_PHASE_3 */

 Unsupported auth. sizes */

		/* DOUBLE-PASS flow (as default)

		 * assoc. + iv + data -compact in one table

		 * if assoclen is ZERO only IV perform

null processing*/

 Get final ICV result */

Decrypt*/

 Get ICV out from hardware */

 Setup cipher state */

 Setup enc. key */

null processing*/

 We must wait for DMA to write all cipher */

 Loading hash ipad xor key state */

 Load init. digest len (64 bytes) */

 Loading MAC state */

 Setup XCBC MAC K1 */

 Setup XCBC MAC K2 */

 Setup XCBC MAC K3 */

 Hash associated data */

 Hash IV */

 Get final ICV result */

 Loading hash opad xor key state */

 Load init. digest len (64 bytes) */

 Perform HASH update */

 Copy MLLI table host-to-sram */

 Decrypt */

		/*

		 * Single-pass flow

	/*

	 * Double-pass flow

	 * Fallback for unsupported single-pass modes,

	 * i.e. using assoc. data of non-word-multiple

 encrypt first.. */

 authenc after..*/

DECRYPT*/

 authenc first..*/

 decrypt after.. */

		/* read the digest result with setting the completion bit

		 * must be after the cipher operation

		/*

		 * Single-pass flow

	/*

	 * Double-pass flow

	 * Fallback for unsupported single-pass modes,

	 * i.e. using assoc. data of non-word-multiple

 encrypt first.. */

 authenc after.. */

DECRYPT*/

 authenc first.. */

 decrypt after..*/

		/* read the digest result with setting the completion bit

		 * must be after the cipher operation

defaulted to fast flow*/

 Encrypt */

 load key */

 load ctr state */

 load MAC key */

 load MAC state */

 process assoc data */

 process the cipher */

 Read temporal MAC */

 load AES-CTR state (for last MAC calculation)*/

 encrypt the "T" value and store MAC in mac_state */

unsigned int size_of_a = 0, rem_a_size = 0;

	/* Note: The code assume that req->iv[0] already contains the value

	 * of L' of RFC3610

 This is L' of RFC 3610. */

 This is M' of RFC 3610. */

 taken from crypto/ccm.c */

 2 <= L <= 8, so 1 <= L' <= 7. */

	/* format control info per RFC 3610 and

	 * NIST Special Publication 800-38C

 Enable bit 6 if Adata exists. */

 Write L'. */

 END of "taken from crypto/ccm.c" */

 l(a) - size of associated data. */

 L' */

	/* For RFC 4309, always use 4 bytes for message length

	 * (at most 2^32-1 bytes).

	/* In RFC 4309 there is an 11-bytes nonce+IV part,

	 * that we build here.

 load key to AES*/

 process one zero block to generate hkey */

 Memory Barrier */

 Load GHASH subkey */

	/* Configure Hash Engine to work with GHASH.

	 * Since it was not possible to extend HASH submodes to add GHASH,

	 * The following command is necessary in order to

	 * select GHASH (according to HW designers)

1=AES_SK RKEK

	/* Load GHASH initial STATE (which is 0). (for any hash there is an

	 * initial state)

 load key to AES*/

 load AES/CTR initial CTR value inc by 2*/

 Encrypt */

 process(ghash) gcm_block_len */

 Store GHASH state after GHASH(Associated Data + Cipher +LenBlock) */

 load AES/CTR initial CTR value inc by 1*/

 Memory Barrier */

 process GCTR on stored GHASH and store MAC in mac_state*/

in RFC4543 no data to encrypt. just copy data from src to dest.

 process(ghash) assoc data */

 Encrypt */

 for gcm and rfc4106.

 process(ghash) assoc data */

 process(gctr+ghash) */

		/* rfc4543=>  all data(AAD,IV,Plain) are considered additional

		 * data that is nothing is encrypted.

 STAT_PHASE_0: Init and sanity checks */

 Check data length according to mode */

 Setup request structure */

 Setup request context */

 STAT_PHASE_1: Map buffers */

		/* Build CTR IV - Copy nonce from last 4 bytes in

		 * CTR key to first 4 bytes in CTR IV

 Initialize counter portion of counter block */

 Replace with counter iv */

 STAT_PHASE_2: Create sequence */

 Load MLLI tables to SRAM if necessary */

 STAT_PHASE_3: Lock HW and push sequence */

 No generated IV required */

 Very similar to cc_aead_encrypt() above. */

 No generated IV required */

 No generated IV required */

 No generated IV required */

 No generated IV required */

plaintext is not encryped with rfc4543

 No generated IV required */

 No generated IV required */

plaintext is not decryped with rfc4543

 No generated IV required */

 aead alg */

 Remove registered algs */

 Linux crypto */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

 Enables the device source clk */

 wait for Cryptocell reset completion */

 check if tee fips error occurred during power down */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited or its affiliates. */

 Note: PIDR3 holds CMOD/Rev so ignored for HW identification purposes */

 Hardware revisions defs. */

 The 703 is a OSCCA only variant of the 713 */

 compute CC_AXIM_CACHE_PARAMS */

 non cached or write-back, write allocate */

 compute CC_AXIM_ACE_CONST */

 system or outer-sharable */

 STAT_OP_TYPE_GENERIC STAT_PHASE_0: Interrupt */

 if driver suspended return, probably shared interrupt */

 read the interrupt status */

 Probably shared interrupt line */

 clear interrupt - must be before processing events */

 Completion interrupt - most probable */

		/* Mask all completion interrupts - will be unmasked in

		 * deferred service handler

 TEE FIPS interrupt */

		/* Mask interrupt - will be unmasked in Deferred service

		 * handler

 AXI error interrupt */

 Read the AXI error ID */

 Just warning */

 712/710/63 has no reset completion indication, always return true */

		/* in cc7x3 NVM_IS_IDLE indicates that CC reset is

		 *  completed and device is fully functional

 hw indicate reset completed */

 allow scheduling other process on the processor */

 reset not completed */

 Unmask all AXI interrupt sources AXI_CFG1 register   */

 AXI interrupt config are obsoleted startign at cc7x3 */

 Clear all pending interrupts */

 Unmask relevant interrupt cause */

 Get device resources */

 First CC registers space */

 Map registers space */

 Then IRQ */

 Wait for Cryptocell reset completion */

 Verify correct mapping */

 Verify correct mapping */

 Check HW engine configuration */

 This is fine */

 Check security disable state */

 Display HW versions */

 register the driver isr function */

 Allocate crypto algs */

 hash must be allocated before aead since hash exports APIs */

	/* If we got here and FIPS mode is enabled

	 * it means all FIPS test passed, so let TEE

	 * know we're good.

 Mask all interrupts */

 Map registers space */

 Module description */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

/**

 * cc_copy_mac() - Copy MAC to temporary location

 *

 * @dev: device object

 * @req: aead request object

 * @dir: [IN] copy from/to sgl

/**

 * cc_get_sgl_nents() - Get scatterlist number of entries.

 *

 * @dev: Device object

 * @sg_list: SG list

 * @nbytes: [IN] Total SGL data bytes.

 * @lbytes: [OUT] Returns the amount of bytes at the last entry

 *

 * Return:

 * Number of entries in the scatterlist

 get the number of bytes in the last entry */

/**

 * cc_copy_sg_portion() - Copy scatter list data,

 * from to_skip to end, to dest and vice versa

 *

 * @dev: Device object

 * @dest: Buffer to copy to/from

 * @sg: SG list

 * @to_skip: Number of bytes to skip before copying

 * @end: Offset of last byte to copy

 * @direct: Transfer direction (true == from SG list to buffer, false == from

 *          buffer to SG list)

 Verify there is no memory overflow*/

handle buffer longer than 64 kbytes */

Last entry */

 Allocate memory from the pointed pool */

 Point to start of MLLI */

 go over all SG's and link it to one MLLI table */

 set last bit in the current table */

			/*Calculate the current MLLI table length for the

			 *length field in the descriptor

 Set MLLI size for the bypass operation */

 create sg for the current buffer */

 prepare for case of MLLI */

 create sg for the current buffer */

 prepare for case of MLLI */

 Release pool */

 Map IV buffer */

 Map the src SGL */

 Handle inplace operation */

 Map the dst sg */

 Release pool */

		/* copy back mac from temporary location to deal with possible

		 * data memory overriding that caused by cache coherence

		 * problem.

	/* in CCM case we have additional entry for

	 * ccm header configurations

INPLACE*/

			/* Backup happens only when ICV is fragmented, ICV

			 * verification is made by CPU compare in order to

			 * simplify MAC verification upon request completion

				/* In coherent platforms (e.g. ACP)

				 * already copying ICV for any

				 * INPLACE-DECRYPT operation, hence

				 * we must neglect this code.

 Contig. ICV */

Should hanlde if the sg is not contig.*/

NON-INPLACE and DECRYPT*/

		/* Backup happens only when ICV is fragmented, ICV



		 * verification is made by CPU compare in order to simplify

		 * MAC verification upon request completion

 Contig. ICV */

Should hanlde if the sg is not contig.*/

NON-INPLACE and ENCRYPT*/

 Contig. ICV */

 non-inplace mode */

check where the data starts

check where the data starts

Inplace case dst nents equal to src nents*/

used for the assoc data fragments */

	/* copy mac to a temporary location to deal with possible

	 * data memory overriding that caused by cache coherence problem.

 cacluate the size for cipher remove ICV in decrypt*/

 If we do in-place encryption, we also need the auth tag */

		/*

		 * Create MLLI table for:

		 *   (1) Assoc. data

		 *   (2) Src/Dst SGLs

		 *   Note: IV is contg. buffer (not an SGL)

 DOUBLE-PASS flow */

		/*

		 * Prepare MLLI table(s) in this order:

		 *

		 * If ENCRYPT/DECRYPT (inplace):

		 *   (1) MLLI table for assoc

		 *   (2) IV entry (chained right after end of assoc)

		 *   (3) MLLI for src/dst (inplace operation)

		 *

		 * If ENCRYPT (non-inplace)

		 *   (1) MLLI table for assoc

		 *   (2) IV entry (chained right after end of assoc)

		 *   (3) MLLI for dst

		 *   (4) MLLI for src

		 *

		 * If DECRYPT (non-inplace)

		 *   (1) MLLI table for assoc

		 *   (2) IV entry (chained right after end of assoc)

		 *   (3) MLLI for src

		 *   (4) MLLI for dst

	/* Mlli support -start building the MLLI according to the above

	 * results

 Init the type of the dma buffer */

 nothing to do */

 map the previous buffer */

build mlli */

 add the src data to the sg_data */

 change the buffer index for the unmap function */

 Init the type of the dma buffer */

 Calculate the residue size*/

 update data len */

 Copy the new residue to next buffer */

 change the buffer index for next operation */

 change the buffer index for next operation */

 only one entry in the SG and no previous data */

 add the src data to the sg_data */

	/*In case a pool was set, a table was

	 *allocated and should be released

			/* clean the previous data length for update

			 * operation

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

 User key */

 HW (FDE) key */

 CPP key */

 Invalid key */

 Alloc hash tfm for essiv */

 Alloc fallabck tfm or essiv when key size != 256 bit */

			/* Note we're still allowing registration with no fallback since it's

			 * better to have most modes supported than none at all.

 Allocate key buffer, cache line aligned */

 Map key buffer */

 Free hash tfm for essiv */

 Unmap key buffer */

 Free key buffer in context */

 STAT_PHASE_0: Init and sanity checks */

 This check the size of the protected key token */

	/* The real key len for crypto op is the size of the HW key

	 * referenced by the HW key slot, not the hardware key token

 Must be SM4 since due to sethkey registration */

 STAT_PHASE_0: Init and sanity checks */

 We only support 256 bit ESSIV-CBC-AES keys */

 Internal ESSIV key buffer is double sized */

	/*

	 * Verify DES weak keys

	 * Note that we're dropping the expanded key since the

	 * HW does the expansion on its own.

 STAT_PHASE_1: Copy key to ctx */

 sha256 for key2 - use sw implementation */

 Read next IV */

  IV */

 Load IV */

 load XEX key */

 Load IV */

 Load key */

 We use the AES key size coding for all CPP algs */

					/* CC_POLICY_UNPROTECTED_KEY

					 * Invalid keys are filtered out in

					 * sethkey()

des*/

 Load AES key */

 bypass */

 Process */

 Not a BACKLOG notification */

 STAT_PHASE_0: Init and sanity checks */

 No data to process is valid */

	/* The IV we are handed may be allocated from the stack so

	 * we must copy it to a DMAable buffer before use.

 Setup request structure */

 Setup CPP operation details */

 Setup request context */

 STAT_PHASE_1: Map buffers */

 STAT_PHASE_2: Create sequence */

 Setup state (IV)  */

 Setup MLLI line, if needed */

 Setup key */

 Setup state (IV and XEX key)  */

 Data processing */

 Read next IV */

 STAT_PHASE_3: Lock HW and push sequence */

		/* Failed to send the request or request completed

		 * synchronously

 Block cipher alg */

		/* See https://www.mail-archive.com/linux-crypto@vger.kernel.org/msg40576.html

		 * for the reason why this differs from the generic

		 * implementation.

 Remove registered algs */

 Linux crypto */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

/**

 * cc_sram_mgr_init() - Initializes SRAM pool.

 *      The pool starts right at the beginning of SRAM.

 *      Returns zero for success, negative value otherwise.

 *

 * @drvdata: Associated device driver context

 *

 * Return:

 * 0 for success, negative error code for failure.

 Pool starts after ROM bytes */

/**

 * cc_sram_alloc() - Allocate buffer from SRAM pool.

 *

 * @drvdata: Associated device driver context

 * @size: The requested numer of bytes to allocate

 *

 * Return:

 * Address offset in SRAM or NULL_SRAM_ADDR for failure.

/**

 * cc_set_sram_desc() - Create const descriptors sequence to

 *	set values in given array into SRAM.

 * Note: each const value can't exceed word size.

 *

 * @src:	  A pointer to array of words to set as consts.

 * @dst:	  The target SRAM buffer to set into

 * @nelement:	  The number of words in "src" array

 * @seq:	  A pointer to the given IN/OUT descriptor sequence

 * @seq_len:	  A pointer to the given IN/OUT sequence length

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited or its affiliates. */

/*

 * This is a global var for the dentry of the

 * debugfs ccree/ dir. It is not tied down to

 * a specific instance of ccree, hence it is

 * global.

 Must be 0th */

 Must be 1st */

 Failing here is not important enough to fail the module load */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

 const value in SRAM*/

 const value in SRAM */

/*

 * Due to the way the HW works, every double word in the SHA384 and SHA512

 * larval hashes must be stored in hi/lo order

 hash per-session context */

	/* holds the origin digest; the digest after "setkey" if HMAC,*

	 * the initial digest if HASH.

 use for hmac with key large then mode block size */

hash*/

 Copy the initial digests if hash flow. */

 Not a BACKLOG notification */

 Not a BACKLOG notification */

 Not a BACKLOG notification */

 Get final MAC result */

 store the hash digest result in the context */

 Loading hash opad xor key state */

 Load the hash current length */

 Memory Barrier: wait for IPAD/OPAD axi write to complete */

 Perform HASH update */

 Setup request structure */

	/* If HMAC then load hash IPAD xor key, if HASH then load initial

	 * digest

 Load the hash current length */

 HW last hash block padding (aka. "DO_PAD") */

 Restore hash digest */

 Restore hash current length */

 no real updates required */

 No hardware updates are required */

 Setup request structure */

 store the hash digest result in context */

 store current hash length in context */

 Setup request structure */

 Pad the hash */

	/* The keylen value distinguishes HASH in case keylen is ZERO bytes,

	 * any NON-ZERO value utilizes HMAC flow

 Load hash initial state */

 Load the hash current length*/

 Get hashed key */

 calc derived HMAC key */

 Load hash initial state */

 Load the hash current length*/

 Prepare ipad key */

 Perform HASH update */

		/* Get the IPAD/OPAD xor key (Note, IPAD is the initial digest

		 * of the first HASH "update" state)

 Not first iteration */

 First iteration */

 1. Load the AES key */

 STAT_PHASE_1: Copy key to ctx */

 no real updates required */

 No hardware updates are required */

 store the hash digest result in context */

 Setup request structure */

 Setup request structure */

 Load key for ECB decryption */

		/* Initiate decryption of block state to previous

		 * block_state-XOR-M[n]

 Memory Barrier: wait for axi write to complete */

 Get final MAC result */

 Setup request structure */

 Get final MAC result */

 Setup request structure */

 Get final MAC result */

 Sanity check the data as much as possible */

 hash descriptors */

Asynchronize hash template

 Copy-to-sram digest-len */

 Copy-to-sram digest-len for sha384/512 */

 The initial digests offset */

 Copy-to-sram initial SHA* digests */

 The initial digest-len offset */

must be set before the alg registration as it is being used there*/

 ahash registration */

 Check that the HW revision and variants are suitable */

 register hmac version */

 register hash version */

 Setup XCBC MAC K1 */

 Setup XCBC MAC K2 */

 Setup XCBC MAC K3 */

 Loading MAC state */

 Setup CMAC Key */

 Load MAC state */

 nothing to build */

 bypass */

 process */

 return updated desc sequence size */

/**

 * cc_larval_digest_addr() - Get the address of the initial digest in SRAM

 * according to the given hash mode

 *

 * @drvdata: Associated device driver context

 * @mode: The Hash mode. Supported modes: MD5/SHA1/SHA224/SHA256

 *

 * Return:

 * The address of the initial digest in SRAM

Ignore*/

This is valid wrong value to avoid kernel crash*/

to avoid kernel crash*/

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

 The highest descriptor count in used */

 Request manager resources */

 HW capability */

	/* This lock protects access to HW register

	 * that must be single request at a time

 backlog queue */

 protect backlog queue */

 Not allocated */

 Kill tasklet */

 Allocate DMA word for "dummy" completion descriptor use */

 Init. "dummy" completion descriptor */

	/*

	 * We do indeed write all 6 command words to the same

	 * register. The HW supports this.

/**

 * request_mgr_complete() - Completion will take place if and only if user

 * requested completion by cc_send_sync_request().

 *

 * @dev: Device pointer

 * @dx_compl_h: The completion event to signal

 * @dummy: unused error code

	/* SW queue is checked only once as it will not

	 * be changed during the poll because the spinlock_bh

	 * is held by the thread

 Wait for space in HW queue. Poll constant num of iterations. */

 If there is enough place return */

 No room in the HW queue try again later */

/**

 * cc_do_send_request() - Enqueue caller request to crypto hardware.

 * Need to be called with HW lock held and PM running

 *

 * @drvdata: Associated device driver context

 * @cc_req: The request to enqueue

 * @desc: The crypto sequence

 * @len: The crypto sequence length

 * @add_comp: If "true": add an artificial dout DMA to mark completion

 *

initial sequence length*/

 Enqueue request - must be locked with HW lock*/

	/*

	 * We are about to push command to the HW via the command registers

	 * that may reference host memory. We need to issue a memory barrier

	 * to make sure there are no outstanding memory writes

 STAT_PHASE_4: Push sequence */

		/* This situation should never occur. Maybe indicating problem

		 * with resuming power. Set the free slot count to 0 and hope

		 * for the best.

 Update the free slots in HW queue */

		/*

		 * Notify the request we're moving out of the backlog

		 * but only if we haven't done so already.

			/*

			 * There is still no room in the FIFO for

			 * this request. Bail out. We'll return here

			 * on the next completion irq.

 Remove ourselves from the backlog list */

 CC_DEBUG_FORCE_BACKLOG */

/**

 * send_request_init() - Enqueue caller request to crypto hardware during init

 * process.

 * Assume this function is not called in the middle of a flow,

 * since we set QUEUE_LAST_IND flag in the last descriptor.

 *

 * @drvdata: Associated device driver context

 * @desc: The crypto sequence

 * @len: The crypto sequence length

 *

 * Return:

 * Returns "0" upon success

initial sequence length*/

	/* Wait for space in HW and SW FIFO. Poll for as much as FIFO_TIMEOUT.

	/*

	 * We are about to push command to the HW via the command registers

	 * that may reference host memory. We need to issue a memory barrier

	 * to make sure there are no outstanding memory writes

 Update the free slots in HW queue */

 Dequeue request */

			/* We are supposed to handle a completion but our

			 * queue is empty. This is not normal. Return and

			 * hope for the best.

 Deferred service handler, run as interrupt-fired tasklet */

	/* To avoid the interrupt from firing as we unmask it,

	 * we clear it now

 Avoid race with above clear: Test completion counter once more */

			/* At this point (after proc_completions()),

			 * request_mgr_handle->axi_completed is 0.

	/* after verifying that there is nothing to do,

	 * unmask AXI completion interrupt

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2012-2019 ARM Limited (or its affiliates). */

/* The function called once at driver entry point to check

 * whether TEE FIPS error occurred.

 Did the TEE report status? */

 Yes. Is it OK? */

 No. It's either not in use or will be reported later */

/*

 * This function should push the FIPS REE library status towards the TEE library

 * by writing the error state to HOST_GPR0 register.

 Push REE side FIPS test failure to TEE side */

 Kill tasklet */

/*

 * This function check if cryptocell tee fips error occurred

 * and in such case triggers system error

 Deferred service handler, run as interrupt-fired tasklet */

	/* after verifying that there is nothing to do,

	 * unmask AXI completion interrupt.

 The function called once at driver entry point .*/

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (c) 2019 BayLibre, SAS

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 AO Offsets */

/*

 * Meson8/Meson8b/Meson8m2 only expose the power management registers of the

 * AO-bus as syscon. 0x3a from GX translates to 0x02, 0x3b translates to 0x03

 * and so on.

 HHI Offsets */

 TOP Power Domains */

 Memory PD Domains */

	/*

         * TOFIX: This is a special case for the VPU power domain, which can

	 * be enabled previously by the bootloader. In this case the VPU

         * pipeline may be functional but no driver maybe never attach

         * to this power domain, and if the domain is disabled it could

         * cause system errors. This is why the pm_domain_always_on_gov

         * is used here.

         * For the same reason, the clocks should be enabled in case

         * we need to power the domain off, otherwise the internal clocks

         * prepare/enable counters won't be in sync.

 sentinel */ }

/*

 * Copyright (c) 2017 Martin Blumenstingl <martin.blumenstingl@googlemail.com>

 *

 * SPDX-License-Identifier: GPL-2.0+

 sentinel */ }

/*

 * Copyright (c) 2017 BayLibre, SAS

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 *

 * SPDX-License-Identifier: GPL-2.0+

 AO Offsets */

 HHI Offsets */

 Power Down Memories */

 Power Down Memories */

 Power Up Memories */

 Power Up Memories */

 If already powered, sync the clock states */

 sentinel */ }

/*

 * Copyright (c) 2017 BayLibre, SAS

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 *

 * SPDX-License-Identifier: GPL-2.0+

 pack_id != 0x20 */

 pack_id & 0xf == 0x3 */

 pack_id == 0x20 */

 Only S912 is known for GXM */

 look up for chipid node */

 check if interface is enabled */

 check if chip-id is available */

 node should be a syscon */

 SPDX-License-Identifier: (GPL-2.0+ OR MIT)

/*

 * Copyright (c) 2019 Amlogic, Inc.

 * Author: Jianxin Pan <jianxin.pan@amlogic.com>

 UART should keep working in ATF after suspend and before resume */

 DMC is for DDR PHY ana/dig and DMC, and should be always on */

 SRAMB is used as ATF runtime memory, and should be always on */

 NIC is for the Arm NIC-400 interconnect, and should be always on */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2018 BayLibre, SAS

 * Copyright (C) 2015 Amlogic, Inc. All rights reserved.

 * Copyright (C) 2014 Endless Mobile

 DMC Registers */

 canvas device lock */

	/*

	 * If priv is NULL, it's probably because the canvas hasn't

	 * properly initialized. Bail out with -EINVAL because, in the

	 * current state, this driver probe cannot return -EPROBE_DEFER

 Force a read-back to make sure everything is flushed. */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (c) 2018 BayLibre, SAS

 * Author: Neil Armstrong <narmstrong@baylibre.com>

 continuous measurement */

 interrupts */

 Set measurement duration */

 Set ID */

 Enable & Start */

 Disable */

 Get the value in multiple of gate time counts */

 Start from max duration and down to min duration */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2013-2015, The Linux Foundation. All rights reserved.

 * Copyright (c) 2019, Linaro Limited

 Register Offsets for RB-CPR and Bit Definitions */

 RBCPR Version Register */

 RBCPR Gate Count and Target Registers */

 RBCPR Timer Control */

 RBCPR Config Register */

 RBCPR Control Register */

 RBCPR Ack/Nack Response */

 RBCPR Result status Register */

 RBCPR Interrupt Control Register */

 CPR eFuse parameters */

 fuse quot */

 fuse quot_offset */

 Program Consecutive Up & Down */

 Program the step quotient and idle clocks */

 Clear the target quotient value and gate count of all ROs */

			/*

			 * Handle the case where another measurement started

			 * after the interrupt was triggered due to a core

			 * exiting from power collapse.

 Maximize the UP threshold */

 Disable UP interrupt */

 Calculate new voltage */

			/*

			 * Handle the case where another measurement started

			 * after the interrupt was triggered due to a core

			 * exiting from power collapse.

 Enable auto nack down */

 Disable DOWN interrupt */

 Calculate new voltage */

 Disable auto nack down */

 Restore default threshold for UP */

 Re-enable default interrupts */

 Ack */

		/*

		 * Following sequence of handling is as per each IRQ's

		 * priority

 RBCPR_CTL_SW_AUTO_CONT_ACK_EN is enabled */

 Save register values for the corner */

 Disable interrupt and CPR */

 Program the default HW ceiling, floor and vlevel */

	/*

	 * Clear the target quotient value and gate count of all

	 * ring oscillators

 Init and save gcnt */

 Program the delay count for the timer */

 Program Consecutive Up & Down */

 Program the control register */

	/*

	 * Determine new corner we're going to.

	 * Remove one since lowest performance state is 1.

 Determine direction */

 Not two's complement.. instead highest bit is sign bit */

 Populate fuse_corner members */

		/*

		 * Update SoC voltages: platforms might choose a different

		 * regulators than the one used to characterize the algorithms

		 * (ie, init_voltage_step).

 Populate uV */

			/*

			 * Allow the highest fuse corner's PVS voltage to

			 * define the ceiling voltage for that corner in order

			 * to support SoC's in which variable ceiling values

			 * are required.

 Populate target quotient by scaling */

 Populate acc settings */

	/*

	 * Restrict all fuse corner PVS voltages based upon per corner

	 * ceiling and floor voltages.

 Convert to MHz */

	/*

	 * Don't interpolate in the wrong direction. This could happen

	 * if the adjusted fuse voltage overlaps with the previous fuse's

	 * adjusted voltage.

	/*

	 * max_volt_scale has units of uV/MHz while freq values

	 * have units of Hz.  Divide by 1000000 to convert to.

	/*

	 * Store maximum frequency for each fuse corner based on the frequency

	 * plan

	/*

	 * Get the quotient adjustment scaling factor, according to:

	 *

	 * scaling = min(1000 * (QUOT(corner_N) - QUOT(corner_N-1))

	 *		/ (freq(corner_N) - freq(corner_N-1)), max_factor)

	 *

	 * QUOT(corner_N):	quotient read from fuse for fuse corner N

	 * QUOT(corner_N-1):	quotient read from fuse for fuse corner (N - 1)

	 * freq(corner_N):	max frequency in MHz supported by fuse corner N

	 * freq(corner_N-1):	max frequency in MHz supported by fuse corner

	 *			 (N - 1)

	 *

	 * Then walk through the corners mapped to each fuse corner

	 * and calculate the quotient adjustment for each one using the

	 * following formula:

	 *

	 * quot_adjust = (freq_max - freq_corner) * scaling / 1000

	 *

	 * freq_max: max frequency in MHz supported by the fuse corner

	 * freq_corner: frequency in MHz corresponding to the corner

	 * scaling: calculated from above equation

	 *

	 *

	 *     +                           +

	 *     |                         v |

	 *   q |           f c           o |           f c

	 *   u |         c               l |         c

	 *   o |       f                 t |       f

	 *   t |     c                   a |     c

	 *     | c f                     g | c f

	 *     |                         e |

	 *     +---------------            +----------------

	 *       0 1 2 3 4 5 6               0 1 2 3 4 5 6

	 *          corner                      corner

	 *

	 *    c = corner

	 *    f = fuse corner

	 *

 This is a fuse corner; don't scale anything */

 Reduce the ceiling voltage if needed */

	/*

	 * Some bootloaders set a CPU clock frequency that is not defined

	 * in the OPP table. When running at an unlisted frequency,

	 * cpufreq_online() will change to the OPP which has the lowest

	 * frequency, at or above the unlisted frequency.

	 * Since cpufreq_online() always "rounds up" in the case of an

	 * unlisted frequency, this function always "rounds down" in case

	 * of an unlisted frequency. That way, when cpufreq_online()

	 * triggers the first ever call to cpr_set_performance_state(),

	 * it will correctly determine the direction as UP.

 fuse corner 0 */

 fuse corner 1 */

 fuse corner 2 */

	/*

	 * This driver only supports scaling voltage for a CPU cluster

	 * where all CPUs in the cluster share a single regulator.

	 * Therefore, save the struct device pointer only for the first

	 * CPU device that gets attached. There is no need to do any

	 * additional initialization when further CPUs get attached.

	/*

	 * cpr_scale_voltage() requires the direction (if we are changing

	 * to a higher or lower OPP). The first time

	 * cpr_set_performance_state() is called, there is no previous

	 * performance state defined. Therefore, we call

	 * cpr_find_initial_corner() that gets the CPU clock frequency

	 * set by the bootloader, so that we can determine the direction

	 * the first time cpr_set_performance_state() is called.

	/*

	 * Everything related to (virtual) corners has to be initialized

	 * here, when attaching to the power domain, since we need to know

	 * the maximum frequency for each fuse corner, and this is only

	 * available after the cpufreq driver has attached to us.

	 * The reason for this is that we need to know the highest

	 * frequency associated with each fuse corner.

 Configure CPR HW but keep it disabled */

 Enable ACC if required */

	/*

	 * Initialize fuse corners, since it simply depends

	 * on data in efuses.

	 * Everything related to (virtual) corners has to be

	 * initialized after attaching to the power domain,

	 * since it depends on the CPU's OPP table.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2020 The Linux Foundation. All rights reserved.

 control access to pdr lookup/indack lists */

 serialize pd status invocation */

 control access to the locator state */

 Create a local client port for QMI communication */

 Service pending lookup requests */

 Skip waiting for response */

 Ack the indication after clients release the PD resources */

 Prepare req message */

 Update ret to indicate that the service is not yet found */

 Always read total_domains from the response msg */

 Bail out early if the SERVREG LOCATOR QMI service is not up */

/**

 * pdr_add_lookup() - register a tracking request for a PD

 * @pdr:		PDR client handle

 * @service_name:	service name of the tracking request

 * @service_path:	service path of the tracking request

 *

 * Registering a pdr lookup allows for tracking the life cycle of the PD.

 *

 * Return: pdr_service object on success, ERR_PTR on failure. -EALREADY is

 * returned if a lookup is already in progress for the given service path.

/**

 * pdr_restart_pd() - restart PD

 * @pdr:	PDR client handle

 * @pds:	PD service handle

 *

 * Restarts the PD tracked by the PDR client handle for a given service path.

 *

 * Return: 0 on success, negative errno on failure.

 Prepare req message */

 Check response if PDR is disabled */

 Check the response for other error case*/

/**

 * pdr_handle_alloc() - initialize the PDR client handle

 * @status:	function to be called on PD state change

 * @priv:	handle for client's use

 *

 * Initializes the PDR client handle to allow for tracking/restart of PDs.

 *

 * Return: pdr_handle object on success, ERR_PTR on failure.

/**

 * pdr_handle_release() - release the PDR client handle

 * @pdr:	PDR client handle

 *

 * Cleans up pending tracking requests and releases the underlying qmi handles.

 SPDX-License-Identifier: GPL-2.0 */

 Copyright (c) 2016-2018, 2020, The Linux Foundation. All rights reserved. */

/**

 * struct entry_header: header for each entry in cmddb

 *

 * @id: resource's identifier

 * @priority: unused

 * @addr: the address of the resource

 * @len: length of the data

 * @offset: offset from :@data_offset, start of the data

/**

 * struct rsc_hdr: resource header information

 *

 * @slv_id: id for the resource

 * @header_offset: entry's header at offset from the end of the cmd_db_header

 * @data_offset: entry's data at offset from the end of the cmd_db_header

 * @cnt: number of entries for HW type

 * @version: MSB is major, LSB is minor

 * @reserved: reserved for future use.

/**

 * struct cmd_db_header: The DB header information

 *

 * @version: The cmd db version

 * @magic: constant expected in the database

 * @header: array of resources

 * @checksum: checksum for the header. Unused.

 * @reserved: reserved memory

 * @data: driver specific data

/**

 * DOC: Description of the Command DB database.

 *

 * At the start of the command DB memory is the cmd_db_header structure.

 * The cmd_db_header holds the version, checksum, magic key as well as an

 * array for header for each slave (depicted by the rsc_header). Each h/w

 * based accelerator is a 'slave' (shared resource) and has slave id indicating

 * the type of accelerator. The rsc_header is the header for such individual

 * slaves of a given type. The entries for each of these slaves begin at the

 * rsc_hdr.header_offset. In addition each slave could have auxiliary data

 * that may be needed by the driver. The data for the slave starts at the

 * entry_header.offset to the location pointed to by the rsc_hdr.data_offset.

 *

 * Drivers have a stringified key to a slave/resource. They can query the slave

 * information and get the slave id and the auxiliary data and the length of the

 * data. Using this information, they can format the request to be sent to the

 * h/w accelerator and request a resource state.

/**

 * cmd_db_ready - Indicates if command DB is available

 *

 * Return: 0 on success, errno otherwise

 Pad out query string to same length as in DB */

/**

 * cmd_db_read_addr() - Query command db for resource id address.

 *

 * @id: resource id to query for address

 *

 * Return: resource address on success, 0 on error

 *

 * This is used to retrieve resource address based on resource

 * id.

/**

 * cmd_db_read_aux_data() - Query command db for aux data.

 *

 *  @id: Resource to retrieve AUX Data on

 *  @len: size of data buffer returned

 *

 *  Return: pointer to data on success, error pointer otherwise

/**

 * cmd_db_read_slave_id - Get the slave ID for a given resource address

 *

 * @id: Resource id to query the DB for version

 *

 * Return: cmd_db_hw_type enum on success, CMD_DB_HW_INVALID on error

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2017-2019, The Linux Foundation. All rights reserved.

 *

/**

 * struct llcc_slice_config - Data associated with the llcc slice

 * @usecase_id: Unique id for the client's use case

 * @slice_id: llcc slice id for each client

 * @max_cap: The maximum capacity of the cache slice provided in KB

 * @priority: Priority of the client used to select victim line for replacement

 * @fixed_size: Boolean indicating if the slice has a fixed capacity

 * @bonus_ways: Bonus ways are additional ways to be used for any slice,

 *		if client ends up using more than reserved cache ways. Bonus

 *		ways are allocated only if they are not reserved for some

 *		other client.

 * @res_ways: Reserved ways for the cache slice, the reserved ways cannot

 *		be used by any other client than the one its assigned to.

 * @cache_mode: Each slice operates as a cache, this controls the mode of the

 *             slice: normal or TCM(Tightly Coupled Memory)

 * @probe_target_ways: Determines what ways to probe for access hit. When

 *                    configured to 1 only bonus and reserved ways are probed.

 *                    When configured to 0 all ways in llcc are probed.

 * @dis_cap_alloc: Disable capacity based allocation for a client

 * @retain_on_pc: If this bit is set and client has maintained active vote

 *               then the ways assigned to this client are not flushed on power

 *               collapse.

 * @activate_on_init: Activate the slice immediately after it is programmed

 * @write_scid_en: Bit enables write cache support for a given scid.

/**

 * llcc_slice_getd - get llcc slice descriptor

 * @uid: usecase_id for the client

 *

 * A pointer to llcc slice descriptor will be returned on success and

 * and error pointer is returned on failure

/**

 * llcc_slice_putd - llcc slice descritpor

 * @desc: Pointer to llcc slice descriptor

 Set the ACTIVE trigger */

 Clear the ACTIVE trigger */

/**

 * llcc_slice_activate - Activate the llcc slice

 * @desc: Pointer to llcc slice descriptor

 *

 * A value of zero will be returned on success and a negative errno will

 * be returned in error cases

/**

 * llcc_slice_deactivate - Deactivate the llcc slice

 * @desc: Pointer to llcc slice descriptor

 *

 * A value of zero will be returned on success and a negative errno will

 * be returned in error cases

/**

 * llcc_get_slice_id - return the slice id

 * @desc: Pointer to llcc slice descriptor

/**

 * llcc_get_slice_size - return the slice id

 * @desc: Pointer to llcc slice descriptor

	/*

	 * LLCC instances can vary for each target.

	 * The SW writes to broadcast register which gets propagated

	 * to each llcc instance (llcc0,.. llccN).

	 * Since the size of the memory is divided equally amongst the

	 * llcc instances, we need to configure the max cap accordingly.

 Set the global pointer to a error code to avoid referencing it */

 Extract major version of the IP */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2011-2017, The Linux Foundation. All rights reserved.

 Copyright (c) 2018, Linaro Limited

 Some random values tbh which does not collide with static modules */

/**

 * apr_send_pkt() - Send a apr message from apr device

 *

 * @adev: Pointer to previously registered apr device.

 * @pkt: Pointer to apr packet to send

 *

 * Return: Will be an negative on packet size on success.

	/*

	 * NOTE: hdr_size is not same as APR_HDR_SIZE as remote can include

	 * optional headers in to apr_hdr which should be ignored

	/*

	 * NOTE: hdr_size is not same as GPR_HDR_SIZE as remote can include

	 * optional headers in to gpr_hdr which should be ignored

 Attempt an OF style match first */

		/*

		 * This function is called with svc_path NULL during

		 * apr_probe(), in which case we register any apr devices

		 * without a qcom,protection-domain specified.

		 *

		 * Then as the protection domains becomes available

		 * (if applicable) this function is again called, but with

		 * svc_path representing the service becoming available. In

		 * this case we register any apr devices with a matching

		 * qcom,protection-domain.

 skip APR services that are PD independent */

 skip APR services whose PD paths don't match */

 skip APR services whose PD lookups are registered */

 try deprecated apr-domain property */

/*

 * __apr_driver_register() - Client driver registration with aprbus

 *

 * @drv:Client driver to be associated with client-device.

 * @owner: owning module/driver

 *

 * This API will register the client driver with the aprbus

 * It is called from the driver's module-init function.

/*

 * apr_driver_unregister() - Undo effect of apr_driver_register

 *

 * @drv: Client driver to be unregistered

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018, The Linux Foundation. All rights reserved.*/

/**

 * struct rpmhpd - top level RPMh power domain resource data structure

 * @dev:		rpmh power domain controller device

 * @pd:			generic_pm_domain corrresponding to the power domain

 * @parent:		generic_pm_domain corrresponding to the parent's power domain

 * @peer:		A peer power domain in case Active only Voting is

 *			supported

 * @active_only:	True if it represents an Active only peer

 * @corner:		current corner

 * @active_corner:	current active corner

 * @enable_corner:	lowest non-zero corner

 * @level:		An array of level (vlvl) to corner (hlvl) mappings

 *			derived from cmd-db

 * @level_count:	Number of levels supported by the power domain. max

 *			being 16 (0 - 15)

 * @enabled:		true if the power domain is enabled

 * @res_name:		Resource name used for cmd-db lookup

 * @addr:		Resource address as looped up using resource name from

 *			cmd-db

 SDM845 RPMH powerdomains */

 SDX55 RPMH powerdomains */

 SM6350 RPMH powerdomains */

 SM8150 RPMH powerdomains */

 SM8350 Power domains */

 SC7180 RPMH powerdomains */

 SC7280 RPMH powerdomains */

 SC8180x RPMH powerdomains */

	/*

	 * Wait for an ack only when we are increasing the

	 * perf state of the power domain

/*

 * This function is used to aggregate the votes across the active only

 * resources and its peers. The aggregated votes are sent to RPMh as

 * ACTIVE_ONLY votes (which take effect immediately), as WAKE_ONLY votes

 * (applied by RPMh on system wakeup) and as SLEEP votes (applied by RPMh

 * on system sleep).

 * We send ACTIVE_ONLY votes for resources without any peers. For others,

 * which have an active only peer, all 3 votes are sent.

	/*

	 * If the level requested is more than that supported by the

	 * max corner, just set it to max anyway.

 Ensure that the domain isn't turn off */

 2 bytes used for each command DB aux data entry */

 Remember the first corner with non-zero level */

		/*

		 * The AUX data may be zero padded.  These 0 valued entries at

		 * the end of the map must be ignored.

 Add subdomains */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011-2021, The Linux Foundation. All rights reserved.

	/*

	 * If a subsystem is in sleep when reading the sleep stats adjust

	 * the accumulated sleep duration to show actual sleep time.

 Items are allocated lazily, so lookup pointer each time */

	/*

	 * On RPM targets, stats offset location is dynamic and changes from target

	 * to target and sometimes from build to build for same target.

	 *

	 * In such cases the dynamic address is present at 0x14 offset from base

	 * address in devicetree. The last 16bits indicates the stats_offset.

		/*

		 * Read the low power mode name and create debugfs file for it.

		 * The names read could be of below,

		 * (may change depending on low power mode supported).

		 * For rpmh-sleep-stats: "aosd", "cxsd" and "ddr".

		 * For rpm-sleep-stats: "vmin" and "vlow".

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014, The Linux foundation. All rights reserved.

 ADM 0 - B */

 ADM 0 - B */

 ADM 1 - A */

 ADM 1 - B */

 get the tcsr node and setup the config and regmap */

 not required, so default to 0 if not present */

	/*

	 * modify tcsr to reflect mode and ADM CRCI mux

	 * Each gsbi contains a pair of bits, one for RX and one for TX

	 * SPI mode requires both bits cleared, otherwise they are set

 make sure the gsbi control write is not reordered */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017-2018, The Linux Foundation. All rights reserved.

/**

 * DOC: Overview

 *

 * Generic Interface (GENI) Serial Engine (SE) Wrapper driver is introduced

 * to manage GENI firmware based Qualcomm Universal Peripheral (QUP) Wrapper

 * controller. QUP Wrapper is designed to support various serial bus protocols

 * like UART, SPI, I2C, I3C, etc.

/**

 * DOC: Hardware description

 *

 * GENI based QUP is a highly-flexible and programmable module for supporting

 * a wide range of serial interfaces like UART, SPI, I2C, I3C, etc. A single

 * QUP module can provide upto 8 serial interfaces, using its internal

 * serial engines. The actual configuration is determined by the target

 * platform configuration. The protocol supported by each interface is

 * determined by the firmware loaded to the serial engine. Each SE consists

 * of a DMA Engine and GENI sub modules which enable serial engines to

 * support FIFO and DMA modes of operation.

 *

 *

 *                      +-----------------------------------------+

 *                      |QUP Wrapper                              |

 *                      |         +----------------------------+  |

 *   --QUP & SE Clocks-->         | Serial Engine N            |  +-IO------>

 *                      |         | ...                        |  | Interface

 *   <---Clock Perf.----+    +----+-----------------------+    |  |

 *     State Interface  |    | Serial Engine 1            |    |  |

 *                      |    |                            |    |  |

 *                      |    |                            |    |  |

 *   <--------AHB------->    |                            |    |  |

 *                      |    |                            +----+  |

 *                      |    |                            |       |

 *                      |    |                            |       |

 *   <------SE IRQ------+    +----------------------------+       |

 *                      |                                         |

 *                      +-----------------------------------------+

 *

 *                         Figure 1: GENI based QUP Wrapper

 *

 * The GENI submodules include primary and secondary sequencers which are

 * used to drive TX & RX operations. On serial interfaces that operate using

 * master-slave model, primary sequencer drives both TX & RX operations. On

 * serial interfaces that operate using peer-to-peer model, primary sequencer

 * drives TX operation and secondary sequencer drives RX operation.

/**

 * DOC: Software description

 *

 * GENI SE Wrapper driver is structured into 2 parts:

 *

 * geni_wrapper represents QUP Wrapper controller. This part of the driver

 * manages QUP Wrapper information such as hardware version, clock

 * performance table that is common to all the internal serial engines.

 *

 * geni_se represents serial engine. This part of the driver manages serial

 * engine information such as clocks, containing QUP Wrapper, etc. This part

 * of driver also supports operations (eg. initialize the concerned serial

 * engine, select between FIFO and DMA mode of operation etc.) that are

 * common to all the serial engines and are independent of serial interfaces.

/**

 * struct geni_wrapper - Data structure to represent the QUP Wrapper Core

 * @dev:		Device pointer of the QUP wrapper core

 * @base:		Base address of this instance of QUP wrapper core

 * @ahb_clks:		Handle to the primary & secondary AHB clocks

 * @to_core:		Core ICC path

 Common SE registers */

 GENI_OUTPUT_CTRL fields */

 GENI_CGC_CTRL fields */

 SE_GSI_EVENT_EN fields */

 SE_IRQ_EN fields */

 SE_DMA_GENERAL_CFG */

/**

 * geni_se_get_qup_hw_version() - Read the QUP wrapper Hardware version

 * @se:	Pointer to the corresponding serial engine.

 *

 * Return: Hardware Version of the wrapper.

/**

 * geni_se_init() - Initialize the GENI serial engine

 * @se:		Pointer to the concerned serial engine.

 * @rx_wm:	Receive watermark, in units of FIFO words.

 * @rx_rfr:	Ready-for-receive watermark, in units of FIFO words.

 *

 * This function is used to initialize the GENI serial engine, configure

 * receive watermark and ready-for-receive watermarks.

	/*

	 * The RX path for the UART is asynchronous and so needs more

	 * complex logic for enabling / disabling its interrupts.

	 *

	 * Specific notes:

	 * - The done and TX-related interrupts are managed manually.

	 * - We don't RX from the main sequencer (we use the secondary) so

	 *   we don't need the RX-related interrupts enabled in the main

	 *   sequencer for UART.

/**

 * geni_se_select_mode() - Select the serial engine transfer mode

 * @se:		Pointer to the concerned serial engine.

 * @mode:	Transfer mode to be selected.

/**

 * DOC: Overview

 *

 * GENI FIFO packing is highly configurable. TX/RX packing/unpacking consist

 * of up to 4 operations, each operation represented by 4 configuration vectors

 * of 10 bits programmed in GENI_TX_PACKING_CFG0 and GENI_TX_PACKING_CFG1 for

 * TX FIFO and in GENI_RX_PACKING_CFG0 and GENI_RX_PACKING_CFG1 for RX FIFO.

 * Refer to below examples for detailed bit-field description.

 *

 * Example 1: word_size = 7, packing_mode = 4 x 8, msb_to_lsb = 1

 *

 *        +-----------+-------+-------+-------+-------+

 *        |           | vec_0 | vec_1 | vec_2 | vec_3 |

 *        +-----------+-------+-------+-------+-------+

 *        | start     | 0x6   | 0xe   | 0x16  | 0x1e  |

 *        | direction | 1     | 1     | 1     | 1     |

 *        | length    | 6     | 6     | 6     | 6     |

 *        | stop      | 0     | 0     | 0     | 1     |

 *        +-----------+-------+-------+-------+-------+

 *

 * Example 2: word_size = 15, packing_mode = 2 x 16, msb_to_lsb = 0

 *

 *        +-----------+-------+-------+-------+-------+

 *        |           | vec_0 | vec_1 | vec_2 | vec_3 |

 *        +-----------+-------+-------+-------+-------+

 *        | start     | 0x0   | 0x8   | 0x10  | 0x18  |

 *        | direction | 0     | 0     | 0     | 0     |

 *        | length    | 7     | 6     | 7     | 6     |

 *        | stop      | 0     | 0     | 0     | 1     |

 *        +-----------+-------+-------+-------+-------+

 *

 * Example 3: word_size = 23, packing_mode = 1 x 32, msb_to_lsb = 1

 *

 *        +-----------+-------+-------+-------+-------+

 *        |           | vec_0 | vec_1 | vec_2 | vec_3 |

 *        +-----------+-------+-------+-------+-------+

 *        | start     | 0x16  | 0xe   | 0x6   | 0x0   |

 *        | direction | 1     | 1     | 1     | 1     |

 *        | length    | 7     | 7     | 6     | 0     |

 *        | stop      | 0     | 0     | 1     | 0     |

 *        +-----------+-------+-------+-------+-------+

 *

/**

 * geni_se_config_packing() - Packing configuration of the serial engine

 * @se:		Pointer to the concerned serial engine

 * @bpw:	Bits of data per transfer word.

 * @pack_words:	Number of words per fifo element.

 * @msb_to_lsb:	Transfer from MSB to LSB or vice-versa.

 * @tx_cfg:	Flag to configure the TX Packing.

 * @rx_cfg:	Flag to configure the RX Packing.

 *

 * This function is used to configure the packing rules for the current

 * transfer.

	/*

	 * Number of protocol words in each FIFO entry

	 * 0 - 4x8, four words in each entry, max word size of 8 bits

	 * 1 - 2x16, two words in each entry, max word size of 16 bits

	 * 2 - 1x32, one word in each entry, max word size of 32 bits

	 * 3 - undefined

/**

 * geni_se_resources_off() - Turn off resources associated with the serial

 *                           engine

 * @se:	Pointer to the concerned serial engine.

 *

 * Return: 0 on success, standard Linux error codes on failure/error.

/**

 * geni_se_resources_on() - Turn on resources associated with the serial

 *                          engine

 * @se:	Pointer to the concerned serial engine.

 *

 * Return: 0 on success, standard Linux error codes on failure/error.

/**

 * geni_se_clk_tbl_get() - Get the clock table to program DFS

 * @se:		Pointer to the concerned serial engine.

 * @tbl:	Table in which the output is returned.

 *

 * This function is called by the protocol drivers to determine the different

 * clock frequencies supported by serial engine core clock. The protocol

 * drivers use the output to determine the clock frequency index to be

 * programmed into DFS.

 *

 * Return: number of valid performance levels in the table on success,

 *	   standard Linux error codes on failure.

/**

 * geni_se_clk_freq_match() - Get the matching or closest SE clock frequency

 * @se:		Pointer to the concerned serial engine.

 * @req_freq:	Requested clock frequency.

 * @index:	Index of the resultant frequency in the table.

 * @res_freq:	Resultant frequency of the source clock.

 * @exact:	Flag to indicate exact multiple requirement of the requested

 *		frequency.

 *

 * This function is called by the protocol drivers to determine the best match

 * of the requested frequency as provided by the serial engine clock in order

 * to meet the performance requirements.

 *

 * If we return success:

 * - if @exact is true  then @res_freq / <an_integer> == @req_freq

 * - if @exact is false then @res_freq / <an_integer> <= @req_freq

 *

 * Return: 0 on success, standard Linux error codes on failure.

 We have a new best! */

 If the new best is exact then we're done */

 Record how close we got */

/**

 * geni_se_tx_dma_prep() - Prepare the serial engine for TX DMA transfer

 * @se:			Pointer to the concerned serial engine.

 * @buf:		Pointer to the TX buffer.

 * @len:		Length of the TX buffer.

 * @iova:		Pointer to store the mapped DMA address.

 *

 * This function is used to prepare the buffers for DMA TX.

 *

 * Return: 0 on success, standard Linux error codes on failure.

/**

 * geni_se_rx_dma_prep() - Prepare the serial engine for RX DMA transfer

 * @se:			Pointer to the concerned serial engine.

 * @buf:		Pointer to the RX buffer.

 * @len:		Length of the RX buffer.

 * @iova:		Pointer to store the mapped DMA address.

 *

 * This function is used to prepare the buffers for DMA RX.

 *

 * Return: 0 on success, standard Linux error codes on failure.

 RX does not have EOT buffer type bit. So just reset RX_ATTR */

/**

 * geni_se_tx_dma_unprep() - Unprepare the serial engine after TX DMA transfer

 * @se:			Pointer to the concerned serial engine.

 * @iova:		DMA address of the TX buffer.

 * @len:		Length of the TX buffer.

 *

 * This function is used to unprepare the DMA buffers after DMA TX.

/**

 * geni_se_rx_dma_unprep() - Unprepare the serial engine after RX DMA transfer

 * @se:			Pointer to the concerned serial engine.

 * @iova:		DMA address of the RX buffer.

 * @len:		Length of the RX buffer.

 *

 * This function is used to unprepare the DMA buffers after DMA RX.

 To do: Replace this by icc_bulk_enable once it's implemented in ICC core */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2017 Linaro Ltd.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2009-2017, The Linux Foundation. All rights reserved.

 * Copyright (c) 2017-2019, Linaro Ltd.

/*

 * SoC version type with major number in the upper 16 bits and minor

 * number in the lower 16 bits.

/*

 * SMEM item id, used to acquire handles to respective

 * SMEM region.

/*

 * SMEM Image table indices

/*

 * SMEM Image table names

 CONFIG_DEBUG_FS */

 Socinfo SMEM item structure */

 Version 2 */

 Version 3 */

 Version 4 */

 Version 5 */

 Version 6 */

 Version 7 */

 Version 8 */

 Version 9 */

 Version 10 */

 Version 11 */

 Version 12 */

 Version 13 */

 Version 14 */

 Version 15 */

 CONFIG_DEBUG_FS */

 CONFIG_DEBUG_FS */

 No need for bounds checking, it happened at socinfo_debugfs_init */

 CONFIG_DEBUG_FS */

 Feed the soc specific unique data into entropy pool */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Linaro Ltd.

/**

 * qmi_recv_new_server() - handler of NEW_SERVER control message

 * @qmi:	qmi handle

 * @service:	service id of the new server

 * @instance:	instance id of the new server

 * @node:	node of the new server

 * @port:	port of the new server

 *

 * Calls the new_server callback to inform the client about a newly registered

 * server matching the currently registered service lookup.

 Ignore EOF marker */

/**

 * qmi_recv_del_server() - handler of DEL_SERVER control message

 * @qmi:	qmi handle

 * @node:	node of the dying server, a value of -1 matches all nodes

 * @port:	port of the dying server, a value of -1 matches all ports

 *

 * Calls the del_server callback for each previously seen server, allowing the

 * client to react to the disappearing server.

/**

 * qmi_recv_bye() - handler of BYE control message

 * @qmi:	qmi handle

 * @node:	id of the dying node

 *

 * Signals the client that all previously registered services on this node are

 * now gone and then calls the bye callback to allow the client client further

 * cleaning up resources associated with this remote.

/**

 * qmi_recv_del_client() - handler of DEL_CLIENT control message

 * @qmi:	qmi handle

 * @node:	node of the dying client

 * @port:	port of the dying client

 *

 * Signals the client about a dying client, by calling the del_client callback.

/**

 * qmi_add_lookup() - register a new lookup with the name service

 * @qmi:	qmi handle

 * @service:	service id of the request

 * @instance:	instance id of the request

 * @version:	version number of the request

 *

 * Registering a lookup query with the name server will cause the name server

 * to send NEW_SERVER and DEL_SERVER control messages to this socket as

 * matching services are registered.

 *

 * Return: 0 on success, negative errno on failure.

/**

 * qmi_add_server() - register a service with the name service

 * @qmi:	qmi handle

 * @service:	type of the service

 * @instance:	instance of the service

 * @version:	version of the service

 *

 * Register a new service with the name service. This allows clients to find

 * and start sending messages to the client associated with @qmi.

 *

 * Return: 0 on success, negative errno on failure.

/**

 * qmi_txn_init() - allocate transaction id within the given QMI handle

 * @qmi:	QMI handle

 * @txn:	transaction context

 * @ei:		description of how to decode a matching response (optional)

 * @c_struct:	pointer to the object to decode the response into (optional)

 *

 * This allocates a transaction id within the QMI handle. If @ei and @c_struct

 * are specified any responses to this transaction will be decoded as described

 * by @ei into @c_struct.

 *

 * A client calling qmi_txn_init() must call either qmi_txn_wait() or

 * qmi_txn_cancel() to free up the allocated resources.

 *

 * Return: Transaction id on success, negative errno on failure.

/**

 * qmi_txn_wait() - wait for a response on a transaction

 * @txn:	transaction handle

 * @timeout:	timeout, in jiffies

 *

 * If the transaction is decoded by the means of @ei and @c_struct the return

 * value will be the returned value of qmi_decode_message(), otherwise it's up

 * to the specified message handler to fill out the result.

 *

 * Return: the transaction response on success, negative errno on failure.

/**

 * qmi_txn_cancel() - cancel an ongoing transaction

 * @txn:	transaction id

/**

 * qmi_invoke_handler() - find and invoke a handler for a message

 * @qmi:	qmi handle

 * @sq:		sockaddr of the sender

 * @txn:	transaction object for the message

 * @buf:	buffer containing the message

 * @len:	length of @buf

 *

 * Find handler and invoke handler for the incoming message.

/**

 * qmi_handle_net_reset() - invoked to handle ENETRESET on a QMI handle

 * @qmi:	the QMI context

 *

 * As a result of registering a name service with the QRTR all open sockets are

 * flagged with ENETRESET and this function will be called. The typical case is

 * the initial boot, where this signals that the local node id has been

 * configured and as such any bound sockets needs to be rebound. So close the

 * socket, inform the client and re-initialize the socket.

 *

 * For clients it's generally sufficient to react to the del_server callbacks,

 * but server code is expected to treat the net_reset callback as a "bye" from

 * all nodes.

 *

 * Finally the QMI handle will send out registration requests for any lookups

 * and services.

 If this is a response, find the matching transaction handle */

 Ignore unexpected responses */

 Create a txn based on the txn_id of the incoming message */

 The old qmi->sock is gone, our work is done */

	/*

	 * This will be NULL if we receive data while being in

	 * qmi_handle_release()

/**

 * qmi_handle_init() - initialize a QMI client handle

 * @qmi:	QMI handle to initialize

 * @recv_buf_size: maximum size of incoming message

 * @ops:	reference to callbacks for QRTR notifications

 * @handlers:	NULL-terminated list of QMI message handlers

 *

 * This initializes the QMI client handle to allow sending and receiving QMI

 * messages. As messages are received the appropriate handler will be invoked.

 *

 * Return: 0 on success, negative errno on failure.

 Make room for the header */

 Must also be sufficient to hold a control packet */

/**

 * qmi_handle_release() - release the QMI client handle

 * @qmi:	QMI client handle

 *

 * This closes the underlying socket and stops any handling of QMI messages.

 Free registered lookup requests */

 Free registered service information */

/**

 * qmi_send_message() - send a QMI message

 * @qmi:	QMI client handle

 * @sq:		destination sockaddr

 * @txn:	transaction object to use for the message

 * @type:	type of message to send

 * @msg_id:	message id

 * @len:	max length of the QMI message

 * @ei:		QMI message description

 * @c_struct:	object to be encoded

 *

 * This function encodes @c_struct using @ei into a message of type @type,

 * with @msg_id and @txn into a buffer of maximum size @len, and sends this to

 * @sq.

 *

 * Return: 0 on success, negative errno on failure.

/**

 * qmi_send_request() - send a request QMI message

 * @qmi:	QMI client handle

 * @sq:		destination sockaddr

 * @txn:	transaction object to use for the message

 * @msg_id:	message id

 * @len:	max length of the QMI message

 * @ei:		QMI message description

 * @c_struct:	object to be encoded

 *

 * Return: 0 on success, negative errno on failure.

/**

 * qmi_send_response() - send a response QMI message

 * @qmi:	QMI client handle

 * @sq:		destination sockaddr

 * @txn:	transaction object to use for the message

 * @msg_id:	message id

 * @len:	max length of the QMI message

 * @ei:		QMI message description

 * @c_struct:	object to be encoded

 *

 * Return: 0 on success, negative errno on failure.

/**

 * qmi_send_indication() - send an indication QMI message

 * @qmi:	QMI client handle

 * @sq:		destination sockaddr

 * @msg_id:	message id

 * @len:	max length of the QMI message

 * @ei:		QMI message description

 * @c_struct:	object to be encoded

 *

 * Return: 0 on success, negative errno on failure.

 We don't care about future messages on this txn */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Sony Mobile Communications Inc.

 * Copyright (c) 2012-2013, The Linux Foundation. All rights reserved.

/**

 * struct qcom_smem_state - state context

 * @refcount:	refcount for the state

 * @orphan:	boolean indicator that this state has been unregistered

 * @list:	entry in smem_states list

 * @of_node:	of_node to use for matching the state in DT

 * @priv:	implementation private data

 * @ops:	ops for the state

/**

 * qcom_smem_state_update_bits() - update the masked bits in state with value

 * @state:	state handle acquired by calling qcom_smem_state_get()

 * @mask:	bit mask for the change

 * @value:	new value for the masked bits

 *

 * Returns 0 on success, otherwise negative errno.

/**

 * qcom_smem_state_get() - acquire handle to a state

 * @dev:	client device pointer

 * @con_id:	name of the state to lookup

 * @bit:	flags from the state reference, indicating which bit's affected

 *

 * Returns handle to the state, or ERR_PTR(). qcom_smem_state_put() must be

 * called to release the returned state handle.

/**

 * qcom_smem_state_put() - release state handle

 * @state:	state handle to be released

/**

 * devm_qcom_smem_state_get() - acquire handle to a devres managed state

 * @dev:	client device pointer

 * @con_id:	name of the state to lookup

 * @bit:	flags from the state reference, indicating which bit's affected

 *

 * Returns handle to the state, or ERR_PTR(). qcom_smem_state_put() is called

 * automatically when @dev is removed.

/**

 * qcom_smem_state_register() - register a new state

 * @of_node:	of_node used for matching client lookups

 * @ops:	implementation ops

 * @priv:	implementation specific private data

/**

 * qcom_smem_state_unregister() - unregister a registered state

 * @state:	state handle to be unregistered

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2012-2015, The Linux Foundation. All rights reserved.

 * Copyright (C) 2017 Linaro Ltd.

/**

 * skip_to_next_elem() - Skip to next element in the structure to be encoded

 * @ei_array: Struct info describing the element to be skipped.

 * @level: Depth level of encoding/decoding to identify nested structures.

 *

 * This function is used while encoding optional elements. If the flag

 * corresponding to an optional element is not set, then encoding the

 * optional element can be skipped. This function can be used to perform

 * that operation.

 *

 * Return: struct info of the next element that can be encoded.

/**

 * qmi_calc_min_msg_len() - Calculate the minimum length of a QMI message

 * @ei_array: Struct info array describing the structure.

 * @level: Level to identify the depth of the nested structures.

 *

 * Return: Expected minimum length of the QMI message or 0 on error.

 Optional elements do not count in minimum length */

		/*

		 * Type & Length info. not prepended for elements in the

		 * nested structure.

/**

 * qmi_encode_basic_elem() - Encodes elements of basic/primary data type

 * @buf_dst: Buffer to store the encoded information.

 * @buf_src: Buffer containing the elements to be encoded.

 * @elem_len: Number of elements, in the buf_src, to be encoded.

 * @elem_size: Size of a single instance of the element to be encoded.

 *

 * This function encodes the "elem_len" number of data elements, each of

 * size "elem_size" bytes from the source buffer "buf_src" and stores the

 * encoded information in the destination buffer "buf_dst". The elements are

 * of primary data type which include u8 - u64 or similar. This

 * function returns the number of bytes of encoded information.

 *

 * Return: The number of bytes of encoded information.

/**

 * qmi_encode_struct_elem() - Encodes elements of struct data type

 * @ei_array: Struct info array descibing the struct element.

 * @buf_dst: Buffer to store the encoded information.

 * @buf_src: Buffer containing the elements to be encoded.

 * @elem_len: Number of elements, in the buf_src, to be encoded.

 * @out_buf_len: Available space in the encode buffer.

 * @enc_level: Depth of the nested structure from the main structure.

 *

 * This function encodes the "elem_len" number of struct elements, each of

 * size "ei_array->elem_size" bytes from the source buffer "buf_src" and

 * stores the encoded information in the destination buffer "buf_dst". The

 * elements are of struct data type which includes any C structure. This

 * function returns the number of bytes of encoded information.

 *

 * Return: The number of bytes of encoded information on success or negative

 * errno on error.

/**

 * qmi_encode_string_elem() - Encodes elements of string data type

 * @ei_array: Struct info array descibing the string element.

 * @buf_dst: Buffer to store the encoded information.

 * @buf_src: Buffer containing the elements to be encoded.

 * @out_buf_len: Available space in the encode buffer.

 * @enc_level: Depth of the string element from the main structure.

 *

 * This function encodes a string element of maximum length "ei_array->elem_len"

 * bytes from the source buffer "buf_src" and stores the encoded information in

 * the destination buffer "buf_dst". This function returns the number of bytes

 * of encoded information.

 *

 * Return: The number of bytes of encoded information on success or negative

 * errno on error.

/**

 * qmi_encode() - Core Encode Function

 * @ei_array: Struct info array describing the structure to be encoded.

 * @out_buf: Buffer to hold the encoded QMI message.

 * @in_c_struct: Pointer to the C structure to be encoded.

 * @out_buf_len: Available space in the encode buffer.

 * @enc_level: Encode level to indicate the depth of the nested structure,

 *             within the main structure, being encoded.

 *

 * Return: The number of bytes of encoded information on success or negative

 * errno on error.

 Check to avoid out of range buffer access */

 Check to avoid out of range buffer access */

/**

 * qmi_decode_basic_elem() - Decodes elements of basic/primary data type

 * @buf_dst: Buffer to store the decoded element.

 * @buf_src: Buffer containing the elements in QMI wire format.

 * @elem_len: Number of elements to be decoded.

 * @elem_size: Size of a single instance of the element to be decoded.

 *

 * This function decodes the "elem_len" number of elements in QMI wire format,

 * each of size "elem_size" bytes from the source buffer "buf_src" and stores

 * the decoded elements in the destination buffer "buf_dst". The elements are

 * of primary data type which include u8 - u64 or similar. This

 * function returns the number of bytes of decoded information.

 *

 * Return: The total size of the decoded data elements, in bytes.

/**

 * qmi_decode_struct_elem() - Decodes elements of struct data type

 * @ei_array: Struct info array describing the struct element.

 * @buf_dst: Buffer to store the decoded element.

 * @buf_src: Buffer containing the elements in QMI wire format.

 * @elem_len: Number of elements to be decoded.

 * @tlv_len: Total size of the encoded information corresponding to

 *           this struct element.

 * @dec_level: Depth of the nested structure from the main structure.

 *

 * This function decodes the "elem_len" number of elements in QMI wire format,

 * each of size "(tlv_len/elem_len)" bytes from the source buffer "buf_src"

 * and stores the decoded elements in the destination buffer "buf_dst". The

 * elements are of struct data type which includes any C structure. This

 * function returns the number of bytes of decoded information.

 *

 * Return: The total size of the decoded data elements on success, negative

 * errno on error.

/**

 * qmi_decode_string_elem() - Decodes elements of string data type

 * @ei_array: Struct info array describing the string element.

 * @buf_dst: Buffer to store the decoded element.

 * @buf_src: Buffer containing the elements in QMI wire format.

 * @tlv_len: Total size of the encoded information corresponding to

 *           this string element.

 * @dec_level: Depth of the string element from the main structure.

 *

 * This function decodes the string element of maximum length

 * "ei_array->elem_len" from the source buffer "buf_src" and puts it into

 * the destination buffer "buf_dst". This function returns number of bytes

 * decoded from the input buffer.

 *

 * Return: The total size of the decoded data elements on success, negative

 * errno on error.

/**

 * find_ei() - Find element info corresponding to TLV Type

 * @ei_array: Struct info array of the message being decoded.

 * @type: TLV Type of the element being searched.

 *

 * Every element that got encoded in the QMI message will have a type

 * information associated with it. While decoding the QMI message,

 * this function is used to find the struct info regarding the element

 * that corresponds to the type being decoded.

 *

 * Return: Pointer to struct info, if found

/**

 * qmi_decode() - Core Decode Function

 * @ei_array: Struct info array describing the structure to be decoded.

 * @out_c_struct: Buffer to hold the decoded C struct

 * @in_buf: Buffer containing the QMI message to be decoded

 * @in_buf_len: Length of the QMI message to be decoded

 * @dec_level: Decode level to indicate the depth of the nested structure,

 *             within the main structure, being decoded

 *

 * Return: The number of bytes of decoded information on success, negative

 * errno on error.

			/*

			 * No length information for elements in nested

			 * structures. So use remaining decodable buffer space.

/**

 * qmi_encode_message() - Encode C structure as QMI encoded message

 * @type:	Type of QMI message

 * @msg_id:	Message ID of the message

 * @len:	Passed as max length of the message, updated to actual size

 * @txn_id:	Transaction ID

 * @ei:		QMI message descriptor

 * @c_struct:	Reference to structure to encode

 *

 * Return: Buffer with encoded message, or negative ERR_PTR() on error

 Check the possibility of a zero length QMI message */

 Encode message, if we have a message */

/**

 * qmi_decode_message() - Decode QMI encoded message to C structure

 * @buf:	Buffer with encoded message

 * @len:	Amount of data in @buf

 * @ei:		QMI message descriptor

 * @c_struct:	Reference to structure to decode into

 *

 * Return: The number of bytes of decoded information on success, negative

 * errno on error.

 Common header in all QMI responses */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Sony Mobile Communications AB.

 * Copyright (c) 2012-2013, The Linux Foundation. All rights reserved.

/*

 * The Shared Memory Point to Point (SMP2P) protocol facilitates communication

 * of a single 32-bit value between two processors.  Each value has a single

 * writer (the local side) and a single reader (the remote side). Values are

 * uniquely identified in the system by the directed edge (local processor ID

 * to remote processor ID) and a string identifier.

 *

 * Each processor is responsible for creating the outgoing SMEM items and each

 * item is writable by the local processor and readable by the remote

 * processor.  By using two separate SMEM items that are single-reader and

 * single-writer, SMP2P does not require any remote locking mechanisms.

 *

 * The driver uses the Linux GPIO and interrupt framework to expose a virtual

 * GPIO for each outbound entry and a virtual interrupt controller for each

 * inbound entry.

/**

 * struct smp2p_smem_item - in memory communication structure

 * @magic:		magic number

 * @version:		version - must be 1

 * @features:		features flag - currently unused

 * @local_pid:		processor id of sending end

 * @remote_pid:		processor id of receiving end

 * @total_entries:	number of entries - always SMP2P_MAX_ENTRY

 * @valid_entries:	number of allocated entries

 * @flags:

 * @entries:		individual communication entries

 *     @name:		name of the entry

 *     @value:		content of the entry

/**

 * struct smp2p_entry - driver context matching one entry

 * @node:	list entry to keep track of allocated entries

 * @smp2p:	reference to the device driver context

 * @name:	name of the entry, to match against smp2p_smem_item

 * @value:	pointer to smp2p_smem_item entry value

 * @last_value:	last handled value

 * @domain:	irq_domain for inbound entries

 * @irq_enabled:bitmap to track enabled irq bits

 * @irq_rising:	bitmap to mark irq bits for rising detection

 * @irq_falling:bitmap to mark irq bits for falling detection

 * @state:	smem state handle

 * @lock:	spinlock to protect read-modify-write of the value

/**

 * struct qcom_smp2p - device driver context

 * @dev:	device driver handle

 * @in:		pointer to the inbound smem item

 * @out:	pointer to the outbound smem item

 * @smem_items:	ids of the two smem items

 * @valid_entries: already scanned inbound entries

 * @local_pid:	processor id of the inbound edge

 * @remote_pid:	processor id of the outbound edge

 * @ipc_regmap:	regmap for the outbound ipc

 * @ipc_offset:	offset within the regmap

 * @ipc_bit:	bit in regmap@offset to kick to signal remote processor

 * @mbox_client: mailbox client handle

 * @mbox_chan:	apcs ipc mailbox channel handle

 * @inbound:	list of inbound entries

 * @outbound:	list of outbound entries

 Make sure any updated data is written before the kick */

 Match newly created entries */

 Fire interrupts based on any value changes */

 Ignore entries not yet allocated by the remote side */

 No changes of this entry? */

/**

 * qcom_smp2p_intr() - interrupt handler for incoming notifications

 * @irq:	unused

 * @data:	smp2p driver context

 *

 * Handle notifications from the remote side to handle newly allocated entries

 * or any changes to the state bits of existing entries.

 Acquire smem item, if not already found */

 Allocate an entry from the smem item */

 Make the logical entry reference the physical value */

	/*

	 * Make sure the rest of the header is written before we validate the

	 * item by writing a valid version number.

 Kick the outgoing edge after allocating entries */

	/*

	 * Treat smp2p interrupt as wakeup source, but keep it disabled

	 * by default. User space can decide enabling it depending on its

	 * use cases. For example if remoteproc crashes and device wants

	 * to handle it immediatedly (e.g. to not miss phone calls) it can

	 * enable wakeup source from user space, while other devices which

	 * do not have proper autosleep feature may want to handle it with

	 * other wakeup events (e.g. Power button) instead waking up immediately.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * The On Chip Memory (OCMEM) allocator allows various clients to allocate

 * memory from OCMEM based on performance, latency and power requirements.

 * This is typically used by the GPU, camera/video, and audio components on

 * some Snapdragon SoCs.

 *

 * Copyright (C) 2019 Brian Masney <masneyb@onstation.org>

 * Copyright (C) 2015 Red Hat. Author: Rob Clark <robdclark@gmail.com>

 TODO: gpu uses phys_to_offset, but others do not.. */

 TODO: add support for other clients... */

 TODO: add support for other clients... */

 The core clock is synchronous with graphics */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2016-2018, The Linux Foundation. All rights reserved.

 DRV HW Solver Configuration Information Register */

 DRV TCS Configuration Information Register */

 Offsets for common TCS Registers, one bit per TCS */

 w/o; write 1 to clear */

/*

 * Offsets for per TCS Registers.

 *

 * TCSes start at 0x10 from tcs_base and are stored one after another.

 * Multiply tcs_id by RSC_DRV_TCS_OFFSET to find a given TCS and add one

 * of the below to find a register.

 1 bit per command */

 zero if tcs is busy */

 1 bit per command */

/*

 * Offsets for per command in a TCS.

 *

 * Commands (up to 16) start at 0x30 in a TCS; multiply command index

 * by RSC_DRV_CMD_OFFSET and add one of the below to find a register.

 TCS CMD register bit mask */

/*

 * Here's a high level overview of how all the registers in RPMH work

 * together:

 *

 * - The main rpmh-rsc address is the base of a register space that can

 *   be used to find overall configuration of the hardware

 *   (DRV_PRNT_CHLD_CONFIG). Also found within the rpmh-rsc register

 *   space are all the TCS blocks. The offset of the TCS blocks is

 *   specified in the device tree by "qcom,tcs-offset" and used to

 *   compute tcs_base.

 * - TCS blocks come one after another. Type, count, and order are

 *   specified by the device tree as "qcom,tcs-config".

 * - Each TCS block has some registers, then space for up to 16 commands.

 *   Note that though address space is reserved for 16 commands, fewer

 *   might be present. See ncpt (num cmds per TCS).

 *

 * Here's a picture:

 *

 *  +---------------------------------------------------+

 *  |RSC                                                |

 *  | ctrl                                              |

 *  |                                                   |

 *  | Drvs:                                             |

 *  | +-----------------------------------------------+ |

 *  | |DRV0                                           | |

 *  | | ctrl/config                                   | |

 *  | | IRQ                                           | |

 *  | |                                               | |

 *  | | TCSes:                                        | |

 *  | | +------------------------------------------+  | |

 *  | | |TCS0  |  |  |  |  |  |  |  |  |  |  |  |  |  | |

 *  | | | ctrl | 0| 1| 2| 3| 4| 5| .| .| .| .|14|15|  | |

 *  | | |      |  |  |  |  |  |  |  |  |  |  |  |  |  | |

 *  | | +------------------------------------------+  | |

 *  | | +------------------------------------------+  | |

 *  | | |TCS1  |  |  |  |  |  |  |  |  |  |  |  |  |  | |

 *  | | | ctrl | 0| 1| 2| 3| 4| 5| .| .| .| .|14|15|  | |

 *  | | |      |  |  |  |  |  |  |  |  |  |  |  |  |  | |

 *  | | +------------------------------------------+  | |

 *  | | +------------------------------------------+  | |

 *  | | |TCS2  |  |  |  |  |  |  |  |  |  |  |  |  |  | |

 *  | | | ctrl | 0| 1| 2| 3| 4| 5| .| .| .| .|14|15|  | |

 *  | | |      |  |  |  |  |  |  |  |  |  |  |  |  |  | |

 *  | | +------------------------------------------+  | |

 *  | |                    ......                     | |

 *  | +-----------------------------------------------+ |

 *  | +-----------------------------------------------+ |

 *  | |DRV1                                           | |

 *  | | (same as DRV0)                                | |

 *  | +-----------------------------------------------+ |

 *  |                      ......                       |

 *  +---------------------------------------------------+

	/*

	 * Wait until we read back the same value.  Use a counter rather than

	 * ktime for timeout since this may be called after timekeeping stops.

/**

 * tcs_invalidate() - Invalidate all TCSes of the given type (sleep or wake).

 * @drv:  The RSC controller.

 * @type: SLEEP_TCS or WAKE_TCS

 *

 * This will clear the "slots" variable of the given tcs_group and also

 * tell the hardware to forget about all entries.

 *

 * The caller must ensure that no other RPMH actions are happening when this

 * function is called, since otherwise the device may immediately become

 * used again even before this function exits.

 Caller ensures nobody else is running so no lock */

/**

 * rpmh_rsc_invalidate() - Invalidate sleep and wake TCSes.

 * @drv: The RSC controller.

 *

 * The caller must ensure that no other RPMH actions are happening when this

 * function is called, since otherwise the device may immediately become

 * used again even before this function exits.

/**

 * get_tcs_for_msg() - Get the tcs_group used to send the given message.

 * @drv: The RSC controller.

 * @msg: The message we want to send.

 *

 * This is normally pretty straightforward except if we are trying to send

 * an ACTIVE_ONLY message but don't have any active_only TCSes.

 *

 * Return: A pointer to a tcs_group or an ERR_PTR.

	/*

	 * If we are making an active request on a RSC that does not have a

	 * dedicated TCS for active state use, then re-purpose a wake TCS to

	 * send active votes. This is safe because we ensure any active-only

	 * transfers have finished before we use it (maybe by running from

	 * the last CPU in PM code).

/**

 * get_req_from_tcs() - Get a stashed request that was xfering on the given TCS.

 * @drv:    The RSC controller.

 * @tcs_id: The global ID of this TCS.

 *

 * For ACTIVE_ONLY transfers we want to call back into the client when the

 * transfer finishes. To do this we need the "request" that the client

 * originally provided us. This function grabs the request that we stashed

 * when we started the transfer.

 *

 * This only makes sense for ACTIVE_ONLY transfers since those are the only

 * ones we track sending (the only ones we enable interrupts for and the only

 * ones we call back to the client for).

 *

 * Return: The stashed request.

/**

 * __tcs_set_trigger() - Start xfer on a TCS or unset trigger on a borrowed TCS

 * @drv:     The controller.

 * @tcs_id:  The global ID of this TCS.

 * @trigger: If true then untrigger/retrigger. If false then just untrigger.

 *

 * In the normal case we only ever call with "trigger=true" to start a

 * transfer. That will un-trigger/disable the TCS from the last transfer

 * then trigger/enable for this transfer.

 *

 * If we borrowed a wake TCS for an active-only transfer we'll also call

 * this function with "trigger=false" to just do the un-trigger/disable

 * before using the TCS for wake purposes again.

 *

 * Note that the AP is only in charge of triggering active-only transfers.

 * The AP never triggers sleep/wake values using this function.

	/*

	 * HW req: Clear the DRV_CONTROL and enable TCS again

	 * While clearing ensure that the AMC mode trigger is cleared

	 * and then the mode enable is cleared.

 Enable the AMC mode on the TCS and then trigger the TCS */

/**

 * enable_tcs_irq() - Enable or disable interrupts on the given TCS.

 * @drv:     The controller.

 * @tcs_id:  The global ID of this TCS.

 * @enable:  If true then enable; if false then disable

 *

 * We only ever call this when we borrow a wake TCS for an active-only

 * transfer. For active-only TCSes interrupts are always left enabled.

/**

 * tcs_tx_done() - TX Done interrupt handler.

 * @irq: The IRQ number (ignored).

 * @p:   Pointer to "struct rsc_drv".

 *

 * Called for ACTIVE_ONLY transfers (those are the only ones we enable the

 * IRQ for) when a transfer is done.

 *

 * Return: IRQ_HANDLED

		/*

		 * If wake tcs was re-purposed for sending active

		 * votes, clear AMC trigger & enable modes and

		 * disable interrupt for this TCS

 Reclaim the TCS */

		/*

		 * Disable interrupt for WAKE TCS to avoid being

		 * spammed with interrupts coming when the solver

		 * sends its wake votes.

/**

 * __tcs_buffer_write() - Write to TCS hardware from a request; don't trigger.

 * @drv:    The controller.

 * @tcs_id: The global ID of this TCS.

 * @cmd_id: The index within the TCS to start writing.

 * @msg:    The message we want to send, which will contain several addr/data

 *          pairs to program (but few enough that they all fit in one TCS).

 *

 * This is used for all types of transfers (active, sleep, and wake).

 Convert all commands to RR when the request has wait_for_compl set */

		/*

		 * Additionally, if the cmd->wait is set, make the command

		 * response reqd even if the overall request was fire-n-forget.

/**

 * check_for_req_inflight() - Look to see if conflicting cmds are in flight.

 * @drv: The controller.

 * @tcs: A pointer to the tcs_group used for ACTIVE_ONLY transfers.

 * @msg: The message we want to send, which will contain several addr/data

 *       pairs to program (but few enough that they all fit in one TCS).

 *

 * This will walk through the TCSes in the group and check if any of them

 * appear to be sending to addresses referenced in the message. If it finds

 * one it'll return -EBUSY.

 *

 * Only for use for active-only transfers.

 *

 * Must be called with the drv->lock held since that protects tcs_in_use.

 *

 * Return: 0 if nothing in flight or -EBUSY if we should try again later.

 *         The caller must re-enable interrupts between tries since that's

 *         the only way tcs_in_use will ever be updated and the only way

 *         RSC_DRV_CMD_ENABLE will ever be cleared.

/**

 * find_free_tcs() - Find free tcs in the given tcs_group; only for active.

 * @tcs: A pointer to the active-only tcs_group (or the wake tcs_group if

 *       we borrowed it because there are zero active-only ones).

 *

 * Must be called with the drv->lock held since that protects tcs_in_use.

 *

 * Return: The first tcs that's free or -EBUSY if all in use.

/**

 * claim_tcs_for_req() - Claim a tcs in the given tcs_group; only for active.

 * @drv: The controller.

 * @tcs: The tcs_group used for ACTIVE_ONLY transfers.

 * @msg: The data to be sent.

 *

 * Claims a tcs in the given tcs_group while making sure that no existing cmd

 * is in flight that would conflict with the one in @msg.

 *

 * Context: Must be called with the drv->lock held since that protects

 * tcs_in_use.

 *

 * Return: The id of the claimed tcs or -EBUSY if a matching msg is in flight

 * or the tcs_group is full.

	/*

	 * The h/w does not like if we send a request to the same address,

	 * when one is already in-flight or being processed.

/**

 * rpmh_rsc_send_data() - Write / trigger active-only message.

 * @drv: The controller.

 * @msg: The data to be sent.

 *

 * NOTES:

 * - This is only used for "ACTIVE_ONLY" since the limitations of this

 *   function don't make sense for sleep/wake cases.

 * - To do the transfer, we will grab a whole TCS for ourselves--we don't

 *   try to share. If there are none available we'll wait indefinitely

 *   for a free one.

 * - This function will not wait for the commands to be finished, only for

 *   data to be programmed into the RPMh. See rpmh_tx_done() which will

 *   be called when the transfer is fully complete.

 * - This function must be called with interrupts enabled. If the hardware

 *   is busy doing someone else's transfer we need that transfer to fully

 *   finish so that we can have the hardware, and to fully finish it needs

 *   the interrupt handler to run. If the interrupts is set to run on the

 *   active CPU this can never happen if interrupts are disabled.

 *

 * Return: 0 on success, -EINVAL on error.

 Wait forever for a free tcs. It better be there eventually! */

		/*

		 * Clear previously programmed WAKE commands in selected

		 * repurposed TCS to avoid triggering them. tcs->slots will be

		 * cleaned from rpmh_flush() by invoking rpmh_rsc_invalidate()

	/*

	 * These two can be done after the lock is released because:

	 * - We marked "tcs_in_use" under lock.

	 * - Once "tcs_in_use" has been marked nobody else could be writing

	 *   to these registers until the interrupt goes off.

	 * - The interrupt can't go off until we trigger w/ the last line

	 *   of __tcs_set_trigger() below.

/**

 * find_slots() - Find a place to write the given message.

 * @tcs:    The tcs group to search.

 * @msg:    The message we want to find room for.

 * @tcs_id: If we return 0 from the function, we return the global ID of the

 *          TCS to write to here.

 * @cmd_id: If we return 0 from the function, we return the index of

 *          the command array of the returned TCS where the client should

 *          start writing the message.

 *

 * Only for use on sleep/wake TCSes since those are the only ones we maintain

 * tcs->slots for.

 *

 * Return: -ENOMEM if there was no room, else 0.

 Do over, until we can fit the full payload in a single TCS */

/**

 * rpmh_rsc_write_ctrl_data() - Write request to controller but don't trigger.

 * @drv: The controller.

 * @msg: The data to be written to the controller.

 *

 * This should only be called for for sleep/wake state, never active-only

 * state.

 *

 * The caller must ensure that no other RPMH actions are happening and the

 * controller is idle when this function is called since it runs lockless.

 *

 * Return: 0 if no error; else -error.

 find the TCS id and the command in the TCS to write to */

/**

 * rpmh_rsc_ctrlr_is_busy() - Check if any of the AMCs are busy.

 * @drv: The controller

 *

 * Checks if any of the AMCs are busy in handling ACTIVE sets.

 * This is called from the last cpu powering down before flushing

 * SLEEP and WAKE sets. If AMCs are busy, controller can not enter

 * power collapse, so deny from the last cpu's pm notification.

 *

 * Context: Must be called with the drv->lock held.

 *

 * Return:

 * * False		- AMCs are idle

 * * True		- AMCs are busy

	/*

	 * If we made an active request on a RSC that does not have a

	 * dedicated TCS for active state use, then re-purposed wake TCSes

	 * should be checked for not busy, because we used wake TCSes for

	 * active requests in this case.

/**

 * rpmh_rsc_cpu_pm_callback() - Check if any of the AMCs are busy.

 * @nfb:    Pointer to the notifier block in struct rsc_drv.

 * @action: CPU_PM_ENTER, CPU_PM_ENTER_FAILED, or CPU_PM_EXIT.

 * @v:      Unused

 *

 * This function is given to cpu_pm_register_notifier so we can be informed

 * about when CPUs go down. When all CPUs go down we know no more active

 * transfers will be started so we write sleep/wake sets. This function gets

 * called from cpuidle code paths and also at system suspend time.

 *

 * If its last CPU going down and AMCs are not busy then writes cached sleep

 * and wake messages to TCSes. The firmware then takes care of triggering

 * them when entering deepest low power modes.

 *

 * Return: See cpu_pm_register_notifier()

		/*

		 * NOTE: comments for num_online_cpus() point out that it's

		 * only a snapshot so we need to be careful. It should be OK

		 * for us to use, though.  It's important for us not to miss

		 * if we're the last CPU going down so it would only be a

		 * problem if a CPU went offline right after we did the check

		 * AND that CPU was not idle AND that CPU was the last non-idle

		 * CPU. That can't happen. CPUs would have to come out of idle

		 * before the CPU could go offline.

	/*

	 * It's likely we're on the last CPU. Grab the drv->lock and write

	 * out the sleep/wake commands to RPMH hardware. Grabbing the lock

	 * means that if we race with another CPU coming up we are still

	 * guaranteed to be safe. If another CPU came up just after we checked

	 * and has grabbed the lock or started an active transfer then we'll

	 * notice we're busy and abort. If another CPU comes up after we start

	 * flushing it will be blocked from starting an active transfer until

	 * we're done flushing. If another CPU starts an active transfer after

	 * we release the lock we're still OK because we're no longer the last

	 * CPU.

 Another CPU must be up */

 Double-check if we're here because someone else is up */

 We won't be called w/ CPU_PM_ENTER_FAILED */

	/*

	 * Even though RPMh doesn't directly use cmd-db, all of its children

	 * do. To avoid adding this check to our children we'll do it now.

	/*

	 * CPU PM notification are not required for controllers that support

	 * 'HW solver' mode where they can be in autonomous mode executing low

	 * power mode to power down.

 Enable the active TCS to send requests immediately */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Qualcomm Peripheral Image Loader

 *

 * Copyright (C) 2016 Linaro Ltd

 * Copyright (C) 2015 Sony Mobile Communications Inc

 * Copyright (c) 2012-2013, The Linux Foundation. All rights reserved.

/**

 * qcom_mdt_get_size() - acquire size of the memory region needed to load mdt

 * @fw:		firmware object for the mdt file

 *

 * Returns size of the loaded firmware blob, or -EINVAL on failure.

/**

 * qcom_mdt_read_metadata() - read header and metadata from mdt or mbn

 * @fw:		firmware of mdt header or mbn

 * @data_len:	length of the read metadata blob

 *

 * The mechanism that performs the authentication of the loading firmware

 * expects an ELF header directly followed by the segment of hashes, with no

 * padding inbetween. This function allocates a chunk of memory for this pair

 * and copy the two pieces into the buffer.

 *

 * In the case of split firmware the hash is found directly following the ELF

 * header, rather than at p_offset described by the second program header.

 *

 * The caller is responsible to free (kfree()) the returned pointer.

 *

 * Return: pointer to data, or ERR_PTR()

 Is the header and hash already packed */

 Invalid firmware metadata */

 Unable to set up relocation */

		/*

		 * The image is relocatable, so offset each segment based on

		 * the lowest segment address.

		/*

		 * Image is not relocatable, so offset each segment based on

		 * the allocated physical chunk of memory.

 Firmware is large enough to be non-split */

 Firmware not large enough, load split-out segments */

/**

 * qcom_mdt_load() - load the firmware which header is loaded as fw

 * @dev:	device handle to associate resources with

 * @fw:		firmware object for the mdt file

 * @firmware:	name of the firmware, for construction of segment file names

 * @pas_id:	PAS identifier

 * @mem_region:	allocated memory region to load firmware into

 * @mem_phys:	physical address of allocated memory region

 * @mem_size:	size of the allocated memory region

 * @reloc_base:	adjusted physical address after relocation

 *

 * Returns 0 on success, negative errno otherwise.

/**

 * qcom_mdt_load_no_init() - load the firmware which header is loaded as fw

 * @dev:	device handle to associate resources with

 * @fw:		firmware object for the mdt file

 * @firmware:	name of the firmware, for construction of segment file names

 * @pas_id:	PAS identifier

 * @mem_region:	allocated memory region to load firmware into

 * @mem_phys:	physical address of allocated memory region

 * @mem_size:	size of the allocated memory region

 * @reloc_base:	adjusted physical address after relocation

 *

 * Returns 0 on success, negative errno otherwise.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016, Linaro Ltd.

 * Copyright (c) 2015, Sony Mobile Communications Inc.

/**

 * struct wcnss_ctrl - driver context

 * @dev:	device handle

 * @channel:	SMD channel handle

 * @ack:	completion for outstanding requests

 * @cbc:	completion for cbc complete indication

 * @ack_status:	status of the outstanding request

 * @probe_work: worker for uploading nv binary

 message types */

/**

 * struct wcnss_msg_hdr - common packet header for requests and responses

 * @type:	packet message type

 * @len:	total length of the packet, including this header

/*

 * struct wcnss_version_resp - version request response

/**

 * struct wcnss_download_nv_req - firmware fragment request

 * @hdr:	common packet wcnss_msg_hdr header

 * @seq:	sequence number of this fragment

 * @last:	boolean indicator of this being the last fragment of the binary

 * @frag_size:	length of this fragment

 * @fragment:	fragment data

/**

 * struct wcnss_download_nv_resp - firmware download response

 * @hdr:	common packet wcnss_msg_hdr header

 * @status:	boolean to indicate success of the download

/**

 * wcnss_ctrl_smd_callback() - handler from SMD responses

 * @rpdev:	remote processor message device pointer

 * @data:	pointer to the incoming data packet

 * @count:	size of the incoming data packet

 * @priv:	unused

 * @addr:	unused

 *

 * Handles any incoming packets from the remote WCNSS_CTRL service.

/**

 * wcnss_request_version() - send a version request to WCNSS

 * @wcnss:	wcnss ctrl driver context

/**

 * wcnss_download_nv() - send nv binary to WCNSS

 * @wcnss:	wcnss_ctrl state handle

 * @expect_cbc:	indicator to caller that an cbc event is expected

 *

 * Returns 0 on success. Negative errno on failure.

 Increment for next fragment */

/**

 * qcom_wcnss_open_channel() - open additional SMD channel to WCNSS

 * @wcnss:	wcnss handle, retrieved from drvdata

 * @name:	SMD channel name

 * @cb:		callback to handle incoming data on the channel

 * @priv:	private data for use in the call-back

 Wait for pending cold boot completion if indicated by the nv downloader */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2011-2014, The Linux Foundation. All rights reserved.

 * Copyright (c) 2014,2015, Linaro Ltd.

 *

 * SAW power controller driver

 SPM register data for 8916 */

 SPM register data for 8974, 8084 */

 SPM register data for 8226 */

 SPM register data for 8064 */

 Ensure a guaranteed write, before return */

 Write the SPM sequences first.. */

	/*

	 * ..and then the control registers.

	 * On some SoC if the control registers are written first and if the

	 * CPU was held in reset, the reset signal could trigger the SPM state

	 * machine, before the sequences are completely written.

 Set up Standby as the default low power mode */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2016-2018, The Linux Foundation. All rights reserved.

/**

 * struct cache_req: the request object for caching

 *

 * @addr: the address of the resource

 * @sleep_val: the sleep vote

 * @wake_val: the wake vote

 * @list: linked list obj

/**

 * struct batch_cache_req - An entry in our batch catch

 *

 * @list: linked list obj

 * @count: number of messages

 * @rpm_msgs: the messages

 Signal the blocking thread we are done */

/**

 * __rpmh_write: Cache and send the RPMH request

 *

 * @dev: The device making the request

 * @state: Active/Sleep request type

 * @rpm_msg: The data that needs to be sent (cmds).

 *

 * Cache the RPMH request and send if the state is ACTIVE_ONLY.

 * SLEEP/WAKE_ONLY requests are not sent to the controller at

 * this time. Use rpmh_flush() to send them to the controller.

 Cache the request in our store and link the payload */

 Clean up our call by spoofing tx_done */

/**

 * rpmh_write_async: Write a set of RPMH commands

 *

 * @dev: The device making the request

 * @state: Active/sleep set

 * @cmd: The payload data

 * @n: The number of elements in payload

 *

 * Write a set of RPMH commands, the order of commands is maintained

 * and will be sent as a single shot.

/**

 * rpmh_write: Write a set of RPMH commands and block until response

 *

 * @dev: The device making the request

 * @state: Active/sleep set

 * @cmd: The payload data

 * @n: The number of elements in @cmd

 *

 * May sleep. Do not call from atomic contexts.

 Send Sleep/Wake requests to the controller, expect no response */

/**

 * rpmh_write_batch: Write multiple sets of RPMH commands and wait for the

 * batch to finish.

 *

 * @dev: the device making the request

 * @state: Active/sleep set

 * @cmd: The payload data

 * @n: The array of count of elements in each batch, 0 terminated.

 *

 * Write a request to the RSC controller without caching. If the request

 * state is ACTIVE, then the requests are treated as completion request

 * and sent to the controller immediately. The function waits until all the

 * commands are complete. If the request was to SLEEP or WAKE_ONLY, then the

 * request is sent as fire-n-forget and no ack is expected.

 *

 * May sleep. Do not call from atomic contexts for ACTIVE_ONLY requests.

			/*

			 * Better hope they never finish because they'll signal

			 * the completion that we're going to free once

			 * we've returned from this function.

 Wake sets are always complete and sleep sets are not */

/**

 * rpmh_flush() - Flushes the buffered sleep and wake sets to TCSes

 *

 * @ctrlr: Controller making request to flush cached data

 *

 * Return:

 * * 0          - Success

 * * Error code - Otherwise

	/*

	 * Currently rpmh_flush() is only called when we think we're running

	 * on the last processor.  If the lock is busy it means another

	 * processor is up and it's better to abort than spin.

 Invalidate the TCSes first to avoid stale data */

 First flush the cached batch requests */

/**

 * rpmh_invalidate: Invalidate sleep and wake sets in batch_cache

 *

 * @dev: The device making the request

 *

 * Invalidate the sleep and wake values in batch_cache.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Sony Mobile Communications AB.

 * Copyright (c) 2012-2013, The Linux Foundation. All rights reserved.

/*

 * The Qualcomm shared memory system is a allocate only heap structure that

 * consists of one of more memory areas that can be accessed by the processors

 * in the SoC.

 *

 * All systems contains a global heap, accessible by all processors in the SoC,

 * with a table of contents data structure (@smem_header) at the beginning of

 * the main shared memory block.

 *

 * The global header contains meta data for allocations as well as a fixed list

 * of 512 entries (@smem_global_entry) that can be initialized to reference

 * parts of the shared memory space.

 *

 *

 * In addition to this global heap a set of "private" heaps can be set up at

 * boot time with access restrictions so that only certain processor pairs can

 * access the data.

 *

 * These partitions are referenced from an optional partition table

 * (@smem_ptable), that is found 4kB from the end of the main smem region. The

 * partition table entries (@smem_ptable_entry) lists the involved processors

 * (or hosts) and their location in the main shared memory region.

 *

 * Each partition starts with a header (@smem_partition_header) that identifies

 * the partition and holds properties for the two internal memory regions. The

 * two regions are cached and non-cached memory respectively. Each region

 * contain a link list of allocation headers (@smem_private_entry) followed by

 * their data.

 *

 * Items in the non-cached region are allocated from the start of the partition

 * while items in the cached region are allocated from the end. The free area

 * is hence the region between the cached and non-cached offsets. The header of

 * cached items comes after the data.

 *

 * Version 12 (SMEM_GLOBAL_PART_VERSION) changes the item alloc/get procedure

 * for the global heap. A new global partition is created from the global heap

 * region with partition type (SMEM_GLOBAL_HOST) and the max smem item count is

 * set by the bootloader.

 *

 * To synchronize allocations in the shared memory heaps a remote spinlock must

 * be held - currently lock number 3 of the sfpb or tcsr is used for this on all

 * platforms.

 *

/*

 * The version member of the smem header contains an array of versions for the

 * various software components in the SoC. We verify that the boot loader

 * version is a valid version as a sanity check.

/*

 * The first 8 items are only to be allocated by the boot loader while

 * initializing the heap.

 Highest accepted item number, for both global and private heaps */

 Processor/host identifier for the application processor */

 Processor/host identifier for the global partition */

 Max number of processors/hosts in a system */

/**

  * struct smem_proc_comm - proc_comm communication struct (legacy)

  * @command:	current command to be executed

  * @status:	status of the currently requested command

  * @params:	parameters to the command

/**

 * struct smem_global_entry - entry to reference smem items on the heap

 * @allocated:	boolean to indicate if this entry is used

 * @offset:	offset to the allocated space

 * @size:	size of the allocated space, 8 byte aligned

 * @aux_base:	base address for the memory region used by this unit, or 0 for

 *		the default region. bits 0,1 are reserved

 bits 1:0 reserved */

/**

 * struct smem_header - header found in beginning of primary smem region

 * @proc_comm:		proc_comm communication interface (legacy)

 * @version:		array of versions for the various subsystems

 * @initialized:	boolean to indicate that smem is initialized

 * @free_offset:	index of the first unallocated byte in smem

 * @available:		number of bytes available for allocation

 * @reserved:		reserved field, must be 0

 * @toc:		array of references to items

/**

 * struct smem_ptable_entry - one entry in the @smem_ptable list

 * @offset:	offset, within the main shared memory region, of the partition

 * @size:	size of the partition

 * @flags:	flags for the partition (currently unused)

 * @host0:	first processor/host with access to this partition

 * @host1:	second processor/host with access to this partition

 * @cacheline:	alignment for "cached" entries

 * @reserved:	reserved entries for later use

/**

 * struct smem_ptable - partition table for the private partitions

 * @magic:	magic number, must be SMEM_PTABLE_MAGIC

 * @version:	version of the partition table

 * @num_entries: number of partitions in the table

 * @reserved:	for now reserved entries

 * @entry:	list of @smem_ptable_entry for the @num_entries partitions

 "$TOC" */

/**

 * struct smem_partition_header - header of the partitions

 * @magic:	magic number, must be SMEM_PART_MAGIC

 * @host0:	first processor/host with access to this partition

 * @host1:	second processor/host with access to this partition

 * @size:	size of the partition

 * @offset_free_uncached: offset to the first free byte of uncached memory in

 *		this partition

 * @offset_free_cached: offset to the first free byte of cached memory in this

 *		partition

 * @reserved:	for now reserved entries

/**

 * struct smem_private_entry - header of each item in the private partition

 * @canary:	magic number, must be SMEM_PRIVATE_CANARY

 * @item:	identifying number of the smem item

 * @size:	size of the data, including padding bytes

 * @padding_data: number of bytes of padding of data

 * @padding_hdr: number of bytes of padding between the header and the data

 * @reserved:	for now reserved entry

 bytes are the same so no swapping needed */

 includes padding bytes */

/**

 * struct smem_info - smem region info located after the table of contents

 * @magic:	magic number, must be SMEM_INFO_MAGIC

 * @size:	size of the smem region

 * @base_addr:	base address of the smem region

 * @reserved:	for now reserved entry

 * @num_items:	highest accepted item number

 SIII */

/**

 * struct smem_region - representation of a chunk of memory used for smem

 * @aux_base:	identifier of aux_mem base

 * @virt_base:	virtual base address of memory with this aux_mem identifier

 * @size:	size of the memory region

/**

 * struct qcom_smem - device data for the smem device

 * @dev:	device pointer

 * @hwlock:	reference to a hwspinlock

 * @global_partition:	pointer to global partition when in use

 * @global_cacheline:	cacheline size for global partition

 * @partitions:	list of pointers to partitions affecting the current

 *		processor/host

 * @cacheline:	list of cacheline sizes for each host

 * @item_count: max accepted item number

 * @socinfo:	platform device pointer

 * @num_regions: number of @regions

 * @regions:	list of the memory regions defining the shared memory

 Pointer to the one and only smem handle */

 Timeout (ms) for the trylock of remote spinlocks */

 Check that we don't grow into the cached region */

	/*

	 * Ensure the header is written before we advance the free offset, so

	 * that remote processors that does not take the remote spinlock still

	 * gets a consistent view of the linked list.

	/*

	 * Ensure the header is consistent before we mark the item allocated,

	 * so that remote processors will get a consistent view of the item

	 * even though they do not take the spinlock on read.

/**

 * qcom_smem_alloc() - allocate space for a smem item

 * @host:	remote processor id, or -1

 * @item:	smem item handle

 * @size:	number of bytes to be allocated

 *

 * Allocate space for a given smem item of size @size, given that the item is

 * not yet allocated.

 Item was not found in the uncached list, search the cached list */

/**

 * qcom_smem_get() - resolve ptr of size of a smem item

 * @host:	the remote processor, or -1

 * @item:	smem item handle

 * @size:	pointer to be filled out with size of the item

 *

 * Looks up smem item and returns pointer to it. Size of smem

 * item is returned in @size.

/**

 * qcom_smem_get_free_space() - retrieve amount of free space in a partition

 * @host:	the remote processor identifying a partition, or -1

 *

 * To be used by smem clients as a quick way to determine if any new

 * allocations has been made.

/**

 * qcom_smem_virt_to_phys() - return the physical address associated

 * with an smem item pointer (previously returned by qcom_smem_get()

 * @p:	the virtual address to convert

 *

 * Returns 0 if the pointer provided is not within any smem region.

/*

 * Validate the partition header for a partition whose partition

 * table entry is supplied.  Returns a pointer to its header if

 * valid, or a null pointer otherwise.

		/*

		 * Fall back to the memory-region reference, if we're not a

		 * reserved-memory node.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Sony Mobile Communications Inc.

 * Copyright (c) 2012-2013, The Linux Foundation. All rights reserved.

/*

 * This driver implements the Qualcomm Shared Memory State Machine, a mechanism

 * for communicating single bit state information to remote processors.

 *

 * The implementation is based on two sections of shared memory; the first

 * holding the state bits and the second holding a matrix of subscription bits.

 *

 * The state bits are structured in entries of 32 bits, each belonging to one

 * system in the SoC. The entry belonging to the local system is considered

 * read-write, while the rest should be considered read-only.

 *

 * The subscription matrix consists of N bitmaps per entry, denoting interest

 * in updates of the entry for each of the N hosts. Upon updating a state bit

 * each host's subscription bitmap should be queried and the remote system

 * should be interrupted if they request so.

 *

 * The subscription matrix is laid out in entry-major order:

 * entry0: [host0 ... hostN]

 *	.

 *	.

 * entryM: [host0 ... hostN]

 *

 * A third, optional, shared memory region might contain information regarding

 * the number of entries in the state bitmap as well as number of columns in

 * the subscription matrix.

/*

 * Shared memory identifiers, used to acquire handles to respective memory

 * region.

/*

 * Default sizes, in case SMEM_SMSM_SIZE_INFO is not found.

/**

 * struct qcom_smsm - smsm driver context

 * @dev:	smsm device pointer

 * @local_host:	column in the subscription matrix representing this system

 * @num_hosts:	number of columns in the subscription matrix

 * @num_entries: number of entries in the state map and rows in the subscription

 *		matrix

 * @local_state: pointer to the local processor's state bits

 * @subscription: pointer to local processor's row in subscription matrix

 * @state:	smem state handle

 * @lock:	spinlock for read-modify-write of the outgoing state

 * @entries:	context for each of the entries

 * @hosts:	context for each of the hosts

/**

 * struct smsm_entry - per remote processor entry context

 * @smsm:	back-reference to driver context

 * @domain:	IRQ domain for this entry, if representing a remote system

 * @irq_enabled: bitmap of which state bits IRQs are enabled

 * @irq_rising:	bitmap tracking if rising bits should be propagated

 * @irq_falling: bitmap tracking if falling bits should be propagated

 * @last_value:	snapshot of state bits last time the interrupts where propagated

 * @remote_state: pointer to this entry's state bits

 * @subscription: pointer to a row in the subscription matrix representing this

 *		entry

/**

 * struct smsm_host - representation of a remote host

 * @ipc_regmap:	regmap for outgoing interrupt

 * @ipc_offset:	offset in @ipc_regmap for outgoing interrupt

 * @ipc_bit:	bit in @ipc_regmap + @ipc_offset for outgoing interrupt

/**

 * smsm_update_bits() - change bit in outgoing entry and inform subscribers

 * @data:	smsm context pointer

 * @mask:	value mask

 * @value:	new value

 *

 * Used to set and clear the bits in the outgoing/local entry and inform

 * subscribers about the change.

 Update the entry */

 Don't signal if we didn't change the value */

 Write out the new value */

 Make sure the value update is ordered before any kicks */

 Iterate over all hosts to check whom wants a kick */

/**

 * smsm_intr() - cascading IRQ handler for SMSM

 * @irq:	unused

 * @data:	entry related to this IRQ

 *

 * This function cascades an incoming interrupt from a remote system, based on

 * the state bits and configuration.

/**

 * smsm_mask_irq() - un-subscribe from cascades of IRQs of a certain staus bit

 * @irqd:	IRQ handle to be masked

 *

 * This un-subscribes the local CPU from interrupts upon changes to the defines

 * status bit. The bit is also cleared from cascading.

/**

 * smsm_unmask_irq() - subscribe to cascades of IRQs of a certain status bit

 * @irqd:	IRQ handle to be unmasked

 *

 * This subscribes the local CPU to interrupts upon changes to the defined

 * status bit. The bit is also marked for cascading.

 Make sure our last cached state is up-to-date */

/**

 * smsm_set_irq_type() - updates the requested IRQ type for the cascading

 * @irqd:	consumer interrupt handle

 * @type:	requested flags

/**

 * smsm_irq_map() - sets up a mapping for a cascaded IRQ

 * @d:		IRQ domain representing an entry

 * @irq:	IRQ to set up

 * @hw:		unused

/**

 * smsm_parse_ipc() - parses a qcom,ipc-%d device tree property

 * @smsm:	smsm driver context

 * @host_id:	index of the remote host to be resolved

 *

 * Parses device tree to acquire the information needed for sending the

 * outgoing interrupts to a remote host - identified by @host_id.

/**

 * smsm_inbound_entry() - parse DT and set up an entry representing a remote system

 * @smsm:	smsm driver context

 * @entry:	entry context to be set up

 * @node:	dt node containing the entry's properties

/**

 * smsm_get_size_info() - parse the optional memory segment for sizes

 * @smsm:	smsm driver context

 *

 * Attempt to acquire the number of hosts and entries from the optional shared

 * memory location. Not being able to find this segment should indicate that

 * we're on a older system where these values was hard coded to

 * SMSM_DEFAULT_NUM_ENTRIES and SMSM_DEFAULT_NUM_HOSTS.

 *

 * Returns 0 on success, negative errno on failure.

 Parse the host properties */

 Acquire the main SMSM state vector */

 Acquire the list of interrupt mask vectors */

 Setup the reference to the local state bits */

 Register the outgoing state */

 Register handlers for remote processor entries of interest. */

 Setup subscription pointers and unsubscribe to any kicks */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015, Sony Mobile Communications AB.

 * Copyright (c) 2012-2013, The Linux Foundation. All rights reserved.

/**

 * struct qcom_smd_rpm - state of the rpm device driver

 * @rpm_channel:	reference to the smd channel

 * @icc:		interconnect proxy device

 * @dev:		rpm device

 * @ack:		completion for acks

 * @lock:		mutual exclusion around the send/complete pair

 * @ack_status:		result of the rpm request

/**

 * struct qcom_rpm_header - header for all rpm requests and responses

 * @service_type:	identifier of the service

 * @length:		length of the payload

/**

 * struct qcom_rpm_request - request message to the rpm

 * @msg_id:	identifier of the outgoing message

 * @flags:	active/sleep state flags

 * @type:	resource type

 * @id:		resource id

 * @data_len:	length of the payload following this header

/**

 * struct qcom_rpm_message - response message from the rpm

 * @msg_type:	indicator of the type of message

 * @length:	the size of this message, including the message header

 * @msg_id:	message id

 * @message:	textual message from the rpm

 *

 * Multiple of these messages can be stacked in an rpm message.

 "req\0" */

 "err\0" */

 "msg#" */

/**

 * qcom_rpm_smd_write - write @buf to @type:@id

 * @rpm:	rpm handle

 * @state:	active/sleep state flags

 * @type:	resource type

 * @id:		resource identifier

 * @buf:	the data to be written

 * @count:	number of bytes in @buf

 SMD packets to the RPM may not exceed 256 bytes */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2019, Linaro Ltd

 AOP-side offsets */

 Linux-side offsets */

 mail */

 64 bytes is enough to store the requests and provides padding to 4 bytes */

/**

 * struct qmp - driver state for QMP implementation

 * @msgram: iomem referencing the message RAM used for communication

 * @dev: reference to QMP device

 * @mbox_client: mailbox client used to ring the doorbell on transmit

 * @mbox_chan: mailbox channel used to ring the doorbell on transmit

 * @offset: offset within @msgram where messages should be written

 * @size: maximum size of the messages to be transmitted

 * @event: wait_queue for synchronization with the IRQ

 * @tx_lock: provides synchronization between multiple callers of qmp_send()

 * @qdss_clk: QDSS clock hw struct

 * @cooling_devs: thermal cooling devices

 Ack remote core's link state */

 Set local core's link state to up */

 Ack remote core's channel state */

/**

 * qmp_send() - send a message to the AOSS

 * @qmp: qmp context

 * @data: message to be sent

 * @len: length of the message

 *

 * Transmit @data to AOSS and wait for the AOSS to acknowledge the message.

 * @len must be a multiple of 4 and not longer than the mailbox size. Access is

 * synchronized by this implementation.

 *

 * Return: 0 on success, negative errno on failure

 The message RAM only implements 32-bit accesses */

 Read back len to confirm data written in message RAM */

 Clear message from buffer */

 Normalize state */

/**

 * qmp_get() - get a qmp handle from a device

 * @dev: client device pointer

 *

 * Return: handle to qmp device on success, ERR_PTR() on failure

/**

 * qmp_put() - release a qmp handle

 * @qmp: qmp handle obtained from qmp_get()

	/*

	 * Match get_device() inside of_find_device_by_node() in

	 * qmp_get()

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2018, The Linux Foundation. All rights reserved.

/**

 * kryo_l2_set_indirect_reg() - write value to an L2 register

 * @reg: Address of L2 register.

 * @val: Value to be written to register.

 *

 * Use architecturally required barriers for ordering between system register

 * accesses, and system registers with respect to device memory

/**

 * kryo_l2_get_indirect_reg() - read an L2 register value

 * @reg: Address of L2 register.

 *

 * Use architecturally required barriers for ordering between system register

 * accesses, and system registers with respect to device memory

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017-2018, The Linux Foundation. All rights reserved. */

/* Resource types:

 Operation Keys */

 corn */

 swen */

 vfc */

 vfl */

 vlvl */

 mdm9607 RPM Power Domains */

 msm8939 RPM Power Domains */

 msm8916 RPM Power Domains */

 msm8953 RPM Power Domains */

 msm8976 RPM Power Domains */

 msm8994 RPM Power domains */

 Attention! *Some* 8994 boards with pm8004 may use SMPC here! */

 msm8996 RPM Power domains */

 msm8998 RPM Power domains */

 qcs404 RPM Power domains */

 sdm660 RPM Power domains */

 sm4250/6115 RPM Power domains */

 Always send updates for vfc and vfl */

 SPDX-License-Identifier: GPL-2.0

/*

 * ZynqMP Generic PM domain support

 *

 *  Copyright (C) 2015-2019 Xilinx, Inc.

 *

 *  Davorin Mista <davorin.mista@aggios.com>

 *  Jolly Shah <jollys@xilinx.com>

 *  Rajan Vaja <rajan.vaja@xilinx.com>

 Flag stating if PM nodes mapped to the PM domain has been requested */

/**

 * struct zynqmp_pm_domain - Wrapper around struct generic_pm_domain

 * @gpd:		Generic power domain

 * @node_id:		PM node ID corresponding to device inside PM domain

 * @flags:		ZynqMP PM domain flags

/**

 * zynqmp_gpd_is_active_wakeup_path() - Check if device is in wakeup source

 *					path

 * @dev:	Device to check for wakeup source path

 * @not_used:	Data member (not required)

 *

 * This function is checks device's child hierarchy and checks if any device is

 * set as wakeup source.

 *

 * Return: 1 if device is in wakeup source path else 0

/**

 * zynqmp_gpd_power_on() - Power on PM domain

 * @domain:	Generic PM domain

 *

 * This function is called before devices inside a PM domain are resumed, to

 * power on PM domain.

 *

 * Return: 0 on success, error code otherwise

/**

 * zynqmp_gpd_power_off() - Power off PM domain

 * @domain:	Generic PM domain

 *

 * This function is called after devices inside a PM domain are suspended, to

 * power off PM domain.

 *

 * Return: 0 on success, error code otherwise

 If domain is already released there is nothing to be done */

 If device is in wakeup path, set capability to WAKEUP */

	/**

	 * If powering down of any node inside this domain fails,

	 * report and return the error

/**

 * zynqmp_gpd_attach_dev() - Attach device to the PM domain

 * @domain:	Generic PM domain

 * @dev:	Device to attach

 *

 * Return: 0 on success, error code otherwise

 If this is not the first device to attach there is nothing to do */

 If requesting a node fails print and return the error */

/**

 * zynqmp_gpd_detach_dev() - Detach device from the PM domain

 * @domain:	Generic PM domain

 * @dev:	Device to detach

 If this is not the last device to detach there is nothing to do */

 If releasing a node fails print the error and return */

 Check for existing pm domains */

	/**

	 * Add index in empty node_id of power domain list as no existing

	 * power domain found for current index.

 Mark all PM domains as initially powered off */

 SPDX-License-Identifier: GPL-2.0

/*

 * Xilinx Zynq MPSoC Power Management

 *

 *  Copyright (C) 2014-2019 Xilinx, Inc.

 *

 *  Davorin Mista <davorin.mista@aggios.com>

 *  Jolly Shah <jollys@xilinx.com>

 *  Rajan Vaja <rajan.vaja@xilinx.com>

/**

 * struct zynqmp_pm_work_struct - Wrapper for struct work_struct

 * @callback_work:	Work structure

 * @args:		Callback arguments

 First element is callback API ID, others are callback arguments */

 First element is callback API ID, others are callback arguments */

 Copy callback arguments into work's structure */

 Send NULL message to mbox controller to ack the message */

/**

 * zynqmp_pm_init_suspend_work_fn - Initialize suspend

 * @work:	Pointer to work_struct

 *

 * Bottom-half of PM callback IRQ handler.

 Convert last space to newline */

 Check PM API version number */

 end of table */ },

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011-2015 Samsung Electronics Co., Ltd.

		http:


 Exynos5250 - CPU PMU (Power Management Unit) support

 { .offset = offset, .val = { AFTR, LPA, SLEEP } */

	/*

	 * When SYS_WDTRESET is set, watchdog timer reset request

	 * is ignored by power management unit.

	/*

	 * Enable both SC_FEEDBACK and SC_COUNTER

	/*

	 * SKIP_DEACTIVATE_ACEACP_IN_PWDN_BITFIELD Enable

	/*

	 * Disable WFI/WFE on XXX_OPTION

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011-2015 Samsung Electronics Co., Ltd.

		http:


 Exynos5420 - CPU PMU (Power Management Unit) support

 { .offset = offset, .val = { AFTR, LPA, SLEEP } */

	/*

	 * set the cluster id to IROM register to ensure that we wake

	 * up with the current cluster.

	/*

	 * Set the CMU_RESET, CMU_SYSCLK and CMU_CLKSTOP registers

	 * for local power blocks to Low initially as per Table 8-4:

	 * "System-Level Power-Down Configuration Registers".

 Enable USE_STANDBY_WFI for all CORE */

	/*

	 * If L2_COMMON is turned off, clocks related to ATB async

	 * bridge are gated. Thus, when ISP power is gated, LPI

	 * may get stuck.

 Prevent issue of new bus request from L2 memory */

 This setting is to reduce suspend/resume time */

 Serialized CPU wakeup of Eagle */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2019 Samsung Electronics Co., Ltd.

 *	      http://www.samsung.com/

 *

 * Samsung Exynos 5422 SoC Adaptive Supply Voltage support

/*

 * This array is a set of 4 ASV data tables, first column of each ASV table

 * contains frequency value in MHz and subsequent columns contain the CPU

 * cluster's supply voltage values in uV.

 * In order to create a set of OPPs for specific SoC revision one of the voltage

 * columns (1...14) from one of the tables (0...3) is selected during

 * initialization. There are separate ASV tables for the big (ARM) and little

 * (KFC) CPU cluster. Only OPPs which are already defined in devicetree

 * will be updated.

 ARM 0, 1 */

 ARM 2 */

 ARM 3 */

 ARM bin 2 */

 KFC 0, 1 */

 KFC 2 */

 KFC 3 */

 KFC bin 2 */

 ARM offset voltage setup */

 KFC offset voltage setup */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011-2015 Samsung Electronics Co., Ltd.

		http:


 Exynos4 - CPU PMU(Power Management Unit) support

 { .offset = offset, .val = { AFTR, LPA, SLEEP } */

 XXX_OPTION register should be set other field */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2019 Samsung Electronics Co., Ltd.

 *	      http://www.samsung.com/

 * Copyright (c) 2020 Krzysztof Kozlowski <krzk@kernel.org>

 *

 * Exynos - CHIP ID support

 * Author: Pankaj Dubey <pankaj.dubey@samsung.com>

 * Author: Bartlomiej Zolnierkiewicz <b.zolnierkie@samsung.com>

 * Author: Krzysztof Kozlowski <krzk@kernel.org>

 *

 * Samsung Exynos SoC Adaptive Supply Voltage and Chip ID support

 revision register offset */

 main revision offset in rev_reg */

 sub revision offset in rev_reg */

 List ordered by SoC name */

 EVT0 revision */

 please note that the actual registration will be deferred */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2019 Samsung Electronics Co., Ltd.

 *	      http://www.samsung.com/

 * Copyright (c) 2020 Krzysztof Kozlowski <krzk@kernel.org>

 * Author: Sylwester Nawrocki <s.nawrocki@samsung.com>

 * Author: Krzysztof Kozlowski <krzk@kernel.org>

 *

 * Samsung Exynos SoC Adaptive Supply Voltage support

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011-2014 Samsung Electronics Co., Ltd.

		http:


 Exynos - CPU PMU(Power Management Unit) support

/*

 * Split the data between ARM architectures because it is relatively big

 * and useless on other arch.

/*

 * PMU platform driver and devicetree bindings.

sentinel*/ },

 SPDX-License-Identifier: GPL-2.0



 Exynos Generic power domain support.



 Copyright (c) 2012 Samsung Electronics Co., Ltd.

		http:


 Implementation of Exynos specific power domain control which is used in

 conjunction with runtime-pm. Support for both device-tree and non-device-tree

 based power domain support is included.

 Value for LOCAL_PWR_CFG and STATUS fields for each domain */

/*

 * Exynos specific wrapper around the generic power domain

 Wait max 1ms */

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2013 Samsung Electronics Co., Ltd.

	Tomasz Figa <t.figa@samsung.com>

 Copyright (C) 2008 Openmoko, Inc.

 Copyright (C) 2004-2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 Samsung common power management (suspend to RAM) debug support

 SPDX-License-Identifier: GPL-2.0



 originally in linux/arch/arm/plat-s3c24xx/pm.c



 Copyright (c) 2004-2008 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 S3C Power Mangament - suspend/resume memory corruption check.

/* suspend checking code...

 *

 * this next area does a set of crc checks over all the installed

 * memory, so the system can verify if the resume was ok.

 *

 * CONFIG_SAMSUNG_PM_CHECK_CHUNKSIZE defines the block-size for the CRC,

 * increasing it will mean that the area corrupted will be less easy to spot,

 * and reducing the size will cause the CRC save area to grow

 size needed for the crc block */

 allocated over suspend/resume */

/* s3c_pm_run_res

 *

 * go through the given resource list, and look for system ram

/* s3c_pm_prepare_check

 *

 * prepare the necessary information for creating the CRCs. This

 * must be done before the final save, as it will require memory

 * allocating, and thus touching bits of the kernel we do not

 * know about.

/* s3c_pm_check_store

 *

 * compute the CRC values for the memory blocks before the final

 * sleep.

/* in_region

 *

 * return TRUE if the area defined by ptr..ptr+size contains the

 * what..what+whatsz

/**

 * s3c_pm_runcheck() - helper to check a resource on restore.

 * @res: The resource to check

 * @val: Pointer to list of CRC32 values to check.

 *

 * Called from the s3c_pm_check_restore() via s3c_pm_run_sysram(), this

 * function runs the given memory resource checking it against the stored

 * CRC to ensure that memory is restored. The function tries to skip as

 * many of the areas used during the suspend process.

 calculate and check the checksum */

/**

 * s3c_pm_check_restore() - memory check called on resume

 *

 * check the CRCs after the restore event and free the memory used

 * to hold them

/**

 * s3c_pm_check_cleanup() - free memory resources

 *

 * Free the resources that where allocated by the suspend

 * memory check code. We do this separately from the

 * s3c_pm_check_restore() function as we cannot call any

 * functions that might sleep during that resume.

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011-2015 Samsung Electronics Co., Ltd.

		http:


 Exynos3250 - CPU PMU (Power Management Unit) support

 { .offset = offset, .val = { AFTR, W-AFTR, SLEEP } */

 Enable only SC_FEEDBACK */

	/*

	 * To prevent from issuing new bus request form L2 memory system

	 * If core status is power down, should be set '1' to L2 power down

 Enable USE_STANDBY_WFI for all CORE */

	/*

	 * Set PSHOLD port for output high

	/*

	 * Enable signal for PSHOLD port

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2020 Samsung Electronics Co., Ltd.

 *	      http://www.samsung.com/

 * Author: Marek Szyprowski <m.szyprowski@samsung.com>

 *

 * Simplified generic voltage coupler from regulator core.c

 * The main difference is that it keeps current regulator voltage

 * if consumers didn't apply their constraints yet.

 Find highest min desired voltage */

 apply constraints */

	/*

	 * Let target_uV be equal to the desired one if possible.

	 * If not, set it to minimum voltage, allowed by other coupled

	 * regulators.

	/*

	 * Find min and max voltages, which currently aren't violating

	 * max_spread.

	/*

	 * Correct target voltage, so as it currently isn't

	 * violating max_spread

 Set current_uV if wasn't done earlier in the code and if necessary */

	/*

	 * Find the best possible voltage change on each loop. Leave the loop

	 * if there isn't any possible change.

		/*

		 * Find highest difference between optimal voltage

		 * and current voltage.

			/*

			 * optimal_uV is the best voltage that can be set for

			 * i-th regulator at the moment without violating

			 * max_spread constraint in order to balance

			 * the coupled voltages.

 Nothing to change, return successfully */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2019 Google Inc

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License

 * as published by the Free Software Foundation; either version

 * 2 of the License, or (at your option) any later version.

 *

 * Provides a simple driver to control the ASPEED P2A interface which allows

 * the host to read and write to various regions of the BMC's memory.

 SCU2C is a Misc. Control Register. */

 SCU180 is the PCIe Configuration Setting Control Register. */

/* Bit 1 controls the P2A bridge, while bit 0 controls the entire VGA device

 * on the PCI bus.

 The ast2400/2500 both have six ranges. */

 min, max, bit */

	/* Access to these needs to be locked, held via probe, mapping ioctl,

	 * and release, remove.

	/* The entire memory space is opened for reading once the bridge is

	 * enabled, therefore this needs only to be tracked once per user.

	 * If any user has it open for read, the bridge must stay enabled.

	/* Each entry of the array corresponds to a P2A Region.  If the user

	 * opens for read or readwrite, the reference goes up here.  On

	 * release, this array is walked and references adjusted accordingly.

 ast2400/2500 AHB accesses are not cache coherent */

 If the value is a legal u32, it will find a match. */

		/* If the top of this region is lower than your base, skip it.

		/* If the bottom of this region is higher than your end, bail.

		/* Lock this and update it, therefore it someone else is

		 * closing their file out, this'll preserve the increment.

		/* Track with the user, so when they close their file, we can

		 * decrement properly.

 Enable the region as read-write. */

		/* If they want a region to be read-only, since the entire

		 * region is read-only once enabled, we just need to track this

		 * user wants to read from the bridge, and if it's not enabled.

		 * Enable it.

			/* Track with the user, so when they close their file,

			 * we can decrement properly.

 If we don't acquire any region return error. */

 Invalid map flags. */

		/* This is a request for the memory-region and corresponding

		 * length that is used by the driver for mmap.

/*

 * When a user opens this file, we create a structure to track their mappings.

 *

 * A user can map a region as read-only (bridge enabled), or read-write (bit

 * flipped, and bridge enabled).  Either way, this tracking is used, s.t. when

 * they release the device references are handled.

 *

 * The bridge is not enabled until a user calls an ioctl to map a region,

 * simply opening the device does not enable it.

 The file's private_data is initialized to the p2a_ctrl. */

 Set the file's private_data to the user's data. */

/*

 * This will close the users mappings.  It will go through what they had opened

 * for readwrite, and decrement those counts.  If at the end, this is the last

 * user, it'll close the bridge.

	/* Lock others from changing these values until everything is updated

	 * in one pass.

	/* Setting a bit to 1 disables the region, so let's just OR with the

	 * above to disable any.

	/* Note, if another user is trying to ioctl, they can't grab tracking,

	 * and therefore can't grab either register mutex.

	 * If another user is trying to close, they can't grab tracking either.

	/* If parent->readers is zero and open windows is 0, disable the

	 * bridge.

 The regions are controlled by SCU2C */

 Disable the bridge. */

 optional. */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (c) 2018 Google LLC

 * Copyright (c) 2021 Aspeed Technology Inc.

 register offsets */

 attributes options */

 routing selector for AST25xx */

 routing selector for AST26xx */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2017 Google Inc

 *

 * Provides a simple driver to control the ASPEED LPC snoop interface which

 * allows the BMC to listen on and save the data written by

 * the host to an arbitrary LPC I/O port.

 *

 * Typically used by the BMC to "watch" host boot progress via port

 * 0x80 writes made by the BIOS during the boot process.

	/* The ast2400 has bits 14 and 15 as reserved, whereas the ast2500

	 * can use them.

 Save a byte to a FIFO and discard the oldest byte if FIFO is full */

 Check if one of the snoop channels is interrupting */

 Ack pending IRQs */

 Read and save most recent snoop'ed data byte to FIFO */

 Create FIFO datastructure */

 Enable LPC snoop channel at requested port */

 Configuration of 2nd snoop channel port is optional */

 Disable both snoop channels */

 SPDX-License-Identifier: GPL-2.0-or-later

 Copyright 2019 IBM Corp. */

 AST2400 */

 AST2500 */

 AST2600 */

 AST2500 and below */

 AST2600 */

 This is optional, the ast2400 does not have it */

	/*

	 * Machine: Romulus BMC

	 * Family: AST2500

	 * Revision: A1

	 * SoC ID: raw silicon revision id

	 * Serial Number: 64-bit chipid

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2017 IBM Corporation

 ast2400/2500 AHB accesses are not cache coherent */

 The flash windows don't report their size */

 Support more than one window id in the future */

 If memory-region is not described in device tree */

		/*

		 * The top half of HICR7 is the MSB of the BMC address of the

		 * mapping.

		 * The bottom half of HICR7 is the MSB of the HOST LPC

		 * firmware space address of the mapping.

		 *

		 * The 1 bits in the top of half of HICR8 represent the bits

		 * (in the requested address) that should be ignored and

		 * replaced with those from the top half of HICR7.

		 * The 1 bits in the bottom half of HICR8 represent the bits

		 * (in the requested address) that should be kept and pass

		 * into the BMC address space.

		/*

		 * It doesn't make sense to talk about a size or offset with

		 * low 16 bits set. Both HICR7 and HICR8 talk about the top 16

		 * bits of addresses and sizes.

		/*

		 * Because of the way the masks work in HICR8 offset has to

		 * be a multiple of size.

 If memory-region is not described in device tree */

 Check overflow first! */

		/*

		 * addr (host lpc address) is safe regardless of values. This

		 * simply changes the address the host has to request on its

		 * side of the LPC bus. This cannot impact the hosts own

		 * memory space by surprise as LPC specific accessors are

		 * required. The only strange thing that could be done is

		 * setting the lower 16 bits but the shift takes care of that.

		/*

		 * Switch to FWH2AHB mode, AST2600 only.

			/*

			 * Enable FWH2AHB in SCU debug control register 2. This

			 * does not turn it on, but makes it available for it

			 * to be configured in HICR6.

			/*

			 * The other bits in this register are interrupt status bits

			 * that are cleared by writing 1. As we don't want to clear

			 * them, set only the bit of interest.

		/*

		 * Enable LPC FHW cycles. This is required for the host to

		 * access the regions specified.

 If flash is described in device tree then store */

 If memory-region is described in device tree then store */

 SPDX-License-Identifier: GPL-2.0

/*

 * SiFive L2 cache controller Driver

 *

 * Copyright (C) 2018-2019 SiFive, Inc.

 *

 end of table */ },

 We want to use private group for L2 cache only */

 Reading this register clears the DirError interrupt sig */

 Reading this register clears the DirFail interrupt sig */

 Reading this register clears the DataError interrupt sig */

 Reading this register clears the DataFail interrupt sig */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Actions Semi Owl Smart Power System (SPS)

 *

 * Copyright 2012 Actions Semi Inc.

 * Author: Actions Semi, Inc.

 *

 * Copyright (c) 2017 Andreas Färber

 SPDX-License-Identifier: GPL-2.0+

/*

 * Actions Semi Owl Smart Power System (SPS) shared helpers

 *

 * Copyright 2012 Actions Semi Inc.

 * Author: Actions Semi, Inc.

 *

 * Copyright (c) 2017 Andreas Färber

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car E3 System Controller

 *

 * Copyright (C) 2018 Renesas Electronics Corp.

 Fixups for R-Car E3 ES1.0 revision */

 sentinel */ }

 Fix incorrect 3DG hierarchy */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas SoC Identification

 *

 * Copyright (C) 2014-2016 Glider bvba

 CCCR or PRR, if not in DT */

 PRR (Product Register) */

 PRR (Product Register) */

 PRR (Product Register) */

 CCCR (Common Chip Code Register) */

 PRR (Product Register) */

 PRR (Product Register) */

 CCCR (Common Chip Code Register) */

 sentinel */ }

		/*

		 * TODO: Upper 4 bits of BSID are for chip version, but the

		 * format is not known at this time so we don't know how to

		 * specify eshi and eslo

 Try PRR first, then hardcoded fallback */

 R-Car M3-W ES1.1 incorrectly identifies as ES2.0 */

 R-Car M3-W ES1.3 incorrectly identifies as ES2.1 */

 SPDX-License-Identifier: GPL-2.0

/*

 * R-Car Gen1 RESET/WDT, R-Car Gen2, Gen3, and RZ/G RST Driver

 *

 * Copyright (C) 2016 Glider bvba

 Mode Monitoring Register Offset */

 Platform specific config */

 MODEMR0 and it has CPG related bits */

 RZ/G1 is handled like R-Car Gen2 */

 RZ/G2 is handled like R-Car Gen3 */

 R-Car Gen1 */

 R-Car Gen2 */

 R-Car Gen3 */

 R-Car V3U */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * R9A06G032 Second CA7 enabler.

 *

 * Copyright (C) 2018 Renesas Electronics Europe Limited

 *

 * Michel Pollet <michel.pollet@bp.renesas.com>, <buserror@gmail.com>

 * Derived from actions,s500-smp

/*

 * The second CPU is parked in ROM at boot time. It requires waking it after

 * writing an address into the BOOTADDR register of sysctrl.

 *

 * So the default value of the "cpu-release-addr" corresponds to BOOTADDR...

 *

 * *However* the BOOTADDR register is not available when the kernel

 * starts in NONSEC mode.

 *

 * So for NONSEC mode, the bootloader re-parks the second CPU into a pen

 * in SRAM, and changes the "cpu-release-addr" of linux's DT to a SRAM address,

 * which is not restricted.

	/*

	 * Determine the address from which the CPU is polling.

	 * The bootloader *does* change this property.

	 * Note: The property can be either 64 or 32 bits, so handle both cases

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G2N System Controller

 * Copyright (C) 2019 Renesas Electronics Corp.

 *

 * Based on Renesas R-Car M3-W System Controller

 * Copyright (C) 2016 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car H1 System Controller

 *

 * Copyright (C) 2016 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G1E System Controller

 *

 * Copyright (C) 2016 Cogent Embedded Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * rmobile power management support

 *

 * Copyright (C) 2012  Renesas Solutions Corp.

 * Copyright (C) 2012  Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>

 * Copyright (C) 2014  Glider bvba

 *

 * based on pm-sh7372.c

 *  Copyright (C) 2011 Magnus Damm

 SYSC */

 SYS Power Down Control Register */

 SYS Wakeup Control Register */

 Power Status Register */

	/*

	 * Serial consoles make use of SCIF hardware located in this domain,

	 * hence keep the power domain on if "no_console_suspend" is set.

 sentinel */ },

 PM domains containing CPUs */

 PM domain containing console */

 PM domains containing other special devices */

		/*

		 * This domain contains the CPU core and therefore it should

		 * only be turned off if the CPU is not in use.

		/*

		 * This domain contains the Coresight-ETM hardware block and

		 * therefore it should only be turned off if the debug module

		 * is not in use.

		/*

		 * This domain contains a memory-controller and therefore it

		 * should only be turned off if memory is not in use.

 Top-level always-on domain */

 always-on domain */

 Find PM domains containing special blocks */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car V2H (R8A7792) System Controller

 *

 * Copyright (C) 2016 Cogent Embedded Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car V3M System Controller

 *

 * Copyright (C) 2017 Cogent Embedded Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G2E System Controller

 * Copyright (C) 2018 Renesas Electronics Corp.

 *

 * Based on Renesas R-Car E3 System Controller

 Fixups for RZ/G2E ES1.0 revision */

 sentinel */ }

 Fix incorrect 3DG hierarchy */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car M3-N System Controller

 * Copyright (C) 2018 Jacopo Mondi <jacopo+renesas@jmondi.org>

 *

 * Based on Renesas R-Car M3-W System Controller

 * Copyright (C) 2016 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car V3U System Controller

 *

 * Copyright (C) 2020 Renesas Electronics Corp.

/*

 * Power Domain flags

 Area contains main CPU core */

 Area contains SCU and L2 cache */

 Area lacks PWR{ON,OFF}CR registers */

 CPU area lacks CR */

 Always-on area */

/*

 * Description of a Power Area

 PDRn */

 -1 if none */

 See PD_* */

/*

 * SoC-specific Power Area Description

 SYSC Common */

 SYSC Status Register */

 Power-ON Status Register 0 */

 Power-OFF Status Register */

 Interrupt Status/Clear Register */

 Interrupt Enable Register */

 Interrupt Mask Register */

 Power Domain Registers */

 PWRON/PWROFF */

 Power-ON/OFF request */

 PDRESR */

 PDRSR */

 Power-OFF state */

 Power-ON state */

 Processing Power-OFF sequence */

 Processing Power-ON sequence */

 All bit sets is not busy */

 SMP CPUs + I/O devices */

 Wait until SYSC is ready to accept a power request */

 Submit power shutoff or power resume request */

	/*

	 * The interrupt source needs to be enabled, but masked, to prevent the

	 * CPU from receiving it.

 Submit power shutoff or resume request until it was accepted */

 Wait until the power shutoff or resume request has completed * */

 Clear interrupt flags */

		/*

		 * This domain contains a CPU core and therefore it should

		 * only be turned off if the CPU is not in use.

		/*

		 * This domain contains an SCU and cache-controller, and

		 * therefore it should only be turned off if the CPU cores are

		 * not in use.

		/*

		 * This domain cannot be turned off.

 Enable Clock Domain for I/O devices */

 Skip CPUs (handled by SMP code) and areas without control */

 sentinel */ }

 Skip NULLified area */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car E2 System Controller

 *

 * Copyright (C) 2016 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car M2-W/N System Controller

 *

 * Copyright (C) 2016 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car M3-W/W+ System Controller

 *

 * Copyright (C) 2016 Glider bvba

 * Copyright (C) 2018-2019 Renesas Electronics Corporation

 CONFIG_SYSC_R8A77960 */

 CONFIG_SYSC_R8A77961 */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G1M System Controller

 *

 * Copyright (C) 2016 Cogent Embedded Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G2M System Controller

 * Copyright (C) 2018 Renesas Electronics Corp.

 *

 * Based on Renesas R-Car M3-W System Controller

 * Copyright (C) 2016 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G1H System Controller

 *

 * Copyright (C) 2020 Renesas Electronics Corp.

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car H2 System Controller

 *

 * Copyright (C) 2016 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car D3 System Controller

 *

 * Copyright (C) 2017 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G2H System Controller

 * Copyright (C) 2020 Renesas Electronics Corp.

 *

 * Based on Renesas R-Car H3 System Controller

 * Copyright (C) 2016-2017 Glider bvba

 SPDX-License-Identifier: GPL-2.0

/*

 * R-Car SYSC Power management support

 *

 * Copyright (C) 2014  Magnus Damm

 * Copyright (C) 2015-2017 Glider bvba

 SYSC Common */

 SYSC Status Register */

 Interrupt Status Register */

 Interrupt Status Clear Register */

 Interrupt Enable Register */

 Interrupt Mask Register */

 SYSC Status Register */

 Ready for power resume requests */

 Ready for power shutoff requests */

/*

 * Power Control Register Offsets inside the register block for each domain

 * Note: The "CR" registers for ARM cores exist on H1 only

 *	 Use WFI to power off, CPG/APMU to resume ARM cores on R-Car Gen2

 *	 Use PSCI on R-Car Gen3

 Power Status Register */

 Power Shutoff Control Register */

 Power Shutoff Status Register */

 Power Resume Control Register */

 Power Resume Status Register */

 Power Shutoff/Resume Error */

 Always-on power area */

 SMP CPUs + I/O devices */

 Wait until SYSC is ready to accept a power request */

 Submit power shutoff or power resume request */

	/*

	 * Mask external power requests for CPU or 3DG domains

	/*

	 * The interrupt source needs to be enabled, but masked, to prevent the

	 * CPU from receiving it.

 Submit power shutoff or resume request until it was accepted */

 Wait until the power shutoff or resume request has completed * */

		/*

		 * This domain contains a CPU core and therefore it should

		 * only be turned off if the CPU is not in use.

		/*

		 * This domain contains an SCU and cache-controller, and

		 * therefore it should only be turned off if the CPU cores are

		 * not in use.

		/*

		 * This domain cannot be turned off.

 Enable Clock Domain for I/O devices */

 Skip CPUs (handled by SMP code) and areas without control */

 RZ/G1N is identical to RZ/G2M w.r.t. power domains. */

 R-Car M2-N is identical to R-Car M2-W w.r.t. power domains. */

 sentinel */ }

 Optional External Request Mask Register */

 Skip NULLified area */

 CONFIG_ARCH_R8A7779 */

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas RZ/G1C System Controller

 *

 * Copyright (C) 2018 Renesas Electronics Corp.

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car H3 System Controller

 *

 * Copyright (C) 2016-2017 Glider bvba

 A2VC0 exists on ES1.x only */

	/*

	 * Fixups for R-Car H3 revisions

 Power domain A2VC0 is present */

 Missing SYSCEXTMASK register */

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0

/*

 * Renesas R-Car V3H System Controller

 *

 * Copyright (C) 2018 Renesas Electronics Corp.

 * Copyright (C) 2018 Cogent Embedded, Inc.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2019 Christoph Hellwig.

 * Copyright (c) 2019 Western Digital Corporation or its affiliates.

 Get power bus clock */

 Populate children */

 sentinel */ },

/*

 * System controller registers base address and size.

/*

 * This needs to be called very early during initialization, given that

 * PLL1 needs to be enabled to be able to use all SRAM.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Rockchip Generic Register Files setup

 *

 * Copyright (c) 2016 Heiko Stuebner <heiko@sntech.de>

	/*

	 * Disable auto jtag/sdmmc switching that causes issues with the

	 * clock-framework and the mmc controllers making them unreliable.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Rockchip IO Voltage Domain driver

 *

 * Copyright 2014 MundoReader S.L.

 * Copyright 2014 Google, Inc.

/*

 * The max voltage for 1.8V and 3.3V come from the Rockchip datasheet under

 * "Recommended Operating Conditions" for "Digital GPIO".   When the typical

 * is 3.3V the max is 3.6V.  When the typical is 1.8V the max is 1.98V.

 *

 * They are used like this:

 * - If the voltage on a rail is above the "1.8" voltage (1.98V) we'll tell the

 *   SoC we're at 3.3.

 * - If the voltage on a rail is above the "3.3" voltage (3.6V) we'll consider

 *   that to be an error.

 pmuio1 */

 pmuio2 */

 vccio2 */

 vccio1 */

 vccio3 */

 vccio4 */

 vccio5 */

 vccio6 */

 vccio7 */

 set value bit */

 apply hiword-mask */

	/*

	 * According to Rockchip it's important to keep the SoC IO domain

	 * higher than (or equal to) the external voltage.  That means we need

	 * to change it before external voltage changes happen in the case

	 * of an increase.

	 *

	 * Note that in the "pre" change we pick the max possible voltage that

	 * the regulator might end up at (the client requests a range and we

	 * don't know for certain the exact voltage).  Right now we rely on the

	 * slop in MAX_VOLTAGE_1_8 and MAX_VOLTAGE_3_3 to save us if clients

	 * request something like a max of 3.6V when they really want 3.3V.

	 * We could attempt to come up with better rules if this fails.

 if no VCCIO6 supply we should leave things alone */

	/*

	 * set vccio6 iodomain to also use this framework

	 * instead of a special gpio.

 if no flash supply we should leave things alone */

	/*

	 * set flash0 iodomain to also use this framework

	 * instead of a special gpio.

 if no vccio2 supply we should leave things alone */

	/*

	 * set vccio2 iodomain to also use this framework

	 * instead of a special gpio.

 if no flash supply we should leave things alone */

	/*

	 * set flash0 iodomain to also use this framework

	 * instead of a special gpio.

 if no pmu io supply we should leave things alone */

	/*

	 * set pmu io iodomain to also use this framework

	 * instead of a special gpio.

/*

 * On the rk3188 the io-domains are handled by a shared register with the

 * lower 8 bits being still being continuing drive-strength settings.

 LCDC_VDD */

 DVPIO_VDD */

 FLASH0_VDD (emmc) */

 FLASH1_VDD (sdio1) */

 APIO3_VDD  (sdio0) */

 APIO5_VDD */

 APIO4_VDD */

 SDMMC0_VDD (sdmmc) */

 APIO1_VDD */

 APIO2_VDD */

 reserved */

 DVPIO_VDD */

 FLASH0_VDD (emmc) */

 APIO2_VDD (sdio0) */

 APIO3_VDD */

 SDMMC0_VDD (sdmmc) */

 APIO1_VDD */

 APIO4_VDD (gpujtag) */

PMU IO domain*/

LCDC IO domain*/

 APIO2_VDD */

 APIO5_VDD */

 SDMMC0_VDD */

 APIO4_VDD */

 PMUIO2_VDD */

 sentinel */ },

 If a supply wasn't specified, that's OK */

 set initial correct value */

 must be a regulator we can get the voltage of */

 setup our supply */

 register regulator notifier */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Rockchip Generic power domain support.

 *

 * Copyright (c) 2015 ROCKCHIP, Co. Ltd.

 mutex lock for pmu */

 Wait util idle_ack = 1 */

 check idle status for idle-only domains */

 1'b0: power on, 1'b1: power off */

 if powering down, idle request to NIU first */

 if powering up, leave idle mode */

	/*

	 * We're in the error cleanup already, so we only complain,

	 * but won't emit another error on top of the original one.

 protect the zeroing of pm->num_clks */

 devm will free our memory */

 devm will free our memory */

 First configure domain power down transition count ... */

 ... and then power up count. */

	/*

	 * Configure power up and down transition delays for CORE

	 * and GPU domains.

 PMU_MISC_CON1 */

 PMU_MISC_CON1 */

 1us */

 1us */

 ARM Trusted Firmware manages power transition times */

 sentinel */ },

		/*

		 * We can't forcibly eject devices form power domain,

		 * so we can't really remove power domains once they

		 * were added.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel IXP4xx Queue Manager driver for Linux

 *

 * Copyright (C) 2007 Krzysztof Halasa <khc@pm.waw.pl>

 128 16-dword pages */

 not yet requested */

 not yet requested */

/**

 * qmgr_stat_empty() - checks if a hardware queue is empty

 * @queue:	queue number

 *

 * Returns non-zero value if the queue is empty.

/**

 * qmgr_stat_below_low_watermark() - checks if a queue is below low watermark

 * @queue:	queue number

 *

 * Returns non-zero value if the queue is below low watermark.

/**

 * qmgr_stat_full() - checks if a hardware queue is full

 * @queue:	queue number

 *

 * Returns non-zero value if the queue is full.

/**

 * qmgr_stat_overflow() - checks if a hardware queue experienced overflow

 * @queue:	queue number

 *

 * Returns non-zero value if the queue experienced overflow.

 8 queues per u32 */

 3 bits + 1 reserved bit per queue */

 IRQ source for queues 32-63 is fixed */

 ACK - it may clear any bits so don't rely on it */

 number of the last "low" queue */

 the IRQ condition is inverted */

 ACK - it may clear any bits so don't rely on it */

 number of the last "high" queue */

 ACK */

 number of the last queue */

 clear */

 dwords */,

 dwords */,

 in 16-dwords */

 in 16-dwords: 1, 2, 4 or 8 */

 found free space */

 not in valid range */

 not requested */

 catch IRQ bugs */

 reset qmgr registers */

 clear */

 4 first pages reserved for config */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Intel IXP4xx Network Processor Engine driver for Linux

 *

 * Copyright (C) 2007 Krzysztof Halasa <khc@pm.waw.pl>

 *

 * The code is based on publicly available information:

 * - Intel IXP4xx Developer's Manual and other e-papers

 * - Intel IXP400 Access Library Software (BSD license)

 * - previous works by Christian Hohnstaedt <chohnstaedt@innominate.com>

 *   Thanks, Christian.

 microseconds */

 in dwords */

 NPE exec status (read) and command (write) */

 instruction memory */

 data memory */

 exec access register */

 pipeline clean */

 Background Executing Context */

		Stack level */

 Priority 1 Executing Context */

		Stack level */

 Priority 2 Executing Context */

		Stack level */

 Debug Executing Context */

		Stack level */

 NPE Instruction Register */

 all levels */

 BG/PRI1/PRI2 levels */

 all levels */

 all levels */

 all levels */

 debug level */

 debug level */

 NPE watchpoint_fifo register bit */

 NPE messaging_status register bit definitions */

 OutFifoNotEmpty */

 InFifoNotFull */

 OutFifoNotFull */

 InFifoNotEmpty */

 Mailbox interrupt */

 InFifo interrupt */

 OutFifo interrupt */

 WatchFifo interrupt */

 NPE messaging_control register bit definitions */

 enable output FIFO */

 enable input FIFO */

 enable FIFO + WRITE */

 NPE mailbox_status value for reset */

	/* Iintroduce extra read cycles after issuing read command to NPE

	   so that we read the register after the NPE has updated it.

 ensure only Background Context Stack Level is active */

FIXME?*/

 set the Active bit, and the LDUR, in the debug level */

	/* set CCTXT at ECS DEBUG L3 to specify in which context to execute

	   the instruction, and set SELCTXT at ECS DEBUG Level to specify

	   which context store to access.

	   Debug ECS Level Reg 1 has form 0x000n000n, where n = context number

 clear the pipeline */

 load NPE instruction into the instruction register */

	/* we need this value later to wait for completion of NPE execution

 issue a Step One command via the Execution Control register */

 Watch Count register increments when NPE completes an instruction */

 here we build the NPE assembler instruction: mov8 d0, #0 */

 OpCode */

 base Operand */

 lower 5 bits to immediate data */

 higher 3 bits to CoProc instr. */

 execute it */

 here we build the NPE assembler instruction: mov16 d0, #0 */

 OpCode */

 base Operand */

 lower 5 bits to immediate data */

 higher 11 bits to CoProc instr. */

 execute it */

 write in 16 bit steps first the high and then the low value */

 disable parity interrupt */

 pre exec - debug instruction */

 turn off the halt bit by clearing Execution Count register. */

	/* ensure that IF and IE are on (temporarily), so that we don't end up

 clear the FIFOs */

 read from the outFIFO until empty */

		/* step execution of the NPE intruction to read inFIFO using

 reset the mailbox reg from the XScale side */

 from NPE side */

 Reset the physical registers in the NPE register file */

 address is either 0 or 4 */

 Reset the context store = each context's Context Store registers */

	/* Context 0 has no STARTPC. Instead, this value is used to set NextPC

 NextPC */ << 16) & ECS_REG_0_NEXTPC_MASK;

 Context 0 has no STEVT nor STARTPC */

 STEVT = off, 0x80 */

 REGMAP = d0->p0, d8->p2, d16->p4 */

 post exec */

 clear active bit in debug level */

 clear the pipeline */

 restore previous values */

 write reset values to Execution Context Stack registers */

 clear the profile counter */

 reset the NPE */

 deassert reset */

 NPE is back alive */

 restore NPE configuration bus Control Register - parity settings */

 swapped file */

 NPE ID */) != npe->id) {

 device ID */)) {

 EOF marker */;

 NPE already disabled or not present */

 Spawn crypto subdevice if using device tree */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * sfr.c - driver for special function registers

 *

 * Copyright (C) 2019 Bootlin.

 *

 sentinel */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Atmel

 *

 * Alexandre Belloni <alexandre.belloni@free-electrons.com

 * Boris Brezillon <boris.brezillon@free-electrons.com

 sentinel */ },

	/*

	 * With SAMA5D2 and later SoCs, CIDR and EXID registers are no more

	 * in the dbgu device but in the chipid device whose purpose is only

	 * to expose these two registers.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 *  Copyright (C) 2011-2015 John Crispin <blogic@phrozen.org>

 *  Copyright (C) 2015 Martin Blumenstingl <martin.blumenstingl@googlemail.com>

 *  Copyright (C) 2017 Hauke Mehrtens <hauke@hauke-m.de>

 RCU configuration is optional */

 disable fpi burst */

 SPDX-License-Identifier: GPL-2.0

/* (C) 2015 Pengutronix, Alexander Aring <aar@pengutronix.de>

 *

 * Authors:

 * Alexander Aring <aar@pengutronix.de>

 * Eric Anholt <eric@anholt.net>

/*

 * Firmware indices for the old power domains interface.  Only a few

 * of them were actually implemented.

/*

 * Packet definition used by RPI_FIRMWARE_SET_POWER_STATE and

 * RPI_FIRMWARE_SET_DOMAIN_STATE

/*

 * Asks the firmware to enable or disable power on a specific power

 * domain.

	/*

	 * Treat all power domains as off at boot.

	 *

	 * The firmware itself may be keeping some domains on, but

	 * from Linux's perspective all we control is the refcounts

	 * that we give to the firmware, and we can't ask the firmware

	 * to turn off something that we haven't ourselves turned on.

 The DT binding index is the firmware's domain index minus one. */

/*

 * Detects whether the firmware supports the new power domains interface.

 *

 * The firmware doesn't actually return an error on an unknown tag,

 * and just skips over it, so we do the detection by putting an

 * unexpected value in the return field and checking if it was

 * unchanged.

	/*

	 * Use the old firmware interface for USB power, so that we

	 * can turn it on even if the firmware hasn't been updated.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Power domain driver for Broadcom BCM2835

 *

 * Copyright (C) 2018 Broadcom

/* The power gates must be enabled with this bit before enabling the LDO in the

 * USB block.

 PM registers. */

 AXI Async bridge registers. */

 Enable the module's async AXI bridges. */

 Enable the module's async AXI bridges. */

 Enable functional isolation */

 Enable electrical isolation */

 Open the power switches. */

 If it was already powered on by the fw, leave it that way. */

	/* Enable power.  Allowing too much current at once may result

	 * in POWOK never getting set, so start low and ramp it up as

	 * necessary to succeed.

 Disable electrical isolation */

 Repair memory */

 Disable functional isolation */

 Wait 32 clocks for reset to propagate, 1 us will be enough */

 Deassert the resets. */

 Assert the resets. */

		/* Some domains don't have a clk, so make sure that we

		 * don't deref an error pointer later.

 XXX: on/off at boot? */

/** bcm2835_reset_reset - Resets a block that has a reset line in the

 * PM block.

 *

 * The consumer of the reset controller must have the power domain up

 * -- there's no reset ability with the power domain down.  To reset

 * the sub-block, we just disable its access to memory through the

 * ASB, reset, and re-enable.

 "BRDG" */) {

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2013 Broadcom

 * Copyright (C) 2020 Rafał Miłecki <rafal@milecki.pl>

 R/O */

 R/O */

 R/O */

 R/O */

 R/O */

 R/O */

 R/O */

 R/O */

 R/O */

 R/O */

 Entire device can be powered off by powering off the 0th zone */

 Does not apply to the BCM963158 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * BCM63xx Power Domain Controller Driver

 *

 * Copyright (C) 2020 Álvaro Fernández Rojas <noltari@gmail.com>

 sentinel */

 sentinel */

 sentinel */

 sentinel */

 sentinel */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Broadcom STB SoCs Bus Unit Interface controls

 *

 * Copyright (C) 2015, Broadcom Corporation

 Bitmask to enable instruction and data prefetching with a 256-bytes stride */

 Odd cases, e.g: 7260A0 */

/* The read-ahead cache present in the Brahma-B53 CPU is a special piece of

 * hardware after the integrated L2 cache of the B53 CPU complex whose purpose

 * is to prefetch instruction and/or data with a line size of either 64 bytes

 * or 256 bytes. The rationale is that the data-bus of the CPU interface is

 * optimized for 256-byte transactions, and enabling the read-ahead cache

 * provides a significant performance boost (typically twice the performance

 * for a memcpy benchmark application).

 *

 * The read-ahead cache is transparent for Virtual Address cache maintenance

 * operations: IC IVAU, DC IVAC, DC CVAC, DC CVAU and DC CIVAC.  So no special

 * handling is needed for the DMA API above and beyond what is included in the

 * arm64 implementation.

 *

 * In addition, since the Point of Unification is typically between L1 and L2

 * for the Brahma-B53 processor no special read-ahead cache handling is needed

 * for the IC IALLU and IC IALLUIS cache maintenance operations.

 *

 * However, it is not possible to specify the cache level (L3) for the cache

 * maintenance instructions operating by set/way to operate on the read-ahead

 * cache.  The read-ahead cache will maintain coherency when inner cache lines

 * are cleaned by set/way, but if it is necessary to invalidate inner cache

 * lines by set/way to maintain coherency with system masters operating on

 * shared memory that does not have hardware support for coherency, then it

 * will also be necessary to explicitly invalidate the read-ahead cache.

 Set all 3 MCP interfaces to 8 credits */

 Max out the number of in-flight Jwords reads on the MCP interface */

	/* Enable writeback throttling, set timeout to 128 cycles, 256 cycles

	 * threshold

	/* We might be running on a multi-platform kernel, don't make this a

	 * fatal error, just bail out early

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright © 2014 NVIDIA Corporation

 * Copyright © 2015 Broadcom Corporation

	/* We could be on a multi-platform kernel, don't make this fatal but

	 * bail out early

	/* We could be on a multi-platform kernel, don't make this fatal but

	 * bail out early

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MIPS-specific support for Broadcom STB S2/S3/S5 power management

 *

 * Copyright (C) 2016-2017 Broadcom

 S3 constants */

 Index each CP0 register that needs to be saved */

 Used for saving registers in asm */

 Generic MIPS */

 Broadcom specific */

 Restore cp0 state */

 Generic MIPS */

 Broadcom specific */

 BSP power handshake, v1 */

	/*

	 * HACK: BSP may have internal race on the CLOCK_STOP command.

	 * Avoid touching the BSP for a few milliseconds.

 Clear magic s3 warm-boot value */

 Set the countdown */

 Prepare to S5 cold boot */

 Prepare for s3 */

 Clear RESET_HISTORY */

 Inhibit DDR_RSTb pulse for both MMCs*/

 Save CP0 context */

 Save RTS(skip debug register) */

 Save I/O context */

 CPU reconfiguration */

 Restore RTS (skip debug register) */

 restore CP0 context */

	/*

	 * We need to pass 6 arguments to an assembly function. Lets avoid the

	 * stack and pass arguments in a explicit 4 byte array. The assembly

	 * code assumes all arguments are 4 bytes and arguments are ordered

	 * like so:

	 *

	 * 0: AON_CTRl base register

	 * 1: DDR_PHY base register

	 * 2: TIMERS base resgister

	 * 3: I-Cache line size

	 * 4: Restart vector address

	 * 5: Restart vector size

 Prepare s2 parameters */

 Drop to standby */

 Send IRQs to BMIPS_WARM_RESTART_VEC */

 Send IRQs to normal runtime vectors */

 sentinel */ }

 sentinel */ }

 sentinel */ }

 sentinel */ }

 AON ctrl registers */

 AON SRAM registers */

 Map MEMC DDR PHY registers */

 MEMC ARB registers */

 Timer registers */

 s3 cold boot aka s5 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARM-specific support for Broadcom STB S2/S3/S5 power management

 *

 * S2: clock gate CPUs and as many peripherals as possible

 * S3: power off all of the chip except the Always ON (AON) island; keep DDR is

 *     self-refresh

 * S5: (a.k.a. S3 cold boot) much like S3, except DDR is powered down, so we

 *     treat this mode like a soft power-off, with wakeup allowed from AON

 *

 * Copyright © 2014-2017 Broadcom

 Method #0 */

 Method #1 */

 Uncached, executable remapping of SRAM */

 sentinel */ }

 1 second */

 Go! */

	/*

	 * If firmware doesn't support the 'ack', then just assume it's done

	 * after 10ms. Note that this only works for command 0, BSP_CLOCK_STOP

 BSP power handshake, v1 */

	/*

	 * HACK: BSP may have internal race on the CLOCK_STOP command.

	 * Avoid touching the BSP for a few milliseconds.

 Complete sequence in order. */

 Cold boot */

 Complete sequence in order */

	/*

	 * S3 Entry Sequence

	 * -----------------

	 * Step 1: SHIMPHY_ADDR_CNTL_0_DDR_PAD_CNTRL [ S3_PWRDWN_SEQ ] = 3

	 * Step 2: MEMC_DDR_0_WARM_BOOT [ WARM_BOOT ] = 1

	/*

	 * S5 Entry Sequence

	 * -----------------

	 * Step 1: SHIMPHY_ADDR_CNTL_0_DDR_PAD_CNTRL [ S3_PWRDWN_SEQ ] = 3

	 * Step 2: MEMC_DDR_0_WARM_BOOT [ WARM_BOOT ] = 0

	 * Step 3: DDR_PHY_CONTROL_REGS_[AB]_0_STANDBY_CONTROL[ CKE ] = 0

	 *	   DDR_PHY_CONTROL_REGS_[AB]_0_STANDBY_CONTROL[ RST_N ] = 0

 Step 3: Channel A (RST_N = CKE = 0) */

 Step 3: Channel B? */

 Must complete */

/*

 * Run a Power Management State Machine (PMSM) shutdown command and put the CPU

 * into a low-power mode

 pm_start_pwrdn transition 0->1 */

 Support S5 cold boot out of "poweroff" */

 Clear magic S3 warm-boot value */

 Skip wait-for-interrupt signal; just use a countdown */

 We should never actually get here */

/*

 * S2 suspend/resume picks up where we left off, so we must execute carefully

 * from SRAM, in order to allow DDR to come back up safely before we continue.

 A previous S3 can set a value hazardous to S2, so make sure. */

/*

 * This function is called on a new stack, so don't allow inlining (which will

 * generate stack references on the old stack). It cannot be made static because

 * it is referenced from brcmstb_pm_s3()

	/*

	 * Clear parameter structure, but not DTU area, which has already been

	 * filled in. We know DTU is a the end, so we can just subtract its

	 * size.

 Load random / fixed key */

 No more writes to DRAM */

 Must have been interrupted from wfi()? */

 Same as v240.1, for the registers we care about */

 AON ctrl registers */

 AON SRAM registers */

 Assume standard offset */

 DDR PHY registers */

 Only need DDR PHY 0 for now? */

	/*

	 * Slightly grosss to use the phy ver to get a memc,

	 * offset but that is the only versioned things so far

	 * we can test for.

 DDR SHIM-PHY registers */

 Sequencer DRAM Param and Control Registers */

 Adjust warm boot offset based on the DDR sequencer */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Linaro Ltd.

 *

 * Author: Linus Walleij <linus.walleij@linaro.org>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2, as

 * published by the Free Software Foundation.

 *

 These all define the priority on the BUS2 backplane */

 Multiplatform guard, only proceed on Gemini */

 Set up system arbitration */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2020 MediaTek Inc.

 numbers of violation index */

 reg offset */

/*

 * devapc_sync_vio_dbg - do "shift" mechansim" to get full violation information.

 *                       shift mechanism is depends on devapc hardware design.

 *                       Mediatek devapc set multiple slaves as a group.

 *                       When violation is triggered, violation info is kept

 *                       inside devapc hardware.

 *                       Driver should do shift mechansim to sync full violation

 *                       info to VIO_DBGs registers.

 *

 Find the minimum shift group which has violation */

 Assign the group to sync */

 Start syncing */

 Stop syncing */

 Write clear */

/*

 * devapc_extract_vio_dbg - extract full violation information after doing

 *                          shift mechanism.

 Print violation information */

/*

 * devapc_violation_irq - the devapc Interrupt Service Routine (ISR) will dump

 *                        violation information including which master violates

 *                        access slave.

/*

 * start_devapc - unmask slave's irq to start receiving devapc violation.

/*

 * stop_devapc - mask slave's irq to stop service.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2020 Collabora Ltd.

 A domain is on when both status bits are set. */

 Either wait until SRAM_PDN_ACK all 1 or 0 */

 Either wait until SRAM_PDN_ACK all 1 or 0 */

 subsys power on */

 wait until PWR_ACK = 1 */

 subsys power off */

 wait until PWR_ACK = 0 */

		/*

		 * Find regulator in current power domain node.

		 * devm_regulator_get() finds regulator in a node and its child

		 * node, so set of_node to current power domain node then change

		 * back to original node after regulator is found for current

		 * power domain node.

 Calculate number of subsys_clks */

	/*

	 * Initially turn on all domains to make the domains usable

	 * with !CONFIG_PM and to get the hardware in sync with the

	 * software.  The unused domains will be switched off during

	 * late_init time.

 recursive call to add all subdomains */

	/*

	 * We're in the error cleanup already, so we only complain,

	 * but won't emit another error on top of the original one.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 MediaTek Inc.

 Add EOF setting so overlay hardware can receive frame done irq */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2018 MediaTek Inc.

		/*

		 * In the case of allocated buffer size (pkt->buf_size) is used

		 * up, the real required size (pkt->cmdq_buf_size) is still

		 * increased, so that the user knows how much memory should be

		 * ultimately allocated after appending all commands and

		 * flushing the command packet. Therefor, the user can call

		 * cmdq_pkt_create() again with the real required buffer size.

 insert EOC and generate IRQ for each command iteration */

 JUMP to end */

 We can send next packet immediately, so just call txdone. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 MediaTek Inc.

 * Author: Flora Fu, MediaTek

 macro for wrapper status */

 macro for WACS FSM */

 macro for device wrapper default value */

 macro for manual command */

 macro for Watch Dog Timer Source */

 Group of bits used for shown slave capability */

 Group of bits used for shown pwrap capability */

 defines for slave device wrapper registers */

 MT6323 only regs */

 MT6358 only regs */

 MT6359 only regs */

 MT6397 only regs */

 MT2701 only regs */

 MT7622 only regs */

 MT8135 only regs */

 MT8173 only regs */

 MT8183 only regs */

 MT8516 only regs */

 Flags indicating the capability for the target slave */

	/*

	 * pwrap operations are highly associated with the PMIC types,

	 * so the pointers added increases flexibility allowing determination

	 * which type is used by the detection through device tree.

 Flags indicating the capability for the target pwrap */

/*

 * Timeout issue sometimes caused by the last read command

 * failed because pmic wrap could not got the FSM_VLDCLR

 * in time after finishing WACS2_CMD. It made state machine

 * still on FSM_VLDCLR and timeout next time.

 * Check the status of FSM and clear the vldclr to recovery the

 * error.

		/*

		 * The pwrap_read operation is the requirement of hardware used

		 * for the synchronization between two successive 16-bit

		 * pwrap_writel operations composing one 32-bit bus writing.

		 * Otherwise, we'll find the result fails on the lower 16-bit

		 * pwrap writing.

/*

 * pwrap_init_sidly - configure serial input delay

 *

 * This configures the serial input delay. We can configure 0, 2, 4 or 6ns

 * delay. Do a read test with all possible values and chose the best delay.

 Enable dual IO mode */

 Check IDLE & INIT_DONE in advance */

 Read Test */

/*

 * pwrap_init_chip_select_ext is used to configure CS extension time for each

 * phase during data transactions on the pwrap bus.

	/*

	 * After finishing a write and read transaction, extends CS high time

	 * to be at least xT of BUS CLK as hext_write and hext_read specifies

	 * respectively.

	/*

	 * Extends CS low time after CSL and before CSH command to be at

	 * least xT of BUS CLK as lext_start and lext_end specifies

	 * respectively.

 Config cipher mode @PMIC */

 wait for cipher data ready@AP */

 wait for cipher data ready@PMIC */

 wait for cipher mode idle */

 Write Test */

 Enable encryption */

 Signature checking - using CRC */

 enable pwrap events and pwrap bridge in AP side */

 enable PMIC event out and sources */

 PMIC_DEWRAP enables */

 GPS_INTF initialization */

 enable 2wire SPI master */

 Enable DCM */

 Reset SPI slave */

 Setup serial input delay */

 Enable dual I/O mode */

 Enable security on bus */

 Setup the init done registers */

		/* The MT6380 PMIC only implements a regulator, so we bind it

		 * directly instead of using a MFD.

 sentinel */

 NEED CONFIRM */

 NEED CONFIRM */

 sentinel */

 Enable internal dynamic clock */

	/*

	 * The PMIC could already be initialized by the bootloader.

	 * Skip initialization here in this case.

 Initialize watchdog, may not be done by the bootloader */

	/*

	 * Since STAUPD was not used on mt8173 platform,

	 * so STAUPD of WDT_SRC which should be turned off

	/*

	 * We add INT1 interrupt to handle starvation and request exception

	 * If we support it, we should enable it here.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014 MediaTek Inc.

 * Author: James Liao <jamesjj.liao@mediatek.com>

 protects mmsys_sw_rst_b reg */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Pengutronix, Sascha Hauer <kernel@pengutronix.de>

/**

 * mtk_infracfg_set_bus_protection - enable bus protection

 * @infracfg: The infracfg regmap

 * @mask: The mask containing the protection bits to be enabled.

 * @reg_update: The boolean flag determines to set the protection bits

 *              by regmap_update_bits with enable register(PROTECTEN) or

 *              by regmap_write with set register(PROTECTEN_SET).

 *

 * This function enables the bus protection bits for disabled power

 * domains so that the system does not hang when some unit accesses the

 * bus while in power down.

/**

 * mtk_infracfg_clear_bus_protection - disable bus protection

 * @infracfg: The infracfg regmap

 * @mask: The mask containing the protection bits to be disabled.

 * @reg_update: The boolean flag determines to clear the protection bits

 *              by regmap_update_bits with enable register(PROTECTEN) or

 *              by regmap_write with clear register(PROTECTEN_CLR).

 *

 * This function disables the bus protection bits previously enabled with

 * mtk_infracfg_set_bus_protection.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2015 Pengutronix, Sascha Hauer <kernel@pengutronix.de>

 MT8173, MT2712 */

 MT2701 */

 MT2712 */

 MT7622 */

 MT7622 */

 MT7622 */

 MT7622 */

 MT2712 */

 MT8173 */

 MT8173 */

 MT8173, MT2712 */

 MT8173, MT2712 */

 MT7622 */

 MT7622 */

 MT7622 */

 MT7622 */

/**

 * struct scp_domain_data - scp domain data for power on/off flow

 * @name: The domain name.

 * @sta_mask: The mask for power on/off status bit.

 * @ctl_offs: The offset for main power control register.

 * @sram_pdn_bits: The mask for sram power control bits.

 * @sram_pdn_ack_bits: The mask for sram power control acked bits.

 * @bus_prot_mask: The mask for single step bus protection.

 * @clk_id: The basic clocks required by this power domain.

 * @caps: The flag for active wake-up action.

	/*

	 * A domain is on when both status bits are set. If only one is set

	 * return an error. This happens while powering up a domain

 Either wait until SRAM_PDN_ACK all 0 or have a force wait */

		/*

		 * Currently, MTK_SCPD_FWAIT_SRAM is necessary only for

		 * MT7622_POWER_DOMAIN_WB and thus just a trivial setup

		 * is applied here.

 Either wait until SRAM_PDN_ACK all 1 or 0 */

 Either wait until SRAM_PDN_ACK all 1 or 0 */

 subsys power on */

 wait until PWR_ACK = 1 */

 subsys power off */

 wait until PWR_ACK = 0 */

		/*

		 * Initially turn on all domains to make the domains usable

		 * with !CONFIG_PM and to get the hardware in sync with the

		 * software.  The unused domains will be switched off during

		 * late_init time.

	/*

	 * We are not allowed to fail here since there is no way to unregister

	 * a power domain. Once registered above we have to keep the domains

	 * valid.

/*

 * MT2701 power domain support

/*

 * MT2712 power domain support

/*

 * MT6797 power domain support

/*

 * MT7622 power domain support

/*

 * MT7623A power domain support

/*

 * MT8173 power domain support

/*

 * scpsys driver init

 sentinel */

/*

 * Allwinner SoCs SRAM Controller Driver

 *

 * Copyright (C) 2015 Maxime Ripard

 *

 * Author: Maxime Ripard <maxime.ripard@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Nothing special */

 last defined register */

 other devices have no business accessing other registers */

 SPDX-License-Identifier: GPL-2.0

 Copyright (C) 2020 Maxime Ripard <maxime@cerno.tech> */

	/*

	 * The display engine virtual devices are not strictly speaking

	 * connected to the MBUS, but since DRM will perform all the

	 * memory allocations and DMA operations through that device, we

	 * need to have the quirk on those devices too.

	/*

	 * And now we have the regular devices connected to the MBUS

	 * (that we know of).

	/*

	 * Only the devices that need a large memory bandwidth do DMA

	 * directly over the memory bus (called MBUS), instead of going

	 * through the regular system bus.

	/*

	 * Devices with an interconnects property have the MBUS

	 * relationship described in their DT and dealt with by

	 * of_dma_configure, so we can just skip them.

	 *

	 * Older DTs or SoCs who are not clearly understood need to set

	 * that DMA offset though.

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Freescale DPAA2 Platforms Console Driver

 *

 * Copyright 2015-2016 Freescale Semiconductor Inc.

 * Copyright 2018 NXP

 MC firmware base low/high registers indexes */

 Bit masks used to get the most/least significant part of the MC base addr */

 MC and AIOP Magic words */

 Check if we need to adjust the end of data addr */

 SPDX-License-Identifier: GPL-2.0



 rcpm.c - Freescale QorIQ RCPM driver



 Copyright 2019-2020 NXP



 Author: Ran Wang <ran.wang_1@nxp.com>

/**

 * rcpm_pm_prepare - performs device-level tasks associated with power

 * management, such as programming related to the wakeup source control.

 * @dev: Device to handle.

 *

 Begin with first registered wakeup source */

 skip object which is not attached to device */

		/*

		 * For DT mode, would handle devices with "fsl,rcpm-wakeup"

		 * pointing to the current RCPM node.

		 *

		 * For ACPI mode, currently we assume there is only one

		 * RCPM controller existing.

		/* Property "#fsl,rcpm-wakeup-cells" of rcpm node defines the

		 * number of IPPDEXPCR register cells, and "fsl,rcpm-wakeup"

		 * of wakeup source IP contains an integer array: <phandle to

		 * RCPM node, IPPDEXPCR0 setting, IPPDEXPCR1 setting,

		 * IPPDEXPCR2 setting, etc>.

		 *

		 * So we will go thought them to collect setting data.

 Program all IPPDEXPCRn once */

 We can only OR related bits */

		/*

		 * Workaround of errata A-008646 on SoC LS1021A:

		 * There is a bug of register ippdexpcr1.

		 * Reading configuration register RCPM_IPPDEXPCR1

		 * always return zero. So save ippdexpcr1's value

		 * to register SCFG_SPARECR8.And the value of

		 * ippdexpcr1 will be read from SCFG_SPARECR8.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Freescale QorIQ Platforms GUTS Driver

 *

 * Copyright (C) 2016 Freescale Semiconductor, Inc.

 SoC die attribute definition for QorIQ platform */

	/*

	 * Power Architecture-based SoCs T Series

 Die: T4240, SoC: T4240/T4160/T4080 */

 Die: T1040, SoC: T1040/T1020/T1042/T1022 */

 Die: T2080, SoC: T2080/T2081 */

 Die: T1024, SoC: T1024/T1014/T1023/T1013 */

	/*

	 * ARM-based SoCs LS Series

 Die: LS1043A, SoC: LS1043A/LS1023A */

 Die: LS2080A, SoC: LS2080A/LS2040A/LS2085A */

 Die: LS1088A, SoC: LS1088A/LS1048A/LS1084A/LS1044A */

 Die: LS1012A, SoC: LS1012A */

 Die: LS1046A, SoC: LS1046A/LS1026A */

 Die: LS2088A, SoC: LS2088A/LS2048A/LS2084A/LS2044A */

 Die: LS1021A, SoC: LS1021A/LS1020A/LS1022A */

 Die: LX2160A, SoC: LX2160A/LX2120A/LX2080A */

 Die: LS1028A, SoC: LS1028A */

 Initialize guts */

 Register soc device */

/*

 * Table for matching compatible strings, for device tree

 * guts node, for Freescale QorIQ SOCs.

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright (C) 2014-2016 Freescale Semiconductor, Inc.

 * Copyright 2016-2019 NXP

 *

 All QBMan command and result structures use this "valid bit" encoding */

 QBMan portal management command codes */

 CINH register offsets */

 CENA register offsets */

 CENA register offsets in memory-backed mode */

 Reverse mapping of QBMAN_CENA_SWP_DQRR() */

 Define token used to determine if response written to memory is valid */

 SDQCR attribute codes */

 opaque token for static dequeues */

 Internal Function declaration */

 Function pointers */

 Portal Access */

 'first' is included, 'last' is excluded */

/**

 * qbman_swp_init() - Create a functional object representing the given

 *                    QBMan portal descriptor.

 * @d: the given qbman swp descriptor

 *

 * Return qbman_swp portal for success, NULL if the object cannot

 * be created.

 Writes Non-cacheable */

 EQCR_CI stashing threshold */

 RPM: RCR in array mode */

 DCM: Discrete consumption ack */

 EPM: EQCR in ring mode */

 mem stashing drop enable enable */

 mem stashing priority enable */

 mem stashing enable */

 dequeue stashing priority enable */

 dequeue stashing enable enable */

 EQCR_CI stashing priority enable */

 Writes Non-cacheable */

 EQCR_CI stashing threshold */

 RPM: RCR in array mode */

 DCM: Discrete consumption ack */

 EPM: EQCR in ring mode */

 mem stashing drop enable */

 mem stashing priority enable */

 mem stashing enable */

 dequeue stashing priority enable */

 dequeue stashing enable */

 EQCR_CI stashing priority enable */

 memory-backed mode */

 VDQCR read triggered mode */

 CR read triggered mode */

	/*

	 * SDQCR needs to be initialized to 0 when no channels are

	 * being dequeued from or else the QMan HW will indicate an

	 * error.  The values that were calculated above will be

	 * applied when dequeues from a specific channel are enabled.

 Initialize the software portal with a irq timeout period of 0us */

/**

 * qbman_swp_finish() - Create and destroy a functional object representing

 *                      the given QBMan portal descriptor.

 * @p: the qbman_swp object to be destroyed

/**

 * qbman_swp_interrupt_read_status()

 * @p: the given software portal

 *

 * Return the value in the SWP_ISR register.

/**

 * qbman_swp_interrupt_clear_status()

 * @p: the given software portal

 * @mask: The mask to clear in SWP_ISR register

/**

 * qbman_swp_interrupt_get_trigger() - read interrupt enable register

 * @p: the given software portal

 *

 * Return the value in the SWP_IER register.

/**

 * qbman_swp_interrupt_set_trigger() - enable interrupts for a swp

 * @p: the given software portal

 * @mask: The mask of bits to enable in SWP_IER

/**

 * qbman_swp_interrupt_get_inhibit() - read interrupt mask register

 * @p: the given software portal object

 *

 * Return the value in the SWP_IIR register.

/**

 * qbman_swp_interrupt_set_inhibit() - write interrupt mask register

 * @p: the given software portal object

 * @inhibit: whether to inhibit the IRQs

/*

 * Different management commands all use this common base layer of code to issue

 * commands and poll for results.

/*

 * Returns a pointer to where the caller should fill in their management command

 * (caller should ignore the verb byte)

/*

 * Commits merges in the caller-supplied command verb (which should not include

 * the valid-bit) and submits the command to hardware

/*

 * Checks for a completed response (returns non-NULL if only if the response

 * is complete).

		/* Remove the valid-bit - command completed if the rest

		 * is non-zero.

 Command completed if the valid bit is toggled */

 Command completed if the rest is non-zero */

/*

 * qbman_eq_desc_clear() - Clear the contents of a descriptor to

 *                         default/starting state.

/**

 * qbman_eq_desc_set_no_orp() - Set enqueue descriptor without orp

 * @d:                the enqueue descriptor.

 * @respond_success:  1 = enqueue with response always; 0 = enqueue with

 *                    rejections returned on a FQ.

/*

 * Exactly one of the following descriptor "targets" should be set. (Calling any

 * one of these will replace the effect of any prior call to one of these.)

 *   -enqueue to a frame queue

 *   -enqueue to a queuing destination

/**

 * qbman_eq_desc_set_fq() - set the FQ for the enqueue command

 * @d:    the enqueue descriptor

 * @fqid: the id of the frame queue to be enqueued

/**

 * qbman_eq_desc_set_qd() - Set Queuing Destination for the enqueue command

 * @d:       the enqueue descriptor

 * @qdid:    the id of the queuing destination to be enqueued

 * @qd_bin:  the queuing destination bin

 * @qd_prio: the queuing destination priority

/**

 * qbman_swp_enqueue_direct() - Issue an enqueue command

 * @s:  the software portal used for enqueue

 * @d:  the enqueue descriptor

 * @fd: the frame descriptor to be enqueued

 *

 * Please note that 'fd' should only be NULL if the "action" of the

 * descriptor is "orp_hole" or "orp_nesn".

 *

 * Return 0 for successful enqueue, -EBUSY if the EQCR is not ready.

/**

 * qbman_swp_enqueue_mem_back() - Issue an enqueue command

 * @s:  the software portal used for enqueue

 * @d:  the enqueue descriptor

 * @fd: the frame descriptor to be enqueued

 *

 * Please note that 'fd' should only be NULL if the "action" of the

 * descriptor is "orp_hole" or "orp_nesn".

 *

 * Return 0 for successful enqueue, -EBUSY if the EQCR is not ready.

/**

 * qbman_swp_enqueue_multiple_direct() - Issue a multi enqueue command

 * using one enqueue descriptor

 * @s:  the software portal used for enqueue

 * @d:  the enqueue descriptor

 * @fd: table pointer of frame descriptor table to be enqueued

 * @flags: table pointer of QBMAN_ENQUEUE_FLAG_DCA flags, not used if NULL

 * @num_frames: number of fd to be enqueued

 *

 * Return the number of fd enqueued, or a negative error number.

 Fill in the EQCR ring */

 Skip copying the verb */

 Set the verb byte, have to substitute in the valid-bit */

 Flush all the cacheline without load/store in between */

/**

 * qbman_swp_enqueue_multiple_mem_back() - Issue a multi enqueue command

 * using one enqueue descriptor

 * @s:  the software portal used for enqueue

 * @d:  the enqueue descriptor

 * @fd: table pointer of frame descriptor table to be enqueued

 * @flags: table pointer of QBMAN_ENQUEUE_FLAG_DCA flags, not used if NULL

 * @num_frames: number of fd to be enqueued

 *

 * Return the number of fd enqueued, or a negative error number.

 Fill in the EQCR ring */

 Skip copying the verb */

 Set the verb byte, have to substitute in the valid-bit */

/**

 * qbman_swp_enqueue_multiple_desc_direct() - Issue a multi enqueue command

 * using multiple enqueue descriptor

 * @s:  the software portal used for enqueue

 * @d:  table of minimal enqueue descriptor

 * @fd: table pointer of frame descriptor table to be enqueued

 * @num_frames: number of fd to be enqueued

 *

 * Return the number of fd enqueued, or a negative error number.

 Fill in the EQCR ring */

 Skip copying the verb */

 Set the verb byte, have to substitute in the valid-bit */

 Flush all the cacheline without load/store in between */

/**

 * qbman_swp_enqueue_multiple_desc_mem_back() - Issue a multi enqueue command

 * using multiple enqueue descriptor

 * @s:  the software portal used for enqueue

 * @d:  table of minimal enqueue descriptor

 * @fd: table pointer of frame descriptor table to be enqueued

 * @num_frames: number of fd to be enqueued

 *

 * Return the number of fd enqueued, or a negative error number.

 Fill in the EQCR ring */

 Skip copying the verb */

 Set the verb byte, have to substitute in the valid-bit */

 Static (push) dequeue */

/**

 * qbman_swp_push_get() - Get the push dequeue setup

 * @s:           the software portal object

 * @channel_idx: the channel index to query

 * @enabled:     returned boolean to show whether the push dequeue is enabled

 *               for the given channel

/**

 * qbman_swp_push_set() - Enable or disable push dequeue

 * @s:           the software portal object

 * @channel_idx: the channel index (0 to 15)

 * @enable:      enable or disable push dequeue

	/* Read make the complete src map.  If no channels are enabled

	 * the SDQCR must be 0 or else QMan will assert errors

/**

 * qbman_pull_desc_clear() - Clear the contents of a descriptor to

 *                           default/starting state

 * @d: the pull dequeue descriptor to be cleared

/**

 * qbman_pull_desc_set_storage()- Set the pull dequeue storage

 * @d:            the pull dequeue descriptor to be set

 * @storage:      the pointer of the memory to store the dequeue result

 * @storage_phys: the physical address of the storage memory

 * @stash:        to indicate whether write allocate is enabled

 *

 * If not called, or if called with 'storage' as NULL, the result pull dequeues

 * will produce results to DQRR. If 'storage' is non-NULL, then results are

 * produced to the given memory location (using the DMA address which

 * the caller provides in 'storage_phys'), and 'stash' controls whether or not

 * those writes to main-memory express a cache-warming attribute.

 save the virtual address */

/**

 * qbman_pull_desc_set_numframes() - Set the number of frames to be dequeued

 * @d:         the pull dequeue descriptor to be set

 * @numframes: number of frames to be set, must be between 1 and 16, inclusive

/*

 * Exactly one of the following descriptor "actions" should be set. (Calling any

 * one of these will replace the effect of any prior call to one of these.)

 * - pull dequeue from the given frame queue (FQ)

 * - pull dequeue from any FQ in the given work queue (WQ)

 * - pull dequeue from any FQ in any WQ in the given channel

/**

 * qbman_pull_desc_set_fq() - Set fqid from which the dequeue command dequeues

 * @d:    the pull dequeue descriptor to be set

 * @fqid: the frame queue index of the given FQ

/**

 * qbman_pull_desc_set_wq() - Set wqid from which the dequeue command dequeues

 * @d:    the pull dequeue descriptor to be set

 * @wqid: composed of channel id and wqid within the channel

 * @dct:  the dequeue command type

/**

 * qbman_pull_desc_set_channel() - Set channelid from which the dequeue command

 *                                 dequeues

 * @d:    the pull dequeue descriptor to be set

 * @chid: the channel id to be dequeued

 * @dct:  the dequeue command type

/**

 * qbman_swp_pull_direct() - Issue the pull dequeue command

 * @s: the software portal object

 * @d: the software portal descriptor which has been configured with

 *     the set of qbman_pull_desc_set_*() calls

 *

 * Return 0 for success, and -EBUSY if the software portal is not ready

 * to do pull dequeue.

 Set the verb byte, have to substitute in the valid-bit */

/**

 * qbman_swp_pull_mem_back() - Issue the pull dequeue command

 * @s: the software portal object

 * @d: the software portal descriptor which has been configured with

 *     the set of qbman_pull_desc_set_*() calls

 *

 * Return 0 for success, and -EBUSY if the software portal is not ready

 * to do pull dequeue.

 Set the verb byte, have to substitute in the valid-bit */

/**

 * qbman_swp_dqrr_next_direct() - Get an valid DQRR entry

 * @s: the software portal object

 *

 * Return NULL if there are no unconsumed DQRR entries. Return a DQRR entry

 * only once, so repeated calls can return a sequence of DQRR entries, without

 * requiring they be consumed immediately or in any particular order.

	/* Before using valid-bit to detect if something is there, we have to

	 * handle the case of the DQRR reset bug...

		/*

		 * We pick up new entries by cache-inhibited producer index,

		 * which means that a non-coherent mapping would require us to

		 * invalidate and read *only* once that PI has indicated that

		 * there's an entry here. The first trip around the DQRR ring

		 * will be much less efficient than all subsequent trips around

		 * it...

 there are new entries if pi != next_idx */

		/*

		 * if next_idx is/was the last ring index, and 'pi' is

		 * different, we can disable the workaround as all the ring

		 * entries have now been DMA'd to so valid-bit checking is

		 * repaired. Note: this logic needs to be based on next_idx

		 * (which increments one at a time), rather than on pi (which

		 * can burst and wrap-around between our snapshots of it).

	/*

	 * If the valid-bit isn't of the expected polarity, nothing there. Note,

	 * in the DQRR reset bug workaround, we shouldn't need to skip these

	 * check, because we've already determined that a new entry is available

	 * and we've invalidated the cacheline before reading it, so the

	 * valid-bit behaviour is repaired and should tell us what we already

	 * knew from reading PI.

	/*

	 * There's something there. Move "next_idx" attention to the next ring

	 * entry (and prefetch it) before returning what we found.

 Wrap around */

	/*

	 * If this is the final response to a volatile dequeue command

	 * indicate that the vdq is available

/**

 * qbman_swp_dqrr_next_mem_back() - Get an valid DQRR entry

 * @s: the software portal object

 *

 * Return NULL if there are no unconsumed DQRR entries. Return a DQRR entry

 * only once, so repeated calls can return a sequence of DQRR entries, without

 * requiring they be consumed immediately or in any particular order.

	/* Before using valid-bit to detect if something is there, we have to

	 * handle the case of the DQRR reset bug...

		/*

		 * We pick up new entries by cache-inhibited producer index,

		 * which means that a non-coherent mapping would require us to

		 * invalidate and read *only* once that PI has indicated that

		 * there's an entry here. The first trip around the DQRR ring

		 * will be much less efficient than all subsequent trips around

		 * it...

 there are new entries if pi != next_idx */

		/*

		 * if next_idx is/was the last ring index, and 'pi' is

		 * different, we can disable the workaround as all the ring

		 * entries have now been DMA'd to so valid-bit checking is

		 * repaired. Note: this logic needs to be based on next_idx

		 * (which increments one at a time), rather than on pi (which

		 * can burst and wrap-around between our snapshots of it).

	/*

	 * If the valid-bit isn't of the expected polarity, nothing there. Note,

	 * in the DQRR reset bug workaround, we shouldn't need to skip these

	 * check, because we've already determined that a new entry is available

	 * and we've invalidated the cacheline before reading it, so the

	 * valid-bit behaviour is repaired and should tell us what we already

	 * knew from reading PI.

	/*

	 * There's something there. Move "next_idx" attention to the next ring

	 * entry (and prefetch it) before returning what we found.

 Wrap around */

	/*

	 * If this is the final response to a volatile dequeue command

	 * indicate that the vdq is available

/**

 * qbman_swp_dqrr_consume() -  Consume DQRR entries previously returned from

 *                             qbman_swp_dqrr_next().

 * @s: the software portal object

 * @dq: the DQRR entry to be consumed

/**

 * qbman_result_has_new_result() - Check and get the dequeue response from the

 *                                 dq storage memory set in pull dequeue command

 * @s: the software portal object

 * @dq: the dequeue result read from the memory

 *

 * Return 1 for getting a valid dequeue result, or 0 for not getting a valid

 * dequeue result.

 *

 * Only used for user-provided storage of dequeue results, not DQRR. For

 * efficiency purposes, the driver will perform any required endianness

 * conversion to ensure that the user's dequeue result storage is in host-endian

 * format. As such, once the user has called qbman_result_has_new_result() and

 * been returned a valid dequeue result, they should not call it again on

 * the same memory location (except of course if another dequeue command has

 * been executed to produce a new result to that location).

	/*

	 * Set token to be 0 so we will detect change back to 1

	 * next time the looping is traversed. Const is cast away here

	 * as we want users to treat the dequeue responses as read only.

	/*

	 * Determine whether VDQCR is available based on whether the

	 * current result is sitting in the first storage location of

	 * the busy command.

/**

 * qbman_release_desc_clear() - Clear the contents of a descriptor to

 *                              default/starting state.

 * @d: the pull dequeue descriptor to be cleared

 Release Command Valid */

/**

 * qbman_release_desc_set_bpid() - Set the ID of the buffer pool to release to

 * @d:    the pull dequeue descriptor to be set

 * @bpid: the bpid value to be set

/**

 * qbman_release_desc_set_rcdi() - Determines whether or not the portal's RCDI

 * interrupt source should be asserted after the release command is completed.

 * @d:      the pull dequeue descriptor to be set

 * @enable: enable (1) or disable (0) value

/**

 * qbman_swp_release_direct() - Issue a buffer release command

 * @s:           the software portal object

 * @d:           the release descriptor

 * @buffers:     a pointer pointing to the buffer address to be released

 * @num_buffers: number of buffers to be released,  must be less than 8

 *

 * Return 0 for success, -EBUSY if the release command ring is not ready.

 Start the release command */

 Copy the caller's buffer pointers to the command */

	/*

	 * Set the verb byte, have to substitute in the valid-bit

	 * and the number of buffers.

/**

 * qbman_swp_release_mem_back() - Issue a buffer release command

 * @s:           the software portal object

 * @d:           the release descriptor

 * @buffers:     a pointer pointing to the buffer address to be released

 * @num_buffers: number of buffers to be released,  must be less than 8

 *

 * Return 0 for success, -EBUSY if the release command ring is not ready.

 Start the release command */

 Copy the caller's buffer pointers to the command */

/**

 * qbman_swp_acquire() - Issue a buffer acquire command

 * @s:           the software portal object

 * @bpid:        the buffer pool index

 * @buffers:     a pointer pointing to the acquired buffer addresses

 * @num_buffers: number of buffers to be acquired, must be less than 8

 *

 * Return 0 for success, or negative error code if the acquire command

 * fails.

 Start the management command */

 Encode the caller-provided attributes */

 Complete the management command */

 Decode the outcome */

 Determine success or failure */

 Copy the acquired buffers to the caller's array */

 Start the management command */

 Complete the management command */

 Decode the outcome */

 Determine success or failure */

 Start the management command */

 Encode the caller-provided attributes */

 Complete the management command */

 Determine success or failure */

 FQID is a 24 bit value */

 Decode the outcome */

 Determine success or failure */

 Decode the outcome */

 Determine success or failure */

/**

 * qbman_swp_set_irq_coalescing() - Set new IRQ coalescing values

 * @p: the software portal object

 * @irq_threshold: interrupt threshold

 * @irq_holdoff: interrupt holdoff (timeout) period in us

 *

 * Return 0 for success, or negative error code on error.

	/* Convert irq_holdoff value from usecs to 256 QBMAN clock cycles

	 * increments. This depends on the QBMAN internal frequency.

/**

 * qbman_swp_get_irq_coalescing() - Get the current IRQ coalescing parameters

 * @p: the software portal object

 * @irq_threshold: interrupt threshold (an IRQ is generated when there are more

 * DQRR entries in the portal than the threshold)

 * @irq_holdoff: interrupt holdoff (timeout) period in us

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright 2013-2016 Freescale Semiconductor Inc.

 * Copyright 2016 NXP

 *

/*

 * Data Path I/O Portal API

 * Contains initialization APIs and runtime control APIs for DPIO

/**

 * dpio_open() - Open a control session for the specified object

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @dpio_id:	DPIO unique ID

 * @token:	Returned token; use in subsequent API calls

 *

 * This function can be used to open a control session for an

 * already created object; an object may have been declared in

 * the DPL or by calling the dpio_create() function.

 * This function returns a unique authentication token,

 * associated with the specific object ID and the specific MC

 * portal; this token must be used in all subsequent commands for

 * this specific object.

 *

 * Return:	'0' on Success; Error code otherwise.

 prepare command */

 retrieve response parameters */

/**

 * dpio_close() - Close the control session of the object

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPIO object

 *

 * Return:	'0' on Success; Error code otherwise.

 prepare command */

/**

 * dpio_enable() - Enable the DPIO, allow I/O portal operations.

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPIO object

 *

 * Return:	'0' on Success; Error code otherwise

 prepare command */

/**

 * dpio_disable() - Disable the DPIO, stop any I/O portal operation.

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPIO object

 *

 * Return:	'0' on Success; Error code otherwise

 prepare command */

/**

 * dpio_get_attributes() - Retrieve DPIO attributes

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPIO object

 * @attr:	Returned object's attributes

 *

 * Return:	'0' on Success; Error code otherwise

 prepare command */

 retrieve response parameters */

/**

 * dpio_get_api_version - Get Data Path I/O API version

 * @mc_io:	Pointer to MC portal's DPIO object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @major_ver:	Major version of DPIO API

 * @minor_ver:	Minor version of DPIO API

 *

 * Return:	'0' on Success; Error code otherwise

 prepare command */

 retrieve response parameters */

/**

 * dpio_reset() - Reset the DPIO, returns the object to initial state.

 * @mc_io:	Pointer to MC portal's I/O object

 * @cmd_flags:	Command flags; one or more of 'MC_CMD_FLAG_'

 * @token:	Token of DPIO object

 *

 * Return:	'0' on Success; Error code otherwise.

 prepare command */

 send command to mc*/

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright 2014-2016 Freescale Semiconductor Inc.

 * Copyright 2016-2019 NXP

 *

 protect against multiple management commands */

 protect notifications list */

 Net DIM */

 protect against concurrent Net DIM updates */

 unaligned value from kmalloc() */

 position of the next-to-be-returned entry */

 portal used to issue VDQCR */

 device used for DMA mapping */

 keep a per cpu array of DPIOs for fast access */

	/*

	 * If cpu == -1, choose the current cpu, with no guarantees about

	 * potentially being migrated away.

 If a specific cpu was requested, pick it up immediately */

/**

 * dpaa2_io_service_select() - return a dpaa2_io service affined to this cpu

 * @cpu: the cpu id

 *

 * Return the affine dpaa2_io service, or NULL if there is no service affined

 * to the specified cpu. If DPAA2_IO_ANY_CPU is used, return the next available

 * service.

/**

 * dpaa2_io_create() - create a dpaa2_io object.

 * @desc: the dpaa2_io descriptor

 * @dev: the actual DPIO device

 *

 * Activates a "struct dpaa2_io" corresponding to the given config of an actual

 * DPIO object.

 *

 * Return a valid dpaa2_io object for success, or NULL for failure.

 check if CPU is out of range (-1 means any cpu) */

	/* Compute how many 256 QBMAN cycles fit into one ns. This is because

	 * the interrupt timeout period register needs to be specified in QBMAN

	 * clock cycles in increments of 256.

 For now only enable DQRR interrupts */

/**

 * dpaa2_io_down() - release the dpaa2_io object.

 * @d: the dpaa2_io object to be released.

 *

 * The "struct dpaa2_io" type can represent an individual DPIO object (as

 * described by "struct dpaa2_io_desc") or an instance of a "DPIO service",

 * which can be used to group/encapsulate multiple DPIO objects. In all cases,

 * each handle obtained should be released using this function.

/**

 * dpaa2_io_irq() - ISR for DPIO interrupts

 *

 * @obj: the given DPIO object.

 *

 * Return IRQ_HANDLED for success or IRQ_NONE if there

 * were no pending interrupts.

/**

 * dpaa2_io_get_cpu() - get the cpu associated with a given DPIO object

 *

 * @d: the given DPIO object.

 *

 * Return the cpu associated with the DPIO object

/**

 * dpaa2_io_service_register() - Prepare for servicing of FQDAN or CDAN

 *                               notifications on the given DPIO service.

 * @d:   the given DPIO service.

 * @ctx: the notification context.

 * @dev: the device that requests the register

 *

 * The caller should make the MC command to attach a DPAA2 object to

 * a DPIO after this function completes successfully.  In that way:

 *    (a) The DPIO service is "ready" to handle a notification arrival

 *        (which might happen before the "attach" command to MC has

 *        returned control of execution back to the caller)

 *    (b) The DPIO service can provide back to the caller the 'dpio_id' and

 *        'qman64' parameters that it should pass along in the MC command

 *        in order for the object to be configured to produce the right

 *        notification fields to the DPIO service.

 *

 * Return 0 for success, or -ENODEV for failure.

 Enable the generation of CDAN notifications */

/**

 * dpaa2_io_service_deregister - The opposite of 'register'.

 * @service: the given DPIO service.

 * @ctx: the notification context.

 * @dev: the device that requests to be deregistered

 *

 * This function should be called only after sending the MC command to

 * to detach the notification-producing device from the DPIO.

/**

 * dpaa2_io_service_rearm() - Rearm the notification for the given DPIO service.

 * @d: the given DPIO service.

 * @ctx: the notification context.

 *

 * Once a FQDAN/CDAN has been produced, the corresponding FQ/channel is

 * considered "disarmed". Ie. the user can issue pull dequeue operations on that

 * traffic source for as long as it likes. Eventually it may wish to "rearm"

 * that source to allow it to produce another FQDAN/CDAN, that's what this

 * function achieves.

 *

 * Return 0 for success.

/**

 * dpaa2_io_service_pull_fq() - pull dequeue functions from a fq.

 * @d: the given DPIO service.

 * @fqid: the given frame queue id.

 * @s: the dpaa2_io_store object for the result.

 *

 * Return 0 for success, or error code for failure.

/**

 * dpaa2_io_service_pull_channel() - pull dequeue functions from a channel.

 * @d: the given DPIO service.

 * @channelid: the given channel id.

 * @s: the dpaa2_io_store object for the result.

 *

 * Return 0 for success, or error code for failure.

/**

 * dpaa2_io_service_enqueue_fq() - Enqueue a frame to a frame queue.

 * @d: the given DPIO service.

 * @fqid: the given frame queue id.

 * @fd: the frame descriptor which is enqueued.

 *

 * Return 0 for successful enqueue, -EBUSY if the enqueue ring is not ready,

 * or -ENODEV if there is no dpio service.

/**

 * dpaa2_io_service_enqueue_multiple_fq() - Enqueue multiple frames

 * to a frame queue using one fqid.

 * @d: the given DPIO service.

 * @fqid: the given frame queue id.

 * @fd: the frame descriptor which is enqueued.

 * @nb: number of frames to be enqueud

 *

 * Return 0 for successful enqueue, -EBUSY if the enqueue ring is not ready,

 * or -ENODEV if there is no dpio service.

/**

 * dpaa2_io_service_enqueue_multiple_desc_fq() - Enqueue multiple frames

 * to different frame queue using a list of fqids.

 * @d: the given DPIO service.

 * @fqid: the given list of frame queue ids.

 * @fd: the frame descriptor which is enqueued.

 * @nb: number of frames to be enqueud

 *

 * Return 0 for successful enqueue, -EBUSY if the enqueue ring is not ready,

 * or -ENODEV if there is no dpio service.

/**

 * dpaa2_io_service_enqueue_qd() - Enqueue a frame to a QD.

 * @d: the given DPIO service.

 * @qdid: the given queuing destination id.

 * @prio: the given queuing priority.

 * @qdbin: the given queuing destination bin.

 * @fd: the frame descriptor which is enqueued.

 *

 * Return 0 for successful enqueue, or -EBUSY if the enqueue ring is not ready,

 * or -ENODEV if there is no dpio service.

/**

 * dpaa2_io_service_release() - Release buffers to a buffer pool.

 * @d: the given DPIO object.

 * @bpid: the buffer pool id.

 * @buffers: the buffers to be released.

 * @num_buffers: the number of the buffers to be released.

 *

 * Return 0 for success, and negative error code for failure.

/**

 * dpaa2_io_service_acquire() - Acquire buffers from a buffer pool.

 * @d: the given DPIO object.

 * @bpid: the buffer pool id.

 * @buffers: the buffer addresses for acquired buffers.

 * @num_buffers: the expected number of the buffers to acquire.

 *

 * Return a negative error code if the command failed, otherwise it returns

 * the number of buffers acquired, which may be less than the number requested.

 * Eg. if the buffer pool is empty, this will return zero.

/*

 * 'Stores' are reusable memory blocks for holding dequeue results, and to

 * assist with parsing those results.

/**

 * dpaa2_io_store_create() - Create the dma memory storage for dequeue result.

 * @max_frames: the maximum number of dequeued result for frames, must be <= 32.

 * @dev:        the device to allow mapping/unmapping the DMAable region.

 *

 * The size of the storage is "max_frames*sizeof(struct dpaa2_dq)".

 * The 'dpaa2_io_store' returned is a DPIO service managed object.

 *

 * Return pointer to dpaa2_io_store struct for successfully created storage

 * memory, or NULL on error.

/**

 * dpaa2_io_store_destroy() - Frees the dma memory storage for dequeue

 *                            result.

 * @s: the storage memory to be destroyed.

/**

 * dpaa2_io_store_next() - Determine when the next dequeue result is available.

 * @s: the dpaa2_io_store object.

 * @is_last: indicate whether this is the last frame in the pull command.

 *

 * When an object driver performs dequeues to a dpaa2_io_store, this function

 * can be used to determine when the next frame result is available. Once

 * this function returns non-NULL, a subsequent call to it will try to find

 * the next dequeue result.

 *

 * Note that if a pull-dequeue has a NULL result because the target FQ/channel

 * was empty, then this function will also return NULL (rather than expecting

 * the caller to always check for this. As such, "is_last" can be used to

 * differentiate between "end-of-empty-dequeue" and "still-waiting".

 *

 * Return dequeue result for a valid dequeue result, or NULL for empty dequeue.

		/*

		 * If we get an empty dequeue result to terminate a zero-results

		 * vdqcr, return NULL to the caller rather than expecting him to

		 * check non-NULL results every time.

/**

 * dpaa2_io_query_fq_count() - Get the frame and byte count for a given fq.

 * @d: the given DPIO object.

 * @fqid: the id of frame queue to be queried.

 * @fcnt: the queried frame count.

 * @bcnt: the queried byte count.

 *

 * Knowing the FQ count at run-time can be useful in debugging situations.

 * The instantaneous frame- and byte-count are hereby returned.

 *

 * Return 0 for a successful query, and negative error code if query fails.

/**

 * dpaa2_io_query_bp_count() - Query the number of buffers currently in a

 * buffer pool.

 * @d: the given DPIO object.

 * @bpid: the index of buffer pool to be queried.

 * @num: the queried number of buffers in the buffer pool.

 *

 * Return 0 for a successful query, and negative error code if query fails.

/**

 * dpaa2_io_set_irq_coalescing() - Set new IRQ coalescing values

 * @d: the given DPIO object

 * @irq_holdoff: interrupt holdoff (timeout) period in us

 *

 * Return 0 for success, or negative error code on error.

/**

 * dpaa2_io_get_irq_coalescing() - Get the current IRQ coalescing parameters

 * @d: the given DPIO object

 * @irq_holdoff: interrupt holdoff (timeout) period in us

/**

 * dpaa2_io_set_adaptive_coalescing() - Enable/disable adaptive coalescing

 * @d: the given DPIO object

 * @use_adaptive_rx_coalesce: adaptive coalescing state

/**

 * dpaa2_io_get_adaptive_coalescing() - Query adaptive coalescing state

 * @d: the given DPIO object

 *

 * Return 1 when adaptive coalescing is enabled on the DPIO object and 0

 * otherwise.

/**

 * dpaa2_io_update_net_dim() - Update Net DIM

 * @d: the given DPIO object

 * @frames: how many frames have been dequeued by the user since the last call

 * @bytes: how many bytes have been dequeued by the user since the last call

 SPDX-License-Identifier: (GPL-2.0+ OR BSD-3-Clause)

/*

 * Copyright 2014-2016 Freescale Semiconductor Inc.

 * Copyright NXP 2016

 *

 sentinel */ }

 sentinel */ }

 sentinel */ }

 sentinel */ }

 clear the affinity hint */

 set the affinity hint */

 initialize DPIO descriptor */

 get the cpu to use for the affinity hint */

 No support for DDR backed portals, use classic mapping */

		/*

		 * Set the CENA regs to be the cache inhibited area of the

		 * portal to avoid coherency issues if a user migrates to

		 * another core.

 Tear down interrupts for a given DPIO object */

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/* Copyright 2017 NXP Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of NXP Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY NXP Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL NXP Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/*

 * Initialize a devices private memory region

	/*

	 * Check if the reg property exists - if not insert the node

	 * so upon kexec() the same memory region address will be preserved.

	 * This is needed because QBMan HW does not allow the base address/

	 * size to be modified once set.

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 protect bman global registers and global data shared among portals */

 use any other online CPU */

 unassigned portal, skip init */

 clear irq affinity if assigned cpu is offline */

		/*

		 * BMan wasn't reset prior to boot (Kexec for example)

		 * Empty all the buffer pools so they are in reset state

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 Enable portal interupts (as opposed to polling mode) */

 protect qman global registers and global data shared among portals */

 We need the same LIODN offset for all portals */

 Determine what should be interrupt-vs-poll driven */

 all assigned portals are initialized now */

 TODO */

 select any other online CPU */

 unassigned portal, skip init */

 clear irq affinity if assigned cpu is offline */

		/*

		 * QMan wasn't reset prior to boot (Kexec for example)

		 * Empty all the frame queues so they are in reset state

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

		/*

		 * On SoCs with BMan revison 2.0, BMan only respects the 40

		 * LS-bits of buffer addresses, masking off the upper 8-bits on

		 * release commands. The API provides for 48-bit addresses

		 * because some SoCs support all 48-bits. When generating

		 * garbage addresses for testing, we either need to zero the

		 * upper 8-bits when releasing to BMan (otherwise we'll be

		 * disappointed when the buffers we acquire back from BMan

		 * don't match), or we need to mask the upper 8-bits off when

		 * comparing. We do the latter.

 test */

 Release buffers */

 Acquire buffers */

 Clean up */

/* Copyright (c) 2009 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 Register offsets */

 Used by all error interrupt registers except 'inhibit' */

 Invalid Command Verb */

 FBPR Low Watermark */

 Multi-bit ECC Error */

 Single-bit ECC Error */

 pool State Change Notification */

 Only trigger low water mark interrupt once only */

 Pointer to the start of the BMan's CCSR space */

 signal transactions for FBPRs with higher priority */

 Track if probe has occurred and if cleanup is required */

 choke if size isn't within range */

 choke if '[e]ba' has lower-alignment than 'size' */

 Check to see if BMan has already been initialized */

 Maker sure ba == what was programmed) */

/*

 * Location and size of BMan private memory

 *

 * Ideally we would use the DMA API to turn rmem->base into a DMA address

 * (especially if iommu translations ever get involved).  Unfortunately, the

 * DMA API currently does not allow mapping anything that is not backed with

 * a struct page.

 Re-arm error capture registers */

	/*

	 * If FBPR memory wasn't defined using the qbman compatible string

	 * try using the of_reserved_mem_device method

 Disable Buffer Pool State Change */

	/*

	 * Write-to-clear any stale bits, (eg. starvation being asserted prior

	 * to resource allocation during driver init).

 Enable Error Interrupts */

 seed BMan resource pool */

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 big enough for "BMan portal %d" */

 Portal register assists */

 Cache-inhibited register offsets */

 Cache-enabled register offsets */

 Cache-inhibited register offsets */

 Cache-enabled register offsets */

/*

 * Portal modes.

 *   Enum types;

 *     pmode == production mode

 *     cmode == consumption mode,

 *   Enum values use 3 letter codes. First letter matches the portal mode,

 *   remaining two letters indicate;

 *     ci == cache-inhibited portal register

 *     ce == cache-enabled portal register

 *     vb == in-band valid-bit (cache-enabled)

 matches BCSP_CFG::RPM */

 PI index, cache-inhibited */

 PI index, cache-enabled */

 valid-bit */

 s/w-only */

 CI index, cache-inhibited */

 CI index, cache-enabled */

 --- Portal structures --- */

 Release Command */

 writes to this are non-coherent */

 used with BM_RCR_VERB_CMD_BPID_SINGLE */

 one of two values; */

 values 1..8 */

 MC (Management Command) command */

 writes to this are non-coherent */

 used by acquire command */

 where the verb contains; */

 values 1..8 go here */

 MC result, Acquire and Query Response */

 0..8 */

 us */

 Can only be _mc_start()ed */

 Can only be _mc_commit()ed or _mc_abort()ed */

 Can only be _mc_retry()ed */

 cache-enabled */

 Same as above but for direct access */

 cache-inhibited */

 Cache-inhibited register access. */

 Cache Enabled Portal Access */

 interrupt sources processed by portal_isr(), configurable */

 probing time config params for cpu-affine portals */

/*

 * This object type refers to a pool, it isn't *the* pool. There may be

 * more than one such object per BMan buffer pool, eg. if different users of the

 * pool are operating via different portals.

 index of the buffer pool to encapsulate (0-63) */

 Used for hash-table admin when using depletion notifications. */

 --- RCR API --- */

 Bit-wise logic to wrap a ring pointer by clearing the "carry bit" */

 Bit-wise logic to convert a ring pointer to a ring index */

 Increment the 'cursor' ring pointer, taking 'vbit' into account */

 increment to the next RCR pointer and handle overflow and 'vbit' */

 BCSP_CFG::RPM */

 --- Management command API --- */

	/*

	 * The inactive response register's verb byte always returns zero until

	 * its command is submitted and completed. This includes the valid-bit,

	 * in case you were wondering...

 Disable all BSCN interrupts for the portal */

	/*

	 * prep the low-level portal struct with the mapped addresses from the

	 * config, everything that follows depends on it and "config" is more

	 * for (de)reference...

	/*

	 * Default to all BPIDs disabled, we enable as required at

	 * run-time.

 Write-to-clear any stale interrupt status bits */

 Need RCR to be empty before continuing */

 Success */

 There should be no status register bits left undefined */

 Acquire buffers until empty */

 Pool is empty */

 1ms */

	/*

	 * we can copy all but the first entry, as this can trigger badness

	 * with the valid-bit

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 Register offsets */

 n=2,3 */

 relative to REG_[FQD|PFDR]_BARE */

 relative to REG_[FQD|PFDR]_BARE */

 Assists for QMAN_MCR */

/*

 * Corenet initiator settings. Stash request queues are 4-deep to match cores

 * ability to snarf. Stash priority is 3, other priorities are 2.

 write SRCCIV enable */

 Follows WQ_CS_CFG0-5 */

 Follows FQD_[BARE|BAR|AR] and PFDR_[BARE|BAR|AR] */

 Used by all error interrupt registers except 'inhibit' */

 Corenet Initiator Data Error */

 Corenet Target Data Error */

 Corenet Invalid Target Transaction */

 PFDR Low Watermark */

 Multi-bit ECC Error */

 Single-bit ECC Error */

 PFDR Enqueues Blocked Interrupt */

 Invalid FQ Flow Control State */

 Invalid Command Verb */

 Invalid Dequeue (Direct-connect) */

 Invalid Dequeue FQ */

 Invalid Dequeue Source */

 Invalid Dequeue Queue */

 Invalid Enqueue Configuration */

 Invalid Enqueue Overflow */

 Invalid Enqueue State */

 Invalid Enqueue Channel */

 Invalid Enqueue Queue */

 QMAN_ECIR valid error bit */

 res[30-31], ptyp[29], pnum[24-28], fqid[0-23] */

 ptyp[31], res[10-30], pnum[0-9] */

 memid[24-27], eadr[0-11] */

 v3: memid[24-28], eadr[0-15] */

/*

 * TODO: unimplemented registers

 *

 * Keeping a list here of QMan registers I have not yet covered;

 * QCSP_DD_IHRSR, QCSP_DD_IHRFR, QCSP_DD_HASR,

 * DCP_DD_IHRSR, DCP_DD_IHRFR, DCP_DD_HASR, CM_CFG,

 * QMAN_EECC, QMAN_SBET, QMAN_EINJ, QMAN_SBEC0-12

 Pointer to the start of the QMan's CCSR space */

 A SDQCR mask comprising all the available/visible pool channels */

 choke if size isn't within range */

 choke if 'ba' has lower-alignment than 'size' */

 Check to see if QMan has already been initialized */

 Maker sure ba == what was programmed) */

 Return 1 to indicate memory was previously programmed */

 Need to temporarily map the area to make sure it is zeroed */

	/*

	 * PPC doesn't appear to flush the cache on memunmap() but the

	 * cache must be flushed since QMan does non coherent accesses

	 * to this memory

 Make sure the command interface is 'idle' */

 Write the MCR command params then the verb */

	/*

	 * TODO: remove this - it's a workaround for a model bug that is

	 * corrected in more recent versions. We use the workaround until

	 * everyone has upgraded.

 Poll for the result */

/*

 * QMan needs two global memory areas initialized at boot time:

 *  1) FQD: Frame Queue Descriptors used to manage frame queues

 *  2) PFDR: Packed Frame Queue Descriptor Records used to store frames

 * Both areas are reserved using the device tree reserved memory framework

 * and the addresses and sizes are initialized when the QMan device is probed

/*

 * Support for PPC Device Tree backward compatibility when compatible

 * string is set to fsl-qman-fqd and fsl-qman-pfdr

 map as cacheable, non-guarded */

 Is portal info valid */

 Re-arm error capture registers */

 FQD memory */

 PFDR memory */

 Only initialize PFDRs if the QMan was not initialized before */

 thresholds */

 clear stale PEBI bit from interrupt status register */

 corenet initiator settings */

 HID settings */

 Set scheduling weights to defaults */

 We are not prepared to accept ERNs for hardware enqueues */

 Each pair of vcpu share the same SRQ(SDEST) */

 parse pool channels into the SDQCR mask */

		/*

		 * For PPC backward DT compatibility

		 * FQD memory MUST be zero'd by software

		/*

		 * Order of memory regions is assumed as FQD followed by PFDR

		 * in order to ensure allocations from the correct regions the

		 * driver initializes then allocates each piece in order

 Setup PFDR memory */

	/*

	 * Write-to-clear any stale bits, (eg. starvation being asserted prior

	 * to resource allocation during driver init).

 Enable Error Interrupts */

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/* Copyright 2009 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

/*

 * Algorithm:

 *

 * Each cpu will have HP_PER_CPU "handlers" set up, each of which incorporates

 * an rx/tx pair of FQ objects (both of which are stashed on dequeue). The

 * organisation of FQIDs is such that the HP_PER_CPU*NUM_CPUS handlers will

 * shuttle a "hot potato" frame around them such that every forwarding action

 * moves it from one cpu to another. (The use of more than one handler per cpu

 * is to allow enough handlers/FQs to truly test the significance of caching -

 * ie. when cache-expiries are occurring.)

 *

 * The "hot potato" frame content will be HP_NUM_WORDS*4 bytes in size, and the

 * first and last words of the frame data will undergo a transformation step on

 * each forwarding action. To achieve this, each handler will be assigned a

 * 32-bit "mixer", that is produced using a 32-bit LFSR. When a frame is

 * received by a handler, the mixer of the expected sender is XOR'd into all

 * words of the entire frame, which is then validated against the original

 * values. Then, before forwarding, the entire frame is XOR'd with the mixer of

 * the current handler. Apart from validating that the frame is taking the

 * expected path, this also provides some quasi-realistic overheads to each

 * forwarding action - dereferencing *all* the frame data, computation, and

 * conditional branching. There is a "special" handler designated to act as the

 * instigator of the test by creating an enqueuing the "hot potato" frame, and

 * to determine when the test has completed by counting HP_LOOPS iterations.

 *

 * Init phases:

 *

 * 1. prepare each cpu's 'hp_cpu' struct using on_each_cpu(,,1) and link them

 *    into 'hp_cpu_list'. Specifically, set processor_id, allocate HP_PER_CPU

 *    handlers and link-list them (but do no other handler setup).

 *

 * 2. scan over 'hp_cpu_list' HP_PER_CPU times, the first time sets each

 *    hp_cpu's 'iterator' to point to its first handler. With each loop,

 *    allocate rx/tx FQIDs and mixer values to the hp_cpu's iterator handler

 *    and advance the iterator for the next loop. This includes a final fixup,

 *    which connects the last handler to the first (and which is why phase 2

 *    and 3 are separate).

 *

 * 3. scan over 'hp_cpu_list' HP_PER_CPU times, the first time sets each

 *    hp_cpu's 'iterator' to point to its first handler. With each loop,

 *    initialise FQ objects and advance the iterator for the next loop.

 *    Moreover, do this initialisation on the cpu it applies to so that Rx FQ

 *    initialisation targets the correct cpu.

/*

 * helper to run something on all cpus (can't use on_each_cpu(), as that invokes

 * the fn from irq context, which is too restrictive).

		/*

		 * If we call kthread_stop() before the "wake up" has had an

		 * effect, then the thread may exit with -EINTR without ever

		 * running the function. So poll until it's started before

		 * requesting it to stop.

 The following data is stashed when 'rx' is dequeued; */

 -------------- */

 The Rx FQ, dequeues of which will stash the entire hp_handler */

 The Tx FQ we should forward to */

 The value we XOR post-dequeue, prior to validating */

 The value we XOR pre-enqueue, after validating */

 what the hotpotato address should be on dequeue */

 The following data isn't (necessarily) stashed on dequeue; */

 -------------- */

 list node for linking us into 'hp_cpu' */

 Just to check ... */

 identify the cpu we run on; */

 root node for the per-cpu list of handlers */

 list node for linking us into 'hp_cpu_list' */

	/*

	 * when repeatedly scanning 'hp_list', each time linking the n'th

	 * handlers together, this is used as per-cpu iterator state

 Each cpu has one of these */

 links together the hp_cpu structs, in first-come first-serve order. */

 the "special" handler, that starts and terminates the test. */

 handlers are allocated out of this, so they're properly aligned. */

 this is the frame data */

 needed for dma_map*() */

 the main function waits on this */

 80 bytes, like a small ethernet frame, and bleeds into a second cacheline */

 First word of the LFSR-based frame data */

 Set up rx */

 Set up tx */

 Rx FQID is the previous handler's Tx FQID */

 Allocate new FQID for Tx */

 Rx mixer is the previous handler's Tx mixer */

 Get new mixer for Tx */

 Fix up the first handler (fqid_rx==0, rx_mixer=0xdeadbeef) */

 and tag it as our "special" handler */

 Init phase 1 */

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 Helpers for initialising and "incrementing" a frame descriptor */

 The only part of the 'fd' we can't memcmp() is the ppid */

 test */

 Initialise (parked) FQ */

 Do enqueues + VDQCR, twice. (Parked FQ) */

 Retire and OOS the FQ */

/* Copyright 2008 - 2016 Freescale Semiconductor, Inc.

 *

 * Redistribution and use in source and binary forms, with or without

 * modification, are permitted provided that the following conditions are met:

 *     * Redistributions of source code must retain the above copyright

 *	 notice, this list of conditions and the following disclaimer.

 *     * Redistributions in binary form must reproduce the above copyright

 *	 notice, this list of conditions and the following disclaimer in the

 *	 documentation and/or other materials provided with the distribution.

 *     * Neither the name of Freescale Semiconductor nor the

 *	 names of its contributors may be used to endorse or promote products

 *	 derived from this software without specific prior written permission.

 *

 * ALTERNATIVELY, this software may be distributed under the terms of the

 * GNU General Public License ("GPL") as published by the Free Software

 * Foundation, either version 2 of that License or (at your option) any

 * later version.

 *

 * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY

 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED

 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE

 * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY

 * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES

 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;

 * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND

 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS

 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 if EQCR congests, interrupt threshold */

 big enough for "QMan portal %d" */

 Portal register assists */

 Cache-inhibited register offsets */

 Cache-enabled register offsets */

 Cache-inhibited register offsets */

 Cache-enabled register offsets */

/*

 * BTW, the drivers (and h/w programming model) already obtain the required

 * synchronisation for portal accesses and data-dependencies. Use of barrier()s

 * or other order-preserving primitives simply degrade performance. Hence the

 * use of the __raw_*() interfaces, which simply ensure that the compiler treats

 * the portal registers as volatile

 Cache-enabled ring access */

/*

 * Portal modes.

 *   Enum types;

 *     pmode == production mode

 *     cmode == consumption mode,

 *     dmode == h/w dequeue mode.

 *   Enum values use 3 letter codes. First letter matches the portal mode,

 *   remaining two letters indicate;

 *     ci == cache-inhibited portal register

 *     ce == cache-enabled portal register

 *     vb == in-band valid-bit (cache-enabled)

 *     dc == DCA (Discrete Consumption Acknowledgment), DQRR-only

 *   As for "enum qm_dqrr_dmode", it should be self-explanatory.

 matches QCSP_CFG::EPM */

 PI index, cache-inhibited */

 PI index, cache-enabled */

 valid-bit */

 matches QCSP_CFG::DP */

 SDQCR  + VDQCR */

 PDQCR */

 s/w-only */

 reads DQRR_PI_CINH */

 reads DQRR_PI_CENA */

 reads valid-bit */

 matches QCSP_CFG::DCM */

 CI index, cache-inhibited */

 CI index, cache-enabled */

 Discrete Consumption Acknowledgment */

 s/w-only */

 reads MR_PI_CINH */

 reads MR_PI_CENA */

 reads valid-bit */

 matches QCSP_CFG::MM */

 CI index, cache-inhibited */

 CI index, cache-enabled */

 --- Portal structures --- */

 "Enqueue Command" */

 writes to this are non-coherent */

 24-bit */

 but only one value; */

 Advance NESN */

 More fragments to come */

 sequence number goes here */

 MC (Management Command) command */

 "FQ" command layout */

 24-bit */

 "CGR" command layout */

 where the verb contains; */

 "non-programmable" fields */

 Schedule FQ */

 Force Eligible FQ */

 Retire FQ */

 Take FQ out of service */

 FQ XON */

 FQ XOFF */

 writes to this are non-coherent */

 MC (Management Command) result */

 "Query FQ" */

 the FQD fields are here */

 "Alter FQ State Commands" */

 Frame Queue Status */

 OOS fails if FQ is !empty */

 ORL fragments to come */

 FQ has enqueued frames */

 us */

 Can be _mc_start()ed */

 Can be _mc_commit()ed or _mc_abort()ed */

 Can only be _mc_retry()ed */

 cache-enabled */

 same value as above but for direct access */

 cache-inhibited */

	/*

	 * In the non-CONFIG_FSL_DPAA_CHECKING case, the following stuff up to

	 * and including 'mc' fits within a cacheline (yay!). The 'config' part

	 * is setup-only, so isn't a cause for a concern. In other words, don't

	 * rearrange this structure on a whim, there be dragons ...

 Cache-inhibited register access. */

 Cache Enabled Portal Access */

 --- EQCR API --- */

 Bit-wise logic to wrap a ring pointer by clearing the "carry bit" */

 Bit-wise logic to convert a ring pointer to a ring index */

 Increment the 'cursor' ring pointer, taking 'vbit' into account */

 increment to the next EQCR pointer and handle overflow and 'vbit' */

 QCSP_CFG: EST */

 QCSP_CFG: EP */

 QCSP_CFG::EPM */

 --- DQRR API --- */

 Make sure the DQRR will be idle when we enable */

 Invalidate every ring entry before beginning */

 DQRR_MF */

 DP */

 DCM */

 RE+SE */

 Ignore RP */

 Ignore SP */

	/*

	 * If PAMU is not available we need to invalidate the cache.

	 * When PAMU is available the cache is updated by stash

 DQRR_DCAP::S */

 DQRR_DCAP::PK */

 DQRR_DCAP::DCAP_CI */

 DQRR_DCAP::S */

 DQRR_DCAP::DCAP_CI */

 --- MR API --- */

 QCSP_CFG:MM */

 --- Management command API --- */

	/*

	 * The expected valid bit polarity for the next CR command is 0

	 * if RR1 contains a valid response, and is 1 if RR0 contains a

	 * valid response. If both RR contain all 0, this indicates either

	 * that no command has been executed since reset (in which case the

	 * expected valid bit polarity is 1)

	/*

	 *  The inactive response register's verb byte always returns zero until

	 * its command is submitted and completed. This includes the valid-bit,

	 * in case you were wondering...

 PORTAL_BITS_*** - dynamic, strictly internal */

 interrupt sources processed by portal_isr(), configurable */

 only 1 volatile dequeue at a time */

 probing time config params for cpu-affine portals */

 2-element array. cgrs[0] is mask, cgrs[1] is snapshot. */

 linked-list of CSCN handlers. */

 list lock */

/*

 * This is what everything can wait on, even if it migrates to a different cpu

 * to the one whose affine portal it is waiting on.

/*

 * Only returns full-service fq objects, not enqueue-only

 * references (QMAN_FQ_FLAG_NO_MODIFY).

 DQRR-handling if it's interrupt-driven */

 Handling of anything else that's interrupt-driven */

		/*

		 * if MR was full and h/w had other FQRNI entries to produce, we

		 * need to allow it time to produce those entries once the

		 * existing entries are consumed. A worst-case situation

		 * (fully-loaded system) means h/w sequencers may have to do 3-4

		 * other things before servicing the portal's MR pump, each of

		 * which (if slow) may take ~50 qman cycles (which is ~200

		 * processor cycles). So rounding up and then multiplying this

		 * worst-case estimate by a factor of 10, just to be

		 * ultra-paranoid, goes as high as 10,000 cycles. NB, we consume

		 * one entry at a time, so h/w has an opportunity to produce new

		 * entries well before the ring has been fully consumed, so

		 * we're being *really* paranoid here.

 We aren't draining anything but FQRNIs */

 PAMU is required for stashing */

	/*

	 * prep the low-level portal struct with the mapped addresses from the

	 * config, everything that follows depends on it and "config" is more

	 * for (de)reference

	/*

	 * If CI-stashing is used, the current defaults use a threshold of 3,

	 * and stash with high-than-DQRR priority.

 static interrupt-gating controls */

 initial snapshot is no-depletion */

 if the given mask is NULL, assume all CGRs can be seen */

 Need EQCR to be empty before continuing */

 special handling, drain just in case it's a few FQRNIs */

 Success */

 Write a sane SDQCR */

 Stop dequeues on the portal */

	/*

	 * NB we do this to "quiesce" EQCR. If we add enqueue-completions or

	 * something related to QM_PIRQ_EQCI, this may need fixing.

	 * Also, due to the prefetching model used for CI updates in the enqueue

	 * path, this update will only invalidate the CI cacheline *after*

	 * working on it, so we need to call this twice to ensure a full update

	 * irrespective of where the enqueue processing was at when the teardown

	 * began.

 Inline helper to reduce nesting in __poll_portal_slow() */

 mask out the ones I'm not interested in */

 check previous snapshot for delta, enter/exit congestion */

 update snapshot */

 Invoke callback */

 The message is a software ERN iff the 0x20 bit is clear */

 nada, we drop FQRNIs on the floor */

 Lookup in the retirement table */

 Parked */

 DCP ERN */

 Its a software ERN */

/*

 * remove some slowish-path stuff from the "fast path" and make sure it isn't

 * inlined.

/*

 * The only states that would conflict with other things if they ran at the

 * same time on the same cpu are:

 *

 *   (i) setting/clearing vdqcr_owned, and

 *  (ii) clearing the NE (Not Empty) flag.

 *

 * Both are safe. Because;

 *

 *   (i) this clearing can only occur after qman_volatile_dequeue() has set the

 *	 vdqcr_owned field (which it does before setting VDQCR), and

 *	 qman_volatile_dequeue() blocks interrupts and preemption while this is

 *	 done so that we can't interfere.

 *  (ii) the NE flag is only cleared after qman_retire_fq() has set it, and as

 *	 with (i) that API prevents us from interfering until it's safe.

 *

 * The good thing is that qman_volatile_dequeue() and qman_retire_fq() run far

 * less frequently (ie. per-FQ) than __poll_portal_fast() does, so the nett

 * advantage comes from this function not having to "lock" anything at all.

 *

 * Note also that the callbacks are invoked at points which are safe against the

 * above potential conflicts, but that this function itself is not re-entrant

 * (this is because the function tracks one end of each FIFO in the portal and

 * we do *not* want to lock that). So the consequence is that it is safe for

 * user callbacks to call into any QMan API.

			/*

			 * VDQCR: don't trust context_b as the FQ may have

			 * been configured for h/w consumption and we're

			 * draining it post-retirement.

			/*

			 * We only set QMAN_FQ_STATE_NE when retiring, so we

			 * only need to check for clearing it when doing

			 * volatile dequeues.  It's one less thing to check

			 * in the critical path (SDQCR).

			/*

			 * This is duplicated from the SDQCR code, but we

			 * have stuff to do before *and* after this callback,

			 * and we don't want multiple if()s in the critical

			 * path (SDQCR).

 Check for VDQCR completion */

 SDQCR: context_b points to the FQ */

 Now let the callback do its stuff */

			/*

			 * The callback can request that we exit without

			 * consuming this entry nor advancing;

 Interpret 'dq' from a driver perspective. */

		/*

		 * Parking isn't possible unless HELDACTIVE was set. NB,

		 * FORCEELIGIBLE implies HELDACTIVE, so we only need to

		 * check for HELDACTIVE to cover both.

 just means "skip it, I'll consume it myself later on" */

 Move forward */

		/*

		 * Entry processed and consumed, increment our counter.  The

		 * callback can request that we exit after consuming the

		 * entry, and we also exit if we reach our processing limit,

		 * so loop back only if neither of these conditions is met.

	/*

	 * Our interrupt handler only processes+clears status register bits that

	 * are in p->irq_sources. As we're trimming that mask, if one of them

	 * were to assert in the status register just before we remove it from

	 * the enable register, there would be an interrupt-storm when we

	 * release the IRQ lock. So we wait for the enable register update to

	 * take effect in h/w (by reading it back) and then clear all other bits

	 * in the status register. Ie. we clear them from ISR once it's certain

	 * IER won't allow them to reassert.

	/*

	 * Using "~ier" (rather than "bits" or "~p->irq_sources") creates a

	 * data-dependency, ie. to protect against re-ordering.

 Frame queue API */

 A context_b of 0 is allegedly special, so don't use that fqid */

	/*

	 * We don't need to lock the FQ as it is a pre-condition that the FQ be

	 * quiesced. Instead, run some checks.

 And can't be set at the same time as TDTHRESH */

 Issue an INITFQ_[PARKED|SCHED] management command */

	/*

	 * If the FQ does *not* have the TO_DCPORTAL flag, context_b is set as a

	 * demux pointer. Otherwise, the caller-provided value is allowed to

	 * stand, don't overwrite it.

		/*

		 *  and the physical address - NB, if the user wasn't trying to

		 * set CONTEXTA, clear the stashing settings.

 Issue a ALTERFQ_SCHED management command */

	/*

	 * "Elegant" would be to treat OK/PENDING the same way; set CHANGING,

	 * and defer the flags until FQRNI or FQRN (respectively) show up. But

	 * "Friendly" is to process OK immediately, and not set CHANGING. We do

	 * friendly, otherwise the caller doesn't necessarily have a fully

	 * "retired" FQ on return even if the retirement was immediate. However

	 * this does mean some code duplication between here and

	 * fq_state_change().

 Process 'fq' right away, we'll ignore FQRNI */

			/*

			 * Another issue with supporting "immediate" retirement

			 * is that we're forced to drop FQRNIs, because by the

			 * time they're seen it may already be "too late" (the

			 * fq may have been OOS'd and free()'d already). But if

			 * the upper layer wants a callback whether it's

			 * immediate or not, we have to fake a "MR" entry to

			 * look like an FQRNI...

 internal function used as a wait_event() expression */

 VDQCR is set */

			/*

			 * NB: don't propagate any error - the caller wouldn't

			 * know whether the VDQCR was issued or not. A signal

			 * could arrive after returning anyway, so the caller

			 * can check signal_pending() if that's an issue.

		/*

		 * The stashing case is easy, only update if we need to in

		 * order to try and liberate ring entries.

		/*

		 * The non-stashing case is harder, need to prefetch ahead of

		 * time.

 congestion state change notification target update control */

	/*

	 * We have to check that the provided CGRID is within the limits of the

	 * data-structures, for obvious reasons. However we'll let h/w take

	 * care of determining whether it's within the limits of what exists on

	 * the SoC.

 send init if flags indicate so */

 Determine if newly added object requires its callback to be called */

 we can't go back, so proceed and return success */

 attempt to delete from other portal than creator */

	/*

	 * If there are no other CGR objects for this CGRID in the list,

	 * update CSCN_TARG accordingly

 add back to the list */

 add back to the list */

 Cleanup FQs */

 Determine the state of the FQID */

 Already OOS, no need to do anymore checks */

 Query which channel the FQ is using */

 Need to store these since the MCR gets reused */

 Make a copy as we reuse MCR below */

			/*

			 * Need to wait for the FQRN in the message ring, which

			 * will only occur once the FQ has been drained.  In

			 * order for the FQ to drain the portal needs to be set

			 * to dequeue from the channel the FQ is scheduled on

 Flag that we need to drain FQ */

 Pool channel, enable the bit in the portal */

 Dedicated channel */

 Set the sdqcr to drain this channel */

 Keep draining DQRR while checking the MR*/

 Process message ring too */

 Restore SDQCR */

			/*

			 * ORL had no entries, no need to wait until the

			 * ERNs come in

		/*

		 * Retirement succeeded, check to see if FQ needs

		 * to be drained

 FQ is Not Empty, drain using volatile DQ commands */

				/*

				 * Wait for a dequeue and process the dequeues,

				 * making sure to empty the ring completely

 Wait for the ORL to have been completely drained */

 Send OOS Command */

  Done */

 FQID allocator */

 pool-channel allocator */

 CGR ID allocator */

	/*

	 * We query all FQDs starting from

	 * FQID 1 until we get an "invalid FQID" error, looking for non-OOS FQDs

	 * whose destination channel is the pool-channel being released.

	 * When a non-OOS FQD is found we attempt to clean it up

 FQID range exceeded, found no problems */

 The channel is the FQ's target, clean it */

					/*

					 * Couldn't shut down the FQ

					 * so the pool must be leaked

 Move to the next FQID */

	/*

	 * query all FQDs starting from FQID 1 until we get an "invalid FQID"

	 * error, looking for non-OOS FQDs whose CGR is the CGR being released

 FQID range exceeded, found no problems */

 Move to the next FQID */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * QUICC Engine GPIOs

 *

 * Copyright (c) MontaVista Software, Inc. 2008.

 *

 * Author: Anton Vorontsov <avorontsov@ru.mvista.com>

 FIXME: needed for gpio_to_chip() get rid of this */

 shadowed data register to clear/set bits safely */

 saved_regs used to restore dedicated functions */

	/*

	 * The qe_gpio_chip name is unfortunate, we should change that to

	 * something like qe_pio_controller. Someday.

/**

 * qe_pin_request - Request a QE pin

 * @np:		device node to get a pin from

 * @index:	index of a pin in the device tree

 * Context:	non-atomic

 *

 * This function return qe_pin so that you could use it with the rest of

 * the QE Pin Multiplexing API.

/**

 * qe_pin_free - Free a pin

 * @qe_pin:	pointer to the qe_pin structure

 * Context:	any

 *

 * This function frees the qe_pin structure and makes a pin available

 * for further qe_pin_request() calls.

/**

 * qe_pin_set_dedicated - Revert a pin to a dedicated peripheral function mode

 * @qe_pin:	pointer to the qe_pin structure

 * Context:	any

 *

 * This function resets a pin to a dedicated peripheral function that

 * has been set up by the firmware.

/**

 * qe_pin_set_gpio - Set a pin to the GPIO mode

 * @qe_pin:	pointer to the qe_pin structure

 * Context:	any

 *

 * This function sets a pin to the GPIO mode.

 Let's make it input by default, GPIO API is able to change that. */

 try others anyway */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/powerpc/sysdev/qe_lib/qe_ic.c

 *

 * Copyright (C) 2006 Freescale Semiconductor, Inc.  All rights reserved.

 *

 * Author: Li Yang <leoli@freescale.com>

 * Based on code from Shlomi Gridish <gridish@freescale.com>

 *

 * QUICC ENGINE Interrupt Controller

 QE IC registers offset */

 Control registers offset */

 The remapper for this QEIC */

 The "linux" controller struct */

 VIRQ numbers of QE high/low irqs */

/*

 * QE interrupt controller internal structure

 Location of this source at the QIMR register */

 Mask register offset */

	/*

	 * For grouped interrupts sources - the interrupt code as

	 * appears at the group priority register

 Group priority register offset */

	/* Flush the above write before enabling interrupts; otherwise,

	 * spurious interrupts will sometimes happen.  To be 100% sure

	 * that the write has reached the device before interrupts are

	 * enabled, the mask register would have to be read back; however,

	 * this is not required for correctness, only to avoid wasting

	 * time on a large number of spurious interrupts.  In testing,

	 * a sync reduced the observed spurious interrupts to zero.

 Exact match, unless qe_ic node is NULL */

 Default chip */

 Return an interrupt vector or 0 if no interrupt is pending. */

 get the interrupt source vector. */

 Return an interrupt vector or 0 if no interrupt is pending. */

 get the interrupt source vector. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * QE USB routines

 *

 * Copyright 2006 Freescale Semiconductor, Inc.

 *               Shlomi Gridish <gridish@freescale.com>

 *               Jerry Huang <Chang-Ming.Huang@freescale.com>

 * Copyright (c) MontaVista Software, Inc. 2008.

 *               Anton Vorontsov <avorontsov@ru.mvista.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2006 Freescale Semiconductor, Inc. All rights reserved.

 *

 * Authors: 	Shlomi Gridish <gridish@freescale.com>

 * 		Li Yang <leoli@freescale.com>

 *

 * Description:

 * QE UCC Fast API Set - UCC Fast specific routines implementations.

 Enable reception and/or transmission on this UCC. */

 Disable reception and/or transmission on this UCC. */

 check if the UCC port number is in range. */

 Check that 'max_rx_buf_length' is properly aligned (4). */

 Validate Virtual Fifo register values */

 Fill fast UCC structure */

 Set the PHY base address */

 STATISTICS */

 Set UCC to fast type */

 Set GUMR */

 For more details see the hardware spec. */

 Allocate memory for Tx Virtual Fifo */

 Allocate memory for Rx Virtual Fifo */

 Set Virtual Fifo registers */

 utfb, urfb are offsets from MURAM base */

 Mux clocking */

 Grant Support */

 Breakpoint Support */

 Set Tsa or NMSI mode. */

 If NMSI (not Tsa), set Tx and Rx clock. */

 Rx clock routing */

 Tx clock routing */

 tdm Rx clock routing */

 tdm Tx clock routing */

 tdm Rx sync clock routing */

 tdm Tx sync clock routing */

 Set interrupt mask register at UCC level. */

	/* First, clear anything pending at UCC level,

	 * otherwise, old garbage may come through

 Writing '1' clears */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/powerpc/sysdev/qe_lib/ucc.c

 *

 * QE UCC API Set - UCC specific routines implementations.

 *

 * Copyright (C) 2006 Freescale Semiconductor, Inc. All rights reserved.

 *

 * Authors: 	Shlomi Gridish <gridish@freescale.com>

 * 		Li Yang <leoli@freescale.com>

/* Configure the UCC to either Slow or Fast.

 *

 * A given UCC can be figured to support either "slow" devices (e.g. UART)

 * or "fast" devices (e.g. Ethernet).

 *

 * 'ucc_num' is the UCC number, from 0 - 7.

 *

 * This function also sets the UCC_GUEMR_SET_RESERVED3 bit because that bit

 * must always be set to 1.

	/* The GUEMR register is at the same location for both slow and fast

 check if the UCC number is in range. */

 check if the UCC number is in range. */

 The communications direction must be RX or TX */

 Check for invalid combination of clock and UCC number */

	/*

	 * for TDM[0, 1, 2, 3], TX and RX use  common

	 * clock source BRG3,4 and CLK1,2

	 * for TDM[4, 5, 6, 7], TX and RX use  common

	 * clock source BRG12,13 and CLK23,24

 tdm_num: TDM A-H port num is 0-7 */

 The communications direction must be RX or TX */

 The communications direction must be RX or TX */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2015 Freescale Semiconductor, Inc. All rights reserved.

 *

 * Authors:	Zhao Qiang <qiang.zhao@nxp.com>

 *

 * Description:

 * QE TDM API Set - TDM specific routines implementations.

 set siram table */

 Set SIxMR register */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2006-2010 Freescale Semiconductor, Inc. All rights reserved.

 *

 * Authors: 	Shlomi Gridish <gridish@freescale.com>

 * 		Li Yang <leoli@freescale.com>

 * Based on cpm2_common.c from Dan Malek (dmalek@jlc.net)

 *

 * Description:

 * General Purpose functions for the global management of the

 * QUICC Engine (QE).

/* We allocate this here because it is used almost exclusively for

 * the communication processor devices.

 Dynamically allocated SNUMs */

	/*

	 * Newer device trees have an "fsl,qe" compatible property for the QE

	 * node, but we still need to support older device trees.

 Reclaim the MURAM memory for our use. */

 Here device is the SNUM, not sub-block */

			/* Here device is the SNUM, and mcnProtocol is

 wait for the QE_CR_FLG to clear */

 On timeout, ret is -ETIMEDOUT, otherwise it will be 0. */

/* Set a baud rate generator. This needs lots of work. There are

 * 16 BRGs, which can be connected to the QE channels or output

 * as clocks. The BRGs are in two different block of internal

 * memory mapped space.

 * The BRG clock is the QE clock divided by 2.

 * It was set up long ago during the initial boot phase and is

 * is given to us.

 * Baud rate clocks are zero-based in the driver code (as that maps

 * to port numbers). Documentation uses 1-based numbering.

 round this if near to a multiple of CLK_GRAN */

/* Program the BRG to the given sampling rate and multiplier

 *

 * @brg: the BRG, QE_BRG1 - QE_BRG16

 * @rate: the desired sampling rate

 * @multiplier: corresponds to the value programmed in GUMR_L[RDCR] or

 * GUMR_L[TDCR].  E.g., if this BRG is the RX clock, and GUMR_L[RDCR]=01,

 * then 'multiplier' should be 8.

	/* Errata QE_General4, which affects some MPC832x and MPC836x SOCs, says

	   that the BRG divisor must be even if you're not using divide-by-16

/* Convert a string to a QE clock source enum

 *

 * This function takes a string, typically from a property in the device

 * tree, and returns the corresponding "enum qe_clock" value.

/* Initialize SNUMs (thread serial numbers) according to

 * QE Module Control chapter, SNUM table

 The default number of snum for threads is 28 */

		/*

		 * Fall back to legacy binding of using the value of

		 * fsl,qe-num-snums to choose one of the static arrays

		 * above.

	/* allocate 2 internal temporary buffers (512 bytes size each) for

 The maximum number of RISCs we support */

 Firmware information stored here for qe_get_firmware_info() */

/*

 * Set to 1 if QE firmware has been uploaded, and therefore

 * qe_firmware_info contains valid data.

/*

 * Upload a QE microcode

 *

 * This function is a worker function for qe_upload_firmware().  It does

 * the actual uploading of the microcode.

 Use auto-increment */

 Set I-RAM Ready Register */

/*

 * Upload a microcode to the I-RAM at a specific address.

 *

 * See Documentation/powerpc/qe_firmware.rst for information on QE microcode

 * uploading.

 *

 * Currently, only version 1 is supported, so the 'version' field must be

 * set to 1.

 *

 * The SOC model and revision are not validated, they are only displayed for

 * informational purposes.

 *

 * 'calc_size' is the calculated size, in bytes, of the firmware structure and

 * all of the microcode structures, minus the CRC.

 *

 * 'length' is the size that the structure says it is, including the CRC.

 Check the magic */

 Check the version */

 Validate some of the fields */

 Validate the length and check if there's a CRC */

		/*

		 * For situations where the second RISC uses the same microcode

		 * as the first, the 'code_offset' and 'count' fields will be

		 * zero, so it's okay to add those.

 Validate the length */

 Validate the CRC */

	/*

	 * If the microcode calls for it, split the I-RAM.

	/*

	 * The QE only supports one microcode per RISC, so clear out all the

	 * saved microcode information and put in the new.

 Loop through each microcode. */

 Upload a microcode if it's present */

 Program the traps for this processor */

 Enable traps */

/*

 * Get info on the currently-loaded firmware

 *

 * This function also checks the device tree to see if the boot loader has

 * uploaded a firmware already.

	/*

	 * If we haven't checked yet, and a driver hasn't uploaded a firmware

	 * yet, then check the device tree for information.

 Find the 'firmware' child node */

 Did we find the 'firmware' node? */

 Copy the data into qe_firmware_info*/

 defined(CONFIG_SUSPEND) && defined(CONFIG_PPC_85xx) */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2006 Freescale Semiconductor, Inc. All rights reserved.

 *

 * Authors: 	Shlomi Gridish <gridish@freescale.com>

 * 		Li Yang <leoli@freescale.com>

 *

 * Description:

 * QE UCC Slow API Set - UCC Slow specific routines implementations.

 Enable reception and/or transmission on this UCC. */

 Disable reception and/or transmission on this UCC. */

/* Initialize the UCC for Slow operations

 *

 * The caller should initialize the following us_info

 check if the UCC port number is in range. */

	/*

	 * Set mrblr

	 * Check that 'max_rx_buf_length' is properly aligned (4), unless

	 * rfw is 1, meaning that QE accepts one byte at a time, unlike normal

	 * case when QE accepts 32 bits at a time.

 Fill slow UCC structure */

 Set the PHY base address */

 Get PRAM base */

 Set UCC to slow type */

 Allocate BDs. */

 Init Tx bds */

 clear bd buffer */

 set bd status and length */

 for last BD set Wrap bit */

 Init Rx bds */

 set bd status and length */

 clear bd buffer */

 for last BD set Wrap bit */

 Set GUMR (For more details see the hardware spec.). */

 gumr_h */

 gumr_l */

 Function code registers */

 if the data is in cachable memory, the 'global' */

 in the function code should be set. */

 rbase, tbase are offsets from MURAM base */

 Mux clocking */

 Grant Support */

 Breakpoint Support */

 Set Tsa or NMSI mode. */

 If NMSI (not Tsa), set Tx and Rx clock. */

 Rx clock routing */

 Tx clock routing */

 Set interrupt mask register at UCC level. */

	/* First, clear anything pending at UCC level,

	 * otherwise, old garbage may come through

 Writing '1' clears */

 Issue QE Init command */

 We know at least one is TRUE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Common CPM code

 *

 * Author: Scott Wood <scottwood@freescale.com>

 *

 * Copyright 2007-2008,2010 Freescale Semiconductor, Inc.

 *

 * Some parts derived from commproc.c/cpm2_common.c, which is:

 * Copyright (c) 1997 Dan error_act (dmalek@jlc.net)

 * Copyright (c) 1999-2001 Dan Malek <dan@embeddedalley.com>

 * Copyright (c) 2000 MontaVista Software, Inc (source@mvista.com)

 * 2006 (c) MontaVista Software, Inc.

 * Vitaly Bordug <vbordug@ru.mvista.com>

 max address size we deal with */

 try legacy bindings */

/*

 * cpm_muram_alloc_common - cpm_muram_alloc common code

 * @size: number of bytes to allocate

 * @algo: algorithm for alloc.

 * @data: data for genalloc's algorithm.

 *

 * This function returns a non-negative offset into the muram area, or

 * a negative errno on failure.

/*

 * cpm_muram_alloc - allocate the requested size worth of multi-user ram

 * @size: number of bytes to allocate

 * @align: requested alignment, in bytes

 *

 * This function returns a non-negative offset into the muram area, or

 * a negative errno on failure.

 * Use cpm_dpram_addr() to get the virtual address of the area.

 * Use cpm_muram_free() to free the allocation.

/**

 * cpm_muram_free - free a chunk of multi-user ram

 * @offset: The beginning of the chunk as returned by cpm_muram_alloc().

/*

 * cpm_muram_alloc_fixed - reserve a specific region of multi-user ram

 * @offset: offset of allocation start address

 * @size: number of bytes to allocate

 * This function returns @offset if the area was available, a negative

 * errno otherwise.

 * Use cpm_dpram_addr() to get the virtual address of the area.

 * Use cpm_muram_free() to free the allocation.

/**

 * cpm_muram_addr - turn a muram offset into a virtual address

 * @offset: muram offset to convert

/**

 * cpm_muram_dma - turn a muram virtual address into a DMA address

 * @addr: virtual address from cpm_muram_addr() to convert

/*

 * As cpm_muram_free, but takes the virtual address rather than the

 * muram offset.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/powerpc/sysdev/qe_lib/qe_io.c

 *

 * QE Parallel I/O ports configuration routines

 *

 * Copyright 2006 Freescale Semiconductor, Inc. All rights reserved.

 *

 * Author: Li Yang <LeoLi@freescale.com>

 * Based on code from Shlomi Gridish <gridish@freescale.com>

 Map Parallel I/O ports registers */

 calculate pin location for single and 2 bits information */

 Set open drain, if required */

 define direction */

 get all bits mask for 2 bit per port */

 Get the final mask we need for the right definition */

 clear and set 2 bits mask */

 define pin assignment */

 clear and set 2 bits mask */

 calculate pin location */

 clear */

 set */

 SPDX-License-Identifier: GPL-2.0

/*

 * Marvell Dove PMU support

/*

 * The PMU contains a register to reset various subsystems within the

 * SoC.  Export this as a reset controller.

/*

 * This deals with the "old" Marvell sequence of bringing a power domain

 * down/up, which is: apply power, release reset, disable isolators.

 *

 * Later devices apparantly use a different sequence: power up, disable

 * isolators, assert repair signal, enable SRMA clock, enable AXI clock,

 * enable module clock, deassert reset.

 *

 * Note: reading the assembly, it seems that the IO accessors have an

 * unfortunate side-effect - they cause memory already read into registers

 * for the if () to be re-read for the bit-set or bit-clear operation.

 * The code is written to avoid this.

 Enable isolators */

 Reset unit */

 Power down */

 Power on */

 Release reset */

 Disable isolators */

 PMU IRQ controller */

	/*

	 * The PMU mask register is not RW0C: it is RW.  This means that

	 * the bits take whatever value is written to them; if you write

	 * a '1', you will set the interrupt.

	 *

	 * Unfortunately this means there is NO race free way to clear

	 * these interrupts.

	 *

	 * So, let's structure the code so that the window is as small as

	 * possible.

 mask and clear all interrupts */

/*

 * pmu: power-manager@d0000 {

 *	compatible = "marvell,dove-pmu";

 *	reg = <0xd0000 0x8000> <0xd8000 0x8000>;

 *	interrupts = <33>;

 *	interrupt-controller;

 *	#reset-cells = 1;

 *	vpu_domain: vpu-domain {

 *		#power-domain-cells = <0>;

 *		marvell,pmu_pwr_mask = <0x00000008>;

 *		marvell,pmu_iso_mask = <0x00000001>;

 *		resets = <&pmu 16>;

 *	};

 *	gpu_domain: gpu-domain {

 *		#power-domain-cells = <0>;

 *		marvell,pmu_pwr_mask = <0x00000004>;

 *		marvell,pmu_iso_mask = <0x00000002>;

 *		resets = <&pmu 18>;

 *	};

 * };

 Lookup the PMU node */

		/*

		 * We parse the reset controller property directly here

		 * to ensure that we can operate when the reset controller

		 * support is not configured into the kernel.

 Loss of the interrupt controller is not a fatal error. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Linaro Ltd.

 *

 * Author: Linus Walleij <linus.walleij@linaro.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Linaro Ltd.

 *

 * Author: Linus Walleij <linus.walleij@linaro.org>

 System ID in syscon */

 FIXME: add attributes for SoC to sysfs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2010

 *

 * Author: Rabin Vincent <rabin.vincent@stericsson.com> for ST-Ericsson

/**

 * struct dbx500_asic_id - fields of the ASIC ID

 * @process: the manufacturing process, 0x40 is 40 nm 0x00 is "standard"

 * @partnumber: hithereto 0x8500 for DB8500

 * @revision: version code in the series

/*

 * SOC		MIDR		ASICID ADDRESS		ASICID VALUE

 * DB8500ed	0x410fc090	0x9001FFF4		0x00850001

 * DB8500v1	0x411fc091	0x9001FFF4		0x008500A0

 * DB8500v1.1	0x411fc091	0x9001FFF4		0x008500A1

 * DB8500v2	0x412fc091	0x9001DBF4		0x008500B0

 * DB8520v2.2	0x412fc091	0x9001DBF4		0x008500B2

 * DB5500v1	0x412fc091	0x9001FFF4		0x005500A0

 * DB9540	0x413fc090	0xFFFFDBF4		0x009540xx

 DB8500ed */

 DB8500v1 */

 DB8520 / DB8500v2 / DB5500v1 */

 DB8500v2 */

 DB5500v1 */

 DB9540 */

 Throw these device-specific numbers into the entropy pool */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Voltage regulators coupler for NVIDIA Tegra30

 * Copyright (C) 2019 GRATE-DRIVER project

 *

 * Voltage constraints borrowed from downstream kernel sources

 * Copyright (C) 2010-2011 NVIDIA Corporation

	/*

	 * Tegra30 SoC has critical DVFS-capable devices that are

	 * permanently-active or active at a boot time, like EMC

	 * (DRAM controller) or Display controller for example.

	 *

	 * The voltage of a CORE SoC power domain shall not be dropped below

	 * a minimum level, which is determined by device's clock rate.

	 * This means that we can't fully allow CORE voltage scaling until

	 * the state of all DVFS-critical CORE devices is synced.

	/*

	 * Limit minimum CORE voltage to a value left from bootloader or,

	 * if it's unreasonably low value, to the most common 1.2v or to

	 * whatever maximum value defined via board's device-tree.

	/*

	 * CPU voltage should not got lower than 300mV from the CORE.

	 * CPU voltage should stay below the CORE by 100mV+, depending

	 * by the CORE voltage. This applies to all Tegra30 SoC's.

	/*

	 * The CORE voltage scaling is currently not hooked up in drivers,

	 * hence we will limit the minimum CORE voltage to a reasonable value.

	 * This should be good enough for the time being.

 store boot voltage level */

	/*

	 * CPU's regulator may not have any consumers, hence the voltage

	 * must not be changed in that case because CPU simply won't

	 * survive the voltage drop if it's running on a higher frequency.

	/*

	 * Bootloader shall set up voltages correctly, but if it

	 * happens that there is a violation, then try to fix it

	 * at first.

 restore boot voltage level */

	/*

	 * Some devices use CPU soft-reboot method and in this case we

	 * should ensure that voltages are sane for the reboot by restoring

	 * the minimum boot levels.

	/*

	 * We don't expect regulators to be decoupled during reboot,

	 * this may race with the reboot handler and shouldn't ever

	 * happen in practice.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/soc/tegra/flowctrl.c

 *

 * Functions and macros to control the flowcontroller

 *

 * Copyright (c) 2010-2012, NVIDIA Corporation. All rights reserved.

 ensure the update has reached the flow controller */

 clear wfe bitmap */

 clear wfi bitmap */

 pwr gating on wfe */

 clear wfe bitmap */

 clear wfi bitmap */

			/*

			 * The wfi doesn't work well on Tegra30 because

			 * CPU hangs under some odd circumstances after

			 * power-gating (like memory running off PLLP),

			 * hence use wfe that is working perfectly fine.

			 * Note that Tegra30 TRM doc clearly stands that

			 * wfi should be used for the "Cluster Switching",

			 * while wfe for the power-gating, just like it

			 * is done on Tegra20.

 pwr gating on wfi */

 clear intr flag */

 clear event flag */

 pwr gating */

 Disable powergating via flow controller for CPU0 */

 clear wfe bitmap */

 clear wfi bitmap */

 clear wfe bitmap */

 clear wfi bitmap */

 clear enable */

 clear intr */

 clear event */

		/*

		 * Hardcoded fallback for 32-bit Tegra

		 * devices if device tree node is missing.

		/*

		 * At this point we're running on a Tegra,

		 * that doesn't support the flow controller

		 * (eg. Tegra186), so just return.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Voltage regulators coupler for NVIDIA Tegra20

 * Copyright (C) 2019 GRATE-DRIVER project

 *

 * Voltage constraints borrowed from downstream kernel sources

 * Copyright (C) 2010-2011 NVIDIA Corporation

	/*

	 * Tegra20 SoC has critical DVFS-capable devices that are

	 * permanently-active or active at a boot time, like EMC

	 * (DRAM controller) or Display controller for example.

	 *

	 * The voltage of a CORE SoC power domain shall not be dropped below

	 * a minimum level, which is determined by device's clock rate.

	 * This means that we can't fully allow CORE voltage scaling until

	 * the state of all DVFS-critical CORE devices is synced.

	/*

	 * Limit minimum CORE voltage to a value left from bootloader or,

	 * if it's unreasonably low value, to the most common 1.2v or to

	 * whatever maximum value defined via board's device-tree.

	/*

	 * RTC and CORE voltages should be no more than 170mV from each other,

	 * CPU should be below RTC and CORE by at least 120mV. This applies

	 * to all Tegra20 SoC's.

	/*

	 * The core voltage scaling is currently not hooked up in drivers,

	 * hence we will limit the minimum core voltage to a reasonable value.

	 * This should be good enough for the time being.

 store boot voltage level */

	/*

	 * CPU's regulator may not have any consumers, hence the voltage

	 * must not be changed in that case because CPU simply won't

	 * survive the voltage drop if it's running on a higher frequency.

 restore boot voltage level */

	/*

	 * Some devices use CPU soft-reboot method and in this case we

	 * should ensure that voltages are sane for the reboot by restoring

	 * the minimum boot levels.

	/*

	 * We don't expect regulators to be decoupled during reboot,

	 * this may race with the reboot handler and shouldn't ever

	 * happen in practice.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2021, NVIDIA CORPORATION.  All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * drivers/soc/tegra/pmc.c

 *

 * Copyright (c) 2010 Google, Inc

 * Copyright (c) 2018-2020, NVIDIA CORPORATION. All rights reserved.

 *

 * Author:

 *	Colin Cross <ccross@google.com>

 inverts INTR polarity */

 CPU pwr req enable */

 CPU pwr req polarity */

 LP0 when CPU pwr gated */

 system clock enable */

 sys clk polarity */

 Tegra186 and later */

 for secure PMC */

	/*

	 * These describe events that can wake the system from sleep (i.e.

	 * LP0 or SC7). Wakeup from other sleep states (such as LP1 or LP2)

	 * are dealt with in the LIC.

/**

 * struct tegra_pmc - NVIDIA Tegra PMC

 * @dev: pointer to PMC device structure

 * @base: pointer to I/O remapped register region

 * @wake: pointer to I/O remapped region for WAKE registers

 * @aotag: pointer to I/O remapped region for AOTAG registers

 * @scratch: pointer to I/O remapped region for scratch registers

 * @clk: pointer to pclk clock

 * @soc: pointer to SoC data structure

 * @tz_only: flag specifying if the PMC can only be accessed via TrustZone

 * @debugfs: pointer to debugfs entry

 * @rate: currently configured rate of pclk

 * @suspend_mode: lowest suspend mode available

 * @cpu_good_time: CPU power good time (in microseconds)

 * @cpu_off_time: CPU power off time (in microsecends)

 * @core_osc_time: core power good OSC time (in microseconds)

 * @core_pmu_time: core power good PMU time (in microseconds)

 * @core_off_time: core power off time (in microseconds)

 * @corereq_high: core power request is active-high

 * @sysclkreq_high: system clock request is active-high

 * @combined_req: combined power request for CPU & core

 * @cpu_pwr_good_en: CPU power good signal is enabled

 * @lp0_vec_phys: physical base address of the LP0 warm boot code

 * @lp0_vec_size: size of the LP0 warm boot code

 * @powergates_available: Bitmap of available power gates

 * @powergates_lock: mutex for power gate register access

 * @pctl_dev: pin controller exposed by the PMC

 * @domain: IRQ domain provided by the PMC

 * @irq: chip implementation for the IRQ domain

 * @clk_nb: pclk clock changes handler

/*

 * TODO Figure out a way to call this with the struct tegra_pmc * passed in.

 * This currently doesn't work because readx_poll_timeout() can only operate

 * on functions that take a single argument.

	/*

	 * As per TRM documentation, the toggle command will be dropped by PMC

	 * if there is contention with a HW-initiated toggling (i.e. CPU core

	 * power-gated), the command should be retried in that case.

 wait for PMC to execute the command */

 wait while PMC power gating is contended */

 wait for PMC to accept the command */

 wait for PMC to execute the command */

/**

 * tegra_powergate_set() - set the state of a partition

 * @pmc: power management controller

 * @id: partition ID

 * @new_state: new state of the partition

	/*

	 * On Tegra124 and later, the clamps for the GPU are controlled by a

	 * separate register (with different semantics).

	/*

	 * Tegra 2 has a bug where PCIE and VDE clamping masks are

	 * swapped relatively to the partition ids

		/*

		 * We don't know whether voltage state is okay for the

		 * current clock rate, hence it's better to temporally

		 * switch clock to a safe rate which is suitable for

		 * all voltages, before enabling the clock.

/**

 * tegra_powergate_power_on() - power on partition

 * @id: partition ID

/**

 * tegra_powergate_power_off() - power off partition

 * @id: partition ID

/**

 * tegra_powergate_is_powered() - check if partition is powered

 * @pmc: power management controller

 * @id: partition ID

/**

 * tegra_powergate_remove_clamping() - remove power clamps for partition

 * @id: partition ID

/**

 * tegra_powergate_sequence_power_up() - power up partition

 * @id: partition ID

 * @clk: clock for partition

 * @rst: reset for partition

 *

 * Must be called with clk disabled, and returns with clk enabled.

/**

 * tegra_get_cpu_powergate_id() - convert from CPU ID to partition ID

 * @pmc: power management controller

 * @cpuid: CPU partition ID

 *

 * Returns the partition ID corresponding to the CPU partition ID or a

 * negative error code on failure.

/**

 * tegra_pmc_cpu_is_powered() - check if CPU partition is powered

 * @cpuid: CPU partition ID

/**

 * tegra_pmc_cpu_power_on() - power on CPU partition

 * @cpuid: CPU partition ID

/**

 * tegra_pmc_cpu_remove_clamping() - remove power clamps for CPU partition

 * @cpuid: CPU partition ID

 reset everything but PMC_SCRATCH0 and PMC_RST_STATUS */

	/*

	 * Clear the bit for this powergate so it cannot be managed

	 * directly via the legacy APIs for controlling powergates.

	/*

	 * Core power domain is the parent of powergate domains, hence it

	 * should be registered first.

 must be at least 200 ns, in APB (PCLK) clock cycles */

/**

 * tegra_io_pad_power_enable() - enable power to I/O pad

 * @id: Tegra I/O pad ID for which to enable power

 *

 * Returns: 0 on success or a negative error code on failure.

/**

 * tegra_io_pad_power_disable() - disable power to I/O pad

 * @id: Tegra I/O pad ID for which to disable power

 *

 * Returns: 0 on success or a negative error code on failure.

 write-enable PMC_PWR_DET_VALUE[pad->voltage] */

 update I/O voltage */

/**

 * tegra_io_rail_power_on() - enable power to I/O rail

 * @id: Tegra I/O pad ID for which to enable power

 *

 * See also: tegra_io_pad_power_enable()

/**

 * tegra_io_rail_power_off() - disable power to I/O rail

 * @id: Tegra I/O pad ID for which to disable power

 *

 * See also: tegra_io_pad_power_disable()

	/*

	 * Calculate checksum of SCRATCH54, SCRATCH55 fields. Bits 23:16 will

	 * contain the checksum and are currently zero, so they are not added.

 GPIO hierarchies stop at the PMC level */

 If there is no wake-up event, there is no PMC mapping */

 clear wake status */

 enable PMC wake */

 clear wake status */

 route wake to tier 2 */

 enable wakeup event */

 pmc clk propagation delay 2 us */

	/*

	 * Early initialisation should have configured an initial

	 * register mapping and setup the soc data pointer. If these

	 * are not valid then something went badly wrong!

 take over the memory region from the early initialization */

	/*

	 * PCLK clock rate can't be retrieved using CLK API because it

	 * causes lockup if CPU enters LP2 idle state from some other

	 * CLK notifier, hence we're caching the rate's value locally.

 Always enable CPU power request */

 configure the output polarity while the request is tristated */

 now enable the request */

 program core timings which are applicable only for suspend state */

 .id                          .dpd  .voltage  .name */      \

   .id                        .dpd     .voltage  .name */        \

   .id                        .dpd      .voltage  .name */         \

   .id                          .dpd      .voltage  .name */           \

	/*

	 * Newer device-trees have power domains, but we need to prepare all

	 * device drivers with runtime PM and OPP support first, otherwise

	 * state syncing is unsafe.

	/*

	 * Older device-trees don't have core PD, and thus, there are

	 * no dependencies that will block the state syncing. We shouldn't

	 * mark the domain as synced in this case.

 this is a no-op if core regulator isn't used */

 write pattern and read it back */

 if we read all-zeroes, access is restricted to TZ only */

 restore original value */

/*

 * Early initialization to allow access to registers in the very early boot

 * process.

		/*

		 * Fall back to legacy initialization for 32-bit ARM only. All

		 * 64-bit ARM device tree files for Tegra are required to have

		 * a PMC node.

		 *

		 * This is for backwards-compatibility with old device trees

		 * that didn't contain a PMC node. Note that in this case the

		 * SoC data can't be matched and therefore powergating is

		 * disabled.

			/*

			 * At this point we're not running on Tegra, so play

			 * nice with multi-platform kernels.

		/*

		 * Extract information from the device tree if we've found a

		 * matching node.

 Create a bitmap of the available and valid partitions */

		/*

		 * Invert the interrupt polarity if a PMC device tree node

		 * exists and contains the nvidia,invert-interrupt property.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 NVIDIA CORPORATION.  All rights reserved.

 first dummy rate-setting initializes voltage vote */

/**

 * devm_tegra_core_dev_init_opp_table() - initialize OPP table

 * @dev: device for which OPP table is initialized

 * @params: pointer to the OPP table configuration

 *

 * This function will initialize OPP table and sync OPP state of a Tegra SoC

 * core device.

 *

 * Return: 0 on success or errorno.

 Tegra114+ doesn't support OPP yet */

	/*

	 * Older device-trees have an empty OPP table, we will get

	 * -ENODEV from devm_pm_opp_of_add_table() in this case.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2016-2017, NVIDIA CORPORATION. All rights reserved

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2014, NVIDIA CORPORATION.  All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2014, NVIDIA CORPORATION.  All rights reserved.

 *

 * Based on drivers/misc/eeprom/sunxi_sid.c

 Early boot code. This code is called before the devices are created */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012-2014, NVIDIA CORPORATION.  All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2014, NVIDIA CORPORATION.  All rights reserved.

 sentinel */ }

 take over the memory region from the early initialization */

 release the early I/O memory mapping */

	/*

	 * Critical for RAM re-repair operation, which must occur on resume

	 * from LP1 system suspend and as part of CCPLEX cluster switching.

	/*

	 * Enable FUSE clock. This needs to be hardcoded because the clock

	 * subsystem is not active during early boot.

	/*

	 * Displays the value in the 'pre_si_platform' field of the HIDREV

	 * register for Tegra194 devices. A value of 0 indicates that the

	 * platform type is silicon and all other non-zero values indicate

	 * the type of simulation platform is being used.

		/*

		 * Fall back to legacy initialization for 32-bit ARM only. All

		 * 64-bit ARM device tree files for Tegra are required to have

		 * a FUSE node.

		 *

		 * This is for backwards-compatibility with old device trees

		 * that didn't contain a FUSE node.

			/*

			 * At this point we're not running on Tegra, so play

			 * nice with multi-platform kernels.

		/*

		 * Extract information from the device tree if we've found a

		 * matching node.

 make sure we're running on Tegra */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2014, NVIDIA CORPORATION.  All rights reserved.

 Assign to default */

 Eng sku */

 Using the default */

 Using the default for the error case */

 GPU Speedo is stored in CPU_SPEEDO_2 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014, NVIDIA CORPORATION.  All rights reserved.

	/*

	 * Chips prior to Tegra194 have a different way of determining whether

	 * they are silicon or not. Since we never supported simulation on the

	 * older Tegra chips, don't bother extracting the information and just

	 * report that we're running on silicon.

		/*

		 * Fall back to legacy initialization for 32-bit ARM only. All

		 * 64-bit ARM device tree files for Tegra are required to have

		 * an APBMISC node.

		 *

		 * This is for backwards-compatibility with old device trees

		 * that didn't contain an APBMISC node.

 APBMISC registers (chip revision, ...) */

 strapping options */

			/*

			 * At this point we're not running on Tegra, so play

			 * nice with multi-platform kernels.

		/*

		 * Extract information from the device tree if we've found a

		 * matching node.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2015, NVIDIA CORPORATION.  All rights reserved.

 Assign to default */

 Engineering SKU */

 Engineering SKU */

 Using the default for the error case */

 Read speedo/IDDQ fuses */

	/*

	 * Determine CPU, GPU and SoC speedo values depending on speedo fusing

	 * revision. Note that GPU speedo value is fused in CPU_SPEEDO_2.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2014, NVIDIA CORPORATION.  All rights reserved.

 Tegra30 and later */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2012-2014, NVIDIA CORPORATION.  All rights reserved.

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP SmartReflex Voltage Control

 *

 * Author: Thara Gopinath	<thara@ti.com>

 *

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Thara Gopinath <thara@ti.com>

 *

 * Copyright (C) 2008 Nokia Corporation

 * Kalle Jokiniemi

 *

 * Copyright (C) 2007 Texas Instruments, Inc.

 * Lesly A M <x0080970@ti.com>

 sr_list contains all the instances of smartreflex module */

	/*

	 * Smartreflex error config register is special as it contains

	 * certain status bits which if written a 1 into means a clear

	 * of those bits. So in order to make sure no accidental write of

	 * 1 happens to those status bits, do a clear of them in the read

	 * value. This mean this API doesn't rewrite values in these bits

	 * if they are currently set, but does allow the caller to write

	 * those bits.

 Read the status bits */

 Clear them by writing back */

 Read the status bits */

 Clear them by writing back */

 Try interconnect target module fck first if it already exists */

/*

 * This function handles the initializations which have to be done

 * only when both sr device and class driver regiter has

 * completed. This will be attempted to be called from both sr class

 * driver register and sr device intializtion API's. Only one call

 * will ultimately succeed.

 *

 * Currently this function registers interrupt handler for a particular SR

 * if smartreflex class driver is already registered and has

 * requested for interrupts and the SR interrupt line in present.

 Enable MCUDisableAcknowledge interrupt */

 SRCONFIG - disable SR */

 Disable all other SR interrupts and clear the status as needed */

	/*

	 * Wait for SR to be disabled.

	 * wait until ERRCONFIG.MCUDISACKINTST = 1. Typical latency is 1us.

 Disable MCUDisableAcknowledge interrupt & clear pending interrupt */

 Enable MCUDisableAcknowledge interrupt */

 SRCONFIG - disable SR */

	/*

	 * Disable all other SR interrupts and clear the status

	 * write to status register ONLY on need basis - only if status

	 * is set.

	/*

	 * Wait for SR to be disabled.

	 * wait until IRQSTATUS.MCUDISACKINTST = 1. Typical latency is 1us.

 Disable MCUDisableAcknowledge interrupt & clear pending interrupt */

 Public Functions */

/**

 * sr_configure_errgen() - Configures the SmartReflex to perform AVS using the

 *			 error generator module.

 * @sr:			SR module to be configured.

 *

 * This API is to be called from the smartreflex class driver to

 * configure the error generator module inside the smartreflex module.

 * SR settings if using the ERROR module inside Smartreflex.

 * SR CLASS 3 by default uses only the ERROR module where as

 * SR CLASS 2 can choose between ERROR module and MINMAXAVG

 * module. Returns 0 on success and error value in case of failure.

 Enabling the interrupts if the ERROR module is used */

/**

 * sr_disable_errgen() - Disables SmartReflex AVS module's errgen component

 * @sr:			SR module to be configured.

 *

 * This API is to be called from the smartreflex class driver to

 * disable the error generator module inside the smartreflex module.

 *

 * Returns 0 on success and error value in case of failure.

 Disable the Sensor and errorgen */

	/*

	 * Disable the interrupts of ERROR module

	 * NOTE: modify is a read, modify,write - an implicit OCP barrier

	 * which is required is present here - sequencing is critical

	 * at this point (after errgen is disabled, vpboundint disable)

/**

 * sr_configure_minmax() - Configures the SmartReflex to perform AVS using the

 *			 minmaxavg module.

 * @sr:			SR module to be configured.

 *

 * This API is to be called from the smartreflex class driver to

 * configure the minmaxavg module inside the smartreflex module.

 * SR settings if using the ERROR module inside Smartreflex.

 * SR CLASS 3 by default uses only the ERROR module where as

 * SR CLASS 2 can choose between ERROR module and MINMAXAVG

 * module. Returns 0 on success and error value in case of failure.

	/*

	 * Enabling the interrupts if MINMAXAVG module is used.

	 * TODO: check if all the interrupts are mandatory

/**

 * sr_enable() - Enables the smartreflex module.

 * @sr:		pointer to which the SR module to be configured belongs to.

 * @volt:	The voltage at which the Voltage domain associated with

 *		the smartreflex module is operating at.

 *		This is required only to program the correct Ntarget value.

 *

 * This API is to be called from the smartreflex class driver to

 * enable a smartreflex module. Returns 0 on success. Returns error

 * value if the voltage passed is wrong or if ntarget value is wrong.

 errminlimit is opp dependent and hence linked to voltage */

 Check if SR is already enabled. If yes do nothing */

 Configure SR */

 SRCONFIG - enable SR */

/**

 * sr_disable() - Disables the smartreflex module.

 * @sr:		pointer to which the SR module to be configured belongs to.

 *

 * This API is to be called from the smartreflex class driver to

 * disable a smartreflex module.

 Check if SR clocks are already disabled. If yes do nothing */

	/*

	 * Disable SR if only it is indeed enabled. Else just

	 * disable the clocks.

/**

 * sr_register_class() - API to register a smartreflex class parameters.

 * @class_data:	The structure containing various sr class specific data.

 *

 * This API is to be called by the smartreflex class driver to register itself

 * with the smartreflex driver during init. Returns 0 on success else the

 * error value.

	/*

	 * Call into late init to do initializations that require

	 * both sr driver and sr class driver to be initiallized.

/**

 * omap_sr_enable() -  API to enable SR clocks and to call into the

 *			registered smartreflex class enable API.

 * @voltdm:	VDD pointer to which the SR module to be configured belongs to.

 *

 * This API is to be called from the kernel in order to enable

 * a particular smartreflex module. This API will do the initial

 * configurations to turn on the smartreflex module and in turn call

 * into the registered smartreflex class enable API.

/**

 * omap_sr_disable() - API to disable SR without resetting the voltage

 *			processor voltage

 * @voltdm:	VDD pointer to which the SR module to be configured belongs to.

 *

 * This API is to be called from the kernel in order to disable

 * a particular smartreflex module. This API will in turn call

 * into the registered smartreflex class disable API. This API will tell

 * the smartreflex class disable not to reset the VP voltage after

 * disabling smartreflex.

/**

 * omap_sr_disable_reset_volt() - API to disable SR and reset the

 *				voltage processor voltage

 * @voltdm:	VDD pointer to which the SR module to be configured belongs to.

 *

 * This API is to be called from the kernel in order to disable

 * a particular smartreflex module. This API will in turn call

 * into the registered smartreflex class disable API. This API will tell

 * the smartreflex class disable to reset the VP voltage after

 * disabling smartreflex.

 PM Debug FS entries to enable and disable smartreflex. */

 Sanity check */

 control enable/disable only if there is a delta in value */

	/*

	 * Call into late init to do initializations that require

	 * both sr driver and sr class driver to be initiallized.

 SPDX-License-Identifier: GPL-2.0

/*

 * Texas Instruments' K3 Interrupt Aggregator MSI bus

 *

 * Copyright (C) 2018-2019 Texas Instruments Incorporated - http://www.ti.com/

 *	Lokesh Vutla <lokeshvutla@ti.com>

 Nothing to do */

 Nothing to do */

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP2+ PRM driver

 *

 * Copyright (C) 2019 Texas Instruments Incorporated - http://www.ti.com/

 *	Tero Kristo <t-kristo@ti.com>

 Mask of hardware supported modes */

 Optional low-power state change */

 Optional logic off mode */

 wait for the transition bit to get cleared */

 No need to check for holes in the mask for the lowest mode */

 wait for the transition bit to get cleared */

/*

 * Note that ti-sysc already manages the module clocks separately so

 * no need to manage those. Interconnect instances need clocks managed

 * for simple-pm-bus.

 Check if we have rstst */

 Check if hw reset line is asserted */

	/*

	 * Check reset status, high value means reset sequence has been

	 * completed successfully so we can return 0 here (reset deasserted)

 assert the reset control line */

 Nothing to do if the reset is already deasserted */

 Clear the reset status by writing 1 to the status bit */

 de-assert the reset control line */

 wait for the reset bit to clear */

 wait for the status to be set */

	/*

	 * Check if we have controllable resets. If either rstctrl is non-zero

	 * or OMAP_PRM_HAS_RSTCTRL flag is set, we have reset control register

	 * for the domain.

 Check if we have the pdata callbacks in place */

 Quirk handling to assert rst_map_012 bits on reset and avoid errors */

 SPDX-License-Identifier: GPL-2.0

/*

 * TI K3 SoC info driver

 *

 * Copyright (C) 2020 Texas Instruments Incorporated - http://www.ti.com

/*

 * Bits:

 *  31-28 VARIANT	Device variant

 *  27-12 PARTNO	Part number

 *  11-1  MFG		Indicates TI as manufacturer (0x17)

 *  1			Always 1

 sentinel */ },

/*

 * Copyright (C) 2014 Texas Instruments Incorporated

 * Authors:	Santosh Shilimkar <santosh.shilimkar@ti.com>

 *		Sandeep Nair <sandeep_n@ti.com>

 *		Cyril Chemparathy <cyril@ti.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 cycles */

/*

 * QMGR & QNUM together make up 14 bits with QMGR as the 2 MSb's in the logical

 * navigator cloud mapping scheme.

 * using the 14bit physical queue numbers directly maps into this scheme.

 msecs */

 registers */

 configuration stuff */

 Keep a copy of the cfg */

 indicate teardown */

 wait for the dma to shut itself down */

 first detach fdqs, starve out the flow */

 teardown the dma channel */

 then disconnect the completion side */

 Always enable all Rx channels. Rx paths are managed using flows */

/**

 * knav_dma_open_channel() - try to setup an exclusive slave channel

 * @dev:	pointer to client device structure

 * @name:	slave channel name

 * @config:	dma configuration parameters

 *

 * Returns pointer to appropriate DMA channel on success or error.

 Look for correct dma instance */

 Look for correct dma channel from dma instance */

/**

 * knav_dma_close_channel()	- Destroy a dma channel

 *

 * @channel:	dma channel handle

 *

	/*

	 * For DSP software usecases or userpace transport software, setup all

	 * the DMA hardware resources.

 Initialise all packet dmas */

 SPDX-License-Identifier: GPL-2.0

/*

 * AM33XX Power Management Routines

 *

 * Copyright (C) 2012-2018 Texas Instruments Incorporated - http://www.ti.com/

 *	Vaibhav Bedia, Dave Gerlach

 RTC */

 Save physical address to calculate resume offset during pm init */

/*

 * Note that the RTC module clock must be re-enabled only for rtc+ddr suspend.

 * And looks like the module can stay in SYSC_IDLE_SMART_WKUP mode configured

 * by the interconnect code just fine for both rtc+ddr suspend and retention

 * suspend.

 print the wakeup reason */

			/*

			 * 32 bits of Interrupt Set-Pending correspond to 32

			 * 32 interrupts. Compute the bit offset of the

			 * Interrupt and set that particular bit

			 * Compute the register offset by dividing interrupt

			 * number by 32 and mutiplying by 4

 CONFIG_SUSPEND */

 Physical resume address to be used by ROM code */

/*

 * Push the minimal suspend-resume code to SRAM

 RTC interconnect target module clock */

	/*

	 * For a system suspend we must flush the caches, we want

	 * the DDR in self-refresh, we want to save the context

	 * of the EMIF, and we want the wkup_m3 to handle low-power

	 * transition.

 CONFIG_SUSPEND */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Keystone Queue Manager subsystem driver

 *

 * Copyright (C) 2014 Texas Instruments Incorporated - http://www.ti.com

 * Authors:	Sandeep Nair <sandeep_n@ti.com>

 *		Cyril Chemparathy <cyril@ti.com>

 *		Santosh Shilimkar <santosh.shilimkar@ti.com>

 Queue manager register indices in DTS */

/* Queue manager register indices in DTS for QMSS in K2G NAVSS.

 * There are no status and vbusm push registers on this version

 * of QMSS. Push registers are same as pop, So all indices above 1

 * are to be re-defined

 PDSP register indices in DTS */

/* All firmware file names end up here. List the firmware file names below.

 * Newest followed by older ones. Search is done from start of the array

 * until a firmware file is found.

/**

 * knav_queue_notify: qmss queue notfier call

 *

 * @inst:		- qmss queue instance like accumulator

 first opener? */

 Adjust the per handle notifier count */

 nothing to do */

 Now adjust the per instance notifier count */

 nothing to do */

/**

 * knav_queue_open()	- open a hardware queue

 * @name:		- name to give the queue handle

 * @id:			- desired queue number if any or specifes the type

 *			  of queue

 * @flags:		- the following flags are applicable to queues:

 *	KNAV_QUEUE_SHARED - allow the queue to be shared. Queues are

 *			     exclusive by default.

 *			     Subsequent attempts to open a shared queue should

 *			     also have this flag.

 *

 * Returns a handle to the open hardware queue if successful. Use IS_ERR()

 * to check the returned value for error codes.

/**

 * knav_queue_close()	- close a hardware queue handle

 * @qhandle:		- handle to close

/**

 * knav_queue_device_control()	- Perform control operations on a queue

 * @qhandle:			- queue handle

 * @cmd:			- control commands

 * @arg:			- command argument

 *

 * Returns 0 on success, errno otherwise.

/**

 * knav_queue_push()	- push data (or descriptor) to the tail of a queue

 * @qhandle:		- hardware queue handle

 * @dma:		- DMA data to push

 * @size:		- size of data to push

 * @flags:		- can be used to pass additional information

 *

 * Returns 0 on success, errno otherwise.

/**

 * knav_queue_pop()	- pop data (or descriptor) from the head of a queue

 * @qhandle:		- hardware queue handle

 * @size:		- (optional) size of the data pop'ed.

 *

 * Returns a DMA address on success, 0 on failure.

 are we accumulated? */

 carve out descriptors and push into queue */

 pop out descriptors and close the queue */

 Get the DMA address of a descriptor */

/**

 * knav_pool_create()	- Create a pool of descriptors

 * @name:		- name to give the pool handle

 * @num_desc:		- numbers of descriptors in the pool

 * @region_id:		- QMSS region id from which the descriptors are to be

 *			  allocated.

 *

 * Returns a pool handle on success.

 * Use IS_ERR_OR_NULL() to identify error values on return.

	/* Region maintains a sorted (by region offset) list of pools

	 * use the first free slot which is large enough to accomodate

	 * the request

/**

 * knav_pool_destroy()	- Free a pool of descriptors

 * @ph:		- pool handle

/**

 * knav_pool_desc_get()	- Get a descriptor from the pool

 * @ph:		- pool handle

 *

 * Returns descriptor from the pool.

/**

 * knav_pool_desc_put()	- return a descriptor to the pool

 * @ph:		- pool handle

 * @desc:	- virtual address

/**

 * knav_pool_desc_map()	- Map descriptor for DMA transfer

 * @ph:				- pool handle

 * @desc:			- address of descriptor to map

 * @size:			- size of descriptor to map

 * @dma:			- DMA address return pointer

 * @dma_sz:			- adjusted return pointer

 *

 * Returns 0 on success, errno otherwise.

 Ensure the descriptor reaches to the memory */

/**

 * knav_pool_desc_unmap()	- Unmap descriptor after DMA transfer

 * @ph:				- pool handle

 * @dma:			- DMA address of descriptor to unmap

 * @dma_sz:			- size of descriptor to unmap

 *

 * Returns descriptor address on success, Use IS_ERR_OR_NULL() to identify

 * error values on return.

/**

 * knav_pool_count()	- Get the number of descriptors in pool.

 * @ph:			- pool handle

 * Returns number of elements in the pool.

 unused region? */

 get hardware descriptor value */

 did we force fit ourselves into nothingness? */

 Next, we run through the regions and set things up */

	/*

	 * Note: link ram resources are specified in "entry" sized units. In

	 * reality, although entries are ~40bits in hardware, we treat them as

	 * 64-bit entities here.

	 *

	 * For example, to specify the internal link ram for Keystone-I class

	 * devices, we would set the linkram0 resource to 0x80000-0x83fff.

	 *

	 * This gets a bit weird when other link rams are used.  For example,

	 * if the range specified is 0x0c000000-0x0c003fff (i.e., 16K entries

	 * in MSMC SRAM), the actual memory used is 0x0c000000-0x0c020000,

	 * which accounts for 64-bits per entry, for 16K entries.

			/*

			 * queue_base specified => using internal or onchip

			 * link ram WARNING - we do not "reserve" this block

 queue_base not specific => allocate requested size */

 set threshold to 1, and flush out the queues */

 return value ignored, we init the rest... */

 ... and barf if they all failed! */

 Use same push register for pop as well */

 download the firmware */

 write a command for sync */

 soft reset the PDSP */

 enable pdsp */

 wait for command register to clear */

 disable all pdsps */

	/* now load them all. We return success even if pdsp

	 * is not loaded as acc channels are optional on having

	 * firmware availability in the system. We set the loaded

	 * and stated flag and when initialize the acc range, check

	 * it and init the range only if pdsp is started.

 how much do we need for instance data? */

	/* round this up to a power of 2, keep the index to instance

	 * arithmetic fast.

 Match table for of_platform binding */

 Initialize queue managers using device tree configuration */

 get pdsp configuration values from device tree */

 get usable queue range values from device tree */

		/*

		 * nothing really, we have one linking ram already, so we just

		 * live within our means

 TODO: Free resources */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AMx3 Wkup M3 IPC driver

 *

 * Copyright (C) 2015 Texas Instruments, Inc.

 *

 * Dave Gerlach <d-gerlach@ti.com>

 AM33XX M3_TXEV_EOI register */

	/*

	 * Write a dummy message to the mailbox in order to trigger the RX

	 * interrupt to alert the M3 that data is available in the IPC

	 * registers. We must enable the IRQ here and disable it after in

	 * the RX callback to avoid multiple interrupts being received

	 * by the CM3.

 Public functions */

/**

 * wkup_m3_set_mem_type - Pass wkup_m3 which type of memory is in use

 * @m3_ipc: Pointer to wkup_m3_ipc context

 * @mem_type: memory type value read directly from emif

 *

 * wkup_m3 must know what memory type is in use to properly suspend

 * and resume.

/**

 * wkup_m3_set_resume_address - Pass wkup_m3 resume address

 * @m3_ipc: Pointer to wkup_m3_ipc context

 * @addr: Physical address from which resume code should execute

/**

 * wkup_m3_request_pm_status - Retrieve wkup_m3 status code after suspend

 * @m3_ipc: Pointer to wkup_m3_ipc context

 *

 * Returns code representing the status of a low power mode transition.

 *	0 - Successful transition

 *	1 - Failure to transition to low power state

/**

 * wkup_m3_prepare_low_power - Request preparation for transition to

 *			       low power state

 * @m3_ipc: Pointer to wkup_m3_ipc context

 * @state: A kernel suspend state to enter, either MEM or STANDBY

 *

 * Returns 0 if preparation was successful, otherwise returns error code

 Program each required IPC register then write defaults to others */

/**

 * wkup_m3_finish_low_power - Return m3 to reset state

 * @m3_ipc: Pointer to wkup_m3_ipc context

 *

 * Returns 0 if reset was successful, otherwise returns error code

/**

 * wkup_m3_request_wake_src - Get the wakeup source info passed from wkup_m3

 * @m3_ipc: Pointer to wkup_m3_ipc context

/**

 * wkup_m3_set_rtc_only - Set the rtc_only flag

 * @m3_ipc: Pointer to wkup_m3_ipc context

/**

 * wkup_m3_ipc_get - Return handle to wkup_m3_ipc

 *

 * Returns NULL if the wkup_m3 is not yet available, otherwise returns

 * pointer to wkup_m3_ipc struct.

/**

 * wkup_m3_ipc_put - Free handle to wkup_m3_ipc returned from wkup_m3_ipc_get

 * @m3_ipc: A pointer to wkup_m3_ipc struct returned by wkup_m3_ipc_get

	/*

	 * Wait for firmware loading completion in a thread so we

	 * can boot the wkup_m3 as soon as it's ready without holding

	 * up kernel boot

	/*

	 * Nothing needs to be done on suspend even with rtc_only flag set

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PRU-ICSS platform driver for various TI SoCs

 *

 * Copyright (C) 2014-2020 Texas Instruments Incorporated - http://www.ti.com/

 * Author(s):

 *	Suman Anna <s-anna@ti.com>

 *	Andrew F. Davis <afd@ti.com>

/**

 * struct pruss_private_data - PRUSS driver private data

 * @has_no_sharedram: flag to indicate the absence of PRUSS Shared Data RAM

 * @has_core_mux_clock: flag to indicate the presence of PRUSS core clock

		/*

		 * On AM437x one of two PRUSS units don't contain Shared RAM,

		 * skip it

 instance-specific driver private data */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TI SCI Generic Power Domain Driver

 *

 * Copyright (C) 2015-2017 Texas Instruments Incorporated - http://www.ti.com/

 *	J Keerthy <j-keerthy@ti.com>

 *	Dave Gerlach <d-gerlach@ti.com>

/**

 * struct ti_sci_genpd_provider: holds common TI SCI genpd provider data

 * @ti_sci: handle to TI SCI protocol driver that provides ops to

 *	    communicate with system control processor.

 * @dev: pointer to dev for the driver for devm allocs

 * @pd_list: list of all the power domains on the device

 * @data: onecell data for genpd core

/**

 * struct ti_sci_pm_domain: TI specific data needed for power domain

 * @idx: index of the device that identifies it with the system

 *	 control processor.

 * @exclusive: Permissions for exclusive request or shared request of the

 *	       device.

 * @pd: generic_pm_domain for use with the genpd framework

 * @node: link for the genpd list

 * @parent: link to the parent TI SCI genpd provider

/*

 * ti_sci_pd_power_off(): genpd power down hook

 * @domain: pointer to the powerdomain to power off

/*

 * ti_sci_pd_power_on(): genpd power up hook

 * @domain: pointer to the powerdomain to power on

/*

 * ti_sci_pd_xlate(): translation service for TI SCI genpds

 * @genpdspec: DT identification data for the genpd

 * @data: genpd core data for all the powerdomains on the device

 Find highest device ID used for power domains */

 SPDX-License-Identifier: GPL-2.0

/*

 * TI K3 NAVSS Ring Accelerator subsystem driver

 *

 * Copyright (C) 2019 Texas Instruments Incorporated - http://www.ti.com

/**

 * struct k3_ring_rt_regs - The RA realtime Control/Status Registers region

 *

 * @resv_16: Reserved

 * @db: Ring Doorbell Register

 * @resv_4: Reserved

 * @occ: Ring Occupancy Register

 * @indx: Ring Current Index Register

 * @hwocc: Ring Hardware Occupancy Register

 * @hwindx: Ring Hardware Current Index Register

/**

 * struct k3_ring_fifo_regs - The Ring Accelerator Queues Registers region

 *

 * @head_data: Ring Head Entry Data Registers

 * @tail_data: Ring Tail Entry Data Registers

 * @peek_head_data: Ring Peek Head Entry Data Regs

 * @peek_tail_data: Ring Peek Tail Entry Data Regs

/**

 * struct k3_ringacc_proxy_gcfg_regs - RA Proxy Global Config MMIO Region

 *

 * @revision: Revision Register

 * @config: Config Register

/**

 * struct k3_ringacc_proxy_target_regs - Proxy Datapath MMIO Region

 *

 * @control: Proxy Control Register

 * @status: Proxy Status Register

 * @resv_512: Reserved

 * @data: Proxy Data Register

/**

 * struct k3_ring_state - Internal state tracking structure

 *

 * @free: Number of free entries

 * @occ: Occupancy

 * @windex: Write index

 * @rindex: Read index

/**

 * struct k3_ring - RA Ring descriptor

 *

 * @rt: Ring control/status registers

 * @fifos: Ring queues registers

 * @proxy: Ring Proxy Datapath registers

 * @ring_mem_dma: Ring buffer dma address

 * @ring_mem_virt: Ring buffer virt address

 * @ops: Ring operations

 * @size: Ring size in elements

 * @elm_size: Size of the ring element

 * @mode: Ring mode

 * @flags: flags

 * @state: Ring state

 * @ring_id: Ring Id

 * @parent: Pointer on struct @k3_ringacc

 * @use_count: Use count for shared rings

 * @proxy_id: RA Ring Proxy Id (only if @K3_RINGACC_RING_USE_PROXY)

 * @dma_dev: device to be used for DMA API (allocation, mapping)

 * @asel: Address Space Select value for physical addresses

/**

 * struct k3_ringacc - Rings accelerator descriptor

 *

 * @dev: pointer on RA device

 * @proxy_gcfg: RA proxy global config registers

 * @proxy_target_base: RA proxy datapath region

 * @num_rings: number of ring in RA

 * @rings_inuse: bitfield for ring usage tracking

 * @rm_gp_range: general purpose rings range from tisci

 * @dma_ring_reset_quirk: DMA reset w/a enable

 * @num_proxies: number of RA proxies

 * @proxy_inuse: bitfield for proxy usage tracking

 * @rings: array of rings descriptors (struct @k3_ring)

 * @list: list of RAs in the system

 * @req_lock: protect rings allocation

 * @tisci: pointer ti-sci handle

 * @tisci_ring_ops: ti-sci rings ops

 * @tisci_dev_id: ti-sci device id

 * @ops: SoC specific ringacc operation

 * @dma_rings: indicate DMA ring (dual ring within BCDMA/PKTDMA)

 number of rings in Ringacc module */

 protect rings allocation */

/**

 * struct k3_ringacc - Rings accelerator SoC data

 *

 * @dma_ring_reset_quirk:  DMA reset w/a enable

 Reverse side of the DMA ring can only be popped by SW */

 Request for any general purpose ring */

	/*

	 * DMA rings must be requested by ID, completion ring is the reverse

	 * side of the forward ring

 TI-SCI ring reset */

		/*

		 * Setup the ring in ring/doorbell mode (if not already in this

		 * mode)

		/*

		 * Ring the doorbell 2**22 – ringOcc times.

		 * This will wrap the internal UDMAP ring state occupancy

		 * counter (which is 21-bits wide) to 0.

			/*

			 * Ring the doorbell with the maximum count each

			 * iteration if possible to minimize the total

			 * of writes

 Restore the original ring mode (if not ring mode) */

 Reset the ring */

	/*

	 * DMA rings: rings shared memory and configuration, only forward ring

	 * is configured and reverse ring considered as slave.

	/*

	 * DMA rings: rings shared memory and configuration, only forward ring

	 * is configured and reverse ring considered as slave.

 DMA rings: configure reverse ring */

	/*

	 * In case of shared ring only the first user (master user) can

	 * configure the ring. The sequence should be by the client:

	 * ring = k3_ringacc_request_ring(ringacc, ring_id, 0); # master user

	 * k3_ringacc_ring_cfg(ring, cfg); # master configuration

	 * k3_ringacc_request_ring(ringacc, ring_id, K3_RING_FLAG_SHARED);

	 * k3_ringacc_request_ring(ringacc, ring_id, K3_RING_FLAG_SHARED);

/*

 * The element is 48 bits of address + ASEL bits in the ring.

 * ASEL is used by the DMAs and should be removed for the kernel as it is not

 * part of the physical memory address.

	/*

	 * DMA rings: forward ring is always tied DMA channel and HW does not

	 * maintain any state data required for POP operation and its unknown

	 * how much elements were consumed by HW. So, to actually

	 * do POP, the read pointer has to be recalculated every time.

 sentinel */}

 Match table for of_platform binding */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Keystone accumulator queue manager

 *

 * Copyright (C) 2014 Texas Instruments Incorporated - http://www.ti.com

 * Author:	Sandeep Nair <sandeep_n@ti.com>

 *		Cyril Chemparathy <cyril@ti.com>

 *		Santosh Shilimkar <santosh.shilimkar@ti.com>

	/*

	 * when enabling, we need to re-trigger an interrupt if we

	 * have descriptors pending

 ack the interrupt */

 flip to the other list */

 reset the interrupt counter */

 ack the interrupt */

 wait for the command to clear */

/**

 * knav_init_acc_range: Initialise accumulator ranges

 *

 * @kdev:		qmss device

 * @node:		device node

 * @range:		qmms range information

 *

 * Return 0 on success or error

 figure out list size */

 allocate memory for the two lists */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2017 Impinj, Inc

 * Author: Andrey Smirnov <andrew.smirnov@gmail.com>

 *

 * Based on the code of analogus driver:

 *

 * Copyright 2015-2017 Pengutronix, Lucas Stach <kernel@pengutronix.de>

/*

 * The PGC offset values in Reference Manual

 * (Rev. 1, 01/2018 and the older ones) GPC chapter's

 * GPC_PGC memory map are incorrect, below offset

 * values are from design RTL.

 Enable reset clocks for all devices in the domain */

 request the domain to power up */

		/*

		 * As per "5.5.9.4 Example Code 4" in IMX7DRM.pdf wait

		 * for PUP_REQ/PDN_REQ bit to be cleared

 disable power control */

 delay for reset to propagate */

 request the ADB400 to power up */

		/*

		 * ret = regmap_read_poll_timeout(domain->regmap, GPC_PU_PWRHSK, reg_val,

		 *				  (reg_val & domain->bits.hskack), 0,

		 *				  USEC_PER_MSEC);

		 * Technically we need the commented code to wait handshake. But that needs

		 * the BLK-CTL module BUS clk-en bit being set.

		 *

		 * There is a separate BLK-CTL module and we will have such a driver for it,

		 * that driver will set the BUS clk-en bit and handshake will be triggered

		 * automatically there. Just add a delay and suppose the handshake finish

		 * after that.

 Disable reset clocks for all devices in the domain */

 Enable reset clocks for all devices in the domain */

 request the ADB400 to power down */

 enable power control */

 request the domain to power down */

		/*

		 * As per "5.5.9.4 Example Code 4" in IMX7DRM.pdf wait

		 * for PUP_REQ/PDN_REQ bit to be cleared

 Disable reset clocks for all devices in the domain */

 no power sequence control */

 no power sequence control */

 no power sequence control */

 no power sequence control */

	/*

	 * This may look strange, but is done so the generic PM_SLEEP code

	 * can power down our domain and more importantly power it up again

	 * after resume, without tripping over our usage of runtime PM to

	 * power up/down the nested domains.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2015-2017 Pengutronix, Lucas Stach <kernel@pengutronix.de>

 * Copyright 2011-2013 Freescale Semiconductor, Inc.

 Read ISO and ISO2SW power down delays */

 Gate off domain when powered down */

 Request GPC to power down domain */

 Wait ISO + ISO2SW IPG clock cycles */

 Enable reset clocks for all devices in the domain */

 Gate off domain when powered down */

 Request GPC to power up domain */

 Wait for the PGC to handle the request */

 Wait for reset to propagate through peripherals */

 Disable reset clocks for all devices in the domain */

 try to get the domain supply regulator */

 try to get all clocks needed for reset propagation */

 if this PD is associated with a DT node try to parse it */

 initially power on the domain */

 bail out if DT too old and doesn't provide the necessary info */

	/*

	 * Disable PU power down by runtime PM if ERR009619 is present.

	 *

	 * The PRE clock will be paused for several cycles when turning on the

	 * PU domain LDO from power down state. If PRE is in use at that time,

	 * the IPU/PRG cannot get the correct display data from the PRE.

	 *

	 * This is not a concern when the whole system enters suspend state, so

	 * it's safe to power down PU in this case.

 Keep DISP always on if ERR006287 is present */

 bail out if DT too old and doesn't provide the necessary info */

	/*

	 * If the old DT binding is used the toplevel driver needs to

	 * de-register the power domains

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright 2021 Pengutronix, Lucas Stach <kernel@pengutronix.de>

 make sure bus domain is awake */

 put devices into reset */

 enable upstream and blk-ctrl clocks to allow reset to propagate */

 power up upstream GPC domain */

 wait for reset to propagate */

 release reset */

 disable upstream clocks */

 put devices into reset and disable clocks */

 power down upstream GPC domain */

 allow bus domain to suspend */

		/*

		 * We use runtime PM to trigger power on/off of the upstream GPC

		 * domain, as a strict hierarchical parent/child power domain

		 * setup doesn't allow us to meet the sequencing requirements.

		 * This means we have nested locking of genpd locks, without the

		 * nesting being visible at the genpd level, so we need a

		 * separate lock class to make lockdep aware of the fact that

		 * this are separate domain locks that can be nested without a

		 * self-deadlock.

	/*

	 * This may look strange, but is done so the generic PM_SLEEP code

	 * can power down our domains and more importantly power them up again

	 * after resume, without tripping over our usage of runtime PM to

	 * control the upstream GPC domains. Things happen in the right order

	 * in the system suspend/resume paths due to the device parent/child

	 * hierarchy.

	/*

	 * The ADB in the VPUMIX domain has no separate reset and clock

	 * enable bits, but is ungated together with the VPU clocks. To

	 * allow the handshake with the GPC to progress we put the VPUs

	 * in reset and ungate the clocks.

		/*

		 * On power up we have no software backchannel to the GPC to

		 * wait for the ADB handshake to happen, so we just delay for a

		 * bit. On power down the GPC driver waits for the handshake.

 set "fuse" bits to enable the VPUs */

 Enable bus clock and deassert bus reset */

	/*

	 * On power up we have no software backchannel to the GPC to

	 * wait for the ADB handshake to happen, so we just delay for a

	 * bit. On power down the GPC driver waits for the handshake.

 Sentinel */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2020 NXP

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 NXP.

 Same as ANADIG_DIGPROG_IMX7D */

	/*

	 * SOC revision on older imx8mq is not available in fuses so query

	 * the value from ATF instead.

 SPDX-License-Identifier: GPL-2.0

/*

 * LiteX SoC Controller Driver

 *

 * Copyright (C) 2020 Antmicro <www.antmicro.com>

 *

 reset register located at the base address */

/*

 * Check LiteX CSR read/write access

 *

 * This function reads and writes a scratch register in order to verify if CSR

 * access works.

 *

 * In case any problems are detected, the driver should panic.

 *

 * Access to the LiteX CSR is, by design, done in CPU native endianness.

 * The driver should not dynamically configure access functions when

 * the endianness mismatch is detected. Such situation indicates problems in

 * the soft SoC design and should be solved at the LiteX generator level,

 * not in the software.

 restore original value of the SCRATCH register */

 CONFIG_OF */

 SPDX-License-Identifier: GPL-2.0

/*

 * SVC Greybus driver.

 *

 * Copyright 2015 Google Inc.

 * Copyright 2015 Linaro Ltd.

 FIXME

 This is a hack, we need to do this "right" and clean the interface up

 properly, not just forcibly yank the thing out of the system and hope for the

 best.  But for now, people want their modules to come out without having to

 throw the thing to the ground or get out a screwdriver.

	/*

	 * The pulse width for module release in svc is long so we need to

	 * increase the timeout so the operation will not return to soon.

 TC0 */

 Creates bi-directional routes between the devices */

 Destroys bi-directional routes between the devices */

	/*

	 * XXX This is a hack/work-around to reconfigure the APBridgeA-Switch

	 * link to PWM G2, 1 Lane, Slow Auto, so that it has sufficient

	 * bandwidth for 3 audio streams plus boot-over-UniPro of a hot-plugged

	 * module.

	 *

	 * The code should be removed once SW-2217, Heuristic for UniPro

	 * Power Mode Changes is resolved.

 The request message size has already been verified. */

 The request message size has already been verified. */

 The request message size has already been verified. */

 The request message size has already been verified. */

 FIXME Reset the interface here */

	/*

	 * SVC requests need to follow a specific order (at least initially) and

	 * below code takes care of enforcing that. The expected order is:

	 * - PROTOCOL_VERSION

	 * - SVC_HELLO

	 * - Any other request, but the earlier two.

	 *

	 * Incoming requests are guaranteed to be serialized and so we don't

	 * need to protect 'state' for any races.

	/*

	 * The SVC protocol is currently driven by the SVC, so the SVC device

	 * is added from the connection request handler when enough

	 * information has been received.

	/*

	 * The SVC device may have been registered from the request handler.

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus operations

 *

 * Copyright 2014-2015 Google Inc.

 * Copyright 2014-2015 Linaro Ltd.

 Workqueue to handle Greybus operation completions. */

 Wait queue for synchronous cancellations. */

/*

 * Protects updates to operation->errno.

/*

 * Increment operation active count and add to connection list unless the

 * connection is going away.

 *

 * Caller holds operation reference.

 Caller holds operation reference. */

/*

 * Set an operation's result.

 *

 * Initially an outgoing operation's errno value is -EBADR.

 * If no error occurs before sending the request message the only

 * valid value operation->errno can be set to is -EINPROGRESS,

 * indicating the request has been (or rather is about to be) sent.

 * At that point nobody should be looking at the result until the

 * response arrives.

 *

 * The first time the result gets set after the request has been

 * sent, that result "sticks."  That is, if two concurrent threads

 * race to set the result, the first one wins.  The return value

 * tells the caller whether its result was recorded; if not the

 * caller has nothing more to do.

 *

 * The result value -EILSEQ is reserved to signal an implementation

 * error; if it's ever observed, the code performing the request has

 * done something fundamentally wrong.  It is an error to try to set

 * the result to -EBADR, and attempts to do so result in a warning,

 * and -EILSEQ is used instead.  Similarly, the only valid result

 * value to set for an operation in initial state is -EINPROGRESS.

 * Attempts to do otherwise will also record a (successful) -EILSEQ

 * operation result.

		/*

		 * -EINPROGRESS is used to indicate the request is

		 * in flight.  It should be the first result value

		 * set after the initial -EBADR.  Issue a warning

		 * and record an implementation error if it's

		 * set at any other time.

	/*

	 * The first result value set after a request has been sent

	 * will be the final result of the operation.  Subsequent

	 * attempts to set the result are ignored.

	 *

	 * Note that -EBADR is a reserved "initial state" result

	 * value.  Attempts to set this value result in a warning,

	 * and the result code is set to -EILSEQ instead.

 Nobody should be setting -EBADR */

 First and final result */

/*

 * Looks up an outgoing operation on a connection and returns a refcounted

 * pointer if found, or NULL otherwise.

/*

 * Cancel a message we have passed to the host device layer to be sent.

/*

 * Process operation work.

 *

 * For incoming requests, call the protocol request handler. The operation

 * result should be -EINPROGRESS at this point.

 *

 * For outgoing requests, the operation result value should have

 * been set before queueing this.  The operation callback function

 * allows the original requester to know the request has completed

 * and its result is available.

 Cancel request message if scheduled by timeout. */

		/*

		 * A stuck request message will be cancelled from the

		 * workqueue.

	/*

	 * The type supplied for incoming message buffers will be

	 * GB_REQUEST_TYPE_INVALID. Such buffers will be overwritten by

	 * arriving data so there's no need to initialize the message header.

		/*

		 * For a request, the operation id gets filled in

		 * when the message is sent.  For a response, it

		 * will be copied from the request by the caller.

		 *

		 * The result field in a request message must be

		 * zero.  It will be set just prior to sending for

		 * a response.

/*

 * Allocate a message to be used for an operation request or response.

 * Both types of message contain a common header.  The request message

 * for an outgoing operation is outbound, as is the response message

 * for an incoming operation.  The message header for an outbound

 * message is partially initialized here.

 *

 * The headers for inbound messages don't need to be initialized;

 * they'll be filled in by arriving data.

 *

 * Our message buffers have the following layout:

 *	message header  \_ these combined are

 *	message payload /  the message size

 Allocate the message structure and buffer. */

 Initialize the message.  Operation id is filled in later. */

/*

 * Map an enum gb_operation_status value (which is represented in a

 * message as a single byte) to an appropriate Linux negative errno.

/*

 * Map a Linux errno value (from operation->errno) into the value

 * that should represent it in a response message status sent

 * over the wire.  Returns an enum gb_operation_status value (which

 * is represented in a message as a single byte).

 Could be underflow too */

	/*

	 * Size and type get initialized when the message is

	 * allocated.  The errno will be set before sending.  All

	 * that's left is the operation id, which we copy from the

	 * request message header (as-is, in little-endian order).

/*

 * Create a Greybus operation to be sent over the given connection.

 * The request buffer will be big enough for a payload of the given

 * size.

 *

 * For outgoing requests, the request message's header will be

 * initialized with the type of the request and the message size.

 * Outgoing operations must also specify the response buffer size,

 * which must be sufficient to hold all expected response data.  The

 * response message header will eventually be overwritten, so there's

 * no need to initialize it here.

 *

 * Request messages for incoming operations can arrive in interrupt

 * context, so they must be allocated with GFP_ATOMIC.  In this case

 * the request buffer will be immediately overwritten, so there is

 * no need to initialize the message header.  Responsibility for

 * allocating a response buffer lies with the incoming request

 * handler for a protocol.  So we don't allocate that here.

 *

 * Returns a pointer to the new operation or a null pointer if an

 * error occurs.

 Allocate the response buffer for outgoing operations */

 Initial value--means "never set" */

/*

 * Create a new operation associated with the given connection.  The

 * request and response sizes provided are the number of bytes

 * required to hold the request/response payload only.  Both of

 * these are allowed to be 0.  Note that 0x00 is reserved as an

 * invalid operation type for all protocols, and this is enforced

 * here.

 Do not export this function. */

 Caller has made sure we at least have a message header. */

/*

 * Get an additional reference on an operation.

/*

 * Destroy a previously created operation.

/*

 * Drop a reference on an operation, and destroy it when the last

 * one is gone.

 Tell the requester we're done */

/**

 * gb_operation_request_send() - send an operation request message

 * @operation:	the operation to initiate

 * @callback:	the operation completion callback

 * @timeout:	operation timeout in milliseconds, or zero for no timeout

 * @gfp:	the memory flags to use for any allocations

 *

 * The caller has filled in any payload so the request message is ready to go.

 * The callback function supplied will be called when the response message has

 * arrived, a unidirectional request has been sent, or the operation is

 * cancelled, indicating that the operation is complete. The callback function

 * can fetch the result of the operation using gb_operation_result() if

 * desired.

 *

 * Return: 0 if the request was successfully queued in the host-driver queues,

 * or a negative errno.

	/*

	 * Record the callback function, which is executed in

	 * non-atomic (workqueue) context when the final result

	 * of an operation has been set.

	/*

	 * Assign the operation's id, and store it in the request header.

	 * Zero is a reserved operation id for unidirectional operations.

	/*

	 * Get an extra reference on the operation. It'll be dropped when the

	 * operation completes.

/*

 * Send a synchronous operation.  This function is expected to

 * block, returning only when the response has arrived, (or when an

 * error is detected.  The return value is the result of the

 * operation.

 Cancel the operation if interrupted */

/*

 * Send a response for an incoming operation request.  A non-zero

 * errno indicates a failed operation.

 *

 * If there is any response payload, the incoming request handler is

 * responsible for allocating the response message.  Otherwise the

 * it can simply supply the result errno; this function will

 * allocate the response message if necessary.

 Record the result */

 Shouldn't happen */

 Sender of request does not care about response. */

 Reference will be dropped when message has been sent. */

 Fill in the response header and send it */

/*

 * This function is called when a message send request has completed.

	/*

	 * If the message was a response, we just need to drop our

	 * reference to the operation.  If an error occurred, report

	 * it.

	 *

	 * For requests, if there's no error and the operation in not

	 * unidirectional, there's nothing more to do until the response

	 * arrives. If an error occurred attempting to send it, or if the

	 * operation is unidrectional, record the result of the operation and

	 * schedule its completion.

/*

 * We've received data on a connection, and it doesn't look like a

 * response, so we assume it's a request.

 *

 * This is called in interrupt context, so just copy the incoming

 * data into the request buffer and handle the rest via workqueue.

	/*

	 * The initial reference to the operation will be dropped when the

	 * request handler returns.

/*

 * We've received data that appears to be an operation response

 * message.  Look up the operation, and record that we've received

 * its response.

 *

 * This is called in interrupt context, so just copy the incoming

 * data into the response buffer and handle the rest via workqueue.

 We must ignore the payload if a bad status is returned */

 The rest will be handled in work queue context */

/*

 * Handle data arriving on a connection.  As soon as we return the

 * supplied data buffer will be reused (so unless we do something

 * with, it's effectively dropped).

 Use memcpy as data may be unaligned */

 XXX Should still complete operation */

/*

 * Cancel an outgoing operation synchronously, and record the given error to

 * indicate why.

/*

 * Cancel an incoming operation synchronously. Called during connection tear

 * down.

		/*

		 * Make sure the request handler has submitted the response

		 * before cancelling it.

/**

 * gb_operation_sync_timeout() - implement a "simple" synchronous operation

 * @connection: the Greybus connection to send this to

 * @type: the type of operation to send

 * @request: pointer to a memory buffer to copy the request from

 * @request_size: size of @request

 * @response: pointer to a memory buffer to copy the response to

 * @response_size: the size of @response.

 * @timeout: operation timeout in milliseconds

 *

 * This function implements a simple synchronous Greybus operation.  It sends

 * the provided operation request and waits (sleeps) until the corresponding

 * operation response message has been successfully received, or an error

 * occurs.  @request and @response are buffers to hold the request and response

 * data respectively, and if they are not NULL, their size must be specified in

 * @request_size and @response_size.

 *

 * If a response payload is to come back, and @response is not NULL,

 * @response_size number of bytes will be copied into @response if the operation

 * is successful.

 *

 * If there is an error, the response buffer is left alone.

/**

 * gb_operation_unidirectional_timeout() - initiate a unidirectional operation

 * @connection:		connection to use

 * @type:		type of operation to send

 * @request:		memory buffer to copy the request from

 * @request_size:	size of @request

 * @timeout:		send timeout in milliseconds

 *

 * Initiate a unidirectional operation by sending a request message and

 * waiting for it to be acknowledged as sent by the host device.

 *

 * Note that successful send of a unidirectional operation does not imply that

 * the request as actually reached the remote end of the connection.

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus debugfs code

 *

 * Copyright 2014 Google Inc.

 * Copyright 2014 Linaro Ltd.

 SPDX-License-Identifier: GPL-2.0

/*

 * SVC Greybus "watchdog" driver.

 *

 * Copyright 2016 Google Inc.

		/*

		 * Something went really wrong, let's warn userspace and then

		 * pull the plug and reset the whole greybus network.

		 * We need to do this outside of this workqueue as we will be

		 * tearing down the svc device itself.  So queue up

		 * yet-another-callback to do that.

			/*

			 * Disable ourselves, we don't want to trip again unless

			 * userspace wants us to.

 resubmit our work to happen again, if we are still "alive" */

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus connections

 *

 * Copyright 2014 Google Inc.

 * Copyright 2014 Linaro Ltd.

 Caller holds gb_connection_mutex. */

/*

 * Returns a reference-counted pointer to the connection if found.

/*

 * Callback from the host driver to let us know that data has been

 * received on the bundle.

/*

 * _gb_connection_create() - create a Greybus connection

 * @hd:			host device of the connection

 * @hd_cport_id:	host-device cport id, or -1 for dynamic allocation

 * @intf:		remote interface, or NULL for static connections

 * @bundle:		remote-interface bundle (may be NULL)

 * @cport_id:		remote-interface cport id, or 0 for static connections

 * @handler:		request handler (may be NULL)

 * @flags:		connection flags

 *

 * Create a Greybus connection, representing the bidirectional link

 * between a CPort on a (local) Greybus host device and a CPort on

 * another Greybus interface.

 *

 * A connection also maintains the state of operations sent over the

 * connection.

 *

 * Serialised against concurrent create and destroy using the

 * gb_connection_mutex.

 *

 * Return: A pointer to the new connection if successful, or an ERR_PTR

 * otherwise.

/*

 * Request the SVC to create a connection from AP's cport to interface's

 * cport.

	/*

	 * Enable either E2EFC or CSD, unless no flow control is requested.

 Inform Interface about active CPorts */

				/*

				 * Allow mode switch to time out waiting for

				 * mailbox event.

/*

 * Cancel all active operations on a connection.

 *

 * Locking: Called with connection lock held and state set to DISABLED or

 * DISCONNECTING.

/*

 * Cancel all active incoming operations on a connection.

 *

 * Locking: Called with connection lock held and state set to ENABLED_TX.

 FIXME: flush, not cancel? */

/*

 * _gb_connection_enable() - enable a connection

 * @connection:		connection to enable

 * @rx:			whether to enable incoming requests

 *

 * Connection-enable helper for DISABLED->ENABLED, DISABLED->ENABLED_TX, and

 * ENABLED_TX->ENABLED state transitions.

 *

 * Locking: Caller holds connection->mutex.

 Handle ENABLED_TX -> ENABLED transitions. */

 Transmit queue should already be empty. */

 control-connection tear down is deferred when mode switching */

 Disable a connection without communicating with the remote end. */

 Caller must have disabled the connection before destroying it. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus "Core"

 *

 * Copyright 2014-2015 Google Inc.

 * Copyright 2014-2015 Linaro Ltd.

 Allow greybus to be disabled at boot if needed */

 FIXME - Dynamic ids? */

 FIXME

 add a uevent that can "load" a bundle type

 This is what we need to bind a driver to so use the info

 in gmod here as well

 match id */

	/*

	 * Unbound bundle devices are always deactivated. During probe, the

	 * Runtime PM is set to enabled and active and the usage count is

	 * incremented. If the driver supports runtime PM, it should call

	 * pm_runtime_put() in its probe routine and pm_runtime_get_sync()

	 * in remove routine.

		/*

		 * Catch buggy drivers that fail to destroy their connections.

	/*

	 * Disable (non-offloaded) connections early in case the interface is

	 * already gone to avoid unceccessary operation timeouts during

	 * driver disconnect. Otherwise, only disable incoming requests.

 Catch buggy drivers that fail to destroy their connections. */

 Success */

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus "AP" USB driver for "ES2" controller chips

 *

 * Copyright 2014-2015 Google Inc.

 * Copyright 2014-2015 Linaro Ltd.

 Default timeout for USB vendor requests. */

 Default timeout for ARPC CPort requests */

 Fixed CPort numbers */

 Memory sizes for the buffers sent to/from the ES2 controller */

 Memory sizes for the ARPC buffers */

/*

 * Number of CPort IN urbs in flight at any point in time.

 * Adjust if we are having stalls in the USB buffer due to not enough urbs in

 * flight.

/* Number of CPort OUT urbs in flight at any point in time.

 * Adjust if we get messages saying we are out of urbs in the system log.

/*

 * Number of ARPC in urbs in flight at any point in time.

/*

 * @endpoint: bulk in endpoint for CPort data

 * @urb: array of urbs for the CPort in messages

 * @buffer: array of buffers for the @cport_in_urb urbs

/**

 * struct es2_ap_dev - ES2 USB Bridge to AP structure

 * @usb_dev: pointer to the USB device we are.

 * @usb_intf: pointer to the USB interface we are bound to.

 * @hd: pointer to our gb_host_device structure

 *

 * @cport_in: endpoint, urbs and buffer for cport in messages

 * @cport_out_endpoint: endpoint for for cport out messages

 * @cport_out_urb: array of urbs for the CPort out messages

 * @cport_out_urb_busy: array of flags to see if the @cport_out_urb is busy or

 *			not.

 * @cport_out_urb_cancelled: array of flags indicating whether the

 *			corresponding @cport_out_urb is being cancelled

 * @cport_out_urb_lock: locks the @cport_out_urb_busy "list"

 * @cdsi1_in_use: true if cport CDSI1 is in use

 * @apb_log_task: task pointer for logging thread

 * @apb_log_dentry: file system entry for the log file interface

 * @apb_log_enable_dentry: file system entry for enabling logging

 * @apb_log_fifo: kernel FIFO to carry logged data

 * @arpc_urb: array of urbs for the ARPC in messages

 * @arpc_buffer: array of buffers for the @arpc_urb urbs

 * @arpc_endpoint_in: bulk in endpoint for APBridgeA RPC

 * @arpc_id_cycle: gives an unique id to ARPC

 * @arpc_lock: locks ARPC list

 * @arpcs: list of in progress ARPCs

 Look in our pool of allocated urbs first, as that's the "fastest" */

	/*

	 * Crap, pool is empty, complain to the syslog and go allocate one

	 * dynamically as we have to succeed.

	/*

	 * See if this was an urb in our pool, if so mark it "free", otherwise

	 * we need to free it ourselves.

 If urb is not NULL, then we need to free this urb */

/*

 * We (ab)use the operation-message header pad bytes to transfer the

 * cport id in order to minimise overhead.

 Clear the pad bytes used for the CPort id */

 Extract the CPort id packed into the header, and clear it */

/*

 * Returns zero if the message was successfully queued, or a negative errno

 * otherwise.

	/*

	 * The data actually transferred will include an indication

	 * of where the data should be sent.  Do one last check of

	 * the target CPort id before filling it in.

 Find a free urb */

 Pack the cport id into the message header */

/*

 * Can not be called in atomic context.

 Prevent dynamically allocated urb from being deallocated. */

 Prevent pre-allocated urb from being reused. */

 Common function to report consistent warnings based on URB status */

 device is gone, stop sending */

 Tear down everything! */

 just to be anal */

 release reserved CDSI0 and CDSI1 cports */

 The urb is being unlinked */

 Extract the CPort id, which is packed in the message header */

 put our urb back in the request pool */

	/*

	 * Tell the submitter that the message send (attempt) is

	 * complete, and report the status.

 The urb is being unlinked */

 put our urb back in the request pool */

 get log from APB1 */

 XXX We will need to rename this per APB */

 We need to fit a CPort ID in one byte of a message header */

/*

 * The ES2 USB Bridge device has 15 endpoints

 * 1 Control - usual USB stuff + AP -> APBridgeA messages

 * 7 Bulk IN - CPort data in

 * 7 Bulk OUT - CPort data out

	/*

	 * Reserve the CDSI0 and CDSI1 CPorts so they won't be allocated

	 * dynamically.

 find all bulk endpoints */

 Allocate buffers for our cport in messages */

 Allocate buffers for ARPC in messages */

 Allocate urbs for our CPort OUT messages */

 just to be anal */

 XXX We will need to rename this per APB */

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus Host Device

 *

 * Copyright 2014-2015 Google Inc.

 * Copyright 2014-2015 Linaro Ltd.

 Locking: Caller guarantees serialisation */

 Locking: Caller guarantees serialisation */

	/*

	 * Validate that the driver implements all of the callbacks

	 * so that we don't have to every time we make them.

	/*

	 * Make sure to never allocate messages larger than what the Greybus

	 * protocol supports.

	/*

	 * Tear down the svc and flush any on-going hotplug processing before

	 * removing the remaining interfaces.

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus Module code

 *

 * Copyright 2016 Google Inc.

 * Copyright 2016 Linaro Ltd.

 Set flag to prevent concurrent activation. */

 Tell the SVC to eject the primary interface. */

/*

 * Register and enable an interface after first attempting to activate it.

 Mark as disconnected to prevent I/O during disable. */

 Register a module and its interfaces. */

 Deregister a module and its interfaces. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus bundles

 *

 * Copyright 2014-2015 Google Inc.

 * Copyright 2014-2015 Linaro Ltd.

 Tell userspace that the file contents changed */

/*

 * Create a gb_bundle structure to represent a discovered

 * bundle.  Returns a pointer to the new bundle or a null

 * pointer if a failure occurs due to memory exhaustion.

	/*

	 * Reject any attempt to reuse a bundle id.  We initialize

	 * these serially, so there's no need to worry about keeping

	 * the interface bundle list locked here.

/*

 * Tear down a previously set up bundle.

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus CPort control protocol.

 *

 * Copyright 2015 Google Inc.

 * Copyright 2015 Linaro Ltd.

 Highest control-protocol version supported */

 Get Manifest's size from the interface */

 Reads Manifest from the interface */

 FIXME: use protocol version instead */

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus interface code

 *

 * Copyright 2014 Google Inc.

 * Copyright 2014 Linaro Ltd.

 Time required for interface to enter standby before disabling REFCLK */

 Don't-care selector index */

 DME attributes */

 FIXME: remove ES2 support and DME_T_TST_SRC_INCREMENT */

 DDBL1 Manufacturer and Product ids */

	/*

	 * Unless this is a Toshiba bridge, bail out until we have defined

	 * standard GMP attributes.

 DME attributes have already been read */

 Allocate an interface device id. */

 FIXME: Hard-coded AP device id. */

	/*

	 * XXX Should we tell SVC that this id doesn't belong to interface

	 * XXX anymore.

 Locking: Caller holds the interface mutex. */

 Mark as disconnected to prevent I/O during disable. */

 Make sure interface is still enabled. */

	/*

	 * Prepare the control device for mode switch and make sure to get an

	 * extra reference before it goes away during interface disable.

 Finalise control-connection mode switch. */

 Re-enable (re-enumerate) interface if still active. */

	/*

	 * Get a reference to the interface device, which will be put once the

	 * mode switch is complete.

/*

 * T_TstSrcIncrement is written by the module on ES2 as a stand-in for the

 * init-status attribute DME_TOSHIBA_INIT_STATUS. The AP needs to read and

 * clear it after reading a non-zero value from it.

 *

 * FIXME: This is module-hardware dependent and needs to be extended for every

 * type of module we want to support.

	/*

	 * ES2 bridges use T_TstSrcIncrement for the init status.

	 *

	 * FIXME: Remove ES2 support

	/*

	 * A nonzero init status indicates the module has finished

	 * initializing.

	/*

	 * Extract the init status.

	 *

	 * For ES2: We need to check lowest 8 bits of 'value'.

	 * For ES3: We need to check highest 8 bits out of 32 of 'value'.

	 *

	 * FIXME: Remove ES2 support

	/*

	 * Check if the interface is executing the quirky ES3 bootrom that,

	 * for example, requires E2EFC, CSD and CSV to be disabled.

 S2 Loader doesn't support runtime PM */

 Clear the init status. */

 interface sysfs attributes */

 Delay to allow interface to enter standby before disabling refclk */

/*

 * A Greybus module represents a user-replaceable component on a GMP

 * phone.  An interface is the physical connection on that module.  A

 * module may have more than one interface.

 *

 * Create a gb_interface structure to represent a discovered interface.

 * The position of interface within the Endo is encoded in "interface_id"

 * argument.

 *

 * Returns a pointer to the new interfce or a null pointer if a

 * failure occurs due to memory exhaustion.

 XXX refcount? */

 Invalid device id to start with */

 FIXME: handle as an error for now */

 FIXME: handle as an error for now */

/*

 * At present, we assume a UniPro-only module to be a Greybus module that

 * failed to send its mailbox poke. There is some reason to believe that this

 * is because of a bug in the ES3 bootrom.

 *

 * FIXME: Check if this is a Toshiba bridge before retrying?

/*

 * Activate an interface.

 *

 * Locking: Caller holds the interface mutex.

 Make sure type is detected correctly during reactivation. */

/*

 * Deactivate an interface.

 *

 * Locking: Caller holds the interface mutex.

 Abort any ongoing mode switch. */

/*

 * Enable an interface by enabling its control connection, fetching the

 * manifest and other information over it, and finally registering its child

 * devices.

 *

 * Locking: Caller holds the interface mutex.

 Establish control connection */

 Get manifest size using control protocol on CPort */

 Get manifest using control protocol on CPort */

	/*

	 * Parse the manifest and build up our data structures representing

	 * what's in it.

 Register the control device and any bundles */

/*

 * Disable an interface and destroy its bundles.

 *

 * Locking: Caller holds the interface mutex.

 Set disconnected flag to avoid I/O during connection tear down. */

 Register an interface. */

 Deregister an interface. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Greybus manifest parsing

 *

 * Copyright 2014-2015 Google Inc.

 * Copyright 2014-2015 Linaro Ltd.

/*

 * We scan the manifest once to identify where all the descriptors

 * are.  The result is a list of these manifest_desc structures.  We

 * then pick through them for what we're looking for (starting with

 * the interface descriptor).  As each is processed we remove it from

 * the list.  When we're done the list should (probably) be empty.

/*

 * Validate the given descriptor.  Its reported size must fit within

 * the number of bytes remaining, and it must have a recognized

 * type.  Check that the reported size is at least as big as what

 * we expect to see.  (It could be bigger, perhaps for a new version

 * of the format.)

 *

 * Returns the (non-zero) number of bytes consumed by the descriptor,

 * or a negative errno.

 Must at least have header */

 Descriptor needs to at least have a header */

 String descriptors are padded to 4 byte boundaries */

 Descriptor bigger than what we expect */

 desc_size is positive and is known to fit in a signed int */

/*

 * Find the string descriptor having the given id, validate it, and

 * allocate a duplicate copy of it.  The duplicate has an extra byte

 * which guarantees the returned string is NUL-terminated.

 *

 * String index 0 is valid (it represents "no string"), and for

 * that a null pointer is returned.

 *

 * Otherwise returns a pointer to a newly-allocated copy of the

 * descriptor string, or an error-coded pointer on failure.

 A zero string id means no string (but no error) */

 Allocate an extra byte so we can guarantee it's NUL-terminated */

 Ok we've used this string, so we're done with it */

/*

 * Find cport descriptors in the manifest associated with the given

 * bundle, and set up data structures for the functions that use

 * them.  Returns the number of cports set up for the bundle, or 0

 * if there is an error.

 Set up all cport descriptors associated with this bundle */

 Nothing else should have its cport_id as control cport id */

		/*

		 * Found one, move it to our temporary list after checking for

		 * duplicates.

 Release the cport descriptor */

	/*

	 * Free all cports for this bundle to avoid 'excess descriptors'

	 * warnings.

 Error; count should also be 0 */

/*

 * Find bundle descriptors in the manifest and set up their data

 * structures.  Returns the number of bundles set up for the

 * given interface.

 Found one.  Set up its bundle structure*/

 Done with this bundle descriptor */

 Ignore any legacy control bundles */

 Nothing else should have its class set to control class */

		/*

		 * Now go set up this bundle's functions and cports.

		 *

		 * A 'bundle' represents a device in greybus. It may require

		 * multiple cports for its functioning. If we fail to setup any

		 * cport of a bundle, we better reject the complete bundle as

		 * the device may not be able to function properly then.

		 *

		 * But, failing to setup a cport of bundle X doesn't mean that

		 * the device corresponding to bundle Y will not work properly.

		 * Bundles should be treated as separate independent devices.

		 *

		 * While parsing manifest for an interface, treat bundles as

		 * separate entities and don't reject entire interface and its

		 * bundles on failing to initialize a cport. But make sure the

		 * bundle which needs the cport, gets destroyed properly.

 An error occurred; undo any changes we've made */

 Error; count should also be 0 */

 Handle the strings first--they can fail */

 Assign feature flags communicated via manifest */

 Release the interface descriptor, now that we're done with it */

 An interface must have at least one bundle descriptor */

/*

 * Parse a buffer containing an interface manifest.

 *

 * If we find anything wrong with the content/format of the buffer

 * we reject it.

 *

 * The first requirement is that the manifest's version is

 * one we can parse.

 *

 * We make an initial pass through the buffer and identify all of

 * the descriptors it contains, keeping track for each its type

 * and the location size of its data in the buffer.

 *

 * Next we scan the descriptors, looking for an interface descriptor;

 * there must be exactly one of those.  When found, we record the

 * information it contains, and then remove that descriptor (and any

 * string descriptors it refers to) from further consideration.

 *

 * After that we look for the interface's bundles--there must be at

 * least one of those.

 *

 * Returns true if parsing was successful, false otherwise.

 Manifest descriptor list should be empty here */

 we have to have at _least_ the manifest header */

 Make sure the size is right */

 Validate major/minor number */

 OK, find all the descriptors */

 There must be a single interface descriptor */

 Parse the manifest, starting with the interface descriptor */

	/*

	 * We really should have no remaining descriptors, but we

	 * don't know what newer format manifests might leave.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Virtual Channel support

 *

 * Copyright (C) 2013 Red Hat, Inc.  All rights reserved.

 *     Author: Alex Williamson <alex.williamson@redhat.com>

/**

 * pci_vc_save_restore_dwords - Save or restore a series of dwords

 * @dev: device

 * @pos: starting config space position

 * @buf: buffer to save to or restore from

 * @dwords: number of dwords to save/restore

 * @save: whether to save or restore

/**

 * pci_vc_load_arb_table - load and wait for VC arbitration table

 * @dev: device

 * @pos: starting position of VC capability (VC/VC9/MFVC)

 *

 * Set Load VC Arbitration Table bit requesting hardware to apply the VC

 * Arbitration Table (previously loaded).  When the VC Arbitration Table

 * Status clears, hardware has latched the table into VC arbitration logic.

/**

 * pci_vc_load_port_arb_table - Load and wait for VC port arbitration table

 * @dev: device

 * @pos: starting position of VC capability (VC/VC9/MFVC)

 * @res: VC resource number, ie. VCn (0-7)

 *

 * Set Load Port Arbitration Table bit requesting hardware to apply the Port

 * Arbitration Table (previously loaded).  When the Port Arbitration Table

 * Status clears, hardware has latched the table into port arbitration logic.

/**

 * pci_vc_enable - Enable virtual channel

 * @dev: device

 * @pos: starting position of VC capability (VC/VC9/MFVC)

 * @res: VC res number, ie. VCn (0-7)

 *

 * A VC is enabled by setting the enable bit in matching resource control

 * registers on both sides of a link.  We therefore need to find the opposite

 * end of the link.  To keep this simple we enable from the downstream device.

 * RC devices do not have an upstream device, nor does it seem that VC9 do

 * (spec is unclear).  Once we find the upstream device, match the VC ID to

 * get the correct resource, disable and enable on both ends.

 Enable VCs from the downstream device */

 If there is no opposite end of the link, skip to enable */

 VC0 is hardwired enabled, so we can start with 1 */

 Disable if enabled */

 Enable on both ends */

/**

 * pci_vc_do_save_buffer - Size, save, or restore VC state

 * @dev: device

 * @pos: starting position of VC capability (VC/VC9/MFVC)

 * @save_state: buffer for save/restore

 * @save: if provided a buffer, this indicates what to do with it

 *

 * Walking Virtual Channel config space to size, save, or restore it

 * is complicated, so we do it all from one function to reduce code and

 * guarantee ordering matches in the buffer.  When called with NULL

 * @save_state, return the size of the necessary save buffer.  When called

 * with a non-NULL @save_state, @save determines whether we save to the

 * buffer or restore from it.

 Sanity check buffer size for save/restore */

 Extended VC Count (not counting VC0) */

 Low Priority Extended VC Count (not counting VC0) */

 Port Arbitration Table Entry Size (bits) */

	/*

	 * Port VC Control Register contains VC Arbitration Select, which

	 * cannot be modified when more than one LPVC is in operation.  We

	 * therefore save/restore it first, as only VC0 should be enabled

	 * after device reset.

	/*

	 * If we have any Low Priority VCs and a VC Arbitration Table Offset

	 * in Port VC Capability Register 2 then save/restore it next.

 Fixed 4 bits per phase per lpevcc (plus VC0) */

				/*

				 * On restore, we need to signal hardware to

				 * re-load the VC Arbitration Table.

	/*

	 * In addition to each VC Resource Control Register, we may have a

	 * Port Arbitration Table attached to each VC.  The Port Arbitration

	 * Table Offset in each VC Resource Capability Register tells us if

	 * it exists.  The entry size is global from the Port VC Capability

	 * Register1 above.  The number of phases is determined per VC.

 VC Resource Control Register */

				/*

				 * For an FLR case, the VC config may remain.

				 * Preserve enable bit, restore the rest.

 Load port arbitration table if used */

 Re-enable if needed */

/**

 * pci_save_vc_state - Save VC state to pre-allocate save buffer

 * @dev: device

 *

 * For each type of VC capability, VC/VC9/MFVC, find the capability and

 * save it to the pre-allocated save buffer.

/**

 * pci_restore_vc_state - Restore VC state from save buffer

 * @dev: device

 *

 * For each type of VC capability, VC/VC9/MFVC, find the capability and

 * restore it from the previously saved buffer.

/**

 * pci_allocate_vc_save_buffers - Allocate save buffers for VC caps

 * @dev: device

 *

 * For each type of VC capability, VC/VC9/MFVC, find the capability, size

 * it, and allocate a buffer for save/restore.

 SPDX-License-Identifier: GPL-2.0

/*

 * For architectures where we want to allow direct access to the PCI config

 * stuff - it would probably be preferable on PCs too, but there people

 * just do it by hand with the magic northbridge registers.

	/* ??? XFree86 doesn't even check the return value.  They

	   just look for 0xffffffff in the output, since that's what

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Peer 2 Peer DMA support.

 *

 * Copyright (c) 2016-2018, Logan Gunthorpe

 * Copyright (c) 2016-2017, Microsemi Corporation

 * Copyright (c) 2017, Christoph Hellwig

 * Copyright (c) 2018, Eideticom Inc.

 Flush and disable pci_alloc_p2p_mem() */

/**

 * pci_p2pdma_add_resource - add memory for use as p2p memory

 * @pdev: the device to add the memory to

 * @bar: PCI BAR to add

 * @size: size of the memory to add, may be zero to use the whole BAR

 * @offset: offset into the PCI BAR

 *

 * The memory will be given ZONE_DEVICE struct pages so that it may

 * be used with any DMA request.

/*

 * Note this function returns the parent PCI device with a

 * reference taken. It is the caller's responsibility to drop

 * the reference.

/*

 * Check if a PCI bridge has its ACS redirection bits set to redirect P2P

 * TLPs upstream via ACS. Returns 1 if the packets will be redirected

 * upstream, 0 otherwise.

 Any AMD CPU whose family ID is Zen or newer supports p2pdma */

 Intel Xeon E5/Core i7 */

 Intel Xeon E7 v3/Xeon E5 v3/Core i7 */

 Intel SkyLake-E */

/*

 * This lookup function tries to find the PCI device corresponding to a given

 * host bridge.

 *

 * It assumes the host bridge device is the first PCI device in the

 * bus->devices list and that the devfn is 00.0. These assumptions should hold

 * for all the devices in the whitelist above.

 *

 * This function is equivalent to pci_get_slot(host->bus, 0), however it does

 * not take the pci_bus_sem lock seeing __host_bridge_whitelist() must not

 * sleep.

 *

 * For this to be safe, the caller should hold a reference to a device on the

 * bridge, which should ensure the host_bridge device will not be freed

 * or removed from the head of the devices list.

/*

 * If we can't find a common upstream bridge take a look at the root

 * complex and compare it to a whitelist of known good hardware.

/*

 * Calculate the P2PDMA mapping type and distance between two PCI devices.

 *

 * If the two devices are the same PCI function, return

 * PCI_P2PDMA_MAP_BUS_ADDR and a distance of 0.

 *

 * If they are two functions of the same device, return

 * PCI_P2PDMA_MAP_BUS_ADDR and a distance of 2 (one hop up to the bridge,

 * then one hop back down to another function of the same device).

 *

 * In the case where two devices are connected to the same PCIe switch,

 * return a distance of 4. This corresponds to the following PCI tree:

 *

 *     -+  Root Port

 *      \+ Switch Upstream Port

 *       +-+ Switch Downstream Port 0

 *       + \- Device A

 *       \-+ Switch Downstream Port 1

 *         \- Device B

 *

 * The distance is 4 because we traverse from Device A to Downstream Port 0

 * to the common Switch Upstream Port, back down to Downstream Port 1 and

 * then to Device B. The mapping type returned depends on the ACS

 * redirection setting of the ports along the path.

 *

 * If ACS redirect is set on any port in the path, traffic between the

 * devices will go through the host bridge, so return

 * PCI_P2PDMA_MAP_THRU_HOST_BRIDGE; otherwise return

 * PCI_P2PDMA_MAP_BUS_ADDR.

 *

 * Any two devices that have a data path that goes through the host bridge

 * will consult a whitelist. If the host bridge is in the whitelist, return

 * PCI_P2PDMA_MAP_THRU_HOST_BRIDGE with the distance set to the number of

 * ports per above. If the device is not in the whitelist, return

 * PCI_P2PDMA_MAP_NOT_SUPPORTED.

	/*

	 * Note, we don't need to take references to devices returned by

	 * pci_upstream_bridge() seeing we hold a reference to a child

	 * device which will already hold a reference to the upstream bridge.

 drop final semicolon */

/**

 * pci_p2pdma_distance_many - Determine the cumulative distance between

 *	a p2pdma provider and the clients in use.

 * @provider: p2pdma provider to check against the client list

 * @clients: array of devices to check (NULL-terminated)

 * @num_clients: number of clients in the array

 * @verbose: if true, print warnings for devices when we return -1

 *

 * Returns -1 if any of the clients are not compatible, otherwise returns a

 * positive number where a lower number is the preferable choice. (If there's

 * one client that's the same as the provider it will return 0, which is best

 * choice).

 *

 * "compatible" means the provider and the clients are either all behind

 * the same PCI root port or the host bridges connected to each of the devices

 * are listed in the 'pci_p2pdma_whitelist'.

/**

 * pci_has_p2pmem - check if a given PCI device has published any p2pmem

 * @pdev: PCI device to check

/**

 * pci_p2pmem_find_many - find a peer-to-peer DMA memory device compatible with

 *	the specified list of clients and shortest distance (as determined

 *	by pci_p2pmem_dma())

 * @clients: array of devices to check (NULL-terminated)

 * @num_clients: number of client devices in the list

 *

 * If multiple devices are behind the same switch, the one "closest" to the

 * client devices in use will be chosen first. (So if one of the providers is

 * the same as one of the clients, that provider will be used ahead of any

 * other providers that are unrelated). If multiple providers are an equal

 * distance away, one will be chosen at random.

 *

 * Returns a pointer to the PCI device with a reference taken (use pci_dev_put

 * to return the reference) or NULL if no compatible device is found. The

 * found provider will also be assigned to the client list.

/**

 * pci_alloc_p2pmem - allocate peer-to-peer DMA memory

 * @pdev: the device to allocate memory from

 * @size: number of bytes to allocate

 *

 * Returns the allocated memory or NULL on error.

	/*

	 * Pairs with synchronize_rcu() in pci_p2pdma_release() to

	 * ensure pdev->p2pdma is non-NULL for the duration of the

	 * read-lock.

/**

 * pci_free_p2pmem - free peer-to-peer DMA memory

 * @pdev: the device the memory was allocated from

 * @addr: address of the memory that was allocated

 * @size: number of bytes that were allocated

/**

 * pci_p2pmem_virt_to_bus - return the PCI bus address for a given virtual

 *	address obtained with pci_alloc_p2pmem()

 * @pdev: the device the memory was allocated from

 * @addr: address of the memory that was allocated

	/*

	 * Note: when we added the memory to the pool we used the PCI

	 * bus address as the physical address. So gen_pool_virt_to_phys()

	 * actually returns the bus address despite the misleading name.

/**

 * pci_p2pmem_alloc_sgl - allocate peer-to-peer DMA memory in a scatterlist

 * @pdev: the device to allocate memory from

 * @nents: the number of SG entries in the list

 * @length: number of bytes to allocate

 *

 * Return: %NULL on error or &struct scatterlist pointer and @nents on success

/**

 * pci_p2pmem_free_sgl - free a scatterlist allocated by pci_p2pmem_alloc_sgl()

 * @pdev: the device to allocate memory from

 * @sgl: the allocated scatterlist

/**

 * pci_p2pmem_publish - publish the peer-to-peer DMA memory for use by

 *	other devices with pci_p2pmem_find()

 * @pdev: the device with peer-to-peer DMA memory to publish

 * @publish: set to true to publish the memory, false to unpublish it

 *

 * Published memory can be used by other PCI device drivers for

 * peer-2-peer DMA operations. Non-published memory is reserved for

 * exclusive use of the device driver that registers the peer-to-peer

 * memory.

/**

 * pci_p2pdma_map_sg_attrs - map a PCI peer-to-peer scatterlist for DMA

 * @dev: device doing the DMA request

 * @sg: scatter list to map

 * @nents: elements in the scatterlist

 * @dir: DMA direction

 * @attrs: DMA attributes passed to dma_map_sg() (if called)

 *

 * Scatterlists mapped with this function should be unmapped using

 * pci_p2pdma_unmap_sg_attrs().

 *

 * Returns the number of SG entries mapped or 0 on error.

/**

 * pci_p2pdma_unmap_sg_attrs - unmap a PCI peer-to-peer scatterlist that was

 *	mapped with pci_p2pdma_map_sg()

 * @dev: device doing the DMA request

 * @sg: scatter list to map

 * @nents: number of elements returned by pci_p2pdma_map_sg()

 * @dir: DMA direction

 * @attrs: DMA attributes passed to dma_unmap_sg() (if called)

/**

 * pci_p2pdma_enable_store - parse a configfs/sysfs attribute store

 *		to enable p2pdma

 * @page: contents of the value to be stored

 * @p2p_dev: returns the PCI device that was selected to be used

 *		(if one was specified in the stored value)

 * @use_p2pdma: returns whether to enable p2pdma or not

 *

 * Parses an attribute value to decide whether to enable p2pdma.

 * The value can select a PCI device (using its full BDF device

 * name) or a boolean (in any format kstrtobool() accepts). A false

 * value disables p2pdma, a true value expects the caller

 * to automatically find a compatible device and specifying a PCI device

 * expects the caller to use the specific provider.

 *

 * pci_p2pdma_enable_show() should be used as the show operation for

 * the attribute.

 *

 * Returns 0 on success

		/*

		 * If the user enters a PCI device that  doesn't exist

		 * like "0000:01:00.1", we don't want kstrtobool to think

		 * it's a '0' when it's clearly not what the user wanted.

		 * So we require 0's and 1's to be exactly one character.

/**

 * pci_p2pdma_enable_show - show a configfs/sysfs attribute indicating

 *		whether p2pdma is enabled

 * @page: contents of the stored value

 * @p2p_dev: the selected p2p device (NULL if no device is selected)

 * @use_p2pdma: whether p2pdma has been enabled

 *

 * Attributes that use pci_p2pdma_enable_store() should use this function

 * to show the value of the attribute.

 *

 * Returns 0 on success

 SPDX-License-Identifier: GPL-2.0

/*

 * Support routines for initializing a PCI subsystem

 *

 * Extruded from code written by

 *      Dave Rusling (david.rusling@reo.mts.dec.com)

 *      David Mosberger (davidm@cs.arizona.edu)

 *	David Miller (davem@redhat.com)

 *

 * Fixed for multiple PCI buses, 1999 Andrea Arcangeli <andrea@suse.de>

 *

 * Nov 2000, Ivan Kokshaysky <ink@jurassic.park.msu.ru>

 *	     Resource sorting

 Per SR-IOV spec 3.4.1.11, VF BARs are RO zero */

	/*

	 * Ignore resources for unimplemented BARs and unused resource slots

	 * for 64 bit BARs.

	/*

	 * Ignore non-moveable resources.  This might be legacy resources for

	 * which no functional BAR register exists or another important

	 * system resource we shouldn't move around.

		/*

		 * Apparently some Matrox devices have ROM BARs that read

		 * as zero when disabled, so don't update ROM BARs unless

		 * they're enabled.  See

		 * https://lore.kernel.org/r/43147B3D.1030309@vc.cvut.cz/

	/*

	 * We can't update a 64-bit BAR atomically, so when possible,

	 * disable decoding so that a half-updated BAR won't conflict

	 * with another device.

	/*

	 * If we have a shadow copy in RAM, the PCI device doesn't respond

	 * to the shadow range, so we don't need to claim it, and upstream

	 * bridges don't need to route the range to the device.

 MMIO Base/Limit */

 Prefetchable MMIO Base/Limit */

/*

 * Generic function that returns a value indicating that the device's

 * original BIOS BAR address was not saved and so is not available for

 * reinstatement.

 *

 * Can be over-ridden by architecture specific code that implements

 * reinstatement functionality rather than leaving it disabled when

 * normal allocation attempts fail.

/*

 * We don't have to worry about legacy ISA devices, so nothing to do here.

 * This is marked as __weak because multiple architectures define it; it should

 * eventually go away.

	/*

	 * First, try exact prefetching match.  Even if a 64-bit

	 * prefetchable bridge window is below 4GB, we can't put a 32-bit

	 * prefetchable resource in it because pbus_size_mem() assumes a

	 * 64-bit window will contain no 32-bit resources.  If we assign

	 * things differently than they were sized, not everything will fit.

	/*

	 * If the prefetchable window is only 32 bits wide, we can put

	 * 64-bit prefetchable resources in it.

	/*

	 * If we didn't find a better match, we can put any memory resource

	 * in a non-prefetchable window.  If this resource is 32 bits and

	 * non-prefetchable, the first call already tried the only possibility

	 * so we don't need to try again.

	/*

	 * If we failed to assign anything, let's try the address

	 * where firmware left it.  That at least has a chance of

	 * working, which is better than just leaving it disabled.

 already aligned with min_align */

 Check if we must preserve the firmware's resource assignment */

 Make sure the resource isn't assigned before resizing it. */

 Check if the new config works by trying to assign everything. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2006 Matthew Wilcox <matthew@wil.cx>

 * Copyright (C) 2006-2009 Hewlett-Packard Development Company, L.P.

 *	Alex Chiang <achiang@hp.com>

	/*

	 * Make sure we hit the realloc case the first time through the

	 * loop.  'len' will be strlen(name) + 3 at that point which is

	 * enough space for "name-X" and the trailing NUL.

 We already hold pci_slot_mutex */

/**

 * pci_create_slot - create or increment refcount for physical PCI slot

 * @parent: struct pci_bus of parent bridge

 * @slot_nr: PCI_SLOT(pci_dev->devfn) or -1 for placeholder

 * @name: user visible string presented in /sys/bus/pci/slots/<name>

 * @hotplug: set if caller is hotplug driver, NULL otherwise

 *

 * PCI slots have first class attributes such as address, speed, width,

 * and a &struct pci_slot is used to manage them. This interface will

 * either return a new &struct pci_slot to the caller, or if the pci_slot

 * already exists, its refcount will be incremented.

 *

 * Slots are uniquely identified by a @pci_bus, @slot_nr tuple.

 *

 * There are known platforms with broken firmware that assign the same

 * name to multiple slots. Workaround these broken platforms by renaming

 * the slots on behalf of the caller. If firmware assigns name N to

 * multiple slots:

 *

 * The first slot is assigned N

 * The second slot is assigned N-1

 * The third slot is assigned N-2

 * etc.

 *

 * Placeholder slots:

 * In most cases, @pci_bus, @slot_nr will be sufficient to uniquely identify

 * a slot. There is one notable exception - pSeries (rpaphp), where the

 * @slot_nr cannot be determined until a device is actually inserted into

 * the slot. In this scenario, the caller may pass -1 for @slot_nr.

 *

 * The following semantics are imposed when the caller passes @slot_nr ==

 * -1. First, we no longer check for an existing %struct pci_slot, as there

 * may be many slots with @slot_nr of -1.  The other change in semantics is

 * user-visible, which is the 'address' parameter presented in sysfs will

 * consist solely of a dddd:bb tuple, where dddd is the PCI domain of the

 * %struct pci_bus and bb is the bus number. In other words, the devfn of

 * the 'placeholder' slot will not be displayed.

	/*

	 * Hotplug drivers are allowed to rename an existing slot,

	 * but only if not already claimed.

/**

 * pci_destroy_slot - decrement refcount for physical PCI slot

 * @slot: struct pci_slot to decrement

 *

 * %struct pci_slot is refcounted, so destroying them is really easy; we

 * just call kobject_put on its kobj and let our release methods do the

 * rest.

/**

 * pci_hp_create_module_link - create symbolic link to hotplug driver module

 * @pci_slot: struct pci_slot

 *

 * Helper function for pci_hotplug_core.c to create symbolic link to

 * the hotplug driver module.

/**

 * pci_hp_remove_module_link - remove symbolic link to the hotplug driver

 * 	module.

 * @pci_slot: struct pci_slot

 *

 * Helper function for pci_hotplug_core.c to remove symbolic link to

 * the hotplug driver module.

 SPDX-License-Identifier: GPL-2.0

/*

 * From setup-res.c, by:

 *	Dave Rusling (david.rusling@reo.mts.dec.com)

 *	David Mosberger (davidm@cs.arizona.edu)

 *	David Miller (davem@redhat.com)

 *	Ivan Kokshaysky (ink@jurassic.park.msu.ru)

/*

 * @res contains CPU addresses.  Clip it so the corresponding bus addresses

 * on @bus are entirely within @region.  This is used to control the bus

 * addresses of resources we allocate, e.g., we may need a resource that

 * can be mapped by a 32-bit BAR.

 type_mask must match */

		/* We cannot allocate a non-prefetching resource

		/*

		 * "min" is typically PCIBIOS_MIN_IO or PCIBIOS_MIN_MEM to

		 * protect badly documented motherboard resources, but if

		 * this is an already-configured bridge window, its start

		 * overrides "min".

 Ok, try it out.. */

/**

 * pci_bus_alloc_resource - allocate a resource from a parent bus

 * @bus: PCI bus

 * @res: resource to allocate

 * @size: size of resource to allocate

 * @align: alignment of resource to allocate

 * @min: minimum /proc/iomem address to allocate

 * @type_mask: IORESOURCE_* type flags

 * @alignf: resource alignment function

 * @alignf_data: data argument for resource alignment function

 *

 * Given the PCI bus a device resides on, the size, minimum address,

 * alignment and type, try to find an acceptable resource allocation

 * for a specific device resource.

/*

 * The @idx resource of @dev should be a PCI-PCI bridge window.  If this

 * resource fits inside a window of an upstream bridge, do nothing.  If it

 * overlaps an upstream window but extends outside it, clip the resource so

 * it fits completely inside.

 no overlap */

 no change */

/**

 * pci_bus_add_device - start driver for a single device

 * @dev: device to add

 *

 * This adds add sysfs entries and start device drivers

	/*

	 * Can not put in pci_device_add yet because resources

	 * are not assigned yet for some devices.

/**

 * pci_bus_add_devices - start driver for PCI devices

 * @bus: bus to check for new devices

 *

 * Start driver for PCI devices and add some sysfs entries.

 Skip already-added devices */

 Skip if device attach failed */

/** pci_walk_bus - walk devices on/under bus, calling callback.

 *  @top      bus whose devices should be walked

 *  @cb       callback to be called for each device found

 *  @userdata arbitrary pointer to be passed to callback.

 *

 *  Walk the given bus, including any bridged devices

 *  on buses under this bus.  Call the provided callback

 *  on each device found.

 *

 *  We check the return of @cb each time. If it returns anything

 *  other than 0, we break out.

 *

 end of this bus, go up or finish */

 this is a pci-pci bridge, do its devices next */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI ROM access routines

 *

 * (C) Copyright 2004 Jon Smirl <jonsmirl@yahoo.com>

 * (C) Copyright 2004 Silicon Graphics, Inc. Jesse Barnes <jbarnes@sgi.com>

/**

 * pci_enable_rom - enable ROM decoding for a PCI device

 * @pdev: PCI device to enable

 *

 * Enable ROM decoding on @dev.  This involves simply turning on the last

 * bit of the PCI ROM BAR.  Note that some cards may share address decoders

 * between the ROM and other resources, so enabling it may disable access

 * to MMIO registers or other card memory.

 Nothing to enable if we're using a shadow copy in RAM */

	/*

	 * Ideally pci_update_resource() would update the ROM BAR address,

	 * and we would only set the enable bit here.  But apparently some

	 * devices have buggy ROM BARs that read as zero when disabled.

/**

 * pci_disable_rom - disable ROM decoding for a PCI device

 * @pdev: PCI device to disable

 *

 * Disable ROM decoding on a PCI device by turning off the last bit in the

 * ROM BAR.

/**

 * pci_get_rom_size - obtain the actual size of the ROM image

 * @pdev: target PCI device

 * @rom: kernel virtual pointer to image of ROM

 * @size: size of PCI window

 *  return: size of actual ROM image

 *

 * Determine the actual length of the ROM image.

 * The PCI window size could be much larger than the

 * actual image size.

 Standard PCI ROMs start out with these bytes 55 AA */

 get the PCI data structure and check its "PCIR" signature */

 Avoid iterating through memory outside the resource window */

 never return a size larger than the PCI resource window */

 there are known ROMs that get the size wrong */

/**

 * pci_map_rom - map a PCI ROM to kernel space

 * @pdev: pointer to pci device struct

 * @size: pointer to receive size of pci window over ROM

 *

 * Return: kernel virtual pointer to image of ROM

 *

 * Map a PCI ROM into kernel space. If ROM is boot video ROM,

 * the shadow BIOS copy will be returned instead of the

 * actual ROM.

 assign the ROM an address if it doesn't have one */

 Enable ROM space decodes */

	/*

	 * Try to find the true size of the ROM since sometimes the PCI window

	 * size is much larger than the actual size of the ROM.

	 * True size is important if the ROM is going to be copied.

 restore enable if ioremap fails */

/**

 * pci_unmap_rom - unmap the ROM from kernel space

 * @pdev: pointer to pci device struct

 * @rom: virtual address of the previous mapping

 *

 * Remove a mapping of a previously mapped ROM

 Disable again before continuing */

 SPDX-License-Identifier: GPL-2.0

	/*

	 * Stopping an SR-IOV PF device removes all the associated VFs,

	 * which will update the bus->devices list and confuse the

	 * iterator.  Therefore, iterate in reverse so we remove the VFs

	 * first, then the PF.

/**

 * pci_stop_and_remove_bus_device - remove a PCI device and any children

 * @dev: the device to remove

 *

 * Remove a PCI device from the device lists, informing the drivers

 * that the device has been removed.  We also remove any subordinate

 * buses and children in a depth-first manner.

 *

 * For each device we remove, delete the device structure from the

 * device lists, remove the /proc entry, and notify userspace

 * (/sbin/hotplug).

 stop the host bridge */

 remove the host bridge */

 SPDX-License-Identifier: GPL-2.0

/*

 * (C) Copyright 2002-2004, 2007 Greg Kroah-Hartman <greg@kroah.com>

 * (C) Copyright 2007 Novell Inc.

/**

 * pci_add_dynid - add a new PCI device ID to this driver and re-probe devices

 * @drv: target pci driver

 * @vendor: PCI vendor ID

 * @device: PCI device ID

 * @subvendor: PCI subvendor ID

 * @subdevice: PCI subdevice ID

 * @class: PCI class

 * @class_mask: PCI class mask

 * @driver_data: private driver data

 *

 * Adds a new dynamic pci device ID to this driver and causes the

 * driver to probe for all devices again.  @drv must have been

 * registered prior to calling this function.

 *

 * CONTEXT:

 * Does GFP_KERNEL allocation.

 *

 * RETURNS:

 * 0 on success, -errno on failure.

/**

 * pci_match_id - See if a PCI device matches a given pci_id table

 * @ids: array of PCI device ID structures to search in

 * @dev: the PCI device structure to match against.

 *

 * Used by a driver to check whether a PCI device is in its list of

 * supported devices.  Returns the matching pci_device_id structure or

 * %NULL if there is no match.

 *

 * Deprecated; don't use this as it will not catch any dynamic IDs

 * that a driver might want to check for.

/**

 * pci_match_device - See if a device matches a driver's list of IDs

 * @drv: the PCI driver to match against

 * @dev: the PCI device structure to match against

 *

 * Used by a driver to check whether a PCI device is in its list of

 * supported devices or in the dynids list, which may have been augmented

 * via the sysfs "new_id" file.  Returns the matching pci_device_id

 * structure or %NULL if there is no match.

 When driver_override is set, only bind to the matching driver */

 Look at the dynamic ids first, before the static ones */

		/*

		 * The match table is split based on driver_override.

		 * In case override_only was set, enforce driver_override

		 * matching.

 driver_override will always match, send a dummy id */

/**

 * new_id_store - sysfs frontend to pci_add_dynid()

 * @driver: target device driver

 * @buf: buffer for scanning device ID data

 * @count: input size

 *

 * Allow PCI IDs to be added to an existing driver via sysfs.

	/* Only accept driver_data values that match an existing id_table

 No match */

/**

 * remove_id_store - remove a PCI device ID from this driver

 * @driver: target device driver

 * @buf: buffer for scanning device ID data

 * @count: input size

 *

 * Removes a dynamic pci device ID to this driver.

	/*

	 * Unbound PCI devices are always put in D0, regardless of

	 * runtime PM status.  During probe, the device is set to

	 * active and the usage count is incremented.  If the driver

	 * supports runtime PM, it should call pm_runtime_put_noidle(),

	 * or any other runtime PM helper function decrementing the usage

	 * count, in its probe routine and pm_runtime_get_noresume() in

	 * its remove routine.

	/*

	 * Probe function should return < 0 for failure, 0 for success

	 * Treat values > 0 as success, but warn.

	/*

	 * Execute driver initialization on node where the device is

	 * attached.  This way the driver likely allocates its local memory

	 * on the right node.

	/*

	 * Prevent nesting work_on_cpu() for the case where a Virtual Function

	 * device is probed from work_on_cpu() of the Physical device.

/**

 * __pci_device_probe - check if a driver wants to claim a specific PCI device

 * @drv: driver to call to check if it wants the PCI device

 * @pci_dev: PCI device being probed

 *

 * returns 0 on success, else error.

 * side-effect: pci_dev->driver is set to drv when drv claims pci_dev.

 Undo the runtime PM settings in local_pci_probe() */

	/*

	 * If the device is still on, set the power state as "unknown",

	 * since it might change by the next time we load the driver.

	/*

	 * We would love to complain here if pci_dev->is_enabled is set, that

	 * the driver should have called pci_disable_device(), but the

	 * unfortunate fact is there are too many odd BIOS and bridge setups

	 * that don't like drivers doing that all of the time.

	 * Oh well, we can dream of sane hardware when we sleep, no matter how

	 * horrible the crap we have to deal with is when we are awake...

	/*

	 * If this is a kexec reboot, turn off Bus Master bit on the

	 * device to tell it to not continue to do DMA. Don't touch

	 * devices in D3cold or unknown states.

	 * If it is not a kexec reboot, firmware will hit the PCI

	 * devices with big hammer and stop their DMA any way.

 Auxiliary functions used for system resume and run-time resume. */

/**

 * pci_restore_standard_config - restore standard config registers of PCI device

 * @pci_dev: PCI device to handle

/*

 * Default "suspend" method for devices that have no driver provided suspend,

 * or not even a driver at all (second part).

	/*

	 * mark its power state as "unknown", since we don't know if

	 * e.g. the BIOS will change its device state when we suspend.

/*

 * Default "resume" method for devices that have no driver provided resume,

 * or not even a driver at all (second part).

 if the device was enabled before suspend, re-enable */

	/*

	 * if the device was busmaster before the suspend, make it busmaster

	 * again

 Auxiliary functions used by the new power management framework */

 Disable non-bridge devices without PM support */

	/*

	 * Legacy PM support is used by default, so warn if the new framework is

	 * supported as well.  Drivers are supposed to support either the

	 * former, or the latter, but not both at the same time.

 New power management framework */

	/*

	 * The PME setting needs to be adjusted here in case the direct-complete

	 * optimization is used with respect to this device.

 Resume device if platform firmware has put it in reset-power-on */

		/*

		 * On platforms with ACPI this check may also trigger for

		 * devices sharing power resources if one of those power

		 * resources has been activated as a result of a change of the

		 * power state of another device sharing it.  However, in that

		 * case it is also better to resume the device, in general.

 !CONFIG_PM_SLEEP */

 !CONFIG_PM_SLEEP */

	/*

	 * Some BIOSes forget to clear Root PME Status bits after system

	 * wakeup, which breaks ACPI-based runtime wakeup on PCI Express.

	 * Clear those bits now just in case (shouldn't hurt).

	/*

	 * PCI devices suspended at run time may need to be resumed at this

	 * point, because in general it may be necessary to reconfigure them for

	 * system suspend.  Namely, if the device is expected to wake up the

	 * system from the sleep state, it may have to be reconfigured for this

	 * purpose, or if the device is not expected to wake up the system from

	 * the sleep state, it should be prevented from signaling wakeup events

	 * going forward.

	 *

	 * Also if the driver of the device does not indicate that its system

	 * suspend callbacks can cope with runtime-suspended devices, it is

	 * better to resume the device from runtime suspend here.

		/*

		 * Either the device is a bridge with a child in D0 below it, or

		 * the function is running for the second time in a row without

		 * going through full resume, which is possible only during

		 * suspend-to-idle in a spurious wakeup case.  The device should

		 * be in D0 at this point, but if it is a bridge, it may be

		 * necessary to save its state.

		/*

		 * Per PCI PM r1.2, table 6-1, a bridge must be in D0 if any

		 * downstream device is in D0, so avoid changing the power state

		 * of the parent bridge by setting the skip_bus_pm flag for it.

	/*

	 * Some BIOSes from ASUS have a bug: If a USB EHCI host controller's

	 * PCI COMMAND register isn't 0, the BIOS assumes that the controller

	 * hasn't been quiesced and tries to turn it off.  If the controller

	 * is already in D3, this can hang or cause memory corruption.

	 *

	 * Since the value of the COMMAND register doesn't matter once the

	 * device has been suspended, we can safely set it to 0 here.

	/*

	 * If the target system sleep state is suspend-to-idle, it is sufficient

	 * to check whether or not the device's wakeup settings are good for

	 * runtime PM.  Otherwise, the pm_resume_via_firmware() check will cause

	 * pci_pm_complete() to take care of fixing up the device's state

	 * anyway, if need be.

	/*

	 * In the suspend-to-idle case, devices left in D0 during suspend will

	 * stay in D0, so it is not necessary to restore or update their

	 * configuration here and attempting to put them into D0 again is

	 * pointless, so avoid doing that.

	/*

	 * This is necessary for the suspend error path in which resume is

	 * called without restoring the standard config registers of the device.

 !CONFIG_SUSPEND */

 !CONFIG_SUSPEND */

	/*

	 * Resume all runtime-suspended devices before creating a snapshot

	 * image of system memory, because the restore kernel generally cannot

	 * be expected to always handle them consistently and they need to be

	 * put into the runtime-active metastate during system resume anyway,

	 * so it is better to ensure that the state saved in the image will be

	 * always consistent with that.

	/*

	 * The pm->thaw_noirq() callback assumes the device has been

	 * returned to D0 and its config state has been restored.

	 *

	 * In addition, pci_restore_state() restores MSI-X state in MMIO

	 * space, which requires the device to be in D0, so return it to D0

	 * in case the driver's "freeze" callbacks put it into a low-power

	 * state.

 The reason to do that is the same as in pci_pm_suspend(). */

	/*

	 * The reason for doing this here is the same as for the analogous code

	 * in pci_pm_suspend_noirq().

	/*

	 * This is necessary for the hibernation error path in which restore is

	 * called without restoring the standard config registers of the device.

 !CONFIG_HIBERNATE_CALLBACKS */

 !CONFIG_HIBERNATE_CALLBACKS */

	/*

	 * If pci_dev->driver is not set (unbound), we leave the device in D0,

	 * but it may go to D3cold when the bridge above it runtime suspends.

	 * Save its config space in case that happens.

		/*

		 * -EBUSY and -EAGAIN is used to request the runtime PM core

		 * to schedule a new suspend, so log the event only with debug

		 * log level.

	/*

	 * Restoring config space is necessary even if the device is not bound

	 * to a driver because although we left it in D0, it may have gone to

	 * D3cold when the bridge above it runtime suspended.

	/*

	 * If pci_dev->driver is not set (unbound), the device should

	 * always remain in D0 regardless of the runtime PM status

 !CONFIG_PM */

 !CONFIG_PM */

/**

 * __pci_register_driver - register a new pci driver

 * @drv: the driver structure to register

 * @owner: owner module of drv

 * @mod_name: module name string

 *

 * Adds the driver structure to the list of registered drivers.

 * Returns a negative value on error, otherwise 0.

 * If no error occurred, the driver remains registered even if

 * no device was claimed during registration.

 initialize common driver fields */

 register with core */

/**

 * pci_unregister_driver - unregister a pci driver

 * @drv: the driver structure to unregister

 *

 * Deletes the driver structure from the list of registered PCI drivers,

 * gives it a chance to clean up by calling its remove() function for

 * each device it was responsible for, and marks those devices as

 * driverless.

/**

 * pci_dev_driver - get the pci_driver of a device

 * @dev: the device to query

 *

 * Returns the appropriate pci_driver structure or %NULL if there is no

 * registered driver for the device.

/**

 * pci_bus_match - Tell if a PCI device structure has a matching PCI device id structure

 * @dev: the PCI device structure to match against

 * @drv: the device driver to search for matching PCI device id structures

 *

 * Used by a driver to check whether a PCI device present in the

 * system is in its list of supported devices. Returns the matching

 * pci_device_id structure or %NULL if there is no match.

/**

 * pci_dev_get - increments the reference count of the pci device structure

 * @dev: the device being referenced

 *

 * Each live reference to a device should be refcounted.

 *

 * Drivers for PCI devices should normally record such references in

 * their probe() methods, when they bind to a device, and release

 * them by calling pci_dev_put(), in their disconnect() methods.

 *

 * A pointer to the device with the incremented reference counter is returned.

/**

 * pci_dev_put - release a use of the pci device structure

 * @dev: device that's been disconnected

 *

 * Must be called when a user of a device is finished with it.  When the last

 * user of the device calls this function, the memory of the device is freed.

/**

 * pci_uevent_ers - emit a uevent during recovery path of PCI device

 * @pdev: PCI device undergoing error recovery

 * @err_type: type of error event

/**

 * pci_dma_configure - Setup DMA configuration

 * @dev: ptr to dev structure

 *

 * Function to update PCI devices's DMA configuration using the same

 * info from the OF node or ACPI node of host bridge's parent (if any).

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Express I/O Virtualization (IOV) support

 *   Address Translation Service 1.0

 *   Page Request Interface added by Joerg Roedel <joerg.roedel@amd.com>

 *   PASID support added by Joerg Roedel <joerg.roedel@amd.com>

 *

 * Copyright (C) 2009 Intel Corporation, Yu Zhao <yu.zhao@intel.com>

 * Copyright (C) 2011 Advanced Micro Devices,

/**

 * pci_ats_supported - check if the device can use ATS

 * @dev: the PCI device

 *

 * Returns true if the device supports ATS and is allowed to use it, false

 * otherwise.

/**

 * pci_enable_ats - enable the ATS capability

 * @dev: the PCI device

 * @ps: the IOMMU page shift

 *

 * Returns 0 on success, or negative on failure.

	/*

	 * Note that enabling ATS on a VF fails unless it's already enabled

	 * with the same STU on the PF.

/**

 * pci_disable_ats - disable the ATS capability

 * @dev: the PCI device

/**

 * pci_ats_queue_depth - query the ATS Invalidate Queue Depth

 * @dev: the PCI device

 *

 * Returns the queue depth on success, or negative on failure.

 *

 * The ATS spec uses 0 in the Invalidate Queue Depth field to

 * indicate that the function can accept 32 Invalidate Request.

 * But here we use the `real' values (i.e. 1~32) for the Queue

 * Depth; and 0 indicates the function shares the Queue with

 * other functions (doesn't exclusively own a Queue).

/**

 * pci_ats_page_aligned - Return Page Aligned Request bit status.

 * @pdev: the PCI device

 *

 * Returns 1, if the Untranslated Addresses generated by the device

 * are always aligned or 0 otherwise.

 *

 * Per PCIe spec r4.0, sec 10.5.1.2, if the Page Aligned Request bit

 * is set, it indicates the Untranslated Addresses generated by the

 * device are always aligned to a 4096 byte boundary.

/**

 * pci_enable_pri - Enable PRI capability

 * @pdev: PCI device structure

 * @reqs: outstanding requests

 *

 * Returns 0 on success, negative value on error

	/*

	 * VFs must not implement the PRI Capability.  If their PF

	 * implements PRI, it is shared by the VFs, so if the PF PRI is

	 * enabled, it is also enabled for the VF.

/**

 * pci_disable_pri - Disable PRI capability

 * @pdev: PCI device structure

 *

 * Only clears the enabled-bit, regardless of its former value

 VFs share the PF PRI */

/**

 * pci_restore_pri_state - Restore PRI

 * @pdev: PCI device structure

/**

 * pci_reset_pri - Resets device's PRI state

 * @pdev: PCI device structure

 *

 * The PRI capability must be disabled before this function is called.

 * Returns 0 on success, negative value on error.

/**

 * pci_prg_resp_pasid_required - Return PRG Response PASID Required bit

 *				 status.

 * @pdev: PCI device structure

 *

 * Returns 1 if PASID is required in PRG Response Message, 0 otherwise.

/**

 * pci_pri_supported - Check if PRI is supported.

 * @pdev: PCI device structure

 *

 * Returns true if PRI capability is present, false otherwise.

 VFs share the PF PRI */

 CONFIG_PCI_PRI */

/**

 * pci_enable_pasid - Enable the PASID capability

 * @pdev: PCI device structure

 * @features: Features to enable

 *

 * Returns 0 on success, negative value on error. This function checks

 * whether the features are actually supported by the device and returns

 * an error if not.

	/*

	 * VFs must not implement the PASID Capability, but if a PF

	 * supports PASID, its VFs share the PF PASID configuration.

 User wants to enable anything unsupported? */

/**

 * pci_disable_pasid - Disable the PASID capability

 * @pdev: PCI device structure

 VFs share the PF PASID configuration */

/**

 * pci_restore_pasid_state - Restore PASID capabilities

 * @pdev: PCI device structure

/**

 * pci_pasid_features - Check which PASID features are supported

 * @pdev: PCI device structure

 *

 * Returns a negative value when no PASI capability is present.

 * Otherwise is returns a bitmask with supported features. Current

 * features reported are:

 * PCI_PASID_CAP_EXEC - Execute permission supported

 * PCI_PASID_CAP_PRIV - Privileged mode supported

/**

 * pci_max_pasids - Get maximum number of PASIDs supported by device

 * @pdev: PCI device structure

 *

 * Returns negative value when PASID capability is not present.

 * Otherwise it returns the number of supported PASIDs.

 CONFIG_PCI_PASID */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI support in ACPI

 *

 * Copyright (C) 2005 David Shaohua Li <shaohua.li@intel.com>

 * Copyright (C) 2004 Tom Long Nguyen <tom.l.nguyen@intel.com>

 * Copyright (C) 2004 Intel Corp.

/*

 * The GUID is defined in the PCI Firmware Specification available here:

 * https://www.pcisig.com/members/downloads/pcifw_r3_1_13Dec10.pdf

 _HPX PCI Setting Record (Type 0); same as _HPP */

 Not present in _HPP */

 Not applicable to PCIe */

 Not applicable to PCIe */

 Program bridge control value */

 _HPX PCI-X Setting Record (Type 1) */

 _HPX PCI Express Setting Record (Type 2) */

	/*

	 * Don't allow _HPX to change MPS or MRRS settings.  We manage

	 * those to make sure they're consistent with the rest of the

	 * platform.

 Initialize Device Control Register */

 Initialize Link Control Register */

		/*

		 * If the Root Port supports Read Completion Boundary of

		 * 128, set RCB to 128.  Otherwise, clear it.

 Find Advanced Error Reporting Enhanced Capability */

 Initialize Uncorrectable Error Mask Register */

 Initialize Uncorrectable Error Severity Register */

 Initialize Correctable Error Mask Register */

 Initialize Advanced Error Capabilities and Control Register */

 Don't enable ECRC generation or checking if unsupported */

	/*

	 * FIXME: The following two registers are not supported yet.

	 *

	 *   o Secondary Uncorrectable Error Severity Register

	 *   o Secondary Uncorrectable Error Mask Register

 _HPX PCI Express Setting Record (Type 3) */

/* pci_acpi_program_hp_params

 *

 * @dev - the pci_dev for which we want parameters

	/*

	 * _HPP settings apply to all child buses, until another _HPP is

	 * encountered. If we don't find an _HPP for the input pci dev,

	 * look for it in the parent device scope since that would apply to

	 * this pci dev.

/**

 * pciehp_is_native - Check whether a hotplug port is handled by the OS

 * @bridge: Hotplug port to check

 *

 * Returns true if the given @bridge is handled by the native PCIe hotplug

 * driver.

/**

 * shpchp_is_native - Check whether a hotplug port is handled by the OS

 * @bridge: Hotplug port to check

 *

 * Returns true if the given @bridge is handled by the native SHPC hotplug

 * driver.

/**

 * pci_acpi_wake_bus - Root bus wakeup notification fork function.

 * @context: Device wakeup context.

/**

 * pci_acpi_wake_dev - PCI device wakeup notification work function.

 * @context: Device wakeup context.

 Clear PME Status if set. */

/**

 * pci_acpi_add_bus_pm_notifier - Register PM notifier for root PCI bus.

 * @dev: PCI root bridge ACPI device.

/**

 * pci_acpi_add_pm_notifier - Register PM notifier for given PCI device.

 * @dev: ACPI device to add the notifier for.

 * @pci_dev: PCI device to check for the PME status if an event is signaled.

/*

 * _SxD returns the D-state with the highest power

 * (lowest D-state number) supported in the S-state "x".

 *

 * If the devices does not have a _PRW

 * (Power Resources for Wake) supporting system wakeup from "x"

 * then the OS is free to choose a lower power (higher number

 * D-state) than the return value from _SxD.

 *

 * But if _PRW is enabled at S-state "x", the OS

 * must not choose a power lower than _SxD --

 * unless the device has an _SxW method specifying

 * the lowest power (highest D-state number) the device

 * may enter while still able to wake the system.

 *

 * ie. depending on global OS policy:

 *

 * if (_PRW at S-state x)

 *	choose from highest power _SxD to lowest power _SxW

 * else // no _PRW at S-state x

 *	choose highest power _SxD or any lower power

/**

 * pci_dev_acpi_reset - do a function level reset using _RST method

 * @dev: device to reset

 * @probe: if true, return 0 if device supports _RST

 Assume D3 support if the bridge is power-manageable by ACPI. */

	/*

	 * The ACPI firmware will provide the device-specific properties through

	 * _DSD configuration object. Look for the 'HotPlugSupportInD3' property

	 * for the root port and if it is set we know the hierarchy behind it

	 * supports D3 just fine.

 If the ACPI device has _EJ0, ignore the device */

 We have reached the root bus. */

	/*

	 * In some cases (eg. Samsung 305V4A) leaving a bridge in suspend over

	 * system-wide suspend/resume confuses the platform firmware, so avoid

	 * doing that.  According to Section 16.1.6 of ACPI 6.2, endpoint

	 * devices are expected to be in D3 before invoking the S3 entry path

	 * from the firmware, so they should not be affected by this issue.

	/*

	 * For a host bridge, check its _DSM for function 8 and if

	 * that is available, mark it in pci_host_bridge.

 ACPI bus type */

/**

 * pci_acpi_set_companion_lookup_hook - Set ACPI companion lookup callback.

 * @func: ACPI companion lookup callback pointer or NULL.

 *

 * Set a special ACPI companion lookup callback for PCI devices whose companion

 * objects in the ACPI namespace have _ADR with non-standard bus-device-function

 * encodings.

 *

 * Return 0 on success or a negative error code on failure (in which case no

 * changes are made).

 *

 * The caller is responsible for the appropriate ordering of the invocations of

 * this function with respect to the enumeration of the PCI devices needing the

 * callback installed by it.

/**

 * pci_acpi_clear_companion_lookup_hook - Clear ACPI companion lookup callback.

 *

 * Clear the special ACPI companion lookup callback previously set by

 * pci_acpi_set_companion_lookup_hook().  Block until the last running instance

 * of the callback returns before clearing it.

 *

 * The caller is responsible for the appropriate ordering of the invocations of

 * this function with respect to the enumeration of the PCI devices needing the

 * callback cleared by it.

 Please ref to ACPI spec for the syntax of _ADR */

	/*

	 * There may be ACPI device objects in the ACPI namespace that are

	 * children of the device object representing the host bridge, but don't

	 * represent PCI devices.  Both _HID and _ADR may be present for them,

	 * even though that is against the specification (for example, see

	 * Section 6.1 of ACPI 6.3), but in many cases the _ADR returns 0 which

	 * appears to indicate that they should not be taken into consideration

	 * as potential companions of PCI devices on the root bus.

	 *

	 * To catch this special case, disregard the returned device object if

	 * it has a valid _HID, addr is 0 and the PCI device at hand is on the

	 * root bus.

/**

 * pci_acpi_optimize_delay - optimize PCI D3 and D3cold delay from ACPI

 * @pdev: the PCI device whose delay is to be updated

 * @handle: ACPI handle of this device

 *

 * Update the d3hot_delay and d3cold_delay of a PCI device from the ACPI _DSM

 * control method of either the device itself or the PCI host bridge.

 *

 * Function 8, "Reset Delay," applies to the entire hierarchy below a PCI

 * host bridge.  If it returns one, the OS may assume that all devices in

 * the hierarchy have already completed power-on reset delays.

 *

 * Function 9, "Device Readiness Durations," applies only to the object

 * where it is located.  It returns delay durations required after various

 * events if the device requires less time than the spec requires.  Delays

 * from this function take precedence over the Reset Delay function.

 *

 * These _DSM functions are defined by the draft ECN of January 28, 2014,

 * titled "ACPI additions for FW latency optimizations."

	/*

	 * These root ports expose PCIe (including DMA) outside of the

	 * system.  Everything downstream from them is external.

	/*

	 * For bridges that can do D3 we enable wake automatically (as

	 * we do for the power management itself in that case). The

	 * reason is that the bridge may have additional methods such as

	 * _DSW that need to be called.

/**

 * pci_msi_register_fwnode_provider - Register callback to retrieve fwnode

 * @fn:       Callback matching a device to a fwnode that identifies a PCI

 *            MSI domain.

 *

 * This should be called by irqchip driver, which is the parent of

 * the MSI domain to provide callback interface to query fwnode.

/**

 * pci_host_bridge_acpi_msi_domain - Retrieve MSI domain of a PCI host bridge

 * @bus:      The PCI host bridge bus.

 *

 * This function uses the callback function registered by

 * pci_msi_register_fwnode_provider() to retrieve the irq_domain with

 * type DOMAIN_BUS_PCI_MSI of the specified host bridge bus.

 * This returns NULL on error or when the domain is not found.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI VPD support

 *

 * Copyright (C) 2010 Broadcom Corporation.

 VPD access through PCI 2.2+ VPD capability */

/**

 * pci_vpd_size - determine actual size of Vital Product Data

 * @dev:	pci device struct

 1 byte tag, 2 bytes length */

 Large Resource Data Type Tag */

 Short Resource Data Type Tag */

 End tag descriptor */

/*

 * Wait for last operation to complete.

 * This code has to spin since there is no other notification from the PCI

 * hardware. Since the VPD is often implemented by serial attachment to an

 * EEPROM, it may take many milliseconds to complete.

 * @set: if true wait for flag to be set, else wait for it to be cleared

 *

 * Returns 0 on success, negative values indicate error.

 look for LRDT tags only, end tag is the only SRDT tag */

/**

 * pci_read_vpd - Read one entry from Vital Product Data

 * @dev:	PCI device struct

 * @pos:	offset in VPD space

 * @count:	number of bytes to read

 * @buf:	pointer to where to store result

 Same, but allow to access any address */

/**

 * pci_write_vpd - Write entry to Vital Product Data

 * @dev:	PCI device struct

 * @pos:	offset in VPD space

 * @count:	number of bytes to write

 * @buf:	buffer containing write data

 Same, but allow to access any address */

 no checksum in VPD */

/*

 * Quirk non-zero PCI functions to route VPD access through function 0 for

 * devices that share VPD resources between functions.  The functions are

 * expected to be identical devices.

/*

 * If a device follows the VPD format spec, the PCI core will not read or

 * write past the VPD End Tag.  But some vendors do not follow the VPD

 * format spec, so we can't tell how much data is safe to access.  Devices

 * may behave unpredictably if we access too much.  Blacklist these devices

 * so we don't touch VPD at all.

/*

 * The Amazon Annapurna Labs 0x0031 device id is reused for other non Root Port

 * device types, so the quirk is registered for the PCI_CLASS_BRIDGE_PCI class.

	/*

	 * If this is a T3-based adapter, there's a 1KB VPD area at offset

	 * 0xc00 which contains the preferred VPD values.  If this is a T4 or

	 * later based adapter, the special VPD is at offset 0x400 for the

	 * Physical Functions (the SR-IOV Virtual Functions have no VPD

	 * Capabilities).  The PCI VPD Access core routines will normally

	 * compute the size of the VPD by parsing the VPD Data Structure at

	 * offset 0x000.  This will result in silent failures when attempting

	 * to accesses these other VPD areas which are beyond those computed

	 * limits.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI searching functions

 *

 * Copyright (C) 1993 -- 1997 Drew Eckhardt, Frederic Potter,

 *					David Mosberger-Tang

 * Copyright (C) 1997 -- 2000 Martin Mares <mj@ucw.cz>

 * Copyright (C) 2003 -- 2004 Greg Kroah-Hartman <greg@kroah.com>

/*

 * pci_for_each_dma_alias - Iterate over DMA aliases for a device

 * @pdev: starting downstream device

 * @fn: function to call for each alias

 * @data: opaque data to pass to @fn

 *

 * Starting @pdev, walk up the bus calling @fn for each possible alias

 * of @pdev at the root bus.

	/*

	 * The device may have an explicit alias requester ID for DMA where the

	 * requester is on another PCI bus.

	/*

	 * If the device is broken and uses an alias requester ID for

	 * DMA, iterate over that too.

 Skip virtual buses */

 stop at bridge where translation unit is associated */

		/*

		 * PCIe-to-PCI/X bridges alias transactions from downstream

		 * devices using the subordinate bus number (PCI Express to

		 * PCI/PCI-X Bridge Spec, rev 1.0, sec 2.3).  For all cases

		 * where the upstream bus is PCI/X we alias to the bridge

		 * (there are various conditions in the previous reference

		 * where the bridge may take ownership of transactions, even

		 * when the secondary interface is PCI-X).

/**

 * pci_find_bus - locate PCI bus from a given domain and bus number

 * @domain: number of PCI domain to search

 * @busnr: number of desired PCI bus

 *

 * Given a PCI bus number and domain number, the desired PCI bus is located

 * in the global list of PCI buses.  If the bus is found, a pointer to its

 * data structure is returned.  If no bus is found, %NULL is returned.

/**

 * pci_find_next_bus - begin or continue searching for a PCI bus

 * @from: Previous PCI bus found, or %NULL for new search.

 *

 * Iterates through the list of known PCI buses.  A new search is

 * initiated by passing %NULL as the @from argument.  Otherwise if

 * @from is not %NULL, searches continue from next device on the

 * global list.

/**

 * pci_get_slot - locate PCI device for a given PCI slot

 * @bus: PCI bus on which desired PCI device resides

 * @devfn: encodes number of PCI slot in which the desired PCI

 * device resides and the logical device number within that slot

 * in case of multi-function devices.

 *

 * Given a PCI bus and slot/function number, the desired PCI device

 * is located in the list of PCI devices.

 * If the device is found, its reference count is increased and this

 * function returns a pointer to its data structure.  The caller must

 * decrement the reference count by calling pci_dev_put().

 * If no device is found, %NULL is returned.

/**

 * pci_get_domain_bus_and_slot - locate PCI device for a given PCI domain (segment), bus, and slot

 * @domain: PCI domain/segment on which the PCI device resides.

 * @bus: PCI bus on which desired PCI device resides

 * @devfn: encodes number of PCI slot in which the desired PCI device

 * resides and the logical device number within that slot in case of

 * multi-function devices.

 *

 * Given a PCI domain, bus, and slot/function number, the desired PCI

 * device is located in the list of PCI devices. If the device is

 * found, its reference count is increased and this function returns a

 * pointer to its data structure.  The caller must decrement the

 * reference count by calling pci_dev_put().  If no device is found,

 * %NULL is returned.

/*

 * pci_get_dev_by_id - begin or continue searching for a PCI device by id

 * @id: pointer to struct pci_device_id to match for the device

 * @from: Previous PCI device found in search, or %NULL for new search.

 *

 * Iterates through the list of known PCI devices.  If a PCI device is found

 * with a matching id a pointer to its device structure is returned, and the

 * reference count to the device is incremented.  Otherwise, %NULL is returned.

 * A new search is initiated by passing %NULL as the @from argument.  Otherwise

 * if @from is not %NULL, searches continue from next device on the global

 * list.  The reference count for @from is always decremented if it is not

 * %NULL.

 *

 * This is an internal function for use by the other search functions in

 * this file.

/**

 * pci_get_subsys - begin or continue searching for a PCI device by vendor/subvendor/device/subdevice id

 * @vendor: PCI vendor id to match, or %PCI_ANY_ID to match all vendor ids

 * @device: PCI device id to match, or %PCI_ANY_ID to match all device ids

 * @ss_vendor: PCI subsystem vendor id to match, or %PCI_ANY_ID to match all vendor ids

 * @ss_device: PCI subsystem device id to match, or %PCI_ANY_ID to match all device ids

 * @from: Previous PCI device found in search, or %NULL for new search.

 *

 * Iterates through the list of known PCI devices.  If a PCI device is found

 * with a matching @vendor, @device, @ss_vendor and @ss_device, a pointer to its

 * device structure is returned, and the reference count to the device is

 * incremented.  Otherwise, %NULL is returned.  A new search is initiated by

 * passing %NULL as the @from argument.  Otherwise if @from is not %NULL,

 * searches continue from next device on the global list.

 * The reference count for @from is always decremented if it is not %NULL.

/**

 * pci_get_device - begin or continue searching for a PCI device by vendor/device id

 * @vendor: PCI vendor id to match, or %PCI_ANY_ID to match all vendor ids

 * @device: PCI device id to match, or %PCI_ANY_ID to match all device ids

 * @from: Previous PCI device found in search, or %NULL for new search.

 *

 * Iterates through the list of known PCI devices.  If a PCI device is

 * found with a matching @vendor and @device, the reference count to the

 * device is incremented and a pointer to its device structure is returned.

 * Otherwise, %NULL is returned.  A new search is initiated by passing %NULL

 * as the @from argument.  Otherwise if @from is not %NULL, searches continue

 * from next device on the global list.  The reference count for @from is

 * always decremented if it is not %NULL.

/**

 * pci_get_class - begin or continue searching for a PCI device by class

 * @class: search for a PCI device with this class designation

 * @from: Previous PCI device found in search, or %NULL for new search.

 *

 * Iterates through the list of known PCI devices.  If a PCI device is

 * found with a matching @class, the reference count to the device is

 * incremented and a pointer to its device structure is returned.

 * Otherwise, %NULL is returned.

 * A new search is initiated by passing %NULL as the @from argument.

 * Otherwise if @from is not %NULL, searches continue from next device

 * on the global list.  The reference count for @from is always decremented

 * if it is not %NULL.

/**

 * pci_dev_present - Returns 1 if device matching the device list is present, 0 if not.

 * @ids: A pointer to a null terminated list of struct pci_device_id structures

 * that describe the type of PCI device the caller is trying to find.

 *

 * Obvious fact: You do not have a reference to any device that might be found

 * by this function, so if that device is removed from the system right after

 * this function is finished, the value will be stale.  Use this function to

 * find devices that are usually built into a system, or for a general hint as

 * to if another device happens to be present at this specific moment in time.

 SPDX-License-Identifier: GPL-2.0

/*

 * Xen PCI Frontend

 *

 * Author: Ryan Wilson <hap9@epoch.ncsc.mil>

 Lock this when doing any operations in sh_info */

 Because we do not expose that information via XenBus. */

 Go */

	/*

	 * We set a poll timeout of 3 seconds but give up on return after

	 * 2 seconds. It is better to time out too late rather than too early

	 * (in the latter case we end up continually re-executing poll() with a

	 * timeout in the past). 1s difference gives plenty of slack for error.

	/*

	 * We might lose backend service request since we

	 * reuse same evtchn with pci_conf backend response. So re-schedule

	 * aer pcifront service.

 Access to this function is spinlocked in drivers/pci/access.c */

 No device here, pretend that it just returned 0 */

 Access to this function is spinlocked in drivers/pci/access.c */

 Vector is useless at this point. */

 we get the result */

 What should do for error ? */

 XXX No response from backend, what shall we do? */

 how can pciback notify us fail? */

 CONFIG_PCI_MSI */

 Claim resources for the PCI frontend as-is, backend won't allow changes */

	/*

	 * Scan the bus for functions and add.

	 * We omit handling of PCI bridge attachment because pciback prevents

	 * bridges from being exported.

 Device is already known. */

	/*

	 * pci_scan_root_bus skips devices which do not have a

	 * devfn==0. The pcifront_scan_bus enumerates all devfn.

 Claim resources before going "live" with our devices */

 Create SysFS and notify udev of the devices. Aka: "going live" */

 If the bus is unknown, create it. */

 Claim resources before going "live" with our devices */

 Create SysFS and notify udev of the devices. Aka: "going live" */

	/*

	 * If a pci_conf op is in progress, we have to wait until it is done

	 * before service aer op

 Post the operation to the guest. */

in case of we lost an aer request in four lines time_window*/

Flag for registering PV AER handler*/

 r/w page */,

 Only connect once */

 Find devices being detached and remove them. */

 Remove device. */

 Missed the backend's CLOSING state */

 enable */);

 disable */);

 SPDX-License-Identifier: GPL-2.0

/*

 * Generic PCI resource mmap helper

 *

 * Copyright © 2017 Amazon.com, Inc. or its affiliates.

 *

 * Author: David Woodhouse <dwmw2@infradead.org>

/*

 * Modern setup: generic pci_mmap_resource_range(), and implement the legacy

 * pci_mmap_page_range() (if needed) as a wrapper round it.

 Adjust vm_pgoff to be the offset within the resource */

 && !ARCH_GENERIC_PCI_MMAP_RESOURCE */

/*

 * Legacy setup: Implement pci_mmap_resource_range() as a wrapper around

 * the architecture's pci_mmap_page_range(), converting to "user visible"

 * addresses as necessary.

	/*

	 * pci_mmap_page_range() expects the same kind of entry as coming

	 * from /proc/bus/pci/ which is a "user visible" value. If this is

	 * different from the resource itself, arch will do necessary fixup.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Message Signaled Interrupt (MSI)

 *

 * Copyright (C) 2003-2004 Intel

 * Copyright (C) Tom Long Nguyen (tom.l.nguyen@intel.com)

 * Copyright (C) 2016 Christoph Hellwig.

 Arch hooks */

	/*

	 * If an architecture wants to support multiple MSI, it needs to

	 * override arch_setup_msi_irqs()

 CONFIG_PCI_MSI_ARCH_FALLBACKS */

/*

 * PCI 2.3 does not specify mask bits for each MSI interrupt.  Attempting to

 * mask all MSI interrupts by clearing the MSI enable bit does not work

 * reliably as devices without an INTx disable bit will then generate a

 * level IRQ which will never be cleared.

 Don't shift by >= width of type */

/*

 * This internal function does not flush PCI writes to the device.  All

 * users must ensure that they read from the device before either assuming

 * that the device state is up to date, or returning out of this file.

 * It does not affect the msi_desc::msix_ctrl cache either. Use with care!

 Flush write to device */

/**

 * pci_msi_mask_irq - Generic IRQ chip callback to mask PCI/MSI interrupts

 * @data:	pointer to irqdata associated to that interrupt

/**

 * pci_msi_unmask_irq - Generic IRQ chip callback to unmask PCI/MSI interrupts

 * @data:	pointer to irqdata associated to that interrupt

 Don't touch the hardware now */

		/*

		 * The specification mandates that the entry is masked

		 * when the message is modified:

		 *

		 * "If software changes the Address or Data value of an

		 * entry while the entry is unmasked, the result is

		 * undefined."

 Ensure that the writes are visible in the device */

 Ensure that the writes are visible in the device */

 route the table */

 MSI Entry Initialization */

 Lies, damned lies, and MSIs */

 Save IOAPIC IRQ */

 Save the initial mask status */

/**

 * msi_capability_init - configure device's MSI capability structure

 * @dev: pointer to the pci_dev data structure of MSI device function

 * @nvec: number of interrupts to allocate

 * @affd: description of automatic IRQ affinity assignments (may be %NULL)

 *

 * Setup the MSI capability structure of the device with the requested

 * number of interrupts.  A return value of zero indicates the successful

 * setup of an entry with the new MSI IRQ.  A negative return value indicates

 * an error, and a positive return value indicates the number of interrupts

 * which could have been allocated.

 Disable MSI during set up */

 All MSIs are unmasked by default; mask them all */

 Configure MSI capability structure */

 Set MSI enabled bits	*/

 No enough memory. Don't try again */

/**

 * msix_capability_init - configure device's MSI-X capability

 * @dev: pointer to the pci_dev data structure of MSI-X device function

 * @entries: pointer to an array of struct msix_entry entries

 * @nvec: number of @entries

 * @affd: Optional pointer to enable automatic affinity assignment

 *

 * Setup the MSI-X capability structure of device function with a

 * single MSI-X IRQ. A return of zero indicates the successful setup of

 * requested MSI-X entries with allocated IRQs or non-zero for otherwise.

	/*

	 * Some devices require MSI-X to be enabled before the MSI-X

	 * registers can be accessed.  Mask all the vectors to prevent

	 * interrupts coming in before they're fully set up.

 Request & Map MSI-X table region */

 Ensure that all table entries are masked. */

 Check if all MSI entries honor device restrictions */

 Set MSI-X enabled bits and unmask the function */

		/*

		 * If we had some success, report the number of IRQs

		 * we succeeded in setting up.

/**

 * pci_msi_supported - check whether MSI may be enabled on a device

 * @dev: pointer to the pci_dev data structure of MSI device function

 * @nvec: how many MSIs have been requested?

 *

 * Look at global flags, the device itself, and its parent buses

 * to determine if MSI/-X are supported for the device. If MSI/-X is

 * supported return 1, else return 0.

 MSI must be globally enabled and supported by the device */

	/*

	 * You can't ask to have 0 or less MSIs configured.

	 *  a) it's stupid ..

	 *  b) the list manipulation code assumes nvec >= 1.

	/*

	 * Any bridge which does NOT route MSI transactions from its

	 * secondary bus to its primary bus must set NO_MSI flag on

	 * the secondary pci_bus.

	 *

	 * The NO_MSI flag can either be set directly by:

	 * - arch-specific PCI host bus controller drivers (deprecated)

	 * - quirks for specific PCI bridges

	 *

	 * or indirectly by platform-specific PCI host bridge drivers by

	 * advertising the 'msi_domain' property, which results in

	 * the NO_MSI flag when no MSI domain is found for this bridge

	 * at probe time.

/**

 * pci_msi_vec_count - Return the number of MSI vectors a device can send

 * @dev: device to report about

 *

 * This function returns the number of MSI vectors a device requested via

 * Multiple Message Capable register. It returns a negative errno if the

 * device is not capable sending MSI interrupts. Otherwise, the call succeeds

 * and returns a power of two, up to a maximum of 2^5 (32), according to the

 * MSI specification.

 Return the device with MSI unmasked as initial states */

 Restore dev->irq to its default pin-assertion IRQ */

/**

 * pci_msix_vec_count - return the number of device's MSI-X table entries

 * @dev: pointer to the pci_dev data structure of MSI-X device function

 * This function returns the number of device's MSI-X table entries and

 * therefore the number of MSI-X vectors device is capable of sending.

 * It returns a negative errno if the device is not capable of sending MSI-X

 * interrupts.

 Check for any invalid entries */

 invalid entry */

 duplicate entry */

 Check whether driver already requested for MSI IRQ */

 Return the device with MSI-X masked as initial states */

/**

 * pci_msi_enabled - is MSI enabled?

 *

 * Returns true if MSI has not been disabled by the command-line option

 * pci=nomsi.

 Check whether driver already requested MSI-X IRQs */

 deprecated, don't use */

/**

 * pci_enable_msix_range - configure device's MSI-X capability structure

 * @dev: pointer to the pci_dev data structure of MSI-X device function

 * @entries: pointer to an array of MSI-X entries

 * @minvec: minimum number of MSI-X IRQs requested

 * @maxvec: maximum number of MSI-X IRQs requested

 *

 * Setup the MSI-X capability structure of device function with a maximum

 * possible number of interrupts in the range between @minvec and @maxvec

 * upon its software driver call to request for MSI-X mode enabled on its

 * hardware device function. It returns a negative errno if an error occurs.

 * If it succeeds, it returns the actual number of interrupts allocated and

 * indicates the successful configuration of MSI-X capability structure

 * with new allocated MSI-X interrupts.

/**

 * pci_alloc_irq_vectors_affinity - allocate multiple IRQs for a device

 * @dev:		PCI device to operate on

 * @min_vecs:		minimum number of vectors required (must be >= 1)

 * @max_vecs:		maximum (desired) number of vectors

 * @flags:		flags or quirks for the allocation

 * @affd:		optional description of the affinity requirements

 *

 * Allocate up to @max_vecs interrupt vectors for @dev, using MSI-X or MSI

 * vectors if available, and fall back to a single legacy vector

 * if neither is available.  Return the number of vectors allocated,

 * (which might be smaller than @max_vecs) if successful, or a negative

 * error code on error. If less than @min_vecs interrupt vectors are

 * available for @dev the function will fail with -ENOSPC.

 *

 * To get the Linux IRQ number used for a vector that can be passed to

 * request_irq() use the pci_irq_vector() helper.

 use legacy IRQ if allowed */

			/*

			 * Invoke the affinity spreading logic to ensure that

			 * the device driver can adjust queue configuration

			 * for the single interrupt case.

/**

 * pci_free_irq_vectors - free previously allocated IRQs for a device

 * @dev:		PCI device to operate on

 *

 * Undoes the allocations and enabling in pci_alloc_irq_vectors().

/**

 * pci_irq_vector - return Linux IRQ number of a device vector

 * @dev: PCI device to operate on

 * @nr: device-relative interrupt vector index (0-based).

/**

 * pci_irq_get_affinity - return the affinity of a particular MSI vector

 * @dev:	PCI device to operate on

 * @nr:		device-relative interrupt vector index (0-based).

/**

 * pci_msi_domain_write_msg - Helper to write MSI message to PCI config space

 * @irq_data:	Pointer to interrupt data of the MSI interrupt

 * @msg:	Pointer to the message

	/*

	 * For MSI-X desc->irq is always equal to irq_data->irq. For

	 * MSI only the first interrupt of MULTI MSI passes the test.

/**

 * pci_msi_domain_calc_hwirq - Generate a unique ID for an MSI source

 * @desc:	Pointer to the MSI descriptor

 *

 * The ID number is only used within the irqdomain.

/**

 * pci_msi_domain_check_cap - Verify that @domain supports the capabilities

 * 			      for @dev

 * @domain:	The interrupt domain to check

 * @info:	The domain info for verification

 * @dev:	The device to check

 *

 * Returns:

 *  0 if the functionality is supported

 *  1 if Multi MSI is requested, but the domain does not support it

 *  -ENOTSUPP otherwise

 Special handling to support __pci_enable_msi_range() */

 Special handling to support __pci_enable_msi_range() */

/**

 * pci_msi_create_irq_domain - Create a MSI interrupt domain

 * @fwnode:	Optional fwnode of the interrupt controller

 * @info:	MSI domain info

 * @parent:	Parent irq domain

 *

 * Updates the domain and chip ops and creates a MSI interrupt domain.

 *

 * Returns:

 * A domain pointer or NULL in case of failure.

 PCI-MSI is oneshot-safe */

/*

 * Users of the generic MSI infrastructure expect a device to have a single ID,

 * so with DMA aliases we have to pick the least-worst compromise. Devices with

 * DMA phantom functions tend to still emit MSIs from the real function number,

 * so we ignore those and only consider topological aliases where either the

 * alias device or RID appears on a different bus number. We also make the

 * reasonable assumption that bridges are walked in an upstream direction (so

 * the last one seen wins), and the much braver assumption that the most likely

 * case is that of PCI->PCIe so we should always use the alias RID. This echoes

 * the logic from intel_irq_remapping's set_msi_sid(), which presumably works

 * well enough in practice; in the face of the horrible PCIe<->PCI-X conditions

 * for taking ownership all we can really do is close our eyes and hope...

/**

 * pci_msi_domain_get_msi_rid - Get the MSI requester id (RID)

 * @domain:	The interrupt domain

 * @pdev:	The PCI device.

 *

 * The RID for a device is formed from the alias, with a firmware

 * supplied mapping applied

 *

 * Returns: The RID.

/**

 * pci_msi_get_device_domain - Get the MSI domain for a given PCI device

 * @pdev:	The PCI device

 *

 * Use the firmware data to find a device-specific MSI domain

 * (i.e. not one that is set as a default).

 *

 * Returns: The corresponding MSI domain or NULL if none has been found.

/**

 * pci_dev_has_special_msi_domain - Check whether the device is handled by

 *				    a non-standard PCI-MSI domain

 * @pdev:	The PCI device to check.

 *

 * Returns: True if the device irqdomain or the bus irqdomain is

 * non-standard PCI/MSI.

 CONFIG_PCI_MSI_IRQ_DOMAIN */

 CONFIG_PCI_MSI */

	/*

	 * Disable the MSI hardware to avoid screaming interrupts

	 * during boot.  This is the power on reset default so

	 * usually this should be a noop.

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI <-> OF mapping helpers

 *

 * Copyright 2011 IBM Corp.

 This should only be called for PHBs */

	/*

	 * Look for a node pointer in either the intermediary device we

	 * create above the root bus or its own parent. Normally only

	 * the later is populated.

 Start looking for a phandle to an MSI controller. */

	/*

	 * If we don't have an msi-parent property, look for a domain

	 * directly attached to the host bridge.

		/*

		 * Some OFs create a parent node "multifunc-device" as

		 * a fake root for all functions of a multi-function

		 * device we go down them as well.

/**

 * of_pci_get_devfn() - Get device and function numbers for a device node

 * @np: device node

 *

 * Parses a standard 5-cell PCI resource and returns an 8-bit value that can

 * be passed to the PCI_SLOT() and PCI_FUNC() macros to extract the device

 * and function numbers respectively. On error a negative error code is

 * returned.

/**

 * of_pci_parse_bus_range() - parse the bus-range property of a PCI device

 * @node: device node

 * @res: address to a struct resource to return the bus-range

 *

 * Returns 0 on success or a negative error-code on failure.

/**

 * of_get_pci_domain_nr - Find the host bridge domain number

 *			  of the given device node.

 * @node: Device tree node with the domain information.

 *

 * This function will try to obtain the host bridge domain number by finding

 * a property called "linux,pci-domain" of the given device node.

 *

 * Return:

 * * > 0	- On success, an associated domain number.

 * * -EINVAL	- The property "linux,pci-domain" does not exist.

 * * -ENODATA	- The linux,pci-domain" property does not have value.

 * * -EOVERFLOW	- Invalid "linux,pci-domain" property value.

 *

 * Returns the associated domain number from DT in the range [0-0xffff], or

 * a negative value if the required property is not found.

/**

 * of_pci_check_probe_only - Setup probe only mode if linux,pci-probe-only

 *                           is present and valid

/**

 * devm_of_pci_get_host_bridge_resources() - Resource-managed parsing of PCI

 *                                           host bridge resources from DT

 * @dev: host bridge device

 * @busno: bus number associated with the bridge root bus

 * @bus_max: maximum number of buses for this bridge

 * @resources: list where the range of resources will be added after DT parsing

 * @ib_resources: list where the range of inbound resources (with addresses

 *                from 'dma-ranges') will be added after DT parsing

 * @io_base: pointer to a variable that will contain on return the physical

 * address for the start of the I/O range. Can be NULL if the caller doesn't

 * expect I/O ranges to be present in the device tree.

 *

 * This function will parse the "ranges" property of a PCI host bridge device

 * node and setup the resource mapping based on its content. It is expected

 * that the property conforms with the Power ePAPR document.

 *

 * It returns zero if the range parsing has been successful or a standard error

 * value if it failed.

 Check for ranges property */

 Read next ranges element */

		/*

		 * If we failed translation or got a zero-sized region

		 * then skip this range

 Check for dma-ranges property */

		/*

		 * If we failed translation or got a zero-sized region

		 * then skip this range

 Keep the resource list sorted */

/**

 * of_irq_parse_pci - Resolve the interrupt for a PCI device

 * @pdev:       the device whose interrupt is to be resolved

 * @out_irq:    structure of_phandle_args filled by this function

 *

 * This function resolves the PCI interrupt for a given PCI device. If a

 * device-node exists for a given pci_dev, it will use normal OF tree

 * walking. If not, it will implement standard swizzling and walk up the

 * PCI tree until an device-node is found, at which point it will finish

 * resolving using the OF tree walking.

	/*

	 * Check if we have a device node, if yes, fallback to standard

	 * device tree parsing

	/*

	 * Ok, we don't, time to have fun. Let's start by building up an

	 * interrupt spec.  we assume #interrupt-cells is 1, which is standard

	 * for PCI. If you do different, then don't use that routine.

 No pin, exit with no error message. */

 Local interrupt-map in the device node? Use it! */

 Now we walk up the PCI tree */

 Get the pci_dev of our parent */

 Ouch, it's a host bridge... */

 No node for host bridge ? give up */

 We found a P2P bridge, check if it has a node */

		/*

		 * Ok, we have found a parent with a device-node, hand over to

		 * the OF parsing code.

		 * We build a unit address from the linux device to be used for

		 * resolution. Note that we use the linux bus number which may

		 * not match your firmware bus numbering.

		 * Fortunately, in most cases, interrupt-map-mask doesn't

		 * include the bus number as part of the matching.

		 * You should still be careful about that though if you intend

		 * to rely on this function (you ship a firmware that doesn't

		 * create device nodes for all PCI devices).

		/*

		 * We can only get here if we hit a P2P bridge with no node;

		 * let's do standard swizzling and try again

/**

 * of_irq_parse_and_map_pci() - Decode a PCI IRQ from the device tree and map to a VIRQ

 * @dev: The PCI device needing an IRQ

 * @slot: PCI slot number; passed when used as map_irq callback. Unused

 * @pin: PCI IRQ pin number; passed when used as map_irq callback. Unused

 *

 * @slot and @pin are unused, but included in the function so that this

 * function can be used directly as the map_irq callback to

 * pci_assign_irq() and struct pci_host_bridge.map_irq pointer

 Proper return code 0 == NO_IRQ */

 CONFIG_OF_IRQ */

 CONFIG_PCI */

/**

 * of_pci_get_max_link_speed - Find the maximum link speed of the given device node.

 * @node: Device tree node with the maximum link speed information.

 *

 * This function will try to find the limitation of link speed by finding

 * a property called "max-link-speed" of the given device node.

 *

 * Return:

 * * > 0	- On success, a maximum link speed.

 * * -EINVAL	- Invalid "max-link-speed" property value, or failure to access

 *		  the property of the device tree node.

 *

 * Returns the associated max link speed from DT, or a negative value if the

 * required property is not found or is invalid.

 SPDX-License-Identifier: GPL-2.0

/*

 * This file contains work-arounds for many known PCI hardware bugs.

 * Devices present only on certain architectures (host bridges et cetera)

 * should be handled in arch-specific code.

 *

 * Note: any quirks for hotpluggable devices must _NOT_ be declared __init.

 *

 * Copyright (c) 1999 Martin Mares <mj@ucw.cz>

 *

 * Init/reset quirks for USB host controllers should be in the USB quirks

 * file, where their drivers can use them.

 isa_dma_bridge_buggy */

 stupid compiler warning, you would think with an enum... */

		/*

		 * If arch hasn't set it explicitly yet, use the CLS

		 * value shared by all PCI devices.  If there's a

		 * mismatch, fall back to the default value.

/*

 * Decoding should be disabled for a PCI device during BAR sizing to avoid

 * conflict. But doing so may cause problems on host bridge and perhaps other

 * key system devices. For devices that need to have mmio decoding always-on,

 * we need to set the dev->mmio_always_on bit.

/*

 * The Mellanox Tavor device gives false positive parity errors.  Disable

 * parity error reporting.

/*

 * Deal with broken BIOSes that neglect to enable passive release,

 * which can cause problems in combination with the 82441FX/PPro MTRRs

	/*

	 * We have to make sure a particular bit is set in the PIIX3

	 * ISA bridge, so we have to go out and find it.

/*

 * The VIA VP2/VP3/MVP3 seem to have some 'features'. There may be a

 * workaround but VIA don't answer queries. If you happen to have good

 * contacts at VIA ask them for me please -- Alan

 *

 * This appears to be BIOS not version dependent. So presumably there is a

 * chipset level fix.

/*

 * It's not totally clear which chipsets are the problematic ones.  We know

 * 82C586 and 82C596 variants are affected.

/*

 * Intel NM10 "TigerPoint" LPC PM1a_STS.BM_STS must be clear

 * for some HT machines to use C4 w/o hanging.

 Chipsets where PCI->PCI transfers vanish or hang */

 Erratum 24 */

 Triton requires workarounds to be used by the drivers */

/*

 * VIA Apollo KT133 needs PCI latency patch

 * Made according to a Windows driver-based patch by George E. Breese;

 * see PCI Latency Adjust on http://www.viahardware.com/download/viatweak.shtm

 * Also see http://www.au-ja.org/review-kt133a-1-en.phtml for the info on

 * which Mr Breese based his work.

 *

 * Updated based on further information from the site and also on

 * information provided by VIA

	/*

	 * Ok, we have a potential problem chipset here. Now see if we have

	 * a buggy southbridge.

		/*

		 * 0x40 - 0x4f == 686B, 0x10 - 0x2f == 686A;

		 * thanks Dan Hollis.

		 * Check for buggy part revisions

 No problem parts */

 Check for buggy part revisions */

	/*

	 * Ok we have the problem. Now set the PCI master grant to occur

	 * every master grant. The apparent bug is that under high PCI load

	 * (quite common in Linux of course) you can get data loss when the

	 * CPU is held off the bus for 3 bus master requests.  This happens

	 * to include the IDE controllers....

	 *

	 * VIA only apply this fix when an SB Live! is present but under

	 * both Linux and Windows this isn't enough, and we have seen

	 * corruption without SB Live! but with things like 3 UDMA IDE

	 * controllers. So we ignore that bit of the VIA recommendation..

	/*

	 * Set bit 4 and bit 5 of byte 76 to 0x01

	 * "Master priority rotation on every PCI master grant"

 Must restore this on a resume from RAM */

 VIA Apollo VP3 needs ETBF on BT848/878 */

/*

 * ALi Magik requires workarounds to be used by the drivers that DMA to AGP

 * space. Latency must be set to 0xA and Triton workaround applied too.

 * [Info kindly provided by ALi]

 Natoma has some interesting boundary conditions with Zoran stuff at least */

/*

 * This chip can cause PCI parity errors if config register 0xA0 is read

 * while DMAs are occurring.

/*

 * This chip can cause bus lockups if config addresses above 0x600

 * are read or written.

  On IBM Crocodile ipr SAS adapters, expand BAR to system page size */

/*

 * S3 868 and 968 chips report region size equal to 32M, but they decode 64M.

 * If it's needed, re-allocate the region.

 Convert from PCI bus to resource space */

/*

 * Some CS5536 BIOSes (for example, the Soekris NET5501 board w/ comBIOS

 * ver. 1.33  20070103) don't set the correct ISA PCI region header info.

 * BAR0 should be 8 bytes; instead, it may be set to something like 8k

 * (which conflicts w/ BAR1's memory range).

 *

 * CS553x's ISA PCI BARs may also be read-only (ref:

 * https://bugzilla.kernel.org/show_bug.cgi?id=85991 - Comment #4 forward).

 SMB */

 GPIO */

 MFGPT */

 Convert from PCI bus to resource space */

/*

 * ATI Northbridge setups MCE the processor if you even read somewhere

 * between 0x3b0->0x3bb or read 0x3d3

 Mae rhaid i ni beidio ag edrych ar y lleoliadiau I/O hyn */

/*

 * In the AMD NL platform, this device ([1022:7912]) has a class code of

 * PCI_CLASS_SERIAL_USB_XHCI (0x0c0330), which means the xhci driver will

 * claim it.

 *

 * But the dwc3 driver is a more specific driver for this device, and we'd

 * prefer to use it instead of xhci. To prevent xhci from claiming the

 * device, change the class code to 0x0c03fe, which the PCI r3.0 spec

 * defines as "USB device (not host controller)". The dwc3 driver can then

 * claim it based on its Vendor and Device ID.

 Use "USB Device (not host controller)" class */

/*

 * Synopsys USB 3.x host HAPS platform has a class code of

 * PCI_CLASS_SERIAL_USB_XHCI, and xhci driver can claim it.  However, these

 * devices should use dwc3-haps driver.  Change these devices' class code to

 * PCI_CLASS_SERIAL_USB_DEVICE to prevent the xhci-pci driver from claiming

 * them.

/*

 * Let's make the southbridge information explicit instead of having to

 * worry about people probing the ACPI areas, for example.. (Yes, it

 * happens, and if you read the wrong ACPI register it will put the machine

 * to sleep with no way of waking it up again. Bummer).

 *

 * ALI M7101: Two IO regions pointed to by words at

 *	0xE0 (64 bytes of ACPI registers)

 *	0xE2 (32 bytes of SMB registers)

	/*

	 * For now we only print it out. Eventually we'll want to

	 * reserve it (at least if it's in the 0x1000+ range), but

	 * let's get enough confirmation reports first.

	/*

	 * For now we only print it out. Eventually we'll want to

	 * reserve it, but let's get enough confirmation reports first.

/*

 * PIIX4 ACPI: Two IO regions pointed to by longwords at

 *	0x40 (64 bytes of ACPI registers)

 *	0x90 (16 bytes of SMB registers)

 * and a few strange programmable PIIX4 device resources.

 Device resource A has enables for some of the other ones */

 Device resource D is just bitfields for static resources */

 Device 12 enabled? */

 Device 13 enabled? */

/*

 * ICH4, ICH4-M, ICH5, ICH5-M ACPI: Three IO regions pointed to by longwords at

 *	0x40 (128 bytes of ACPI, GPIO & TCO registers)

 *	0x58 (64 bytes of GPIO I/O space)

	/*

	 * The check for PCIBIOS_MIN_IO is to ensure we won't create a conflict

	 * with low legacy (and fixed) ports. We don't know the decoding

	 * priority and can't tell whether the legacy device or the one created

	 * here is really at that address.  This happens on boards with broken

	 * BIOSes.

 Enabled? */

		/*

		 * This is not correct. It is 16, 32 or 64 bytes depending on

		 * register D31:F0:ADh bits 5:4.

		 *

		 * But this gets us at least _part_ of it.

	/*

	 * Just print it out for now. We should reserve it after more

	 * debugging.

 Shared ACPI/GPIO decode with all ICH6+ */

 ICH6-specific generic IO decode */

 Enabled? */

 IO base in bits 15:2, mask in bits 23:18, both are dword-based */

	/*

	 * Just print it out for now. We should reserve it after more

	 * debugging.

 ICH7-10 has the same common LPC generic IO decode registers */

 We share the common ACPI/GPIO decode with ICH6 */

 And have 4 ICH7+ generic decodes */

/*

 * VIA ACPI: One IO region pointed to by longword at

 *	0x48 or 0x20 (256 bytes of ACPI registers)

/*

 * VIA VT82C686 ACPI: Three IO region pointed to by (long)words at

 *	0x48 (256 bytes of ACPI registers)

 *	0x70 (128 bytes of hardware monitoring register)

 *	0x90 (16 bytes of SMB registers)

/*

 * VIA VT8235 ISA Bridge: Two IO regions pointed to by words at

 *	0x88 (128 bytes of power management registers)

 *	0xd0 (16 bytes of SMB registers)

/*

 * TI XIO2000a PCIe-PCI Bridge erroneously reports it supports fast

 * back-to-back: Disable fast back-to-back on the secondary bus segment

/*

 * VIA 686A/B: If an IO-APIC is active, we need to route all on-chip

 * devices to the external APIC.

 *

 * TODO: When we have device-specific interrupt routers, this code will go

 * away from quirks.

 nothing routed to external APIC */

 all known bits (4-0) routed to external APIC */

 Offset 0x58: External APIC IRQ output control */

/*

 * VIA 8237: Some BIOSes don't set the 'Bypass APIC De-Assert Message' Bit.

 * This leads to doubled level interrupt rates.

 * Set this bit to get rid of cycle wastage.

 * Otherwise uncritical.

/*

 * The AMD IO-APIC can hang the box when an APIC IRQ is masked.

 * We check all revs >= B0 (yet not in the pre production!) as the bug

 * is currently marked NoFix

 *

 * We have multiple reports of hangs with this chipset that went away with

 * noapic specified. For the moment we assume it's the erratum. We may be wrong

 * of course. However the advice is demonstrably good even if so.

 CONFIG_X86_IO_APIC */

 Fix for improper SR-IOV configuration on Cavium cn88xx RNM device */

/*

 * Some settings of MMRBC can lead to data corruption so block changes.

 * See AMD 8131 HyperTransport PCI-X Tunnel Revision Guide

/*

 * FIXME: it is questionable that quirk_via_acpi() is needed.  It shows up

 * as an ISA bridge, and does not support the PCI_INTERRUPT_LINE register

 * at all.  Therefore it seems like setting the pci_dev's IRQ to the value

 * of the ACPI SCI interrupt is only done for convenience.

 *	-jgarzik

 VIA ACPI device: SCI IRQ line in PCI config byte 0x42 */

 VIA bridges which have VLink */

 See what bridge we have and find the device ranges */

		/*

		 * The VT82C686 is special; it attaches to PCI and can have

		 * any device number. All its subdevices are functions of

		 * that single device.

/*

 * quirk_via_vlink		-	VIA VLink IRQ number update

 * @dev: PCI device

 *

 * If the device we are dealing with is on a PIC IRQ we need to ensure that

 * the IRQ line register which usually is not relevant for PCI cards, is

 * actually written so that interrupts get sent to the right place.

 *

 * We only do this on systems where a VIA south bridge was detected, and

 * only for VIA devices on the motherboard (see quirk_via_bridge above).

 Check if we have VLink at all */

 Don't quirk interrupts outside the legacy IRQ range */

 Internal device ? */

	/*

	 * This is an internal VLink device on a PIC interrupt. The BIOS

	 * ought to have set this but may not have, so we redo it.

 unknown if delay really needed */

/*

 * VIA VT82C598 has its device ID settable and many BIOSes set it to the ID

 * of VT82C597 for backward compatibility.  We need to switch it off to be

 * able to recognize the real type of the chip.

/*

 * CardBus controllers have a legacy base address that enables them to

 * respond as i82365 pcmcia controllers.  We don't want them to do this

 * even if the Linux CardBus driver is not loaded, because the Linux i82365

 * driver does not (and should not) handle CardBus.

/*

 * Following the PCI ordering rules is optional on the AMD762. I'm not sure

 * what the designers were smoking but let's not inhale...

 *

 * To be fair to AMD, it follows the spec by default, it's BIOS people who

 * turn it off!

 Required in this mode */

/*

 * DreamWorks-provided workaround for Dunord I-3000 problem

 *

 * This card decodes and responds to addresses not apparently assigned to

 * it.  We force a larger allocation to ensure that nothing gets put too

 * close to it.

/*

 * i82380FB mobile docking controller: its PCI-to-PCI bridge is subtractive

 * decoding (transparent), and does indicate this in the ProgIf.

 * Unfortunately, the ProgIf value is wrong - 0x80 instead of 0x01.

/*

 * Common misconfiguration of the MediaGX/Geode PCI master that will reduce

 * PCI bandwidth from 70MB/s to 25MB/s.  See the GXM/GXLV/GX1 datasheets

 * found at http://www.national.com/analog for info on what these bits do.

 * <christer@weinigel.se>

/*

 * Ensure C0 rev restreaming is off. This is normally done by the BIOS but

 * in the odd case it is not the results are corruption hence the presence

 * of a Linux check.

 Only C0 requires this */

 set SBX00/Hudson-2 SATA in IDE mode to AHCI mode */

 Serverworks CSB5 IDE does not fully support native mode */

 PCI layer will sort out resources */

 Intel 82801CAM ICH3-M datasheet says IDE modes must be the same */

 Some ATA devices break if put into D3 */

 Quirk the legacy ATA devices only. The AHCI ones are ok */

 ALi loses some register settings that we cannot then restore */

/* VIA comes back fine but we need to keep it alive or ACPI GTM failures

/*

 * This was originally an Alpha-specific thing, but it really fits here.

 * The i82375 PCI/EISA bridge appears as non-classified. Fix that.

/*

 * On ASUS P4B boards, the SMBus PCI Device within the ICH2/4 southbridge

 * is not activated. The myth is that Asus said that they do not want the

 * users to be irritated by just another PCI Device in the Win98 device

 * manager. (see the file prog/hotplug/README.p4b in the lm_sensors

 * package 2.7.0 for details)

 *

 * The SMBus PCI Device can be activated by setting a bit in the ICH LPC

 * bridge. Unfortunately, this device has no subvendor/subdevice ID. So it

 * becomes necessary to do this tweak in two steps -- the chosen trigger

 * is either the Host bridge (preferred) or on-board VGA controller.

 *

 * Note that we used to unhide the SMBus that way on Toshiba laptops

 * (Satellite A40 and Tecra M2) but then found that the thermal management

 * was done by SMM code, which could cause unsynchronized concurrent

 * accesses to the SMBus registers, with potentially bad effects. Thus you

 * should be very careful when adding new entries: if SMM is accessing the

 * Intel SMBus, this is a very good reason to leave it hidden.

 *

 * Likewise, many recent laptops use ACPI for thermal management. If the

 * ACPI DSDT code accesses the SMBus, then Linux should not access it

 * natively, and keeping the SMBus hidden is the right thing to do. If you

 * are about to add an entry in the table below, please first disassemble

 * the DSDT and double-check that there is no code accessing the SMBus.

 P4B-LX */

 P4B */

 P4B533 */

 L3C notebook */

 P4GE-V */

 P4PE */

 P4B533-V */

 P4T533 */

 P4G8X Deluxe */

 PU-DLS */

 M2N notebook */

 M5N notebook */

 A6L notebook */

 W1N notebook */

 M6Ne notebook */

 P4P800-X */

 M6V notebook */

 A6VA notebook */

 HP Compaq nc8000 */

 HP Compaq nc6000 */

 HP D330L */

 HP D530 */

 HP Compaq nx9500 */

 HP xw4100 */

 Samsung P35 notebook */

 Compaq Evo N620c */

 Compaq Deskpro EP 401963-001 (PCA# 010174) */

				/* Motherboard doesn't have Host bridge

				 * subvendor/subdevice IDs, therefore checking

 Compaq Evo D510 CMT */

 Compaq Evo D510 SFF */

 Compaq Evo D510 USDT */

				/* Motherboard doesn't have Host bridge

				 * subvendor/subdevice IDs and on-board VGA

				 * controller is disabled if an AGP card is

				 * inserted, therefore checking USB UHCI

 Compaq Deskpro EN SSF P667 815E */

				/* Motherboard doesn't have host bridge

				 * subvendor/subdevice IDs, therefore checking

 It appears we just have one such device. If not, we have a warning */

 use bits 31:14, 16 kB aligned */

 read the Function Disable register, dword mode only */

 enable the SMBus device */

 SiS 96x south bridge: BIOS typically hides SMBus device...  */

/*

 * ... This is further complicated by the fact that some SiS96x south

 * bridges pretend to be 85C503/5513 instead.  In that case see if we

 * spotted a compatible north bridge to make sure.

 * (pci_find_device() doesn't work yet)

 *

 * We can also enable the sis96x bit in the discovery register..

	/*

	 * Ok, it now shows up as a 96x.  Run the 96x quirk by hand in case

	 * it has already been processed.  (Depends on link order, which is

	 * apparently not guaranteed)

/*

 * On ASUS A8V and A8V Deluxe boards, the onboard AC97 audio controller

 * and MC97 modem controller are disabled when a second PCI soundcard is

 * present. This patch, tweaking the VT8237 ISA bridge, enables them.

 * -- bjd

/*

 * If we are using libata we can drive this chip properly but must do this

 * early on to make the additional device appear during the PCI scanning.

 Only poke fn 0 */

 Clear bit 1, 8, 9, 12-19, 22, 23 */

 Clear bit 24 */

 SATA single port */

 SATA dual ports */

 SATA dual ports */

 The controller should be in single function ahci mode */

 Set 8, 13, 15, 17 */

 Redirect IDE second PATA port to the right spot */

 Enable dual function mode, AHCI on fn 0, IDE fn1 */

 Set the class codes correctly and then direct IDE 0 */

 Set 0, 1, 4, 5, 7, 8, 13, 15, 17, 22, 23 */

 The controller should be in single function IDE mode */

 Set 22, 23 */

 Update pdev accordingly */

	/*

	 * The first BAR is the location of the IO-APIC... we must

	 * not touch this (and it's already covered by the fixmap), so

	 * forcibly insert it into the resource tree.

	/*

	 * The next five BARs all seem to be rubbish, so just clean

	 * them out.

/*

 * HiSilicon KunPeng920 and KunPeng930 have devices appear as PCI but are

 * actually on the AMBA bus. These fake PCI devices can support SVA via

 * SMMU stall feature, by setting dma-can-stall for ACPI platforms.

 *

 * Normally stalling must not be enabled for PCI devices, since it would

 * break the PCI requirement for free-flowing writes and may lead to

 * deadlock.  We expect PCI devices to support ATS and PRI if they want to

 * be fault-tolerant, so there's no ACPI binding to describe anything else,

 * even when a "PCI" device turns out to be a regular old SoC device

 * dressed up as a RCiEP and normal rules don't apply.

	/*

	 * Set the dma-can-stall property on ACPI platforms. Device tree

	 * can set it directly.

/*

 * It's possible for the MSI to get corrupted if SHPC and ACPI are used

 * together on certain PXH-based systems.

/*

 * Some Intel PCI Express chipsets have trouble with downstream device

 * power management.

/*

 * Ryzen5/7 XHCI controllers fail upon resume from runtime suspend or s2idle.

 * https://bugzilla.kernel.org/show_bug.cgi?id=205587

 *

 * The kernel attempts to transition these devices to D3cold, but that seems

 * to be ineffective on the platforms in question; the PCI device appears to

 * remain on in D3hot state. The D3hot-to-D0 transition then requires an

 * extended delay in order to succeed.

	/*

	 * Systems to exclude from boot interrupt reroute quirks

/*

 * Boot interrupts on some chipsets cannot be turned off. For these chipsets,

 * remap the original interrupt in the Linux kernel to the boot interrupt, so

 * that a PCI device's interrupt handler is installed on the boot interrupt

 * line instead.

/*

 * On some chipsets we can disable the generation of legacy INTx boot

 * interrupts.

/*

 * IO-APIC1 on 6300ESB generates boot interrupts, see Intel order no

 * 300641-004US, section 5.7.3.

 *

 * Core IO on Xeon E5 1600/2600/4600, see Intel order no 326509-003.

 * Core IO on Xeon E5 v2, see Intel order no 329188-003.

 * Core IO on Xeon E7 v2, see Intel order no 329595-002.

 * Core IO on Xeon E5 v3, see Intel order no 330784-003.

 * Core IO on Xeon E7 v3, see Intel order no 332315-001US.

 * Core IO on Xeon E5 v4, see Intel order no 333810-002US.

 * Core IO on Xeon E7 v4, see Intel order no 332315-001US.

 * Core IO on Xeon D-1500, see Intel order no 332051-001.

 * Core IO on Xeon Scalable, see Intel order no 610950.

 Bus 0, Dev 29, Func 5 */

 Bus 0, Dev 5, Func 0 */

 Xeon E5 1600/2600/4600	*/

 Xeon E5/E7 V2		*/

 Xeon E5/E7 V3,V4		*/

 Xeon D-1500			*/

 Xeon Scalable Family		*/

/*

 * Device 29 Func 5 Device IDs of IO-APIC

 * containing ABAR—APIC1 Alternate Base Address Register

/*

 * Device 5 Func 0 Device IDs of Core IO modules/hubs

 * containing Coherent Interface Protocol Interrupt Control

 *

 * Device IDs obtained from volume 2 datasheets of commented

 * families above.

 Disable boot interrupts on HT-1000 */

 Disable boot interrupts on AMD and ATI chipsets */

/*

 * NOIOAMODE needs to be disabled to disable "boot interrupts". For AMD 8131

 * rev. A0 and B0, NOIOAMODE needs to be disabled anyway to fix IO-APIC mode

 * (due to an erratum).

 CONFIG_X86_IO_APIC */

/*

 * Toshiba TC86C001 IDE controller reports the standard 8-byte BAR0 size

 * but the PIO transfers won't work if BAR0 falls at the odd 8 bytes.

 * Re-allocate the region if needed...

/*

 * PLX PCI 9050 PCI Target bridge controller has an erratum that prevents the

 * local configuration registers accessible via BAR0 (memory) or BAR1 (i/o)

 * being read correctly if bit 7 of the base address is set.

 * The BAR0 or BAR1 region may be disabled (size 0) or enabled (size 128).

 * Re-allocate the regions to a 256-byte boundary if necessary.

 Fixed in revision 2 (PCI 9052). */

/*

 * The following Meilhaus (vendor ID 0x1402) device IDs (amongst others)

 * may be using the PLX PCI 9050: 0x0630, 0x0940, 0x0950, 0x0960, 0x100b,

 * 0x1400, 0x140a, 0x140b, 0x14e0, 0x14ea, 0x14eb, 0x1604, 0x1608, 0x160c,

 * 0x168f, 0x2000, 0x2600, 0x3000, 0x810a, 0x810b.

 *

 * Currently, device IDs 0x2000 and 0x2600 are used by the Comedi "me_daq"

 * driver.

	/*

	 * These Netmos parts are multiport serial devices with optional

	 * parallel ports.  Even when parallel ports are present, they

	 * are identified as class SERIAL, which means the serial driver

	 * will claim them.  To prevent this, mark them as class OTHER.

	 * These combo devices should be claimed by parport_serial.

	 *

	 * The subdevice ID is of the form 0x00PS, where <P> is the number

	 * of parallel ports and <S> is the number of serial ports.

 Well, this rule doesn't hold for the following 9835 device */

 PCI IDs taken from drivers/net/e100.c */

	/*

	 * Some firmware hands off the e100 with interrupts enabled,

	 * which can cause a flood of interrupts if packets are

	 * received before the driver attaches to the device.  So

	 * disable all e100 interrupts here.  The driver will

	 * re-enable them when it's ready.

	/*

	 * Check that the device is in the D0 power state. If it's not,

	 * there is no point to look any further.

 Convert from PCI bus to resource space.  */

/*

 * The 82575 and 82598 may experience data corruption issues when transitioning

 * out of L0S.  To prevent this we need to disable L0S on the PCIe link.

/*

 * ASM1083/1085 PCIe-PCI bridge devices cause AER timeout errors on the

 * upstream PCIe root port when ASPM is enabled. At least L0s mode is affected;

 * disable both L0s and L1 for now to be safe.

/*

 * Some Pericom PCIe-to-PCI bridges in reverse mode need the PCIe Retrain

 * Link bit cleared after starting the link retrain process to allow this

 * process to finish.

 *

 * Affected devices: PI7C9X110, PI7C9X111SL, PI7C9X130.  See also the

 * Pericom Errata Sheet PI7C9X111SLB_errata_rev1.2_102711.pdf.

	/*

	 * rev 1 ncr53c810 chips don't set the class at all which means

	 * they don't get their resources remapped. Fix that here.

 Enable 1k I/O space granularity on the Intel P64H2 */

/*

 * Under some circumstances, AER is not linked with extended capabilities.

 * Force it to be linked by setting the corresponding control bit in the

 * config space.

	/*

	 * Disable PCI Bus Parking and PCI Master read caching on CX700

	 * which causes unspecified timing errors with a VT6212L on the PCI

	 * bus leading to USB2.0 packet loss.

	 *

	 * This quirk is only enabled if a second (on the external PCI bus)

	 * VT6212L is found -- the CX700 core itself also contains a USB

	 * host controller with the same PCI ID as the VT6212L.

 Count VT6212L instances */

	/*

	 * p should contain the first (internal) VT6212L -- see if we have

	 * an external one by searching again.

 Turn off PCI Bus Parking */

 Turn off PCI Master read caching */

 Set PCI Master Bus time-out to "1x16 PCLK" */

 Disable "Read FIFO Timer" */

 Only CAP the MRRS if the device is a 5719 A0 */

/*

 * Originally in EDAC sources for i82875P: Intel tells BIOS developers to

 * hide device 6 which configures the overflow device access containing the

 * DRBs - this is where we expose device 6.

 * http://www.x86-secret.com/articles/tweak/pat/patsecrets-2.htm

/*

 * Some chipsets do not support MSI. We cannot easily rely on setting

 * PCI_BUS_FLAGS_NO_MSI in its bus flags because there are actually some

 * other buses controlled by the chipset even if Linux is not aware of it.

 * Instead of setting the flag on all buses in the machine, simply disable

 * MSI globally.

 Disable MSI on chipsets that are known to not support it */

/*

 * The APC bridge device in AMD 780 family northbridges has some random

 * OEM subsystem ID in its vendor ID register (erratum 18), so instead

 * we use the possible vendor/device IDs of the host bridge for the

 * declared quirk, and search for the APC bridge by slot number.

/*

 * Go through the list of HyperTransport capabilities and return 1 if a HT

 * MSI capability is found and enabled.

 Check the HyperTransport MSI mapping to know whether MSI is enabled or not */

/*

 * The nVidia CK804 chipset may have 2 HT MSI mappings.  MSI is supported

 * if the MSI capability is set in any of these mappings.

	/*

	 * Check HT MSI cap on this chipset and the root one.  A single one

	 * having MSI is enough to be sure that MSI is supported.

 Force enable MSI mapping capability on HT bridges */

/*

 * The P5N32-SLI motherboards from Asus have a problem with MSI

 * for the MCP55 NIC. It is not yet determined whether the MSI problem

 * also affects other devices. As for now, turn off MSI for this device.

/*

 * PCIe spec r4.0 sec 7.7.1.2 and sec 7.7.2.2 say that if MSI/MSI-X is enabled,

 * then the device can't use INTx interrupts. Tegra's PCIe root ports don't

 * generate MSI interrupts for PME and AER events instead only INTx interrupts

 * are generated. Though Tegra's PCIe root ports can generate MSI interrupts

 * for other events, since PCIe specification doesn't support using a mix of

 * INTx and MSI/MSI-X, it is required to disable MSI interrupts to avoid port

 * service drivers registering their respective ISRs for MSIs.

/*

 * Some versions of the MCP55 bridge from Nvidia have a legacy IRQ routing

 * config register.  This register controls the routing of legacy

 * interrupts from devices that route through the MCP55.  If this register

 * is misprogrammed, interrupts are only sent to the BSP, unlike

 * conventional systems where the IRQ is broadcast to all online CPUs.  Not

 * having this register set properly prevents kdump from booting up

 * properly, so let's make sure that we have it set correctly.

 * Note that this is an undocumented register.

 Check if there is HT MSI cap or enabled on this device */

 found next host bridge? */

 link control */

 link control to */

 don't enable end_device/host_bridge with leaf directly here */

 root did that ! */

 check if there is HT MSI cap or enabled on this device */

 no HT MSI CAP */

	/*

	 * HT MSI mapping should be disabled on devices that are below

	 * a non-Hypertransport host bridge. Locate the host bridge...

 Host bridge is to HT */

 it is not enabled, try to enable it */

 HT MSI is not enabled */

 Host bridge is not to HT, disable HT MSI mapping on this device */

	/*

	 * SB700 MSI issue will be fixed at HW level from revision A21;

	 * we need check PCI REVISION ID of SMBus controller to get SB700

	 * revision.

 AR816X/AR817X/E210X MSI is fixed at HW level from revision 0x18 */

/*

 * Amazon's Annapurna Labs 1c36:0031 Root Ports don't support MSI-X, so it

 * should be disabled on platforms where the device (mistakenly) advertises it.

 *

 * Notice that this quirk also disables MSI (which may work, but hasn't been

 * tested), since currently there is no standard way to disable only MSI-X.

 *

 * The 0031 device id is reused for other non Root Port device types,

 * therefore the quirk is registered for the PCI_CLASS_BRIDGE_PCI class.

 CONFIG_PCI_MSI */

/*

 * Allow manual resource allocation for PCI hotplug bridges via

 * pci=hpmemsize=nnM and pci=hpiosize=nnM parameters. For some PCI-PCI

 * hotplug bridges, like PLX 6254 (former HINT HB6), kernel fails to

 * allocate resources when hotplug device is inserted and PCI bus is

 * rescanned.

/*

 * This is a quirk for the Ricoh MMC controller found as a part of some

 * multifunction chips.

 *

 * This is very similar and based on the ricoh_mmc driver written by

 * Philip Langdale. Thank you for these magic sequences.

 *

 * These chips implement the four main memory card controllers (SD, MMC,

 * MS, xD) and one or both of CardBus or FireWire.

 *

 * It happens that they implement SD and MMC support as separate

 * controllers (and PCI functions). The Linux SDHCI driver supports MMC

 * cards but the chip detects MMC cards in hardware and directs them to the

 * MMC controller - so the SDHCI driver never sees them.

 *

 * To get around this, we must disable the useless MMC controller.  At that

 * point, the SDHCI controller will start seeing them.  It seems to be the

 * case that the relevant PCI registers to deactivate the MMC controller

 * live on PCI function 0, which might be the CardBus controller or the

 * FireWire controller, depending on the particular chip in question

 *

 * This has to be done early, because as soon as we disable the MMC controller

 * other PCI functions shift up one level, e.g. function #2 becomes function

 * #1, and this will confuse the PCI core.

	/*

	 * Disable via CardBus interface

	 *

	 * This must be done via function #0

	/*

	 * Disable via FireWire interface

	 *

	 * This must be done via function #0

	/*

	 * RICOH 0xe822 and 0xe823 SD/MMC card readers fail to recognize

	 * certain types of SD/MMC cards. Lowering the SD base clock

	 * frequency from 200Mhz to 50Mhz fixes this issue.

	 *

	 * 0x150 - SD2.0 mode enable for changing base clock

	 *	   frequency to 50Mhz

	 * 0xe1  - Base clock frequency

	 * 0x32  - 50Mhz new clock frequency

	 * 0xf9  - Key register for 0x150

	 * 0xfc  - key register for 0xe1

CONFIG_MMC_RICOH_MMC*/

/*

 * This is a quirk for masking VT-d spec-defined errors to platform error

 * handling logic. Without this, platforms using Intel 7500, 5500 chipsets

 * (and the derivative chipsets like X58 etc) seem to generate NMI/SMI (based

 * on the RAS config settings of the platform) when a VT-d fault happens.

 * The resulting SMI caused the system to hang.

 *

 * VT-d spec-related errors are already handled by the VT-d OS code, so no

 * need to report the same error through other channels.

 TI 816x devices do not have class code set when in PCIe boot mode */

/*

 * Some PCIe devices do not work reliably with the claimed maximum

 * payload size supported.

 256 bytes */

/*

 * Intel 5000 and 5100 Memory controllers have an erratum with read completion

 * coalescing (which is enabled by default on some BIOSes) and MPS of 256B.

 * Since there is no way of knowing what the PCIe MPS on each fabric will be

 * until all of the devices are discovered and buses walked, read completion

 * coalescing must be disabled.  Unfortunately, it cannot be re-enabled because

 * it is possible to hotplug a device with MPS of 256B.

	/*

	 * Intel erratum specifies bits to change but does not say what

	 * they are.  Keeping them magical until such time as the registers

	 * and values can be explained.

 Intel 5000 series memory controllers and ports 2-7 */

 Intel 5100 series memory controllers and ports 2-7 */

/*

 * Ivytown NTB BAR sizes are misreported by the hardware due to an erratum.

 * To work around this, query the size it should be configured to by the

 * device and modify the resource end to correspond to this new size.

/*

 * Some BIOS implementations leave the Intel GPU interrupts enabled, even

 * though no one is handling them (e.g., if the i915 driver is never

 * loaded).  Additionally the interrupt destination is not set up properly

 * and the interrupt ends up -somewhere-.

 *

 * These spurious interrupts are "sticky" and the kernel disables the

 * (shared) interrupt line after 100,000+ generated interrupts.

 *

 * Fix it by disabling the still enabled interrupts.  This resolves crashes

 * often seen on monitor unplug.

 Check if any interrupt line is still enabled */

/*

 * PCI devices which are on Intel chips can skip the 10ms delay

 * before entering D3 mode.

 C600 Series devices do not need 10ms d3hot_delay */

 Lynxpoint-H PCH devices do not need 10ms d3hot_delay */

 Intel Cherrytrail devices do not need 10ms d3hot_delay */

/*

 * Some devices may pass our check in pci_intx_mask_supported() if

 * PCI_COMMAND_INTX_DISABLE works though they actually do not properly

 * support this feature.

 Ralink RT2800 802.11n PCI */

 Ceton InfiniTV4 */

/*

 * Realtek RTL8169 PCI Gigabit Ethernet Controller (rev 10)

 * Subsystem: Realtek RTL8169/8110 Family PCI Gigabit Ethernet NIC

 *

 * RTL8110SC - Fails under PCI device assignment using DisINTx masking.

/*

 * Intel i40e (XL710/X710) 10/20/40GbE NICs all have broken INTx masking,

 * DisINTx can be set but the interrupt status bit is non-functional.

/*

 * Check ConnectX-4/LX FW version to see if it supports legacy interrupts.

 * If so, don't mark it as broken.

 * FW minor > 99 means older FW version format and no INTx masking support.

 * FW minor < 14 means new FW version format and no INTx masking support.

	/*

	 * Getting here means Connect-IB cards and up. Connect-IB has no INTx

	 * support so shouldn't be checked further

 For ConnectX-4 and ConnectX-4LX, need to check FW support */

 Reading from resource space should be 32b aligned */

/*

 * Some NVIDIA GPU devices do not work with bus reset, SBR needs to be

 * prevented for those affected devices.

/*

 * Some Atheros AR9xxx and QCA988x chips do not behave after a bus reset.

 * The device will throw a Link Down error on AER-capable systems and

 * regardless of AER, config space of the device is never accessible again

 * and typically causes the system to hang or reset when access is attempted.

 * https://lore.kernel.org/r/20140923210318.498dacbd@dualc.maya.org/

/*

 * Root port on some Cavium CN8xxx chips do not successfully complete a bus

 * reset when used with certain child devices.  After the reset, config

 * accesses to the child may fail.

/*

 * Some TI KeyStone C667X devices do not support bus/hot reset.  The PCIESS

 * automatically disables LTSSM when Secondary Bus Reset is received and

 * the device stops working.  Prevent bus reset for these devices.  With

 * this change, the device can be assigned to VMs with VFIO, but it will

 * leak state between VMs.  Reference

 * https://e2e.ti.com/support/processors/f/791/t/954382

	/*

	 * We can't do a bus reset on root bus devices, but an ineffective

	 * PM reset may be better than nothing.

/*

 * Some AMD/ATI GPUS (HD8570 - Oland) report that a D3hot->D0 transition

 * causes a reset (i.e., they advertise NoSoftRst-).  This transition seems

 * to have no effect on the device: it retains the framebuffer contents and

 * monitor sync.  Advertising this support makes other layers, like VFIO,

 * assume pci_reset_function() is viable for this device.  Mark it as

 * unavailable to skip it when testing reset methods.

/*

 * Thunderbolt controllers with broken MSI hotplug signaling:

 * Entire 1st generation (Light Ridge, Eagle Ridge, Light Peak) and part

 * of the 2nd generation (Cactus Ridge 4C up to revision 1, Port Ridge).

/*

 * Apple: Shutdown Cactus Ridge Thunderbolt controller.

 *

 * On Apple hardware the Cactus Ridge Thunderbolt controller needs to be

 * shutdown before suspend. Otherwise the native host interface (NHI) will not

 * be present after resume if a device was plugged in before suspend.

 *

 * The Thunderbolt controller consists of a PCIe switch with downstream

 * bridges leading to the NHI and to the tunnel PCI bridges.

 *

 * This quirk cuts power to the whole chip. Therefore we have to apply it

 * during suspend_noirq of the upstream bridge.

 *

 * Power is automagically restored before resume. No action is needed.

	/*

	 * SXIO/SXFP/SXLF turns off power to the Thunderbolt controller.

	 * We don't know how to turn it back on again, but firmware does,

	 * so we can only use SXIO/SXFP/SXLF if we're suspending via

	 * firmware.

	/*

	 * SXIO and SXLV are present only on machines requiring this quirk.

	 * Thunderbolt bridges in external devices might have the same

	 * device ID as those on the host, but they will not have the

	 * associated ACPI methods. This implicitly checks that we are at

	 * the right bridge.

 magic sequence */

/*

 * Following are device-specific reset methods which can be used to

 * reset a single function if other methods (e.g. FLR, PM D0->D3) are

 * not available.

	/*

	 * http://www.intel.com/content/dam/doc/datasheet/82599-10-gbe-controller-datasheet.pdf

	 *

	 * The 82599 supports FLR on VFs, but FLR support is reported only

	 * in the PF DEVCAP (sec 9.3.10.4), not in the VF DEVCAP (sec 9.5).

	 * Thus we must call pcie_flr() directly without first checking if it is

	 * supported.

 set timeout 10 seconds */

	/*

	 * Clobbering SOUTH_CHICKEN2 register is fine only if the next

	 * driver loaded sets the right bits. However, this's a reset and

	 * the bits have been set by i915 previously, so we clobber

	 * SOUTH_CHICKEN2 register directly here.

 Device-specific reset method for Chelsio T4-based adapters */

	/*

	 * If this isn't a Chelsio T4-based device, return -ENOTTY indicating

	 * that we have no device-specific reset method.

	/*

	 * If this is the "probe" phase, return 0 indicating that we can

	 * reset this device.

	/*

	 * T4 can wedge if there are DMAs in flight within the chip and Bus

	 * Master has been disabled.  We need to have it on till the Function

	 * Level Reset completes.  (BUS_MASTER is disabled in

	 * pci_reset_function()).

	/*

	 * Perform the actual device function reset, saving and restoring

	 * configuration information around the reset.

	/*

	 * T4 also suffers a Head-Of-Line blocking problem if MSI-X interrupts

	 * are disabled when an MSI-X interrupt message needs to be delivered.

	 * So we briefly re-enable MSI-X interrupts for the duration of the

	 * FLR.  The pci_restore_state() below will restore the original

	 * MSI-X state.

	/*

	 * Restore the configuration information (BAR values, etc.) including

	 * the original PCI Configuration Space Command word, and return

	 * success.

/*

 * The Samsung SM961/PM961 controller can sometimes enter a fatal state after

 * FLR where config space reads from the device return -1.  We seem to be

 * able to avoid this condition if we disable the NVMe controller prior to

 * FLR.  This quirk is generic for any NVMe class device requiring similar

 * assistance to quiesce the device prior to FLR.

 *

 * NVMe specification: https://nvmexpress.org/resources/specifications/

 * Revision 1.0e:

 *    Chapter 2: Required and optional PCI config registers

 *    Chapter 3: NVMe control registers

 *    Chapter 7.3: Reset behavior

 Disable controller if enabled */

		/*

		 * Per nvme_disable_ctrl() skip shutdown notification as it

		 * could complete commands to the admin queue.  We only intend

		 * to quiesce the device before reset.

		/*

		 * Some controllers require an additional delay here, see

		 * NVME_QUIRK_DELAY_BEFORE_CHK_RDY.  None of those are yet

		 * supported by this quirk.

 Cap register provides max timeout in 500ms increments */

 Ready status becomes zero on disable complete */

/*

 * Intel DC P3700 NVMe controller will timeout waiting for ready status

 * to change after NVMe enable if the driver starts interacting with the

 * device too soon after FLR.  A 250ms delay after FLR has heuristically

 * proven to produce reliably working results for device assignment cases.

 15 seconds */

 Device-specific reset method for Huawei Intelligent NIC virtual functions */

 Get and check firmware capabilities */

 Set HINIC_VF_FLR_PROC_BIT for the start of FLR */

	/*

	 * The device must recapture its Bus and Device Numbers after FLR

	 * in order generate Completions.  Issue a config write to let the

	 * device capture this information.

 Firmware clears HINIC_VF_FLR_PROC_BIT when reset is complete */

/*

 * These device-specific reset methods are here rather than in a driver

 * because when a host assigns a device to a guest VM, the host may need

 * to reset the device but probably doesn't have a driver for it.

/*

 * https://bugzilla.redhat.com/show_bug.cgi?id=605888

 *

 * Some Ricoh devices use function 0 as the PCIe requester ID for DMA.

/*

 * Marvell 88SE9123 uses function 1 as the requester ID for DMA.  In some

 * SKUs function 1 is present and is a legacy IDE controller, in other

 * SKUs this function is not present, making this a ghost requester.

 * https://bugzilla.kernel.org/show_bug.cgi?id=42679

bugzilla.kernel.org/show_bug.cgi?id=42679#c14 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c47 + c57 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c59 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c78 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c134 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c46 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c135 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c127 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c49 */

bugs.gentoo.org/show_bug.cgi?id=497630 */

bugzilla.kernel.org/show_bug.cgi?id=42679#c117 */

 Lite-On */

 Plextor M6E (Marvell 88SS9183)*/

/*

 * Some devices DMA with the wrong devfn, not just the wrong function.

 * quirk_fixed_dma_alias() uses this table to create fixed aliases, where

 * the alias is "fixed" and independent of the device devfn.

 *

 * For example, the Adaptec 3405 is a PCIe card with an Intel 80333 I/O

 * processor.  To software, this appears as a PCIe-to-PCI/X bridge with a

 * single device on the secondary bus.  In reality, the single exposed

 * device at 0e.0 is the Address Translation Unit (ATU) of the controller

 * that provides a bridge to the internal bus of the I/O processor.  The

 * controller supports private devices, which can be hidden from PCI config

 * space.  In the case of the Adaptec 3405, a private device at 01.0

 * appears to be the DMA engine, which therefore needs to become a DMA

 * alias for the device.

 Adaptec 3405 */

 Adaptec 3805 */

/*

 * A few PCIe-to-PCI bridges fail to expose a PCIe capability, resulting in

 * using the wrong DMA alias for the device.  Some of these devices can be

 * used as either forward or reverse bridges, so we need to test whether the

 * device is operating in the correct mode.  We could probably apply this

 * quirk to PCI_ANY_ID, but for now we'll just use known offenders.  The test

 * is for a non-root, non-PCIe bridge where the upstream device is PCIe and

 * is not a PCIe-to-PCI bridge, then @pdev is actually a PCIe-to-PCI bridge.

bugzilla.kernel.org/show_bug.cgi?id=44881#c46 */

bugzilla.kernel.org/show_bug.cgi?id=44881#c43 */

bugzilla.kernel.org/show_bug.cgi?id=73551 */

 ITE 8893 has the same problem as the 8892 */

bugzilla.kernel.org/show_bug.cgi?id=44881#c49 */

/*

 * MIC x200 NTB forwards PCIe traffic using multiple alien RIDs. They have to

 * be added as aliases to the DMA device in order to allow buffer access

 * when IOMMU is enabled. Following devfns have to match RIT-LUT table

 * programmed in the EEPROM.

/*

 * Intel Visual Compute Accelerator (VCA) is a family of PCIe add-in devices

 * exposing computational units via Non Transparent Bridges (NTB, PEX 87xx).

 *

 * Similarly to MIC x200, we need to add DMA aliases to allow buffer access

 * when IOMMU is enabled.  These aliases allow computational unit access to

 * host memory.  These aliases mark the whole VCA device as one IOMMU

 * group.

 *

 * All possible slot numbers (0x20) are used, since we are unable to tell

 * what slot is used on other side.  This quirk is intended for both host

 * and computational unit sides.  The VCA devices have up to five functions

 * (four for DMA channels and one additional).

/*

 * The IOMMU and interrupt controller on Broadcom Vulcan/Cavium ThunderX2 are

 * associated not at the root bus, but at a bridge below. This quirk avoids

 * generating invalid DMA aliases.

/*

 * Intersil/Techwell TW686[4589]-based video capture cards have an empty (zero)

 * class code.  Fix it.

 Use "Multimedia controller" class */

/*

 * Some devices have problems with Transaction Layer Packets with the Relaxed

 * Ordering Attribute set.  Such devices should mark themselves and other

 * device drivers should check before sending TLPs with RO set.

/*

 * Intel Xeon processors based on Broadwell/Haswell microarchitecture Root

 * Complex have a Flow Control Credit issue which can cause performance

 * problems with Upstream Transaction Layer Packets with Relaxed Ordering set.

/*

 * The AMD ARM A1100 (aka "SEATTLE") SoC has a bug in its PCIe Root Complex

 * where Upstream Transaction Layer Packets with the Relaxed Ordering

 * Attribute clear are allowed to bypass earlier TLPs with Relaxed Ordering

 * set.  This is a violation of the PCIe 3.0 Transaction Ordering Rules

 * outlined in Section 2.4.1 (PCI Express(r) Base Specification Revision 3.0

 * November 10, 2010).  As a result, on this platform we can't use Relaxed

 * Ordering for Upstream TLPs.

/*

 * Per PCIe r3.0, sec 2.2.9, "Completion headers must supply the same

 * values for the Attribute as were supplied in the header of the

 * corresponding Request, except as explicitly allowed when IDO is used."

 *

 * If a non-compliant device generates a completion with a different

 * attribute than the request, the receiver may accept it (which itself

 * seems non-compliant based on sec 2.3.2), or it may handle it as a

 * Malformed TLP or an Unexpected Completion, which will probably lead to a

 * device access timeout.

 *

 * If the non-compliant device generates completions with zero attributes

 * (instead of copying the attributes from the request), we can work around

 * this by disabling the "Relaxed Ordering" and "No Snoop" attributes in

 * upstream devices so they always generate requests with zero attributes.

 *

 * This affects other devices under the same Root Port, but since these

 * attributes are performance hints, there should be no functional problem.

 *

 * Note that Configuration Space accesses are never supposed to have TLP

 * Attributes, so we're safe waiting till after any Configuration Space

 * accesses to do the Root Port fixup.

/*

 * The Chelsio T5 chip fails to copy TLP Attributes from a Request to the

 * Completion it generates.

	/*

	 * This mask/compare operation selects for Physical Function 4 on a

	 * T5.  We only need to fix up the Root Port once for any of the

	 * PFs.  PF[0..3] have PCI Device IDs of 0x50xx, but PF4 is uniquely

	 * 0x54xx so we use that one.

/*

 * pci_acs_ctrl_enabled - compare desired ACS controls with those provided

 *			  by a device

 * @acs_ctrl_req: Bitmask of desired ACS controls

 * @acs_ctrl_ena: Bitmask of ACS controls enabled or provided implicitly by

 *		  the hardware design

 *

 * Return 1 if all ACS controls in the @acs_ctrl_req bitmask are included

 * in @acs_ctrl_ena, i.e., the device provides all the access controls the

 * caller desires.  Return 0 otherwise.

/*

 * AMD has indicated that the devices below do not support peer-to-peer

 * in any system where they are found in the southbridge with an AMD

 * IOMMU in the system.  Multifunction devices that do not support

 * peer-to-peer between functions can claim to support a subset of ACS.

 * Such devices effectively enable request redirect (RR) and completion

 * redirect (CR) since all transactions are redirected to the upstream

 * root complex.

 *

 * https://lore.kernel.org/r/201207111426.q6BEQTbh002928@mail.maya.org/

 * https://lore.kernel.org/r/20120711165854.GM25282@amd.com/

 * https://lore.kernel.org/r/20121005130857.GX4009@amd.com/

 *

 * 1002:4385 SBx00 SMBus Controller

 * 1002:439c SB7x0/SB8x0/SB9x0 IDE Controller

 * 1002:4383 SBx00 Azalia (Intel HDA)

 * 1002:439d SB7x0/SB8x0/SB9x0 LPC host controller

 * 1002:4384 SBx00 PCI to PCI Bridge

 * 1002:4399 SB7x0/SB8x0/SB9x0 USB OHCI2 Controller

 *

 * https://bugzilla.kernel.org/show_bug.cgi?id=81841#c15

 *

 * 1022:780f [AMD] FCH PCI Bridge

 * 1022:7809 [AMD] FCH USB OHCI Controller

 Targeting multifunction devices on the SB (appears on root bus) */

 The IVRS table describes the AMD IOMMU */

 Filter out flags not applicable to multifunction */

	/*

	 * Effectively selects all downstream ports for whole ThunderX1

	 * (which represents 8 SoCs).

 ThunderX1 */

 ThunderX2 */

 ThunderX3 */

	/*

	 * Cavium Root Ports don't advertise an ACS capability.  However,

	 * the RTL internally implements similar protection as if ACS had

	 * Source Validation, Request Redirection, Completion Redirection,

	 * and Upstream Forwarding features enabled.  Assert that the

	 * hardware implements and enables equivalent ACS functionality for

	 * these flags.

	/*

	 * X-Gene Root Ports matching this quirk do not allow peer-to-peer

	 * transactions with others, allowing masking out these bits as if they

	 * were unimplemented in the ACS capability.

/*

 * Many Zhaoxin Root Ports and Switch Downstream Ports have no ACS capability.

 * But the implementation could block peer-to-peer transactions between them

 * and provide ACS-like functionality.

/*

 * Many Intel PCH Root Ports do provide ACS-like features to disable peer

 * transactions and validate bus numbers in requests, but do not provide an

 * actual PCIe ACS capability.  This is the list of device IDs known to fall

 * into that category as provided by Intel in Red Hat bugzilla 1037684.

 Ibexpeak PCH */

 Cougarpoint PCH */

 Pantherpoint PCH */

 Lynxpoint-H PCH */

 Lynxpoint-LP PCH */

 Wildcat PCH */

 Patsburg (X79) PCH */

 Wellsburg (X99) PCH */

 Lynx Point (9 series) PCH */

 Filter out a few obvious non-matches first */

/*

 * These QCOM Root Ports do provide ACS-like features to disable peer

 * transactions and validate bus numbers in requests, but do not provide an

 * actual PCIe ACS capability.  Hardware supports source validation but it

 * will report the issue as Completer Abort instead of ACS Violation.

 * Hardware doesn't support peer-to-peer and each Root Port is a Root

 * Complex with unique segment numbers.  It is not possible for one Root

 * Port to pass traffic to another Root Port.  All PCIe transactions are

 * terminated inside the Root Port.

/*

 * Each of these NXP Root Ports is in a Root Complex with a unique segment

 * number and does provide isolation features to disable peer transactions

 * and validate bus numbers in requests, but does not provide an ACS

 * capability.

	/*

	 * Amazon's Annapurna Labs root ports don't include an ACS capability,

	 * but do include ACS-like functionality. The hardware doesn't support

	 * peer-to-peer transactions via the root port and each has a unique

	 * segment number.

	 *

	 * Additionally, the root ports cannot send traffic to each other.

/*

 * Sunrise Point PCH root ports implement ACS, but unfortunately as shown in

 * the datasheet (Intel 100 Series Chipset Family PCH Datasheet, Vol. 2,

 * 12.1.46, 12.1.47)[1] this chipset uses dwords for the ACS capability and

 * control registers whereas the PCIe spec packs them into words (Rev 3.0,

 * 7.16 ACS Extended Capability).  The bit definitions are correct, but the

 * control register is at offset 8 instead of 6 and we should probably use

 * dword accesses to them.  This applies to the following PCI Device IDs, as

 * found in volume 1 of the datasheet[2]:

 *

 * 0xa110-0xa11f Sunrise Point-H PCI Express Root Port #{0-16}

 * 0xa167-0xa16a Sunrise Point-H PCI Express Root Port #{17-20}

 *

 * N.B. This doesn't fix what lspci shows.

 *

 * The 100 series chipset specification update includes this as errata #23[3].

 *

 * The 200 series chipset (Union Point) has the same bug according to the

 * specification update (Intel 200 Series Chipset Family Platform Controller

 * Hub, Specification Update, January 2017, Revision 001, Document# 335194-001,

 * Errata 22)[4].  Per the datasheet[5], root port PCI Device IDs for this

 * chipset include:

 *

 * 0xa290-0xa29f PCI Express Root port #{0-16}

 * 0xa2e7-0xa2ee PCI Express Root port #{17-24}

 *

 * Mobile chipsets are also affected, 7th & 8th Generation

 * Specification update confirms ACS errata 22, status no fix: (7th Generation

 * Intel Processor Family I/O for U/Y Platforms and 8th Generation Intel

 * Processor Family I/O for U Quad Core Platforms Specification Update,

 * August 2017, Revision 002, Document#: 334660-002)[6]

 * Device IDs from I/O datasheet: (7th Generation Intel Processor Family I/O

 * for U/Y Platforms and 8th Generation Intel ® Processor Family I/O for U

 * Quad Core Platforms, Vol 1 of 2, August 2017, Document#: 334658-003)[7]

 *

 * 0x9d10-0x9d1b PCI Express Root port #{1-12}

 *

 * [1] https://www.intel.com/content/www/us/en/chipsets/100-series-chipset-datasheet-vol-2.html

 * [2] https://www.intel.com/content/www/us/en/chipsets/100-series-chipset-datasheet-vol-1.html

 * [3] https://www.intel.com/content/www/us/en/chipsets/100-series-chipset-spec-update.html

 * [4] https://www.intel.com/content/www/us/en/chipsets/200-series-chipset-pch-spec-update.html

 * [5] https://www.intel.com/content/www/us/en/chipsets/200-series-chipset-pch-datasheet-vol-1.html

 * [6] https://www.intel.com/content/www/us/en/processors/core/7th-gen-core-family-mobile-u-y-processor-lines-i-o-spec-update.html

 * [7] https://www.intel.com/content/www/us/en/processors/core/7th-gen-core-family-mobile-u-y-processor-lines-i-o-datasheet-vol-1.html

 Sunrise Point */

 Union Point */

 7th & 8th Gen Mobile */

 see pci_acs_flags_enabled() */

	/*

	 * SV, TB, and UF are not relevant to multifunction endpoints.

	 *

	 * Multifunction devices are only required to implement RR, CR, and DT

	 * in their ACS capability if they support peer-to-peer transactions.

	 * Devices matching this quirk have been verified by the vendor to not

	 * perform peer-to-peer with other functions, allowing us to mask out

	 * these bits as if they were unimplemented in the ACS capability.

	/*

	 * Intel RCiEP's are required to allow p2p only on translated

	 * addresses.  Refer to Intel VT-d specification, r3.1, sec 3.16,

	 * "Root-Complex Peer to Peer Considerations".

	/*

	 * iProc PAXB Root Ports don't advertise an ACS capability, but

	 * they do not allow peer-to-peer transactions between Root Ports.

	 * Allow each Root Port to be in a separate IOMMU group by masking

	 * SV/RR/CR/UF bits.

 82580 */

 82576 */

 82575 */

 I350 */

 82571 (Quads omitted due to non-ACS switch) */

 I219 */

 QCOM QDF2xxx root ports */

 HXT SD4800 root ports. The ACS design is same as QCOM QDF2xxx */

 Intel PCH root ports */

 Emulex BE3-R */

 Emulex Skyhawk-R */

 Cavium ThunderX */

 Cavium multi-function devices */

 APM X-Gene */

 Ampere Computing */

 Broadcom multi-function device */

 Amazon Annapurna Labs */

 Zhaoxin multi-function devices */

 NXP root ports, xx=16, 12, or 08 cores */

 LX2xx0A : without security features + CAN-FD */

 LX2xx0C : security features + CAN-FD */

 LX2xx0E : security features + CAN */

 LX2xx0N : without security features + CAN */

 LX2xx2A : without security features + CAN-FD */

 LX2xx2C : security features + CAN-FD */

 LX2xx2E : security features + CAN */

 LX2xx2N : without security features + CAN */

 Zhaoxin Root/Downstream Ports */

/*

 * pci_dev_specific_acs_enabled - check whether device provides ACS controls

 * @dev:	PCI device

 * @acs_flags:	Bitmask of desired ACS controls

 *

 * Returns:

 *   -ENOTTY:	No quirk applies to this device; we can't tell whether the

 *		device provides the desired controls

 *   0:		Device does not provide all the desired controls

 *   >0:	Device provides all the controls in @acs_flags

	/*

	 * Allow devices that do not expose standard PCIe ACS capabilities

	 * or control to indicate their support here.  Multi-function express

	 * devices which do not allow internal peer-to-peer between functions,

	 * but do not implement PCIe ACS may wish to return true here.

 Config space offset of Root Complex Base Address register */

 31:14 RCBA address */

 RCBA Enable */

 Backbone Scratch Pad Register */

 Backbone Peer Non-Posted Disable */

 Backbone Peer Posted Disable */

 Upstream Peer Decode Configuration Register */

 5:0 Peer Decode Enable bits */

	/*

	 * Read the RCBA register from the LPC (D31:F0).  PCH root ports

	 * are D28:F* and therefore get probed before LPC, thus we can't

	 * use pci_get_slot()/pci_read_config_dword() here.

	/*

	 * The BSPR can disallow peer cycles, but it's set by soft strap and

	 * therefore read-only.  If both posted and non-posted peer cycles are

	 * disallowed, we're ok.  If either are allowed, then we need to use

	 * the UPDCR to disable peer decodes for each port.  This provides the

	 * PCIe ACS equivalent of PCI_ACS_RR | PCI_ACS_CR | PCI_ACS_UF

 Miscellaneous Port Configuration register */

 MPC: Invalid Receive Bus Number Check Enable */

	/*

	 * When enabled, the IRBNCE bit of the MPC register enables the

	 * equivalent of PCI ACS Source Validation (PCI_ACS_SV), which

	 * ensures that requester IDs fall within the bus number range

	 * of the bridge.  Enable if not already.

/*

 * Currently this quirk does the equivalent of

 * PCI_ACS_SV | PCI_ACS_RR | PCI_ACS_CR | PCI_ACS_UF

 *

 * TODO: This quirk also needs to do equivalent of PCI_ACS_TB,

 * if dev->external_facing || dev->untrusted

/*

 * The PCI capabilities list for Intel DH895xCC VFs (device ID 0x0443) with

 * QuickAssist Technology (QAT) is prematurely terminated in hardware.  The

 * Next Capability pointer in the MSI Capability Structure should point to

 * the PCIe Capability Structure but is incorrectly hardwired as 0 terminating

 * the list.

 Bail if the hardware bug is fixed */

 Bail if MSI Capability Structure is not found for some reason */

	/*

	 * Bail if Next Capability pointer in the MSI Capability Structure

	 * is not the expected incorrect 0x00.

	/*

	 * PCIe Capability Structure is expected to be at 0x50 and should

	 * terminate the list (Next Capability pointer is 0x00).  Verify

	 * Capability Id and Next Capability pointer is as expected.

	 * Open-code some of set_pcie_port_type() and pci_cfg_space_size_ext()

	 * to correctly set kernel data structures which have already been

	 * set incorrectly due to the hardware bug.

 Save PCIe cap */

/*

 * FLR may cause the following to devices to hang:

 *

 * AMD Starship/Matisse HD Audio Controller 0x1487

 * AMD Starship USB 3.0 Host Controller 0x148c

 * AMD Matisse USB 3.0 Host Controller 0x149c

 * Intel 82579LM Gigabit Ethernet Controller 0x1502

 * Intel 82579V Gigabit Ethernet Controller 0x1503

 *

/*

 * Some devices require additional driver setup to enable ATS.  Don't use

 * ATS for those devices as ATS will be enabled before the driver has had a

 * chance to load and configure the device.

 AMD Stoney platform GPU */

 AMD Iceland dGPU */

 AMD Navi10 dGPU */

 AMD Navi14 dGPU */

 AMD Raven platform iGPU */

 CONFIG_PCI_ATS */

 Freescale PCIe doesn't support MSI in RC mode */

/*

 * Although not allowed by the spec, some multi-function devices have

 * dependencies of one function (consumer) on another (supplier).  For the

 * consumer to work in D0, the supplier must also be in D0.  Create a

 * device link from the consumer to the supplier to enforce this

 * dependency.  Runtime PM is allowed by default on the consumer to prevent

 * it from permanently keeping the supplier awake.

/*

 * Create device link for GPUs with integrated HDA controller for streaming

 * audio to attached displays.

/*

 * Create device link for GPUs with integrated USB xHCI Host

 * controller to VGA.

/*

 * Create device link for GPUs with integrated Type-C UCSI controller

 * to VGA. Currently there is no class code defined for UCSI device over PCI

 * so using UNKNOWN class for now and it will be updated when UCSI

 * over PCI gets a class code.

/*

 * Enable the NVIDIA GPU integrated HDA controller if the BIOS left it

 * disabled.  https://devtalk.nvidia.com/default/topic/1024022

 There was no integrated HDA controller before MCP89 */

 Bit 25 at offset 0x488 enables the HDA controller */

 The GPU becomes a multi-function device when the HDA is enabled */

/*

 * Some IDT switches incorrectly flag an ACS Source Validation error on

 * completions for config read requests even though PCIe r4.0, sec

 * 6.12.1.1, says that completions are never affected by ACS Source

 * Validation.  Here's the text of IDT 89H32H8G3-YC, erratum #36:

 *

 *   Item #36 - Downstream port applies ACS Source Validation to Completions

 *   Section 6.12.1.1 of the PCI Express Base Specification 3.1 states that

 *   completions are never affected by ACS Source Validation.  However,

 *   completions received by a downstream port of the PCIe switch from a

 *   device that has not yet captured a PCIe bus number are incorrectly

 *   dropped by ACS Source Validation by the switch downstream port.

 *

 * The workaround suggested by IDT is to issue a config write to the

 * downstream device before issuing the first config read.  This allows the

 * downstream device to capture its bus and device numbers (see PCIe r4.0,

 * sec 2.2.9), thus avoiding the ACS error on the completion.

 *

 * However, we don't know when the device is ready to accept the config

 * write, so we do config reads until we receive a non-Config Request Retry

 * Status, then do the config write.

 *

 * To avoid hitting the erratum when doing the config reads, we disable ACS

 * SV around this process.

 Disable ACS SV before initial config reads */

 Write Vendor ID (read-only) so the endpoint latches its bus/dev */

 Re-enable ACS_SV if it was previously enabled */

/*

 * Microsemi Switchtec NTB uses devfn proxy IDs to move TLPs between

 * NT endpoints via the internal switch fabric. These IDs replace the

 * originating requestor ID TLPs which access host memory on peer NTB

 * ports. Therefore, all proxy IDs must be aliased to the NTB device

 * to permit access when the IOMMU is turned on.

 PFX 24xG3 */

 PFX 32xG3 */

 PFX 48xG3 */

 PFX 64xG3 */

 PFX 80xG3 */

 PFX 96xG3 */

 PSX 24xG3 */

 PSX 32xG3 */

 PSX 48xG3 */

 PSX 64xG3 */

 PSX 80xG3 */

 PSX 96xG3 */

 PAX 24XG3 */

 PAX 32XG3 */

 PAX 48XG3 */

 PAX 64XG3 */

 PAX 80XG3 */

 PAX 96XG3 */

 PFXL 24XG3 */

 PFXL 32XG3 */

 PFXL 48XG3 */

 PFXL 64XG3 */

 PFXL 80XG3 */

 PFXL 96XG3 */

 PFXI 24XG3 */

 PFXI 32XG3 */

 PFXI 48XG3 */

 PFXI 64XG3 */

 PFXI 80XG3 */

 PFXI 96XG3 */

 PFX 100XG4 */

 PFX 84XG4  */

 PFX 68XG4  */

 PFX 52XG4  */

 PFX 36XG4  */

 PFX 28XG4  */

 PSX 100XG4 */

 PSX 84XG4  */

 PSX 68XG4  */

 PSX 52XG4  */

 PSX 36XG4  */

 PSX 28XG4  */

 PAX 100XG4 */

 PAX 84XG4  */

 PAX 68XG4  */

 PAX 52XG4  */

 PAX 36XG4  */

 PAX 28XG4  */

/*

 * The PLX NTB uses devfn proxy IDs to move TLPs between NT endpoints.

 * These IDs are used to forward responses to the originator on the other

 * side of the NTB.  Alias all possible IDs to the NTB to permit access when

 * the IOMMU is turned on.

 PLX NTB may use all 256 devfns */

/*

 * On Lenovo Thinkpad P50 SKUs with a Nvidia Quadro M1000M, the BIOS does

 * not always reset the secondary Nvidia GPU between reboots if the system

 * is configured to use Hybrid Graphics mode.  This results in the GPU

 * being left in whatever state it was in during the *previous* boot, which

 * causes spurious interrupts from the GPU, which in turn causes us to

 * disable the wrong IRQ and end up breaking the touchpad.  Unsurprisingly,

 * this also completely breaks nouveau.

 *

 * Luckily, it seems a simple reset of the Nvidia GPU brings it back to a

 * clean state and fixes all these issues.

 *

 * When the machine is configured in Dedicated display mode, the issue

 * doesn't occur.  Fortunately the GPU advertises NoReset+ when in this

 * mode, so we can detect that and avoid resetting it.

	/*

	 * Based on nvkm_device_ctor() in

	 * drivers/gpu/drm/nouveau/nvkm/engine/device/base.c

	/*

	 * Make sure the GPU looks like it's been POSTed before resetting

	 * it.

/*

 * Device [1b21:2142]

 * When in D0, PME# doesn't get asserted when plugging USB 3.0 device.

/*

 * Device 12d8:0x400e [OHCI] and 12d8:0x400f [EHCI]

 *

 * These devices advertise PME# support in all power states but don't

 * reliably assert it.

 *

 * These devices also advertise MSI, but documentation (PI7C9X440SL.pdf)

 * says "The MSI Function is not implemented on this device" in chapters

 * 7.3.27, 7.3.29-7.3.31.

/*

 * Pericom PI7C9X2G404/PI7C9X2G304/PI7C9X2G303 switch erratum E5 -

 * ACS P2P Request Redirect is not functional

 *

 * When ACS P2P Request Redirect is enabled and bandwidth is not balanced

 * between upstream and downstream ports, packets are queued in an internal

 * buffer until CPLD packet. The workaround is to use the switch in store and

 * forward mode.

 Downstream ports only */

 Check for ACS P2P Request Redirect use */

/*

 * Apply fixup on enable and on resume, in order to apply the fix up whenever

 * ACS configuration changes or switch mode is reset

 SPDX-License-Identifier: GPL-2.0

/*

 * This interrupt-safe spinlock protects all accesses to PCI

 * configuration space.

/*

 * Wrappers for all PCI configuration access functions.  They just check

 * alignment, do locking and call the low-level functions pointed to

 * by pci_dev->ops.

	/*

	 * In general, hardware that supports only 32-bit writes on PCI is

	 * not spec-compliant.  For example, software may perform a 16-bit

	 * write.  If the hardware only supports 32-bit accesses, we must

	 * do a 32-bit read, merge in the 16 bits we intend to write,

	 * followed by a 32-bit write.  If the 16 bits we *don't* intend to

	 * write happen to have any RW1C (write-one-to-clear) bits set, we

	 * just inadvertently cleared something we shouldn't have.

/**

 * pci_bus_set_ops - Set raw operations of pci bus

 * @bus:	pci bus struct

 * @ops:	new raw operations

 *

 * Return previous raw operations

/*

 * The following routines are to prevent the user from accessing PCI config

 * space when it's unsafe to do so.  Some devices require this during BIST and

 * we're required to prevent it during D-state transitions.

 *

 * We have a bit per device to indicate it's blocked and a global wait queue

 * for callers to sleep on until devices are unblocked.

 Returns 0 on success, negative values indicate error. */

 Returns 0 on success, negative values indicate error. */

/**

 * pci_cfg_access_lock - Lock PCI config reads/writes

 * @dev:	pci device struct

 *

 * When access is locked, any userspace reads or writes to config

 * space and concurrent lock requests will sleep until access is

 * allowed via pci_cfg_access_unlock() again.

/**

 * pci_cfg_access_trylock - try to lock PCI config reads/writes

 * @dev:	pci device struct

 *

 * Same as pci_cfg_access_lock, but will return 0 if access is

 * already locked, 1 otherwise. This function can be used from

 * atomic contexts.

/**

 * pci_cfg_access_unlock - Unlock PCI config reads/writes

 * @dev:	pci device struct

 *

 * This function allows PCI config accesses to resume.

	/*

	 * This indicates a problem in the caller, but we don't need

	 * to kill them, unlike a double-block above.

/*

 * Note that these accessor functions are only for the "PCI Express

 * Capability" (see PCIe spec r3.0, sec 7.8).  They do not apply to the

 * other "PCI Express Extended Capabilities" (AER, VC, ACS, MFVC, etc.)

		/*

		 * Reset *val to 0 if pci_read_config_word() fails, it may

		 * have been written as 0xFFFF if hardware error happens

		 * during pci_read_config_word().

	/*

	 * For Functions that do not implement the Slot Capabilities,

	 * Slot Status, and Slot Control registers, these spaces must

	 * be hardwired to 0b, with the exception of the Presence Detect

	 * State bit in the Slot Status register of Downstream Ports,

	 * which must be hardwired to 1b.  (PCIe Base Spec 3.0, sec 7.8)

		/*

		 * Reset *val to 0 if pci_read_config_dword() fails, it may

		 * have been written as 0xFFFFFFFF if hardware error happens

		 * during pci_read_config_dword().

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Bus Services, see include/linux/pci.h for further explanation.

 *

 * Copyright 1993 -- 1997 Drew Eckhardt, Frederic Potter,

 * David Mosberger-Tang

 *

 * Copyright 1997 -- 2000 Martin Mares <mj@ucw.cz>

 How long between PME checks */

 pci=cbmemsize=nnM,cbiosize=nn can override this */

 hpiosize=nn can override this */

/*

 * pci=hpmmiosize=nnM overrides non-prefetchable MMIO size,

 * pci=hpmmioprefsize=nnM overrides prefetchable MMIO size;

 * pci=hpmemsize=nnM overrides both

 PCIe MPS/MRRS strategy; can be overridden by kernel command-line param */

/*

 * The default CLS is used if arch didn't set CLS explicitly and not

 * all pci devices agree on the same value.  Arch can override either

 * the dfl or actual value as it sees fit.  Don't forget this is

 * measured in 32-bit words, not bytes.

/*

 * If we set up a device for bus mastering, we need to check the latency

 * timer as certain BIOSes forget to set it properly.

 If set, the PCIe ARI capability will not be used. */

 If set, the PCIe ATS capability will not be used. */

 If set, the PCI config space of each device is printed during boot. */

 Disable bridge_d3 for all PCIe ports */

 Force bridge_d3 for all PCIe ports */

 Time to wait after a reset for device to become responsive */

/**

 * pci_bus_max_busnr - returns maximum PCI bus number of given bus' children

 * @bus: pointer to PCI bus structure to search

 *

 * Given a PCI bus, returns the highest PCI bus number present in the set

 * including the given PCI bus and its list of child PCI buses.

/**

 * pci_status_get_and_clear_errors - return and clear error bits in PCI_STATUS

 * @pdev: the PCI device

 *

 * Returns error bits set in PCI_STATUS and clears them.

	/*

	 * Make sure the BAR is actually a memory resource, not an IO resource

/**

 * pci_dev_str_match_path - test if a path string matches a device

 * @dev: the PCI device to test

 * @path: string to match the device against

 * @endptr: pointer to the string after the match

 *

 * Test if a string (typically from a kernel parameter) formatted as a

 * path of device/function addresses matches a PCI device. The string must

 * be of the form:

 *

 *   [<domain>:]<bus>:<device>.<func>[/<device>.<func>]*

 *

 * A path for a device can be obtained using 'lspci -t'.  Using a path

 * is more robust against bus renumbering than using only a single bus,

 * device and function address.

 *

 * Returns 1 if the string matches the device, 0 if it does not and

 * a negative error code if it fails to parse the string.

		/*

		 * Note: we don't need to get a reference to the upstream

		 * bridge because we hold a reference to the top level

		 * device which should hold a reference to the bridge,

		 * and so on.

/**

 * pci_dev_str_match - test if a string matches a device

 * @dev: the PCI device to test

 * @p: string to match the device against

 * @endptr: pointer to the string after the match

 *

 * Test if a string (typically from a kernel parameter) matches a specified

 * PCI device. The string may be of one of the following formats:

 *

 *   [<domain>:]<bus>:<device>.<func>[/<device>.<func>]*

 *   pci:<vendor>:<device>[:<subvendor>:<subdevice>]

 *

 * The first format specifies a PCI bus/device/function address which

 * may change if new hardware is inserted, if motherboard firmware changes,

 * or due to changes caused in kernel parameters. If the domain is

 * left unspecified, it is taken to be 0.  In order to be robust against

 * bus renumbering issues, a path of PCI device/function numbers may be used

 * to address the specific device.  The path for a device can be determined

 * through the use of 'lspci -t'.

 *

 * The second format matches devices using IDs in the configuration

 * space which may match multiple devices in the system. A value of 0

 * for any field will match all devices. (Note: this differs from

 * in-kernel code that uses PCI_ANY_ID which is ~0; this is for

 * legacy reasons and convenience so users don't have to specify

 * FFFFFFFFs on the command line.)

 *

 * Returns 1 if the string matches the device, 0 if it does not and

 * a negative error code if the string cannot be parsed.

 PCI vendor/device (subvendor/subdevice) IDs are specified */

		/*

		 * PCI Bus, Device, Function IDs are specified

		 * (optionally, may include a path of devfns following it)

/**

 * pci_find_capability - query for devices' capabilities

 * @dev: PCI device to query

 * @cap: capability code

 *

 * Tell if a device supports a given PCI capability.

 * Returns the address of the requested capability structure within the

 * device's PCI configuration space or 0 in case the device does not

 * support it.  Possible values for @cap include:

 *

 *  %PCI_CAP_ID_PM           Power Management

 *  %PCI_CAP_ID_AGP          Accelerated Graphics Port

 *  %PCI_CAP_ID_VPD          Vital Product Data

 *  %PCI_CAP_ID_SLOTID       Slot Identification

 *  %PCI_CAP_ID_MSI          Message Signalled Interrupts

 *  %PCI_CAP_ID_CHSWP        CompactPCI HotSwap

 *  %PCI_CAP_ID_PCIX         PCI-X

 *  %PCI_CAP_ID_EXP          PCI Express

/**

 * pci_bus_find_capability - query for devices' capabilities

 * @bus: the PCI bus to query

 * @devfn: PCI device to query

 * @cap: capability code

 *

 * Like pci_find_capability() but works for PCI devices that do not have a

 * pci_dev structure set up yet.

 *

 * Returns the address of the requested capability structure within the

 * device's PCI configuration space or 0 in case the device does not

 * support it.

/**

 * pci_find_next_ext_capability - Find an extended capability

 * @dev: PCI device to query

 * @start: address at which to start looking (0 to start at beginning of list)

 * @cap: capability code

 *

 * Returns the address of the next matching extended capability structure

 * within the device's PCI configuration space or 0 if the device does

 * not support it.  Some capabilities can occur several times, e.g., the

 * vendor-specific capability, and this provides a way to find them all.

 minimum 8 bytes per capability */

	/*

	 * If we have no capabilities, this is indicated by cap ID,

	 * cap version and next pointer all being 0.

/**

 * pci_find_ext_capability - Find an extended capability

 * @dev: PCI device to query

 * @cap: capability code

 *

 * Returns the address of the requested extended capability structure

 * within the device's PCI configuration space or 0 if the device does

 * not support it.  Possible values for @cap include:

 *

 *  %PCI_EXT_CAP_ID_ERR		Advanced Error Reporting

 *  %PCI_EXT_CAP_ID_VC		Virtual Channel

 *  %PCI_EXT_CAP_ID_DSN		Device Serial Number

 *  %PCI_EXT_CAP_ID_PWR		Power Budgeting

/**

 * pci_get_dsn - Read and return the 8-byte Device Serial Number

 * @dev: PCI device to query

 *

 * Looks up the PCI_EXT_CAP_ID_DSN and reads the 8 bytes of the Device Serial

 * Number.

 *

 * Returns the DSN, or zero if the capability does not exist.

	/*

	 * The Device Serial Number is two dwords offset 4 bytes from the

	 * capability position. The specification says that the first dword is

	 * the lower half, and the second dword is the upper half.

/**

 * pci_find_next_ht_capability - query a device's HyperTransport capabilities

 * @dev: PCI device to query

 * @pos: Position from which to continue searching

 * @ht_cap: HyperTransport capability code

 *

 * To be used in conjunction with pci_find_ht_capability() to search for

 * all capabilities matching @ht_cap. @pos should always be a value returned

 * from pci_find_ht_capability().

 *

 * NB. To be 100% safe against broken PCI devices, the caller should take

 * steps to avoid an infinite loop.

/**

 * pci_find_ht_capability - query a device's HyperTransport capabilities

 * @dev: PCI device to query

 * @ht_cap: HyperTransport capability code

 *

 * Tell if a device supports a given HyperTransport capability.

 * Returns an address within the device's PCI configuration space

 * or 0 in case the device does not support the request capability.

 * The address points to the PCI capability, of type PCI_CAP_ID_HT,

 * which has a HyperTransport capability matching @ht_cap.

/**

 * pci_find_vsec_capability - Find a vendor-specific extended capability

 * @dev: PCI device to query

 * @vendor: Vendor ID for which capability is defined

 * @cap: Vendor-specific capability ID

 *

 * If @dev has Vendor ID @vendor, search for a VSEC capability with

 * VSEC ID @cap. If found, return the capability offset in

 * config space; otherwise return 0.

/**

 * pci_find_dvsec_capability - Find DVSEC for vendor

 * @dev: PCI device to query

 * @vendor: Vendor ID to match for the DVSEC

 * @dvsec: Designated Vendor-specific capability ID

 *

 * If DVSEC has Vendor ID @vendor and DVSEC ID @dvsec return the capability

 * offset in config space; otherwise return 0.

/**

 * pci_find_parent_resource - return resource region of parent bus of given

 *			      region

 * @dev: PCI device structure contains resources to be searched

 * @res: child resource record for which parent is sought

 *

 * For given resource region of given device, return the resource region of

 * parent bus the given region is contained in.

			/*

			 * If the window is prefetchable but the BAR is

			 * not, the allocator made a mistake.

			/*

			 * If we're below a transparent bridge, there may

			 * be both a positively-decoded aperture and a

			 * subtractively-decoded region that contain the BAR.

			 * We want the positively-decoded one, so this depends

			 * on pci_bus_for_each_resource() giving us those

			 * first.

/**

 * pci_find_resource - Return matching PCI device resource

 * @dev: PCI device to query

 * @res: Resource to look for

 *

 * Goes over standard PCI resources (BARs) and checks if the given resource

 * is partially or fully contained in any of them. In that case the

 * matching resource is returned, %NULL otherwise.

/**

 * pci_wait_for_pending - wait for @mask bit(s) to clear in status word @pos

 * @dev: the PCI device to operate on

 * @pos: config space offset of status word

 * @mask: mask of bit(s) to care about in status word

 *

 * Return 1 when mask bit(s) in status word clear, 0 otherwise.

 Wait for Transaction Pending bit clean */

/**

 * pci_request_acs - ask for ACS to be enabled if supported

/**

 * pci_disable_acs_redir - disable ACS redirect capabilities

 * @dev: the PCI device

 *

 * For only devices specified in the disable_acs_redir parameter.

 Found a match */

 End of param or invalid format */

 P2P Request & Completion Redirect */

/**

 * pci_std_enable_acs - enable ACS on devices using standard ACS capabilities

 * @dev: the PCI device

 Source Validation */

 P2P Request Redirect */

 P2P Completion Redirect */

 Upstream Forwarding */

 Enable Translation Blocking for external devices and noats */

/**

 * pci_enable_acs - enable ACS if hardware support it

 * @dev: the PCI device

	/*

	 * Note: pci_disable_acs_redir() must be called even if ACS was not

	 * enabled by the kernel because it may have been enabled by

	 * platform firmware.  So if we are told to disable it, we should

	 * always disable it after setting the kernel's default

	 * preferences.

/**

 * pci_restore_bars - restore a device's BAR values (e.g. after wake-up)

 * @dev: PCI device to have its BARs restored

 *

 * Restore the BAR values for a given device, so as to make it

 * accessible by its driver.

/**

 * pci_raw_set_power_state - Use PCI PM registers to set the power state of

 *			     given PCI device

 * @dev: PCI device to handle.

 * @state: PCI power state (D0, D1, D2, D3hot) to put the device into.

 *

 * RETURN VALUE:

 * -EINVAL if the requested state is invalid.

 * -EIO if device does not support PCI PM or its PM capabilities register has a

 * wrong version, or device doesn't support the requested state.

 * 0 if device already is in the requested state.

 * 0 if device's power state has been successfully changed.

 Check if we're already there */

	/*

	 * Validate transition: We can enter D0 from any state, but if

	 * we're already in a low-power state, we can only go deeper.  E.g.,

	 * we can go from D1 to D3, but we can't go directly from D3 to D1;

	 * we'd have to go from D3 to D0, then to D1.

 Check if this device supports the desired state */

	/*

	 * If we're (effectively) in D3, force entire word to 0.

	 * This doesn't affect PME_Status, disables PME_En, and

	 * sets PowerState to 0.

 Boot-up */

 force to D0 */

 Enter specified state */

	/*

	 * Mandatory power management transition delays; see PCI PM 1.1

	 * 5.6.1 table 18

	/*

	 * According to section 5.4.1 of the "PCI BUS POWER MANAGEMENT

	 * INTERFACE SPECIFICATION, REV. 1.2", a device transitioning

	 * from D3hot to D0 _may_ perform an internal reset, thereby

	 * going to "D0 Uninitialized" rather than "D0 Initialized".

	 * For example, at least some versions of the 3c905B and the

	 * 3c556B exhibit this behaviour.

	 *

	 * At least some laptop BIOSen (e.g. the Thinkpad T21) leave

	 * devices in a D3hot state at boot.  Consequently, we need to

	 * restore at least the BARs so that the device will be

	 * accessible to its driver.

/**

 * pci_update_current_state - Read power state of given device and cache it

 * @dev: PCI device to handle.

 * @state: State to cache in case the device doesn't have the PM capability

 *

 * The power state is read from the PMCSR register, which however is

 * inaccessible in D3cold.  The platform firmware is therefore queried first

 * to detect accessibility of the register.  In case the platform firmware

 * reports an incorrect state or the device isn't power manageable by the

 * platform at all, we try to detect D3cold by testing accessibility of the

 * vendor ID in config space.

/**

 * pci_refresh_power_state - Refresh the given device's power state data

 * @dev: Target PCI device.

 *

 * Ask the platform to refresh the devices power state information and invoke

 * pci_update_current_state() to update its current PCI power state.

/**

 * pci_platform_power_transition - Use platform to change device power state

 * @dev: PCI device to handle.

 * @state: State to put the device into.

 Fall back to PCI_D0 */

/**

 * pci_resume_bus - Walk given bus and runtime resume devices on it

 * @bus: Top bus of the subtree to walk.

	/*

	 * After reset, the device should not silently discard config

	 * requests, but it may still indicate that it needs more time by

	 * responding to them with CRS completions.  The Root Port will

	 * generally synthesize ~0 data to complete the read (except when

	 * CRS SV is enabled and the read was for the Vendor ID; in that

	 * case it synthesizes 0x0001 data).

	 *

	 * Wait for the device to return a non-CRS completion.  Read the

	 * Command register instead of Vendor ID so we don't have to

	 * contend with the CRS SV value.

/**

 * pci_power_up - Put the given device into D0

 * @dev: PCI device to power up

	/*

	 * Mandatory power management transition delays are handled in

	 * pci_pm_resume_noirq() and pci_pm_runtime_resume() of the

	 * corresponding bridge.

		/*

		 * When powering on a bridge from D3cold, the whole hierarchy

		 * may be powered on into D0uninitialized state, resume them to

		 * give them a chance to suspend again

/**

 * __pci_dev_set_current_state - Set current state of a PCI device

 * @dev: Device to handle

 * @data: pointer to state to be set

/**

 * pci_bus_set_current_state - Walk given bus and set current state of devices

 * @bus: Top bus of the subtree to walk.

 * @state: state to be set

/**

 * pci_set_power_state - Set the power state of a PCI device

 * @dev: PCI device to handle.

 * @state: PCI power state (D0, D1, D2, D3hot) to put the device into.

 *

 * Transition a device to a new power state, using the platform firmware and/or

 * the device's PCI PM registers.

 *

 * RETURN VALUE:

 * -EINVAL if the requested state is invalid.

 * -EIO if device does not support PCI PM or its PM capabilities register has a

 * wrong version, or device doesn't support the requested state.

 * 0 if the transition is to D1 or D2 but D1 and D2 are not supported.

 * 0 if device already is in the requested state.

 * 0 if the transition is to D3 but D3 is not supported.

 * 0 if device's power state has been successfully changed.

 Bound the state we're entering */

		/*

		 * If the device or the parent bridge do not support PCI

		 * PM, ignore the request if we're doing anything other

		 * than putting it into D0 (which would only happen on

		 * boot).

 Check if we're already there */

	/*

	 * This device is quirked not to be put into D3, so don't put it in

	 * D3

	/*

	 * To put device in D3cold, we put device into D3hot in native

	 * way, then put device into D3cold with platform ops

 Powering off a bridge may power off the whole hierarchy */

	/*

	 * Downstream ports reset the LTR enable bit when link goes down.

	 * Check and re-configure the bit here before restoring device.

	 * PCIe r5.0, sec 7.5.3.16.

/**

 * pci_save_state - save the PCI configuration space of a device before

 *		    suspending

 * @dev: PCI device that we're dealing with

 XXX: 100% dword access ok here? */

 Restore BARs before the command register. */

		/*

		 * Force rewriting of prefetch registers to avoid S3 resume

		 * issues on Intel PCI bridges that occur when these

		 * registers are not explicitly written.

/**

 * pci_restore_state - Restore the saved state of a PCI device

 * @dev: PCI device that we're dealing with

	/*

	 * Restore max latencies (in the LTR capability) before enabling

	 * LTR itself (in the PCIe capability).

 Restore ACS and IOV configuration state */

/**

 * pci_store_saved_state - Allocate and return an opaque struct containing

 *			   the device saved state.

 * @dev: PCI device that we're dealing with

 *

 * Return NULL if no state or error.

 Empty cap_save terminates list */

/**

 * pci_load_saved_state - Reload the provided save state into struct pci_dev.

 * @dev: PCI device that we're dealing with

 * @state: Saved state returned from pci_store_saved_state()

/**

 * pci_load_and_free_saved_state - Reload the save state pointed to by state,

 *				   and free the memory allocated for it.

 * @dev: PCI device that we're dealing with

 * @state: Pointer to saved state returned from pci_store_saved_state()

/**

 * pci_reenable_device - Resume abandoned device

 * @dev: PCI device to be resumed

 *

 * NOTE: This function is a backend of pci_default_resume() and is not supposed

 * to be called by normal code, write proper resume handler and use it instead.

	/*

	 * Power state could be unknown at this point, either due to a fresh

	 * boot or a device removal call.  So get the current power state

	 * so that things like MSI message writing will behave as expected

	 * (e.g. if the device really is in D0 at enable time).

 already enabled */

 only skip sriov related */

/**

 * pci_enable_device_io - Initialize a device for use with IO space

 * @dev: PCI device to be initialized

 *

 * Initialize device before it's used by a driver. Ask low-level code

 * to enable I/O resources. Wake up the device if it was suspended.

 * Beware, this function can fail.

/**

 * pci_enable_device_mem - Initialize a device for use with Memory space

 * @dev: PCI device to be initialized

 *

 * Initialize device before it's used by a driver. Ask low-level code

 * to enable Memory resources. Wake up the device if it was suspended.

 * Beware, this function can fail.

/**

 * pci_enable_device - Initialize device before it's used by a driver.

 * @dev: PCI device to be initialized

 *

 * Initialize device before it's used by a driver. Ask low-level code

 * to enable I/O and memory. Wake up the device if it was suspended.

 * Beware, this function can fail.

 *

 * Note we don't actually enable the device many times if we call

 * this function repeatedly (we just increment the count).

/*

 * Managed PCI resources.  This manages device on/off, INTx/MSI/MSI-X

 * on/off and BAR regions.  pci_dev itself records MSI/MSI-X status, so

 * there's no need to track it separately.  pci_devres is initialized

 * when a device is enabled using managed PCI device enable interface.

/**

 * pcim_enable_device - Managed pci_enable_device()

 * @pdev: PCI device to be initialized

 *

 * Managed pci_enable_device().

/**

 * pcim_pin_device - Pin managed PCI device

 * @pdev: PCI device to pin

 *

 * Pin managed PCI device @pdev.  Pinned device won't be disabled on

 * driver detach.  @pdev must have been enabled with

 * pcim_enable_device().

/*

 * pcibios_device_add - provide arch specific hooks when adding device dev

 * @dev: the PCI device being added

 *

 * Permits the platform to provide architecture specific functionality when

 * devices are added. This is the default implementation. Architecture

 * implementations can override this.

/**

 * pcibios_release_device - provide arch specific hooks when releasing

 *			    device dev

 * @dev: the PCI device being released

 *

 * Permits the platform to provide architecture specific functionality when

 * devices are released. This is the default implementation. Architecture

 * implementations can override this.

/**

 * pcibios_disable_device - disable arch specific PCI resources for device dev

 * @dev: the PCI device to disable

 *

 * Disables architecture specific PCI resources for the device. This

 * is the default implementation. Architecture implementations can

 * override this.

/**

 * pcibios_penalize_isa_irq - penalize an ISA IRQ

 * @irq: ISA IRQ to penalize

 * @active: IRQ active or not

 *

 * Permits the platform to provide architecture-specific functionality when

 * penalizing ISA IRQs. This is the default implementation. Architecture

 * implementations can override this.

/**

 * pci_disable_enabled_device - Disable device without updating enable_cnt

 * @dev: PCI device to disable

 *

 * NOTE: This function is a backend of PCI power management routines and is

 * not supposed to be called drivers.

/**

 * pci_disable_device - Disable PCI device after use

 * @dev: PCI device to be disabled

 *

 * Signal to the system that the PCI device is not in use by the system

 * anymore.  This only involves disabling PCI bus-mastering, if active.

 *

 * Note we don't actually disable the device until all callers of

 * pci_enable_device() have called pci_disable_device().

/**

 * pcibios_set_pcie_reset_state - set reset state for device dev

 * @dev: the PCIe device reset

 * @state: Reset state to enter into

 *

 * Set the PCIe reset state for the device. This is the default

 * implementation. Architecture implementations can override this.

/**

 * pci_set_pcie_reset_state - set reset state for device dev

 * @dev: the PCIe device reset

 * @state: Reset state to enter into

 *

 * Sets the PCI reset state for the device.

/**

 * pcie_clear_root_pme_status - Clear root port PME interrupt status.

 * @dev: PCIe root port or event collector.

/**

 * pci_check_pme_status - Check if given device has generated PME.

 * @dev: Device to check.

 *

 * Check the PME status of the device and if set, clear it and clear PME enable

 * (if set).  Return 'true' if PME status and PME enable were both set or

 * 'false' otherwise.

 Clear PME status. */

 Disable PME to avoid interrupt flood. */

/**

 * pci_pme_wakeup - Wake up a PCI device if its PME Status bit is set.

 * @dev: Device to handle.

 * @pme_poll_reset: Whether or not to reset the device's pme_poll flag.

 *

 * Check if @dev has generated PME and queue a resume request for it in that

 * case.

/**

 * pci_pme_wakeup_bus - Walk given bus and wake up devices on it, if necessary.

 * @bus: Top bus of the subtree to walk.

/**

 * pci_pme_capable - check the capability of PCI device to generate PME#

 * @dev: PCI device to handle.

 * @state: PCI state from which device will issue PME#.

			/*

			 * If bridge is in low power state, the

			 * configuration space of subordinate devices

			 * may be not accessible

			/*

			 * If the device is in D3cold it should not be

			 * polled either.

 Clear PME_Status by writing 1 to it and enable PME# */

/**

 * pci_pme_restore - Restore PME configuration after config space restore.

 * @dev: PCI device to update.

/**

 * pci_pme_active - enable or disable PCI device's PME# function

 * @dev: PCI device to handle.

 * @enable: 'true' to enable PME# generation; 'false' to disable it.

 *

 * The caller must verify that the device is capable of generating PME# before

 * calling this function with @enable equal to 'true'.

	/*

	 * PCI (as opposed to PCIe) PME requires that the device have

	 * its PME# line hooked up correctly. Not all hardware vendors

	 * do this, so the PME never gets delivered and the device

	 * remains asleep. The easiest way around this is to

	 * periodically walk the list of suspended devices and check

	 * whether any have their PME flag set. The assumption is that

	 * we'll wake up often enough anyway that this won't be a huge

	 * hit, and the power savings from the devices will still be a

	 * win.

	 *

	 * Although PCIe uses in-band PME message instead of PME# line

	 * to report PME, PME does not work for some PCIe devices in

	 * reality.  For example, there are devices that set their PME

	 * status bits, but don't really bother to send a PME message;

	 * there are PCI Express Root Ports that don't bother to

	 * trigger interrupts when they receive PME messages from the

	 * devices below.  So PME poll is used for PCIe devices too.

/**

 * __pci_enable_wake - enable PCI device as wakeup event source

 * @dev: PCI device affected

 * @state: PCI state from which device will issue wakeup events

 * @enable: True to enable event generation; false to disable

 *

 * This enables the device as a wakeup event source, or disables it.

 * When such events involves platform-specific hooks, those hooks are

 * called automatically by this routine.

 *

 * Devices with legacy power management (no standard PCI PM capabilities)

 * always require such platform hooks.

 *

 * RETURN VALUE:

 * 0 is returned on success

 * -EINVAL is returned if device is not supposed to wake up the system

 * Error code depending on the platform is returned if both the platform and

 * the native mechanism fail to enable the generation of wake-up events

	/*

	 * Bridges that are not power-manageable directly only signal

	 * wakeup on behalf of subordinate devices which is set up

	 * elsewhere, so skip them. However, bridges that are

	 * power-manageable may signal wakeup for themselves (for example,

	 * on a hotplug event) and they need to be covered here.

 Don't do the same thing twice in a row for one device. */

	/*

	 * According to "PCI System Architecture" 4th ed. by Tom Shanley & Don

	 * Anderson we should be doing PME# wake enable followed by ACPI wake

	 * enable.  To disable wake-up we call the platform first, for symmetry.

		/*

		 * Enable PME signaling if the device can signal PME from

		 * D3cold regardless of whether or not it can signal PME from

		 * the current target state, because that will allow it to

		 * signal PME when the hierarchy above it goes into D3cold and

		 * the device itself ends up in D3cold as a result of that.

/**

 * pci_enable_wake - change wakeup settings for a PCI device

 * @pci_dev: Target device

 * @state: PCI state from which device will issue wakeup events

 * @enable: Whether or not to enable event generation

 *

 * If @enable is set, check device_may_wakeup() for the device before calling

 * __pci_enable_wake() for it.

/**

 * pci_wake_from_d3 - enable/disable device to wake up from D3_hot or D3_cold

 * @dev: PCI device to prepare

 * @enable: True to enable wake-up event generation; false to disable

 *

 * Many drivers want the device to wake up the system from D3_hot or D3_cold

 * and this function allows them to set that up cleanly - pci_enable_wake()

 * should not be called twice in a row to enable wake-up due to PCI PM vs ACPI

 * ordering constraints.

 *

 * This function only returns error code if the device is not allowed to wake

 * up the system from sleep or it is not capable of generating PME# from both

 * D3_hot and D3_cold and the platform is unable to enable wake-up power for it.

/**

 * pci_target_state - find an appropriate low power state for a given PCI dev

 * @dev: PCI device

 * @wakeup: Whether or not wakeup functionality will be enabled for the device.

 *

 * Use underlying platform code to find a supported low power state for @dev.

 * If the platform can't manage @dev, return the deepest state from which it

 * can generate wake events, based on any available PME info.

		/*

		 * Call the platform to find the target state for the device.

	/*

	 * If the device is in D3cold even though it's not power-manageable by

	 * the platform, it may have been powered down by non-standard means.

	 * Best to let it slumber.

		/*

		 * Find the deepest state from which the device can generate

		 * PME#.

/**

 * pci_prepare_to_sleep - prepare PCI device for system-wide transition

 *			  into a sleep state

 * @dev: Device to handle.

 *

 * Choose the power state appropriate for the device depending on whether

 * it can wake up the system and/or is power manageable by the platform

 * (PCI_D3hot is the default) and put the device into that state.

	/*

	 * There are systems (for example, Intel mobile chips since Coffee

	 * Lake) where the power drawn while suspended can be significantly

	 * reduced by disabling PTM on PCIe root ports as this allows the

	 * port to enter a lower-power PM state and the SoC to reach a

	 * lower-power idle state as a whole.

/**

 * pci_back_from_sleep - turn PCI device on during system-wide transition

 *			 into working state

 * @dev: Device to handle.

 *

 * Disable device's system wake-up capability and put it into D0.

/**

 * pci_finish_runtime_suspend - Carry out PCI-specific part of runtime suspend.

 * @dev: PCI device being suspended.

 *

 * Prepare @dev to generate wake-up events at run time and put it into a low

 * power state.

	/*

	 * There are systems (for example, Intel mobile chips since Coffee

	 * Lake) where the power drawn while suspended can be significantly

	 * reduced by disabling PTM on PCIe root ports as this allows the

	 * port to enter a lower-power PM state and the SoC to reach a

	 * lower-power idle state as a whole.

/**

 * pci_dev_run_wake - Check if device can generate run-time wake-up events.

 * @dev: Device to check.

 *

 * Return true if the device itself is capable of generating wake-up events

 * (through the platform or using the native PCIe PME) or if the device supports

 * PME and one of its upstream bridges can generate wake-up events.

 PME-capable in principle, but not from the target power state */

 We have reached the root bus. */

/**

 * pci_dev_need_resume - Check if it is necessary to resume the device.

 * @pci_dev: Device to check.

 *

 * Return 'true' if the device is not runtime-suspended or it has to be

 * reconfigured due to wakeup settings difference between system and runtime

 * suspend, or the current power state of it is not suitable for the upcoming

 * (system-wide) transition.

	/*

	 * If the earlier platform check has not triggered, D3cold is just power

	 * removal on top of D3hot, so no need to resume the device in that

	 * case.

/**

 * pci_dev_adjust_pme - Adjust PME setting for a suspended device.

 * @pci_dev: Device to check.

 *

 * If the device is suspended and it is not configured for system wakeup,

 * disable PME for it to prevent it from waking up the system unnecessarily.

 *

 * Note that if the device's power state is D3cold and the platform check in

 * pci_dev_need_resume() has not triggered, the device's configuration need not

 * be changed.

/**

 * pci_dev_complete_resume - Finalize resume from system sleep for a device.

 * @pci_dev: Device to handle.

 *

 * If the device is runtime suspended and wakeup-capable, enable PME for it as

 * it might have been disabled during the prepare phase of system suspend if

 * the device was not configured for system wakeup.

/**

 * pci_choose_state - Choose the power state of a PCI device.

 * @dev: Target PCI device.

 * @state: Target state for the whole system.

 *

 * Returns PCI power state suitable for @dev and @state.

	/*

	 * pdev->current_state is set to PCI_D3cold during suspending,

	 * so wait until suspending completes

	/*

	 * Only need to resume devices in D3cold, because config

	 * registers are still accessible for devices suspended but

	 * not in D3cold.

		/*

		 * Gigabyte X299 root port is not marked as hotplug capable

		 * which allows Linux to power manage it.  However, this

		 * confuses the BIOS SMI handler so don't power manage root

		 * ports on that system.

/**

 * pci_bridge_d3_possible - Is it possible to put the bridge into D3

 * @bridge: Bridge to check

 *

 * This function checks if it is possible to move the bridge to D3.

 * Currently we only allow D3 for recent enough PCIe ports and Thunderbolt.

		/*

		 * Hotplug ports handled by firmware in System Management Mode

		 * may not be put into D3 by the OS (Thunderbolt on non-Macs).

 Even the oldest 2010 Thunderbolt controller supports D3. */

 Platform might know better if the bridge supports D3 */

		/*

		 * Hotplug ports handled natively by the OS were not validated

		 * by vendors for runtime D3 at least until 2018 because there

		 * was no OS support.

		/*

		 * It should be safe to put PCIe ports from 2015 or newer

		 * to D3.

 The device needs to be allowed to go D3cold ... */

 ... and if it is wakeup capable to do so from D3cold. */

 If it is a bridge it must be allowed to go to D3. */

/*

 * pci_bridge_d3_update - Update bridge D3 capabilities

 * @dev: PCI device which is changed

 *

 * Update upstream bridge PM capabilities accordingly depending on if the

 * device PM configuration was changed or the device is being removed.  The

 * change is also propagated upstream.

	/*

	 * If D3 is currently allowed for the bridge, removing one of its

	 * children won't change that.

	/*

	 * If D3 is currently allowed for the bridge and a child is added or

	 * changed, disallowance of D3 can only be caused by that child, so

	 * we only need to check that single device, not any of its siblings.

	 *

	 * If D3 is currently not allowed for the bridge, checking the device

	 * first may allow us to skip checking its siblings.

	/*

	 * If D3 is currently not allowed for the bridge, this may be caused

	 * either by the device being changed/removed or any of its siblings,

	 * so we need to go through all children to find out if one of them

	 * continues to block D3.

 Propagate change to upstream bridges */

/**

 * pci_d3cold_enable - Enable D3cold for device

 * @dev: PCI device to handle

 *

 * This function can be used in drivers to enable D3cold from the device

 * they handle.  It also updates upstream PCI bridge PM capabilities

 * accordingly.

/**

 * pci_d3cold_disable - Disable D3cold for device

 * @dev: PCI device to handle

 *

 * This function can be used in drivers to disable D3cold from the device

 * they handle.  It also updates upstream PCI bridge PM capabilities

 * accordingly.

/**

 * pci_pm_init - Initialize PM functions of given PCI device

 * @dev: PCI device to handle.

 find PCI PM capability in list */

 Check device's ability to generate PME# */

		/*

		 * Make device's PM flags reflect the wake-up capability, but

		 * let the user space enable it to wake up the system as needed.

 Disable the PME# generation functionality */

 Read an Enhanced Allocation (EA) entry */

 Entry size field indicates DWORDs after 1st */

 Entry not enabled */

	/*

	 * If the Property is in the reserved range, try the Secondary

	 * Property instead.

 Read Base */

 Read MaxOffset */

 Read Base MSBs (if 64-bit entry) */

 entry starts above 32-bit boundary, can't use */

 Read MaxOffset MSBs (if 64-bit entry) */

 entry too big, can't use */

 Enhanced Allocation Initialization */

 find PCI EA capability in list */

 determine the number of entries */

 Skip DWORD 2 for type 1 functions */

 parse each EA entry */

/**

 * _pci_add_cap_save_buffer - allocate buffer for saving given

 *			      capability registers

 * @dev: the PCI device

 * @cap: the capability to allocate the buffer for

 * @extended: Standard or Extended capability ID

 * @size: requested size of the buffer

/**

 * pci_allocate_cap_save_buffers - allocate buffers for saving capabilities

 * @dev: the PCI device

/**

 * pci_configure_ari - enable or disable ARI forwarding

 * @dev: the PCI device

 *

 * If @dev and its upstream bridge both support ARI, enable ARI in the

 * bridge.  Otherwise, disable ARI in the bridge.

	/*

	 * Except for egress control, capabilities are either required

	 * or only required if controllable.  Features missing from the

	 * capability field can therefore be assumed as hard-wired enabled.

/**

 * pci_acs_enabled - test ACS against required flags for a given device

 * @pdev: device to test

 * @acs_flags: required PCI ACS flags

 *

 * Return true if the device supports the provided flags.  Automatically

 * filters out flags that are not implemented on multifunction devices.

 *

 * Note that this interface checks the effective ACS capabilities of the

 * device rather than the actual capabilities.  For instance, most single

 * function endpoints are not required to support ACS because they have no

 * opportunity for peer-to-peer access.  We therefore return 'true'

 * regardless of whether the device exposes an ACS capability.  This makes

 * it much easier for callers of this function to ignore the actual type

 * or topology of the device when testing ACS support.

	/*

	 * Conventional PCI and PCI-X devices never support ACS, either

	 * effectively or actually.  The shared bus topology implies that

	 * any device on the bus can receive or snoop DMA.

	/*

	 * PCI/X-to-PCIe bridges are not specifically mentioned by the spec,

	 * but since their primary interface is PCI/X, we conservatively

	 * handle them as we would a non-PCIe device.

	/*

	 * PCIe 3.0, 6.12.1 excludes ACS on these devices.  "ACS is never

	 * applicable... must never implement an ACS Extended Capability...".

	 * This seems arbitrary, but we take a conservative interpretation

	 * of this statement.

	/*

	 * PCIe 3.0, 6.12.1.1 specifies that downstream and root ports should

	 * implement ACS in order to indicate their peer-to-peer capabilities,

	 * regardless of whether they are single- or multi-function devices.

	/*

	 * PCIe 3.0, 6.12.1.2 specifies ACS capabilities that should be

	 * implemented by the remaining PCIe types to indicate peer-to-peer

	 * capabilities, but only when they are part of a multifunction

	 * device.  The footnote for section 6.12 indicates the specific

	 * PCIe types included here.

	/*

	 * PCIe 3.0, 6.12.1.3 specifies no ACS capabilities are applicable

	 * to single function devices with the exception of downstream ports.

/**

 * pci_acs_path_enabled - test ACS flags from start to end in a hierarchy

 * @start: starting downstream device

 * @end: ending upstream device or NULL to search to the root bus

 * @acs_flags: required flags

 *

 * Walk up a device tree from start to end testing PCI ACS support.  If

 * any step along the way does not support the required flags, return false.

/**

 * pci_acs_init - Initialize ACS if hardware supports it

 * @dev: the PCI device

	/*

	 * Attempt to enable ACS regardless of capability because some Root

	 * Ports (e.g. those quirked with *_intel_pch_acs_*) do not have

	 * the standard ACS capability but still support ACS via those

	 * quirks.

/**

 * pci_rebar_find_pos - find position of resize ctrl reg for BAR

 * @pdev: PCI device

 * @bar: BAR to find

 *

 * Helper to find the position of the ctrl register for a BAR.

 * Returns -ENOTSUPP if resizable BARs are not supported at all.

 * Returns -ENOENT if no ctrl register for the BAR could be found.

/**

 * pci_rebar_get_possible_sizes - get possible sizes for BAR

 * @pdev: PCI device

 * @bar: BAR to query

 *

 * Get the possible sizes of a resizable BAR as bitmask defined in the spec

 * (bit 0=1MB, bit 19=512GB). Returns 0 if BAR isn't resizable.

 Sapphire RX 5600 XT Pulse has an invalid cap dword for BAR 0 */

/**

 * pci_rebar_get_current_size - get the current size of a BAR

 * @pdev: PCI device

 * @bar: BAR to set size to

 *

 * Read the size of a BAR from the resizable BAR config.

 * Returns size if found or negative error code.

/**

 * pci_rebar_set_size - set a new size for a BAR

 * @pdev: PCI device

 * @bar: BAR to set size to

 * @size: new size as defined in the spec (0=1MB, 19=512GB)

 *

 * Set the new size of a BAR as defined in the spec.

 * Returns zero if resizing was successful, error code otherwise.

/**

 * pci_enable_atomic_ops_to_root - enable AtomicOp requests to root port

 * @dev: the PCI device

 * @cap_mask: mask of desired AtomicOp sizes, including one or more of:

 *	PCI_EXP_DEVCAP2_ATOMIC_COMP32

 *	PCI_EXP_DEVCAP2_ATOMIC_COMP64

 *	PCI_EXP_DEVCAP2_ATOMIC_COMP128

 *

 * Return 0 if all upstream bridges support AtomicOp routing, egress

 * blocking is disabled on all upstream ports, and the root port supports

 * the requested completion capabilities (32-bit, 64-bit and/or 128-bit

 * AtomicOp completion), or negative otherwise.

	/*

	 * Per PCIe r5.0, sec 9.3.5.10, the AtomicOp Requester Enable bit

	 * in Device Control 2 is reserved in VFs and the PF value applies

	 * to all associated VFs.

	/*

	 * Per PCIe r4.0, sec 6.15, endpoints and root ports may be

	 * AtomicOp requesters.  For now, we only support endpoints as

	 * requesters and root ports as completers.  No endpoints as

	 * completers, and no peer-to-peer.

 Ensure switch ports support AtomicOp routing */

 Ensure root port supports all the sizes we care about */

 Ensure upstream ports don't block AtomicOps on egress */

/**

 * pci_swizzle_interrupt_pin - swizzle INTx for device behind bridge

 * @dev: the PCI device

 * @pin: the INTx pin (1=INTA, 2=INTB, 3=INTC, 4=INTD)

 *

 * Perform INTx swizzling for a device behind one level of bridge.  This is

 * required by section 9.1 of the PCI-to-PCI bridge specification for devices

 * behind bridges on add-in cards.  For devices with ARI enabled, the slot

 * number is always 0 (see the Implementation Note in section 2.2.8.1 of

 * the PCI Express Base Specification, Revision 2.1)

/**

 * pci_common_swizzle - swizzle INTx all the way to root bridge

 * @dev: the PCI device

 * @pinp: pointer to the INTx pin value (1=INTA, 2=INTB, 3=INTD, 4=INTD)

 *

 * Perform INTx swizzling for a device.  This traverses through all PCI-to-PCI

 * bridges all the way up to a PCI root bus.

/**

 * pci_release_region - Release a PCI bar

 * @pdev: PCI device whose resources were previously reserved by

 *	  pci_request_region()

 * @bar: BAR to release

 *

 * Releases the PCI I/O and memory resources previously reserved by a

 * successful call to pci_request_region().  Call this function only

 * after all use of the PCI regions has ceased.

/**

 * __pci_request_region - Reserved PCI I/O and memory resource

 * @pdev: PCI device whose resources are to be reserved

 * @bar: BAR to be reserved

 * @res_name: Name to be associated with resource.

 * @exclusive: whether the region access is exclusive or not

 *

 * Mark the PCI region associated with PCI device @pdev BAR @bar as

 * being reserved by owner @res_name.  Do not access any

 * address inside the PCI regions unless this call returns

 * successfully.

 *

 * If @exclusive is set, then the region is marked so that userspace

 * is explicitly not allowed to map the resource via /dev/mem or

 * sysfs MMIO access.

 *

 * Returns 0 on success, or %EBUSY on error.  A warning

 * message is also printed on failure.

/**

 * pci_request_region - Reserve PCI I/O and memory resource

 * @pdev: PCI device whose resources are to be reserved

 * @bar: BAR to be reserved

 * @res_name: Name to be associated with resource

 *

 * Mark the PCI region associated with PCI device @pdev BAR @bar as

 * being reserved by owner @res_name.  Do not access any

 * address inside the PCI regions unless this call returns

 * successfully.

 *

 * Returns 0 on success, or %EBUSY on error.  A warning

 * message is also printed on failure.

/**

 * pci_release_selected_regions - Release selected PCI I/O and memory resources

 * @pdev: PCI device whose resources were previously reserved

 * @bars: Bitmask of BARs to be released

 *

 * Release selected PCI I/O and memory resources previously reserved.

 * Call this function only after all use of the PCI regions has ceased.

/**

 * pci_request_selected_regions - Reserve selected PCI I/O and memory resources

 * @pdev: PCI device whose resources are to be reserved

 * @bars: Bitmask of BARs to be requested

 * @res_name: Name to be associated with resource

/**

 * pci_release_regions - Release reserved PCI I/O and memory resources

 * @pdev: PCI device whose resources were previously reserved by

 *	  pci_request_regions()

 *

 * Releases all PCI I/O and memory resources previously reserved by a

 * successful call to pci_request_regions().  Call this function only

 * after all use of the PCI regions has ceased.

/**

 * pci_request_regions - Reserve PCI I/O and memory resources

 * @pdev: PCI device whose resources are to be reserved

 * @res_name: Name to be associated with resource.

 *

 * Mark all PCI regions associated with PCI device @pdev as

 * being reserved by owner @res_name.  Do not access any

 * address inside the PCI regions unless this call returns

 * successfully.

 *

 * Returns 0 on success, or %EBUSY on error.  A warning

 * message is also printed on failure.

/**

 * pci_request_regions_exclusive - Reserve PCI I/O and memory resources

 * @pdev: PCI device whose resources are to be reserved

 * @res_name: Name to be associated with resource.

 *

 * Mark all PCI regions associated with PCI device @pdev as being reserved

 * by owner @res_name.  Do not access any address inside the PCI regions

 * unless this call returns successfully.

 *

 * pci_request_regions_exclusive() will mark the region so that /dev/mem

 * and the sysfs MMIO access will not be allowed.

 *

 * Returns 0 on success, or %EBUSY on error.  A warning message is also

 * printed on failure.

/*

 * Record the PCI IO range (expressed as CPU physical address + size).

 * Return a negative value if an error has occurred, zero otherwise

 Ignore duplicates due to deferred probing */

/**

 * pci_remap_iospace - Remap the memory mapped I/O space

 * @res: Resource describing the I/O space

 * @phys_addr: physical address of range to be mapped

 *

 * Remap the memory mapped I/O space described by the @res and the CPU

 * physical address @phys_addr into virtual address space.  Only

 * architectures that have memory mapped IO functions defined (and the

 * PCI_IOBASE value defined) should call this function.

	/*

	 * This architecture does not have memory mapped I/O space,

	 * so this function should never be called

/**

 * pci_unmap_iospace - Unmap the memory mapped I/O space

 * @res: resource to be unmapped

 *

 * Unmap the CPU virtual address @res from virtual address space.  Only

 * architectures that have memory mapped IO functions defined (and the

 * PCI_IOBASE value defined) should call this function.

/**

 * devm_pci_remap_iospace - Managed pci_remap_iospace()

 * @dev: Generic device to remap IO address for

 * @res: Resource describing the I/O space

 * @phys_addr: physical address of range to be mapped

 *

 * Managed pci_remap_iospace().  Map is automatically unmapped on driver

 * detach.

/**

 * devm_pci_remap_cfgspace - Managed pci_remap_cfgspace()

 * @dev: Generic device to remap IO address for

 * @offset: Resource address to map

 * @size: Size of map

 *

 * Managed pci_remap_cfgspace().  Map is automatically unmapped on driver

 * detach.

/**

 * devm_pci_remap_cfg_resource - check, request region and ioremap cfg resource

 * @dev: generic device to handle the resource for

 * @res: configuration space resource to be handled

 *

 * Checks that a resource is a valid memory region, requests the memory

 * region and ioremaps with pci_remap_cfgspace() API that ensures the

 * proper PCI configuration space memory attributes are guaranteed.

 *

 * All operations are managed and will be undone on driver detach.

 *

 * Returns a pointer to the remapped memory or an ERR_PTR() encoded error code

 * on failure. Usage example::

 *

 *	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);

 *	base = devm_pci_remap_cfg_resource(&pdev->dev, res);

 *	if (IS_ERR(base))

 *		return PTR_ERR(base);

/**

 * pcibios_setup - process "pci=" kernel boot arguments

 * @str: string used to pass in "pci=" kernel boot arguments

 *

 * Process kernel boot arguments.  This is the default implementation.

 * Architecture specific implementations can override this as necessary.

/**

 * pcibios_set_master - enable PCI bus-mastering for device dev

 * @dev: the PCI device to enable

 *

 * Enables PCI bus-mastering for the device.  This is the default

 * implementation.  Architecture specific implementations can override

 * this if necessary.

 The latency timer doesn't apply to PCIe (either Type 0 or Type 1) */

/**

 * pci_set_master - enables bus-mastering for device dev

 * @dev: the PCI device to enable

 *

 * Enables bus-mastering on the device and calls pcibios_set_master()

 * to do the needed arch specific settings.

/**

 * pci_clear_master - disables bus-mastering for device dev

 * @dev: the PCI device to disable

/**

 * pci_set_cacheline_size - ensure the CACHE_LINE_SIZE register is programmed

 * @dev: the PCI device for which MWI is to be enabled

 *

 * Helper function for pci_set_mwi.

 * Originally copied from drivers/net/acenic.c.

 * Copyright 1998-2001 by Jes Sorensen, <jes@trained-monkey.org>.

 *

 * RETURNS: An appropriate -ERRNO error value on error, or zero for success.

	/* Validate current setting: the PCI_CACHE_LINE_SIZE must be

 Write the correct value. */

 Read it back. */

/**

 * pci_set_mwi - enables memory-write-invalidate PCI transaction

 * @dev: the PCI device for which MWI is enabled

 *

 * Enables the Memory-Write-Invalidate transaction in %PCI_COMMAND.

 *

 * RETURNS: An appropriate -ERRNO error value on error, or zero for success.

/**

 * pcim_set_mwi - a device-managed pci_set_mwi()

 * @dev: the PCI device for which MWI is enabled

 *

 * Managed pci_set_mwi().

 *

 * RETURNS: An appropriate -ERRNO error value on error, or zero for success.

/**

 * pci_try_set_mwi - enables memory-write-invalidate PCI transaction

 * @dev: the PCI device for which MWI is enabled

 *

 * Enables the Memory-Write-Invalidate transaction in %PCI_COMMAND.

 * Callers are not required to check the return value.

 *

 * RETURNS: An appropriate -ERRNO error value on error, or zero for success.

/**

 * pci_clear_mwi - disables Memory-Write-Invalidate for device dev

 * @dev: the PCI device to disable

 *

 * Disables PCI Memory-Write-Invalidate transaction on the device

/**

 * pci_disable_parity - disable parity checking for device

 * @dev: the PCI device to operate on

 *

 * Disable parity checking for device @dev

/**

 * pci_intx - enables/disables PCI INTx for device dev

 * @pdev: the PCI device to operate on

 * @enable: boolean: whether to enable or disable PCI INTx

 *

 * Enables/disables PCI INTx for device @pdev

	/*

	 * We do a single dword read to retrieve both command and status.

	 * Document assumptions that make this possible.

	/*

	 * Check interrupt status register to see whether our device

	 * triggered the interrupt (when masking) or the next IRQ is

	 * already pending (when unmasking).

/**

 * pci_check_and_mask_intx - mask INTx on pending interrupt

 * @dev: the PCI device to operate on

 *

 * Check if the device dev has its INTx line asserted, mask it and return

 * true in that case. False is returned if no interrupt was pending.

/**

 * pci_check_and_unmask_intx - unmask INTx if no interrupt is pending

 * @dev: the PCI device to operate on

 *

 * Check if the device dev has its INTx line asserted, unmask it if not and

 * return true. False is returned and the mask remains active if there was

 * still an interrupt pending.

/**

 * pci_wait_for_pending_transaction - wait for pending transaction

 * @dev: the PCI device to operate on

 *

 * Return 0 if transaction is pending 1 otherwise.

/**

 * pcie_flr - initiate a PCIe function level reset

 * @dev: device to reset

 *

 * Initiate a function level reset unconditionally on @dev without

 * checking any flags and DEVCAP

	/*

	 * Per PCIe r4.0, sec 6.6.2, a device must complete an FLR within

	 * 100ms, but may silently discard requests while the FLR is in

	 * progress.  Wait 100ms before trying to access the device.

/**

 * pcie_reset_flr - initiate a PCIe function level reset

 * @dev: device to reset

 * @probe: if true, return 0 if device can be reset this way

 *

 * Initiate a function level reset on @dev.

	/*

	 * Wait for Transaction Pending bit to clear.  A word-aligned test

	 * is used, so we use the control offset rather than status and shift

	 * the test bit to match.

	/*

	 * Per Advanced Capabilities for Conventional PCI ECN, 13 April 2006,

	 * updated 27 July 2006; a device must complete an FLR within

	 * 100ms, but may silently discard requests while the FLR is in

	 * progress.  Wait 100ms before trying to access the device.

/**

 * pci_pm_reset - Put device into PCI_D3 and back into PCI_D0.

 * @dev: Device to reset.

 * @probe: if true, return 0 if the device can be reset this way.

 *

 * If @dev supports native PCI PM and its PCI_PM_CTRL_NO_SOFT_RESET flag is

 * unset, it will be reinitialized internally when going from PCI_D3hot to

 * PCI_D0.  If that's the case and the device is not in a low-power state

 * already, force it into PCI_D3hot and back to PCI_D0, causing it to be reset.

 *

 * NOTE: This causes the caller to sleep for twice the device power transition

 * cooldown period, which for the D0->D3hot and D3hot->D0 transitions is 10 ms

 * by default (i.e. unless the @dev's d3hot_delay field has a different value).

 * Moreover, only devices in D0 can be reset by this function.

/**

 * pcie_wait_for_link_delay - Wait until link is active or inactive

 * @pdev: Bridge device

 * @active: waiting for active or inactive?

 * @delay: Delay to wait after link has become active (in ms)

 *

 * Use this to wait till link becomes active or inactive.

	/*

	 * Some controllers might not implement link active reporting. In this

	 * case, we wait for 1000 ms + any delay requested by the caller.

	/*

	 * PCIe r4.0 sec 6.6.1, a component must enter LTSSM Detect within 20ms,

	 * after which we should expect an link active if the reset was

	 * successful. If so, software must wait a minimum 100ms before sending

	 * configuration requests to devices downstream this port.

	 *

	 * If the link fails to activate, either the device was physically

	 * removed or the link is permanently failed.

/**

 * pcie_wait_for_link - Wait until link is active or inactive

 * @pdev: Bridge device

 * @active: waiting for active or inactive?

 *

 * Use this to wait till link becomes active or inactive.

/*

 * Find maximum D3cold delay required by all the devices on the bus.  The

 * spec says 100 ms, but firmware can lower it and we allow drivers to

 * increase it as well.

 *

 * Called with @pci_bus_sem locked for reading.

/**

 * pci_bridge_wait_for_secondary_bus - Wait for secondary bus to be accessible

 * @dev: PCI bridge

 *

 * Handle necessary delays before access to the devices on the secondary

 * side of the bridge are permitted after D3cold to D0 transition.

 *

 * For PCIe this means the delays in PCIe 5.0 section 6.6.1. For

 * conventional PCI it means Tpvrh + Trhfa specified in PCI 3.0 section

 * 4.3.2.

	/*

	 * We only deal with devices that are present currently on the bus.

	 * For any hot-added devices the access delay is handled in pciehp

	 * board_added(). In case of ACPI hotplug the firmware is expected

	 * to configure the devices before OS is notified.

 Take d3cold_delay requirements into account */

	/*

	 * Conventional PCI and PCI-X we need to wait Tpvrh + Trhfa before

	 * accessing the device after reset (that is 1000 ms + 100 ms). In

	 * practice this should not be needed because we don't do power

	 * management for them (see pci_bridge_d3_possible()).

	/*

	 * For PCIe downstream and root ports that do not support speeds

	 * greater than 5 GT/s need to wait minimum 100 ms. For higher

	 * speeds (gen3) we need to wait first for the data link layer to

	 * become active.

	 *

	 * However, 100 ms is the minimum and the PCIe spec says the

	 * software must allow at least 1s before it can determine that the

	 * device that did not respond is a broken device. There is

	 * evidence that 100 ms is not always enough, for example certain

	 * Titan Ridge xHCI controller does not always respond to

	 * configuration requests if we only wait for 100 ms (see

	 * https://bugzilla.kernel.org/show_bug.cgi?id=203885).

	 *

	 * Therefore we wait for 100 ms and check for the device presence.

	 * If it is still not present give it an additional 100 ms.

 Did not train, no need to wait any further */

	/*

	 * PCI spec v3.0 7.6.4.2 requires minimum Trst of 1ms.  Double

	 * this to 2ms to ensure that we meet the minimum requirement.

	/*

	 * Trhfa for conventional PCI is 2^25 clock cycles.

	 * Assuming a minimum 33MHz clock this results in a 1s

	 * delay before we can consider subordinate devices to

	 * be re-initialized.  PCIe has some ways to shorten this,

	 * but we don't make use of them yet.

/**

 * pci_bridge_secondary_bus_reset - Reset the secondary bus on a PCI bridge.

 * @dev: Bridge device

 *

 * Use the bridge control register to assert reset on the secondary bus.

 * Devices on the secondary bus are left in power-on state.

 block PM suspend, driver probe, etc. */

 Return 1 on successful lock, 0 on contention */

	/*

	 * dev->driver->err_handler->reset_prepare() is protected against

	 * races with ->remove() by the device lock, which must be held by

	 * the caller.

	/*

	 * Wake-up device prior to save.  PM registers default to D0 after

	 * reset and a simple register restore doesn't reliably return

	 * to a non-D0 state anyway.

	/*

	 * Disable the device by clearing the Command register, except for

	 * INTx-disable which is set.  This not only disables MMIO and I/O port

	 * BARs, but also prevents the device from being Bus Master, preventing

	 * DMA from the device including MSI/MSI-X interrupts.  For PCI 2.3

	 * compliant devices, INTx-disable prevents legacy interrupts.

	/*

	 * dev->driver->err_handler->reset_done() is protected against

	 * races with ->remove() by the device lock, which must be held by

	 * the caller.

 dev->reset_methods[] is a 0-terminated list of indices into this array */

 not found */

 Warn if dev-specific supported but not highest priority */

 Leave previous methods unchanged */

/**

 * __pci_reset_function_locked - reset a PCI device function while holding

 * the @dev mutex lock.

 * @dev: PCI device to reset

 *

 * Some devices allow an individual function to be reset without affecting

 * other functions in the same device.  The PCI device must be responsive

 * to PCI config space in order to use this function.

 *

 * The device function is presumed to be unused and the caller is holding

 * the device mutex lock when this function is called.

 *

 * Resetting the device will make the contents of PCI configuration space

 * random, so any caller of this must be prepared to reinitialise the

 * device including MSI, bus mastering, BARs, decoding IO and memory spaces,

 * etc.

 *

 * Returns 0 if the device function was successfully reset or negative if the

 * device doesn't support resetting a single function.

	/*

	 * A reset method returns -ENOTTY if it doesn't support this device and

	 * we should try the next method.

	 *

	 * If it returns 0 (success), we're finished.  If it returns any other

	 * error, we're also finished: this indicates that further reset

	 * mechanisms might be broken on the device.

/**

 * pci_init_reset_methods - check whether device can be safely reset

 * and store supported reset mechanisms.

 * @dev: PCI device to check for reset mechanisms

 *

 * Some devices allow an individual function to be reset without affecting

 * other functions in the same device.  The PCI device must be in D0-D3hot

 * state.

 *

 * Stores reset mechanisms supported by device in reset_methods byte array

 * which is a member of struct pci_dev.

/**

 * pci_reset_function - quiesce and reset a PCI device function

 * @dev: PCI device to reset

 *

 * Some devices allow an individual function to be reset without affecting

 * other functions in the same device.  The PCI device must be responsive

 * to PCI config space in order to use this function.

 *

 * This function does not just reset the PCI portion of a device, but

 * clears all the state associated with the device.  This function differs

 * from __pci_reset_function_locked() in that it saves and restores device state

 * over the reset and takes the PCI device lock.

 *

 * Returns 0 if the device function was successfully reset or negative if the

 * device doesn't support resetting a single function.

/**

 * pci_reset_function_locked - quiesce and reset a PCI device function

 * @dev: PCI device to reset

 *

 * Some devices allow an individual function to be reset without affecting

 * other functions in the same device.  The PCI device must be responsive

 * to PCI config space in order to use this function.

 *

 * This function does not just reset the PCI portion of a device, but

 * clears all the state associated with the device.  This function differs

 * from __pci_reset_function_locked() in that it saves and restores device state

 * over the reset.  It also differs from pci_reset_function() in that it

 * requires the PCI device lock to be held.

 *

 * Returns 0 if the device function was successfully reset or negative if the

 * device doesn't support resetting a single function.

/**

 * pci_try_reset_function - quiesce and reset a PCI device function

 * @dev: PCI device to reset

 *

 * Same as above, except return -EAGAIN if unable to lock device.

 Do any devices on or below this bus prevent a bus reset? */

 Lock devices from the top of the tree down */

 Unlock devices from the bottom of the tree up */

 Return 1 on successful lock, 0 on contention */

 Do any devices on or below this slot prevent a bus reset? */

 Lock devices from the top of the tree down */

 Unlock devices from the bottom of the tree up */

 Return 1 on successful lock, 0 on contention */

/*

 * Save and disable devices from the top of the tree down while holding

 * the @dev mutex lock for the entire tree.

/*

 * Restore devices from top of the tree down while holding @dev mutex lock

 * for the entire tree.  Parent bridges need to be restored before we can

 * get to subordinate devices.

/*

 * Save and disable devices from the top of the tree down while holding

 * the @dev mutex lock for the entire tree.

/*

 * Restore devices from top of the tree down while holding @dev mutex lock

 * for the entire tree.  Parent bridges need to be restored before we can

 * get to subordinate devices.

/**

 * pci_probe_reset_slot - probe whether a PCI slot can be reset

 * @slot: PCI slot to probe

 *

 * Return 0 if slot can be reset, negative if a slot reset is not supported.

/**

 * __pci_reset_slot - Try to reset a PCI slot

 * @slot: PCI slot to reset

 *

 * A PCI bus may host multiple slots, each slot may support a reset mechanism

 * independent of other slots.  For instance, some slots may support slot power

 * control.  In the case of a 1:1 bus to slot architecture, this function may

 * wrap the bus reset to avoid spurious slot related events such as hotplug.

 * Generally a slot reset should be attempted before a bus reset.  All of the

 * function of the slot and any subordinate buses behind the slot are reset

 * through this function.  PCI config space of all devices in the slot and

 * behind the slot is saved before and restored after reset.

 *

 * Same as above except return -EAGAIN if the slot cannot be locked

/**

 * pci_bus_error_reset - reset the bridge's subordinate bus

 * @bridge: The parent device that connects to the bus to reset

 *

 * This function will first try to reset the slots on this bus if the method is

 * available. If slot reset fails or is not available, this will fall back to a

 * secondary bus reset.

/**

 * pci_probe_reset_bus - probe whether a PCI bus can be reset

 * @bus: PCI bus to probe

 *

 * Return 0 if bus can be reset, negative if a bus reset is not supported.

/**

 * __pci_reset_bus - Try to reset a PCI bus

 * @bus: top level PCI bus to reset

 *

 * Same as above except return -EAGAIN if the bus cannot be locked

/**

 * pci_reset_bus - Try to reset a PCI bus

 * @pdev: top level PCI device to reset via slot/bus

 *

 * Same as above except return -EAGAIN if the bus cannot be locked

/**

 * pcix_get_max_mmrbc - get PCI-X maximum designed memory read byte count

 * @dev: PCI device to query

 *

 * Returns mmrbc: maximum designed memory read count in bytes or

 * appropriate error value.

/**

 * pcix_get_mmrbc - get PCI-X maximum memory read byte count

 * @dev: PCI device to query

 *

 * Returns mmrbc: maximum memory read count in bytes or appropriate error

 * value.

/**

 * pcix_set_mmrbc - set PCI-X maximum memory read byte count

 * @dev: PCI device to query

 * @mmrbc: maximum memory read count in bytes

 *    valid values are 512, 1024, 2048, 4096

 *

 * If possible sets maximum memory read byte count, some bridges have errata

 * that prevent this.

/**

 * pcie_get_readrq - get PCI Express read request size

 * @dev: PCI device to query

 *

 * Returns maximum memory read request in bytes or appropriate error value.

/**

 * pcie_set_readrq - set PCI Express maximum memory read request

 * @dev: PCI device to query

 * @rq: maximum memory read count in bytes

 *    valid values are 128, 256, 512, 1024, 2048, 4096

 *

 * If possible sets maximum memory read request in bytes

	/*

	 * If using the "performance" PCIe config, we clamp the read rq

	 * size to the max packet size to keep the host bridge from

	 * generating requests larger than we can cope with.

/**

 * pcie_get_mps - get PCI Express maximum payload size

 * @dev: PCI device to query

 *

 * Returns maximum payload size in bytes

/**

 * pcie_set_mps - set PCI Express maximum payload size

 * @dev: PCI device to query

 * @mps: maximum payload size in bytes

 *    valid values are 128, 256, 512, 1024, 2048, 4096

 *

 * If possible sets maximum payload size

/**

 * pcie_bandwidth_available - determine minimum link settings of a PCIe

 *			      device and its bandwidth limitation

 * @dev: PCI device to query

 * @limiting_dev: storage for device causing the bandwidth limitation

 * @speed: storage for speed of limiting device

 * @width: storage for width of limiting device

 *

 * Walk up the PCI device chain and find the point where the minimum

 * bandwidth is available.  Return the bandwidth available there and (if

 * limiting_dev, speed, and width pointers are supplied) information about

 * that point.  The bandwidth returned is in Mb/s, i.e., megabits/second of

 * raw bandwidth.

 Check if current device limits the total bandwidth */

/**

 * pcie_get_speed_cap - query for the PCI device's link speed capability

 * @dev: PCI device to query

 *

 * Query the PCI device speed capability.  Return the maximum link speed

 * supported by the device.

	/*

	 * Link Capabilities 2 was added in PCIe r3.0, sec 7.8.18.  The

	 * implementation note there recommends using the Supported Link

	 * Speeds Vector in Link Capabilities 2 when supported.

	 *

	 * Without Link Capabilities 2, i.e., prior to PCIe r3.0, software

	 * should use the Supported Link Speeds field in Link Capabilities,

	 * where only 2.5 GT/s and 5.0 GT/s speeds were defined.

 PCIe r3.0-compliant */

/**

 * pcie_get_width_cap - query for the PCI device's link width capability

 * @dev: PCI device to query

 *

 * Query the PCI device width capability.  Return the maximum link width

 * supported by the device.

/**

 * pcie_bandwidth_capable - calculate a PCI device's link bandwidth capability

 * @dev: PCI device

 * @speed: storage for link speed

 * @width: storage for link width

 *

 * Calculate a PCI device's link bandwidth by querying for its link speed

 * and width, multiplying them, and applying encoding overhead.  The result

 * is in Mb/s, i.e., megabits/second of raw bandwidth.

/**

 * __pcie_print_link_status - Report the PCI device's link speed and width

 * @dev: PCI device to query

 * @verbose: Print info even when enough bandwidth is available

 *

 * If the available bandwidth at the device is less than the device is

 * capable of, report the device's maximum possible bandwidth and the

 * upstream link that limits its performance.  If @verbose, always print

 * the available bandwidth, even if the device isn't constrained.

/**

 * pcie_print_link_status - Report the PCI device's link speed and width

 * @dev: PCI device to query

 *

 * Report the available bandwidth at the device.

/**

 * pci_select_bars - Make BAR mask from the type of resource

 * @dev: the PCI device for which BAR mask is made

 * @flags: resource type mask to be selected

 *

 * This helper routine makes bar mask from the type of resource.

 Some architectures require additional programming to enable VGA */

 NULL disables */

/**

 * pci_set_vga_state - set VGA decode state on device and parents if requested

 * @dev: the PCI device

 * @decode: true = enable decoding, false = disable decoding

 * @command_bits: PCI_COMMAND_IO and/or PCI_COMMAND_MEMORY

 * @flags: traverse ancestors and change bridges

 * CHANGE_BRIDGE_ONLY / CHANGE_BRIDGE

 ARCH specific VGA enables */

/**

 * pci_add_dma_alias - Add a DMA devfn alias for a device

 * @dev: the PCI device for which alias is added

 * @devfn_from: alias slot and function

 * @nr_devfns: number of subsequent devfns to alias

 *

 * This helper encodes an 8-bit devfn as a bit number in dma_alias_mask

 * which is used to program permissible bus-devfn source addresses for DMA

 * requests in an IOMMU.  These aliases factor into IOMMU group creation

 * and are useful for devices generating DMA requests beyond or different

 * from their logical bus-devfn.  Examples include device quirks where the

 * device simply uses the wrong devfn, as well as non-transparent bridges

 * where the alias may be a proxy for devices in another domain.

 *

 * IOMMU group creation is performed during device discovery or addition,

 * prior to any potential DMA mapping and therefore prior to driver probing

 * (especially for userspace assigned devices where IOMMU group definition

 * cannot be left as a userspace activity).  DMA aliases should therefore

 * be configured via quirks, such as the PCI fixup header quirk.

 Propagate the "ignore hotplug" setting to the parent bridge. */

/**

 * pci_real_dma_dev - Get PCI DMA device for PCI device

 * @dev: the PCI device that may have a PCI DMA alias

 *

 * Permits the platform to provide architecture-specific functionality to

 * devices needing to alias DMA to another PCI device on another PCI bus. If

 * the PCI device is on the same bus, it is recommended to use

 * pci_add_dma_alias(). This is the default implementation. Architecture

 * implementations can override this.

/*

 * Arches that don't want to expose struct resource to userland as-is in

 * sysfs and /proc can implement their own pci_resource_to_user().

/**

 * pci_specified_resource_alignment - get resource alignment specified by user.

 * @dev: the PCI device to get

 * @resize: whether or not to change resources' size when reassigning alignment

 *

 * RETURNS: Resource alignment if it is specified.

 *          Zero if it is not specified.

 End of param or invalid format */

	/*

	 * Increase the alignment of the resource.  There are two ways we

	 * can do this:

	 *

	 * 1) Increase the size of the resource.  BARs are aligned on their

	 *    size, so when we reallocate space for this resource, we'll

	 *    allocate it with the larger alignment.  This also prevents

	 *    assignment of any other BARs inside the alignment region, so

	 *    if we're requesting page alignment, this means no other BARs

	 *    will share the page.

	 *

	 *    The disadvantage is that this makes the resource larger than

	 *    the hardware BAR, which may break drivers that compute things

	 *    based on the resource size, e.g., to find registers at a

	 *    fixed offset before the end of the BAR.

	 *

	 * 2) Retain the resource size, but use IORESOURCE_STARTALIGN and

	 *    set r->start to the desired alignment.  By itself this

	 *    doesn't prevent other BARs being put inside the alignment

	 *    region, but if we realign *every* resource of every device in

	 *    the system, none of them will share an alignment region.

	 *

	 * When the user has requested alignment for only some devices via

	 * the "pci=resource_alignment" argument, "resize" is true and we

	 * use the first method.  Otherwise we assume we're aligning all

	 * devices and we use the second.

/*

 * This function disables memory decoding and releases memory resources

 * of the device specified by kernel's boot parameter 'pci=resource_alignment='.

 * It also rounds up size to specified alignment.

 * Later on, the kernel will assign page-aligned memory resource back

 * to the device.

	/*

	 * VF BARs are read-only zero according to SR-IOV spec r1.1, sec

	 * 3.4.1.11.  Their resources are allocated from the space

	 * described by the VF BARx register in the PF's SR-IOV capability.

	 * We can't influence their alignment here.

 check if specified PCI is target device to reassign */

	/*

	 * Need to disable bridge's resource window,

	 * to enable the kernel to reassign new resource

	 * window later on.

	/*

	 * Check DT domain and use_dt_domains values.

	 *

	 * If DT domain property is valid (domain >= 0) and

	 * use_dt_domains != 0, the DT assignment is valid since this means

	 * we have not previously allocated a domain number by using

	 * pci_get_new_domain_nr(); we should also update use_dt_domains to

	 * 1, to indicate that we have just assigned a domain number from

	 * DT.

	 *

	 * If DT domain property value is not valid (ie domain < 0), and we

	 * have not previously assigned a domain number from DT

	 * (use_dt_domains != 1) we should assign a domain number by

	 * using the:

	 *

	 * pci_get_new_domain_nr()

	 *

	 * API and update the use_dt_domains value to keep track of method we

	 * are using to assign domain numbers (use_dt_domains = 0).

	 *

	 * All other combinations imply we have a platform that is trying

	 * to mix domain numbers obtained from DT and pci_get_new_domain_nr(),

	 * which is a recipe for domain mishandling and it is prevented by

	 * invalidating the domain value (domain = -1) and printing a

	 * corresponding error.

/**

 * pci_ext_cfg_avail - can we access extended PCI config space?

 *

 * Returns 1 if we can access PCI extended config space (offsets

 * greater than 0xff). This is the default implementation. Architecture

 * implementations can override this.

/*

 * 'resource_alignment_param' and 'disable_acs_redir_param' are initialized

 * in pci_setup(), above, to point to data in the __initdata section which

 * will be freed after the init sequence is complete. We can't allocate memory

 * in pci_setup() because some architectures do not have any memory allocation

 * service available during an early_param() call. So we allocate memory and

 * copy the variable here before the init section is freed.

 *

 SPDX-License-Identifier: GPL-2.0

/*

 * (C) Copyright 2002-2004 Greg Kroah-Hartman <greg@kroah.com>

 * (C) Copyright 2002-2004 IBM Corp.

 * (C) Copyright 2003 Matthew Wilcox

 * (C) Copyright 2003 Hewlett-Packard

 * (C) Copyright 2004 Jon Smirl <jonsmirl@yahoo.com>

 * (C) Copyright 2004 Silicon Graphics, Inc. Jesse Barnes <jbarnes@sgi.com>

 *

 * File attributes for PCI devices

 *

 * Modeled after usb's driverfs.c

 = 0 */

 show configuration fields */

	/*

	 * For MSI, show the first MSI IRQ; for all other cases including

	 * MSI-X, show the legacy INTx IRQ.

/*

 * PCI Bus Class Devices

 show resources */

 this can crash the machine when done on the "wrong" device */

	/*

	 * "no_msi" and "bus_flags" only affect what happens when a driver

	 * requests MSI or MSI-X.  They don't affect any drivers that have

	 * already requested MSI or MSI-X.

 We need to keep extra room for a newline */

 Several chips lock up trying to read undefined config space */

/**

 * pci_read_legacy_io - read byte(s) from legacy I/O port space

 * @filp: open sysfs file

 * @kobj: kobject corresponding to file to read from

 * @bin_attr: struct bin_attribute for this file

 * @buf: buffer to store results

 * @off: offset into legacy I/O port space

 * @count: number of bytes to read

 *

 * Reads 1, 2, or 4 bytes from legacy I/O port space using an arch specific

 * callback routine (pci_legacy_read).

 Only support 1, 2 or 4 byte accesses */

/**

 * pci_write_legacy_io - write byte(s) to legacy I/O port space

 * @filp: open sysfs file

 * @kobj: kobject corresponding to file to read from

 * @bin_attr: struct bin_attribute for this file

 * @buf: buffer containing value to be written

 * @off: offset into legacy I/O port space

 * @count: number of bytes to write

 *

 * Writes 1, 2, or 4 bytes from legacy I/O port space using an arch specific

 * callback routine (pci_legacy_write).

 Only support 1, 2 or 4 byte accesses */

/**

 * pci_mmap_legacy_mem - map legacy PCI memory into user memory space

 * @filp: open sysfs file

 * @kobj: kobject corresponding to device to be mapped

 * @attr: struct bin_attribute for this file

 * @vma: struct vm_area_struct passed to mmap

 *

 * Uses an arch specific callback, pci_mmap_legacy_mem_page_range, to mmap

 * legacy memory space (first meg of bus space) into application virtual

 * memory space.

/**

 * pci_mmap_legacy_io - map legacy PCI IO into user memory space

 * @filp: open sysfs file

 * @kobj: kobject corresponding to device to be mapped

 * @attr: struct bin_attribute for this file

 * @vma: struct vm_area_struct passed to mmap

 *

 * Uses an arch specific callback, pci_mmap_legacy_io_page_range, to mmap

 * legacy IO space (first meg of bus space) into application virtual

 * memory space. Returns -ENOSYS if the operation isn't supported

/**

 * pci_adjust_legacy_attr - adjustment of legacy file attributes

 * @b: bus to create files under

 * @mmap_type: I/O port or memory

 *

 * Stub implementation. Can be overridden by arch if necessary.

/**

 * pci_create_legacy_files - create legacy I/O port and memory files

 * @b: bus to create files under

 *

 * Some platforms allow access to legacy I/O port and ISA memory space on

 * a per-bus basis.  This routine creates the files and ties them into

 * their associated read, write and mmap files from pci-sysfs.c

 *

 * On error unwind, but don't propagate the error to the caller

 * as it is ok to set up the PCI bus without these files.

 Allocated above after the legacy_io struct */

 both are allocated here */

 HAVE_PCI_LEGACY */

/**

 * pci_mmap_resource - map a PCI resource into user memory space

 * @kobj: kobject for mapping

 * @attr: struct bin_attribute for the file being mapped

 * @vma: struct vm_area_struct passed into the mmap

 * @write_combine: 1 for write_combine mapping

 *

 * Use the regular PCI mapping routines to map a PCI resource into userspace.

/**

 * pci_remove_resource_files - cleanup resource files

 * @pdev: dev to cleanup

 *

 * If we created resource files for @pdev, remove them from sysfs and

 * free their resources.

 allocate attribute structure, piggyback attribute name */

/**

 * pci_create_resource_files - create resource files in sysfs for @dev

 * @pdev: dev in question

 *

 * Walk the resources in @pdev creating files for each resource available.

 Expose the PCI resources from this device as files */

 skip empty resources */

 for prefetchable resources, create a WC mappable file */

 !(defined(HAVE_PCI_MMAP) || defined(ARCH_GENERIC_PCI_MMAP_RESOURCE)) */

/**

 * pci_write_rom - used to enable access to the PCI ROM display

 * @filp: sysfs file

 * @kobj: kernel object handle

 * @bin_attr: struct bin_attribute for this file

 * @buf: user input

 * @off: file offset

 * @count: number of byte in input

 *

 * writing anything except 0 enables it

/**

 * pci_read_rom - read a PCI ROM

 * @filp: sysfs file

 * @kobj: kernel object handle

 * @bin_attr: struct bin_attribute for this file

 * @buf: where to put the data we read from the ROM

 * @off: file offset

 * @count: number of bytes to read

 *

 * Put @count bytes starting at @off into @buf from the ROM in the PCI

 * device corresponding to @kobj.

 size starts out as PCI window size */

 If the device has a ROM, try to expose it in sysfs. */

/**

 * pci_remove_sysfs_dev_files - cleanup PCI specific sysfs files

 * @pdev: device whose entries we should free

 *

 * Cleanup when @pdev is removed from sysfs.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2018 Marvell

 *

 * Author: Thomas Petazzoni <thomas.petazzoni@bootlin.com>

 *

 * This file helps PCI controller drivers implement a fake root port

 * PCI bridge when the HW doesn't provide such a root port PCI

 * bridge.

 *

 * It emulates a PCI bridge by providing a fake PCI configuration

 * space (and optionally a PCIe capability configuration space) in

 * memory. By default the read/write operations simply read and update

 * this fake configuration space in memory. However, PCI controller

 * drivers can provide through the 'struct pci_sw_bridge_ops'

 * structure a set of operations to override or complement this

 * default behavior.

/**

 * struct pci_bridge_reg_behavior - register bits behaviors

 * @ro:		Read-Only bits

 * @rw:		Read-Write bits

 * @w1c:	Write-1-to-Clear bits

 *

 * Reads and Writes will be filtered by specified behavior. All other bits not

 * declared are assumed 'Reserved' and will return 0 on reads, per PCIe 5.0:

 * "Reserved register fields must be read only and must return 0 (all 0's for

 * multi-bit fields) when read".

 Read-only bits */

 Read-write bits */

 Write-1-to-clear bits */

	/*

	 * Cache Line Size register: implement as read-only, we do not

	 * pretend implementing "Memory Write and Invalidate"

	 * transactions"

	 *

	 * Latency Timer Register: implemented as read-only, as "A

	 * bridge that is not capable of a burst transfer of more than

	 * two data phases on its primary interface is permitted to

	 * hardwire the Latency Timer to a value of 16 or less"

	 *

	 * Header Type: always read-only

	 *

	 * BIST register: implemented as read-only, as "A bridge that

	 * does not support BIST must implement this register as a

	 * read-only register that returns 0 when read"

	/*

	 * Base Address registers not used must be implemented as

	 * read-only registers that return 0 when read.

 Primary, secondary and subordinate bus are RW */

 Secondary latency is read-only */

 The high four bits of I/O base/limit are RW */

 The low four bits of I/O base/limit are RO */

 The high 12-bits of mem base/limit are RW */

 The low four bits of mem base/limit are RO */

 The high 12-bits of pref mem base/limit are RW */

 The low four bits of pref mem base/limit are RO */

	/*

	 * Interrupt line (bits 7:0) are RW, interrupt pin (bits 15:8)

	 * are RO, and bridge control (31:16) are a mix of RW, RO,

	 * reserved and W1C bits

 Interrupt line is RW */

 Interrupt pin is RO */

		/*

		 * Capability ID, Next Capability Pointer and

		 * Capabilities register are all read-only.

 Device control register is RW */

		/*

		 * Device status register has bits 6 and [3:0] W1C, [5:4] RO,

		 * the rest is reserved

 All bits are RO, except bit 23 which is reserved */

		/*

		 * Link control has bits [15:14], [11:3] and [1:0] RW, the

		 * rest is reserved.

		 *

		 * Link status has bits [13:0] RO, and bits [15:14]

		 * W1C.

		/*

		 * Slot control has bits [14:0] RW, the rest is

		 * reserved.

		 *

		 * Slot status has bits 8 and [4:0] W1C, bits [7:5] RO, the

		 * rest is reserved.

		/*

		 * Root control has bits [4:0] RW, the rest is

		 * reserved.

		 *

		 * Root capabilities has bit 0 RO, the rest is reserved.

		/*

		 * Root status has bits 17 and [15:0] RO, bit 16 W1C, the rest

		 * is reserved.

/*

 * Initialize a pci_bridge_emul structure to represent a fake PCI

 * bridge configuration space. The caller needs to have initialized

 * the PCI configuration space with whatever values make sense

 * (typically at least vendor, device, revision), the ->ops pointer,

 * and optionally ->data and ->has_pcie.

 Set PCIe v2, root port, slot support */

/*

 * Cleanup a pci_bridge_emul structure that was previously initialized

 * using pci_bridge_emul_init().

/*

 * Should be called by the PCI controller driver when reading the PCI

 * configuration space of the fake bridge. It will call back the

 * ->ops->read_base or ->ops->read_pcie operations.

	/*

	 * Make sure we never return any reserved bit with a value

	 * different from 0.

/*

 * Should be called by the PCI controller driver when writing the PCI

 * configuration space of the fake bridge. It will call back the

 * ->ops->write_base or ->ops->write_pcie operations.

 Keep all bits, except the RW bits */

 Update the value of the RW bits */

 Clear the W1C bits */

 Save the new value with the cleared W1C bits into the cfgspace */

	/*

	 * Clear the W1C bits not specified by the write mask, so that the

	 * write_op() does not clear them.

	/*

	 * Set the W1C bits specified by the write mask, so that write_op()

	 * knows about that they are to be cleared.

 SPDX-License-Identifier: GPL-2.0

/*

 * Support routines for initializing a PCI subsystem

 *

 * Extruded from code written by

 *      Dave Rusling (david.rusling@reo.mts.dec.com)

 *      David Mosberger (davidm@cs.arizona.edu)

 *	David Miller (davem@redhat.com)

 *

 * Nov 2000, Ivan Kokshaysky <ink@jurassic.park.msu.ru>

 *	     PCI-PCI bridges cleanup, sorted resource allocation.

 * Feb 2002, Ivan Kokshaysky <ink@jurassic.park.msu.ru>

 *	     Converted to allocation in 3 passes, which gives

 *	     tighter packing. Prefetchable range support.

/**

 * add_to_list() - Add a new resource tracker to the list

 * @head:	Head of the list

 * @dev:	Device to which the resource belongs

 * @res:	Resource to be tracked

 * @add_size:	Additional size to be optionally added to the resource

 * @min_align:	Minimum memory window alignment

 Sort resources by alignment */

 Fallback is smallest one or list is empty */

 Insert it just before n */

 Don't touch classless devices or host bridges or IOAPICs */

 Don't touch IOAPIC devices already enabled by firmware */

/**

 * reassign_resources_sorted() - Satisfy any additional resource requests

 *

 * @realloc_head:	Head of the list tracking requests requiring

 *			additional resources

 * @head:		Head of the list tracking requests with allocated

 *			resources

 *

 * Walk through each element of the realloc_head and try to procure additional

 * resources for the element, provided the element is in the head list.

 Skip resource that has been reset */

 Skip this resource if not found in head list */

 Just skip */

/**

 * assign_requested_resources_sorted() - Satisfy resource requests

 *

 * @head:	Head of the list tracking requests for resources

 * @fail_head:	Head of the list tracking requests that could not be

 *		allocated

 *

 * Satisfy resource requests of each element in the list.  Add requests that

 * could not be satisfied to the failed_list.

				/*

				 * If the failed resource is a ROM BAR and

				 * it will be enabled later, don't add it

				 * to the list.

 don't care */,

 don't care */);

 Check failed type */

	/*

	 * One pref failed resource will set IORESOURCE_MEM, as we can

	 * allocate pref in non-pref range.  Will release all assigned

	 * non-pref sibling resources according to that bit.

 Check pref at first */

 Count pref if its parent is non-pref */

 Should not get here */

	/*

	 * Should not assign requested resources at first.  They could be

	 * adjacent, so later reassign can not reallocate them one by one in

	 * parent resource window.

	 *

	 * Try to assign requested + add_size at beginning.  If could do that,

	 * could get out early.  If could not do that, we still try to assign

	 * requested at first, then try to reassign add_size for some resources.

	 *

	 * Separate three resource type checking if we need to release

	 * assigned resource after requested + add_size try.

	 *

	 *	1. If IO port assignment fails, will release assigned IO

	 *	   port.

	 *	2. If pref MMIO assignment fails, release assigned pref

	 *	   MMIO.  If assigned pref MMIO's parent is non-pref MMIO

	 *	   and non-pref MMIO assignment fails, will release that

	 *	   assigned pref MMIO.

	 *	3. If non-pref MMIO assignment fails or pref MMIO

	 *	   assignment fails, will release assigned non-pref MMIO.

 Check if optional add_size is there */

 Save original start, end, flags etc at first */

 Update res in head list with add_size in realloc_head list */

		/*

		 * There are two kinds of additional resources in the list:

		 * 1. bridge resource  -- IORESOURCE_STARTALIGN

		 * 2. SR-IOV resource  -- IORESOURCE_SIZEALIGN

		 * Here just fix the additional alignment for bridge

		/*

		 * The "head" list is sorted by alignment so resources with

		 * bigger alignment will be assigned first.  After we

		 * change the alignment of a dev_res in "head" list, we

		 * need to reorder the list by alignment to make it

		 * consistent.

 Try updated head list with add_size added */

 All assigned with add_size? */

 Remove head list from realloc_head list */

 Check failed type */

 Remove not need to be released assigned res from head list etc */

 Remove it from realloc_head list */

 Release assigned resource */

 Restore start/end/flags from saved list */

 Satisfy the must-have resource requests */

 Try to satisfy any additional optional resource requests */

		/*

		 * The IO resource is allocated a range twice as large as it

		 * would normally need.  This allows us to set both IO regs.

/*

 * Initialize bridges with base/limit values we have collected.  PCI-to-PCI

 * Bridge Architecture Specification rev. 1.1 (1998) requires that if there

 * are no I/O ports or memory behind the bridge, the corresponding range

 * must be turned off by writing base value greater than limit to the

 * bridge's base/limit registers.

 *

 * Note: care must be taken when updating I/O base/limit registers of

 * bridges which support 32-bit I/O.  This update requires two config space

 * writes, so it's quite possible that an I/O window of the bridge will

 * have some undesirable address (e.g. 0) after the first write.  Ditto

 * 64-bit prefetchable MMIO.

 Set up the top and bottom of the PCI I/O segment for this bus */

 Set up upper 16 bits of I/O base/limit */

 Clear upper 16 bits of I/O base/limit */

 Temporarily disable the I/O range before updating PCI_IO_BASE */

 Update lower 16 bits of I/O base/limit */

 Update upper 16 bits of I/O base/limit */

 Set up the top and bottom of the PCI Memory segment for this bus */

	/*

	 * Clear out the upper 32 bits of PREF limit.  If

	 * PCI_PREF_BASE_UPPER32 was non-zero, this temporarily disables

	 * PREF range, which is ok.

 Set up PREF base/limit */

 Set the upper 32 bits of PREF base & limit */

 Claimed the window */

 Clipping didn't change anything */

 Claimed a smaller window */

/*

 * Check whether the bridge supports optional I/O and prefetchable memory

 * ranges.  If not, the respective base/limit registers must be read-only

 * and read as 0.

/*

 * Helper function for sizing routines.  Assigned resources have non-NULL

 * parent resource.

 *

 * Return first unassigned resource of the correct type.  If there is none,

 * return first assigned resource of the correct type.  If none of the

 * above, return NULL.

 *

 * Returning an assigned resource of the correct type allows the caller to

 * distinguish between already assigned and no resource of the correct type.

	/*

	 * To be fixed in 2.5: we should have sort of HAVE_ISA flag in the

	 * struct pci_bus.

 1MiB */

 4KiB */

 1KiB */

		/*

		 * Per spec, I/O windows are 4K-aligned, but some bridges have

		 * an extension to support 1K alignment.

/**

 * pbus_size_io() - Size the I/O window of a given bus

 *

 * @bus:		The bus

 * @min_size:		The minimum I/O window that must be allocated

 * @add_size:		Additional optional I/O window

 * @realloc_head:	Track the additional I/O window on this list

 *

 * Sizing the I/O windows of the PCI-PCI bridge is trivial, since these

 * windows have 1K or 4K granularity and the I/O ranges of non-bridge PCI

 * devices are limited to 256 bytes.  We must be careful with the ISA

 * aliasing though.

 If resource is already assigned, nothing more to do */

 Might be re-aligned for ISA */

/**

 * pbus_size_mem() - Size the memory window of a given bus

 *

 * @bus:		The bus

 * @mask:		Mask the resource flag, then compare it with type

 * @type:		The type of free resource from bridge

 * @type2:		Second match type

 * @type3:		Third match type

 * @min_size:		The minimum memory window that must be allocated

 * @add_size:		Additional optional memory window

 * @realloc_head:	Track the additional memory window on this list

 *

 * Calculate the size of the bus and minimal alignment which guarantees

 * that all child resources fit in this size.

 *

 * Return -ENOSPC if there's no available bus resource of the desired

 * type.  Otherwise, set the bus resource start/end to indicate the

 * required size, add things to realloc_head (if supplied), and return 0.

 Alignments from 1MB to 128GB */

 If resource is already assigned, nothing more to do */

 Put SRIOV requested res to the optional list */

 Don't care */);

			/*

			 * aligns[0] is for 1MB (since bridge memory

			 * windows are always at least 1MB aligned), so

			 * keep "order" from being negative for smaller

			 * resources.

			/*

			 * Exclude ranges with size > align from calculation of

			 * the alignment.

	/*

	 * Reserve some resources for CardBus.  We reserve a fixed amount

	 * of bus space for CardBus bridges.

 MEM1 must not be pref MMIO */

 Check whether prefetchable memory is supported by this bridge. */

	/*

	 * If we have prefetchable memory support, allocate two regions.

	 * Otherwise, allocate one region of twice the size.

 Reduce that to half */

 The root bus? */

 Intentionally invalid - not a PCI device. */

 Don't size CardBuses yet */

		/*

		 * If there's a 64-bit prefetchable MMIO window, compute

		 * the size required to put all 64-bit prefetchable

		 * resources in it.

			/*

			 * If successful, all non-prefetchable resources

			 * and any 32-bit prefetchable resources will go in

			 * the non-prefetchable window.

		/*

		 * If there is no 64-bit prefetchable window, compute the

		 * size required to put all prefetchable resources in the

		 * 32-bit prefetchable window (if there is one).

			/*

			 * If successful, only non-prefetchable resources

			 * will go in the non-prefetchable window.

		/*

		 * Compute the size required to put everything else in the

		 * non-prefetchable window. This includes:

		 *

		 *   - all non-prefetchable resources

		 *   - 32-bit prefetchable resources if there's a 64-bit

		 *     prefetchable window or no prefetchable window at all

		 *   - 64-bit prefetchable resources if there's no prefetchable

		 *     window at all

		 *

		 * Note that the strategy in __pci_assign_resource() must match

		 * that used here. Specifically, we cannot put a 32-bit

		 * prefetchable resource in a 64-bit prefetchable window.

/*

 * Try to assign any resources marked as IORESOURCE_PCI_FIXED, as they are

 * skipped by pbus_assign_resources_sorted().

	/*

	 * Carry out a depth-first search on the PCI bus tree to allocate

	 * bridge apertures.  Read the programmed bridge bases and

	 * recursively claim the respective bridge resources.

	/*

	 * 1. If IO port assignment fails, release bridge IO port.

	 * 2. If non pref MMIO assignment fails, release bridge nonpref MMIO.

	 * 3. If 64bit pref MMIO assignment fails, and bridge pref is 64bit,

	 *    release bridge pref MMIO.

	 * 4. If pref MMIO assignment fails, and bridge pref is 32bit,

	 *    release bridge pref MMIO.

	 * 5. If pref MMIO assignment fails, and bridge pref is not

	 *    assigned, release bridge nonpref MMIO.

 If there are children, release them all */

 Keep the old size */

 Avoiding touch the one without PREF */

 For next child res under same bridge */

/*

 * Try to release PCI bridge resources from leaf bridge, so we can allocate

 * a larger window later.

/*

 * -1: undefined, will auto detect later

 *  0: disabled by user

 *  1: disabled by auto detect

 *  2: enabled by user

 *  3: enabled by auto detect

 Not assigned or rejected by kernel? */

 Return early from pci_walk_bus() */

/*

 * First try will not touch PCI bridge res.

 * Second and later try will clear small leaf bridge res.

 * Will stop till to the max depth if can not find good one.

 List of resources that want additional resources */

 Don't realloc if asked to do so */

	/*

	 * Last try will use add_list, otherwise will try good to have as must

	 * have, so can realloc parent bridge resource

	/*

	 * Depth first, calculate sizes and alignments of all subordinate buses.

 Depth last, allocate resources and update the hardware. */

 Any device complain? */

 Third times and later will not check if it is leaf */

	/*

	 * Try to release leaf bridge's resources that doesn't fit resource of

	 * child device under that bridge.

 Restore size and flags */

 Dump the resource on buses */

 Make sure the root bridge has a companion ACPI device */

	/*

	 * The alignment of this bridge is yet to be considered, hence it must

	 * be done now before extending its bridge window.

	/*

	 * Now that we have adjusted for alignment, update the bridge window

	 * resources to fill as much remaining resource space as possible.

	/*

	 * Calculate how many hotplug bridges and normal bridges there

	 * are on this bus.  We will distribute the additional available

	 * resources between hotplug bridges.

	/*

	 * There is only one bridge on the bus so it gets all available

	 * resources which it can then distribute to the possible hotplug

	 * bridges below.

	/*

	 * Calculate the total amount of extra resource space we can

	 * pass to bridges below this one.  This is basically the

	 * extra space reduced by the minimal required space for the

	 * non-hotplug bridges.

		/*

		 * Reduce the available resource space by what the

		 * bridge and devices below it occupy.

	/*

	 * Go over devices on this bus and distribute the remaining

	 * resource space between hotplug bridges.

		/*

		 * Distribute available extra resources equally between

		 * hotplug-capable downstream ports taking alignment into

		 * account.

 Take the initial extra resources from the hotplug port */

 List of resources that want additional resources */

	/*

	 * Distribute remaining resources (if any) equally between hotplug

	 * bridges below.  This makes it possible to extend the hierarchy

	 * later without running out of resources.

 Still fail, don't need to try more */

	/*

	 * Try to release leaf bridge's resources that aren't big enough

	 * to contain child device resources.

 Restore size and flags */

 Walk to the root hub, releasing bridge BARs when possible */

 Ignore BARs which are still in use */

 Skip the bridge we just assigned resources for */

 Restore size and flags */

 Revert to the old configuration */

 List of resources that want additional resources */

 SPDX-License-Identifier: GPL-2.0

/*

 * Export the firmware instance and label associated with a PCI device to

 * sysfs

 *

 * Copyright (C) 2010 Dell Inc.

 * by Narendra K <Narendra_K@dell.com>,

 * Jordan Hargrave <Jordan_Hargrave@dell.com>

 *

 * PCI Firmware Specification Revision 3.1 section 4.6.7 (DSM for Naming a

 * PCI or PCI Express Device Under Operating Systems) defines an instance

 * number and string name. This code retrieves them and exports them to sysfs.

 * If the system firmware does not provide the ACPI _DSM (Device Specific

 * Method), then the SMBIOS type 41 instance number and string is exported to

 * sysfs.

 *

 * SMBIOS defines type 41 for onboard pci devices. This code retrieves

 * the instance number and string from the type 41 record and exports

 * it to sysfs.

 *

 * Please see https://linux.dell.com/files/biosdevname/ for more

 * information.

		/*

		 * The second string element is optional even when

		 * this _DSM is implemented; when not implemented,

		 * this entry must return a null string.

 SPDX-License-Identifier: GPL-2.0

/*

 * Host bridge related code

 SPDX-License-Identifier: GPL-2.0

/* pci-pf-stub - simple stub driver for PCI SR-IOV PF device

 *

 * This driver is meant to act as a "whitelist" for devices that provide

 * SR-IOV functionality while at the same time not actually needing a

 * driver of their own.

/*

 * pci_pf_stub_whitelist - White list of devices to bind pci-pf-stub onto

 *

 * This table provides the list of IDs this driver is supposed to bind

 * onto.  You could think of this as a list of "quirked" devices where we

 * are adding support for SR-IOV here since there are no other drivers

 * that they would be running under.

 required last entry */

 SPDX-License-Identifier: GPL-2.0

/*

 * Procfs interface for the PCI bus

 *

 * Copyright (c) 1997--1999 Martin Mares <mj@ucw.cz>

 = 0 */

	/*

	 * Normal users can read only the standardized portion of the

	 * configuration space as several chips lock up when trying to read

	 * undefined locations (think of Intel PIIX4 as a typical example).

 HAVE_PCI_MMAP */

 If arch decided it can't, fall through... */

 HAVE_PCI_MMAP */

 Make sure the caller is mapping a real resource for this device */

 HAVE_PCI_MMAP */

 HAVE_ARCH_PCI_GET_UNMAPPED_AREA */

 HAVE_PCI_MMAP */

 iterator */

 only print standard and ROM resources to preserve compatibility */

 SPDX-License-Identifier: GPL-2.0

/*

 * Support routines for initializing a PCI subsystem

 *

 * Extruded from code written by

 *      Dave Rusling (david.rusling@reo.mts.dec.com)

 *      David Mosberger (davidm@cs.arizona.edu)

 *	David Miller (davem@redhat.com)

	/*

	 * If this device is not on the primary bus, we need to figure out

	 * which interrupt pin it will come in on. We know which slot it

	 * will come in on because that slot is where the bridge is. Each

	 * time the interrupt line passes through a PCI-PCI bridge we must

	 * apply the swizzle function.

 Cope with illegal. */

 Follow the chain of bridges, swizzling as we go. */

		/*

		 * If a swizzling function is not used, map_irq() must

		 * ignore slot.

	/*

	 * Always tell the device, so the driver knows what is the real IRQ

	 * to use; the device does not use it.

 SPDX-License-Identifier: GPL-2.0

/*

 * Intel MID platform PM support

 *

 * Copyright (C) 2016, Intel Corporation

 *

 * Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>

/*

 * This table should be in sync with the one in

 * arch/x86/platform/intel-mid/pwr.c.

 SPDX-License-Identifier: GPL-2.0

/*

 * Simple stub driver to reserve a PCI device

 *

 * Copyright (C) 2008 Red Hat, Inc.

 * Author:

 *	Chris Wright

 *

 * Usage is simple, allocate a new id to the stub driver and bind the

 * device to it.  For example:

 *

 * # echo "8086 10f5" > /sys/bus/pci/drivers/pci-stub/new_id

 * # echo -n 0000:00:19.0 > /sys/bus/pci/drivers/e1000e/unbind

 * # echo -n 0000:00:19.0 > /sys/bus/pci/drivers/pci-stub/bind

 * # ls -l /sys/bus/pci/devices/0000:00:19.0/driver

 * .../0000:00:19.0/driver -> ../../../bus/pci/drivers/pci-stub

 only dynamic id's */

 no ids passed actually */

 add ids specified in the module parameter */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI detection and setup code

 secondary latency timer */

 Ugh.  Need to stop exporting this to modules. */

/*

 * Some device drivers need know if PCI is initiated.

 * Basically, we think PCI is not initiated when there

 * is no device to be found on the pci_bus_type.

/*

 * PCI Bus Class

 Find the significant bits */

	/*

	 * Get the lowest of them to find the decode size, and from that

	 * the extent.

	/*

	 * base == maxbase can be valid only if the BAR has already been

	 * programmed with all 1s.

 1M mem BAR treated as 32-bit BAR */

 mem unknown type treated as 32-bit BAR */

/**

 * __pci_read_base - Read a PCI BAR

 * @dev: the PCI device

 * @type: type of the BAR

 * @res: resource buffer to be filled in

 * @pos: BAR position in the config space

 *

 * Returns 1 if the BAR is 64-bit, or 0 if 32-bit.

 No printks while decoding is disabled! */

	/*

	 * All bits set in sz means the device isn't working properly.

	 * If the BAR isn't implemented, all bits must be 0.  If it's a

	 * memory BAR or a ROM, bit 0 must be clear; if it's an io BAR, bit

	 * 1 must be clear.

	/*

	 * I don't know how l can have all bits set.  Copied from old code.

	 * Maybe it fixes a bug on some ancient platform.

 Above 32-bit boundary; try to reallocate */

	/*

	 * If "A" is a BAR value (a bus address), "bus_to_resource(A)" is

	 * the corresponding resource address (the physical address used by

	 * the CPU.  Converting that resource address back to a bus address

	 * should yield the original BAR value:

	 *

	 *     resource_to_bus(bus_to_resource(A)) == A

	 *

	 * If it doesn't, CPU accesses to "bus_to_resource(A)" will not

	 * be claimed by the device.

 Per PCIe r4.0, sec 9.3.4.1.11, the VF BARs are all RO Zero */

	/*

	 * DECchip 21050 pass 2 errata: the bridge may miss an address

	 * disconnect boundary by one PCI data phase.  Workaround: do not

	 * use prefetching on this device.

		/*

		 * Bridge claims to have a 64-bit prefetchable memory

		 * window; verify that the upper bits are actually

		 * writable.

 Support 1K I/O space granularity */

		/*

		 * Some bridges set the base > limit by default, and some

		 * (broken) BIOSes do not initialize them.  If we find

		 * this, just assume they are not being used.

 It's a host bus, nothing to read */

	/*

	 * We assume we can manage these PCIe features.  Some systems may

	 * reserve these for use by the platform itself, e.g., an ACPI BIOS

	 * may implement its own AER handling and use _OSC to prevent the

	 * OS from interfering.

 Indexed by PCI_X_SSTATUS_FREQ (secondary bus mode and frequency) */

 0 */

 1 */

 2 */

 3 */

 4 */

 5 */

 6 */

 7 */

 8 */

 9 */

 A */

 B */

 C */

 D */

 E */

 F */

 Indexed by PCI_EXP_LNKCAP_SLS, PCI_EXP_LNKSTA_CLS */

 0 */

 1 */

 2 */

 3 */

 4 */

 5 */

 6 */

 7 */

 8 */

 9 */

 A */

 B */

 C */

 D */

 E */

 F */

 Indexed by the pci_bus_speed enum */

 0x00 */

 0x01 */

 0x02 */

 0x03 */

 0x04 */

 0x05 */

 0x06 */

 0x07 */

 0x08 */

 0x09 */

 0x0a */

 0x0b */

 0x0c */

 0x0d */

 0x0e */

 0x0f */

 0x10 */

 0x11 */

 0x12 */

 0x13 */

 0x14 */

 0x15 */

 0x16 */

 0x17 */

 0x18 */

 0x19 */

 If the host bridge driver sets a MSI domain of the bridge, use it */

	/*

	 * Any firmware interface that can resolve the msi_domain

	 * should be called from here.

	/*

	 * If no IRQ domain was found via the OF tree, try looking it up

	 * directly through the fwnode_handle.

	/*

	 * The bus can be a root bus, a subordinate bus, or a virtual bus

	 * created by an SR-IOV device.  Walk up to the first bridge device

	 * found or derive the domain from the host bridge.

 Temporarily move resources off the list */

 Ignore it if we already got here via a different bridge */

 Create legacy_io and legacy_mem files for this bus */

 Coalesce contiguous windows */

 Add initial resources to the bus */

	/*

	 * If extended config space isn't accessible on a bridge's primary

	 * bus, we certainly can't access it on the secondary bus.

	/*

	 * PCIe Root Ports and switch ports are PCIe on both sides, so if

	 * extended config space is accessible on the primary, it's also

	 * accessible on the secondary.

	/*

	 * For the other bridge types:

	 *   - PCI-to-PCI bridges

	 *   - PCIe-to-PCI/PCI-X forward bridges

	 *   - PCI/PCI-X-to-PCIe reverse bridges

	 * extended config space on the secondary side is only accessible

	 * if the bridge supports PCI-X Mode 2.

 Allocate a new bus and inherit stuff from the parent */

	/*

	 * Initialize some portions of the bus device, but don't register

	 * it now as the parent is not properly set up yet.

 Set up the primary, secondary and subordinate bus numbers */

	/*

	 * Check whether extended config space is accessible on the child

	 * bus.  Note that we currently assume it is always accessible on

	 * the root bus.

 Set up default resource pointers and names */

 Create legacy_io and legacy_mem files for this bus */

 Enable CRS Software Visibility if supported */

/**

 * pci_ea_fixed_busnrs() - Read fixed Secondary and Subordinate bus

 * numbers from EA capability.

 * @dev: Bridge

 * @sec: updated with secondary bus number from EA

 * @sub: updated with subordinate bus number from EA

 *

 * If @dev is a bridge with EA capability that specifies valid secondary

 * and subordinate bus numbers, return true with the bus numbers in @sec

 * and @sub.  Otherwise return false.

 find PCI EA capability in list */

/*

 * pci_scan_bridge_extend() - Scan buses behind a bridge

 * @bus: Parent bus the bridge is on

 * @dev: Bridge itself

 * @max: Starting subordinate number of buses behind this bridge

 * @available_buses: Total number of buses available for this bridge and

 *		     the devices below. After the minimal bus space has

 *		     been allocated the remaining buses will be

 *		     distributed equally between hotplug-capable bridges.

 * @pass: Either %0 (scan already configured bridges) or %1 (scan bridges

 *        that need to be reconfigured.

 *

 * If it's a bridge, configure it and scan the bus behind it.

 * For CardBus bridges, we don't scan behind as the devices will

 * be handled by the bridge driver itself.

 *

 * We need to process bridges in two passes -- first we scan those

 * already configured by the BIOS and after we are done with all of

 * them, we proceed to assigning numbers to the remaining buses in

 * order to avoid overlaps between old and new bus numbers.

 *

 * Return: New subordinate number covering all buses behind this bridge.

	/*

	 * Make sure the bridge is powered on to be able to access config

	 * space of devices below it.

 Check if setup is sensible at all */

	/*

	 * Disable Master-Abort Mode during probing to avoid reporting of

	 * bus errors in some architectures.

		/*

		 * Bus already configured by firmware, process it in the

		 * first pass and just note the configuration.

		/*

		 * The bus might already exist for two reasons: Either we

		 * are rescanning the bus or the bus is reachable through

		 * more than one bridge. The second case can happen with

		 * the i450NX chipset.

 Subordinate should equal child->busn_res.end */

		/*

		 * We need to assign a number to this bus which we always

		 * do in the second pass.

				/*

				 * Temporarily disable forwarding of the

				 * configuration cycles on all bridges in

				 * this bus segment to avoid possible

				 * conflicts in the second pass between two

				 * bridges programmed with overlapping bus

				 * ranges.

 Clear errors */

 Read bus numbers from EA Capability (if present) */

		/*

		 * Prevent assigning a bus number that already exists.

		 * This can happen when a bridge is hot-plugged, so in this

		 * case we only re-scan this bus.

		/*

		 * yenta.c forces a secondary latency timer of 176.

		 * Copy that behaviour here.

 We need to blast all three values with a single write */

			/*

			 * For CardBus bridges, we leave 4 bus numbers as

			 * cards with a PCI-to-PCI bridge can be inserted

			 * later.

					/*

					 * Often, there are two CardBus

					 * bridges -- try to leave one

					 * valid bus number for each one.

		/*

		 * Set subordinate bus number to its real value.

		 * If fixed subordinate bus number exists from EA

		 * capability then use it.

 Check that all devices are accessible */

/*

 * pci_scan_bridge() - Scan buses behind a bridge

 * @bus: Parent bus the bridge is on

 * @dev: Bridge itself

 * @max: Starting subordinate number of buses behind this bridge

 * @pass: Either %0 (scan already configured bridges) or %1 (scan bridges

 *        that need to be reconfigured.

 *

 * If it's a bridge, configure it and scan the bus behind it.

 * For CardBus bridges, we don't scan behind as the devices will

 * be handled by the bridge driver itself.

 *

 * We need to process bridges in two passes -- first we scan those

 * already configured by the BIOS and after we are done with all of

 * them, we proceed to assigning numbers to the remaining buses in

 * order to avoid overlaps between old and new bus numbers.

 *

 * Return: New subordinate number covering all buses behind this bridge.

/*

 * Read interrupt line and base address registers.

 * The architecture-dependent code can tweak these, of course.

 VFs are not allowed to use INTx, so skip the config reads */

	/*

	 * Some systems do not identify their upstream/downstream ports

	 * correctly so detect impossible configurations here and correct

	 * the port type accordingly.

		/*

		 * If pdev claims to be downstream port but the parent

		 * device is also downstream port assume pdev is actually

		 * upstream port.

		/*

		 * If pdev claims to be upstream port but the parent

		 * device is also upstream port assume pdev is actually

		 * downstream port.

 Is the device part of a Thunderbolt controller? */

	/*

	 * If the upstream bridge is untrusted we treat this device

	 * untrusted as well.

	/*

	 * We (only) consider everything downstream from an external_facing

	 * device to be removable by the user. We're mainly concerned with

	 * consumer platforms with user accessible thunderbolt ports that are

	 * vulnerable to DMA attacks, and we expect those ports to be marked by

	 * the firmware as external_facing. Devices in traditional hotplug

	 * slots can technically be removed, but the expectation is that unless

	 * the port is marked with external_facing, such devices are less

	 * accessible to user / may not be removed by end user, and thus not

	 * exposed as "removable" to userspace.

/**

 * pci_ext_cfg_is_aliased - Is ext config space just an alias of std config?

 * @dev: PCI device

 *

 * PCI Express to PCI/PCI-X Bridge Specification, rev 1.0, 4.1.4 says that

 * when forwarding a type1 configuration request the bridge must check that

 * the extended register address field is zero.  The bridge is not permitted

 * to forward the transactions and must handle it as an Unsupported Request.

 * Some bridges do not follow this rule and simply drop the extended register

 * bits, resulting in the standard config space being aliased, every 256

 * bytes across the entire configuration space.  Test for this condition by

 * comparing the first dword of each potential alias to the vendor/device ID.

 * Known offenders:

 *   ASM1083/1085 PCIe-to-PCI Reversible Bridge (1b21:1080, rev 01 & 03)

 *   AMD/ATI SBx00 PCI to PCI Bridge (1002:4384, rev 40)

/**

 * pci_cfg_space_size_ext - Get the configuration space size of the PCI device

 * @dev: PCI device

 *

 * Regular PCI devices have 256 bytes, but PCI-X 2 and PCI Express devices

 * have 4096 bytes.  Even if the device is capable, that doesn't mean we can

 * access it.  Maybe we don't have a way to generate extended config space

 * accesses, or the device is behind a reverse Express bridge.  So we try

 * reading the dword at 0x100 which must either be 0 or a valid extended

 * capability header.

	/*

	 * Per the SR-IOV specification (rev 1.1, sec 3.5), VFs are required to

	 * implement a PCIe capability and therefore must implement extended

	 * config space.  We can skip the NO_EXTCFG test below and the

	 * reachability/aliasing test in pci_cfg_space_size_ext() by virtue of

	 * the fact that the SR-IOV capability on the PF resides in extended

	 * config space and must be accessible and non-aliased to have enabled

	 * support for this VF.  This is a micro performance optimization for

	 * systems supporting many VFs.

/**

 * pci_intx_mask_broken - Test PCI_COMMAND_INTX_DISABLE writability

 * @dev: PCI device

 *

 * Test whether PCI_COMMAND_INTX_DISABLE is writable for @dev.  Check this

 * at enumeration-time to avoid modifying PCI_COMMAND at run-time.

	/*

	 * PCI_COMMAND_INTX_DISABLE was reserved and read-only prior to PCI

	 * r2.3, so strictly speaking, a device is not *broken* if it's not

	 * writable.  But we'll live with the misnomer for now.

/**

 * pci_setup_device - Fill in class and map information of a device

 * @dev: the device structure to fill

 *

 * Initialize the device structure with information about the device's

 * vendor,class,memory and IO-space addresses, IRQ lines etc.

 * Called at initialisation of the PCI subsystem and by CardBus services.

 * Returns 0 on success and negative if unknown type of device (not normal,

 * bridge or CardBus).

	/*

	 * Assume 32-bit PCI; let 64-bit PCI cards (which are far rarer)

	 * set this higher, assuming the system even supports it.

 upper 3 bytes */

 Need to have dev->class ready */

 Need to have dev->cfg_size ready */

 "Unknown power state" */

 Early fixups, before probing the BARs */

 Device class may be changed after fixup */

 header type */

 standard header */

		/*

		 * Do the ugly legacy mode stuff here rather than broken chip

		 * quirk code. Legacy mode ATA controllers have fixed

		 * addresses. These are not always echoed in BAR0-3, and

		 * BAR0-3 in a few cases contain junk!

 bridge header */

		/*

		 * The PCI-to-PCI bridge spec requires that subtractive

		 * decoding (i.e. transparent) bridge must have programming

		 * interface code of 0x01.

 CardBus bridge header */

 unknown header */

 We found a fine healthy device, go go go... */

 MPS and MRRS fields are of type 'RsvdP' for VFs, short-circuit out */

	/*

	 * For Root Complex Integrated Endpoints, program the maximum

	 * supported value unless limited by the PCIE_BUS_PEER2PEER case.

	/*

	 * Fancier MPS configuration is done later by

	 * pcie_bus_configure_settings()

	/*

	 * If some device in the hierarchy doesn't handle Extended Tags

	 * correctly, make sure they're disabled.

/**

 * pcie_relaxed_ordering_enabled - Probe for PCIe relaxed ordering enable

 * @dev: PCI device to query

 *

 * Returns true if the device has enabled relaxed ordering attribute.

 PCI_EXP_DEVICE_RELAX_EN is RsvdP in VFs */

	/*

	 * For now, we only deal with Relaxed Ordering issues with Root

	 * Ports. Peer-to-Peer DMA is another can of worms.

 Read L1 PM substate capabilities */

	/*

	 * Software must not enable LTR in an Endpoint unless the Root

	 * Complex and all intermediate Switches indicate support for LTR.

	 * PCIe r4.0, sec 6.18.

	/*

	 * If we're configuring a hot-added device, LTR was likely

	 * disabled in the upstream bridge, so re-enable it before enabling

	 * it in the new device.

		/*

		 * A bridge will not forward ERR_ messages coming from an

		 * endpoint unless SERR# forwarding is enabled.

/**

 * pci_release_dev - Free a PCI device structure when all users of it are

 *		     finished

 * @dev: device that's been disconnected

 *

 * Will be called only by the device core when all users of this PCI device are

 * done.

 not a CRS completion */

 CRS, but caller doesn't want to wait */

	/*

	 * We got the reserved Vendor ID that indicates a completion with

	 * Configuration Request Retry Status (CRS).  Retry until we get a

	 * valid Vendor ID or we time out.

 Some broken boards return 0 or ~0 if a slot is empty: */

	/*

	 * Certain IDT switches have an issue where they improperly trigger

	 * ACS Source Validation errors on completions for config reads.

/*

 * Read the config data for a PCI device, sanity-check it,

 * and fill in the dev structure.

 Look from the device up to avoid downstream ports with no devices */

 Multi-function PCIe devices share the same link/status */

 Print link status only if the device is constrained by the fabric */

 Enhanced Allocation */

 Disable MSI */

 Disable MSI-X */

 Buffers for saving PCIe and PCI-X capabilities */

 Power Management */

 Vital Product Data */

 Alternative Routing-ID Forwarding */

 Single Root I/O Virtualization */

 Address Translation Services */

 Page Request Interface */

 Process Address Space ID */

 Access Control Services */

 Precision Time Measurement */

 Advanced Error Reporting */

 Downstream Port Containment */

 Root Complex Event Collector */

/*

 * This is the equivalent of pci_host_bridge_msi_domain() that acts on

 * devices. Firmware interfaces that can select the MSI domain on a

 * per-device basis should be called from here.

	/*

	 * If a domain has been set through the pcibios_device_add()

	 * callback, then this is the one (platform code knows best).

	/*

	 * Let's see if we have a firmware interface able to provide

	 * the domain.

	/*

	 * If the platform or firmware interfaces cannot supply a

	 * device-specific MSI domain, then inherit the default domain

	 * from the host bridge itself.

 Fix up broken headers */

	/*

	 * Add the device to our list of discovered devices

	 * and the bus list for fixup functions, etc.

 Set up MSI IRQ domain */

 Notifier could use PCI capabilities */

 protect against malformed list */

 dev may be NULL for non-contiguous multifunction devices */

	/*

	 * Systems with unusual topologies set PCI_SCAN_ALL_PCIE_DEVS so

	 * we scan for all possible devices, not just Device 0.

	/*

	 * A PCIe Downstream Port normally leads to a Link with only Device

	 * 0 on it (PCIe spec r3.1, sec 7.3.1).  As an optimization, scan

	 * only for Device 0 in that situation.

/**

 * pci_scan_slot - Scan a PCI slot on a bus for devices

 * @bus: PCI bus to scan

 * @devfn: slot number to scan (must have zero function)

 *

 * Scan a PCI slot on the specified PCI bus for devices, adding

 * discovered devices to the @bus->devices list.  New devices

 * will not have is_added set.

 *

 * Returns the number of new devices found.

 Already scanned the entire slot */

 Only one slot has PCIe device */

	/*

	 * We don't have a way to change MPS settings on devices that have

	 * drivers attached.  A hot-added device might support only the minimum

	 * MPS setting (MPS=128).  Therefore, if the fabric contains a bridge

	 * where devices may be hot-added, we limit the fabric MPS to 128 so

	 * hot-added devices will work correctly.

	 *

	 * However, if we hot-add a device to a slot directly below a Root

	 * Port, it's impossible for there to be other existing devices below

	 * the port.  We don't limit the MPS in this case because we can

	 * reconfigure MPS on both the Root Port and the hot-added device,

	 * and there are no other devices involved.

	 *

	 * Note that this PCIE_BUS_SAFE path assumes no peer-to-peer DMA.

			/*

			 * For "Performance", the assumption is made that

			 * downstream communication will never be larger than

			 * the MRRS.  So, the MPS only needs to be configured

			 * for the upstream communication.  This being the case,

			 * walk from the top down and set the MPS of the child

			 * to that of the parent bus.

			 *

			 * Configure the device MPS with the smaller of the

			 * device MPSS or the bridge MPS (which is assumed to be

			 * properly configured at this point to the largest

			 * allowable MPS based on its parent bus).

	/*

	 * In the "safe" case, do not configure the MRRS.  There appear to be

	 * issues with setting MRRS to 0 on a number of devices.

	/*

	 * For max performance, the MRRS must be set to the largest supported

	 * value.  However, it cannot be configured larger than the MPS the

	 * device or the bus can support.  This should already be properly

	 * configured by a prior call to pcie_write_mps().

	/*

	 * MRRS is a R/W register.  Invalid values can be written, but a

	 * subsequent read will verify if the value is acceptable or not.

	 * If the MRRS value provided is not acceptable (e.g., too large),

	 * shrink the value until it is acceptable to the HW.

/*

 * pcie_bus_configure_settings() requires that pci_walk_bus work in a top-down,

 * parents then children fashion.  If this changes, then this code will not

 * work as designed.

	/*

	 * FIXME - Peer to peer DMA is possible, though the endpoint would need

	 * to be aware of the MPS of the destination.  To work around this,

	 * simply force the MPS of the entire system to the smallest possible.

/*

 * Called after each bus is probed, but before its children are examined.  This

 * is marked as __weak because multiple architectures define it.

 nothing to do, expected to be removed in the future */

/**

 * pci_scan_child_bus_extend() - Scan devices below a bus

 * @bus: Bus to scan for devices

 * @available_buses: Total number of buses available (%0 does not try to

 *		     extend beyond the minimal)

 *

 * Scans devices below @bus including subordinate buses. Returns new

 * subordinate number including all the found devices. Passing

 * @available_buses causes the remaining bus space to be distributed

 * equally between hotplug-capable bridges to allow future extension of the

 * hierarchy.

 Go find them, Rover! */

		/*

		 * The Jailhouse hypervisor may pass individual functions of a

		 * multi-function device to a guest without passing function 0.

		 * Look for them as well.

 Reserve buses for SR-IOV capability */

	/*

	 * After performing arch-dependent fixup of the bus, look behind

	 * all PCI-to-PCI bridges on this bus.

	/*

	 * Calculate how many hotplug bridges and normal bridges there

	 * are on this bus. We will distribute the additional available

	 * buses between hotplug bridges.

	/*

	 * Scan bridges that are already configured. We don't touch them

	 * unless they are misconfigured (which will be done in the second

	 * scan below).

		/*

		 * Reserve one bus for each bridge now to avoid extending

		 * hotplug bridges too much during the second scan below.

 Scan bridges that need to be reconfigured */

			/*

			 * There is only one bridge on the bus (upstream

			 * port) so it gets all available buses which it

			 * can then distribute to the possible hotplug

			 * bridges below.

			/*

			 * Distribute the extra buses between hotplug

			 * bridges if any.

 One bus is already accounted so don't add it again */

	/*

	 * Make sure a hotplug bridge has at least the minimum requested

	 * number of buses but allow it to grow up to the maximum available

	 * bus number of there is room.

 Do not allocate more buses than we have room left */

	/*

	 * We've scanned the bus and so we know all about what's on

	 * the other side of any bridges that may be on this bus plus

	 * any devices.

	 *

	 * Return how far we've got finding sub-buses.

/**

 * pci_scan_child_bus() - Scan devices below a bus

 * @bus: Bus to scan for devices

 *

 * Scans devices below @bus including subordinate buses. Returns new

 * subordinate number including all the found devices.

/**

 * pcibios_root_bridge_prepare - Platform-specific host bridge setup

 * @bridge: Host bridge to set up

 *

 * Default empty implementation.  Replace with an architecture-specific setup

 * routine, if necessary.

	/*

	 * We insert PCI resources into the iomem_resource and

	 * ioport_resource trees in either pci_bus_claim_resources()

	 * or pci_bus_assign_resources().

/**

 * pci_rescan_bus_bridge_resize - Scan a PCI bus for devices

 * @bridge: PCI bridge for the bus to scan

 *

 * Scan a PCI bus and child buses for new devices, add them,

 * and enable them, resizing bridge mmio/io resource if necessary

 * and possible.  The caller must ensure the child devices are already

 * removed for resizing to occur.

 *

 * Returns the max number of subordinate bus discovered.

/**

 * pci_rescan_bus - Scan a PCI bus for devices

 * @bus: PCI bus to scan

 *

 * Scan a PCI bus and child buses for new devices, add them,

 * and enable them.

 *

 * Returns the max number of subordinate bus discovered.

/*

 * pci_rescan_bus(), pci_rescan_bus_bridge_resize() and PCI device removal

 * routines should always be executed under this mutex.

 Scan bridges that are already configured */

	/*

	 * Distribute the available bus numbers between hotplug-capable

	 * bridges to make extending the chain later possible.

 Scan bridges that need to be reconfigured */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI IRQ handling code

 *

 * Copyright (c) 2008 James Bottomley <James.Bottomley@HansenPartnership.com>

 * Copyright (C) 2017 Christoph Hellwig.

/**

 * pci_request_irq - allocate an interrupt line for a PCI device

 * @dev:	PCI device to operate on

 * @nr:		device-relative interrupt vector index (0-based).

 * @handler:	Function to be called when the IRQ occurs.

 *		Primary handler for threaded interrupts.

 *		If NULL and thread_fn != NULL the default primary handler is

 *		installed.

 * @thread_fn:	Function called from the IRQ handler thread

 *		If NULL, no IRQ thread is created

 * @dev_id:	Cookie passed back to the handler function

 * @fmt:	Printf-like format string naming the handler

 *

 * This call allocates interrupt resources and enables the interrupt line and

 * IRQ handling. From the point this call is made @handler and @thread_fn may

 * be invoked.  All interrupts requested using this function might be shared.

 *

 * @dev_id must not be NULL and must be globally unique.

/**

 * pci_free_irq - free an interrupt allocated with pci_request_irq

 * @dev:	PCI device to operate on

 * @nr:		device-relative interrupt vector index (0-based).

 * @dev_id:	Device identity to free

 *

 * Remove an interrupt handler. The handler is removed and if the interrupt

 * line is no longer in use by any driver it is disabled.  The caller must

 * ensure the interrupt is disabled on the device before calling this function.

 * The function does not return until any executing interrupts for this IRQ

 * have completed.

 *

 * This function must not be called from interrupt context.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2016 Broadcom

/*

 * On 64-bit systems, we do a single ioremap for the whole config space

 * since we have enough virtual address range available.  On 32-bit, we

 * ioremap the config space for each bus individually.

/*

 * Create a PCI config space window

 *  - reserve mem region

 *  - alloc struct pci_config_window with space for all mappings

 *  - ioremap the config space

 ECAM-compliant platforms need not supply ops->bus_shift */

/*

 * Function to implement the pci_ops ->map_bus method

 ECAM ops */

 ECAM ops for 32-bit access only (non-compliant) */

 ECAM ops for 32-bit read only (non-compliant) */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Express I/O Virtualization (IOV) support

 *   Single Root IOV 1.0

 *   Address Translation Service 1.0

 *

 * Copyright (C) 2009 Intel Corporation, Yu Zhao <yu.zhao@intel.com>

/*

 * Per SR-IOV spec sec 3.3.10 and 3.3.11, First VF Offset and VF Stride may

 * change when NumVFs changes.

 *

 * Update iov->offset and iov->stride when NumVFs is written.

/*

 * The PF consumes one bus number.  NumVFs, First VF Offset, and VF Stride

 * determine how many additional bus numbers will be consumed by VFs.

 *

 * Iterate over all valid NumVFs, validate offset and stride, and calculate

 * the maximum number of bus numbers that could ever be required.

	/*

	 * Some config registers are the same across all associated VFs.

	 * Read them once from VF0 so we can skip reading them from the

	 * other VFs.

	 *

	 * PCIe r4.0, sec 9.3.4.1, technically doesn't require all VFs to

	 * have the same Revision ID and Subsystem ID, but we assume they

	 * do.

		/*

		 * A driver is already attached to this VF and has configured

		 * itself based on the current MSI-X vector count. Changing

		 * the vector size could mess up the driver, so block it.

	/*

	 * pci_stop_dev() could have been called for this virtfn already,

	 * so the directory for the virtfn may have been removed before.

	 * Double check to avoid spurious sysfs warnings.

 balance pci_get_domain_bus_and_slot() */

 Serialize vs sriov_numvfs_store() so readers see valid num_VFs */

/*

 * num_vfs > 0; number of VFs to enable

 * num_vfs = 0; disable all VFs

 *

 * Note: SRIOV spec does not allow partial VF

 *	 disable, so it's all or none.

 is PF driver loaded */

 is PF driver loaded w/callback */

 disable VFs */

 enable VFs */

		/*

		 * If it is already FIXED, don't change it, something

		 * (perhaps EA or header fixups) wants it this way.

	/*

	 * Restore PCI_SRIOV_CTRL_ARI before pci_iov_set_numvfs() because

	 * it reads offset & stride, which depend on PCI_SRIOV_CTRL_ARI.

/**

 * pci_iov_init - initialize the IOV capability

 * @dev: the PCI device

 *

 * Returns 0 on success, or negative on failure.

/**

 * pci_iov_release - release resources used by the IOV capability

 * @dev: the PCI device

/**

 * pci_iov_remove - clean up SR-IOV state after PF driver is detached

 * @dev: the PCI device

/**

 * pci_iov_update_resource - update a VF BAR

 * @dev: the PCI device

 * @resno: the resource number

 *

 * Update a VF BAR in the SR-IOV capability of a PF.

	/*

	 * The generic pci_restore_bars() path calls this for all devices,

	 * including VFs and non-SR-IOV devices.  If this is not a PF, we

	 * have nothing to do.

	/*

	 * Ignore unimplemented BARs, unused resource slots for 64-bit

	 * BARs, and non-movable resources, e.g., those described via

	 * Enhanced Allocation.

/**

 * pci_sriov_resource_alignment - get resource alignment for VF BAR

 * @dev: the PCI device

 * @resno: the resource number

 *

 * Returns the alignment of the VF BAR found in the SR-IOV capability.

 * This is not the same as the resource size which is defined as

 * the VF BAR size multiplied by the number of VFs.  The alignment

 * is just the VF BAR size.

/**

 * pci_restore_iov_state - restore the state of the IOV capability

 * @dev: the PCI device

/**

 * pci_vf_drivers_autoprobe - set PF property drivers_autoprobe for VFs

 * @dev: the PCI device

 * @auto_probe: set VF drivers auto probe flag

/**

 * pci_iov_bus_range - find bus range used by Virtual Function

 * @bus: the PCI bus

 *

 * Returns max number of buses (exclude current one) used by Virtual

 * Functions.

/**

 * pci_enable_sriov - enable the SR-IOV capability

 * @dev: the PCI device

 * @nr_virtfn: number of virtual functions to enable

 *

 * Returns 0 on success, or negative on failure.

/**

 * pci_disable_sriov - disable the SR-IOV capability

 * @dev: the PCI device

/**

 * pci_num_vf - return number of VFs associated with a PF device_release_driver

 * @dev: the PCI device

 *

 * Returns number of VFs, or 0 if SR-IOV is not enabled.

/**

 * pci_vfs_assigned - returns number of VFs are assigned to a guest

 * @dev: the PCI device

 *

 * Returns number of VFs belonging to this device that are assigned to a guest.

 * If device is not a physical function returns 0.

 only search if we are a PF */

	/*

	 * determine the device ID for the VFs, the vendor ID will be the

	 * same as the PF so there is no need to check for that one

 loop through all the VFs to see if we own any that are assigned */

		/*

		 * It is considered assigned if it is a virtual function with

		 * our dev as the physical function and the assigned bit is set

/**

 * pci_sriov_set_totalvfs -- reduce the TotalVFs available

 * @dev: the PCI PF device

 * @numvfs: number that should be used for TotalVFs supported

 *

 * Should be called from PF driver's probe routine with

 * device's mutex held.

 *

 * Returns 0 if PF is an SRIOV-capable device and

 * value of numvfs valid. If not a PF return -ENOSYS;

 * if numvfs is invalid return -EINVAL;

 * if VFs already enabled, return -EBUSY.

 Shouldn't change if VFs already enabled */

/**

 * pci_sriov_get_totalvfs -- get total VFs supported on this device

 * @dev: the PCI PF device

 *

 * For a PCIe device with SRIOV support, return the PCIe

 * SRIOV capability value of TotalVFs or the value of driver_max_VFs

 * if the driver reduced it.  Otherwise 0.

/**

 * pci_sriov_configure_simple - helper to configure SR-IOV

 * @dev: the PCI device

 * @nr_virtfn: number of virtual functions to enable, 0 to disable

 *

 * Enable or disable SR-IOV for devices that don't require any PF setup

 * before enabling SR-IOV.  Return value is negative on error, or number of

 * VFs allocated on success.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe AER software error injection support.

 *

 * Debugging PCIe AER code is quite difficult because it is hard to

 * trigger various real hardware errors. Software based error

 * injection can fake almost all kinds of errors with the help of a

 * user space helper tool aer-inject, which can be gotten from:

 *   https://www.kernel.org/pub/linux/utils/pci/aer-inject/

 *

 * Copyright 2009 Intel Corporation.

 *     Huang Ying <ying.huang@intel.com>

 Override the existing corrected and uncorrected error masks */

 Protect einjected and pci_bus_ops_list */

 inject_lock must be held before calling */

 inject_lock must be held before calling */

 inject_lock must be held before calling */

 If Root Port not found, try to find an RCEC */

 SPDX-License-Identifier: GPL-2.0

/*

 * Enable PCIe link L0s/L1 state and Clock Power Management

 *

 * Copyright (C) 2007 Intel

 * Copyright (C) Zhang Yanmin (yanmin.zhang@intel.com)

 * Copyright (C) Shaohua Li (shaohua.li@intel.com)

 Note: those are not register definitions */

 Upstream direction L0s state */

 Downstream direction L0s state */

 L1 state */

 ASPM L1.1 state */

 ASPM L1.2 state */

 PCI PM L1.1 state */

 PCI PM L1.2 state */

 L0s latency (nsec) */

 L1 latency (nsec) */

 Upstream component of the Link */

 Downstream component, function 0 */

 pointer to the root port link */

 pointer to the parent Link state */

 node in link_list */

 ASPM state */

 Supported ASPM state */

 Enabled ASPM state */

 Capable ASPM state with latency */

 Default ASPM state by BIOS */

 Disabled ASPM state */

 Clock PM state */

 Clock PM capable? */

 Current Clock PM state */

 Default Clock PM state by BIOS */

 Clock PM disabled */

 Exit latencies */

 Upstream direction exit latency */

 Downstream direction exit latency */

	/*

	 * Endpoint acceptable latencies. A pcie downstream port only

	 * has one slot under it, so at most there are 8 functions.

 BIOS default setting */

 high performance */

 high power saving */

 possibly even more power saving */

 Disable ASPM and Clock PM */

 Enable ASPM L0s/L1 */

 Enable Everything */

 Disable ASPM and Clock PM */

 Enable Clock PM */

	/*

	 * Don't enable Clock PM if the link is not Clock PM capable

	 * or Clock PM is disabled

 Need nothing if the specified equals to current state */

 All functions should have the same cap and state, take the worst */

		/*

		 * Due to an erratum in some devices the Retrain Link bit

		 * needs to be cleared again manually to allow the link

		 * training to succeed.

 Wait for link training end. Break out after waiting for timeout */

/*

 * pcie_aspm_configure_common_clock: check if the 2 ends of a link

 *   could use common clock. If they are, configure them to use the

 *   common clock. That will reduce the ASPM state exit latency.

	/*

	 * All functions of a slot should have the same Slot Clock

	 * Configuration, so just check one function

 Check downstream component if bit Slot Clock Configuration is 1 */

 Check upstream component if bit Slot Clock Configuration is 1 */

 Port might be already in common clock mode */

 Configure downstream component, all functions */

 Configure upstream component */

 Training failed. Restore common clock configurations */

 Convert L0s latency encoding to ns */

 > 4us */

 Convert L0s acceptable latency encoding to ns */

 Convert L1 latency encoding to ns */

 > 64us */

 Convert L1 acceptable latency encoding to ns */

 Convert L1SS T_pwr encoding to usec */

 See PCIe r3.1, sec 7.33.3 and sec 6.18 */

 Device not in D0 doesn't need latency check */

 Check upstream direction L0s latency */

 Check downstream direction L0s latency */

		/*

		 * Check L1 latency.

		 * Every switch on the path to root complex need 1

		 * more microsecond for L1. Spec doesn't mention L0s.

		 *

		 * The exit latencies for L1 substates are not advertised

		 * by a device.  Since the spec also doesn't mention a way

		 * to determine max latencies introduced by enabling L1

		 * substates on the components, it is not clear how to do

		 * a L1 substate exit latency check.  We assume that the

		 * L1 exit latencies advertised by a device include L1

		 * substate latencies (and hence do not do any check).

/*

 * The L1 PM substate capability is only implemented in function 0 in a

 * multi function device.

 Calculate L1.2 PM substate timing parameters */

 Choose the greater of the two Port Common_Mode_Restore_Times */

 Choose the greater of the two Port T_POWER_ON times */

	/*

	 * Set LTR_L1.2_THRESHOLD to the time required to transition the

	 * Link from L0 to L1.2 and back to L0 so we enter L1.2 only if

	 * downstream devices report (via LTR) that they can tolerate at

	 * least that much latency.

	 *

	 * Based on PCIe r3.1, sec 5.5.3.3.1, Figures 5-16 and 5-17, and

	 * Table 5-11.  T(POWER_OFF) is at most 2us and T(L1.2) is at

	 * least 4us.

 Disable L1.2 while updating.  See PCIe r5.0, sec 5.5.4, 7.8.3.3 */

 Program T_POWER_ON times in both ports */

 Program Common_Mode_Restore_Time in upstream device */

 Program LTR_L1.2_THRESHOLD time in both ports */

 Set enabled/disable so that we will disable ASPM later */

	/*

	 * If ASPM not supported, don't mess with the clocks and link,

	 * bail out now.

 Configure common clock before checking latencies */

	/*

	 * Re-read upstream/downstream components' register state after

	 * clock configuration.  L0s & L1 exit latencies in the otherwise

	 * read-only Link Capabilities may change depending on common clock

	 * configuration (PCIe r5.0, sec 7.5.3.6).

	/*

	 * Setup L0s state

	 *

	 * Note that we must not enable L0s in either direction on a

	 * given link unless components on both sides of the link each

	 * support L0s.

 Setup L1 state */

 Setup L1 substate */

	/*

	 * If we don't have LTR for the entire path from the Root Complex

	 * to this device, we can't use ASPM L1.2 because it relies on the

	 * LTR_L1.2_THRESHOLD.  See PCIe r4.0, secs 5.5.4, 6.18.

 Save default state */

 Setup initial capable state. Will be updated later */

 Get and check endpoint acceptable latencies */

 Calculate endpoint L0s acceptable latency */

 Calculate endpoint L1 acceptable latency */

 Configure the ASPM L1 substates */

	/*

	 * Here are the rules specified in the PCIe spec for enabling L1SS:

	 * - When enabling L1.x, enable bit at parent first, then at child

	 * - When disabling L1.x, disable bit at child first, then at parent

	 * - When enabling ASPM L1.x, need to disable L1

	 *   (at child followed by parent).

	 * - The ASPM/PCIPM L1.2 must be disabled while programming timing

	 *   parameters

	 *

	 * To keep it simple, disable all L1SS bits first, and later enable

	 * what is needed.

 Disable all L1 substates */

	/*

	 * If needed, disable L1, and it gets enabled later

	 * in pcie_config_aspm_link().

 Enable what we need to enable */

 Enable only the states that were not explicitly disabled */

 Can't enable any substates if L1 is not enabled */

 Spec says both ports must be in D0 before enabling PCI PM substates*/

 Nothing to do if the link is already in the requested state */

 Convert ASPM state to upstream/downstream ASPM register state */

	/*

	 * Spec 2.0 suggests all functions should be configured the

	 * same setting for ASPM. Enabling ASPM L1 should be done in

	 * upstream component first and then downstream, and vice

	 * versa for disabling ASPM L1. Spec doesn't mention L0S.

	/*

	 * Some functions in a slot might not all be PCIe functions,

	 * very strange. Disable ASPM for the whole slot

		/*

		 * If ASPM is disabled then we're not going to change

		 * the BIOS state. It's safe to continue even if it's a

		 * pre-1.1 device

		/*

		 * Disable ASPM for pre-1.1 PCIe device, we follow MS to use

		 * RBER bit to determine if a function is 1.1 version device

	/*

	 * Root Ports and PCI/PCI-X to PCIe Bridges are roots of PCIe

	 * hierarchies.  Note that some PCIe host implementations omit

	 * the root ports entirely, in which case a downstream port on

	 * a switch may become the root of the link state chain for all

	 * its subordinate endpoints.

/*

 * pcie_aspm_init_link_state: Initiate PCI express link state.

 * It is called after the pcie and its children devices are scanned.

 * @pdev: the root port or switch downstream port

	/*

	 * We allocate pcie_link_state for the component on the upstream

	 * end of a Link, so there's nothing to do unless this device is

	 * downstream port.

 VIA has a strange chipset, root port is under a bridge */

	/*

	 * Setup initial ASPM state. Note that we need to configure

	 * upstream links also because capable state of them can be

	 * update through pcie_aspm_cap_init().

 Setup initial Clock PM state */

	/*

	 * At this stage drivers haven't had an opportunity to change the

	 * link policy setting. Enabling ASPM on broken hardware can cripple

	 * it even before the driver has had a chance to disable ASPM, so

	 * default to a safe level right now. If we're enabling ASPM beyond

	 * the BIOS's expectation, we'll do so once pci_enable_device() is

	 * called.

 Recheck latencies and update aspm_capable for links under the root */

 @pdev: the endpoint device */

	/*

	 * All PCIe functions are in one slot, remove one function will remove

	 * the whole slot, so just wait until we are the last function left.

 All functions are removed, so just disable ASPM for the link */

 Clock PM is for endpoint device */

 Recheck latencies and configure upstream links */

 @pdev: the root port or switch downstream port */

	/*

	 * Devices changed PM state, we should recheck if latency

	 * meets all functions' requirement

	/*

	 * A driver requested that ASPM be disabled on this device, but

	 * if we don't have permission to manage ASPM (e.g., on ACPI

	 * systems we have to observe the FADT ACPI_FADT_NO_ASPM bit and

	 * the _OSC method), we can't honor that request.  Windows has

	 * a similar mechanism using "PciASPMOptOut", which is also

	 * ignored in this situation.

 L1 PM substates require L1 */

/**

 * pci_disable_link_state - Disable device's link state, so the link will

 * never enter specific states.  Note that if the BIOS didn't grant ASPM

 * control to the OS, this does nothing because we can't touch the LNKCTL

 * register. Returns 0 or a negative errno.

 *

 * @pdev: PCI device

 * @state: ASPM link state to disable

/**

 * pcie_aspm_enabled - Check if PCIe ASPM has been enabled for a device.

 * @pdev: Target device.

 *

 * Relies on the upstream bridge's link_state being valid.  The link_state

 * is deallocated only when the last child of the bridge (i.e., @pdev or a

 * sibling) is removed, and the caller should be holding a reference to

 * @pdev, so this should be safe.

 need to enable L1 for substates */

	/*

	 * Disabling ASPM is intended to prevent the kernel from modifying

	 * existing hardware state, not to clear existing state. To that end:

	 * (a) set policy to POLICY_DEFAULT in order to avoid changing state

	 * (b) prevent userspace from changing policy

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Express Downstream Port Containment services driver

 * Author: Keith Busch <keith.busch@intel.com>

 *

 * Copyright (C) 2016 Intel Corp.

 Bit Position 0  */

 Bit Position 1  */

 Bit Position 2  */

 Bit Position 8  */

 Bit Position 9  */

 Bit Position 10 */

 Bit Position 16 */

 Bit Position 17 */

 Bit Position 18 */

/**

 * pci_dpc_recovered - whether DPC triggered and has recovered successfully

 * @pdev: PCI device

 *

 * Return true if DPC was triggered for @pdev and has recovered successfully.

 * Wait for recovery if it hasn't completed yet.  Called from the PCIe hotplug

 * driver to recognize and ignore Link Down/Up events caused by DPC.

	/*

	 * Synchronization between hotplug and DPC is not supported

	 * if DPC is owned by firmware and EDR is not enabled.

	/*

	 * Need a timeout in case DPC never completes due to failure of

	 * dpc_wait_rp_inactive().  The spec doesn't mandate a time limit,

	 * but reports indicate that DPC completes within 4 seconds.

 CONFIG_HOTPLUG_PCI_PCIE */

	/*

	 * DPC disables the Link automatically in hardware, so it has

	 * already been reset by the time we get here.

	/*

	 * Wait until the Link is inactive, then clear DPC Trigger Status

	 * to allow the Port to leave DPC.

 Get First Error Pointer */

 show RP PIO error detail information */

 We configure DPC so it only triggers on ERR_FATAL */

 SPDX-License-Identifier: GPL-2.0

/*

 * Root Complex Event Collector Support

 *

 * Authors:

 *  Sean V Kelley <sean.v.kelley@intel.com>

 *  Qiuxu Zhuo <qiuxu.zhuo@intel.com>

 *

 * Copyright (C) 2020 Intel Corp.

 An RCiEP found on a different bus in range */

 Same bus, so check bitmap */

 Walk own bus for bitmap based association */

 All RCiEP devices are on the same bus as the RCEC */

 No association indicated (PCIe 5.0-1, 7.9.10.3) */

 Find RCiEP devices on the given bus ranges */

/**

 * pcie_link_rcec - Link RCiEP devices associated with RCEC.

 * @rcec: RCEC whose RCiEP devices should be linked.

 *

 * Link the given RCEC to each RCiEP device found.

/**

 * pcie_walk_rcec - Walk RCiEP devices associating with RCEC and call callback.

 * @rcec:	RCEC whose RCiEP devices should be walked

 * @cb:		Callback to be called for each RCiEP device found

 * @userdata:	Arbitrary pointer to be passed to callback

 *

 * Walk the given RCEC. Call the callback on each RCiEP found.

 *

 * If @cb returns anything other than 0, break out.

 Only for Root Complex Event Collectors */

 Check whether RCEC BUSN register is present */

 Avoid later ver check by setting nextbusn */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Error Disconnect Recover support

 * Author: Kuppuswamy Sathyanarayanan <sathyanarayanan.kuppuswamy@linux.intel.com>

 *

 * Copyright (C) 2020 Intel Corp.

/*

 * _DSM wrapper function to enable/disable DPC

 * @pdev   : PCI device structure

 *

 * returns 0 on success or errno on failure.

	/*

	 * Behavior when calling unsupported _DSM functions is undefined,

	 * so check whether EDR_PORT_DPC_ENABLE_DSM is supported.

	/*

	 * Per Downstream Port Containment Related Enhancements ECN to PCI

	 * Firmware Specification r3.2, sec 4.6.12, EDR_PORT_DPC_ENABLE_DSM is

	 * optional.  Return success if it's not implemented.

/*

 * _DSM wrapper function to locate DPC port

 * @pdev   : Device which received EDR event

 *

 * Returns pci_dev or NULL.  Caller is responsible for dropping a reference

 * on the returned pci_dev with pci_dev_put().

	/*

	 * Behavior when calling unsupported _DSM functions is undefined,

	 * so check whether EDR_PORT_DPC_ENABLE_DSM is supported.

	/*

	 * Firmware returns DPC port BDF details in following format:

	 *	15:8 = bus

	 *	 7:3 = device

	 *	 2:0 = function

/*

 * _OST wrapper function to let firmware know the status of EDR event

 * @pdev   : Device used to send _OST

 * @edev   : Device which experienced EDR event

 * @status : Status of EDR event

 Locate the port which issued EDR event */

 If port does not support DPC, just send the OST */

 Check if there is a valid DPC trigger */

	/*

	 * Irrespective of whether the DPC event is triggered by ERR_FATAL

	 * or ERR_NONFATAL, since the link is already down, use the FATAL

	 * error recovery path for both cases.

	/*

	 * If recovery is successful, send _OST(0xF, BDF << 16 | 0x80)

	 * to firmware. If not successful, send _OST(0xF, BDF << 16 | 0x81).

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Express Precision Time Measurement

 * Copyright (c) 2016, Intel Corporation.

	/*

	 * Enable PTM only on interior devices (root ports, switch ports,

	 * etc.) on the assumption that it causes no link traffic until an

	 * endpoint enables it.

	/*

	 * Switch Downstream Ports are not permitted to have a PTM

	 * capability; their PTM behavior is controlled by the Upstream

	 * Port (PCIe r5.0, sec 7.9.16).

	/*

	 * There's no point in enabling PTM unless it's enabled in the

	 * upstream device or this device can be a PTM Root itself.  Per

	 * the spec recommendation (PCIe r3.1, sec 7.32.3), select the

	 * furthest upstream Time Source as the PTM Root.

	/*

	 * For a PCIe Endpoint, PTM is only useful if the endpoint can

	 * issue PTM requests to upstream devices that have PTM enabled.

	 *

	 * For Root Complex Integrated Endpoints, there is no upstream

	 * device, so there must be some implementation-specific way to

	 * associate the endpoint with a time source.

 SPDX-License-Identifier: GPL-2.0

/*

 * Implement the AER root port service driver. The driver registers an IRQ

 * handler. When a root port triggers an AER interrupt, the IRQ handler

 * collects root port status and schedules work.

 *

 * Copyright (C) 2006 Intel Corp.

 *	Tom Long Nguyen (tom.l.nguyen@intel.com)

 *	Zhang Yanmin (yanmin.zhang@intel.com)

 *

 * (C) Copyright 2009 Hewlett-Packard Development Company, L.P.

 *    Andrew Patterson <andrew.patterson@hp.com>

 as per PCI_ERR_COR_STATUS */

 as per PCI_ERR_UNCOR_STATUS*/

 Root Port device */

 AER stats for the device */

	/*

	 * Fields for all AER capable devices. They indicate the errors

	 * "as seen by this device". Note that this may mean that if an

	 * end point is causing problems, the AER counters may increment

	 * at its link partner (e.g. root port) because the errors will be

	 * "seen" by the link partner and not the problematic end point

	 * itself (which may report all counters as 0 as it never saw any

	 * problems).

 Counters for different type of correctable errors */

 Counters for different type of fatal uncorrectable errors */

 Counters for different type of nonfatal uncorrectable errors */

 Total number of ERR_COR sent by this device */

 Total number of ERR_FATAL sent by this device */

 Total number of ERR_NONFATAL sent by this device */

	/*

	 * Fields for Root ports & root complex event collectors only, these

	 * indicate the total number of ERR_COR, ERR_FATAL, and ERR_NONFATAL

	 * messages received by the root port / event collector, INCLUDING the

	 * ones that are generated internally (by the rootport itself)

 ECRC set by BIOS */

 ECRC off for performance */

 ECRC on for data integrity */

/**

 * enable_ecrc_checking - enable PCIe ECRC checking for a device

 * @dev: the PCI device

 *

 * Returns 0 on success, or negative on failure.

/**

 * disable_ecrc_checking - disables PCIe ECRC checking for a device

 * @dev: the PCI device

 *

 * Returns 0 on success, or negative on failure.

/**

 * pcie_set_ecrc_checking - set/unset PCIe ECRC checking for a device based on global policy

 * @dev: the PCI device

/**

 * pcie_ecrc_get_policy - parse kernel command-line ecrc option

 * @str: ECRC policy from kernel command line to use

 CONFIG_PCIE_ECRC */

 Clear status bits for ERR_NONFATAL errors only */

 Clear status bits for ERR_FATAL errors only */

/**

 * pci_aer_raw_clear_status - Clear AER error registers.

 * @dev: the PCI device

 *

 * Clearing AER error status registers unconditionally, regardless of

 * whether they're owned by firmware or the OS.

 *

 * Returns 0 on success, or negative on failure.

	/*

	 * We save/restore PCI_ERR_UNCOR_MASK, PCI_ERR_UNCOR_SEVER,

	 * PCI_ERR_COR_MASK, and PCI_ERR_CAP.  Root and Root Complex Event

	 * Collectors also implement PCI_ERR_ROOT_COMMAND (PCIe r5.0, sec

	 * 7.8.4).

/*

 * AER error strings

 Bit Position 0	*/

 Bit Position 6	*/

 Bit Position 7	*/

 Bit Position 8	*/

 Bit Position 12	*/

 Bit Position 13	*/

 Bit Position 14	*/

 Bit Position 15	*/

 Bit Position 16	*/

 Bit Position 17	*/

 Bit Position 18	*/

 Bit Position 19	*/

 Bit Position 20	*/

 Bit Position 21	*/

 Bit Position 22	*/

 Bit Position 23	*/

 Bit Position 24	*/

 Bit Position 25	*/

 Bit Position 26	*/

 Bit Position 27	*/

 Bit Position 28	*/

 Bit Position 29	*/

 Bit Position 30	*/

 Bit Position 31	*/

 Bit Position 0	*/

 Bit Position 4	*/

 Bit Position 5	*/

 Bit Position 12	*/

 Bit Position 13	*/

 Bit Position 14	*/

 Bit Position 15	*/

 Bit Position 16	*/

 Bit Position 17	*/

 Bit Position 18	*/

 Bit Position 19	*/

 Bit Position 20	*/

 Bit Position 21	*/

 Bit Position 22	*/

 Bit Position 23	*/

 Bit Position 24	*/

 Bit Position 25	*/

 Bit Position 26	*/

 Bit Position 27	*/

 Bit Position 28	*/

 Bit Position 29	*/

 Bit Position 30	*/

 Bit Position 31	*/

/**

 * add_error_device - list device to be handled

 * @e_info: pointer to error info

 * @dev: pointer to pci_dev to be added

/**

 * is_error_source - check whether the device is source of reported error

 * @dev: pointer to pci_dev to be checked

 * @e_info: pointer to reported error info

	/*

	 * When bus id is equal to 0, it might be a bad id

	 * reported by root port.

 Device ID match? */

 Continue id comparing if there is no multiple error */

	/*

	 * When either

	 *      1) bus id is equal to 0. Some ports might lose the bus

	 *              id of error source id;

	 *      2) bus flag PCI_BUS_FLAGS_NO_AERSID is set

	 *      3) There are multiple errors and prior ID comparing fails;

	 * We check AER status registers to find possible reporter.

 Check if AER is enabled */

 Check if error is recorded */

 List this device */

 We cannot handle more... Stop iteration */

 TODO: Should print error message here? */

 If there is only a single error, stop iteration */

/**

 * find_source_device - search through device hierarchy for source device

 * @parent: pointer to Root Port pci_dev data structure

 * @e_info: including detailed error information such like id

 *

 * Return true if found.

 *

 * Invoked by DPC when error is detected at the Root Port.

 * Caller of this function must set id, severity, and multi_error_valid of

 * struct aer_err_info pointed by @e_info properly.  This function must fill

 * e_info->error_dev_num and e_info->dev[], based on the given information.

 Must reset in this function */

 Is Root Port an agent that sends error message? */

/**

 * handle_error_source - handle logging error into an event log

 * @dev: pointer to pci_dev data structure of error source device

 * @info: comprehensive error information

 *

 * Invoked when an error being detected by Root Port.

		/*

		 * Correctable error does not need software intervention.

		 * No need to go through error recovery process.

/*

 * Mutual exclusion for writers of aer_recover_ring, reader side don't

 * need lock, because there is only one reader and lock is not needed

 * between reader and writer.

/**

 * aer_get_device_error_info - read error status from dev and store it to info

 * @dev: pointer to the device expected to have a error record

 * @info: pointer to structure to store the error record

 *

 * Return 1 on success, 0 on error.

 *

 * Note that @info is reused among all error devices. Clear fields properly.

 Must reset in this function */

 The device might not support AER */

 Link is still healthy for IO reads */

 Get First Error Pointer */

 Report all before handle them, not to lost records by reset etc. */

/**

 * aer_isr_one_error - consume an error detected by root port

 * @rpc: pointer to the root port which holds an error

 * @e_src: pointer to an error source

	/*

	 * There is a possibility that both correctable error and

	 * uncorrectable error being logged. Report correctable error first.

/**

 * aer_isr - consume errors detected by root port

 * @irq: IRQ assigned to Root Port

 * @context: pointer to Root Port data structure

 *

 * Invoked, as DPC, when root port records new detected error

/**

 * aer_irq - Root Port's ISR

 * @irq: IRQ assigned to Root Port

 * @context: pointer to Root Port data structure

 *

 * Invoked when Root Port detects AER messages.

/**

 * set_downstream_devices_error_reporting - enable/disable the error reporting  bits on the root port and its downstream ports.

 * @dev: pointer to root port's pci_dev data structure

 * @enable: true = enable error reporting, false = disable error reporting.

/**

 * aer_enable_rootport - enable Root Port's interrupts when receiving messages

 * @rpc: pointer to a Root Port data structure

 *

 * Invoked when PCIe bus loads AER service driver.

 Clear PCIe Capability's Device Status */

 Disable system error generation in response to error messages */

 Clear error status */

	/*

	 * Enable error reporting for the root port device and downstream port

	 * devices.

 Enable Root Port's interrupt in response to error messages */

/**

 * aer_disable_rootport - disable Root Port's interrupts when receiving messages

 * @rpc: pointer to a Root Port data structure

 *

 * Invoked when PCIe bus unloads AER service driver.

	/*

	 * Disable error reporting for the root port device and downstream port

	 * devices.

 Disable Root's interrupt in response to error messages */

 Clear Root's error status reg */

/**

 * aer_remove - clean up resources

 * @dev: pointer to the pcie_dev data structure

 *

 * Invoked when PCI Express bus unloads or AER probe fails.

/**

 * aer_probe - initialize resources

 * @dev: pointer to the pcie_dev data structure

 *

 * Invoked when PCI Express bus loads AER service driver.

 Limit to Root Ports or Root Complex Event Collectors */

/**

 * aer_root_reset - reset Root Port hierarchy, RCEC, or RCiEP

 * @dev: pointer to Root Port, RCEC, or RCiEP

 *

 * Invoked by Port Bus driver when performing reset.

	/*

	 * Only Root Ports and RCECs have AER Root Command and Root Status

	 * registers.  If "dev" is an RCiEP, the relevant registers are in

	 * the RCEC.

	/*

	 * If the platform retained control of AER, an RCiEP may not have

	 * an RCEC visible to us, so dev->rcec ("root") may be NULL.  In

	 * that case, firmware is responsible for these registers.

 Disable Root's interrupt in response to error messages */

 Clear Root Error Status */

 Enable Root Port's interrupt in response to error messages */

/**

 * pcie_aer_init - register AER root service driver

 *

 * Invoked when AER root service driver is loaded.

 SPDX-License-Identifier: GPL-2.0

/*

 * Purpose:	PCI Express Port Bus Driver's Core Functions

 *

 * Copyright (C) 2004 Intel

 * Copyright (C) Tom Long Nguyen (tom.l.nguyen@intel.com)

/**

 * release_pcie_device - free PCI Express port service device structure

 * @dev: Port service device to release

 *

 * Invoked automatically when device is being removed in response to

 * device_unregister(dev).  Release all resources being claimed.

/*

 * Fill in *pme, *aer, *dpc with the relevant Interrupt Message Numbers if

 * services are enabled in "mask".  Return the number of MSI/MSI-X vectors

 * required to accommodate the largest Message Number.

	/*

	 * The Interrupt Message Number indicates which vector is used, i.e.,

	 * the MSI-X table entry or the MSI offset between the base Message

	 * Data and the generated interrupt message.  See PCIe r3.1, sec

	 * 7.8.2, 7.10.10, 7.31.2.

/**

 * pcie_port_enable_irq_vec - try to set up MSI-X or MSI as interrupt mode

 * for given port

 * @dev: PCI Express port to handle

 * @irqs: Array of interrupt vectors to populate

 * @mask: Bitmask of port capabilities returned by get_port_device_capability()

 *

 * Return value: 0 on success, error code on failure

 Allocate the maximum possible number of MSI/MSI-X vectors */

 See how many and which Interrupt Message Numbers we actually use */

	/*

	 * If we allocated more than we need, free them and reallocate fewer.

	 *

	 * Reallocating may change the specific vectors we get, so

	 * pci_irq_vector() must be done *after* the reallocation.

	 *

	 * If we're using MSI, hardware is *allowed* to change the Interrupt

	 * Message Numbers when we free and reallocate the vectors, but we

	 * assume it won't because we allocate enough vectors for the

	 * biggest Message Number we found.

 PME, hotplug and bandwidth notification share an MSI/MSI-X vector */

/**

 * pcie_init_service_irqs - initialize irqs for PCI Express port services

 * @dev: PCI Express port to handle

 * @irqs: Array of irqs to populate

 * @mask: Bitmask of port capabilities returned by get_port_device_capability()

 *

 * Return value: Interrupt mode associated with the port

	/*

	 * If we support PME but can't use MSI/MSI-X for it, we have to

	 * fall back to INTx or other interrupts, e.g., a system shared

	 * interrupt.

 Try to use MSI-X or MSI if supported */

 fall back to legacy IRQ */

/**

 * get_port_device_capability - discover capabilities of a PCI Express port

 * @dev: PCI Express port to examine

 *

 * The capabilities are read from the port's PCI Express configuration registers

 * as described in PCI Express Base Specification 1.0a sections 7.8.2, 7.8.9 and

 * 7.9 - 7.11.

 *

 * Return value: Bitmask of discovered port capabilities

		/*

		 * Disable hot-plug interrupts in case they have been enabled

		 * by the BIOS and the hot-plug service driver is not loaded.

		/*

		 * Disable AER on this port in case it's been enabled by the

		 * BIOS (the AER service driver will enable it when necessary).

 Root Ports and Root Complex Event Collectors may generate PMEs */

		/*

		 * Disable PME interrupt on this port in case it's been enabled

		 * by the BIOS (the PME service driver will enable it when

		 * necessary).

	/*

	 * With dpc-native, allow Linux to use DPC even if it doesn't have

	 * permission to use AER.

/**

 * pcie_device_init - allocate and initialize PCI Express port service device

 * @pdev: PCI Express port to associate the service device with

 * @service: Type of service to associate with the service device

 * @irq: Interrupt vector to associate with the service device

 Initialize generic device interface */

 callback to free pcie dev */

/**

 * pcie_port_device_register - register PCI Express port

 * @dev: PCI Express port to register

 *

 * Allocate the port extension structure and register services associated with

 * the port.

 Enable PCI Express port device */

 Get and check PCI Express port services */

		/*

		 * Initialize service IRQs. Don't use service devices that

		 * require interrupts if there is no way to generate them.

		 * However, some drivers may have a polling mode (e.g.

		 * pciehp_poll_mode) that can be used in the absence of IRQs.

		 * Allow them to determine if that is to be used.

 Allocate child services if any */

/**

 * pcie_port_device_suspend - suspend port services associated with a PCIe port

 * @dev: PCI Express port to handle

/**

 * pcie_port_device_resume - resume port services associated with a PCIe port

 * @dev: PCI Express port to handle

/**

 * pcie_port_device_runtime_suspend - runtime suspend port services

 * @dev: PCI Express port to handle

/**

 * pcie_port_device_runtime_resume - runtime resume port services

 * @dev: PCI Express port to handle

 PM */

/**

 * pcie_port_find_device - find the struct device

 * @dev: PCI Express port the service is associated with

 * @service: For the service to find

 *

 * Find the struct device associated with given service on a pci_dev

/**

 * pcie_port_device_remove - unregister PCI Express port service devices

 * @dev: PCI Express port the service devices to unregister are associated with

 *

 * Remove PCI Express port service devices associated with given port and

 * disable MSI-X or MSI for the port.

/**

 * pcie_port_probe_service - probe driver for given PCI Express port service

 * @dev: PCI Express port service device to probe against

 *

 * If PCI Express port service driver is registered with

 * pcie_port_service_register(), this function will be called by the driver core

 * whenever match is found between the driver and a port service device.

/**

 * pcie_port_remove_service - detach driver from given PCI Express port service

 * @dev: PCI Express port service device to handle

 *

 * If PCI Express port service driver is registered with

 * pcie_port_service_register(), this function will be called by the driver core

 * when device_unregister() is called for the port service device associated

 * with the driver.

/**

 * pcie_port_shutdown_service - shut down given PCI Express port service

 * @dev: PCI Express port service device to handle

 *

 * If PCI Express port service driver is registered with

 * pcie_port_service_register(), this function will be called by the driver core

 * when device_shutdown() is called for the port service device associated

 * with the driver.

/**

 * pcie_port_service_register - register PCI Express port service driver

 * @new: PCI Express port service driver to register

/**

 * pcie_port_service_unregister - unregister PCI Express port service driver

 * @drv: PCI Express port service driver to unregister

 SPDX-License-Identifier: GPL-2.0

/*

 * Purpose:	PCI Express Port Bus Driver

 * Author:	Tom Nguyen <tom.l.nguyen@intel.com>

 *

 * Copyright (C) 2004 Intel

 * Copyright (C) Tom Long Nguyen (tom.l.nguyen@intel.com)

 If this switch is set, PCIe port native services should not be enabled. */

/*

 * If the user specified "pcie_ports=native", use the PCIe services regardless

 * of whether the platform has given us permission.  On ACPI systems, this

 * means we ignore _OSC.

/*

 * If the user specified "pcie_ports=dpc-native", use the Linux DPC PCIe

 * service even if the platform hasn't given us permission.

 global data */

	/*

	 * Assume the PCI core has set bridge_d3 whenever it thinks the port

	 * should be good to go to D3.  Everything else, including moving

	 * the port to D3, is handled by the PCI core.

 !PM */

 !PM */

/*

 * pcie_portdrv_probe - Probe PCI-Express port devices

 * @dev: PCI-Express port device being probed

 *

 * If detected invokes the pcie_port_device_register() method for

 * this port device.

 *

		/*

		 * Keep the port resumed 100ms to make sure things like

		 * config space accesses from userspace (lspci) will not

		 * cause the port to repeatedly suspend and resume.

/*

 * LINUX Device Driver Model

 handle any PCI-Express port */

 subtractive decode PCI-to-PCI bridge, class type is 060401h */

 handle any Root Complex Event Collector */

	/*

	 * Boxes that should not use MSI for PCIe PME signaling.

 SPDX-License-Identifier: GPL-2.0

/*

 * This file implements the error recovery as a core part of PCIe error

 * reporting. When a PCIe error is delivered, an error message will be

 * collected and printed to console, then, an error recovery procedure

 * will be executed by following the PCI error recovery rules.

 *

 * Copyright (C) 2006 Intel Corp.

 *	Tom Long Nguyen (tom.l.nguyen@intel.com)

 *	Zhang Yanmin (yanmin.zhang@intel.com)

		/*

		 * If any device in the subtree does not have an error_detected

		 * callback, PCI_ERS_RESULT_NO_AER_DRIVER prevents subsequent

		 * error callbacks of "any" device in the subtree, and will

		 * exit in the disconnected error state.

/**

 * pci_walk_bridge - walk bridges potentially AER affected

 * @bridge:	bridge which may be a Port, an RCEC, or an RCiEP

 * @cb:		callback to be called for each device found

 * @userdata:	arbitrary pointer to be passed to callback

 *

 * If the device provided is a bridge, walk the subordinate bus, including

 * any bridged devices on buses under this bus.  Call the provided callback

 * on each device found.

 *

 * If the device provided has no subordinate bus, e.g., an RCEC or RCiEP,

 * call the callback on the device itself.

	/*

	 * If the error was detected by a Root Port, Downstream Port, RCEC,

	 * or RCiEP, recovery runs on the device itself.  For Ports, that

	 * also includes any subordinate devices.

	 *

	 * If it was detected by another device (Endpoint, etc), recovery

	 * runs on the device and anything else under the same Port, i.e.,

	 * everything under "bridge".

		/*

		 * TODO: Should call platform-specific

		 * functions to reset slot before calling

		 * drivers' slot_reset callbacks?

	/*

	 * If we have native control of AER, clear error status in the device

	 * that detected the error.  If the platform retained control of AER,

	 * it is responsible for clearing this status.  In that case, the

	 * signaling device may not even be visible to the OS.

 TODO: Should kernel panic here? */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe Native PME support

 *

 * Copyright (C) 2007 - 2009 Intel Corp

 * Copyright (C) 2007 - 2009 Shaohua Li <shaohua.li@intel.com>

 * Copyright (C) 2009 Rafael J. Wysocki <rjw@sisk.pl>, Novell Inc.

/*

 * If this switch is set, MSI will not be used for PCIe PME signaling.  This

 * causes the PCIe port driver to use INTx interrupts only, but it turns out

 * that using MSI for PCIe PME signaling doesn't play well with PCIe PME-based

 * wake-up from system sleep states.

 If set, keep the PME interrupt disabled. */

/**

 * pcie_pme_interrupt_enable - Enable/disable PCIe PME interrupt generation.

 * @dev: PCIe root port or event collector.

 * @enable: Enable or disable the interrupt.

/**

 * pcie_pme_walk_bus - Scan a PCI bus for devices asserting PME#.

 * @bus: PCI bus to scan.

 *

 * Scan given PCI bus and all buses under it for devices asserting PME#.

 Skip PCIe devices in case we started from a root port. */

/**

 * pcie_pme_from_pci_bridge - Check if PCIe-PCI bridge generated a PME.

 * @bus: Secondary bus of the bridge.

 * @devfn: Device/function number to check.

 *

 * PME from PCI devices under a PCIe-PCI bridge may be converted to an in-band

 * PCIe PME message.  In such that case the bridge should use the Requester ID

 * of device/function number 0 on its secondary bus.

/**

 * pcie_pme_handle_request - Find device that generated PME and handle it.

 * @port: Root port or event collector that generated the PME interrupt.

 * @req_id: PCIe Requester ID of the device that generated the PME.

 First, check if the PME is from the root port itself. */

			/*

			 * Apparently, the root port generated the PME on behalf

			 * of a non-PCIe device downstream.  If this is done by

			 * a root port, the Requester ID field in its status

			 * register may contain either the root port's, or the

			 * source device's information (PCI Express Base

			 * Specification, Rev. 2.0, Section 6.1.9).

 Second, find the bus the source device is on. */

 Next, check if the PME is from a PCIe-PCI bridge. */

 Finally, try to find the PME source on the bus. */

 The device is there, but we have to check its PME status. */

		/*

		 * The device is not there, but we can still try to recover by

		 * assuming that the PME was reported by a PCIe-PCI bridge that

		 * used devfn different from zero.

/**

 * pcie_pme_work_fn - Work handler for PCIe PME interrupt.

 * @work: Work structure giving access to service data.

			/*

			 * Clear PME status of the port.  If there are other

			 * pending PMEs, the status will be set again.

 No need to loop if there are no more PMEs pending. */

/**

 * pcie_pme_irq - Interrupt handler for PCIe root port PME interrupt.

 * @irq: Interrupt vector.

 * @context: Interrupt context pointer.

 We don't use pm_wq, because it's freezable. */

/**

 * pcie_pme_can_wakeup - Set the wakeup capability flag.

 * @dev: PCI device to handle.

 * @ign: Ignored.

/**

 * pcie_pme_mark_devices - Set the wakeup flag for devices below a port.

 * @port: PCIe root port or event collector to handle.

 *

 * For each device below given root port, including the port itself (or for each

 * root complex integrated endpoint if @port is a root complex event collector)

 * set the flag indicating that it can signal run-time wake-up events.

/**

 * pcie_pme_probe - Initialize PCIe PME service for given root port.

 * @srv: PCIe service to initialize.

 Limit to Root Ports or Root Complex Event Collectors */

/**

 * pcie_pme_suspend - Suspend PCIe PME service device.

 * @srv: PCIe service device to suspend.

/**

 * pcie_pme_resume - Resume PCIe PME service device.

 * @srv: PCIe service device to resume.

/**

 * pcie_pme_remove - Prepare PCIe PME service device for removal.

 * @srv: PCIe service device to remove.

/**

 * pcie_pme_init - Register the PCIe PME service driver.

 SPDX-License-Identifier: GPL-2.0

/*

 * Volume Management Device driver

 * Copyright (c) 2015, Intel Corporation.

	/*

	 * Device may contain registers which hint the physical location of the

	 * membars, in order to allow proper address translation during

	 * resource assignment to enable guest virtualization

	/*

	 * Device may provide root port configuration information which limits

	 * bus numbering

	/*

	 * Device contains physical location shadow registers in

	 * vendor-specific capability space

	/*

	 * Device may use MSI-X vector 0 for software triggering and will not

	 * be used for MSI remapping

	/*

	 * Device can bypass remapping MSI-X transactions into its MSI-X table,

	 * avoiding the requirement of a VMD MSI domain for child device

	 * interrupt handling.

/*

 * Lock for manipulating VMD IRQ lists.

/**

 * struct vmd_irq - private data to map driver IRQ to the VMD shared vector

 * @node:	list item for parent traversal.

 * @irq:	back pointer to parent.

 * @enabled:	true if driver enabled IRQ

 * @virq:	the virtual IRQ value provided to the requesting driver.

 *

 * Every MSI/MSI-X IRQ requested for a device in a VMD domain will be mapped to

 * a VMD IRQ using this structure.

/**

 * struct vmd_irq_list - list of driver requested IRQs mapping to a VMD vector

 * @irq_list:	the list of irq's the VMD one demuxes to.

 * @srcu:	SRCU struct for local synchronization.

 * @count:	number of child IRQs assigned to this vector; used to track

 *		sharing.

/*

 * Drivers managing a device in a VMD domain allocate their own IRQs as before,

 * but the MSI entry for the hardware it's driving will be programmed with a

 * destination ID for the VMD MSI-X table.  The VMD muxes interrupts in its

 * domain into one of its own, and the VMD driver de-muxes these for the

 * handlers sharing that VMD IRQ.  The vmd irq_domain provides the operations

 * and irq_chip to set this up.

/*

 * We rely on MSI_FLAG_USE_DEF_CHIP_OPS to set the IRQ mask/unmask ops.

/*

 * XXX: Stubbed until we develop acceptable way to not create conflicts with

 * other devices sharing the same vector.

/*

 * XXX: We can be even smarter selecting the best IRQ once we solve the

 * affinity problem.

	/*

	 * White list for fast-interrupt handlers. All others will share the

	 * "slow" interrupt vector.

 XXX: Potential optimization to rebalance */

	/*

	 * Some production BIOS won't enable remapping between soft reboots.

	 * Ensure remapping is restored before unloading the driver.

/*

 * CPU may deadlock if config space is not serialized on some versions of this

 * hardware, so all config space access is done under a spinlock.

/*

 * VMD h/w converts non-posted config writes to posted memory writes. The

 * read-back in this function forces the completion so it returns only after

 * the config space was written, as expected.

	/*

	 * The address computation below is only applicable to relative bus

	 * numbers below 32.

 CONFIG_ACPI */

/*

 * VMD domains start at 0x10000 to not clash with ACPI _SEG domains.

 * Per ACPI r6.0, sec 6.5.6,  _SEG returns an integer, of which the lower

 * 16 bits are the PCI Segment Group (domain) number.  Other bits are

 * currently reserved.

 Hypervisor-Emulated Vendor-Specific Capability */

 "SHDW" */

	/*

	 * Shadow registers may exist in certain VMD device ids which allow

	 * guests to correctly assign host physical addresses to the root ports

	 * and child devices. These registers will either return the host value

	 * or 0, depending on an enable bit in the VMD device.

	/*

	 * Certain VMD devices may have a root port configuration option which

	 * limits the bus range to between 0-127, 128-255, or 224-255

	/*

	 * If the window is below 4GB, clear IORESOURCE_MEM_64 so we can

	 * put 32-bit resources in the window.

	 *

	 * There's no hardware reason why a 64-bit window *couldn't*

	 * contain a 32-bit resource, but pbus_size_mem() computes the

	 * bridge window size assuming a 64-bit window will contain no

	 * 32-bit resources.  __pci_assign_resource() enforces that

	 * artificial restriction to make sure everything will fit.

	 *

	 * The only way we could use a 64-bit non-prefetchable MEMBAR is

	 * if its address is <4GB so that we can convert it to a 32-bit

	 * resource.  To be visible to the host OS, all VMD endpoints must

	 * be initially configured by platform BIOS, which includes setting

	 * up these resources.  We can assume the device is configured

	 * according to the platform needs.

	/*

	 * Currently MSI remapping must be enabled in guest passthrough mode

	 * due to some missing interrupt remapping plumbing. This is probably

	 * acceptable because the guest is usually CPU-limited and MSI

	 * remapping doesn't become a performance bottleneck.

		/*

		 * Override the IRQ domain bus token so the domain can be

		 * distinguished from a regular PCI/MSI domain.

	/*

	 * VMD root buses are virtual and don't return true on pci_is_pcie()

	 * and will fail pcie_bus_configure_settings() early. It can instead be

	 * run on each of the real root ports.

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for the Aardvark PCIe controller, used on Marvell Armada

 * 3700.

 *

 * Copyright (C) 2016 Marvell

 *

 * Author: Hezi Shahmoon <hezi.shahmoon@marvell.com>

 PCIe core registers */

 PIO registers base address and register offsets */

 Aardvark Control registers */

 PCIe window configuration */

 LMI registers base address and register offsets */

 LTSSM values in CFG_REG */

 PCIe core controller registers */

 PCIe Central Interrupts Registers */

 Transaction types */

 1.5 s */

 2 us*/

 check if LTSSM is in normal operation - some L* state */

	/*

	 * According to PCIe Base specification 3.0, Table 4-14: Link

	 * Status Mapped to the LTSSM, and 4.2.6.3.6 Configuration.Idle

	 * is Link Up mapped to LTSSM Configuration.Idle, Recovery, L0,

	 * L0s, L1 and L2 states. And according to 3.2.1. Data Link

	 * Control and Management State Machine Rules is DL Up status

	 * reported in DL Active state.

	/*

	 * According to PCIe Base specification 3.0, Table 4-14: Link

	 * Status Mapped to the LTSSM is Link Training mapped to LTSSM

	 * Configuration and Recovery states.

 check if the link is up or not */

 10ms delay is needed for some cards */

	/*

	 * Setup PCIe rev / gen compliance based on device tree property

	 * 'max-link-speed' which also forces maximal link speed.

	/*

	 * Set maximal link speed value also into PCIe Link Control 2 register.

	 * Armada 3700 Functional Specification says that default value is based

	 * on SPEED_GEN but tests showed that default value is always 8.0 GT/s.

 Enable link training after selecting PCIe generation */

	/*

	 * Reset PCIe card via PERST# signal. Some cards are not detected

	 * during link training when they are in some non-initial state.

	/*

	 * PERST# signal could have been asserted by pinctrl subsystem before

	 * probe() callback has been called or issued explicitly by reset gpio

	 * function advk_pcie_issue_perst(), making the endpoint going into

	 * fundamental reset. As required by PCI Express spec (PCI Express

	 * Base Specification, REV. 4.0 PCI Express, February 19 2014, 6.6.1

	 * Conventional Reset) a delay for at least 100ms after such a reset

	 * before sending a Configuration Request to the device is needed.

	 * So wait until PCIe link is up. Function advk_pcie_wait_for_link()

	 * waits for link at least 900ms.

/*

 * Set PCIe address window register which could be used for memory

 * mapping.

	/*

	 * Configure PCIe Reference clock. Direction is from the PCIe

	 * controller to the endpoint card, so enable transmitting of

	 * Reference clock differential signal off-chip and disable

	 * receiving off-chip differential signal.

 Set to Direct mode */

 Set PCI global control register to RC mode */

	/*

	 * Replace incorrect PCI vendor id value 0x1b4b by correct value 0x11ab.

	 * VENDOR_ID_REG contains vendor id in low 16 bits and subsystem vendor

	 * id in high 16 bits. Updating this register changes readback value of

	 * read-only vendor id bits in PCIE_CORE_DEV_ID_REG register. Workaround

	 * for erratum 4.1: "The value of device and vendor ID is incorrect".

	/*

	 * Change Class Code of PCI Bridge device to PCI Bridge (0x600400),

	 * because the default value is Mass storage controller (0x010400).

	 *

	 * Note that this Aardvark PCI Bridge does not have compliant Type 1

	 * Configuration Space and it even cannot be accessed via Aardvark's

	 * PCI config space access method. Something like config space is

	 * available in internal Aardvark registers starting at offset 0x0

	 * and is reported as Type 0. In range 0x10 - 0x34 it has totally

	 * different registers.

	 *

	 * Therefore driver uses emulation of PCI Bridge which emulates

	 * access to configuration space via internal Aardvark registers or

	 * emulated configuration buffer.

 Disable Root Bridge I/O space, memory space and bus mastering */

 Set Advanced Error Capabilities and Control PF0 register */

 Set PCIe Device Control register */

 Program PCIe Control 2 to disable strict ordering */

 Set lane X1 */

 Enable MSI */

 Clear all interrupts */

 Disable All ISR0/1 Sources */

 Unmask all MSIs */

 Enable summary interrupt for GIC SPI source */

	/*

	 * Enable AXI address window location generation:

	 * When it is enabled, the default outbound window

	 * configurations (Default User Field: 0xD0074CFC)

	 * are used to transparent address translation for

	 * the outbound transactions. Thus, PCIe address

	 * windows are not required for transparent memory

	 * access when default outbound window configuration

	 * is set for memory access.

	/*

	 * Set memory access in Default User Field so it

	 * is not required to configure PCIe address for

	 * transparent memory access.

	/*

	 * Bypass the address window mapping for PIO:

	 * Since PIO access already contains all required

	 * info over AXI interface by PIO registers, the

	 * address window is not required.

	/*

	 * Configure PCIe address windows for non-memory or

	 * non-transparent access as by default PCIe uses

	 * transparent memory access.

 Disable remaining PCIe outbound windows */

	/*

	 * According to HW spec, the PIO status check sequence as below:

	 * 1) even if COMPLETION_STATUS(bit9:7) indicates successful,

	 *    it still needs to check Error Status(bit11), only when this bit

	 *    indicates no error happen, the operation is successful.

	 * 2) value Unsupported Request(1) of COMPLETION_STATUS(bit9:7) only

	 *    means a PIO write error, and for PIO read it is successful with

	 *    a read value of 0xFFFFFFFF.

	 * 3) value Completion Retry Status(CRS) of COMPLETION_STATUS(bit9:7)

	 *    only means a PIO write error, and for PIO read it is successful

	 *    with a read value of 0xFFFF0001.

	 * 4) value Completer Abort (CA) of COMPLETION_STATUS(bit9:7) means

	 *    error for both PIO read and PIO write operation.

	 * 5) other errors are indicated as 'unknown'.

 Get the read result */

 No error */

			/* PCIe r4.0, sec 2.3.2, says:

			 * If CRS Software Visibility is enabled:

			 * For a Configuration Read Request that includes both

			 * bytes of the Vendor ID field of a device Function's

			 * Configuration Space Header, the Root Complex must

			 * complete the Request to the host by returning a

			 * read-data value of 0001h for the Vendor ID field and

			 * all '1's for any additional bytes included in the

			 * request.

			 *

			 * So CRS in this case is not an error status.

		/* PCIe r4.0, sec 2.3.2, says:

		 * If CRS Software Visibility is not enabled, the Root Complex

		 * must re-issue the Configuration Request as a new Request.

		 * If CRS Software Visibility is enabled: For a Configuration

		 * Write Request or for any other Configuration Read Request,

		 * the Root Complex must re-issue the Configuration Request as

		 * a new Request.

		 * A Root Complex implementation may choose to limit the number

		 * of Configuration Request/CRS Completion Status loops before

		 * determining that something is wrong with the target of the

		 * Request and taking appropriate action, e.g., complete the

		 * Request to the host as a failed transaction.

		 *

		 * So return -EAGAIN and caller (pci-aardvark.c driver) will

		 * re-issue request again up to the PIO_RETRY_CNT retries.

		/*

		 * From the whole 32bit register we support reading from HW only

		 * one bit: PCI_BRIDGE_CTL_BUS_RESET.

		 * Other bits are retrieved only from emulated config buffer.

		/*

		 * PCI_EXP_LNKCAP_DLLLARC bit is hardwired in aardvark HW to 0.

		 * But support for PCI_EXP_LNKSTA_DLLLA is emulated via ltssm

		 * state so explicitly enable PCI_EXP_LNKCAP_DLLLARC flag.

 u32 contains both PCI_EXP_LNKCTL and PCI_EXP_LNKSTA */

 Only mask/unmask PME interrupt */

/*

 * Initialize the configuration space of the PCI-to-PCI bridge

 * associated with the given PCIe interface.

 Support 32 bits I/O addressing */

 Support 64 bits memory pref */

 Support interrupt A for MSI feature */

 Indicates supports for Completion Retry Status */

	/*

	 * If the link goes down after we check for link-up, nothing bad

	 * happens but the config access times out.

	/*

	 * Trying to start a new PIO transfer when previous has not completed

	 * cause External Abort on CPU which results in kernel panic:

	 *

	 *     SError Interrupt on CPU0, code 0xbf000002 -- SError

	 *     Kernel panic - not syncing: Asynchronous SError Interrupt

	 *

	 * Functions advk_pcie_rd_conf() and advk_pcie_wr_conf() are protected

	 * by raw_spin_lock_irqsave() at pci_lock_config() level to prevent

	 * concurrent calls at the same time. But because PIO transfer may take

	 * about 1.5s when link is down or card is disconnected, it means that

	 * advk_pcie_wait_pio() does not always have to wait for completion.

	 *

	 * Some versions of ARM Trusted Firmware handles this External Abort at

	 * EL3 level and mask it to prevent kernel panic. Relevant TF-A commit:

	 * https://git.trustedfirmware.org/TF-A/trusted-firmware-a.git/commit/?id=3c7dcdac5c50

	/*

	 * Completion Retry Status is possible to return only when reading all

	 * 4 bytes from PCI_VENDOR_ID and PCI_DEVICE_ID registers at once and

	 * CRSSVE flag on Root Bridge is enabled.

 Program the control register */

 Program the address registers */

 Program the data strobe */

 Clear PIO DONE ISR and start the transfer */

 Check PIO status and get the read result */

	/*

	 * If it is possible, return Completion Retry Status so that caller

	 * tries to issue the request again instead of failing.

 Program the control register */

 Program the address registers */

 Calculate the write strobe */

 Program the data register */

 Program the data strobe */

 Clear PIO DONE ISR and start the transfer */

		/*

		 * msi_idx contains bits [4:0] of the msi_data and msi_data

		 * contains 16bit MSI interrupt number

 Process MSI interrupts */

 Process legacy interrupts */

 Clear interrupt */

 Old bindings miss the PHY handle */

		/*

		 * Aardvark hardware allows to configure also PCIe window

		 * for config type 0 and type 1 mapping, but driver uses

		 * only PIO for issuing configuration transfers which does

		 * not use PCIe window configuration.

		/*

		 * Skip transparent memory resources. Default outbound access

		 * configuration is set to transparent memory access so it

		 * does not need window configuration.

		/*

		 * The n-th PCIe window is configured by tuple (match, remap, mask)

		 * and an access to address A uses this window if A matches the

		 * match with given mask.

		 * So every PCIe window size must be a power of two and every start

		 * address must be aligned to window size. Minimal size is 64 KiB

		 * because lower 16 bits of mask must be zero. Remapped address

		 * may have set only bits from the mask.

 Calculate the largest aligned window size */

 Disable outbound address windows mapping */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2015 Broadcom Corporation

 Max number of GIC interrupts */

 Number of entries in each event queue */

 Size of each event queue memory region */

 Size of each MSI address region */

/**

 * struct iproc_msi_grp - iProc MSI group

 *

 * One MSI group is allocated per GIC interrupt, serviced by one iProc MSI

 * event queue.

 *

 * @msi: pointer to iProc MSI data

 * @gic_irq: GIC interrupt

 * @eq: Event queue number

/**

 * struct iproc_msi - iProc event queue based MSI

 *

 * Only meant to be used on platforms without MSI support integrated into the

 * GIC.

 *

 * @pcie: pointer to iProc PCIe data

 * @reg_offsets: MSI register offsets

 * @grps: MSI groups

 * @nr_irqs: number of total interrupts connected to GIC

 * @nr_cpus: number of toal CPUs

 * @has_inten_reg: indicates the MSI interrupt enable register needs to be

 * set explicitly (required for some legacy platforms)

 * @bitmap: MSI vector bitmap

 * @bitmap_lock: lock to protect access to the MSI bitmap

 * @nr_msi_vecs: total number of MSI vectors

 * @inner_domain: inner IRQ domain

 * @msi_domain: MSI IRQ domain

 * @nr_eq_region: required number of 4K aligned memory region for MSI event

 * queues

 * @nr_msi_region: required number of 4K aligned address region for MSI posted

 * writes

 * @eq_cpu: pointer to allocated memory region for MSI event queues

 * @eq_dma: DMA address of MSI event queues

 * @msi_addr: MSI address

/*

 * In iProc PCIe core, each MSI group is serviced by a GIC interrupt and a

 * dedicated event queue.  Each MSI group can support up to 64 MSI vectors.

 *

 * The number of MSI groups varies between different iProc SoCs.  The total

 * number of CPU cores also varies.  To support MSI IRQ affinity, we

 * distribute GIC interrupts across all available CPUs.  MSI vector is moved

 * from one GIC interrupt to another to steer to the target CPU.

 *

 * Assuming:

 * - the number of MSI groups is M

 * - the number of CPU cores is N

 * - M is always a multiple of N

 *

 * Total number of raw MSI vectors = M * 64

 * Total number of supported MSI vectors = (M * 64) / N

 steer MSI to the target CPU */

	/*

	 * Allocate 'nr_irqs' multiplied by 'nr_cpus' number of MSI vectors

	 * each time

	/*

	 * Since we have multiple hwirq mapped to a single MSI vector,

	 * now we need to derive the hwirq at CPU0.  It can then be used to

	 * mapped back to virq.

	/*

	 * iProc MSI event queue is tracked by head and tail pointers.  Head

	 * pointer indicates the next entry (MSI data) to be consumed by SW in

	 * the queue and needs to be updated by SW.  iProc MSI core uses the

	 * tail pointer as the next data insertion point.

	 *

	 * Entries between head and tail pointers contain valid MSI data.  MSI

	 * data is guaranteed to be in the event queue memory before the tail

	 * pointer is updated by the iProc MSI core.

		/*

		 * Figure out total number of events (MSI data) to be

		 * processed.

 process all outstanding events */

		/*

		 * Now all outstanding events have been processed.  Update the

		 * head pointer.

		/*

		 * Now go read the tail pointer again to see if there are new

		 * outstanding events that came in during the above window.

 Program memory region for each event queue */

 Program address region for MSI posted writes */

 Enable MSI event queue */

		/*

		 * Some legacy platforms require the MSI interrupt enable

		 * register to be set explicitly.

 Dedicate GIC interrupt to each CPU core */

 Free all configured/unconfigured IRQs */

 Reserve memory for event queue and make sure memories are zeroed */

 SPDX-License-Identifier: GPL-2.0

/*

 *  pci-rcar-gen2: internal PCI bus support

 *

 * Copyright (C) 2013 Renesas Solutions Corp.

 * Copyright (C) 2013 Cogent Embedded, Inc.

 *

 * Author: Valentine Barshak <valentine.barshak@cogentembedded.com>

 AHB-PCI Bridge PCI communication registers */

 PCI configuration space operations */

 Only one EHCI/OHCI device built-in */

 bridge logic only has registers to 0x40 */

 if debug enabled, then attach an error handler irq to the bridge */

 clear the error(s) */

 PCI host controller setup */

 Disable Direct Power Down State and assert reset */

 De-assert reset and reset PCIAHB window1 size */

 Setup PCIAHB window1 size */

 Configure AHB master and slave modes */

 Configure PCI arbiter */

 PCI-AHB mapping */

 AHB-PCI mapping: OHCI/EHCI registers */

 Enable AHB-PCI bridge PCI configuration access */

 Set PCI-AHB Window1 address */

 Set AHB-PCI bridge PCI communication area address */

 Enable PCI interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 * Generic PCI host driver common code

 *

 * Copyright (C) 2014 ARM Limited

 *

 * Author: Will Deacon <will.deacon@arm.com>

 Parse and map our Configuration Space windows */

 Do not reassign resources if probe only */

 SPDX-License-Identifier: GPL-2.0

/*

 * Simple, generic PCI host controller driver targeting firmware-initialised

 * systems and virtual machines (e.g. the PCI emulation provided by kvmtool).

 *

 * Copyright (C) 2014 ARM Limited

 *

 * Author: Will Deacon <will.deacon@arm.com>

	/*

	 * The Synopsys DesignWare PCIe controller in ECAM mode will not filter

	 * type 0 config TLPs sent to devices 1 and up on its downstream port,

	 * resulting in devices appearing multiple times on bus 0 unless we

	 * filter out those accesses here.

 SPDX-License-Identifier: GPL-2.0

/*

 * Microchip AXI PCIe Bridge host controller driver

 *

 * Copyright (c) 2018 - 2020 Microchip Corporation. All rights reserved.

 *

 * Author: Daire McNamara <daire.mcnamara@microchip.com>

 Number of MSI IRQs */

 PCIe Bridge Phy and Controller Phy offsets */

 PCIe Controller Phy Regs */

 PCIe Bridge Phy Regs */

 PCIe Config space MSI capability structure */

 PCIe Master table init defines */

 PCIe AXI slave table init defines */

 Protect used bitmap */

 Enable MSI interrupts */

	/*

	 * PCIe may be clocked via Fabric Interface using between 1 and 4

	 * clocks. Scan DT for clocks and enable them if present

 Setup INTx */

 Plug the INTx chained handler */

 Plug the MSI chained handler */

 Plug the main event chained handler */

 Hardware doesn't setup MSI by default */

 Configure Address Translation Table 0 for PCIe config space */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Rockchip AXI PCIe host controller driver

 *

 * Copyright (c) 2016 Rockchip, Inc.

 *

 * Author: Shawn Lin <shawn.lin@rock-chips.com>

 *         Wenrui Li <wenrui.li@rock-chips.com>

 *

 * Bits taken from Synopsys DesignWare Host controller driver and

 * ARM PCI Host generic driver.

 Update Tx credit maximum update interval */

 ns */

	/*

	 * Access only one slot on each root port.

	 * Do not read more than one device on the bus directly attached

	 * to RC's downstream side.

 The link may be using a reverse-indexed mapping. */

	/*

	 * N.B. This read/modify/write isn't safe in general because it can

	 * corrupt RW1C bits in adjacent registers.  But the hardware

	 * doesn't support smaller writes.

	/*

	 * Set RC's captured slot power limit and scale if

	 * vpcie3v3 available. The default values are both zero

	 * which means the software should set these two according

	 * to the actual power supply.

 0.001x */

 convert to mA */

 milliwatt */

/**

 * rockchip_pcie_host_init_port - Initialize hardware

 * @rockchip: PCIe port information

 Fix the transmitted FTS count desired to exit from L0s. */

 Set RC's clock architecture as common clock */

 Set RC's RCB to 128 */

 Enable Gen1 training */

 500ms timeout value should be enough for Gen1/2 training */

		/*

		 * Enable retrain for gen2. This should be configured only after

		 * gen1 finished.

 Check the final link width from negotiated lane counter from MGMT */

 Power off unused lane(s) */

 Clear THP cap's next cap pointer to remove L1 substate cap */

 Clear L0s from RC's link cap */

/**

 * rockchip_pcie_parse_host_dt - Parse Device Tree

 * @rockchip: PCIe port information

 *

 * Return: '0' on success and error value on failure

 store the register number offset to program RC io outbound ATU */

 assign message regions */

 send PME_TURN_OFF message */

 read LTSSM and wait for falling into L2 link state */

 disable core and cli int since we don't need to ack PME_ACK */

 Need this to enter L1 again */

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for handling the PCIe controller errors on

 * HiSilicon HIP SoCs.

 *

 * Copyright (c) 2020 HiSilicon Limited.

 HISI PCIe controller error definitions */

/*

 * Firmware reports the socket port ID where the error occurred.  These

 * macros convert that to the core ID and core port ID required by the

 * ACPI reset method.

	/*

	 * The initialization time of subordinate devices after

	 * hot reset is no more than 1s, which is required by

	 * the PCI spec v5.0 sec 6.6.1. The time will shorten

	 * if Readiness Notifications mechanisms are used. But

	 * wait 1s here to adapt any conditions.

 add root port and downstream devices */

	/* Recovery for the PCIe controller errors, try reset

	 * PCI port for the error recovery

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2015 Broadcom Corporation

 sentinel */ }

	/*

	 * DT nodes are not used by all platforms that use the iProc PCIe

	 * core driver. For platforms that require explicit inbound mapping

	 * configuration, "dma-ranges" would have been present in DT

 PHY use is optional */

 PAXC doesn't support legacy IRQs, skip mapping */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCIe host controller driver for Xilinx Versal CPM DMA Bridge

 *

 * (C) Copyright 2019 - 2020, Xilinx, Inc.

 Register definitions */

 Interrupt registers definitions */

 Root Port Error FIFO Read Register definitions */

 Root Port Status/control Register definitions */

 Phy Status/Control Register definitions */

/**

 * struct xilinx_cpm_pcie_port - PCIe port information

 * @reg_base: Bridge Register Base

 * @cpm_base: CPM System Level Control and Status Register(SLCR) Base

 * @dev: Device pointer

 * @intx_domain: Legacy IRQ domain pointer

 * @cpm_domain: CPM IRQ domain pointer

 * @cfg: Holds mappings of config space window

 * @intx_irq: legacy interrupt number

 * @irq: Error interrupt number

 * @lock: lock protecting shared register access

/**

 * xilinx_cpm_pcie_intx_map - Set the handler for the INTx and mark IRQ as valid

 * @domain: IRQ domain

 * @irq: Virtual IRQ number

 * @hwirq: HW interrupt number

 *

 * Return: Always returns 0.

 INTx IRQ Domain operations */

	/*

	 * XILINX_CPM_PCIE_MISC_IR_STATUS register is mapped to

	 * CPM SLCR block.

/**

 * xilinx_cpm_pcie_init_irq_domain - Initialize IRQ domain

 * @port: PCIe port information

 *

 * Return: '0' on success and error value on failure

 Setup INTx */

 Plug the INTx chained handler */

 Plug the main event chained handler */

/**

 * xilinx_cpm_pcie_init_port - Initialize hardware

 * @port: PCIe port information

 Disable all interrupts */

 Clear pending interrupts */

	/*

	 * XILINX_CPM_PCIE_MISC_IR_ENABLE register is mapped to

	 * CPM SLCR block.

 Enable the Bridge enable bit */

/**

 * xilinx_cpm_pcie_parse_dt - Parse Device tree

 * @port: PCIe port information

 * @bus_range: Bus resource

 *

 * Return: '0' on success and error value on failure

/**

 * xilinx_cpm_pcie_probe - Probe function

 * @pdev: Platform device pointer

 *

 * Return: '0' on success and error value on failure

 SPDX-License-Identifier: GPL-2.0

/*

 * Support for V3 Semiconductor PCI Local Bus to PCI Bridge

 * Copyright (C) 2017 Linus Walleij <linus.walleij@linaro.org>

 *

 * Based on the code from arch/arm/mach-integrator/pci_v3.c

 * Copyright (C) 1999 ARM Limited

 * Copyright (C) 2000-2001 Deep Blue Solutions Ltd

 *

 * Contributors to the old driver include:

 * Russell King <linux@armlinux.org.uk>

 * David A. Rusling <david.rusling@linaro.org> (uHAL, ARM Firmware suite)

 * Rob Herring <robh@kernel.org>

 * Liviu Dudau <Liviu.Dudau@arm.com>

 * Grant Likely <grant.likely@secretlab.ca>

 * Arnd Bergmann <arnd@arndb.de>

 * Bjorn Helgaas <bhelgaas@google.com>

 PCI STATUS bits */

 LB ISTAT bits */

 PCI COMMAND bits */

 SYSTEM bits */

 PCI CFG bits */

/*

 * This is the value applied to C/BE[3:1], with bit 0 always held 0

 * during DMA access.

 PCI BASE bits (PCI -> Local Bus) */

 PCI MAP bits (PCI -> Local bus) */

 LB_BASE0,1 bits (Local bus -> PCI) */

 LB_MAP0,1 bits (Local bus -> PCI) */

 LB_BASE2 bits (Local bus -> PCI IO) */

 LB_MAP2 bits (Local bus -> PCI IO) */

 FIFO priority bits */

 Local bus configuration bits */

 ARM Integrator-specific extended control registers */

/*

 * The V3 PCI interface chip in Integrator provides several windows from

 * local bus memory into the PCI memory areas. Unfortunately, there

 * are not really enough windows for our usage, therefore we reuse

 * one of the windows for access to PCI configuration space. On the

 * Integrator/AP, the memory map is as follows:

 *

 * Local Bus Memory         Usage

 *

 * 40000000 - 4FFFFFFF      PCI memory.  256M non-prefetchable

 * 50000000 - 5FFFFFFF      PCI memory.  256M prefetchable

 * 60000000 - 60FFFFFF      PCI IO.  16M

 * 61000000 - 61FFFFFF      PCI Configuration. 16M

 *

 * There are three V3 windows, each described by a pair of V3 registers.

 * These are LB_BASE0/LB_MAP0, LB_BASE1/LB_MAP1 and LB_BASE2/LB_MAP2.

 * Base0 and Base1 can be used for any type of PCI memory access.   Base2

 * can be used either for PCI I/O or for I20 accesses.  By default, uHAL

 * uses this only for PCI IO space.

 *

 * Normally these spaces are mapped using the following base registers:

 *

 * Usage Local Bus Memory         Base/Map registers used

 *

 * Mem   40000000 - 4FFFFFFF      LB_BASE0/LB_MAP0

 * Mem   50000000 - 5FFFFFFF      LB_BASE1/LB_MAP1

 * IO    60000000 - 60FFFFFF      LB_BASE2/LB_MAP2

 * Cfg   61000000 - 61FFFFFF

 *

 * This means that I20 and PCI configuration space accesses will fail.

 * When PCI configuration accesses are needed (via the uHAL PCI

 * configuration space primitives) we must remap the spaces as follows:

 *

 * Usage Local Bus Memory         Base/Map registers used

 *

 * Mem   40000000 - 4FFFFFFF      LB_BASE0/LB_MAP0

 * Mem   50000000 - 5FFFFFFF      LB_BASE0/LB_MAP0

 * IO    60000000 - 60FFFFFF      LB_BASE2/LB_MAP2

 * Cfg   61000000 - 61FFFFFF      LB_BASE1/LB_MAP1

 *

 * To make this work, the code depends on overlapping windows working.

 * The V3 chip translates an address by checking its range within

 * each of the BASE/MAP pairs in turn (in ascending register number

 * order).  It will use the first matching pair.   So, for example,

 * if the same address is mapped by both LB_BASE0/LB_MAP0 and

 * LB_BASE1/LB_MAP1, the V3 will use the translation from

 * LB_BASE0/LB_MAP0.

 *

 * To allow PCI Configuration space access, the code enlarges the

 * window mapped by LB_BASE0/LB_MAP0 from 256M to 512M.  This occludes

 * the windows currently mapped by LB_BASE1/LB_MAP1 so that it can

 * be remapped for use by configuration cycles.

 *

 * At the end of the PCI Configuration space accesses,

 * LB_BASE1/LB_MAP1 is reset to map PCI Memory.  Finally the window

 * mapped by LB_BASE0/LB_MAP0 is reduced in size from 512M to 256M to

 * reveal the now restored LB_BASE1/LB_MAP1 window.

 *

 * NOTE: We do not set up I2O mapping.  I suspect that this is only

 * for an intelligent (target) device.  Using I2O disables most of

 * the mappings into PCI memory.

		/*

		 * local bus segment so need a type 0 config cycle

		 *

		 * build the PCI configuration "address" with one-hot in

		 * A31-A11

		 *

		 * mapaddress:

		 *  3:1 = config cycle (101)

		 *  0   = PCI A1 & A0 are 0 (0)

			/*

			 * high order bits are handled by the MAP register

			/*

			 * low order bits handled directly in the address

		/*

		 * not the local bus segment so need a type 1 config cycle

		 *

		 * address:

		 *  23:16 = bus number

		 *  15:11 = slot number (7:3 of devfn)

		 *  10:8  = func number (2:0 of devfn)

		 *

		 * mapaddress:

		 *  3:1 = config cycle (101)

		 *  0   = PCI A1 & A0 from host bus (1)

	/*

	 * Set up base0 to see all 512Mbytes of memory space (not

	 * prefetchable), this frees up base1 for re-use by

	 * configuration memory

	/*

	 * Set up base1/map1 to point into configuration space.

	 * The config mem is always 16MB.

	/*

	 * Reassign base1 for use by prefetchable PCI memory

 was V3_LB_MAP_TYPE_MEM_MULTIPLE */

	/*

	 * And shrink base0 back to a 256M window (NOTE: MAP0 already correct)

 Clear all possible interrupts on the local bus */

 Take the PCI bridge out of reset, clear IRQs */

 If we were in reset we need to sleep a bit */

 Set the physical base for the controller itself */

 Wait for the mailbox to settle after reset */

 Setup window 2 - PCI I/O */

 Setup window 1 - PCI prefetchable memory */

 Was V3_LB_MAP_TYPE_MEM_MULTIPLE */

 Setup window 0 - PCI non-prefetchable memory */

 Get and enable host clock */

	/*

	 * The hardware has a register with the physical base address

	 * of the V3 controller itself, verify that this is the same

	 * as the physical memory we've remapped it from.

 Configuration space is 16MB directly mapped */

 Get and request error IRQ resource */

	/*

	 * Unlock V3 registers, but only if they were previously locked.

 Disable all slave access while we set up the windows */

 Put the PCI bus into reset */

 Retry until we're ready */

 Set up the local bus protocol */

 Byte enable input */

 Byte enable output */

 Little endian */

 TODO: when using on PPC403Gx, set to 1 */

 Enable the PCI bus master */

 Get the I/O and memory ranges from DT */

	/*

	 * Disable PCI to host IO cycles, enable I/O buffers @3.3V,

	 * set AD_LOW0 to 1 if one of the LB_MAP registers choose

	 * to use this (should be unused).

	/*

	 * DMA read and write from PCI bus commands types

	/*

	 * Set the V3 FIFO such that writes have higher priority than

	 * reads, and local bus write causes local bus read fifo flush

	 * on aperture 1. Same for PCI.

	/*

	 * Clear any error interrupts, and enable parity and write error

	 * interrupts

 Special Integrator initialization */

 Post-init: enable PCI memory and invalidate (master already on) */

 Clear pending interrupts */

 Read or write errors and parity errors cause interrupts */

 Take the PCI bus out of reset so devices can initialize */

	/*

	 * Re-lock the system register.

 SPDX-License-Identifier: GPL-2.0

/*

 * Support for Intel IXP4xx PCI host controller

 *

 * Copyright (C) 2017 Linus Walleij <linus.walleij@linaro.org>

 *

 * Based on the IXP4xx arch/arm/mach-ixp4xx/common-pci.c driver

 * Copyright (C) 2002 Intel Corporation

 * Copyright (C) 2003 Greg Ungerer <gerg@linux-m68k.org>

 * Copyright (C) 2003-2004 MontaVista Software, Inc.

 * Copyright (C) 2005 Deepak Saxena <dsaxena@plexity.net>

 * Copyright (C) 2005 Alessandro Zummo <a.zummo@towertech.it>

 *

 * TODO:

 * - Test IO-space access

 * - DMA support

 Register offsets */

 CSR bit definitions */

 ISR (Interrupt status) Register bit definitions */

 INTEN (Interrupt Enable) Register bit definitions */

 Shift value for byte enable on NP cmd/byte enable register */

 PCI commands supported by NP access unit */

 Constants for CRP access into local config space */

 Special PCI configuration space registers for this controller */

/*

 * The IXP4xx has a peculiar address bus that will change the

 * byte order on SoC peripherals depending on whether the device

 * operates in big-endian or little-endian mode. That means that

 * readl() and writel() that always use little-endian access

 * will not work for SoC peripherals such as the PCI controller

 * when used in big-endian mode. The accesses to the individual

 * PCI devices on the other hand, are always little-endian and

 * can use readl() and writel().

 *

 * For local AHB bus access we need to use __raw_[readl|writel]()

 * to make sure that we access the SoC devices in the CPU native

 * endianness.

 Make sure the master abort bit is reset */

		/*

		 * PCI workaround - only works if NP PCI space reads have

		 * no side effects. Hammer the register and read twice 8

		 * times. last one will be good.

 Set up the write */

 Execute the write by writing to NP_WDATA */

 Root bus is always 0 in this hardware */

 type 0 */

 type 1 */

/*

 * CRP functions are "Controller Configuration Port" accesses

 * initiated from within this driver itself to read/write PCI

 * control information in the config space.

 Should not happen */

/*

 * Then follows the functions that read and write from the common PCI

 * configuration space.

 Should not happen */

 Commit configuration */

		/*

		 * Setup I/O space location for PCI->AHB access, the

		 * upper 24 bits of the address goes into the lower

		 * 24 bits of this register.

		/*

		 * 4 PCI-to-AHB windows of 16 MB each, write the 8 high bits

		 * into each byte of the PCI_AHBMEMBASE register.

 Commit AHB membase */

 Only used to get context for abort handling */

 Make sure the Master Abort bit is reset */

	/*

	 * If it was an imprecise abort, then we need to correct the

	 * return address to be _after_ the instruction.

	/*

	 * Set up quirk for erratic behaviour in the 42x variant

	 * when accessing config space.

 Hook in our fault handler for PCI errors */

 This is only configured in host mode */

 This is a noop (0x00) but explains what is going on */

 Write this directly into the config space */

		/*

		 * Enable CSR window at 64 MiB to allow PCI masters to continue

		 * prefetching past the 64 MiB boundary, if all AHB to PCI

		 * windows are consecutive.

		/*

		 * Put the IO memory window at the very end of physical memory

		 * at 0xfffffc00. This is when the system is trying to access IO

		 * memory over AHB.

		/*

		 * Retry timeout to 0x80

		 * Transfer ready timeout to 0xff

 Clear interrupts */

	/*

	 * Set Initialize Complete in PCI Control Register: allow IXP4XX to

	 * generate PCI configuration cycles. Specify that the AHB bus is

	 * operating in big-endian mode. Set up byte lane swapping between

	 * little-endian PCI and the big-endian AHB bus.

/*

 * This driver needs to be a builtin module with suppressed bind

 * attributes since the probe() is initializing a hard exception

 * handler and this can only be done from __init-tagged code

 * sections. This module cannot be removed and inserted at all.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Rockchip AXI PCIe host controller driver

 *

 * Copyright (c) 2016 Rockchip, Inc.

 *

 * Author: Shawn Lin <shawn.lin@rock-chips.com>

 *         Wenrui Li <wenrui.li@rock-chips.com>

 *

 * Bits taken from Synopsys DesignWare Host controller driver and

 * ARM PCI Host generic driver.

	/*

	 * Please don't reorder the deassert sequence of the following

	 * four reset pins.

 inactive lanes are already powered off */

 Configuration Accesses for region 0 */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2015 Broadcom Corporation

 * Copyright (C) 2015 Hauke Mehrtens <hauke@hauke-m.de>

 NS: CLASS field is R/O, and set to wrong 0x200 value */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe driver for Renesas R-Car SoCs

 *  Copyright (C) 2014-2020 Renesas Electronics Europe Ltd

 *

 * Author: Phil Edworthy <phil.edworthy@renesas.com>

 Setup PCIe address space mappings for each resource */

	/*

	 * The PAMR mask is calculated in units of 128Bytes, which

	 * keeps things pretty simple.

 First resource is for IO */

	/*

	 * Set up 64-bit inbound regions as the range parser doesn't

	 * distinguish between 32 and 64-bit types.

 SPDX-License-Identifier: GPL-2.0+

/*

 * APM X-Gene MSI Driver

 *

 * Copyright (c) 2014, Applied Micro Circuits Corporation

 * Author: Tanmay Inamdar <tinamdar@apm.com>

 *	   Duc Dang <dhdang@apm.com>

 Global data */

/*

 * X-Gene v1 has 16 groups of MSI termination registers MSInIRx, where

 * n is group number (0..F), x is index of registers in each group (0..7)

 * The register layout is as follows:

 * MSI0IR0			base_addr

 * MSI0IR1			base_addr +  0x10000

 * ...				...

 * MSI0IR6			base_addr +  0x60000

 * MSI0IR7			base_addr +  0x70000

 * MSI1IR0			base_addr +  0x80000

 * MSI1IR1			base_addr +  0x90000

 * ...				...

 * MSI1IR7			base_addr +  0xF0000

 * MSI2IR0			base_addr + 0x100000

 * ...				...

 * MSIFIR0			base_addr + 0x780000

 * MSIFIR1			base_addr + 0x790000

 * ...				...

 * MSIFIR7			base_addr + 0x7F0000

 * MSIINT0			base_addr + 0x800000

 * MSIINT1			base_addr + 0x810000

 * ...				...

 * MSIINTF			base_addr + 0x8F0000

 *

 * Each index register supports 16 MSI vectors (0..15) to generate interrupt.

 * There are total 16 GIC IRQs assigned for these 16 groups of MSI termination

 * registers.

 *

 * Each MSI termination group has 1 MSIINTn register (n is 0..15) to indicate

 * the MSI pending status caused by 1 of its 8 index registers.

 MSInIRx read helper */

 MSIINTn read helper */

/*

 * With 2048 MSI vectors supported, the MSI message can be constructed using

 * following scheme:

 * - Divide into 8 256-vector groups

 *		Group 0: 0-255

 *		Group 1: 256-511

 *		Group 2: 512-767

 *		...

 *		Group 7: 1792-2047

 * - Each 256-vector group is divided into 16 16-vector groups

 *	As an example: 16 16-vector groups for 256-vector group 0-255 is

 *		Group 0: 0-15

 *		Group 1: 16-32

 *		...

 *		Group 15: 240-255

 * - The termination address of MSI vector in 256-vector group n and 16-vector

 *   group x is the address of MSIxIRn

 * - The data for MSI vector in 16-vector group x is x

/*

 * X-Gene v1 only has 16 MSI GIC IRQs for 2048 MSI vectors.  To maintain

 * the expected behaviour of .set_affinity for each MSI interrupt, the 16

 * MSI GIC IRQs are statically allocated to 8 X-Gene v1 cores (2 GIC IRQs

 * for each core).  The MSI vector is moved fom 1 MSI GIC IRQ to another

 * MSI GIC IRQ to steer its MSI interrupt to correct X-Gene v1 core.  As a

 * consequence, the total MSI vectors that X-Gene v1 supports will be

 * reduced to 256 (2048/8) vectors.

 Update MSI number to target the new CPU */

	/*

	 * MSIINTn (n is 0..F) indicates if there is a pending MSI interrupt

	 * If bit x of this register is set (x is 0..7), one or more interrupts

	 * corresponding to MSInIRx is set.

		/*

		 * Calculate MSInIRx address to read to check for interrupts

		 * (refer to termination address and data assignment

		 * described in xgene_compose_msi_msg() )

			/*

			 * Calculate MSI vector number (refer to the termination

			 * address and data assignment described in

			 * xgene_compose_msi_msg function)

			/*

			 * As we have multiple hw_irq that maps to single MSI,

			 * always look up the virq using the hw_irq as seen from

			 * CPU0

			/*

			 * We handled all interrupts happened in this group,

			 * resample this group MSI_INTx register in case

			 * something else has been made pending in the meantime

		/*

		 * Statically allocate MSI GIC IRQs to each CPU core.

		 * With 8-core X-Gene v1, 2 MSI GIC IRQs are allocated

		 * to each core.

	/*

	 * MSInIRx registers are read-to-clear; before registering

	 * interrupt handlers, read all of them to clear spurious

	 * interrupts that may occur before the driver is probed.

 Read MSIINTn to confirm */

 SPDX-License-Identifier: GPL-2.0+

/*

 * BRIEF MODULE DESCRIPTION

 *     PCI init for Ralink RT2880 solution

 *

 * Copyright 2007 Ralink Inc. (bruce_chang@ralinktech.com.tw)

 *

 * May 2007 Bruce Chang

 * Initial Release

 *

 * May 2009 Bruce Chang

 * support RT2880/RT3883 PCIe

 *

 * May 2011 Bruce Chang

 * support RT6855/MT7620 PCIe

 MediaTek-specific configuration registers */

 Host-PCI bridge registers */

 PCIe RC control registers */

 Some definition values */

/**

 * struct mt7621_pcie_port - PCIe port information

 * @base: I/O mapped register base

 * @list: port list

 * @pcie: pointer to PCIe host info

 * @clk: pointer to the port clock gate

 * @phy: pointer to PHY control block

 * @pcie_rst: pointer to port reset control

 * @gpio_rst: gpio reset

 * @slot: port slot

 * @enabled: indicates if port is enabled

/**

 * struct mt7621_pcie - PCIe host information

 * @base: IO Mapped Register Base

 * @dev: Pointer to PCIe device

 * @ports: pointer to PCIe port information

 * @resets_inverted: depends on chip revision

 * reset lines are inverted.

		/*

		 * FIXME: hardware doesn't accept mask values with 1s after

		 * 0s (e.g. 0xffef), so it would be great to warn if that's

		 * about to happen

 PCIe RC reset assert */

 PCIe EP reset assert */

 enable pcie interrupt */

 map 2G DDR region */

 configure class code and revision ID */

 configure RC FTS number to 250 when it leaves L0s */

 Setup MEMWIN and IOWIN */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCIe host controller driver for NWL PCIe Bridge

 * Based on pcie-xilinx.c, pci-tegra.c

 *

 * (C) Copyright 2014 - 2015, Xilinx, Inc.

 Bridge core config registers */

 Egress - Bridge translation registers */

 Ingress - address translations */

 Rxed msg fifo  - Interrupt status registers */

 Msg filter mask bits */

 Misc interrupt status mask bits */

 Legacy interrupt status mask bits */

 MSI interrupt status mask bits */

 Bridge config interrupt mask */

 E_ECAM status mask bits */

 Readin the PS_LINKUP */

 Parameters for the waiting for link up routine */

 MSI information */

 protect bitmap variable */

 Physical Bridge Register Base */

 Physical PCIe Controller Base */

 Physical Configuration Base */

 check if the link is up or not */

 Check link before accessing downstream ports */

 Only one device down on each root port */

/**

 * nwl_pcie_map_bus - Get configuration base

 *

 * @bus: Bus structure of current bus

 * @devfn: Device/function

 * @where: Offset from base

 *

 * Return: Base address of the configuration space needed to be

 *	   accessed.

 PCIe operations */

 Checking for misc interrupts */

 Clear misc interrupt status */

 Get msi_1 IRQ number */

 Get msi_0 IRQ number */

 Check for msii_present bit */

 Enable MSII */

 Enable MSII status */

 setup AFI/FPCI range */

	/*

	 * For high range MSI interrupts: disable, clear any pending,

	 * and enable

	/*

	 * For low range MSI interrupts: disable, clear any pending,

	 * and enable

 Write bridge_off to breg base */

 Enable BREG */

 Disable DMA channel registers */

 Enable Ingress subtractive decode translation */

 Enable msg filtering details */

 This routes the PCIe DMA traffic to go through CCI path */

 Enable ECAM */

 Get bus range */

 Write primary, secondary and subordinate bus numbers */

 Get misc IRQ number */

 Disable all misc interrupts */

 Clear pending misc interrupts */

 Enable all misc interrupts */

 Disable all legacy interrupts */

 Clear pending legacy interrupts */

 Enable all legacy interrupts */

 Enable the bridge config interrupt */

 Get intx IRQ number */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2004 Koninklijke Philips Electronics NV

 *

 * Conversion to platform driver and DT:

 * Copyright 2014 Linaro Ltd.

 *

 * 14/04/2005 Initial version, colin.king@philips.com

	/*

	 * We need to discover the PCI core first to configure itself

	 * before the main PCI probing is performed

	/*

	 * Do not to map Versatile FPGA PCI device into memory space

	/*

	 * Configure the PCI inbound memory windows to be 1:1 mapped to SDRAM

	/*

	 * For many years the kernel and QEMU were symbiotically buggy

	 * in that they both assumed the same broken IRQ mapping.

	 * QEMU therefore attempts to auto-detect old broken kernels

	 * so that they still work on newer QEMU as they did on old

	 * QEMU. Since we now use the correct (ie matching-hardware)

	 * IRQ mapping we write a definitely different value to a

	 * PCI_INTERRUPT_LINE register to tell QEMU that we expect

	 * real hardware behaviour and it need not be backwards

	 * compatible for us. This write is harmless on real hardware.

 SPDX-License-Identifier: GPL-2.0

/*

 * Loongson PCI Host Controller Driver

 *

 * Copyright (C) 2020 Jiaxun Yang <jiaxun.yang@flygoat.com>

 Device IDs */

 Fixup wrong class code in PCIe bridges */

	/*

	 * The address space consumed by these devices is outside the

	 * resources of the host bridge.

 look for the matching bridge */

		/*

		 * Some Loongson PCIe ports have a h/w limitation of

		 * 256 bytes maximum read request size. They can't handle

		 * anything larger than this. So force this limit on

		 * any devices attached under these ports.

 Type 1 Access */

 Type 1 Access */

	/*

	 * Do not read more than one device on the bus other than

	 * the host bus. For our hardware the root bus is always bus 0.

 CFG0 can only access standard space */

 CFG1 can access extended space */

 Care i8259 legacy systems */

 i8259 only have 15 IRQs */

 H/w only accept 32-bit PCI operations */

 CFG1 is optional */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright Altera Corporation (C) 2013-2015. All rights reserved

 *

 * Author: Ley Foon Tan <lftan@altera.com>

 * Description: Altera PCIe host controller driver

 TLP configuration type 0 and 1 */

 Configuration Read Type 0 */

 Configuration Write Type 0 */

 Configuration Read Type 1 */

 Configuration Write Type 1 */

 PCIe capability structure register offset */

/*

 * Altera PCIe port uses BAR0 of RC's configuration space as the translation

 * from PCI bus to native BUS.  Entire DDR region is mapped into PCIe space

 * using these registers, so it can be reached by DMA from EP devices.

 * This BAR0 will also access to MSI vector when receiving MSI/MSIX interrupt

 * from EP devices, eventually trigger interrupt to GIC.  The BAR0 of bridge

 * should be hidden during enumeration to avoid the sizing and resource

 * allocation by PCIe core.

 If there is no link, then there is no device */

 access only one slot on each root port */

	/*

	 * Minimum 2 loops to read TLP headers and 1 loop to read data

	 * payload.

 Read first DW */

 SOP detection failed, return error */

 Poll for EOP */

 check alignment to Qword */

	/*

	 * Monitor changes to PCI_PRIMARY_BUS register on root port

	 * and update local copy of root bus number accordingly.

	/*

	 * Monitor changes to PCI_PRIMARY_BUS register on root port

	 * and update local copy of root bus number accordingly.

 Wait for link training end. */

 Wait for link is up */

	/*

	 * Set the retrain bit if the PCIe rootport support > 2.5GB/s, but

	 * current speed is 2.5 GB/s.

 clear interrupts */

 Setup INTx */

 setup IRQ */

 clear all interrupts */

 enable all interrupts */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCIe host controller driver for Xilinx AXI PCIe Bridge

 *

 * Copyright (c) 2012 - 2014 Xilinx, Inc.

 *

 * Based on the Tegra PCIe driver

 *

 * Bits taken from Synopsys DesignWare Host controller driver and

 * ARM PCI Host generic driver.

 Register definitions */

 Interrupt registers definitions */

 Root Port Error FIFO Read Register definitions */

 Root Port Interrupt FIFO Read Register 1 definitions */

 Bridge Info Register definitions */

 Root Port Interrupt FIFO Read Register 2 definitions */

 Root Port Status/control Register definitions */

 Phy Status/Control Register definitions */

 Number of MSI IRQs */

/**

 * struct xilinx_pcie_port - PCIe port information

 * @reg_base: IO Mapped Register Base

 * @dev: Device pointer

 * @msi_map: Bitmap of allocated MSIs

 * @map_lock: Mutex protecting the MSI allocation

 * @msi_domain: MSI IRQ domain pointer

 * @leg_domain: Legacy IRQ domain pointer

 * @resources: Bus Resources

/**

 * xilinx_pcie_clear_err_interrupts - Clear Error Interrupts

 * @port: PCIe port information

/**

 * xilinx_pcie_valid_device - Check if a valid device is present on bus

 * @bus: PCI Bus structure

 * @devfn: device/function

 *

 * Return: 'true' on success and 'false' if invalid device is found

 Check if link is up when trying to access downstream ports */

 Only one device down on each root port */

/**

 * xilinx_pcie_map_bus - Get configuration base

 * @bus: PCI Bus structure

 * @devfn: Device/function

 * @where: Offset from base

 *

 * Return: Base address of the configuration space needed to be

 *	   accessed.

 PCIe operations */

 MSI functions */

	/*

	 * xilinx_pcie_intr_handler() will have performed the Ack.

	 * Eventually, this should be fixed and the Ack be moved in

	 * the respective callbacks for INTx and MSI.

 INTx Functions */

/**

 * xilinx_pcie_intx_map - Set the handler for the INTx and mark IRQ as valid

 * @domain: IRQ domain

 * @irq: Virtual IRQ number

 * @hwirq: HW interrupt number

 *

 * Return: Always returns 0.

 INTx IRQ Domain operations */

 PCIe HW Functions */

/**

 * xilinx_pcie_intr_handler - Interrupt Service Handler

 * @irq: IRQ number

 * @data: PCIe port information

 *

 * Return: IRQ_HANDLED on success and IRQ_NONE on failure

 Read interrupt decode and mask registers */

 Check whether interrupt valid */

 Decode the IRQ number */

 Clear interrupt FIFO register 1 */

 Clear the Interrupt Decode register */

/**

 * xilinx_pcie_init_irq_domain - Initialize IRQ domain

 * @port: PCIe port information

 *

 * Return: '0' on success and error value on failure

 Setup INTx */

 Setup MSI */

/**

 * xilinx_pcie_init_port - Initialize hardware

 * @port: PCIe port information

 Disable all interrupts */

 Clear pending interrupts */

 Enable all interrupts we handle */

 Enable the Bridge enable bit */

/**

 * xilinx_pcie_parse_dt - Parse Device tree

 * @port: PCIe port information

 *

 * Return: '0' on success and error value on failure

/**

 * xilinx_pcie_probe - Probe function

 * @pdev: Platform device pointer

 *

 * Return: '0' on success and error value on failure

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2014 Hauke Mehrtens <hauke@hauke-m.de>

 * Copyright (C) 2015 Broadcom Corporation

 500 milliseconds */

 derive the enum index of the outbound/inbound mapping registers */

/*

 * Maximum number of outbound mapping window sizes that can be supported by any

 * OARR/OMAP mapping pair

/*

 * Maximum number of inbound mapping region sizes that can be supported by an

 * IARR

/**

 * struct iproc_pcie_ob_map - iProc PCIe outbound mapping controller-specific

 * parameters

 * @window_sizes: list of supported outbound mapping window sizes in MB

 * @nr_sizes: number of supported outbound mapping window sizes

 OARR0/OMAP0 */

 OARR1/OMAP1 */

 OARR0/OMAP0 */

 OARR1/OMAP1 */

 OARR2/OMAP2 */

 OARR3/OMAP3 */

/**

 * enum iproc_pcie_ib_map_type - iProc PCIe inbound mapping type

 * @IPROC_PCIE_IB_MAP_MEM: DDR memory

 * @IPROC_PCIE_IB_MAP_IO: device I/O memory

 * @IPROC_PCIE_IB_MAP_INVALID: invalid or unused

/**

 * struct iproc_pcie_ib_map - iProc PCIe inbound mapping controller-specific

 * parameters

 * @type: inbound mapping region type

 * @size_unit: inbound mapping region size unit, could be SZ_1K, SZ_1M, or

 * SZ_1G

 * @region_sizes: list of supported inbound mapping region sizes in KB, MB, or

 * GB, depending on the size unit

 * @nr_sizes: number of supported inbound mapping region sizes

 * @nr_windows: number of supported inbound mapping windows for the region

 * @imap_addr_offset: register offset between the upper and lower 32-bit

 * IMAP address registers

 * @imap_window_offset: register offset between each IMAP window

 IARR0/IMAP0 */

 IARR1/IMAP1 */

 IARR2/IMAP2 */

 IARR3/IMAP3 */

 IARR4/IMAP4 */

/*

 * iProc PCIe host registers

 clock/reset signal control */

	/*

	 * To allow MSI to be steered to an external MSI controller (e.g., ARM

	 * GICv3 ITS)

	/*

	 * IPROC_PCIE_MSI_BASE_ADDR and IPROC_PCIE_MSI_WINDOW_SIZE define the

	 * window where the MSI posted writes are written, for the writes to be

	 * interpreted as MSI writes.

	/*

	 * To hold the address of the register where the MSI writes are

	 * programmed.  When ARM GICv3 ITS is used, this should be programmed

	 * with the address of the GITS_TRANSLATER register.

 enable MSI */

 allow access to root complex configuration space */

 allow access to device configuration space */

 enable INTx */

 outbound address mapping */

 inbound address mapping */

 config read status */

 link status */

 enable APB error for unsupported requests */

 total number of core registers */

 iProc PCIe PAXB BCMA registers */

 iProc PCIe PAXB registers */

 iProc PCIe PAXB v2 registers */

 iProc PCIe PAXC v1 registers */

 iProc PCIe PAXC v2 registers */

/*

 * List of device IDs of controllers that have corrupted capability list that

 * require SW fixup

/*

 * APB error forwarding can be disabled during access of configuration

 * registers of the endpoint device, to prevent unsupported requests

 * (typically seen during enumeration with multi-function devices) from

 * triggering a system exception.

 EP device access */

	/*

	 * As per PCIe spec r3.1, sec 2.3.2, CRS Software Visibility only

	 * affects config reads of the Vendor ID.  For config writes or any

	 * other config reads, the Root may automatically reissue the

	 * configuration request again as a new request.

	 *

	 * For config reads, this hardware returns CFG_RETRY_STATUS data

	 * when it receives a CRS completion, regardless of the address of

	 * the read or the CRS Software Visibility Enable bit.  As a

	 * partial workaround for this, we retry in software any read that

	 * returns CFG_RETRY_STATUS.

	 *

	 * Note that a non-Vendor ID config register may have a value of

	 * CFG_RETRY_STATUS.  If we read that, we can't distinguish it from

	 * a CRS completion, so we will incorrectly retry the read and

	 * eventually return the wrong data (0xffffffff).

		/*

		 * CRS state is set in CFG_RD status register

		 * This will handle the case where CFG_RETRY_STATUS is

		 * valid config data.

		/*

		 * Activate fixup for those controllers that have corrupted

		 * capability list registers

 advertise PM, force next capability to PCIe */

 advertise root port, version 2, terminate here */

 Don't advertise CRS SV support */

 root complex access */

	/*

	 * For PAXC and PAXCv2, the total number of PFs that one can enumerate

	 * depends on the firmware configuration. Unfortunately, due to an ASIC

	 * bug, unconfigured PFs cannot be properly hidden from the root

	 * complex. As a result, write access to these PFs will cause bus lock

	 * up on the embedded processor

	 *

	 * Since all unconfigured PFs are left with an incorrect, staled device

	 * ID of 0x168e (PCI_DEVICE_ID_NX2_57810), we try to catch those access

	 * early here and reject them all

/*

 * Note access to the configuration registers are protected at the higher layer

 * by 'pci_lock' in drivers/pci/access.c

 root complex access */

	/*

	 * PAXC and the internal emulated endpoint device downstream should not

	 * be reset.  If firmware has been loaded on the endpoint device at an

	 * earlier boot stage, reset here causes issues.

	/*

	 * PAXC connects to emulated endpoint devices directly and does not

	 * have a Serdes.  Therefore skip the link detection logic here.

 make sure we are not in EP mode */

 force class to PCI_CLASS_BRIDGE_PCI (0x0604) */

 check link status to see if link is active */

 try GEN 1 link speed */

	/*

	 * Derive the OARR/OMAP offset from the first pair (OARR0/OMAP0) based

	 * on window index.

	/*

	 * Program the OARR registers.  The upper 32-bit OARR register is

	 * always right after the lower 32-bit OARR register.

 now program the OMAP registers */

/*

 * Some iProc SoCs require the SW to configure the outbound address mapping

 *

 * Outbound address translation:

 *

 * iproc_pcie_address = axi_address - axi_offset

 * OARR = iproc_pcie_address

 * OMAP = pci_addr

 *

 * axi_addr -> iproc_pcie_address -> OARR -> OMAP -> pci_address

	/*

	 * Translate the AXI address to the internal address used by the iProc

	 * PCIe core before programming the OARR

 iterate through all OARR/OMAP mapping windows */

		/*

		 * If current outbound window is already in use, move on to the

		 * next one.

		/*

		 * Iterate through all supported window sizes within the

		 * OARR/OMAP pair to find a match.  Go through the window sizes

		 * in a descending order.

			/*

			 * Keep iterating until we reach the last window and

			 * with the minimal window size at index zero. In this

			 * case, we take a compromise by mapping it using the

			 * minimum window size that can be supported

				/*

				 * For the corner case of reaching the minimal

				 * window size that can be supported on the

				 * last window

			/*

			 * Match found!  Program both OARR and OMAP and mark

			 * them as a valid entry.

			/*

			 * If we are here, we are done with the current window,

			 * but not yet finished all mappings.  Need to move on

			 * to the next window.

	/*

	 * Program the IARR registers.  The upper 32-bit IARR register is

	 * always right after the lower 32-bit IARR register.

	/*

	 * Now program the IMAP registers.  Each IARR region may have one or

	 * more IMAP windows.

 iterate through all IARR mapping regions */

		/*

		 * If current inbound region is already in use or not a

		 * compatible type, move on to the next.

 iterate through all supported region sizes to find a match */

 Match found!  Program IARR and all IMAP windows. */

 Each range entry corresponds to an inbound mapping region */

 iterate through all OARR mapping regions */

 iterate through all IARR mapping regions */

	/*

	 * Check if 'msi-map' points to ARM GICv3 ITS, which is the only

	 * supported external MSI controller that requires steering.

 derive GITS_TRANSLATER address from GICv3 */

		/*

		 * Disable PAXC MSI steering. All write transfers will be

		 * treated as non-MSI transfers

	/*

	 * Program bits [43:13] of address of GITS_TRANSLATER register into

	 * bits [30:0] of the MSI base address register.  In fact, in all iProc

	 * based SoCs, all I/O register bases are well below the 32-bit

	 * boundary, so we can safely assume bits [43:32] are always zeros.

 use a default 8K window size */

 steering MSI to GICv3 ITS */

	/*

	 * Program bits [43:2] of address of GITS_TRANSLATER register into the

	 * iProc MSI address registers.

 enable MSI */

	/*

	 * Either the "msi-parent" or the "msi-map" phandle needs to exist

	 * for us to obtain the MSI node.

	/*

	 * Certain revisions of the iProc PCIe controller require additional

	 * configurations to steer the MSI writes towards an external MSI

	 * controller.

	/*

	 * If another MSI controller is being used, the call below should fail

	 * but that is okay

 go through the register table and populate all valid registers */

/*

 * The MSI parsing logic in certain revisions of Broadcom PAXC based root

 * complex does not work and needs to be disabled

	/*

	 * The PCI config space is shared with the PAXC root port and the first

	 * Ethernet device.  So, we need to workaround this by telling the PCI

	 * code that the bridge is not an Ethernet device.

	/*

	 * MPSS is not being set properly (as it is currently 0).  This is

	 * because that area of the PCI config space is hard coded to zero, and

	 * is not modifiable by firmware.  Set this to 2 (e.g., 512 byte MPS)

	 * so that the MPS can be set to the real max value.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) Microsoft Corporation.

 *

 * Author:

 *   Haiyang Zhang <haiyangz@microsoft.com>

 *

 * This small module is a helper driver allows other drivers to

 * have a common interface with the Hyper-V PCI frontend driver.

 SPDX-License-Identifier: GPL-2.0

/*

 * MediaTek PCIe host controller driver.

 *

 * Copyright (c) 2020 MediaTek Inc.

 * Author: Jianjun Wang <jianjun.wang@mediatek.com>

/**

 * struct mtk_msi_set - MSI information for each set

 * @base: IO mapped register base

 * @msg_addr: MSI message address

 * @saved_irq_state: IRQ enable state saved at suspend time

/**

 * struct mtk_pcie_port - PCIe port information

 * @dev: pointer to PCIe device

 * @base: IO mapped register base

 * @reg_base: physical register base

 * @mac_reset: MAC reset control

 * @phy_reset: PHY reset control

 * @phy: PHY controller block

 * @clks: PCIe clocks

 * @num_clks: PCIe clocks count for this port

 * @irq: PCIe controller interrupt number

 * @saved_irq_state: IRQ enable state saved at suspend time

 * @irq_lock: lock protecting IRQ register access

 * @intx_domain: legacy INTx IRQ domain

 * @msi_domain: MSI IRQ domain

 * @msi_bottom_domain: MSI IRQ bottom domain

 * @msi_sets: MSI sets information

 * @lock: lock protecting IRQ bit map

 * @msi_irq_in_use: bit map for assigned MSI IRQ

/**

 * mtk_pcie_config_tlp_header() - Configure a configuration TLP header

 * @bus: PCI bus to query

 * @devfn: device/function number

 * @where: offset in config space

 * @size: data size in TLP header

 *

 * Set byte enable field and device information in configuration TLP header.

 Configure the MSI capture address */

 Set as RC mode */

 Set class code */

 Mask all INTx interrupts */

 Assert all reset signals */

	/*

	 * Described in PCIe CEM specification setctions 2.2 (PERST# Signal)

	 * and 2.2.1 (Initial Power-Up (G3 to S0)).

	 * The deassertion of PERST# should be delayed 100ms (TPVPERL)

	 * for the power and clock to become stable.

 De-assert reset signals */

 Check if the link is up or not */

 Set PCIe translation windows */

/**

 * mtk_intx_eoi() - Clear INTx IRQ status at the end of interrupt

 * @data: pointer to chip specific data

 *

 * As an emulated level IRQ, its interrupt status will remain

 * until the corresponding de-assert message is received; hence that

 * the status can only be cleared when the interrupt has been serviced.

 Setup INTx */

 Setup MSI */

 PHY power on and enable pipe clock */

 MAC power on and enable transaction layer clocks */

 Don't touch the hardware registers before power up */

 Try link up */

 Check the link is L2 */

 Trigger link to L2 state */

 Pull down the PERST# pin */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2015 - 2016 Cavium, Inc.

/*

 * Enhanced Configuration Access Mechanism (ECAM)

 *

 * N.B. This is a non-standard platform-specific ECAM bus shift value.  For

 * standard values defined in the PCI Express Base Specification see

 * include/linux/pci-ecam.h.

	/*

	 * 32-bit accesses only.  Write the address to the low order

	 * bits of PEM_CFG_RD, then trigger the read by reading back.

	 * The config data lands in the upper 32-bits of PEM_CFG_RD.

	/*

	 * The config space contains some garbage, fix it up.  Also

	 * synthesize an EA capability for the BAR used by MSI-X.

 Skip MSI CAP */

 Express Cap */

		/*

		 * Change PME interrupt to vector 2 on T88 where it

		 * reads as 0, else leave it alone.

 MSI-X Cap */

 TableSize=2 or 4, Next Cap is EA */

		/*

		 * If Express Cap(0x70) raw PME vector reads as 0 we are on

		 * T88 and TableSize is reported as 4, else TableSize

		 * is 2.

 Table offset=0, BIR=0 */

 BPA offset=0xf0000, BIR=0 */

 EA, 1 entry, no next Cap */

 DW2 for type-1 */

 Entry BEI=0, PP=0x00, SP=0xff, ES=3 */

	/*

	 * The first device on the bus is the PEM PCIe bridge.

	 * Special case its config access.

/*

 * Some of the w1c_bits below also include read-only or non-writable

 * reserved bits, this makes the code simpler and is OK as the bits

 * are not affected by writing zeros to them.

 Command/Status */

 Base and I/O Limit/Secondary Status */

 Power Management Control and Status */

 Device Control/Device Status */

 Link Control/Link Status */

 Slot Control/Slot Status */

 Root Status */

 Link Control 2 Registers/Link Status 2 */

 Uncorrectable Error Status */

 Correctable Error Status */

 Error Status */

 Link Control 4 */

 Some bits must be written to one so they appear to be read-only. */

 I/O Base / I/O Limit, Secondary Status */

 Force 32-bit I/O addressing. */

 Prefetchable Memory Base / Prefetchable Memory Limit */

 Force 64-bit addressing */

	/*

	 * 32-bit accesses only.  If the write is for a size smaller

	 * than 32-bits, we must first read the 32-bit value and merge

	 * in the desired bits and then write the whole 32-bits back

	 * out.

	/*

	 * By expanding the write width to 32 bits, we may

	 * inadvertently hit some W1C bits that were not intended to

	 * be written.  Calculate the mask that must be applied to the

	 * data to be written to avoid these cases.

	/*

	 * Some bits must be read-only with value of one.  Since the

	 * access method allows these to be cleared if a zero is

	 * written, force them to one before writing.

	/*

	 * Low order bits are the config address, the high order 32

	 * bits are the data to be written.

	/*

	 * The first device on the bus is the PEM PCIe bridge.

	 * Special case its config access.

	/*

	 * The MSI-X BAR for the PEM and AER interrupts is located at

	 * a fixed offset from the PEM register base.  Generate a

	 * fragment of the synthesized Enhanced Allocation capability

	 * structure here for the BAR.

	/*

	 * If we fail to gather resources it means that we run with old

	 * FW where we need to calculate PEM-specific resources manually.

		/*

		 * Reserve 64K size PEM specific resources. The full 16M range

		 * size is required for thunder_pem_init() call.

 Reserve PCI configuration space as well. */

	/*

	 * The second register range is the PEM bridge to the PCIe

	 * bus.  It has a different config access method than those

	 * devices behind the bridge.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe driver for Renesas R-Car SoCs

 *  Copyright (C) 2014-2020 Renesas Electronics Europe Ltd

 *

 * Based on:

 *  arch/sh/drivers/pci/pcie-sh7786.c

 *  arch/sh/drivers/pci/ops-sh7786.c

 *  Copyright (C) 2009 - 2011  Paul Mundt

 *

 * Author: Phil Edworthy <phil.edworthy@renesas.com>

/*

 * Here we keep a static copy of the remapped PCIe controller address.

 * This is only used on aarch32 systems, all of which have one single

 * PCIe controller, to provide quick access to the PCIe controller in

 * the L1 link state fixup function, called from the ARM fault handler.

/*

 * Static copy of bus clock pointer, so we can check whether the clock

 * is enabled or not.

 Structure representing the PCIe interface */

 Serialization is provided by 'pci_lock' in drivers/pci/access.c */

	/*

	 * While each channel has its own memory-mapped extended config

	 * space, it's generally only accessible when in endpoint mode.

	 * When in root complex mode, the controller is unable to target

	 * itself with either type 0 or type 1 accesses, and indeed, any

	 * controller initiated target transfer to its own config space

	 * result in a completer abort.

	 *

	 * Each channel effectively only supports a single device, but as

	 * the same channel <-> device access works for any PCI_SLOT()

	 * value, we cheat a bit here and bind the controller's config

	 * space to devfn 0 in order to enable self-enumeration. In this

	 * case the regular ECAR/ECDR path is sidelined and the mangled

	 * config access itself is initiated as an internal bus transaction.

 Clear errors */

 Set the PIO address */

 Enable the configuration access */

 Check for errors */

 Check for master and target aborts */

 Disable the configuration access */

 Serialization is provided by 'pci_lock' in drivers/pci/access.c */

 Set target link speed to 5.0 GT/s */

 Set speed change reason as intentional factor */

 Clear SPCHGFIN, SPCHGSUC, and SPCHGFAIL */

 Start link speed change */

 Clear the interrupt bits */

 Try setting 5 GT/s link speed */

 Setup PCI resources */

 Set write data */

 Ignore errors as they will be dealt with if the data link is down */

 Clear command */

 Ignore errors as they will be dealt with if the data link is down */

 Begin initialization */

 Set mode */

	/*

	 * Initial header for port config space is type 1, set the device

	 * class to match. Hardware takes care of propagating the IDSETR

	 * settings, so there is no need to bother with a quirk.

	/*

	 * Setup Secondary Bus Number & Subordinate Bus Number, even though

	 * they aren't used, to avoid bridge being detected as broken.

 Initialize default capabilities. */

 Enable data link layer active state reporting */

 Write out the physical slot number = 0 */

 Set the completion timer timeout to the maximum 50ms. */

 Terminate list of capabilities (Next Capability Offset=0) */

 Enable MSI */

 Finish initialization - establish a PCI Express link */

 This will timeout if we don't have a link. */

 Enable INTx interrupts */

 Initialize the phy */

	/*

	 * These settings come from the R-Car Series, 2nd Generation User's

	 * Manual, section 50.3.1 (2) Initialization of the physical layer.

 The following value is for DC connection, no termination resistor */

 MSI & INTx share an interrupt - we only handle MSI here */

 Unknown MSI, just clear it */

 see if there's any more pending in this vector */

 clear the interrupt */

 Two irqs are for MSI, but they are also used for non-MSI irqs */

 disable all MSIs */

	/*

	 * Setup MSI data target using RC base address address, which

	 * is guaranteed to be in the low 32bit range on any RCar HW.

 Disable all MSI interrupts */

 Disable address decoding of the MSI interrupt, MSIFE */

 Cache static copy for L1 link state fixup hook on aarch32 */

		/*

		 * If the size of the range is larger than the alignment of

		 * the start address, we have to use multiple entries to

		 * perform the mapping.

 Hardware supports max 4GiB inbound region */

 Failure to get a link might just be that no cards are inserted */

 Failure to get a link might just be that no cards are inserted */

 Enable MSI */

 Re-establish the PCIe link */

	/*

	 * Test if the PCIe controller received PM_ENTER_L1 DLLP and

	 * the PCIe controller is not in L1 link state. If true, apply

	 * fix, which will put the controller into L1 link state, from

	 * which it can return to L0s/L0 on its own.

 SPDX-License-Identifier: GPL-2.0

/*

 * Support for Faraday Technology FTPC100 PCI Controller

 *

 * Copyright (C) 2017 Linus Walleij <linus.walleij@linaro.org>

 *

 * Based on the out-of-tree OpenWRT patch for Cortina Gemini:

 * Copyright (C) 2009 Janos Laube <janos.dev@gmail.com>

 * Copyright (C) 2009 Paulius Zaleckas <paulius.zaleckas@teltonika.lt>

 * Based on SL2312 PCI controller code

 * Storlink (C) 2003

/*

 * Special configuration registers directly in the first few words

 * in I/O space.

 AHB protection */

 PCI control signal */

 Soft reset counter and response error enable */

 PCI configuration command register */

 Status and command */

 Power management control */

 Power management status */

 Control register 1 */

 Control register 2 */

 Memory base and size #1 */

 Memory base and size #2 */

 Memory base and size #3 */

 Bits 31..28 gives INTD..INTA status */

 Bits 25..22 masks INTD..INTA */

 Bit 15 reserved */

 Bits 7..4 reserved */

 Bits 3..0 TRDYW */

/*

 * Memory configs:

 * Bit 31..20 defines the PCI side memory base

 * Bit 19..16 (4 bits) defines the size per below

/*

 * The DMA base is set to 0x0 for all memory segments, it reflects the

 * fact that the memory of the host system starts at 0x0.

 Defines for PCI configuration command register */

/**

 * struct faraday_pci_variant - encodes IP block differences

 * @cascaded_irq: this host has cascaded IRQs from an interrupt controller

 *	embedded in the host bridge.

 This is probably not good */

 Translate to bridge side address space */

 All PCI IRQs cascade off this one */

 Retrieve and enable optional clocks */

 setup I/O space size */

 Setup hostbridge */

 Mask and clear all interrupts */

 Check bus clock if we can gear up to 66 MHz */

 Bumping the clock may fail so read back the rate */

/*

 * We encode bridge variants here, we have at least two so it doesn't

 * hurt to have infrastructure to encompass future variants as well.

 SPDX-License-Identifier: GPL-2.0

/*

 * MediaTek PCIe host controller driver.

 *

 * Copyright (c) 2017 MediaTek Inc.

 * Author: Ryder Lee <ryder.lee@mediatek.com>

 *	   Honghui Zhang <honghui.zhang@mediatek.com>

 PCIe shared registers */

 PCIe per port registers */

 MediaTek specific configuration registers */

 PCIe V2 share registers */

 PCIe V2 per-port registers */

/*

 * Define PCIe to AHB window size as 2^33 to support max 8GB address space

 * translate, support least 4GB DRAM size access from EP DMA(physical DRAM

 * start from 0x40000000).

 PCIe V2 configuration transaction header */

/**

 * struct mtk_pcie_soc - differentiate between host generations

 * @need_fix_class_id: whether this host's class ID needed to be fixed or not

 * @need_fix_device_id: whether this host's device ID needed to be fixed or not

 * @no_msi: Bridge has no MSI support, and relies on an external block

 * @device_id: device ID which this host need to be fixed

 * @ops: pointer to configuration access functions

 * @startup: pointer to controller setting functions

 * @setup_irq: pointer to initialize IRQ functions

/**

 * struct mtk_pcie_port - PCIe port information

 * @base: IO mapped register base

 * @list: port list

 * @pcie: pointer to PCIe host info

 * @reset: pointer to port reset control

 * @sys_ck: pointer to transaction/data link layer clock

 * @ahb_ck: pointer to AHB slave interface operating clock for CSR access

 *          and RC initiated MMIO access

 * @axi_ck: pointer to application layer MMIO channel operating clock

 * @aux_ck: pointer to pe2_mac_bridge and pe2_mac_core operating clock

 *          when pcie_mac_ck/pcie_pipe_ck is turned off

 * @obff_ck: pointer to OBFF functional block operating clock

 * @pipe_ck: pointer to LTSSM and PHY/MAC layer operating clock

 * @phy: pointer to PHY control block

 * @slot: port slot

 * @irq: GIC irq

 * @irq_domain: legacy INTx IRQ domain

 * @inner_domain: inner IRQ domain

 * @msi_domain: MSI IRQ domain

 * @lock: protect the msi_irq_in_use bitmap

 * @msi_irq_in_use: bit map for assigned MSI IRQ

/**

 * struct mtk_pcie - PCIe host information

 * @dev: pointer to PCIe device

 * @base: IO mapped register base

 * @cfg: IO mapped register map for PCIe config

 * @free_ck: free-run reference clock

 * @mem: non-prefetchable memory resource

 * @ports: pointer to PCIe port information

 * @soc: pointer to SoC-dependent operations

 Write PCIe configuration transaction header for Cfgrd */

 Trigger h/w to transmit Cfgrd TLP */

 Check completion status */

 Read cpld payload of Cfgrd */

 Write PCIe configuration transaction header for Cfgwr */

 Write Cfgwr data */

 Trigger h/w to transmit Cfgwr TLP */

 Check completion status */

	/*

	 * Walk the bus hierarchy to get the devfn value

	 * of the port in the root bus.

 MT2712/MT7622 only support 32-bit MSI addresses */

 Setup INTx */

 Clear the INTx */

 Clear MSI interrupt status */

 MT7622 platforms need to enable LTSSM and ASPM from PCIe subsys */

 Assert all reset signals */

	/*

	 * Enable PCIe link down reset, if link status changed from link up to

	 * link down, this will reset MAC control registers and configuration

	 * space.

 De-assert PHY, PE, PIPE, MAC and configuration reset	*/

 Set up vendor ID and class code */

 100ms timeout value should be enough for Gen1/2 training */

 Set INTx mask */

 Set AHB to PCIe translation windows */

 Set PCIe to AXI translation memory space.*/

 assert port PERST_N */

 de-assert port PERST_N */

 100ms timeout value should be enough for Gen1/2 training */

 enable interrupt */

 map to all DDR region. We need to set it before cfg operation. */

 configure class code and revision ID */

 configure FC credit */

 configure RC FTS number to 250 when it leaves L0s */

 sys_ck might be divided into the following parts in some chips */

 some platforms may use default PHY setting */

 get shared registers, which are optional */

 enable top level clock */

 enable each port, and then check link status */

 power down PCIe subsys if slots are all empty (link down) */

 In case of EP was removed while system suspend. */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Rockchip AXI PCIe endpoint controller driver

 *

 * Copyright (c) 2018 Rockchip, Inc.

 *

 * Author: Shawn Lin <shawn.lin@rock-chips.com>

 *         Simon Xue <xxm@rock-chips.com>

/**

 * struct rockchip_pcie_ep - private data for PCIe endpoint controller driver

 * @rockchip: Rockchip PCIe controller

 * @epc: PCI EPC device

 * @max_regions: maximum number of regions supported by hardware

 * @ob_region_map: bitmask of mapped outbound regions

 * @ob_addr: base addresses in the AXI bus where the outbound regions start

 * @irq_phys_addr: base address on the AXI bus where the MSI/legacy IRQ

 *		   dedicated outbound regions is mapped.

 * @irq_cpu_addr: base address in the CPU space where a write access triggers

 *		  the sending of a memory write (MSI) / normal message (legacy

 *		  IRQ) TLP through the PCIe bus.

 * @irq_pci_addr: used to save the current mapping of the MSI/legacy IRQ

 *		  dedicated outbound region.

 * @irq_pci_fn: the latest PCI function that has updated the mapping of

 *		the MSI/legacy IRQ dedicated outbound region.

 * @irq_pending: bitmask of asserted legacy IRQs.

 The minimal region size is 1MB */

 PCI bus address region */

 CPU bus address region */

 All functions share the same vendor ID with function 0 */

 BAR size is 2^(aperture + 7) */

	/*

	 * roundup_pow_of_two() returns an unsigned long, which is not suited

	 * for 64bit values.

 128B -> 0, 256B -> 1, 512B -> 2, ... */

	/*

	 * Region 0 is reserved for configuration space and shouldn't

	 * be used elsewhere per TRM, so leave it out.

	/*

	 * Region 0 is reserved for configuration space and shouldn't

	 * be used elsewhere per TRM, so leave it out.

	/*

	 * Should add some delay between toggling INTx per TRM vaguely saying

	 * it depends on some cycles of the AHB bus clock to function it. So

	 * add sufficient 1ms here.

 Check MSI enable bit */

 Get MSI numbers from MME */

 Set MSI private data */

 Get MSI PCI address */

 Set the outbound region if needed. */

 Establish the link automatically */

 Only enable function 0 by default */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) Microsoft Corporation.

 *

 * Author:

 *   Jake Oshins <jakeo@microsoft.com>

 *

 * This driver acts as a paravirtual front-end for PCI Express root buses.

 * When a PCI Express function (either an entire device or an SR-IOV

 * Virtual Function) is being passed through to the VM, this driver exposes

 * a new bus to the guest VM.  This is modeled as a root PCI bus because

 * no bridges are being exposed to the VM.  In fact, with a "Generation 2"

 * VM within Hyper-V, there may seem to be no PCI bus at all in the VM

 * until a device as been exposed using this driver.

 *

 * Each root PCI bus has its own PCI domain, which is called "Segment" in

 * the PCI Firmware Specifications.  Thus while each device passed through

 * to the VM using this front-end will appear at "device 0", the domain will

 * be unique.  Typically, each bus will have one PCI function on it, though

 * this driver does support more than one.

 *

 * In order to map the interrupts from the device through to the guest VM,

 * this driver also implements an IRQ Domain, which handles interrupts (either

 * MSI or MSI-X) associated with the functions on the bus.  As interrupts are

 * set up, torn down, or reaffined, this driver communicates with the

 * underlying hypervisor to adjust the mappings in the I/O MMU so that each

 * interrupt will be delivered to the correct virtual processor at the right

 * vector.  This driver does not support level-triggered (line-based)

 * interrupts, and will report that the Interrupt Line register in the

 * function's configuration space is zero.

 *

 * The rest of this driver mostly maps PCI concepts onto underlying Hyper-V

 * facilities.  For instance, the configuration space of a function exposed

 * by Hyper-V is mapped into a single page of memory space, and the

 * read and write handlers for config space must be aware of this mechanism.

 * Similarly, device setup and teardown involves messages sent to and from

 * the PCI back-end driver in Hyper-V.

/*

 * Protocol versions. The low word is the minor version, the high word the

 * major version.

 Win10 */

 RS1 */

 Vibranium */

 WS2022 */

/*

 * Supported protocol versions in the order of probing - highest go

 * first.

 space for 32bit serial number as string */

/*

 * Message Types

	/*

	 * Version 1.1

 unused */

/*

 * Structures defining the virtual PCI Express protocol.

/*

 * Function numbers are 8-bits wide on Express, as interpreted through ARI,

 * which is all this driver does.  This representation is the one used in

 * Windows, which is what is expected when sending this back and forth with

 * the Hyper-V parent partition.

/*

 * Pretty much as defined in the PCI Specifications.

 vendor ID */

 device ID */

 serial number */

 vendor ID */

 device ID */

 serial number */

/**

 * struct hv_msi_desc

 * @vector:		IDT entry

 * @delivery_mode:	As defined in Intel's Programmer's

 *			Reference Manual, Volume 3, Chapter 8.

 * @vector_count:	Number of contiguous entries in the

 *			Interrupt Descriptor Table that are

 *			occupied by this Message-Signaled

 *			Interrupt. For "MSI", as first defined

 *			in PCI 2.2, this can be between 1 and

 *			32. For "MSI-X," as first defined in PCI

 *			3.0, this must be 1, as each MSI-X table

 *			entry would have its own descriptor.

 * @reserved:		Empty space

 * @cpu_mask:		All the target virtual processors.

/**

 * struct hv_msi_desc2 - 1.2 version of hv_msi_desc

 * @vector:		IDT entry

 * @delivery_mode:	As defined in Intel's Programmer's

 *			Reference Manual, Volume 3, Chapter 8.

 * @vector_count:	Number of contiguous entries in the

 *			Interrupt Descriptor Table that are

 *			occupied by this Message-Signaled

 *			Interrupt. For "MSI", as first defined

 *			in PCI 2.2, this can be between 1 and

 *			32. For "MSI-X," as first defined in PCI

 *			3.0, this must be 1, as each MSI-X table

 *			entry would have its own descriptor.

 * @processor_count:	number of bits enabled in array.

 * @processor_array:	All the target virtual processors.

/*

 * struct hv_msi_desc3 - 1.3 version of hv_msi_desc

 *	Everything is the same as in 'hv_msi_desc2' except that the size of the

 *	'vector' field is larger to support bigger vector values. For ex: LPI

 *	vectors on ARM.

/**

 * struct tran_int_desc

 * @reserved:		unused, padding

 * @vector_count:	same as in hv_msi_desc

 * @data:		This is the "data payload" value that is

 *			written by the device when it generates

 *			a message-signaled interrupt, either MSI

 *			or MSI-X.

 * @address:		This is the address to which the data

 *			payload is written on interrupt

 *			generation.

/*

 * A generic message format for virtual PCI.

 * Specific message formats are defined later in the file.

 negative values are failures */

/*

 * Specific message types supporting the PCI protocol.

/*

 * Version negotiation message. Sent from the guest to the host.

 * The guest is free to try different versions until the host

 * accepts the version.

 *

 * pci_version: The protocol version requested.

 * is_last_attempt: If TRUE, this is the last version guest will request.

 * reservedz: Reserved field, set to zero.

/*

 * Bus D0 Entry.  This is sent from the guest to the host when the virtual

 * bus (PCI Express port) is ready for action.

 negative values are failures */

 In Windows terms */

 negative values are failures */

 In Windows terms */

 not used here */

 not used here */

/*

 * Note: the VM must pass a valid block id, wslot and bytes_requested.

/*

 * Note: the VM must pass a valid block id, wslot and byte_count.

/*

 * Driver specific state.

 Protocol version negotiated with the host */

 Avoid two threads writing index page */

 Protect lists below */

 Highest slot of child device with resources allocated */

 hypercall arg, must not cross page boundary */

	/*

	 * Don't put anything here: retarget_msi_interrupt_params must be last

/*

 * Tracks "Device Relations" messages from the host, which must be both

 * processed in order and deferred so that they don't run in the context

 * of the incoming packet callback.

 vendor ID */

 device ID */

 serial number */

 List protected by pci_rescan_remove_lock */

	/*

	 * What would be observed if one wrote 0xFFFFFFFF to a BAR and then

	 * read it back, for each of the BAR offsets within config space.

/**

 * hv_pci_generic_compl() - Invoked for a completion packet

 * @context:		Set up by the sender of the packet.

 * @resp:		The response packet

 * @resp_packet_size:	Size in bytes of the packet

 *

 * This function is used to trigger an event and report status

 * for any message for which the completion packet contains a

 * status and nothing else.

/*

 * There is no good way to get notified from vmbus_onoffer_rescind(),

 * so let's use polling here, since this is not a hot path.

/**

 * devfn_to_wslot() - Convert from Linux PCI slot to Windows

 * @devfn:	The Linux representation of PCI slot

 *

 * Windows uses a slightly different representation of PCI slot.

 *

 * Return: The Windows representation

/**

 * wslot_to_devfn() - Convert from Windows PCI slot to Linux

 * @wslot:	The Windows representation of PCI slot

 *

 * Windows uses a slightly different representation of PCI slot.

 *

 * Return: The Linux representation

/*

 * PCI Configuration Space for these root PCI buses is implemented as a pair

 * of pages in memory-mapped I/O space.  Writing to the first page chooses

 * the PCI function being written or read.  Once the first page has been

 * written to, the following page maps in the entire configuration space of

 * the function.

/**

 * _hv_pcifront_read_config() - Internal PCI config read

 * @hpdev:	The PCI driver's representation of the device

 * @where:	Offset within config space

 * @size:	Size of the transfer

 * @val:	Pointer to the buffer receiving the data

	/*

	 * If the attempt is to read the IDs or the ROM BAR, simulate that.

 ROM BARs are unimplemented */

		/*

		 * Interrupt Line and Interrupt PIN are hard-wired to zero

		 * because this front-end only supports message-signaled

		 * interrupts.

 Choose the function to be read. (See comment above) */

 Make sure the function was chosen before we start reading. */

 Read from that function's config space. */

		/*

		 * Make sure the read was done before we release the spinlock

		 * allowing consecutive reads/writes.

 Choose the function to be read. (See comment above) */

 Make sure the function was chosen before we start reading. */

 Read from that function's config space. */

	/*

	 * mb() is not required here, because the spin_unlock_irqrestore()

	 * is a barrier.

/**

 * _hv_pcifront_write_config() - Internal PCI config write

 * @hpdev:	The PCI driver's representation of the device

 * @where:	Offset within config space

 * @size:	Size of the transfer

 * @val:	The data being transferred

 SSIDs and ROM BARs are read-only */

 Choose the function to be written. (See comment above) */

 Make sure the function was chosen before we start writing. */

 Write to that function's config space. */

		/*

		 * Make sure the write was done before we release the spinlock

		 * allowing consecutive reads/writes.

/**

 * hv_pcifront_read_config() - Read configuration space

 * @bus: PCI Bus structure

 * @devfn: Device/function

 * @where: Offset from base

 * @size: Byte/word/dword

 * @val: Value to be read

 *

 * Return: PCIBIOS_SUCCESSFUL on success

 *	   PCIBIOS_DEVICE_NOT_FOUND on failure

/**

 * hv_pcifront_write_config() - Write configuration space

 * @bus: PCI Bus structure

 * @devfn: Device/function

 * @where: Offset from base

 * @size: Byte/word/dword

 * @val: Value to be written to device

 *

 * Return: PCIBIOS_SUCCESSFUL on success

 *	   PCIBIOS_DEVICE_NOT_FOUND on failure

 PCIe operations */

/*

 * Paravirtual backchannel

 *

 * Hyper-V SR-IOV provides a backchannel mechanism in software for

 * communication between a VF driver and a PF driver.  These

 * "configuration blocks" are similar in concept to PCI configuration space,

 * but instead of doing reads and writes in 32-bit chunks through a very slow

 * path, packets of up to 128 bytes can be sent or received asynchronously.

 *

 * Nearly every SR-IOV device contains just such a communications channel in

 * hardware, so using this one in software is usually optional.  Using the

 * software channel, however, allows driver implementers to leverage software

 * tools that fuzz the communications channel looking for vulnerabilities.

 *

 * The usage model for these packets puts the responsibility for reading or

 * writing on the VF driver.  The VF driver sends a read or a write packet,

 * indicating which "block" is being referred to by number.

 *

 * If the PF driver wishes to initiate communication, it can "invalidate" one or

 * more of the first 64 blocks.  This invalidation is delivered via a callback

 * supplied by the VF driver by this driver.

 *

 * No protocol is implied, except that supplied by the PF and VF drivers.

/**

 * hv_pci_read_config_compl() - Invoked when a response packet

 * for a read config block operation arrives.

 * @context:		Identifies the read config operation

 * @resp:		The response packet itself

 * @resp_packet_size:	Size in bytes of the response packet

/**

 * hv_read_config_block() - Sends a read config block request to

 * the back-end driver running in the Hyper-V parent partition.

 * @pdev:		The PCI driver's representation for this device.

 * @buf:		Buffer into which the config block will be copied.

 * @len:		Size in bytes of buf.

 * @block_id:		Identifies the config block which has been requested.

 * @bytes_returned:	Size which came back from the back-end driver.

 *

 * Return: 0 on success, -errno on failure

/**

 * hv_pci_write_config_compl() - Invoked when a response packet for a write

 * config block operation arrives.

 * @context:		Identifies the write config operation

 * @resp:		The response packet itself

 * @resp_packet_size:	Size in bytes of the response packet

/**

 * hv_write_config_block() - Sends a write config block request to the

 * back-end driver running in the Hyper-V parent partition.

 * @pdev:		The PCI driver's representation for this device.

 * @buf:		Buffer from which the config block will	be copied.

 * @len:		Size in bytes of buf.

 * @block_id:		Identifies the config block which is being written.

 *

 * Return: 0 on success, -errno on failure

	/*

	 * This quirk is required on some hosts shipped around 2018, because

	 * these hosts don't check the pkt_size correctly (new hosts have been

	 * fixed since early 2019). The quirk is also safe on very old hosts

	 * and new hosts, because, on them, what really matters is the length

	 * specified in write_blk->byte_count.

/**

 * hv_register_block_invalidate() - Invoked when a config block invalidation

 * arrives from the back-end driver.

 * @pdev:		The PCI driver's representation for this device.

 * @context:		Identifies the device.

 * @block_invalidate:	Identifies all of the blocks being invalidated.

 *

 * Return: 0 on success, -errno on failure

 Interrupt management hooks */

/**

 * hv_msi_free() - Free the MSI.

 * @domain:	The interrupt domain pointer

 * @info:	Extra MSI-related context

 * @irq:	Identifies the IRQ.

 *

 * The Hyper-V parent partition and hypervisor are tracking the

 * messages that are in use, keeping the interrupt redirection

 * table up to date.  This callback sends a message that frees

 * the IRT entry and related tracking nonsense.

/**

 * hv_irq_unmask() - "Unmask" the IRQ by setting its current

 * affinity.

 * @data:	Describes the IRQ

 *

 * Build new a destination for the MSI and make a hypercall to

 * update the Interrupt Redirection Table. "Device Logical ID"

 * is built out of this PCI bus's instance GUID and the function

 * number of the device.

	/*

	 * Honoring apic->delivery_mode set to APIC_DELIVERY_MODE_FIXED by

	 * setting the HV_DEVICE_INTERRUPT_TARGET_MULTICAST flag results in a

	 * spurious interrupt storm. Not doing so does not seem to have a

	 * negative effect (yet?).

		/*

		 * PCI_PROTOCOL_VERSION_1_2 supports the VP_SET version of the

		 * HVCALL_RETARGET_INTERRUPT hypercall, which also coincides

		 * with >64 VP support.

		 * ms_hyperv.hints & HV_X64_EX_PROCESSOR_MASKS_RECOMMENDED

		 * is not sufficient for this hypercall.

		/*

		 * var-sized hypercall, var-size starts after vp_mask (thus

		 * vp_set.format does not count, but vp_set.valid_bank_mask

		 * does).

	/*

	 * During hibernation, when a CPU is offlined, the kernel tries

	 * to move the interrupt to the remaining CPUs that haven't

	 * been offlined yet. In this case, the below hv_do_hypercall()

	 * always fails since the vmbus channel has been closed:

	 * refer to cpu_disable_common() -> fixup_irqs() ->

	 * irq_migrate_all_off_this_cpu() -> migrate_one_irq().

	 *

	 * Suppress the error message for hibernation because the failure

	 * during hibernation does not matter (at this time all the devices

	 * have been frozen). Note: the correct affinity info is still updated

	 * into the irqdata data structure in migrate_one_irq() ->

	 * irq_do_set_affinity() -> hv_set_affinity(), so later when the VM

	 * resumes, hv_pci_restore_msi_state() is able to correctly restore

	 * the interrupt with the correct affinity.

	/*

	 * Create MSI w/ dummy vCPU set, overwritten by subsequent retarget in

	 * hv_irq_unmask().

/*

 * Create MSI w/ dummy vCPU set targeting just one vCPU, overwritten

 * by subsequent retarget in hv_irq_unmask().

/**

 * hv_compose_msi_msg() - Supplies a valid MSI address/data

 * @data:	Everything about this MSI

 * @msg:	Buffer that is filled in by this function

 *

 * This function unpacks the IRQ looking for target CPU set, IDT

 * vector and mode and sends a message to the parent partition

 * asking for a mapping for that tuple in this partition.  The

 * response supplies a data value and address to which that data

 * should be written to trigger that interrupt.

 Free any previous message that might have already been composed. */

		/* As we only negotiate protocol versions known to this driver,

		 * this path should never hit. However, this is it not a hot

		 * path so we print a message to aid future updates.

	/*

	 * Prevents hv_pci_onchannelcallback() from running concurrently

	 * in the tasklet.

	/*

	 * Since this function is called with IRQ locks held, can't

	 * do normal wait for completion; instead poll.

 0xFFFF means an invalid PCI VENDOR ID. */

		/*

		 * Make sure that the ring buffer data structure doesn't get

		 * freed while we dereference the ring buffer pointer.  Test

		 * for the channel's onchannel_callback being NULL within a

		 * sched_lock critical section.  See also the inline comments

		 * in vmbus_reset_channel_cb().

	/*

	 * Record the assignment so that this can be unwound later. Using

	 * irq_set_chip_data() here would be appropriate, but the lock it takes

	 * is already held.

 Pass up the result. */

 HW Interrupt Chip Descriptor */

/**

 * hv_pcie_init_irq_domain() - Initialize IRQ domain

 * @hbus:	The root PCI bus

 *

 * This function creates an IRQ domain which will be used for

 * interrupts from devices that have been passed through.  These

 * devices only support MSI and MSI-X, not line-based interrupts

 * or simulations of line-based interrupts through PCIe's

 * fabric-layer messages.  Because interrupts are remapped, we

 * can support multi-message MSI here.

 *

 * Return: '0' on success and error value on failure

/**

 * get_bar_size() - Get the address space consumed by a BAR

 * @bar_val:	Value that a BAR returned after -1 was written

 *              to it.

 *

 * This function returns the size of the BAR, rounded up to 1

 * page.  It has to be rounded up because the hypervisor's page

 * table entry that maps the BAR into the VM can't specify an

 * offset within a page.  The invariant is that the hypervisor

 * must place any BARs of smaller than page length at the

 * beginning of a page.

 *

 * Return:	Size in bytes of the consumed MMIO space.

/**

 * survey_child_resources() - Total all MMIO requirements

 * @hbus:	Root PCI bus, as understood by this driver

 If nobody is waiting on the answer, don't compute it. */

 If the answer has already been computed, go with it. */

	/*

	 * Due to an interesting quirk of the PCI spec, all memory regions

	 * for a child device are a power of 2 in size and aligned in memory,

	 * so it's sufficient to just add them up without tracking alignment.

				/*

				 * A probed BAR has all the upper bits set that

				 * can be changed.

/**

 * prepopulate_bars() - Fill in BARs with defaults

 * @hbus:	Root PCI bus, as understood by this driver

 *

 * The core PCI driver code seems much, much happier if the BARs

 * for a device have values upon first scan. So fill them in.

 * The algorithm below works down from large sizes to small,

 * attempting to pack the assignments optimally. The assumption,

 * enforced in other parts of the code, is that the beginning of

 * the memory-mapped I/O space will be aligned on the largest

 * BAR size.

	/*

	 * Clear the memory enable bit, in case it's already set. This occurs

	 * in the suspend path of hibernation, where the device is suspended,

	 * resumed and suspended again: see hibernation_snapshot() and

	 * hibernation_platform_enter().

	 *

	 * If the memory enable bit is already set, Hyper-V silently ignores

	 * the below BAR updates, and the related PCI device driver can not

	 * work, because reading from the device register(s) always returns

	 * 0xFFFFFFFF.

 Pick addresses for the BARs. */

 Set the memory enable bit. */

/*

 * Assign entries in sysfs pci slot directory.

 *

 * Note that this function does not need to lock the children list

 * because it is called from pci_devices_present_work which

 * is serialized with hv_eject_device_work because they are on the

 * same ordered workqueue. Therefore hbus->children list will not change

 * even when pci_create_slot sleeps.

/*

 * Remove entries in sysfs pci slot directory.

/*

 * Set NUMA node for the devices on the bus

/**

 * create_root_hv_pci_bus() - Expose a new root PCI bus

 * @hbus:	Root PCI bus, as understood by this driver

 *

 * Return: 0 on success, -errno on failure

/**

 * q_resource_requirements() - Query Resource Requirements

 * @context:		The completion context.

 * @resp:		The response that came from the host.

 * @resp_packet_size:	The size in bytes of resp.

 *

 * This function is invoked on completion of a Query Resource

 * Requirements packet.

/**

 * new_pcichild_device() - Create a new child device

 * @hbus:	The internal struct tracking this root PCI bus.

 * @desc:	The information supplied so far from the host

 *              about the device.

 *

 * This function creates the tracking structure for a new child

 * device and kicks off the process of figuring out what it is.

 *

 * Return: Pointer to the new tracking struct

/**

 * get_pcichild_wslot() - Find device from slot

 * @hbus:	Root PCI bus, as understood by this driver

 * @wslot:	Location on the bus

 *

 * This function looks up a PCI device and returns the internal

 * representation of it.  It acquires a reference on it, so that

 * the device won't be deleted while somebody is using it.  The

 * caller is responsible for calling put_pcichild() to release

 * this reference.

 *

 * Return:	Internal representation of a PCI device

/**

 * pci_devices_present_work() - Handle new list of child devices

 * @work:	Work struct embedded in struct hv_dr_work

 *

 * "Bus Relations" is the Windows term for "children of this

 * bus."  The terminology is preserved here for people trying to

 * debug the interaction between Hyper-V and Linux.  This

 * function is called when the parent partition reports a list

 * of functions that should be observed under this PCI Express

 * port (bus).

 *

 * This function updates the list, and must tolerate being

 * called multiple times with the same information.  The typical

 * number of child devices is one, with very atypical cases

 * involving three or four, so the algorithms used here can be

 * simple and inefficient.

 *

 * It must also treat the omission of a previously observed device as

 * notification that the device no longer exists.

 *

 * Note that this function is serialized with hv_eject_device_work(),

 * because both are pushed to the ordered workqueue hbus->wq.

 Pull this off the queue and process it if it was the last one. */

 Throw this away if the list still has stuff in it. */

 First, mark all existing children as reported missing. */

 Next, add back any reported devices. */

 Move missing children to a list on the stack. */

 Delete everything that should no longer exist. */

		/*

		 * Tell the core to rescan bus

		 * because there may have been changes.

/**

 * hv_pci_start_relations_work() - Queue work to start device discovery

 * @hbus:	Root PCI bus, as understood by this driver

 * @dr:		The list of children returned from host

 *

 * Return:  0 on success, -errno on failure

	/*

	 * If pending_dr is true, we have already queued a work,

	 * which will see the new dr. Otherwise, we need to

	 * queue a new work.

/**

 * hv_pci_devices_present() - Handle list of new children

 * @hbus:      Root PCI bus, as understood by this driver

 * @relations: Packet from host listing children

 *

 * Process a new list of devices on the bus. The list of devices is

 * discovered by VSP and sent to us via VSP message PCI_BUS_RELATIONS,

 * whenever a new list of devices for this bus appears.

/**

 * hv_pci_devices_present2() - Handle list of new children

 * @hbus:	Root PCI bus, as understood by this driver

 * @relations:	Packet from host listing children

 *

 * This function is the v2 version of hv_pci_devices_present()

/**

 * hv_eject_device_work() - Asynchronously handles ejection

 * @work:	Work struct embedded in internal device struct

 *

 * This function handles ejecting a device.  Windows will

 * attempt to gracefully eject a device, waiting 60 seconds to

 * hear back from the guest OS that this completed successfully.

 * If this timer expires, the device will be forcibly removed.

	/*

	 * Ejection can come before or after the PCI bus has been set up, so

	 * attempt to find it and tear down the bus state, if it exists.  This

	 * must be done without constructs like pci_domain_nr(hbus->bridge->bus)

	 * because hbus->bridge->bus may not exist yet.

 For the get_pcichild() in hv_pci_eject_device() */

 For the two refs got in new_pcichild_device() */

 hpdev has been freed. Do not use it any more. */

/**

 * hv_pci_eject_device() - Handles device ejection

 * @hpdev:	Internal device tracking struct

 *

 * This function is invoked when an ejection packet arrives.  It

 * just schedules work so that we don't re-enter the packet

 * delivery code handling the ejection.

/**

 * hv_pci_onchannelcallback() - Handles incoming packets

 * @context:	Internal bus tracking struct

 *

 * This function is invoked whenever the host sends a packet to

 * this channel (which is private to this root PCI bus).

 Handle large packet */

 Zero length indicates there are no more packets. */

		/*

		 * All incoming packets must be at least as large as a

		 * response.

			/*

			 * The host is trusted, and thus it's safe to interpret

			 * this transaction ID as a pointer.

/**

 * hv_pci_protocol_negotiation() - Set up protocol

 * @hdev:		VMBus's tracking struct for this root PCI bus.

 * @version:		Array of supported channel protocol versions in

 *			the order of probing - highest go first.

 * @num_version:	Number of elements in the version array.

 *

 * This driver is intended to support running on Windows 10

 * (server) and later versions. It will not run on earlier

 * versions, as they assume that many of the operations which

 * Linux needs accomplished with a spinlock held were done via

 * asynchronous messaging via VMBus.  Windows 10 increases the

 * surface area of PCI emulation so that these actions can take

 * place by suspending a virtual processor for their duration.

 *

 * This function negotiates the channel protocol version,

 * failing if the host doesn't support the necessary protocol

 * level.

	/*

	 * Initiate the handshake with the host and negotiate

	 * a version that the host can support. We start with the

	 * highest version number and go down if the host cannot

	 * support it.

/**

 * hv_pci_free_bridge_windows() - Release memory regions for the

 * bus

 * @hbus:	Root PCI bus, as understood by this driver

	/*

	 * Set the resources back to the way they looked when they

	 * were allocated by setting IORESOURCE_BUSY again.

/**

 * hv_pci_allocate_bridge_windows() - Allocate memory regions

 * for the bus

 * @hbus:	Root PCI bus, as understood by this driver

 *

 * This function calls vmbus_allocate_mmio(), which is itself a

 * bit of a compromise.  Ideally, we might change the pnp layer

 * in the kernel such that it comprehends either PCI devices

 * which are "grandchildren of ACPI," with some intermediate bus

 * node (in this case, VMBus) or change it such that it

 * understands VMBus.  The pnp layer, however, has been declared

 * deprecated, and not subject to change.

 *

 * The workaround, implemented here, is to ask VMBus to allocate

 * MMIO space for this bus.  VMBus itself knows which ranges are

 * appropriate by looking at its own ACPI objects.  Then, after

 * these ranges are claimed, they're modified to look like they

 * would have looked if the ACPI and pnp code had allocated

 * bridge windows.  These descriptors have to exist in this form

 * in order to satisfy the code which will get invoked when the

 * endpoint PCI function driver calls request_mem_region() or

 * request_mem_region_exclusive().

 *

 * Return: 0 on success, -errno on failure

 Modify this resource to become a bridge window. */

 Modify this resource to become a bridge window. */

/**

 * hv_allocate_config_window() - Find MMIO space for PCI Config

 * @hbus:	Root PCI bus, as understood by this driver

 *

 * This function claims memory-mapped I/O space for accessing

 * configuration space for the functions on this bus.

 *

 * Return: 0 on success, -errno on failure

	/*

	 * Set up a region of MMIO space to use for accessing configuration

	 * space.

	/*

	 * vmbus_allocate_mmio() gets used for allocating both device endpoint

	 * resource claims (those which cannot be overlapped) and the ranges

	 * which are valid for the children of this bus, which are intended

	 * to be overlapped by those children.  Set the flag on this claim

	 * meaning that this region can't be overlapped.

/**

 * hv_pci_enter_d0() - Bring the "bus" into the D0 power state

 * @hdev:	VMBus's tracking struct for this root PCI bus

 *

 * Return: 0 on success, -errno on failure

	/*

	 * Tell the host that the bus is ready to use, and moved into the

	 * powered-on state.  This includes telling the host which region

	 * of memory-mapped I/O space has been chosen for configuration space

	 * access.

/**

 * hv_pci_query_relations() - Ask host to send list of child

 * devices

 * @hdev:	VMBus's tracking struct for this root PCI bus

 *

 * Return: 0 on success, -errno on failure

 Ask the host to send along the list of child devices */

/**

 * hv_send_resources_allocated() - Report local resource choices

 * @hdev:	VMBus's tracking struct for this root PCI bus

 *

 * The host OS is expecting to be sent a request as a message

 * which contains all the resources that the device will use.

 * The response contains those same resources, "translated"

 * which is to say, the values which should be used by the

 * hardware, when it delivers an interrupt.  (MMIO resources are

 * used in local terms.)  This is nice for Windows, and lines up

 * with the FDO/PDO split, which doesn't exist in Linux.  Linux

 * is deeply expecting to scan an emulated PCI configuration

 * space.  So this message is sent here only to drive the state

 * machine on the host forward.

 *

 * Return: 0 on success, -errno on failure

/**

 * hv_send_resources_released() - Report local resources

 * released

 * @hdev:	VMBus's tracking struct for this root PCI bus

 *

 * Return: 0 on success, -errno on failure

/*

 * PCI domain number 0 is used by emulated devices on Gen1 VMs, so define 0

 * as invalid for passthrough PCI devices of this driver.

/**

 * hv_get_dom_num() - Get a valid PCI domain number

 * Check if the PCI domain number is in use, and return another number if

 * it is in use.

 *

 * @dom: Requested domain number

 *

 * return: domain number on success, HVPCI_DOM_INVALID on failure

/**

 * hv_put_dom_num() - Mark the PCI domain number as free

 * @dom: Domain number to be freed

/**

 * hv_pci_probe() - New VMBus channel probe, for a root PCI bus

 * @hdev:	VMBus's tracking struct for this root PCI bus

 * @dev_id:	Identifies the device itself

 *

 * Return: 0 on success, -errno on failure

	/*

	 * hv_pcibus_device contains the hypercall arguments for retargeting in

	 * hv_irq_unmask(). Those must not cross a page boundary.

	/*

	 * With the recent 59bb47985c1d ("mm, sl[aou]b: guarantee natural

	 * alignment for kmalloc(power-of-two)"), kzalloc() is able to allocate

	 * a 4KB buffer that is guaranteed to be 4KB-aligned. Here the size and

	 * alignment of hbus is important because hbus's field

	 * retarget_msi_interrupt_params must not cross a 4KB page boundary.

	 *

	 * Here we prefer kzalloc to get_zeroed_page(), because a buffer

	 * allocated by the latter is not tracked and scanned by kmemleak, and

	 * hence kmemleak reports the pointer contained in the hbus buffer

	 * (i.e. the hpdev struct, which is created in new_pcichild_device() and

	 * is tracked by hbus->children) as memory leak (false positive).

	 *

	 * If the kernel doesn't have 59bb47985c1d, get_zeroed_page() *must* be

	 * used to allocate the hbus buffer and we can avoid the kmemleak false

	 * positive by using kmemleak_alloc() and kmemleak_free() to ask

	 * kmemleak to track and scan the hbus buffer.

	/*

	 * The PCI bus "domain" is what is called "segment" in ACPI and other

	 * specs. Pull it from the instance ID, to get something usually

	 * unique. In rare cases of collision, we will find out another number

	 * not in use.

	 *

	 * Note that, since this code only runs in a Hyper-V VM, Hyper-V

	 * together with this guest driver can guarantee that (1) The only

	 * domain used by Gen1 VMs for something that looks like a physical

	 * PCI bus (which is actually emulated by the hypervisor) is domain 0.

	 * (2) There will be no overlap between domains (after fixing possible

	 * collisions) in the same VM.

	/*

	 * In certain case (Kdump) the pci device of interest was

	 * not cleanly shut down and resource is still held on host

	 * side, the host could return invalid device status.

	 * We need to explicitly request host to release the resource

	 * and try to enter D0 again.

	 * Since the hv_pci_bus_exit() call releases structures

	 * of all its child devices, we need to start the retry from

	 * hv_pci_query_relations() call, requesting host to send

	 * the synchronous child device relations message before this

	 * information is needed in hv_send_resources_allocated()

	 * call later.

		/*

		 * Hv_pci_bus_exit() calls hv_send_resources_released()

		 * to free up resources of its child devices.

		 * In the kdump kernel we need to set the

		 * wslot_res_allocated to 255 so it scans all child

		 * devices to release resources allocated in the

		 * normal kernel before panic happened.

	/*

	 * After the host sends the RESCIND_CHANNEL message, it doesn't

	 * access the per-channel ringbuffer any longer.

 Move all present children to the list on stack */

 Remove all children in the list */

 For the two refs got in new_pcichild_device() */

/**

 * hv_pci_remove() - Remove routine for this VMBus channel

 * @hdev:	VMBus's tracking struct for this root PCI bus

 *

 * Return: 0 on success, -errno on failure

		/*

		 * At this point, no work is running or can be scheduled

		 * on hbus-wq. We can't race with hv_pci_devices_present()

		 * or hv_pci_eject_device(), it's safe to proceed.

 Remove the bus from PCI's point of view. */

	/*

	 * hv_pci_suspend() must make sure there are no pending work items

	 * before calling vmbus_close(), since it runs in a process context

	 * as a callback in dpm_suspend().  When it starts to run, the channel

	 * callback hv_pci_onchannelcallback(), which runs in a tasklet

	 * context, can be still running concurrently and scheduling new work

	 * items onto hbus->wq in hv_pci_devices_present() and

	 * hv_pci_eject_device(), and the work item handlers can access the

	 * vmbus channel, which can be being closed by hv_pci_suspend(), e.g.

	 * the work item handler pci_devices_present_work() ->

	 * new_pcichild_device() writes to the vmbus channel.

	 *

	 * To eliminate the race, hv_pci_suspend() disables the channel

	 * callback tasklet, sets hbus->state to hv_pcibus_removing, and

	 * re-enables the tasklet. This way, when hv_pci_suspend() proceeds,

	 * it knows that no new work item can be scheduled, and then it flushes

	 * hbus->wq and safely closes the vmbus channel.

 Change the hbus state to prevent new work items. */

/*

 * Upon resume, pci_restore_msi_state() -> ... ->  __pci_write_msi_msg()

 * directly writes the MSI/MSI-X registers via MMIO, but since Hyper-V

 * doesn't trap and emulate the MMIO accesses, here hv_compose_msi_msg()

 * must be used to ask Hyper-V to re-create the IOMMU Interrupt Remapping

 * Table entries.

 Only use the version that was in use before hibernation. */

 PCI Pass-through Class ID */

 44C4F61D-4444-4400-9D52-802E27EDE19F */

 Set the invalid domain number's bit, so it will not be used */

 Initialize PCI block r/w interface */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2015, 2016 Cavium, Inc.

 Entries are 16-byte aligned; bits[2,3] select word in entry */

 BAR 0 */

 EA entry-1. Base-L */

 BAR 0 */

 zeros in unsettable bits */

 EA entry-2. Offset-L */

 BAR 1 */

 EA entry-3. Base-H */

 EA Base[63:32] may be missing some bits ... */

	/*

	 * Bit 44 of the 64-bit Base must match the same bit in

	 * the config space access window.  Since we are working with

	 * the high-order 32 bits, shift everything down by 32 bits.

 Check for non type-00 header */

 Pass-2 handling */

	/*

	 * All BARs have fixed addresses specified by the EA

	 * capability; they must return zero on read.

 BAR or SR-IOV BAR */

 Check for non type-00 header */

 E_CAP */

 next capability is EA at 0xbc */

 next capability is EA at 0xbc */

 EA last in chain, 4 entries */

 EA last in chain, 3 entries */

 EA last in chain, 2 entries */

 EA last in chain, 1 entry */

 EA entry-0. PP=0, BAR0 Size:3 */

 EA entry-1. PP=0, BAR4 Size:3 */

 EA entry-2. PP=0, BAR2, Size:3 */

 EA entry-2. PP=4, VF_BAR0 (9), Size:3 */

 EA entry-3. PP=4, VF_BAR4 (d), Size:3 */

 next capability is EA at 0xbc */

 EA last in chain, 1 entry */

 EA last in chain, no entries */

 subordinate:secondary = 1:1 */

 subordinate:secondary = 2:2 */

 subordinate:secondary = 3:3 */

 subordinate:secondary = 4:4 */

 Enabled, not-Write, SP=ff, PP=05, BEI=6, ES=4 */

 Base-L 64-bit */

 MaxOffset-L 64-bit */

 NIC Base-H */

 MaxOffset-H */

	/*

	 * All BARs have fixed addresses; ignore BAR writes so they

	 * don't get corrupted.

 BAR or SR-IOV BAR */

 SPDX-License-Identifier: GPL-2.0+

/*

 * APM X-Gene PCIe Driver

 *

 * Copyright (c) 2014 Applied Micro Circuits Corporation.

 *

 * Author: Tanmay Inamdar <tinamdar@apm.com>.

 PCIe IP version */

/*

 * When the address bit [17:16] is 2'b01, the Configuration access will be

 * treated as Type 1 and it will be forwarded to external PCIe device.

/*

 * For Configuration request, RTDID register is used as Bus Number,

 * Device Number and Function number of the header fields.

 read the register back to ensure flush */

/*

 * X-Gene PCIe port uses BAR0-BAR1 of RC's configuration space as

 * the translation from PCI bus to native BUS.  Entire DDR region

 * is mapped into PCIe space using these registers, so it can be

 * reached by DMA from EP devices.  The BAR0/1 of bridge should be

 * hidden during enumeration to avoid the sizing and resource allocation

 * by PCIe core.

	/*

	 * The v1 controller has a bug in its Configuration Request

	 * Retry Status (CRS) logic: when CRS Software Visibility is

	 * enabled and we read the Vendor and Device ID of a non-existent

	 * device, the controller fabricates return data of 0xFFFF0001

	 * ("device exists but is not ready") instead of 0xFFFFFFFF

	 * ("device does not exist").  This causes the PCI core to retry

	 * the read until it times out.  Avoid this by not claiming to

	 * support CRS SV.

/*

 * X-Gene PCIe support maximum 3 inbound memory regions

 * This function helps to select a region based on size of region

 clear BAR configuration which was done by firmware */

 setup the vendor and device IDs correctly */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host bridge driver for Apple system-on-chips.

 *

 * The HW is ECAM compliant, so once the controller is initialized,

 * the driver mostly deals MSI mapping and handling of per-port

 * interrupts (INTx, management and error signals).

 *

 * Initialization requires enabling power and clocks, along with a

 * number of register pokes.

 *

 * Copyright (C) 2021 Alyssa Rosenzweig <alyssa@rosenzweig.io>

 * Copyright (C) 2021 Google LLC

 * Copyright (C) 2021 Corellium LLC

 * Copyright (C) 2021 Mark Kettenis <kettenis@openbsd.org>

 *

 * Author: Alyssa Rosenzweig <alyssa@rosenzweig.io>

 * Author: Marc Zyngier <maz@kernel.org>

/*

 * The doorbell address is set to 0xfffff000, which by convention

 * matches what MacOS does, and it is possible to use any other

 * address (in the bottom 4GB, as the base register is only 32bit).

 * However, it has to be excluded from the IOVA range, and the DART

 * driver has to know about it.

	/*

	 * It doesn't seem that there is any way to configure the

	 * trigger, so assume INTx have to be level (as per the spec),

	 * and the rest is edge (which looks likely).

 FIXME: consider moving each interrupt under each port */

 Disable all interrupts */

 Configure MSI base address */

 Enable MSIs, shared between all ports */

 Read back to ensure completion of the write */

 Use the first reg entry to work out the port index */

 Reset all RID/SID mappings, and check for RAZ/WI registers */

 Find the root port this device is on */

 If finding the port itself, nothing to do */

	/*

	 * This is a bit ugly. We assume that if we get notified for

	 * any PCI device, we must be in charge of it, and that there

	 * is no other PCI controller in the whole system. It probably

	 * holds for now, but who knows for how long?

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe endpoint driver for Renesas R-Car SoCs

 *  Copyright (c) 2020 Renesas Electronics Europe GmbH

 *

 * Author: Lad Prabhakar <prabhakar.mahadev-lad.rj@bp.renesas.com>

 Structure representing the PCIe interface */

 Set endpoint mode */

 Initialize default capabilities. */

 Write out the physical slot number = 0 */

 device supports fixed 128 bytes MPSS */

 read requests size 128 bytes */

 payload size 128 bytes */

 Set target link speed to 5.0 GT/s */

 Set the completion timer timeout to the maximum 50ms. */

 Terminate list of capabilities (Next Capability Offset=0) */

 flush modifications */

		/* controller doesn't support multiple allocation

		 * from same window, so set page_size to window size

 use 64-bit BARs */

 check if we have a link. */

 Check MSI enable bit */

 Get MSI numbers from MME */

 use 64-bit BARs so mark BAR[1,3,5] as reserved */

 SPDX-License-Identifier: GPL-2.0+

 Copyright (C) 2009 - 2019 Broadcom */

 BRCM_PCIE_CAP_REGS - Offset for the mandatory capability config regs */

 Broadcom STB PCIe Register Offsets */

 Offsets from PCIE_INTR2_CPU_BASE and PCIE_MSI_INTR2_BASE */

 PCIe parameters */

 MSI target addresses */

 MDIO registers */

 Rescal registers */

 Forward declarations */

 guards the alloc/free operations */

 used indicates which MSI interrupts have been alloc'd */

 Some chips have MSIs in bits [31..24] of a shared register. */

 No. of MSI available, depends on chip */

 This is the base pointer for interrupt status/set/clr regs */

 Internal PCIe Host Controller Information.*/

/*

 * This is to convert the size of the inbound "BAR" region to the

 * non-linear values of PCIE_X_MISC_RC_BAR[123]_CONFIG_LO.SIZE

 Covers 4KB to 32KB (inclusive) */

 Covers 64KB to 32GB, (inclusive) */

 Something is awry so disable */

 negative return value indicates error */

 negative return value indicates error */

/*

 * Configures device for Spread Spectrum Clocking (SSC) mode; a negative

 * return value indicates error.

 Limits operation to a specific generation (1, 2, or 3) */

 Set the base of the pcie_addr window */

 Write the addr base & limit lower bits (in MBs) */

 Write the cpu & limit addr upper bits */

 Multi MSI is supported by the controller, but not by this driver */

	/*

	 * The 0 bit of PCIE_MISC_MSI_BAR_CONFIG_LO is repurposed to MSI

	 * enable, which we set to 1.

 The controller is capable of serving in both RC and EP roles */

 Accesses to the RC go right to the RC registers if slot==0 */

 For devices, write to the config space index register */

 Perst bit has moved and assert value is 0 */

 Make an educated guess */

 Each memc is viewed through a "port" that is a power of 2 */

 System memory starts at this address in PCIe-space */

 The sum of all memc views must also be a power of 2 */

	/*

	 * We validate the inbound memory view even though we should trust

	 * whatever the device-tree provides. This is because of an HW issue on

	 * early Raspberry Pi 4's revisions (bcm2711). It turns out its

	 * firmware has to dynamically edit dma-ranges due to a bug on the

	 * PCIe controller integration, which prohibits any access above the

	 * lower 3GB of memory. Given this, we decided to keep the dma-ranges

	 * in check, avoiding hard to debug device-tree related issues in the

	 * future:

	 *

	 * The PCIe host controller by design must set the inbound viewport to

	 * be a contiguous arrangement of all of the system's memory.  In

	 * addition, its size mut be a power of two.  To further complicate

	 * matters, the viewport must start on a pcie-address that is aligned

	 * on a multiple of its size.  If a portion of the viewport does not

	 * represent system memory -- e.g. 3GB of memory requires a 4GB

	 * viewport -- we can map the outbound memory in or after 3GB and even

	 * though the viewport will overlap the outbound memory the controller

	 * will know to send outbound memory downstream and everything else

	 * upstream.

	 *

	 * For example:

	 *

	 * - The best-case scenario, memory up to 3GB, is to place the inbound

	 *   region in the first 4GB of pcie-space, as some legacy devices can

	 *   only address 32bits. We would also like to put the MSI under 4GB

	 *   as well, since some devices require a 32bit MSI target address.

	 *

	 * - If the system memory is 4GB or larger we cannot start the inbound

	 *   region at location 0 (since we have to allow some space for

	 *   outbound memory @ 3GB). So instead it will  start at the 1x

	 *   multiple of its size

 Reset the bridge */

 Take the bridge out of reset */

 Wait for SerDes to be stable */

	/*

	 * SCB_MAX_BURST_SIZE is a two bit field.  For GENERIC chips it

	 * is encoded as 0=128, 1=256, 2=512, 3=Rsvd, for BCM7278 it

	 * is encoded as 0=Rsvd, 1=128, 2=256, 3=512.

 128B */

 512 bytes */

 512 bytes */

 Set SCB_MAX_BURST_SIZE, CFG_READ_UR_MODE, SCB_ACCESS_EN */

	/*

	 * We ideally want the MSI target address to be located in the 32bit

	 * addressable memory area. Some devices might depend on it. This is

	 * possible either when the inbound window is located above the lower

	 * 4GB or when the inbound area is smaller than 4GB (taking into

	 * account the rounding-up we're forced to perform).

 disable the PCIe->GISB memory window (RC_BAR1) */

 disable the PCIe->SCB memory window (RC_BAR3) */

 Unassert the fundamental reset */

	/*

	 * Give the RC/EP time to wake up, before trying to configure RC.

	 * Intermittently check status for link-up, up to a total of 100ms.

 Don't advertise L0s capability if 'aspm-no-l0s' */

	/*

	 * For config space accesses on the RC, show the right class for

	 * a PCIe-PCIe bridge (the default setting is to be EP mode).

 PCIe->SCB endian mode for BAR */

	/*

	 * Refclk from RC should be gated with CLKREQ# input when ASPM L0s,L1

	 * is enabled => setting the CLKREQ_DEBUG_ENABLE field to 1.

 L23 is a low-power PCIe link state */

 Assert request for L23 */

 Wait up to 36 msec for L23 */

 Assert fundamental reset */

 Deassert request for L23 in case it was asserted */

 Turn off SerDes */

 Shutdown PCIe bridge */

 Take bridge out of reset so we can access the SERDES reg */

 SERDES_IDDQ = 0 */

 wait for serdes to be stable */

 SPDX-License-Identifier: GPL-2.0

/*

 * Altera PCIe MSI support

 *

 * Author: Ley Foon Tan <lftan@altera.com>

 *

 * Copyright Altera Corporation (C) 2013-2015. All rights reserved

 protect "used" bitmap */

 Dummy read from vector to clear the interrupt */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe driver for Marvell Armada 370 and Armada XP SoCs

 *

 * Author: Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

/*

 * PCIe unit register offsets.

 Structure representing all PCIe interfaces */

 Structure representing one PCIe interface */

/*

 * Setup PCIE BARs and Address Decode Wins:

 * BAR[0] -> internal registers (needed for MSI)

 * BAR[1] -> covers all DRAM banks

 * BAR[2] -> Disabled

 * WIN[0-3] -> DRAM bank[0-3]

 First, disable and clear BARs and windows. */

 Setup windows for DDR banks.  Count total DDR size on the fly. */

 Round up 'size' to the nearest power of two. */

 Setup BAR[1] to all DRAM banks. */

	/*

	 * Point BAR[0] to the device's internal registers.

 Point PCIe unit MBUS decode windows to DRAM space. */

 Master + slave enable. */

 Enable interrupt lines A-D. */

/*

 * Remove windows, starting from the largest ones to the smallest

 * ones.

/*

 * MBus windows can only have a power of two size, but PCI BARs do not

 * have this constraint. Therefore, we have to split the PCI BAR into

 * areas each having a power of two size. We start from the largest

 * one (i.e highest order bit set in the size).

		/*

		 * If something tries to change the window while it is enabled

		 * the change will not be done atomically. That would be

		 * difficult to do in the general case.

 Are the new iobase/iolimit values invalid? */

	/*

	 * We read the PCI-to-PCI bridge emulated registers, and

	 * calculate the base address and size of the address decoding

	 * window to setup, according to the PCI-to-PCI bridge

	 * specifications. iobase is the bus address, port->iowin_base

	 * is the CPU address.

 Are the new membase/memlimit values invalid? */

	/*

	 * We read the PCI-to-PCI bridge emulated registers, and

	 * calculate the base address and size of the address decoding

	 * window to setup, according to the PCI-to-PCI bridge

	 * specifications.

		/*

		 * PCIe requires the clock power management capability to be

		 * hard-wired to zero for downstream ports

		/*

		 * We keep bit 1 set, it is a read-only bit that

		 * indicates we support 32 bits addressing for the

		 * I/O

		/*

		 * Armada370 data says these bits must always

		 * be zero when in root complex mode.

		/*

		 * If we don't support CLKREQ, we must ensure that the

		 * CLKREQ enable bit always reads zero.  Since we haven't

		 * had this capability, and it's dependent on board wiring,

		 * disable it for the time being.

/*

 * Initialize the configuration space of the PCI-to-PCI bridge

 * associated with the given PCIe interface.

 We support 32 bits I/O addressing */

 PCI configuration space write function */

 Access the emulated PCI-to-PCI bridge */

 Access the real PCIe interface */

 PCI configuration space read function */

 Access the emulated PCI-to-PCI bridge */

 Access the real PCIe interface */

	/*

	 * On the PCI-to-PCI bridge side, the I/O windows must have at

	 * least a 64 KB size and the memory windows must have at

	 * least a 1 MB size. Moreover, MBus windows need to have a

	 * base address aligned on their size, and their size must be

	 * a power of two. This means that if the BAR doesn't have a

	 * power of two size, several MBus windows will actually be

	 * created. We need to ensure that the biggest MBus window

	 * (which will be the first one) is aligned on its size, which

	 * explains the rounddown_pow_of_two() being done here.

 In the case of skipping, we need to free these */

/*

 * Power up a PCIe port.  PCIe requires the refclk to be stable for 100µs

 * prior to releasing PERST.  See table 2-4 in section 2.6.2 AC Specifications

 * of the PCI Express Card Electromechanical Specification, 1.1.

/*

 * Power down a PCIe port.  Strictly, PCIe requires us to place the card

 * in D3hot state before asserting PERST#.

/*

 * devm_of_pci_get_host_bridge_resources() only sets up translateable resources,

 * so we need extra resource setup parsing our special DT properties encoding

 * the MEM and IO apertures.

 Get the PCIe memory aperture */

 Get the PCIe IO aperture */

/*

 * This is a copy of pci_host_probe(), except that it does the I/O

 * remap as the last step, once we are sure we won't fail.

 *

 * It should be removed once the I/O remap error handling issue has

 * been sorted out.

	/*

	 * We insert PCI resources into the iomem_resource and

	 * ioport_resource trees in either pci_bus_claim_resources()

	 * or pci_bus_assign_resources().

 driver unloading/unbinding currently not supported */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCIe host controller driver for Tegra SoCs

 *

 * Copyright (c) 2010, CompuLab, Ltd.

 * Author: Mike Rapoport <mike@compulab.co.il>

 *

 * Based on NVIDIA PCIe driver

 * Copyright (c) 2008-2009, NVIDIA Corporation.

 *

 * Bits taken from arch/arm/mach-dove/pcie.c

 *

 * Author: Thierry Reding <treding@nvidia.com>

 register definitions */

/*

 * Fields in PADS_REFCLK_CFG*. Those registers form an array of 16-bit

 * entries, one entry per PCIe port. These field definitions and desired

 * values aren't in the TRM, but do come from NVIDIA.

 6:2 */

 11:8 */

 15:12 */

 in usec */

 used to differentiate between Tegra SoC generations */

/*

 * The configuration space mapping on Tegra is somewhat similar to the ECAM

 * defined by PCIe. However it deviates a bit in how the 4 bits for extended

 * register accesses are mapped:

 *

 *    [27:24] extended register number

 *    [23:16] bus number

 *    [15:11] device number

 *    [10: 8] function number

 *    [ 7: 0] register number

 *

 * Mapping the whole extended configuration space would require 256 MiB of

 * virtual address space, only a small part of which will actually be used.

 *

 * To work around this, a 4 KiB region is used to generate the required

 * configuration transaction with relevant B:D:F and register offset values.

 * This is achieved by dynamically programming base address and size of

 * AFI_AXI_BAR used for end point config space mapping to make sure that the

 * address (access to which generates correct config transaction) falls in

 * this 4 KiB region.

 move 4 KiB window to offset within the FPCI region */

 move to correct offset within the 4 KiB page */

 pulse reset signal */

 Enable AER capability */

 Optimal settings to enhance bandwidth */

	/*

	 * LTSSM will wait for DLLP to finish before entering L1 or L2,

	 * to avoid truncation of PM messages which results in receiver errors

	/*

	 * Sometimes link speed change from Gen2 to Gen1 fails due to

	 * instability in deskew logic on lane-0. Increase the deskew

	 * retry time to resolve this issue.

	/*

	 * PCIe link doesn't come up with few legacy PCIe endpoints if

	 * root port advertises both Gen-1 and Gen-2 speeds in Tegra.

	 * Hence, the strategy followed here is to initially advertise

	 * only Gen-1 and after link is up, retrain link to Gen-2 speed

 enable reference clock */

 assert port reset */

 disable reference clock */

 disable PCIe port and set CLKREQ# as GPIO to allow PLLE power down */

 Tegra PCIE root complex wrongly reports device class */

 Tegra20 and Tegra30 PCIE requires relaxed ordering */

	/*

	 * do not pollute kernel log with master abort reports since they

	 * happen a lot during enumeration

/*

 * FPCI map is as follows:

 * - 0xfdfc000000: I/O space

 * - 0xfdfe000000: type 0 configuration space

 * - 0xfdff000000: type 1 configuration space

 * - 0xfe00000000: type 0 extended configuration space

 * - 0xfe10000000: type 1 extended configuration space

 Bar 0: type 1 extended configuration space */

 Bar 1: downstream IO bar */

 Bar 2: prefetchable memory BAR */

 Bar 3: non prefetchable memory BAR */

 NULL out the remaining BARs as they are not used */

 map all upstream transactions as uncached */

 MSI translations are setup only when needed */

 initialize internal PHY, enable up to 16 PCIE lanes */

 override IDDQ to 1 on all 4 lanes */

	/*

	 * Set up PHY PLL inputs select PLLE output as refclock,

	 * set TX ref sel to div10 (not div5).

 reset PLL */

 take PLL out of reset  */

 wait for the PLL to lock */

 turn off IDDQ override */

 enable TX/RX data */

 disable TX/RX data */

 override IDDQ */

 reset PLL */

 enable PLL power down */

 power down PCIe slot clock bias pad */

 configure mode and disable all ports */

 Disable AFI dynamic clock gating and enable PCIe */

 don't enable MSI for now, only when needed */

 disable all exceptions */

 enable regulators */

 Configure the reference clock driver */

 request configuration space, but remap later, on demand */

 constrain configuration space to 4 KiB */

 request interrupt */

				/*

				 * that's weird who triggered this?

				 * just clear it

 see if there's any more pending in this vector */

 clear the interrupt */

	/* Though the PCIe controller can address >32-bit address space, to

	 * facilitate endpoints that support only 32-bit MSI target address,

	 * the mask is set to 32-bit to make sure that MSI target address is

	 * always a 32-bit address

 this register is in 4K increments */

 Restore the MSI allocation state */

 and unmask the MSI interrupt */

 mask the MSI interrupt */

/*

 * Check whether a given set of supplies is available in a device tree node.

 * This is used to check whether the new or the legacy device tree bindings

 * should be used.

/*

 * Old versions of the device tree binding for this device used a set of power

 * supplies that didn't match the hardware inputs. This happened to work for a

 * number of cases but is not future proof. However to preserve backwards-

 * compatibility with old device trees, this function will try to use the old

 * set of supplies.

/*

 * Obtains the list of regulators required for a particular generation of the

 * IP block.

 *

 * This would've been nice to do simply by providing static tables for use

 * with the regulator_bulk_*() API, but unfortunately Tegra30 is a bit quirky

 * in that it has two pairs or AVDD_PEX and VDD_PEX supplies (PEXA and PEXB)

 * and either seems to be optional depending on which ports are being used.

 VDD_PEXA and AVDD_PEXA supply lanes 0 to 3 */

 VDD_PEXB and AVDD_PEXB supply lanes 4 to 5 */

	/*

	 * If not all regulators are available for this new scheme, assume

	 * that the device tree complies with an older version of the device

	 * tree binding.

 parse root ports */

		/*

		 * Returns -ENOENT if reset-gpios property is not populated

		 * and in this case fall back to using AFI per port register

		 * to toggle PERST# SFIO line.

/*

 * FIXME: If there are no PCIe cards attached, then calling this function

 * can result in the increase of the bootup time as there are big timeout

 * loops.

 up to 1.2 seconds */

 override presence detection */

		/*

		 * "Supported Link Speeds Vector" in "Link Capabilities 2"

		 * is not supported by Tegra. tegra_pcie_change_link_speed()

		 * is called only for Tegra chips which support Gen2.

		 * So there no harm if supported link speed is not verified.

		/*

		 * Poll until link comes back from recovery to avoid race

		 * condition.

 Retrain the link */

 Start LTSSM from Tegra side */

 FC threshold is bit[25:18] */

	/*

	 * AFI_INTR is unmasked in tegra_pcie_enable_controller(), mask it to

	 * avoid unwanted interrupts raised by AFI after pex_rst is asserted.

 SPDX-License-Identifier: GPL-2.0

/*

 * Qualcomm PCIe root complex driver

 *

 * Copyright (c) 2014-2015, The Linux Foundation. All rights reserved.

 * Copyright 2015 Linaro Limited.

 *

 * Author: Stanimir Varbanov <svarbanov@mm-sol.com>

 PARF registers */

 6 clocks typically, 7 for sm8250 */

 DT parf */

 DT elbi */

 Ensure that PERST has been asserted for at least 100 ms */

 Enable Link Training state machine */

 enable link training */

 iface, core, phy are required */

 aux, ref are optional */

 reset the PCIe interface as uboot can leave it undefined state */

 enable PCIe clocks and resets */

 set TX termination offset */

 enable external reference clock */

 USE_PAD is required only for ipq806x */

 wait for clock acquisition */

 Set the Max TLP size to 2K, instead of using default of 4K */

 change DBI base address */

 enable link training */

 enable PCIe clocks and resets */

 change DBI base address */

 MAC PHY_POWERDOWN MUX DISABLE  */

 qcom,pcie-ipq4019 is defined without "iface" */

		/*

		 * These resources relates to the PHY or are secure clocks, but

		 * are controlled here for IPQ4019

 enable PCIe clocks and resets */

 change DBI base address */

 MAC PHY_POWERDOWN MUX DISABLE  */

	/*

	 * Don't have a way to see if the reset has completed.

	 * Wait for some time.

	/*

	 * Not checking for failure, will anyway return

	 * the original failure in 'ret'.

 Set TCXO as clock source for pcie_pipe_clk_src */

 configure PCIe to RC mode */

 enable PCIe clocks and resets */

 change DBI base address */

 MAC PHY_POWERDOWN MUX DISABLE  */

 Set pipe clock as clock source for pcie_pipe_clk_src */

 iommu map structure */

 Registers need to be zero out first */

 Extract the SMMU SID base from the first entry of iommu-map */

 Look for an available entry to hold the mapping */

 If the register is already populated, look for next available entry */

 If NEXT field is NULL then update it with next hash */

 BDF [31:16] | SID [15:8] | NEXT [7:0] */

 Qcom IP rev.: 2.1.0	Synopsys IP rev.: 4.01a */

 Qcom IP rev.: 1.0.0	Synopsys IP rev.: 4.11a */

 Qcom IP rev.: 2.3.2	Synopsys IP rev.: 4.21a */

 Qcom IP rev.: 2.4.0	Synopsys IP rev.: 4.20a */

 Qcom IP rev.: 2.3.3	Synopsys IP rev.: 4.30a */

 Qcom IP rev.: 2.7.0	Synopsys IP rev.: 4.30a */

 Qcom IP rev.: 1.9.0 */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Rockchip SoCs.

 *

 * Copyright (C) 2021 Rockchip Electronics Co., Ltd.

 *		http://www.rock-chips.com

 *

 * Author: Simon Xue <xxm@rock-chips.com>

/*

 * The upper 16 bits of PCIE_CLIENT_CONFIG are a write

 * mask for the lower 16 bits.

 Reset device */

	/*

	 * PCIe requires the refclk to be stable for 100µs prior to releasing

	 * PERST. See table 2-4 in section 2.6.2 AC Specifications of the PCI

	 * Express Card Electromechanical Specification, 1.1. However, we don't

	 * know if the refclk is coming from RC's PHY or external OSC. If it's

	 * from RC, so enabling LTSSM is the just right place to release #PERST.

	 * We need more extra time as before, rather than setting just

	 * 100us as we don't know how long should the device need to reset.

 LTSSM enable control mode */

 DON'T MOVE ME: must be enable before PHY init */

 SPDX-License-Identifier: GPL-2.0

/*

 * Synopsys DesignWare PCIe Endpoint controller driver

 *

 * Copyright (C) 2017 Texas Instruments

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

 Raise MSI per the PCI Local Bus Specification Revision 3.0, 6.8.1. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PCIe controller driver for Intel Keem Bay

 * Copyright (C) 2020 Intel Corporation

 PCIE_REGS_APB_SLV Registers */

	/*

	 * Ensure that PERST# is asserted for a minimum of 100ms.

	 *

	 * For more details, refer to PCI Express Card Electromechanical

	 * Specification Revision 1.1, Table-2.4.

/*

 * Initialize the internal PCIe PLL in Host mode.

 * See the following sections in Keem Bay data book,

 * (1) 6.4.6.1 PCIe Subsystem Example Initialization,

 * (2) 6.8 PCIe Low Jitter PLL for Ref Clk Generation.

	/*

	 * Keem Bay PCIe Controller provides an additional IP logic on top of

	 * standard DWC IP to clear MSI IRQ by writing '1' to the respective

	 * bit of the status register.

	 *

	 * So, a chained irq handler is defined to handle this additional

	 * IP logic.

 Legacy interrupts are not supported in Keem Bay */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCIe host controller driver for Tegra194 SoC

 *

 * Copyright (C) 2019 NVIDIA Corporation.

 *

 * Author: Vidya Sagar <vidyas@nvidia.com>

 50ms */

 Endpoint mode specific */

	/*

	 * NOTE:- Since this scenario is uncommon and link as such is not

	 * stable anyway, not waiting to confirm if link is really

	 * transitioning to Gen-2 speed

 SBR & Surprise Link Down WAR */

 If EP doesn't advertise L1SS, just return */

 Check if BME is set to '1' */

 110us for both snoop and no-snoop */

 Send LTR upstream */

	/*

	 * This is an endpoint mode specific register happen to appear even

	 * when controller is operating in root port mode and system hangs

	 * when it is accessed with link being in ASPM-L1 state.

	 * So skip accessing it altogether

	/*

	 * This is an endpoint mode specific register happen to appear even

	 * when controller is operating in root port mode and system hangs

	 * when it is accessed with link being in ASPM-L1 state.

	 * So skip accessing it altogether

 Clear all counters */

 Re-enable counting */

 Enable ASPM counters */

 Program T_cmrt and T_pwr_on values */

 Program L0s and L1 entrance latencies */

 Enable legacy interrupt generation */

 Enable MSI interrupt generation */

 Clear interrupt statuses before enabling interrupts */

 Program init preset */

 Enable as 0xFFFF0001 response for CRS */

 Configure Max lane width from DT */

 Disable ASPM-L1SS advertisement if there is no CLKREQ routing */

 Assert RST */

 Enable LTSSM */

 De-assert RST */

		/*

		 * There are some endpoints which can't get the link up if

		 * root port has Data Link Feature (DLF) enabled.

		 * Refer Spec rev 4.0 ver 1.0 sec 3.4.2 & 7.7.4 for more info

		 * on Scaled Flow Control and DLF.

		 * So, need to confirm that is indeed the case here and attempt

		 * link up once again with DLF disabled.

 Link is down for all good reasons */

 Disable LTSSM */

 Endpoint mode specific DT entries */

 Controller-5 doesn't need to have its state set by BPMP-FW */

	/*

	 * link doesn't go into L2 state with some of the endpoints with Tegra

	 * if they are not in D0 state. So, need to make sure that immediate

	 * downstream devices are in D0 state before sending PME_TurnOff to put

	 * link into L2 state.

	 * This is as per PCI Express Base r4.0 v1.0 September 27-2017,

	 * 5.2 Link State Power Management (Page #428).

 Bring downstream devices to D0 if they are not already in */

	/*

	 * According to PCI Express Card Electromechanical Specification

	 * Revision 1.1, Table-2.4, T_PVPERL (Power stable to PERST# inactive)

	 * should be a minimum of 100ms.

 Enable HW_HOT_RST mode */

 Update CFG base address */

 Configure this core for RP mode operation */

 Update iATU_DMA base address */

	/*

	 * PCIe controller exits from L2 only if reset is applied, so

	 * controller doesn't handle interrupts. But in cases where

	 * L2 entry fails, PERST# is asserted which can trigger surprise

	 * link down AER. However this function call happens in

	 * suspend_noirq(), so AER interrupt will not be processed.

	 * Disable all interrupts to avoid such a scenario.

		/*

		 * TX lane clock freq will reset to Gen1 only if link is in L2

		 * or detect state.

		 * So apply pex_rst to end point to force RP to go into detect

		 * state

		/*

		 * Some cards do not go to detect state even after de-asserting

		 * PERST#. So, de-assert LTSSM to bring link to detect state.

	/*

	 * DBI registers may not be accessible after this as PLL-E would be

	 * down depending on how CLKREQ is pulled by end point

 Cut REFCLK to slot */

 Disable LTSSM */

 Clear any stale interrupt statuses */

 configure this core for EP mode operation */

 Disable ASPM-L1SS advertisement if there is no CLKREQ routing */

 Enable LTSSM */

 Tegra194 supports only INTA */

 Enable HW_HOT_RST mode */

 Save MSI interrupt vector */

 Restore MSI interrupt vector */

 Disable HW_HOT_RST mode */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Marvell Armada-8K SoCs

 *

 * Armada-8K PCIe Glue Layer Source Code

 *

 * Copyright (C) 2016 Marvell Technology Group Ltd.

 *

 * Author: Yehuda Yitshak <yehuday@marvell.com>

 * Author: Shadi Ammouri <shadi@marvell.com>

 Root complex */

/*

 * AR/AW Cache defaults: Normal memory, Write-Back, Read / Write

 * allocate

 Old bindings miss the PHY handle, so just warn if there is no PHY */

 Start LTSSM */

 Disable LTSSM state machine to enable configuration */

 Set the device to root complex mode */

 Set the PCIe master AxCache attributes */

 Set the PCIe master AxDomain attributes */

 Enable INT A-D interrupts */

	/*

	 * Interrupts are directly handled by the device driver of the

	 * PCI device. However, they are also latched into the PCIe

	 * controller, so we simply discard them.

 Get the dw-pcie unit configuration/control registers base. */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Freescale Layerscape SoCs

 *

 * Copyright (C) 2014 Freescale Semiconductor.

 *

 * Author: Minghuan Lian <Minghuan.Lian@freescale.com>

 PEX1/2 Misc Ports Status Register */

 L0 state */

 PEX Internal Configuration Registers */

 Symbol Timer & Filter Mask Register1 */

 Bridge Slave Error Response Register */

 Forward error of non-posted request */

 Clear multi-function bit */

 Drop MSG TLP except for Vendor MSG */

 Forward error response of outbound non-posted requests */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe controller EP driver for Freescale Layerscape SoCs

 *

 * Copyright (C) 2018 NXP Semiconductor.

 *

 * Author: Xiaowei Bao <xiaowei.bao@nxp.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for UniPhier SoCs

 * Copyright 2018 Socionext Inc.

 * Author: Kunihiko Hayashi <hayashi.kunihiko@socionext.com>

 set RC MODE */

 use auxiliary power detection */

 assert PERST# */

 deassert PERST# */

 wait PIPE clock */

 INT for debug */

 INTx */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for HiSilicon SoCs

 *

 * Copyright (C) 2015 HiSilicon Co., Ltd. http://www.hisilicon.com

 *

 * Authors: Zhou Wang <wangzhou1@hisilicon.com>

 *          Dacai Zhu <zhudacai@hisilicon.com>

 *          Gabriele Paoloni <gabriele.paoloni@huawei.com>

 access only one slot on each root port */

 access only one slot on each root port */

	/*

	 * Retrieve RC base and size from a HISI0081 device with _UID

	 * matching our segment.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe endpoint controller driver for UniPhier SoCs

 * Copyright 2018 Socionext Inc.

 * Author: Kunihiko Hayashi <hayashi.kunihiko@socionext.com>

 Link Glue registers */

 assertion time of INTx in usec */

 set EP mode */

 clock request */

 deassert PIPE3 and AXI reset */

	/*

	 * This makes pulse signal to send INTx to the RC, so this should

	 * be cleared as soon as possible. This sequence is covered with

	 * mutex in pci_epc_raise_irq().

 assert INTx */

 deassert INTx */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0

/*

 * Synopsys DesignWare PCIe host controller driver

 *

 * Copyright (C) 2013 Samsung Electronics Co., Ltd.

 *		https://www.samsung.com

 *

 * Author: Jingoo Han <jg1.han@samsung.com>

/*

 * These interfaces resemble the pci_find_*capability() interfaces, but these

 * are for configuring host controllers, which are bridges *to* PCI devices but

 * are not PCI devices themselves.

 minimum 8 bytes per capability */

	/*

	 * If we have no capabilities, this is indicated by cap ID,

	 * cap version and next pointer all being 0.

	/*

	 * DesignWare core version 4.90A has a design issue where the 'TD'

	 * bit in the Control register-1 of the ATU outbound region acts

	 * like an override for the ECRC setting, i.e., the presence of TLP

	 * Digest (ECRC) in the outgoing TLPs is solely determined by this

	 * bit. This is contrary to the PCIe spec which says that the

	 * enablement of the ECRC is solely determined by the AER

	 * registers.

	 *

	 * Because of this, even when the ECRC is enabled through AER

	 * registers, the transactions going through ATU won't have TLP

	 * Digest as there is no way the PCI core AER code could program

	 * the TD bit which is specific to the DesignWare core.

	 *

	 * The best way to handle this scenario is to program the TD bit

	 * always. It affects only the traffic from root port to downstream

	 * devices.

	 *

	 * At this point,

	 * When ECRC is enabled in AER registers, everything works normally

	 * When ECRC is NOT enabled in AER registers, then,

	 * on Root Port:- TLP Digest (DWord size) gets appended to each packet

	 *                even through it is not required. Since downstream

	 *                TLPs are mostly for configuration accesses and BAR

	 *                accesses, they are not in critical path and won't

	 *                have much negative effect on the performance.

	 * on End Point:- TLP Digest is received for some/all the packets coming

	 *                from the root port. TLP Digest is ignored because,

	 *                as per the PCIe Spec r5.0 v1.0 section 2.2.3

	 *                "TLP Digest Rules", when an endpoint receives TLP

	 *                Digest when its ECRC check functionality is disabled

	 *                in AER registers, received TLP Digest is just ignored.

	 * Since there is no issue or error reported either side, best way to

	 * handle the scenario is to program TD bit by default.

	/*

	 * Make sure ATU enable takes effect before any subsequent config

	 * and I/O accesses.

	/*

	 * Make sure ATU enable takes effect before any subsequent config

	 * and I/O accesses.

	/*

	 * Make sure ATU enable takes effect before any subsequent config

	 * and I/O accesses.

	/*

	 * Make sure ATU enable takes effect before any subsequent config

	 * and I/O accesses.

 Check if the link is up or not */

 Use hardware capability */

 Pick a minimal default, enough for 8 in and 8 out windows */

 Configure Gen1 N_FTS */

 Configure Gen2+ N_FTS */

 Set the number of lanes */

 Set link width speed control register */

 SPDX-License-Identifier: GPL-2.0

/*

 * DWC PCIe RC driver for Toshiba Visconti ARM SoC

 *

 * Copyright (C) 2021 Toshiba Electronic Device & Storage Corporation

 * Copyright (C) 2021 TOSHIBA CORPORATION

 *

 * Nobuhiro Iwamatsu <nobuhiro1.iwamatsu@toshiba.co.jp>

 Access registers in PCIe ulreg */

 Access registers in PCIe smu */

 Access registers in PCIe mpu */

/*

 * In this SoC specification, the CPU bus outputs the offset value from

 * 0x40000000 to the PCIe bus, so 0x40000000 is subtracted from the CPU

 * bus address. This 0x40000000 is also based on io_base from DT.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for HiSilicon STB SoCs

 *

 * Copyright (C) 2016-2017 HiSilicon Co., Ltd. http://www.hisilicon.com

 *

 * Authors: Ruqiang Ju <juruqiang@hisilicon.com>

 *          Jianguo Sun <sunjianguo1@huawei.com>

 assert LTSSM enable */

 PCIe RC work mode */

 power on PCIe device if have */

		/* fall through here!

		 * if no pcie-phy found, phy init

		 * should be done under boot!

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe RC driver for Synopsys DesignWare Core

 *

 * Copyright (C) 2015-2016 Synopsys, Inc. (www.synopsys.com)

 *

 * Authors: Joao Pinto <Joao.Pinto@synopsys.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Texas Instruments Keystone SoCs

 *

 * Copyright (C) 2013-2014 Texas Instruments., Ltd.

 *		https://www.ti.com

 *

 * Author: Murali Karicheri <m-karicheri2@ti.com>

 * Implementation based on pci-exynos.c and pcie-designware.c

 Application registers */

 8MB */

 IRQ register defines */

 ECRC error */

 AM6 ECRC error */

 AXI tag lookup fatal error */

 Correctable error */

 Non-fatal error */

 Fatal error */

 System error */

 PCIE controller device IDs */

 PCI Device ID */

 Application register space */

 DT 1st resource */

 EOI the INTx interrupt */

/**

 * ks_pcie_set_dbi_mode() - Set DBI mode to access overlaid BAR mask registers

 * @ks_pcie: A pointer to the keystone_pcie structure which holds the KeyStone

 *	     PCIe host controller driver information.

 *

 * Since modification of dbi_cs2 involves different clock domain, read the

 * status back to ensure the transition is complete.

/**

 * ks_pcie_clear_dbi_mode() - Disable DBI mode

 * @ks_pcie: A pointer to the keystone_pcie structure which holds the KeyStone

 *	     PCIe host controller driver information.

 *

 * Since modification of dbi_cs2 involves different clock domain, read the

 * status back to ensure the transition is complete.

 Disable BARs for inbound access */

 Using Direct 1:1 mapping of RC <-> PCI memory space */

/**

 * ks_pcie_v3_65_add_bus() - keystone add_bus post initialization

 * @bus: A pointer to the PCI bus structure.

 *

 * This sets BAR0 to enable inbound access for MSI_IRQ register

 Configure and set up BAR0 */

 Enable BAR0 */

	 /*

	  * For BAR0, just setting bus address for inbound writes (MSI) should

	  * be sufficient.  Use physical address to avoid any conflicts.

/**

 * ks_pcie_link_up() - Check if link up

 * @pci: A pointer to the dw_pcie structure which holds the DesignWare PCIe host

 *	 controller driver information.

 Disable Link training */

 Initiate Link Training */

 look for the host bridge */

	/*

	 * Keystone PCI controller has a h/w limitation of

	 * 256 bytes maximum read request size.  It can't handle

	 * anything higher than this.  So force this limit on

	 * all downstream devices.

	/*

	 * The chained irq handler installation would have replaced normal

	 * interrupt driver handler so we need to take care of mask/unmask and

	 * ack operation.

	/*

	 * MSI0 status bit 0-3 shows vectors 0, 8, 16, 24, MSI1 status bit

	 * shows 1, 9, 17, 25 and so forth

/**

 * ks_pcie_legacy_irq_handler() - Handle legacy interrupt

 * @desc: Pointer to irq descriptor

 *

 * Traverse through pending legacy interrupts and invoke handler for each. Also

 * takes care of interrupt controller level mask/ack operation.

	/*

	 * The chained irq handler installation would have replaced normal

	 * interrupt driver handler so we need to take care of mask/unmask and

	 * ack operation.

		/*

		 * Since legacy interrupts are modeled as edge-interrupts in

		 * AM6, keep it disabled for now.

/*

 * When a PCI device does not exist during config cycles, keystone host gets a

 * bus error instead of returning 0xffffffff. This handler always returns 0

 * for this kind of faults.

	/*

	 * PCIe access errors that result into OCP errors are caught by ARM as

	 * "External aborts"

		/*

		 * "Power Sequencing and Reset Signal Timings" table in

		 * PCI EXPRESS CARD ELECTROMECHANICAL SPECIFICATION, REV. 2.0

		 * indicates PERST# should be deasserted after minimum of 100us

		 * once REFCLK is stable. The REFCLK to the connector in RC

		 * mode is selected while enabling the PHY. So deassert PERST#

		 * after 100 us.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Intel Gateway SoCs

 *

 * Copyright (c) 2019 Intel Corporation.

 PCIe Application logic Registers */

 Make initial reset last for 100us */

	/*

	 * One micro-second delay to make sure the reset pulse

	 * wide enough so that core reset is clean.

	/*

	 * Some SoC core reset also reset PHY, more delay needed

	 * to make sure the reset process is done.

 Send PME_TURN_OFF message */

 Read PMC status and wait for falling into L2 link state */

 Put endpoint device in reset state */

 Enable integrated interrupts */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Freescale i.MX6 SoCs

 *

 * Copyright (C) 2013 Kosagi

 *		https://www.kosagi.com

 *

 * Author: Sean Cross <xobs@kosagi.com>

 power domain for pcie */

 power domain for pcie phy */

 Parameters for the waiting for PCIe PHY PLL to lock on i.MX7 */

 PCIe Port Logic registers (memory-mapped) */

 PHY registers (not memory-mapped) */

 iMX7 PCIe PHY registers */

 These are probably the bits that *aren't* DCC_FB_EN */

 Read from the 16-bit PCIe PHY control registers (not memory-mapped) */

 assert Read signal */

 deassert Read signal */

 write addr */

 cap addr */

 capture data */

 deassert cap data */

 wait for ack de-assertion */

 assert wr signal */

 wait for ack */

 deassert wr signal */

 wait for ack de-assertion */

  Added for PCI abort handling */

	/*

	 * If the instruction being executed was a read,

	 * make it look like it read all-ones.

 Do nothing when in a single power domain */

 Do nothing when power domain missing */

 Force PCIe PHY reset */

 power up core phy and enable ref clock */

		/*

		 * the async reset input need ref clock to sync internally,

		 * when the ref clock comes after reset, internal synced

		 * reset time is too short, cannot meet the requirement.

		 * add one ~10us delay here.

		/*

		 * Set the over ride low and enabled

		 * make sure that REF_CLK is turned on.

 allow the clocks to stabilize */

 Some boards don't have PCIe reset GPIO. */

		/* Workaround for ERR010728, failure of PCI-e PLL VCO to

		 * oscillate, especially when cold.  This turns off "Duty-cycle

		 * Corrector" and other mysterious undocumented things.

 De-assert DCC_FB_EN */

 Assert RX_EQS and RX_EQS_SEL */

 Assert ATT_MODE */

 Nothing to do */

		/*

		 * TODO: Currently this code assumes external

		 * oscillator is being used

		/*

		 * Regarding the datasheet, the PCIE_VPH is suggested

		 * to be 1.8V. If the PCIE_VPH is supplied by 3.3V, the

		 * VREG_BYPASS should be cleared to zero.

 configure constant input signal to the pcie ctrl and phy */

		/*

		 * The default settings of the MPLL are for a 125MHz input

		 * clock, so no need to reconfigure anything in that case.

 Test if the speed change finished. */

	/*

	 * Force Gen1 operation when starting the link.  In case the link is

	 * started in Gen2 mode, there is a possibility the devices on the

	 * bus will not be detected at all.  This happens with PCIe switches.

 Start LTSSM. */

 Allow Gen2 mode after the link is up. */

		/*

		 * Start Directed Speed Change so the best possible

		 * speed both link partners support can be negotiated.

			/*

			 * On i.MX7, DIRECT_SPEED_CHANGE behaves differently

			 * from i.MX6 family when no link speed transition

			 * occurs and we go Gen1 -> yep, Gen1. The difference

			 * is that, in such case, it will not be cleared by HW

			 * which will cause the following code to report false

			 * failure.

 Make sure link training is finished as well! */

 Some variants have a turnoff reset in DT */

 Others poke directly at IOMUXC registers */

	/*

	 * Components with an upstream port must respond to

	 * PME_Turn_Off with PME_TO_Ack but we can't check.

	 *

	 * The standard recommends a 1-10ms timeout after which to

	 * proceed anyway as if acks were received.

 Find the PHY if one is defined, only imx7d uses it */

 Fetch GPIOs */

 Fetch clocks */

 Grab turnoff reset */

 Grab GPR config register range */

 Grab PCIe PHY Tx Settings */

 Limit link speed */

 bring down link, so bootloader gets clean state in case of reboot */

 Bus parent is the PCI bridge, its parent is this platform driver */

 Make sure we only quirk devices associated with this driver */

		/*

		 * Limit config length to avoid the kernel reading beyond

		 * the register set and causing an abort on i.MX 6Quad

	/*

	 * Since probe() can be deferred we need to make sure that

	 * hook_fault_code is not called after __init memory is freed

	 * by kernel and since imx6q_pcie_abort_handler() is a no-op,

	 * we can install the handler here without risking it

	 * accessing some uninitialized driver state.

 SPDX-License-Identifier: GPL-2.0

/*

 * FU740 DesignWare PCIe Controller integration

 * Copyright (C) 2019-2021 SiFive, Inc.

 * Paul Walmsley

 * Greentime Hu

 *

 * Based in part on the i.MX6 PCIe host controller shim which is:

 *

 * Copyright (C) 2013 Kosagi

 *		https://www.kosagi.com

 Assert PERST_N GPIO */

 Assert controller PERST_N */

 Deassert controller PERST_N */

 Deassert PERST_N GPIO */

	/*

	 * Ensure that PERST has been asserted for at least 100 ms.

	 * Section 2.2 of PCI Express Card Electromechanical Specification

	 * Revision 3.0

 Setup */

 Wait for wait_idle */

 Clear */

 Wait for ~wait_idle */

 Enable phy cr_para_sel interfaces */

	/*

	 * Wait 10 cr_para cycles to guarantee that the registers are ready

	 * to be edited.

 Set PHY AC termination mode */

 Enable LTSSM */

 Power on reset */

 Enable pcieauxclk */

	/*

	 * Assert hold_phy_rst (hold the controller LTSSM in reset after

	 * power_up_rst_n for register programming with cr_para)

 Deassert power_up_rst_n */

 Disable pcieauxclk */

 Clear hold_phy_rst */

 Enable pcieauxclk */

 Set RC mode */

 SiFive specific region: mgmt */

 Fetch GPIOs */

 Fetch clocks */

 Fetch reset */

 Bring down link, so bootloader gets clean state in case of reboot */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for ST Microelectronics SPEAr13xx SoCs

 *

 * SPEAr13xx PCIe Glue Layer Source Code

 *

 * Copyright (C) 2010-2014 ST Microelectronics

 * Pratyush Anand <pratyush.anand@gmail.com>

 * Mohit Kumar <mohit.kumar.dhaka@gmail.com>

 cr0 */

 cr1 */

 cr2 */

 cr3 */

 cr4 */

 cr5 */

 cr6 */

 cr7 */

 cr8 */

 cr9 */

 cr10 */

 cr11 */

 cr12 */

 cr13 */

 cr14 */

 cr15 */

 cr16 */

 cr17 */

 cr18 */

 cr19 */

 cr20 */

 CR0 ID */

 CR3 ID */

 CR6 */

 enable ltssm */

 Enable MSI interrupt */

	/*

	 * this controller support only 128 bytes read size, however its

	 * default value in capability register is 512 bytes. So force

	 * it to 128 here.

 SPDX-License-Identifier: GPL-2.0

/*

 * pcie-dra7xx - PCIe controller driver for TI DRA7xx SoCs

 *

 * Copyright (C) 2013-2014 Texas Instruments Incorporated - https://www.ti.com

 *

 * Authors: Kishon Vijay Abraham I <kishon@ti.com>

 PCIe controller wrapper DRA7XX configuration registers */

 DT ti_conf */

 DT phy-names count */

	/**

	 * Need to make sure all MSI status bits read 0 before exiting.

	 * Else, new MSI IRQs are not registered by the wrapper. Have an

	 * upperbound for the loop and exit the IRQ in case of IRQ flood

	 * to avoid locking up system in interrupt context.

 MSI IRQ is muxed */

/*

 * dra7xx_pcie_unaligned_memaccess: workaround for AM572x/AM571x Errata i870

 * @dra7xx: the dra7xx device where the workaround should be applied

 *

 * Access to the PCIe slave port that are not 32-bit aligned will result

 * in incorrect mapping to TLP Address and Byte enable fields. Therefore,

 * byte and half-word accesses are not possible to byte offset 0x1, 0x2, or

 * 0x3.

 *

 * To avoid this issue set PCIE_SS1_AXI2OCP_LEGACY_MODE_ENABLE to 1.

 Fallback to x1 lane mode */

 clear MSE */

 set MSE */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Amlogic MESON SoCs

 *

 * Copyright (c) 2018 Amlogic, inc.

 * Author: Yue Wang <yue.wang@amlogic.com>

 PCIe specific config registers */

	/*

	 * dwc supports 2^(val+7) payload size, which val is 0~5 default to 1.

	 * So if input size is not 2^order alignment or less than 2^7 or bigger

	 * than 2^12, just set to default size 2^(1+7).

	/*

	 * There is a bug in the MESON AXG PCIe controller whereby software

	 * cannot program the PCI_CLASS_DEVICE register, so we must fabricate

	 * the return value in the config accessors.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Kirin Phone SoCs

 *

 * Copyright (C) 2017 HiSilicon Electronics Co., Ltd.

 *		https://www.huawei.com

 *

 * Author: Xiaowei Song <songxiaowei@huawei.com>

 PCIe ELBI registers */

 info located in APB */

 info located in sysctrl */

/*

 * Max number of connected PCI slots at an external PCI bridge

 *

 * This is used on HiKey 970, which has a PEX 8606 bridge with 4 connected

 * lanes (lane 0 upstream, and the other three lanes, one connected to an

 * in-board Ethernet adapter and the other two connected to M.2 and mini

 * PCI slots.

 *

 * Each slot has a different clock source and uses a separate PERST# pin.

 only for PCIE_KIRIN_INTERNAL_PHY */

 DWC PERST# */

 Per-slot PERST# */

 Per-slot clkreq */

/*

 * Kirin 960 PHY. Can't be split into a PHY driver without changing the

 * DT schema.

 PHY info located in APB */

 peri_crg ctrl */

 Time for delay */

 Registers in PCIePHY */

 registers */

 Power supply for Host */

 ISO disable, PCIeCtrl, PHY assert and clk gate clear */

 registers */

 Drop power supply for Host */

/*

 * The non-PHY part starts here

 This is an optional property */

 pcie internal PERST# gpio */

 Parse OF children */

 Send PERST# to each slot */

 assert LTSSM enable */

 perst assert Endpoint */

 SPDX-License-Identifier: GPL-2.0+

/*

 * ACPI quirks for Tegra194 PCIe host controller

 *

 * Copyright (C) 2021 NVIDIA Corporation.

 *

 * Author: Vidya Sagar <vidyas@nvidia.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * Synopsys DesignWare PCIe host controller driver

 *

 * Copyright (C) 2013 Samsung Electronics Co., Ltd.

 *		https://www.samsung.com

 *

 * Author: Jingoo Han <jg1.han@samsung.com>

 MSI int handler */

 Chained MSI interrupt service routine */

 Program the msi_data */

 Get the I/O range from DT */

 Set default bus ops */

 Ignore errors, the link may come up later */

	/*

	 * Checking whether the link is up here is a last line of defense

	 * against platforms that forward errors on the system bus as

	 * SError upon PCI configuration transactions issued when the link

	 * is down. This check is racy by definition and does not stop

	 * the system from triggering an SError if the link goes down

	 * after this check is performed.

	/*

	 * Enable DBI read-only registers for writing/updating configuration.

	 * Write permission gets disabled towards the end of this function.

 Initialize IRQ Status array */

 Setup RC BARs */

 Setup interrupt pins */

 Setup bus numbers */

 Setup command register */

 Ensure all outbound windows are disabled so there are multiple matches */

	/*

	 * If the platform provides its own child bus config accesses, it means

	 * the platform uses its own address translation component rather than

	 * ATU, so we should not program the ATU here.

 Get last memory resource entry */

 Program correct class for RC */

 SPDX-License-Identifier: GPL-2.0

/*

 * Qualcomm PCIe Endpoint controller driver

 *

 * Copyright (c) 2020, The Linux Foundation. All rights reserved.

 * Author: Siddartha Mohanadoss <smohanad@codeaurora.org

 *

 * Copyright (c) 2021, Linaro Ltd.

 * Author: Manivannan Sadhasivam <manivannan.sadhasivam@linaro.org

 PARF registers */

 PARF_INT_ALL_{STATUS/CLEAR/MASK} register fields */

 PARF_BDF_TO_SID_CFG register fields */

 PARF_DEBUG_INT_EN register fields */

 PARF_DEVICE_TYPE register fields */

 PARF_PM_CTRL register fields */

 PARF_AXI_MSTR_RD_HALT_NO_WRITES register fields */

 PARF_AXI_MSTR_WR_ADDR_HALT register fields */

 PARF_Q2A_FLUSH register fields */

 PARF_SYS_CTRL register fields */

 PARF_DB_CTRL register fields */

 PARF_CFG_BITS register fields */

 ELBI registers */

 DBI registers */

 DBI register fields */

 2 ms */

/*

 * Delatch PERST_EN and PERST_SEPARATION_ENABLE with TCSR to avoid

 * device reset during host reboot and hibernation. The driver is

 * expected to handle this situation.

 Assert WAKE# to RC to indicate device is ready */

 Disable BDF to SID mapping */

 Enable debug IRQ */

 Configure PCIe to endpoint mode */

 Allow entering L1 state */

 Read halts write */

 Write after write halt */

 Q2A flush disable */

 Disable DBI Wakeup, core clock CGC and enable AUX power */

 Disable the debouncers */

 Request to exit from L1SS for MSI and LTR MSG */

 Set the L0s Exit Latency to 2us-4us = 0x6 */

 Set the L1 Exit Latency to be 32us-64 us = 0x6 */

	/*

	 * The physical address of the MMIO region which is exposed as the BAR

	 * should be written to MHI BASE registers.

 Enable LTSSM */

 Common DWC controller ops */

 TODO: Notify clients about PCIe state change */

 PHY needs to be powered on for dw_pcie_ep_init() */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Samsung Exynos SoCs

 *

 * Copyright (C) 2013-2020 Samsung Electronics Co., Ltd.

 *		https://www.samsung.com

 *

 * Author: Jingoo Han <jg1.han@samsung.com>

 *	   Jaehoon Chung <jh80.chung@samsung.com>

 PCIe ELBI registers */

 assert LTSSM enable */

 External Local Bus interface (ELBI) registers */

 exynos_pcie_host_init controls ep->phy */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Amazon's Annapurna Labs IP (used in chips

 * such as Graviton and Alpine)

 *

 * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.

 *

 * Author: Jonathan Chocron <jonnyc@amazon.com>

		/*

		 * The DW PCIe core doesn't filter out transactions to other

		 * devices/functions on the root bus num, so we do this here.

 defined(CONFIG_ACPI) && defined(CONFIG_PCI_QUIRKS) */

 base of PCIe unit (not DW core) */

 This portion is taken from the transaction address */

 This portion is taken from the cfg_target_bus reg */

 Set the valid values of secondary and subordinate buses */

 CONFIG_PCIE_AL*/

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Axis ARTPEC-6 SoC

 *

 * Author: Niklas Cassel <niklas.cassel@axis.com>

 *

 * Based on work done by Phil Edworthy <phil@edworthys.org>

 DT axis,syscon-pcie */

 DT phy */

 ARTPEC-6 specific registers */

 ARTPEC-7 specific fields */

 ARTPEC-7 specific fields */

 Receiver term. 50 Ohm */

 Reference clock term. 100 Ohm */

 Check if external reference clock is connected */

 Receiver term. 50 Ohm */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Mobiveil PCIe Host controller

 *

 * Copyright (c) 2018 Mobiveil Inc.

 * Copyright 2019 NXP

 *

 * Author: Subrahmanya Lingappa <l.subrahmanya@mobiveil.co.in>

 *	   Hou Zhiqiang <Zhiqiang.Hou@nxp.com>

/*

 * mobiveil_pcie_sel_page - routine to access paged register

 *

 * Registers whose address greater than PAGED_ADDR_BNDRY (0xc00) are paged,

 * for this scheme to work extracted higher 6 bits of the offset will be

 * written to pg_sel field of PAB_CTRL register and rest of the lower 10

 * bits enabled with PAGED_ADDR_BNDRY are used as offset of the register.

 For directly accessed registers, clear the pg_sel field */

/*

 * routine to program the outbound windows

	/*

	 * program Enable Bit to 1, Type Bit to (00) base 2, AXI Window Size Bit

	 * to 4 KB in PAB_AXI_AMAP_CTRL register

	/*

	 * program AXI window base with appropriate value in

	 * PAB_AXI_AMAP_AXI_WIN0 register

 check if the link is up or not */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe Gen4 host controller driver for NXP Layerscape SoCs

 *

 * Copyright 2019-2020 NXP

 *

 * Author: Zhiqiang Hou <Zhiqiang.Hou@nxp.com>

 LUT and PF control registers */

 L0 state */

 Clear the interrupt status */

 Poll for pab_csb_reset to set and PAB activity to clear */

 clear PEX_RESET bit in PEX_PF0_DBG register */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Mobiveil PCIe Host controller

 *

 * Copyright (c) 2018 Mobiveil Inc.

 * Copyright 2019 NXP

 *

 * Author: Subrahmanya Lingappa <l.subrahmanya@mobiveil.co.in>

 *	   Hou Zhiqiang <Zhiqiang.Hou@nxp.com>

 allocate the PCIe port */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCIe host controller driver for Mobiveil PCIe Host controller

 *

 * Copyright (c) 2018 Mobiveil Inc.

 * Copyright 2019-2020 NXP

 *

 * Author: Subrahmanya Lingappa <l.subrahmanya@mobiveil.co.in>

 *	   Hou Zhiqiang <Zhiqiang.Hou@nxp.com>

 Only one device down on each root port */

	/*

	 * Do not read more than one device on the bus directly

	 * attached to RC

/*

 * mobiveil_pcie_map_bus - routine to get the configuration base of either

 * root port or endpoint

 RC config access */

	/*

	 * EP config access (in Config/APIO space)

	 * Program PEX Address base (31..16 bits) with appropriate value

	 * (BDF) in PAB_AXI_AMAP_PEX_WIN_L0 Register.

	 * Relies on pci_lock serialization

	/*

	 * The core provides a single interrupt for both INTx/MSI messages.

	 * So we'll read both INTx and MSI status

 read INTx status */

 Handle INTx */

 clear interrupt handled */

 read extra MSI status register */

 handle MSI interrupts */

		/*

		 * MSI_STATUS_OFFSET register gets updated to zero

		 * once we pop not only the MSI data but also address

		 * from MSI hardware FIFO. So keeping these following

		 * two dummy reads.

 Clear the interrupt status */

 map config resource */

 map csr resource */

 read the number of windows requested */

 setup bus numbers */

	/*

	 * program Bus Master Enable Bit in Command Register in PAB Config

	 * Space

	/*

	 * program PIO Enable Bit to 1 (and PEX PIO Enable to 1) in PAB_CTRL

	 * register

	/*

	 * program PIO Enable Bit to 1 and Config Window Enable Bit to 1 in

	 * PAB_AXI_PIO_CTRL Register

 Enable PCIe PIO master */

	/*

	 * we'll program one outbound window for config reads and

	 * another default inbound window for all the upstream traffic

	 * rest of the outbound windows will be configured according to

	 * the "ranges" field defined in device tree

 config outbound translation window */

 memory inbound translation window */

 Get the I/O and memory ranges from DT */

 configure outbound translation window */

 fixup for PCIe class register */

 routine to setup the INTx related data */

 INTx domain operations structure */

 setup INTx */

 setup MSI */

 map MSI config resource */

 setup MSI hardware registers */

 initialize the IRQ domains */

 Enable interrupts */

	/*

	 * configure all inbound and outbound windows and prepare the RC for

	 * config access

 Initialize bridge */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017 Cadence

 Cadence PCIe host controller driver.

 Author: Cyrille Pitchen <cyrille.pitchen@free-electrons.com>

		/*

		 * Only the root port (devfn == 0) is connected to this bus.

		 * All other PCI devices are behind some bridge hence on another

		 * bus.

 Check that the link is up */

 Clear AXI link-down status */

 Update Output registers for AXI region 0. */

 Configuration Type 0 or Type 1 access. */

	/*

	 * The bus number was already set once for all in desc1 by

	 * cdns_pcie_host_init_address_translation().

 Check if the link is up or not */

	/*

	 * Set retrain bit if current speed is 2.5 GB/s,

	 * but the PCIe root port support is > 2.5 GB/s.

	/*

	 * Retrain link for Gen2 training defect

	 * if quirk flag is set.

	/*

	 * Set the root complex BAR configuration register:

	 * - disable both BAR0 and BAR1.

	 * - enable Prefetchable Memory Base and Limit registers in type 1

	 *   config space (64 bits).

	 * - enable IO Base and Limit registers in type 1 config

	 *   space (32 bits).

 Set root port configuration space */

		/*

		 * Try to find a minimum BAR whose size is greater than

		 * or equal to the remaining resource_entry size. This will

		 * fail if the size of each of the available BARs is less than

		 * the remaining resource_entry size.

		 * If a minimum BAR is found, IB ATU will be configured and

		 * exited.

		/*

		 * If the control reaches here, it would mean the remaining

		 * resource_entry size cannot be fitted in a single BAR. So we

		 * find a maximum BAR whose size is less than or equal to the

		 * remaining resource_entry size and split the resource entry

		 * so that part of resource entry is fitted inside the maximum

		 * BAR. The remaining size would be fitted during the next

		 * iteration of the loop.

		 * If a maximum BAR is not found, there is no way we can fit

		 * this resource_entry, so we error out.

	/*

	 * Reserve region 0 for PCI configure space accesses:

	 * OB_REGION_PCI_ADDR0 and OB_REGION_DESC0 are updated dynamically by

	 * cdns_pci_map_bus(), other region registers are set here once for all.

 Should be programmed to zero. */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017 Cadence

 Cadence PCIe controller driver.

 Author: Cyrille Pitchen <cyrille.pitchen@free-electrons.com>

	/*

	 * Set the LTSSM Detect Quiet state min. delay to 2ms.

	/*

	 * roundup_pow_of_two() returns an unsigned long, which is not suited

	 * for 64bit values.

 Set the PCI address */

 Set the PCIe header descriptor */

	/*

	 * Whatever Bit [23] is set or not inside DESC0 register of the outbound

	 * PCIe descriptor, the PCI function number must be set into

	 * Bits [26:24] of DESC0 anyway.

	 *

	 * In Root Complex mode, the function number is always 0 but in Endpoint

	 * mode, the PCIe controller may support more than one function. This

	 * function number needs to be set properly into the outbound PCIe

	 * descriptor.

	 *

	 * Besides, setting Bit [23] is mandatory when in Root Complex mode:

	 * then the driver must provide the bus, resp. device, number in

	 * Bits [7:0] of DESC1, resp. Bits[31:27] of DESC0. Like the function

	 * number, the device number is always 0 in Root Complex mode.

	 *

	 * However when in Endpoint mode, we can clear Bit [23] of DESC0, hence

	 * the PCIe controller will use the captured values for the bus and

	 * device numbers.

 The device and function numbers are always 0. */

		/*

		 * Use captured values for bus and device numbers but still

		 * need to set the function number.

 Set the CPU address */

 See cdns_pcie_set_outbound_region() comments above. */

 Set the CPU address */

 SPDX-License-Identifier: GPL-2.0

/*

 * pci-j721e - PCIe controller driver for TI's J721E SoCs

 *

 * Copyright (C) 2020 Texas Instruments Incorporated - http://www.ti.com

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

 Do not error out to maintain old DT compatibility */

		/*

		 * "Power Sequencing and Reset Signal Timings" table in

		 * PCI EXPRESS CARD ELECTROMECHANICAL SPECIFICATION, REV. 3.0

		 * indicates PERST# should be deasserted after minimum of 100us

		 * once REFCLK is stable. The REFCLK to the connector in RC

		 * mode is selected while enabling the PHY. So deassert PERST#

		 * after 100 us.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2017 Cadence

 Cadence PCIe endpoint controller driver.

 Author: Cyrille Pitchen <cyrille.pitchen@free-electrons.com>

 128 bytes */

	/*

	 * Vendor ID can only be modified from function 0, all other functions

	 * use the same vendor ID as function 0.

 Update the vendor IDs. */

 BAR size is 2^(aperture + 7) */

	/*

	 * roundup_pow_of_two() returns an unsigned long, which is not suited

	 * for 64bit values.

 128B -> 0, 256B -> 1, 512B -> 2, ... */

	/*

	 * Set the Multiple Message Capable bitfield into the Message Control

	 * register.

 Validate that the MSI feature is actually enabled. */

	/*

	 * Get the Multiple Message Enable bitfield from the Message Control

	 * register.

 Set MSIX BAR and offset */

 Set PBA BAR and offset.  BAR must match MSIX BAR */

 Set the outbound region if needed. */

 First region was reserved for IRQ writes. */

	/*

	 * The mdelay() value was taken from dra7xx_pcie_raise_legacy_irq()

 Check whether the MSI feature has been enabled by the PCI host. */

 Get the number of enabled MSIs */

 Compute the data value to be written. */

 Get the PCI address where to write the data into. */

 Set the outbound region if needed. */

 First region was reserved for IRQ writes. */

 Check whether the MSI feature has been enabled by the PCI host. */

 Get the number of enabled MSIs */

 Compute the data value to be written. */

 Get the PCI address where to write the data into. */

 Check whether the MSI-X feature has been enabled by the PCI host. */

 Set the outbound region if needed. */

 First region was reserved for IRQ writes. */

	/*

	 * BIT(0) is hardwired to 1, hence function 0 is always enabled

	 * and can't be disabled anyway.

 Disable all but function 0 (anyway BIT(0) is hardwired to 1). */

 Reserve region 0 for IRQs */

 SPDX-License-Identifier: GPL-2.0

/*

 * Cadence PCIe platform  driver.

 *

 * Copyright (c) 2019, Cadence Design Systems

 * Author: Tom Joseph <tjoseph@cadence.com>

/**

 * struct cdns_plat_pcie - private data for this PCIe platform driver

 * @pcie: Cadence PCIe controller

 * @is_rc: Set to 1 indicates the PCIe controller mode is Root Complex,

 *         if 0 it is in Endpoint mode.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Endpoint *Controller* Address Space Management

 *

 * Copyright (C) 2017 Texas Instruments

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

/**

 * pci_epc_mem_get_order() - determine the allocation order of a memory size

 * @mem: address space of the endpoint controller

 * @size: the size for which to get the order

 *

 * Reimplement get_order() for mem->page_size since the generic get_order

 * always gets order with a constant PAGE_SIZE.

/**

 * pci_epc_multi_mem_init() - initialize the pci_epc_mem structure

 * @epc: the EPC device that invoked pci_epc_mem_init

 * @windows: pointer to windows supported by the device

 * @num_windows: number of windows device supports

 *

 * Invoke to initialize the pci_epc_mem structure used by the

 * endpoint functions to allocate mapped PCI address.

/**

 * pci_epc_mem_exit() - cleanup the pci_epc_mem structure

 * @epc: the EPC device that invoked pci_epc_mem_exit

 *

 * Invoke to cleanup the pci_epc_mem structure allocated in

 * pci_epc_mem_init().

/**

 * pci_epc_mem_alloc_addr() - allocate memory address from EPC addr space

 * @epc: the EPC device on which memory has to be allocated

 * @phys_addr: populate the allocated physical address here

 * @size: the size of the address space that has to be allocated

 *

 * Invoke to allocate memory address from the EPC address space. This

 * is usually done to map the remote RC address into the local system.

/**

 * pci_epc_mem_free_addr() - free the allocated memory address

 * @epc: the EPC device on which memory was allocated

 * @phys_addr: the allocated physical address

 * @virt_addr: virtual address of the allocated mem space

 * @size: the size of the allocated address space

 *

 * Invoke to free the memory allocated using pci_epc_mem_alloc_addr.

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Endpoint *Function* (EPF) library

 *

 * Copyright (C) 2017 Texas Instruments

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

/**

 * pci_epf_type_add_cfs() - Help function drivers to expose function specific

 *                          attributes in configfs

 * @epf: the EPF device that has to be configured using configfs

 * @group: the parent configfs group (corresponding to entries in

 *         pci_epf_device_id)

 *

 * Invoke to expose function specific attributes in configfs. If the function

 * driver does not have anything to expose (attributes configured by user),

 * return NULL.

/**

 * pci_epf_unbind() - Notify the function driver that the binding between the

 *		      EPF device and EPC device has been lost

 * @epf: the EPF device which has lost the binding with the EPC device

 *

 * Invoke to notify the function driver that the binding between the EPF device

 * and EPC device has been lost.

/**

 * pci_epf_bind() - Notify the function driver that the EPF device has been

 *		    bound to a EPC device

 * @epf: the EPF device which has been bound to the EPC device

 *

 * Invoke to notify the function driver that it has been bound to a EPC device

/**

 * pci_epf_add_vepf() - associate virtual EP function to physical EP function

 * @epf_pf: the physical EP function to which the virtual EP function should be

 *   associated

 * @epf_vf: the virtual EP function to be added

 *

 * A physical endpoint function can be associated with multiple virtual

 * endpoint functions. Invoke pci_epf_add_epf() to add a virtual PCI endpoint

 * function to a physical PCI endpoint function.

/**

 * pci_epf_remove_vepf() - remove virtual EP function from physical EP function

 * @epf_pf: the physical EP function from which the virtual EP function should

 *   be removed

 * @epf_vf: the virtual EP function to be removed

 *

 * Invoke to remove a virtual endpoint function from the physical endpoint

 * function.

/**

 * pci_epf_free_space() - free the allocated PCI EPF register space

 * @epf: the EPF device from whom to free the memory

 * @addr: the virtual address of the PCI EPF register space

 * @bar: the BAR number corresponding to the register space

 * @type: Identifies if the allocated space is for primary EPC or secondary EPC

 *

 * Invoke to free the allocated PCI EPF register space.

/**

 * pci_epf_alloc_space() - allocate memory for the PCI EPF register space

 * @epf: the EPF device to whom allocate the memory

 * @size: the size of the memory that has to be allocated

 * @bar: the BAR number corresponding to the allocated register space

 * @align: alignment size for the allocation region

 * @type: Identifies if the allocation is for primary EPC or secondary EPC

 *

 * Invoke to allocate memory for the PCI EPF register space.

/**

 * pci_epf_unregister_driver() - unregister the PCI EPF driver

 * @driver: the PCI EPF driver that has to be unregistered

 *

 * Invoke to unregister the PCI EPF driver.

/**

 * __pci_epf_register_driver() - register a new PCI EPF driver

 * @driver: structure representing PCI EPF driver

 * @owner: the owner of the module that registers the PCI EPF driver

 *

 * Invoke to register a new PCI EPF driver.

/**

 * pci_epf_destroy() - destroy the created PCI EPF device

 * @epf: the PCI EPF device that has to be destroyed.

 *

 * Invoke to destroy the PCI EPF device created by invoking pci_epf_create().

/**

 * pci_epf_create() - create a new PCI EPF device

 * @name: the name of the PCI EPF device. This name will be used to bind the

 *	  EPF device to a EPF driver

 *

 * Invoke to create a new PCI EPF device by providing the name of the function

 * device.

 VFs are numbered starting with 1. So set BIT(0) by default */

 SPDX-License-Identifier: GPL-2.0

/*

 * PCI Endpoint *Controller* (EPC) library

 *

 * Copyright (C) 2017 Texas Instruments

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

/**

 * pci_epc_put() - release the PCI endpoint controller

 * @epc: epc returned by pci_epc_get()

 *

 * release the refcount the caller obtained by invoking pci_epc_get()

/**

 * pci_epc_get() - get the PCI endpoint controller

 * @epc_name: device name of the endpoint controller

 *

 * Invoke to get struct pci_epc * corresponding to the device name of the

 * endpoint controller

/**

 * pci_epc_get_first_free_bar() - helper to get first unreserved BAR

 * @epc_features: pci_epc_features structure that holds the reserved bar bitmap

 *

 * Invoke to get the first unreserved BAR that can be used by the endpoint

 * function. For any incorrect value in reserved_bar return '0'.

/**

 * pci_epc_get_next_free_bar() - helper to get unreserved BAR starting from @bar

 * @epc_features: pci_epc_features structure that holds the reserved bar bitmap

 * @bar: the starting BAR number from where unreserved BAR should be searched

 *

 * Invoke to get the next unreserved BAR starting from @bar that can be used

 * for endpoint function. For any incorrect value in reserved_bar return '0'.

 If 'bar - 1' is a 64-bit BAR, move to the next BAR */

 Find if the reserved BAR is also a 64-bit BAR */

 Set the adjacent bit if the reserved BAR is also a 64-bit BAR */

/**

 * pci_epc_get_features() - get the features supported by EPC

 * @epc: the features supported by *this* EPC device will be returned

 * @func_no: the features supported by the EPC device specific to the

 *	     endpoint function with func_no will be returned

 * @vfunc_no: the features supported by the EPC device specific to the

 *	     virtual endpoint function with vfunc_no will be returned

 *

 * Invoke to get the features provided by the EPC which may be

 * specific to an endpoint function. Returns pci_epc_features on success

 * and NULL for any failures.

/**

 * pci_epc_stop() - stop the PCI link

 * @epc: the link of the EPC device that has to be stopped

 *

 * Invoke to stop the PCI link

/**

 * pci_epc_start() - start the PCI link

 * @epc: the link of *this* EPC device has to be started

 *

 * Invoke to start the PCI link

/**

 * pci_epc_raise_irq() - interrupt the host system

 * @epc: the EPC device which has to interrupt the host

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @type: specify the type of interrupt; legacy, MSI or MSI-X

 * @interrupt_num: the MSI or MSI-X interrupt number

 *

 * Invoke to raise an legacy, MSI or MSI-X interrupt

/**

 * pci_epc_map_msi_irq() - Map physical address to MSI address and return

 *                         MSI data

 * @epc: the EPC device which has the MSI capability

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @phys_addr: the physical address of the outbound region

 * @interrupt_num: the MSI interrupt number

 * @entry_size: Size of Outbound address region for each interrupt

 * @msi_data: the data that should be written in order to raise MSI interrupt

 *            with interrupt number as 'interrupt num'

 * @msi_addr_offset: Offset of MSI address from the aligned outbound address

 *                   to which the MSI address is mapped

 *

 * Invoke to map physical address to MSI address and return MSI data. The

 * physical address should be an address in the outbound region. This is

 * required to implement doorbell functionality of NTB wherein EPC on either

 * side of the interface (primary and secondary) can directly write to the

 * physical address (in outbound region) of the other interface to ring

 * doorbell.

/**

 * pci_epc_get_msi() - get the number of MSI interrupt numbers allocated

 * @epc: the EPC device to which MSI interrupts was requested

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 *

 * Invoke to get the number of MSI interrupts allocated by the RC

/**

 * pci_epc_set_msi() - set the number of MSI interrupt numbers required

 * @epc: the EPC device on which MSI has to be configured

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @interrupts: number of MSI interrupts required by the EPF

 *

 * Invoke to set the required number of MSI interrupts.

/**

 * pci_epc_get_msix() - get the number of MSI-X interrupt numbers allocated

 * @epc: the EPC device to which MSI-X interrupts was requested

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 *

 * Invoke to get the number of MSI-X interrupts allocated by the RC

/**

 * pci_epc_set_msix() - set the number of MSI-X interrupt numbers required

 * @epc: the EPC device on which MSI-X has to be configured

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @interrupts: number of MSI-X interrupts required by the EPF

 * @bir: BAR where the MSI-X table resides

 * @offset: Offset pointing to the start of MSI-X table

 *

 * Invoke to set the required number of MSI-X interrupts.

/**

 * pci_epc_unmap_addr() - unmap CPU address from PCI address

 * @epc: the EPC device on which address is allocated

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @phys_addr: physical address of the local system

 *

 * Invoke to unmap the CPU address from PCI address.

/**

 * pci_epc_map_addr() - map CPU address to PCI address

 * @epc: the EPC device on which address is allocated

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @phys_addr: physical address of the local system

 * @pci_addr: PCI address to which the physical address should be mapped

 * @size: the size of the allocation

 *

 * Invoke to map CPU address with PCI address.

/**

 * pci_epc_clear_bar() - reset the BAR

 * @epc: the EPC device for which the BAR has to be cleared

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @epf_bar: the struct epf_bar that contains the BAR information

 *

 * Invoke to reset the BAR of the endpoint device.

/**

 * pci_epc_set_bar() - configure BAR in order for host to assign PCI addr space

 * @epc: the EPC device on which BAR has to be configured

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @epf_bar: the struct epf_bar that contains the BAR information

 *

 * Invoke to configure the BAR of the endpoint device.

/**

 * pci_epc_write_header() - write standard configuration header

 * @epc: the EPC device to which the configuration header should be written

 * @func_no: the physical endpoint function number in the EPC device

 * @vfunc_no: the virtual endpoint function number in the physical function

 * @header: standard configuration header fields

 *

 * Invoke to write the configuration header to the endpoint controller. Every

 * endpoint controller will have a dedicated location to which the standard

 * configuration header would be written. The callback function should write

 * the header fields to this dedicated location.

 Only Virtual Function #1 has deviceID */

/**

 * pci_epc_add_epf() - bind PCI endpoint function to an endpoint controller

 * @epc: the EPC device to which the endpoint function should be added

 * @epf: the endpoint function to be added

 * @type: Identifies if the EPC is connected to the primary or secondary

 *        interface of EPF

 *

 * A PCI endpoint device can have one or more functions. In the case of PCIe,

 * the specification allows up to 8 PCIe endpoint functions. Invoke

 * pci_epc_add_epf() to add a PCI endpoint function to an endpoint controller.

/**

 * pci_epc_remove_epf() - remove PCI endpoint function from endpoint controller

 * @epc: the EPC device from which the endpoint function should be removed

 * @epf: the endpoint function to be removed

 * @type: identifies if the EPC is connected to the primary or secondary

 *        interface of EPF

 *

 * Invoke to remove PCI endpoint function from the endpoint controller.

/**

 * pci_epc_linkup() - Notify the EPF device that EPC device has established a

 *		      connection with the Root Complex.

 * @epc: the EPC device which has established link with the host

 *

 * Invoke to Notify the EPF device that the EPC device has established a

 * connection with the Root Complex.

/**

 * pci_epc_init_notify() - Notify the EPF device that EPC device's core

 *			   initialization is completed.

 * @epc: the EPC device whose core initialization is completed

 *

 * Invoke to Notify the EPF device that the EPC device's initialization

 * is completed.

/**

 * pci_epc_destroy() - destroy the EPC device

 * @epc: the EPC device that has to be destroyed

 *

 * Invoke to destroy the PCI EPC device

/**

 * devm_pci_epc_destroy() - destroy the EPC device

 * @dev: device that wants to destroy the EPC

 * @epc: the EPC device that has to be destroyed

 *

 * Invoke to destroy the devres associated with this

 * pci_epc and destroy the EPC device.

/**

 * __pci_epc_create() - create a new endpoint controller (EPC) device

 * @dev: device that is creating the new EPC

 * @ops: function pointers for performing EPC operations

 * @owner: the owner of the module that creates the EPC device

 *

 * Invoke to create a new EPC device and add it to pci_epc class.

/**

 * __devm_pci_epc_create() - create a new endpoint controller (EPC) device

 * @dev: device that is creating the new EPC

 * @ops: function pointers for performing EPC operations

 * @owner: the owner of the module that creates the EPC device

 *

 * Invoke to create a new EPC device and add it to pci_epc class.

 * While at that, it also associates the device with the pci_epc using devres.

 * On driver detach, release function is invoked on the devres data,

 * then, devres data is freed.

 SPDX-License-Identifier: GPL-2.0

/*

 * configfs to configure the PCI endpoint

 *

 * Copyright (C) 2017 Texas Instruments

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * Endpoint Function Driver to implement Non-Transparent Bridge functionality

 *

 * Copyright (C) 2020 Texas Instruments

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

/*

 * The PCI NTB function driver configures the SoC with multiple PCIe Endpoint

 * (EP) controller instances (see diagram below) in such a way that

 * transactions from one EP controller are routed to the other EP controller.

 * Once PCI NTB function driver configures the SoC with multiple EP instances,

 * HOST1 and HOST2 can communicate with each other using SoC as a bridge.

 *

 *    +-------------+                                   +-------------+

 *    |             |                                   |             |

 *    |    HOST1    |                                   |    HOST2    |

 *    |             |                                   |             |

 *    +------^------+                                   +------^------+

 *           |                                                 |

 *           |                                                 |

 * +---------|-------------------------------------------------|---------+

 * |  +------v------+                                   +------v------+  |

 * |  |             |                                   |             |  |

 * |  |     EP      |                                   |     EP      |  |

 * |  | CONTROLLER1 |                                   | CONTROLLER2 |  |

 * |  |             <----------------------------------->             |  |

 * |  |             |                                   |             |  |

 * |  |             |                                   |             |  |

 * |  |             |  SoC With Multiple EP Instances   |             |  |

 * |  |             |  (Configured using NTB Function)  |             |  |

 * |  +-------------+                                   +-------------+  |

 * +---------------------------------------------------------------------+

/**

 * epf_ntb_link_up() - Raise link_up interrupt to both the hosts

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @link_up: true or false indicating Link is UP or Down

 *

 * Once NTB function in HOST1 and the NTB function in HOST2 invoke

 * ntb_link_enable(), this NTB function driver will trigger a link event to

 * the NTB client in both the hosts.

/**

 * epf_ntb_configure_mw() - Configure the Outbound Address Space for one host

 *   to access the memory window of other host

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 * @mw: Index of the memory window (either 0, 1, 2 or 3)

 *

 * +-----------------+    +---->+----------------+-----------+-----------------+

 * |       BAR0      |    |     |   Doorbell 1   +-----------> MSI|X ADDRESS 1 |

 * +-----------------+    |     +----------------+           +-----------------+

 * |       BAR1      |    |     |   Doorbell 2   +---------+ |                 |

 * +-----------------+----+     +----------------+         | |                 |

 * |       BAR2      |          |   Doorbell 3   +-------+ | +-----------------+

 * +-----------------+----+     +----------------+       | +-> MSI|X ADDRESS 2 |

 * |       BAR3      |    |     |   Doorbell 4   +-----+ |   +-----------------+

 * +-----------------+    |     |----------------+     | |   |                 |

 * |       BAR4      |    |     |                |     | |   +-----------------+

 * +-----------------+    |     |      MW1       +---+ | +-->+ MSI|X ADDRESS 3||

 * |       BAR5      |    |     |                |   | |     +-----------------+

 * +-----------------+    +---->-----------------+   | |     |                 |

 *   EP CONTROLLER 1            |                |   | |     +-----------------+

 *                              |                |   | +---->+ MSI|X ADDRESS 4 |

 *                              +----------------+   |       +-----------------+

 *                      (A)      EP CONTROLLER 2     |       |                 |

 *                                 (OB SPACE)        |       |                 |

 *                                                   +------->      MW1        |

 *                                                           |                 |

 *                                                           |                 |

 *                                                   (B)     +-----------------+

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           +-----------------+

 *                                                           PCI Address Space

 *                                                           (Managed by HOST2)

 *

 * This function performs stage (B) in the above diagram (see MW1) i.e., map OB

 * address space of memory window to PCI address space.

 *

 * This operation requires 3 parameters

 *  1) Address in the outbound address space

 *  2) Address in the PCI Address space

 *  3) Size of the address region to be mapped

 *

 * The address in the outbound address space (for MW1, MW2, MW3 and MW4) is

 * stored in epf_bar corresponding to BAR_DB_MW1 for MW1 and BAR_MW2, BAR_MW3

 * BAR_MW4 for rest of the BARs of epf_ntb_epc that is connected to HOST1. This

 * is populated in epf_ntb_alloc_peer_mem() in this driver.

 *

 * The address and size of the PCI address region that has to be mapped would

 * be provided by HOST2 in ctrl->addr and ctrl->size of epf_ntb_epc that is

 * connected to HOST2.

 *

 * Please note Memory window1 (MW1) and Doorbell registers together will be

 * mapped to a single BAR (BAR2) above for 32-bit BARs. The exact BAR that's

 * used for Memory window (MW) can be obtained from epf_ntb_bar[BAR_DB_MW1],

 * epf_ntb_bar[BAR_MW2], epf_ntb_bar[BAR_MW2], epf_ntb_bar[BAR_MW2].

/**

 * epf_ntb_teardown_mw() - Teardown the configured OB ATU

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 * @mw: Index of the memory window (either 0, 1, 2 or 3)

 *

 * Teardown the configured OB ATU configured in epf_ntb_configure_mw() using

 * pci_epc_unmap_addr()

/**

 * epf_ntb_configure_msi() - Map OB address space to MSI address

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 * @db_count: Number of doorbell interrupts to map

 *

 *+-----------------+    +----->+----------------+-----------+-----------------+

 *|       BAR0      |    |      |   Doorbell 1   +---+------->   MSI ADDRESS   |

 *+-----------------+    |      +----------------+   |       +-----------------+

 *|       BAR1      |    |      |   Doorbell 2   +---+       |                 |

 *+-----------------+----+      +----------------+   |       |                 |

 *|       BAR2      |           |   Doorbell 3   +---+       |                 |

 *+-----------------+----+      +----------------+   |       |                 |

 *|       BAR3      |    |      |   Doorbell 4   +---+       |                 |

 *+-----------------+    |      |----------------+           |                 |

 *|       BAR4      |    |      |                |           |                 |

 *+-----------------+    |      |      MW1       |           |                 |

 *|       BAR5      |    |      |                |           |                 |

 *+-----------------+    +----->-----------------+           |                 |

 *  EP CONTROLLER 1             |                |           |                 |

 *                              |                |           |                 |

 *                              +----------------+           +-----------------+

 *                     (A)       EP CONTROLLER 2             |                 |

 *                                 (OB SPACE)                |                 |

 *                                                           |      MW1        |

 *                                                           |                 |

 *                                                           |                 |

 *                                                   (B)     +-----------------+

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           +-----------------+

 *                                                           PCI Address Space

 *                                                           (Managed by HOST2)

 *

 *

 * This function performs stage (B) in the above diagram (see Doorbell 1,

 * Doorbell 2, Doorbell 3, Doorbell 4) i.e map OB address space corresponding to

 * doorbell to MSI address in PCI address space.

 *

 * This operation requires 3 parameters

 *  1) Address reserved for doorbell in the outbound address space

 *  2) MSI-X address in the PCIe Address space

 *  3) Number of MSI-X interrupts that has to be configured

 *

 * The address in the outbound address space (for the Doorbell) is stored in

 * epf_bar corresponding to BAR_DB_MW1 of epf_ntb_epc that is connected to

 * HOST1. This is populated in epf_ntb_alloc_peer_mem() in this driver along

 * with address for MW1.

 *

 * pci_epc_map_msi_irq() takes the MSI address from MSI capability register

 * and maps the OB address (obtained in epf_ntb_alloc_peer_mem()) to the MSI

 * address.

 *

 * epf_ntb_configure_msi() also stores the MSI data to raise each interrupt

 * in db_data of the peer's control region. This helps the peer to raise

 * doorbell of the other host by writing db_data to the BAR corresponding to

 * BAR_DB_MW1.

/**

 * epf_ntb_configure_msix() - Map OB address space to MSI-X address

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 * @db_count: Number of doorbell interrupts to map

 *

 *+-----------------+    +----->+----------------+-----------+-----------------+

 *|       BAR0      |    |      |   Doorbell 1   +-----------> MSI-X ADDRESS 1 |

 *+-----------------+    |      +----------------+           +-----------------+

 *|       BAR1      |    |      |   Doorbell 2   +---------+ |                 |

 *+-----------------+----+      +----------------+         | |                 |

 *|       BAR2      |           |   Doorbell 3   +-------+ | +-----------------+

 *+-----------------+----+      +----------------+       | +-> MSI-X ADDRESS 2 |

 *|       BAR3      |    |      |   Doorbell 4   +-----+ |   +-----------------+

 *+-----------------+    |      |----------------+     | |   |                 |

 *|       BAR4      |    |      |                |     | |   +-----------------+

 *+-----------------+    |      |      MW1       +     | +-->+ MSI-X ADDRESS 3||

 *|       BAR5      |    |      |                |     |     +-----------------+

 *+-----------------+    +----->-----------------+     |     |                 |

 *  EP CONTROLLER 1             |                |     |     +-----------------+

 *                              |                |     +---->+ MSI-X ADDRESS 4 |

 *                              +----------------+           +-----------------+

 *                     (A)       EP CONTROLLER 2             |                 |

 *                                 (OB SPACE)                |                 |

 *                                                           |      MW1        |

 *                                                           |                 |

 *                                                           |                 |

 *                                                   (B)     +-----------------+

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           +-----------------+

 *                                                           PCI Address Space

 *                                                           (Managed by HOST2)

 *

 * This function performs stage (B) in the above diagram (see Doorbell 1,

 * Doorbell 2, Doorbell 3, Doorbell 4) i.e map OB address space corresponding to

 * doorbell to MSI-X address in PCI address space.

 *

 * This operation requires 3 parameters

 *  1) Address reserved for doorbell in the outbound address space

 *  2) MSI-X address in the PCIe Address space

 *  3) Number of MSI-X interrupts that has to be configured

 *

 * The address in the outbound address space (for the Doorbell) is stored in

 * epf_bar corresponding to BAR_DB_MW1 of epf_ntb_epc that is connected to

 * HOST1. This is populated in epf_ntb_alloc_peer_mem() in this driver along

 * with address for MW1.

 *

 * The MSI-X address is in the MSI-X table of EP CONTROLLER 2 and

 * the count of doorbell is in ctrl->argument of epf_ntb_epc that is connected

 * to HOST2. MSI-X table is stored memory mapped to ntb_epc->msix_bar and the

 * offset is in ntb_epc->msix_table_offset. From this epf_ntb_configure_msix()

 * gets the MSI-X address and data.

 *

 * epf_ntb_configure_msix() also stores the MSI-X data to raise each interrupt

 * in db_data of the peer's control region. This helps the peer to raise

 * doorbell of the other host by writing db_data to the BAR corresponding to

 * BAR_DB_MW1.

/**

 * epf_ntb_configure_db() - Configure the Outbound Address Space for one host

 *   to ring the doorbell of other host

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 * @db_count: Count of the number of doorbells that has to be configured

 * @msix: Indicates whether MSI-X or MSI should be used

 *

 * Invokes epf_ntb_configure_msix() or epf_ntb_configure_msi() required for

 * one HOST to ring the doorbell of other HOST.

/**

 * epf_ntb_teardown_db() - Unmap address in OB address space to MSI/MSI-X

 *   address

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Invoke pci_epc_unmap_addr() to unmap OB address to MSI/MSI-X address.

/**

 * epf_ntb_cmd_handler() - Handle commands provided by the NTB Host

 * @work: work_struct for the two epf_ntb_epc (PRIMARY and SECONDARY)

 *

 * Workqueue function that gets invoked for the two epf_ntb_epc

 * periodically (once every 5ms) to see if it has received any commands

 * from NTB host. The host can send commands to configure doorbell or

 * configure memory window or to update link status.

/**

 * epf_ntb_peer_spad_bar_clear() - Clear Peer Scratchpad BAR

 * @ntb_epc: EPC associated with one of the HOST which holds peer's outbound

 *	     address.

 *

 *+-----------------+------->+------------------+        +-----------------+

 *|       BAR0      |        |  CONFIG REGION   |        |       BAR0      |

 *+-----------------+----+   +------------------+<-------+-----------------+

 *|       BAR1      |    |   |SCRATCHPAD REGION |        |       BAR1      |

 *+-----------------+    +-->+------------------+<-------+-----------------+

 *|       BAR2      |            Local Memory            |       BAR2      |

 *+-----------------+                                    +-----------------+

 *|       BAR3      |                                    |       BAR3      |

 *+-----------------+                                    +-----------------+

 *|       BAR4      |                                    |       BAR4      |

 *+-----------------+                                    +-----------------+

 *|       BAR5      |                                    |       BAR5      |

 *+-----------------+                                    +-----------------+

 *  EP CONTROLLER 1                                        EP CONTROLLER 2

 *

 * Clear BAR1 of EP CONTROLLER 2 which contains the HOST2's peer scratchpad

 * region. While BAR1 is the default peer scratchpad BAR, an NTB could have

 * other BARs for peer scratchpad (because of 64-bit BARs or reserved BARs).

 * This function can get the exact BAR used for peer scratchpad from

 * epf_ntb_bar[BAR_PEER_SPAD].

 *

 * Since HOST2's peer scratchpad is also HOST1's self scratchpad, this function

 * gets the address of peer scratchpad from

 * peer_ntb_epc->epf_ntb_bar[BAR_CONFIG].

/**

 * epf_ntb_peer_spad_bar_set() - Set peer scratchpad BAR

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 *+-----------------+------->+------------------+        +-----------------+

 *|       BAR0      |        |  CONFIG REGION   |        |       BAR0      |

 *+-----------------+----+   +------------------+<-------+-----------------+

 *|       BAR1      |    |   |SCRATCHPAD REGION |        |       BAR1      |

 *+-----------------+    +-->+------------------+<-------+-----------------+

 *|       BAR2      |            Local Memory            |       BAR2      |

 *+-----------------+                                    +-----------------+

 *|       BAR3      |                                    |       BAR3      |

 *+-----------------+                                    +-----------------+

 *|       BAR4      |                                    |       BAR4      |

 *+-----------------+                                    +-----------------+

 *|       BAR5      |                                    |       BAR5      |

 *+-----------------+                                    +-----------------+

 *  EP CONTROLLER 1                                        EP CONTROLLER 2

 *

 * Set BAR1 of EP CONTROLLER 2 which contains the HOST2's peer scratchpad

 * region. While BAR1 is the default peer scratchpad BAR, an NTB could have

 * other BARs for peer scratchpad (because of 64-bit BARs or reserved BARs).

 * This function can get the exact BAR used for peer scratchpad from

 * epf_ntb_bar[BAR_PEER_SPAD].

 *

 * Since HOST2's peer scratchpad is also HOST1's self scratchpad, this function

 * gets the address of peer scratchpad from

 * peer_ntb_epc->epf_ntb_bar[BAR_CONFIG].

/**

 * epf_ntb_config_sspad_bar_clear() - Clear Config + Self scratchpad BAR

 * @ntb_epc: EPC associated with one of the HOST which holds peer's outbound

 *	     address.

 *

 * +-----------------+------->+------------------+        +-----------------+

 * |       BAR0      |        |  CONFIG REGION   |        |       BAR0      |

 * +-----------------+----+   +------------------+<-------+-----------------+

 * |       BAR1      |    |   |SCRATCHPAD REGION |        |       BAR1      |

 * +-----------------+    +-->+------------------+<-------+-----------------+

 * |       BAR2      |            Local Memory            |       BAR2      |

 * +-----------------+                                    +-----------------+

 * |       BAR3      |                                    |       BAR3      |

 * +-----------------+                                    +-----------------+

 * |       BAR4      |                                    |       BAR4      |

 * +-----------------+                                    +-----------------+

 * |       BAR5      |                                    |       BAR5      |

 * +-----------------+                                    +-----------------+

 *   EP CONTROLLER 1                                        EP CONTROLLER 2

 *

 * Clear BAR0 of EP CONTROLLER 1 which contains the HOST1's config and

 * self scratchpad region (removes inbound ATU configuration). While BAR0 is

 * the default self scratchpad BAR, an NTB could have other BARs for self

 * scratchpad (because of reserved BARs). This function can get the exact BAR

 * used for self scratchpad from epf_ntb_bar[BAR_CONFIG].

 *

 * Please note the self scratchpad region and config region is combined to

 * a single region and mapped using the same BAR. Also note HOST2's peer

 * scratchpad is HOST1's self scratchpad.

/**

 * epf_ntb_config_sspad_bar_set() - Set Config + Self scratchpad BAR

 * @ntb_epc: EPC associated with one of the HOST which holds peer's outbound

 *	     address.

 *

 * +-----------------+------->+------------------+        +-----------------+

 * |       BAR0      |        |  CONFIG REGION   |        |       BAR0      |

 * +-----------------+----+   +------------------+<-------+-----------------+

 * |       BAR1      |    |   |SCRATCHPAD REGION |        |       BAR1      |

 * +-----------------+    +-->+------------------+<-------+-----------------+

 * |       BAR2      |            Local Memory            |       BAR2      |

 * +-----------------+                                    +-----------------+

 * |       BAR3      |                                    |       BAR3      |

 * +-----------------+                                    +-----------------+

 * |       BAR4      |                                    |       BAR4      |

 * +-----------------+                                    +-----------------+

 * |       BAR5      |                                    |       BAR5      |

 * +-----------------+                                    +-----------------+

 *   EP CONTROLLER 1                                        EP CONTROLLER 2

 *

 * Map BAR0 of EP CONTROLLER 1 which contains the HOST1's config and

 * self scratchpad region. While BAR0 is the default self scratchpad BAR, an

 * NTB could have other BARs for self scratchpad (because of reserved BARs).

 * This function can get the exact BAR used for self scratchpad from

 * epf_ntb_bar[BAR_CONFIG].

 *

 * Please note the self scratchpad region and config region is combined to

 * a single region and mapped using the same BAR. Also note HOST2's peer

 * scratchpad is HOST1's self scratchpad.

/**

 * epf_ntb_config_spad_bar_free() - Free the physical memory associated with

 *   config + scratchpad region

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 *

 * +-----------------+------->+------------------+        +-----------------+

 * |       BAR0      |        |  CONFIG REGION   |        |       BAR0      |

 * +-----------------+----+   +------------------+<-------+-----------------+

 * |       BAR1      |    |   |SCRATCHPAD REGION |        |       BAR1      |

 * +-----------------+    +-->+------------------+<-------+-----------------+

 * |       BAR2      |            Local Memory            |       BAR2      |

 * +-----------------+                                    +-----------------+

 * |       BAR3      |                                    |       BAR3      |

 * +-----------------+                                    +-----------------+

 * |       BAR4      |                                    |       BAR4      |

 * +-----------------+                                    +-----------------+

 * |       BAR5      |                                    |       BAR5      |

 * +-----------------+                                    +-----------------+

 *   EP CONTROLLER 1                                        EP CONTROLLER 2

 *

 * Free the Local Memory mentioned in the above diagram. After invoking this

 * function, any of config + self scratchpad region of HOST1 or peer scratchpad

 * region of HOST2 should not be accessed.

/**

 * epf_ntb_config_spad_bar_alloc() - Allocate memory for config + scratchpad

 *   region

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * +-----------------+------->+------------------+        +-----------------+

 * |       BAR0      |        |  CONFIG REGION   |        |       BAR0      |

 * +-----------------+----+   +------------------+<-------+-----------------+

 * |       BAR1      |    |   |SCRATCHPAD REGION |        |       BAR1      |

 * +-----------------+    +-->+------------------+<-------+-----------------+

 * |       BAR2      |            Local Memory            |       BAR2      |

 * +-----------------+                                    +-----------------+

 * |       BAR3      |                                    |       BAR3      |

 * +-----------------+                                    +-----------------+

 * |       BAR4      |                                    |       BAR4      |

 * +-----------------+                                    +-----------------+

 * |       BAR5      |                                    |       BAR5      |

 * +-----------------+                                    +-----------------+

 *   EP CONTROLLER 1                                        EP CONTROLLER 2

 *

 * Allocate the Local Memory mentioned in the above diagram. The size of

 * CONFIG REGION is sizeof(struct epf_ntb_ctrl) and size of SCRATCHPAD REGION

 * is obtained from "spad-count" configfs entry.

 *

 * The size of both config region and scratchpad region has to be aligned,

 * since the scratchpad region will also be mapped as PEER SCRATCHPAD of

 * other host using a separate BAR.

 Check if epc_features is populated incorrectly */

 Align to QWORD or 8 Bytes */

	/*

	 * In order to make sure SPAD offset is aligned to its size,

	 * expand control region size to the size of SPAD if SPAD size

	 * is greater than control region size.

/**

 * epf_ntb_config_spad_bar_alloc_interface() - Allocate memory for config +

 *   scratchpad region for each of PRIMARY and SECONDARY interface

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 *

 * Wrapper for epf_ntb_config_spad_bar_alloc() which allocates memory for

 * config + scratchpad region for a specific interface

/**

 * epf_ntb_free_peer_mem() - Free memory allocated in peers outbound address

 *   space

 * @ntb_epc: EPC associated with one of the HOST which holds peers outbound

 *   address regions

 *

 * +-----------------+    +---->+----------------+-----------+-----------------+

 * |       BAR0      |    |     |   Doorbell 1   +-----------> MSI|X ADDRESS 1 |

 * +-----------------+    |     +----------------+           +-----------------+

 * |       BAR1      |    |     |   Doorbell 2   +---------+ |                 |

 * +-----------------+----+     +----------------+         | |                 |

 * |       BAR2      |          |   Doorbell 3   +-------+ | +-----------------+

 * +-----------------+----+     +----------------+       | +-> MSI|X ADDRESS 2 |

 * |       BAR3      |    |     |   Doorbell 4   +-----+ |   +-----------------+

 * +-----------------+    |     |----------------+     | |   |                 |

 * |       BAR4      |    |     |                |     | |   +-----------------+

 * +-----------------+    |     |      MW1       +---+ | +-->+ MSI|X ADDRESS 3||

 * |       BAR5      |    |     |                |   | |     +-----------------+

 * +-----------------+    +---->-----------------+   | |     |                 |

 *   EP CONTROLLER 1            |                |   | |     +-----------------+

 *                              |                |   | +---->+ MSI|X ADDRESS 4 |

 *                              +----------------+   |       +-----------------+

 *                      (A)      EP CONTROLLER 2     |       |                 |

 *                                 (OB SPACE)        |       |                 |

 *                                                   +------->      MW1        |

 *                                                           |                 |

 *                                                           |                 |

 *                                                   (B)     +-----------------+

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           +-----------------+

 *                                                           PCI Address Space

 *                                                           (Managed by HOST2)

 *

 * Free memory allocated in EP CONTROLLER 2 (OB SPACE) in the above diagram.

 * It'll free Doorbell 1, Doorbell 2, Doorbell 3, Doorbell 4, MW1 (and MW2, MW3,

 * MW4).

/**

 * epf_ntb_db_mw_bar_clear() - Clear doorbell and memory BAR

 * @ntb_epc: EPC associated with one of the HOST which holds peer's outbound

 *   address

 *

 * +-----------------+    +---->+----------------+-----------+-----------------+

 * |       BAR0      |    |     |   Doorbell 1   +-----------> MSI|X ADDRESS 1 |

 * +-----------------+    |     +----------------+           +-----------------+

 * |       BAR1      |    |     |   Doorbell 2   +---------+ |                 |

 * +-----------------+----+     +----------------+         | |                 |

 * |       BAR2      |          |   Doorbell 3   +-------+ | +-----------------+

 * +-----------------+----+     +----------------+       | +-> MSI|X ADDRESS 2 |

 * |       BAR3      |    |     |   Doorbell 4   +-----+ |   +-----------------+

 * +-----------------+    |     |----------------+     | |   |                 |

 * |       BAR4      |    |     |                |     | |   +-----------------+

 * +-----------------+    |     |      MW1       +---+ | +-->+ MSI|X ADDRESS 3||

 * |       BAR5      |    |     |                |   | |     +-----------------+

 * +-----------------+    +---->-----------------+   | |     |                 |

 *   EP CONTROLLER 1            |                |   | |     +-----------------+

 *                              |                |   | +---->+ MSI|X ADDRESS 4 |

 *                              +----------------+   |       +-----------------+

 *                      (A)      EP CONTROLLER 2     |       |                 |

 *                                 (OB SPACE)        |       |                 |

 *                                                   +------->      MW1        |

 *                                                           |                 |

 *                                                           |                 |

 *                                                   (B)     +-----------------+

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           +-----------------+

 *                                                           PCI Address Space

 *                                                           (Managed by HOST2)

 *

 * Clear doorbell and memory BARs (remove inbound ATU configuration). In the above

 * diagram it clears BAR2 TO BAR5 of EP CONTROLLER 1 (Doorbell BAR, MW1 BAR, MW2

 * BAR, MW3 BAR and MW4 BAR).

/**

 * epf_ntb_db_mw_bar_cleanup() - Clear doorbell/memory BAR and free memory

 *   allocated in peers outbound address space

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Wrapper for epf_ntb_db_mw_bar_clear() to clear HOST1's BAR and

 * epf_ntb_free_peer_mem() which frees up HOST2 outbound memory.

/**

 * epf_ntb_configure_interrupt() - Configure MSI/MSI-X capaiblity

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Configure MSI/MSI-X capability for each interface with number of

 * interrupts equal to "db_count" configfs entry.

/**

 * epf_ntb_alloc_peer_mem() - Allocate memory in peer's outbound address space

 * @dev: The PCI device.

 * @ntb_epc: EPC associated with one of the HOST whose BAR holds peer's outbound

 *   address

 * @bar: BAR of @ntb_epc in for which memory has to be allocated (could be

 *   BAR_DB_MW1, BAR_MW2, BAR_MW3, BAR_MW4)

 * @peer_ntb_epc: EPC associated with HOST whose outbound address space is

 *   used by @ntb_epc

 * @size: Size of the address region that has to be allocated in peers OB SPACE

 *

 *

 * +-----------------+    +---->+----------------+-----------+-----------------+

 * |       BAR0      |    |     |   Doorbell 1   +-----------> MSI|X ADDRESS 1 |

 * +-----------------+    |     +----------------+           +-----------------+

 * |       BAR1      |    |     |   Doorbell 2   +---------+ |                 |

 * +-----------------+----+     +----------------+         | |                 |

 * |       BAR2      |          |   Doorbell 3   +-------+ | +-----------------+

 * +-----------------+----+     +----------------+       | +-> MSI|X ADDRESS 2 |

 * |       BAR3      |    |     |   Doorbell 4   +-----+ |   +-----------------+

 * +-----------------+    |     |----------------+     | |   |                 |

 * |       BAR4      |    |     |                |     | |   +-----------------+

 * +-----------------+    |     |      MW1       +---+ | +-->+ MSI|X ADDRESS 3||

 * |       BAR5      |    |     |                |   | |     +-----------------+

 * +-----------------+    +---->-----------------+   | |     |                 |

 *   EP CONTROLLER 1            |                |   | |     +-----------------+

 *                              |                |   | +---->+ MSI|X ADDRESS 4 |

 *                              +----------------+   |       +-----------------+

 *                      (A)      EP CONTROLLER 2     |       |                 |

 *                                 (OB SPACE)        |       |                 |

 *                                                   +------->      MW1        |

 *                                                           |                 |

 *                                                           |                 |

 *                                                   (B)     +-----------------+

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           |                 |

 *                                                           +-----------------+

 *                                                           PCI Address Space

 *                                                           (Managed by HOST2)

 *

 * Allocate memory in OB space of EP CONTROLLER 2 in the above diagram. Allocate

 * for Doorbell 1, Doorbell 2, Doorbell 3, Doorbell 4, MW1 (and MW2, MW3, MW4).

/**

 * epf_ntb_db_mw_bar_init() - Configure Doorbell and Memory window BARs

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Wrapper for epf_ntb_alloc_peer_mem() and pci_epc_set_bar() that allocates

 * memory in OB address space of HOST2 and configures BAR of HOST1

/**

 * epf_ntb_epc_destroy_interface() - Cleanup NTB EPC interface

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Unbind NTB function device from EPC and relinquish reference to pci_epc

 * for each of the interface.

/**

 * epf_ntb_epc_destroy() - Cleanup NTB EPC interface

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 *

 * Wrapper for epf_ntb_epc_destroy_interface() to cleanup all the NTB interfaces

/**

 * epf_ntb_epc_create_interface() - Create and initialize NTB EPC interface

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @epc: struct pci_epc to which a particular NTB interface should be associated

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Allocate memory for NTB EPC interface and initialize it.

/**

 * epf_ntb_epc_create() - Create and initialize NTB EPC interface

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 *

 * Get a reference to EPC device and bind NTB function device to that EPC

 * for each of the interface. It is also a wrapper to

 * epf_ntb_epc_create_interface() to allocate memory for NTB EPC interface

 * and initialize it

/**

 * epf_ntb_init_epc_bar_interface() - Identify BARs to be used for each of

 *   the NTB constructs (scratchpad region, doorbell, memorywindow)

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Identify the free BARs to be used for each of BAR_CONFIG, BAR_PEER_SPAD,

 * BAR_DB_MW1, BAR_MW2, BAR_MW3 and BAR_MW4.

 These are required BARs which are mandatory for NTB functionality */

 These are optional BARs which don't impact NTB functionality */

/**

 * epf_ntb_init_epc_bar() - Identify BARs to be used for each of the NTB

 * constructs (scratchpad region, doorbell, memorywindow)

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 *

 * Wrapper to epf_ntb_init_epc_bar_interface() to identify the free BARs

 * to be used for each of BAR_CONFIG, BAR_PEER_SPAD, BAR_DB_MW1, BAR_MW2,

 * BAR_MW3 and BAR_MW4 for all the interfaces.

/**

 * epf_ntb_epc_init_interface() - Initialize NTB interface

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Wrapper to initialize a particular EPC interface and start the workqueue

 * to check for commands from host. This function will write to the

 * EP controller HW for configuring it.

/**

 * epf_ntb_epc_cleanup_interface() - Cleanup NTB interface

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 * @type: PRIMARY interface or SECONDARY interface

 *

 * Wrapper to cleanup a particular NTB interface.

/**

 * epf_ntb_epc_cleanup() - Cleanup all NTB interfaces

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 *

 * Wrapper to cleanup all NTB interfaces.

/**

 * epf_ntb_epc_init() - Initialize all NTB interfaces

 * @ntb: NTB device that facilitates communication between HOST1 and HOST2

 *

 * Wrapper to initialize all NTB interface and start the workqueue

 * to check for commands from host.

/**

 * epf_ntb_bind() - Initialize endpoint controller to provide NTB functionality

 * @epf: NTB endpoint function device

 *

 * Initialize both the endpoint controllers associated with NTB function device.

 * Invoked when a primary interface or secondary interface is bound to EPC

 * device. This function will succeed only when EPC is bound to both the

 * interfaces.

/**

 * epf_ntb_unbind() - Cleanup the initialization from epf_ntb_bind()

 * @epf: NTB endpoint function device

 *

 * Cleanup the initialization from epf_ntb_bind()

/**

 * epf_ntb_add_cfs() - Add configfs directory specific to NTB

 * @epf: NTB endpoint function device

 * @group: A pointer to the config_group structure referencing a group of

 *	   config_items of a specific type that belong to a specific sub-system.

 *

 * Add configfs directory specific to NTB. This directory will hold

 * NTB specific properties like db_count, spad_count, num_mws etc.,

/**

 * epf_ntb_probe() - Probe NTB function driver

 * @epf: NTB endpoint function device

 *

 * Probe NTB function driver when endpoint function bus detects a NTB

 * endpoint function.

 SPDX-License-Identifier: GPL-2.0

/*

 * Test driver to test endpoint functionality

 *

 * Copyright (C) 2017 Texas Instruments

 * Author: Kishon Vijay Abraham I <kishon@ti.com>

/**

 * pci_epf_test_data_transfer() - Function that uses dmaengine API to transfer

 *				  data between PCIe EP and remote PCIe RC

 * @epf_test: the EPF test device that performs the data transfer operation

 * @dma_dst: The destination address of the data transfer. It can be a physical

 *	     address given by pci_epc_mem_alloc_addr or DMA mapping APIs.

 * @dma_src: The source address of the data transfer. It can be a physical

 *	     address given by pci_epc_mem_alloc_addr or DMA mapping APIs.

 * @len: The size of the data transfer

 *

 * Function that uses dmaengine API to transfer data between PCIe EP and remote

 * PCIe RC. The source and destination address can be a physical address given

 * by pci_epc_mem_alloc_addr or the one obtained using DMA mapping APIs.

 *

 * The function returns '0' on success and negative value on failure.

/**

 * pci_epf_test_init_dma_chan() - Function to initialize EPF test DMA channel

 * @epf_test: the EPF test device that performs data transfer operation

 *

 * Function to initialize EPF test DMA channel.

/**

 * pci_epf_test_clean_dma_chan() - Function to cleanup EPF test DMA channel

 * @epf_test: the EPF test device that performs data transfer operation

 *

 * Helper to cleanup EPF test DMA channel.

 convert both size (stored in 'rate') and time in terms of 'ns' */

 Divide both size (stored in 'rate') and ns by a common factor */

 calculate the rate */

	/*

	 * wait 1ms inorder for the write to complete. Without this delay L3

	 * error in observed in the host system.

		/*

		 * pci_epc_set_bar() sets PCI_BASE_ADDRESS_MEM_TYPE_64

		 * if the specific implementation required a 64-bit BAR,

		 * even if we only requested a 32-bit BAR.

 Align to QWORD or 8 Bytes */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Standard Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>, <kristen.c.accardi@intel.com>

 *

 Global variables */

 register this slot with the hotplug pci core */

/*

 * set_attention_status - Turns the Amber LED for a slot on, off or blink

	/*

	 * It is assumed that AMD GOLAM chips support SHPC but they do not

	 * have SHPC capability.

 Setup the slot information structures */

 end: all zeroes */ }

 SPDX-License-Identifier: GPL-2.0+

/*

 * Compaq Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman <greg@kroah.com>

 * Copyright (C) 2001 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>

 *

 * Jan 12, 2003 -	Added 66/100/133MHz PCI-X support,

 *			Torben Mathiasen <torben.mathiasen@hp.com>

 Global variables */

 = NULL */

 local variables */

/**

 * detect_SMBIOS_pointer - find the System Management BIOS Table in mem region.

 * @begin: begin pointer for region to be scanned.

 * @end: end pointer for region to be scanned.

 *

 * Returns pointer to the head of the SMBIOS tables (or %NULL).

/**

 * init_SERR - Initializes the per slot SERR generation.

 * @ctrl: controller to use

 *

 * For unexpected switch opens

 Loop through slots */

 nice debugging output */

/**

 * get_subsequent_smbios_entry: get the next entry from bios table.

 * @smbios_start: where to start in the SMBIOS table

 * @smbios_table: location of the SMBIOS table

 * @curr: %NULL or pointer to previously returned structure

 *

 * Gets the first entry if previous == NULL;

 * otherwise, returns the next entry.

 * Uses global SMBIOS Table pointer.

 *

 * Returns a pointer to an SMBIOS structure or NULL if none found.

 set p_max to the end of the table */

		/* Look for the double NULL terminator

		 * The first condition is the previous byte

		 * and the second is the curr

/**

 * get_SMBIOS_entry - return the requested SMBIOS entry or %NULL

 * @smbios_start: where to start in the SMBIOS table

 * @smbios_table: location of the SMBIOS table

 * @type: SMBIOS structure type to be returned

 * @previous: %NULL or pointer to previously returned structure

 *

 * Gets the first entry of the specified type if previous == %NULL;

 * Otherwise, returns the next entry of the given type.

 * Uses global SMBIOS Table pointer.

 * Uses get_subsequent_smbios_entry.

 *

 * Returns a pointer to an SMBIOS structure or %NULL if none found.

 Free IRQ associated with hot plug device */

 Unmap the memory */

 Finally reclaim PCI mem */

/**

 * get_slot_mapping - determine logical slot mapping for PCI device

 *

 * Won't work for more than one PCI-PCI bridge in a slot.

 *

 * @bus: pointer to the PCI bus structure

 * @bus_num: bus number of PCI device

 * @dev_num: device number of PCI device

 * @slot: Pointer to u8 where slot number will	be returned

 *

 * Output:	SUCCESS or FAILURE

			/* Did not get a match on the target PCI device. Check

			 * if the current IRQ table entry is a PCI-to-PCI

			 * bridge device.  If so, and it's secondary bus

			 * matches the bus number for the target device, I need

			 * to save the bridge's slot number.  If I can not find

			 * an entry for the target device, I will have to

			 * assume it's on the other side of the bridge, and

			 * assign it the bridge's slot.

 See if bridge's secondary bus matches target bus.

	/* If we got here, we didn't find an entry in the IRQ mapping table for

	 * the target PCI device.  If we did determine that the target device

	 * is on the other side of a PCI-to-PCI bridge, return the slot number

	 * for the bridge.

 Couldn't find an entry in the routing table for this PCI device */

/**

 * cpqhp_set_attention_status - Turns the Amber LED for a slot on or off

 * @ctrl: struct controller to use

 * @func: PCI device/function info

 * @status: LED control flag: 1 = LED on, 0 = LED off

 Wait for exclusive access to hardware */

 Done with exclusive hardware access */

 Wait for SOBS to be unset */

 Done with exclusive hardware access */

/**

 * set_attention_status - Turns the Amber LED for a slot on or off

 * @hotplug_slot: slot to change LED on

 * @status: LED control flag

		/*FIXME: these capabilities aren't used but if they are

		 *	 they need to be correctly implemented

 Check presence */

 Check the switch state */

 Check the slot enable */

 register this slot with the hotplug pci core */

	/* FIXME: We also need to hook the NMI handler eventually.

	 * this also needs to be worked with Christoph

	 * register_NMI_handler();

 Map rom address */

	/* Now, map the int15 entry point if we are on compaq specific

	 * hardware

 Map smbios table entry point structure */

	/* Need to read VID early b/c it's used to differentiate CPQ and INTC

	 * discovery

	/* Check for the proper subsystem IDs

	 * Intel uses a different SSID programming model than Compaq.

	 * For Intel, each SSID bit identifies a PHP capability.

	 * Also Intel HPCs may have RID=0.

	/* TODO: This code can be made to support non-Compaq or Intel

	 * subsystem IDs

	/* Set Vendor ID, so it can be accessed later from other

	 * functions

 CIOBX */

 Original 6500/7000 implementation */

 First Pushbutton implementation */

 Third party (6500/7000) */

 First 66 Mhz implementation */

 First PCI-X implementation, 100MHz */

 Check for speed capability (0=33, 1=66) */

 Check for push button */

 Check for slot switch type (0=mechanical, 1=not mechanical) */

 PHP Status (0=De-feature PHP, 1=Normal operation) */

 PHP supported */

 PHP not supported */

		/* Alternate Base Address Register Interface

		 * (0=not supported, 1=supported)

 PCI Config Space Index (0=not supported, 1=supported) */

 PCI-X support */

 133MHz PCI-X if bit 7 is 1 */

 100MHz PCI-X if bit 7 is 1 and bit 0 is 0, */

 66MHz PCI-X if bit 7 is 1 and bit 0 is 1 */

 Conventional PCI */

 Tell the user that we found one. */

	/* make our own copy of the pci bus structure,

 initialize our threads if they haven't already been started up */

 Check for 66Mhz operation */

	/********************************************************

	 *

	 *              Save configuration headers for this and

	 *              subordinate PCI buses

	 *

 find the physical slot number of the first hot plug slot */

	/* Get slot won't work for devices behind bridges, but

	 * in this case it will always be called for the "base"

	 * bus/dev/func of a slot.

	 * CS: this is leveraging the PCIIRQ routing code from the kernel

 Store PCI Config Space for all devices on this bus */

	/*

	 * Get IO, memory, and IRQ resources for new devices

 The next line is required for cpqhp_find_available_resources */

	/*

	 * Finish setting up the hot plug ctrl device

 Setup the slot information structures */

 Mask all general input interrupts */

 set up the interrupt */

	/* Enable Shift Out interrupt and clear it, also enable SERR on power

	 * fault

 Changed 05/05/97 to clear all interrupts at start */

	/* turn off empty slots here unless command line option "ON" set

	 * Wait for exclusive access to hardware

 find first device number for the ctrl */

 We have to save the presence info for these slots */

 Wait for SOBS to be unset */

 Done with exclusive hardware access */

 Stop the notification mechanism */

 unmap the rom address */

 handle any PCI Hotplug controller */

 no matter who makes it */

 end: all zeroes */ }

 remove:	cpqhpc_remove_one, */

 SPDX-License-Identifier: GPL-2.0+

/*

 * ACPI PCI Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2002 Hiroshi Aono (h-aono@ap.jp.nec.com)

 * Copyright (C) 2002,2003 Takayoshi Kochi (t-kochi@bq.jp.nec.com)

 * Copyright (C) 2002,2003 NEC Corporation

 * Copyright (C) 2003-2005 Matthew Wilcox (willy@infradead.org)

 * Copyright (C) 2003-2005 Hewlett Packard

 *

 * All rights reserved.

 *

 * Send feedback to <kristen.c.accardi@intel.com>

 *

 name size which is used for entries in pcihpfs */

 {_SUN} */

 local variables */

/**

 * acpiphp_register_attention - set attention LED callback

 * @info: must be completely filled with LED callbacks

 *

 * Description: This is used to register a hardware specific ACPI

 * driver that manipulates the attention LED.  All the fields in

 * info must be set.

/**

 * acpiphp_unregister_attention - unset attention LED callback

 * @info: must match the pointer used to register

 *

 * Description: This is used to un-register a hardware specific acpi

 * driver that manipulates the attention LED.  The pointer to the

 * info struct must be the same as the one used to set it.

/**

 * enable_slot - power on and enable a slot

 * @hotplug_slot: slot to enable

 *

 * Actual tasks are done in acpiphp_enable_slot()

 enable the specified slot */

/**

 * disable_slot - disable and power off a slot

 * @hotplug_slot: slot to disable

 *

 * Actual tasks are done in acpiphp_disable_slot()

 disable the specified slot */

/**

 * set_attention_status - set attention LED

 * @hotplug_slot: slot to set attention LED on

 * @status: value to set attention LED to (0 or 1)

 *

 * attention status LED, so we use a callback that

 * was registered with us.  This allows hardware specific

 * ACPI implementations to blink the light for us.

/**

 * get_power_status - get power status of a slot

 * @hotplug_slot: slot to get status

 * @value: pointer to store status

 *

 * Some platforms may not implement _STA method properly.

 * In that case, the value returned may not be reliable.

/**

 * get_attention_status - get attention LED status

 * @hotplug_slot: slot to get status from

 * @value: returns with value of attention LED

 *

 * ACPI doesn't have known method to determine the state

 * of the attention status LED, so we use a callback that

 * was registered with us.  This allows hardware specific

 * ACPI implementations to determine its state.

/**

 * get_latch_status - get latch status of a slot

 * @hotplug_slot: slot to get status

 * @value: pointer to store status

 *

 * ACPI doesn't provide any formal means to access latch status.

 * Instead, we fake latch status from _STA.

/**

 * get_adapter_status - get adapter status of a slot

 * @hotplug_slot: slot to get status

 * @value: pointer to store status

 *

 * ACPI doesn't provide any formal means to access adapter status.

 * Instead, we fake adapter status from _STA.

 callback routine to initialize 'struct slot' for each slot */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Compaq Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001,2003 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>

 *

 SPDX-License-Identifier: GPL-2.0+

/*

 * IBM Hot Plug Controller Driver

 *

 * Written By: Irene Zubarev, IBM Corporation

 *

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001,2002 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <gregkh@us.ibm.com>

 *

/*

 * NOTE..... If BIOS doesn't provide default routing, we assign:

 * 9 for SCSI, 10 for LAN adapters, and 11 for everything else.

 * If adapter is bridged, then we assign 11 to it and devices behind it.

 * We also assign the same irq numbers for multi function devices.

 * These are PIC mode, so shouldn't matter n.e.ways (hopefully)

/*

 * Configures the device to be added (will allocate needed resources if it

 * can), the device can be a bridge or a regular pci device, can also be

 * multi-functional

 *

 * Input: function to be added

 *

 * TO DO:  The error case with Multifunction device or multi function bridge,

 * if there is an error, will need to go through all previous functions and

 * unconfigure....or can add some code into unconfigure_card....

 for multi devices */

 to see if we are able to read from card any device info at all */

	/* We only get bus and device from IRQ routing table.  So at this point,

	 * func->busno is correct, and func->device contains only device (at the 5

	 * highest bits)

 For every function on the card */

 found correct device!!! */

			/* header: x x x x x x x x

			 *         | |___________|=> 1=PPB bridge, 0=normal device, 2=CardBus Bridge

			 *         |_=> 0 = single function device, 1 = multi-function device

 to take revision out, class = class.subclass.prog i/f */

 We need to do this in case some other BARs were properly inserted */

 We need to do this in case some other BARs were properly inserted */

 We need to do this in case some other BARs were properly inserted */

 To indicate to the unconfigure function that this is a PPB */

 This could only happen if kmalloc failed */

 We need to do this in case bridge itself got configured properly, but devices behind it failed */

 To indicate to the unconfigure function that this is a PPB */

 We need to do this in case some other BARs were properly inserted */

 To indicate to the unconfigure function that this is a PPB */

 Again, this case should not happen... For complete paranoia, will need to call remove_bus */

 We need to do this in case some other BARs were properly inserted */

 To indicate to the unconfigure function that this is a PPB */

 end of switch */

 end of valid device */

 end of for */

/*

 * This function configures the pci BARs of a single device.

 * Input: pointer to the pci_func

 * Output: configured PCI, 0, or error

 for 6 BARs */

		/* not sure if i need this.  per scott, said maybe need * something like this

		   if devices don't adhere 100% to the spec, so don't want to write

		   to the reserved bits



		pcibios_read_config_byte(cur_func->busno, cur_func->device,

		PCI_BASE_ADDRESS_0 + 4 * count, &tmp);

		if (tmp & 0x01) // IO

			pcibios_write_config_dword(cur_func->busno, cur_func->device,

			PCI_BASE_ADDRESS_0 + 4 * count, 0xFFFFFFFD);

		else  // Memory

			pcibios_write_config_dword(cur_func->busno, cur_func->device,

			PCI_BASE_ADDRESS_0 + 4 * count, 0xFFFFFFFF);

 This BAR is not implemented */

 This is IO */

 _______________This is for debugging purposes only_____________________ */

 _________________________________________________________________________*/

 This is Memory */

 pfmem */

_______________This is for debugging purposes only______________________________*/

_________________________________________________________________________________*/

 takes up another dword */

 on the 2nd dword, write all 0s, since we can't handle them n.e.ways */

 regular memory */

 _______________________This is for debugging purposes only _______________________*/

 __________________________________________________________________________________*/

 takes up another dword */

 on the 2nd dword, write all 0s, since we can't handle them n.e.ways */

 end of mem */

 end of for */

 To indicate that this is not a PPB */

/******************************************************************************

 * This routine configures a PCI-2-PCI bridge and the functions behind it

 * Parameters: pci_func

 * Returns:

	/* Configuring necessary info for the bridge so that we could see the devices

	 * behind it

	/* _____________________For debugging purposes only __________________________

	pci_bus_config_byte(ibmphp_pci_bus, devfn, PCI_PRIMARY_BUS, &pri_number);

	debug("primary # written into the bridge is %x\n", pri_number);

 in EBDA, only get allocated 1 additional bus # per slot */

	/* __________________For debugging purposes only __________________________________

	pci_bus_read_config_byte(ibmphp_pci_bus, devfn, PCI_SECONDARY_BUS, &sec_number);

	debug("sec_number after write/read is %x\n", sec_number);

	/* __________________For debugging purposes only ____________________________________

	pci_bus_read_config_byte(ibmphp_pci_bus, devfn, PCI_SUBORDINATE_BUS, &sec_number);

	debug("subordinate number after write/read is %x\n", sec_number);

	/* !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

	   !!!!!!!!!!!!!!!NEED TO ADD!!!  FAST BACK-TO-BACK ENABLE!!!!!!!!!!!!!!!!!!!!

 First we need to allocate mem/io for the bridge itself in case it needs it */

 for 2 BARs */

 This BAR is not implemented */

  tmp_bar = bar[count];

 This is IO */

 This is Memory */

 pfmem */

 takes up another dword */

 on the 2nd dword, write all 0s, since we can't handle them n.e.ways */

 regular memory */

 takes up another dword */

 on the 2nd dword, write all 0s, since we can't handle them n.e.ways */

 end of mem */

 end of for  */

 Now need to see how much space the devices behind the bridge needed */

 for 2 BARs */

		/* If on bootup, there was a bridged card in this slot,

		 * then card was removed and ibmphp got unloaded and loaded

		 * back again, there's no way for us to remove the bus

		 * struct, so no need to kmalloc, can use existing node

			/* _______________This is for debugging purposes only ____________________

			pci_bus_read_config_byte(ibmphp_pci_bus, devfn, PCI_IO_BASE, &temp);

			debug("io_base = %x\n", (temp & PCI_IO_RANGE_TYPE_MASK) << 8);

			pci_bus_read_config_byte(ibmphp_pci_bus, devfn, PCI_IO_LIMIT, &temp);

			debug("io_limit = %x\n", (temp & PCI_IO_RANGE_TYPE_MASK) << 8);

 since can't support n.e.ways */

			/* ____________________This is for debugging purposes only ________________________

			pci_bus_read_config_word(ibmphp_pci_bus, devfn, PCI_MEMORY_BASE, &temp);

			debug("mem_base = %x\n", (temp & PCI_MEMORY_RANGE_TYPE_MASK) << 16);

			pci_bus_read_config_word(ibmphp_pci_bus, devfn, PCI_MEMORY_LIMIT, &temp);

			debug("mem_limit = %x\n", (temp & PCI_MEMORY_RANGE_TYPE_MASK) << 16);

			/* __________________________This is for debugging purposes only _______________________

			pci_bus_read_config_word(ibmphp_pci_bus, devfn, PCI_PREF_MEMORY_BASE, &temp);

			debug("pfmem_base = %x", (temp & PCI_MEMORY_RANGE_TYPE_MASK) << 16);

			pci_bus_read_config_word(ibmphp_pci_bus, devfn, PCI_PREF_MEMORY_LIMIT, &temp);

			debug("pfmem_limit = %x\n", (temp & PCI_MEMORY_RANGE_TYPE_MASK) << 16);

 since can't support n.e.ways */

		/*

		pci_bus_write_config_byte(ibmphp_pci_bus, devfn, PCI_BRIDGE_CONTROL, ctrl);

		pci_bus_write_config_byte(ibmphp_pci_bus, devfn, PCI_BRIDGE_CONTROL, PCI_BRIDGE_CTL_PARITY);

		pci_bus_write_config_byte(ibmphp_pci_bus, devfn, PCI_BRIDGE_CONTROL, PCI_BRIDGE_CTL_SERR);

 For unconfiguring, to indicate it's PPB */

 for 2 BARs */

/*****************************************************************************

 * This function adds up the amount of resources needed behind the PPB bridge

 * and passes it to the configure_bridge function

 * Input: bridge function

 * Output: amount of resources needed

this is to see if there are any devices behind the bridge */

 found correct device!!! */

 to take revision out, class = class.subclass.prog i/f */

 for 6 BARs */

					/*

					pci_bus_read_config_byte(ibmphp_pci_bus, devfn, address[count], &tmp);

					if (tmp & 0x01) // IO

						pci_bus_write_config_dword(ibmphp_pci_bus, devfn, address[count], 0xFFFFFFFD);

					else // MEMORY

						pci_bus_write_config_dword(ibmphp_pci_bus, devfn, address[count], 0xFFFFFFFF);

 This BAR is not implemented */

tmp_bar = bar[count];

 This is IO */

 This is Memory */

 pfmem */

 takes up another dword */

 regular memory */

 takes up another dword */

 end for */

 end if (valid) */

 end for */

 end for */

/* The following 3 unconfigure_boot_ routines deal with the case when we had the card

 * upon bootup in the system, since we don't allocate func to such case, we need to read

 * the start addresses from pci config space and then find the corresponding entries in

 * our resource lists.  The functions return either 0, -ENODEV, or -1 (general failure)

 * Change: we also call these functions even if we configured the card ourselves (i.e., not

 * the bootup case), since it should work same way

 for 6 BARs */

 We can do this here, b/c by that time the device driver of the card has been stopped */

 This BAR is not implemented */

 This is IO */

 This is needed b/c of the old I/O restrictions in the BIOS */

 ????????? DO WE NEED TO WRITE ANYTHING INTO THE PCI CONFIG SPACE BACK ?????????? */

 This is Memory */

 pfmem */

 regular memory */

 takes up another dword */

 end of mem */

 end of for */

 for 2 BARs */

 This BAR is not implemented */

 This is IO */

 ????????? DO WE NEED TO WRITE ANYTHING INTO THE PCI CONFIG SPACE BACK ?????????? */

 This is Memory */

 pfmem */

 regular memory */

 takes up another dword */

 end of mem */

 end of for */

 To see if we are ever able to find valid device and read it */

 For every function on the card */

 found correct device!!! */

			/* header: x x x x x x x x

			 *         | |___________|=> 1=PPB bridge, 0=normal device, 2=CardBus Bridge

			 *         |_=> 0 = single function device, 1 = multi-function device

 to take revision out, class = class.subclass.prog i/f */

 end of switch */

 end of valid device */

 end of for */

/*

 * free the resources of the card (multi, single, or bridged)

 * Parameters: slot, flag to say if this is for removing entire module or just

 * unconfiguring the device

 * TO DO:  will probably need to add some code in case there was some resource,

 * to remove it... this is from when we have errors in the configure_card...

 *			!!!!!!!!!!!!!!!!!!!!!!!!!FOR BUSES!!!!!!!!!!!!

 * Returns: 0, -1, -ENODEV

 Need to unconfigure the card */

 In all other cases, will still need to get rid of func structure if it exists */

 TO DO: WILL MOST LIKELY NEED TO GET RID OF THE BUS STRUCTURE FROM RESOURCES AS WELL */

 in other words, it's a PPB */

/*

 * add a new bus resulting from hot-plugging a PPB bridge with devices

 *

 * Input: bus and the amount of resources needed (we know we can assign those,

 *        since they've been checked already

 * Output: bus added to the correct spot

 *         0, -1, error

 Trying to find the parent bus number */

/*

 * find the 1st available bus number for PPB to set as its secondary bus

 * Parameters: bus_number of the primary bus

 * Returns: bus_number of the secondary bus or 0xff in case of failure

	/* either there is no such bus number, or there are no ranges, which

	 * can only happen if we removed the bridged device in previous load

	 * of the driver, and now only have the skeleton bus struct

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Express Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>, <kristen.c.accardi@intel.com>

 *

/* The following routines constitute the bulk of the

   hotplug controller logic

	/*

	 * Turn off slot, turn on attention indicator, turn off power

	 * indicator

		/*

		 * After turning power off, we must wait for at least 1 second

		 * before taking any action that relies on power having been

		 * removed from the slot/adapter.

/**

 * board_added - Called after a board has been added to the system.

 * @ctrl: PCIe hotplug controller where board is added

 *

 * Turns power on for the board.

 * Configures board.

 Power on slot */

 Check link training status */

 Check for a power fault */

/**

 * remove_board - Turn off slot and Power Indicator

 * @ctrl: PCIe hotplug controller where board is being removed

 * @safe_removal: whether the board is safely removed (versus surprise removed)

		/*

		 * After turning power off, we must wait for at least 1 second

		 * before taking any action that relies on power having been

		 * removed from the slot/adapter.

 Ignore link or presence changes caused by power off */

 blink power indicator and turn off attention */

		/*

		 * Cancel if we are still blinking; this means that we

		 * press the attention again before the 5 sec. limit

		 * expires to cancel hot-add or hot-remove

	/*

	 * If the slot is on and presence or link has changed, turn it off.

	 * Even if it's occupied again, we cannot assume the card is the same.

 Turn the slot on if it's occupied or link is up */

 may be blinking */

		/*

		 * The IRQ thread becomes a no-op if the user pulls out the

		 * card before the thread wakes up, so initialize to -ENODEV.

 SPDX-License-Identifier: GPL-2.0+

/*

 * RPA Virtual I/O device functions

 * Copyright (C) 2004 Linda Xie <lxie@us.ibm.com>

 *

 * All rights reserved.

 *

 * Send feedback to <lxie@us.ibm.com>

 *

 free up the memory used by a slot */

 should not try to register the same slot twice */

 add slot to our internal list */

 SPDX-License-Identifier: GPL-2.0+

/*

 * CompactPCI Hot Plug Driver

 *

 * Copyright (C) 2002,2005 SOMA Networks, Inc.

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <scottm@somanetworks.com>

 local variables */

 Unconfigure device */

 Clear EXT (by setting it) */

	/*

	 * Create a structure for each slot, and register that slot

	 * with the pci_hotplug subsystem.

 Add slot to our internal list */

 This is the interrupt mode interrupt handler */

 Check to see if it was our interrupt */

 Disable ENUM interrupt */

 Trigger processing by the event thread */

/*

 * According to PICMG 2.1 R2.0, section 6.3.2, upon

 * initialization, the system driver shall clear the

 * INS bits of the cold-inserted devices.

			/*

			 * Some broken hardware (e.g. PLX 9054AB) asserts

			 * ENUM# twice...

 Process insertion */

 GSM, debug */

 Configure device */

 GSM, debug */

 GSM, debug */

 Process extraction request */

 GSM, debug */

				/*

				 * Hmmm, we're likely hosed at this point, should we

				 * bother trying to tell the driver or not?

 This is the interrupt mode worker thread body */

 Give userspace a chance to handle extraction */

 Re-enable ENUM# interrupt */

 This is the polling mode worker thread body */

 Give userspace a chance to handle extraction */

	/*

	 * Unregister all of our slots with the pci_hotplug subsystem,

	 * and free up all memory that we had allocated.

 Start enum interrupt processing */

 Stop enum interrupt processing */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Standard Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>, <kristen.c.accardi@intel.com>

 *

 Attention Button Change */

	/*

	 *  Button pressed - See if need to TAKE ACTION!!!

 Switch Change */

		/*

		 * Switch opened

		/*

		 *  Switch closed

 Presence Change */

	/*

	 * Save the presence state

		/*

		 * Card Present

		/*

		 * Not Present

 Power fault */

		/*

		 * Power fault Cleared

		/*

		 *   Power fault

 set power fault status for this board */

/* The following routines constitute the bulk of the

   hotplug controller logic

	/*

	 * If other slots on the same bus are occupied, we cannot

	 * change the bus speed.

/**

 * board_added - Called after a board has been added to the system.

 * @p_slot: target &slot

 *

 * Turns power on for the board.

 * Configures board.

 Power on slot without connecting to bus */

 turn on board, blink green LED, turn off Amber LED */

 Check if there are other slots or devices on the same bus */

 turn on board, blink green LED, turn off Amber LED */

 Wait for ~1 second */

 Check for a power fault */

 power fault occurred, but it was benign */

 turn off slot, turn on Amber LED, turn off Green LED */

/**

 * remove_board - Turns off slot and LEDs

 * @p_slot: target &slot

 Change status to shutdown */

 turn off slot, turn on Amber LED, turn off Green LED */

/**

 * shpchp_pushbutton_thread - handle pushbutton events

 * @work: &struct work_struct to be handled

 *

 * Scheduled procedure to handle blocking stuff for the pushbuttons.

 * Handles all pending events and exits.

/*

 * Note: This function must be called with slot->lock held

 blink green LED and turn off amber */

		/*

		 * Cancel if we are still blinking; this means that we

		 * press the attention again before the 5 sec. limit

		 * expires to cancel hot-add or hot-remove

		/*

		 * Ignore if the slot is on power-on or power-off state;

		 * this means that the previous attention button action

		 * to hot-add or hot-remove is undergoing

 Check to see if (latch closed, card present, power off) */

 We have to save the presence info for these slots */

 handle AMD POGO errata; this must be done before enable  */

 handle AMD POGO errata; this must be done after enable  */

 Check to see if (latch closed, card present, power on) */

 SPDX-License-Identifier: GPL-2.0+

/*

 * IBM Hot Plug Controller Driver

 *

 * Written By: Tong Yu, IBM Corporation

 *

 * Copyright (C) 2001,2003 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001-2003 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <gregkh@us.ibm.com>

 *

/*

 * POST builds data blocks(in this data block definition, a char-1

 * byte, short(or word)-2 byte, long(dword)-4 byte) in the Extended

 * BIOS Data Area which describe the configuration of the hot-plug

 * controllers and resources used by the PCI Hot-Plug devices.

 *

 * This file walks EBDA, maps data block from physical addr,

 * reconstruct linked lists about all system resource(MEM, PFM, IO)

 * already assigned by POST, as well as linked lists about hot plug

 * controllers (ctlr#, slot#, bus&slot features...)

 Global lists */

 Local variables */

 Local functions */

 Make sure what we read is still in the mapped section */

 offset of next blk */

 0 indicate it's last blk */

 this blk id */

 check if it is hot swap block or rio block */

 found hs table */

 hot swap sub blk */

 next sub blk */

 sub blk id */

 rc sub blk signature  */

  offset of RSRC_CONTROLLER blk */

 re sub blk */

 FIXME: rc is never used/checked */

 next sub blk */

 sub blk id */

 signature of re */

 offset of RSRC_ENTRIES blk */

 found rio table, blk_id == 0x4752 */

/*

 * map info of scalability details and rio details from physical address

 we do concern about rio details

		debug("rio_node_id: %x\nbbar: %x\nrio_type: %x\nowner_id: %x\nport0_node: %x\nport0_port: %x\nport1_node: %x\nport1_port: %x\nfirst_slot_num: %x\nstatus: %x\n", rio_detail_ptr->rio_node_id, rio_detail_ptr->bbar, rio_detail_ptr->rio_type, rio_detail_ptr->owner_id, rio_detail_ptr->port0_node_connect, rio_detail_ptr->port0_port_connect, rio_detail_ptr->port1_node_connect, rio_detail_ptr->port1_port_connect, rio_detail_ptr->first_slot_num, rio_detail_ptr->status);

create linked list of chassis

create linked list of expansion box

 not in my concern

/*

 * reorganizing linked list of chassis

/*

 * reorganizing linked list of expansion box

/* Since we don't know the max slot number per each chassis, hence go

 * through the list of all chassis to find out the range

 * Arguments: slot_num, 1st slot number of the chassis we think we are on,

 * var (0 = chassis, 1 = expansion box)

check to see if this slot_num belongs to expansion box

check to see if this slot_num belongs to chassis

/* This routine will find out how many slots are in the chassis, so that

 * the slot numbers for rxe100 would start from 1, and not from 7, or 6 etc

 rxe = 1, chassis = 0 */

 either chassis or rxe # */

 it is RXE */

 if both NULL and we DO have correct RIO table in BIOS */

/*

 * map info (ctlr-id, slot count, slot#.. bus count, bus#, ctlr type...) of

 * each hpc from physical address to a list of hot plug controllers based on

 * hpc descriptors.

 offset of slot structure */

 offset of bus */

 offset of ctlr_type */

 init hpc structure */

 init slot structure, fetch slot, bus, cap... */

 create bus_info lined list --- if only one slot per bus: slot_min = slot_max

 end of creating the bus_info linked list

 init bus structure */

reorganize chassis' linked list

 register slots with hpc core as well as create linked list of ibm slot

 end of registering ibm slot with hotplug core

 each hpc  */

/*

 * map info (bus, devfun, start addr, end addr..) of i/o, memory,

 * pfm from the physical addr to a list of resource.

/* To find:

 *	- the smallest slot number

 *	- the largest slot number

 *	- the total number of the slots based on each bus

 *	  (if only one slot per bus slot_min = slot_max )

/*  Finding relative bus number, in order to map corresponding

 *  bus register

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Express Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>, <kristen.c.accardi@intel.com>

 *

 * Authors:

 *   Dan Zink <dan.zink@compaq.com>

 *   Greg Kroah-Hartman <greg@kroah.com>

 *   Dely Sy <dely.l.sy@intel.com>"

 Global variables */

/*

 * not really modular, but the easiest way to keep compat with existing

 * bootargs behaviour is to continue using module_param here.

 Setup hotplug slot ops */

 register this slot with the hotplug pci core */

/*

 * set_attention_status - Turns the Attention Indicator on, off or blinking

/**

 * pciehp_check_presence() - synthesize event if presence has changed

 * @ctrl: controller to check

 *

 * On probe and resume, an explicit presence check is necessary to bring up an

 * occupied slot or bring down an unoccupied slot.  This can't be triggered by

 * events in the Slot Status register, they may be stale and are therefore

 * cleared.  Secondly, sending an interrupt for "events that occur while

 * interrupt generation is disabled [when] interrupt generation is subsequently

 * enabled" is optional per PCIe r4.0, sec 6.7.3.4.

 If this is not a "hotplug" service, we have no business here. */

 Can happen if we run out of bus numbers during probe */

 Setup the slot information structures */

 Enable events after we have setup the data structures */

 Publish to user space */

	/*

	 * Disable hotplug interrupt so that it does not trigger

	 * immediately when the downstream link goes down.

	/*

	 * If the port is already runtime suspended we can keep it that

	 * way.

 pci_restore_state() just wrote to the Slot Control register */

 clear spurious events from rediscovery of inserted card */

 pci_restore_state() just wrote to the Slot Control register */

 clear spurious events from rediscovery of inserted card */

 PM */

 PM */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Standard PCI Hot Plug Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>,<kristen.c.accardi@intel.com>

 *

 Slot Available Register I field definition */

 Slot Available Register II field definition */

 Slot Configuration */

/*

 * Interrupt Locator Register definitions

/*

 * Controller SERR-INT Register

/*

 * Logical Slot Register definitions

/*

 * SHPC Command Code definitions

 *

 *     Slot Operation				00h - 3Fh

 *     Set Bus Segment Speed/Mode A		40h - 47h

 *     Power-Only All Slots			48h

 *     Enable All Slots				49h

 *     Set Bus Segment Speed/Mode B (PI=2)	50h - 5Fh

 *     Reserved Command Codes			60h - BFh

 *     Vendor Specific Commands			C0h - FFh

 Slot Operation */

 Set Bus Segment Speed/Mode A */

 Power-Only All Slots */

 Enable All Slots */

 Set Bus Segment Speed/Mode B */

/*

 * SHPC controller command error code

/*

 * For accessing SHPC Working Register Set via PCI Configuration Space

 Field Offset in Logical Slot Register - byte boundary */

/*

 * This is the interrupt polling timeout function.

 Poll for interrupt events.  regs == NULL => polling */

 default polling interval is 2 sec */

/*

 * This function starts the interrupt polling timer.

 Clamp to sane value */

/*

 * Returns 1 if SHPC finishes executing a command within 1 sec,

 * otherwise returns 0.

 Check every 0.1 sec for a total of 1 sec */

 After 1 sec and the controller is still busy */

	/* To make sure the Controller Busy bit is 0 before we send out the

	 * command.

	/*

	 * Wait for command completion.

 On */

 Blink */

 Off */

 Reserved */

 Powered only */

 Enabled */

 Disabled */

 Reserved */

 0 -> close; 1 -> open */

 Note: Logic 0 => fault */

 OFF */

 ON */

 BLINK */

	/*

	 * Mask event interrupts and SERRs of all slots

	/*

	 * Mask SERR and System Interrupt generation

 Slot - Enable, Power Indicator - Blink, Attention Indicator - Off */

 Slot - Disable, Power Indicator - Off, Attention Indicator - On */

 Check to see if it was our interrupt */

		/*

		 * Mask Global Interrupt Mask - see implementation

		 * note on p. 139 of SHPC spec rev 1.0

		/*

		 * Command Complete Interrupt Pending

		 * RO only - clear by writing 1 to the Command Completion

		 * Detect bit in Controller SERR-INT register

 To find out which slot has interrupt pending */

 Clear all slot events */

 Unmask Global Interrupt Mask */

 pci_dev of the P2P bridge */

 amd shpc driver doesn't use Base Offset; assume 0 */

 Setup wait queue */

 Return PCI Controller Info */

 Mask Global Interrupt Mask & Command Complete Interrupt Mask */

	/* Mask the MRL sensor SERR Mask of individual slot in

	 * Slot SERR-INT Mask & clear all the existing event if any

 Install interrupt polling timer. Start with 10 sec delay */

 Installs the interrupt handler */

	/*

	 * Unmask all event interrupts of all slots

 Unmask all general input interrupts and SERR */

 We end up here for the many possible ways to fail this API.  */

 SPDX-License-Identifier: GPL-2.0+

/*

 * cpcihp_zt5550.c

 *

 * Intel/Ziatech ZT5550 CompactPCI Host Controller driver

 *

 * Copyright 2002 SOMA Networks, Inc.

 * Copyright 2001 Intel San Luis Obispo

 * Copyright 2000,2001 MontaVista Software Inc.

 *

 * Send feedback to <scottm@somanetworks.com>

 IRQF_SHARED */

 local variables */

 Primary cPCI bus bridge device */

 Host controller device */

 Host controller register addresses */

 Since we know that no boards exist with two HC chips, treat it as an error */

	/*

	 * Disable host control, fault and serial interrupts

	/*

	 * Disable timer0, timer1 and ENUM interrupts

 Look for first device matching cPCI bus's bridge vendor and device IDs */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Hot Plug Controller Driver for RPA-compliant PPC64 platform.

 * Copyright (C) 2003 Linda Xie <lxie@us.ibm.com>

 *

 * All rights reserved.

 *

 * Send feedback to <lxie@us.ibm.com>

 *

 for eeh_add_device() */

 rtas_call */

 for pci_controller */

 for pci_add_new_bus */

 and pci_do_scan_bus */

/**

 * set_attention_status - set attention LED

 * @hotplug_slot: target &hotplug_slot

 * @value: LED control value

 *

 * echo 0 > attention -- set LED OFF

 * echo 1 > attention -- set LED ON

 * echo 2 > attention -- set LED ID(identify, light is blinking)

/**

 * get_power_status - get power status of a slot

 * @hotplug_slot: slot to get status

 * @value: pointer to store status

/**

 * get_attention_status - get attention LED status

 * @hotplug_slot: slot to get status

 * @value: pointer to store status

 speed for case 1-6 */

 Slot does not have dynamically-removable children */

 &drc_names[1] contains NULL terminated slot names */

 &drc_types[1] contains NULL terminated slot types */

/* Verify the existence of 'drc_name' and/or 'drc_type' within the

 * current node.  First obtain its my-drc-index property.  Next,

 * obtain the DRC info from its parent.  Use the my-drc-index for

 * correlation, and obtain/validate the requested properties.

 Iterate through parent properties, looking for my-drc-index */

 Should now know end of current entry */

 Found it */

 Node isn't DLPAR/hotplug capable */

 PCI Hotplug nodes have an integer for drc_type */

/**

 * is_php_dn() - return 1 if this is a hotpluggable pci slot, else 0

 * @dn: target &device_node

 * @indexes: passed to get_children_props()

 * @names: passed to get_children_props()

 * @types: returned from get_children_props()

 * @power_domains:

 *

 * This routine will return true only if the device node is

 * a hotpluggable slot. This routine will return false

 * for built-in pci slots (even when the built-in slots are

 * dlparable.)

 If this is not a hotplug slot, return without doing anything. */

 register PCI devices */

 XXX FIXME: reports a failure only if last entry in loop failed */

/**

 * rpaphp_add_slot -- declare a hotplug slot to the hotplug subsystem.

 * @dn: device node of slot

 *

 * This subroutine will register a hotpluggable slot with the

 * PCI hotplug infrastructure. This routine is typically called

 * during boot time, if the hotplug slots are present at boot time,

 * or is called later, by the dlpar add code, if the slot is

 * being dynamically added during runtime.

 *

 * If the device node points at an embedded (built-in) slot, this

 * routine will just return without doing anything, since embedded

 * slots cannot be hotplugged.

 *

 * To remove a slot, it suffices to call rpaphp_deregister_slot().

	/*

	 * Unregister all of our slots with the pci_hotplug subsystem,

	 * and free up all memory that we had allocated.

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI HotPlug Controller Core

 *

 * Copyright (C) 2001-2002 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001-2002 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <kristen.c.accardi@intel.com>

 *

 * Authors:

 *   Greg Kroah-Hartman <greg@kroah.com>

 *   Scott Murray <scottm@somanetworks.com>

 try_module_get & module_put */

 local variables */

 Weee, fun with macros... */

 Create symbolic link to the hotplug driver module */

/**

 * __pci_hp_register - register a hotplug_slot with the PCI hotplug subsystem

 * @bus: bus this slot is on

 * @slot: pointer to the &struct hotplug_slot to register

 * @devnr: device number

 * @name: name registered with kobject core

 * @owner: caller module owner

 * @mod_name: caller module name

 *

 * Prepares a hotplug slot for in-kernel use and immediately publishes it to

 * user space in one go.  Drivers may alternatively carry out the two steps

 * separately by invoking pci_hp_initialize() and pci_hp_add().

 *

 * Returns 0 if successful, anything else for an error.

/**

 * __pci_hp_initialize - prepare hotplug slot for in-kernel use

 * @slot: pointer to the &struct hotplug_slot to initialize

 * @bus: bus this slot is on

 * @devnr: slot number

 * @name: name registered with kobject core

 * @owner: caller module owner

 * @mod_name: caller module name

 *

 * Allocate and fill in a PCI slot for use by a hotplug driver.  Once this has

 * been called, the driver may invoke hotplug_slot_name() to get the slot's

 * unique name.  The driver must be prepared to handle a ->reset_slot callback

 * from this point on.

 *

 * Returns 0 on success or a negative int on error.

	/*

	 * No problems if we call this interface from both ACPI_PCI_SLOT

	 * driver and call it here again. If we've already created the

	 * pci_slot, the interface will simply bump the refcount.

/**

 * pci_hp_add - publish hotplug slot to user space

 * @slot: pointer to the &struct hotplug_slot to publish

 *

 * Make a hotplug slot's sysfs interface available and inform user space of its

 * addition by sending a uevent.  The hotplug driver must be prepared to handle

 * all &struct hotplug_slot_ops callbacks from this point on.

 *

 * Returns 0 on success or a negative int on error.

/**

 * pci_hp_deregister - deregister a hotplug_slot with the PCI hotplug subsystem

 * @slot: pointer to the &struct hotplug_slot to deregister

 *

 * The @slot must have been registered with the pci hotplug subsystem

 * previously with a call to pci_hp_register().

 *

 * Returns 0 if successful, anything else for an error.

/**

 * pci_hp_del - unpublish hotplug slot from user space

 * @slot: pointer to the &struct hotplug_slot to unpublish

 *

 * Remove a hotplug slot's sysfs interface.

 *

 * Returns 0 on success or a negative int on error.

/**

 * pci_hp_destroy - remove hotplug slot from in-kernel use

 * @slot: pointer to the &struct hotplug_slot to destroy

 *

 * Destroy a PCI slot used by a hotplug driver.  Once this has been called,

 * the driver may no longer invoke hotplug_slot_name() to get the slot's

 * unique name.  The driver no longer needs to handle a ->reset_slot callback

 * from this point on.

 *

 * Returns 0 on success or a negative int on error.

/*

 * not really modular, but the easiest way to keep compat with existing

 * bootargs behaviour is to continue using module_param here.

 SPDX-License-Identifier: GPL-2.0+

/*

 * ACPI PCI HotPlug glue functions to ACPI CA subsystem

 *

 * Copyright (C) 2002,2003 Takayoshi Kochi (t-kochi@bq.jp.nec.com)

 * Copyright (C) 2002 Hiroshi Aono (h-aono@ap.jp.nec.com)

 * Copyright (C) 2002,2003 NEC Corporation

 * Copyright (C) 2003-2005 Matthew Wilcox (willy@infradead.org)

 * Copyright (C) 2003-2005 Hewlett Packard

 * Copyright (C) 2005 Rajesh Shah (rajesh.shah@intel.com)

 * Copyright (C) 2005 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <kristen.c.accardi@intel.com>

 *

/*

 * Lifetime rules for pci_dev:

 *  - The one in acpiphp_bridge has its refcount elevated by pci_get_slot()

 *    when the bridge is scanned and it loses a refcount when the bridge

 *    is removed.

 *  - When a P2P bridge is present, we elevate the refcount on the subordinate

 *    bus. It loses the refcount when the driver unloads.

/**

 * acpiphp_init_context - Create hotplug context and grab a reference to it.

 * @adev: ACPI device object to create the context for.

 *

 * Call under acpi_hp_context_lock.

/**

 * acpiphp_get_context - Get hotplug context and grab a reference to it.

 * @adev: ACPI device object to get the context for.

 *

 * Call under acpi_hp_context_lock.

/**

 * acpiphp_put_context - Drop a reference to ACPI hotplug context.

 * @context: ACPI hotplug context to drop a reference to.

 *

 * The context object is removed if there are no more references to it.

 *

 * Call under acpi_hp_context_lock.

 Root bridges will not have hotplug context. */

 Release the reference taken by acpiphp_enumerate_slots(). */

/**

 * acpiphp_post_dock_fixup - Post-dock fixups for PCI devices.

 * @adev: ACPI device object corresponding to a PCI device.

 *

 * TBD - figure out a way to only call fixups for systems that require them.

	/* fixup bad _DCK function that rewrites

	 * secondary bridge on slot

/**

 * acpiphp_add_context - Add ACPIPHP context to an ACPI device object.

 * @handle: ACPI handle of the object to add a context to.

 * @lvl: Not used.

 * @data: The object's parent ACPIPHP bridge.

 * @rv: Not used.

	/*

	 * If this is a dock device, its _EJ0 should be executed by the dock

	 * notify handler after calling _DCK.

 search for objects that share the same slot */

	/*

	 * Expose slots to user space for functions that have _EJ0 or _RMV or

	 * are located in dock stations.  Do not expose them for devices handled

	 * by the native PCIe hotplug (PCIeHP) or standard PCI hotplug

	 * (SHPCHP), because that code is supposed to expose slots to user

	 * space in those cases.

 Even if the slot registration fails, we can still use it. */

/**

 * acpiphp_max_busnr - return the highest reserved bus number under the given bus.

 * @bus: bus to start search with

	/*

	 * pci_bus_max_busnr will return the highest

	 * reserved busnr for all these children.

	 * that is equivalent to the bus->subordinate

	 * value.  We don't want to use the parent's

	 * bus->subordinate value because it could have

	 * padding in it.

 _REG is optional, we don't care about if there is failure */

 quirk, or pcie could set it already */

 Scan already configured non-hotplug bridges */

 Scan non-hotplug bridges that need to be reconfigured */

/**

 * enable_slot - enable, configure a slot

 * @slot: slot to be enabled

 * @bridge: true if enable is for the whole bridge (not a single slot)

 *

 * This function should be called per *physical slot*,

 * not per each slot object in ACPI namespace.

		/*

		 * If native hotplug is used, it will take care of hotplug

		 * slot management and resource allocation for hotplug

		 * bridges. However, ACPI hotplug may still be used for

		 * non-hotplug bridges to bring in additional devices such

		 * as a Thunderbolt host controller.

 Assume that newly added devices are powered on already. */

			/* Do not set SLOT_ENABLED flag if some funcs

/**

 * disable_slot - disable a slot

 * @slot: ACPI PHP slot

	/*

	 * enable_slot() enumerates all functions in this device via

	 * pci_scan_slot(), whether they have associated ACPI hotplug

	 * methods (_EJ0, etc.) or not.  Therefore, we remove all functions

	 * here.

/**

 * get_slot_status - get ACPI slot status

 * @slot: ACPI PHP slot

 *

 * If a slot has _STA for each function and if any one of them

 * returned non-zero status, return it.

 *

 * If a slot doesn't have _STA and if any one of its functions'

 * configuration space is configured, return 0x0f as a _STA.

 *

 * Otherwise return 0.

		/*

		 * Check for the slot itself since it may be that the

		 * ACPI slot is a device below PCIe upstream port so in

		 * that case it may not even be reachable yet.

	/*

	 * ACPI spec says that _STA may return bit 0 clear with bit 3 set

	 * if the device is valid but does not require a device driver to be

	 * loaded (Section 6.3.7 of ACPI 5.0A).

/**

 * trim_stale_devices - remove PCI devices that are not responding.

 * @dev: PCI device to start walking the hierarchy from.

 The device is a bridge. so check the bus below it. */

/**

 * acpiphp_check_bridge - re-enumerate devices

 * @bridge: where to begin re-enumeration

 *

 * Iterate over all slots under this bridge and make sure that if a

 * card is present they are enabled, and if not they are disabled.

 Bail out if the bridge is going away. */

 do nothing */

 remove stale devices if any */

 configure all functions */

/*

 * Remove devices for which we could not assign resources, call

 * arch specific code to fix-up the bus

				/* Could not assign a required resources

/*

 * ACPI event handlers

 bus re-enumerate */

 device check */

			/*

			 * Check if anything has changed in the slot and rescan

			 * from the parent if that's the case.

 request device eject */

/**

 * acpiphp_enumerate_slots - Enumerate PCI slots for a given bus.

 * @bus: PCI bus to enumerate the slots for.

 *

 * A "slot" is an object associated with a PCI device number.  All functions

 * (PCI devices) with the same bus and device number belong to the same slot.

	/*

	 * Grab a ref to the subordinate PCI bus in case the bus is

	 * removed via PCI core logical hotplug. The ref pins the bus

	 * (which we access during module unload).

		/*

		 * This bridge should have been registered as a hotplug function

		 * under its parent, so the context should be there, unless the

		 * parent is going to be handled by pciehp, in which case this

		 * bridge is not interesting to us either.

 Get a reference to the parent bridge. */

 Must be added to the list prior to calling acpiphp_add_context(). */

 register all slot objects under this bridge */

/**

 * acpiphp_remove_slots - Remove slot objects associated with a given bus.

 * @bus: PCI bus to remove the slot objects for.

/**

 * acpiphp_enable_slot - power on slot

 * @slot: ACPI PHP slot

 configure all functions */

/**

 * acpiphp_disable_and_eject_slot - power off and eject slot

 * @slot: ACPI PHP slot

 unconfigure all functions */

	/*

	 * Acquire acpi_scan_lock to ensure that the execution of _EJ0 in

	 * acpiphp_disable_and_eject_slot() will be synchronized properly.

/*

 * slot enabled:  1

 * slot disabled: 0

/*

 * latch   open:  1

 * latch closed:  0

/*

 * adapter presence : 1

 *          absence : 0

 SPDX-License-Identifier: GPL-2.0+

/*

 * Interface for Dynamic Logical Partitioning of I/O Slots on

 * RPA-compliant PPC64 platform.

 *

 * John Rose <johnrose@austin.ibm.com>

 * Linda Xie <lxie@us.ibm.com>

 *

 * October 2003

 *

 * Copyright (C) 2003 IBM.

 Find dlpar-capable pci node that contains the specified name and type */

 Returns a device_node with its reference count incremented */

/**

 * find_php_slot - return hotplug slot structure for device node

 * @dn: target &device_node

 *

 * This routine will return the hotplug slot structure

 * for a given device node. Note that built-in PCI slots

 * may be dlpar-able, but not hot-pluggable, so this routine

 * will return NULL for built-in PCI slots.

 Add EADS device to PHB bus, adding new entry to bus->devices */

 Scan below the new bridge */

 Map IO space for child bus, which may or may not succeed */

	/* Finish adding it : resource allocation, adding devices, etc...

	 * Note that we need to perform the finish pass on the -parent-

	 * bus of the EADS bridge so the bridge device itself gets

	 * properly added

 Add pci bus */

 Confirm new bridge dev was created */

 Add hotplug slot */

 If pci slot is hotpluggable, use hotplug to remove it */

 PHB already exists */

/**

 * dlpar_add_slot - DLPAR add an I/O Slot

 * @drc_name: drc-name of newly added slot

 *

 * Make the hotplug module and the kernel aware of a newly added I/O Slot.

 * Return Codes:

 * 0			Success

 * -ENODEV		Not a valid drc_name

 * -EINVAL		Slot already added

 * -ERESTARTSYS		Signalled before obtaining lock

 * -EIO			Internal PCI Error

 Find newly added node */

/**

 * dlpar_remove_vio_slot - DLPAR remove a virtual I/O Slot

 * @drc_name: drc-name of newly added slot

 * @dn: &device_node

 *

 * Remove the kernel and hotplug representations of an I/O Slot.

 * Return Codes:

 * 0			Success

 * -EINVAL		Vio dev doesn't exist

/**

 * dlpar_remove_pci_slot - DLPAR remove a PCI I/O Slot

 * @drc_name: drc-name of newly added slot

 * @dn: &device_node

 *

 * Remove the kernel and hotplug representations of a PCI I/O Slot.

 * Return Codes:

 * 0			Success

 * -ENODEV		Not a valid drc_name

 * -EIO			Internal PCI Error

 Remove all devices below slot */

 Unmap PCI IO space */

 Remove the EADS bridge device itself */

/**

 * dlpar_remove_slot - DLPAR remove an I/O Slot

 * @drc_name: drc-name of newly added slot

 *

 * Remove the kernel and hotplug representations of an I/O Slot.

 * Return Codes:

 * 0			Success

 * -ENODEV		Not a valid drc_name

 * -EINVAL		Slot already removed

 * -ERESTARTSYS		Signalled before obtaining lock

 * -EIO			Internal Error

 SPDX-License-Identifier: GPL-2.0+

/*

 * IBM Hot Plug Controller Driver

 *

 * Written By: Irene Zubarev, IBM Corporation

 *

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001,2002 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <gregkh@us.ibm.com>

 *

 for testing */

 need to insert our range */

/* Notes:

 * 1. The ranges are ordered.  The buses are not ordered.  (First come)

 *

 * 2. If cannot allocate out of PFMem range, allocate from Mem ranges.  PFmemFromMem

 * are not sorted. (no need since use mem node). To not change the entire code, we

 * also add mem node whenever this case happens so as not to change

 * ibmphp_check_mem_resource etc(and since it really is taking Mem resource)

/*****************************************************************************

 * This is the Resource Management initialization function.  It will go through

 * the Resource list taken from EBDA and fill in this module's data structures

 *

 * THIS IS NOT TAKING INTO CONSIDERATION IO RESTRICTIONS OF PRIMARY BUSES,

 * SINCE WE'RE GOING TO ASSUME FOR NOW WE DON'T HAVE THOSE ON OUR BUSES FOR NOW

 *

 * Input: ptr to the head of the resource list from EBDA

 * Output: 0, -1 or error codes

 EBDA still lists non PCI devices, so ignore... */

 continue;

 this is a primary bus resource */

 memory */

 no bus structure exists in place yet */

 found our bus */

 went through all the buses and didn't find ours, need to create a new bus node */

 prefetchable memory */

 no bus structure exists in place yet */

 found our bus */

 went through all the buses and didn't find ours, need to create a new bus node */

 IO */

 no bus structure exists in place yet */

 went through all the buses and didn't find ours, need to create a new bus node */

				;	/* type is reserved  WHAT TO DO IN THIS CASE???

 regular pci device resource */

 Memory resource */

				/*

				 * if it didn't find the bus, means PCI dev

				 * came b4 the Primary Bus info, so need to

				 * create a bus rangeno becomes a problem...

				 * assign a -1 and then update once the range

				 * actually appears...

 PFMemory resource */

 IO resource */

				/*

				 * if it didn't find the bus, means PCI dev

				 * came b4 the Primary Bus info, so need to

				 * create a bus rangeno becomes a problem...

				 * Can assign a -1 and then update once the

				 * range actually appears...

 This is to get info about PPB resources, since EBDA doesn't put this info into the primary bus info */

 This is to align ranges (so no -1) */

/********************************************************************************

 * This function adds a range into a sorted list of ranges per bus for a particular

 * range type, it then calls another routine to update the range numbers on the

 * pci devices' resources for the appropriate resource

 *

 * Input: type of the resource, range to add, current bus

 * Output: 0 or -1, bus and range ptrs

 our range will go at the beginning of the list */

 our range will go at the end of the list */

 the range is in the middle */

/*******************************************************************************

 * This routine goes through the list of resources of type 'type' and updates

 * the range numbers that they correspond to.  It was called from add_bus_range fnc

 *

 * Input: bus, type of the resource, the rangeno starting from which to update

 end of list indicator */

 found the range */

/*****************************************************************************

 * This routine reassigns the range numbers to the resources that had a -1

 * This case can happen only if upon initialization, resources taken by pci dev

 * appear in EBDA before the resources allocated for that bus, since we don't

 * know the range, we assign -1, and this routine is called after a new range

 * is assigned to see the resources with unknown range belong to the added range

 *

 * Input: current bus

 * Output: none, list of resources for that bus are fixed if can be

/*******************************************************************************

 * This routine adds a resource to the list of resources to the appropriate bus

 * based on their resource type and sorted by their starting addresses.  It assigns

 * the ptrs to next and nextRange if needed.

 *

 * Input: resource ptr

 * Output: ptrs assigned (to the node)

 * 0 or -1

 didn't find a bus, something's wrong!!! */

 Normal case */

	/* !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

	 * this is again the case of rangeno = -1

	 * !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

 no first{IO,Mem,Pfmem} on the bus, 1st IO/Mem/Pfmem resource ever */

 at the end of the resource list */

 in the same range */

 the last resource in this range */

 at the beginning or middle of the range */

 this is the case where it is 1st occurrence of the range */

 at the beginning of the resource list */

 in the middle of the resource list */

/****************************************************************************

 * This routine will remove the resource from the list of resources

 *

 * Input: io, mem, and/or pfmem resource to be deleted

 * Output: modified resource list

 *        0 or error code

			/*

			 * case where pfmem might be in the PFMemFromMem list

			 * so will also need to remove the corresponding mem

			 * entry

 first device to be deleted */

/*****************************************************************************

 * This routine will check to make sure the io/mem/pfmem->len that the device asked for

 * can fit w/i our list of available IO/MEM/PFMEM resources.  If cannot, returns -EINVAL,

 * otherwise, returns 0

 *

 * Input: resource

 * Output: the correct start and end address are inputted into the resource node,

 *        0 or -EINVAL

 this is to make sure start address is divisible by the length needed */

 The rules for bridges are different, 4K divisible for IO, 1M for (pf)mem*/

 didn't find a bus, something's wrong!!! */

	/* This is a quick fix to not mess up with the code very much.  i.e.,

 found our range */

 first time in the loop */

 just perfect, starting address is divisible by length */

 Needs adjusting */

 To restore the balance */

 last device on the range */

 just perfect, starting address is divisible by length */

 Needs adjusting */

 To restore the balance */

 1st device on this range */

 just perfect, starting address is divisible by length */

 Needs adjusting */

 To restore the balance */

 in the same range */

 just perfect, starting address's divisible by length */

 Needs adjusting */

 To restore the balance */

 end if (res_prev) */

 end of while */

 1st device ever */

 need to find appropriate range */

 just perfect, starting address's divisible by length */

 Needs adjusting */

 To restore the balance */

 end of while */

 have gone through the list of devices and ranges and haven't found n.e.thing */

 To restore the balance */

 if there're more ranges out there to check */

 just perfect, starting address's divisible by length */

 Needs adjusting */

 To restore the balance */

 end of while */

 have gone through the list of devices and ranges and haven't found n.e.thing */

 To restore the balance */

 no more ranges to check on */

 To restore the balance */

 have gone through the list of devices and haven't found n.e.thing */

 end if (!res_cur) */

/********************************************************************************

 * This routine is called from remove_card if the card contained PPB.

 * It will remove all the resources on the bus as well as the bus itself

 * Input: Bus

 * Output: 0, -ENODEV

/******************************************************************************

 * This routine deletes the ranges from a given bus, and the entries from the

 * parent's bus in the resources

 * Input: current bus, previous bus

 * Output: 0, -EINVAL

/*

 * find the resource node in the bus

 * Input: Resource needed, start address of the resource, type of resource

/***********************************************************************

 * This routine will free the resource structures used by the

 * system.  It is called from cleanup routine for the module

 * Parameters: none

 * Returns: none

/*********************************************************************************

 * This function will go over the PFmem resources to check if the EBDA allocated

 * pfmem out of memory buckets of the bus.  If so, it will change the range numbers

 * and a flag to indicate that this resource is out of memory. It will also move the

 * Pfmem out of the pfmem resource list to the PFMemFromMem list, and will create

 * a new Mem node

 * This routine is called right after initialization

					/* we don't need to sort PFMemFromMem since we're using mem node for

					   all the real work anyways, so just insert at the beginning of the

					   list

 end for pfmem */

 end if */

 end list_for_each bus */

/* This routine just goes through the buses to see if the bus already exists.

 * It is called from ibmphp_find_sec_number, to find out a secondary bus number for

 * bridged cards

 * Parameters: bus_number

 * Returns: Bus pointer or NULL

/* This routine will read the windows for any PPB we have and update the

 * range info for the secondary bus, and will also input this info into

 * primary bus, since BIOS doesn't. This is for PPB that are in the system

 * on bootup.  For bridged cards that were added during previous load of the

 * driver, only the ranges and the bus structure are added, the devices are

 * added from NVRAM

 * Input: primary busno

 * Returns: none

 * Note: this function doesn't take into account IO restrictions etc,

 *	 so will only work for bridges with no video/ISA devices behind them It

 *	 also will not work for onboard PPBs that can have more than 1 *bus

 *	 behind them All these are TO DO.

 *	 Also need to add more error checkings... (from fnc returns etc)

 found correct device!!! */

						/* We assume here that only 1 bus behind the bridge

						   TO DO: add functionality for several:

						   temp = secondary;

						   while (temp < subordinate) {

						   ...

						   temp++;

						   }

 this bus structure doesn't exist yet, PPB was configured during previous loading of ibmphp */

 the rest will be populated during NVRAM call */

 1st IO Range on the bus */

 1st Mem Range on the bus */

 1st PFMem Range on the bus */

 end of switch */

 end if vendor */

 end for function */

 end for device */

 SPDX-License-Identifier: GPL-2.0+

/*

 * IBM Hot Plug Controller Driver

 *

 * Written By: Jyoti Shah, IBM Corporation

 *

 * Copyright (C) 2001-2003 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <gregkh@us.ibm.com>

 *                  <jshah@us.ibm.com>

 *

----------------------------------------------------------------------------

 timeout values

----------------------------------------------------------------------------

 give HPC 60 sec to finish cmd

 give HPC 60 sec to finish cmd

 seconds

 poll HPC every 2 seconds

 poll latch 5 times, then poll slots

----------------------------------------------------------------------------

 Winnipeg Architected Register Offsets

----------------------------------------------------------------------------

 I2C Message Buffer Low

 I2C Master Operation Setup Reg

 I2C Master Control Register

 I2C Parameter Register

 I2C Status Register

----------------------------------------------------------------------------

 Winnipeg Store Type commands (Add this commands to the register offset)

----------------------------------------------------------------------------

 I2C AND operation

 I2C OR operation

----------------------------------------------------------------------------

 Command set for I2C Master Operation Setup Register

----------------------------------------------------------------------------

 read,bytes,I2C shifted,index

 write,bytes,I2C shifted,index

----------------------------------------------------------------------------

 bit masks for I2C Master Control Register

----------------------------------------------------------------------------

 Start the Operation

----------------------------------------------------------------------------



----------------------------------------------------------------------------

 size of linear address interval

----------------------------------------------------------------------------

 command index

----------------------------------------------------------------------------

 index - 1st slot for ctlr

 index - ctlr

 index - 1st ext slot for ctlr

 index - 1st bus for ctlr

----------------------------------------------------------------------------

 macro utilities

----------------------------------------------------------------------------

 if bits 20,22,25,26,27,29,30 are OFF return 1

----------------------------------------------------------------------------

 global variables

----------------------------------------------------------------------------

 lock access to HPC

 lock all operations and

 access to data structures

 make sure polling thread goes away

----------------------------------------------------------------------------

 local function prototypes

----------------------------------------------------------------------------

----------------------------------------------------------------------------

/*----------------------------------------------------------------------

* Name:    i2c_ctrl_read

*

* Action:  read from HPC over I2C

*

 base addr + offset

 data to/from WPG LOHI format

 actual data HILO format

--------------------------------------------------------------------

 READ - step 1

 read at address, byte length, I2C address (shifted), index

 or read direct, byte length, index

 fill in I2C address

 fill in index

 fill in index

 swap data before writing

--------------------------------------------------------------------

 READ - step 2 : clear the message buffer

--------------------------------------------------------------------

 READ - step 3 : issue start operation, I2C master control bit 30:ON

                 2020 : [20] OR operation at [20] offset 0x20

--------------------------------------------------------------------

 READ - step 4 : wait until start operation bit clears

--------------------------------------------------------------------

 READ - step 5 : read I2C status register

--------------------------------------------------------------------

 READ - step 6 : get DATA

/*----------------------------------------------------------------------

* Name:    i2c_ctrl_write

*

* Action:  write to HPC over I2C

*

* Return   0 or error codes

 base addr + offset

 data to/from WPG LOHI format

 actual data HILO format

--------------------------------------------------------------------

 WRITE - step 1

 write at address, byte length, I2C address (shifted), index

 or write direct, byte length, index

 fill in I2C address

 fill in index

 fill in index

 swap data before writing

--------------------------------------------------------------------

 WRITE - step 2 : clear the message buffer

--------------------------------------------------------------------

 WRITE - step 3 : issue start operation,I2C master control bit 30:ON

                 2020 : [20] OR operation at [20] offset 0x20

--------------------------------------------------------------------

 WRITE - step 4 : wait until start operation bit clears

--------------------------------------------------------------------

 WRITE - step 5 : read I2C status register

------------------------------------------------------------

  Read from ISA type HPC

------------------------------------------------------------

--------------------------------------------------------------

 Write to ISA type HPC

--------------------------------------------------------------

/*----------------------------------------------------------------------

* Name:    hpc_writecmdtoindex()

*

* Action:  convert a write command to proper index within a controller

*

* Return   index, HPC_ERROR

 0x00.N.15

 0x06.N.15

 0x07.N.15

 0x08.N.15

 0x01.N.15

 0x11.N.15

 0x12.N.15

 0x02.Y.0-14

 0x03.Y.0-14

 0x04.N.0-14

 0x05.N.0-14

 0x13.N.0-14

/*----------------------------------------------------------------------

* Name:    hpc_readcmdtoindex()

*

* Action:  convert a read command to proper index within a controller

*

* Return   index, HPC_ERROR

/*----------------------------------------------------------------------

* Name:    HPCreadslot()

*

* Action:  issue a READ command to HPC

*

* Input:   pslot   - cannot be NULL for READ_ALLSTAT

*          pstatus - can be NULL for READ_ALLSTAT

*

* Return   0 or error codes

--------------------------------------------------------------------

 map physical address to logical address

--------------------------------------------------------------------

--------------------------------------------------------------------

 check controller status before reading

--------------------------------------------------------------------

 update the slot structure

 DO NOT update the slot structure

 DO NOT update the slot structure

 DO NOT update the slot structure

 DO NOT update the slot structure

 Not used

--------------------------------------------------------------------

 cleanup

--------------------------------------------------------------------

 remove physical to logical address mapping

/*----------------------------------------------------------------------

* Name:    ibmphp_hpc_writeslot()

*

* Action: issue a WRITE command to HPC

--------------------------------------------------------------------

 map physical address to logical address

--------------------------------------------------------------------

--------------------------------------------------------------------

 check controller status before writing

--------------------------------------------------------------------

--------------------------------------------------------------------

 check controller is still not working on the command

--------------------------------------------------------------------

 cleanup

 remove physical to logical address mapping

/*----------------------------------------------------------------------

* Name:    get_hpc_access()

*

* Action: make sure only one process can access HPC at one time

/*----------------------------------------------------------------------

* Name:    free_hpc_access()

/*----------------------------------------------------------------------

* Name:    ibmphp_lock_operations()

*

* Action: make sure only one process can change the data structure

/*----------------------------------------------------------------------

* Name:    ibmphp_unlock_operations()

/*----------------------------------------------------------------------

* Name:    poll_hpc()

 try to get the lock to do some kind of hardware access */

 make a copy of the old status

 don't sleep with a lock on the hardware */

 give up the hardware semaphore */

 sleep for a short time just for good measure */

/*----------------------------------------------------------------------

* Name:    process_changeinstatus

*

* Action:  compare old and new slot status, process the change in status

*

* Input:   pointer to slot struct, old slot struct

*

* Return   0 or error codes

* Value:

*

* Side

* Effects: None.

*

* Notes:

 bit 0 - HPC_SLOT_POWER

 bit 1 - HPC_SLOT_CONNECT

 ignore

 bit 2 - HPC_SLOT_ATTN

 bit 3 - HPC_SLOT_PRSNT2

 bit 4 - HPC_SLOT_PRSNT1

 bit 5 - HPC_SLOT_PWRGD

 OFF -> ON: ignore, ON -> OFF: disable slot

 bit 6 - HPC_SLOT_BUS_SPEED

 ignore

 bit 7 - HPC_SLOT_LATCH

 OPEN -> CLOSE

 power goes on and off after closing latch

 check again to make sure power is still ON

 overwrite power in pslot to OFF

 CLOSE -> OPEN

 else - ignore

 bit 4 - HPC_SLOT_BLINK_ATTN

/*----------------------------------------------------------------------

* Name:    process_changeinlatch

*

* Action:  compare old and new latch reg status, process the change

*

* Input:   old and current latch register status

*

* Return   0 or error codes

* Value:

 bit 0 reserved, 0 is LSB, check bit 1-6 for 6 slots

/*----------------------------------------------------------------------

* Name:    ibmphp_hpc_start_poll_thread

*

* Action:  start polling thread

/*----------------------------------------------------------------------

* Name:    ibmphp_hpc_stop_poll_thread

*

* Action:  stop polling thread and cleanup

 wait for poll thread to exit

 cleanup

/*----------------------------------------------------------------------

* Name:    hpc_wait_ctlr_notworking

*

* Action:  wait until the controller is in a not working state

*

* Return   0, HPC_ERROR

* Value:

 SPDX-License-Identifier: GPL-2.0+

/*

 * IBM Hot Plug Controller Driver

 *

 * Written By: Chuck Cole, Jyoti Shah, Tong Yu, Irene Zubarev, IBM Corporation

 *

 * Copyright (C) 2001,2003 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001-2003 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <gregkh@us.ibm.com>

 *

 for struct irq_routing_table */

static int irqs[16];    /* PIC mode IRQs we're using so far (in case MPS

/*

static int get_max_adapter_speed_1 (struct hotplug_slot *, u8 *, u8);



static inline int get_max_adapter_speed (struct hotplug_slot *hs, u8 *value)

{

	return get_max_adapter_speed_1 (hs, value, 1);

}

 sometimes the hot-pluggable slots start with 4 (not always from 1) */

/* This routine will put the correct slot->device information per slot.  It's

 * called from initialization of the slot structures. It will also assign

 * interrupt numbers per each slot.

 * Parameters: struct slot

 * Returns 0 or errors

 For ServeRAID cards, and some 66 PCI */

 avoid compiler warning */

 Note (will need to change): there would be soon 256, 512 also */

/*

static int get_max_adapter_speed_1(struct hotplug_slot *hotplug_slot, u8 *value, u8 flag)

{

	int rc = -ENODEV;

	struct slot *pslot;

	struct slot myslot;



	debug("get_max_adapter_speed_1 - Entry hotplug_slot[%lx] pvalue[%lx]\n",

						(ulong)hotplug_slot, (ulong) value);



	if (flag)

		ibmphp_lock_operations();



	if (hotplug_slot && value) {

		pslot = hotplug_slot->private;

		if (pslot) {

			memcpy(&myslot, pslot, sizeof(struct slot));

			rc = ibmphp_hpc_readslot(pslot, READ_SLOTSTATUS,

						&(myslot.status));



			if (!(SLOT_LATCH (myslot.status)) &&

					(SLOT_PRESENT (myslot.status))) {

				rc = ibmphp_hpc_readslot(pslot,

						READ_EXTSLOTSTATUS,

						&(myslot.ext_status));

				if (!rc)

					*value = SLOT_SPEED(myslot.ext_status);

			} else

				*value = MAX_ADAPTER_NONE;

		}

	}



	if (flag)

		ibmphp_unlock_operations();



	debug("get_max_adapter_speed_1 - Exit rc[%d] value[%x]\n", rc, *value);

	return rc;

}



static int get_bus_name(struct hotplug_slot *hotplug_slot, char *value)

{

	int rc = -ENODEV;

	struct slot *pslot = NULL;



	debug("get_bus_name - Entry hotplug_slot[%lx]\n", (ulong)hotplug_slot);



	ibmphp_lock_operations();



	if (hotplug_slot) {

		pslot = hotplug_slot->private;

		if (pslot) {

			rc = 0;

			snprintf(value, 100, "Bus %x", pslot->bus);

		}

	} else

		rc = -ENODEV;



	ibmphp_unlock_operations();

	debug("get_bus_name - Exit rc[%d] value[%x]\n", rc, *value);

	return rc;

}

/****************************************************************************

 * This routine will initialize the ops data structure used in the validate

 * function. It will also power off empty slots that are powered on since BIOS

 * leaves those on, albeit disconnected

	/*		retval = slot_update(&slot_cur);

	 *		if (retval)

	 *			return retval;

	 *		ibmphp_update_slot_info(slot_cur);

/* This operation will check whether the slot is within the bounds and

 * the operation is valid to perform on that slot

 * Parameters: slot, operation

 * Returns: 0 or error codes

/****************************************************************************

 * This routine is for updating the data structures in the hotplug core

 * Parameters: struct slot

 * Returns: 0 or error

 To do: bus_names

/******************************************************************************

 * This function will return the pci_func, given bus and devfunc, or NULL.  It

 * is called from visit routines

/*************************************************************

 * This routine frees up memory used by struct slot, including

 * the pointers to pci_func, bus, hotplug_slot, controller,

 * and deregistering from the hotplug core

		/*

		 * We don't want to actually remove the resources,

		 * since ibmphp_free_resources() will do just that.

/*

 * The following function is to fix kernel bug regarding

 * getting bus entries, here we manually add those primary

 * bus entries to kernel bus structure whenever apply

	int flag = 0;	/* this is to make sure we don't double scan the bus,

/*******************************************************

 * Returns whether the bus is empty or not

/***********************************************************

 * If the HPC permits and the bus currently empty, tries to set the

 * bus speed and mode at the maximum card and bus capability

 * Parameters: slot

 * Returns: bus is set (0) or error code

					/* if max slot/bus capability is 66 pci

					and there's no bus mode mismatch, then

 This is to take care of the bug in CIOBX chip */

	/* This is for x440, once Brandon fixes the firmware,

/* This routine checks the bus limitations that the slot is on from the BIOS.

 * This is used in deciding whether or not to power up the slot.

 * (electrical/spec limitations. For example, >1 133 MHz or >2 66 PCI cards on

 * same bus)

 * Parameters: slot

 * Returns: 0 = no limitations, -EINVAL = exceeded limitations on the bus

/* This routine will power on the slot, configure the device(s) and find the

 * drivers for them.

 * Parameters: hotplug_slot

 * Returns: 0 or failure codes

-----------------debugging------------------------------*/

----------------------------------------------------------*/

 need to turn off before on, otherwise, blinking overwrites */

 Check to see the error of why it failed */

-----------------------debugging---------------------------*/

----------------------------------------------------------*/

	/* Don't think this case will happen after above checks...

 do update_slot_info here? */

		/* true because don't need to actually deallocate resources,

 need to turn off if was blinking b4 */

 need to turn off if was blinking b4 */

/**************************************************************

* HOT REMOVING ADAPTER CARD                                   *

* INPUT: POINTER TO THE HOTPLUG SLOT STRUCTURE                *

* OUTPUT: SUCCESS 0 ; FAILURE: UNCONFIGURE , VALIDATE         *

*		DISABLE POWER ,                               *

 checking if powered off already & valid slot # */

 We need this for functions that were there on bootup */

	/*

	 * If we got here from latch suddenly opening on operating card or

	 * a power fault, there's no power to the card, so cannot

	 * read from it to determine what resources it occupied.  This operation

	 * is forbidden anyhow.  The best we can do is remove it from kernel

  Need to turn off if was blinking b4 */

/*	.get_max_adapter_speed =	get_max_adapter_speed,

	.get_bus_name_status =		get_bus_name,

 SPDX-License-Identifier: GPL-2.0+

/*

 * ACPI PCI Hot Plug IBM Extension

 *

 * Copyright (C) 2004 Vernon Mauery <vernux@us.ibm.com>

 * Copyright (C) 2004 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <vernux@us.ibm.com>

 *

 these are the names for the IBM ACPI pseudo-device */

/* union apci_descriptor - allows access to the

 * various device descriptors that are embedded in the

 * aPCI table

/* struct notification - keeps info about the device

 * that cause the ACPI notification event

/**

 * ibm_slot_from_id - workaround for bad ibm hardware

 * @id: the slot number that linux refers to the slot by

 *

 * Description: This method returns the aCPI slot descriptor

 * corresponding to the Linux slot number.  This descriptor

 * has info about the aPCI slot id and attention status.

 * This descriptor must be freed using kfree when done.

/**

 * ibm_set_attention_status - callback method to set the attention LED

 * @slot: the hotplug_slot to work with

 * @status: what to set the LED to (0 or 1)

 *

 * Description: This method is registered with the acpiphp module as a

 * callback to do the device specific task of setting the LED status.

/**

 * ibm_get_attention_status - callback method to get attention LED status

 * @slot: the hotplug_slot to work with

 * @status: returns what the LED is set to (0 or 1)

 *

 * Description: This method is registered with the acpiphp module as a

 * callback to do the device specific task of getting the LED status.

 *

 * Because there is no direct method of getting the LED status directly

 * from an ACPI call, we read the aPCI table and parse out our

 * slot descriptor to read the status from that.

/**

 * ibm_handle_events - listens for ACPI events for the IBM37D0 device

 * @handle: an ACPI handle to the device that caused the event

 * @event: the event info (device specific)

 * @context: passed context (our notification struct)

 *

 * Description: This method is registered as a callback with the ACPI

 * subsystem it is called when this device has an event to notify the OS of.

 *

 * The events actually come from the device as two events that get

 * synthesized into one event with data by this function.  The event

 * ID comes first and then the slot number that caused it.  We report

 * this as one event to the OS.

 *

 * From section 5.6.2.2 of the ACPI 2.0 spec, I understand that the OSPM will

 * only re-enable the interrupt that causes this event AFTER this method

 * has returned, thereby enforcing serial access for the notification struct.

/**

 * ibm_get_table_from_acpi - reads the APLS buffer from ACPI

 * @bufp: address to pointer to allocate for the table

 *

 * Description: This method reads the APLS buffer in from ACPI and

 * stores the "stripped" table into a single buffer

 * it allocates and passes the address back in bufp.

 *

 * If NULL is passed in as buffer, this method only calculates

 * the size of the table and returns that without filling

 * in the buffer.

 *

 * Returns < 0 on error or the size of the table on success.

/**

 * ibm_read_apci_table - callback for the sysfs apci_table file

 * @filp: the open sysfs file

 * @kobj: the kobject this binary attribute is a part of

 * @bin_attr: struct bin_attribute for this file

 * @buffer: the kernel space buffer to fill

 * @pos: the offset into the file

 * @size: the number of bytes requested

 *

 * Description: Gets registered with sysfs as the reader callback

 * to be executed when /sys/bus/pci/slots/apci_table gets read.

 *

 * Since we don't get notified on open and close for this file,

 * things get really tricky here...

 * our solution is to only allow reading the table in all at once.

/**

 * ibm_find_acpi_device - callback to find our ACPI device

 * @handle: the ACPI handle of the device we are inspecting

 * @lvl: depth into the namespace tree

 * @context: a pointer to our handle to fill when we find the device

 * @rv: a return value to fill if desired

 *

 * Description: Used as a callback when calling acpi_walk_namespace

 * to find our device.  When this method returns non-zero

 * acpi_walk_namespace quits its search and returns our value.

		/* returning non-zero causes the search to stop

		 * and returns this value to the caller of

		 * acpi_walk_namespace, but it also causes some warnings

		 * in the acpi debug code to print...

 remove the /sys entries */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Compaq Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>

 *

 eax */

 ax */

 al */

 ah */

 see below */

 if the reg. is a pointer, how much data */

 lock for ordering int15_bios_call() */

/* This is a series of function that deals with

 * setting & getting the hotplug resource table in some environment variable.

/*

 * We really shouldn't be doing this unless there is a _very_ good reason to!!!

 * greg k-h

/*

 * check_for_compaq_ROM

 *

 * this routine verifies that the ROM OEM string is 'COMPAQ'

 *

 * returns 0 for non-Compaq ROM, 1 for Compaq ROM

/*

 * load_HRT

 *

 * Read the hot plug Resource Table from NVRAM

 Now load the EV */

	/* We're maintaining the resource lists so write FF to invalidate old

	 * info

/*

 * store_HRT

 *

 * Save the hot plug Resource Table in NVRAM

 The revision of this structure */

 The number of controllers */

 The bus number */

 The device Number */

 The function Number */

 Skip the number of available entries */

 Figure out memory Available */

 base */

 length */

 Fill in the number of entries */

 Figure out prefetchable memory Available */

 base */

 length */

 Fill in the number of entries */

 Figure out IO Available */

 base */

 length */

 Fill in the number of entries */

 Figure out bus Available */

 base */

 length */

 Fill in the number of entries */

 Now store the EV */

 Read the resource list information in from NVRAM */

 If we saved information in NVRAM, use it now */

	/* The following code is for systems where version 1.0 of this

	 * driver has been loaded, but doesn't support the hardware.

	 * In that case, the driver would incorrectly store something

	 * in NVRAM.

 Skip forward to the next entry */

		/* If all of the following fail, we don't have any resources for

		 * hot plug add

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Express Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>, <kristen.c.accardi@intel.com>

 *

/**

 * pciehp_configure_device() - enumerate PCI devices below a hotplug bridge

 * @ctrl: PCIe hotplug controller

 *

 * Enumerate PCI devices below a hotplug bridge and add them to the system.

 * Return 0 on success, %-EEXIST if the devices are already enumerated or

 * %-ENODEV if enumeration failed.

		/*

		 * The device is already there. Either configured by the

		 * boot firmware or a previous hotplug event.

/**

 * pciehp_unconfigure_device() - remove PCI devices below a hotplug bridge

 * @ctrl: PCIe hotplug controller

 * @presence: whether the card is still present in the slot;

 *	true for safe removal via sysfs or an Attention Button press,

 *	false for surprise removal

 *

 * Unbind PCI devices below a hotplug bridge from their drivers and remove

 * them from the system.  Safely removed devices are quiesced.  Surprise

 * removed devices are marked as such to prevent further accesses.

	/*

	 * Stopping an SR-IOV PF device removes all the associated VFs,

	 * which will update the bus->devices list and confuse the

	 * iterator.  Therefore, iterate in reverse so we remove the VFs

	 * first, then the PF.  We do the same in pci_stop_bus_device().

		/*

		 * Ensure that no new Requests will be generated from

		 * the device.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Common ACPI functions for hot plug platforms

 *

 * Copyright (C) 2006 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <kristen.c.accardi@intel.com>

/* acpi_run_oshp - get control of hotplug from the firmware

 *

 * @handle - the handle of the hotplug controller.

 run OSHP */

/**

 * acpi_get_hp_hw_control_from_firmware

 * @pdev: the pci_dev of the bridge that has a hotplug controller

 *

 * Attempt to take hotplug control from firmware.

	/*

	 * If there's no ACPI host bridge (i.e., ACPI support is compiled

	 * into the kernel but the hardware platform doesn't support ACPI),

	 * there's nothing to do here.

	/*

	 * If _OSC exists, it determines whether we're allowed to manage

	 * the SHPC.  We executed it while enumerating the host bridge.

	/*

	 * In the absence of _OSC, we're always allowed to manage the SHPC.

	 * However, if an OSHP method is present, we must execute it so the

	 * firmware can transfer control to the OS, e.g., direct interrupts

	 * to the OS instead of to the firmware.

	 *

	 * N.B. The PCI Firmware Spec (r3.2, sec 4.8) does not endorse

	 * searching up the ACPI hierarchy, so the loops below are suspect.

		/*

		 * This hotplug controller was not listed in the ACPI name

		 * space at all. Try to get ACPI handle of parent PCI bus.

/**

 * acpi_pci_check_ejectable - check if handle is ejectable ACPI PCI slot

 * @pbus: the PCI bus of the PCI slot corresponding to 'handle'

 * @handle: ACPI handle to check

 *

 * Return 1 if handle is ejectable PCI slot, 0 otherwise.

/**

 * acpi_pci_detect_ejectable - check if the PCI bus has ejectable slots

 * @handle: handle of the PCI bus to scan

 *

 * Returns 1 if the PCI bus has ACPI based ejectable slots, 0 otherwise.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Standard Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>, <kristen.c.accardi@intel.com>

 *

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Hotplug Driver for PowerPC PowerNV platform.

 *

 * Copyright Gavin Shan, IBM Corporation 2016.

/*

 * Remove pdn for all children of the indicated device node.

 * The function should remove pdn in a depth-first manner.

/*

 * Detach all child nodes of the indicated device nodes. The

 * function should handle device nodes in depth-first manner.

 *

 * We should not invoke of_node_release() as the memory for

 * individual device node is part of large memory block. The

 * large block is allocated from memblock (system bootup) or

 * kmalloc() when unflattening the device tree by OF changeset.

 * We can not free the large block allocated from memblock. For

 * later case, it should be released at once.

	/*

	 * Decrease the refcount if the device nodes were created

	 * through OF changeset before detaching them.

/*

 * As the nodes in OF changeset are applied in reverse order, we

 * need revert the nodes in advance so that we have correct node

 * order after the changeset is applied.

 In-depth first */

 Reverse the nodes in the child list */

	/* We don't know the FDT blob size. We try to get it through

	 * maximal memory chunk and then copy it to another chunk that

	 * fits the real size.

 Unflatten device tree blob */

 Initialize and apply the changeset */

 Add device node firmware data */

	/*

	 * Retrieve power status from firmware. If we fail

	 * getting that, the power status fails back to

	 * be on.

	/*

	 * Retrieve presence status from firmware. If we can't

	 * get that, it will fail back to be empty.

 Check if the slot has been configured */

 Retrieve slot presence status */

	/*

	 * Proceed if there have nothing behind the slot. However,

	 * we should leave the slot in registered state at the

	 * beginning. Otherwise, the PCI devices inserted afterwards

	 * won't be probed and populated.

	/*

	 * If the power supply to the slot is off, we can't detect

	 * adapter presence state. That means we have to turn the

	 * slot on before going to probe slot's presence state.

	 *

	 * On the first time, we don't change the power status to

	 * boost system boot with assumption that the firmware

	 * supplies consistent slot power status: empty slot always

	 * has its power off and non-empty slot has its power on.

 Check the power status. Scan the slot if it is already on */

 Power is off, turn it on and then scan the slot */

 Rescan for child hotpluggable slots */

	/*

	 * The CAPI folks want pnv_php to drive OpenCAPI slots

	 * which don't have a bridge. Only claim to support

	 * reset_slot() if we have a bridge device (for now...)

 mask our interrupt while resetting the bridge */

 clear any state changes that happened due to the reset */

	/*

	 * Allow to disable a slot already in the registered state to

	 * cover cases where the slot couldn't be enabled and never

	 * reached the populated state

 Remove all devices behind the slot */

 Detach the child hotpluggable slots */

 Notify firmware and remove device nodes */

 Remove from global or child list */

 Detach from parent */

 Placeholder slot */

 Check if the slot is registered or not */

 Register PCI slot */

 Attach to the parent's child list or global list */

 Get total number of MSIx entries */

 Check hotplug MSIx entry is in range */

 Enable MSIx */

 Freeze the removed PE to avoid unexpected error reporting */

	/*

	 * The PE is left in frozen state if the event is missed. It's

	 * fine as the PCI devices (PE) aren't functional any more.

 Allocate workqueue */

 Check PDC (Presence Detection Change) is broken or not */

 Clear pending interrupts */

 Request the interrupt */

 Enable the interrupts */

 The interrupt is initialized successfully when @irq is valid */

	/*

	 * The MSI/MSIx interrupt might have been occupied by other

	 * drivers. Don't populate the surprise hotplug capability

	 * in that case.

 Enable MSIx interrupt */

	/*

	 * Use MSI if MSIx doesn't work. Fail back to legacy INTx

	 * if MSI doesn't work either

 Check if it's hotpluggable slot */

 Enable interrupt if the slot supports surprise hotplug */

	/*

	 * The parent slots should be registered before their

	 * child slots.

 The child slots should go before their parent slots */

 slot directly under the PHB */

 slot directly under the PHB */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Express PCI Hot Plug Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 * Copyright (C) 2003-2004 Intel Corporation

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>,<kristen.c.accardi@intel.com>

	/*

	 * Match all Dell systems, as some Dell systems have inband

	 * presence disabled on NVMe slots (but don't support the bit to

	 * report it). Setting inband presence disabled should have no

	 * negative effect, except on broken hotplug slots that never

	 * assert presence detect--and those will still work, they will

	 * just have a bit of extra delay before being probed.

 Installs the interrupt handler */

 timeout */

	/*

	 * If the controller does not generate notifications for command

	 * completions, we never need to wait between writes.

	/*

	 * Even if the command has already timed out, we want to call

	 * pcie_poll_cmd() so it can clear PCI_EXP_SLTSTA_CC.

	/*

	 * Always wait for any previous command that might still be in progress

	/*

	 * Controllers with the Intel CF118 and similar errata advertise

	 * Command Completed support, but they only set Command Completed

	 * if we change the "Control" bits for power, power indicator,

	 * attention indicator, or interlock.  If we only change the

	 * "Enable" bits, they never set the Command Completed bit.

	/*

	 * Optionally wait for the hardware to be ready for a new command,

	 * indicating completion of the above issued command.

/**

 * pcie_write_cmd - Issue controller command

 * @ctrl: controller to which the command is issued

 * @cmd:  command value written to slot control register

 * @mask: bitmask of slot control register to be modified

 Same as above without waiting for the hardware to latch */

/**

 * pciehp_check_link_active() - Is the link active

 * @ctrl: PCIe hotplug controller

 *

 * Check whether the downstream link is currently active. Note it is

 * possible that the card is removed immediately after this so the

 * caller may need to take it into account.

 *

 * If the hotplug controller itself is not available anymore returns

 * %-ENODEV.

 ignore link or presence changes up to this point */

 On */

 Blink */

 Off */

 On */

 Off */

/**

 * pciehp_card_present() - Is the card present

 * @ctrl: PCIe hotplug controller

 *

 * Function checks whether the card is currently present in the slot and

 * in that case returns true. Note it is possible that the card is

 * removed immediately after the check so the caller may need to take

 * this into account.

 *

 * It the hotplug controller itself is not available anymore returns

 * %-ENODEV.

/**

 * pciehp_card_present_or_link_active() - whether given slot is occupied

 * @ctrl: PCIe hotplug controller

 *

 * Unlike pciehp_card_present(), which determines presence solely from the

 * Presence Detect State bit, this helper also returns true if the Link Active

 * bit is set.  This is a concession to broken hotplug ports which hardwire

 * Presence Detect State to zero, such as Wilocity's [1ae9:0200].

 *

 * Returns: %1 if the slot is occupied and %0 if it is not. If the hotplug

 *	    port is not present anymore returns %-ENODEV.

/**

 * pciehp_set_indicators() - set attention indicator, power indicator, or both

 * @ctrl: PCIe hotplug controller

 * @pwr: one of:

 *	PCI_EXP_SLTCTL_PWR_IND_ON

 *	PCI_EXP_SLTCTL_PWR_IND_BLINK

 *	PCI_EXP_SLTCTL_PWR_IND_OFF

 * @attn: one of:

 *	PCI_EXP_SLTCTL_ATTN_IND_ON

 *	PCI_EXP_SLTCTL_ATTN_IND_BLINK

 *	PCI_EXP_SLTCTL_ATTN_IND_OFF

 *

 * Either @pwr or @attn can also be INDICATOR_NOOP to leave that indicator

 * unchanged.

 Clear power-fault bit from previous power failures */

	/*

	 * Ignore link changes which occurred while waiting for DPC recovery.

	 * Could be several if DPC triggered multiple times consecutively.

	/*

	 * If the link is unexpectedly down after successful recovery,

	 * the corresponding link change may have been ignored above.

	 * Synthesize it to ensure that it is acted on.

	/*

	 * Interrupts only occur in D3hot or shallower and only if enabled

	 * in the Slot Control register (PCIe r4.0, sec 6.7.3.4).

	/*

	 * Keep the port accessible by holding a runtime PM ref on its parent.

	 * Defer resume of the parent to the IRQ thread if it's suspended.

	 * Mask the interrupt until then.

	/*

	 * Slot Status contains plain status bits as well as event

	 * notification bits; right now we only want the event bits.

	/*

	 * If we've already reported a power fault, don't report it again

	 * until we've done something to handle it.

		/*

		 * In MSI mode, all event bits must be zero before the port

		 * will send a new interrupt (PCIe Base Spec r5.0 sec 6.7.3.4).

		 * So re-read the Slot Status register in case a bit was set

		 * between read and write.

	/*

	 * Command Completed notifications are not deferred to the

	 * IRQ thread because it may be waiting for their arrival.

 Save pending events for consumption by IRQ thread. */

 rerun pciehp_isr() if the port was inaccessible on interrupt */

 Check Attention Button Pressed */

 Check Power Fault Detected */

	/*

	 * Ignore Link Down/Up events caused by Downstream Port Containment

	 * if recovery from the error succeeded.

	/*

	 * Disable requests have higher priority than Presence Detect Changed

	 * or Data Link Layer State Changed events.

 start with 10 sec delay */

 poll for interrupt events or user requests */

 clamp to sane value */

	/*

	 * TBD: Power fault detected software notification support.

	 *

	 * Power fault detected software notification is not enabled

	 * now, because it caused power fault detected interrupt storm

	 * on some machines. On those machines, power fault detected

	 * bit in the slot status register was set again immediately

	 * when it is cleared in the interrupt service routine, and

	 * next power fault detected interrupt was notified again.

	/*

	 * Always enable link events: thus link-up and link-down shall

	 * always be treated as hotplug and unplug respectively. Enable

	 * presence detect only if Attention Button is not present.

	/*

	 * Mask hot-plug interrupt to prevent it triggering immediately

	 * when the link goes inactive (we still get PME when any of the

	 * enabled events is detected). Same goes with Link Layer State

	 * changed event which generates PME immediately when the link goes

	 * inactive so mask it as well.

/**

 * pciehp_slot_reset() - ignore link event caused by error-induced hot reset

 * @dev: PCI Express port service device

 *

 * Called from pcie_portdrv_slot_reset() after AER or DPC initiated a reset

 * further up in the hierarchy to recover from an error.  The reset was

 * propagated down to this hotplug port.  Ignore the resulting link flap.

 * If the link failed to retrain successfully, synthesize the ignored event.

 * Surprise removal during reset is detected through Presence Detect Changed.

/*

 * pciehp has a 1:1 bus:slot relationship so we ultimately want a secondary

 * bus reset of the bridge, but at the same time we want to ensure that it is

 * not seen as a hot-unplug, followed by the hot-plug of the device. Thus,

 * disable link state notification and presence detection change notification

 * momentarily, if we see that they could interfere. Also, clear any spurious

 * events after.

	/*

	 * We assume no Thunderbolt controllers support Command Complete events,

	 * but some controllers falsely claim they do.

 Check if Data Link Layer Link Active Reporting is implemented */

 Clear all remaining event bits in Slot Status register. */

	/*

	 * If empty slot's power status is on, turn power off.  The IRQ isn't

	 * requested yet, so avoid triggering a notification with this command.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Compaq Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>

 *

/*

 * detect_HRT_floating_pointer

 *

 * find the Hot Plug Resource Table in the specified region of memory.

 *

 No pci device, we need to create it then */

/*

 * cpqhp_set_irq

 *

 * @bus_num: bus number of PCI device

 * @dev_num: device number of PCI device

 * @slot: pointer to u8 where slot number will be returned

 set the Edge Level Control Register (ELCR) */

		/* This should only be for x86 as it sets the Edge Level

		 * Control Register

 Scan for access first */

 Yep we got one. Not a bridge ? */

 Scan for access first */

 Yep we got one. bridge ? */

 XXX: no recursion, wtf? */

 plain (bridges allowed) */

/* More PCI configuration routines; this time centered around hotplug

 * controller

/*

 * cpqhp_save_config

 *

 * Reads configuration for all slots in a PCI bus and saves info.

 *

 * Note:  For non-hot plug buses, the slot # saved is the device #

 *

 * returns 0 if success

 Decide which slots are supported */

		/*

		 * is_hot_plug is the slot mask

 Save PCI configuration space for all devices in supported slots */

				/* Setup slot structure with entry for empty

				 * slot

 If multi-function device, set max_functions to 8 */

				/* Recurse the subordinate bus

				 * get the subordinate bus number

					/* Save secondary bus cfg spc

					 * with this recursive call.

 Setup slot structure. */

 In case of unsupported board */

			/* this loop skips to the next present function

			 * reading in Class Code and Header type.

 End of FOR loop */

/*

 * cpqhp_save_slot_config

 *

 * Saves configuration info for all PCI devices in a given slot

 * including subordinate buses.

 *

 * returns 0 if success

 Multi-function device */

  Recurse the subordinate bus */

			/* Save the config headers for the secondary

			 * bus.

		/* this loop skips to the next present function

		 * reading in the Class Code and the Header type.

/*

 * cpqhp_save_base_addr_length

 *

 * Saves the length of all base address registers for the

 * specified slot.  this is for hot plug REPLACE

 *

 * returns 0 if success

 Check for Bridge */

			/* FIXME: this loop is duplicated in the non-bridge

			 * case.  The two could be rolled together Figure out

			 * IO and memory base lengths

 If this register is implemented */

						/* IO base

						 * set base = amount of IO space

						 * requested

 memory base */

 Save information in slot structure */

 End of base register loop */

 Figure out IO and memory base lengths */

 If this register is implemented */

						/* IO base

						 * base = amount of IO space

						 * requested

						/* memory base

						 * base = amount of memory

						 * space requested

 Save information in slot structure */

 End of base register loop */

 Some other unknown header type */

 find the next device in this slot */

/*

 * cpqhp_save_used_resources

 *

 * Stores used resource information for existing boards.  this is

 * for boards that were in the system when this driver was loaded.

 * this function is for hot plug ADD

 *

 * returns 0 if success

 Save the command register */

 disable card */

 Check for Bridge */

 Clear Bridge Control Register */

 Save IO base and Limit registers */

 Save memory base and Limit registers */

 Save prefetchable memory base and Limit registers */

 Figure out IO and memory base lengths */

 If this register is implemented */

						/* IO base

						 * set temp_register = amount

						 * of IO space requested

 prefetchable memory base */

 prefetchable memory base */

 End of base register loop */

 Standard header */

 Figure out IO and memory base lengths */

 If this register is implemented */

						/* IO base

						 * set temp_register = amount

						 * of IO space requested

 prefetchable memory base */

 prefetchable memory base */

 End of base register loop */

 find the next device in this slot */

/*

 * cpqhp_configure_board

 *

 * Copies saved configuration information to one slot.

 * this is called recursively for bridge devices.

 * this is for hot plug REPLACE!

 *

 * returns 0 if success

		/* Start at the top of config space so that the control

		 * registers are programmed last

 If this is a bridge device, restore subordinate devices */

			/* Check all the base Address Registers to make sure

			 * they are the same.  If not, the board is different.

/*

 * cpqhp_valid_replace

 *

 * this function checks to see if a board is the same as the

 * one it is replacing.  this check will detect if the device's

 * vendor or device id's are the same

 *

 * returns 0 if the board is the same nonzero otherwise

 No adapter present */

 Check for same revision number and class code */

 Adapter not the same */

 Check for Bridge */

			/* In order to continue checking, we must program the

			 * bus registers in the bridge to respond to accesses

			 * for its subordinate bus(es)

 Check to see if it is a standard config header */

 Check subsystem vendor and ID */

				/* If it's a SMART-2 and the register isn't

				 * filled in, ignore the difference because

				 * they just have an old rev of the firmware

 Figure out IO and memory base lengths */

 If this register is implemented */

						/* IO base

						 * set base = amount of IO

						 * space requested

 memory base */

 Check information in slot structure */

 End of base register loop */

 End of (type 0 config space) else */

			/* this is not a type 0 or 1 config space header so

			 * we don't know how to do it

 Get the next function */

/*

 * cpqhp_find_available_resources

 *

 * Finds available memory, IO, and IRQ resources for programming

 * devices which may be added to the system

 * this function is for hot plug ADD!

 *

 * returns 0 if success

 Sum all resources and setup resource maps */

 If this entry isn't for our controller's bus, ignore it */

 find out if this entry is for an occupied slot */

 If we can't find a match, skip this table entry */

 this may not work and shouldn't be used */

 If we've got a valid IO base, use it */

 If we've got a valid memory base, use it */

		/* If we've got a valid prefetchable memory base, and

		 * the base + length isn't greater than 0xFFFF

		/* If we've got a valid bus number, use it

		 * The second condition is to ignore bus numbers on

		 * populated slots that don't have PCI-PCI bridges

	/* If all of the following fail, we don't have any resources for

	 * hot plug add

/*

 * cpqhp_return_board_resources

 *

 * this routine returns all resources allocated to a board to

 * the available pool.

 *

 * returns 0 if success

/*

 * cpqhp_destroy_resource_list

 *

 * Puts node back in the resource list pointed to by head

/*

 * cpqhp_destroy_board_resources

 *

 * Puts node back in the resource list pointed to by head

 SPDX-License-Identifier: GPL-2.0+

/*

 * Compaq Hot Plug Controller Driver

 *

 * Copyright (C) 1995,2001 Compaq Computer Corporation

 * Copyright (C) 2001 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (C) 2001 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>

 *

 = NULL */

 delay is in jiffies to wait for */

	/*

	 * XXX(hch): if someone is bored please convert all callers

	 * to call msleep_interruptible directly.  They really want

	 * to specify timeouts in natural units and spend a lot of

	 * effort converting them to jiffies..

 FIXME: The following line needs to be somewhere else... */

 Switch Change */

			/*

			 * this one changed.

			/* this is the structure that tells the worker thread

			 * what to do

				/*

				 * Switch opened

				/*

				 * Switch closed

/**

 * cpqhp_find_slot - find the struct slot of given device

 * @ctrl: scan lots of this controller

 * @device: the device id to find

	/*

	 * Presence Change

			/*

			 * this one changed.

			/* If the switch closed, must be a button

			 * If not in button mode, nevermind

					/*

					 * button Pressed (doesn't do anything)

					/*

					 * button Released - TAKE ACTION!!!!

 Cancel if we are still blinking */

 info(msg_button_ignore, p_slot->number); */

				/* Switch is open, assume a presence change

				 * Save the presence state

 Present */

 Not Present */

	/*

	 * power fault

			/*

			 * this one changed.

				/*

				 * power fault Cleared

				/*

				 * power fault

					/* this is a fatal condition, we want

					 * to crash the machine to protect from

					 * data corruption. simulated_NMI

					/* FIXME

					/* The following code causes a software

					 * crash just in case simulated_NMI did

					/*FIXME

 set power fault status for this board */

/**

 * sort_by_size - sort nodes on the list by their length, smallest first.

 * @head: list to sort

 Special case for swapping list head */

 End of out_of_order loop */

/**

 * sort_by_max_size - sort nodes on the list by their length, largest first.

 * @head: list to sort

 Special case for swapping list head */

 End of out_of_order loop */

/**

 * do_pre_bridge_resource_split - find node of resources that are unused

 * @head: new list head

 * @orig_head: original list head

 * @alignment: max node size (?)

	/* If we got here, there the bridge requires some of the resource, but

	 * we may be able to split some off of the front

		/* this one isn't an aligned length, so we'll make a new entry

		 * and split it up.

 Put it in the list */

 Now unlink it */

/**

 * do_bridge_resource_split - find one node of resources that aren't in use

 * @head: list head

 * @alignment: max node size (?)

 Short circuit if adjusted size is too small */

 There's stuff in use after this node */

/**

 * get_io_resource - find first node of given size not in ISA aliasing window.

 * @head: list to search

 * @size: size of node to find, must be a power of two.

 *

 * Description: This function sorts the resource list by size and then

 * returns the first node of "size" length that is not in the ISA aliasing

 * window.  If it finds a node larger than "size" it will split it up.

			/* this one isn't base aligned properly

			 * so we'll make a new entry and split it up

 Short circuit if adjusted size is too small */

 Put it in the list */

 End of non-aligned base */

 Don't need to check if too small since we already did */

			/* this one is longer than we need

			 * so we'll make a new entry and split it up

 Put it in the list */

 End of too big on top end */

 For IO make sure it's not in the ISA aliasing space */

		/* If we got here, then it is the right size

		 * Now take it out of the list and break

/**

 * get_max_resource - get largest node which has at least the given size.

 * @head: the list to search the node in

 * @size: the minimum size of the node to find

 *

 * Description: Gets the largest node that is at least "size" big from the

 * list pointed to by head.  It aligns the node on top and bottom

 * to "size" alignment before returning it.

		/* If not big enough we could probably just bail,

		 * instead we'll continue to the next.

			/* this one isn't base aligned properly

			 * so we'll make a new entry and split it up

 Short circuit if adjusted size is too small */

			/* this one isn't end aligned properly at the top

			 * so we'll make a new entry and split it up

 Make sure it didn't shrink too much when we aligned it */

 Now take it out of the list */

/**

 * get_resource - find resource of given size and split up larger ones.

 * @head: the list to search for resources

 * @size: the size limit to use

 *

 * Description: This function sorts the resource list by size and then

 * returns the first node of "size" length.  If it finds a node

 * larger than "size" it will split it up.

 *

 * size must be a power of two.

			/* this one isn't base aligned properly

			 * so we'll make a new entry and split it up

 Short circuit if adjusted size is too small */

 End of non-aligned base */

 Don't need to check if too small since we already did */

			/* this one is longer than we need

			 * so we'll make a new entry and split it up

 Put it in the list */

 End of too big on top end */

		/* If we got here, then it is the right size

/**

 * cpqhp_resource_sort_and_combine - sort nodes by base addresses and clean up

 * @head: the list to sort and clean up

 *

 * Description: Sorts all of the nodes in the list in ascending order by

 * their base addresses.  Also does garbage collection by

 * combining adjacent nodes.

 *

 * Returns %0 if success.

 only one item on the list, already sorted! */

 Special case for swapping list head */

 End of out_of_order loop */

 Combine */

	/*

	 * Check to see if it was our interrupt

		/*

		 * Serial Output interrupt Pending

 Clear the interrupt */

 Read to clear posted writes */

 General-interrupt-input interrupt Pending */

 Clear the interrupt */

 Read it back to clear any posted writes */

 Clear all interrupts */

 Bus reset has completed */

/**

 * cpqhp_slot_create - Creates a node and adds it to the proper bus.

 * @busnumber: bus where new node is to be located

 *

 * Returns pointer to the new node or %NULL if unsuccessful.

/**

 * slot_remove - Removes a node from the linked list of slots.

 * @old_slot: slot to remove

 *

 * Returns %0 if successful, !0 otherwise.

/**

 * bridge_slot_remove - Removes a node from the linked list of slots.

 * @bridge: bridge to remove

 *

 * Returns %0 if successful, !0 otherwise.

/**

 * cpqhp_slot_find - Looks for a node by bus, and device, multiple functions accessed

 * @bus: bus to find

 * @device: device to find

 * @index: is %0 for first function found, %1 for the second...

 *

 * Returns pointer to the node if successful, %NULL otherwise.

/* DJZ: I don't think is_bridge will work as is.

 Check the header type */

/**

 * set_controller_speed - set the frequency and/or mode of a specific controller segment.

 * @ctrl: controller to change frequency/mode for.

 * @adapter_speed: the speed of the adapter we want to match.

 * @hp_slot: the slot number where the adapter is installed.

 *

 * Returns %0 if we successfully change frequency and/or mode to match the

 * adapter speed.

	/* We don't allow freq/mode changes if we find another adapter running

	 * in another slot on this controller

		/* If another adapter is running on the same segment but at a

		 * lower speed/mode, we allow the new adapter to function at

		 * this rate if supported

	/* If the controller doesn't support freq/mode changes and the

	 * controller is running at a higher mode, we bail

 But we allow the adapter to run at a lower rate if possible */

	/* We try to set the max speed supported by both the adapter and

	 * controller

 33MHz PCI 2.2 */

 Re-enable interrupts */

 Restart state machine */

 Only if mode change...*/

 Restore LED/Slot state */

/* the following routines constitute the bulk of the

 * hotplug controller logic

/**

 * board_replaced - Called after a board has been replaced in the system.

 * @func: PCI device/function information

 * @ctrl: hotplug controller

 *

 * This is only used if we don't have resources for hot add.

 * Turns power on for the board.

 * Checks to see if board is the same.

 * If board is same, reconfigures it.

 * If board isn't same, turns it back off.

	/*

	 * The switch is open.

	/*

	 * The board is already on

 turn on board without attaching to the bus */

 Wait for SOBS to be unset */

		/* Change bits in slot power register to force another shift out

 Wait for SOBS to be unset */

 turn off board without attaching to the bus */

 Wait for SOBS to be unset */

 Wait for SOBS to be unset */

 Wait for ~1 second because of hot plug spec */

 Check for a power fault */

 power fault occurred, but it was benign */

 It must be the same board */

			/* If configuration fails, turn it off

			 * Get slot won't work for devices behind

			 * bridges, but in this case it will always be

			 * called for the "base" bus/dev/func of an

			 * adapter.

 Wait for SOBS to be unset */

			/* Something is wrong



			 * Get slot won't work for devices behind bridges, but

			 * in this case it will always be called for the "base"

			 * bus/dev/func of an adapter.

 Wait for SOBS to be unset */

/**

 * board_added - Called after a board has been added to the system.

 * @func: PCI device/function info

 * @ctrl: hotplug controller

 *

 * Turns power on for the board.

 * Configures board.

 turn on board without attaching to the bus */

 Wait for SOBS to be unset */

	/* Change bits in slot power register to force another shift out

	 * NOTE: this is to work around the timer bug

 Wait for SOBS to be unset */

 turn off board without attaching to the bus */

 Wait for SOBS to be unset */

 turn on board and blink green LED */

 Wait for SOBS to be unset */

 Wait for ~1 second because of hot plug spec */

 Check for a power fault */

 power fault occurred, but it was benign */

 Get vendor/device ID u32 */

 Something's wrong here */

 Preset return code.  It will be changed later if things go okay. */

 All F's is an empty slot or an invalid board */

 Wait for SOBS to be unset */

		/* next, we will instantiate the linux pci_dev structures (with

 Wait for SOBS to be unset */

 Wait for SOBS to be unset */

/**

 * remove_board - Turns off slot and LEDs

 * @func: PCI device/function info

 * @replace_flag: whether replacing or adding a new device

 * @ctrl: target controller

	/* When we get here, it is safe to change base address registers.

		/* Here we check to see if we've saved any of the board's

		 * resources already.  If so, we'll skip the attempt to

 Change status to shutdown */

 turn off SERR for slot */

 Wait for SOBS to be unset */

 Setup slot structure with entry for empty slot */

 this is the main worker thread */

 Do stuff here */

 dbg("loop %d\n", loop); */

 slot is on */

 slot is off */

 Wait for SOBS to be unset */

** button Released (No action on press...) */

 Wait for SOBS to be unset */

					p_slot->physical_slot = physical_slot; */

 5 second delay */

**********POWER FAULT */

 End of FOR loop */

/**

 * cpqhp_pushbutton_thread - handle pushbutton events

 * @t: pointer to struct timer_list which holds all timer-related callbacks

 *

 * Scheduled procedure to handle blocking stuff for the pushbuttons.

 * Handles all pending events and exits.

 power Down board */

 Wait for SOBS to be unset */

 slot is off */

 Wait for SOBS to be unset */

 Check to see if the interlock is closed */

 add board */

 We have to save the presence info for these slots */

 Setup slot structure with entry for empty slot */

 We have to save the presence info for these slots */

 Make sure there are no video controllers here */

 Check the Class Code */

 Display/Video adapter (not supported) */

 See if it's a bridge */

 If it's a bridge, check the VGA Enable bit */

				/* If the VGA Enable bit is set, remove isn't

 FIXME: Replace flag should be passed into process_SS */

/**

 * switch_leds - switch the leds, go from one site to the other.

 * @ctrl: controller to use

 * @num_of_slots: number of slots to use

 * @work_LED: LED control value

 * @direction: 1 to start from the left side, 0 to start right.

 Wait for SOGO interrupt */

 Get ready for next iteration */

/**

 * cpqhp_hardware_test - runs hardware tests

 * @ctrl: target controller

 * @test_num: the number written to the "test" file in sysfs.

 *

 * For hot plug ctrl folks to play with.

 Do stuff here! */

 Do that funky LED thing */

 so we can restore them later */

 Wait for SOGO interrupt */

 Get ready for next iteration */

 Wait for SOGO interrupt */

 Get ready for next iteration */

 put it back the way it was */

 Wait for SOBS to be unset */

 Do other stuff here! */

 and more... */

/**

 * configure_new_device - Configures the PCI header information of one board.

 * @ctrl: pointer to controller structure

 * @func: pointer to function structure

 * @behind_bridge: 1 if this is a recursive call, 0 if not

 * @resources: pointer to set of resource lists

 *

 * Returns 0 if success.

 Check for Multi-function device */

 Multi-function device */

		/* The following loop skips to the next present function

 Setup slot structure. */

/*

 * Configuration logic that involves the hotplug data structures and

 * their bookkeeping

/**

 * configure_new_function - Configures the PCI header information of one device

 * @ctrl: pointer to controller structure

 * @func: pointer to function structure

 * @behind_bridge: 1 if this is a recursive call, 0 if not

 * @resources: pointer to set of resource lists

 *

 * Calls itself recursively for bridged devices.

 * Returns 0 if success.

 Check for Bridge */

 set Primary bus */

 find range of buses to use */

 If we don't have any buses to allocate, we can't continue */

 set Secondary bus */

 set subordinate bus */

 set subordinate Latency Timer and base Latency Timer */

 set Cache Line size */

 Setup the IO, memory, and prefetchable windows */

 set up the IRQ info */

		/* set up resource lists that are now aligned on top and bottom

		/* Make copies of the nodes we are going to pass down so that

		 * if there is a problem,we can just use these to free resources

		/* If we have IO resources copy them and fill in the bridge's

 set IO base and Limit registers */

		/* Copy the memory resources and fill in the bridge's memory

		 * range registers.

 set Mem base and Limit registers */

 set Pre Mem base and Limit registers */

		/* Adjust this to compensate for extra adjustment in first loop

 Here we actually find the devices and configure them */

  device present */

 Setup slot structure. */

 End of IF (device in slot?) */

 End of FOR loop */

 save the interrupt routing information */

 We need to hook up the interrupts here */

 end of for loop */

		/* Return unused bus resources

		 * First use the temporary node to store information for

 set subordinate bus */

		/* If we have IO space available and there is some left,

 Check if we were able to split something off */

 Check if we were able to split something off */

				/* First use the temporary node to store

 If we used any, add it to the board's list */

 it doesn't need any IO */

 it used most of the range */

 it used the whole range */

		/* If we have memory space available and there is some left,

 Check if we were able to split something off */

 Check if we were able to split something off */

				/* First use the temporary node to store

 configure end address */

 Return unused resources to the pool */

 it doesn't need any Mem */

 it used most of the range */

 it used the whole range */

		/* If we have prefetchable memory space available and there

 Check if we were able to split something off */

 Check if we were able to split something off */

				/* First use the temporary node to store

 If we used any, add it to the board's list */

 it doesn't need any PMem */

 it used the most of the range */

 it used the whole range */

		/* We should be configuring an IRQ and the bridge's base address

		 * registers if it needs them.  Although we have never seen such

 enable card */

		command = 0x0157;	/* = PCI_COMMAND_IO |

					 *   PCI_COMMAND_MEMORY |

					 *   PCI_COMMAND_MASTER |

					 *   PCI_COMMAND_INVALIDATE |

					 *   PCI_COMMAND_PARITY |

 set Bridge Control Register */

		command = 0x07;		/* = PCI_BRIDGE_CTL_PARITY |

					 *   PCI_BRIDGE_CTL_SERR |

 Standard device */

 Display (video) adapter (not supported) */

 Figure out IO and memory needs */

 If this register is implemented */

 Map IO */

 set base = amount of IO space */

 allocate the resource to the board */

 Map prefetchable memory */

 allocate the resource to the board */

 Map memory */

 allocate the resource to the board */

 Reserved bits or requesting space below 1M */

 Check for 64-bit base */

					/* Upper 32 bits of address always zero

					/* FIXME this is probably not true on

 End of base register loop */

 Figure out which interrupt pin this function uses */

			/* If this function needs an interrupt and we are behind

			 * a bridge and the pin is tied to something that's

 We have to share with something already set up */

 Program IRQ based on card type */

 IRQ Line */

			/* TBD - this code may also belong in the other clause

 Latency Timer */

 Cache Line size */

 disable ROM base Address */

 enable card */

		temp_word = 0x0157;	/* = PCI_COMMAND_IO |

					 *   PCI_COMMAND_MEMORY |

					 *   PCI_COMMAND_MASTER |

					 *   PCI_COMMAND_INVALIDATE |

					 *   PCI_COMMAND_PARITY |

 End of Not-A-Bridge else */

 It's some strange type of PCI adapter (Cardbus?) */

 SPDX-License-Identifier: GPL-2.0+

/*

 * CompactPCI Hot Plug Driver PCI functions

 *

 * Copyright (C) 2002,2005 by SOMA Networks, Inc.

 *

 * All rights reserved.

 *

 * Send feedback to <scottm@somanetworks.com>

 Clear INS (by setting it) */

 Clear EXT (by setting it) */

/*

 * Device configuration functions

 Still NULL? Well then scan for it! */

		/*

		 * This will generate pci_dev structures for all functions, but

		 * we will only call this case when lookup fails.

 SPDX-License-Identifier: GPL-2.0+

/*

 * cpcihp_generic.c

 *

 * Generic port I/O CompactPCI driver

 *

 * Copyright 2002 SOMA Networks, Inc.

 * Copyright 2001 Intel San Luis Obispo

 * Copyright 2000,2001 MontaVista Software Inc.

 *

 * This generic CompactPCI hotplug driver should allow using the PCI hotplug

 * mechanism on any CompactPCI board that exposes the #ENUM signal as a bit

 * in a system register that can be read through standard port I/O.

 *

 * Send feedback to <scottm@somanetworks.com>

 local variables */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Compaq Hot Plug Controller Driver

 *

 * Copyright (c) 1995,2001 Compaq Computer Corporation

 * Copyright (c) 2001,2003 Greg Kroah-Hartman (greg@kroah.com)

 * Copyright (c) 2001 IBM Corp.

 *

 * All rights reserved.

 *

 * Send feedback to <greg@kroah.com>

 *

 A few routines that create sysfs entries for the hot plug controller */

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Hot Plug Controller Driver for System z

 *

 * Copyright 2012 IBM Corp.

 *

 * Author(s):

 *   Jan Glauber <jang@linux.vnet.ibm.com>

	/*

	 * We can't take the zdev->lock as reset_slot may be called during

	 * probing and/or device removal which already happens under the

	 * zdev->lock. Instead the user should use the higher level

	 * pci_reset_function() or pci_bus_reset() which hold the PCI device

	 * lock preventing concurrent removal. If not using these functions

	 * holding the PCI device lock is required.

 As long as the function is configured we can reset */

 if the slot exits it always contains a function */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Interface for Dynamic Logical Partitioning of I/O Slots on

 * RPA-compliant PPC64 platform.

 *

 * John Rose <johnrose@austin.ibm.com>

 * October 2003

 *

 * Copyright (C) 2003 IBM.

/* Those two have no quotes because they are passed to __ATTR() which

 * stringifies the argument (yuck !)

 SPDX-License-Identifier: GPL-2.0+

/*

 * PCI Hot Plug Controller Driver for RPA-compliant PPC64 platform.

 * Copyright (C) 2003 Linda Xie <lxie@us.ibm.com>

 *

 * All rights reserved.

 *

 * Send feedback to <lxie@us.ibm.com>

 *

 for pci_add_new_bus */

			/* some slots have to be powered up

			 * before get-sensor will succeed.

/**

 * rpaphp_enable_slot - record slot state, config pci device

 * @slot: target &slot

 *

 * Initialize values in the slot structure to indicate if there is a pci card

 * plugged into the slot. If the slot is not empty, run the pcibios routine

 * to get pcibios stuff correctly set up.

 Find out if the power is turned on for the slot */

 Figure out if there is an adapter in the slot */

 if there's an adapter in the slot, go add the pci devices */

 non-empty slot has to have child */

 SPDX-License-Identifier: GPL-2.0

/*

 * Microsemi Switchtec(tm) PCIe Management Driver

 * Copyright (c) 2017, Microsemi Corporation

/*

 * The MMIO reads to the device_id register should always return the device ID

 * of the device, otherwise the firmware is probably stuck or unreachable

 * due to a firmware reset which clears PCI state including the BARs and Memory

 * Space Enable bits.

 requires the mrpc_mutex to already be held when called */

	/*

	 * odb (outbound doorbell) register is processed by low latency

	 * hardware and w/o side effect

 requires the mrpc_mutex to already be held when called */

 requires the mrpc_mutex to already be held when called */

 requires the mrpc_mutex to already be held when called */

 requires the mrpc_mutex to already be held when called */

 requires the mrpc_mutex to already be held when called */

 component_vendor field not supported after gen3 */

 component_id field not supported after gen3 */

 component_revision field not supported after gen3 */

 Mark the hardware as unavailable and complete all completions */

 Wake up and kill any users waiting on an MRPC request */

 Wake up any users waiting on event_wq */

PFX 24xG3

PFX 32xG3

PFX 48xG3

PFX 64xG3

PFX 80xG3

PFX 96xG3

PSX 24xG3

PSX 32xG3

PSX 48xG3

PSX 64xG3

PSX 80xG3

PSX 96xG3

PAX 24XG3

PAX 32XG3

PAX 48XG3

PAX 64XG3

PAX 80XG3

PAX 96XG3

PFXL 24XG3

PFXL 32XG3

PFXL 48XG3

PFXL 64XG3

PFXL 80XG3

PFXL 96XG3

PFXI 24XG3

PFXI 32XG3

PFXI 48XG3

PFXI 64XG3

PFXI 80XG3

PFXI 96XG3

PFX 100XG4

PFX 84XG4

PFX 68XG4

PFX 52XG4

PFX 36XG4

PFX 28XG4

PSX 100XG4

PSX 84XG4

PSX 68XG4

PSX 52XG4

PSX 36XG4

PSX 28XG4

PAX 100XG4

PAX 84XG4

PAX 68XG4

PAX 52XG4

PAX 36XG4

PAX 28XG4

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DaVinci Voice Codec Core Interface for TI platforms

 *

 * Copyright (C) 2010 Texas Instruments, Inc

 *

 * Author: Miguel Aguilar <miguel.aguilar@ridgerun.com>

 Voice codec interface client */

 Voice codec CQ93VC client */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * tps65910.c  --  TI TPS6591x

 *

 * Copyright 2010 Texas Instruments Inc.

 *

 * Author: Jorge Eduardo Candelaria <jedu@slimlogic.co.uk>

 Comparator 1 voltage selection table in millivolts */

 Create sysfs entry */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * timberdale.c timberdale FPGA MFD driver

 * Copyright (c) 2009 Intel Corporation

/* Supports:

 * Timberdale FPGA

--------------------------------------------------------------------------*/

	/* bits per word and devices will be filled in runtime depending

	 * on the HW config

 Requires jumper JP9 to be off */

	/*

	note that the "frame buffer" is located in DMA area

	starting at 0x1200000

 UART RX */

 UART TX */

 MLB RX */

 MLB TX */

 Video RX */

 Video framedrop */

 SDHCI RX */

 SDHCI TX */

 ETH RX */

 ETH TX */

 located in bar 1 and bar 2 */

--------------------------------------------------------------------------*/

 create a resource for the PCI master register */

 read the HW config */

 Reset all FPGA PLB peripherals */

 update IRQ offsets in I2C board info */

 Update the SPI configuration depending on the HW (8 or 16 bit) */

 only version 0 and 3 have the iNand routed to SDHCI */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * STA2x11 mfd for GPIO, SCTL and APBREG

 *

 * Copyright (c) 2009-2011 Wind River Systems, Inc.

 * Copyright (c) 2011 ST Microelectronics (Alessandro Rubini, Davide Ciminaghi)

 This describes STA2X11 MFD chip for us, we may have several */

 Three functions to act on the list */

 This function is exported and is not expected to fail */

/*

 * Special sta2x11-mfd regmap lock/unlock functions

 OTP (one time programmable registers do not require locking */

 Two blocks (CAN and MLB, SARAC) 0x100 bytes apart */

 Probe for the four platform devices */

	/*

	   No caching, registers could be reached both via regmap and via

	   void __iomem *

 The three platform drivers */

/*

 * What follows are the PCI devices that host the above pdevs.

 * Each logic block is 4kB and they are all consecutive: we use this info.

 Mfd 0 device */

 Mfd 0, Bar 0 */

 Mfd 0 , Bar 1 */

 4 consecutive cells, 1 driver */

 offset 0: we add pdata later */

 Mfd 1 devices */

 Mfd 1, Bar 0 */

 Mfd 1, Bar 1 */

 Mfd 0: gpio, sctl, scr, timers / apbregs */

 Mfd 1: vic / apb-soc-regs */

 platform data is the pci device for all of them */

 Record this pdev before mfd_add_devices: their probe looks for it */

 Just 2 bars for all mfd's at present */

/*

 * All of this must be ready before "normal" devices like MMCI appear.

 * But MFD (the pci device) can't be too early. The following choice

 * prepares platform drivers very early and probe the PCI device later,

 * but before other PCI devices.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Regmap tables for CS47L85 codec

 *

 * Copyright (C) 2015-2017 Cirrus Logic

 R32 (0x20) - Tone Generator 1 */

 R33 (0x21) - Tone Generator 2 */

 R34 (0x22) - Tone Generator 3 */

 R35 (0x23) - Tone Generator 4 */

 R36 (0x24) - Tone Generator 5 */

 R48 (0x30) - PWM Drive 1 */

 R49 (0x31) - PWM Drive 2 */

 R50 (0x32) - PWM Drive 3 */

 R97 (0x61) - Sample Rate Sequence Select 1 */

 R98 (0x62) - Sample Rate Sequence Select 2 */

 R99 (0x63) - Sample Rate Sequence Select 3 */

 R100 (0x64) - Sample Rate Sequence Select 4 */

 R102 (0x66) - Always On Triggers Sequence Select 1*/

 R103 (0x67) - Always On Triggers Sequence Select 2*/

 R144 (0x90) - Haptics Control 1 */

 R145 (0x91) - Haptics Control 2 */

 R146 (0x92) - Haptics phase 1 intensity */

 R147 (0x93) - Haptics phase 1 duration */

 R148 (0x94) - Haptics phase 2 intensity */

 R149 (0x95) - Haptics phase 2 duration */

 R150 (0x96) - Haptics phase 3 intensity */

 R151 (0x97) - Haptics phase 3 duration */

 R160 (0xa0) - Comfort Noise Generator */

 R256 (0x100) - Clock 32k 1 */

 R257 (0x101) - System Clock 1 */

 R258 (0x102) - Sample rate 1 */

 R259 (0x103) - Sample rate 2 */

 R260 (0x104) - Sample rate 3 */

 R274 (0x112) - Async clock 1 */

 R275 (0x113) - Async sample rate 1 */

 R276 (0x114) - Async sample rate 2 */

 R288 (0x120) - DSP Clock 1 */

 R290 (0x122) - DSP Clock 2 */

 R329 (0x149) - Output system clock */

 R330 (0x14a) - Output async clock */

 R338 (0x152) - Rate Estimator 1 */

 R339 (0x153) - Rate Estimator 2 */

 R340 (0x154) - Rate Estimator 3 */

 R341 (0x155) - Rate Estimator 4 */

 R342 (0x156) - Rate Estimator 5 */

 R369 (0x171) - FLL1 Control 1 */

 R370 (0x172) - FLL1 Control 2 */

 R371 (0x173) - FLL1 Control 3 */

 R372 (0x174) - FLL1 Control 4 */

 R373 (0x175) - FLL1 Control 5 */

 R374 (0x176) - FLL1 Control 6 */

 R377 (0x179) - FLL1 Control 7 */

 R385 (0x181) - FLL1 Synchroniser 1 */

 R386 (0x182) - FLL1 Synchroniser 2 */

 R387 (0x183) - FLL1 Synchroniser 3 */

 R388 (0x184) - FLL1 Synchroniser 4 */

 R389 (0x185) - FLL1 Synchroniser 5 */

 R390 (0x186) - FLL1 Synchroniser 6 */

 R391 (0x187) - FLL1 Synchroniser 7 */

 R393 (0x189) - FLL1 Spread Spectrum */

 R394 (0x18a) - FLL1 GPIO Clock */

 R401 (0x191) - FLL2 Control 1 */

 R402 (0x192) - FLL2 Control 2 */

 R403 (0x193) - FLL2 Control 3 */

 R404 (0x194) - FLL2 Control 4 */

 R405 (0x195) - FLL2 Control 5 */

 R406 (0x196) - FLL2 Control 6 */

 R409 (0x199) - FLL2 Control 7 */

 R417 (0x1a1) - FLL2 Synchroniser 1 */

 R418 (0x1a2) - FLL2 Synchroniser 2 */

 R419 (0x1a3) - FLL2 Synchroniser 3 */

 R420 (0x1a4) - FLL2 Synchroniser 4 */

 R421 (0x1a5) - FLL2 Synchroniser 5 */

 R422 (0x1a6) - FLL2 Synchroniser 6 */

 R423 (0x1a7) - FLL2 Synchroniser 7 */

 R425 (0x1a9) - FLL2 Spread Spectrum */

 R426 (0x1aa) - FLL2 GPIO Clock */

 R433 (0x1b1) - FLL3 Control 1 */

 R434 (0x1b2) - FLL3 Control 2 */

 R435 (0x1b3) - FLL3 Control 3 */

 R436 (0x1b4) - FLL3 Control 4 */

 R437 (0x1b5) - FLL3 Control 5 */

 R438 (0x1b6) - FLL3 Control 6 */

 R441 (0x1b9) - FLL3 Control 7 */

 R449 (0x1c1) - FLL3 Synchroniser 1 */

 R450 (0x1c2) - FLL3 Synchroniser 2 */

 R451 (0x1c3) - FLL3 Synchroniser 3 */

 R452 (0x1c4) - FLL3 Synchroniser 4 */

 R453 (0x1c5) - FLL3 Synchroniser 5 */

 R454 (0x1c6) - FLL3 Synchroniser 6 */

 R455 (0x1c7) - FLL3 Synchroniser 7 */

 R457 (0x1c9) - FLL3 Spread Spectrum */

 R458 (0x1ca) - FLL3 GPIO Clock */

 R512 (0x200) - Mic Charge Pump 1 */

 R523 (0x20B) - HP Charge Pump 8 */

 R528 (0x210) - LDO1 Control 1 */

 R531 (0x213) - LDO2 Control 1 */

 R536 (0x218) - Mic Bias Ctrl 1 */

 R537 (0x219) - Mic Bias Ctrl 2 */

 R538 (0x21a) - Mic Bias Ctrl 3 */

 R539 (0x21b) - Mic Bias Ctrl 4 */

 R638 (0x27e) - EDRE HP stereo control */

 R659 (0x293) - Accessory Detect Mode 1 */

 R667 (0x29b) - Headphone Detect 1 */

 R675 (0x2a3) - Mic Detect Control 1 */

 R676 (0x2a4) - Mic Detect Control 2 */

 R678 (0x2a6) - Mic Detect Level 1 */

 R679 (0x2a7) - Mic Detect Level 2 */

 R680 (0x2a8) - Mic Detect Level 3 */

 R681 (0x2a9) - Mic Detect Level 4 */

 R710 (0x2c6) - Mic Clamp control */

 R712 (0x2c8) - GP switch 1 */

 R723 (0x2d3) - Jack detect analogue */

 R768 (0x300) - Input Enables */

 R776 (0x308) - Input Rate */

 R777 (0x309) - Input Volume Ramp */

 R780 (0x30c) - HPF Control */

 R784 (0x310) - IN1L Control */

 R785 (0x311) - ADC Digital Volume 1L */

 R786 (0x312) - DMIC1L Control */

 R788 (0x314) - IN1R Control */

 R789 (0x315) - ADC Digital Volume 1R */

 R790 (0x316) - DMIC1R Control */

 R792 (0x318) - IN2L Control */

 R793 (0x319) - ADC Digital Volume 2L */

 R794 (0x31a) - DMIC2L Control */

 R796 (0x31c) - IN2R Control */

 R797 (0x31d) - ADC Digital Volume 2R */

 R798 (0x31e) - DMIC2R Control */

 R800 (0x320) - IN3L Control */

 R801 (0x321) - ADC Digital Volume 3L */

 R802 (0x322) - DMIC3L Control */

 R804 (0x324) - IN3R Control */

 R805 (0x325) - ADC Digital Volume 3R */

 R806 (0x326) - DMIC3R Control */

 R808 (0x328) - IN4 Control */

 R809 (0x329) - ADC Digital Volume 4L */

 R810 (0x32a) - DMIC4L Control */

 R812 (0x32c) - IN4R Control */

 R813 (0x32d) - ADC Digital Volume 4R */

 R814 (0x32e) - DMIC4R Control */

 R816 (0x330) - IN5L Control */

 R817 (0x331) - ADC Digital Volume 5L */

 R818 (0x332) - DMIC5L Control */

 R820 (0x334) - IN5R Control */

 R821 (0x335) - ADC Digital Volume 5R */

 R822 (0x336) - DMIC5R Control */

 R824 (0x338) - IN6L Control */

 R825 (0x339) - ADC Digital Volume 6L */

 R826 (0x33a) - DMIC6L Control */

 R828 (0x33c) - IN6R Control */

 R829 (0x33d) - ADC Digital Volume 6R */

 R830 (0x33e) - DMIC6R Control */

 R1024 (0x400) - Output Enables 1 */

 R1032 (0x408) - Output Rate 1 */

 R1033 (0x409) - Output Volume Ramp */

 R1040 (0x410) - Output Path Config 1L */

 R1041 (0x411) - DAC Digital Volume 1L */

 R1043 (0x413) - Noise Gate Select 1L */

 R1044 (0x414) - Output Path Config 1R */

 R1045 (0x415) - DAC Digital Volume 1R */

 R1047 (0x417) - Noise Gate Select 1R */

 R1048 (0x418) - Output Path Config 2L */

 R1049 (0x419) - DAC Digital Volume 2L */

 R1051 (0x41b) - Noise Gate Select 2L */

 R1052 (0x41c) - Output Path Config 2R */

 R1053 (0x41d) - DAC Digital Volume 2R */

 R1055 (0x41f) - Noise Gate Select 2R */

 R1056 (0x420) - Output Path Config 3L */

 R1057 (0x421) - DAC Digital Volume 3L */

 R1059 (0x423) - Noise Gate Select 3L */

 R1060 (0x424) - Output Path Config 3R */

 R1061 (0x425) - DAC Digital Volume 3R */

 R1063 (0x427) - Noise Gate Select 3R */

 R1064 (0x428) - Output Path Config 4L */

 R1065 (0x429) - DAC Digital Volume 4L */

 R1067 (0x42b) - Noise Gate Select 4L */

 R1068 (0x42c) - Output Path Config 4R */

 R1069 (0x42d) - DAC Digital Volume 4R */

 R1071 (0x42f) - Noise Gate Select 4R */

 R1072 (0x430) - Output Path Config 5L */

 R1073 (0x431) - DAC Digital Volume 5L */

 R1075 (0x433) - Noise Gate Select 5L */

 R1076 (0x434) - Output Path Config 5R */

 R1077 (0x435) - DAC Digital Volume 5R */

 R1079 (0x437) - Noise Gate Select 5R */

 R1080 (0x438) - Output Path Config 6L */

 R1081 (0x439) - DAC Digital Volume 6L */

 R1083 (0x43b) - Noise Gate Select 6L */

 R1084 (0x43c) - Output Path Config 6R */

 R1085 (0x43d) - DAC Digital Volume 6R */

 R1087 (0x43f) - Noise Gate Select 6R */

 R1104 (0x450) - DAC AEC Control 1 */

 R1105 (0x451) - DAC AEC Control 2 */

 R1112 (0x458) - Noise Gate Control */

 R1168 (0x490) - PDM SPK1 CTRL 1 */

 R1169 (0x491) - PDM SPK1 CTRL 2 */

 R1170 (0x492) - PDM SPK2 CTRL 1 */

 R1171 (0x493) - PDM SPK2 CTRL 2 */

 R1184 (0x4a0) - HP1 Short Circuit Ctrl */

 R1185 (0x4a1) - HP2 Short Circuit Ctrl */

 R1186 (0x4a2) - HP3 Short Circuit Ctrl */

 R1192 (0x4a8) - HP Test Ctrl 5 */

 R1193 (0x4a9) - HP Test Ctrl 6 */

 R1280 (0x500) - AIF1 BCLK Ctrl */

 R1281 (0x501) - AIF1 Tx Pin Ctrl */

 R1282 (0x502) - AIF1 Rx Pin Ctrl */

 R1283 (0x503) - AIF1 Rate Ctrl */

 R1284 (0x504) - AIF1 Format */

 R1286 (0x506) - AIF1 Rx BCLK Rate */

 R1287 (0x507) - AIF1 Frame Ctrl 1 */

 R1288 (0x508) - AIF1 Frame Ctrl 2 */

 R1289 (0x509) - AIF1 Frame Ctrl 3 */

 R1290 (0x50a) - AIF1 Frame Ctrl 4 */

 R1291 (0x50b) - AIF1 Frame Ctrl 5 */

 R1292 (0x50c) - AIF1 Frame Ctrl 6 */

 R1293 (0x50d) - AIF1 Frame Ctrl 7 */

 R1294 (0x50e) - AIF1 Frame Ctrl 8 */

 R1295 (0x50f) - AIF1 Frame Ctrl 9 */

 R1296 (0x510) - AIF1 Frame Ctrl 10 */

 R1297 (0x511) - AIF1 Frame Ctrl 11 */

 R1298 (0x512) - AIF1 Frame Ctrl 12 */

 R1299 (0x513) - AIF1 Frame Ctrl 13 */

 R1300 (0x514) - AIF1 Frame Ctrl 14 */

 R1301 (0x515) - AIF1 Frame Ctrl 15 */

 R1302 (0x516) - AIF1 Frame Ctrl 16 */

 R1303 (0x517) - AIF1 Frame Ctrl 17 */

 R1304 (0x518) - AIF1 Frame Ctrl 18 */

 R1305 (0x519) - AIF1 Tx Enables */

 R1306 (0x51a) - AIF1 Rx Enables */

 R1344 (0x540) - AIF2 BCLK Ctrl */

 R1345 (0x541) - AIF2 Tx Pin Ctrl */

 R1346 (0x542) - AIF2 Rx Pin Ctrl */

 R1347 (0x543) - AIF2 Rate Ctrl */

 R1348 (0x544) - AIF2 Format */

 R1350 (0x546) - AIF2 Rx BCLK Rate */

 R1351 (0x547) - AIF2 Frame Ctrl 1 */

 R1352 (0x548) - AIF2 Frame Ctrl 2 */

 R1353 (0x549) - AIF2 Frame Ctrl 3 */

 R1354 (0x54a) - AIF2 Frame Ctrl 4 */

 R1355 (0x54b) - AIF2 Frame Ctrl 5 */

 R1356 (0x54c) - AIF2 Frame Ctrl 6 */

 R1357 (0x54d) - AIF2 Frame Ctrl 7 */

 R1358 (0x54e) - AIF2 Frame Ctrl 8 */

 R1359 (0x54f) - AIF2 Frame Ctrl 9 */

 R1360 (0x550) - AIF2 Frame Ctrl 10 */

 R1361 (0x551) - AIF2 Frame Ctrl 11 */

 R1362 (0x552) - AIF2 Frame Ctrl 12 */

 R1363 (0x553) - AIF2 Frame Ctrl 13 */

 R1364 (0x554) - AIF2 Frame Ctrl 14 */

 R1365 (0x555) - AIF2 Frame Ctrl 15 */

 R1366 (0x556) - AIF2 Frame Ctrl 16 */

 R1367 (0x557) - AIF2 Frame Ctrl 17 */

 R1368 (0x558) - AIF2 Frame Ctrl 18 */

 R1369 (0x559) - AIF2 Tx Enables */

 R1370 (0x55a) - AIF2 Rx Enables */

 R1408 (0x580) - AIF3 BCLK Ctrl */

 R1409 (0x581) - AIF3 Tx Pin Ctrl */

 R1410 (0x582) - AIF3 Rx Pin Ctrl */

 R1411 (0x583) - AIF3 Rate Ctrl */

 R1412 (0x584) - AIF3 Format */

 R1414 (0x586) - AIF3 Rx BCLK Rate */

 R1415 (0x587) - AIF3 Frame Ctrl 1 */

 R1416 (0x588) - AIF3 Frame Ctrl 2 */

 R1417 (0x589) - AIF3 Frame Ctrl 3 */

 R1418 (0x58a) - AIF3 Frame Ctrl 4 */

 R1425 (0x591) - AIF3 Frame Ctrl 11 */

 R1426 (0x592) - AIF3 Frame Ctrl 12 */

 R1433 (0x599) - AIF3 Tx Enables */

 R1434 (0x59a) - AIF3 Rx Enables */

 R1440 (0x5a0) - AIF4 BCLK Ctrl */

 R1441 (0x5a1) - AIF4 Tx Pin Ctrl */

 R1442 (0x5a2) - AIF4 Rx Pin Ctrl */

 R1443 (0x5a3) - AIF4 Rate Ctrl */

 R1444 (0x5a4) - AIF4 Format */

 R1446 (0x5a6) - AIF4 Rx BCLK Rate */

 R1447 (0x5a7) - AIF4 Frame Ctrl 1 */

 R1448 (0x5a8) - AIF4 Frame Ctrl 2 */

 R1449 (0x5a9) - AIF4 Frame Ctrl 3 */

 R1450 (0x5aa) - AIF4 Frame Ctrl 4 */

 R1457 (0x5b1) - AIF4 Frame Ctrl 11 */

 R1458 (0x5b2) - AIF4 Frame Ctrl 12 */

 R1465 (0x5b9) - AIF4 Tx Enables */

 R1466 (0x5ba) - AIF4 Rx Enables */

 R1474 (0x5c2) - SPD1 TX Control */

 R1507 (0x5e3) - SLIMbus Framer Ref Gear */

 R1509 (0x5e5) - SLIMbus Rates 1 */

 R1510 (0x5e6) - SLIMbus Rates 2 */

 R1511 (0x5e7) - SLIMbus Rates 3 */

 R1512 (0x5e8) - SLIMbus Rates 4 */

 R1513 (0x5e9) - SLIMbus Rates 5 */

 R1514 (0x5ea) - SLIMbus Rates 6 */

 R1515 (0x5eb) - SLIMbus Rates 7 */

 R1516 (0x5ec) - SLIMbus Rates 8 */

 R1525 (0x5f5) - SLIMbus RX Channel Enable */

 R1526 (0x5F6) - SLIMbus TX Channel Enable */

 R1600 (0x640) - PWM1MIX Input 1 Source */

 R1601 (0x641) - PWM1MIX Input 1 Volume */

 R1602 (0x642) - PWM1MIX Input 2 Source */

 R1603 (0x643) - PWM1MIX Input 2 Volume */

 R1604 (0x644) - PWM1MIX Input 3 Source */

 R1605 (0x645) - PWM1MIX Input 3 Volume */

 R1606 (0x646) - PWM1MIX Input 4 Source */

 R1607 (0x647) - PWM1MIX Input 4 Volume */

 R1608 (0x648) - PWM2MIX Input 1 Source */

 R1609 (0x649) - PWM2MIX Input 1 Volume */

 R1610 (0x64a) - PWM2MIX Input 2 Source */

 R1611 (0x64b) - PWM2MIX Input 2 Volume */

 R1612 (0x64c) - PWM2MIX Input 3 Source */

 R1613 (0x64d) - PWM2MIX Input 3 Volume */

 R1614 (0x64e) - PWM2MIX Input 4 Source */

 R1615 (0x64f) - PWM2MIX Input 4 Volume */

 R1664 (0x680) - OUT1LMIX Input 1 Source */

 R1665 (0x681) - OUT1LMIX Input 1 Volume */

 R1666 (0x682) - OUT1LMIX Input 2 Source */

 R1667 (0x683) - OUT1LMIX Input 2 Volume */

 R1668 (0x684) - OUT1LMIX Input 3 Source */

 R1669 (0x685) - OUT1LMIX Input 3 Volume */

 R1670 (0x686) - OUT1LMIX Input 4 Source */

 R1671 (0x687) - OUT1LMIX Input 4 Volume */

 R1672 (0x688) - OUT1RMIX Input 1 Source */

 R1673 (0x689) - OUT1RMIX Input 1 Volume */

 R1674 (0x68a) - OUT1RMIX Input 2 Source */

 R1675 (0x68b) - OUT1RMIX Input 2 Volume */

 R1672 (0x68c) - OUT1RMIX Input 3 Source */

 R1673 (0x68d) - OUT1RMIX Input 3 Volume */

 R1674 (0x68e) - OUT1RMIX Input 4 Source */

 R1675 (0x68f) - OUT1RMIX Input 4 Volume */

 R1680 (0x690) - OUT2LMIX Input 1 Source */

 R1681 (0x691) - OUT2LMIX Input 1 Volume */

 R1682 (0x692) - OUT2LMIX Input 2 Source */

 R1683 (0x693) - OUT2LMIX Input 2 Volume */

 R1684 (0x694) - OUT2LMIX Input 3 Source */

 R1685 (0x695) - OUT2LMIX Input 3 Volume */

 R1686 (0x696) - OUT2LMIX Input 4 Source */

 R1687 (0x697) - OUT2LMIX Input 4 Volume */

 R1688 (0x698) - OUT2RMIX Input 1 Source */

 R1689 (0x699) - OUT2RMIX Input 1 Volume */

 R1690 (0x69a) - OUT2RMIX Input 2 Source */

 R1691 (0x69b) - OUT2RMIX Input 2 Volume */

 R1692 (0x69c) - OUT2RMIX Input 3 Source */

 R1693 (0x69d) - OUT2RMIX Input 3 Volume */

 R1694 (0x69e) - OUT2RMIX Input 4 Source */

 R1695 (0x69f) - OUT2RMIX Input 4 Volume */

 R1696 (0x6a0) - OUT3LMIX Input 1 Source */

 R1697 (0x6a1) - OUT3LMIX Input 1 Volume */

 R1698 (0x6a2) - OUT3LMIX Input 2 Source */

 R1699 (0x6a3) - OUT3LMIX Input 2 Volume */

 R1700 (0x6a4) - OUT3LMIX Input 3 Source */

 R1701 (0x6a5) - OUT3LMIX Input 3 Volume */

 R1702 (0x6a6) - OUT3LMIX Input 4 Source */

 R1703 (0x6a7) - OUT3LMIX Input 4 Volume */

 R1704 (0x6a8) - OUT3RMIX Input 1 Source */

 R1705 (0x6a9) - OUT3RMIX Input 1 Volume */

 R1706 (0x6aa) - OUT3RMIX Input 2 Source */

 R1707 (0x6ab) - OUT3RMIX Input 2 Volume */

 R1708 (0x6ac) - OUT3RMIX Input 3 Source */

 R1709 (0x6ad) - OUT3RMIX Input 3 Volume */

 R1710 (0x6ae) - OUT3RMIX Input 4 Source */

 R1711 (0x6af) - OUT3RMIX Input 4 Volume */

 R1712 (0x6b0) - OUT4LMIX Input 1 Source */

 R1713 (0x6b1) - OUT4LMIX Input 1 Volume */

 R1714 (0x6b2) - OUT4LMIX Input 2 Source */

 R1715 (0x6b3) - OUT4LMIX Input 2 Volume */

 R1716 (0x6b4) - OUT4LMIX Input 3 Source */

 R1717 (0x6b5) - OUT4LMIX Input 3 Volume */

 R1718 (0x6b6) - OUT4LMIX Input 4 Source */

 R1719 (0x6b7) - OUT4LMIX Input 4 Volume */

 R1720 (0x6b8) - OUT4RMIX Input 1 Source */

 R1721 (0x6b9) - OUT4RMIX Input 1 Volume */

 R1722 (0x6ba) - OUT4RMIX Input 2 Source */

 R1723 (0x6bb) - OUT4RMIX Input 2 Volume */

 R1724 (0x6bc) - OUT4RMIX Input 3 Source */

 R1725 (0x6bd) - OUT4RMIX Input 3 Volume */

 R1726 (0x6be) - OUT4RMIX Input 4 Source */

 R1727 (0x6bf) - OUT4RMIX Input 4 Volume */

 R1728 (0x6c0) - OUT5LMIX Input 1 Source */

 R1729 (0x6c1) - OUT5LMIX Input 1 Volume */

 R1730 (0x6c2) - OUT5LMIX Input 2 Source */

 R1731 (0x6c3) - OUT5LMIX Input 2 Volume */

 R1732 (0x6c4) - OUT5LMIX Input 3 Source */

 R1733 (0x6c5) - OUT5LMIX Input 3 Volume */

 R1734 (0x6c6) - OUT5LMIX Input 4 Source */

 R1735 (0x6c7) - OUT5LMIX Input 4 Volume */

 R1736 (0x6c8) - OUT5RMIX Input 1 Source */

 R1737 (0x6c9) - OUT5RMIX Input 1 Volume */

 R1738 (0x6ca) - OUT5RMIX Input 2 Source */

 R1739 (0x6cb) - OUT5RMIX Input 2 Volume */

 R1740 (0x6cc) - OUT5RMIX Input 3 Source */

 R1741 (0x6cd) - OUT5RMIX Input 3 Volume */

 R1742 (0x6ce) - OUT5RMIX Input 4 Source */

 R1743 (0x6cf) - OUT5RMIX Input 4 Volume */

 R1744 (0x6d0) - OUT6LMIX Input 1 Source */

 R1745 (0x6d1) - OUT6LMIX Input 1 Volume */

 R1746 (0x6d2) - OUT6LMIX Input 2 Source */

 R1747 (0x6d3) - OUT6LMIX Input 2 Volume */

 R1748 (0x6d4) - OUT6LMIX Input 3 Source */

 R1749 (0x6d5) - OUT6LMIX Input 3 Volume */

 R1750 (0x6d6) - OUT6LMIX Input 4 Source */

 R1751 (0x6d7) - OUT6LMIX Input 4 Volume */

 R1752 (0x6d8) - OUT6RMIX Input 1 Source */

 R1753 (0x6d9) - OUT6RMIX Input 1 Volume */

 R1754 (0x6da) - OUT6RMIX Input 2 Source */

 R1755 (0x6db) - OUT6RMIX Input 2 Volume */

 R1756 (0x6dc) - OUT6RMIX Input 3 Source */

 R1757 (0x6dd) - OUT6RMIX Input 3 Volume */

 R1758 (0x6de) - OUT6RMIX Input 4 Source */

 R1759 (0x6df) - OUT6RMIX Input 4 Volume */

 R1792 (0x700) - AIF1TX1MIX Input 1 Source */

 R1793 (0x701) - AIF1TX1MIX Input 1 Volume */

 R1794 (0x702) - AIF1TX1MIX Input 2 Source */

 R1795 (0x703) - AIF1TX1MIX Input 2 Volume */

 R1796 (0x704) - AIF1TX1MIX Input 3 Source */

 R1797 (0x705) - AIF1TX1MIX Input 3 Volume */

 R1798 (0x706) - AIF1TX1MIX Input 4 Source */

 R1799 (0x707) - AIF1TX1MIX Input 4 Volume */

 R1800 (0x708) - AIF1TX2MIX Input 1 Source */

 R1801 (0x709) - AIF1TX2MIX Input 1 Volume */

 R1802 (0x70a) - AIF1TX2MIX Input 2 Source */

 R1803 (0x70b) - AIF1TX2MIX Input 2 Volume */

 R1804 (0x70c) - AIF1TX2MIX Input 3 Source */

 R1805 (0x70d) - AIF1TX2MIX Input 3 Volume */

 R1806 (0x70e) - AIF1TX2MIX Input 4 Source */

 R1807 (0x70f) - AIF1TX2MIX Input 4 Volume */

 R1808 (0x710) - AIF1TX3MIX Input 1 Source */

 R1809 (0x711) - AIF1TX3MIX Input 1 Volume */

 R1810 (0x712) - AIF1TX3MIX Input 2 Source */

 R1811 (0x713) - AIF1TX3MIX Input 2 Volume */

 R1812 (0x714) - AIF1TX3MIX Input 3 Source */

 R1813 (0x715) - AIF1TX3MIX Input 3 Volume */

 R1814 (0x716) - AIF1TX3MIX Input 4 Source */

 R1815 (0x717) - AIF1TX3MIX Input 4 Volume */

 R1816 (0x718) - AIF1TX4MIX Input 1 Source */

 R1817 (0x719) - AIF1TX4MIX Input 1 Volume */

 R1818 (0x71a) - AIF1TX4MIX Input 2 Source */

 R1819 (0x71b) - AIF1TX4MIX Input 2 Volume */

 R1820 (0x71c) - AIF1TX4MIX Input 3 Source */

 R1821 (0x71d) - AIF1TX4MIX Input 3 Volume */

 R1822 (0x71e) - AIF1TX4MIX Input 4 Source */

 R1823 (0x71f) - AIF1TX4MIX Input 4 Volume */

 R1824 (0x720) - AIF1TX5MIX Input 1 Source */

 R1825 (0x721) - AIF1TX5MIX Input 1 Volume */

 R1826 (0x722) - AIF1TX5MIX Input 2 Source */

 R1827 (0x723) - AIF1TX5MIX Input 2 Volume */

 R1828 (0x724) - AIF1TX5MIX Input 3 Source */

 R1829 (0x725) - AIF1TX5MIX Input 3 Volume */

 R1830 (0x726) - AIF1TX5MIX Input 4 Source */

 R1831 (0x727) - AIF1TX5MIX Input 4 Volume */

 R1832 (0x728) - AIF1TX6MIX Input 1 Source */

 R1833 (0x729) - AIF1TX6MIX Input 1 Volume */

 R1834 (0x72a) - AIF1TX6MIX Input 2 Source */

 R1835 (0x72b) - AIF1TX6MIX Input 2 Volume */

 R1836 (0x72c) - AIF1TX6MIX Input 3 Source */

 R1837 (0x72d) - AIF1TX6MIX Input 3 Volume */

 R1838 (0x72e) - AIF1TX6MIX Input 4 Source */

 R1839 (0x72f) - AIF1TX6MIX Input 4 Volume */

 R1840 (0x730) - AIF1TX7MIX Input 1 Source */

 R1841 (0x731) - AIF1TX7MIX Input 1 Volume */

 R1842 (0x732) - AIF1TX7MIX Input 2 Source */

 R1843 (0x733) - AIF1TX7MIX Input 2 Volume */

 R1844 (0x734) - AIF1TX7MIX Input 3 Source */

 R1845 (0x735) - AIF1TX7MIX Input 3 Volume */

 R1846 (0x736) - AIF1TX7MIX Input 4 Source */

 R1847 (0x737) - AIF1TX7MIX Input 4 Volume */

 R1848 (0x738) - AIF1TX8MIX Input 1 Source */

 R1849 (0x739) - AIF1TX8MIX Input 1 Volume */

 R1850 (0x73a) - AIF1TX8MIX Input 2 Source */

 R1851 (0x73b) - AIF1TX8MIX Input 2 Volume */

 R1852 (0x73c) - AIF1TX8MIX Input 3 Source */

 R1853 (0x73d) - AIF1TX8MIX Input 3 Volume */

 R1854 (0x73e) - AIF1TX8MIX Input 4 Source */

 R1855 (0x73f) - AIF1TX8MIX Input 4 Volume */

 R1856 (0x740) - AIF2TX1MIX Input 1 Source */

 R1857 (0x741) - AIF2TX1MIX Input 1 Volume */

 R1858 (0x742) - AIF2TX1MIX Input 2 Source */

 R1859 (0x743) - AIF2TX1MIX Input 2 Volume */

 R1860 (0x744) - AIF2TX1MIX Input 3 Source */

 R1861 (0x745) - AIF2TX1MIX Input 3 Volume */

 R1862 (0x746) - AIF2TX1MIX Input 4 Source */

 R1863 (0x747) - AIF2TX1MIX Input 4 Volume */

 R1864 (0x748) - AIF2TX2MIX Input 1 Source */

 R1865 (0x749) - AIF2TX2MIX Input 1 Volume */

 R1866 (0x74a) - AIF2TX2MIX Input 2 Source */

 R1867 (0x74b) - AIF2TX2MIX Input 2 Volume */

 R1868 (0x74c) - AIF2TX2MIX Input 3 Source */

 R1869 (0x74d) - AIF2TX2MIX Input 3 Volume */

 R1870 (0x74e) - AIF2TX2MIX Input 4 Source */

 R1871 (0x74f) - AIF2TX2MIX Input 4 Volume */

 R1872 (0x750) - AIF2TX3MIX Input 1 Source */

 R1873 (0x751) - AIF2TX3MIX Input 1 Volume */

 R1874 (0x752) - AIF2TX3MIX Input 2 Source */

 R1875 (0x753) - AIF2TX3MIX Input 2 Volume */

 R1876 (0x754) - AIF2TX3MIX Input 3 Source */

 R1877 (0x755) - AIF2TX3MIX Input 3 Volume */

 R1878 (0x756) - AIF2TX3MIX Input 4 Source */

 R1879 (0x757) - AIF2TX3MIX Input 4 Volume */

 R1880 (0x758) - AIF2TX4MIX Input 1 Source */

 R1881 (0x759) - AIF2TX4MIX Input 1 Volume */

 R1882 (0x75a) - AIF2TX4MIX Input 2 Source */

 R1883 (0x75b) - AIF2TX4MIX Input 2 Volume */

 R1884 (0x75c) - AIF2TX4MIX Input 3 Source */

 R1885 (0x75d) - AIF2TX4MIX Input 3 Volume */

 R1886 (0x75e) - AIF2TX4MIX Input 4 Source */

 R1887 (0x75f) - AIF2TX4MIX Input 4 Volume */

 R1888 (0x760) - AIF2TX5MIX Input 1 Source */

 R1889 (0x761) - AIF2TX5MIX Input 1 Volume */

 R1890 (0x762) - AIF2TX5MIX Input 2 Source */

 R1891 (0x763) - AIF2TX5MIX Input 2 Volume */

 R1892 (0x764) - AIF2TX5MIX Input 3 Source */

 R1893 (0x765) - AIF2TX5MIX Input 3 Volume */

 R1894 (0x766) - AIF2TX5MIX Input 4 Source */

 R1895 (0x767) - AIF2TX5MIX Input 4 Volume */

 R1896 (0x768) - AIF2TX6MIX Input 1 Source */

 R1897 (0x769) - AIF2TX6MIX Input 1 Volume */

 R1898 (0x76a) - AIF2TX6MIX Input 2 Source */

 R1899 (0x76b) - AIF2TX6MIX Input 2 Volume */

 R1900 (0x76c) - AIF2TX6MIX Input 3 Source */

 R1901 (0x76d) - AIF2TX6MIX Input 3 Volume */

 R1902 (0x76e) - AIF2TX6MIX Input 4 Source */

 R1903 (0x76f) - AIF2TX6MIX Input 4 Volume */

 R1904 (0x770) - AIF2TX7MIX Input 1 Source */

 R1905 (0x771) - AIF2TX7MIX Input 1 Volume */

 R1906 (0x772) - AIF2TX7MIX Input 2 Source */

 R1907 (0x773) - AIF2TX7MIX Input 2 Volume */

 R1908 (0x774) - AIF2TX7MIX Input 3 Source */

 R1909 (0x775) - AIF2TX7MIX Input 3 Volume */

 R1910 (0x776) - AIF2TX7MIX Input 4 Source */

 R1911 (0x777) - AIF2TX7MIX Input 4 Volume */

 R1912 (0x778) - AIF2TX8MIX Input 1 Source */

 R1913 (0x779) - AIF2TX8MIX Input 1 Volume */

 R1914 (0x77a) - AIF2TX8MIX Input 2 Source */

 R1915 (0x77b) - AIF2TX8MIX Input 2 Volume */

 R1916 (0x77c) - AIF2TX8MIX Input 3 Source */

 R1917 (0x77d) - AIF2TX8MIX Input 3 Volume */

 R1918 (0x77e) - AIF2TX8MIX Input 4 Source */

 R1919 (0x77f) - AIF2TX8MIX Input 4 Volume */

 R1920 (0x780) - AIF3TX1MIX Input 1 Source */

 R1921 (0x781) - AIF3TX1MIX Input 1 Volume */

 R1922 (0x782) - AIF3TX1MIX Input 2 Source */

 R1923 (0x783) - AIF3TX1MIX Input 2 Volume */

 R1924 (0x784) - AIF3TX1MIX Input 3 Source */

 R1925 (0x785) - AIF3TX1MIX Input 3 Volume */

 R1926 (0x786) - AIF3TX1MIX Input 4 Source */

 R1927 (0x787) - AIF3TX1MIX Input 4 Volume */

 R1928 (0x788) - AIF3TX2MIX Input 1 Source */

 R1929 (0x789) - AIF3TX2MIX Input 1 Volume */

 R1930 (0x78a) - AIF3TX2MIX Input 2 Source */

 R1931 (0x78b) - AIF3TX2MIX Input 2 Volume */

 R1932 (0x78c) - AIF3TX2MIX Input 3 Source */

 R1933 (0x78d) - AIF3TX2MIX Input 3 Volume */

 R1934 (0x78e) - AIF3TX2MIX Input 4 Source */

 R1935 (0x78f) - AIF3TX2MIX Input 4 Volume */

 R1952 (0x7a0) - AIF4TX1MIX Input 1 Source */

 R1953 (0x7a1) - AIF4TX1MIX Input 1 Volume */

 R1954 (0x7a2) - AIF4TX1MIX Input 2 Source */

 R1955 (0x7a3) - AIF4TX1MIX Input 2 Volume */

 R1956 (0x7a4) - AIF4TX1MIX Input 3 Source */

 R1957 (0x7a5) - AIF4TX1MIX Input 3 Volume */

 R1958 (0x7a6) - AIF4TX1MIX Input 4 Source */

 R1959 (0x7a7) - AIF4TX1MIX Input 4 Volume */

 R1960 (0x7a8) - AIF4TX2MIX Input 1 Source */

 R1961 (0x7a9) - AIF4TX2MIX Input 1 Volume */

 R1962 (0x7aa) - AIF4TX2MIX Input 2 Source */

 R1963 (0x7ab) - AIF4TX2MIX Input 2 Volume */

 R1964 (0x7ac) - AIF4TX2MIX Input 3 Source */

 R1965 (0x7ad) - AIF4TX2MIX Input 3 Volume */

 R1966 (0x7ae) - AIF4TX2MIX Input 4 Source */

 R1967 (0x7af) - AIF4TX2MIX Input 4 Volume */

 R1984 (0x7c0) - SLIMTX1MIX Input 1 Source */

 R1985 (0x7c1) - SLIMTX1MIX Input 1 Volume */

 R1986 (0x7c2) - SLIMTX1MIX Input 2 Source */

 R1987 (0x7c3) - SLIMTX1MIX Input 2 Volume */

 R1988 (0x7c4) - SLIMTX1MIX Input 3 Source */

 R1989 (0x7c5) - SLIMTX1MIX Input 3 Volume */

 R1990 (0x7c6) - SLIMTX1MIX Input 4 Source */

 R1991 (0x7c7) - SLIMTX1MIX Input 4 Volume */

 R1992 (0x7c8) - SLIMTX2MIX Input 1 Source */

 R1993 (0x7c9) - SLIMTX2MIX Input 1 Volume */

 R1994 (0x7ca) - SLIMTX2MIX Input 2 Source */

 R1995 (0x7cb) - SLIMTX2MIX Input 2 Volume */

 R1996 (0x7cc) - SLIMTX2MIX Input 3 Source */

 R1997 (0x7cd) - SLIMTX2MIX Input 3 Volume */

 R1998 (0x7ce) - SLIMTX2MIX Input 4 Source */

 R1999 (0x7cf) - SLIMTX2MIX Input 4 Volume */

 R2000 (0x7d0) - SLIMTX3MIX Input 1 Source */

 R2001 (0x7d1) - SLIMTX3MIX Input 1 Volume */

 R2002 (0x7d2) - SLIMTX3MIX Input 2 Source */

 R2003 (0x7d3) - SLIMTX3MIX Input 2 Volume */

 R2004 (0x7d4) - SLIMTX3MIX Input 3 Source */

 R2005 (0x7d5) - SLIMTX3MIX Input 3 Volume */

 R2006 (0x7d6) - SLIMTX3MIX Input 4 Source */

 R2007 (0x7d7) - SLIMTX3MIX Input 4 Volume */

 R2008 (0x7d8) - SLIMTX4MIX Input 1 Source */

 R2009 (0x7d9) - SLIMTX4MIX Input 1 Volume */

 R2010 (0x7da) - SLIMTX4MIX Input 2 Source */

 R2011 (0x7db) - SLIMTX4MIX Input 2 Volume */

 R2012 (0x7dc) - SLIMTX4MIX Input 3 Source */

 R2013 (0x7dd) - SLIMTX4MIX Input 3 Volume */

 R2014 (0x7de) - SLIMTX4MIX Input 4 Source */

 R2015 (0x7df) - SLIMTX4MIX Input 4 Volume */

 R2016 (0x7e0) - SLIMTX5MIX Input 1 Source */

 R2017 (0x7e1) - SLIMTX5MIX Input 1 Volume */

 R2018 (0x7e2) - SLIMTX5MIX Input 2 Source */

 R2019 (0x7e3) - SLIMTX5MIX Input 2 Volume */

 R2020 (0x7e4) - SLIMTX5MIX Input 3 Source */

 R2021 (0x7e5) - SLIMTX5MIX Input 3 Volume */

 R2022 (0x7e6) - SLIMTX5MIX Input 4 Source */

 R2023 (0x7e7) - SLIMTX5MIX Input 4 Volume */

 R2024 (0x7e8) - SLIMTX6MIX Input 1 Source */

 R2025 (0x7e9) - SLIMTX6MIX Input 1 Volume */

 R2026 (0x7ea) - SLIMTX6MIX Input 2 Source */

 R2027 (0x7eb) - SLIMTX6MIX Input 2 Volume */

 R2028 (0x7ec) - SLIMTX6MIX Input 3 Source */

 R2029 (0x7ed) - SLIMTX6MIX Input 3 Volume */

 R2030 (0x7ee) - SLIMTX6MIX Input 4 Source */

 R2031 (0x7ef) - SLIMTX6MIX Input 4 Volume */

 R2032 (0x7f0) - SLIMTX7MIX Input 1 Source */

 R2033 (0x7f1) - SLIMTX7MIX Input 1 Volume */

 R2034 (0x7f2) - SLIMTX7MIX Input 2 Source */

 R2035 (0x7f3) - SLIMTX7MIX Input 2 Volume */

 R2036 (0x7f4) - SLIMTX7MIX Input 3 Source */

 R2037 (0x7f5) - SLIMTX7MIX Input 3 Volume */

 R2038 (0x7f6) - SLIMTX7MIX Input 4 Source */

 R2039 (0x7f7) - SLIMTX7MIX Input 4 Volume */

 R2040 (0x7f8) - SLIMTX8MIX Input 1 Source */

 R2041 (0x7f9) - SLIMTX8MIX Input 1 Volume */

 R2042 (0x7fa) - SLIMTX8MIX Input 2 Source */

 R2043 (0x7fb) - SLIMTX8MIX Input 2 Volume */

 R2044 (0x7fc) - SLIMTX8MIX Input 3 Source */

 R2045 (0x7fd) - SLIMTX8MIX Input 3 Volume */

 R2046 (0x7fe) - SLIMTX8MIX Input 4 Source */

 R2047 (0x7ff) - SLIMTX8MIX Input 4 Volume */

 R2048 (0x800) - SPDIF1TX1MIX Input 1 Source */

 R2049 (0x801) - SPDIF1TX1MIX Input 1 Volume */

 R2056 (0x808) - SPDIF1TX2MIX Input 1 Source */

 R2057 (0x809) - SPDIF1TX2MIX Input 1 Volume */

 R2176 (0x880) - EQ1MIX Input 1 Source */

 R2177 (0x881) - EQ1MIX Input 1 Volume */

 R2178 (0x882) - EQ1MIX Input 2 Source */

 R2179 (0x883) - EQ1MIX Input 2 Volume */

 R2180 (0x884) - EQ1MIX Input 3 Source */

 R2181 (0x885) - EQ1MIX Input 3 Volume */

 R2182 (0x886) - EQ1MIX Input 4 Source */

 R2183 (0x887) - EQ1MIX Input 4 Volume */

 R2184 (0x888) - EQ2MIX Input 1 Source */

 R2185 (0x889) - EQ2MIX Input 1 Volume */

 R2186 (0x88a) - EQ2MIX Input 2 Source */

 R2187 (0x88b) - EQ2MIX Input 2 Volume */

 R2188 (0x88c) - EQ2MIX Input 3 Source */

 R2189 (0x88d) - EQ2MIX Input 3 Volume */

 R2190 (0x88e) - EQ2MIX Input 4 Source */

 R2191 (0x88f) - EQ2MIX Input 4 Volume */

 R2192 (0x890) - EQ3MIX Input 1 Source */

 R2193 (0x891) - EQ3MIX Input 1 Volume */

 R2194 (0x892) - EQ3MIX Input 2 Source */

 R2195 (0x893) - EQ3MIX Input 2 Volume */

 R2196 (0x894) - EQ3MIX Input 3 Source */

 R2197 (0x895) - EQ3MIX Input 3 Volume */

 R2198 (0x896) - EQ3MIX Input 4 Source */

 R2199 (0x897) - EQ3MIX Input 4 Volume */

 R2200 (0x898) - EQ4MIX Input 1 Source */

 R2201 (0x899) - EQ4MIX Input 1 Volume */

 R2202 (0x89a) - EQ4MIX Input 2 Source */

 R2203 (0x89b) - EQ4MIX Input 2 Volume */

 R2204 (0x89c) - EQ4MIX Input 3 Source */

 R2205 (0x89d) - EQ4MIX Input 3 Volume */

 R2206 (0x89e) - EQ4MIX Input 4 Source */

 R2207 (0x89f) - EQ4MIX Input 4 Volume */

 R2240 (0x8c0) - DRC1LMIX Input 1 Source */

 R2241 (0x8c1) - DRC1LMIX Input 1 Volume */

 R2242 (0x8c2) - DRC1LMIX Input 2 Source */

 R2243 (0x8c3) - DRC1LMIX Input 2 Volume */

 R2244 (0x8c4) - DRC1LMIX Input 3 Source */

 R2245 (0x8c5) - DRC1LMIX Input 3 Volume */

 R2246 (0x8c6) - DRC1LMIX Input 4 Source */

 R2247 (0x8c7) - DRC1LMIX Input 4 Volume */

 R2248 (0x8c8) - DRC1RMIX Input 1 Source */

 R2249 (0x8c9) - DRC1RMIX Input 1 Volume */

 R2250 (0x8ca) - DRC1RMIX Input 2 Source */

 R2251 (0x8cb) - DRC1RMIX Input 2 Volume */

 R2252 (0x8cc) - DRC1RMIX Input 3 Source */

 R2253 (0x8cd) - DRC1RMIX Input 3 Volume */

 R2254 (0x8ce) - DRC1RMIX Input 4 Source */

 R2255 (0x8cf) - DRC1RMIX Input 4 Volume */

 R2256 (0x8d0) - DRC2LMIX Input 1 Source */

 R2257 (0x8d1) - DRC2LMIX Input 1 Volume */

 R2258 (0x8d2) - DRC2LMIX Input 2 Source */

 R2259 (0x8d3) - DRC2LMIX Input 2 Volume */

 R2260 (0x8d4) - DRC2LMIX Input 3 Source */

 R2261 (0x8d5) - DRC2LMIX Input 3 Volume */

 R2262 (0x8d6) - DRC2LMIX Input 4 Source */

 R2263 (0x8d7) - DRC2LMIX Input 4 Volume */

 R2264 (0x8d8) - DRC2RMIX Input 1 Source */

 R2265 (0x8d9) - DRC2RMIX Input 1 Volume */

 R2266 (0x8da) - DRC2RMIX Input 2 Source */

 R2267 (0x8db) - DRC2RMIX Input 2 Volume */

 R2268 (0x8dc) - DRC2RMIX Input 3 Source */

 R2269 (0x8dd) - DRC2RMIX Input 3 Volume */

 R2270 (0x8de) - DRC2RMIX Input 4 Source */

 R2271 (0x8df) - DRC2RMIX Input 4 Volume */

 R2304 (0x900) - HPLP1MIX Input 1 Source */

 R2305 (0x901) - HPLP1MIX Input 1 Volume */

 R2306 (0x902) - HPLP1MIX Input 2 Source */

 R2307 (0x903) - HPLP1MIX Input 2 Volume */

 R2308 (0x904) - HPLP1MIX Input 3 Source */

 R2309 (0x905) - HPLP1MIX Input 3 Volume */

 R2310 (0x906) - HPLP1MIX Input 4 Source */

 R2311 (0x907) - HPLP1MIX Input 4 Volume */

 R2312 (0x908) - HPLP2MIX Input 1 Source */

 R2313 (0x909) - HPLP2MIX Input 1 Volume */

 R2314 (0x90a) - HPLP2MIX Input 2 Source */

 R2315 (0x90b) - HPLP2MIX Input 2 Volume */

 R2316 (0x90c) - HPLP2MIX Input 3 Source */

 R2317 (0x90d) - HPLP2MIX Input 3 Volume */

 R2318 (0x90e) - HPLP2MIX Input 4 Source */

 R2319 (0x90f) - HPLP2MIX Input 4 Volume */

 R2320 (0x910) - HPLP3MIX Input 1 Source */

 R2321 (0x911) - HPLP3MIX Input 1 Volume */

 R2322 (0x912) - HPLP3MIX Input 2 Source */

 R2323 (0x913) - HPLP3MIX Input 2 Volume */

 R2324 (0x914) - HPLP3MIX Input 3 Source */

 R2325 (0x915) - HPLP3MIX Input 3 Volume */

 R2326 (0x916) - HPLP3MIX Input 4 Source */

 R2327 (0x917) - HPLP3MIX Input 4 Volume */

 R2328 (0x918) - HPLP4MIX Input 1 Source */

 R2329 (0x919) - HPLP4MIX Input 1 Volume */

 R2330 (0x91a) - HPLP4MIX Input 2 Source */

 R2331 (0x91b) - HPLP4MIX Input 2 Volume */

 R2332 (0x91c) - HPLP4MIX Input 3 Source */

 R2333 (0x91d) - HPLP4MIX Input 3 Volume */

 R2334 (0x91e) - HPLP4MIX Input 4 Source */

 R2335 (0x91f) - HPLP4MIX Input 4 Volume */

 R2368 (0x940) - DSP1LMIX Input 1 Source */

 R2369 (0x941) - DSP1LMIX Input 1 Volume */

 R2370 (0x942) - DSP1LMIX Input 2 Source */

 R2371 (0x943) - DSP1LMIX Input 2 Volume */

 R2372 (0x944) - DSP1LMIX Input 3 Source */

 R2373 (0x945) - DSP1LMIX Input 3 Volume */

 R2374 (0x946) - DSP1LMIX Input 4 Source */

 R2375 (0x947) - DSP1LMIX Input 4 Volume */

 R2376 (0x948) - DSP1RMIX Input 1 Source */

 R2377 (0x949) - DSP1RMIX Input 1 Volume */

 R2378 (0x94a) - DSP1RMIX Input 2 Source */

 R2379 (0x94b) - DSP1RMIX Input 2 Volume */

 R2380 (0x94c) - DSP1RMIX Input 3 Source */

 R2381 (0x94d) - DSP1RMIX Input 3 Volume */

 R2382 (0x94e) - DSP1RMIX Input 4 Source */

 R2383 (0x94f) - DSP1RMIX Input 4 Volume */

 R2384 (0x950) - DSP1AUX1MIX Input 1 Source */

 R2392 (0x958) - DSP1AUX2MIX Input 1 Source */

 R2400 (0x960) - DSP1AUX3MIX Input 1 Source */

 R2408 (0x968) - DSP1AUX4MIX Input 1 Source */

 R2416 (0x970) - DSP1AUX5MIX Input 1 Source */

 R2424 (0x978) - DSP1AUX6MIX Input 1 Source */

 R2432 (0x980) - DSP2LMIX Input 1 Source */

 R2433 (0x981) - DSP2LMIX Input 1 Volume */

 R2434 (0x982) - DSP2LMIX Input 2 Source */

 R2435 (0x983) - DSP2LMIX Input 2 Volume */

 R2436 (0x984) - DSP2LMIX Input 3 Source */

 R2437 (0x985) - DSP2LMIX Input 3 Volume */

 R2438 (0x986) - DSP2LMIX Input 4 Source */

 R2439 (0x987) - DSP2LMIX Input 4 Volume */

 R2440 (0x988) - DSP2RMIX Input 1 Source */

 R2441 (0x989) - DSP2RMIX Input 1 Volume */

 R2442 (0x98a) - DSP2RMIX Input 2 Source */

 R2443 (0x98b) - DSP2RMIX Input 2 Volume */

 R2444 (0x98c) - DSP2RMIX Input 3 Source */

 R2445 (0x98d) - DSP2RMIX Input 3 Volume */

 R2446 (0x98e) - DSP2RMIX Input 4 Source */

 R2447 (0x98f) - DSP2RMIX Input 4 Volume */

 R2448 (0x990) - DSP2AUX1MIX Input 1 Source */

 R2456 (0x998) - DSP2AUX2MIX Input 1 Source */

 R2464 (0x9a0) - DSP2AUX3MIX Input 1 Source */

 R2472 (0x9a8) - DSP2AUX4MIX Input 1 Source */

 R2480 (0x9b0) - DSP2AUX5MIX Input 1 Source */

 R2488 (0x9b8) - DSP2AUX6MIX Input 1 Source */

 R2496 (0x9c0) - DSP3LMIX Input 1 Source */

 R2497 (0x9c1) - DSP3LMIX Input 1 Volume */

 R2498 (0x9c2) - DSP3LMIX Input 2 Source */

 R2499 (0x9c3) - DSP3LMIX Input 2 Volume */

 R2500 (0x9c4) - DSP3LMIX Input 3 Source */

 R2501 (0x9c5) - DSP3LMIX Input 3 Volume */

 R2502 (0x9c6) - DSP3LMIX Input 4 Source */

 R2503 (0x9c7) - DSP3LMIX Input 4 Volume */

 R2504 (0x9c8) - DSP3RMIX Input 1 Source */

 R2505 (0x9c9) - DSP3RMIX Input 1 Volume */

 R2506 (0x9ca) - DSP3RMIX Input 2 Source */

 R2507 (0x9cb) - DSP3RMIX Input 2 Volume */

 R2508 (0x9cc) - DSP3RMIX Input 3 Source */

 R2509 (0x9cd) - DSP3RMIX Input 3 Volume */

 R2510 (0x9ce) - DSP3RMIX Input 4 Source */

 R2511 (0x9cf) - DSP3RMIX Input 4 Volume */

 R2512 (0x9d0) - DSP3AUX1MIX Input 1 Source */

 R2520 (0x9d8) - DSP3AUX2MIX Input 1 Source */

 R2528 (0x9e0) - DSP3AUX3MIX Input 1 Source */

 R2536 (0x9e8) - DSP3AUX4MIX Input 1 Source */

 R2544 (0x9f0) - DSP3AUX5MIX Input 1 Source */

 R2552 (0x9f8) - DSP3AUX6MIX Input 1 Source */

 R2560 (0xa00) - DSP4LMIX Input 1 Source */

 R2561 (0xa01) - DSP4LMIX Input 1 Volume */

 R2562 (0xa02) - DSP4LMIX Input 2 Source */

 R2563 (0xa03) - DSP4LMIX Input 2 Volume */

 R2564 (0xa04) - DSP4LMIX Input 3 Source */

 R2565 (0xa05) - DSP4LMIX Input 3 Volume */

 R2566 (0xa06) - DSP4LMIX Input 4 Source */

 R2567 (0xa07) - DSP4LMIX Input 4 Volume */

 R2568 (0xa08) - DSP4RMIX Input 1 Source */

 R2569 (0xa09) - DSP4RMIX Input 1 Volume */

 R2570 (0xa0a) - DSP4RMIX Input 2 Source */

 R2571 (0xa0b) - DSP4RMIX Input 2 Volume */

 R2572 (0xa0c) - DSP4RMIX Input 3 Source */

 R2573 (0xa0d) - DSP4RMIX Input 3 Volume */

 R2574 (0xa0e) - DSP4RMIX Input 4 Source */

 R2575 (0xa0f) - DSP4RMIX Input 4 Volume */

 R2576 (0xa10) - DSP4AUX1MIX Input 1 Source */

 R2584 (0xa18) - DSP4AUX2MIX Input 1 Source */

 R2592 (0xa20) - DSP4AUX3MIX Input 1 Source */

 R2600 (0xa28) - DSP4AUX4MIX Input 1 Source */

 R2608 (0xa30) - DSP4AUX5MIX Input 1 Source */

 R2616 (0xa38) - DSP4AUX6MIX Input 1 Source */

 R2624 (0xa40) - DSP5LMIX Input 1 Source */

 R2625 (0xa41) - DSP5LMIX Input 1 Volume */

 R2626 (0xa42) - DSP5LMIX Input 2 Source */

 R2627 (0xa43) - DSP5LMIX Input 2 Volume */

 R2628 (0xa44) - DSP5LMIX Input 3 Source */

 R2629 (0xa45) - DSP5LMIX Input 3 Volume */

 R2630 (0xa46) - DSP5LMIX Input 4 Source */

 R2631 (0xa47) - DSP5LMIX Input 4 Volume */

 R2632 (0xa48) - DSP5RMIX Input 1 Source */

 R2633 (0xa49) - DSP5RMIX Input 1 Volume */

 R2634 (0xa4a) - DSP5RMIX Input 2 Source */

 R2635 (0xa4b) - DSP5RMIX Input 2 Volume */

 R2636 (0xa4c) - DSP5RMIX Input 3 Source */

 R2637 (0xa4d) - DSP5RMIX Input 3 Volume */

 R2638 (0xa4e) - DSP5RMIX Input 4 Source */

 R2639 (0xa4f) - DSP5RMIX Input 4 Volume */

 R2640 (0xa50) - DSP5AUX1MIX Input 1 Source */

 R2658 (0xa58) - DSP5AUX2MIX Input 1 Source */

 R2656 (0xa60) - DSP5AUX3MIX Input 1 Source */

 R2664 (0xa68) - DSP5AUX4MIX Input 1 Source */

 R2672 (0xa70) - DSP5AUX5MIX Input 1 Source */

 R2680 (0xa78) - DSP5AUX6MIX Input 1 Source */

 R2688 (0xa80) - ASRC1_1LMIX Input 1 Source */

 R2696 (0xa88) - ASRC1_1RMIX Input 1 Source */

 R2704 (0xa90) - ASRC1_2LMIX Input 1 Source */

 R2712 (0xa98) - ASRC1_2RMIX Input 1 Source */

 R2720 (0xaa0) - ASRC2_1LMIX Input 1 Source */

 R2728 (0xaa8) - ASRC2_1RMIX Input 1 Source */

 R2736 (0xab0) - ASRC2_2LMIX Input 1 Source */

 R2744 (0xab8) - ASRC2_2RMIX Input 1 Source */

 R2816 (0xb00) - ISRC1DEC1MIX Input 1 Source*/

 R2824 (0xb08) - ISRC1DEC2MIX Input 1 Source*/

 R2832 (0xb10) - ISRC1DEC3MIX Input 1 Source*/

 R2840 (0xb18) - ISRC1DEC4MIX Input 1 Source*/

 R2848 (0xb20) - ISRC1INT1MIX Input 1 Source*/

 R2856 (0xb28) - ISRC1INT2MIX Input 1 Source*/

 R2864 (0xb30) - ISRC1INT3MIX Input 1 Source*/

 R2872 (0xb38) - ISRC1INT4MIX Input 1 Source*/

 R2880 (0xb40) - ISRC2DEC1MIX Input 1 Source*/

 R2888 (0xb48) - ISRC2DEC2MIX Input 1 Source*/

 R2896 (0xb50) - ISRC2DEC3MIX Input 1 Source*/

 R2904 (0xb58) - ISRC2DEC4MIX Input 1 Source*/

 R2912 (0xb60) - ISRC2INT1MIX Input 1 Source*/

 R2920 (0xb68) - ISRC2INT2MIX Input 1 Source*/

 R2928 (0xb70) - ISRC2INT3MIX Input 1 Source*/

 R2936 (0xb78) - ISRC2INT4MIX Input 1 Source*/

 R2944 (0xb80) - ISRC3DEC1MIX Input 1 Source*/

 R2952 (0xb88) - ISRC3DEC2MIX Input 1 Source*/

 R2976 (0xb80) - ISRC3INT1MIX Input 1 Source*/

 R2984 (0xb88) - ISRC3INT2MIX Input 1 Source*/

 R3008 (0xbc0) - ISRC4DEC1MIX Input 1 Source */

 R3016 (0xbc8) - ISRC4DEC2MIX Input 1 Source */

 R3040 (0xbe0) - ISRC4INT1MIX Input 1 Source */

 R3048 (0xbe8) - ISRC4INT2MIX Input 1 Source */

 R3072 (0xc00) - DSP6LMIX Input 1 Source */

 R3073 (0xc01) - DSP6LMIX Input 1 Volume */

 R3074 (0xc02) - DSP6LMIX Input 2 Source */

 R3075 (0xc03) - DSP6LMIX Input 2 Volume */

 R3076 (0xc04) - DSP6LMIX Input 3 Source */

 R3077 (0xc05) - DSP6LMIX Input 3 Volume */

 R3078 (0xc06) - DSP6LMIX Input 4 Source */

 R3079 (0xc07) - DSP6LMIX Input 4 Volume */

 R3080 (0xc08) - DSP6RMIX Input 1 Source */

 R3081 (0xc09) - DSP6RMIX Input 1 Volume */

 R3082 (0xc0a) - DSP6RMIX Input 2 Source */

 R3083 (0xc0b) - DSP6RMIX Input 2 Volume */

 R3084 (0xc0c) - DSP6RMIX Input 3 Source */

 R3085 (0xc0d) - DSP6RMIX Input 3 Volume */

 R3086 (0xc0e) - DSP6RMIX Input 4 Source */

 R3087 (0xc0f) - DSP6RMIX Input 4 Volume */

 R3088 (0xc10) - DSP6AUX1MIX Input 1 Source */

 R3088 (0xc18) - DSP6AUX2MIX Input 1 Source */

 R3088 (0xc20) - DSP6AUX3MIX Input 1 Source */

 R3088 (0xc28) - DSP6AUX4MIX Input 1 Source */

 R3088 (0xc30) - DSP6AUX5MIX Input 1 Source */

 R3088 (0xc38) - DSP6AUX6MIX Input 1 Source */

 R3136 (0xc40) - DSP7LMIX Input 1 Source */

 R3137 (0xc41) - DSP7LMIX Input 1 Volume */

 R3138 (0xc42) - DSP7LMIX Input 2 Source */

 R3139 (0xc43) - DSP7LMIX Input 2 Volume */

 R3140 (0xc44) - DSP7LMIX Input 3 Source */

 R3141 (0xc45) - DSP7lMIX Input 3 Volume */

 R3142 (0xc46) - DSP7lMIX Input 4 Source */

 R3143 (0xc47) - DSP7LMIX Input 4 Volume */

 R3144 (0xc48) - DSP7RMIX Input 1 Source */

 R3145 (0xc49) - DSP7RMIX Input 1 Volume */

 R3146 (0xc4a) - DSP7RMIX Input 2 Source */

 R3147 (0xc4b) - DSP7RMIX Input 2 Volume */

 R3148 (0xc4c) - DSP7RMIX Input 3 Source */

 R3159 (0xc4d) - DSP7RMIX Input 3 Volume */

 R3150 (0xc4e) - DSP7RMIX Input 4 Source */

 R3151 (0xc4f) - DSP7RMIX Input 4 Volume */

 R3152 (0xc50) - DSP7AUX1MIX Input 1 Source */

 R3160 (0xc58) - DSP7AUX2MIX Input 1 Source */

 R3168 (0xc60) - DSP7AUX3MIX Input 1 Source */

 R3176 (0xc68) - DSP7AUX4MIX Input 1 Source */

 R3184 (0xc70) - DSP7AUX5MIX Input 1 Source */

 R3192 (0xc78) - DSP7AUX6MIX Input 1 Source */

 R3584 (0xe00) - FX Ctrl1 */

 R3600 (0xe10) - EQ1_1 */

 R3601 (0xe11) - EQ1_2 */

 R3602 (0xe12) - EQ1_3 */

 R3603 (0xe13) - EQ1_4 */

 R3604 (0xe14) - EQ1_5 */

 R3605 (0xe15) - EQ1_6 */

 R3606 (0xe16) - EQ1_7 */

 R3607 (0xe17) - EQ1_8 */

 R3608 (0xe18) - EQ1_9 */

 R3609 (0xe19) - EQ1_10 */

 R3610 (0xe1a) - EQ1_11 */

 R3611 (0xe1b) - EQ1_12 */

 R3612 (0xe1c) - EQ1_13 */

 R3613 (0xe1d) - EQ1_14 */

 R3614 (0xe1e) - EQ1_15 */

 R3615 (0xe1f) - EQ1_16 */

 R3616 (0xe20) - EQ1_17 */

 R3617 (0xe21) - EQ1_18 */

 R3618 (0xe22) - EQ1_19 */

 R3619 (0xe23) - EQ1_20 */

 R3620 (0xe24) - EQ1_21 */

 R3622 (0xe26) - EQ2_1 */

 R3623 (0xe27) - EQ2_2 */

 R3624 (0xe28) - EQ2_3 */

 R3625 (0xe29) - EQ2_4 */

 R3626 (0xe2a) - EQ2_5 */

 R3627 (0xe2b) - EQ2_6 */

 R3628 (0xe2c) - EQ2_7 */

 R3629 (0xe2d) - EQ2_8 */

 R3630 (0xe2e) - EQ2_9 */

 R3631 (0xe2f) - EQ2_10 */

 R3632 (0xe30) - EQ2_11 */

 R3633 (0xe31) - EQ2_12 */

 R3634 (0xe32) - EQ2_13 */

 R3635 (0xe33) - EQ2_14 */

 R3636 (0xe34) - EQ2_15 */

 R3637 (0xe35) - EQ2_16 */

 R3638 (0xe36) - EQ2_17 */

 R3639 (0xe37) - EQ2_18 */

 R3640 (0xe38) - EQ2_19 */

 R3641 (0xe39) - EQ2_20 */

 R3642 (0xe3a) - EQ2_21 */

 R3644 (0xe3c) - EQ3_1 */

 R3645 (0xe3d) - EQ3_2 */

 R3646 (0xe3e) - EQ3_3 */

 R3647 (0xe3f) - EQ3_4 */

 R3648 (0xe40) - EQ3_5 */

 R3649 (0xe41) - EQ3_6 */

 R3650 (0xe42) - EQ3_7 */

 R3651 (0xe43) - EQ3_8 */

 R3652 (0xe44) - EQ3_9 */

 R3653 (0xe45) - EQ3_10 */

 R3654 (0xe46) - EQ3_11 */

 R3655 (0xe47) - EQ3_12 */

 R3656 (0xe48) - EQ3_13 */

 R3657 (0xe49) - EQ3_14 */

 R3658 (0xe4a) - EQ3_15 */

 R3659 (0xe4b) - EQ3_16 */

 R3660 (0xe4c) - EQ3_17 */

 R3661 (0xe4d) - EQ3_18 */

 R3662 (0xe4e) - EQ3_19 */

 R3663 (0xe4f) - EQ3_20 */

 R3664 (0xe50) - EQ3_21 */

 R3666 (0xe52) - EQ4_1 */

 R3667 (0xe53) - EQ4_2 */

 R3668 (0xe54) - EQ4_3 */

 R3669 (0xe55) - EQ4_4 */

 R3670 (0xe56) - EQ4_5 */

 R3671 (0xe57) - EQ4_6 */

 R3672 (0xe58) - EQ4_7 */

 R3673 (0xe59) - EQ4_8 */

 R3674 (0xe5a) - EQ4_9 */

 R3675 (0xe5b) - EQ4_10 */

 R3676 (0xe5c) - EQ4_11 */

 R3677 (0xe5d) - EQ4_12 */

 R3678 (0xe5e) - EQ4_13 */

 R3679 (0xe5f) - EQ4_14 */

 R3680 (0xe60) - EQ4_15 */

 R3681 (0xe61) - EQ4_16 */

 R3682 (0xe62) - EQ4_17 */

 R3683 (0xe63) - EQ4_18 */

 R3684 (0xe64) - EQ4_19 */

 R3685 (0xe65) - EQ4_20 */

 R3686 (0xe66) - EQ4_21 */

 R3712 (0xe80) - DRC1 ctrl1 */

 R3713 (0xe81) - DRC1 ctrl2 */

 R3714 (0xe82) - DRC1 ctrl3 */

 R3715 (0xe83) - DRC1 ctrl4 */

 R3716 (0xe84) - DRC1 ctrl5 */

 R3720 (0xe88) - DRC2 ctrl1 */

 R3721 (0xe89) - DRC2 ctrl2 */

 R3722 (0xe8a) - DRC2 ctrl3 */

 R3723 (0xe8b) - DRC2 ctrl4 */

 R3724 (0xe8c) - DRC2 ctrl5 */

 R3776 (0xec0) - HPLPF1_1 */

 R3777 (0xec1) - HPLPF1_2 */

 R3780 (0xec4) - HPLPF2_1 */

 R3781 (0xec5) - HPLPF2_2 */

 R3784 (0xec8) - HPLPF3_1 */

 R3785 (0xec9) - HPLPF3_2 */

 R3788 (0xecc) - HPLPF4_1 */

 R3789 (0xecd) - HPLPF4_2 */

 R3792 (0xed0) - ASRC2_ENABLE */

 R3794 (0xed2) - ASRC2_RATE1 */

 R3795 (0xed3) - ASRC2_RATE2 */

 R3808 (0xee0) - ASRC1_ENABLE */

 R3810 (0xee2) - ASRC1_RATE1 */

 R3811 (0xee3) - ASRC1_RATE2 */

 R3824 (0xef0) - ISRC 1 CTRL 1 */

 R3825 (0xef1) - ISRC 1 CTRL 2 */

 R3826 (0xef2) - ISRC 1 CTRL 3 */

 R3827 (0xef3) - ISRC 2 CTRL 1 */

 R3828 (0xef4) - ISRC 2 CTRL 2 */

 R3829 (0xef5) - ISRC 2 CTRL 3 */

 R3830 (0xef6) - ISRC 3 CTRL 1 */

 R3831 (0xef7) - ISRC 3 CTRL 2 */

 R3832 (0xef8) - ISRC 3 CTRL 3 */

 R3833 (0xef9) - ISRC 4 CTRL 1 */

 R3834 (0xefa) - ISRC 4 CTRL 2 */

 R3835 (0xefb) - ISRC 4 CTRL 3 */

 R3841 (0xf01) - ANC_SRC */

 R3842 (0xf02) - DSP Status */

 R3848 (0xf08) - ANC Coefficient */

 R3849 (0xf09) - ANC Coefficient */

 R3850 (0xf0a) - ANC Coefficient */

 R3851 (0xf0b) - ANC Coefficient */

 R3852 (0xf0c) - ANC Coefficient */

 R3853 (0xf0d) - ANC Coefficient */

 R3854 (0xf0e) - ANC Coefficient */

 R3855 (0xf0f) - ANC Coefficient */

 R3856 (0xf10) - ANC Coefficient */

 R3857 (0xf11) - ANC Coefficient */

 R3858 (0xf12) - ANC Coefficient */

 R3861 (0xf15) - FCL Filter Control */

 R3863 (0xf17) - FCL ADC Reformatter Control */

 R3864 (0xf18) - ANC Coefficient */

 R3865 (0xf19) - ANC Coefficient */

 R3866 (0xf1a) - ANC Coefficient */

 R3867 (0xf1b) - ANC Coefficient */

 R3868 (0xf1c) - ANC Coefficient */

 R3869 (0xf1d) - ANC Coefficient */

 R3870 (0xf1e) - ANC Coefficient */

 R3871 (0xf1f) - ANC Coefficient */

 R3872 (0xf20) - ANC Coefficient */

 R3873 (0xf21) - ANC Coefficient */

 R3874 (0xf22) - ANC Coefficient */

 R3875 (0xf23) - ANC Coefficient */

 R3876 (0xf24) - ANC Coefficient */

 R3877 (0xf25) - ANC Coefficient */

 R3878 (0xf26) - ANC Coefficient */

 R3879 (0xf27) - ANC Coefficient */

 R3880 (0xf28) - ANC Coefficient */

 R3881 (0xf29) - ANC Coefficient */

 R3882 (0xf2a) - ANC Coefficient */

 R3883 (0xf2b) - ANC Coefficient */

 R3884 (0xf2c) - ANC Coefficient */

 R3885 (0xf2d) - ANC Coefficient */

 R3886 (0xf2e) - ANC Coefficient */

 R3887 (0xf2f) - ANC Coefficient */

 R3888 (0xf30) - ANC Coefficient */

 R3889 (0xf31) - ANC Coefficient */

 R3890 (0xf32) - ANC Coefficient */

 R3891 (0xf33) - ANC Coefficient */

 R3892 (0xf34) - ANC Coefficient */

 R3893 (0xf35) - ANC Coefficient */

 R3894 (0xf36) - ANC Coefficient */

 R3895 (0xf37) - ANC Coefficient */

 R3896 (0xf38) - ANC Coefficient */

 R3897 (0xf39) - ANC Coefficient */

 R3898 (0xf3a) - ANC Coefficient */

 R3899 (0xf3b) - ANC Coefficient */

 R3900 (0xf3c) - ANC Coefficient */

 R3901 (0xf3d) - ANC Coefficient */

 R3902 (0xf3e) - ANC Coefficient */

 R3903 (0xf3f) - ANC Coefficient */

 R3904 (0xf40) - ANC Coefficient */

 R3905 (0xf41) - ANC Coefficient */

 R3906 (0xf42) - ANC Coefficient */

 R3907 (0xf43) - ANC Coefficient */

 R3908 (0xf44) - ANC Coefficient */

 R3909 (0xf45) - ANC Coefficient */

 R3910 (0xf46) - ANC Coefficient */

 R3911 (0xf47) - ANC Coefficient */

 R3912 (0xf48) - ANC Coefficient */

 R3913 (0xf49) - ANC Coefficient */

 R3914 (0xf4a) - ANC Coefficient */

 R3915 (0xf4b) - ANC Coefficient */

 R3916 (0xf4c) - ANC Coefficient */

 R3917 (0xf4d) - ANC Coefficient */

 R3918 (0xf4e) - ANC Coefficient */

 R3919 (0xf4f) - ANC Coefficient */

 R3920 (0xf50) - ANC Coefficient */

 R3921 (0xf51) - ANC Coefficient */

 R3922 (0xf52) - ANC Coefficient */

 R3923 (0xf53) - ANC Coefficient */

 R3924 (0xf54) - ANC Coefficient */

 R3925 (0xf55) - ANC Coefficient */

 R3926 (0xf56) - ANC Coefficient */

 R3927 (0xf57) - ANC Coefficient */

 R3928 (0xf58) - ANC Coefficient */

 R3929 (0xf59) - ANC Coefficient */

 R3930 (0xf5a) - ANC Coefficient */

 R3931 (0xf5b) - ANC Coefficient */

 R3932 (0xf5c) - ANC Coefficient */

 R3933 (0xf5d) - ANC Coefficient */

 R3934 (0xf5e) - ANC Coefficient */

 R3935 (0xf5f) - ANC Coefficient */

 R3936 (0xf60) - ANC Coefficient */

 R3937 (0xf61) - ANC Coefficient */

 R3938 (0xf62) - ANC Coefficient */

 R3939 (0xf63) - ANC Coefficient */

 R3940 (0xf64) - ANC Coefficient */

 R3941 (0xf65) - ANC Coefficient */

 R3942 (0xf66) - ANC Coefficient */

 R3943 (0xf67) - ANC Coefficient */

 R3944 (0xf68) - ANC Coefficient */

 R3945 (0xf69) - ANC Coefficient */

 R3953 (0xf71) - FCR Filter Control */

 R3955 (0xf73) - FCR ADC Reformatter Control */

 R3956 (0xf74) - ANC Coefficient */

 R3957 (0xf75) - ANC Coefficient */

 R3958 (0xf76) - ANC Coefficient */

 R3959 (0xf77) - ANC Coefficient */

 R3960 (0xf78) - ANC Coefficient */

 R3961 (0xf79) - ANC Coefficient */

 R3962 (0xf7a) - ANC Coefficient */

 R3963 (0xf7b) - ANC Coefficient */

 R3964 (0xf7c) - ANC Coefficient */

 R3965 (0xf7d) - ANC Coefficient */

 R3966 (0xf7e) - ANC Coefficient */

 R3967 (0xf7f) - ANC Coefficient */

 R3968 (0xf80) - ANC Coefficient */

 R3969 (0xf81) - ANC Coefficient */

 R3970 (0xf82) - ANC Coefficient */

 R3971 (0xf83) - ANC Coefficient */

 R3972 (0xf84) - ANC Coefficient */

 R3973 (0xf85) - ANC Coefficient */

 R3974 (0xf86) - ANC Coefficient */

 R3975 (0xf87) - ANC Coefficient */

 R3976 (0xf88) - ANC Coefficient */

 R3977 (0xf89) - ANC Coefficient */

 R3978 (0xf8a) - ANC Coefficient */

 R3979 (0xf8b) - ANC Coefficient */

 R3980 (0xf8c) - ANC Coefficient */

 R3981 (0xf8d) - ANC Coefficient */

 R3982 (0xf8e) - ANC Coefficient */

 R3983 (0xf8f) - ANC Coefficient */

 R3984 (0xf90) - ANC Coefficient */

 R3985 (0xf91) - ANC Coefficient */

 R3986 (0xf92) - ANC Coefficient */

 R3987 (0xf93) - ANC Coefficient */

 R3988 (0xf94) - ANC Coefficient */

 R3989 (0xf95) - ANC Coefficient */

 R3990 (0xf96) - ANC Coefficient */

 R3991 (0xf97) - ANC Coefficient */

 R3992 (0xf98) - ANC Coefficient */

 R3993 (0xf99) - ANC Coefficient */

 R3994 (0xf9a) - ANC Coefficient */

 R3995 (0xf9b) - ANC Coefficient */

 R3996 (0xf9c) - ANC Coefficient */

 R3997 (0xf9d) - ANC Coefficient */

 R3998 (0xf9e) - ANC Coefficient */

 R3999 (0xf9f) - ANC Coefficient */

 R4000 (0xfa0) - ANC Coefficient */

 R4001 (0xfa1) - ANC Coefficient */

 R4002 (0xfa2) - ANC Coefficient */

 R4003 (0xfa3) - ANC Coefficient */

 R4004 (0xfa4) - ANC Coefficient */

 R4005 (0xfa5) - ANC Coefficient */

 R4006 (0xfa6) - ANC Coefficient */

 R4007 (0xfa7) - ANC Coefficient */

 R4008 (0xfa8) - ANC Coefficient */

 R4009 (0xfa9) - ANC Coefficient */

 R4010 (0xfaa) - ANC Coefficient */

 R4011 (0xfab) - ANC Coefficient */

 R4012 (0xfac) - ANC Coefficient */

 R4013 (0xfad) - ANC Coefficient */

 R4014 (0xfae) - ANC Coefficient */

 R4015 (0xfaf) - ANC Coefficient */

 R4016 (0xfb0) - ANC Coefficient */

 R4017 (0xfb1) - ANC Coefficient */

 R4018 (0xfb2) - ANC Coefficient */

 R4019 (0xfb3) - ANC Coefficient */

 R4020 (0xfb4) - ANC Coefficient */

 R4021 (0xfb5) - ANC Coefficient */

 R4022 (0xfb6) - ANC Coefficient */

 R4023 (0xfb7) - ANC Coefficient */

 R4024 (0xfb8) - ANC Coefficient */

 R4025 (0xfb9) - ANC Coefficient */

 R4026 (0xfba) - ANC Coefficient */

 R4027 (0xfbb) - ANC Coefficient */

 R4028 (0xfbc) - ANC Coefficient */

 R4029 (0xfbd) - ANC Coefficient */

 R4030 (0xfbe) - ANC Coefficient */

 R4031 (0xfbf) - ANC Coefficient */

 R4032 (0xfc0) - ANC Coefficient */

 R4033 (0xfc1) - ANC Coefficient */

 R4034 (0xfc2) - ANC Coefficient */

 R4035 (0xfc3) - ANC Coefficient */

 R4036 (0xfc4) - ANC Coefficient */

 R4037 (0xfc5) - ANC Coefficient */

 R5888 (0x1700) - GPIO1 Control 1 */

 R5889 (0x1701) - GPIO1 Control 2 */

 R5890 (0x1702) - GPIO2 Control 1 */

 R5891 (0x1703) - GPIO2 Control 2 */

 R5892 (0x1704) - GPIO3 Control 1 */

 R5893 (0x1705) - GPIO3 Control 2 */

 R5894 (0x1706) - GPIO4 Control 1 */

 R5895 (0x1707) - GPIO4 Control 2 */

 R5896 (0x1708) - GPIO5 Control 1 */

 R5897 (0x1709) - GPIO5 Control 2 */

 R5898 (0x170a) - GPIO6 Control 1 */

 R5899 (0x170b) - GPIO6 Control 2 */

 R5900 (0x170c) - GPIO7 Control 1 */

 R5901 (0x170d) - GPIO7 Control 2 */

 R5902 (0x170e) - GPIO8 Control 1 */

 R5903 (0x170f) - GPIO8 Control 2 */

 R5904 (0x1710) - GPIO9 Control 1 */

 R5905 (0x1711) - GPIO9 Control 2 */

 R5906 (0x1712) - GPIO10 Control 1 */

 R5907 (0x1713) - GPIO10 Control 2 */

 R5908 (0x1714) - GPIO11 Control 1 */

 R5909 (0x1715) - GPIO11 Control 2 */

 R5910 (0x1716) - GPIO12 Control 1 */

 R5911 (0x1717) - GPIO12 Control 2 */

 R5912 (0x1718) - GPIO13 Control 1 */

 R5913 (0x1719) - GPIO13 Control 2 */

 R5914 (0x171a) - GPIO14 Control 1 */

 R5915 (0x171b) - GPIO14 Control 2 */

 R5916 (0x171c) - GPIO15 Control 1 */

 R5917 (0x171d) - GPIO15 Control 2 */

 R5918 (0x171e) - GPIO16 Control 1 */

 R5919 (0x171f) - GPIO16 Control 2 */

 R5920 (0x1720) - GPIO17 Control 1 */

 R5921 (0x1721) - GPIO17 Control 2 */

 R5922 (0x1722) - GPIO18 Control 1 */

 R5923 (0x1723) - GPIO18 Control 2 */

 R5924 (0x1724) - GPIO19 Control 1 */

 R5925 (0x1725) - GPIO19 Control 2 */

 R5926 (0x1726) - GPIO20 Control 1 */

 R5927 (0x1727) - GPIO20 Control 2 */

 R5928 (0x1728) - GPIO21 Control 1 */

 R5929 (0x1729) - GPIO21 Control 2 */

 R5930 (0x172a) - GPIO22 Control 1 */

 R5931 (0x172b) - GPIO22 Control 2 */

 R5932 (0x172c) - GPIO23 Control 1 */

 R5933 (0x172d) - GPIO23 Control 2 */

 R5934 (0x172e) - GPIO24 Control 1 */

 R5935 (0x172f) - GPIO24 Control 2 */

 R5936 (0x1730) - GPIO25 Control 1 */

 R5937 (0x1731) - GPIO25 Control 2 */

 R5938 (0x1732) - GPIO26 Control 1 */

 R5939 (0x1733) - GPIO26 Control 2 */

 R5940 (0x1734) - GPIO27 Control 1 */

 R5941 (0x1735) - GPIO27 Control 2 */

 R5942 (0x1736) - GPIO28 Control 1 */

 R5943 (0x1737) - GPIO28 Control 2 */

 R5944 (0x1738) - GPIO29 Control 1 */

 R5945 (0x1739) - GPIO29 Control 2 */

 R5946 (0x173a) - GPIO30 Control 1 */

 R5947 (0x173b) - GPIO30 Control 2 */

 R5948 (0x173c) - GPIO31 Control 1 */

 R5949 (0x173d) - GPIO31 Control 2 */

 R5950 (0x173e) - GPIO32 Control 1 */

 R5951 (0x173f) - GPIO32 Control 2 */

 R5952 (0x1740) - GPIO33 Control 1 */

 R5953 (0x1741) - GPIO33 Control 2 */

 R5954 (0x1742) - GPIO34 Control 1 */

 R5955 (0x1743) - GPIO34 Control 2 */

 R5956 (0x1744) - GPIO35 Control 1 */

 R5957 (0x1745) - GPIO35 Control 2 */

 R5958 (0x1746) - GPIO36 Control 1 */

 R5959 (0x1747) - GPIO36 Control 2 */

 R5960 (0x1748) - GPIO37 Control 1 */

 R5961 (0x1749) - GPIO37 Control 2 */

 R5962 (0x174a) - GPIO38 Control 1 */

 R5963 (0x174b) - GPIO38 Control 2 */

 R5964 (0x174c) - GPIO39 Control 1 */

 R5965 (0x174d) - GPIO39 Control 2 */

 R5966 (0x174e) - GPIO40 Control 1 */

 R5967 (0x174f) - GPIO40 Control 2 */

 R6208 (0x1840) - IRQ1 Mask 1 */

 R6209 (0x1841) - IRQ1 Mask 2 */

 R6210 (0x1842) - IRQ1 Mask 3 */

 R6211 (0x1843) - IRQ1 Mask 4 */

 R6212 (0x1844) - IRQ1 Mask 5 */

 R6213 (0x1845) - IRQ1 Mask 6 */

 R6214 (0x1846) - IRQ1 Mask 7 */

 R6215 (0x1847) - IRQ1 Mask 8 */

 R6216 (0x1848) - IRQ1 Mask 9 */

 R6217 (0x1849) - IRQ1 Mask 10 */

 R6218 (0x184a) - IRQ1 Mask 11 */

 R6219 (0x184b) - IRQ1 Mask 12 */

 R6220 (0x184c) - IRQ1 Mask 13 */

 R6221 (0x184d) - IRQ1 Mask 14 */

 R6222 (0x184e) - IRQ1 Mask 15 */

 R6223 (0x184f) - IRQ1 Mask 16 */

 R6224 (0x1850) - IRQ1 Mask 17 */

 R6225 (0x1851) - IRQ1 Mask 18 */

 R6226 (0x1852) - IRQ1 Mask 19 */

 R6227 (0x1853) - IRQ1 Mask 20 */

 R6228 (0x1854) - IRQ1 Mask 21 */

 R6229 (0x1855) - IRQ1 Mask 22 */

 R6230 (0x1856) - IRQ1 Mask 23 */

 R6231 (0x1857) - IRQ1 Mask 24 */

 R6232 (0x1858) - IRQ1 Mask 25 */

 R6233 (0x1859) - IRQ1 Mask 26 */

 R6234 (0x185a) - IRQ1 Mask 27 */

 R6235 (0x185b) - IRQ1 Mask 28 */

 R6236 (0x185c) - IRQ1 Mask 29 */

 R6237 (0x185d) - IRQ1 Mask 30 */

 R6238 (0x185e) - IRQ1 Mask 31 */

 R6239 (0x185f) - IRQ1 Mask 32 */

 R6240 (0x1860) - IRQ1 Mask 33 */

 R6662 (0x1a06) - Interrupt Debounce 7 */

 R6784 (0x1a80) - IRQ1 CTRL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TI/National Semiconductor LP3943 MFD Core Driver

 *

 * Copyright 2013 Texas Instruments

 *

 * Author: Milo Kim <milo.kim@ti.com>

 *

 * Driver structure:

 *   LP3943 is an integrated device capable of driving 16 output channels.

 *   It can be used for a GPIO expander and PWM generators.

 *

 *                                   LED control    General usage for a device

 *                                   ___________   ____________________________

 *

 *   LP3943 MFD ---- GPIO expander    leds-gpio        eg) HW enable pin

 *               |

 *               --- PWM generator    leds-pwm         eg) PWM input

 *

 *   Internal two PWM channels are used for LED dimming effect.

 *   And each output pin can be used as a GPIO as well.

 *   The LED functionality can work with GPIOs or PWMs.

 *   LEDs can be controlled with legacy leds-gpio(static brightness) or

 *   leds-pwm drivers(dynamic brightness control).

 *   Alternatively, it can be used for generic GPIO and PWM controller.

 *   For example, a GPIO is HW enable pin of a device.

 *   A PWM is input pin of a backlight device.

 Register configuration for pin MUX */

 address, mask, shift */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Core functions for:

 *  Philips UCB1400 multifunction chip

 *

 * Based on ucb1400_ts.c:

 *  Author:	Nicolas Pitre

 *  Created:	September 25, 2006

 *  Copyright:	MontaVista Software, Inc.

 *

 * Spliting done by: Marek Vasut <marek.vasut@gmail.com>

 * If something doesn't work and it worked before spliting, e-mail me,

 * dont bother Nicolas please ;-)

 *

 * This code is heavily based on ucb1x00-*.c copyrighted by Russell King

 * covering the UCB1100, UCB1200 and UCB1300..  Support for the UCB1400 has

 * been made separate from ucb1x00-core/ucb1x00-ts on Russell's request.

 GPIO */

 TOUCHSCREEN */

 SPDX-License-Identifier: GPL-2.0+



 max8998.c - mfd core driver for the Maxim 8998



  Copyright (C) 2009-2010 Samsung Electronics

  Kyungmin Park <kyungmin.park@samsung.com>

  Marek Szyprowski <m.szyprowski@samsung.com>

/*

 * Only the common platform data elements for max8998 are parsed here from the

 * device tree. Other sub-modules of max8998 such as pmic, rtc and others have

 * to parse their own platform data elements from device tree.

 *

 * The max8998 platform data structure is instantiated here and the drivers for

 * the sub-modules need not instantiate another instance while parsing their

 * platform data.

	/*

	 * ToDo: the 'wakeup' member in the platform data is more of a linux

	 * specfic information. Hence, there is no binding for that yet and

	 * not parsed here.

	/*

	 * In LP3974, if IRQ registers are not "read & clear"

	 * when it's set during sleep, the interrupt becomes

	 * disabled.

 Save registers before hibernation */

 Restore registers after hibernation */

 init early so consumer devices can complete system boot */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2009-2010 Creative Product Design

 * Marc Reilly marc@cpdesign.com.au

 sentinel */

 sentinel */

 SPDX-License-Identifier: GPL-2.0

/*

 * Device access for Basin Cove PMIC

 *

 * Copyright (c) 2019, Intel Corporation.

 * Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>

/*

 * Level 2 IRQs

 *

 * Firmware on the systems with Basin Cove PMIC services Level 1 IRQs

 * without an assistance. Thus, each of the Level 1 IRQ is represented

 * as a separate RTE in IOAPIC.

 power button */

 TMU */

 thermal */

 BCU */

 ADC */

 charger */

 GPIO */

 SPDX-License-Identifier: GPL-2.0+



 max77686.c - mfd core driver for the Maxim 77686/802



 Copyright (C) 2012 Samsung Electronics

 Chiwoong Byun <woong.byun@samsung.com>

 Jonghwa Lee <jonghwa3.lee@samsung.com>



This driver is based on max8997.c

 INT1 interrupts */

 INT2 interrupts */

 same masks as 77686 */

	/*

	 * IRQ must be disabled during suspend because if it happens

	 * while suspended it will be handled before resuming I2C.

	 *

	 * When device is woken up from suspend (e.g. by RTC wake alarm),

	 * an interrupt occurs before resuming I2C bus controller.

	 * Interrupt handler tries to read registers but this read

	 * will fail because I2C is still suspended.

 CONFIG_PM_SLEEP */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Core driver for ams AS3722 PMICs

 *

 * Copyright (C) 2013 AMS AG

 * Copyright (c) 2013, NVIDIA Corporation. All rights reserved.

 *

 * Author: Florian Lobmaier <florian.lobmaier@ams.com>

 * Author: Laxman Dewangan <ldewangan@nvidia.com>

 INT1 IRQs */

 INT2 IRQs */

 INT3 IRQs */

 INT4 IRQs */

 Check that this is actually a AS3722 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Kontron PLD MFD core driver

 *

 * Copyright (c) 2010-2013 Kontron Europe GmbH

 * Author: Michael Brunner <michael.brunner@kontron.com>

/*

 * Get hardware mutex to block firmware from accessing the pld.

 * It is possible for the firmware may hold the mutex for an extended length of

 * time. This function will block until access has been granted.

 The mutex bit will read 1 until access has been granted */

 The harware mutex is released when 1 is written to the mutex bit. */

/**

 * kempld_read8 - read 8 bit register

 * @pld: kempld_device_data structure describing the PLD

 * @index: register index on the chip

 *

 * kempld_get_mutex must be called prior to calling this function.

/**

 * kempld_write8 - write 8 bit register

 * @pld: kempld_device_data structure describing the PLD

 * @index: register index on the chip

 * @data: new register value

 *

 * kempld_get_mutex must be called prior to calling this function.

/**

 * kempld_read16 - read 16 bit register

 * @pld: kempld_device_data structure describing the PLD

 * @index: register index on the chip

 *

 * kempld_get_mutex must be called prior to calling this function.

/**

 * kempld_write16 - write 16 bit register

 * @pld: kempld_device_data structure describing the PLD

 * @index: register index on the chip

 * @data: new register value

 *

 * kempld_get_mutex must be called prior to calling this function.

/**

 * kempld_read32 - read 32 bit register

 * @pld: kempld_device_data structure describing the PLD

 * @index: register index on the chip

 *

 * kempld_get_mutex must be called prior to calling this function.

/**

 * kempld_write32 - write 32 bit register

 * @pld: kempld_device_data structure describing the PLD

 * @index: register index on the chip

 * @data: new register value

 *

 * kempld_get_mutex must be called prior to calling this function.

/**

 * kempld_get_mutex - acquire PLD mutex

 * @pld: kempld_device_data structure describing the PLD

/**

 * kempld_release_mutex - release PLD mutex

 * @pld: kempld_device_data structure describing the PLD

/**

 * kempld_get_info - update device specific information

 * @pld: kempld_device_data structure describing the PLD

 *

 * This function calls the configured board specific kempld_get_info_XXXX

 * function which is responsible for gathering information about the specific

 * hardware. The information is then stored within the pld structure.

	/* The Kontron PLD firmware version string has the following format:

	 * Pwxy.zzzz

	 *   P:    Fixed

	 *   w:    PLD number    - 1 hex digit

	 *   x:    Major version - 1 alphanumerical digit (0-9A-V)

	 *   y:    Minor version - 1 alphanumerical digit (0-9A-V)

/*

 * kempld_register_cells - register cell drivers

 *

 * This function registers cell drivers for the detected hardware by calling

 * the configured kempld_register_cells_XXXX function which is responsible

 * to detect and register the needed cell drivers.

 Check for empty IO space */

 Release hardware mutex if acquired */

 PXT and COMe-cPC2 boards may require a second release */

 CONFIG_ACPI */

		/*

		 * No kempld_pdev device has been registered in kempld_init,

		 * so we seem to be probing an ACPI platform device.

		/*

		 * The platform device we are probing is not the one we

		 * registered in kempld_init using the DMI table, so this one

		 * comes from ACPI.

		 * As we can only probe one - abort here and use the DMI

		 * based one instead.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  lpc_ich.c - LPC interface for Intel ICH

 *

 *  LPC bridge function of the Intel ICH contains many other

 *  functional units, such as Interrupt controllers, Timers,

 *  Power Management, System Management, GPIO, RTC, and LPC

 *  Configuration Registers.

 *

 *  This driver is derived from lpc_sch.



 *  Copyright (c) 2011 Extreme Engineering Solution, Inc.

 *  Author: Aaron Sierra <asierra@xes-inc.com>

 *

 *  This driver supports the following I/O Controller hubs:

 *	(See the intel documentation on http://developer.intel.com.)

 *	document number 290655-003, 290677-014: 82801AA (ICH), 82801AB (ICHO)

 *	document number 290687-002, 298242-027: 82801BA (ICH2)

 *	document number 290733-003, 290739-013: 82801CA (ICH3-S)

 *	document number 290716-001, 290718-007: 82801CAM (ICH3-M)

 *	document number 290744-001, 290745-025: 82801DB (ICH4)

 *	document number 252337-001, 252663-008: 82801DBM (ICH4-M)

 *	document number 273599-001, 273645-002: 82801E (C-ICH)

 *	document number 252516-001, 252517-028: 82801EB (ICH5), 82801ER (ICH5R)

 *	document number 300641-004, 300884-013: 6300ESB

 *	document number 301473-002, 301474-026: 82801F (ICH6)

 *	document number 313082-001, 313075-006: 631xESB, 632xESB

 *	document number 307013-003, 307014-024: 82801G (ICH7)

 *	document number 322896-001, 322897-001: NM10

 *	document number 313056-003, 313057-017: 82801H (ICH8)

 *	document number 316972-004, 316973-012: 82801I (ICH9)

 *	document number 319973-002, 319974-002: 82801J (ICH10)

 *	document number 322169-001, 322170-003: 5 Series, 3400 Series (PCH)

 *	document number 320066-003, 320257-008: EP80597 (IICH)

 *	document number 324645-001, 324646-001: Cougar Point (CPT)

 ACPI base */

 ACPI control or PMC base */

 GPIO base */

 GPIO control */

 Cached ACPI base value */

 Cached ACPI control or PMC base value */

 Cached GPIO control value */

 ACPI - TCO */

 ACPI - SMI */

 GCS or PMC */

 GPIO */

 ACPI - GPE0 */

 chipset related info */

 ICH */

 ICH0 */

 ICH2 */

 ICH2-M */

 ICH3-S */

 ICH3-M */

 ICH4 */

 ICH4-M */

 C-ICH */

 ICH5 & ICH5R */

 6300ESB */

 ICH6 & ICH6R */

 ICH6-M */

 ICH6W & ICH6RW */

 631xESB/632xESB */

 ICH7 & ICH7R */

 ICH7DH */

 ICH7-M & ICH7-U */

 ICH7-M DH */

 NM10 */

 ICH8 & ICH8R */

 ICH8DH */

 ICH8DO */

 ICH8M */

 ICH8M-E */

 ICH9 */

 ICH9R */

 ICH9DH */

 ICH9DO */

 ICH9M */

 ICH9M-E */

 ICH10 */

 ICH10R */

 ICH10D */

 ICH10DO */

 PCH Desktop Full Featured */

 PCH Mobile Full Featured */

 P55 */

 PM55 */

 H55 */

 QM57 */

 H57 */

 HM55 */

 Q57 */

 HM57 */

 PCH Mobile SFF Full Featured */

 QS57 */

 3400 */

 3420 */

 3450 */

 EP80579 */

 Cougar Point */

 Cougar Point Desktop */

 Cougar Point Mobile */

 Patsburg */

 DH89xxCC */

 Panther Point */

 Lynx Point */

 Lynx Point-LP */

 Wellsburg */

 Avoton SoC */

 Bay Trail SoC */

 Coleto Creek */

 Wildcat Point-LP */

 Braswell SoC */

 Lewisburg */

 9 Series */

 Apollo Lake SoC */

 Gemini Lake SoC */

 Cougar Mountain SoC*/

/*

 * This data only exists for exporting the supported PCI ids

 * via MODULE_DEVICE_TABLE.  We do not actually register a

 * pci_driver, because the I/O Controller Hub has also other

 * functions that probably will be registered by other drivers.

 End of list */

		/*

		 * Some chipsets (eg Avoton) enable the ACPI space in the

		 * ACPI BASE register.

		/*

		 * Most chipsets enable the ACPI space in the ACPI control

		 * register.

/*

 * We don't check for resource conflict globally. There are 2 or 3 independent

 * GPIO groups and it's enough to have access to one of these to instantiate

 * the device.

 Setup power management base register */

		/*

		 * This isn't fatal for the GPIO, but we have to make sure that

		 * the platform_device subsystem doesn't see this resource

		 * or it will register an invalid region.

 Setup GPIO base register */

 Older devices provide fewer GPIO and have a smaller resource size. */

 this isn't necessarily fatal for the GPIO */

 If we have ACPI based watchdog use that instead */

 Setup power management base register */

	/*

	 * iTCO v2:

	 * Get the Memory-Mapped GCS register. To get access to it

	 * we have to read RCBA from PCI Config space 0xf0 and use

	 * it as base. GCS = RCBA + ICH6_GCS(0x3410).

	 *

	 * iTCO v3:

	 * Get the Power Management Configuration register.  To get access

	 * to it we have to read the PMC BASE from config space and address

	 * the register at offset 0x8.

 Don't register iomem for TCO ver 1 */

		/*

		 * The P2SB is hidden by BIOS and we need to unhide it in

		 * order to read BAR of the SPI flash device. Once that is

		 * done we hide it again.

	/*

	 * We only care if at least one or none of the cells registered

	 * successfully.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * The Netronix embedded controller is a microcontroller found in some

 * e-book readers designed by the original design manufacturer Netronix, Inc.

 * It contains RTC, battery monitoring, system power management, and PWM

 * functionality.

 *

 * This driver implements register access, version detection, and system

 * power-off/reset.

 *

 * Copyright 2020 Jonathan Neuschäfer <j.neuschaefer@gmx.net>

	/*

	 * The time from the register write until the host CPU is powered off

	 * has been observed to be about 2.5 to 3 seconds. Sleep long enough to

	 * safely avoid returning from the poweroff handler.

	/*

	 * NOTE: The lower half of the reset value is not sent, because sending

	 * it causes an I2C error. (The reset handler in the downstream driver

	 * does send the full two-byte value, but doesn't check the result).

/*

 * Some firmware versions do not ack written data, add a wrapper. It

 * is used to stack another regmap on top.

 Determine the firmware version */

 Bail out if we encounter an unknown firmware version */

 Another regmap stacked on top of the other */

		/*

		 * Set the 'powerkeep' bit. This is necessary on some boards

		 * in order to keep the system running.

			/*

			 * Another instance of the driver already took

			 * poweroff/restart duties.

 Another driver already registered a poweroff handler. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Arizona core driver

 *

 * Copyright 2012 Wolfson Microelectronics plc

 *

 * Author: Mark Brown <broonie@opensource.wolfsonmicro.com>

		/* Some bits are shifted on WM8998,

		 * rearrange to match the standard bit layout

	/*

	 * We can't use an interrupt as we need to runtime resume to do so,

	 * we won't race with the interrupt handler as it'll be blocked on

	 * runtime resume.

 Meet requirements for minimum reset duration */

 Cache existing FLL and SYSCLK settings */

 Start up SYSCLK using the FLL in free running mode */

 Start the write sequencer and wait for it to finish */

/*

 * Register patch to some of the CODECs internal write sequences

 * to ensure a clean exit from the low power sleep state.

			/*

			 * As this is only called for the internal regulator

			 * (where we know voltage ranges available) it is ok

			 * to request an exact range.

			/*

			 * As this is only called for the internal regulator

			 * (where we know voltage ranges available) it is ok

			 * to request an exact range.

 Allow us to completely power down if no jack detection */

 Handle old non-standard DT binding */

		/*

		 * Reset missing will be caught when other binding is read

		 * but all other errors imply this binding is in use but has

		 * encountered a problem so should be handled.

		/*

		 * All values are literal except out of range values

		 * which are chip default, translate into platform

		 * data which uses 0 as chip default and out of range

		 * as zero.

 Mark DCVDD as external, LDO1 driver will clear if internal */

 No LDO1 regulator */

	/**

	 * Don't use devres here because the only device we have to get

	 * against is the MFD device and DCVDD will likely be supplied by

	 * one of its children. Meaning that the regulator will be

	 * destroyed by the time devres calls regulator put.

 Start out with /RESET low to put the chip into reset */

 Verify that this is a chip we know about */

 If we have a /RESET GPIO we'll already be reset */

 Ensure device startup is complete */

 Read the device ID information & do device specific stuff */

 Chip default */

 Apply default for bypass mode */

 Set up for interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MFD core driver for X-Powers' AC100 Audio Codec IC

 *

 * The AC100 is a highly integrated audio codec and RTC subsystem designed

 * for mobile applications. It has 3 I2S/PCM interfaces, a 2 channel DAC,

 * a 2 channel ADC with 5 inputs and a builtin mixer. The RTC subsystem has

 * 3 clock outputs.

 *

 * The audio codec and RTC parts are completely separate, sharing only the

 * host interface for access to its registers.

 *

 * Copyright (2016) Chen-Yu Tsai

 *

 * Author: Chen-Yu Tsai <wens@csie.org>

 SPDX-License-Identifier: GPL-2.0

/*

 * Driver for AT91 USART

 *

 * Copyright (C) 2018 Microchip Technology

 *

 * Author: Radu Pirea <radu.pirea@microchip.com>

 *

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Driver for the Diolan DLN-2 USB adapter

 *

 * Copyright (c) 2014 Intel Corporation

 *

 * Derived from:

 *  i2c-diolan-u2c.c

 *  Copyright (c) 2010-2011 Ericsson AB

 in ms */

 don't change, hardware defined */

/*

 * Receive context used between the receive demultiplexer and the transfer

 * routine. While sending a request the transfer routine will look for a free

 * receive context and use it to wait for a response and to receive the URB and

 * thus the response data.

 completion used to wait for a response */

 if non-NULL the URB contains the response */

 if true then this context is used to wait for a response */

/*

 * Receive contexts for a particular DLN2 module (i2c, gpio, etc.). We use the

 * handle header field to identify the module in dln2_dev.mod_rx_slots and then

 * the echo header field to index the slots field and find the receive context

 * for a particular request.

 RX slots bitmap */

 used to wait for a free RX slot */

 used to wait for an RX operation to complete */

 avoid races between alloc/free_rx_slot and dln2_rx_transfer */

/*

 * Returns true if a valid transfer slot is found. In this case the URB must not

 * be resubmitted immediately in dln2_rx as we need the data when dln2_transfer

 * is woke up. It will be resubmitted there.

 success */

 this urb is terminated, clean up */

 URB will be re-submitted in _dln2_transfer (free_rx_slot) */

	/*

	 * No need to timeout here, the wait is bounded by the timeout in

	 * _dln2_transfer.

 if we got here we know that the response header has been checked */

 Only one I2C port seems to be supported on current hardware */

 Only one SPI port supported */

 Only one ADC port supported */

 don't allow starting new transfers */

 cancel in progress transfers */

 cancel all response waiters */

 wait for transfers to end */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Regmap tables for CS47L15 codec

 *

 * Copyright (C) 2016-2019 Cirrus Logic, Inc. and

 *                         Cirrus Logic International Semiconductor Ltd.

 R32 (0x20) - Tone Generator 1 */

 R33 (0x21) - Tone Generator 2 */

 R34 (0x22) - Tone Generator 3 */

 R35 (0x23) - Tone Generator 4 */

 R36 (0x24) - Tone Generator 5 */

 R48 (0x30) - PWM Drive 1 */

 R49 (0x31) - PWM Drive 2 */

 R50 (0x32) - PWM Drive 3 */

 R97 (0x61) - Sample Rate Sequence Select 1 */

 R98 (0x62) - Sample Rate Sequence Select 2 */

 R99 (0x63) - Sample Rate Sequence Select 3 */

 R100 (0x64) - Sample Rate Sequence Select 4 */

 R102 (0x66) - Always On Triggers Sequence Select 1 */

 R103 (0x67) - Always On Triggers Sequence Select 2 */

 R144 (0x90) - Haptics Control 1 */

 R145 (0x91) - Haptics Control 2 */

 R146 (0x92) - Haptics Phase 1 Intensity */

 R147 (0x93) - Haptics Phase 1 Duration */

 R148 (0x94) - Haptics Phase 2 Intensity */

 R149 (0x95) - Haptics Phase 2 Duration */

 R150 (0x96) - Haptics Phase 3 Intensity */

 R151 (0x97) - Haptics Phase 3 Duration */

 R160 (0xA0) - Comfort Noise Generator */

 R256 (0x100) - Clock 32K 1 */

 R257 (0x101) - System Clock 1 */

 R258 (0x102) - Sample Rate 1 */

 R259 (0x103) - Sample Rate 2 */

 R260 (0x104) - Sample Rate 3 */

 R288 (0x120) - DSP Clock 1 */

 R290 (0x122) - DSP Clock 2 */

 R329 (0x149) - Output System Clock */

 R338 (0x152) - Rate Estimator 1 */

 R339 (0x153) - Rate Estimator 2 */

 R340 (0x154) - Rate Estimator 3 */

 R341 (0x155) - Rate Estimator 4 */

 R342 (0x156) - Rate Estimator 5 */

 R369 (0x171) - FLL1 Control 1 */

 R370 (0x172) - FLL1 Control 2 */

 R371 (0x173) - FLL1 Control 3 */

 R372 (0x174) - FLL1 Control 4 */

 R373 (0x175) - FLL1 Control 5 */

 R374 (0x176) - FLL1 Control 6 */

 R377 (0x179) - FLL1 Control 7 */

 R378 (0x17A) - FLL1 EFS 2 */

 R385 (0x181) - FLL1 Synchroniser 1 */

 R386 (0x182) - FLL1 Synchroniser 2 */

 R387 (0x183) - FLL1 Synchroniser 3 */

 R388 (0x184) - FLL1 Synchroniser 4 */

 R389 (0x185) - FLL1 Synchroniser 5 */

 R390 (0x186) - FLL1 Synchroniser 6 */

 R391 (0x187) - FLL1 Synchroniser 7 */

 R393 (0x189) - FLL1 Spread Spectrum */

 R394 (0x18A) - FLL1 GPIO Clock */

 R465 (0x1D1) - FLL AO Control 1 */

 R466 (0x1D2) - FLL AO Control 2 */

 R467 (0x1D3) - FLL AO Control 3 */

 R468 (0x1D4) - FLL AO Control 4 */

 R469 (0x1D5) - FLL AO Control 5 */

 R470 (0x1D6) - FLL AO Control 6 */

 R472 (0x1D8) - FLL AO Control 7 */

 R474 (0x1DA) - FLL AO Control 8 */

 R475 (0x1DB) - FLL AO Control 9 */

 R476 (0x1DC) - FLL AO Control 10 */

 R477 (0x1DD) - FLL AO Control 11 */

 R536 (0x218) - Mic Bias Ctrl 1 */

 R540 (0x21C) - Mic Bias Ctrl 5 */

 R659 (0x293) - Accessory Detect Mode 1 */

 R665 (0x299) - Headphone Detect 0 */

 R667 (0x29B) - Headphone Detect 1 */

 R674 (0x2A2) - Mic Detect 1 Control 0 */

 R675 (0x2A3) - Mic Detect 1 Control 1 */

 R676 (0x2A4) - Mic Detect 1 Control 2 */

 R678 (0x2A6) - Mic Detect 1 Level 1 */

 R679 (0x2A7) - Mic Detect 1 Level 2 */

 R680 (0x2A8) - Mic Detect 1 Level 3 */

 R681 (0x2A9) - Mic Detect 1 Level 4 */

 R710 (0x2C6) - Micd Clamp Control */

 R712 (0x2C8) - GP Switch 1 */

 R723 (0x2D3) - Jack Detect Analogue */

 R768 (0x300) - Input Enables */

 R776 (0x308) - Input Rate */

 R777 (0x309) - Input Volume Ramp */

 R780 (0x30C) - HPF Control */

 R784 (0x310) - IN1L Control */

 R785 (0x311) - ADC Digital Volume 1L */

 R786 (0x312) - DMIC1L Control */

 R787 (0x313) - IN1L Rate Control */

 R788 (0x314) - IN1R Control */

 R789 (0x315) - ADC Digital Volume 1R */

 R790 (0x316) - DMIC1R Control */

 R791 (0x317) - IN1R Rate Control */

 R792 (0x318) - IN2L Control */

 R793 (0x319) - ADC Digital Volume 2L */

 R794 (0x31A) - DMIC2L Control */

 R795 (0x31B) - IN2L Rate Control */

 R796 (0x31C) - IN2R Control */

 R797 (0x31D) - ADC Digital Volume 2R */

 R798 (0x31E) - DMIC2R Control */

 R799 (0x31F) - IN2R Rate Control */

 R936 (0x3A8) - CS47L15 ADC Int Bias */

 R964 (0x3C4) - CS47L15 PGA Bias Sel */

 R1024 (0x400) - Output Enables 1 */

 R1032 (0x408) - Output Rate 1 */

 R1033 (0x409) - Output Volume Ramp */

 R1040 (0x410) - Output Path Config 1L */

 R1041 (0x411) - DAC Digital Volume 1L */

 R1042 (0x412) - Output Path Config 1 */

 R1043 (0x413) - Noise Gate Select 1L */

 R1044 (0x414) - Output Path Config 1R */

 R1045 (0x415) - DAC Digital Volume 1R */

 R1047 (0x417) - Noise Gate Select 1R */

 R1050 (0x41A) - Output Path Config 2 */

 R1064 (0x428) - Output Path Config 4L */

 R1065 (0x429) - DAC Digital Volume 4L */

 R1067 (0x42B) - Noise Gate Select 4L */

 R1072 (0x430) - Output Path Config 5L */

 R1073 (0x431) - DAC Digital Volume 5L */

 R1075 (0x433) - Noise Gate Select 5L */

 R1076 (0x434) - Output Path Config 5R */

 R1077 (0x435) - DAC Digital Volume 5R */

 R1079 (0x437) - Noise Gate Select 5R */

 R1104 (0x450) - DAC AEC Control 1 */

 R1105 (0x451) - DAC AEC Control 2 */

 R1112 (0x458) - Noise Gate Control */

 R1168 (0x490) - PDM SPK1 Ctrl 1 */

 R1169 (0x491) - PDM SPK1 Ctrl 2 */

 R1184 (0x4A0) - HP1 Short Circuit Ctrl */

 R1192 (0x4A8) - HP Test Ctrl 5 */

 R1193 (0x4A9) - HP Test Ctrl 6 */

 R1280 (0x500) - AIF1 BCLK Ctrl */

 R1281 (0x501) - AIF1 Tx Pin Ctrl */

 R1282 (0x502) - AIF1 Rx Pin Ctrl */

 R1283 (0x503) - AIF1 Rate Ctrl */

 R1284 (0x504) - AIF1 Format */

 R1286 (0x506) - AIF1 Rx BCLK Rate */

 R1287 (0x507) - AIF1 Frame Ctrl 1 */

 R1288 (0x508) - AIF1 Frame Ctrl 2 */

 R1289 (0x509) - AIF1 Frame Ctrl 3 */

 R1290 (0x50A) - AIF1 Frame Ctrl 4 */

 R1291 (0x50B) - AIF1 Frame Ctrl 5 */

 R1292 (0x50C) - AIF1 Frame Ctrl 6 */

 R1293 (0x50D) - AIF1 Frame Ctrl 7 */

 R1294 (0x50E) - AIF1 Frame Ctrl 8 */

 R1297 (0x511) - AIF1 Frame Ctrl 11 */

 R1298 (0x512) - AIF1 Frame Ctrl 12 */

 R1299 (0x513) - AIF1 Frame Ctrl 13 */

 R1300 (0x514) - AIF1 Frame Ctrl 14 */

 R1301 (0x515) - AIF1 Frame Ctrl 15 */

 R1302 (0x516) - AIF1 Frame Ctrl 16 */

 R1305 (0x519) - AIF1 Tx Enables */

 R1306 (0x51A) - AIF1 Rx Enables */

 R1344 (0x540) - AIF2 BCLK Ctrl */

 R1345 (0x541) - AIF2 Tx Pin Ctrl */

 R1346 (0x542) - AIF2 Rx Pin Ctrl */

 R1347 (0x543) - AIF2 Rate Ctrl */

 R1348 (0x544) - AIF2 Format */

 R1350 (0x546) - AIF2 Rx BCLK Rate */

 R1351 (0x547) - AIF2 Frame Ctrl 1 */

 R1352 (0x548) - AIF2 Frame Ctrl 2 */

 R1353 (0x549) - AIF2 Frame Ctrl 3 */

 R1354 (0x54A) - AIF2 Frame Ctrl 4 */

 R1355 (0x54B) - AIF2 Frame Ctrl 5 */

 R1356 (0x54C) - AIF2 Frame Ctrl 6 */

 R1361 (0x551) - AIF2 Frame Ctrl 11 */

 R1362 (0x552) - AIF2 Frame Ctrl 12 */

 R1363 (0x553) - AIF2 Frame Ctrl 13 */

 R1364 (0x554) - AIF2 Frame Ctrl 14 */

 R1369 (0x559) - AIF2 Tx Enables */

 R1370 (0x55A) - AIF2 Rx Enables */

 R1408 (0x580) - AIF3 BCLK Ctrl */

 R1409 (0x581) - AIF3 Tx Pin Ctrl */

 R1410 (0x582) - AIF3 Rx Pin Ctrl */

 R1411 (0x583) - AIF3 Rate Ctrl */

 R1412 (0x584) - AIF3 Format */

 R1414 (0x586) - AIF3 Rx BCLK Rate */

 R1415 (0x587) - AIF3 Frame Ctrl 1 */

 R1416 (0x588) - AIF3 Frame Ctrl 2 */

 R1417 (0x589) - AIF3 Frame Ctrl 3 */

 R1418 (0x58A) - AIF3 Frame Ctrl 4 */

 R1425 (0x591) - AIF3 Frame Ctrl 11 */

 R1426 (0x592) - AIF3 Frame Ctrl 12 */

 R1433 (0x599) - AIF3 Tx Enables */

 R1434 (0x59A) - AIF3 Rx Enables */

 R1474 (0x5C2) - SPD1 Tx Control */

 R1600 (0x640) - PWM1MIX Input 1 Source */

 R1601 (0x641) - PWM1MIX Input 1 Volume */

 R1602 (0x642) - PWM1MIX Input 2 Source */

 R1603 (0x643) - PWM1MIX Input 2 Volume */

 R1604 (0x644) - PWM1MIX Input 3 Source */

 R1605 (0x645) - PWM1MIX Input 3 Volume */

 R1606 (0x646) - PWM1MIX Input 4 Source */

 R1607 (0x647) - PWM1MIX Input 4 Volume */

 R1608 (0x648) - PWM2MIX Input 1 Source */

 R1609 (0x649) - PWM2MIX Input 1 Volume */

 R1610 (0x64A) - PWM2MIX Input 2 Source */

 R1611 (0x64B) - PWM2MIX Input 2 Volume */

 R1612 (0x64C) - PWM2MIX Input 3 Source */

 R1613 (0x64D) - PWM2MIX Input 3 Volume */

 R1614 (0x64E) - PWM2MIX Input 4 Source */

 R1615 (0x64F) - PWM2MIX Input 4 Volume */

 R1664 (0x680) - OUT1LMIX Input 1 Source */

 R1665 (0x681) - OUT1LMIX Input 1 Volume */

 R1666 (0x682) - OUT1LMIX Input 2 Source */

 R1667 (0x683) - OUT1LMIX Input 2 Volume */

 R1668 (0x684) - OUT1LMIX Input 3 Source */

 R1669 (0x685) - OUT1LMIX Input 3 Volume */

 R1670 (0x686) - OUT1LMIX Input 4 Source */

 R1671 (0x687) - OUT1LMIX Input 4 Volume */

 R1672 (0x688) - OUT1RMIX Input 1 Source */

 R1673 (0x689) - OUT1RMIX Input 1 Volume */

 R1674 (0x68A) - OUT1RMIX Input 2 Source */

 R1675 (0x68B) - OUT1RMIX Input 2 Volume */

 R1676 (0x68C) - OUT1RMIX Input 3 Source */

 R1677 (0x68D) - OUT1RMIX Input 3 Volume */

 R1678 (0x68E) - OUT1RMIX Input 4 Source */

 R1679 (0x68F) - OUT1RMIX Input 4 Volume */

 R1712 (0x6B0) - OUT4LMIX Input 1 Source */

 R1713 (0x6B1) - OUT4LMIX Input 1 Volume */

 R1714 (0x6B2) - OUT4LMIX Input 2 Source */

 R1715 (0x6B3) - OUT4LMIX Input 2 Volume */

 R1716 (0x6B4) - OUT4LMIX Input 3 Source */

 R1717 (0x6B5) - OUT4LMIX Input 3 Volume */

 R1718 (0x6B6) - OUT4LMIX Input 4 Source */

 R1719 (0x6B7) - OUT4LMIX Input 4 Volume */

 R1728 (0x6C0) - OUT5LMIX Input 1 Source */

 R1729 (0x6C1) - OUT5LMIX Input 1 Volume */

 R1730 (0x6C2) - OUT5LMIX Input 2 Source */

 R1731 (0x6C3) - OUT5LMIX Input 2 Volume */

 R1732 (0x6C4) - OUT5LMIX Input 3 Source */

 R1733 (0x6C5) - OUT5LMIX Input 3 Volume */

 R1734 (0x6C6) - OUT5LMIX Input 4 Source */

 R1735 (0x6C7) - OUT5LMIX Input 4 Volume */

 R1736 (0x6C8) - OUT5RMIX Input 1 Source */

 R1737 (0x6C9) - OUT5RMIX Input 1 Volume */

 R1738 (0x6CA) - OUT5RMIX Input 2 Source */

 R1739 (0x6CB) - OUT5RMIX Input 2 Volume */

 R1740 (0x6CC) - OUT5RMIX Input 3 Source */

 R1741 (0x6CD) - OUT5RMIX Input 3 Volume */

 R1742 (0x6CE) - OUT5RMIX Input 4 Source */

 R1743 (0x6CF) - OUT5RMIX Input 4 Volume */

 R1792 (0x700) - AIF1TX1MIX Input 1 Source */

 R1793 (0x701) - AIF1TX1MIX Input 1 Volume */

 R1794 (0x702) - AIF1TX1MIX Input 2 Source */

 R1795 (0x703) - AIF1TX1MIX Input 2 Volume */

 R1796 (0x704) - AIF1TX1MIX Input 3 Source */

 R1797 (0x705) - AIF1TX1MIX Input 3 Volume */

 R1798 (0x706) - AIF1TX1MIX Input 4 Source */

 R1799 (0x707) - AIF1TX1MIX Input 4 Volume */

 R1800 (0x708) - AIF1TX2MIX Input 1 Source */

 R1801 (0x709) - AIF1TX2MIX Input 1 Volume */

 R1802 (0x70A) - AIF1TX2MIX Input 2 Source */

 R1803 (0x70B) - AIF1TX2MIX Input 2 Volume */

 R1804 (0x70C) - AIF1TX2MIX Input 3 Source */

 R1805 (0x70D) - AIF1TX2MIX Input 3 Volume */

 R1806 (0x70E) - AIF1TX2MIX Input 4 Source */

 R1807 (0x70F) - AIF1TX2MIX Input 4 Volume */

 R1808 (0x710) - AIF1TX3MIX Input 1 Source */

 R1809 (0x711) - AIF1TX3MIX Input 1 Volume */

 R1810 (0x712) - AIF1TX3MIX Input 2 Source */

 R1811 (0x713) - AIF1TX3MIX Input 2 Volume */

 R1812 (0x714) - AIF1TX3MIX Input 3 Source */

 R1813 (0x715) - AIF1TX3MIX Input 3 Volume */

 R1814 (0x716) - AIF1TX3MIX Input 4 Source */

 R1815 (0x717) - AIF1TX3MIX Input 4 Volume */

 R1816 (0x718) - AIF1TX4MIX Input 1 Source */

 R1817 (0x719) - AIF1TX4MIX Input 1 Volume */

 R1818 (0x71A) - AIF1TX4MIX Input 2 Source */

 R1819 (0x71B) - AIF1TX4MIX Input 2 Volume */

 R1820 (0x71C) - AIF1TX4MIX Input 3 Source */

 R1821 (0x71D) - AIF1TX4MIX Input 3 Volume */

 R1822 (0x71E) - AIF1TX4MIX Input 4 Source */

 R1823 (0x71F) - AIF1TX4MIX Input 4 Volume */

 R1824 (0x720) - AIF1TX5MIX Input 1 Source */

 R1825 (0x721) - AIF1TX5MIX Input 1 Volume */

 R1826 (0x722) - AIF1TX5MIX Input 2 Source */

 R1827 (0x723) - AIF1TX5MIX Input 2 Volume */

 R1828 (0x724) - AIF1TX5MIX Input 3 Source */

 R1829 (0x725) - AIF1TX5MIX Input 3 Volume */

 R1830 (0x726) - AIF1TX5MIX Input 4 Source */

 R1831 (0x727) - AIF1TX5MIX Input 4 Volume */

 R1832 (0x728) - AIF1TX6MIX Input 1 Source */

 R1833 (0x729) - AIF1TX6MIX Input 1 Volume */

 R1834 (0x72A) - AIF1TX6MIX Input 2 Source */

 R1835 (0x72B) - AIF1TX6MIX Input 2 Volume */

 R1836 (0x72C) - AIF1TX6MIX Input 3 Source */

 R1837 (0x72D) - AIF1TX6MIX Input 3 Volume */

 R1838 (0x72E) - AIF1TX6MIX Input 4 Source */

 R1839 (0x72F) - AIF1TX6MIX Input 4 Volume */

 R1856 (0x740) - AIF2TX1MIX Input 1 Source */

 R1857 (0x741) - AIF2TX1MIX Input 1 Volume */

 R1858 (0x742) - AIF2TX1MIX Input 2 Source */

 R1859 (0x743) - AIF2TX1MIX Input 2 Volume */

 R1860 (0x744) - AIF2TX1MIX Input 3 Source */

 R1861 (0x745) - AIF2TX1MIX Input 3 Volume */

 R1862 (0x746) - AIF2TX1MIX Input 4 Source */

 R1863 (0x747) - AIF2TX1MIX Input 4 Volume */

 R1864 (0x748) - AIF2TX2MIX Input 1 Source */

 R1865 (0x749) - AIF2TX2MIX Input 1 Volume */

 R1866 (0x74A) - AIF2TX2MIX Input 2 Source */

 R1867 (0x74B) - AIF2TX2MIX Input 2 Volume */

 R1868 (0x74C) - AIF2TX2MIX Input 3 Source */

 R1869 (0x74D) - AIF2TX2MIX Input 3 Volume */

 R1870 (0x74E) - AIF2TX2MIX Input 4 Source */

 R1871 (0x74F) - AIF2TX2MIX Input 4 Volume */

 R1872 (0x750) - AIF2TX3MIX Input 1 Source */

 R1873 (0x751) - AIF2TX3MIX Input 1 Volume */

 R1874 (0x752) - AIF2TX3MIX Input 2 Source */

 R1875 (0x753) - AIF2TX3MIX Input 2 Volume */

 R1876 (0x754) - AIF2TX3MIX Input 3 Source */

 R1877 (0x755) - AIF2TX3MIX Input 3 Volume */

 R1878 (0x756) - AIF2TX3MIX Input 4 Source */

 R1879 (0x757) - AIF2TX3MIX Input 4 Volume */

 R1880 (0x758) - AIF2TX4MIX Input 1 Source */

 R1881 (0x759) - AIF2TX4MIX Input 1 Volume */

 R1882 (0x75A) - AIF2TX4MIX Input 2 Source */

 R1883 (0x75B) - AIF2TX4MIX Input 2 Volume */

 R1884 (0x75C) - AIF2TX4MIX Input 3 Source */

 R1885 (0x75D) - AIF2TX4MIX Input 3 Volume */

 R1886 (0x75E) - AIF2TX4MIX Input 4 Source */

 R1887 (0x75F) - AIF2TX4MIX Input 4 Volume */

 R1920 (0x780) - AIF3TX1MIX Input 1 Source */

 R1921 (0x781) - AIF3TX1MIX Input 1 Volume */

 R1922 (0x782) - AIF3TX1MIX Input 2 Source */

 R1923 (0x783) - AIF3TX1MIX Input 2 Volume */

 R1924 (0x784) - AIF3TX1MIX Input 3 Source */

 R1925 (0x785) - AIF3TX1MIX Input 3 Volume */

 R1926 (0x786) - AIF3TX1MIX Input 4 Source */

 R1927 (0x787) - AIF3TX1MIX Input 4 Volume */

 R1928 (0x788) - AIF3TX2MIX Input 1 Source */

 R1929 (0x789) - AIF3TX2MIX Input 1 Volume */

 R1930 (0x78A) - AIF3TX2MIX Input 2 Source */

 R1931 (0x78B) - AIF3TX2MIX Input 2 Volume */

 R1932 (0x78C) - AIF3TX2MIX Input 3 Source */

 R1933 (0x78D) - AIF3TX2MIX Input 3 Volume */

 R1934 (0x78E) - AIF3TX2MIX Input 4 Source */

 R1935 (0x78F) - AIF3TX2MIX Input 4 Volume */

 R2048 (0x800) - SPDIF1TX1MIX Input 1 Source */

 R2049 (0x801) - SPDIF1TX1MIX Input 1 Volume */

 R2056 (0x808) - SPDIF1TX2MIX Input 1 Source */

 R2057 (0x809) - SPDIF1TX2MIX Input 1 Volume */

 R2176 (0x880) - EQ1MIX Input 1 Source */

 R2177 (0x881) - EQ1MIX Input 1 Volume */

 R2178 (0x882) - EQ1MIX Input 2 Source */

 R2179 (0x883) - EQ1MIX Input 2 Volume */

 R2180 (0x884) - EQ1MIX Input 3 Source */

 R2181 (0x885) - EQ1MIX Input 3 Volume */

 R2182 (0x886) - EQ1MIX Input 4 Source */

 R2183 (0x887) - EQ1MIX Input 4 Volume */

 R2184 (0x888) - EQ2MIX Input 1 Source */

 R2185 (0x889) - EQ2MIX Input 1 Volume */

 R2186 (0x88A) - EQ2MIX Input 2 Source */

 R2187 (0x88B) - EQ2MIX Input 2 Volume */

 R2188 (0x88C) - EQ2MIX Input 3 Source */

 R2189 (0x88D) - EQ2MIX Input 3 Volume */

 R2190 (0x88E) - EQ2MIX Input 4 Source */

 R2191 (0x88F) - EQ2MIX Input 4 Volume */

 R2192 (0x890) - EQ3MIX Input 1 Source */

 R2193 (0x891) - EQ3MIX Input 1 Volume */

 R2194 (0x892) - EQ3MIX Input 2 Source */

 R2195 (0x893) - EQ3MIX Input 2 Volume */

 R2196 (0x894) - EQ3MIX Input 3 Source */

 R2197 (0x895) - EQ3MIX Input 3 Volume */

 R2198 (0x896) - EQ3MIX Input 4 Source */

 R2199 (0x897) - EQ3MIX Input 4 Volume */

 R2200 (0x898) - EQ4MIX Input 1 Source */

 R2201 (0x899) - EQ4MIX Input 1 Volume */

 R2202 (0x89A) - EQ4MIX Input 2 Source */

 R2203 (0x89B) - EQ4MIX Input 2 Volume */

 R2204 (0x89C) - EQ4MIX Input 3 Source */

 R2205 (0x89D) - EQ4MIX Input 3 Volume */

 R2206 (0x89E) - EQ4MIX Input 4 Source */

 R2207 (0x89F) - EQ4MIX Input 4 Volume */

 R2240 (0x8C0) - DRC1LMIX Input 1 Source */

 R2241 (0x8C1) - DRC1LMIX Input 1 Volume */

 R2242 (0x8C2) - DRC1LMIX Input 2 Source */

 R2243 (0x8C3) - DRC1LMIX Input 2 Volume */

 R2244 (0x8C4) - DRC1LMIX Input 3 Source */

 R2245 (0x8C5) - DRC1LMIX Input 3 Volume */

 R2246 (0x8C6) - DRC1LMIX Input 4 Source */

 R2247 (0x8C7) - DRC1LMIX Input 4 Volume */

 R2248 (0x8C8) - DRC1RMIX Input 1 Source */

 R2249 (0x8C9) - DRC1RMIX Input 1 Volume */

 R2250 (0x8CA) - DRC1RMIX Input 2 Source */

 R2251 (0x8CB) - DRC1RMIX Input 2 Volume */

 R2252 (0x8CC) - DRC1RMIX Input 3 Source */

 R2253 (0x8CD) - DRC1RMIX Input 3 Volume */

 R2254 (0x8CE) - DRC1RMIX Input 4 Source */

 R2255 (0x8CF) - DRC1RMIX Input 4 Volume */

 R2256 (0x8D0) - DRC2LMIX Input 1 Source */

 R2257 (0x8D1) - DRC2LMIX Input 1 Volume */

 R2258 (0x8D2) - DRC2LMIX Input 2 Source */

 R2259 (0x8D3) - DRC2LMIX Input 2 Volume */

 R2260 (0x8D4) - DRC2LMIX Input 3 Source */

 R2261 (0x8D5) - DRC2LMIX Input 3 Volume */

 R2262 (0x8D6) - DRC2LMIX Input 4 Source */

 R2263 (0x8D7) - DRC2LMIX Input 4 Volume */

 R2264 (0x8D8) - DRC2RMIX Input 1 Source */

 R2265 (0x8D9) - DRC2RMIX Input 1 Volume */

 R2266 (0x8DA) - DRC2RMIX Input 2 Source */

 R2267 (0x8DB) - DRC2RMIX Input 2 Volume */

 R2268 (0x8DC) - DRC2RMIX Input 3 Source */

 R2269 (0x8DD) - DRC2RMIX Input 3 Volume */

 R2270 (0x8DE) - DRC2RMIX Input 4 Source */

 R2271 (0x8DF) - DRC2RMIX Input 4 Volume */

 R2304 (0x900) - HPLP1MIX Input 1 Source */

 R2305 (0x901) - HPLP1MIX Input 1 Volume */

 R2306 (0x902) - HPLP1MIX Input 2 Source */

 R2307 (0x903) - HPLP1MIX Input 2 Volume */

 R2308 (0x904) - HPLP1MIX Input 3 Source */

 R2309 (0x905) - HPLP1MIX Input 3 Volume */

 R2310 (0x906) - HPLP1MIX Input 4 Source */

 R2311 (0x907) - HPLP1MIX Input 4 Volume */

 R2312 (0x908) - HPLP2MIX Input 1 Source */

 R2313 (0x909) - HPLP2MIX Input 1 Volume */

 R2314 (0x90A) - HPLP2MIX Input 2 Source */

 R2315 (0x90B) - HPLP2MIX Input 2 Volume */

 R2316 (0x90C) - HPLP2MIX Input 3 Source */

 R2317 (0x90D) - HPLP2MIX Input 3 Volume */

 R2318 (0x90E) - HPLP2MIX Input 4 Source */

 R2319 (0x90F) - HPLP2MIX Input 4 Volume */

 R2320 (0x910) - HPLP3MIX Input 1 Source */

 R2321 (0x911) - HPLP3MIX Input 1 Volume */

 R2322 (0x912) - HPLP3MIX Input 2 Source */

 R2323 (0x913) - HPLP3MIX Input 2 Volume */

 R2324 (0x914) - HPLP3MIX Input 3 Source */

 R2325 (0x915) - HPLP3MIX Input 3 Volume */

 R2326 (0x916) - HPLP3MIX Input 4 Source */

 R2327 (0x917) - HPLP3MIX Input 4 Volume */

 R2328 (0x918) - HPLP4MIX Input 1 Source */

 R2329 (0x919) - HPLP4MIX Input 1 Volume */

 R2330 (0x91A) - HPLP4MIX Input 2 Source */

 R2331 (0x91B) - HPLP4MIX Input 2 Volume */

 R2332 (0x91C) - HPLP4MIX Input 3 Source */

 R2333 (0x91D) - HPLP4MIX Input 3 Volume */

 R2334 (0x91E) - HPLP4MIX Input 4 Source */

 R2335 (0x91F) - HPLP4MIX Input 4 Volume */

 R2368 (0x940) - DSP1LMIX Input 1 Source */

 R2369 (0x941) - DSP1LMIX Input 1 Volume */

 R2370 (0x942) - DSP1LMIX Input 2 Source */

 R2371 (0x943) - DSP1LMIX Input 2 Volume */

 R2372 (0x944) - DSP1LMIX Input 3 Source */

 R2373 (0x945) - DSP1LMIX Input 3 Volume */

 R2374 (0x946) - DSP1LMIX Input 4 Source */

 R2375 (0x947) - DSP1LMIX Input 4 Volume */

 R2376 (0x948) - DSP1RMIX Input 1 Source */

 R2377 (0x949) - DSP1RMIX Input 1 Volume */

 R2378 (0x94A) - DSP1RMIX Input 2 Source */

 R2379 (0x94B) - DSP1RMIX Input 2 Volume */

 R2380 (0x94C) - DSP1RMIX Input 3 Source */

 R2381 (0x94D) - DSP1RMIX Input 3 Volume */

 R2382 (0x94E) - DSP1RMIX Input 4 Source */

 R2383 (0x94F) - DSP1RMIX Input 4 Volume */

 R2384 (0x950) - DSP1AUX1MIX Input 1 Source */

 R2392 (0x958) - DSP1AUX2MIX Input 1 Source */

 R2400 (0x960) - DSP1AUX3MIX Input 1 Source */

 R2408 (0x968) - DSP1AUX4MIX Input 1 Source */

 R2416 (0x970) - DSP1AUX5MIX Input 1 Source */

 R2424 (0x978) - DSP1AUX6MIX Input 1 Source */

 R2816 (0xB00) - ISRC1DEC1MIX Input 1 Source */

 R2824 (0xB08) - ISRC1DEC2MIX Input 1 Source */

 R2832 (0xB10) - ISRC1DEC3MIX Input 1 Source */

 R2840 (0xB18) - ISRC1DEC4MIX Input 1 Source */

 R2848 (0xB20) - ISRC1INT1MIX Input 1 Source */

 R2856 (0xB28) - ISRC1INT2MIX Input 1 Source */

 R2864 (0xB30) - ISRC1INT3MIX Input 1 Source */

 R2872 (0xB38) - ISRC1INT4MIX Input 1 Source */

 R2880 (0xB40) - ISRC2DEC1MIX Input 1 Source */

 R2888 (0xB48) - ISRC2DEC2MIX Input 1 Source */

 R2896 (0xB50) - ISRC2DEC3MIX Input 1 Source */

 R2904 (0xB58) - ISRC2DEC4MIX Input 1 Source */

 R2912 (0xB60) - ISRC2INT1MIX Input 1 Source */

 R2920 (0xB68) - ISRC2INT2MIX Input 1 Source */

 R2928 (0xB70) - ISRC2INT3MIX Input 1 Source */

 R2936 (0xB78) - ISRC2INT4MIX Input 1 Source */

 R3584 (0xE00) - FX Ctrl 1 */

 R3600 (0xE10) - EQ1 1 */

 R3601 (0xE11) - EQ1 2 */

 R3602 (0xE12) - EQ1 3 */

 R3603 (0xE13) - EQ1 4 */

 R3604 (0xE14) - EQ1 5 */

 R3605 (0xE15) - EQ1 6 */

 R3606 (0xE16) - EQ1 7 */

 R3607 (0xE17) - EQ1 8 */

 R3608 (0xE18) - EQ1 9 */

 R3609 (0xE19) - EQ1 10 */

 R3610 (0xE1A) - EQ1 11 */

 R3611 (0xE1B) - EQ1 12 */

 R3612 (0xE1C) - EQ1 13 */

 R3613 (0xE1D) - EQ1 14 */

 R3614 (0xE1E) - EQ1 15 */

 R3615 (0xE1F) - EQ1 16 */

 R3616 (0xE20) - EQ1 17 */

 R3617 (0xE21) - EQ1 18 */

 R3618 (0xE22) - EQ1 19 */

 R3619 (0xE23) - EQ1 20 */

 R3620 (0xE24) - EQ1 21 */

 R3622 (0xE26) - EQ2 1 */

 R3623 (0xE27) - EQ2 2 */

 R3624 (0xE28) - EQ2 3 */

 R3625 (0xE29) - EQ2 4 */

 R3626 (0xE2A) - EQ2 5 */

 R3627 (0xE2B) - EQ2 6 */

 R3628 (0xE2C) - EQ2 7 */

 R3629 (0xE2D) - EQ2 8 */

 R3630 (0xE2E) - EQ2 9 */

 R3631 (0xE2F) - EQ2 10 */

 R3632 (0xE30) - EQ2 11 */

 R3633 (0xE31) - EQ2 12 */

 R3634 (0xE32) - EQ2 13 */

 R3635 (0xE33) - EQ2 14 */

 R3636 (0xE34) - EQ2 15 */

 R3637 (0xE35) - EQ2 16 */

 R3638 (0xE36) - EQ2 17 */

 R3639 (0xE37) - EQ2 18 */

 R3640 (0xE38) - EQ2 19 */

 R3641 (0xE39) - EQ2 20 */

 R3642 (0xE3A) - EQ2 21 */

 R3644 (0xE3C) - EQ3 1 */

 R3645 (0xE3D) - EQ3 2 */

 R3646 (0xE3E) - EQ3 3 */

 R3647 (0xE3F) - EQ3 4 */

 R3648 (0xE40) - EQ3 5 */

 R3649 (0xE41) - EQ3 6 */

 R3650 (0xE42) - EQ3 7 */

 R3651 (0xE43) - EQ3 8 */

 R3652 (0xE44) - EQ3 9 */

 R3653 (0xE45) - EQ3 10 */

 R3654 (0xE46) - EQ3 11 */

 R3655 (0xE47) - EQ3 12 */

 R3656 (0xE48) - EQ3 13 */

 R3657 (0xE49) - EQ3 14 */

 R3658 (0xE4A) - EQ3 15 */

 R3659 (0xE4B) - EQ3 16 */

 R3660 (0xE4C) - EQ3 17 */

 R3661 (0xE4D) - EQ3 18 */

 R3662 (0xE4E) - EQ3 19 */

 R3663 (0xE4F) - EQ3 20 */

 R3664 (0xE50) - EQ3 21 */

 R3666 (0xE52) - EQ4 1 */

 R3667 (0xE53) - EQ4 2 */

 R3668 (0xE54) - EQ4 3 */

 R3669 (0xE55) - EQ4 4 */

 R3670 (0xE56) - EQ4 5 */

 R3671 (0xE57) - EQ4 6 */

 R3672 (0xE58) - EQ4 7 */

 R3673 (0xE59) - EQ4 8 */

 R3674 (0xE5A) - EQ4 9 */

 R3675 (0xE5B) - EQ4 10 */

 R3676 (0xE5C) - EQ4 11 */

 R3677 (0xE5D) - EQ4 12 */

 R3678 (0xE5E) - EQ4 13 */

 R3679 (0xE5F) - EQ4 14 */

 R3680 (0xE60) - EQ4 15 */

 R3681 (0xE61) - EQ4 16 */

 R3682 (0xE62) - EQ4 17 */

 R3683 (0xE63) - EQ4 18 */

 R3684 (0xE64) - EQ4 19 */

 R3685 (0xE65) - EQ4 20 */

 R3686 (0xE66) - EQ4 21 */

 R3712 (0xE80) - DRC1 Ctrl 1 */

 R3713 (0xE81) - DRC1 Ctrl 2 */

 R3714 (0xE82) - DRC1 Ctrl 3 */

 R3715 (0xE83) - DRC1 Ctrl 4 */

 R3716 (0xE84) - DRC1 Ctrl 5 */

 R3720 (0xE88) - DRC2 Ctrl 1 */

 R3721 (0xE89) - DRC2 Ctrl 2 */

 R3722 (0xE8A) - DRC2 Ctrl 3 */

 R3723 (0xE8B) - DRC2 Ctrl 4 */

 R3724 (0xE8C) - DRC2 Ctrl 5 */

 R3776 (0xEC0) - HPLPF1 1 */

 R3777 (0xEC1) - HPLPF1 2 */

 R3780 (0xEC4) - HPLPF2 1 */

 R3781 (0xEC5) - HPLPF2 2 */

 R3784 (0xEC8) - HPLPF3 1 */

 R3785 (0xEC9) - HPLPF3 2 */

 R3788 (0xECC) - HPLPF4 1 */

 R3789 (0xECD) - HPLPF4 2 */

 R3824 (0xEF0) - ISRC1 Ctrl 1 */

 R3825 (0xEF1) - ISRC1 Ctrl 2 */

 R3826 (0xEF2) - ISRC1 Ctrl 3 */

 R3827 (0xEF3) - ISRC2 Ctrl 1 */

 R3828 (0xEF4) - ISRC2 Ctrl 2 */

 R3829 (0xEF5) - ISRC2 Ctrl 3 */

 R5888 (0x1700) - GPIO1 Ctrl 1 */

 R5889 (0x1701) - GPIO1 Ctrl 2 */

 R5890 (0x1702) - GPIO2 Ctrl 1 */

 R5891 (0x1703) - GPIO2 Ctrl 2 */

 R5892 (0x1704) - GPIO3 Ctrl 1 */

 R5893 (0x1705) - GPIO3 Ctrl 2 */

 R5894 (0x1706) - GPIO4 Ctrl 1 */

 R5895 (0x1707) - GPIO4 Ctrl 2 */

 R5896 (0x1708) - GPIO5 Ctrl 1 */

 R5897 (0x1709) - GPIO5 Ctrl 2 */

 R5898 (0x170A) - GPIO6 Ctrl 1 */

 R5899 (0x170B) - GPIO6 Ctrl 2 */

 R5900 (0x170C) - GPIO7 Ctrl 1 */

 R5901 (0x170D) - GPIO7 Ctrl 2 */

 R5902 (0x170E) - GPIO8 Ctrl 1 */

 R5903 (0x170F) - GPIO8 Ctrl 2 */

 R5904 (0x1710) - GPIO9 Ctrl 1 */

 R5905 (0x1711) - GPIO9 Ctrl 2 */

 R5906 (0x1712) - GPIO10 Ctrl 1 */

 R5907 (0x1713) - GPIO10 Ctrl 2 */

 R5908 (0x1714) - GPIO11 Ctrl 1 */

 R5909 (0x1715) - GPIO11 Ctrl 2 */

 R5910 (0x1716) - GPIO12 Ctrl 1 */

 R5911 (0x1717) - GPIO12 Ctrl 2 */

 R5912 (0x1718) - GPIO13 Ctrl 1 */

 R5913 (0x1719) - GPIO13 Ctrl 2 */

 R5914 (0x171A) - GPIO14 Ctrl 1 */

 R5915 (0x171B) - GPIO14 Ctrl 2 */

 R5916 (0x171C) - GPIO15 Ctrl 1 */

 R5917 (0x171D) - GPIO15 Ctrl 2 */

 R6208 (0x1840) - IRQ1 Mask 1 */

 R6209 (0x1841) - IRQ1 Mask 2 */

 R6210 (0x1842) - IRQ1 Mask 3 */

 R6211 (0x1843) - IRQ1 Mask 4 */

 R6212 (0x1844) - IRQ1 Mask 5 */

 R6213 (0x1845) - IRQ1 Mask 6 */

 R6214 (0x1846) - IRQ1 Mask 7 */

 R6215 (0x1847) - IRQ1 Mask 8 */

 R6216 (0x1848) - IRQ1 Mask 9 */

 R6217 (0x1849) - IRQ1 Mask 10 */

 R6218 (0x184A) - IRQ1 Mask 11 */

 R6219 (0x184B) - IRQ1 Mask 12 */

 R6220 (0x184C) - IRQ1 Mask 13 */

 R6221 (0x184D) - IRQ1 Mask 14 */

 R6222 (0x184E) - IRQ1 Mask 15 */

 R6223 (0x184F) - IRQ1 Mask 16 */

 R6224 (0x1850) - IRQ1 Mask 17 */

 R6225 (0x1851) - IRQ1 Mask 18 */

 R6226 (0x1852) - IRQ1 Mask 19 */

 R6227 (0x1853) - IRQ1 Mask 20 */

 R6228 (0x1854) - IRQ1 Mask 21 */

 R6229 (0x1855) - IRQ1 Mask 22 */

 R6230 (0x1856) - IRQ1 Mask 23 */

 R6231 (0x1857) - IRQ1 Mask 24 */

 R6232 (0x1858) - IRQ1 Mask 25 */

 R6233 (0x1859) - IRQ1 Mask 26 */

 R6234 (0x185A) - IRQ1 Mask 27 */

 R6235 (0x185B) - IRQ1 Mask 28 */

 R6236 (0x185C) - IRQ1 Mask 29 */

 R6237 (0x185D) - IRQ1 Mask 30 */

 R6238 (0x185E) - IRQ1 Mask 31 */

 R6239 (0x185F) - IRQ1 Mask 32 */

 R6240 (0x1860) - IRQ1 Mask 33 */

 R6662 (0x1A06) - Interrupt Debounce 7 */

 R6784 (0x1A80) - IRQ1 Ctrl */

