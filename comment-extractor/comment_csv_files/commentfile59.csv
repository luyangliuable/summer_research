 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Rabin Vincent <rabin at rab.in>

 No PC, no problem */

	/*

	 * fls instead of ffs ensures that for "ldrd r0, r1, [pc]" we would

	 * pick LR instead of R1.

 PC will be taken care of by common code */

 Use LR instead of PC */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Rabin Vincent <rabin at rab.in>

 Replace the return addr with trampoline addr */

 Thumb not yet support */

 Unconditional instruction */

 Copy condition from insn */

 Initialize the slot */

 flush caches (dcache/icache) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/probes/kprobes/checkers-common.c

 *

 * Copyright (C) 2014 Huawei Inc.

/*

 * Different from other insn uses imm8, the real addressing offset of

 * STRD in T32 encoding should be imm8 * 4. See ARMARM description.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/probes/kprobes/checkers-thumb.c

 *

 * Copyright (C) 2014 Huawei Inc.

	/*

	 * PROBES_T32_LDMSTM, PROBES_T32_LDRDSTRD and PROBES_T32_LDRSTR

	 * may get here. Simply mark all normal insns as STACK_USE_NONE.

		/*

		 * First, filter out all ldr insns to make our life easier.

		 * Following load insns may come here:

		 * LDM, LDRD, LDR.

		 * In T32 encoding, bit 20 is enough for distinguishing

		 * load and store. All load insns have this bit set, when

		 * all store insns have this bit clear.

		/*

		 * Mark all 'STR{,B,H}, Rt, [Rn, Rm]' as STACK_USE_UNKNOWN

		 * if Rn or Rm is SP. T32 doesn't encode STRD.

                                 xx | Rn | Rt |         | Rm |*/

 STR (register)	1111 1000 0100 xxxx xxxx 0000 00xx xxxx */

 STRB (register)	1111 1000 0000 xxxx xxxx 0000 00xx xxxx */

 STRH (register)	1111 1000 0010 xxxx xxxx 0000 00xx xxxx */

 INVALID INSN		1111 1000 0110 xxxx xxxx 0000 00xx xxxx */

 By Introducing INVALID INSN, bit 21 and 22 can be ignored. */

                                 xx | Rn | Rt | PUW|   imm8  |*/

 STR (imm 8)		1111 1000 0100 1101 xxxx 110x xxxx xxxx */

 STRB (imm 8)		1111 1000 0000 1101 xxxx 110x xxxx xxxx */

 STRH (imm 8)		1111 1000 0010 1101 xxxx 110x xxxx xxxx */

 INVALID INSN		1111 1000 0110 1101 xxxx 110x xxxx xxxx */

 Only consider U == 0 and P == 1: strx rx, [sp, #-<imm>] */

 For STR{,B,H} (imm 12), offset is always positive, so ignore them. */

                              P U W | Rn | Rt | Rt2|   imm8  |*/

 STRD (immediate)	1110 1001 01x0 1101 xxxx xxxx xxxx xxxx */

		/*

		 * Only consider U == 0 and P == 1.

		 * Also note that STRD in T32 encoding is special:

		 * imm = ZeroExtend(imm8:'00', 32)

                                    | Rn | */

 STMDB		1110 1001 00x0 1101 xxxx xxxx xxxx xxxx */

 fall through */

/*

 * See following comments. This insn must be 'push'.

/*

 * T16 encoding is simple: only the 'push' insn can need extra stack space.

 * Other insns, like str, can only use r0-r7 as Rn.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/probes/kprobes/actions-thumb.c

 *

 * Copyright (C) 2011 Jon Medhurst <tixy@yxit.co.uk>.

 These emulation encodings are functionally equivalent... */

 t32 thumb actions */

 TBH */

 TBB */

 Mask out execution state */

 imm11 */

 imm6 */

 J1 */

 J2 */

 Apply sign bit */

 imm11 */

 imm10 */

 J1 */

 J2 */

 Apply sign bit */

 Invert J1 and J2 */

 BL or BLX */

 BLX so switch to ARM mode */

 LDR */

 LDRH */

 LDRB */

 Fixup modified instruction to have halfwords in correct order...*/

 Writeback base register */

 Writeback base register */

 Can't be true for a STR as they aren't allowed */

 t16 thumb actions */

 BLX ? */

 LDR */

 STR */

 SUB */

 ADD */

	/*

	 * The 8 IT state bits are split into two parts in CPSR:

	 *	ITSTATE<1:0> are in CPSR<26:25>

	 *	ITSTATE<7:2> are in CPSR<15:10>

	 * The new IT state is in the lower byte of insn.

 Apply sign bit */

 Apply sign bit */

 Set Rdn = R1 and Rm = R0 */

	/*

	 * To simulate a PUSH we use a Thumb-2 "STMDB R9!, {registers}"

	 * and call it with R9=SP and LR in the register list represented

	 * by R8.

 1st half STMDB R9!,{} */

 2nd half (register list) */

	/*

	 * To simulate a POP we use a Thumb-2 "LDMDB R9!, {registers}"

	 * and call it with R9=SP and PC in the register list represented

	 * by R8.

 1st half LDMIA R9!,{} */

 2nd half (register list) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/kernel/kprobes-test.c

 *

 * Copyright (C) 2011 Jon Medhurst <tixy@yxit.co.uk>.

/*

 * This file contains test code for ARM kprobes.

 *

 * The top level function run_all_tests() executes tests for all of the

 * supported instruction sets: ARM, 16-bit Thumb, and 32-bit Thumb. These tests

 * fall into two categories; run_api_tests() checks basic functionality of the

 * kprobes API, and run_test_cases() is a comprehensive test for kprobes

 * instruction decoding and simulation.

 *

 * run_test_cases() first checks the kprobes decoding table for self consistency

 * (using table_test()) then executes a series of test cases for each of the CPU

 * instruction forms. coverage_start() and coverage_end() are used to verify

 * that these test cases cover all of the possible combinations of instructions

 * described by the kprobes decoding tables.

 *

 * The individual test cases are in kprobes-test-arm.c and kprobes-test-thumb.c

 * which use the macros defined in kprobes-test.h. The rest of this

 * documentation will describe the operation of the framework used by these

 * test cases.

/*

 * TESTING METHODOLOGY

 * -------------------

 *

 * The methodology used to test an ARM instruction 'test_insn' is to use

 * inline assembler like:

 *

 * test_before: nop

 * test_case:	test_insn

 * test_after:	nop

 *

 * When the test case is run a kprobe is placed of each nop. The

 * post-handler of the test_before probe is used to modify the saved CPU

 * register context to that which we require for the test case. The

 * pre-handler of the of the test_after probe saves a copy of the CPU

 * register context. In this way we can execute test_insn with a specific

 * register context and see the results afterwards.

 *

 * To actually test the kprobes instruction emulation we perform the above

 * step a second time but with an additional kprobe on the test_case

 * instruction itself. If the emulation is accurate then the results seen

 * by the test_after probe will be identical to the first run which didn't

 * have a probe on test_case.

 *

 * Each test case is run several times with a variety of variations in the

 * flags value of stored in CPSR, and for Thumb code, different ITState.

 *

 * For instructions which can modify PC, a second test_after probe is used

 * like this:

 *

 * test_before: nop

 * test_case:	test_insn

 * test_after:	nop

 *		b test_done

 * test_after2: nop

 * test_done:

 *

 * The test case is constructed such that test_insn branches to

 * test_after2, or, if testing a conditional instruction, it may just

 * continue to test_after. The probes inserted at both locations let us

 * determine which happened. A similar approach is used for testing

 * backwards branches...

 *

 *		b test_before

 *		b test_done  @ helps to cope with off by 1 branches

 * test_after2: nop

 *		b test_done

 * test_before: nop

 * test_case:	test_insn

 * test_after:	nop

 * test_done:

 *

 * The macros used to generate the assembler instructions describe above

 * are TEST_INSTRUCTION, TEST_BRANCH_F (branch forwards) and TEST_BRANCH_B

 * (branch backwards). In these, the local variables numbered 1, 50, 2 and

 * 99 represent: test_before, test_case, test_after2 and test_done.

 *

 * FRAMEWORK

 * ---------

 *

 * Each test case is wrapped between the pair of macros TESTCASE_START and

 * TESTCASE_END. As well as performing the inline assembler boilerplate,

 * these call out to the kprobes_test_case_start() and

 * kprobes_test_case_end() functions which drive the execution of the test

 * case. The specific arguments to use for each test case are stored as

 * inline data constructed using the various TEST_ARG_* macros. Putting

 * this all together, a simple test case may look like:

 *

 *	TESTCASE_START("Testing mov r0, r7")

 *	TEST_ARG_REG(7, 0x12345678) // Set r7=0x12345678

 *	TEST_ARG_END("")

 *	TEST_INSTRUCTION("mov r0, r7")

 *	TESTCASE_END

 *

 * Note, in practice the single convenience macro TEST_R would be used for this

 * instead.

 *

 * The above would expand to assembler looking something like:

 *

 *	@ TESTCASE_START

 *	bl	__kprobes_test_case_start

 *	.pushsection .rodata

 *	"10:

 *	.ascii "mov r0, r7"	@ text title for test case

 *	.byte	0

 *	.popsection

 *	@ start of inline data...

 *	.word	10b		@ pointer to title in .rodata section

 *

 *	@ TEST_ARG_REG

 *	.byte	ARG_TYPE_REG

 *	.byte	7

 *	.short	0

 *	.word	0x1234567

 *

 *	@ TEST_ARG_END

 *	.byte	ARG_TYPE_END

 *	.byte	TEST_ISA	@ flags, including ISA being tested

 *	.short	50f-0f		@ offset of 'test_before'

 *	.short	2f-0f		@ offset of 'test_after2' (if relevent)

 *	.short	99f-0f		@ offset of 'test_done'

 *	@ start of test case code...

 *	0:

 *	.code	TEST_ISA	@ switch to ISA being tested

 *

 *	@ TEST_INSTRUCTION

 *	50:	nop		@ location for 'test_before' probe

 *	1:	mov r0, r7	@ the test case instruction 'test_insn'

 *		nop		@ location for 'test_after' probe

 *

 *	// TESTCASE_END

 *	2:

 *	99:	bl __kprobes_test_case_end_##TEST_ISA

 *	.code	NONMAL_ISA

 *

 * When the above is execute the following happens...

 *

 * __kprobes_test_case_start() is an assembler wrapper which sets up space

 * for a stack buffer and calls the C function kprobes_test_case_start().

 * This C function will do some initial processing of the inline data and

 * setup some global state. It then inserts the test_before and test_after

 * kprobes and returns a value which causes the assembler wrapper to jump

 * to the start of the test case code, (local label '0').

 *

 * When the test case code executes, the test_before probe will be hit and

 * test_before_post_handler will call setup_test_context(). This fills the

 * stack buffer and CPU registers with a test pattern and then processes

 * the test case arguments. In our example there is one TEST_ARG_REG which

 * indicates that R7 should be loaded with the value 0x12345678.

 *

 * When the test_before probe ends, the test case continues and executes

 * the "mov r0, r7" instruction. It then hits the test_after probe and the

 * pre-handler for this (test_after_pre_handler) will save a copy of the

 * CPU register context. This should now have R0 holding the same value as

 * R7.

 *

 * Finally we get to the call to __kprobes_test_case_end_{32,16}. This is

 * an assembler wrapper which switches back to the ISA used by the test

 * code and calls the C function kprobes_test_case_end().

 *

 * For each run through the test case, test_case_run_count is incremented

 * by one. For even runs, kprobes_test_case_end() saves a copy of the

 * register and stack buffer contents from the test case just run. It then

 * inserts a kprobe on the test case instruction 'test_insn' and returns a

 * value to cause the test case code to be re-run.

 *

 * For odd numbered runs, kprobes_test_case_end() compares the register and

 * stack buffer contents to those that were saved on the previous even

 * numbered run (the one without the kprobe on test_insn). These should be

 * the same if the kprobe instruction simulation routine is correct.

 *

 * The pair of test case runs is repeated with different combinations of

 * flag values in CPSR and, for Thumb, different ITState. This is

 * controlled by test_context_cpsr().

 *

 * BUILDING TEST CASES

 * -------------------

 *

 *

 * As an aid to building test cases, the stack buffer is initialised with

 * some special values:

 *

 *   [SP+13*4]	Contains SP+120. This can be used to test instructions

 *		which load a value into SP.

 *

 *   [SP+15*4]	When testing branching instructions using TEST_BRANCH_{F,B},

 *		this holds the target address of the branch, 'test_after2'.

 *		This can be used to test instructions which load a PC value

 *		from memory.

/*

 * Test basic API

 Back to Thumb if necessary */

 CONFIG_THUMB2_KERNEL */

 CONFIG_THUMB2_KERNEL */

 Clear disable flag to allow reuse */

 Clear disable flag to allow reuse */

/*

 * Benchmarking

 Stop once we took more than 0.25 seconds */

 Time for one iteration in nanoseconds */

		/*

		 * benchmark_pushpop{1,3} will have the optimised

		 * instruction emulation, whilst benchmark_pushpop{2,4} will

		 * be the equivalent unoptimised instructions.

 BENCHMARKING */

/*

 * Decoding table self-consistency tests

/*

 * Decoding table test coverage analysis

 *

 * coverage_start() builds a coverage_table which contains a list of

 * coverage_entry's to match each entry in the specified kprobes instruction

 * decoding table.

 *

 * When test cases are run, coverage_add() is called to process each case.

 * This looks up the corresponding entry in the coverage_table and sets it as

 * being matched, as well as clearing the regs flag appropriate for the test.

 *

 * After all test cases have been run, coverage_end() is called to check that

 * all entries in coverage_table have been matched and that all regs flags are

 * cleared. I.e. that all possible combinations of instructions described by

 * the kprobes decoding tables have had a test case executed for them.

 Skip sub-table we didn't match */

 End of sub-table we were scanning */

/*

 * Framework for instruction set test cases

 CONFIG_THUMB2_KERNEL */

 0 = no, 1 = yes, -1 = unknown */

 Default case is that we cycle through 16 combinations of flags */

 N,Z,C,V flags */

 GE flags */

 Toggle Q flag */

 Testing ARM code */

 Testing Thumb code without setting ITSTATE */

 Testing Thumb code with all combinations of ITSTATE */

 ITSTATE<7:5> */

 ITSTATE<4:0>, bits reversed */

 Finish by testing state from instruction 'itt al' */

 ITSTATE<7:5> */

 ITSTATE<4> */

 ITSTATE<3> */

 ITSTATE<2> */

 ITSTATE<1> */

 ITSTATE<0> */

 Testing Thumb code with several combinations of ITSTATE */

 Clear NZCV flags and 'it eq' state (false as Z=0) */

 Set NZCV flags and 'it vc' state (false as V=1) */

 Clear NZCV flags and 'it ls' state (true as C=0) */

 Set NZCV flags and 'it cs' state (true as C=1) */

 Initialise test memory on stack */

 Put target of branch on stack for tests which load PC from memory */

 Put a value for SP on stack for tests which load SP from memory */

 Initialise register values to their default state */

 Perform testcase specific register setup  */

			/*

			 * Test memory at an address below SP is in danger of

			 * being altered by an interrupt occurring and pushing

			 * data onto the stack. Disable interrupts to stop this.

 Clear disable flag to allow reuse */

 Already run for this test instance */

 Mask out results which are indeterminate */

 Undo any changes done to SP by the test case */

 Enable interrupts in case setup_test_context disabled them */

 Code starts after args */

 Start first run of test case */

 kprobes_test_case_start did all the needed testing */

 kprobes_test_case_start failed */

	/*

	 * Even numbered test runs ran without a probe on the test case so

	 * we can gather reference results. The subsequent odd numbered run

	 * will have the probe inserted.

 Save results from run without probe */

 Insert probe onto test case instruction */

 Check probe ran as expected */

 Remove probe for any subsequent reference run */

 Do next test run */

/*

 * Top level test functions

 CONFIG_THUMB2_KERNEL */

 We are able to run all test cases so coverage should be complete */

/*

 * Module setup

 !MODULE */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Kernel Probes Jump Optimization (Optprobes)

 *

 * Copyright (C) IBM Corporation, 2002, 2004

 * Copyright (C) Hitachi Ltd., 2012

 * Copyright (C) Huawei Inc., 2014

 for arm_gen_branch */

 for patch_text */

/*

 * See register_usage_flags. If the probed instruction doesn't use PC,

 * we can copy it into template and have it executed directly without

 * simulation or emulation.

/*

 * NOTE: the first sub and add instruction will be modified according

 * to the stack cost of the instruction.

			/*

			 * AEABI requires an 8-bytes alignment stack. If

			 * SP % 8 != 0 (SP % 4 == 0 should be ensured),

			 * alloc more bytes here.

/*

 * ARM can always optimize an instruction when using ARM ISA, except

 * instructions like 'str r0, [sp, r1]' which store to stack and unable

 * to determine stack space consumption statically.

/*

 * In ARM ISA, kprobe opt always replace one instruction (4 bytes

 * aligned and 4 bytes long). It is impossible to encounter another

 * kprobe in the address range. So always return 0.

 Caller must ensure addr & 3 == 0 */

	/*

	 * 255 is the biggest imm can be used in 'sub r0, r0, #<imm>'.

	 * Number larger than 255 needs special encoding.

 Free optimized instruction slot */

 Save skipped registers */

	/*

	 * We singlestep the replaced instruction only when it can't be

	 * executed directly during restore.

	/*

	 * Verify if the address gap is in 32MiB range, because this uses

	 * a relative jump.

	 *

	 * kprobe opt use a 'b' instruction to branch to optinsn.insn.

	 * According to ARM manual, branch instruction is:

	 *

	 *   31  28 27           24 23             0

	 *  +------+---+---+---+---+----------------+

	 *  | cond | 1 | 0 | 1 | 0 |      imm24     |

	 *  +------+---+---+---+---+----------------+

	 *

	 * imm24 is a signed 24 bits integer. The real branch offset is computed

	 * by: imm32 = SignExtend(imm24:'00', 32);

	 *

	 * So the maximum forward branch should be:

	 *   (0x007fffff << 2) = 0x01fffffc =  0x1fffffc

	 * The maximum backword branch should be:

	 *   (0xff800000 << 2) = 0xfe000000 = -0x2000000

	 *

	 * We can simply check (rel & 0xfe000003):

	 *  if rel is positive, (rel & 0xfe000000) shoule be 0

	 *  if rel is negitive, (rel & 0xfe000000) should be 0xfe000000

	 *  the last '3' is used for alignment checking.

		/*

		 * Different from x86, we free code buf directly instead of

		 * calling __arch_remove_optimized_kprobe() because

		 * we have not fill any field in op.

 Copy arch-dep-instance from template. */

 Adjust buffer according to instruction. */

 Should have been filtered by can_optimize(). */

 Create a 'sub sp, sp, #<stack_protect>' */

 Create a 'add r3, sp, #<stack_protect>' */

 Set probe information */

 Set probe function call */

 If possible, copy insn and have it executed during restore */

			/*

			 * Replace original 'ldmia sp, {r0 - r15}' with

			 * 'ldmia {r0 - r14}', restore all registers except pc.

 The original probed instruction */

 Jump back to next instruction */

 Set op->optinsn.insn means prepared. */

		/*

		 * Backup instructions which will be replaced

		 * by jump address

		/*

		 * Make it a conditional branch if replaced insn

		 * is consitional

		/*

		 * Similar to __arch_disarm_kprobe, operations which

		 * removing breakpoints must be wrapped by stop_machine

		 * to avoid racing.

/*

 * Recover original instructions and breakpoints from relative jumps.

 * Caller must call with locking kprobe_mutex.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/probes/kprobes/actions-arm.c

 *

 * Copyright (C) 2006, 2007 Motorola Inc.

/*

 * We do not have hardware single-stepping on ARM, This

 * effort is further complicated by the ARM not having a

 * "next PC" register.  Instructions that change the PC

 * can't be safely single-stepped in a MP environment, so

 * we have a lot of work to do:

 *

 * In the prepare phase:

 *   *) If it is an instruction that does anything

 *      with the CPU mode, we reject it for a kprobe.

 *      (This is out of laziness rather than need.  The

 *      instructions could be simulated.)

 *

 *   *) Otherwise, decode the instruction rewriting its

 *      registers to take fixed, ordered registers and

 *      setting a handler for it to run the instruction.

 *

 * In the execution phase by an instruction's handler:

 *

 *   *) If the PC is written to by the instruction, the

 *      instruction must be fully simulated in software.

 *

 *   *) Otherwise, a modified form of the instruction is

 *      directly executed.  Its handler calls the

 *      instruction in insn[0].  In insn[1] is a

 *      "mov pc, lr" to return.

 *

 *      Before calling, load up the reordered registers

 *      from the original instruction's registers.  If one

 *      of the original input registers is the PC, compute

 *      and adjust the appropriate input register.

 *

 *	After call completes, copy the output registers to

 *      the original instruction's original registers.

 *

 * We don't use a real breakpoint instruction since that

 * would have us in the kernel go from SVC mode to SVC

 * mode losing the link register.  Instead we use an

 * undefined instruction.  To simplify processing, the

 * undefined instruction used for kprobes must be reserved

 * exclusively for kprobes use.

 *

 * TODO: ifdef out some instruction decoding based on architecture.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/probes/kprobes/actions-common.c

 *

 * Copyright (C) 2011 Jon Medhurst <tixy@yxit.co.uk>.

 *

 * Some contents moved here from arch/arm/include/asm/kprobes-arm.c which is

 * Copyright (C) 2006, 2007 Motorola Inc.

 lr = regs */

 Instruction only uses registers in the range R0..R12 */

 Instruction only uses registers in the range R2..R14 */

 Instruction only uses registers in the range R3..R15 */

 We can emulate the instruction in (possibly) modified form */

 Fallback to slower simulation... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/kernel/kprobes-test-arm.c

 *

 * Copyright (C) 2011 Jon Medhurst <tixy@yxit.co.uk>.

 This has special case emulation code */

 Data-processing with PC and a shift count in a register */

 Data-processing with PC as a target and status registers updated */

 Data-processing with SP as target */

 Data-processing with PC as target */

 UNPREDICTABLE before and after ARMv6 */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 __LINUX_ARM_ARCH__ >= 7 */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 __LINUX_ARM_ARCH__ >= 6 */

 __LINUX_ARM_ARCH__ >= 6 */

 Permanently UNDEFINED */

 Permanently UNDEFINED */

 __LINUX_ARM_ARCH__ >= 6 */

	/*

	 * We can't really test these by executing them, so all

	 * we can do is check that probes are, or are not allowed.

	 * At the moment none are allowed...

 __LINUX_ARM_ARCH__ >= 6 */

 __LINUX_ARM_ARCH__ >= 6 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/kernel/kprobes.c

 *

 * Kprobes on ARM

 *

 * Abhishek Sagar <sagar.abhishek@gmail.com>

 * Copyright (C) 2006, 2007 Motorola Inc.

 *

 * Nicolas Pitre <nico@marvell.com>

 * Copyright (C) 2007 Marvell Ltd.

 Bit 0 would normally be set to indicate Thumb code */

 !CONFIG_THUMB2_KERNEL */

 not supported */

 instruction uses slot */

 instruction doesn't need insn slot */

	/*

	 * Never instrument insn like 'str r0, [sp, +/-r1]'. Also, insn likes

	 * 'str r0, [sp, #-68]' should also be prohibited.

	 * See __und_svc.

 Remove any Thumb flag */

 Unconditional instruction */

 Copy condition from insn */

/*

 * The actual disarming is done here on each CPU and synchronized using

 * stop_machine. This synchronization is necessary on SMP to avoid removing

 * a probe between the moment the 'Undefined Instruction' exception is raised

 * and the moment the exception handler reads the faulting instruction from

 * memory. It is also needed to atomically set the two half-words of a 32-bit

 * Thumb breakpoint.

/*

 * Called with IRQs disabled. IRQs must remain disabled from that point

 * all the way until processing this kprobe is complete.  The current

 * kprobes implementation cannot process more than one nested level of

 * kprobe, and that level is reserved for user kprobe handlers, so we can't

 * risk encountering a new kprobe in an interrupt handler.

	/*

	 * First look for a probe which was registered using an address with

	 * bit 0 set, this is the usual situation for pointers to Thumb code.

	 * If not found, fallback to looking for one with bit 0 clear.

 ! CONFIG_THUMB2_KERNEL */

			/*

			 * Probe hit but conditional execution check failed,

			 * so just skip the instruction and continue as if

			 * nothing had happened.

			 * In this case, we can skip recursing check too.

 Kprobe is pending, so we're recursing. */

 A pre- or post-handler probe got us here. */

 A nested probe was hit in FIQ, it is a BUG */

 impossible cases */

 Probe hit and conditional execution check ok. */

			/*

			 * If we have no pre-handler or it returned 0, we

			 * continue with normal processing. If we have a

			 * pre-handler and it returned non-zero, it will

			 * modify the execution path and no need to single

			 * stepping. Let's just reset current kprobe and exit.

		/*

		 * The probe was removed and a race is in progress.

		 * There is nothing we can do about it.  Let's restart

		 * the instruction.  By the time we can restart, the

		 * real instruction will be there.

		/*

		 * We are here because the instruction being single

		 * stepped caused a page fault. We reset the current

		 * kprobe and the PC to point back to the probe address

		 * and allow the page fault handler to continue as a

		 * normal page fault.

	/*

	 * notify_die() is currently never called on ARM,

	 * so this callback is currently empty.

/*

 * When a retprobed function returns, trampoline_handler() is called,

 * calling the kretprobe's handler. We construct a struct pt_regs to

 * give a view of registers r0-r11, sp, lr, and pc to the user

 * return-handler. This is not a complete pt_regs structure, but that

 * should be enough for stacktrace from the return handler with or

 * without pt_regs.

 __kretprobe_trampoline makes a framepointer on pt_regs. */

 In clang case, pt_regs->ip = lr. */

 fp points regs->r11 (fp) */

 !CONFIG_CC_IS_CLANG */

 In gcc case, pt_regs->ip = fp. */

 fp points regs->r15 (pc) */

 CONFIG_CC_IS_CLANG */

 !CONFIG_FRAME_POINTER */

 CONFIG_FRAME_POINTER */

 Called from __kretprobe_trampoline */

 Replace the return addr with trampoline addr. */

 !CONFIG_THUMB2_KERNEL */

 !CONFIG_THUMB2_KERNEL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/probes/kprobes/test-thumb.c

 *

 * Copyright (C) 2011 Jon Medhurst <tixy@yxit.co.uk>.

 To align 1f */	\

 To align the bx pc*/

 Assumes TEST_MEMORY_SIZE < 0x400 */

 Unassigned hints */

 Unassigned hints */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 Unallocated space */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/probes/kprobes/checkers-arm.c

 *

 * Copyright (C) 2014 Huawei Inc.

	/*

	 * PROBES_LDRSTRD, PROBES_LDMSTM, PROBES_STORE,

	 * PROBES_STORE_EXTRA may get here. Simply mark all normal

	 * insns as STACK_USE_NONE.

		/*

		 * 'STR{,D,B,H}, Rt, [Rn, Rm]' should be marked as UNKNOWN

		 * if Rn or Rm is SP.

		 *                                 x

		 * STR (register)	cccc 011x x0x0 xxxx xxxx xxxx xxxx xxxx

		 * STRB (register)	cccc 011x x1x0 xxxx xxxx xxxx xxxx xxxx

		/*

		 *                                                     x

		 * STRD (register)	cccc 000x x0x0 xxxx xxxx xxxx 1111 xxxx

		 * STRH (register)	cccc 000x x0x0 xxxx xxxx xxxx 1011 xxxx

		/*

		 * For PROBES_LDMSTM, only stmdx sp, [...] need to examine

		 *

		 * Bit B/A (bit 24) encodes arithmetic operation order. 1 means

		 * before, 0 means after.

		 * Bit I/D (bit 23) encodes arithmetic operation. 1 means

		 * increment, 0 means decrement.

		 *

		 * So:

		 *                              B I

		 *                              / /

		 *                              A D   | Rn |

		 * STMDX SP, [...]	cccc 100x 00x0 xxxx xxxx xxxx xxxx xxxx

                              P U W | Rn | Rt |     imm12    |*/

 STR (immediate)	cccc 010x x0x0 1101 xxxx xxxx xxxx xxxx */

 STRB (immediate)	cccc 010x x1x0 1101 xxxx xxxx xxxx xxxx */

                              P U W | Rn | Rt |imm4|    |imm4|*/

 STRD (immediate)	cccc 000x x1x0 1101 xxxx xxxx 1111 xxxx */

 STRH (immediate)	cccc 000x x1x0 1101 xxxx xxxx 1011 xxxx */

		/*

		 * index = (P == '1'); add = (U == '1').

		 * Above insns with:

		 *    index == 0 (str{,d,h} rx, [sp], #+/-imm) or

		 *    add == 1 (str{,d,h} rx, [sp, #+<imm>])

		 * should be STACK_USE_NONE.

		 * Only str{,b,d,h} rx,[sp,#-n] (P == 1 and U == 0) are

		 * required to be examined.

 STR{,B} Rt,[SP,#-n]	cccc 0101 0xx0 1101 xxxx xxxx xxxx xxxx */

 STR{D,H} Rt,[SP,#-n]	cccc 0001 01x0 1101 xxxx xxxx 1x11 xxxx */

 fall through */

 Instruction is 'mov ip, sp' i.e. 'mov r12, r13' */

/*

 *                                    | Rn |Rt/d|         | Rm |

 * LDRD (register)      cccc 000x x0x0 xxxx xxxx xxxx 1101 xxxx

 * STRD (register)      cccc 000x x0x0 xxxx xxxx xxxx 1111 xxxx

 *                                    | Rn |Rt/d|         |imm4L|

 * LDRD (immediate)     cccc 000x x1x0 xxxx xxxx xxxx 1101 xxxx

 * STRD (immediate)     cccc 000x x1x0 xxxx xxxx xxxx 1111 xxxx

 *

 * Such instructions access Rt/d and its next register, so different

 * from others, a specific checker is required to handle this extra

 * implicit register usage.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CPU complex suspend & resume functions for Tegra SoCs

 *

 * Copyright (c) 2009-2012, NVIDIA Corporation. All rights reserved.

/*

 * restore_cpu_complex

 *

 * restores cpu clock setting, clears flow controller

 *

 * Always called on CPU 0.

 Restore the CPU clock settings */

/*

 * suspend_cpu_complex

 *

 * saves pll state for use by restart_plls, prepares flow controller for

 * transition to suspend state

 *

 * Must always be called on cpu 0.

 Save the CPU clock settings */

	/*

	 * L2 cache disabling using kernel API only allowed when all

	 * secondary CPU's are offline. Cache have to be disabled with

	 * MMU-on if cache maintenance is done via Trusted Foundations

	 * firmware. Note that CPUIDLE won't ever enter powergate on Tegra30

	 * if any of secondary CPU's is online and this is the LP2-idle

	 * code-path only for Tegra20/30.

	/*

	 * Note that besides of setting up CPU reset vector this firmware

	 * call may also do the following, depending on the FW version:

	 *  1) Disable L2. But this doesn't matter since we already

	 *     disabled the L2.

	 *  2) Disable D-cache. This need to be taken into account in

	 *     particular by the tegra_disable_clean_inv_dcache() which

	 *     shall avoid the re-disable.

 should never here */

 Turn off CRAIL */

	/*

	 * Resume L2 cache if it wasn't re-enabled early during resume,

	 * which is the case for Tegra30 that has to re-enable the cache

	 * via firmware call. In other cases cache is already enabled and

	 * hence re-enabling is a no-op. This is always a no-op on Tegra114+.

	/*

	 * The Tegra devices support suspending to LP1 or lower currently.

	/*

	 * Cache have to be disabled with MMU-on if cache maintenance is done

	 * via Trusted Foundations firmware. This is a no-op on Tegra114+.

 should never here */

/*

 * tegra_lp1_iram_hook

 *

 * Hooking the address of LP1 reset vector and SDRAM self-refresh code in

 * SDRAM. These codes not be copied to IRAM in this fuction. We need to

 * copy these code to IRAM before LP0/LP1 suspend and restore the content

 * of IRAM after resume.

 copy the reset vector & SDRAM shutdown code into IRAM */

 restore IRAM */

	/*

	 * Resume L2 cache if it wasn't re-enabled early during resume,

	 * which is the case for Tegra30 that has to re-enable the cache

	 * via firmware call. In other cases cache is already enabled and

	 * hence re-enabling is a no-op.

 set up sleep function for cpu_suspend */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-tegra/io.c

 *

 * Copyright (C) 2010 Google, Inc.

 *

 * Author:

 *	Colin Cross <ccross@google.com>

 *	Erik Gilling <konkers@google.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-tegra/platsmp.c

 *

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

 *

 *  Copyright (C) 2009 Palm

 *  All Rights Reserved

	/*

	 * Force the CPU into reset. The CPU must remain in reset when

	 * the flow controller state is cleared (which will cause the

	 * flow controller to stop driving reset if the CPU has been

	 * power-gated via the flow controller). This will have no

	 * effect on first boot of the CPU since it should already be

	 * in reset.

	/*

	 * Unhalt the CPU. If the flow controller was used to

	 * power-gate the CPU this will cause the flow controller to

	 * stop driving reset. The CPU will remain in reset because the

	 * clock and reset block is now driving reset.

 Clear flow controller CSR. */

	/*

	 * The power up sequence of cold boot CPU and warm boot CPU

	 * was different.

	 *

	 * For warm boot CPU that was resumed from CPU hotplug, the

	 * power will be resumed automatically after un-halting the

	 * flow controller of the warm boot CPU. We need to wait for

	 * the confirmaiton that the CPU is powered then removing

	 * the IO clamps.

	 * For cold boot CPU, do not wait. After the cold boot CPU be

	 * booted, it will run to tegra_secondary_init() and set

	 * tegra_cpu_init_mask which influences what tegra30_boot_secondary()

	 * next time around.

	/*

	 * The power status of the cold boot CPU is power gated as

	 * default. To power up the cold boot CPU, the power should

	 * be un-gated by un-toggling the power gate register

	 * manually.

 CPU partition is powered. Enable the CPU clock. */

 Remove I/O clamps. */

 Clear flow controller CSR. */

		/*

		 * Warm boot flow

		 * The flow controller in charge of the power state and

		 * control for each CPU.

 set SCLK as event trigger for flow controller */

		/*

		 * Cold boot flow

		 * The CPU is powered up by toggling PMC directly. It will

		 * also initial power state in flow controller. After that,

		 * the CPU's power state is maintained by flow controller.

 Always mark the boot CPU (CPU0) as initialized. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * NVIDIA Tegra SoC device tree board support

 *

 * Copyright (C) 2011, 2013, NVIDIA Corporation

 * Copyright (C) 2010 Secret Lab Technologies, Ltd.

 * Copyright (C) 2010 Google, Inc.

/*

 * Storage for debug-macro.S's state.

 *

 * This must be in .data not .bss so that it gets initialized each time the

 * kernel is loaded. The data is declared here rather than debug-macro.S so

 * that multiple inclusions of debug-macro.S point at the same data.

 Debug UART initialization required */

 Debug UART physical address */

 Debug UART virtual address */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

 *  Copyright (c) 2010, 2012-2013, NVIDIA Corporation. All rights reserved.

 Clock gate the CPU */

/*

 * platform-specific code to shutdown a CPU

 *

 * Called with IRQs disabled

 Clean L1 data cache */

 Shut down the current CPU. */

 Should never return here. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013, NVIDIA Corporation. All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013, NVIDIA Corporation. All rights reserved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-tegra/board-paz00.c

 *

 * Copyright (C) 2011 Marc Dietrich <marvin24@gmx.de>

 *

 * Based on board-harmony.c

 * Copyright (C) 2010 Google, Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-tegra/reset.c

 *

 * Copyright (C) 2011,2012 NVIDIA Corporation.

	/*

	 * NOTE: This must be the one and only write to the EVP CPU reset

	 *       vector in the entire system.

	/*

	 * Prevent further modifications to the physical reset vector.

	 *  NOTE: Has no effect on chips prior to Tegra30.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2011 Google, Inc.

 *

 * Author:

 *	Colin Cross <ccross@android.com>

 *

 * Copyright (C) 2010,2013, NVIDIA Corporation

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  arch/arm/mach-sti/platsmp.c

 *

 * Copyright (C) 2013 STMicroelectronics (R&D) Limited.

 *		http://www.st.com

 *

 * Cloned from linux/arch/arm/mach-vexpress/platsmp.c

 *

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

	/*

	 * Secondary CPU is initialised and started by a U-BOOTROM firmware.

	 * Secondary CPU is spinning and waiting for a write at cpu_strt_ptr.

	 * Writing secondary_startup address at cpu_strt_ptr makes it to

	 * jump directly to secondary_startup().

 wmb so that data is actually written before cache flush is done */

		/*

		 * cpu-release-addr is usually configured in SBC DMEM but can

		 * also be in RAM.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 STMicroelectronics (R&D) Limited.

 * Author(s): Srinivas Kandagatla <srinivas.kandagatla@st.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Author: Alexander Shiyan <shc_work@mail.ru>, 2016

/*

 * arch/arm/mach-orion5x/wnr854t-setup.c

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Power LED green (0=on) */

 Reset Button (0=off) */

 Power LED blink (0=off) */

 WAN Status LED amber (0=off) */

 PCI int */

 ??? */

 ??? */

 ??? */

 ??? */

 GE_RXERR */

 ??? */

 ??? */

 GE_TXD[4] */

 GE_TXD[5] */

 GE_TXD[6] */

 GE_TXD[7] */

 GE_RXD[4] */

 GE_RXD[5] */

 GE_RXD[6] */

 GE_RXD[7] */

/*

 * 8M NOR flash Device bus boot chip select

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * Mini-PCI slot.

 Maintainer: Imre Kaloz <kaloz@openwrt.org> */

/*

 * arch/arm/mach-orion5x/ts78xx-setup.c

 *

 * Maintainer: Alexander Clouter <alex@digriz.org.uk>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * TS-78xx Info

/*

 * FPGA - lives where the PCI bus would be at ORION5X_PCI_MEM_PHYS_BASE

	.supports	= ... - populated by ts78xx_fpga_supports() */

/*****************************************************************************

 * I/O Address Mapping

/*****************************************************************************

 * Ethernet

/*****************************************************************************

 * SATA

/*****************************************************************************

 * RTC M48T86 - nicked^Wborrowed from arch/arm/mach-ep93xx/ts72xx.c

/*****************************************************************************

 * NAND Flash

 VIRT */

 PHYS */

/*

 * hardware specific access to control-lines

 *

 * ctrl:

 * NAND_NCE: bit 0 -> bit 2

 * NAND_CLE: bit 1 -> bit 1

 * NAND_ALE: bit 2 -> bit 0

		/*

		 * The HW ECC offloading functions, used to give about a 9%

		 * performance increase for 'dd if=/dev/mtdblockX' and 5% for

		 * nanddump.  This all however was changed by git commit

		 * e6cf5df1838c28bb060ac45b5585e48e71bbc740 so now there is

		 * no performance advantage to be had so we no longer bother

/*****************************************************************************

 * HW RNG

 one second */

/*****************************************************************************

 * FPGA 'hotplug' support code

 TODO: put this 'table' into ts78xx-fpga.h */

 enable devices if magic matches */

	/*

	 * There does not seem to be a feasible way to block access to the GPIO

	 * pins from userspace (/dev/mem).  This if clause should hopefully warn

	 * those foolish enough not to follow 'policy' :)

	 *

	 * UrJTAG SVN since r1381 can be used to reprogram the FPGA

/*****************************************************************************

 * General Setup

 JTAG Clock */

 JTAG Data In */

 Lat ECP2 256 FPGA - PB2B */

 JTAG Data Out */

 JTAG TMS */

 Lat ECP2 256 FPGA - PB31A_CLK4+ */

 Lat ECP2 256 FPGA - PB22B */

	/*

	 * MPP[20] PCI Clock Out 1

	 * MPP[21] PCI Clock Out 0

	 * MPP[22] Unused

	 * MPP[23] Unused

	 * MPP[24] Unused

	 * MPP[25] Unused

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

 FPGA init */

 Maintainer: Alexander Clouter <alex@digriz.org.uk> */

/*

 * arch/arm/mach-orion5x/mpp.c

 *

 * MPP functions for Marvell Orion 5x SoCs

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * arch/arm/mach-orion5x/db88f5281-setup.c

 *

 * Marvell Orion-2 Development Board Setup

 *

 * Maintainer: Tzachi Perelstein <tzachi@marvell.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * DB-88F5281 on board devices

/*

 * 512K NOR flash Device bus boot chip select

/*

 * 7-Segment on Device bus chip select 0

/*

 * 32M NOR flash on Device bus chip select 1

/*

 * 32M NAND flash on Device bus chip select 2

/*

 * PCI

/*****************************************************************************

 * 512M NOR Flash on Device bus Boot CS

 8 bit bus width */

/*****************************************************************************

 * 32M NOR Flash on Device bus CS1

 32 bit bus width */

/*****************************************************************************

 * 32M NAND Flash on Device bus CS2

/*****************************************************************************

 * 7-Segment on Device bus CS0

 * Dummy counter every 2 sec

/*****************************************************************************

 * PCI

	/*

	 * Configure PCI GPIO IRQ pins

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * PCI IRQs are connected via GPIOs.

/*****************************************************************************

 * Ethernet

/*****************************************************************************

 * RTC DS1339 on I2C bus

/*****************************************************************************

 * General Setup

 USB Over Current */

 USB Vbat input */

 PCI_REQn[2] */

 PCI_GNTn[2] */

 PCI_REQn[3] */

 PCI_GNTn[3] */

 JP0, CON17.2 */

 JP1, CON17.1 */

 JP2, CON11.2 */

 JP3, CON11.3 */

 RTC int */

 Baud Rate Generator */

 PCI int 1 */

 PCI int 2 */

 NAND_REn[2] */

 NAND_WEn[2] */

 UART1_RX */

 UART1_TX */

 UART1_CTSn */

 UART1_RTSn */

	/*

	 * Basic Orion setup. Need to be called early.

 DEV_D[31:16] */

	/*

	 * Configure peripherals.

 Maintainer: Tzachi Perelstein <tzachi@marvell.com> */

/*

 * arch/arm/mach-orion5x/rd88f5182-setup.c

 *

 * Marvell Orion-NAS Reference Design Setup

 *

 * Maintainer: Ronen Shitrit <rshitrit@marvell.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * RD-88F5182 Info

/*

 * 512K NOR flash Device bus boot chip select

/*

 * 16M NOR flash on Device bus chip select 1

/*

 * PCI

/*****************************************************************************

 * 16M NOR Flash on Device bus CS1

/*****************************************************************************

 * Use GPIO LED as CPU active indication

/*****************************************************************************

 * PCI

	/*

	 * Configure PCI GPIO IRQ pins

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * PCI IRQs are connected via GPIOs

/*****************************************************************************

 * Ethernet

/*****************************************************************************

 * RTC DS1338 on I2C bus

/*****************************************************************************

 * Sata

/*****************************************************************************

 * General Setup

 Debug Led */

 Reset Switch */

 RTC Int */

 PCI_intA */

 PCI_intB */

 SATA 0 presence */

 SATA 1 presence */

 SATA 0 active */

 SATA 1 active */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * MPP[20] PCI Clock to MV88F5182

	 * MPP[21] PCI Clock to mini PCI CON11

	 * MPP[22] USB 0 over current indication

	 * MPP[23] USB 1 over current indication

	 * MPP[24] USB 1 over current enable

	 * MPP[25] USB 0 over current enable

	/*

	 * Configure peripherals.

 Maintainer: Ronen Shitrit <rshitrit@marvell.com> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * QNAP TS-x09 Boards common functions

 *

 * Maintainers: Lennert Buytenhek <buytenh@marvell.com>

 *		Byron Bradley <byron.bbradley@gmail.com>

/*****************************************************************************

 * QNAP TS-x09 specific power off method via UART1-attached PIC

 19200 baud divisor */

 hijack uart1 and reset into sane state (19200,8n1) */

 send the power-off command 'A' to PIC */

/*****************************************************************************

 * Ethernet

		/*

		 * Enforce "xx:xx:xx:xx:xx:xx\n" format.

/*

 * The 'NAS Config' flash partition has an ext2 filesystem which

 * contains a file that has the ethernet MAC address in plain text

 * (format "xx:xx:xx:xx:xx:xx\n").

/*

 * arch/arm/mach-orion5x/wrt350n-v2-setup.c

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * LEDs attached to GPIO

/*

 * Buttons attached to GPIO

/*

 * General setup

 Power LED green (0=on) */

 Security LED (0=on) */

 Internal Button (0=on) */

 Reset Button (0=on) */

 PCI int */

 Power LED orange (0=on) */

 USB LED (0=on) */

 Wireless LED (0=on) */

 ??? */

 GE_RXERR */

 ??? */

 ??? */

 GE_TXD[4] */

 GE_TXD[5] */

 GE_TXD[6] */

 GE_TXD[7] */

 GE_RXD[4] */

 GE_RXD[5] */

 GE_RXD[6] */

 GE_RXD[7] */

/*

 * 8M NOR flash Device bus boot chip select

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * Mini-PCI slot.

 Maintainer: Lennert Buytenhek <buytenh@marvell.com> */

/*

 * arch/arm/mach-orion5x/pci.c

 *

 * PCI and PCIe functions for Marvell Orion System On Chip

 *

 * Maintainer: Tzachi Perelstein <tzachi@marvell.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * Orion has one PCIe controller and one PCI controller.

 *

 * Note1: The local PCIe bus number is '0'. The local PCI bus number

 * follows the scanned PCIe bridged busses, if any.

 *

 * Note2: It is possible for PCI/PCIe agents to access many subsystem's

 * space, by configuring BARs and Address Decode Windows, e.g. flashes on

 * device bus, Orion registers, etc. However this code only enable the

 * access to DDR banks.

/*****************************************************************************

 * PCIe controller

	/*

	 * Don't go out when trying to access --

	 * 1. nonexisting device on local bus

	 * 2. where there's no device connected (no link)

/*

 * PCIe config cycles are done by programming the PCIE_CONF_ADDR register

 * and then reading the PCIE_CONF_DATA register. Need to make sure these

 * transactions are atomic.

	/*

	 * We only support access to the non-extended configuration

	 * space when using the WA access method (or we would have to

	 * sacrifice 256M of CPU virtual address space.)

	/*

	 * Generic PCIe unit setup.

	/*

	 * Check whether to apply Orion-1/Orion-NAS PCIe config

	 * read transaction workaround.

	/*

	 * Request resources.

	/*

	 * IORESOURCE_MEM

/*****************************************************************************

 * PCI controller

/*

 * PCI_MODE bits

/*

 * PCI_CMD bits

/*

 * PCI_P2P_CONF bits

/*

 * PCI_CONF_ADDR bits

/*

 * Internal configuration space

/*

 * PCI Address Decode Windows registers

/*

 * PCI configuration helpers for BAR settings

/*

 * PCI config cycles are done by programming the PCI_CONF_ADDR register

 * and then reading the PCI_CONF_DATA register. Need to make sure these

 * transactions are atomic.

		/*

		 * Don't go out for local device

		/*

		 * When the PCI signals are directly connected to a

		 * Cardbus slot, ignore all but device IDs 0 and 1.

		/*

		 * PCI-X mode

		/*

		 * PCI Conventional mode

	/*

	 * First, disable windows.

	/*

	 * Setup windows for DDR banks.

		/*

		 * Write DRAM bank base address register.

		/*

		 * Write DRAM bank size register.

		/*

		 * Enable decode window for this chip select.

	/*

	 * Re-enable decode windows.

	/*

	 * Disable automatic update of address remapping when writing to BARs.

	/*

	 * Point PCI unit MBUS decode windows to DRAM space.

	/*

	 * Master + Slave enable

	/*

	 * Force ordering

	/*

	 * Request resources

	/*

	 * IORESOURCE_MEM

/*****************************************************************************

 * General PCIe + PCI

	/*

	 * Prevent enumeration of root complex.

	/*

	 * PCIe endpoint?

/*

 * arch/arm/mach-orion5x/board-d2net.c

 *

 * LaCie d2Network and Big Disk Network NAS setup

 *

 * Copyright (C) 2009 Simon Guinot <sguinot@lacie.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * LaCie d2 Network Info

/*****************************************************************************

 * GPIO LED's

/*

 * The blue front LED is wired to the CPLD and can blink in relation with the

 * SATA activity.

 *

 * The following array detail the different LED registers and the combination

 * of their possible values:

 *

 * led_off   | blink_ctrl | SATA active | LED state

 *           |            |             |

 *    1      |     x      |      x      |  off

 *    0      |     0      |      0      |  off

 *    0      |     1      |      0      |  blink (rate 300ms)

 *    0      |     x      |      1      |  on

 *

 * Notes: The blue and the red front LED's can't be on at the same time.

 *        Red LED have priority.

 Configure register blink_ctrl to allow SATA activity LED blinking. */

/*****************************************************************************

 * General Setup

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Maxtor Shared Storage II Board Setup

 *

 * Maintainer: Sylver Bruneau <sylver.bruneau@googlemail.com>

/*****************************************************************************

 * Maxtor Shared Storage II Info

/****************************************************************************

 * PCI setup

	/*

	 * Check for devices with hard-wired IRQs.

/*****************************************************************************

 * MSS2 power off method

/*

 * On the Maxtor Shared Storage II, the shutdown process is the following :

 * - Userland modifies U-boot env to tell U-boot to go idle at next boot

 * - The board reboots

 * - U-boot starts and go into an idle mode until the user press "power"

	/*

	 * Enable and issue soft reset

 register mss2 specific power-off method */

/*

 * arch/arm/mach-orion5x/rd88f5181l-ge-setup.c

 *

 * Marvell Orion-VoIP GE Reference Design Setup

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * RD-88F5181L GE Info

/*

 * 16M NOR flash Device bus boot chip select

/*****************************************************************************

 * 16M NOR Flash on Device bus Boot chip select

/*****************************************************************************

 * General Setup

 LED1 */

 LED5 */

 LED4 */

 LED3 */

 PCI_intA */

 RTC interrupt */

 CPU PCI refclk */

 PCI/PCIe refclk */

 88e6131 interrupt */

 GE_RXERR */

 PCI_intB */

 LED2 */

 GE_TXD[4] */

 GE_TXD[5] */

 GE_TXD[6] */

 GE_TXD[7] */

 GE_RXD[4] */

 GE_RXD[5] */

 GE_RXD[6] */

 GE_RXD[7] */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * Cardbus slot.

 Maintainer: Lennert Buytenhek <buytenh@marvell.com> */

/*

 * arch/arm/mach-orion5x/dns323-setup.c

 *

 * Copyright (C) 2007 Herbert Valerio Riedel <hvr@gnu.org>

 *

 * Support for HW Rev C1:

 *

 * Copyright (C) 2010 Benjamin Herrenschmidt <benh@kernel.crashing.org>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU Lesser General Public License as

 * published by the Free Software Foundation; either version 2 of the

 * License, or (at your option) any later version.

 *

 Rev A1 and B1 */

 Rev C1 */

 Exposed to userspace, do not change */

 0 */

 1 */

 2 */

/****************************************************************************

 * PCI setup

	/*

	 * Check for devices with hard-wired IRQs.

	/* Rev B1 and C1 doesn't really use its PCI bus, and initialising PCI

	 * gets in the way of initialising the SATA controller.

/****************************************************************************

 * 8MiB NOR flash (Spansion S29GL064M90TFIR4)

 *

 * Layout as used by D-Link:

 *  0x00000000-0x00010000 : "MTD1"

 *  0x00010000-0x00020000 : "MTD2"

 *  0x00020000-0x001a0000 : "Linux Kernel"

 *  0x001a0000-0x007d0000 : "File System"

 *  0x007d0000-0x00800000 : "u-boot"

/****************************************************************************

 * Ethernet

/* dns323_parse_hex_*() taken from tsx09-common.c; should a common copy of these

 * functions be kept somewhere?

	/* MAC address is stored as a regular ol' string in /dev/mtdblock4

	 * (0x007d0000-0x00800000) starting at offset 196480 (0x2ff80).

 Sanity check the string we're looking at */

/****************************************************************************

 * GPIO LEDs (simple - doesn't use hardware blinking support)

/****************************************************************************

 * GPIO Attached Keys

/*****************************************************************************

 * SATA

/****************************************************************************

 * General Setup

 right amber LED (sata ch0) */

 left amber LED (sata ch1) */

 power button LED */

 power button LED */

 GMT G751-2f overtemp */

 M41T80 nIRQ/OUT/SQW */

 triggers power off */

 power button switch */

 reset button switch */

 right amber LED (sata ch0) */

 left amber LED (sata ch1) */

 system up flag */

 power button LED */

 power button LED */

 GMT G751-2f overtemp */

 M41T80 nIRQ/OUT/SQW */

 triggers power off */

 power button switch */

 reset button switch */

 ? input */

 input power switch (0 = pressed) */

 output power off */

 ? output */

 ? output */

 ? output */

 ? output */

 ? output */

 i/o right amber LED */

 i/o left amber LED */

 input */

 power button LED */

 fan speed bit 0 */

 fan speed bit 1 */

/* Rev C1 Fan speed notes:

 *

 * The fan is controlled by 2 GPIOs on this board. The settings

 * of the bits is as follow:

 *

 *  GPIO 18    GPIO 19    Fan

 *

 *    0          0        stopped

 *    0          1        low speed

 *    1          0        high speed

 *    1          1        don't do that (*)

 *

 * (*) I think the two bits control two feed-in resistors into a fixed

 *     PWN circuit, setting both bits will basically go a 'bit' faster

 *     than high speed, but d-link doesn't do it and you may get out of

 *     HW spec so don't do it.

/*

 * On the DNS-323 A1 and B1 the following devices are attached via I2C:

 *

 *  i2c addr | chip        | description

 *  0x3e     | GMT G760Af  | fan speed PWM controller

 *  0x48     | GMT G751-2f | temp. sensor and therm. watchdog (LM75 compatible)

 *  0x68     | ST M41T80   | RTC w/ alarm

/*

 * On the DNS-323 C1 the following devices are attached via I2C:

 *

 *  i2c addr | chip        | description

 *  0x48     | GMT G751-2f | temp. sensor and therm. watchdog (LM75 compatible)

 *  0x68     | ST M41T80   | RTC w/ alarm

 DNS-323 rev. A specific power off method */

 DNS-323 rev B specific power off method */

 Pin has to be changed to 1 and back to 0 to do actual power off. */

 DNS-323 rev. C specific power off method */

 Rev A1 has a 5181 */

	/* Rev B1 and C1 both have 5182, let's poke at the eth PHY. This is

	 * a bit gross but we want to do that without links into the eth

	 * driver so let's poke at it directly. We default to rev B1 in

	 * case the accesses fail

 phy ID reg */ |

 phy addr */ |

	/* Note: the Marvell tools mask the ID with 0x3f0 before comparison

	 * but I don't see that making a difference here, at least with

	 * any known Marvell PHY ID

 MV88E1111 */

 MV88E1118 */

 Setup basic Orion functions. Need to be called early. */

 Identify revision */

	/* Just to be tricky, the 5182 has a completely different

	 * set of MPP modes to the 5181.

 DEV_D[31:16] */

	/* setup flash mapping

	 * CS3 holds a 8 MB Spansion S29GL064M90TFIR4

 Sort out LEDs, Buttons and i2c devices */

		/* The 5181 power LED is active low and requires

		 * DNS323_GPIO_LED_POWER1 to also be low.

 Hookup LEDs & Buttons */

 Hookup i2c devices and fan driver */

 Register fixup for the PHY LEDs */

	/*

	 * Configure peripherals.

 Remaining GPIOs */

 Poweroff GPIO */

 5182 built-in SATA init */

		/* The DNS323 rev B1 has flag to indicate the system is up.

		 * Without this flag set, power LED will flash and cannot be

		 * controlled via leds-gpio.

 Poweroff GPIO */

 5182 built-in SATA init */

 Poweroff GPIO */

		/* Now, -this- should theorically be done by the sata_mv driver

		 * once I figure out what's going on there. Maybe the behaviour

		 * of the LEDs should be somewhat passed via the platform_data.

		 * for now, just whack the register and make the LEDs happy

		 *

		 * Note: AFAIK, rev B1 needs the same treatement but I'll let

		 * somebody else test it.

 Warning: D-Link uses a wrong mach-type (=526) in their bootloader */

 Maintainer: Herbert Valerio Riedel <hvr@gnu.org> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * QNAP TS-409 Board Setup

 *

 * Maintainer: Sylver Bruneau <sylver.bruneau@gmail.com>

 *

 * Copyright (C) 2008  Sylver Bruneau <sylver.bruneau@gmail.com>

 * Copyright (C) 2008  Martin Michlmayr <tbm@cyrius.com>

/*****************************************************************************

 * QNAP TS-409 Info

/*

 * QNAP TS-409 hardware :

 * - Marvell 88F5281-D0

 * - Marvell 88SX7042 SATA controller (PCIe)

 * - Marvell 88E1118 Gigabit Ethernet PHY

 * - RTC S35390A (@0x30) on I2C bus

 * - 8MB NOR flash

 * - 256MB of DDR-2 RAM

/*

 * 8MB NOR flash Device bus boot chip select

/****************************************************************************

 * 8MiB NOR flash. The struct mtd_partition is not in the same order as the

 *     partitions on the device because we want to keep compatibility with

 *     existing QNAP firmware.

 *

 * Layout as used by QNAP:

 *  [2] 0x00000000-0x00200000 : "Kernel"

 *  [3] 0x00200000-0x00600000 : "RootFS1"

 *  [4] 0x00600000-0x00700000 : "RootFS2"

 *  [6] 0x00700000-0x00760000 : "NAS Config" (read-only)

 *  [5] 0x00760000-0x00780000 : "U-Boot Config"

 *  [1] 0x00780000-0x00800000 : "U-Boot" (read-only)

/*****************************************************************************

 * PCI

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * PCI isn't used on the TS-409

/*****************************************************************************

 * RTC S35390A on I2C bus

/*****************************************************************************

 * LEDs attached to GPIO

/****************************************************************************

 * GPIO Attached Keys

 *     Power button is attached to the PIC microcontroller

/*****************************************************************************

 * General Setup

 HDD 1 status */

 HDD 2 status */

 HDD 3 status */

 HDD 4 status */

 RTC int */

 SW_RST */

 USB copy button */

 UART1 RXD */

 UART1 TXD */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

 Get RTC IRQ and register the chip */

 register tsx09 specific power-off method */

 Maintainer:  Sylver Bruneau <sylver.bruneau@gmail.com> */

/*

 * arch/arm/mach-orion5x/rd88f5181l-fxo-setup.c

 *

 * Marvell Orion-VoIP FXO Reference Design Setup

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * RD-88F5181L FXO Info

/*

 * 8M NOR flash Device bus boot chip select

/*****************************************************************************

 * 8M NOR Flash on Device bus Boot chip select

/*****************************************************************************

 * General Setup

 LED1 CardBus LED (front panel) */

 PCI_intA */

 Hard Reset / Factory Init*/

 FXS or DAA select */

 LED6 - phone LED (front panel) */

 LED5 - phone LED (front panel) */

 CPU PCI refclk */

 PCI/PCIe refclk */

 CardBus reset */

 GE_RXERR */

 LED2 MiniPCI LED (front panel) */

 Lifeline control */

 GE_TXD[4] */

 GE_TXD[5] */

 GE_TXD[6] */

 GE_TXD[7] */

 GE_RXD[4] */

 GE_RXD[5] */

 GE_RXD[6] */

 GE_RXD[7] */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * Mini-PCI / Cardbus slot.

 Maintainer: Nicolas Pitre <nico@marvell.com> */

/*

 * Copyright 2012 (C), Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * arch/arm/mach-orion5x/board-dt.c

 *

 * Flattened Device Tree board initialization

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Setup Orion address map

	/*

	 * Don't issue "Wait for Interrupt" instruction if we are

	 * running on D0 5281 silicon.

 Maintainer: Thomas Petazzoni <thomas.petazzoni@free-electrons.com> */

/*

 * arch/arm/mach-orion5x/net2big-setup.c

 *

 * LaCie 2Big Network NAS setup

 *

 * Copyright (C) 2009 Simon Guinot <sguinot@lacie.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * LaCie 2Big Network Info

/*

 * 512KB NOR flash Device bus boot chip select

/*****************************************************************************

 * 512KB NOR Flash on Boot Device

/*

 * TODO: Check write support on flash MX29LV400CBTC-70G

/*****************************************************************************

 * Ethernet

/*****************************************************************************

 * I2C devices

/*

 * i2c addr | chip         | description

 * 0x32     | Ricoh 5C372b | RTC

 * 0x50     | HT24LC08     | eeprom (1kB)

/*****************************************************************************

 * SATA

 Configure GPIOs over MPP max number. */

	/*

	 * SATA power up on both disk is done by pulling high the CPLD power

	 * request line. The 300ms delay is related to the CPLD clock and is

	 * needed to be sure that the CPLD has take into account the low line

	 * status.

/*****************************************************************************

 * GPIO LEDs

/*

 * The power front LEDs (blue and red) and SATA red LEDs are controlled via a

 * single GPIO line and are compatible with the leds-gpio driver.

 *

 * The SATA blue LEDs have some hardware blink capabilities which are detailed

 * in the following array:

 *

 * SATAx blue LED | SATAx activity | LED state

 *                |                |

 *       0        |       0        |  blink (rate 300ms)

 *       1        |       0        |  off

 *       ?        |       1        |  on

 *

 * Notes: The blue and the red front LED's can't be on at the same time.

 *        Blue LED have priority.

 Stop initial CPLD slow red/blue blinking on power LED. */

	/*

	 * Configure SATA0 and SATA1 blue LEDs to blink in relation with the

	 * hard disk activity.

/****************************************************************************

 * GPIO keys

/*****************************************************************************

 * General Setup

 Raid mode (bit 0) */

 USB port 2 fuse (0 = Fail, 1 = Ok) */

 Raid mode (bit 1) */

 Board ID (bit 0) */

 Fan activity (0 = Off, 1 = On) */

 Fan fail detection */

 Red front LED (0 = Off, 1 = On) */

 Disable initial blinking on front LED */

 Rear power switch (on|auto) */

 Rear power switch (auto|off) */

 SATA 1 red LED (0 = Off, 1 = On) */

 SATA 0 red LED (0 = Off, 1 = On) */

 Board ID (bit 1) */

 SATA 1 blue LED blink control */

 Blue front LED control */

 SATA 0 blue LED blink control */

 Front button (0 = Released, 1 = Pushed ) */

 SATA{0,1} power On/Off request */

 22: USB port 1 fuse (0 = Fail, 1 = Ok) */

 23: SATA 0 power status */

 24: Board power off */

 25: SATA 1 power status */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

 Warning: LaCie use a wrong mach-type (0x20e=526) in their bootloader. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Buffalo Terastation Pro II/Live Board Setup

 *

 * Maintainer: Sylver Bruneau <sylver.bruneau@googlemail.com>

/*****************************************************************************

 * Terastation Pro 2/Live Info

/*

 * Terastation Pro 2 hardware :

 * - Marvell 88F5281-D0

 * - Marvell 88SX6042 SATA controller (PCI)

 * - Marvell 88E1118 Gigabit Ethernet PHY

 * - 256KB NOR flash

 * - 128MB of DDR RAM

 * - PCIe port (not equipped)

/*

 * 256K NOR flash Device bus boot chip select

/*****************************************************************************

 * 256KB NOR Flash on BOOT Device

/*****************************************************************************

 * PCI

	/*

	 * Configure PCI GPIO IRQ pins

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * PCI IRQs are connected via GPIOs.

/*****************************************************************************

 * Ethernet

/*****************************************************************************

 * RTC 5C372a on I2C bus

/*****************************************************************************

 * Terastation Pro II specific power off method via UART1-attached

 * microcontroller

 return read bytes */

 Generate checksum */

 Send data */

 send checksum */

 send preamble to clear the receive buffer */

 make dummy reads */

 Generate expected ack */

 checksum Check */

 Check Received Data */

 Interval for next command */

 Receive ACK */

 Received NAK or illegal Data */

 Interval for next command */

 38400 baud divisor */

 hijack uart1 and reset into sane state (38400,8n1,even parity) */

 Send the commands to shutdown the Terastation Pro II */

/*****************************************************************************

 * General Setup

 BOOT NAND Flash REn */

 BOOT NAND Flash WEn */

 BOOT NAND Flash HREn[0] */

 BOOT NAND Flash WEn[0] */

 MICON int */

 RTC int */

 PCI Int A */

 UPS on UART0 enable */

 UPS low battery detection */

 UART1 RXD */

 UART1 TXD */

 UART1 CTSn */

 UART1 RTSn */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

 Get RTC IRQ and register the chip */

 register Terastation Pro II specific power-off method */

 Maintainer:  Sylver Bruneau <sylver.bruneau@googlemail.com> */

/*

 * Copyright (C) 2007 Herbert Valerio Riedel <hvr@gnu.org>

 * Copyright (C) 2008 Martin Michlmayr <tbm@cyrius.com>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU Lesser General Public License as

 * published by the Free Software Foundation; either version 2 of the

 * License, or (at your option) any later version.

/*****************************************************************************

 * Ethernet

/****************************************************************************

 * General Setup

 Sys status LED */

 Sys error LED */

 OverTemp interrupt */

 RTC interrupt */

 V_LED 5V */

 V_LED 3.3V */

 SATA 0 fail LED */

 SATA 1 fail LED */

 SATA 0 presence */

 SATA 1 presence */

 SATA 0 active */

 SATA 1 active */

 Reset button */

 Power button */

 Power off */

 Setup basic Orion functions. Need to be called early. */

	/*

	 * Configure peripherals.

 register mv2120 specific power-off method */

 Warning: HP uses a wrong mach-type (=526) in their bootloader */

 Maintainer: Martin Michlmayr <tbm@cyrius.com> */

/*

 * arch/arm/mach-orion5x/rd88f5182-setup.c

 *

 * Marvell Orion-NAS Reference Design Setup

 *

 * Maintainer: Ronen Shitrit <rshitrit@marvell.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * RD-88F5182 Info

/*

 * PCI

/*****************************************************************************

 * PCI

	/*

	 * Configure PCI GPIO IRQ pins

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * PCI IRQs are connected via GPIOs

/*

 * arch/arm/mach-orion5x/common.c

 *

 * Core functions for Marvell Orion 5x SoCs

 *

 * Maintainer: Tzachi Perelstein <tzachi@marvell.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * I/O Address Mapping

/*****************************************************************************

 * CLK tree

/*****************************************************************************

 * EHCI0

/*****************************************************************************

 * EHCI1

/*****************************************************************************

 * GE00

/*****************************************************************************

 * Ethernet switch

/*****************************************************************************

 * I2C

/*****************************************************************************

 * SATA

/*****************************************************************************

 * SPI

/*****************************************************************************

 * UART0

/*****************************************************************************

 * UART1

/*****************************************************************************

 * XOR engine

/*****************************************************************************

 * Cryptographic Engines and Security Accelerator (CESA)

/*****************************************************************************

 * Watchdog

/*****************************************************************************

 * Time handling

 Initialize the MBUS driver */

	/*

	 * The PCIe windows will no longer be statically allocated

	 * here once Orion5x is migrated to the pci-mvebu driver.

/*****************************************************************************

 * General

/*

 * Identify device ID and rev from PCIe configuration header space '0'.

	/*

	 * Setup Orion address map

 Setup root of clk tree */

	/*

	 * Don't issue "Wait for Interrupt" instruction if we are

	 * running on D0 5281 silicon.

	/*

	 * The 5082/5181l/5182/6082/6082l/6183 have crypto

	 * while 5180n/5181/5281 don't have crypto.

	/*

	 * Register watchdog driver

	/*

	 * Enable and issue soft reset

/*

 * Many orion-based systems have buggy bootloader implementations.

 * This is a common fixup for bogus memory tags.

/*

 * arch/arm/mach-orion5x/ls_hgl-setup.c

 *

 * Maintainer: Zhu Qingsen <zhuqs@cn.fujitsu.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * Linkstation LS-HGL Info

/*

 * 256K NOR flash Device bus boot chip select

/*****************************************************************************

 * 256KB NOR Flash on BOOT Device

/*****************************************************************************

 * Ethernet

/*****************************************************************************

 * RTC 5C372a on I2C bus

/*****************************************************************************

 * LEDs attached to GPIO

/****************************************************************************

 * GPIO Attached Keys

/*****************************************************************************

 * SATA

/*****************************************************************************

 * Linkstation LS-HGL specific power off method: reboot

/*

 * On the Linkstation LS-HGL, the shutdown process is following:

 * - Userland monitors key events until the power switch goes to off position

 * - The board reboots

 * - U-boot starts and goes into an idle mode waiting for the user

 *   to move the switch to ON position

/*****************************************************************************

 * General Setup

 LED_PWR */

 HDD_PWR */

 LED_ALARM */

 LED_INFO */

 FAN_LCK */

 INIT */

 POWER */

 USB_PWR */

 AUTO_POWER */

 LED_ETH (dummy) */

 FUNC */

 LED_FUNC */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

 enable USB power */

 register power-off method */

 Maintainer: Zhu Qingsen <zhuqs@cn.fujistu.com> */

/*

 * arch/arm/mach-orion5x/kurobox_pro-setup.c

 *

 * Maintainer: Ronen Shitrit <rshitrit@marvell.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * KUROBOX-PRO Info

/*

 * 256K NOR flash Device bus boot chip select

/*

 * 256M NAND flash on Device bus chip select 1

/*****************************************************************************

 * 256MB NAND Flash on Device bus CS0

/*****************************************************************************

 * 256KB NOR Flash on BOOT Device

/*****************************************************************************

 * PCI

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * PCI isn't used on the Kuro

/*****************************************************************************

 * Ethernet

/*****************************************************************************

 * RTC 5C372a on I2C bus

/*****************************************************************************

 * SATA

/*****************************************************************************

 * Kurobox Pro specific power off method via UART1-attached microcontroller

 return read bytes */

 Generate checksum */

 Send data */

 send checksum */

 send preamble to clear the receive buffer */

 make dummy reads */

 Generate expected ack */

 checksum Check */

 Check Received Data */

 Interval for next command */

 Receive ACK */

 Received NAK or illegal Data */

 Interval for next command */

 38400 baud divisor */

 hijack uart1 and reset into sane state (38400,8n1,even parity) */

 Send the commands to shutdown the Kurobox Pro */

/*****************************************************************************

 * General Setup

 GPIO Micon */

 GPIO Rtc */

 NAND Flash REn */

 NAND Flash WEn */

 SATA 0 presence */

 SATA 1 presence */

 SATA 0 active */

 SATA 1 active */

 UART1 RXD */

 UART1 TXD */

 UART1 CTSn */

 UART1 RTSn */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

 register Kurobox Pro specific power-off method */

 Maintainer: Ronen Shitrit <rshitrit@marvell.com> */

 Maintainer: Byron Bradley <byron.bbradley@gmail.com> */

/*

 * arch/arm/mach-orion5x/irq.c

 *

 * Core IRQ functions for Marvell Orion System On Chip

 *

 * Maintainer: Tzachi Perelstein <tzachi@marvell.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Initialize gpiolib for GPIOs 0-31.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * QNAP TS-109/TS-209 Board Setup

 *

 * Maintainer: Byron Bradley <byron.bbradley@gmail.com>

/****************************************************************************

 * 8MiB NOR flash. The struct mtd_partition is not in the same order as the

 *     partitions on the device because we want to keep compatibility with

 *     existing QNAP firmware.

 *

 * Layout as used by QNAP:

 *  [2] 0x00000000-0x00200000 : "Kernel"

 *  [3] 0x00200000-0x00600000 : "RootFS1"

 *  [4] 0x00600000-0x00700000 : "RootFS2"

 *  [6] 0x00700000-0x00760000 : "NAS Config" (read-only)

 *  [5] 0x00760000-0x00780000 : "U-Boot Config"

 *  [1] 0x00780000-0x00800000 : "U-Boot" (read-only)

/*****************************************************************************

 * PCI

	/*

	 * Configure PCI GPIO IRQ pins

	/*

	 * Check for devices with hard-wired IRQs.

	/*

	 * PCI IRQs are connected via GPIOs.

/*****************************************************************************

 * RTC S35390A on I2C bus

/****************************************************************************

 * GPIO Attached Keys

 *     Power button is attached to the PIC microcontroller

/*****************************************************************************

 * SATA

/*****************************************************************************



 * General Setup

 USB copy button */

 Load defaults button */

 GPIO RTC */

 PCI Int A */

 PCI Int B */

 SATA 0 presence */

 SATA 1 presence */

 SATA 0 active */

 SATA 1 active */

 UART1 RXD */

 UART1 TXD */

 SW_RST */

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * MPP[20] PCI clock 0

	 * MPP[21] PCI clock 1

	 * MPP[22] USB 0 over current

	 * MPP[23-25] Reserved

	/*

	 * Configure peripherals.

 Get RTC IRQ and register the chip */

 register tsx09 specific power-off method */

 Maintainer: Byron Bradley <byron.bbradley@gmail.com> */

/*

 * arch/arm/mach-orion5x/rd88f6183-ap-ge-setup.c

 *

 * Marvell Orion-1-90 AP GE Reference Design Setup

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Setup basic Orion functions. Need to be called early.

	/*

	 * Configure peripherals.

 Maintainer: Lennert Buytenhek <buytenh@marvell.com> */

/*

 *  linux/arch/arm/vfp/vfpsingle.c

 *

 * This code is derived in part from John R. Housers softfloat library, which

 * carries the following notice:

 *

 * ===========================================================================

 * This C source file is part of the SoftFloat IEC/IEEE Floating-point

 * Arithmetic Package, Release 2.

 *

 * Written by John R. Hauser.  This work was made possible in part by the

 * International Computer Science Institute, located at Suite 600, 1947 Center

 * Street, Berkeley, California 94704.  Funding was partially provided by the

 * National Science Foundation under grant MIP-9311980.  The original version

 * of this code was written as part of a project to build a fixed-point vector

 * processor in collaboration with the University of California at Berkeley,

 * overseen by Profs. Nelson Morgan and John Wawrzynek.  More information

 * is available through the web page `http://HTTP.CS.Berkeley.EDU/~jhauser/

 * arithmetic/softfloat.html'.

 *

 * THIS SOFTWARE IS DISTRIBUTED AS IS, FOR FREE.  Although reasonable effort

 * has been made to avoid it, THIS SOFTWARE MAY CONTAIN FAULTS THAT WILL AT

 * TIMES RESULT IN INCORRECT BEHAVIOR.  USE OF THIS SOFTWARE IS RESTRICTED TO

 * PERSONS AND ORGANIZATIONS WHO CAN AND WILL TAKE FULL RESPONSIBILITY FOR ANY

 * AND ALL LOSSES, COSTS, OR OTHER PROBLEMS ARISING FROM ITS USE.

 *

 * Derivative works are acceptable, even for commercial purposes, so long as

 * (1) they include prominent notice that the work is derivative, and (2) they

 * include prominent notice akin to these three paragraphs for those parts of

 * this code that are retained.

 * ===========================================================================

	/*

	 * Infinities and NaNs are a special case.

	/*

	 * Special-case zero.

	/*

	 * Normalise first.  Note that we shift the significand up to

	 * bit 31, so we have VFP_SINGLE_LOW_BITS + 1 below the least

	 * significant bit.

	/*

	 * Tiny number?

	/*

	 * Select rounding increment.

	/*

	 * Is our rounding going to overflow?

	/*

	 * If any of the low bits (which will be shifted out of the

	 * number) are non-zero, the result is inexact.

	/*

	 * Do our rounding.

	/*

	 * Infinity?

 infinity */

/*

 * Propagate the NaN, setting exceptions if it is signalling.

 * 'n' is always a NaN.  'm' may be a number, NaN or infinity.

		/*

		 * Default NaN mode - always returns a quiet NaN

		/*

		 * Contemporary mode - select the first signalling

		 * NAN, or if neither are signalling, the first

		 * quiet NAN.

		/*

		 * Make the NaN quiet.

	/*

	 * If one was a signalling NAN, raise invalid operation.

/*

 * Extended operations

	/*

	 * sqrt(+/- 0) == +/- 0

	/*

	 * Normalise a denormalised number

	/*

	 * sqrt(<0) = invalid

	/*

	 * Estimate the square root.

	/*

	 * And now adjust.

/*

 * Equal	:= ZC

 * Less than	:= N

 * Greater than	:= C

 * Unordered	:= CV

			/*

			 * Signalling NaN, or signalling on quiet NaN

			/*

			 * Signalling NaN, or signalling on quiet NaN

			/*

			 * equal

			/*

			 * different signs

				/*

				 * d is negative, so d < m

				/*

				 * d is positive, so d > m

			/*

			 * d < m

			/*

			 * d > m

	/*

	 * If we have a signalling NaN, signal invalid operation.

	/*

	 * If we have an infinity or NaN, the exponent must be 2047.

	/*

	 * Do we have a denormalised number?

		/*

		 * 2^0 <= m < 2^32-2^8

	/*

	 * Do we have a denormalised number?

		/*

		 * m >= 2^31-2^7: invalid

 2^0 <= m <= 2^31-2^7 */

		/*

		 * Two infinities.  Are they different signs?

			/*

			 * different signs -> invalid

			/*

			 * same signs -> valid

		/*

		 * One infinity and one number -> infinity

		/*

		 * 'n' is a NaN of some type

	/*

	 * Ensure that 'n' is the largest magnitude number.  Note that

	 * if 'n' and 'm' have equal exponents, we do not swap them.

	 * This ensures that NaN propagation works correctly.

	/*

	 * Is 'n' an infinity or a NaN?  Note that 'm' may be a number,

	 * infinity or a NaN here.

	/*

	 * We have two proper numbers, where 'vsn' is the larger magnitude.

	 *

	 * Copy 'n' to 'd' before doing the arithmetic.

	/*

	 * Align both numbers.

	/*

	 * If the signs are different, we are really subtracting.

	/*

	 * Ensure that 'n' is the largest magnitude number.  Note that

	 * if 'n' and 'm' have equal exponents, we do not swap them.

	 * This ensures that NaN propagation works correctly.

	/*

	 * If 'n' is an infinity or NaN, handle it.  'm' may be anything.

	/*

	 * If 'm' is zero, the result is always zero.  In this case,

	 * 'n' may be zero or a number, but it doesn't matter which.

	/*

	 * We add 2 to the destination exponent for the same reason as

	 * the addition case - though this time we have +1 from each

	 * input operand.

/*

 * Standard operations

/*

 * sd = sd + (sn * sm)

/*

 * sd = sd - (sn * sm)

/*

 * sd = -sd + (sn * sm)

/*

 * sd = -sd - (sn * sm)

/*

 * sd = sn * sm

/*

 * sd = -(sn * sm)

/*

 * sd = sn + sm

	/*

	 * Unpack and normalise denormals.

/*

 * sd = sn - sm

	/*

	 * Subtraction is addition with one sign inverted.

/*

 * sd = sn / sm

	/*

	 * Is n a NAN?

	/*

	 * Is m a NAN?

	/*

	 * If n and m are infinity, the result is invalid

	 * If n and m are zero, the result is invalid

	/*

	 * If n is infinity, the result is infinity

	/*

	 * If m is zero, raise div0 exception

	/*

	 * If m is infinity, or n is zero, the result is zero

	/*

	 * Ok, we have two numbers, we can perform division.

	/*

	 * fcvtsd takes a dN register number as destination, not sN.

	 * Technically, if bit 0 of dd is set, this is an invalid

	 * instruction.  However, we ignore this for efficiency.

	 * It also only operates on scalars.

	/*

	 * If destination bank is zero, vector length is always '1'.

	 * ARM DDI0100F C5.1.3, C5.3.2.

		/*

		 * CHECK: It appears to be undefined whether we stop when

		 * we encounter an exception.  We continue.

/*

 *  linux/arch/arm/vfp/vfpdouble.c

 *

 * This code is derived in part from John R. Housers softfloat library, which

 * carries the following notice:

 *

 * ===========================================================================

 * This C source file is part of the SoftFloat IEC/IEEE Floating-point

 * Arithmetic Package, Release 2.

 *

 * Written by John R. Hauser.  This work was made possible in part by the

 * International Computer Science Institute, located at Suite 600, 1947 Center

 * Street, Berkeley, California 94704.  Funding was partially provided by the

 * National Science Foundation under grant MIP-9311980.  The original version

 * of this code was written as part of a project to build a fixed-point vector

 * processor in collaboration with the University of California at Berkeley,

 * overseen by Profs. Nelson Morgan and John Wawrzynek.  More information

 * is available through the web page `http://HTTP.CS.Berkeley.EDU/~jhauser/

 * arithmetic/softfloat.html'.

 *

 * THIS SOFTWARE IS DISTRIBUTED AS IS, FOR FREE.  Although reasonable effort

 * has been made to avoid it, THIS SOFTWARE MAY CONTAIN FAULTS THAT WILL AT

 * TIMES RESULT IN INCORRECT BEHAVIOR.  USE OF THIS SOFTWARE IS RESTRICTED TO

 * PERSONS AND ORGANIZATIONS WHO CAN AND WILL TAKE FULL RESPONSIBILITY FOR ANY

 * AND ALL LOSSES, COSTS, OR OTHER PROBLEMS ARISING FROM ITS USE.

 *

 * Derivative works are acceptable, even for commercial purposes, so long as

 * (1) they include prominent notice that the work is derivative, and (2) they

 * include prominent notice akin to these three paragraphs for those parts of

 * this code that are retained.

 * ===========================================================================

	/*

	 * Infinities and NaNs are a special case.

	/*

	 * Special-case zero.

	/*

	 * Tiny number?

	/*

	 * Select rounding increment.

	/*

	 * Is our rounding going to overflow?

	/*

	 * If any of the low bits (which will be shifted out of the

	 * number) are non-zero, the result is inexact.

	/*

	 * Do our rounding.

	/*

	 * Infinity?

 infinity */

/*

 * Propagate the NaN, setting exceptions if it is signalling.

 * 'n' is always a NaN.  'm' may be a number, NaN or infinity.

		/*

		 * Default NaN mode - always returns a quiet NaN

		/*

		 * Contemporary mode - select the first signalling

		 * NAN, or if neither are signalling, the first

		 * quiet NAN.

		/*

		 * Make the NaN quiet.

	/*

	 * If one was a signalling NAN, raise invalid operation.

/*

 * Extended operations

	/*

	 * sqrt(+/- 0) == +/- 0

	/*

	 * Normalise a denormalised number

	/*

	 * sqrt(<0) = invalid

	/*

	 * Estimate the square root.

	/*

	 * And now adjust.

/*

 * Equal	:= ZC

 * Less than	:= N

 * Greater than	:= C

 * Unordered	:= CV

			/*

			 * Signalling NaN, or signalling on quiet NaN

			/*

			 * Signalling NaN, or signalling on quiet NaN

			/*

			 * equal

			/*

			 * different signs

				/*

				 * d is negative, so d < m

				/*

				 * d is positive, so d > m

			/*

			 * d < m

			/*

			 * d > m

	/*

	 * If we have a signalling NaN, signal invalid operation.

	/*

	 * If we have an infinity or a NaN, the exponent must be 255

	/*

	 * Do we have a denormalised number?

		/*

		 * 2^0 <= m < 2^32-2^8

	/*

	 * Do we have denormalised number?

 58 */

		/*

		 * Two infinities.  Are they different signs?

			/*

			 * different signs -> invalid

			/*

			 * same signs -> valid

		/*

		 * One infinity and one number -> infinity

		/*

		 * 'n' is a NaN of some type

	/*

	 * Ensure that 'n' is the largest magnitude number.  Note that

	 * if 'n' and 'm' have equal exponents, we do not swap them.

	 * This ensures that NaN propagation works correctly.

	/*

	 * Is 'n' an infinity or a NaN?  Note that 'm' may be a number,

	 * infinity or a NaN here.

	/*

	 * We have two proper numbers, where 'vdn' is the larger magnitude.

	 *

	 * Copy 'n' to 'd' before doing the arithmetic.

	/*

	 * Align 'm' with the result.

	/*

	 * If the signs are different, we are really subtracting.

	/*

	 * Ensure that 'n' is the largest magnitude number.  Note that

	 * if 'n' and 'm' have equal exponents, we do not swap them.

	 * This ensures that NaN propagation works correctly.

	/*

	 * If 'n' is an infinity or NaN, handle it.  'm' may be anything.

	/*

	 * If 'm' is zero, the result is always zero.  In this case,

	 * 'n' may be zero or a number, but it doesn't matter which.

	/*

	 * We add 2 to the destination exponent for the same reason

	 * as the addition case - though this time we have +1 from

	 * each input operand.

/*

 * Standard operations

/*

 * sd = sd + (sn * sm)

/*

 * sd = sd - (sn * sm)

/*

 * sd = -sd + (sn * sm)

/*

 * sd = -sd - (sn * sm)

/*

 * sd = sn * sm

/*

 * sd = -(sn * sm)

/*

 * sd = sn + sm

/*

 * sd = sn - sm

	/*

	 * Subtraction is like addition, but with a negated operand.

/*

 * sd = sn / sm

	/*

	 * Is n a NAN?

	/*

	 * Is m a NAN?

	/*

	 * If n and m are infinity, the result is invalid

	 * If n and m are zero, the result is invalid

	/*

	 * If n is infinity, the result is infinity

	/*

	 * If m is zero, raise div0 exceptions

	/*

	 * If m is infinity, or n is zero, the result is zero

	/*

	 * Ok, we have two numbers, we can perform division.

	/*

	 * fcvtds takes an sN register number as destination, not dN.

	 * It also always operates on scalars.

	/*

	 * f[us]ito takes a sN operand, not a dN operand.

	/*

	 * If destination bank is zero, vector length is always '1'.

	 * ARM DDI0100F C5.1.3, C5.3.2.

		/*

		 * CHECK: It appears to be undefined whether we stop when

		 * we encounter an exception.  We continue.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/vfp/vfpmodule.c

 *

 *  Copyright (C) 2004 ARM Limited.

 *  Written by Deep Blue Solutions Limited.

/*

 * Our undef handlers (in entry.S)

/*

 * Dual-use variable.

 * Used in startup: set to non-zero if VFP checks fail

 * After startup, holds VFP architecture

/*

 * The pointer to the vfpstate structure of the thread which currently

 * owns the context held in the VFP hardware, or NULL if the hardware

 * context is invalid.

 *

 * For UP, this is sufficient to tell which thread owns the VFP context.

 * However, for SMP, we also need to check the CPU number stored in the

 * saved state too to catch migrations.

/*

 * Is 'thread's most up to date state stored in this CPUs hardware?

 * Must be called from non-preemptible context.

/*

 * Force a reload of the VFP context from the thread structure.  We do

 * this by ensuring that access to the VFP hardware is disabled, and

 * clear vfp_current_hw_state.  Must be called from non-preemptible context.

/*

 * Per-thread VFP initialization.

	/*

	 * Disable VFP to ensure we initialize it first.  We must ensure

	 * that the modification of vfp_current_hw_state[] and hardware

	 * disable are done for the same CPU and without preemption.

	 *

	 * Do this first to ensure that preemption won't overwrite our

	 * state saving should access to the VFP be enabled at this point.

 release case: Per-thread VFP cleanup. */

/*

 * When this function is called with the following 'cmd's, the following

 * is true while this function is being run:

 *  THREAD_NOFTIFY_SWTICH:

 *   - the previously running thread will not be scheduled onto another CPU.

 *   - the next thread to be run (v) will not be running on another CPU.

 *   - thread->cpu is the local CPU number

 *   - not preemptible as we're called in the middle of a thread switch

 *  THREAD_NOTIFY_FLUSH:

 *   - the thread (v) will be running on the local CPU, so

 *	v === current_thread_info()

 *   - thread->cpu is the local CPU number at the time it is accessed,

 *	but may change at any time.

 *   - we could be preempted if tree preempt rcu is enabled, so

 *	it is unsafe to use thread->cpu.

 *  THREAD_NOTIFY_EXIT

 *   - we could be preempted if tree preempt rcu is enabled, so

 *	it is unsafe to use thread->cpu.

		/*

		 * On SMP, if VFP is enabled, save the old state in

		 * case the thread migrates to a different CPU. The

		 * restoring is done lazily.

		/*

		 * Always disable VFP so we can lazily save/restore the

		 * old state.

/*

 * Raise a SIGFPE for the current process.

 * sicode describes the signal being raised.

	/*

	 * This is the same as NWFPE, because it's not clear what

	 * this is used for

/*

 * Process bitmask of exception conditions.

	/*

	 * If any of the status flags are set, update the FPSCR.

	 * Comparison instructions always return at least one of

	 * these flags set.

	/*

	 * These are arranged in priority order, least to highest.

/*

 * Emulate a VFP instruction.

			/*

			 * CPDO

			/*

			 * A CPRT instruction can not appear in FPINST2, nor

			 * can it cause an exception.  Therefore, we do not

			 * have to emulate it.

		/*

		 * A CPDT instruction can not appear in FPINST2, nor can

		 * it cause an exception.  Therefore, we do not have to

		 * emulate it.

/*

 * Package up a bounce condition.

	/*

	 * At this point, FPEXC can have the following configuration:

	 *

	 *  EX DEX IXE

	 *  0   1   x   - synchronous exception

	 *  1   x   0   - asynchronous exception

	 *  1   x   1   - sychronous on VFP subarch 1 and asynchronous on later

	 *  0   0   1   - synchronous on VFP9 (non-standard subarch 1

	 *                implementation), undefined otherwise

	 *

	 * Clear various bits and enable access to the VFP so we can

	 * handle the bounce.

	/*

	 * Check for the special VFP subarch 1 and FPSCR.IXE bit case

		/*

		 * Synchronous exception, emulate the trigger instruction

		/*

		 * Asynchronous exception. The instruction is read from FPINST

		 * and the interrupted instruction has to be restarted.

		/*

		 * Illegal combination of bits. It can be caused by an

		 * unallocated VFP instruction but with FPSCR.IXE set and not

		 * on VFP subarch 1.

	/*

	 * Modify fpscr to indicate the number of iterations remaining.

	 * If FPEXC.EX is 0, FPEXC.DEX is 1 and the FPEXC.VV bit indicates

	 * whether FPEXC.VECITR or FPSCR.LEN is used.

	/*

	 * Handle the first FP instruction.  We used to take note of the

	 * FPEXC bounce reason, but this appears to be unreliable.

	 * Emulate the bounced instruction instead.

	/*

	 * If there isn't a second FP instruction, exit now. Note that

	 * the FPEXC.FP2V bit is valid only if FPEXC.EX is 1.

	/*

	 * The barrier() here prevents fpinst2 being read

	 * before the condition above.

	/*

	 * Enable full access to VFP (cp10 and cp11)

/* Called by platforms on which we want to disable VFP because it may not be

 * present on all CPUs within a SMP complex. Needs to be called prior to

 * vfp_init().

 if vfp is on, then save state for resumption */

 disable, just in case */

 clear any information we had about last context state */

 ensure we have access to the vfp */

 and disable it to ensure the next usage restores the state */

 CONFIG_CPU_PM */

/*

 * Ensure that the VFP state stored in 'thread->vfpstate' is up to date

 * with the hardware state.

		/*

		 * Save the last VFP state on this CPU.

 Ensure that the thread reloads the hardware VFP state on the next use. */

/*

 * Save the current VFP state into the provided structures and prepare

 * for entry into a new function (signal handler).

 Ensure that the saved hwstate is up-to-date. */

	/*

	 * Copy the floating point registers. There can be unused

	 * registers see asm/hwcap.h for details.

	/*

	 * Copy the status and control register.

	/*

	 * Copy the exception registers.

 Ensure that VFP is disabled. */

	/*

	 * As per the PCS, clear the length and stride bits for function

	 * entry.

 Sanitise and restore the current VFP state from the provided structures. */

 Disable VFP to avoid corrupting the new thread state. */

	/*

	 * Copy the floating point registers. There can be unused

	 * registers see asm/hwcap.h for details.

	/*

	 * Copy the status and control register.

	/*

	 * Sanitise and restore the exception registers.

 Ensure the VFP is enabled. */

 Ensure FPINST2 is invalid and the exception flag is cleared. */

/*

 * VFP hardware can lose all context when a CPU goes offline.

 * As we will be running in SMP mode with CPU hotplug, we will save the

 * hardware state at every thread switch.  We clear our held state when

 * a CPU has been killed, indicating that the VFP hardware doesn't contain

 * a threads VFP state.  When a CPU starts up, we re-enable access to the

 * VFP hardware. The callbacks below are called on the CPU which

 * is being offlined/onlined.

	/*

	 * If we reach this point, a floating point exception has been raised

	 * while running in kernel mode. If the NEON/VFP unit was enabled at the

	 * time, it means a VFP instruction has been issued that requires

	 * software assistance to complete, something which is not currently

	 * supported in kernel mode.

	 * If the NEON/VFP unit was disabled, and the location pointed to below

	 * is properly preceded by a call to kernel_neon_begin(), something has

	 * caused the task to be scheduled out and back in again. In this case,

	 * rebuilding and running with CONFIG_DEBUG_ATOMIC_SLEEP enabled should

	 * be helpful in localizing the problem.

/*

 * Kernel-side NEON support functions

	/*

	 * Kernel mode NEON is only allowed outside of interrupt context

	 * with preemption disabled. This will make sure that the kernel

	 * mode NEON register contents never need to be preserved.

	/*

	 * Save the userland NEON/VFP state. Under UP,

	 * the owner could be a task other than 'current'

 Disable the NEON/VFP unit. */

 CONFIG_KERNEL_MODE_NEON */

 mark as not present */

/*

 * VFP support code initialisation.

	/*

	 * Enable the access to the VFP on all online CPUs so the

	 * following test on FPSID will succeed.

	/*

	 * First check that there is a VFP that we can use.

	 * The handler is already setup to just log calls, so

	 * we just need to read the VFPSID register.

 Extract the architecture on CPUID scheme */

		/*

		 * Check for the presence of the Advanced SIMD

		 * load/store instructions, integer and single

		 * precision floating point operations. Only check

		 * for NEON if the hardware has the MVFR registers.

				/*

				 * Check for VFPv3 D16 and VFPv4 D16.  CPUs in

				 * this configuration only have 16 x 64bit

				 * registers.

 also v4-D16 */

 Extract the architecture version on pre-cpuid scheme */

	/*

	 * We detected VFP, and the support code is

	 * in place; report VFP support to userspace.

 SPDX-License-Identifier: GPL-2.0

/*

 * IXP4xx Device Tree boot support

/*

 * These are the only fixed phys to virt mappings we ever need

 * we put it right after the UART mapping at 0xffc80000-0xffc81fff

	/*

	 * This is needed for runtime system configuration checks,

	 * such as reading if hardware so-and-so is present. This

	 * could eventually be converted into a syscon once all boards

	 * are converted to device tree.

 This is needed for LL-debug/earlyprintk/debug-macro.S */

/*

 * We handle 4 differen SoC families. These compatible strings are enough

 * to provide the core so that different boards can add their more detailed

 * specifics.

 SPDX-License-Identifier: GPL-2.0

/*

 * arch/arm/mach-ixp4xx/gateway7001-setup.c

 *

 * Board setup for the Gateway 7001 board

 *

 * Copyright (C) 2007 Imre Kaloz <kaloz@openwrt.org>

 *

 * based on coyote-setup.c:

 *      Copyright (C) 2003-2005 MontaVista Software, Inc.

 *

 * Author: Imre Kaloz <Kaloz@openwrt.org>

 Maintainer: Imre Kaloz <kaloz@openwrt.org> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-ixp4xx/common-pci.c 

 *

 * IXP4XX PCI routines for all platforms

 *

 * Maintainer: Deepak Saxena <dsaxena@plexity.net>

 *

 * Copyright (C) 2002 Intel Corporation.

 * Copyright (C) 2003 Greg Ungerer <gerg@snapgear.com>

 * Copyright (C) 2003-2004 MontaVista Software, Inc.

/*

 * IXP4xx PCI read function is dependent on whether we are 

 * running A0 or B0 (AppleGate) silicon.

/*

 * Base address for PCI register region

/*

 * PCI cfg an I/O routines are done by programming a 

 * command/byte enable register, and then read/writing

 * the data from a data register. We need to ensure

 * these transactions are atomic or we will end up

 * with corrupt data on the bus or in a driver.

/*

 * Read from PCI config space

/*

 * Write to PCI config space

 check Master Abort bit after access */

 make sure the Master Abort bit is reset */    

	/* 

	 * PCI workaround  - only works if NP PCI space reads have 

	 * no side effects!!! Read 8 times. last one will be good.

 set up and execute the read */    

 the result of the read is now in NP_RDATA */

 set up the write */

 execute the write by writing to NP_WDATA */

 type 0 */

 type 1 */

/*

 * Mask table, bits to mask for quantity of size 1, 2 or 4 bytes.

 * 0 and 3 are not valid indexes...

0*/	0,

1*/	0xff,

2*/	0xffff,

3*/	0,

4*/	0xffffffff,

/*

 * PCI abort handler

 make sure the Master Abort bit is reset */    

	/*

	 * If it was an imprecise abort, then we need to correct the

	 * return address to be _after_ the instruction.

 1 GB of indirect PCI MMIO space */

 64 MB of PCI MMIO space */

	/*

	 * Determine which PCI read method to use.

	 * Rev 0 IXP425 requires workaround.

 hook in our fault handler for PCI errors */

	/*

	 * We use identity AHB->PCI address translation

	 * in the 0x48000000 to 0x4bffffff address space

	/*

	 * We also use identity PCI->AHB address translation

	 * in 4 16MB BARs that begin at the physical memory start

		/*

		 * We configure the PCI inbound memory windows to be

		 * 1:1 mapped to SDRAM

		/*

		 * Enable CSR window at 64 MiB to allow PCI masters

		 * to continue prefetching past 64 MiB boundary.

		/*

		 * Enable the IO window to be way up high, at 0xfffffc00

 No TRDY time limit */

	/*

	 * Set Initialize Complete in PCI Control Register: allow IXP4XX to

	 * respond to PCI configuration cycles. Specify that the AHB bus is

	 * operating in big endian mode. Set up byte lane swapping between 

	 * little-endian PCI and the big-endian AHB bus 

		/* 

		 * If we're out of memory this early, something is wrong,

		 * so we might as well catch it here.

 SPDX-License-Identifier: GPL-2.0

/*

 * Goramo MultiLink router platform code

 * Copyright (C) 2006-2009 Krzysztof Halasa <khc@pm.waw.pl>

 IDSEL = AD21 */

 IDSEL = AD20 */

 IDSEL = AD19 */

 IDSEL = AD18 */

 GPIO lines */

 GPIO15 is not connected */

 Control outputs from 74HC4094 */

 offsets from start of flash ROM = 0x50000000 */

 6 bytes */

 6 bytes */

 u32 */

 u32 */

 u32 */

 u32 */

 u32 */

 u32 */

 0 = no NEC chip, 1-5 = ports # */

 0x81 in 16-bit mode */

 assume all hardware present */;

/*

 * FIXME: this is reimplementing I2C bit-bangining. Move this

 * over to using driver/i2c/busses/i2c-gpio.c like all other boards

 * and register proper I2C device(s) on the bus for this. (See

 * other IXP4xx boards for examples.)

 MSB first */

 active edge */

 Be ready for START */

 catch bugs */

 Flash memory */

 IXP425 2 UART ports */

 Built-in 10/100 Ethernet MAC interfaces */

 IXP425 2 synchronous serial ports */

 index 0 */

 flash */

 max index 1 */

 max index 2 */

 max index 3 */

 max index 4 */

 max index 5 */

 Wait for PCI devices to initialize */

 need to adjust number of USB ports on NEC chip */

 CONFIG_PCI */

 Maintainer: Krzysztof Halasa */

/*

 * arch/arm/mach-ixp4xx/common.c

 *

 * Generic code shared across all IXP4XX platforms

 *

 * Maintainer: Deepak Saxena <dsaxena@plexity.net>

 *

 * Copyright 2002 (c) Intel Corporation

 * Copyright 2003-2004 (c) MontaVista, Software, Inc. 

 * 

 * This file is licensed under  the terms of the GNU General Public 

 * License version 2. This program is licensed "as is" without any 

 * warranty of any kind, whether express or implied.

/*************************************************************************

 * IXP4xx chipset I/O mapping

 UART, Interrupt ctrl, GPIO, timers, NPEs, MACs, USB .... */

 Expansion Bus Config Registers */

 PCI Registers */

	/*

	 * ixp4xx does not implement the XScale PWRMODE register

	 * so it must not call cpu_do_idle().

/*

 * USB device controller. The IXP4xx uses the same controller as PXA25X,

 * so we just use the same device.

 A single 32-bit register on IXP46x */

/*

 * I2C controller. The IXP46x uses the same block as the IOP3xx, so

 * we just use the same device name.

 Jump into ROM at address 0 */

 Use on-chip reset capability */

		/* set the "key" register to enable access to

		 * "timer" and "enable" registers

 write 0 to the timer register for an immediate reset */

/*

 * Setup DMA mask to 64MB on PCI devices and 4 GB on all other things.

 64 MB */

 64 MB */

 device wanted sub-64MB mask */

/*

 * In the case of using indirect PCI, we simply return the actual PCI

 * address and our read/write implementation use that to drive the

 * access registers. If something outside of PCI is ioremap'd, we

 * fallback to the default.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arch/mach-ixp4xx/gateway7001-pci.c

 *

 * PCI setup routines for Gateway 7001

 *

 * Copyright (C) 2007 Imre Kaloz <kaloz@openwrt.org>

 *

 * based on coyote-pci.c:

 *	Copyright (C) 2002 Jungo Software Technologies.

 *	Copyright (C) 2003 MontaVista Softwrae, Inc.

 *

 * Maintainer: Imre Kaloz <kaloz@openwrt.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

 *  Copyright (c) 2010, Code Aurora Forum. All rights reserved.

 *  Copyright (c) 2014 The Linux Foundation. All rights reserved.

 Put the CPU into reset. */

 Turn on the BHS and set the BHS_CNT to 16 XO clock cycles */

 Wait for the BHS to settle */

 Release CPU out of reset and bring it to life. */

 Turn on CPU rail */

 Krait bring-up sequence */

 Turn on the BHS, turn off LDO Bypass and power down LDO */

 wait for the BHS to settle */

 Turn on BHS segments */

 wait for the BHS to settle */

 Finally turn on the bypass so that BHS supplies power */

 enable max phases */

	/*

	 * Send the secondary CPU a soft interrupt, thereby causing

	 * the boot monitor to read the system wide flags register,

	 * and branch to the address found there.

/*

 * arch/arm/mach-dove/mpp.c

 *

 * MPP functions for Marvell Dove SoCs

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Map a group to a range of GPIO pins in that group */

/* Enable gpio for a range of pins. mode should be a combination of

/* Dump all the extra MPP registers. The platform code will dump the

/* Configure the group registers, enabling GPIO if sel indicates the

 Configure the various MPP pins on Dove */

 Use platform code for pins 0-23 */

/*

 * arch/arm/mach-dove/dove-db-setup.c

 *

 * Marvell DB-MV88AP510-BP Development Board Setup

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * SPI Devices:

 * 	SPI0: 4M Flash ST-M25P32-VMF6P

/*****************************************************************************

 * PCI

/*****************************************************************************

 * Board Init

	/*

	 * Basic Dove setup. Needs to be called early.

/*

 * arch/arm/mach-dove/cm-a510.c

 *

 * Copyright (C) 2010 CompuLab, Ltd.

 * Konstantin Sinyuk <kostyas@compulab.co.il>

 *

 * Based on Marvell DB-MV88AP510-BP Development Board Setup

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * SPI Devices:

 * SPI0: 1M Flash Winbond w25q32bv

 Board Init */

	/*

	 * Basic Dove setup. Needs to be called early.

/*

 * arch/arm/mach-dove/common.c

 *

 * Core functions for Marvell Dove 88AP510 System On Chip

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 These can go away once Dove uses the mvebu-mbus DT binding */

/*****************************************************************************

 * I/O Address Mapping

/*****************************************************************************

 * CLK tree

/*****************************************************************************

 * EHCI0

/*****************************************************************************

 * EHCI1

/*****************************************************************************

 * GE00

/*****************************************************************************

 * SoC RTC

/*****************************************************************************

 * SATA

/*****************************************************************************

 * UART0

/*****************************************************************************

 * UART1

/*****************************************************************************

 * UART2

/*****************************************************************************

 * UART3

/*****************************************************************************

 * SPI

/*****************************************************************************

 * I2C

/*****************************************************************************

 * Time handling

/*****************************************************************************

 * XOR 0

/*****************************************************************************

 * XOR 1

/*****************************************************************************

 * SDIO

	/*

	 * The PCIe windows will no longer be statically allocated

	 * here once Dove is migrated to the pci-mvebu driver. The

	 * non-PCIe windows will no longer be created here once Dove

	 * fully moves to DT.

 sentinel */

 Setup root of clk tree */

 internal devices that every board has */

	/*

	 * Enable soft reset to assert RSTOUTn.

	/*

	 * Assert soft reset.

/*

 * arch/arm/mach-dove/irq.c

 *

 * Dove IRQ handling.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Initialize gpiolib for GPIOs 0-71.

/*

 * arch/arm/mach-dove/pcie.c

 *

 * PCIe functions for Marvell Dove 88AP510 SoC

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Generic PCIe unit setup.

	/*

	 * IORESOURCE_MEM

	/*

	 * Don't go out when trying to access nonexisting devices

	 * on the local bus.

	/*

	 * Prevent enumeration of root complex.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018 Nuvoton Technology corporation.

 Copyright 2018 Google, Inc.

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2018 Nuvoton Technology corporation.

 Copyright 2018 Google, Inc.

 give boot ROM kernel start address. */

 make sure the previous write is seen by all observers. */

 SPDX-License-Identifier: GPL-2.0

 Copyright 2021 Jonathan Neuschfer

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Support for the LSI Axxia SoC devices based on ARM cores.

 *

 * Copyright (C) 2012 LSI

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-axxia/platsmp.c

 *

 * Copyright (C) 2012 LSI Corporation

 Syscon register offsets for releasing cores from reset */

/*

 * Write the kernel entry point for secondary CPUs to the specified address

 Make sure this store is visible to other CPUs */

	/*

	 * Initialise the present map, which describes the set of CPUs actually

	 * populated at the present time.

 SPDX-License-Identifier: GPL-2.0

/*

 * Gemini Device Tree boot support

 This is needed for LL-debug/earlyprintk/debug-macro.S */

	/*

	 * Because of broken hardware we have to enable interrupts or the CPU

	 * will never wakeup... Acctualy it is not very good to enable

	 * interrupts first since scheduler can miss a tick, but there is

	 * no other way around this. Platforms that needs it for power saving

	 * should enable it in init code, since by default it is

	 * disabled.

 FIXME: Enabling interrupts here is racy! */

/*

 * Suspend/resume support. Currently supporting Armada XP only.

 *

 * Copyright (C) 2014 Marvell

 *

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Issue a Data Synchronization Barrier instruction to ensure

	 * that all state saving has been completed.

 Flush the DLB and wait ~7 usec */

 Set DRAM in battery backup mode */

 Prepare to go to self-refresh */

/*

 * Those registers are accessed before switching the internal register

 * base, which is why we hardcode the 0xd0000000 base address, the one

 * used by the SoC out of reset.

	/*

	 * Ask the DT what is the internal register address on this

	 * platform. In the mvebu-mbus DT binding, 0xf0010000

	 * corresponds to the internal register window.

	/*

	 * The bootloader expects the first two words to be a magic

	 * value (BOOT_MAGIC_WORD), followed by the address of the

	 * resume code to jump to. Then, it expects a sequence of

	 * (address, value) pairs, which can be used to restore the

	 * value of certain registers. This sequence must end with the

	 * BOOT_MAGIC_LIST_END magic value.

	/*

	 * Some platforms remap their internal register base address

	 * to 0xf1000000. However, out of reset, window 12 starts at

	 * 0xf0000000 and ends at 0xf7ffffff, which would overlap with

	 * the internal registers. Therefore, disable window 12.

	/*

	 * Set the internal register base address to the value

	 * expected by Linux, as read from the Device Tree.

	/*

	 * Ask the mvebu-mbus driver to store the SDRAM window

	 * configuration, which has to be restored by the bootloader

	 * before re-entering the kernel on resume.

/*

 * arch/arm/mach-mvebu/dove.c

 *

 * Marvell Dove 88AP510 System On Chip FDT Board

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * Symmetric Multi Processing (SMP) support for Marvell EBU Cortex-A9

 * based SOCs (Armada 375/38x).

 *

 * Copyright (C) 2014 Marvell

 *

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Write the address of secondary startup into the system-wide

	 * flags register. The boot monitor waits until it receives a

	 * soft interrupt, and then the secondary CPU branches to this

	 * address.

	/*

	 * Doing this before deasserting the CPUs is needed to wake up CPUs

	 * in the offline state after using CPU hotplug.

/*

 * When a CPU is brought back online, either through CPU hotplug, or

 * because of the boot of a kexec'ed kernel, the PMSU configuration

 * for this CPU might be in the deep idle state, preventing this CPU

 * from receiving interrupts. Here, we therefore take out the current

 * CPU from this state, which was entered by armada_38x_cpu_die()

 * below.

	/*

	 * CPU hotplug is implemented by putting offline CPUs into the

	 * deep idle sleep state.

/*

 * We need a dummy function, so that platform_can_cpu_hotplug() knows

 * we support CPU hotplug. However, the function does not need to do

 * anything, because CPUs going offline can enter the deep idle state

 * by themselves, without any help from a still alive CPU.

/*

 * Device Tree support for Armada 370 and XP platforms.

 *

 * Copyright (C) 2012 Marvell

 *

 * Lior Amsalem <alior@marvell.com>

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * Enables the SCU when available. Obviously, this is only useful on

 * Cortex-A based SOCs, not on PJ4B based ones.

/*

 * When returning from suspend, the platform goes through the

 * bootloader, which executes its DDR3 training code. This code has

 * the unfortunate idea of using the first 10 KB of each DRAM bank to

 * exercise the RAM and calculate the optimal timings. Therefore, this

 * area of RAM is overwritten, and shouldn't be used by the kernel if

 * suspend/resume is supported.

	/*

	 * Only revisons more recent than A0 support the offload

	 * mechanism. We can exit only if we are sure that we can

	 * get the SoC revision and it is more recent than A0.

/*

 * Copyright (C) 2014 Marvell

 *

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

		/*

		 * This code is kept for backward compatibility with

		 * old Device Trees.

 No reset node found */

/*

 * Copyright 2012 (C), Jason Cooper <jason@lakedaemon.net>

 *

 * arch/arm/mach-mvebu/kirkwood.c

 *

 * Flattened Device Tree board initialization

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * The ethernet interfaces forget the MAC address assigned by u-boot

	 * if the clocks are turned off. Usually, u-boot on kirkwood boards

	 * has no DT support to properly set local-mac-address property.

	 * As a workaround, we get the MAC address from mv643xx_eth registers

	 * and update the port device node if no valid MAC address is set.

 skip disabled nodes or nodes with valid MAC address*/

 ensure port clock is not gated to not hang CPU */

 store MAC address register contents in local-mac-address */

/*

 * Disable propagation of mbus errors to the CPU local bus, as this

 * causes mbus errors (which can occur for example for PCI aborts) to

 * throw CPU aborts, which we're not set up to deal with.

 sentinel */ }

 Maintainer: Jason Cooper <jason@lakedaemon.net> */

/*

 * Symmetric Multi Processing (SMP) support for Armada XP

 *

 * Copyright (C) 2012 Marvell

 *

 * Lior Amsalem <alior@marvell.com>

 * Yehuda Yitschak <yehuday@marvell.com>

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * The Armada XP SoC has 4 ARMv7 PJ4B CPUs running in full HW coherency

 * This file implements the routines for preparing the SMP infrastructure

 * and waking up the secondary CPUs

	/*

	 * This is needed to wake up CPUs in the offline state after

	 * using CPU hotplug.

	/*

	 * This is needed to take secondary CPUs out of reset on the

	 * initial boot.

/*

 * When a CPU is brought back online, either through CPU hotplug, or

 * because of the boot of a kexec'ed kernel, the PMSU configuration

 * for this CPU might be in the deep idle state, preventing this CPU

 * from receiving interrupts. Here, we therefore take out the current

 * CPU from this state, which was entered by armada_xp_cpu_die()

 * below.

	/*

	 * In order to boot the secondary CPUs we need to ensure

	 * the bootROM is mapped at the correct address.

	/*

	 * CPU hotplug is implemented by putting offline CPUs into the

	 * deep idle sleep state.

/*

 * We need a dummy function, so that platform_can_cpu_hotplug() knows

 * we support CPU hotplug. However, the function does not need to do

 * anything, because CPUs going offline can enter the deep idle state

 * by themselves, without any help from a still alive CPU.

 end of list */ },

	/*

	 * This is needed to wake up CPUs in the offline state after

	 * using CPU hotplug.

	/*

	 * This is needed to take secondary CPUs out of reset on the

	 * initial boot.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Power Management driver for Marvell Kirkwood SoCs

 *

 * Copyright (C) 2013 Ezequiel Garcia <ezequiel@free-electrons.com>

 * Copyright (C) 2010 Simon Guinot <sguinot@lacie.com>

 Set peripherals to low-power mode */

 Set DDR in self-refresh */

	/*

	 * Set CPU in wait-for-interrupt state.

	 * This disables the CPU core clocks,

	 * the array clocks, and also the L2 controller.

/*

 * ID and revision information for mvebu SoCs

 *

 * Copyright (C) 2014 Marvell

 *

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * All the mvebu SoCs have information related to their variant and

 * revision that can be read from the PCI control register. This is

 * done before the PCI initialization to avoid any conflict. Once the

 * ID and revision are retrieved, the mapping is freed.

	/*

	 * ID and revision are available from any port, so we

	 * just pick the first one

 SoC ID */

 SoC revision */

	/*

	 * If the PCIe unit is actually enabled and we have PCI

	 * support in the kernel, we intentionally do not release the

	 * reference to the clock. We want to keep it running since

	 * the bootloader does some PCIe link configuration that the

	 * kernel is for now unable to do, and gating the clock would

	 * make us loose this precious configuration.

	/*

	 * First try to get the ID and the revision by the system

	 * register and use PCI registers only if it is not possible

 Also protects against running on non-mvebu systems */

/*

 * Coherency fabric (Aurora) support for Armada 370, 375, 38x and XP

 * platforms.

 *

 * Copyright (C) 2012 Marvell

 *

 * Yehuda Yitschak <yehuday@marvell.com>

 * Gregory Clement <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * The Armada 370, 375, 38x and XP SOCs have a coherency fabric which is

 * responsible for ensuring hardware coherency between all CPUs and between

 * CPUs and I/O masters. This file initializes the coherency fabric and

 * supplies basic routines for configuring and controlling hardware coherency

 Coherency fabric registers */

 end of list */ },

 Functions defined in coherency_ll.S */

/*

 * Disable the "Shared L2 Present" bit in CPU Configuration register

 * on Armada XP.

 *

 * The "Shared L2 Present" bit affects the "level of coherence" value

 * in the clidr CP15 register.  Cache operation functions such as

 * "flush all" and "invalidate all" operate on all the cache levels

 * that included in the defined level of coherence. When HW I/O

 * coherency is used, this bit causes unnecessary flushes of the L2

 * cache.

	/*

	 * Ensure secondary CPUs will see the updated value,

	 * which they read before they join the coherency

	 * fabric, and therefore before they are coherent with

	 * the boot CPU cache.

/*

 * This ioremap hook is used on Armada 375/38x to ensure that all MMIO

 * areas are mapped as MT_UNCACHED instead of MT_DEVICE. This is

 * needed for the HW I/O coherency mechanism to work properly without

 * deadlock.

	/*

	 * We should switch the PL310 to I/O coherency mode only if

	 * I/O coherency is actually enabled.

	/*

	 * Add the PL310 property "arm,io-coherent". This makes sure the

	 * outer sync operation is not used, which allows to

	 * workaround the system erratum that causes deadlocks when

	 * doing PCIe in an SMP situation on Armada 375 and Armada

	 * 38x.

	/*

	 * The coherency fabric is needed:

	 * - For coherency between processors on Armada XP, so only

	 *   when SMP is enabled.

	 * - For coherency between the processor and I/O devices, but

	 *   this coherency requires many pre-requisites (write

	 *   allocate cache policy, shareable pages, SMP bit set) that

	 *   are only meant in SMP situations.

	 *

	 * Note that this means that on Armada 370, there is currently

	 * no way to use hardware I/O coherency, because even when

	 * CONFIG_SMP is enabled, is_smp() returns false due to the

	 * Armada 370 being a single-core processor. To lift this

	 * limitation, we would have to find a way to make the cache

	 * policy set to write-allocate (on all Armada SoCs), and to

	 * set the shareable attribute in page tables (on all Armada

	 * SoCs except the Armada 370). Unfortunately, such decisions

	 * are taken very early in the kernel boot process, at a point

	 * where we don't know yet on which SoC we are running.



/*

 * Power Management Service Unit(PMSU) support for Armada 370/XP platforms.

 *

 * Copyright (C) 2012 Marvell

 *

 * Yehuda Yitschak <yehuday@marvell.com>

 * Gregory Clement <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * The Armada 370 and Armada XP SOCs have a power management service

 * unit which is responsible for powering down and waking up CPUs and

 * other SOC units

 PMSU MP registers */

 PMSU fabric registers */

 PMSU delay registers */

 CA9 MPcore SoC Control registers */

 end of list */ },

/*

 * This function sets up the boot address workaround needed for SMP

 * boot on Armada 375 Z1 and cpuidle on Armada 370. It unmaps the

 * BootROM Mbus window, and instead remaps a crypto SRAM into which a

 * custom piece of code is copied to replace the problematic BootROM.

	/*

	 * The last word of the code copied in SRAM must contain the

	 * physical base address of the PMSU register. We

	 * intentionally store this address in the native endianness

	 * of the system.

 Enable L2 & Fabric powerdown in Deep-Idle mode - Fabric */

 No locking is needed because we only access per-CPU registers */

	/*

	 * Adjust the PMSU configuration to wait for WFI signal, enable

	 * IRQ and FIQ as wakeup events, set wait for snoop queue empty

	 * indication and mask IRQ and FIQ from CPU

 ask HW to power down the L2 Cache if needed */

 request power down */

 Disable snoop disable by HW - SW is taking care of it */

	/* If we are here, wfi failed. As processors run out of

	 * coherency for some time, tlbs might be stale, so flush them

 Test the CR_C bit and set it if it was cleared */

	/*

	 * Already flushed cache, but do it again as the outer cache

	 * functions dirty the cache with spinlocks

 No locking is needed because we only access per-CPU registers */

 cancel ask HW to power down the L2 Cache if possible */

 cancel Enable wakeup events and mask interrupts */

	/*

	 * On Armada 370, there is "a slow exit process from the deep

	 * idle state due to heavy L1/L2 cache cleanup operations

	 * performed by the BootROM software". To avoid this, we

	 * replace the restart code of the bootrom by a a simple jump

	 * to the boot address. Then the code located at this boot

	 * address will take care of the initialization.

 Set up reset mask when powering down the cpus */

 Set up delay */

	/*

	 * Currently the CPU idle support for Armada 38x is broken, as

	 * the CPU hotplug uses some of the CPU idle functions it is

	 * broken too, so let's disable it

 Prepare to enter idle */

 Request the DFS transition */

 The fact of entering idle will trigger the DFS transition */

	/*

	 * We're back from idle, the DFS transition has completed,

	 * clear the idle wait indication.

 Clear any previous DFS DONE event */

 Mask the DFS done interrupt, since we are going to poll */

 Trigger the DFS on the appropriate CPU */

 Poll until the DFS done event is generated */

 Restore the DFS mask to its original state */

/*

 * System controller support for Armada 370, 375 and XP platforms.

 *

 * Copyright (C) 2012 Marvell

 *

 * Lior Amsalem <alior@marvell.com>

 * Gregory CLEMENT <gregory.clement@free-electrons.com>

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * The Armada 370, 375 and Armada XP SoCs have a range of

 * miscellaneous registers, that do not belong to a particular device,

 * but rather provide system-level features. This basic

 * system-controller driver provides a device tree binding for those

 * registers, and implements utility functions offering various

 * features related to those registers.

 *

 * For now, the feature set is limited to restarting the platform by a

 * soft-reset, but it might be extended in the future.

 end of list */ },

		/*

		 * Enable soft reset to assert RSTOUTn.

		/*

		 * Assert soft reset.

/*

 * Board-level suspend/resume support.

 *

 * Copyright (C) 2014-2015 Marvell

 *

 * Thomas Petazzoni <thomas.petazzoni@free-electrons.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Put 001 as value on the GPIOs */

 Prepare writing 111 to the GPIOs */

	/*

	 * Wait a while, the PIC needs quite a bit of time between the

	 * two GPIO commands.

 Align to a cache line */

 Enter self refresh */

		/*

		 * Wait 100 cycles for DDR to enter self refresh, by

		 * doing 50 times two instructions.

 Issue the command ACK */

 Trap the processor */

/*

 * Registering the mvebu_board_pm_enter callback must be done before

 * the platform_suspend_ops will be registered. In the same time we

 * also need to have the gpio devices registered. That's why we use a

 * device_initcall_sync which is called after all the device_initcall

 * (used by the gpio device) but before the late_initcall (used to

 * register the platform_suspend_ops)

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2004-2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 S3C common power management (suspend to ram) support.

 for external use */

/* The IRQ ext-int code goes here, it is too small to currently bother

/* s3c_pm_enter

 *

 * central control for sleep/resume process

 ensure the debug is initialised (if enabled) */

	/* check if we have anything to wake-up with... bad things seem

	 * to happen if you suspend with no wakeup (system will often

	 * require a full power-cycle)

 save all necessary core registers not covered by the drivers */

 set the irq configuration for wake */

 call cpu specific preparation */

 flush cache back to ram */

 send the cpu to sleep... */

	/* this will also act as our return point from when

	 * we resume as it saves its own register state and restores it

 restore the system state */

 check what irq (if any) restored the system */

 LEDs should now be 1110 */

 ok, let's return from sleep */

 prepare check area if configured */

/* s3c_pm_init

 *

 * Attach the power management functions. This should be called

 * from the board specific initialisation if the board supports

 * it.

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2006-2007 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>

	Vincent Sanders <vince@arm.linux.org.uk>



 S3C2410 CPU PLL tables

 This array should be sorted in ascending order of the frequencies */

 2410A extras */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (C) 2004 by FS Forth-Systeme GmbH

 All rights reserved.



 @Author: Jonas Dietsche



 @History:

 derived from linux/arch/arm/mach-s3c2410/mach-bast.c, written by

 Ben Dooks <ben@simtec.co.uk>

 nothing here yet */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

MACHINE_START(SMDK2410, "SMDK2410") /* @TODO: request a new identifier and switch

 Maintainer: Jonas Dietsche */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2010 Ben Dooks <ben-linux <at> fluff.org>



 Helper for platform data setting

 too early to use dev_name(), may not be registered */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (C) 2006 by OpenMoko, Inc.

 Author: Harald Welte <laforge@openmoko.org>

 All rights reserved.

 LCD driver info */

 Configuration for 640x480 SHARP LQ080V3DG01 */

 HCLK/4 */

 Configuration for 480x640 toppoly TD028TTEC1 */

 HCLK/4 */

 Config for 240x320 LCD */

 HCLK/10 */

 CS8900 */

 LED */

 SPI */

 bus pins */

 Board devices */

/* choose a set of timings which should suit most 512Mbit

 * chips and beyond.

 UDC */

 production */

 big */

 small */

 set initial state of the LED GPIO */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006-2009 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 S3C24XX CPU Frequency scaling - IO timing for S3C2410/S3C2440/S3C2442

/**

 * s3c2410_print_timing - print bank timing data for debug purposes

 * @pfx: The prefix to put on the output

 * @timings: The timing inforamtion to print.

/**

 * bank_reg - convert bank number to pointer to the control register.

 * @bank: The IO bank number.

/**

 * bank_is_io - test whether bank is used for IO

 * @bankcon: The bank control register.

 *

 * This is a simplistic test to see if any BANKCON[x] is not an IO

 * bank. It currently does not take into account whether BWSCON has

 * an illegal width-setting in it, or if the pin connected to nCS[x]

 * is actually being handled as a chip-select.

/**

 * to_div - convert cycle time to divisor

 * @cyc: The cycle time, in 10ths of nanoseconds.

 * @hclk_tns: The cycle time for HCLK, in 10ths of nanoseconds.

 *

 * Convert the given cycle time into the divisor to use to obtain it from

 * HCLK.

/**

 * calc_0124 - calculate divisor control for divisors that do /0, /1. /2 and /4

 * @cyc: The cycle time, in 10ths of nanoseconds.

 * @hclk_tns: The cycle time for HCLK, in 10ths of nanoseconds.

 * @v: Pointer to register to alter.

 * @shift: The shift to get to the control bits.

 *

 * Calculate the divisor, and turn it into the correct control bits to

 * set in the result, @v.

 Currently no support for Tacp calculations. */

/**

 * calc_tacc - calculate divisor control for tacc.

 * @cyc: The cycle time, in 10ths of nanoseconds.

 * @nwait_en: IS nWAIT enabled for this bank.

 * @hclk_tns: The cycle time for HCLK, in 10ths of nanoseconds.

 * @v: Pointer to register to alter.

 *

 * Calculate the divisor control for tACC, taking into account whether

 * the bank has nWAIT enabled. The result is used to modify the value

 * pointed to by @v.

 if nWait enabled on an bank, Tacc must be at-least 4 cycles. */

/**

 * s3c2410_calc_bank - calculate bank timing information

 * @cfg: The configuration we need to calculate for.

 * @bt: The bank timing information.

 *

 * Given the cycle timine for a bank @bt, calculate the new BANKCON

 * setting for the @cfg timing. This updates the timing information

 * ready for the cpu frequency change.

 tacp: 2,3,4,5 */

 tcah: 0,1,2,4 */

 tcoh: 0,1,2,4 */

 tacc: 1,2,3,4,6,7,10,14 (>4 for nwait) */

 tcos: 0,1,2,4 */

 tacs: 0,1,2,4 */

/**

 * get_tacc - turn tACC value into cycle time

 * @hclk_tns: The cycle time for HCLK, in 10ths of nanoseconds.

 * @val: The bank timing register value, shifed down.

/**

 * get_0124 - turn 0/1/2/4 divider into cycle time

 * @hclk_tns: The cycle time for HCLK, in 10ths of nanoseconds.

 * @val: The bank timing register value, shifed down.

/**

 * s3c2410_iotiming_getbank - turn BANKCON into cycle time information

 * @cfg: The frequency configuration

 * @bt: The bank timing to fill in (uses cached BANKCON)

 *

 * Given the BANKCON setting in @bt and the current frequency settings

 * in @cfg, update the cycle timing information.

/**

 * s3c2410_iotiming_debugfs - debugfs show io bank timing information

 * @seq: The seq_file to write output to using seq_printf().

 * @cfg: The current configuration.

 * @iob: The IO bank information to decode.

/**

 * s3c2410_iotiming_calc - Calculate bank timing for frequency change.

 * @cfg: The frequency configuration

 * @iot: The IO timing information to fill out.

 *

 * Calculate the new values for the banks in @iot based on the new

 * frequency information in @cfg. This is then used by s3c2410_iotiming_set()

 * to update the timing when necessary.

/**

 * s3c2410_iotiming_set - set the IO timings from the given setup.

 * @cfg: The frequency configuration

 * @iot: The IO timing information to use.

 *

 * Set all the currently used IO bank timing information generated

 * by s3c2410_iotiming_calc() once the core has validated that all

 * the new values are within permitted bounds.

 set the io timings from the specifier */

/**

 * s3c2410_iotiming_get - Get the timing information from current registers.

 * @cfg: The frequency configuration

 * @timings: The IO timing information to fill out.

 *

 * Calculate the @timings timing information from the current frequency

 * information in @cfg, and the new frequency configuration

 * through all the IO banks, reading the state and then updating @iot

 * as necessary.

 *

 * This is used at the moment on initialisation to get the current

 * configuration so that boards do not have to carry their own setup

 * if the timings are correct on initialisation.

 look through all banks to see what is currently set. */

 find out in nWait is enabled for bank. */

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2011 Samsung Electronics Ltd.

		http:
 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2009 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 Audio setup for various Simtec S3C24XX implementations

 platform ops for audio */

 copy platform data so the source can be __initdata */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2004-2006 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 Samsung S3C2440 and S3C2442 Mobile CPU support (not S3C2443)

 uart initialisation */

 register our io-tables */

 rename any peripherals used differing from the s3c2410 */

 Since the S3C2442 and S3C2440 share items, put both subsystems here */

/* need to register the subsystem before we actually register the device, and

 * we also need to ensure that it has been initialised before any of the

 * drivers even try to use it (even if not on an s3c2440 based system)

 * as a driver which may support both 2410 and 2440 may try and use it.

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2010 Maurus Cuelenaere

 Labels according to the SmartQ manual */

 Maintainer: Maurus Cuelenaere <mcuelenaere AT gmail DOT com> */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (C) 2011 Samsung Electronics Co.Ltd

 Author: Joonyoung Shim <jy0922.shim@samsung.com>

 set clock frequency for PLL */

 default reference clock */

 TODO: select external clock/oscillator */

 set to normal OTG PHY */

 reset OTG PHY and Link */

 at-least 10uS */

 SPDX-License-Identifier: GPL-2.0



 mach-hmt.c - Platform code for Airgoo HMT



 Copyright 2009 Peter Korsgaard <jacmet@sunsite.dk>

	/*

	 * translate from CIELUV/CIELAB L*->brightness, E.G. from

	 * perceived luminance to light output. Assumes range 0..25600

 Y = Yn * L / 903.3 */

 Y = Yn * ((L + 16) / 116 )^3 */

 405566 clocks per frame => 60Hz refresh requires 24333960Hz clock */

 left function keys */

 right function keys - red */

 right function keys - green */

 right function keys - blue */

 Maintainer: Peter Korsgaard <jacmet@sunsite.dk> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2009-2011 Samsung Electronics Co., Ltd.

		http:


 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

      Ben Dooks <ben@simtec.co.uk>

      http:


 Samsung - GPIOlib support

/*

 * samsung_gpio_setcfg_2bit - Samsung 2bit style GPIO configuration.

 * @chip: The gpio chip that is being configured.

 * @off: The offset for the GPIO being configured.

 * @cfg: The configuration value to set.

 *

 * This helper deal with the GPIO cases where the control register

 * has two bits of configuration per gpio, which have the following

 * functions:

 *	00 = input

 *	01 = output

 *	1x = special function

/*

 * samsung_gpio_getcfg_2bit - Samsung 2bit style GPIO configuration read.

 * @chip: The gpio chip that is being configured.

 * @off: The offset for the GPIO being configured.

 *

 * The reverse of samsung_gpio_setcfg_2bit(). Will return a value which

 * could be directly passed back to samsung_gpio_setcfg_2bit(), from the

 * S3C_GPIO_SPECIAL() macro.

 this conversion works for IN and OUT as well as special mode */

/*

 * samsung_gpio_setcfg_4bit - Samsung 4bit single register GPIO config.

 * @chip: The gpio chip that is being configured.

 * @off: The offset for the GPIO being configured.

 * @cfg: The configuration value to set.

 *

 * This helper deal with the GPIO cases where the control register has 4 bits

 * of control per GPIO, generally in the form of:

 *	0000 = Input

 *	0001 = Output

 *	others = Special functions (dependent on bank)

 *

 * Note, since the code to deal with the case where there are two control

 * registers instead of one, we do not have a separate set of functions for

 * each case.

/*

 * samsung_gpio_getcfg_4bit - Samsung 4bit single register GPIO config read.

 * @chip: The gpio chip that is being configured.

 * @off: The offset for the GPIO being configured.

 *

 * The reverse of samsung_gpio_setcfg_4bit(), turning a gpio configuration

 * register setting into a value the software can use, such as could be passed

 * to samsung_gpio_setcfg_4bit().

 *

 * @sa samsung_gpio_getcfg_2bit

 this conversion works for IN and OUT as well as special mode */

/*

 * s3c24xx_gpio_setcfg_abank - S3C24XX style GPIO configuration (Bank A)

 * @chip: The gpio chip that is being configured.

 * @off: The offset for the GPIO being configured.

 * @cfg: The configuration value to set.

 *

 * This helper deal with the GPIO cases where the control register

 * has one bit of configuration for the gpio, where setting the bit

 * means the pin is in special function mode and unset means output.

 Map output to 0, and SFN2 to 1 */

/*

 * s3c24xx_gpio_getcfg_abank - S3C24XX style GPIO configuration read (Bank A)

 * @chip: The gpio chip that is being configured.

 * @off: The offset for the GPIO being configured.

 *

 * The reverse of s3c24xx_gpio_setcfg_abank() turning an GPIO into a usable

 * GPIO configuration value.

 *

 * @sa samsung_gpio_getcfg_2bit

 * @sa samsung_gpio_getcfg_4bit

/*

 * Default routines for controlling GPIO, based on the original S3C24XX

 * GPIO functions which deal with the case where each gpio bank of the

 * chip is as following:

 *

 * base + 0x00: Control register, 2 bits per gpio

 *	        gpio n: 2 bits starting at (2*n)

 *		00 = input, 01 = output, others mean special-function

 * base + 0x04: Data register, 1 bit per gpio

 *		bit n: data bit n

/*

 * The samsung_gpiolib_4bit routines are to control the gpio banks where

 * the gpio configuration register (GPxCON) has 4 bits per GPIO, as the

 * following example:

 *

 * base + 0x00: Control register, 4 bits per gpio

 *		gpio n: 4 bits starting at (4*n)

 *		0000 = input, 0001 = output, others mean special-function

 * base + 0x04: Data register, 1 bit per gpio

 *		bit n: data bit n

 *

 * Note, since the data register is one bit per gpio and is at base + 0x4

 * we can use samsung_gpiolib_get and samsung_gpiolib_set to change the

 * state of the output.

/*

 * The next set of routines are for the case where the GPIO configuration

 * registers are 4 bits per GPIO but there is more than one register (the

 * bank has more than 8 GPIOs.

 *

 * This case is the similar to the 4 bit case, but the registers are as

 * follows:

 *

 * base + 0x00: Control register, 4 bits per gpio (lower 8 GPIOs)

 *		gpio n: 4 bits starting at (4*n)

 *		0000 = input, 0001 = output, others mean special-function

 * base + 0x04: Control register, 4 bits per gpio (up to 8 additions GPIOs)

 *		gpio n: 4 bits starting at (4*n)

 *		0000 = input, 0001 = output, others mean special-function

 * base + 0x08: Data register, 1 bit per gpio

 *		bit n: data bit n

 *

 * To allow us to use the samsung_gpiolib_get and samsung_gpiolib_set

 * routines we store the 'base + 0x4' address so that these routines see

 * the data register at ourchip->base + 0x04.

 The next set of routines are for the case of s3c24xx bank a */

/*

 * CONFIG_S3C_GPIO_TRACK enables the tracking of the s3c specific gpios

 * for use with the configuration calls, and other parts of the s3c gpiolib

 * support code.

 *

 * Not all s3c support code will need this, as some configurations of cpu

 * may only support one or two different configuration options and have an

 * easy gpio to samsung_gpio_chip mapping function. If this is the case, then

 * the machine support file should provide its own samsung_gpiolib_getchip()

 * and any other necessary functions.

 CONFIG_S3C_GPIO_TRACK */

/*

 * samsung_gpiolib_add() - add the Samsung gpio_chip.

 * @chip: The chip to register

 *

 * This is a wrapper to gpiochip_add() that takes our specific gpio chip

 * information and makes the necessary alterations for the platform and

 * notes the information for use with the configuration systems and any

 * other parts of the system.

 gpiochip_add() prints own failure message on error. */

 skip banks not present on SoC */

/*

 * samsung_gpiolib_add_4bit_chips - 4bit single register GPIO config.

 * @chip: The gpio chip that is being configured.

 * @nr_chips: The no of chips (gpio ports) for the GPIO being configured.

 *

 * This helper deal with the GPIO cases where the control register has 4 bits

 * of control per GPIO, generally in the form of:

 * 0000 = Input

 * 0001 = Output

 * others = Special functions (dependent on bank)

 *

 * Note, since the code to deal with the case where there are two control

 * registers instead of one, we do not have a separate set of function

 * (samsung_gpiolib_add_4bit2_chips)for each case.

 GPIOS for the S3C2443 and later devices. */

/*

 * GPIO bank summary:

 *

 * Bank	GPIOs	Style	SlpCon	ExtInt Group

 * A	8	4Bit	Yes	1

 * B	7	4Bit	Yes	1

 * C	8	4Bit	Yes	2

 * D	5	4Bit	Yes	3

 * E	5	4Bit	Yes	None

 * F	16	2Bit	Yes	4 [1]

 * G	7	4Bit	Yes	5

 * H	10	4Bit[2]	Yes	6

 * I	16	2Bit	Yes	None

 * J	12	2Bit	Yes	None

 * K	16	4Bit[2]	No	None

 * L	15	4Bit[2] No	None

 * M	6	4Bit	No	IRQ_EINT

 * N	16	2Bit	No	IRQ_EINT

 * O	16	2Bit	Yes	7

 * P	15	2Bit	Yes	8

 * Q	9	2Bit	Yes	9

 *

 * [1] BANKF pins 14,15 do not form part of the external interrupt sources

 * [2] BANK has two control registers, GPxCON0 and GPxCON1

 TODO: cleanup soc_is_* */

	/*

	 * Currently there are two drivers that can provide GPIO support for

	 * Samsung SoCs. For device tree enabled platforms, the new

	 * pinctrl-samsung driver is used, providing both GPIO and pin control

	 * interfaces. For legacy (non-DT) platforms this driver is used.

 SPDX-License-Identifier: GPL-2.0



 Samsung's S3C64XX generic DMA support using amba-pl08x driver.



 Copyright (c) 2013 Tomasz Figa <tomasz.figa@gmail.com>

/*

 * DMA0

/*

 * DMA1

 Set all DMA configuration to be DMA, not SDMA */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2003-2008 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 http:
 macros for virtual address mods for the io space entries */

 macros to modify the physical addresses for io space */

 ISA IO areas */

 bast CPLD control registers, and external interrupt controls */

 PC104 IRQ mux */

 peripheral space... one for each of fast/slow/byte/16bit */

  /* note, ide is only decoded in word space, even though some registers

 slow, byte */

 slow, word */

 fast, byte */

 fast, word */

 port 2 is not actually used */

 NAND Flash on BAST board */

 ensure that an nRESET is not generated on resume. */

/* the bast has 4 selectable slots for nand-flash, the three

 * on-board chip areas, as well as the external SmartMedia

 * slot.

 *

 * Note, there is no current hot-plug support for the SmartMedia

 * socket.

 DM9000 */

/* for the moment we limit ourselves to 16bit IO until some

 * better IO routines can be written and tested

 serial devices */

/* we have devices on the bus which cannot work much over the

 * standard 100KHz i2c bus frequency

 Asix AX88796 10/100 ethernet controller */

 Asix AX88796 10/100 ethernet controller parallel port */

 LCD/VGA controller */

 LCD/VGA controller */

 I2C devices fitted. */

 LCD contrast (0-6.6V) */

 LED current feedback */

 LCD feedback (0-6.6V) */

 Vcore (1.8-2.0V), Vref 3.3V  */

 Standard BAST devices */

 cat /sys/devices/platform/s3c24xx-adc/s3c-hwmon/in_0

 7.8usec */

 Maintainer: Ben Dooks <ben@simtec.co.uk> */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2004-2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 S3C24XX Power Manager (Suspend-To-RAM) support



 See Documentation/arm/samsung-s3c24xx/suspend.rst for more information



 Parts based on arch/arm/mach-pxa/pm.c



 Thanks to Dimitry Andric for debugging

	/* we restore the timings here, with the proviso that the board

	 * brings the system up in an slower, or equal frequency setting

	 * to the original system.

	 *

	 * if we cannot guarantee this, then things are going to go very

	 * wrong here, as we modify the refresh and both pll settings.

/* s3c_pm_check_resume_pin

 *

 * check to see if the pin is configured correctly for sleep mode, and

 * make any necessary adjustments if it is not

/* s3c_pm_configure_extint

 *

 * configure all external interrupt pins

	/* for each of the external interrupts (EINT0..EINT15) we

	 * need to check whether it is an external interrupt source,

	 * and then configure it as an input if it is not

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011 Wolfson Microelectronics, plc

 Copyright (c) 2011 Samsung Electronics Co., Ltd.

		http:
 Setup PWRCFG to enter idle mode */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2010 Samsung Electronics Co., Ltd.

		http:


 S3C2416 - PM support (Based on Ben Dooks' S3C2412 PM support)

 enable wakeup sources regardless of battery state */

 set the mode as sleep, 2BED represents "Go to BED" */

 Aborting suspend */

	/*

	 * write the magic value u-boot uses to check for resume into

	 * the INFORM0 register, and ensure INFORM1 is set to the

	 * correct address to resume from.

 unset the return-from-sleep amd inform flags */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011 Samsung Electronics Co., Ltd.

		http:


 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 Common Codes for S3C64XX machines

/*

 * NOTE: Code in this file is not used when booting with Device Tree support.

 External clock frequency */

 uart registration process */

 table of supported CPUs */

 minimal IO mapping */

/*

 * note, for the boot process to work we have to keep the UART

 * virtual address aligned to an 1MiB boundary for the L1

 * mapping the head code makes. We keep the UART virtual address

 * aligned and add in the offset when we load the value here.

 read cpu identification code */

 initialise the io descriptors we need for initialisation */

 detect cpu id */

 Not applicable when using DT. */

/*

 * setup the sources the vic should advertise resume

 * for, even though it is not doing the wake

 * (set_irq_wake needs to be valid)

 initialise the pair of VICs */

 compiler should in-line these */

 set the GPIO pin appropriately */

/* s3c_irq_demux_eint

 *

 * This function demuxes the IRQ from the group0 external interrupts,

 * from IRQ_EINT(0) to IRQ_EINT(27). It is designed to be inlined into

 * the specific handlers s3c_irq_demux_eintX_Y.

 On DT-enabled systems EINTs are handled by pinctrl-s3c64xx driver. */

 SPDX-License-Identifier: GPL-2.0



 Samsung's S3C2416 flattened device tree enabled machine



 Copyright (c) 2012 Heiko Stuebner <heiko@sntech.de>



 based on mach-exynos/mach-exynos4-dt.c



 Copyright (c) 2010-2011 Samsung Electronics Co., Ltd.

		http:
 Copyright (c) 2010-2011 Linaro Ltd.

		www.linaro.org

 Maintainer: Heiko Stuebner <heiko@sntech.de> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:
 framebuffer and LCD setup. */

/* GPF15 = LCD backlight control

 * GPF13 => Panel power

 * GPN5 = LCD nRESET signal

 * PWM_TOUT1 => backlight brightness

 fire nRESET on power up */

 405566 clocks per frame => 60Hz refresh requires 24333960Hz clock */

/*

 * Configuring Ethernet on SMDK6410

 *

 * Both CS8900A and LAN9115 chips share one chip select mediated by CFG6.

 * The constant address below corresponds to nCS1

 *

 *  1) Set CFGB2 p3 ON others off, no other CFGB selects "ethernet"

 *  2) CFG6 needs to be switched to "LAN9115" side

 KEY(row, col, keycode) */

 ARM core */

 VDDARM, BUCK1 on J5 */

 VDD_INT, BUCK2 on J5 */

 VDD_HI, LDO3 on J5 */

 VDD_PLL, LDO2 on J5 */

 VDD_UH_MMC, LDO5 on J5 */

 VCCM3BT, LDO8 on J5 */

 VCCM2MTV, LDO11 on J5 */

 VDD_LCD, LDO12 on J5 */

 VDD_OTGI, LDO9 on J5 */

 VDD_OTG, LDO14 on J5 */

 VDD_ALIVE, LDO15 on J5 */

 VDD_AUDIO, VLDO_AUDIO on J5 */

 S3C64xx internal logic & PLL */

 Memory */

 USB, EXT, PCM, ADC/DAC, USB, MMC */

 OTGi/1190-EV1 HPVDD & AVDD */

 Configure the IRQ line */

 Instantiate the regulators */

 Configure the IRQ line */

 WM8580 */

 DCDC1 */

 DCDC2 */

 LDO1 */

 LDO2 */

 LDO3 NC */

 LDO4 */

 LDO5 */

 LDO6 */

 LDO7 */

 LDO8 */

 LDO9 */

 LDO10 */

 LDO11 */

 Samsung S524AD0XD1 */

 LCD Backlight data */

 Intentionally blank */

 set the LCD type */

 remove the lcd bypass */

 configure nCS1 width to 16 bits */

 set timing for nCS1 suitable for ethernet chip */

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006-2009 Victor Chukhantsev, Denis Grigoriev,

 Copyright (c) 2007-2010 Vasily Khoruzhick



 based on smdk2440 written by Ben Dooks

 IR port */

 Charge status S3C2410_GPF(3) */

 GPC11-GPC15->OUTPUT */

 Wait a bit here... */

 GPD2-GPD7->OUTPUT */

 GPD11-GPD15->OUTPUT */

 GPD2-GPD7->1, GPD11-GPD15->1 */

 Wait a bit here...*/

 GPB0->OUTPUT, GPB0->0 */

 GPC1-GPC4->OUTPUT, GPC1-4->0 */

 GPC15-GPC11->0 */

 GPD15-GPD11->0, GPD2->GPD7->0 */

 GPC6->0, GPC7->0, GPC5->0 */

 GPB1->OUTPUT, GPB1->0 */

 GPC0->0, GPC10->0 */

 LED driver need a "push" to power on */

			/* Warm up backlight for one period of PWM.

			 * Without this trick its almost impossible to

			 * enable backlight with low brightness value

	/*

	 * Call pwm_init_state to initialize .polarity and .period. The other

	 * values are fixed in this driver.

 Card detect S3C2410_GPF(5) */

 Write protect S3C2410_GPH(8) */

 bus pins */

 setup PM */

	/* Turn off suspend on both USB ports, and switch the

 mmc power is disabled by default */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 H1940 and RX3715 need to reserve this for suspend */

 Maintainers: Vasily Khoruzhick */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 Base S3C64XX I2C bus 0 gpio configuration

 don't need the contents */

 SPDX-License-Identifier: GPL-2.0+



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 S3C series GPIO PM code

 PM GPIO helpers */

	/* GPACON only has one bit per control / data and no PULLUPs.

 first set all SFN bits to SFN */

 now set all the other bits */

/* Test whether the given masked+shifted bits of an GPIO configuration

 Test if the given masked+shifted GPIO configuration is an input */

 Test if the given masked+shifted GPIO configuration is an output */

/**

 * samsung_gpio_pm_2bit_resume() - restore the given GPIO bank

 * @chip: The chip information to resume.

 *

 * Restore one of the GPIO banks that was saved during suspend. This is

 * not as simple as once thought, due to the possibility of glitches

 * from the order that the CON and DAT registers are set in.

 *

 * The three states the pin can be are {IN,OUT,SFN} which gives us 9

 * combinations of changes to check. Three of these, if the pin stays

 * in the same configuration can be discounted. This leaves us with

 * the following:

 *

 * { IN => OUT }  Change DAT first

 * { IN => SFN }  Change CON first

 * { OUT => SFN } Change CON first, so new data will not glitch

 * { OUT => IN }  Change CON first, so new data will not glitch

 * { SFN => IN }  Change CON first

 * { SFN => OUT } Change DAT first, so new data will not glitch [1]

 *

 * We do not currently deal with the UP registers as these control

 * weak resistors, so a small delay in change should not need to bring

 * these into the calculations.

 *

 * [1] this assumes that writing to a pin DAT whilst in SFN will set the

 *     state for when it is next output.

 restore GPIO pull-up settings */

	/* Create a change_mask of all the items that need to have

	 * their CON value changed before their DAT value, so that

	 * we minimise the work between the two settings.

 If there is no change, then skip */

 If both are special function, then skip */

 Change is IN => OUT, do not change now */

 Change is SFN => OUT, do not change now */

		/* We should now be at the case of IN=>SFN,

 Write the new CON settings */

 Now change any items that require DAT,CON */

 If there is no change, then skip */

 If both are special function, then skip */

 Change is IN => OUT, do not change now */

 Change is SFN => OUT, do not change now */

		/* We should now be at the case of IN=>SFN,

 First, modify the CON settings */

 Now change the configurations that require DAT,CON */

 CONFIG_ARCH_S3C64XX */

/**

 * samsung_pm_save_gpio() - save gpio chip data for suspend

 * @ourchip: The chip for suspend.

/**

 * samsung_pm_save_gpios() - Save the state of the GPIO banks.

 *

 * For all the GPIO banks, save the state of each one ready for going

 * into a suspend mode.

/**

 * samsung_pm_resume_gpio() - restore gpio chip data after suspend

 * @ourchip: The suspended chip.

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2009-2011 Samsung Electronics Co., Ltd.

		http:


 Samsung CPU Support

		/*

		 * S3C6400 has the ID register in a different place,

		 * and needs a write before it can be read.

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2010 Samsung Electronics Co., Ltd.

		http:


 S3C64XX setup information for IDE

 Independent CF interface, CF chip select configuration */

 Set XhiDATA[15:0] pins as CF Data[15:0] */

 Set XhiADDR[2:0] pins as CF ADDR[2:0] */

 Set Xhi ctrl pins as CF ctrl pins(IORDY, IOWR, IORD, CE[0:1]) */

 SPDX-License-Identifier: GPL-2.0

 linux/arch/arm/mach-s3c2440/mach-smdk2440.c



 Copyright (c) 2004-2005 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 http:


 Thanks to Dimity Andric and TomTom for the loan of an SMDK2440.

 ISA IO Space map (memory space selected by A24) */

 IR port */

 LCD driver info */

 HCLK 60 MHz, divisor 10 */

 currently setup by downloader */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 Thanks to Dimity Andric (TomTom) and Steven Ryu (Samsung) for the

 loans of SMDK2413 to work with.

#include <asm/debug-ll.h>

 IR port */

{	/* Turn off suspend on both USB ports, and switch the

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2008 Ramax Lo <ramaxlo@gmail.com>

      Based on mach-anubis.c by Ben Dooks <ben@simtec.co.uk>

      and modifications by SBZ <sbz@spgui.org> and

      Weibing <http:
      Michel Pollet <buserror@gmail.com>



 For product information, visit https:
 nothing to declare, move along */

 USB device UDC support */

 LCD timing and setup */

/*

 * This macro simplifies the table bellow

 mini2440 + 3.5" TFT + touchscreen */

 The 3.5 is quite fast */

 x timing */

 y timing */

 refresh rate */

 mini2440 + 7" TFT + touchscreen */

 the 7" runs slower */

 x timing */

 y timing */

 refresh rate */

	/* The VGA shield can outout at several resolutions. All share

	 * the same timings, however, anything smaller than 1024x768

	 * will only be displayed in the top left corner of a 1024x768

	 * XGA output unless you add optional dip switches to the shield.

	 * Therefore timings for other resolutions have been omitted here.

 y timing */

 x timing */

			24),	/* refresh rate, maximum stable,

				 * tested with the FPGA shield

 mini2440 + 3.5" TFT (LCD-W35i, LQ035Q1DG06 type) + touchscreen*/

 clock */

 xres, margin_right, margin_left, hsync */

 yres, margin_top, margin_bottom, vsync */

 refresh rate */

 todo - put into gpio header */

 not constant! see init */

	/* Enable VD[2..7], VD[10..15], VD[18..23] and VCLK, syncs, VDEN

	 * and disable the pull down resistors on pins we are using for LCD

	 * data.

 MMC/SD  */

 Card detect S3C2410_GPG(8) */

 Write protect S3C2410_GPH(8) */

 bus pins */

 NAND Flash on MINI2440 board */

		/* 5 megabytes, for a kernel with no modules

		 * or a uImage with a ramdisk attached

 we use u-boot to create a BBT */

 DM9000AEP 10/100 ethernet controller */

/*

 * The DM9000 has no eeprom, and it's MAC address is set by

 * the bootloader before starting the kernel.

/*  CON5

 *	+--+	 /-----\

 *	|  |    |	|

 *	|  |	|  BAT	|

 *	|  |	 \_____/

 *	|  |

 *	|  |  +----+  +----+

 *	|  |  | K5 |  | K1 |

 *	|  |  +----+  +----+

 *	|  |  +----+  +----+

 *	|  |  | K4 |  | K2 |

 *	|  |  +----+  +----+

 *	|  |  +----+  +----+

 *	|  |  | K6 |  | K3 |

 *	|  |  +----+  +----+

 *	  .....

 K1 */

 K2 */

 K3 */

 K4 */

 K5 */

	/* this pin is also known as TCLK1 and seems to already

	 * marked as "in use" somehow in the kernel -- possibly wrongly

 K6 */

 LEDS */

 AUDIO */

/*

 * I2C devices

/*

 * mini2440_features string

 *

 * t = Touchscreen present

 * b = backlight control

 * c = camera [TODO]

 * 0-9 LCD configuration

 *

 tft screen */

 Parse the feature string */

 turn LCD on */

 Turn the backlight early on */

 remove pullup on optional PWM backlight -- unused on 3.5 and 7"s */

 mark the key as input, without pullups (there is one on the board) */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 Disable pull-up on the LED lines */

 Add lookups for the lines */

 the optional features */

 Maintainer: Michel Pollet <buserror@gmail.com> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2010 Samsung Electronics Co., Ltd.

                     http:


 Based on S3C24XX setup for i2c device

 don't need the contents */

/**

 * s3c24xx_ts_cfg_gpio - configure gpio for s3c2410 systems

 * @dev: Device to configure GPIO for (ignored)

 *

 * Configure the GPIO for the S3C2410 system, where we have external FETs

 * connected to the device (later systems such as the S3C2440 integrate

 * these into the device).

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2013 Samsung Electronics Co., Ltd.

	Tomasz Figa <t.figa@samsung.com>

 Copyright (C) 2008 Openmoko, Inc.

 Copyright (C) 2004-2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 Samsung common power management helper functions.

 helper functions to save and restore register state */

/**

 * s3c_pm_do_save() - save a set of registers for restoration on resume.

 * @ptr: Pointer to an array of registers.

 * @count: Size of the ptr array.

 *

 * Run through the list of registers given, saving their contents in the

 * array for later restoration when we wakeup.

/**

 * s3c_pm_do_restore() - restore register values from the save list.

 * @ptr: Pointer to an array of registers.

 * @count: Size of the ptr array.

 *

 * Restore the register values saved from s3c_pm_do_save().

 *

 * Note, we do not use S3C_PMDBG() in here, as the system may not have

 * restore the UARTs state yet

/**

 * s3c_pm_do_restore_core() - early restore register values from save list.

 * @ptr: Pointer to an array of registers.

 * @count: Size of the ptr array.

 *

 * This is similar to s3c_pm_do_restore() except we try and minimise the

 * side effects of the function in case registers that hardware might need

 * to work has been restored.

 *

 * WARNING: Do not put any debug in here that may effect memory or use

 * peripherals, as things may be changing!

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2003-2005 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 https:
 IR port */

 Board control latch control */

/*

 * Set lcd on or off

 Charge status S3C2410_GPF(3) */

 TODO Check backup volt multiplier */

 Card detect S3C2410_GPF(5) */

 Write protect S3C2410_GPH(8) */

 bus pins */

 wait for 3ac */

 setup PM */

 Add latch gpio chip, set latch initial value */

 H1940 and RX3715 need to reserve this for suspend */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

	/* Turn off suspend on both USB ports, and switch the

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Simtec Electronics

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:
/*

 * NOTE: Code in this file is not used when booting with Device Tree support.

 initialise device information early */

 the i2c devices are directly compatible with s3c2440 */

 VIC0 is missing IRQ7, VIC1 is fully populated. */

 Not applicable when using DT. */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2007 TinCanTools

	David Anders <danders@amltd.com>



 @History:

 derived from linux/arch/arm/mach-s3c2410/mach-bast.c, written by

 Ben Dooks <ben@simtec.co.uk>

 force read-only */

 bus pins */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2009 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:
/*

 * NOTE: Code in this file is not used when booting with Device Tree support.

 setup SDHCI */

 the i2c devices are directly compatible with s3c2440 */

	/* VIC0 does not have IRQS 5..7,

 Not applicable when using DT. */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2004 Nex Vision

   Guillaume GOURAT <guillaume.gourat@nexvision.fr>

 Device area */

 port 2 is not actually used */

 NOR Flash on NexVision OTOM board */

 Standard OTOM devices */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 Maintainer: Guillaume GOURAT <guillaume.gourat@nexvision.tv> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 S3C24XX Base setup for i2c device

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2003-2005 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 http:
 Initial IO mappings */

 our uart devices */

 uart registration process */

/* s3c2410_map_io

 *

 * register the standard cpu IO areas, and any passed in from the

 * machine specific initialisation.

/* Note, we would have liked to name this s3c2410-core, but we cannot

 * register two subsystems with the same name.

/* need to register the subsystem before we actually register the device, and

 * we also need to ensure that it has been initialised before any of the

 * drivers even try to use it (even if not on an s3c2410 based system)

 * as a driver which may support both 2410 and 2440 may try and use it.

 SPDX-License-Identifier: GPL-1.0+



 Copyright (c) 2008 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>, <ben-linux@fluff.org>



 Samsung ADC device core

/* This driver is designed to control the usage of the ADC block between

 * the touchscreen and any other drivers that may need to use it, such as

 * the hwmon driver.

 *

 * Priority will be given to the touchscreen driver, but as this itself is

 * rate limited it should not starve other requests which are processed in

 * order that they are received.

 *

 * Each user registers to get a client block which uniquely identifies it

 * and stores information such as the necessary functions to callback when

 * action is required.

 S3C24XX */

 S3C2443 */

 S3C2416, S3C2450 */

 S3C64XX */

 S5PV210, S5PC110, Exynos4210 */

 protected by adc_device.lock */

 We should really check that nothing is in progress. */

 S3C2416/S3C64XX/S5P ADC resolution is 12-bit */

 fire another conversion for this */

 Clear ADC interrupt */

 Enable 12-bit ADC resolution */

 Enable 12-bit ADC resolution */

 SPDX-License-Identifier: GPL-2.0



 HS-SPI device setup for S3C2443/S3C2416



 Copyright (C) 2011 Samsung Electronics Ltd.

		http:
 enable hsspi bit in misccr */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 Base S3C64XX setup information for 24bpp LCD framebuffer

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011 Samsung Electronics Co., Ltd.

		http:


 Base Samsung platform device definitions

 CONFIG_PLAT_S3C24XX */

 AC97 */

 CONFIG_CPU_S3C2440 */

 ADC */

 CONFIG_PLAT_S3C24XX */

 CONFIG_SAMSUNG_DEV_ADC */

 Camif Controller */

 CONFIG_CPU_S3C2440 */

 FB */

 CONFIG_S3C_DEV_FB */

 HWMON */

 CONFIG_S3C_DEV_HWMON */

 HSMMC */

 CONFIG_S3C_DEV_HSMMC */

 CONFIG_S3C_DEV_HSMMC1 */

 HSMMC2 */

 CONFIG_S3C_DEV_HSMMC2 */

 CONFIG_S3C_DEV_HSMMC3 */

 I2C */

 CONFIG_S3C_DEV_I2C1 */

 CONFIG_S3C_DEV_I2C2 */

CONFIG_S3C_DEV_I2C3 */

CONFIG_S3C_DEV_I2C4 */

CONFIG_S3C_DEV_I2C5 */

 CONFIG_S3C_DEV_I2C6 */

 CONFIG_S3C_DEV_I2C7 */

 I2S */

 CONFIG_PLAT_S3C24XX */

 IDE CFCON */

 CONFIG_SAMSUNG_DEV_IDE */

 KEYPAD */

 CONFIG_SAMSUNG_DEV_KEYPAD */

 LCD Controller */

 CONFIG_PLAT_S3C24XX */

 NAND */

/*

 * s3c_nand_copy_set() - copy nand set data

 * @set: The new structure, directly copied from the old.

 *

 * Copy all the fields from the NAND set field from what is probably __initdata

 * to new kernel memory. The code returns 0 if the copy happened correctly or

 * an error code for the calling function to display.

 *

 * Note, we currently do not try and look to see if we've already copied the

 * data in a previous set.

	/* note, if we get a failure in allocation, we simply drop out of the

	 * function. If there is so little memory available at initialisation

	 * time then there is little chance the system is going to run.

 now see if we need to copy any of the nand set data */

 set, even if we failed */

 CONFIG_S3C_DEV_NAND */

 ONENAND */

 CONFIG_S3C_DEV_ONENAND */

 CONFIG_S3C64XX_DEV_ONENAND1 */

 PWM Timer */

 CONFIG_SAMSUNG_DEV_PWM */

 RTC */

 CONFIG_PLAT_S3C24XX */

 CONFIG_S3C_DEV_RTC */

 SDI */

 Configure GPE5...GPE10 pins in SD mode */

	/* This is currently here to avoid a number of if (host->pdata)

 CONFIG_PLAT_S3C24XX */

 SPI */

 CONFIG_PLAT_S3C24XX */

 Touchscreen */

 CONFIG_PLAT_S3C24XX */

 CONFIG_SAMSUNG_DEV_TS */

 USB */

/*

 * s3c_ohci_set_platdata - initialise OHCI device platform data

 * @info: The platform data.

 *

 * This call copies the @info passed in and sets the device .platform_data

 * field to that copy. The @info is copied so that the original can be marked

 * __initdata.

 CONFIG_S3C_DEV_USB_HOST */

 USB Device (Gadget) */

 CONFIG_PLAT_S3C24XX */

 USB HSOTG */

 CONFIG_S3C_DEV_USB_HSOTG */

 USB High Spped 2.0 Device (Gadget) */

 CONFIG_PLAT_S3C24XX */

 WDT */

 CONFIG_S3C_DEV_WDT */

 Reject invalid configuration */

 CONFIG_S3C64XX_DEV_SPI0 */

 Reject invalid configuration */

 CONFIG_S3C64XX_DEV_SPI1 */

 Reject invalid configuration */

 CONFIG_S3C64XX_DEV_SPI2 */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2004-2005 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 S3C2442 core and lock support

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2009 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 S3C24XX CPU Frequency scaling - utils for S3C2410/S3C2440/S3C2442

/**

 * s3c2410_cpufreq_setrefresh - set SDRAM refresh value

 * @cfg: The frequency configuration

 *

 * Set the SDRAM refresh value appropriately for the configured

 * frequency.

	/* Reduce both the refresh time (in ns) and the frequency (in MHz)

	 * down to ensure that we do not overflow 32 bit numbers.

	 *

	 * This should work for HCLK up to 133MHz and refresh period up

	 * to 30usec.

 apply scale  */

/**

 * s3c2410_set_fvco - set the PLL value

 * @cfg: The frequency configuration

 SPDX-License-Identifier: GPL-2.0

 linux/arch/arm/mach-s3c2440/mach-nexcoder.c



 Copyright (c) 2004 Nex Vision

   Guillaume GOURAT <guillaume.gourat@nexvision.tv>



 Modifications:

     15-10-2004 GG  Created initial version

     12-03-2005 BJD Updated for release

#include <asm/debug-ll.h>

 nothing here yet */

 NOR Flash on NexVision NexCoder 2440 board */

 Standard Nexcoder devices */

 Initialize SCCB bus */

 IICSCL */

 IICSDA */

 Power up the sensor board */

 CAM_GPIO7 => nLDO_PWRDN */

 CAM_GPIO6 => CAM_PWRDN */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 Maintainer: Guillaume GOURAT <guillaume.gourat@nexvision.tv> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006-2007 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>

	Vincent Sanders <vince@arm.linux.org.uk>



 S3C2440/S3C2442 CPU PLL tables (12MHz Crystal)

 This array should be sorted in ascending order of the frequencies */

 FVco 600.000000 */

 FVco 640.000000 */

 FVco 720.000000 */

 FVco 800.000000 */

 FVco 880.000000 */

 FVco 960.000000 */

 FVco 600.000000 */

 FVco 640.000000 */

 FVco 680.000000 */

 FVco 720.000000 */

 FVco 760.000000 */

 FVco 800.000000 */

 FVco 840.000000 */

 FVco 880.000000 */

 FVco 920.000000 */

 FVco 960.000000 */

 FVco 600.000000 */

 FVco 620.000000 */

 FVco 640.000000 */

 FVco 660.000000 */

 FVco 680.000000 */

 FVco 700.000000 */

 FVco 720.000000 */

 FVco 740.000000 */

 FVco 760.000000 */

 FVco 780.000000 */

 FVco 800.000000 */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2008 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 Simtec NOR mapping

 SPDX-License-Identifier: GPL-1.0+



 Copyright (c) Arnaud Patard <arnaud.patard@rtp-net.org>



	    S3C2410 bluetooth "driver"

 Bluetooth control */

 Power on the chip */

 Reset the chip */

 Configures BT serial port GPIOs */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2003-2008 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 Machine support for Thorcom VR1000 board. Designed for Thorcom by

 Simtec Electronics, http:
 macros for virtual address mods for the io space entries */

 macros to modify the physical addresses for io space */

 ISA IO areas */

  CPLD control registers, and external interrupt controls */

 port 2 is not actually used */

 definitions for the vr1000 extra 16550 serial ports */

 DM9000 ethernet devices */

/* for the moment we limit ourselves to 16bit IO until some

 * better IO routines can be written and tested

 LEDS */

 I2C devices. */

 devices for this board */

 Disable pull-up on LED lines and register GPIO lookups */

 Maintainer: Ben Dooks <ben@simtec.co.uk> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2008-2009 Samsung Electronics

 REVISIT: NCP uses only serial 1, 2 */

 Maintainer: Samsung Electronics */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2007 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 http:


 Thanks to Samsung for the loan of an SMDK2443

 ISA IO Space map (memory space selected by A24) */

 IR port */

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 S3C series CPU initialisation

/*

 * NOTE: Code in this file is not used on S3C64xx when booting with

 * Device Tree support.

/* s3c24xx_init_clocks

 *

 * Initialise the clock subsystem and associated information from the

 * given master crystal value.

 *

 * xtal  = 0 -> use default PLL crystal value (normally 12MHz)

 *      != 0 -> PLL crystal value in Hz

 uart management */

/* s3c24xx_init_uartdevs

 *

 * copy the specified platform data and configuration into our central

 * set of devices, before the data is thrown away after the init process.

 *

 * This also fills in the array passed to the serial driver for the

 * early initialisation of the console.

 init is only needed for ATAGS based platforms */

 do the correct init for cpu

 Not needed when booting with device tree. */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011 Samsung Electronics Co., Ltd.

              http:


 Common infrastructure for PWM Backlight for Samsung boards

 Configure GPIO pin with specific GPIO function for PWM timer */

/* Initialize few important fields of platform_pwm_backlight_data

 * structure with default values. These fields can be overridden by

 * board-specific values sent from machine file.

 * For ease of operation, these fields are initialized with values

 * used by most samsung boards.

 * Users has the option of sending info about other parameters

 * for their specific boards

/* samsung_bl_set - Set board specific data (if any) provided by user for

 * PWM Backlight control and register specific PWM and backlight device.

 * @gpio_info:	structure containing GPIO info for PWM timer

 * @bl_data:	structure containing Backlight control data

 Copy board specific data provided by user */

 Register the Backlight dev */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2004 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 http:


 Power Management helpers for Simtec S3C24XX implementations

/* pm_simtec_init

 *

 * enable the power management functions

 check which machine we are running on */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

      Ben Dooks <ben@simtec.co.uk>

      http:


 S3C64XX - Interrupt handling Power Management

/*

 * NOTE: Code in this file is not used when booting with Device Tree support.

/* We handled all the IRQ types in this code, to save having to make several

 * small files to handle each different type separately. Having the EINT_GRP

 * code here shouldn't be as much bloat as the IRQ table space needed when

 * they are enabled. The added benefit is we ensure that these registers are

 * in the same state as we suspended.

 Appropriate drivers (pinctrl, uart) handle this when using DT. */

 SPDX-License-Identifier: GPL-2.0



 (C) 2006 Thomas Gleixner <tglx@linutronix.de>



 Derived from mach-smdk2413.c - (C) 2006 Simtec Electronics

/* choose a set of timings which should suit most 512Mbit

 * chips and beyond.

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2010 Maurus Cuelenaere

 Labels according to the SmartQ manual */

 Maintainer: Maurus Cuelenaere <mcuelenaere AT gmail DOT com> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 Common code for SMDK2410 and SMDK2440 boards



 http:
 LED devices */

 NAND parititon from 2.4.18-swl5 */

/* choose a set of timings which should suit most 512Mbit

 * chips and beyond.

 devices we initialise */

 Disable pull-up on the LED lines */

 Add lookups for the lines */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 S3C2410 (and compatible) Power Manager (Suspend-To-RAM) support

 ensure at least GSTATUS3 has the resume address */

 generate check for the bootloader to check on resume */

	/* RX3715 and RX1950 use similar to H1940 code and the

 generate check for the bootloader to check on resume */

		/* According to S3C2442 user's manual, page 7-17,

		 * when the system is operating in NAND boot mode,

		 * the hardware pin configuration - EINT[23:21] 

		 * must be set as input for starting up after

		 * wakeup from sleep mode

 unset the return-from-sleep flag, to ensure reset */

 register ourselves */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2010 Ben Dooks <ben-linux@fluff.org>



 Support for wakeup mask interrupts on newer SoCs

 bit of a liberty to read this directly from irq_data. */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2006 American Microsystems Limited

	David Anders <danders@amltd.com>



 @History:

 derived from linux/arch/arm/mach-s3c2410/mach-bast.c, written by

 Ben Dooks <ben@simtec.co.uk>

 force read-only */

 bus pins */

 HCLK = 100MHz */

 configure the suspend/resume status pin */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * S3C24XX IRQ handling

 *

 * Copyright (c) 2003-2004 Simtec Electronics

 *	Ben Dooks <ben@simtec.co.uk>

 * Copyright (c) 2012 Heiko Stuebner <heiko@sntech.de>

 data gets filled during init */

/*

 * Structure holding the controller data

 * @reg_pending		register holding pending irqs

 * @reg_intpnd		special register intpnd in main intc

 * @reg_mask		mask register

 * @domain		irq_domain of the controller

 * @parent		parent controller for ext and sub irqs

 * @irqs		irq-data, always s3c_irq_data[32]

/*

 * Array holding pointers to the global controller structs

 * [0] ... main_intc

 * [1] ... sub_intc

 * [2] ... main_intc2 on s3c2416

		/* check to see if we need to mask the parent IRQ

		 * The parent_irq is always in main_intc, so the hwirq

		 * for find_mapping does not need an offset in any case.

 Set the GPIO to external interrupt mode */

 Set the external interrupt to pointed trigger type */

	/* we're using individual domains for the non-dt case

	 * and one big domain for the dt case where the subintc

	 * starts at hwirq number 32.

 non-dt machines use individual domains */

	/* We have a problem that the INTOFFSET register does not always

	 * show one interrupt. Occasionally we get two interrupts through

	 * the prioritiser, and this causes the INTOFFSET register to show

	 * what looks like the logical-or of the two interrupt numbers.

	 *

	 * Thanks to Klaus, Shannon, et al for helping to debug this problem

	/* Find the bit manually, when the offset is wrong.

	 * The pending register only ever contains the one bit of the next

	 * interrupt to handle.

		/*

		 * For platform based machines, neither ERR nor NULL can happen here.

		 * The s3c24xx_handle_irq() will be set as IRQ handler iff this succeeds:

		 *

		 *    s3c_intc[0] = s3c24xx_init_intc()

		 *

		 * If this fails, the next calls to s3c24xx_init_intc() won't be executed.

		 *

		 * For DT machine, s3c_init_intc_of() could set the IRQ handler without

		 * setting s3c_intc[0] only if it was called with num_ctrl=0. There is no

		 * such code path, so again the s3c_intc[0] will have a valid pointer if

		 * set_handle_irq() is called.

		 *

		 * Therefore in s3c24xx_handle_irq(), the s3c_intc[0] is always something.

/**

 * s3c24xx_set_fiq - set the FIQ routing

 * @irq: IRQ number to route to FIQ on processor.

 * @ack_ptr: pointer to a location for storing the bit mask

 * @on: Whether to route @irq to the FIQ, or to remove the FIQ routing.

 *

 * Change the state of the IRQ to FIQ routing depending on @irq and @on. If

 * @on is true, the @irq is checked to see if it can be routed and the

 * interrupt controller updated to route the IRQ. If @on is false, the FIQ

 * routing is cleared, regardless of which @irq is specified.

 *

 * returns the mask value for the register.

 attach controller pointer to irq_data */

 set handler and flags */

		/* On the S3C2412, the EINT0to3 have a parent irq

		 * but need the s3c_irq_eint0t4 chip

 attach the demuxer to the parent irq */

 if intpnd is set, read the next pending irq from there */

 static mapping */

	/* select the correct data for the controller.

	 * Need to hard code the irq num start and offset

	 * to preserve the static mapping for now

 now that all the data is complete, init the irq-domain */

 reserved */

 reserved */

 reserved */

 reserved */

 EINT4 */

 EINT5 */

 EINT6 */

 EINT7 */

 EINT8 */

 EINT9 */

 EINT10 */

 EINT11 */

 EINT12 */

 EINT13 */

 EINT14 */

 EINT15 */

 EINT16 */

 EINT17 */

 EINT18 */

 EINT19 */

 EINT20 */

 EINT21 */

 EINT22 */

 EINT23 */

 EINT0 */

 EINT1 */

 EINT2 */

 EINT3 */

 EINT4to7 */

 EINT8to23 */

 reserved */

 nBATT_FLT */

 TICK */

 WDT */

 TIMER0 */

 TIMER1 */

 TIMER2 */

 TIMER3 */

 TIMER4 */

 UART2 */

 LCD */

 DMA0 */

 DMA1 */

 DMA2 */

 DMA3 */

 SDI */

 SPI0 */

 UART1 */

 reserved */

 USBD */

 USBH */

 IIC */

 UART0 */

 SPI1 */

 RTC */

 ADCPARENT */

 UART0-RX */

 UART0-TX */

 UART0-ERR */

 UART1-RX */

 UART1-TX */

 UART1-ERR */

 UART2-RX */

 UART2-TX */

 UART2-ERR */

 TC */

 ADC */

 EINT0 */

 EINT1 */

 EINT2 */

 EINT3 */

 EINT4to7 */

 EINT8to23 */

 reserved */

 nBATT_FLT */

 TICK */

 WDT */

 TIMER0 */

 TIMER1 */

 TIMER2 */

 TIMER3 */

 TIMER4 */

 UART2 */

 LCD */

 DMA0 */

 DMA1 */

 DMA2 */

 DMA3 */

 SDI/CF */

 SPI0 */

 UART1 */

 reserved */

 USBD */

 USBH */

 IIC */

 UART0 */

 SPI1 */

 RTC */

 ADCPARENT */

 EINT0 */

 EINT1 */

 EINT2 */

 EINT3 */

 EINT4 */

 EINT5 */

 EINT6 */

 EINT7 */

 EINT8 */

 EINT9 */

 EINT10 */

 EINT11 */

 EINT12 */

 EINT13 */

 EINT14 */

 EINT15 */

 EINT16 */

 EINT17 */

 EINT18 */

 EINT19 */

 EINT20 */

 EINT21 */

 EINT22 */

 EINT23 */

 UART0-RX */

 UART0-TX */

 UART0-ERR */

 UART1-RX */

 UART1-TX */

 UART1-ERR */

 UART2-RX */

 UART2-TX */

 UART2-ERR */

 TC */

 ADC */

 SDI */

 CF */

 EINT0 */

 EINT1 */

 EINT2 */

 EINT3 */

 EINT4to7 */

 EINT8to23 */

 reserved */

 nBATT_FLT */

 TICK */

 WDT/AC97 */

 TIMER0 */

 TIMER1 */

 TIMER2 */

 TIMER3 */

 TIMER4 */

 UART2 */

 LCD */

 DMA */

 UART3 */

 reserved */

 SDI1 */

 SDI0 */

 SPI0 */

 UART1 */

 NAND */

 USBD */

 USBH */

 IIC */

 UART0 */

 RTC */

 ADCPARENT */

 UART0-RX */

 UART0-TX */

 UART0-ERR */

 UART1-RX */

 UART1-TX */

 UART1-ERR */

 UART2-RX */

 UART2-TX */

 UART2-ERR */

 TC */

 ADC */

 reserved */

 reserved */

 reserved */

 reserved */

 LCD2 */

 LCD3 */

 LCD4 */

 DMA0 */

 DMA1 */

 DMA2 */

 DMA3 */

 DMA4 */

 DMA5 */

 UART3-RX */

 UART3-TX */

 UART3-ERR */

 WDT */

 AC97 */

 2D */

 reserved */

 reserved */

 reserved */

 PCM0 */

 reserved */

 I2S0 */

 EINT0 */

 EINT1 */

 EINT2 */

 EINT3 */

 EINT4to7 */

 EINT8to23 */

 CAM */

 nBATT_FLT */

 TICK */

 WDT/AC97 */

 TIMER0 */

 TIMER1 */

 TIMER2 */

 TIMER3 */

 TIMER4 */

 UART2 */

 LCD */

 DMA0 */

 DMA1 */

 DMA2 */

 DMA3 */

 SDI */

 SPI0 */

 UART1 */

 NFCON */

 USBD */

 USBH */

 IIC */

 UART0 */

 SPI1 */

 RTC */

 ADCPARENT */

 UART0-RX */

 UART0-TX */

 UART0-ERR */

 UART1-RX */

 UART1-TX */

 UART1-ERR */

 UART2-RX */

 UART2-TX */

 UART2-ERR */

 TC */

 ADC */

 CAM_C */

 CAM_P */

 WDT */

 AC97 */

 EINT0 */

 EINT1 */

 EINT2 */

 EINT3 */

 EINT4to7 */

 EINT8to23 */

 CAM */

 nBATT_FLT */

 TICK */

 WDT */

 TIMER0 */

 TIMER1 */

 TIMER2 */

 TIMER3 */

 TIMER4 */

 UART2 */

 LCD */

 DMA0 */

 DMA1 */

 DMA2 */

 DMA3 */

 SDI */

 SPI0 */

 UART1 */

 NFCON */

 USBD */

 USBH */

 IIC */

 UART0 */

 SPI1 */

 RTC */

 ADCPARENT */

 UART0-RX */

 UART0-TX */

 UART0-ERR */

 UART1-RX */

 UART1-TX */

 UART1-ERR */

 UART2-RX */

 UART2-TX */

 UART2-ERR */

 TC */

 ADC */

 CAM_C */

 CAM_P */

 EINT0 */

 EINT1 */

 EINT2 */

 EINT3 */

 EINT4to7 */

 EINT8to23 */

 CAM */

 nBATT_FLT */

 TICK */

 WDT/AC97 */

 TIMER0 */

 TIMER1 */

 TIMER2 */

 TIMER3 */

 TIMER4 */

 UART2 */

 LCD */

 DMA */

 UART3 */

 CFON */

 SDI1 */

 SDI0 */

 SPI0 */

 UART1 */

 NAND */

 USBD */

 USBH */

 IIC */

 UART0 */

 SPI1 */

 RTC */

 ADCPARENT */

 UART0-RX */

 UART0-TX */

 UART0-ERR */

 UART1-RX */

 UART1-TX */

 UART1-ERR */

 UART2-RX */

 UART2-TX */

 UART2-ERR */

 TC */

 ADC */

 CAM_C */

 CAM_P */

 reserved */

 LCD1 */

 LCD2 */

 LCD3 */

 LCD4 */

 DMA0 */

 DMA1 */

 DMA2 */

 DMA3 */

 DMA4 */

 DMA5 */

 UART3-RX */

 UART3-TX */

 UART3-ERR */

 WDT */

 AC97 */

 attach controller pointer to irq_data */

/* Translate our of irq notation

 * format: <ctrl_num ctrl_irq parent_irq type>

 parent_intc is always s3c_intc[0], so no offset */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2004-2006 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 Samsung S3C2440 Mobile CPU support

 change irq for watchdog */

 register suspend/resume handlers */

 register our system device for everything else */

 SPDX-License-Identifier: GPL-2.0+



 Copyright 2003-2005 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 http:
 handle PC104 ISA interrupts from the system CPLD */

/* table of ISA irq nos to the relevant mask... zero means

 * the irq is not implemented

 0 */

 1 */

 2 */

 3 */

 4 */

 5 */

 6 */

 7 */

 8 */

 9 */

 10 */

 11 */

 12 */

 13 */

 14 */

 15 */

 ack if we get an irq with nothing (ie, startup) */

 handle the IRQ */

 zap all the IRQs */

 register our IRQs */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2011 Wolfson Microelectronics plc

	Mark Brown <broonie@opensource.wolfsonmicro.com>



 Copyright 2011 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

 serial port setup */

 640x480 URT */

 405566 clocks per frame => 60Hz refresh requires 24333960Hz clock */

 2x6 keypad */

 KEY(row, col, keycode) */

 EINT 18 */

 EINT 11 */

 VDDARM is controlled by DVS1 connected to GPK(0) */

 mV */

 uA */

 GPIO5: DVS1_REQ - CMOS, DBVDD, active high */

 GPIO11: Touchscreen data - CMOS, DBVDD, active high*/

 GPIO12: Touchscreen pen down - CMOS, DBVDD, active high*/

 DCDC1 */

 DCDC2 */

 DCDC3 */

 LDO1 */

 LDO2 */

 LDO3 */

 LDO4 */

 LDO5 */

 LDO6 */

 LDO7 */

 LDO8 */

 LDO9 */

 LDO10 */

 LDO11 */

/*

 * VDDARM is eventually ending up as a regulator hanging on the MFD cell device

 * "wm831x-buckv.1" spawn from drivers/mfd/wm831x-core.c.

 *

 * From the note on the platform data we can see that this is clearly DVS1

 * and assigned as dcdc1 resource to the MFD core which sets .id of the cell

 * spawning the DVS1 platform device to 1, then the cell platform device

 * name is calculated from 10*instance + id resulting in the device name

 * "wm831x-buckv.11"

 GPIO1-3: IRQ inputs, rising edge triggered, CMOS */

 DCDC1 */

 DCDC2 */

 DCDC3 */

 LCD type and Bypass set by bootloader */

 Set all the necessary GPG pins to special-function 2 */

 force card-detected for prototype 0 */

 Open drain IRQs need pullups */

 turn off */

 Maintainer: Mark Brown <broonie@opensource.wolfsonmicro.com> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2003-2004 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 https:
 dump ISA space somewhere unused */

 IR port */

 framebuffer lcd controller information */

 H1940 and RX3715 need to reserve this for suspend */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006-2008 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>

	Vincent Sanders <vince@arm.linux.org.uk>



 S3C2440/S3C2442 CPU PLL tables (16.93444MHz Crystal)

 This array should be sorted in ascending order of the frequencies */

 FVco 624.153600 */

 FVco 672.537600 */

 FVco 720.921600 */

 FVco 769.305600 */

 FVco 817.084800 */

 FVco 866.073600 */

 FVco 914.457600 */

 FVco 961.873920 */

 FVco 1009.290240 */

 FVco 1056.706560 */

 FVco 1104.122880 */

 FVco 1158.312960 */

 FVco 600.401454 */

 FVco 624.153600 */

 FVco 648.345600 */

 FVco 672.537600 */

 FVco 696.192000 */

 FVco 720.921600 */

 FVco 745.113600 */

 FVco 769.305600 */

 FVco 792.529920 */

 FVco 817.084800 */

 FVco 841.075200 */

 FVco 866.073600 */

 FVco 889.056000 */

 FVco 914.457600 */

 FVco 937.036800 */

 FVco 961.873920 */

 FVco 987.840000 */

 FVco 1009.290240 */

 FVco 1032.998400 */

 FVco 1056.706560 */

 FVco 1083.801600 */

 FVco 1104.122880 */

 FVco 1128.960000 */

 FVco 1158.312960 */

 FVco 1176.940800 */

 FVco 600.401454 */

 FVco 612.717380 */

 FVco 624.153600 */

 FVco 636.733440 */

 FVco 648.345600 */

 FVco 660.441600 */

 FVco 672.537600 */

 FVco 684.149760 */

 FVco 696.192000 */

 FVco 711.244800 */

 FVco 720.921600 */

 FVco 732.412800 */

 FVco 745.113600 */

 FVco 756.403200 */

 FVco 769.305600 */

 FVco 783.216000 */

 FVco 792.529920 */

 FVco 804.384000 */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2007 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 http:
/* Jive flash assignment

 *

 * 0x00000000-0x00028000 : uboot

 * 0x00028000-0x0002c000 : uboot env

 * 0x0002c000-0x00030000 : spare

 * 0x00030000-0x00200000 : zimage A

 * 0x00200000-0x01600000 : cramfs A

 * 0x01600000-0x017d0000 : zimage B

 * 0x017d0000-0x02bd0000 : cramfs B

 * 0x02bd0000-0x03fd0000 : yaffs

 Don't allow access to the bootloader from linux */

 force read-only */

 spare */

 booted images */

 force read-only */

 force read-only */

 yaffs */

 bootloader environment */

 upgrade images */

 Don't allow access to the bootloader from linux */

 force read-only */

 spare */

 booted images */

 force read-only */

 force read-only */

 yaffs */

 bootloader environment */

 upgrade images */

 set taken from osiris nand timings, possibly still conservative */

 this is already setup in the nand info */

 parse the mtdset= option given to the kernel command line */

 LCD timing and setup */

 todo - put into gpio header */

	/* Enable VD[2..7], VD[10..15], VD[18..23] and VCLK, syncs, VDEN

	 * and disable the pull down resistors on pins we are using for LCD

 ILI9320 support. */

 LCD SPI support */

 WM8750 audio code SPI definition */

 JIVE SPI devices. */

 CPOL=1, CPHA=1 */

 CPOL=0, CPHA=0 */

 I2C bus and device configuration. */

 The platform devices being used. */

 detect is on GPG1 */

 Jive power management device */

	/* Write the magic value u-boot uses to check for resume into

	 * the INFORM0 register, and ensure INFORM1 is set to the

 register system core operations for managing low level suspend */

	/* write our sleep configurations for the IO. Pull down all unused

	 * IO, ensure that we have turned off all peripherals we do not

 Port B sleep */

 Port C sleep */

 Port D sleep */

 Port F sleep */

 Port G sleep */

 Port H sleep */

 initialise the power management now we've setup everything. */

* TODO - check that this is after the cmdline option! */

	/* Turn off suspend on both USB ports, and switch the

 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 S3C64XX CPU PM support.

 Not all domains provide power status readback */

/* since both s3c6400 and s3c6410 share the same sleep pm calls, we

 * put the per-cpu code in here until any new cpu comes along and changes

 * this.

 set our standby method to sleep */

 clear any old wakeup */

 set the LED state to 0110 over sleep */

	/* issue the standby signal into the pm unit. Note, we

 we should never get past here */

 Aborting suspend */

 mapping of interrupts to parts of the wakeup mask */

 store address of resume. */

 ensure previous wakeup state is cleared before sleeping */

	/* S3C64XX UART blocks only support level interrupts, so ensure that

	 * when we restore unused UART blocks we force the level interrupt

	/* We have a constraint on changing the clock type of the UART

	 * between UCLKx and PCLK, so ensure that when we restore UCON

	 * that the CLK field is correctly modified if the bootloader

	 * has changed anything.

		/* change from UCLKx => wrong PCLK,

		 * either UCLK can be tested for by a bit-test

			/* as an precaution, don't change from

 SPDX-License-Identifier: GPL-2.0+



 S3C2442 Machine Support for Openmoko GTA02 / FreeRunner.



 Copyright (C) 2006-2009 by Openmoko, Inc.

 Authors: Harald Welte <laforge@openmoko.org>

          Andy Green <andy@openmoko.org>

          Werner Almesberger <werner@openmoko.org>

 All rights reserved.

/*

 * This gets called frequently when we paniced.

/*

 * On GTA02 the 1A charger features a 48K resistor to 0V on the ID pin.

 * We use this to recognize that we can pull 1A from the USB socket.

 *

 * These constants are the measured pcf50633 ADC levels with the 1A

 * charger / 48K resistor, and with no pulldown resistor.

 Interpret charger type */

		/*

		 * Sanity - stop GPO driving out now that we have a 1A charger

		 * GPO controls USB Host power generation on GTA02

	/*

	 * If the PCF50633 ADC is disabled we fallback to a

	 * 100mA limit for safety.

 !CONFIG_CHARGER_PCF50633 */

 NOR Flash. */

 GCS3 */

 2MBytes */

		/*

		 * This name is also hard-coded in the boot loaders, so

		 * changing it would would require all users to upgrade

		 * their boot loaders, some of which are stored in a NOR

		 * that is considered to be immutable.

/*

 * Choose a set of timings derived from S3C@2442B MCP54

 * data sheet (K5D2G13ACM-D075 MCP Memory).

 Get PMU to set USB current limit accordingly. */

 USB */

 Touchscreen */

 slow as we can go */

 Buttons */

 bus pins */

 These are the guys that don't need to be children of PMU. */

 Set the panic callback to turn AUX LED on or off. */

 Configure the I2S pins (GPE0...GPE4) in correct mode */

 Maintainer: Nelson Castillo <arhuaco@freaks-unidos.net> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2004-2005 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 http:


 Simtec BAST and Thorcom VR1000 USB port support functions

/* control power and monitor over-current events on various Simtec

 * designed boards.

 turn power on */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2003-2009 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>

 ISA IO areas */

  /* we could possibly compress the next set down into a set of smaller tables

   * pagetables, but that would mean using an L2 section, and it still means

   * we cannot actually feed the same register to an LDR due to 16K spacing

 CPLD control registers */

 NAND Flash on Anubis board */

/* the Anubis has 3 selectable slots for nand-flash, the two

 * on-board chip areas, as well as the external slot.

 *

 * Note, there is no current hot-plug support for the External

 * socket.

 IDE channels */

 Asix AX88796 10/100 ethernet controller */

 SM501 */

 24bit panel */

 SDRAM timing */

 set the SDRAM and bus clocks */

 Standard Anubis devices */

 I2C devices. */

 Audio setup */

 check for the newer revision boards with large page nand */

 ensure that the GPIO is setup */

 Maintainer: Ben Dooks <ben@simtec.co.uk> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2010 Maurus Cuelenaere

 This isn't present on a SmartQ 5 board */

 Battery voltage (?-4.2V) */

 Reference voltage (1.2V) */

 turn power off */

 GPM0 -> CS */

 Init iNAND first, ... */

 ... then the external SD card */

 set the LCD type */

 remove the LCD bypass */

 leave power on */

 This isn't present on a SmartQ 5 board */

 turn power off */

 turn power on */

 reset device */

 SPDX-License-Identifier: GPL-2.0



 Samsung's S3C64XX flattened device tree enabled machine



 Copyright (c) 2013 Tomasz Figa <tomasz.figa@gmail.com>

/*

 * IO mapping for shared system controller IP.

 *

 * FIXME: Make remaining drivers use dynamic mapping.

 Maintainer: Tomasz Figa <tomasz.figa@gmail.com> */

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0



 Speyside modules for Cragganmore - board data probing



 Copyright 2011 Wolfson Microelectronics plc

	Mark Brown <broonie@opensource.wolfsonmicro.com>

 Active high for Glenfarclas Rev 2 */

 IRQ: CMOS output */

 CLKOUT: CMOS output */

 GPIO1 == ADCLRCLK1 */

 GPIO2 == ADCLRCLK2, input due to CPU */

 GPIO3 == HP_SEL */

 GPIO4 == IRQ */

 GPIO5 == CLKOUT */

 Open drain mode */

 IRQ out, active high, CMOS */

 WM8958 is the superset */

 I2C device name */

 AIF3TXLRCLK */

 OPCLK */

 SPI device name */

 AIF3TXLRCLK */

 OPCLK */

 SPI device name */

 GPIO3 24.576MHz output clock */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 http:
 set our standby method to sleep */

 Aborting suspend */

 mapping of interrupts to parts of the wakeup mask */

 save the PWRCFG to get back to original sleep method */

	/* save the sleep configuration anyway, just in case these

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006-2008 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 S3C2412/S3C2443 (PL093 based) IO timing support

/**

 * s3c2412_print_timing - print timing information via printk.

 * @pfx: The prefix to print each line with.

 * @iot: The IO timing information

/**

 * to_div - turn a cycle length into a divisor setting.

 * @cyc_tns: The cycle time in 10ths of nanoseconds.

 * @clk_tns: The clock period in 10ths of nanoseconds.

/**

 * calc_timing - calculate timing divisor value and check in range.

 * @hwtm: The hardware timing in 10ths of nanoseconds.

 * @clk_tns: The clock period in 10ths of nanoseconds.

 * @err: Pointer to err variable to update in event of failure.

/**

 * s3c2412_calc_bank - calculate the bank divisor settings.

 * @cfg: The current frequency configuration.

 * @bt: The bank timing.

/**

 * s3c2412_iotiming_debugfs - debugfs show io bank timing information

 * @seq: The seq_file to write output to using seq_printf().

 * @cfg: The current configuration.

 * @iob: The IO bank information to decode.

/**

 * s3c2412_iotiming_calc - calculate all the bank divisor settings.

 * @cfg: The current frequency configuration.

 * @iot: The bank timing information.

 *

 * Calculate the timing information for all the banks that are

 * configured as IO, using s3c2412_calc_bank().

/**

 * s3c2412_iotiming_set - set the timing information

 * @cfg: The current frequency configuration.

 * @iot: The bank timing information.

 *

 * Set the IO bank information from the details calculated earlier from

 * calling s3c2412_iotiming_calc().

 set the io timings from the specifier */

 ssmc clock??? */

/**

 * bank_is_io - return true if bank is (possibly) IO.

 * @bank: The bank number.

 * @bankcfg: The value of S3C2412_EBI_BANKCFG.

 look through all banks to see what is currently set. */

/* this is in here as it is so small, it doesn't currently warrant a file

 * to itself. We expect that any s3c24xx needing this is going to also

 * need the iotiming support.

	/* Reduce both the refresh time (in ns) and the frequency (in MHz)

	 * down to ensure that we do not overflow 32 bit numbers.

	 *

	 * This should work for HCLK up to 133MHz and refresh period up

	 * to 30usec.

 apply scale  */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2009 Yauhen Kharuzhy <jekhor@gmail.com>,

	as part of OpenInkpot project

 Copyright (c) 2009 Promwad Innovation Company

	Yauhen Kharuzhy <yauhen.kharuzhy@promwad.com>



 Samsung S3C2416 Mobile CPU support

 change WDT IRQ number */

 the i2c devices are directly compatible with s3c2440 */

/* s3c2416_map_io

 *

 * register the standard cpu IO areas, and any passed in from the

 * machine specific initialisation.

 initialize device information early */

/* need to register the subsystem before we actually register the device, and

 * we also need to ensure that it has been initialised before any of the

 * drivers even try to use it (even if not on an s3c2416 based system)

 * as a driver which may support both 2443 and 2440 may try and use it.

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2008 Ramax Lo <ramaxlo@gmail.com>

      Based on mach-anubis.c by Ben Dooks <ben@simtec.co.uk>

      and modifications by SBZ <sbz@spgui.org> and

      Weibing <http:


 For product information, visit http:
 Nothing here */

 NAND Flash on AT2440EVB board */

 DM9000AEP 10/100 ethernet controller */

 Card detect S3C2410_GPG(10) */

 bus pins */

 7" LCD panel */

 HCLK 60 MHz, divisor 2 */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 Base S3C64XX UART resource and device definitions

 Serial port registrations */

 64xx uarts are closer together */

 SPDX-License-Identifier: GPL-2.0



 Machine specific code for the Acer n30, Acer N35, Navman PiN 570,

 Yakumo AlphaX and Airis NC05 PDAs.



 Copyright (c) 2003-2005 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 Copyright (c) 2005-2008 Christer Weinigel <christer@weinigel.se>



 There is a wiki with more information about the n30 port at

 https:
 nothing here yet */

 Normal serial port */

 IR port */

	/* On the N30 the bluetooth controller is connected here.

 This is the bluetooth LED on the device. */

/* This is the blue LED on the device. Originally used to indicate GPS activity

/* This LED is driven by the battery microcontroller, and is blinking

 * red, blinking green or solid green when the battery is low,

 * charging or full respectively.  By driving GPD9 low, it's possible

 Card detect S3C2410_GPF(1) */

 Write protect S3C2410_GPG(10) */

 bus pins */

/* Lots of hardcoded stuff, but it sets up the hardware in a useful

	/* GPA0-11 special functions -- unknown what they do

	 * GPA12 N30 special function -- unknown what it does

	 *       N35/PiN output -- unknown what it does

	 *

	 * A12 is nGCS1 on the N30 and an output on the N35/PiN.  I

	 * don't think it does anything useful on the N30, so I ought

	 * to make it an output there too since it always driven to 0

	/* GPB0 TOUT0 backlight level

	 * GPB1 output 1=backlight on

	 * GPB2 output IrDA enable 0=transceiver enabled, 1=disabled

	 * GPB3 output USB D+ pull up 0=disabled, 1=enabled

	 * GPB4 N30 output -- unknown function

	 *      N30/PiN GPS control 0=GPS enabled, 1=GPS disabled

	 * GPB5 output -- unknown function

	 * GPB6 input -- unknown function

	 * GPB7 output -- unknown function

	 * GPB8 output -- probably LCD driver enable

	 * GPB9 output -- probably LCD VSYNC driver enable

	 * GPB10 output -- probably LCD HSYNC driver enable

	/* GPC0 input RS232 DCD/DSR/RI

	 * GPC1 LCD

	 * GPC2 output RS232 DTR?

	 * GPC3 input RS232 DCD/DSR/RI

	 * GPC4 LCD

	 * GPC5 output 0=NAND write enabled, 1=NAND write protect

	 * GPC6 input -- unknown function

	 * GPC7 input charger status 0=charger connected

	 *      this input can be triggered by power on the USB device

	 *      port too, but will go back to disconnected soon after.

	 * GPC8 N30/N35 output -- unknown function, always driven to 1

	 *      PiN input -- unknown function, always read as 1

	 *      Make it an input with a pull up for all models.

	 * GPC9-15 LCD

	/* GPD0 input -- unknown function

	 * GPD1-D7 LCD

	 * GPD8 N30 output -- unknown function

	 *      N35/PiN output 1=GPS LED on

	 * GPD9 output 0=power led blinks red, 1=normal power led function

	 * GPD10 output -- unknown function

	 * GPD11-15 LCD drivers

	/* GPE0-4 I2S audio bus

	 * GPE5-10 SD/MMC bus

	 * E11-13 outputs -- unknown function, probably power management

	 * E14-15 I2C bus connected to the battery controller

	/* GPF0  input 0=power button pressed

	 * GPF1  input SD/MMC switch 0=card present

	 * GPF2  N30 1=reset button pressed (inverted compared to the rest)

	 *	 N35/PiN 0=reset button pressed

	 * GPF3  N30/PiN input -- unknown function

	 *       N35 input GPS antenna position, 0=antenna closed, 1=open

	 * GPF4  input 0=button 4 pressed

	 * GPF5  input 0=button 3 pressed

	 * GPF6  input 0=button 2 pressed

	 * GPF7  input 0=button 1 pressed

	/* GPG0  input RS232 DCD/DSR/RI

	 * GPG1  input 1=USB gadget port has power from a host

	 * GPG2  N30 input -- unknown function

	 *       N35/PiN input 0=headphones plugged in, 1=not plugged in

	 * GPG3  N30 output -- unknown function

	 *       N35/PiN input with unknown function

	 * GPG4  N30 output 0=MMC enabled, 1=MMC disabled

	 * GPG5  N30 output 0=BlueTooth chip disabled, 1=enabled

	 *       N35/PiN input joystick right

	 * GPG6  N30 output 0=blue led on, 1=off

	 *       N35/PiN input joystick left

	 * GPG7  input 0=thumbwheel pressed

	 * GPG8  input 0=thumbwheel down

	 * GPG9  input 0=thumbwheel up

	 * GPG10 input SD/MMC write protect switch

	 * GPG11 N30 input -- unknown function

	 *       N35 output 0=GPS antenna powered, 1=not powered

	 *       PiN output -- unknown function

	 * GPG12-15 touch screen functions

	 *

	 * The pullups differ between the models, so enable all

	 * pullups that are enabled on any of the models.

	/* GPH0/1/2/3 RS232 serial port

	 * GPH4/5 IrDA serial port

	 * GPH6/7  N30 BlueTooth serial port

	 *         N35/PiN GPS receiver

	 * GPH8 input -- unknown function

	 * GPH9 CLKOUT0 HCLK -- unknown use

	 * GPH10 CLKOUT1 FCLK -- unknown use

	 *

	 * The pull ups for H6/H7 are enabled on N30 but not on the

	 * N35/PiN.  I suppose is useful for a budget model of the N30

	 * with no bluetooth.  It doesn't hurt to have the pull ups

	 * enabled on the N35, so leave them enabled for all models.

 GPB3 is the line that controls the pull-up for the USB D+ line */

	/* Turn off suspend on both USB ports, and switch the

 Configure the I2S pins (GPE0...GPE4) in correct mode */

		/* Turn off suspend on both USB ports, and switch the

 Disable pull-up and add GPIO tables */

		/* Turn off suspend and switch the selectable USB port

		 * to USB device mode.  Turn on suspend for the host

		 * port since it is not connected on the N35.

		 *

		 * Actually, the host port is available at some pads

		 * on the back of the device, so it would actually be

		 * possible to add a USB device inside the N35 if you

 Disable pull-up and add GPIO tables */

	/* Maintainer: Christer Weinigel <christer@weinigel.se>,

				Ben Dooks <ben-linux@fluff.org>

	/* Maintainer: Christer Weinigel <christer@weinigel.se>

 SPDX-License-Identifier: GPL-2.0



 Copyright 2010 Darius Augulis <augulis.darius@gmail.com>

 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:
 DM9000AEP 10/100 ethernet controller */

 4.3" 480x272 */

 7.0" 800x480 */

 set the LCD type */

 remove the LCD bypass */

/*

 * real6410_features string

 *

 * 0-9 LCD configuration

 *

 tft screen */

 Parse the feature string */

 configure nCS1 width to 16 bits */

 set timing for nCS1 suitable for ethernet chip */

 Maintainer: Darius Augulis <augulis.darius@gmail.com> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2007 Simtec Electronics

   Ben Dooks <ben@simtec.co.uk>



 Samsung S3C2443 Mobile CPU support

 change WDT IRQ number */

/* s3c2443_map_io

 *

 * register the standard cpu IO areas, and any passed in from the

 * machine specific initialisation.

 initialize device information early */

/* need to register the subsystem before we actually register the device, and

 * we also need to ensure that it has been initialised before any of the

 * drivers even try to use it (even if not on an s3c2443 based system)

 * as a driver which may support both 2443 and 2440 may try and use it.

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2009 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 Simtec Osiris Dynamic Voltage Scaling support.

 turn off in low-power mode */

 at the moment, we assume ARMCLK = HCLK => DVS */

 keep track of current state */

 start with dvs disabled */

 disable any current dvs */

/* the CONFIG_PM block is so small, it isn't worth actually compiling it

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:
 Maintainer: Ben Dooks <ben-linux@fluff.org> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2009 Wolfson Microelectronics

      Mark Brown <broonie@opensource.wolfsonmicro.com>

 PCM Controller platform_devices */

 AC97 Controller platform devices */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2003-2004 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 S3C24XX - IRQ PM code

/* the extint values move between the s3c2410/s3c2440 and the s3c2412

 * so we use an array to hold them, and to calculate the address of

 * the register at run-time

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 http:
 Initial IO mappings */

 uart registration process */

 rename devices that are s3c2412/s3c2413 specific */

 alter IRQ of SDI controller */

 spi channel related changes, s3c2412/13 specific */

/* s3c2412_idle

 *

 * use the standard idle call by ensuring the idle mode

 * in power config, then issuing the idle co-processor

 * instruction

 ensure our idle mode is to go to idle */

/* s3c2412_map_io

 *

 * register the standard cpu IO areas, and any passed in from the

 * machine specific initialisation.

 move base of IO */

 set our idle function */

 register our io-tables */

/* need to register the subsystem before we actually register the device, and

 * we also need to ensure that it has been initialised before any of the

 * drivers even try to use it (even if not on an s3c2412 based system)

 * as a driver which may support both 2410 and 2440 may try and use it.

 SPDX-License-Identifier: GPL-2.0



 Copyright 2007 Simtec Electronics

	http:
	http:
	Ben Dooks <ben@simtec.co.uk>

 IDE ports */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2005-2008 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>

 onboard perihperal map */

 ISA IO areas (may be over-written later) */

 CPLD control registers */

 NAND Flash on Osiris board */

/* the Osiris has 3 selectable slots for nand-flash, the two

 * on-board chip areas, as well as the external slot.

 *

 * Note, there is no current hot-plug support for the External

 * socket.

 PCMCIA control and configuration */

 Osiris power management device */

 ensure correct NAND slot is selected on resume */

 ensure that an nRESET is not generated on resume. */

 Link for DVS driver to TPS65011 */

 static device, do not need to release anything */

 GPIO can go anywhere at the moment */

 I2C devices fitted. */

 Standard Osiris devices */

 refresh period is 7.8usec */

 check for the newer revision boards with large page nand */

 write-protect line to the NAND */

 fix bus configuration (nBE settings wrong on ABLE pre v2.20) */

 Maintainer: Ben Dooks <ben@simtec.co.uk> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 S3C64XX - Helper functions for setting up SDHCI device(s) GPIO (HSMMC)

 Set all the necessary GPG pins to special-function 2 */

 Set all the necessary GPH pins to special-function 2 */

 Set all the necessary GPH pins to special-function 3 */

 Set all the necessary GPC pins to special-function 3 */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2010 Darius Augulis <augulis.darius@gmail.com>

 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:
 DM9000AEP 10/100 ethernet controller */

 4.3" 480x272 */

 7.0" 800x480 */

 set the LCD type */

 remove the LCD bypass */

/*

 * mini6410_features string

 *

 * 0-9 LCD configuration

 *

 tft screen */

 Parse the feature string */

 configure nCS1 width to 16 bits */

 set timing for nCS1 suitable for ethernet chip */

 Maintainer: Darius Augulis <augulis.darius@gmail.com> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:


 Base S3C64XX I2C bus 1 gpio configuration

 don't need the contents */

 SPDX-License-Identifier: GPL-2.0



	originally from arch/arm/plat-s3c24xx/devs.c



 Copyright (c) 2004 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>



 Base S3C24XX platform device definitions

 uart devices */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2009 Yauhen Kharuzhy <jekhor@gmail.com>,

	as part of OpenInkpot project

 Copyright (c) 2009 Promwad Innovation Company

	Yauhen Kharuzhy <yauhen.kharuzhy@promwad.com>

 ISA IO Space map (memory space selected by A24) */

 IR port */

 Maintainer: Yauhen Kharuzhy <jekhor@gmail.com> */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2008 Openmoko, Inc.

 Copyright 2008 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

	http:
 Copyright 2009 Kwangwoo Lee

	Kwangwoo Lee <kwangwoo.lee@gmail.com>

 DM9000 */

/* A hardware buffer to control external devices is mapped at 0x30000000.

 * It can not be read. So current status must be kept in anw6410_extdev_status.

 framebuffer and LCD setup. */

 set the LCD type */

 remove the LCD bypass */

/* GPF1 = LCD panel power

 * GPF4 = LCD backlight control

 405566 clocks per frame => 60Hz refresh requires 24333960Hz clock */

 DM9000AEP 10/100 ethernet controller */

 dev_addr can be set to provide hwaddr. */

 Maintainer: Kwangwoo Lee <kwangwoo.lee@gmail.com> */

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2010 Samsung Electronics Co., Ltd.

		http:


 GPIO configuration for S3C64XX KeyPad device

 Set all the necessary GPK pins to special-function 3: KP_ROW[x] */

 Set all the necessary GPL pins to special-function 3: KP_COL[x] */

 SPDX-License-Identifier: GPL-2.0+



 Copyright (c) 2004-2005 Simtec Electronics

	http:
	Ben Dooks <ben@simtec.co.uk>



 Common code for S3C24XX machines

 table of supported CPUs */

 a newer version of the s3c2412 */

 a strange version of the s3c2416 */

 minimal IO mapping */

 read cpu identificaiton code */

 s3c2416 is v5, with S3C24XX_GSTATUS1 instead of S3C2412_GSTATUS1 */

 test for s3c2416 or similar device */

 don't look like an 2400 */

	/* idle the system by using the idle mode which will wait for an

	 * interrupt to happen before restarting the system.

 Warning: going into idle state upsets jtag scanning */

 the samsung port seems to do a loop and then unset idle.. */

 ensure loop not optimised out */

 this bit is not cleared on re-start... */

 initialise the io descriptors we need for initialisation */

 Serial port registrations */

	/*

	 * The DMA request source[1] (DMACH_UARTx_SRC2) are

	 * not used in the UART driver.

 TODO: DMACH_XD0 */

 TODO: DMACH_XD1 */

 TODO: DMACH_TIMER */

 SPDX-License-Identifier: GPL-2.0



 Copyright 2010 Promwad Innovation Company

	Yauhen Kharuzhy <yauhen.kharuzhy@promwad.com>



 S3C2416 - Helper functions for setting up SDHCI device(s) GPIO (HSMMC)



 Based on mach-s3c64xx/setup-sdhci-gpio.c

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) ST-Ericsson SA 2010-2013

 * Author: Rickard Andersson <rickard.andersson@stericsson.com> for

 *         ST-Ericsson.

 * Author: Daniel Lezcano <daniel.lezcano@linaro.org> for Linaro.

 * Author: Ulf Hansson <ulf.hansson@linaro.org> for Linaro.

 ARM WFI Standby signal register */

 Dual A9 core interrupt management unit registers */

 This function decouple the gic from the prcmu */

 Set bit 0 register value to 1 */

 Make sure the register is updated */

 Wait a few cycles for the gic mask completion */

 This function recouple the gic with the prcmu */

 Set bit 0 register value to 0 */

/*

 * This function checks if there are pending irq on the gic. It only

 * makes sense if the gic has been decoupled before with the

 * db8500_prcmu_gic_decouple function. Disabling an interrupt only

 * disables the forwarding of the interrupt to any CPU interface. It

 * does not prevent the interrupt from changing state, for example

 * becoming pending, or active and pending if it is already

 * active. Hence, we have to check the interrupt is pending *and* is

 * active.

 Pending register */

 Enable register */

 5 registers. STI & PPI not skipped */

 There is a pending interrupt */

/*

 * This function checks if there are pending interrupt on the

 * prcmu which has been delegated to monitor the irqs with the

 * db8500_prcmu_copy_gic_settings function.

 There is a pending interrupt */

/*

 * This function checks if the specified cpu is in in WFI. It's usage

 * makes sense only if the gic is decoupled with the db8500_prcmu_gic_decouple

 * function. Of course passing smp_processor_id() to this function will

 * always return false...

/*

 * This function copies the gic SPI settings to the prcmu in order to

 * monitor them and abort/finish the retention/off sequence or state.

 Enable register */

 We skip the STI and PPI */

	/*

	 * On watchdog reboot the GIC is in some cases decoupled.

	 * This will make sure that the GIC is correctly configured.

 Set up ux500 suspend callbacks. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2008-2009 ST-Ericsson SA

 *

 * Author: Srinidhi KASAGAR <srinidhi.kasagar@stericsson.com>

	/*

	 * Unlock Data and Instruction Lock if locked. Ux500 U-Boot versions

	 * apparently locks both caches before jumping to the kernel. The

	 * l2x0 core will not touch the unlock registers if the l2x0 is

	 * already enabled, so we do it right here instead. The PL310 has

	 * 8 sets of registers, one per possible CPU.

	/*

	 * We can't write to secure registers as we are in non-secure

	 * mode, until we have some SMI service available.

/*

 * FIXME: Should we set up the GPIO domain here?

 *

 * The problem is that we cannot put the interrupt resources into the platform

 * device until the irqdomain has been added. Right now, we set the GIC interrupt

 * domain from init_irq(), then load the gpio driver from

 * core_initcall(nmk_gpio_init) and add the platform devices from

 * arch_initcall(customize_machine).

 *

 * This feels fragile because it depends on the gpio device getting probed

 * _before_ any device uses the gpio interrupts.

 Unlock before init */

 only create devices below soc node */

 Initialize ux500 power domains */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2002 ARM Ltd.

 * Copyright (C) 2008 STMicroelctronics.

 * Copyright (C) 2009 ST-Ericsson.

 * Author: Srinidhi Kasagar <srinidhi.kasagar@stericsson.com>

 *

 * This file is based on arm realview platform

 Magic triggers in backup RAM */

	/*

	 * write the address of secondary startup into the backup ram register

	 * at offset 0x1FF4, then write the magic number 0xA1FEED01 to the

	 * backup ram register at offset 0x1FF0, which is what boot rom code

	 * is waiting for. This will wake up the secondary core from WFE.

 make sure write buffer is drained */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Linaro Ltd.

 *

 * Author: Ulf Hansson <ulf.hansson@linaro.org>

 *

 * Implements PM domains using the generic PM domain for ux500.

	/*

	 * Handle the gating of the PM domain regulator here.

	 *

	 * Drivers/subsystems handling devices in the PM domain needs to perform

	 * register context save/restore from their respective runtime PM

	 * callbacks, to be able to enable PM domain gating/ungating.

	/*

	 * Handle the ungating of the PM domain regulator here.

	 *

	 * Drivers/subsystems handling devices in the PM domain needs to perform

	 * register context save/restore from their respective runtime PM

	 * callbacks, to be able to enable PM domain gating/ungating.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/common/time-acorn.c

 *

 *  Copyright (c) 1996-2000 Russell King.

 *

 *  Changelog:

 *   24-Sep-1996	RMK	Created

 *   10-Oct-1996	RMK	Brought up to date with arch-sa110eval

 *   04-Dec-1997	RMK	Updated for new arch/arm/time.c

 *   13=Jun-2004	DS	Moved to arch/arm/common b/c shared w/CLPS7500

		/*

		 * The timer has not reloaded between reading count1 and

		 * count2, check whether an interrupt was actually pending.

		/*

		 * The timer has reloaded, so count2 indicates the new

		 * count since the wrap.  The interrupt would not have

		 * been processed, so add the missed ticks.

/*

 * Set up timer interrupt.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-rpc/dma.c

 *

 *  Copyright (C) 1998 Russell King

 *

 *  DMA functions specific to RiscPC architecture

 Controller base address */

 Controller IRQ */

 This efficiently implements state = OFL != AB ? AB : 0

		/*

		 * Cope with ISA-style drivers which expect cache

		 * coherence.

/*

 * This is virtual DMA - we don't need anything here.

	/*

	 * Setup DMA channels 2,3 to be for podules

	 * and channels 0,1 for internal devices

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/ecard.c

 *

 *  Copyright 1995-2001 Russell King

 *

 *  Find all installed expansion cards, and handle interrupts from them.

 *

 *  Created from information from Acorns RiscOS3 PRMs

 *

 *  08-Dec-1996	RMK	Added code for the 9'th expansion card - the ether

 *			podule slot.

 *  06-May-1997	RMK	Added blacklist for cards whose loader doesn't work.

 *  12-Sep-1997	RMK	Created new handling of interrupt enables/disables

 *			- cards can now register their own routine to control

 *			interrupts (recommended).

 *  29-Sep-1997	RMK	Expansion card interrupt hardware not being re-enabled

 *			on reset from Linux. (Caused cards not to respond

 *			under RiscOS without hard reset).

 *  15-Feb-1998	RMK	Added DMA support

 *  12-Sep-1998	RMK	Added EASI support

 *  10-Jan-1999	RMK	Run loaders in a simulated RISC OS environment.

 *  17-Apr-1999	RMK	Support for EASI Type C cycles.

/* List of descriptions of cards which don't have an extended

 * identification, or chunk directories containing a description.

 ===================== Expansion card daemon ======================== */

/*

 * Since the loader programs on the expansion cards need to be run

 * in a specific environment, create a separate task with this

 * environment up, and pass requests to this task as and when we

 * need to.

 *

 * This should allow 99% of loaders to be called from Linux.

 *

 * From a security standpoint, we trust the card vendors.  This

 * may be a misplaced trust.

		/*

		 * The card maintains an index which increments the address

		 * into a 4096-byte page on each access.  We need to keep

		 * track of the counter.

		/*

		 * If we are reading offset 0, or our current index is

		 * greater than the offset, reset the hardware index counter.

		/*

		 * Increment the hardware index counter until we get to the

		 * required offset.  The read bytes are discarded.

				/*

				 * The following is required by some

				 * expansion card loader programs.

/*

 * Set up the expansion card daemon's page tables.

	/* We want to set up the page tables for the following mapping:

	 *  Virtual	Physical

	 *  0x03000000	0x03000000

	 *  0x03010000	unmapped

	 *  0x03210000	0x03210000

	 *  0x03400000	unmapped

	 *  0x08000000	0x08000000

	 *  0x10000000	unmapped

	 *

	 * FIXME: we don't follow this 100% yet.

	/*

	 * Allocate a mm.  We're not a lazy-TLB kernel task since we need

	 * to set page table entries where the user space would be.  Note

	 * that this also creates the page tables.  Failure is not an

	 * option here.

/*

 * Wake the expansion card daemon to action our request.

 *

 * FIXME: The test here is not sufficient to detect if the

 * kcardd is running.

	/*

	 * Now wait for kecardd to run.

 ======================= Mid-level card control ===================== */

 link */

 loader */

 ======================= Interrupt control ============================ */

/*

 * Enable and disable interrupts from expansion cards.

 * (interrupts are disabled for these functions).

 *

 * They are not meant to be called directly, but via enable/disable_irq.

	/*

	 * If the timer interrupt has not run since the last million

	 * unrecognised expansion card interrupts, then there is

	 * something seriously wrong.  Disable the expansion card

	 * interrupts so at least we can continue.

	 *

	 * Maybe we ought to start a timer to re-enable them some time

	 * later?

	/*

	 * If we did not recognise the source of this interrupt,

	 * warn the user, but don't flood the user with these messages.

 Disable interrupts on each port */

/*

 * Probe for an expansion card.

 *

 * If bit 1 of the first byte of the card is set, then the

 * card does not exist.

	/*

	 * hook the interrupt handlers

 On RiscPC, only first two slots have DMA capability */

/*

 * Initialise the expansion card system.

 * Locate all hardware - interrupt management and

 * actual cards.

/*

 *	ECARD "bus"

	/*

	 * Restore the default operations.  We ensure that the

	 * ops are set before we change the data.

/*

 * Before rebooting, we must make sure that the expansion card is in a

 * sensible state, so it can be re-detected.  This means that the first

 * page of the ROM must be visible.  We call the expansion cards reset

 * handler, if any.

	/*

	 * If this card has a loader, call the reset handler.

 SPDX-License-Identifier: GPL-2.0

 These are offsets from the stat register for each IRQ bank

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-rpc/riscpc.c

 *

 *  Copyright (C) 1998-2001 Russell King

 *

 *  Architecture specific fixups.

 ??? */

 VRAM		*/

 IO space	*/

 EASI space	*/

	/*

	 * Turn off floppy.

	/*

	 * RiscPC can't handle half-word loads and stores

 VIDC */

 grumble */

	/*

	 * Jump into the ROM

 Maintainer: Russell King */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 ARM Limited

 *

 * Author: Vladimir Murzin <vladimir.murzin@arm.com>

/*

 * Versatile Express Serial Power Controller (SPC) support

 *

 * Copyright (C) 2013 ARM Ltd.

 *

 * Authors: Sudeep KarkadaNagesha <sudeep.karkadanagesha@arm.com>

 *          Achin Gupta           <achin.gupta@arm.com>

 *          Lorenzo Pieralisi     <lorenzo.pieralisi@arm.com>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 SPC wake-up IRQs status and mask */

 SPC power down registers */

 SPC per-CPU mailboxes */

 SPC CPU/cluster reset statue */

 SPC system config interface registers */

 A15/A7 OPP virtual register base */

 Config interface control bits */

 wake-up interrupt masks */

 TC2 static dual-cluster configuration */

/*

 * Even though the SPC takes max 3-5 ms to complete any OPP/COMMS

 * operation, the operation could start just before jiffie is about

 * to be incremented. So setting timeout value of 20ms = 2jiffies@100Hz

	/*

	 * A15s cluster identifier

	 * It corresponds to A15 processors MPIDR[15:8] bitfield

/**

 * ve_spc_global_wakeup_irq()

 *

 * Function to set/clear global wakeup IRQs. Not protected by locking since

 * it might be used in code paths where normal cacheable locks are not

 * working. Locking must be provided by the caller to ensure atomicity.

 *

 * @set: if true, global wake-up IRQs are set, if false they are cleared

/**

 * ve_spc_cpu_wakeup_irq()

 *

 * Function to set/clear per-CPU wake-up IRQs. Not protected by locking since

 * it might be used in code paths where normal cacheable locks are not

 * working. Locking must be provided by the caller to ensure atomicity.

 *

 * @cluster: mpidr[15:8] bitfield describing cluster affinity level

 * @cpu: mpidr[7:0] bitfield describing cpu affinity level

 * @set: if true, wake-up IRQs are set, if false they are cleared

/**

 * ve_spc_set_resume_addr() - set the jump address used for warm boot

 *

 * @cluster: mpidr[15:8] bitfield describing cluster affinity level

 * @cpu: mpidr[7:0] bitfield describing cpu affinity level

 * @addr: physical resume address

/**

 * ve_spc_powerdown()

 *

 * Function to enable/disable cluster powerdown. Not protected by locking

 * since it might be used in code paths where normal cacheable locks are not

 * working. Locking must be provided by the caller to ensure atomicity.

 *

 * @cluster: mpidr[15:8] bitfield describing cluster affinity level

 * @enable: if true enables powerdown, if false disables it

/**

 * ve_spc_cpu_in_wfi(u32 cpu, u32 cluster)

 *

 * @cpu: mpidr[7:0] bitfield describing CPU affinity level within cluster

 * @cluster: mpidr[15:8] bitfield describing cluster affinity level

 *

 * @return: non-zero if and only if the specified CPU is in WFI

 *

 * Take care when interpreting the result of this function: a CPU might

 * be in WFI temporarily due to idle, and is not necessarily safely

 * parked.

 find closest match to given frequency in OPP table */

 OPP entries in kHz */

 Set the control value */

/*

 *  +--------------------------+

 *  | 31      20 | 19        0 |

 *  +--------------------------+

 *  |   m_volt   |  freq(kHz)  |

 *  +--------------------------+

	/*

	 * Multi-cluster systems may need this data when non-coherent, during

	 * cluster power-up/power-down. Make sure driver info reaches main

	 * memory.

 Continue only if SPC is initialised */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-vexpress/dcscb.c - Dual Cluster System Configuration Block

 *

 * Created by:	Nicolas Pitre, May 2012

 * Copyright:	(C) 2012-2013  Linaro Limited

 remove cluster reset and add individual CPU's reset */

 Disable and flush the local CPU cache. */

 Flush all cache levels for this cluster. */

	/*

	 * A full outer cache flush could be needed at this point

	 * on platforms with such a cache, depending on where the

	 * outer cache sits. In some cases the notion of a "last

	 * cluster standing" would need to be implemented if the

	 * outer cache is shared across clusters. In any case, when

	 * the outer cache needs flushing, there is no concurrent

	 * access to the cache controller to worry about and no

	 * special locking besides what is already provided by the

	 * MCPM state machinery is needed.

	/*

	 * Disable cluster-level coherency by masking

	 * incoming snoops and DVM messages:

	/*

	 * Future entries into the kernel can now go

	 * through the cluster entry vectors.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-vexpress/platsmp.c

 *

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

	/*

	 * The best way to detect a multi-cluster configuration

	 * is to detect if the kernel can take over CCI ports

	 * control. Loop over possible CPUs and check if CCI

	 * port control is available.

	 * Override the default vexpress_smp_ops if so.

	/*

	 * Write the address of secondary startup into the

	 * system-wide flags register. The boot monitor waits

	 * until it receives a soft interrupt, and then the

	 * secondary CPU branches to this address.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-vexpress/tc2_pm.c - TC2 power management support

 *

 * Created by:	Nicolas Pitre, October 2012

 * Copyright:	(C) 2012-2013  Linaro Limited

 *

 * Some portions of this file were originally written by Achin Gupta

 * Copyright:   (C) 2012  ARM Limited

 SCC conf registers */

	/*

	 * If the CPU is committed to power down, make sure

	 * the power controller will be in charge of waking it

	 * up upon IRQ, ie IRQ lines are cut from GIC CPU IF

	 * to the CPU by disabling the GIC CPU IF to prevent wfi

	 * from completing execution behind power controller back

		/*

		 * On the Cortex-A15 we need to disable

		 * L2 prefetching before flushing the cache.

		/*

		 * We need the CPU to reach WFI, but the power

		 * controller may put the cluster in reset and

		 * power it off as soon as that happens, before

		 * we have a chance to see STANDBYWFI.

		 *

		 * So we need to check for both conditions:

 success: the CPU is halted */

 Otherwise, wait and retry: */

 timeout */

/*

 * Enable cluster-level coherency, in preparation for turning on the MMU.

	/*

	 * The power management-related features are hidden behind

	 * SCC registers. We need to extract runtime information like

	 * cluster ids and number of CPUs really available in clusters.

	/*

	 * A subset of the SCC registers is also used to communicate

	 * with the SPC (power controller). We need to be able to

	 * drive it very early in the boot process to power up

	 * processors, so we initialize the SPC driver here.

 test if we can (re)enable the CCI on our own */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/simone.c

 * Simplemachines Sim.One support.

 *

 * Copyright (C) 2010 Ryan Mallon

 *

 * Based on the 2.6.24.7 support:

 *   Copyright (C) 2009 Simplemachines

 *   MMC support by Peter Ivanov <ivanovp@gmail.com>, 2007

 "mmc_spi" @ CS0 */

 Card detect */

		/*

		 * We use 10 MHz even though the maximum is 3.7 MHz. The driver

		 * will limit it automatically to max. frequency.

/*

 * Up to v1.3, the Sim.One used SFRMOUT as SD card chip select, but this goes

 * low between multi-message command blocks. From v1.4, it uses a GPIO instead.

 * v1.3 parts will still work, since the signal on SFRMOUT is automatic.

 Maintainer: Ryan Mallon */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/clock.c

 * Clock control for Cirrus EP93xx chips.

 *

 * Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

/*

 * PLL rate = 14.7456 MHz * (X1FBD + 1) * (X2FBD + 1) / (X2IPD + 1) / 2^PS

 X1FBD */

 X2FBD */

 X2IPD */

 PS */

	/*

	 * Try the two pll's and the external clock

	 * Because the valid predividers are 2, 2.5 and 3, we multiply

	 * all the clocks by 2 to avoid floating point math.

	 *

	 * This is based on the algorithm in the ep93xx raster guide:

	 * http://be-a-maverick.com/en/pubs/appNote/AN269REV1.pdf

	 *

 Try each predivider value */

 Clear old dividers */

 Set the new pdiv and div bits for the new clock rate */

 parenting uart gate clocks to uart clock */

 Determine the bootloader configured pll1 rate */

 Initialize the pll1 derived clocks */

 Determine the bootloader configured pll2 rate */

 Initialize the pll2 derived clocks */

	/*

	 * These four bits set the divide ratio between the PLL2

	 * output and the USB clock.

	 * 0000 - Divide by 1

	 * 0001 - Divide by 2

	 * 0010 - Divide by 3

	 * 0011 - Divide by 4

	 * 0100 - Divide by 5

	 * 0101 - Divide by 6

	 * 0110 - Divide by 7

	 * 0111 - Divide by 8

	 * 1000 - Divide by 9

	 * 1001 - Divide by 10

	 * 1010 - Divide by 11

	 * 1011 - Divide by 12

	 * 1100 - Divide by 13

	 * 1101 - Divide by 14

	 * 1110 - Divide by 15

	 * 1111 - Divide by 1

	 * On power-on-reset these bits are reset to 0000b.

	/*

	 * EP93xx SSP clock rate was doubled in version E2. For more information

	 * see:

	 *     http://www.cirrus.com/en/pubs/appNote/AN273REV4.pdf

 pwm clock */

 touchscreen/adc clock */

 keypad clock */

	/* On reset PDIV and VDIV is set to zero, while PDIV zero

	 * means clock disable, VDIV shouldn't be zero.

	 * So i set both dividers to minimum.

 ENA - Enable CLK divider. */

 PDIV - 00 - Disable clock */

 VDIV - at least 2 */

 Check and enable video clk registers */

 check and enable i2s clk registers */

 video clk */

 i2s clk */

 i2s sclk */

 i2s lrclk */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/dma.c

 *

 * Platform support code for the EP93xx dmaengine driver.

 *

 * Copyright (C) 2011 Mika Westerberg

 *

 * This work is based on the original dma-m2p implementation with

 * following copyrights:

 *

 *   Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

 *   Copyright (C) 2006 Applied Data Systems

 *   Copyright (C) 2009 Ryan Mallon <rmallon@gmail.com>

/*

 * DMA M2P channels.

 *

 * On the EP93xx chip the following peripherals my be allocated to the 10

 * Memory to Internal Peripheral (M2P) channels (5 transmit + 5 receive).

 *

 *	I2S	contains 3 Tx and 3 Rx DMA Channels

 *	AAC	contains 3 Tx and 3 Rx DMA Channels

 *	UART1	contains 1 Tx and 1 Rx DMA Channels

 *	UART2	contains 1 Tx and 1 Rx DMA Channels

 *	UART3	contains 1 Tx and 1 Rx DMA Channels

 *	IrDA	contains 1 Tx and 1 Rx DMA Channels

 *

 * Registers are mapped statically in ep93xx_map_io().

/*

 * DMA M2M channels.

 *

 * There are 2 M2M channels which support memcpy/memset and in addition simple

 * hardware requests from/to SSP and IDE. We do not implement an external

 * hardware requests.

 *

 * Registers are mapped statically in ep93xx_map_io().

 SPDX-License-Identifier: GPL-2.0

/*************************************************************************

 * Timer handling for EP93xx

 *************************************************************************

 * The ep93xx has four internal timers.  Timers 1, 2 (both 16 bit) and

 * 3 (32 bit) count down at 508 kHz, are self-reloading, and can generate

 * an interrupt on underflow.  Timer 4 (40 bit) counts down at 983.04 kHz,

 * is free-running, and can't generate interrupts.

 *

 * The 508 kHz timers are ideal for use for the timer interrupt, as the

 * most common values of HZ divide 508 kHz nicely.  We pick the 32 bit

 * timer (timer 3) to get as long sleep intervals as possible when using

 * CONFIG_NO_HZ.

 *

 * The higher clock rate of timer 4 makes it a better choice than the

 * other timers for use as clock source and for sched_clock(), providing

 * a stable 40 bit time base.

 *************************************************************************

 Default mode: periodic, off, 508 kHz */

 Clear timer */

 Set next event */

 Disable timer */

 Writing any value clears the timer interrupt */

 Enable and register clocksource and sched_clock on timer 4 */

 Set up clockevent on timer 3 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/gesbc9312.c

 * Glomation GESBC-9312-sx support.

 *

 * Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/adssphere.c

 * ADS Sphere support.

 *

 * Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-ep93xx/micro9.c

 *

 * Copyright (C) 2006 Contec Steuerungstechnik & Automation GmbH

 *                    Manfred Gruber <m.gruber@tirol.com>

 * Copyright (C) 2009 Contec Steuerungstechnik & Automation GmbH

 *                    Hubert Feurstein <hubert.feurstein@contec.at>

/*************************************************************************

 * Micro9 NOR Flash

 *

 * Micro9-High has up to 64MB of 32-bit flash on CS1

 * Micro9-Mid has up to 64MB of either 32-bit or 16-bit flash on CS1

 * Micro9-Lite uses a separate MTD map driver for flash support

 * Micro9-Slim has up to 64MB of either 32-bit or 16-bit flash on CS1

 Detect the bus width of the external flash memory */

 32-bit */

 16-bit */

/*************************************************************************

 * Micro9 Ethernet

 Maintainer: Hubert Feurstein <hubert.feurstein@contec.at> */

 Maintainer: Hubert Feurstein <hubert.feurstein@contec.at> */

 Maintainer: Hubert Feurstein <hubert.feurstein@contec.at> */

 Maintainer: Hubert Feurstein <hubert.feurstein@contec.at> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/core.c

 * Core routines for Cirrus EP93xx chips.

 *

 * Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

 * Copyright (C) 2007 Herbert Valerio Riedel <hvr@gnu.org>

 *

 * Thanks go to Michael Burian and Ray Lehtiniemi for their key

 * role in the ep93xx linux community.

/*************************************************************************

 * Static I/O mappings that are needed for all EP93xx platforms

/*************************************************************************

 * EP93xx IRQ handling

/*************************************************************************

 * EP93xx System Controller Software Locked register handling

/*

 * syscon_swlock prevents anything else from writing to the syscon

 * block while a software locked register is being written.

/**

 * ep93xx_chip_revision() - returns the EP93xx chip revision

 *

 * See "platform.h" for more information.

/*************************************************************************

 * EP93xx GPIO

/*************************************************************************

 * EP93xx peripheral handling

/*************************************************************************

 * EP93xx OHCI USB Host

/*************************************************************************

 * EP93xx physmap'ed flash

/**

 * ep93xx_register_flash() - Register the external flash device.

 * @width:	bank width in octets

 * @start:	resource start address

 * @size:	resource size

/*************************************************************************

 * EP93xx ethernet peripheral handling

/**

 * ep93xx_register_eth - Register the built-in ethernet platform device.

 * @data:	platform specific ethernet configuration (__initdata)

 * @copy_addr:	flag indicating that the MAC address should be copied

 *		from the IndAd registers (as programmed by the bootloader)

/*************************************************************************

 * EP93xx i2c peripheral handling

 All EP93xx devices use the same two GPIO pins for I2C bit-banging */

 Use local offsets on gpiochip/port "G" */

/**

 * ep93xx_register_i2c - Register the i2c platform device.

 * @devices:	platform specific i2c bus device information (__initdata)

 * @num:	the number of devices on the i2c bus

	/*

	 * FIXME: this just sets the two pins as non-opendrain, as no

	 * platforms tries to do that anyway. Flag the applicable lines

	 * as open drain in the GPIO_LOOKUP above and the driver or

	 * gpiolib will handle open drain/open drain emulation as need

	 * be. Right now i2c-gpio emulates open drain which is not

	 * optimal.

/*************************************************************************

 * EP93xx SPI peripheral handling

/**

 * ep93xx_register_spi() - registers spi platform device

 * @info: ep93xx board specific spi master info (__initdata)

 * @devices: SPI devices to register (__initdata)

 * @num: number of SPI devices to register

 *

 * This function registers platform device for the EP93xx SPI controller and

 * also makes sure that SPI pins are muxed so that I2S is not using those pins.

	/*

	 * When SPI is used, we need to make sure that I2S is muxed off from

	 * SPI pins.

/*************************************************************************

 * EP93xx LEDs

/*************************************************************************

 * EP93xx pwm peripheral handling

 NOTE: EP9307 does not have PWMOUT1 (pin EGPIO14) */

 PWM 1 output on EGPIO[14] */

 EGPIO[14] used for GPIO */

/*************************************************************************

 * EP93xx video peripheral handling

 The backlight use a single register in the framebuffer's register space */

/**

 * ep93xx_register_fb - Register the framebuffer platform device.

 * @data:	platform specific framebuffer configuration (__initdata)

/*************************************************************************

 * EP93xx matrix keypad peripheral handling

/**

 * ep93xx_register_keypad - Register the keypad platform device.

 * @data:	platform specific keypad configuration (__initdata)

 Enable the keypad controller; GPIO ports C and D used for keypad */

 Disable the keypad controller; GPIO ports C and D used for GPIO */

/*************************************************************************

 * EP93xx I2S audio peripheral handling

	/*

	 * This is potentially racy with the clock api for i2s_mclk, sclk and 

	 * lrclk. Since the i2s driver is the only user of those clocks we

	 * rely on it to prevent parallel use of this function and the 

	 * clock api for the i2s clocks.

/*************************************************************************

 * EP93xx AC97 audio peripheral handling

	/*

	 * Make sure that the AC97 pins are not used by I2S.

/*************************************************************************

 * EP93xx Watchdog

/*************************************************************************

 * EP93xx IDE

 GPIO ports E[7:2], G[7:4] and H used by IDE */

 GPIO ports E[7:2], G[7:4] and H used by GPIO */

/*************************************************************************

 * EP93xx ADC

 Power up ADC, deactivate Touch Screen Controller */

/*************************************************************************

 * EP93xx Security peripheral

/*

 * The Maverick Key is 256 bits of micro fuses blown at the factory during

 * manufacturing to uniquely identify a part.

 *

 * See: http://arm.cirrus.com/forum/viewtopic.php?t=486&highlight=maverick+key

 Toss the unique ID into the entropy pool */

 Disallow access to MaverickCrunch initially */

 Default all ports to GPIO */

 Get the GPIO working early, other devices need it */

	/*

	 * Set then clear the SWRST bit to initiate a software reset

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/vision_ep9307.c

 * Vision Engraving Systems EP9307 SoM support.

 *

 * Copyright (C) 2008-2011 Vision Engraving Systems

 * H Hartley Sweeten <hsweeten@visionengravers.com>

/*************************************************************************

 * Static I/O mappings for the FPGA

/*************************************************************************

 * Ethernet

/*************************************************************************

 * Framebuffer

/*************************************************************************

 * GPIO Expanders

/*************************************************************************

 * I2C Bus

/*************************************************************************

 * SPI CS4271 Audio Codec

/*************************************************************************

 * SPI Flash

/*************************************************************************

 * SPI SD/MMC host

 "mmc_spi @ CS2 */

 Card detect */

 Write protect */

/*************************************************************************

 * SPI Bus

/*************************************************************************

 * I2S Audio

/*************************************************************************

 * Machine Initialization

	/*

	 * Request the gpio expander's interrupt gpio line now to prevent

	 * the kernel from doing a WARN in gpiolib:gpio_ensure_requested().

 Maintainer: H Hartley Sweeten <hsweeten@visionengravers.com> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/edb93xx.c

 * Cirrus Logic EDB93xx Development Board support.

 *

 * EDB93XX, EDB9301, EDB9307A

 * Copyright (C) 2008-2009 H Hartley Sweeten <hsweeten@visionengravers.com>

 *

 * EDB9302

 * Copyright (C) 2006 George Kashperko <george@chas.com.ua>

 *

 * EDB9302A, EDB9315, EDB9315A

 * Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

 *

 * EDB9307

 * Copyright (C) 2007 Herbert Valerio Riedel <hvr@gnu.org>

 *

 * EDB9312

 * Copyright (C) 2006 Infosys Technologies Limited

 *                    Toufeeq Hussain <toufeeq_hussain@infosys.com>

/*************************************************************************

 * EDB93xx i2c peripheral handling

/*************************************************************************

 * EDB93xx SPI peripheral handling

 filled in later */

 Intentionally left blank */

/*************************************************************************

 * EDB93xx I2S

/*************************************************************************

 * EDB93xx pwm

 EP9301 and EP9302 only have pwm.1 (EGPIO14) */

 EP9307 only has pwm.0 (PWMOUT) */

 EP9312 and EP9315 have both */

/*************************************************************************

 * EDB93xx framebuffer

 These platforms have an ep93xx with video capability */

/*************************************************************************

 * EDB93xx IDE

	/*

	 * Although EDB9312 and EDB9315 do have IDE capability, they have

	 * INTRQ line wired as pull-up, which makes using IDE interface

	 * problematic.

 Maintainer: H Hartley Sweeten <hsweeten@visionengravers.com> */

 Maintainer: George Kashperko <george@chas.com.ua> */

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

 Maintainer: Herbert Valerio Riedel <hvr@gnu.org> */

 Maintainer: H Hartley Sweeten <hsweeten@visionengravers.com> */

 Maintainer: Toufeeq Hussain <toufeeq_hussain@infosys.com> */

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/snappercl15.c

 * Bluewater Systems Snapper CL15 system module

 *

 * Copyright (C) 2009 Bluewater Systems Ltd

 * Author: Ryan Mallon

 *

 * NAND code adapted from driver by:

 *   Andre Renaud <andre@bluewatersys.com>

 *   James R. McKaskill

 Write protect (active low) */

 Address latch */

 Command latch */

 Chip enable (active low) */

 Device ready */

 Audio codec */

 Maintainer: Ryan Mallon */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-ep93xx/ts72xx.c

 * Technologic Systems TS72xx SBC support.

 *

 * Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

/*************************************************************************

 * IO map

/*************************************************************************

 * NAND flash

 0xN0400000 */

 0xN0800000 */

 bit 0 -> bit 2 */

 bit 1 -> bit 1 */

 bit 2 -> bit 0 */

 force read-only */

 leave so much for last partition */

 force read-only */

 filled in later */

 filled in later */

	/*

	 * TS7200 has NOR flash all other TS72xx board have NAND flash.

/*************************************************************************

 * RTC M48T86

/*************************************************************************

 * Watchdog (in CPLD)

/*************************************************************************

 * ETH

/*************************************************************************

 * SPI SD/MMC host

/*************************************************************************

 * SPI Bus - SD card access

/*

 * This is a stub -> the FGPIO[3] pin is not connected on the schematic

 * The all work is performed automatically by !SPI_FRAME (SFRM1) and

 * goes through CPLD

/*************************************************************************

 * TS72XX support code

 Relative to EP93XX_CS1_PHYS_BASE */

/*************************************************************************

 * SPI Bus

 DIO_17 */

 Intentionally left blank */

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

/*************************************************************************

 * EP93xx I2S audio peripheral handling

/*************************************************************************

 * BK3 support code

 force RO */

 Configure ep93xx's I2S to use AC97 pins */

 Maintainer: Lukasz Majewski <lukma@denx.de> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  linux/arch/arm/mach-integrator/integrator_ap.c

 *

 *  Copyright (C) 2000-2003 Deep Blue Solutions Ltd

 Regmap to the AP system controller */

/*

 * All IO addresses are mapped onto VA 0xFFFx.xxxx, where x.xxxx

 * is the (PA >> 12).

 *

 * Setup a VA for the Integrator interrupt controller (for header #0,

 * just for now).

/*

 * Logical      Physical

 * f1400000	14000000	Interrupt controller

 * f1600000	16000000	UART 0

 disable all irq sources */

/*

 * For the PL010 found in the Integrator/AP some of the UART control is

 * implemented in the system controller and accessed using a callback

 * from the driver.

 UART0 */

 UART1 */

 For the Device Tree, add in the UART callbacks as AUXDATA */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-integrator/integrator_cp.c

 *

 *  Copyright (C) 2003 Deep Blue Solutions Ltd

 Base address to the core module header */

 Base address to the CP controller */

/*

 * Logical      Physical

 * f1400000	14000000	Interrupt controller

 * f1600000	16000000	UART 0

 * fca00000	ca000000	SIC

/*

 * It seems that the card insertion interrupt remains active after

 * we've acknowledged it.  We therefore ignore the interrupt, and

 * rely on reading it from the SIC.  This also means that we must

 * clear the latched interrupt.

 MMIO so discard return code */

/*

 * For the Device Tree, add in the UART, MMC and CLCD specifics as AUXDATA

 * and enforce the bus names since these are used for clock lookups.

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-integrator/core.c

 *

 *  Copyright (C) 2000-2003 Deep Blue Solutions Ltd

/**

 * cm_get - get the value from the CM_CTRL register

/**

 * cm_control - update the CM_CTRL register.

 * @mask: bits to change

 * @set: bits to set

 disable core module IRQs */

/*

 * We need to stop things allocating the low memory; ideally we need a

 * better implementation of GFP_DMA which does not assume that DMA-able

 * memory starts at zero.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Actions Semi Leopard

 *

 * This file is based on arm realview smp platform.

 *

 * Copyright 2012 Actions Semi Inc.

 * Author: Actions Semi, Inc.

 *

 * Copyright (c) 2017 Andreas Frber

 The generic PM domain driver is not available this early. */

 wait for CPUx to run to WFE instruction */

		/*

		 * While the number of cpus is gathered from dt, also get the

		 * number of cores from the scu to verify this value when

		 * booting the cores.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-moxart/moxart.c

 *

 * (C) Copyright 2013, Jonas Jensen <jonas.jensen@gmail.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2014 Marvell Technology Group Ltd.

 *

 * Antoine Tnart <antoine.tenart@free-electrons.com>

/*

 * There are two reset registers, one with self-clearing (SC)

 * reset and one with non-self-clearing reset (NON_SC).

	/*

	 * Reset the CPU, making it to execute the instruction in the reset

	 * exception vector.

	/*

	 * Write the first instruction the CPU will execute after being reset

	 * in the reset exception vector.

	/*

	 * Write the secondary startup address into the SW reset address

	 * vector. This is used by boot_inst.

 SPDX-License-Identifier: GPL-2.0

/*

 * Device Tree support for Marvell Berlin SoCs.

 *

 * Sebastian Hesselbarth <sebastian.hesselbarth@gmail.com>

 *

 * based on GPL'ed 2.6 kernel sources

 *  (c) Marvell International Ltd.

	/*

	 * with DT probing for L2CCs, berlin_init_machine can be removed.

	 * Note: 88DE3005 (Armada 1500-mini) uses pl310 l2cc

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright:	(C) 2018 Socionext Inc.

 * Copyright:	(C) 2015 Linaro Ltd.

 Boot just like a secondary */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/plat-versatile/platsmp.c

 *

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

 *

 * This code is specific to the hardware found on ARM Realview and

 * Versatile Express platforms where the CPUs are unable to be individually

 * woken, and where there is no way to hot-unplug CPUs.  Real platforms

 * should not copy this code.

/*

 * versatile_cpu_release controls the release of CPUs from the holding

 * pen in headsmp.S, which exists because we are not always able to

 * control the release of individual CPUs from the board firmware.

 * Production platforms do not need this.

/*

 * Write versatile_cpu_release in a way that is guaranteed to be visible to

 * all observers, irrespective of whether they're taking part in coherency

 * or not.  This is necessary for the hotplug code to work reliably.

/*

 * versatile_lock exists to avoid running the loops_per_jiffy delay loop

 * calibrations on the secondary CPU while the requesting CPU is using

 * the limited-bandwidth bus - which affects the calibration value.

 * Production platforms do not need this.

	/*

	 * let the primary processor know we're out of the

	 * pen, then head off into the C entry point

	/*

	 * Synchronise with the boot thread.

	/*

	 * Set synchronisation state between this boot processor

	 * and the secondary one

	/*

	 * This is really belt and braces; we hold unintended secondary

	 * CPUs in the holding pen until we're ready for them.  However,

	 * since we haven't sent them a soft interrupt, they shouldn't

	 * be there.

	/*

	 * Send the secondary CPU a soft interrupt, thereby causing

	 * the boot monitor to read the system wide flags register,

	 * and branch to the address found there.

	/*

	 * now the secondary core is starting up let it run its

	 * calibrations, then wait for it to finish

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

 *

 * This hotplug implementation is _specific_ to the situation found on

 * ARM development platforms where there is _no_ possibility of actually

 * taking a CPU offline, resetting it, or otherwise.  Real platforms must

 * NOT copy this code.

	/*

	 * Turn off coherency

	/*

	 * there is no power-control hardware on this platform, so all

	 * we can do is put the core into WFI; this is safe as the calling

	 * code will have already disabled interrupts.

	 *

	 * This code should not be used outside Versatile platforms.

			/*

			 * OK, proper wakeup, we're done

		/*

		 * Getting here, means that we have come out of WFI without

		 * having been woken up - this shouldn't happen

		 *

		 * Just note it happening - when we're woken, we can report

		 * its occurrence.

/*

 * platform-specific code to shutdown a CPU.

 * This code supports immitation-style CPU hotplug for Versatile/Realview/

 * Versatile Express platforms that are unable to do real CPU hotplug.

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011-2014 Samsung Electronics Co., Ltd.

		http:


 Exynos - Power Management support



 Based on arch/arm/mach-s3c2410/pm.c

 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

 For Cortex-A9 Diagnostic and Power control register */

 Save Power control register */

 Save Diagnostic register */

 Restore Power control register */

 Restore Diagnostic register */

 Setting Central Sequence Register for power down mode */

	/*

	 * If PMU failed while entering sleep mode, WFI will be

	 * ignored by PMU and then exiting cpu_do_idle().

	 * S5P_CENTRAL_LOWPWR_CFG bit will not be set automatically

	 * in this situation.

 clear the wakeup state register */

 No need to perform below restore code */

 Ext-GIC nIRQ/nFIQ is the only wakeup source in AFTR */

 Set value of power down register for aftr mode */

 Setting SEQ_OPTION register */

	/*

	 * If the other cpu is powered on, we have to power it off, because

	 * the AFTR state won't work otherwise

		/*

		 * We reach a sync point with the coupled idle state, we know

		 * the other cpu will power down itself or will abort the

		 * sequence, let's wait for one of these to happen

			/*

			 * The other cpu may skip idle and boot back

			 * up again

			/*

			 * The other cpu may bounce through idle and

			 * boot back up again, getting stuck in the

			 * boot rom code

		/*

		 * Set the boot vector to something non-zero

		/*

		 * Turn on cpu1 and wait for it to be on

			/*

			 * Poke cpu1 out of the boot rom

	/*

	 * Idle sequence for cpu1

	/*

	 * Turn off cpu 1

	/*

	 * Notify cpu 0 that cpu 1 is awake

 CONFIG_SMP && CONFIG_ARM_EXYNOS_CPUIDLE */

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2010-2011 Samsung Electronics Co., Ltd.

		http:


 Cloned from linux/arch/arm/mach-vexpress/platsmp.c



  Copyright (C) 2002 ARM Ltd.

  All Rights Reserved

 XXX exynos_pen_release is cargo culted code - DO NOT COPY XXX */

 Turn the CPU off on next WFI instruction. */

			/*

			 * OK, proper wakeup, we're done

		/*

		 * Getting here, means that we have come out of WFI without

		 * having been woken up - this shouldn't happen

		 *

		 * Just note it happening - when we're woken, we can report

		 * its occurrence.

 CONFIG_HOTPLUG_CPU */

/**

 * exynos_cpu_power_down() - power down the specified cpu

 * @cpu: the cpu to power down

 *

 * Power down the specified cpu. The sequence must be finished by a

 * call to cpu_do_idle()

		/*

		 * Bypass power down for CPU0 during suspend. Check for

		 * the SYS_PWR_REG value to decide if we are suspending

		 * the system.

/**

 * exynos_cpu_power_up() - power up the specified cpu

 * @cpu: the cpu to power up

 *

 * Power up the specified cpu

/**

 * exynos_cpu_power_state() - returns the power state of the cpu

 * @cpu: the cpu to retrieve the power state from

/**

 * exynos_cluster_power_down() - power down the specified cluster

 * @cluster: the cluster to power down

/**

 * exynos_cluster_power_up() - power up the specified cluster

 * @cluster: the cluster to power up

/**

 * exynos_cluster_power_state() - returns the power state of the cluster

 * @cluster: the cluster to retrieve the power state from

 *

/**

 * exynos_scu_enable() - enables SCU for Cortex-A9 based system

/*

 * Set wake up by local power mode and execute software reset for given core.

 *

 * Currently this is needed only when booting secondary CPU on Exynos3250.

/*

 * XXX CARGO CULTED CODE - DO NOT COPY XXX

 *

 * Write exynos_pen_release in a way that is guaranteed to be visible to

 * all observers, irrespective of whether they're taking part in coherency

 * or not.  This is necessary for the hotplug code to work reliably.

	/*

	 * let the primary processor know we're out of the

	 * pen, then head off into the C entry point

	/*

	 * Synchronise with the boot thread.

	/*

	 * Try to set boot address using firmware first

	 * and fall back to boot register if it fails.

	/*

	 * Try to get boot address using firmware first

	 * and fall back to boot register if it fails.

	/*

	 * Set synchronisation state between this boot processor

	 * and the secondary one

	/*

	 * The secondary processor is waiting to be released from

	 * the holding pen - release it, then wait for it to flag

	 * that it has been released by resetting exynos_pen_release.

	 *

	 * Note that "exynos_pen_release" is the hardware CPU core ID, whereas

	 * "cpu" is Linux's internal ID.

 wait max 10 ms until cpu1 is on */

	/*

	 * Send the secondary CPU a soft interrupt, thereby causing

	 * the boot monitor to read the system wide flags register,

	 * and branch to the address found there.

	/*

	 * now the secondary core is starting up let it run its

	 * calibrations, then wait for it to finish

/*

 * platform-specific code to shutdown a CPU

 *

 * Called with IRQs disabled

	/*

	 * bring this CPU back into the world of cache

	 * coherency, and then restore interrupts

 CONFIG_HOTPLUG_CPU */

 SPDX-License-Identifier: GPL-2.0



 Copyright (C) 2012 Samsung Electronics.

 Kyungmin Park <kyungmin.park@samsung.com>

 Tomasz Figa <t.figa@samsung.com>

 Save Power control and Diagnostic registers */

	/*

	 * Exynos3250 doesn't need to send smc command for secondary CPU boot

	 * because Exynos3250 removes WFE in secure mode.

	/*

	 * The second parameter of SMC_CMD_CPU1BOOT command means CPU id.

	/*

	 * Almost all Exynos-series of SoCs that run in secure mode don't need

	 * additional offset for every CPU, with Exynos4412 being the only

	 * exception.

			/*

			 * Before the cache can be enabled, due to firmware

			 * design, SMC_CMD_L2X0INVALL must be called.

	/*

	 * Exynos 4 SoCs (based on Cortex A9 and equipped with L2C-310),

	 * running under secure firmware, require certain registers of L2

	 * cache controller to be written in secure mode. Here .write_sec

	 * callback is provided to perform necessary SMC calls.

 SPDX-License-Identifier: GPL-2.0



 Samsung Exynos Flattened Device Tree enabled machine



 Copyright (c) 2010-2014 Samsung Electronics Co., Ltd.

		http:
 detect cpu id and rev. */

/*

 * Set or clear the USE_DELAYED_RESET_ASSERTION option. Used by smp code

 * and suspend.

 *

 * This is necessary only on Exynos4 SoCs. When system is running

 * USE_DELAYED_RESET_ASSERTION should be set so the ARM CLK clock down

 * feature could properly detect global idle state when secondary CPU is

 * powered down.

 *

 * However this should not be set when such system is going into suspend.

/*

 * Apparently, these SoCs are not able to wake-up from suspend using

 * the PMU. Too bad. Should they suddenly become capable of such a

 * feat, the matches below should be moved to suspend.c.

sentinel*/ },

	/*

	 * Since platsmp.c needs pmu base address by the time

	 * DT is not unflatten so we can't use DT APIs before

	 * init_irq

	/*

	 * This is called from smp_prepare_cpus if we've built for SMP, but

	 * we still need to set it up for PM and firmware ops if not.

	/*

	 * Some versions of uboot pass garbage entries in the memory node,

	 * use the old CONFIG_ARM_NR_BANKS

 SPDX-License-Identifier: GPL-2.0

 Copyright (c) 2014 Samsung Electronics Co., Ltd.

		http:


 Based on arch/arm/mach-vexpress/dcscb.c

/*

 * The common v7_exit_coherency_flush API could not be used because of the

 * Erratum 799270 workaround. This macro is the same as the common one (in

 * arch/arm/include/asm/cacheflush.h) except for the erratum handling.

 Dummy Load of a device register to avoid Erratum 799270 */ \

		/*

		 * This assumes the cluster number of the big cores(Cortex A15)

		 * is 0 and the Little cores(Cortex A7) is 1.

		 * When the system was booted from the Little core,

		 * they should be reset during power up cpu.

			/*

			 * Before we reset the Little cores, we should wait

			 * the SPARE2 register is set to 1 because the init

			 * codes of the iROM will set the register after

			 * initialization.

 Disable and flush the local CPU cache. */

		/*

		 * On the Cortex-A15 we need to disable

		 * L2 prefetching before flushing the cache.

 Flush all cache levels for this cluster. */

	/*

	 * Disable cluster-level coherency by masking

	 * incoming snoops and DVM messages:

 Wait for the core state to be OFF */

 success: the CPU is halted */

 Otherwise, wait and retry: */

 timeout */

 especially when resuming: make sure power control is set */

/*

 * Enable cluster-level coherency, in preparation for turning on the MMU.

	/*

	 * U-Boot SPL is hardcoded to jump to the start of ns_sram_base_addr

	 * as part of secondary_cpu_start().  Let's redirect it to the

	 * mcpm_entry_point(). This is done during both secondary boot-up as

	 * well as system resume.

 ldr r0, [pc, #0] */

 bx  r0 */

	/*

	 * To increase the stability of KFC reset we need to program

	 * the PMU SPARE3 register

 turn on the CCI */

	/*

	 * On Exynos5420/5800 for the A15 and A7 clusters:

	 *

	 * EXYNOS5420_ENABLE_AUTOMATIC_CORE_DOWN ensures that all the cores

	 * in a cluster are turned off before turning off the cluster L2.

	 *

	 * EXYNOS5420_USE_ARM_CORE_DOWN_STATE ensures that a cores is powered

	 * off before waking it up.

	 *

	 * EXYNOS5420_USE_L2_COMMON_UP_STATE ensures that cluster L2 will be

	 * turned on before the first man is powered up.

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2011-2014 Samsung Electronics Co., Ltd.

		http:


 Exynos - Suspend support



 Based on arch/arm/mach-s3c2410/pm.c

 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

/**

 * struct exynos_wkup_irq - PMU IRQ to mask mapping

 * @hwirq: Hardware IRQ signal of the PMU

 * @mask: Mask in PMU wake-up mask register

 Used only on Exynos542x/5800 */

/*

 * GIC wake-up support

 RTC alarm */

 RTC tick */

 sentinel */ },

 RTC alarm */

 RTC tick */

 sentinel */ },

 RTC alarm */

 RTC tick */

 sentinel */ },

 No PPI should point to this domain */

 Not GIC compliant */

 No PPI should point to this domain */

	/*

	 * Clear the OF_POPULATED flag set in of_irq_init so that

	 * later the Exynos PMU platform device won't be skipped.

 issue the standby signal into the pm unit. */

 Aborting suspend */

 MCPM works with HW CPU identifiers */

 return value != 0 means failure */

	/*

	 * Set wake-up mask registers

	 * EXYNOS_EINT_WAKEUP_MASK is set by pinctrl driver in late suspend.

 Set value of power down register for sleep mode */

 Set wake-up mask registers */

 ensure at least INFORM0 has the resume address */

 Set wake-up mask registers */

 ensure at least INFORM0 has the resume address */

 Set wake-up mask registers */

	/*

	 * The cpu state needs to be saved and restored so that the

	 * secondary CPUs will enter low power start. Though the U-Boot

	 * is setting the cpu state with low power flag, the kernel

	 * needs to restore it back in case, the primary cpu fails to

	 * suspend for any reason.

 ensure at least INFORM0 has the resume address */

 Setting SEQ_OPTION register */

 Setting SEQ_OPTION register */

 Clear SLEEP mode set in INFORM1 */

 Clear SLEEP mode set in INFORM1 */

		/*

		 * When system is resumed on the LITTLE/KFC core (cluster 1),

		 * the DSCR is not properly updated until the power is turned

		 * on also for the cluster 0. Enable it for a while to

		 * propagate the SPNIDEN and SPIDEN signals from Secure JTAG

		 * block and avoid undefined instruction issue on CP14 reset.

 Restore the CPU0 low power state register */

 Restore the sysram cpu state register */

 Clear SLEEP mode set in INFORM1 */

/*

 * Suspend Ops

	/*

	 * REVISIT: It would be better if struct platform_suspend_ops

	 * .prepare handler get the suspend_state_t as a parameter to

	 * avoid hard-coding the suspend to mem state. It's safe to do

	 * it now only because the suspend_valid_only_mem function is

	 * used as the .valid callback used to check if a given state

	 * is supported by the platform anyways.

sentinel*/ },

 All wakeup disable */

	/*

	 * Applicable as of now only to Exynos542x. If booted under secure

	 * firmware, the non-secure region of sysram should be used.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/lcd_dma.c

 *

 * Extracted from arch/arm/plat-omap/dma.c

 * Copyright (C) 2003 - 2008 Nokia Corporation

 * Author: Juha Yrjl <juha.yrjola@nokia.com>

 * DMA channel linking for 1610 by Samuel Ortiz <samuel.ortiz@nokia.com>

 * Graphics DMA and LCD DMA graphics tranformations

 * by Imre Deak <imre.deak@nokia.com>

 * OMAP2/3 support Copyright (C) 2004-2007 Texas Instruments, Inc.

 * Merged to support both OMAP1 and OMAP2 by Tony Lindgren <tony@atomide.com>

 * Some functions based on earlier dma-omap.c Copyright (C) 2001 RidgeRun, Inc.

 *

 * Copyright (C) 2009 Texas Instruments

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * Support functions for the OMAP internal DMA channels.

	/*

	 * On OMAP1510, internal LCD controller will start the transfer

	 * when it gets enabled, so assume DMA running if LCD enabled.

 Check if LCD DMA is running */

			/* 1510 DMA requires the bottom address to be 2 more

 Suppress warning about uninitialized vars */

 1610 regs */

 Always set the source port as SDRAM for now*/

 Block interrupt enable */

 Set the double-indexed addressing mode */

 Ack the IRQ */

	/*

	 * Set the Enable bit only if an external controller is

	 * connected. Otherwise the OMAP internal controller will

	 * start the transfer when it gets enabled.

 Set some reasonable defaults */

		/*

		 * If DMA was already active set the end_prog bit to have

		 * the programmed register set loaded into the active

		 * register set.

 End_prog */

 Auto_init, repeat */

 this would prevent OMAP sleep */

/*

 * linux/arch/arm/mach-omap1/pm.c

 *

 * OMAP Power Management Routines

 *

 * Original code for the SA11x0:

 * Copyright (c) 2001 Cliff Brake <cbrake@accelent.com>

 *

 * Modified for the PXA250 by Nicolas Pitre:

 * Copyright (c) 2002 Monta Vista Software, Inc.

 *

 * Modified for the OMAP1510 by David Singleton:

 * Copyright (c) 2002 Monta Vista Software, Inc.

 *

 * Cleanup 2004 for OMAP1510/1610 by Dirk Behme <dirk.behme@de.bosch.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the

 * Free Software Foundation; either version 2 of the License, or (at your

 * option) any later version.

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN

 * NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,

 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT

 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF

 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON

 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF

 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * You should have received a copy of the GNU General Public License along

 * with this program; if not, write to the Free Software Foundation, Inc.,

 * 675 Mass Ave, Cambridge, MA 02139, USA.

/*

 * Let's power down on idle, but only if we are really

 * idle, because once we start down the path of

 * going idle we continue to do idle even if we get

 * a clock tick interrupt . .

	/*

	 * We should be able to remove the do_sleep variable and multiple

	 * tests above as soon as drivers, timer and DMA code have been fixed.

	 * Even the sleep block count should become obsolete.

/*

 * Configuration of the wakeup event is board specific. For the

 * moment we put it into this helper function. Later it may move

 * to board specific files.

	/*

	 * Turn off all interrupts except GPIO bank 1, L1-2nd level cascade,

	 * and the L2 wakeup interrupts: keypad and UART2. Note that the

	 * drivers must still separately call omap_set_gpio_wakeup() to

	 * wake up to a GPIO interrupt.

 INT_1610_WAKE_UP_REQ is needed for GPIO wakeup... */

  New IRQ agreement, recalculate in cascade order */

 ARM_CKCTL */

 ARM_IDLECT2 */

 ARM_RSTCT1 */

	/*

	 * Step 1: turn off interrupts (FIXME: NOTE: already disabled)

	/*

	 * Step 2: save registers

	 *

	 * The omap is a strange/beautiful device. The caches, memory

	 * and register state are preserved across power saves.

	 * We have to save and restore very little register state to

	 * idle the omap.

         *

	 * Save interrupt, MPUI, ARM and UPLD control registers.

 (Step 3 removed - we now allow deep sleep by default) */

	/*

	 * Step 4: OMAP DSP Shutdown

 stop DSP */

 shut down dsp_ck */

 temporarily enabling api_ck to access DSP registers */

 save DSP registers */

 Stop all DSP domain clocks */

	/*

	 * Step 5: Wakeup Event Setup

	/*

	 * Step 6: ARM and Traffic controller shutdown

 disable ARM watchdog */

	/*

	 * Step 6b: ARM and Traffic controller shutdown

	 *

	 * Step 6 continues here. Prepare jump to power management

	 * assembly code in internal SRAM.

	 *

	 * Since the omap_cpu_suspend routine has been copied to

	 * SRAM, we'll do an indirect procedure call to it and pass the

	 * contents of arm_idlect1 and arm_idlect2 so it can restore

	 * them when it wakes up and it will return.

	/*

	 * Step 6c: ARM and Traffic controller shutdown

	 *

	 * Jump to assembly code. The processor will stay there

	 * until wake up.

	/*

	 * If we are here, processor is woken up!

	/*

	 * Restore DSP clocks

 again temporarily enabling api_ck to access DSP registers */

 Restore DSP domain clocks */

	/*

	 * Restore ARM state, except ARM_IDLECT1/2 which omap_cpu_suspend did

	/*

	 * Re-enable interrupts

/*

 * Read system PM registers for debugging

 CONFIG_DEBUG_FS */

/*

 *	omap_pm_prepare - Do preliminary suspend work.

 *

 We cannot sleep in idle until we have resumed */

/*

 *	omap_pm_enter - Actually enter a sleep state.

 *	@state:		State we're entering.

 *

/**

 *	omap_pm_finish - Finish up suspend sequence.

 *

 *	This is called after we wake back up (or if entering the sleep state

 *	failed).

 OMAP16xx only */

	/*

	 * We copy the assembler sleep/wakeup routines to SRAM.

	 * These routines need to be in SRAM as that's the only

	 * memory the MPU can see when it wakes up.

	/* Program new power ramp-up time

	 * (0 for most boards since we don't lower voltage when in deep sleep)

 Setup ULPD POWER_CTRL_REG - enter deep sleep whenever possible */

 Configure IDLECT3 */

 configure LOW_PWR pin */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP SRAM detection and management

 *

 * Copyright (C) 2005 Nokia Corporation

 * Written by Tony Lindgren <tony@atomide.com>

/*

 * The amount of SRAM depends on the core type.

 * Note that we cannot try to test for SRAM here because writes

 * to secure SRAM will hang the system. Also the SRAM is not

 * yet mapped at this point.

 200K */

 192K */

 16K */

 On 730, bit 13 must always be 1 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-sx1-mmc.c

 *

 * Copyright (C) 2007 Instituto Nokia de Tecnologia - INdT

 * Author: Carlos Eduardo Aguiar <carlos.aguiar@indt.org.br>

 *

 * This code is based on linux/arch/arm/mach-omap1/board-h2-mmc.c, which is:

 * Copyright (C) 2007 Instituto Nokia de Tecnologia - INdT

 Cover switch is at OMAP_MPUIO(3) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/mcbsp.c

 *

 * Copyright (C) 2008 Instituto Nokia de Tecnologia

 * Contact: Eduardo Valentin <eduardo.valentin@indt.org.br>

 *

 * Multichannel mode not supported.

	/*

	 * On 1510, 1610 and 1710, McBSP1 and McBSP3

	 * are DSP public peripherals.

				/*

				 * DSP external peripheral reset

				 * FIXME: This should be moved to dsp code

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/io.c

 *

 * OMAP1 I/O mapping code

/*

 * The machine specific code may provide the extra mapping besides the

 * default mapping provided here.

/*

 * Maps common IO regions for omap1

/*

 * Common low-level hardware init for omap1.

	/* REVISIT: Refer to OMAP5910 Errata, Advisory SYS_1: "Timeout Abort

	 * on a Posted Write in the TIPB Bridge".

	/* Must init clocks early to assure that timer interrupt works

/*

 * NOTE: Please use ioremap + __raw_read/write where possible instead of these

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-omap1/clock_data.c

 *

 *  Copyright (C) 2004 - 2005, 2009-2010 Nokia Corporation

 *  Written by Tuukka Tikkanen <tuukka.tikkanen@elektrobit.com>

 *  Based on clocks.h by Tony Lindgren, Gordon McNutt and RidgeRun, Inc

 *

 * To do:

 * - Clocks that are only available on some chips should be marked with the

 *   chips that they are present on.

 for machine_is_* */

 for OTG_BASE */

 Some ARM_IDLECT1 bit shifts - used in struct arm_idlect1_clk */

 undocumented? */

 undocumented? */

 Some MOD_CONF_CTRL_0 bit shifts - used in struct clk.enable_bit */

 Some MOD_CONF_CTRL_1 bit shifts - used in struct clk.enable_bit */

 Some OTG_SYSCON_2-specific bit fields */

 Some SOFT_REQ_REG bit fields - used in struct clk.enable_bit */

 sys_ck gate for UART2 ? */

 sys_ck gate for USB host? */

 sys_ck gate for Bluetooth? */

 sys_ck gate for com proc? */

/*

 * Omap1 clocks

/*

 * FIXME: This clock seems to be necessary but no-one has asked for its

 * activation.  [ FIX: SoSSI, SSR ]

/*

 * FIXME: This clock seems to be necessary but no-one has asked for its

 * activation.  [ GPIO code for 1510 ]

	/* Note: On 16xx the frequency can be divided by 2 by programming

	 * ARM_CKCTL:ARM_INTHCK_SEL(14) to 1

	 *

	 * 1510 version is in TC clocks.

	/* Note: On 1510 the frequency follows TC_CK

	 *

	 * 16xx version is in MPU clocks.

 No-idle controlled by "tc_ck" */

 No-idle controlled by "tc_ck" */

/*

 * FIXME: This clock seems to be necessary but no-one has asked for its

 * activation.  [ pm.c (SRAM), CCP, Camera ]

 No-idle controlled by "tc_ck" */

/*

 * XXX The enable_bit here is misused - it simply switches between 12MHz

 * and 48MHz.  Reimplement with clksel.

 *

 * XXX does this need SYSC register handling?

 Direct from ULPD, no real parent */

/*

 * XXX The enable_bit here is misused - it simply switches between 12MHz

 * and 48MHz.  Reimplement with clksel.

 *

 * XXX SYSC register handling does not belong in the clock framework

 Direct from ULPD, no real parent */

/*

 * XXX The enable_bit here is misused - it simply switches between 12MHz

 * and 48MHz.  Reimplement with clksel.

 *

 * XXX does this need SYSC register handling?

 Direct from ULPD, no real parent */

/*

 * XXX The enable_bit here is misused - it simply switches between 12MHz

 * and 48MHz.  Reimplement with clksel.

 *

 * XXX does this need SYSC register handling?

 Direct from ULPD, no real parent */

/*

 * XXX The enable_bit here is misused - it simply switches between 12MHz

 * and 48MHz.  Reimplement with clksel.

 *

 * XXX SYSC register handling does not belong in the clock framework

 Direct from ULPD, no real parent */

 6 MHz output on W4_USB_CLKO */

 Direct from ULPD, no parent */

 Direct from ULPD, no parent */

 Actually 2 clocks, 12MHz and 48MHz */

 Direct from ULPD, no parent */

 OTG_SYSCON_2.OTG_PADEN == 0 (not 1510-compatible) */

 OTG_SYSCON_2 */

 Direct from ULPD, no parent */

 Direct from ULPD, no parent */

 Direct from ULPD, no parent */

 Direct from ULPD, no parent. May be enabled by ext hardware. */

 Direct from ULPD, no parent. May be enabled by ext hardware. */

 Direct from ULPD, no parent. May be enabled by ext hardware. */

 Direct from ULPD, no parent. May be enabled by ext hardware. */

 Functional clock is direct from ULPD, interface clock is ARMPER */

/*

 * XXX MOD_CONF_CTRL_0 bit 20 is defined in the 1510 TRM as

 * CONF_MOD_MCBSP3_AUXON ??

 Functional clock is direct from ULPD, interface clock is ARMPER */

 Functional clock is direct from ULPD, interface clock is ARMPER */

 Is smarter alias for */

/* virtual functional clock domain for I2C. Just for making sure that ARMXOR_CK

/*

 * clkdev integration

 non-ULPD clocks */

 CK_GEN1 clocks */

 CK_GEN2 clocks */

 CK_GEN3 clocks */

 ULPD clocks */

 Virtual clocks */

/*

 * init

 Default 12 MHz */

	/*

	 * Resets some clocks that may be left on from bootloader,

	 * but leaves serial clocks on.

 USB_REQ_EN will be disabled later if necessary (usb_dc_ck) */

 By default all idlect1 clocks are allowed to idle */

 Pointers to these clocks are needed by code in clock.c */

 We want to be in syncronous scalable mode */

	/*

	 * Initially use the values set by bootloader. Determine PLL rate and

	 * recalculate dependent clocks as if kernel had changed PLL or

	 * divisors. See also omap1_clk_late_init() that can reprogram dpll1

	 * after the SRAM is initialized.

 Base xtal rate */

 PLL enabled, apply multiplier and divisor */

 PLL disabled, apply bypass divisor */

 Cache rates for clocks connected to ck_ref (not dpll1) */

 Select slicer output as OMAP input clock */

 Amstrad Delta wants BCLK high when inactive */

 Turn off DSP and ARM_TIMXO. Make sure ARM_INTHCK is not divided */

 (on 730, bit 13 must not be cleared) */

 Put DSP/MPUI into reset until needed */

	/*

	 * According to OMAP5910 Erratum SYS_DMA_1, bit DMACK_REQ (bit 8)

	 * of the ARM_IDLECT2 register must be set to zero. The power-on

	 * default value of this bit is one.

 Turn LCD clock off also */

	/*

	 * Only enable those clocks we will need, let the drivers

	 * enable other clocks as necessary

 This should be done by timer code */

 Find the highest supported frequency and enable it */

		/*

		 * Reprogramming the DPLL is tricky, it must be done from SRAM.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * linux/arch/arm/mach-omap1/mux.c

 *

 * OMAP1 pin multiplexing configurations

 *

 * Copyright (C) 2003 - 2008 Nokia Corporation

 *

 * Written by Tony Lindgren

 MMC Pins */

 I2C interface */

 SPI pins */

 UART pins */

 CONFIG_ARCH_OMAP730 || CONFIG_ARCH_OMAP850 */

/*

 *	 description		mux  mode   mux	 pull pull  pull  pu_pd	 pu  dbg

 *				reg  offset mode reg  bit   ena	  reg

 UART2 (COM_UART_GATING), conflicts with USB2 */

 UART3 (GIGA_UART_GATING) */

 PWT & PWL, conflicts with UART3 */

 USB internal master generic */

 works around erratum:  W4_USB_PUEN and W4_USB_PUDIS are switched! */

 USB1 master */

 USB2 master */

 OMAP-1510 GPIO */

 OMAP1610 GPIO */

 OMAP-1710 GPIO */

 MPUIO */

 MCBSP2 */

 MCBSP3 NOTE: Mode must 1 for clock */

 Misc ballouts */

 OMAP-1610 MMC2 */

 OMAP-1610 External Trace Interface */

 OMAP16XX GPIO */

 OMAP-1610 uWire */

 OMAP-1610 SPI */

 OMAP-1610 Flash */

 First MMC interface, same on 1510, 1610 and 1710 */

 OMAP-1610 USB0 alternate configuration */

 USB2 interface */

 16XX UART */

 I2C interface */

 Keypad */

 Power management */

 MCLK Settings */

 CompactFlash controller, conflicts with MMC1 */

 parallel camera */

 serial camera */

 REVISIT 5912 spec sez CCP_* can't pullup or pulldown ... ? */

 CONFIG_ARCH_OMAP15XX || CONFIG_ARCH_OMAP16XX */

 Check the mux register in question */

 The mux registers always seem to be 3 bits long */

 Check for pull up or pull down selection on 1610 */

 Use pull up */

 Use pull down */

 Check for an associated pull down register */

 Low bit = pull enabled */

 High bit = pull disabled */

/*

 * Sets the Omap MUX and PULL_DWN registers based on the table

 CONFIG_OMAP_MUX */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * linux/arch/arm/mach-omap1/devices.c

 *

 * OMAP1 platform device setup/initialization

-------------------------------------------------------------------------*/

 NOTE: DAT2 can be on W10 (here) or M15 */

 Block 2 is on newer chips, and has many pinout options */

 These are needed for the level shifter */

 Feedback clock must be set on OMAP-1710 MMC2 */

/*

 * Register MMC devices.

 return device handle to board setup code */

-------------------------------------------------------------------------*/

 OMAP7xx SPI support */

-------------------------------------------------------------------------*/

/* Numbering for the SPI-capable controllers when used for SPI:

 * spi		= 1

 * uwire	= 2

 * mmc1..2	= 3..4

 * mcbsp1..3	= 5..7

	/* FIXME define and use a boot tag; not all boards will be hooking

	 * up devices to the microwire controller, and multi-board configs

	 * mean that CONFIG_SPI_OMAP_UWIRE may be configured anyway...

	/* board-specific code must configure chipselects (only a few

	 * are normally used) and SCLK/SDI/SDO (each has two choices).

-------------------------------------------------------------------------*/

/*

 * This gets called after board-specific INIT_MACHINE, and initializes most

 * on-chip peripherals accessible on this board (except for few like USB):

 *

 *  (a) Does any "standard config" pin muxing needed.  Board-specific

 *	code will have muxed GPIO pins and done "nonstandard" setup;

 *	that code could live in the boot loader.

 *  (b) Populating board-specific platform_data with the data drivers

 *	rely on to handle wiring variations.

 *  (c) Creating platform devices as meaningful on this board and

 *	with this kernel configuration.

 *

 * Claiming GPIOs, and setting their direction and initial values, is the

 * responsibility of the device drivers.  So is responding to probe().

 *

 * Board-specific knowledge like creating devices or pin setup is to be

 * kept out of drivers as much as possible.  In particular, pin setup

 * may be handled by the boot loader, and drivers should expect it will

 * normally have been done by the time they're probed.

	/* please keep these calls, and their implementations above,

	 * in alphabetical order so they're easier to sort through.

/*

 * linux/arch/arm/mach-omap1/time.c

 *

 * OMAP Timers

 *

 * Copyright (C) 2004 Nokia Corporation

 * Partial timer rewrite and additional dynamic tick timer support by

 * Tony Lindgen <tony@atomide.com> and

 * Tuukka Tikkanen <tuukka.tikkanen@elektrobit.com>

 *

 * MPU timer code based on the older MPU timer code for OMAP

 * Copyright (C) 2000 RidgeRun, Inc.

 * Author: Greg Lonnon <glonnon@ridgerun.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the

 * Free Software Foundation; either version 2 of the License, or (at your

 * option) any later version.

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN

 * NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,

 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT

 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF

 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON

 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF

 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * You should have received a copy of the  GNU General Public License along

 * with this program; if not, write  to the Free Software Foundation, Inc.,

 * 675 Mass Ave, Cambridge, MA 02139, USA.

 CNTL_TIMER, R/W */

 LOAD_TIM,   W */

 READ_TIM,   R */

/*

 * ---------------------------------------------------------------------------

 * MPU timer 1 ... count down to zero, interrupt, reload

 * ---------------------------------------------------------------------------

/*

 * ---------------------------------------------------------------------------

 * MPU timer 2 ... free running 32-bit clock source and scheduler clock

 * ---------------------------------------------------------------------------

 PTV = 0 */

 CONFIG_OMAP_MPU_TIMER */

/*

 * ---------------------------------------------------------------------------

 * Timer initialization

 * ---------------------------------------------------------------------------

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-omap1/clock.c

 *

 *  Copyright (C) 2004 - 2005, 2009-2010 Nokia Corporation

 *  Written by Tuukka Tikkanen <tuukka.tikkanen@elektrobit.com>

 *

 *  Modified to use omap shared clock framework by

 *  Tony Lindgren <tony@atomide.com>

/*

 * Omap1 specific clock functions

	/* This function checks for following limitations set

	 * by the hardware (all conditions must be true):

	 * DSPMMU_CK == DSP_CK  or  DSPMMU_CK == DSP_CK/2

	 * ARM_CK >= TC_CK

	 * DSP_CK >= TC_CK

	 * DSPMMU_CK >= TC_CK

	 *

	 * In addition following rules are enforced:

	 * LCD_CK <= TC_CK

	 * ARMPER_CK <= TC_CK

	 *

	 * However, maximum frequencies are not checked for!

	/* Note: If target frequency is too low, this function will return 4,

	 * which is invalid value. Caller must check for this value and act

	 * accordingly.

	 *

	 * Note: This function does not check for following limitations set

	 * by the hardware (all conditions must be true):

	 * DSPMMU_CK == DSP_CK  or  DSPMMU_CK == DSP_CK/2

	 * ARM_CK >= TC_CK

	 * DSP_CK >= TC_CK

	 * DSPMMU_CK >= TC_CK

 Calculate divisor encoded as 2-bit exponent */

	/* Calculate divisor encoded as 2-bit exponent

	 *

	 * The clock control bits are in DSP domain,

	 * so api_ck is needed for access.

	 * Note that DSP_CKCTL virt addr = phys addr, so

	 * we must use __raw_readw() instead of omap_readw().

 MPU virtual clock functions */

 Find the highest supported frequency <= rate and switch to it */

 Can check only after xtal frequency check */

	/*

	 * In most cases we should not need to reprogram DPLL.

	 * Reprogramming the DPLL is tricky, it must be done from SRAM.

 XXX Do we need to recalculate the tree below DPLL1 at this point? */

 Find the highest supported frequency <= rate */

 Can check only after xtal frequency check */

	/* MCLK and BCLK divisor selection is not linear:

	 * freq = 96MHz / dsor

	 *

	 * RATIO_SEL range: dsor <-> RATIO_SEL

	 * 0..6: (RATIO_SEL+2) <-> (dsor-2)

	 * 6..48:  (8+(RATIO_SEL-6)*2) <-> ((dsor-8)/2+6)

	 * Minimum dsor is 2 and maximum is 96. Odd divisors starting from 9

	 * can not be used.

 XXX Only needed on 1510 */

 External clock (MCLK & BCLK) functions */

 Round towards slower frequency */

 Determine current rate and ensure clock is based on 96MHz APLL */

 XXX SYSC register handling does not belong in the clock framework */

 Set smart idle acknowledgement mode */

 XXX SYSC register handling does not belong in the clock framework */

 Set force idle acknowledgement mode */

 XXX SYSC register handling does not belong in the clock framework */

/*

 * Omap1 clock reset and init functions

	/* Clocks in the DSP domain need api_ck. Just assume bootloader

 Is the clock already disabled? */

/*

 * Optional clock functions defined in include/linux/clk.h

/*

 * OMAP specific clock functions shared between omap1 and omap2

 Used for clocks that always have same value as the parent clock */

/*

 * Used for clocks that have the same value as the parent clock,

 * divided by some factor

	/* now do the debugfs renaming to reattach the child

 Propagate rate to children */

/**

 * recalculate_root_clocks - recalculate and propagate all root clocks

 *

 * Recalculates all root clocks (clocks with no parent), which if the

 * clock's .recalc is set correctly, should also propagate their rates.

 * Called at init.

/**

 * clk_preinit - initialize any fields in the struct clk before clk init

 * @clk: struct clk * to initialize

 *

 * Initialize any struct clk fields needed before normal clk initialization

 * can run.  No return value.

	/*

	 * trap out already registered clocks

/**

 * omap_clk_get_by_name - locate OMAP struct clk by its name

 * @name: name of the struct clk to locate

 *

 * Locate an OMAP struct clk by its name.  Assumes that struct clk

 * names are unique.  Returns NULL if not found or a pointer to the

 * struct clk if found.

/*

 * Low level helpers

/*

 * Dummy clock

 *

 * Used for clock aliases that are needed on some OMAPs, but not others

/*

 *

/*

 * Disable any unused clocks left on by the bootloader

/*

 *	debugfs support to trace clock tree hierarchy and attributes

 defined(CONFIG_PM_DEBUG) && defined(CONFIG_DEBUG_FS) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Amstrad E3 FIQ handling

 *

 *  Copyright (C) 2009 Janusz Krzysztofik

 *  Copyright (c) 2006 Matt Callow

 *  Copyright (c) 2004 Amstrad Plc

 *  Copyright (C) 2001 RidgeRun, Inc.

 *

 * Parts of this code are taken from linux/arch/arm/mach-omap/irq.c

 * in the MontaVista 2.4 kernel (and the Amstrad changes therein)

/*

 * This buffer is shared between FIQ and IRQ contexts.

 * The FIQ and IRQ isrs can both read and write it.

 * It is structured as a header section several 32bit slots,

 * followed by the circular buffer where the FIQ isr stores

 * keystrokes received from the qwerty keyboard.  See

 * <linux/platform_data/ams-delta-fiq.h> for details of offsets.

	/*

	 * For each handled GPIO interrupt, keep calling its interrupt handler

	 * until the IRQ counter catches the FIQ incremented interrupt counter.

			/*

			 * handle_simple_irq() that OMAP GPIO edge

			 * interrupts default to since commit 80ac93c27441

			 * requires interrupt already acked and unmasked.

 Store irq_chip location for IRQ handler use */

 Store irq_data location for IRQ handler use */

		/*

		 * FIQ handler takes full control over serio data and clk GPIO

		 * pins.  Initialize them and keep requested so nobody can

		 * interfere.  Fail if any of those two couldn't be requested.

	/*

	 * Since no set_type() method is provided by OMAP irq chip,

	 * switch to edge triggered interrupt type manually.

	/*

	 * Initialise the buffer which is shared

	 * between FIQ mode and IRQ mode

	/*

	 * FIQ mode r9 always points to the fiq_buffer, because the FIQ isr

	 * will run in an unpredictable context. The fiq_buffer is the FIQ isr's

	 * only means of communication with the IRQ level and other kernel

	 * context code.

	/*

	 * Redirect GPIO interrupts to FIQ

 Initialize serio device IRQ resource and platform_data */

	/*

	 * Since FIQ handler performs handling of GPIO registers for

	 * "keybrd_clk" IRQ pin, ams_delta_serio driver used to set

	 * handle_simple_irq() as active IRQ handler for that pin to avoid

	 * bad interaction with gpio-omap driver.  This is no longer needed

	 * as handle_simple_irq() is now the default handler for OMAP GPIO

	 * edge interrupts.

	 * This comment replaces the obsolete code which has been removed

	 * from the ams_delta_serio driver and stands here only as a reminder

	 * of that dependency on gpio-omap driver behavior.

 SPDX-License-Identifier: GPL-2.0-only

/*

* linux/arch/arm/mach-omap1/board-sx1.c

*

* Modified from board-generic.c

*

* Support for the Siemens SX1 mobile phone.

*

* Original version : Vladimir Ananiev (Vovan888-at-gmail com)

*

* Maintainters : Vladimir Ananiev (aka Vovan888), Sergge

*		oslik.ru

 Write to I2C device */

 I2C address of chip */

 register num */

 register data */

 Read from I2C device */

 I2C address of chip */

 register num */

 I2C address */

 set keyboard backlight intensity */

 get current keylight intensity */

 set LCD backlight intensity */

 get current LCD backlight intensity */

 set LCD backlight power on/off */

 set USB power on/off */

----------- Keypad -------------------------*/

 camera Qt::Key_F17 */

 voice memo Qt::Key_F14 */

 voice memo */

 voice memo */

 red button Qt::Key_Hangup */

 joystick press or Qt::Key_Select */

 "*" */

 # F13 Toggle input method Qt::Key_F13 */

 green button Qt::Key_Call */

 left soft Qt::Key_Context1 */

 right soft Qt::Key_Back */

 shift */

 C (clear) */

 menu Qt::Key_Menu */

----------- MTD -------------------------*/

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 kernel */

 file system */

 MTD Intel 4000 flash - new flashes */

----------- USB -------------------------*/

----------- LCD -------------------------*/

-----------------------------------------*/

-----------------------------------------*/

 mux pins for uarts */

 turn on USB power */

 sx1_setusbpower(1); can't do it here because i2c is not ready */

A_IRDA_OFF = 1 */

A_SWITCH = 0 */

A_USB_ON = 0 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/fpga.c

 *

 * Interrupt handler for OMAP-1510 Innovator FPGA

 *

 * Copyright (C) 2001 RidgeRun, Inc.

 * Author: Greg Lonnon <glonnon@ridgerun.com>

 *

 * Copyright (C) 2002 MontaVista Software, Inc.

 *

 * Separated FPGA interrupts from innovator1510.c and cleaned up for 2.6

 * Copyright (C) 2004 Nokia Corporation by Tony Lindrgen <tony@atomide.com>

 Don't need to explicitly ACK FPGA interrupts */

/*

 * All of the FPGA interrupt request inputs except for the touchscreen are

 * edge-sensitive; the touchscreen is level-sensitive.  The edge-sensitive

 * interrupts are acknowledged as a side-effect of reading the interrupt

 * status register from the FPGA.  The edge-sensitive interrupt inputs

 * cause a problem with level interrupt requests, such as Ethernet.  The

 * problem occurs when a level interrupt request is asserted while its

 * interrupt input is masked in the FPGA, which results in a missed

 * interrupt.

 *

 * In an attempt to workaround the problem with missed interrupts, the

 * mask_ack routine for all of the FPGA interrupts has been changed from

 * fpga_mask_ack_irq() to fpga_ack_irq() so that the specific FPGA interrupt

 * being serviced is left unmasked.  We can do this because the FPGA cascade

 * interrupt is run with all interrupts masked.

 *

 * Limited testing indicates that this workaround appears to be effective

 * for the smc9194 Ethernet driver used on the Innovator.  It should work

 * on other FPGA interrupts as well, but any drivers that explicitly mask

 * interrupts at the interrupt controller via disable_irq/enable_irq

 * could pose a problem.

			/*

			 * The touchscreen interrupt is level-sensitive, so

			 * we'll use the regular mask_ack routine for it.

			/*

			 * All FPGA interrupts except the touchscreen are

			 * edge-sensitive, so we won't mask them.

	/*

	 * The FPGA interrupt line is connected to GPIO13. Claim this pin for

	 * the ARM.

	 *

	 * NOTE: For general GPIO/MPUIO access and interrupts, please see

	 * gpio.[ch]

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP1/OMAP7xx - specific DMA driver

 *

 * Copyright (C) 2003 - 2008 Nokia Corporation

 * Author: Juha Yrjl <juha.yrjola@nokia.com>

 * DMA channel linking for 1610 by Samuel Ortiz <samuel.ortiz@nokia.com>

 * Graphics DMA and LCD DMA graphics tranformations

 * by Imre Deak <imre.deak@nokia.com>

 * OMAP2/3 support Copyright (C) 2004-2007 Texas Instruments, Inc.

 * Some functions based on earlier dma-omap.c Copyright (C) 2001 RidgeRun, Inc.

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 * Converted DMA library into platform driver

 *                   - G, Manjunath Kondaiah <manjugk@ti.com>

 Common Registers */

 15xx only */

 Channel specific register offsets */

 Handled in lcd_dma.c */

 irq's for omap16xx and omap7xx */

 Clear pending interrupts */

 Disable OMAP 3.0/3.1 compatibility mode. */

	/*

	 * Erratum 3.2/3.3: sometimes 0 is returned if CSAC/CDAC is

	 * read before the DMA controller finished disabling the channel.

 OMAP730, OMAP850 */

 OMAP1510, OMAP1610*/

 Valid attributes for omap1 plus processors */

 available logical channels */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/serial.c

 *

 * OMAP1 serial support.

/*

 * Internal UARTs need to be initialized for the 8250 autoconfig to work

 * properly. Note that the TX watermark initialization may not be needed

 * once the 8250.c watermark handling code is merged.

 disable UART */

 TX watermark */

 enable UART */

/*

 * Note that on Innovator-1510 UART2 pins conflict with USB2.

 * By default UART2 does not work on Innovator-1510 if you have

 * USB OHCI enabled. To use UART2, you must disable USB2 first.

 Don't look at UARTs higher than 2 for omap7xx */

 Static mapping, never released */

 Need to do something with serial port right after wake-up? */

/*

 * Reroutes serial RX lines to GPIO lines for the duration of

 * sleep to allow waking up the device from serial port even

 * in deep sleep.

 CONFIG_OMAP_SERIAL_WAKE */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * HTC Herald board configuration

 * Copyright (C) 2009 Cory Maccarrone <darkstar6262@gmail.com>

 * Copyright (C) 2009 Wing Linux

 *

 * Based on the board-htcwizard.c file from the linwizard project:

 * Copyright (C) 2006 Unai Uribarri

 * Copyright (C) 2008 linwizard.sourceforge.net

 LCD register definition */

 GPIO definitions for the power button and keyboard slide switch */

 GPIO definitions for the touchscreen */

 HTCPLD definitions */

/*

 * CPLD Logic

 *

 * Chip 3 - 0x03

 *

 * Function            7 6 5 4  3 2 1 0

 * ------------------------------------

 * DPAD light          x x x x  x x x 1

 * SoundDev            x x x x  1 x x x

 * Screen white        1 x x x  x x x x

 * MMC power on        x x x x  x 1 x x

 * Happy times (n)     0 x x x  x 1 x x

 *

 * Chip 4 - 0x04

 *

 * Function            7 6 5 4  3 2 1 0

 * ------------------------------------

 * Keyboard light      x x x x  x x x 1

 * LCD Bright (4)      x x x x  x 1 1 x

 * LCD Bright (3)      x x x x  x 0 1 x

 * LCD Bright (2)      x x x x  x 1 0 x

 * LCD Bright (1)      x x x x  x 0 0 x

 * LCD Off             x x x x  0 x x x

 * LCD image (fb)      1 x x x  x x x x

 * LCD image (white)   0 x x x  x x x x

 * Caps lock LED       x x 1 x  x x x x

 *

 * Chip 5 - 0x05

 *

 * Function            7 6 5 4  3 2 1 0

 * ------------------------------------

 * Red (solid)         x x x x  x 1 x x

 * Red (flash)         x x x x  x x 1 x

 * Green (GSM flash)   x x x x  1 x x x

 * Green (GSM solid)   x x x 1  x x x x

 * Green (wifi flash)  x x 1 x  x x x x

 * Blue (bt flash)     x 1 x x  x x x x

 * DPAD Int Enable     1 x x x  x x x 0

 *

 * (Combinations of the above can be made for different colors.)

 * The direction pad interrupt enable must be set each time the

 * interrupt is handled.

 *

 * Chip 6 - 0x06

 *

 * Function            7 6 5 4  3 2 1 0

 * ------------------------------------

 * Vibrator            x x x x  1 x x x

 * Alt LED             x x x 1  x x x x

 * Screen white        1 x x x  x x x x

 * Screen white        x x 1 x  x x x x

 * Screen white        x 0 x x  x x x x

 * Enable kbd dpad     x x x x  x x 0 x

 * Happy Times         0 1 0 x  x x 0 x

/*

 * HTCPLD GPIO lines start 16 after OMAP_MAX_GPIO_LINES to account

 * for the 16 MPUIO lines.

/*

 * The htcpld chip requires a gpio write to a specific line

 * to re-enable interrupts after one has occurred.

 Chip 5 */

 Chip 6 */

 Keyboard definition */

 Mail button */

 Camera */

 Send key */

 Volume up */

 Right bar (landscape) */

 Win key (portrait) */

 Right bar (protrait) */

 Windows key */

 OK key */

 Shift */

 Voice button */

 End key */

 Volume down */

 Left bar (landscape) */

 OK button (portrait) */

 Left bar (portrait) */

 GPIO buttons for keyboard slide and power button */

 LEDs for the Herald.  These connect to the HTCPLD GPIO device. */

 HTC PLD chips */

 USB Device */

 LCD Device resources */

 MMC Card */

 Platform devices for the Herald */

/*

 * Touchscreen

/*

 * Init functions from here on

 disable controller if active */

 wait for end of frame */

 turn off DMA */

	/*

	 * The LCD panel must be disabled and DMA turned off here, as doing

	 * it later causes the LCD never to reinitialize.

 Disable watchdog if running */

		/*

		 * disable a potentially running watchdog timer before

		 * it kills us.

 Request the GPIOs we need to control here */

 force USB_EN GPIO to 0 */

 output low */

 output low */

 input */

 input */

 Do board initialization before we register all the devices */

 Maintainer: Cory Maccarrone <darkstar6262@gmail.com> */

 Maintainer: wing-linux.sourceforge.net */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-generic.c

 *

 * Modified from board-innovator1510.c

 *

 * Code for generic OMAP board. Should work on many OMAP systems where

 * the device drivers take care of all the necessary hardware initialization.

 * Do not put any board specific code to this file; create a new machine

 * type if you need custom low-level initializations.

 assume no Mini-AB port */

 mux pins for uarts */

 Maintainer: Tony Lindgren <tony@atomide.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-h2.c

 *

 * Board specific inits for OMAP-1610 H2

 *

 * Copyright (C) 2001 RidgeRun, Inc.

 * Author: Greg Lonnon <glonnon@ridgerun.com>

 *

 * Copyright (C) 2002 MontaVista Software, Inc.

 *

 * Separated FPGA interrupts from innovator1510.c and cleaned up for 2.6

 * Copyright (C) 2004 Nokia Corporation by Tony Lindrgen <tony@atomide.com>

 *

 * H2 specific changes and cleanup

 * Copyright (C) 2004 Nokia Corporation by Imre Deak <imre.deak@nokia.com>

 The first 16 SoC GPIO lines are on this GPIO chip */

 At OMAP1610 Innovator the Ethernet is directly connected to CS1 */

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 kernel */

 file system */

 This is on CS3, wherever it's mapped */

	/* REVISIT:  enable these partitions if you make NAND BOOT

	 * work on your H2 (rev C or newer); published versions of

	 * x-load only support P2 and H3.

 force read-only */

 force read-only */

 Physical */

 Active low since the irq triggers on falling edge */

 usb1 has a Mini-AB port and external isp1301 transceiver */

 0:host(off) 1:dev|otg 2:disabled */

 .hmc_mode	= 21,*/	
 needs OTG cable, or NONSTANDARD (B-to-MiniB) */

 1:dev|otg(off) 1:host 2:disabled */

	/* Here we assume the NOR boot config:  NOR on CS3 (possibly swapped

	 * to address 0 by a dip switch), NAND on CS2B.  The NAND driver will

	 * notice whether a NAND chip is enabled at probe time.

	 *

	 * FIXME revC boards (and H3) support NAND-boot, with a dip switch to

	 * put NOR on CS2B and NAND (which on H2 may be 16bit) on CS3.  Try

	 * detecting that in code here, to avoid probing every possible flash

	 * configuration...

 MMC:  card detect and WP */

 omap_cfg_reg(U19_ARMIO1); */		
 WP */

 Mux pins for keypad */

 GPIO based LEDs */

 ISP1301 IRQ wired at M14 */

 Maintainer: Imre Deak <imre.deak@nokia.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-perseus2.c

 *

 * Modified from board-generic.c

 *

 * Original OMAP730 support by Jean Pihet <j-pihet@ti.com>

 * Updated for 2.6 by Kevin Hilman <kjh@hilman.org>

 Physical */

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 kernel */

 rest of flash is a file system */

 Early, board-dependent init */

	/*

	 * Hold GSM Reset until needed

	/*

	 * UARTs -> done automagically by 8250 driver

	/*

	 * CSx timings, GPIO Mux ... setup

 Flash: CS0 timings setup */

	/*

	 * Ethernet support through the debug board

	 * CS1 timings setup

	/*

	 * Configure MPU_EXT_NIRQ IO in IO_CONF9 register,

	 * It is used as the Ethernet controller interrupt

 Mux pins for keypad */

 Only FPGA needs to be mapped here. All others are done with ioremap */

 Maintainer: Kevin Hilman <kjh@hilman.org> */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Platform level USB initialization for FS USB OTG controller on omap1

 *

 * Copyright (C) 2004 Texas Instruments, Inc.

/* These routines should handle the standard chip-specific modes

 * for usb0/1/2 ports, covering basic mux and transceiver setup.

 *

 * Some board-*.c files will need to set up additional mux options,

 * like for suspend handling, vbus sensing, GPIOs, and the D+ pullup.

/* TESTED ON:

 *  - 1611B H2 (with usb1 mini-AB) using standard Mini-B or OTG cables

 *  - 5912 OSK OHCI (with usb0 standard-A), standard A-to-B cables

 *  - 5912 OSK UDC, with *nonstandard* A-to-A cable

 *  - 1510 Innovator UDC with bundled usb0 cable

 *  - 1510 Innovator OHCI with bundled usb1/usb2 cable

 *  - 1510 Innovator OHCI with custom usb0 cable, feeding 5V VBUS

 *  - 1710 custom development board using alternate pin group

 *  - 1710 H3 (with usb1 mini-AB) using standard Mini-B or OTG cables

 NOTE:  no bus or clock setup (yet?) */

omap_writew(0, OTG_IRQ_EN);

 pin muxing and transceiver pinouts */

 alt pingroup 2 */

 B_ASE0_BRST */;

 leave USB clocks/controllers off until needed */

 order is significant! */

 registers */

 general IRQ */

 PIO IRQ */

 SOF IRQ */

 IRQ numbers for omap7xx */

 The dmamask must be set for OHCI to work */

 order is significant! */

 pulldown D+/D- */

 omap_cfg_reg(P9_USB_DP);

 omap_cfg_reg(R8_USB_DM);

 This works on 1510-Innovator */

		/* NOTES:

		 *  - peripheral should configure VBUS detection!

		 *  - only peripherals may use the internal D+/D- pulldowns

		 *  - OTG support on this port not yet written

 Don't do this for omap7xx -- it causes USB to not work correctly */

 alternate pin config, external transceiver */

	/* NOTE:  SPEED and SUSP aren't configured here.  OTG hosts

	 * may be able to use I2C requests to set those bits along

	 * with VBUS switching and overcurrent detection.

 external transceiver */

 SUSP

 SUSP

 SUSP

 NOTE omap1 erratum: must leave USB2_UNI_R set if usb0 in use */

 external transceiver */

 there is no USB2_SPEED */

 FIXME omap_cfg_reg(USB2_SPEED);

 omap_cfg_reg(USB2_SUSP);

 OMAP-1510 OHCI has its own MMU for DMA */

 Should be same as SDRAM size */

/*

 * Bus address is physical address, except for OMAP-1510 Local Bus.

 * OMAP-1510 bus address is translated into a Local Bus address if the

 * OMAP bus type is lbus.

/*

 * OMAP-1510 specific Local Bus clock on/off

/*

 * OMAP-1510 specific Local Bus initialization

 * NOTE: This assumes 32MB memory size in OMAP1510LB_MEMSIZE.

 *       See also arch/mach-omap/memory.h for __virt_to_dma() and

 *       __dma_to_virt() which need to match with the physical

 *       Local Bus address below.

 Configure the Local Bus MMU table */

 Enable the walking table */

 ULPD_DPLL_CTRL */

 ULPD_APLL_CTRL */

 use DPLL for 48 MHz function clock */

 udc driver gates 48MHz by D+ pullup */

 hcd explicitly gates 48MHz */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-h3-mmc.c

 *

 * Copyright (C) 2007 Instituto Nokia de Tecnologia - INdT

 * Author: Felipe Balbi <felipe.lima@indt.org.br>

 *

 * This code is based on linux/arch/arm/mach-omap2/board-n800-mmc.c, which is:

 * Copyright (C) 2006 Nokia Corporation

/*

 * H3 could use the following functions tested:

 * - mmc_get_cover_state that uses OMAP_MPUIO(1)

 * - mmc_get_wp that maybe uses OMAP_MPUIO(3)

/*

 * OMAP16xx specific gpio init

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 *

 * Author:

 *	Charulatha V <charu@ti.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 smart idle, enable wakeup */

 mpu gpio */

 gpio1 */

 gpio2 */

 gpio3 */

 gpio4 */

/*

 * omap16xx_gpio_init needs to be done before

 * machine_init functions access gpio APIs.

 * Hence omap16xx_gpio_init is a postcore_initcall.

	/*

	 * Enable system clock for GPIO module.

	 * The CAM_CLK_CTRL *is* really the right place.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-palmz71.c

 *

 * Modified from board-generic.c

 *

 * Support for the Palm Zire71 PDA.

 *

 * Original version : Laurent Gonzalez

 *

 * Modified for zire71 : Marek Vasut

 PalmOS "Small ROM", contains the bootloader and the debugger */

 PalmOS "Big ROM", a filesystem with all the OS code and data */

		/*

		 * 0x5f0000 bytes big in the multi-language ("EFIGS") version,

		 * 0x7b0000 bytes in the English-only ("enUS") version.

 internal, no capacitor */

 MicroWire (bus 2) CS0 has an ads7846e */

 max sample rate at 3V */

 command + data + overhead */,

 Mini-B only receptacle */

 Only set GPIO1 so we have a working serial */

 Set MMC/SD host WP pin as input */

 Monitor the Power-cable-connected signal */

 mux pins for uarts */

/*

 * OMAP1 Dual-Mode Timers - platform device registration

 *

 * Contains first level initialization routines which internally

 * generates timer device information and registers with linux

 * device model. It also has a low level function to change the timer

 * input clock source.

 *

 * Copyright (C) 2011 Texas Instruments Incorporated - https://www.ti.com/

 * Tarun Kanti DebBarma <tarun.kanti@ti.com>

 * Thara Gopinath <thara@ti.com>

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

			/*

			 * not supposed to reach here.

			 * this is to remove warning.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * File: arch/arm/plat-omap/fb.c

 *

 * Framebuffer device registration for TI OMAP platforms

 *

 * Copyright (C) 2006 Nokia Corporation

 * Author: Imre Deak <imre.deak@nokia.com>

	/*

	 * If the board file has not set the lcd config with

	 * omapfb_set_lcd_config(), don't bother registering the omapfb device

/*

 * OMAP7xx specific gpio init

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 *

 * Author:

 *	Charulatha V <charu@ti.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 mpu gpio */

 gpio1 */

 gpio2 */

 gpio3 */

 gpio4 */

 gpio5 */

 gpio6 */

/*

 * omap7xx_gpio_init needs to be done before

 * machine_init functions access gpio APIs.

 * Hence omap7xx_gpio_init is a postcore_initcall.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-nokia770.c

 *

 * Modified from board-generic.c

 assume no Mini-AB port */

 Only the second MMC controller is used */

 clk */

 dat */

 sel */

 CONFIG_I2C_CBUS_GPIO */

 CONFIG_I2C_CBUS_GPIO */

	/* On Nokia 770, the SleepX signal is masked with an

	 * MPUIO line by default.  It has to be unmasked for it

 SleepX mask direction */

 Unmask SleepX signal */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-h3.c

 *

 * This file contains OMAP1710 H3 specific code.

 *

 * Copyright (C) 2004 Texas Instruments, Inc.

 * Copyright (C) 2002 MontaVista Software, Inc.

 * Copyright (C) 2001 RidgeRun, Inc.

 * Author: RidgeRun, Inc.

 *         Greg Lonnon (glonnon@ridgerun.com) or info@ridgerun.com

 In OMAP1710 H3 the Ethernet is directly connected to CS1 */

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 kernel */

 file system */

 This is on CS3, wherever it's mapped */

 REVISIT: enable these partitions if you make NAND BOOT work */

 force read-only */

 force read-only */

 Physical */

 Physical */

 .platform_data	= &tsc_platform_data, */

 usb1 has a Mini-AB port and external isp1301 transceiver */

 0:host(off) 1:dev|otg 2:disabled */

 NONSTANDARD CABLE NEEDED (B-to-Mini-B) */

 1:dev|otg(off) 1:host 2:disabled */

	/* Here we assume the NOR boot config:  NOR on CS3 (possibly swapped

	 * to address 0 by a dip switch), NAND on CS2B.  The NAND driver will

	 * notice whether a NAND chip is enabled at probe time.

	 *

	 * H3 support NAND-boot, with a dip switch to put NOR on CS2B and NAND

	 * (which on H2 may be 16bit) on CS3.  Try detecting that in code here,

	 * to avoid probing every possible flash configuration...

 GPIO10 Func_MUX_CTRL reg bit 29:27, Configure V2 to mode1 as GPIO */

 GPIO10 pullup/down register, Enable pullup on GPIO10 */

 Mux pins for keypad */

 GPIO based LEDs */

 Maintainer: Texas Instruments, Inc. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-ams-delta.c

 *

 * Modified from board-generic.c

 *

 * Board specific inits for the Amstrad E3 (codename Delta) videophone

 *

 * Copyright (C) 2006 Jonathan McDowell <noodles@earth.li>

 Advert    */

 Games     */

 Directory */

 Internet  */

 Services  */

 VoiceMail */

 Delete    */

 Play      */

 Up        */

 Down      */

 ReadEmail */

 Stop      */

 Numeric keypad portion */

 # key     */

 Mute      */

 Recall    */

 Redial    */

 Handsfree */

 Video     */

 Photo     */

 Home      */

 Office    */

 Mobile    */

 SMS       */

 Email     */

 QWERTY portion of keypad */

 Vol up    */

 Vol down  */

 AMS_DELTA_LATCH1 */

 AMS_DELTA_LATCH2 */

 AMS_DELTA_MODEM */

/*

 * Define partitions for flash device

		/*

		 * Initialize IRQ resource with invalid IRQ number.

		 * It will be replaced with dynamically allocated GPIO IRQ

		 * obtained from GPIO chip as soon as the chip is available.

		/*

		 * Initialize .platform_data explicitly with NULL to

		 * indicate it is going to be used.  It will be replaced

		 * with FIQ buffer address as soon as FIQ is initialized.

	/*

	 * Initialize supply .dev_name with NULL.  It will be replaced

	 * with serio dev_name() as soon as the serio device is registered.

/*

 * Some drivers may not use GPIO lookup tables but need to be provided

 * with GPIO numbers.  The same applies to GPIO based IRQ lines - some

 * drivers may even not use GPIO layer but expect just IRQ numbers.

 * We could either define GPIO lookup tables then use them on behalf

 * of those devices, or we can use GPIO driver level methods for

 * identification of GPIO and IRQ numbers. For the purpose of the latter,

 * defina a helper function which identifies GPIO chips by their labels.

/*

 * Obtain MODEM IRQ GPIO descriptor using its hardware pin

 * number and assign related IRQ number to the MODEM port.

 * Keep the GPIO descriptor open so nobody steps in.

/*

 * The purpose of this function is to take care of proper initialization of

 * devices and data structures which depend on GPIO lines provided by OMAP GPIO

 * banks but their drivers don't use GPIO lookup tables or GPIO layer at all.

 * The function may be called as soon as OMAP GPIO devices are probed.

 * Since that happens at postcore_initcall, it can be called successfully

 * from init_machine or later.

 * Dependent devices may be registered from within this function or later.

	/*

	 * Start with FIQ initialization as it may have to request

	 * and release successfully each OMAP GPIO pin in turn.

/*

 * Initialize latch2 pins with values which are safe for dependent on-board

 * devices or useful for their successull initialization even before GPIO

 * driver takes control over the latch pins:

 * - LATCH2_PIN_LCD_VBLEN	= 0

 * - LATCH2_PIN_LCD_NDISP	= 0	Keep LCD device powered off before its

 *					driver takes control over it.

 * - LATCH2_PIN_NAND_NCE	= 0

 * - LATCH2_PIN_NAND_NWP	= 0	Keep NAND device down and write-

 *					protected before its driver takes

 *					control over it.

 * - LATCH2_PIN_KEYBRD_PWR	= 0	Keep keyboard powered off before serio

 *					driver takes control over it.

 * - LATCH2_PIN_KEYBRD_DATAOUT	= 0	Keep low to avoid corruption of first

 *					byte of data received from attached

 *					keyboard when serio device is probed;

 *					the pin is also hogged low by the latch2

 *					GPIO driver as soon as it is ready.

 * - LATCH2_PIN_MODEM_NRESET	= 1	Enable voice MODEM device, allowing for

 *					its successful probe even before a

 *					regulator it depends on, which in turn

 *					takes control over the pin, is set up.

 * - LATCH2_PIN_MODEM_CODEC	= 1	Attach voice MODEM CODEC data port

 *					to the MODEM so the CODEC is under

 *					control even if audio driver doesn't

 *					take it over.

 mux pins for uarts */

 parallel camera interface */

	/*

	 * As soon as regulator consumers have been registered, assign their

	 * dev_names to consumer supply entries of respective regulators.

	/*

	 * Once consumer supply entries are populated with dev_names,

	 * register regulator devices.  At this stage only the keyboard

	 * power regulator has its consumer supply table fully populated.

	/*

	 * As soon as GPIO consumers have been registered, assign

	 * their dev_names to respective GPIO lookup tables.

	/*

	 * Once GPIO lookup tables are populated with dev_names, register them.

 changed later */

/*

 * This function expects MODEM IRQ number already assigned to the port.

 * The MODEM device requires its RESET# pin kept high during probe.

 * That requirement can be fulfilled in several ways:

 * - with a descriptor of already functional modem_nreset regulator

 *   assigned to the MODEM private data,

 * - with the regulator not yet controlled by modem_pm function but

 *   already enabled by default on probe,

 * - before the modem_nreset regulator is probed, with the pin already

 *   set high explicitly.

 * The last one is already guaranteed by ams_delta_latch2_init() called

 * from machine_init.

 * In order to avoid taking over ttyS0 device slot, the MODEM device

 * should be registered after OMAP serial ports.  Since those ports

 * are registered at arch_initcall, this function can be called safely

 * at arch_initcall_sync earliest.

 Initialize the modem_nreset regulator consumer before use */

	/*

	 * Once the modem device is registered, the modem_nreset

	 * regulator can be requested on behalf of that device.

 Maintainer: Jonathan McDowell <noodles@earth.li> */

/*

 * linux/arch/arm/mach-omap1/timer32k.c

 *

 * OMAP 32K Timer

 *

 * Copyright (C) 2004 - 2005 Nokia Corporation

 * Partial timer rewrite and additional dynamic tick timer support by

 * Tony Lindgen <tony@atomide.com> and

 * Tuukka Tikkanen <tuukka.tikkanen@elektrobit.com>

 * OMAP Dual-mode timer framework support by Timo Teras

 *

 * MPU timer code based on the older MPU timer code for OMAP

 * Copyright (C) 2000 RidgeRun, Inc.

 * Author: Greg Lonnon <glonnon@ridgerun.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the

 * Free Software Foundation; either version 2 of the License, or (at your

 * option) any later version.

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN

 * NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,

 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT

 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF

 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON

 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF

 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * You should have received a copy of the  GNU General Public License along

 * with this program; if not, write  to the Free Software Foundation, Inc.,

 * 675 Mass Ave, Cambridge, MA 02139, USA.

/*

 * ---------------------------------------------------------------------------

 * 32KHz OS timer

 *

 * This currently works only on 16xx, as 1510 does not have the continuous

 * 32KHz synchronous timer. The 32KHz synchronous timer is used to keep track

 * of time in addition to the 32KHz OS timer. Using only the 32KHz OS timer

 * on 1510 would be possible, but the timer would not be as accurate as

 * with the 32KHz synchronized timer.

 * ---------------------------------------------------------------------------

 16xx specific defines */

/*

 * TRM says 1 / HZ = ( TVR + 1) / 32768, so TRV = (32768 / HZ) - 1

 * so with HZ = 128, TVR = 255.

/*

 * ---------------------------------------------------------------------------

 * Timer initialization

 * ---------------------------------------------------------------------------

/*

 * Runtime PM support code for OMAP1

 *

 * Author: Kevin Hilman, Deep Root Systems, LLC

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-palmtt.c

 *

 * Modified from board-palmtt2.c

 *

 * Modified and amended for Palm Tungsten|T

 * by Marek Vasut <marek.vasut@gmail.com>

 internal, no capacitor */

 MicroWire (bus 2) CS0 has an ads7846e */

 max sample rate at 3V */

 command + data + overhead */,

 mux pins for uarts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-h2-mmc.c

 *

 * Copyright (C) 2007 Instituto Nokia de Tecnologia - INdT

 * Author: Felipe Balbi <felipe.lima@indt.org.br>

 *

 * This code is based on linux/arch/arm/mach-omap2/board-n800-mmc.c, which is:

 * Copyright (C) 2006 Nokia Corporation

/*

 * H2 could use the following functions tested:

 * - mmc_get_cover_state that uses OMAP_MPUIO(1)

 * - mmc_get_wp that uses OMAP_MPUIO(3)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-innovator.c

 *

 * Board specific inits for OMAP-1510 and OMAP-1610 Innovator

 *

 * Copyright (C) 2001 RidgeRun, Inc.

 * Author: Greg Lonnon <glonnon@ridgerun.com>

 *

 * Copyright (C) 2002 MontaVista Software, Inc.

 *

 * Separated FPGA interrupts from innovator1510.c and cleaned up for 2.6

 * Copyright (C) 2004 Nokia Corporation by Tony Lindrgen <tony@atomide.com>

 At OMAP1610 Innovator the Ethernet is directly connected to CS1 */

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 kernel */

 rest of flash1 is a file system */

 file system */

 Only FPGA needs to be mapped here. All others are done with ioremap */

 Physical */

 internal, no capacitor */

 FPGA (bus "10") CS0 has an ads7846e */

 max sample rate at 3V */

 command + data + overhead */,

 CONFIG_ARCH_OMAP15XX */

 Physical */

 CONFIG_ARCH_OMAP16XX */

 for bundled non-standard host and peripheral cables */

 Conflicts with UART2 */

 usb1 has a Mini-AB port and external isp1301 transceiver */

 0:host(off) 1:dev|otg 2:disabled */

 .hmc_mode	= 21,*/	
 NONSTANDARD CABLE NEEDED (B-to-Mini-B) */

 1:dev|otg(off) 1:host 2:disabled */

/*

 * Innovator could use the following functions tested:

 * - mmc_get_wp that uses OMAP_MPUIO(3)

 * - mmc_get_cover_state that uses FPGA F4 UIO43

 mux pins for uarts */

/*

 * REVISIT: Assume 15xx for now, we don't want to do revision check

 * until later on. The right way to fix this is to set up a different

 * machine_id for 16xx Innovator, or use device tree.

 Delay needed for FPGA */

 Dump the Innovator FPGA rev early - useful info for support. */

 Maintainer: MontaVista Software, Inc. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-fsample.c

 *

 * Modified from board-perseus2.c

 *

 * Original OMAP730 support by Jean Pihet <j-pihet@ti.com>

 * Updated for 2.6 by Kevin Hilman <kjh@hilman.org>

 fsample is pretty close to p2-sample */

 Physical */

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 kernel */

 rest of flash is a file system */

 Early, board-dependent init */

	/*

	 * Hold GSM Reset until needed

	/*

	 * UARTs -> done automagically by 8250 driver

	/*

	 * CSx timings, GPIO Mux ... setup

 Flash: CS0 timings setup */

	/*

	 * Ethernet support through the debug board

	 * CS1 timings setup

	/*

	 * Configure MPU_EXT_NIRQ IO in IO_CONF9 register,

	 * It is used as the Ethernet controller interrupt

 Mux pins for keypad */

 Only FPGA needs to be mapped here. All others are done with ioremap */

 Maintainer: Brian Swetland <swetland@google.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-nand.c

 *

 * Common OMAP1 board NAND code

 *

 * Copyright (C) 2004, 2012 Texas Instruments, Inc.

 * Copyright (C) 2002 MontaVista Software, Inc.

 * Copyright (C) 2001 RidgeRun, Inc.

 * Author: RidgeRun, Inc.

 *         Greg Lonnon (glonnon@ridgerun.com) or info@ridgerun.com

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * linux/arch/arm/plat-omap/ocpi.c

 *

 * Minimal OCP bus support for omap16xx

 *

 * Copyright (C) 2003 - 2005 Nokia Corporation

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Written by Tony Lindgren <tony@atomide.com>

 *

 * Modified for clock framework by Paul Mundt <paul.mundt@nokia.com>.

 USB OHCI OCPI access error registers */

/*

 * Enables device access to OMAP buses via the OCPI bridge

 Enable access for OHCI in OCPI */

 val &= (1 << 0);	 Allow access only to EMIFS */

 REVISIT: Disable OCPI */

/*

 * linux/arch/arm/mach-omap1/board-osk.c

 *

 * Board specific init for OMAP5912 OSK

 *

 * Written by Dirk Behme <dirk.behme@de.bosch.com>

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the

 * Free Software Foundation; either version 2 of the License, or (at your

 * option) any later version.

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN

 * NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,

 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT

 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF

 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON

 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF

 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * You should have received a copy of the  GNU General Public License along

 * with this program; if not, write  to the Free Software Foundation, Inc.,

 * 675 Mass Ave, Cambridge, MA 02139, USA.

 Name of the GPIO chip used by the OMAP for GPIOs 0..15 */

 At OMAP5912 OSK the Ethernet is directly connected to CS1 */

/* TPS65010 has four GPIOs.  nPG and LED2 can be treated like GPIOs with

 * alternate pin configurations for hardware-controlled blinking.

 MPUIO */)

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 this is on CS3, wherever it's mapped */

 Physical */

 CS2 */,

	/* NOTE:  D9 and D2 have hardware blink support.

	 * Also, D9 requires non-battery power.

	/* Set GPIO 1 HIGH to disable VBUS power supply;

	 * OHCI driver powers it up/down as needed.

 Free the GPIO again as the driver will request it */

 Set GPIO 2 high so LED D3 is off by default */

 Set GPIO 3 low to take ethernet out of reset */

 GPIO4 is VDD_DSP */

 REVISIT if DSP support isn't configured, power it off ... */

 Let LED1 (D9) blink; leds-gpio may override it */

 Set LED2 off by default */

 Enable LOW_PWR handshake */

 Switch VLDO2 to 3.0V for AIC23 */

 register these three LEDs */

 This device will get the name "i2c-tps65010" */

	/* TODO when driver support is ready:

	 *  - optionally on Mistral, ov9640 camera sensor at 0x30

 Check EMIFS wait states to fix errors with SMC_GET_PKT_HDR */

 the CF I/O IRQ is really active-low */

 Power GPIO on the I2C-attached TPS65010 */

	/* has usb host connector (A) ... for development it can also

	 * be used, with a NONSTANDARD gender-bending cable/dongle, as

	 * a peripheral.

 NOTE:  powered from LCD supply */

	/* TODO when driver support is ready:

	 *  - optionally ov9640 camera sensor at 0x30

 KEY(col, row, code) */

 SW4 */

 (sw2/up) */

 SW5 */

 (sw2/left) */

 SW3 */

 SW6 */

 (sw2/down) */

 (sw2/select) */

 (sw2/right) */

 internal, no capacitor */

 MicroWire (bus 2) CS0 has an ads7846e */

 max sample rate at 3V */

 command + data + overhead */,

	/* NOTE:  we could actually tell if there's a Mistral board

	 * attached, e.g. by trying to read something from the ads7846.

	 * But this arch_init() code is too early for that, since we

	 * can't talk to the ads or even the i2c eeprom.

 parallel camera interface */

 serial camera interface */

 CCP_DATAM CONFLICTS WITH UART1.TX (and serial console) */

 omap_cfg_reg(Y14_1610_CCP_DATAM); */

 CAM_PWDN */

 omap_cfg_reg(P19_1610_GPIO6); */	
 PENIRQ */

	/* the sideways button (SW1) is for use as a "wakeup" button

	 *

	 * NOTE:  The Mistral board has the wakeup button (SW1) wired

	 * to the LCD 3.3V rail, which is powered down during suspend.

	 * To allow this button to wake up the omap, work around this

	 * HW bug by rewiring SW1 to use the main 3.3V rail.

		/* share the IRQ in case someone wants to use the

		 * button for more than wakeup from system sleep.

	/* LCD:  backlight, and power; power controls other devices on the

	 * board, like the touchscreen, EEPROM, and wakeup (!) switch.

	/*

	 * GPIO based LEDs

	/* Workaround for wrong CS3 (NOR flash) timing

	 * There are some U-Boot versions out there which configure

	 * wrong CS3 memory timings. This mainly leads to CRC

	 * or similar errors if you use NOR flash (e.g. with JFFS2)

 irq for tps65010 chip */

 bootloader effectively does:  omap_cfg_reg(U19_1610_MPUIO1); */

 Maintainer: Dirk Behme <dirk.behme@de.bosch.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Flash support for OMAP1

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/board-palmte.c

 *

 * Modified from board-generic.c

 *

 * Support for the Palm Tungsten E PDA.

 *

 * Original version : Laurent Gonzalez

 *

 * Maintainers : http://palmtelinux.sf.net

 *                palmtelinux-developpers@lists.sf.net

 *

 * Copyright (c) 2006 Andrzej Zaborowski  <balrog@zabor.org>

 Calendar */

 Contacts */

 Tasks List */

 Note Pad */

 PalmOS "Small ROM", contains the bootloader and the debugger */

 PalmOS "Big ROM", a filesystem with all the OS code and data */

		/*

		 * 0x5f0000 bytes big in the multi-language ("EFIGS") version,

		 * 0x7b0000 bytes in the English-only ("enUS") version.

 Mini-B only receptacle */

 uWire (officially) */

 As opposed to 3 */

 Set TSC2102 PINTDAV pin as input (used by TSC2102 driver) */

 Set USB-or-DC-IN pin as input (unused) */

 CONFIG_MMC_OMAP */

 CONFIG_MMC_OMAP */

 mux pins for uarts */

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP1 reset support

 ARM_SYSST bit shifts related to SoC reset sources */

 Standardized reset source bits (across all OMAP SoCs) */

	/*

	 * Workaround for 5912/1611b bug mentioned in sprz209d.pdf p. 28

	 * "Global Software Reset Affects Traffic Controller Frequency".

/**

 * omap1_get_reset_sources - return the source of the SoC's last reset

 *

 * Returns bits that represent the last reset source for the SoC.  The

 * format is standardized across OMAPs for use by the OMAP watchdog.

/*

 * linux/arch/arm/mach-omap1/irq.c

 *

 * Interrupt handler for all OMAP boards

 *

 * Copyright (C) 2004 Nokia Corporation

 * Written by Tony Lindgren <tony@atomide.com>

 * Major cleanups by Juha Yrjl <juha.yrjola@nokia.com>

 *

 * Completely re-written to support various OMAP chips with bank specific

 * interrupt handlers.

 *

 * Some snippets of the code taken from the older OMAP interrupt handler

 * Copyright (C) 2001 RidgeRun, Inc. Greg Lonnon <glonnon@ridgerun.com>

 *

 * GPIO interrupt handler moved to gpio.c by Juha Yrjola

 *

 * This program is free software; you can redistribute it and/or modify it

 * under the terms of the GNU General Public License as published by the

 * Free Software Foundation; either version 2 of the License, or (at your

 * option) any later version.

 *

 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED

 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF

 * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN

 * NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,

 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT

 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF

 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON

 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT

 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF

 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

 *

 * You should have received a copy of the  GNU General Public License along

 * with this program; if not, write  to the Free Software Foundation, Inc.,

 * 675 Mass Ave, Cambridge, MA 02139, USA.

/*

 * Allows tuning the IRQ type and priority

 *

 * NOTE: There is currently no OMAP fiq handler for Linux. Read the

 *	 mailing list threads on FIQ handlers if you are planning to

 *	 add a FIQ handler for OMAP.

 FIQ is only available on bank 0 interrupts */

 Mask and clear all interrupts */

 Clear any pending interrupts */

 Enable interrupts in global mask */

 Install the interrupt handlers for each bank */

 Unmask level 2 handler */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-omap1/opp_data.c

 *

 *  Copyright (C) 2004 - 2005 Nokia corporation

 *  Written by Tuukka Tikkanen <tuukka.tikkanen@elektrobit.com>

 *  Based on clocks.h by Tony Lindgren, Gordon McNutt and RidgeRun, Inc

/*-------------------------------------------------------------------------

 * Omap1 MPU rate table

	/* MPU MHz, xtal MHz, dpll1 MHz, CKCTL, DPLL_CTL

	 * NOTE: Comment order here is different from bits in CKCTL value:

	 * armdiv, dspdiv, dspmmu, tcdiv, perdiv, lcddiv

 1/1/2/2/2/8 */

 1/1/2/2/4/8 */

 1/1/2/2/8/8 */

 1/1/2/2/8/8 */

 2/2/2/2/8/8 */

 4/4/4/8/8/8 */

 8/8/8/8/8/8 */

 1/1/2/2/4/8 */

 1/1/1/2/8/8 */

 1/1/1/2/4/4 */

 1/1/1/2/4/4 */

 1/1/1/1/2/2 */

 1/1/1/1/2/2 */

 2/2/2/2/2/2 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap1/id.c

 *

 * OMAP1 CPU identification code

 *

 * Copyright (C) 2004 Nokia Corporation

 * Written by Tony Lindgren <tony@atomide.com>

 Used to determine OMAP type */

 Processor revision */

 OMAP revision */

 Cpu id bits [31:08], cpu class bits [07:00] */

 Register values to detect the OMAP version */

/*

 * Get OMAP type from PROD_ID.

 * 1710 has the PROD_ID in bits 15:00, not in 16:01 as documented in TRM.

 * 1510 PROD_ID is empty, and 1610 PROD_ID does not make sense.

 * Undocumented register in TEST BLOCK is used as fallback; This seems to

 * work on 1510, 1610 & 1710. The official way hopefully will work in future

 * processors.

 Check for unusable OMAP_PRODUCTION_ID_1 on 1611B/5912 and 730/850 */

 Use OMAP32_ID_1 as fallback */

/*

 * Get OMAP revision from DIE_REV.

 * Early 1710 processors may have broken OMAP_DIE_ID, it contains PROD_ID.

 * Undocumented register in the TEST BLOCK is used as fallback.

 * REVISIT: This does not seem to work on 1510

 Check for broken OMAP_DIE_ID on early 1710 */

 First check only the major version in a safe way */

 Check if we can find the die revision */

 Finally check also the omap_id */

 Add the cpu class info (7xx, 15xx, 16xx, 24xx) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Helper module for board specific I2C bus registration

 *

 * Copyright (C) 2009 Nokia Corporation.

 all OMAP1 have IP version 1 register set */

 all OMAP1 I2C are implemented like this */

 how the cpu bus is wired up differs for 7xx only */

/**

 * omap_i2c_bus_setup - Process command line options for the I2C bus speed

 * @str: String of options

 *

 * This function allow to override the default I2C bus speed for given I2C

 * bus with a command line option.

 *

 * Format: i2c_bus=bus_id,clkrate (in kHz)

 *

 * Returns 1 on success, 0 otherwise.

/*

 * Register busses defined in command line but that are not registered with

 * omap_register_i2c_bus from board initialization code.

/**

 * omap_register_i2c_bus - register I2C bus with device descriptors

 * @bus_id: bus id counting from number 1

 * @clkrate: clock rate of the bus in kHz

 * @info: pointer into I2C device descriptor table or NULL

 * @len: number of descriptors in the table

 *

 * Returns 0 on success or an error code.

/*

 * OMAP15xx specific gpio init

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 *

 * Author:

 *	Charulatha V <charu@ti.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 gpio1 */

 gpio2 */

/*

 * omap15xx_gpio_init needs to be done before

 * machine_init functions access gpio APIs.

 * Hence omap15xx_gpio_init is a postcore_initcall.

/*

 * arch/arm/mach-lpc32xx/pm.c

 *

 * Original authors: Vitaly Wool, Dmitry Chigirev <source@mvista.com>

 * Modified by Kevin Wells <kevin.wells@nxp.com>

 *

 * 2005 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

/*

 * LPC32XX CPU and system power management

 *

 * The LPC32XX has three CPU modes for controlling system power: run,

 * direct-run, and halt modes. When switching between halt and run modes,

 * the CPU transistions through direct-run mode. For Linux, direct-run

 * mode is not used in normal operation. Halt mode is used when the

 * system is fully suspended.

 *

 * Run mode:

 * The ARM CPU clock (HCLK_PLL), HCLK bus clock, and PCLK bus clocks are

 * derived from the HCLK PLL. The HCLK and PCLK bus rates are divided from

 * the HCLK_PLL rate. Linux runs in this mode.

 *

 * Direct-run mode:

 * The ARM CPU clock, HCLK bus clock, and PCLK bus clocks are driven from

 * SYSCLK. SYSCLK is usually around 13MHz, but may vary based on SYSCLK

 * source or the frequency of the main oscillator. In this mode, the

 * HCLK_PLL can be safely enabled, changed, or disabled.

 *

 * Halt mode:

 * SYSCLK is gated off and the CPU and system clocks are halted.

 * Peripherals based on the 32KHz oscillator clock (ie, RTC, touch,

 * key scanner, etc.) still operate if enabled. In this state, an enabled

 * system event (ie, GPIO state change, RTC match, key press, etc.) will

 * wake the system up back into direct-run mode.

 *

 * DRAM refresh

 * DRAM clocking and refresh are slightly different for systems with DDR

 * DRAM or regular SDRAM devices. If SDRAM is used in the system, the

 * SDRAM will still be accessible in direct-run mode. In DDR based systems,

 * a transition to direct-run mode will stop all DDR accesses (no clocks).

 * Because of this, the code to switch power modes and the code to enter

 * and exit DRAM self-refresh modes must not be executed in DRAM. A small

 * section of IRAM is used instead for this.

 *

 * Suspend is handled with the following logic:

 *  Backup a small area of IRAM used for the suspend code

 *  Copy suspend code to IRAM

 *  Transfer control to code in IRAM

 *  Places DRAMs in self-refresh mode

 *  Enter direct-run mode

 *  Save state of HCLK_PLL PLL

 *  Disable HCLK_PLL PLL

 *  Enter halt mode - CPU and buses will stop

 *  System enters direct-run mode when an enabled event occurs

 *  HCLK PLL state is restored

 *  Run mode is entered

 *  DRAMS are placed back into normal mode

 *  Code execution returns from IRAM

 *  IRAM code are used for suspend is restored

 *  Suspend mode is exited

/*

 * Both STANDBY and MEM suspend states are handled the same with no

 * loss of CPU or memory state

 Allocate some space for temporary IRAM storage */

	/*

	 * Copy code to suspend system into IRAM. The suspend code

	 * needs to run from IRAM as DRAM may no longer be available

	 * when the PLL is stopped.

 Transfer to suspend code in IRAM */

 Restore original IRAM contents */

	/*

	 * Setup SDRAM self-refresh clock to automatically disable o

	 * start of self-refresh. This only needs to be done once.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Platform support for LPC32xx SoC

 *

 * Author: Kevin Wells <kevin.wells@nxp.com>

 *

 * Copyright (C) 2012 Roland Stigge <stigge@antcom.de>

 * Copyright (C) 2010 NXP Semiconductors

 SLC NAND Flash */

 MLC NAND Flash */

 Some reasonable memcpy defaults */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-lpc32xx/serial.c

 *

 * Author: Kevin Wells <kevin.wells@nxp.com>

 *

 * Copyright (C) 2010 NXP Semiconductors

 LPC3250 Errata HSUART.1: Hang workaround via loopback mode on inactivity */

 Setup UART clock modes for all UARTs, disable autoclock */

 pre-UART clock divider set to 1 */

		/*

		 * Force a flush of the RX FIFOs to work around a

		 * HW bug

 This needs to be done after all UART clocks are setup */

 Force a flush of the RX FIFOs to work around a HW bug */

 Disable IrDA pulsing support on UART6 */

 Disable UART5->USB transparent mode or USB won't work */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-lpc32xx/common.c

 *

 * Author: Kevin Wells <kevin.wells@nxp.com>

 *

 * Copyright (C) 2010 NXP Semiconductors

/*

 * Returns the unique ID for the device

/*

 * Detects and returns IRAM size for the device variation

 SPDX-License-Identifier: GPL-2.0



 Copyright (c) 2010-2014 Samsung Electronics Co., Ltd.

		http:


 S5PV210 - Power Management support



 Based on arch/arm/mach-s3c2410/pm.c

 Copyright (c) 2006 Simtec Electronics

	Ben Dooks <ben@simtec.co.uk>

 helper functions to save and restore register state */

/**

 * s3c_pm_do_save() - save a set of registers for restoration on resume.

 * @ptr: Pointer to an array of registers.

 * @count: Size of the ptr array.

 *

 * Run through the list of registers given, saving their contents in the

 * array for later restoration when we wakeup.

/**

 * s3c_pm_do_restore() - restore register values from the save list.

 * @ptr: Pointer to an array of registers.

 * @count: Size of the ptr array.

 *

 * Restore the register values saved from s3c_pm_do_save().

 *

 * WARNING: Do not put any debug in here that may effect memory or use

 * peripherals, as things may be changing!

 Clock ETC */

/*

 * VIC wake-up support (TODO)

/*

 * Suspend helpers.

	/* issue the standby signal into the pm unit. Note, we

 Aborting suspend */

	/*

	 * Set wake-up mask registers

	 * S5P_EINT_WAKEUP_MASK is set by pinctrl driver in late suspend.

 ensure at least INFORM0 has the resume address */

 WFI for SLEEP mode configuration by SYSCON */

 SYSCON interrupt handling disable */

/*

 * Suspend operations.

/*

 * Syscore operations used to delay restore of certain registers.

/*

 * Initialization entry point.

 SPDX-License-Identifier: GPL-2.0



 Samsung's S5PC110/S5PV210 flattened device tree enabled machine.



 Copyright (c) 2013-2014 Samsung Electronics Co., Ltd.

 Mateusz Krawczuk <m.krawczuk@partner.samsung.com>

 Tomasz Figa <t.figa@samsung.com>

/*

 * arch/arm/mach-spear3xx/spear320.c

 *

 * SPEAr320 machine source file

 *

 * Copyright (C) 2009-2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 DMAC platform data's slave info */

 Add SPEAr310 auxdata to pass platform data */

/*

 * arch/arm/mach-spear13xx/spear1310.c

 *

 * SPEAr1310 machine source file

 *

 * Copyright (C) 2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Base addresses */

/*

 * Following will create 16MB static virtual/physical mappings

 * PHYSICAL		VIRTUAL

 * 0xD8000000		0xFA000000

/*

 * arch/arm/mach-spear3xx/spear3xx.c

 *

 * SPEAr3XX machines common source file

 *

 * Copyright (C) 2009-2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 ssp device registration */

 dmac device registration */

/*

 * Following will create 16MB static virtual/physical mappings

 * PHYSICAL		VIRTUAL

 * 0xD0000000		0xFD000000

 * 0xFC000000		0xFC000000

 This will create static memory mapping for selected devices */

 get the system timer clock */

 get the suitable parent clock for timer*/

/*

 * arch/arm/plat-spear/time.c

 *

 * Copyright (C) 2010 ST Microelectronics

 * Shiraz Hashim<shiraz.linux.kernel@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * We would use TIMER0 and TIMER1 as clockevent and clocksource.

 * Timer0 and Timer1 both belong to same gpt block in cpu subbsystem. Further

 * they share same functional clock. Any change in one's functional clock will

 * also affect other timer.

 gpt0, channel0 as clockevent */

 gpt0, channel1 as clocksource */

 Register offsets, x is channel number */

 Reg bit definitions */

/*

 * Minimum clocksource/clockevent timer range in seconds

 program the prescaler (/256)*/

 find out actual clock driving Timer */

 autoreload mode */

 register the clocksource */

 stop the timer */

 stop the timer */

 stop the timer */

 to be computed */

 program the prescaler */

/*

 * arch/arm/plat-spear/pl080.c

 *

 * DMAC pl080 definitions for SPEAr platform

 *

 * Copyright (C) 2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Return if signal is already acquired by somebody else */

 If acquiring for the first time, configure it */

		/*

		 * Each request line has two bits in DMA_CHN_CFG register. To

		 * goto the bits of current request line, do left shift of

		 * value by 2 * signal number.

 if signal is not used */

/*

 * arch/arm/mach-spear3xx/spear300.c

 *

 * SPEAr300 machine source file

 *

 * Copyright (C) 2009-2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 DMAC platform data's slave info */

 Add SPEAr300 auxdata to pass platform data */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-spear13xx/platsmp.c

 *

 * based upon linux/arch/arm/mach-realview/platsmp.c

 *

 * Copyright (C) 2012 ST Microelectronics Ltd.

 * Shiraz Hashim <shiraz.linux.kernel@gmail.com>

 XXX spear_pen_release is cargo culted code - DO NOT COPY XXX */

/*

 * XXX CARGO CULTED CODE - DO NOT COPY XXX

 *

 * Write spear_pen_release in a way that is guaranteed to be visible to

 * all observers, irrespective of whether they're taking part in coherency

 * or not.  This is necessary for the hotplug code to work reliably.

	/*

	 * let the primary processor know we're out of the

	 * pen, then head off into the C entry point

	/*

	 * Synchronise with the boot thread.

	/*

	 * set synchronisation state between this boot processor

	 * and the secondary one

	/*

	 * The secondary processor is waiting to be released from

	 * the holding pen - release it, then wait for it to flag

	 * that it has been released by resetting spear_pen_release.

	 *

	 * Note that "spear_pen_release" is the hardware CPU ID, whereas

	 * "cpu" is Linux's internal ID.

	/*

	 * now the secondary core is starting up let it run its

	 * calibrations, then wait for it to finish

/*

 * Initialise the CPU possible map early - this describes the CPUs

 * which may be present or become present in the system.

	/*

	 * Write the address of secondary startup into the system-wide location

	 * (presently it is in SRAM). The BootMonitor waits until it receives a

	 * soft interrupt, and then the secondary CPU branches to this address.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-spear13xx/hotplug.c

 *

 * Copyright (C) 2012 ST Microelectronics Ltd.

 * Deepak Sikri <deepak.sikri@st.com>

 *

 * based upon linux/arch/arm/mach-realview/hotplug.c

	/*

	 * Turn off coherency

			/*

			 * OK, proper wakeup, we're done

		/*

		 * Getting here, means that we have come out of WFI without

		 * having been woken up - this shouldn't happen

		 *

		 * Just note it happening - when we're woken, we can report

		 * its occurrence.

/*

 * platform-specific code to shutdown a CPU

 *

 * Called with IRQs disabled

	/*

	 * we're ready for shutdown now, so do it

	/*

	 * bring this CPU back into the world of cache

	 * coherency, and then restore interrupts

/*

 * arch/arm/mach-spear3xx/spear310.c

 *

 * SPEAr310 machine source file

 *

 * Copyright (C) 2009-2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 DMAC platform data's slave info */

 uart devices plat data */

 Add SPEAr310 auxdata to pass platform data */

/*

 * arch/arm/plat-spear/restart.c

 *

 * SPEAr platform specific restart functions

 *

 * Copyright (C) 2009 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 software reset, Jump into ROM at address 0 */

 hardware reset, Use on-chip reset capability */

/*

 * arch/arm/mach-spear13xx/spear1340.c

 *

 * SPEAr1340 machine source file

 *

 * Copyright (C) 2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * arch/arm/mach-spear6xx/spear6xx.c

 *

 * SPEAr6XX machines common source file

 *

 * Copyright (C) 2009 ST Microelectronics

 * Rajeev Kumar<rajeev-dlh.kumar@st.com>

 *

 * Copyright 2012 Stefan Roese <sr@denx.de>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 dmac device registration */

/*

 * Following will create 16MB static virtual/physical mappings

 * PHYSICAL		VIRTUAL

 * 0xF0000000		0xF0000000

 * 0xF1000000		0xF1000000

 * 0xD0000000		0xFD000000

 * 0xFC000000		0xFC000000

 This will create static memory mapping for selected devices */

 get the system timer clock */

 get the suitable parent clock for timer*/

 Add auxdata to pass platform data */

/*

 * arch/arm/mach-spear13xx/spear13xx.c

 *

 * SPEAr13XX machines common source file

 *

 * Copyright (C) 2012 ST Microelectronics

 * Viresh Kumar <vireshk@kernel.org>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * 512KB (64KB/way), 8-way associativity, parity supported

	 *

	 * FIXME: 9th bit, of Auxillary Controller register must be set

	 * for some spear13xx devices for stable L2 operation.

	 *

	 * Enable Early BRESP, L2 prefetch for Instruction and Data,

	 * write alloc and 'Full line of zero' options

	 *

	/*

	 * Program following latencies in order to make

	 * SPEAr1340 work at 600 MHz

/*

 * Following will create 16MB static virtual/physical mappings

 * PHYSICAL		VIRTUAL

 * 0xB3000000		0xF9000000

 * 0xE0000000		0xFD000000

 * 0xEC000000		0xFC000000

 * 0xED000000		0xFB000000

 This will create static memory mapping for selected devices */

 get the system timer clock */

 get the suitable parent clock for timer*/

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/plat-iop/setup.c

 *

 * Author: Nicolas Pitre <nico@fluxnic.net>

 * Copyright (C) 2001 MontaVista Software, Inc.

 * Copyright (C) 2004 Intel Corporation.

/*

 * Standard IO mapping for all IOP3xx based systems.  Note that

 * the IOP3xx OCCDR must be mapped uncached and unbuffered.

 mem mapped registers */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * platform device definitions for the iop3xx dma/xor engines

 * Copyright  2006, Intel Corporation.

 AAU and DMA Channels */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-iop32x/iq31244.c

 *

 * Board support code for the Intel EP80219 and IQ31244 platforms.

 *

 * Author: Rory Bolt <rorybolt@pacbell.net>

 * Copyright (C) 2002 Rory Bolt

 * Copyright 2003 (c) MontaVista, Software, Inc.

 * Copyright (C) 2004 Intel Corp.

/*

 * Until March of 2007 iq31244 platforms and ep80219 platforms shared the

 * same machine id, and the processor type was used to select board type.

 * However this assumption breaks for an iq80219 board which is an iop219

 * processor on an iq31244 board.  The force_ep80219 flag has been added

 * for old boot loaders using the iq31244 machine id for an ep80219 platform.

/*

 * EP80219/IQ31244 timer tick configuration.

 33.333 MHz crystal.  */

 33.000 MHz crystal.  */

/*

 * IQ31244 I/O.

 on-board devices */

/*

 * EP80219/IQ31244 PCI.

 CFlash */

 82551 Pro 100 */

 PCI-X Slot */

 SATA */

 CFlash */

 SATA */

 PCI-X Slot */

 82546 GigE */

/*

 * IQ31244 machine initialisation.

/*

 * This function will send a SHUTDOWN_COMPLETE message to the PIC

 * controller over I2C.  We are not using the i2c subsystem since

 * we are going to power off and it may be removed

	/*

	 * Send the Address byte w/ the start condition

	/*

	 * Send the START_MSG byte w/ no start or stop condition

	/*

	 * Send the SHUTDOWN_COMPLETE Message ID byte w/ no start or

	 * stop condition

	/*

	 * Send an ignored byte w/ stop condition

 Maintainer: Intel Corp. */

/* There should have been an ep80219 machine identifier from the beginning.

 * Boot roms older than March 2007 do not know the ep80219 machine id.  Pass

 * "force_ep80219" on the kernel command line, otherwise iq31244 operation

 * will be selected.

 Maintainer: Intel Corp. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/plat-iop/time.c

 *

 * Timer code for IOP32x and IOP33x based systems

 *

 * Author: Deepak Saxena <dsaxena@mvista.com>

 *

 * Copyright 2002-2003 MontaVista Software Inc.

/*

 * Minimum clocksource/clockevent timer range in seconds

/*

 * IOP clocksource (free-running timer 1).

/*

 * IOP sched_clock() implementation via its clocksource.

/*

 * IOP clockevents (interrupting timer 0).

 ->set_next_event sets period and enables timer */

	/*

	 * Set up interrupting clockevent timer 0.

	/*

	 * Set up free-running clocksource timer 1.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-iop32x/n2100.c

 *

 * Board support code for the Thecus N2100 platform.

 *

 * Author: Rory Bolt <rorybolt@pacbell.net>

 * Copyright (C) 2002 Rory Bolt

 * Copyright 2003 (c) MontaVista, Software, Inc.

 * Copyright (C) 2004 Intel Corp.

/*

 * N2100 timer tick configuration.

 33.000 MHz crystal.  */

/*

 * N2100 I/O.

 on-board devices */

/*

 * N2100 PCI.

 RTL8110SB #1 */

 RTL8110SB #2 */

 Sil3512 */

 VT6212 INTA */

 VT6212 INTB */

 VT6212 INTC */

 Mini-PCI slot */

/*

 * Both r8169 chips on the n2100 exhibit PCI parity problems.  Turn

 * off parity reporting for both ports so we don't get error interrupts

 * for them.

/*

 * N2100 machine initialisation.

 power OFF gpio */

 reset gpio */

/*

 * Pull PCA9532 GPIO #8 low to power off the machine.

 Start condition, I2C address of PCA9532, write transaction.  */

 Write address 0x08.  */

 Write data 0x01, stop condition.  */

 Wait for reset to happen */

 Set up power button poll timer */

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PMU IRQ registration for the iop3xx xscale PMU families.

 * Copyright (C) 2010 Will Deacon, ARM Ltd.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/plat-iop/pci.c

 *

 * PCI support for the Intel IOP32X and IOP33X processors

 *

 * Author: Rory Bolt <rorybolt@pacbell.net>

 * Copyright (C) 2002 Rory Bolt

 #define DEBUG

/*

 * This routine builds either a type0 or type1 configuration command.  If the

 * bus is on the 803xx then a type0 made, else a type1 is created.

/*

 * This routine checks the status of the last configuration cycle.  If an error

 * was detected it returns a 1, else it returns a 0.  The errors being checked

 * are parity, master abort, target abort (master and target).  These types of

 * errors occur during a config cycle where there is no device, like during

 * the discovery stage.

	/*

	 * Check the status registers.

/*

 * Simply write the address register and read the configuration

 * data.  Note that the 4 nops ensure that we are able to handle

 * a delayed abort (in theory.)

/*

 * The read routines must check the error status of the last configuration

 * cycle.  If there was an error, the routine returns all hex f's.

/*

 * When a PCI device does not exist during config cycles, the 80200 gets a

 * bus error instead of returning 0xffffffff. This handler simply returns.

	/*

	 * If it was an imprecise abort, then we need to correct the

	 * return address to be _after_ the instruction.

	/*

	 * Use whatever translation is already setup.

 BAR 0 ( Disabled ) */

 BAR 1 ( Disabled ) */

 BAR 2 (1:1 mapping with Physical RAM) */

 Set limit and enable */

 Align the inbound bar with the base of memory */

 Outbound window 0 */

 Outbound window 1 */

 BAR 3 ( Disabled ) */

	/* Setup the I/O Bar

	/* Enable inbound and outbound cycles

 wait for cycles to quiesce */

 BAR 0 ( Disabled ) */

 BAR 1 ( Disabled ) */

 BAR 2 ( Disabled ) */

 BAR 3 ( Disabled ) */

 Clear the outbound windows */

 Outbound window 0 */

 Outbound window 1 */

 Flag to determine whether the ATU is initialized and the PCI bus scanned */

 check if default has been overridden */

 for platforms that might be host-bus-adapters */

 allow init_atu to be user overridden */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * restart.c

 *

 * Copyright (C) 2001 MontaVista Software, Inc.

 Jump into ROM at address 0 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-iop32x/glantank.c

 *

 * Board support code for the GLAN Tank.

 *

 * Copyright (C) 2006, 2007 Martin Michlmayr <tbm@cyrius.com>

 * Copyright (C) 2006 Lennert Buytenhek <buytenh@wantstofly.org>

/*

 * GLAN Tank timer tick configuration.

 33.333 MHz crystal.  */

/*

 * GLAN Tank I/O.

 on-board devices */

/*

 * GLAN Tank PCI.

		/*

		 * PCI IDSEL/INTPIN->INTLINE

		 * A       B       C       D

 UART (8250) */

 Ethernet (E1000) */

 IDE (AEC6280R) */

 USB (NEC) */

/*

 * GLAN Tank machine initialization.

 Maintainer: Lennert Buytenhek <buytenh@wantstofly.org> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IOP Coprocessor-6 access handler

 * Copyright (c) 2006, Intel Corporation.

 enable cp6 access */

/* permit kernel space cp6 access

 * deny user space cp6 access

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-iop32x/iq80321.c

 *

 * Board support code for the Intel IQ80321 platform.

 *

 * Author: Rory Bolt <rorybolt@pacbell.net>

 * Copyright (C) 2002 Rory Bolt

 * Copyright (C) 2004 Intel Corp.

/*

 * IQ80321 timer tick configuration.

 33.333 MHz crystal.  */

/*

 * IQ80321 I/O.

 on-board devices */

/*

 * IQ80321 PCI.

 PCI-X Slot INTA */

 PCI-X Slot INTA */

 PCI-X Slot INTA */

 PCI-X Slot INTA */

 Gig-E */

/*

 * IQ80321 machine initialisation.

 Maintainer: Intel Corp. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-iop32x/em7210.c

 *

 * Board support code for the Lanner EM7210 platforms.

 *

 * Based on arch/arm/mach-iop32x/iq31244.c file.

 *

 * Copyright (C) 2007 Arnaud Patard <arnaud.patard@rtp-net.org>

www.kwaak.net/fotos/fotos-nas/slide_24.html */

 33.333 MHz crystal.                                */

/*

 * EM7210 RTC

/*

 * EM7210 I/O

 on-board devices */

/*

 * EM7210 PCI

		/*

		 * PCI IDSEL/INTPIN->INTLINE

		 * A       B       C       D

 console / uart */

 1st 82541      */

 2nd 82541      */

 GD31244        */

 mini-PCI       */

 NEC USB        */

/*

 * EM7210 Flash

/*

 * EM7210 UART

 * The physical address of the serial port is 0xfe800000,

 * so it can be used for physical and virtual address.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-iop32x/irq.c

 *

 * Generic IOP32X IRQ handling functionality

 *

 * Author: Rory Bolt <rorybolt@pacbell.net>

 * Copyright (C) 2002 Rory Bolt

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/plat-iop/i2c.c

 *

 * Author: Nicolas Pitre <nico@cam.org>

 * Copyright (C) 2001 MontaVista Software, Inc.

 * Copyright (C) 2004 Intel Corporation.

/*

 * Each of the I2C busses have corresponding GPIO lines, and the driver

 * need to access these directly to drive the bus low at times.

 SPDX-License-Identifier: GPL-2.0

	/*

	 * The following are the standard ARMv3 and ARMv4 aborts.  ARMv5

	 * defines these to be "precise" aborts.

	/*

	 * The following are "imprecise" aborts, which are signalled by bit

	 * 10 of the FSR, and may not be recoverable.  These are only

	 * supported if the CPU abort handler supports bit 10.

 xscale */

 xscale */

 xscale */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/context.c

 *

 *  Copyright (C) 2002-2003 Deep Blue Solutions Ltd, all rights reserved.

 *  Copyright (C) 2012 ARM Limited

 *

 *  Author: Will Deacon <will.deacon@arm.com>

/*

 * On ARMv6, we have the following structure in the Context ID:

 *

 * 31                         7          0

 * +-------------------------+-----------+

 * |      process ID         |   ASID    |

 * +-------------------------+-----------+

 * |              context ID             |

 * +-------------------------------------+

 *

 * The ASID is used to tag entries in the CPU caches and TLBs.

 * The context ID is used by debuggers and trace logic, and

 * should be unique within all running processes.

 *

 * In big endian operation, the two 32 bit words are swapped if accessed

 * by non-64-bit operations.

		/*

		 * We only need to send an IPI if the other CPUs are

		 * running the same ASID as the one being invalidated.

/*

 * With LPAE, the ASID and page tables are updated atomicly, so there is

 * no need for a reserved set of tables (the active ASID tracking prevents

 * any issues across a rollover).

	/*

	 * Copy TTBR1 into TTBR0.

	 * This points at swapper_pg_dir, which contains only global

	 * entries so any speculative walks are perfectly safe.

 Update the list of reserved ASIDs and the ASID bitmap. */

		/*

		 * If this CPU has already been through a

		 * rollover, but hasn't run another task in

		 * the meantime, we must preserve its reserved

		 * ASID, as this is the only trace we have of

		 * the process it is still running.

 Queue a TLB invalidate and flush the I-cache if necessary. */

	/*

	 * Iterate over the set of reserved ASIDs looking for a match.

	 * If we find one, then we can update our mm to use newasid

	 * (i.e. the same ASID in the current generation) but we can't

	 * exit the loop early, since we need to ensure that all copies

	 * of the old ASID are updated to reflect the mm. Failure to do

	 * so could result in us missing the reserved ASID in a future

	 * generation.

		/*

		 * If our current ASID was active during a rollover, we

		 * can continue to use it and this was just a false alarm.

		/*

		 * We had a valid ASID in a previous life, so try to re-use

		 * it if possible.,

	/*

	 * Allocate a free ASID. If we can't find one, take a note of the

	 * currently active ASIDs and mark the TLBs as requiring flushes.

	 * We always count from ASID #1, as we reserve ASID #0 to switch

	 * via TTBR0 and to avoid speculative page table walks from hitting

	 * in any partial walk caches, which could be populated from

	 * overlapping level-1 descriptors used to map both the module

	 * area and the userspace stack.

	/*

	 * We cannot update the pgd and the ASID atomicly with classic

	 * MMU, so switch exclusively to global mappings to avoid

	 * speculative page table walking with the wrong TTBR.

 Check that our ASID belongs to the current generation. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * L220/L310 cache controller support

 *

 * Copyright (C) 2016 ARM Limited

/*

 * The L220/PL310 PMU has two equivalent counters, Counter1 and Counter0.

 * Registers controlling these are laid out in pairs, in descending order, i.e.

 * the register for Counter1 comes first, followed by the register for

 * Counter0.

 * We ensure that idx 0 -> Counter0, and idx1 -> Counter1.

 Find an unused counter */

 How many counters are allocated? */

	/*

	 * The L2X0 counters saturate at 0xffffffff rather than wrapping, so we

	 * will *always* lose some number of events when a counter saturates,

	 * and have no way of detecting how many were lost.

	 *

	 * To minimize the impact of this, we try to maximize the period by

	 * always starting counters at zero. To ensure that group ratios are

	 * representative, we poll periodically to avoid counters saturating.

	 * See l2x0_pmu_poll().

	/*

	 * Pin the timer, so that the overflows are handled by the chosen

	 * event->cpu (this is the same one as presented in "cpumask"

	 * attribute).

	/*

	 * Determine whether we support the PMU, and choose the name for sysfs.

	 * This is also used by l2x0_pmu_event_attr_is_visible to determine

	 * which events to display, as the PL310 PMU supports a superset of

	 * L220 events.

	 *

	 * The L210 PMU has a different programmer's interface, and is not

	 * supported by this driver.

	 *

	 * We must defer registering the PMU until the perf subsystem is up and

	 * running, so just stash the name and base, and leave that to another

	 * initcall.

	/*

	 * We always use a hrtimer rather than an interrupt.

	 * See comments in l2x0_pmu_event_configure and l2x0_pmu_poll.

	 *

	 * Polling once a second allows the counters to fill up to 1/128th on a

	 * quad-core test chip with cores clocked at 400MHz. Hopefully this

	 * leaves sufficient headroom to avoid overflow on production silicon

	 * at higher frequencies.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Based on linux/arch/arm/mm/dma-mapping.c

 *

 *  Copyright (C) 2000-2004 Russell King

		/*

		 * Cache support for v7m is optional, so can be treated as

		 * coherent if no cache has been detected. Note that it is not

		 * enough to check if MPU is in use or not since in absense of

		 * MPU system memory map is used.

		/*

		 * Assume coherent DMA in case MMU/MPU has not been set up.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This file contains kasan initialization code for ARM.

 *

 * Copyright (c) 2018 Samsung Electronics Co., Ltd.

 * Author: Andrey Ryabinin <ryabinin.a.a@gmail.com>

 * Author: Linus Walleij <linus.walleij@linaro.org>

			/*

			 * The early shadow memory is mapping all KASan

			 * operations to one and the same page in memory,

			 * "kasan_early_shadow_page" so that the instrumentation

			 * will work on a scratch area until we can set up the

			 * proper KASan shadow memory.

			/*

			 * Early shadow mappings are PMD_SIZE aligned, so if the

			 * first entry is already set, they must all be set.

/*

 * The pmd (page middle directory) is only used on LPAE

			/*

			 * We attempt to allocate a shadow block for the PMDs

			 * used by the PTEs for this address if it isn't already

			 * allocated.

		/*

		 * Allocate and populate the shadow block of p4d folded into

		 * pud folded into pmd if it doesn't already exist

		/*

		 * We just immediately jump over the p4d and pud page

		 * directories since we believe ARM32 will never gain four

		 * nor five level page tables.

	/*

	 * locate processor in the list of supported processor

	 * types.  The linker builds this table for us from the

	 * entries in arch/arm/mm/proc-*.S

	/*

	 * We walk the page table and set all of the shadow memory to point

	 * to the scratch page.

	/*

	 * We are going to perform proper setup of shadow memory.

	 *

	 * At first we should unmap early shadow (clear_pgds() call bellow).

	 * However, instrumented code can't execute without shadow memory.

	 *

	 * To keep the early shadow memory MMU tables around while setting up

	 * the proper shadow memory, we copy swapper_pg_dir (the initial page

	 * table) to tmp_pgd_table and use that to keep the early shadow memory

	 * mapped until the full shadow setup is finished. Then we swap back

	 * to the proper swapper_pg_dir.

 We need to be in the same PGD or this won't work */

 Do not attempt to shadow highmem */

	/*

	 * 1. The module global variables are in MODULES_VADDR ~ MODULES_END,

	 *    so we need to map this area.

	 * 2. PKMAP_BASE ~ PKMAP_BASE+PMD_SIZE's shadow and MODULES_VADDR

	 *    ~ MODULES_END's shadow is in the same PMD_SIZE, so we can't

	 *    use kasan_populate_zero_shadow.

	/*

	 * KAsan may reuse the contents of kasan_early_shadow_pte directly, so

	 * we should make sure that it maps the zero page read-only.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mm/cache-l2x0.c - L210/L220/L310 cache controller support

 *

 * Copyright (C) 2007 ARM Limited

 Bitmask of active ways */

/*

 * Common code for all cache controllers.

 wait for cache operation by line or way to complete */

/*

 * By default, we write directly to secure registers.  Platforms must

 * override this if they are running non-secure.

/*

 * This should only be called when we have a requirement that the

 * register be written due to a work-around, as platforms running

 * in non-secure mode may not be able to access this register.

/*

 * Enable the L2 cache controller.  This function must only be

 * called when the cache controller is known to be disabled.

 Do not touch the controller if already enabled. */

/*

 * L2C-210 specific code.

 *

 * The L2C-2x0 PA, set/way and sync operations are atomic, but we must

 * ensure that no background operation is running.  The way operations

 * are all background tasks.

 *

 * While a background operation is in progress, any new operation is

 * ignored (unspecified whether this causes an error.)  Thankfully, not

 * used on SMP.

 *

 * Never has a different sync register other than L2X0_CACHE_SYNC, but

 * we use sync_reg_offset here so we can share some of this with L2C-310.

/*

 * L2C-220 specific code.

 *

 * All operations are background operations: they have to be waited for.

 * Conflicting requests generate a slave error (which will cause an

 * imprecise abort.)  Never uses sync_reg_offset, so we hard-code the

 * sync register here.

 *

 * However, we can re-use the l2c210_resume call.

	/*

	 * Always enable non-secure access to the lockdown registers -

	 * we write to them as part of the L2C enable sequence so they

	 * need to be accessible.

/*

 * L2C-310 specific code.

 *

 * Very similar to L2C-210, the PA, set/way and sync operations are atomic,

 * and the way operations are all background tasks.  However, issuing an

 * operation while a background operation is in progress results in a

 * SLVERR response.  We can reuse:

 *

 *  __l2c210_cache_sync (using sync_reg_offset)

 *  l2c210_sync

 *  l2c210_inv_range (if 588369 is not applicable)

 *  l2c210_clean_range

 *  l2c210_flush_range (if 588369 is not applicable)

 *  l2c210_flush_all (if 727915 is not applicable)

 *

 * Errata:

 * 588369: PL310 R0P0->R1P0, fixed R2P0.

 *	Affects: all clean+invalidate operations

 *	clean and invalidate skips the invalidate step, so we need to issue

 *	separate operations.  We also require the above debug workaround

 *	enclosing this code fragment on affected parts.  On unaffected parts,

 *	we must not use this workaround without the debug register writes

 *	to avoid exposing a problem similar to 727915.

 *

 * 727915: PL310 R2P0->R3P0, fixed R3P1.

 *	Affects: clean+invalidate by way

 *	clean and invalidate by way runs in the background, and a store can

 *	hit the line between the clean operation and invalidate operation,

 *	resulting in the store being lost.

 *

 * 752271: PL310 R3P0->R3P1-50REL0, fixed R3P2.

 *	Affects: 8x64-bit (double fill) line fetches

 *	double fill line fetches can fail to cause dirty data to be evicted

 *	from the cache before the new data overwrites the second line.

 *

 * 753970: PL310 R3P0, fixed R3P1.

 *	Affects: sync

 *	prevents merging writes after the sync operation, until another L2C

 *	operation is performed (or a number of other conditions.)

 *

 * 769419: PL310 R0P0->R3P1, fixed R3P2.

 *	Affects: store buffer

 *	store buffer is not automatically drained.

 Erratum 588369 for both clean+invalidate operations */

 From r2p0, there is Prefetch offset/control register */

 From r3p0, there is Power control register */

 restore pl310 setup */

	/*

	 * Always enable non-secure access to the lockdown registers -

	 * we write to them as part of the L2C enable sequence so they

	 * need to be accessible.

 Read back resulting AUX_CTRL value as it could have been altered. */

 r3p0 or later has power control register */

 For bcm compatibility */

	/*

	 * If full-line-of-zeros is enabled, we must first disable it in the

	 * Cortex-A9 auxiliary control register before disabling the L2 cache.

 Re-enable full-line-of-zeros for Cortex-A9 */

	/*

	 * Save the pointer globally so that callbacks which do not receive

	 * context from callers can access the structure.

	/*

	 * Sanity check the aux values.  aux_mask is the bits we preserve

	 * from reading the hardware register, and aux_val is the bits we

	 * set.

 Determine the number of ways */

 Assume unknown chips have 8 ways */

	/*

	 * way_size_0 is the size that a way_size value of zero would be

	 * given the calculation: way_size = way_size_0 << way_size_bits.

	 * So, if way_size_bits=0 is reserved, but way_size_bits=1 is 16k,

	 * then way_size_0 would be 8k.

	 *

	 * L2 cache size = number of ways * way size.

	/*

	 * Check if l2x0 controller is already enabled.  If we are booting

	 * in non-secure mode accessing the below registers will fault.

	/*

	 * It is strange to save the register state before initialisation,

	 * but hey, this is what the DT implementations decided to do.

 Re-read it in case some bits are reserved. */

 Read back current (default) hardware configuration */

/* Aurora don't have the cache ID register available, so we have to

/**

 * l2x0_cache_size_of_parse() - read cache size parameters from DT

 * @np: the device tree node for the l2 cache

 * @aux_val: pointer to machine-supplied auxilary register value, to

 * be augmented by the call (bits to be set to 1)

 * @aux_mask: pointer to machine-supplied auxilary register mask, to

 * be augmented by the call (bits to be set to 0)

 * @associativity: variable to return the calculated associativity in

 * @max_way_size: the maximum size in bytes for the cache ways

 All these l2 caches have the same line = block size actually */

 If linesize is not given, it is equal to blocksize */

 Fall back to known size */

	/*

	 * Since:

	 * set size = cache size / sets

	 * ways = cache size / (sets * line size)

	 * way size = cache size / (cache size / (sets * line size))

	 * way size = sets * line size

	 * associativity = ways = cache size / way size

	/*

	 * Calculates the bits 17:19 to set for way size:

	 * 512KB -> 6, 256KB -> 5, ... 16KB -> 1

/*

 * This is a variant of the of_l2c310_data with .sync set to

 * NULL. Outer sync operations are not needed when the system is I/O

 * coherent, and potentially harmful in certain situations (PCIe/PL310

 * deadlock on Armada 375/38x due to hardware I/O coherency). The

 * other operations are kept because they are infrequent (therefore do

 * not cause the deadlock in practice) and needed for secondary CPU

 * boot and other power management activities.

/*

 * Note that the end addresses passed to Linux primitives are

 * noninclusive, while the hardware cache range operations use

 * inclusive start and end addresses.

	/*

	 * Limit the number of cache lines processed at once,

	 * since cache range operations stall the CPU pipeline

	 * until completion.

	/*

	 * Cache range operations can't straddle a page boundary.

	/*

	 * round start and end adresses up to cache line size

	/*

	 * perform operation on all full cache lines between 'start' and 'end'

	/*

	 * If L2 is forced to WT, the L2 will always be clean and we

	 * don't need to do anything here.

 clean all ways */

/*

 * For Aurora cache in no outer mode, enable via the CP15 coprocessor

 * broadcasting of cache commands to L2.

 Set the FW bit */

 Determine and save the write policy */

/*

 * For certain Broadcom SoCs, depending on the address range, different offsets

 * need to be added to the address before passing it to L2 for

 * invalidation/clean/flush

 *

 * Section Address Range              Offset        EMI

 *   1     0x00000000 - 0x3FFFFFFF    0x80000000    VC

 *   2     0x40000000 - 0xBFFFFFFF    0x40000000    SYS

 *   3     0xC0000000 - 0xFFFFFFFF    0x80000000    VC

 *

 * When the start and end addresses have crossed two different sections, we

 * need to break the L2 operation into two, each within its own section.

 * For example, if we need to invalidate addresses starts at 0xBFFF0000 and

 * ends at 0xC0001000, we need do invalidate 1) 0xBFFF0000 - 0xBFFFFFFF and 2)

 * 0xC0000000 - 0xC0001000

 *

 * Note 1:

 * By breaking a single L2 operation into two, we may potentially suffer some

 * performance hit, but keep in mind the cross section case is very rare

 *

 * Note 2:

 * We do not need to handle the case when the start address is in

 * Section 1 and the end address is in Section 3, since it is not a valid use

 * case

 *

 * Note 3:

 * Section 1 in practical terms can no longer be used on rev A2. Because of

 * that the code does not need to handle section 1 at all.

 *

 normal case, no cross section between start and end */

	/* They cross sections, so it can only be a cross from section

	 * 2 to section 3

 normal case, no cross section between start and end */

	/* They cross sections, so it can only be a cross from section

	 * 2 to section 3

 normal case, no cross section between start and end */

	/* They cross sections, so it can only be a cross from section

	 * 2 to section 3

 Broadcom L2C-310 start from ARMs R3P2 or later, and require no fixups */

 Tauros3 broadcasts L1 cache operations to L2 */

 Deprecated IDs */

 All L2 caches are unified, so this property should be specified */

 Read back current (default) hardware configuration */

 L2 configuration can only be changed if the cache is disabled */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/copypage-v4wb.c

 *

 *  Copyright (C) 1995-1999 Russell King

/*

 * ARMv4 optimised copy_user_highpage

 *

 * We flush the destination cache lines just before we write the data into the

 * corresponding address.  Since the Dcache is read-allocate, this removes the

 * Dcache aliasing issue.  The writes will be forwarded to the write buffer,

 * and merged as appropriate.

 *

 * Note: We rely on all ARMv4 processors implementing the "invalidate D line"

 * instruction.  If your processor does not supply this, you have to write your

 * own copy_user_highpage that does the right thing.

/*

 * ARMv4 optimised clear_user_page

 *

 * Same story as above.

 SPDX-License-Identifier: GPL-2.0

/*

 * Note: accesses outside of the kernel image and the identity map area

 * are not supported on any CPU using the idmap tables as its current

 * page tables.

		/*

		 * Copy the original PMD to ensure that the PMD entries for

		 * the kernel image are preserved.

 !CONFIG_ARM_LPAE */

 CONFIG_ARM_LPAE */

 Flush L1 for the hardware to see this page table content */

/*

 * In order to soft-boot, we need to switch to a 1:1 mapping for the

 * cpu_reset functions. This will then ensure that we have predictable

 * results when turning off the mmu.

 Switch to the identity mapping. */

	/*

	 * We don't have a clean ASID for the identity mapping, which

	 * may clash with virtual addresses of the previous page tables

	 * and therefore potentially in the TLB.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/pgd.c

 *

 *  Copyright (C) 1998-2005 Russell King

/*

 * need to get a 16k page for level 1

	/*

	 * Copy over the kernel and IO PGD entries

	/*

	 * Allocate PMD table for modules and pkmap mappings.

	/*

	 * Copy PMD table for KASAN shadow mappings.

 CONFIG_KASAN */

 CONFIG_LPAE */

		/*

		 * On ARM, first page must always be allocated since it

		 * contains the machine vectors. The vectors are always high

		 * with LPAE.

		/*

		 * Modify the PTE pointer to have the correct domain.  This

		 * needs to be the vectors domain to avoid the low vectors

		 * being unmapped.

	/*

	 * Free modules/pkmap or identity pmd tables.

/*

 * Based on linux/arch/arm/mm/nommu.c

 *

 * ARM PMSAv7 supporting functions.

 Region number */

 Data-side / unified region attributes */

 Region access control register */

 Region size register */

 Region base address register */

 Optional instruction-side region attributes */

 I-side Region access control register */

 I-side Region size register */

 I-side Region base address register */

 Data-side / unified region attributes */

 Region access control register */

 Region size register */

 Region base address register */

 ARMv7-M only supports a unified MPU, so I-side operations are nop */

 Try cover region as is (maybe with help of subregions) */

			/*

			 * Maximum aligned region might overflow phys_addr_t

			 * if "base" is 0. Hence we keep everything below 4G

			 * until we take the smaller of the aligned region

			 * size ("asize") and rounded region size ("p2size"),

			 * one of which is guaranteed to be smaller than the

			 * maximum physical address.

 MPU initialisation functions */

 Free-up PMSAv7_PROBE_REGION */

 How many regions are supported */

 We need to keep one slot for background region */

 ... and one for vectors */

 plus some regions to cover XIP ROM */

			/*

			 * Initially only use memory continuous from

			/*

			 * memblock auto merges contiguous blocks, remove

			 * all blocks afterwards in one go (we can't remove

			 * blocks separately while iterating)

	/*

	 * We don't support a different number of I/D side regions so if we

	 * have separate instruction and data memory maps then return

	 * whichever side has a smaller number of supported regions.

 Check for separate d-side and i-side memory maps */

 Use the smallest of the two maxima */

 MPUIR.nU specifies whether there is *not* a unified memory map */

 We've kept a region free for this probing */

	/*

	 * As per ARM ARM, write 0xFFFFFFFC to DRBAR to find the minimum

	 * region order

 If the MPU is non-unified, we use the larger of the two minima*/

 Ensure that MPU region operations have completed */

 Return whichever result is larger */

 We kept a region free for probing resolution of MPU regions*/

 Writing N to bits 5:1 (RSR_SZ)  specifies region size 2^N+1 */

 Ensure all previous data accesses occur with old mappings */

 Propagate properties before enabling region */

 Check for independent I-side registers */

 Store region info (we treat i/d side the same, so only store d) */

/*

* Set up default MPU regions, doing nothing if there is no MPU

 Setup MPU (order is important) */

 Background */

 ROM */

		/*

                 * In case we overwrite RAM region we set earlier in

                 * head-nommu.S (which is cachable) all subsequent

                 * data access till we setup RAM bellow would be done

                 * with BG region (which is uncachable), thus we need

                 * to clean and invalidate cache.

 RAM */

 Vectors */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/nommu.c

 *

 * ARM uCLinux supporting functions.

 CONFIG_CPU_HIGH_VECTOR */

 Write exception base address to VBAR */

/*

 * Security extensions, bits[7:4], permitted values,

 * 0b0000 - not implemented, 0b0001/0b0010 - implemented

 Check CPUID Identification Scheme before ID_PFR1 read */

 CONFIG_CPU_HIGH_VECTOR */

 CONFIG_CPU_CP15 */

	/*

	 * Register the exception vector page.

	 * some architectures which the DRAM is the exception vector to trap,

	 * alloc_page breaks with error, although it is not NULL, but "0."

 ifndef CONFIG_CPU_V7M */

	/*

	 * There is no dedicated vector page on V7-M. So nothing needs to be

	 * reserved here.

	/*

	 * In any case, always ensure address 0 is never used as many things

	 * get very confused if 0 is returned as a legitimate address.

/*

 * paging_init() sets up the page tables, initialises the zone memory

 * maps, and sets up the zero page, bad page and bad page tables.

/*

 * We don't need to do anything here for nommu machines.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/copypage-xsc3.S

 *

 *  Copyright (C) 2004 Intel Corp.

 *

 * Adapted for 3rd gen XScale core, no more mini-dcache

 * Author: Matt Gilbert (matthew.m.gilbert@intel.com)

/*

 * General note:

 *  We don't really want write-allocate cache behaviour for these functions

 *  since that will just eat through 8K of the cache.

/*

 * XSC3 optimised copy_user_highpage

 *

 * The source page may have some clean entries in the cache already, but we

 * can safely ignore them - break_cow() will flush them out of the cache

 * if we eventually end up using our copied page.

 *

/*

 * XScale optimised clear_user_page

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/copypage-v6.c

 *

 *  Copyright (C) 2002 Deep Blue Solutions Ltd, All Rights Reserved.

/*

 * Copy the user page.  No aliasing to deal with so we can just

 * attack the kernel's existing mapping of these pages.

/*

 * Clear the user page.  No aliasing to deal with so we can just

 * attack the kernel's existing mapping of this page.

/*

 * Discard data in the kernel mapping for the new page.

 * FIXME: needs this MCRR to be supported.

/*

 * Copy the page, taking account of the cache colour.

 FIXME: not highmem safe */

	/*

	 * Now copy the page using the same cache colour as the

	 * pages ultimate destination.

/*

 * Clear the user page.  We need to deal with the aliasing issues,

 * so remap the kernel page into the same cache colour as the user

 * page.

 FIXME: not highmem safe */

	/*

	 * Now clear the page using the same cache colour as

	 * the pages ultimate destination.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/lib/copypage-xscale.S

 *

 *  Copyright (C) 1995-2005 Russell King

 *

 * This handles the mini data cache, as found on SA11x0 and XScale

 * processors.  When we copy a user page page, we map it in such a way

 * that accesses to this page will not touch the main data cache, but

 * will be cached in the mini data cache.  This prevents us thrashing

 * the main data cache on page faults.

/*

 * XScale mini-dcache optimised copy_user_highpage

 *

 * We flush the destination cache lines just before we write the data into the

 * corresponding address.  Since the Dcache is read-allocate, this removes the

 * Dcache aliasing issue.  The writes will be forwarded to the write buffer,

 * and merged as appropriate.

	/*

	 * Strangely enough, best performance is achieved

	 * when prefetching destination as well.  (NP)

/*

 * XScale optimised clear_user_page

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2010 ARM Ltd.

 * Written by Catalin Marinas <catalin.marinas@arm.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Debug helper to dump the current kernel pagetables of the system

 * so that we can see what the various memory ranges are set to.

 *

 * Derived from x86 implementation:

 * (C) Copyright 2008 Intel Corporation

 *

 * Author: Arjan van de Ven <arjan@linux.intel.com>

 ARMv4/ARMv5  */

 These are approximate */

 pgd */

 p4d */

 pud */

 pmd */

 pte */

/*

 * arch/arm/mm/cache-tauros2.c - Tauros2 L2 cache controller support

 *

 * Copyright (C) 2008 Marvell Semiconductor

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * References:

 * - PJ1 CPU Core Datasheet,

 *   Document ID MV-S104837-01, Rev 0.7, January 24 2008.

 * - PJ4 CPU Core Datasheet,

 *   Document ID MV-S105190-00, Rev 0.7, March 14 2008.

 CP15 PJ4 Control configuration register */

/*

 * When Tauros2 is used on a CPU that supports the v7 hierarchical

 * cache operations, the cache handling code in proc-v7.S takes care

 * of everything, including handling DMA coherency.

 *

 * So, we only need to register outer cache operations here if we're

 * being used on a pre-v7 CPU, and we only need to build support for

 * outer cache operations into the kernel image if the kernel has been

 * configured to support a pre-v7 CPU.

/*

 * Low-level cache maintenance operations.

/*

 * Linux primitives.

 *

 * Note that the end addresses passed to Linux primitives are

 * noninclusive.

	/*

	 * Clean and invalidate partial first cache line.

	/*

	 * Clean and invalidate partial last cache line.

	/*

	 * Invalidate all full cache lines between 'start' and 'end'.

		/*

		 * v5 CPUs with Tauros2 have the L2 cache enable bit

		 * located in the CPU Extra Features register.

	/*

	 * Check whether this CPU has support for the v7 hierarchical

	 * cache ops.  (PJ4 is in its v7 personality mode if the MMFR3

	 * register indicates support for the v7 hierarchical cache

	 * ops.)

	 *

	 * (Although strictly speaking there may exist CPUs that

	 * implement the v7 cache ops but are only ARMv6 CPUs (due to

	 * not complying with all of the other ARMv7 requirements),

	 * there are no real-life examples of Tauros2 being used on

	 * such CPUs as of yet.)

		/*

		 * When Tauros2 is used in an ARMv7 system, the L2

		 * enable bit is located in the Auxiliary System Control

		 * Register (which is the only register allowed by the

		 * ARMv7 spec to contain fine-grained cache control bits).

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/lib/copypage-armv4mc.S

 *

 *  Copyright (C) 1995-2005 Russell King

 *

 * This handles the mini data cache, as found on SA11x0 and XScale

 * processors.  When we copy a user page page, we map it in such a way

 * that accesses to this page will not touch the main data cache, but

 * will be cached in the mini data cache.  This prevents us thrashing

 * the main data cache on page faults.

/*

 * ARMv4 mini-dcache optimised copy_user_highpage

 *

 * We flush the destination cache lines just before we write the data into the

 * corresponding address.  Since the Dcache is read-allocate, this removes the

 * Dcache aliasing issue.  The writes will be forwarded to the write buffer,

 * and merged as appropriate.

 *

 * Note: We rely on all ARMv4 processors implementing the "invalidate D line"

 * instruction.  If your processor does not supply this, you have to write your

 * own copy_user_highpage that does the right thing.

/*

 * ARMv4 optimised clear_user_page

 SPDX-License-Identifier: GPL-2.0

/*

 *  linux/arch/arm/mm/iomap.c

 *

 * Map IO port and PCI memory spaces so that {read,write}[bwl] can

 * be used to access this memory.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/fault-armv.c

 *

 *  Copyright (C) 1995  Linus Torvalds

 *  Modifications for ARM processor (c) 1995-2002 Russell King

/*

 * We take the easy way out of this problem - we make the

 * PTE uncacheable.  However, we leave the write buffer on.

 *

 * Note that the pte lock held when calling update_mmu_cache must also

 * guard the pte (somewhere else in the same mm) that we modify here.

 * Therefore those configurations which might call adjust_pte (those

 * without CONFIG_CPU_CACHE_VIPT) cannot support split page_table_lock.

	/*

	 * If this page is present, it's actually being shared.

	/*

	 * If this page isn't present, or is already setup to

	 * fault (ie, is old), we can safely ignore any issues.

/*

 * If we are using split PTE locks, then we need to take the page

 * lock here.  Otherwise we are using shared mm->page_table_lock

 * which is already locked, thus cannot take it.

	/*

	 * Use nested version here to indicate that we are already

	 * holding one similar spinlock.

 !USE_SPLIT_PTE_PTLOCKS */

 USE_SPLIT_PTE_PTLOCKS */

	/*

	 * This is called while another page table is mapped, so we

	 * must use the nested version.  This also means we need to

	 * open-code the spin-locking.

	/*

	 * If we have any shared mappings that are in the same mm

	 * space, then we need to handle them specially to maintain

	 * cache coherency.

		/*

		 * If this VMA is not in our MM, we can ignore it.

		 * Note that we intentionally mask out the VMA

		 * that we are fixing up.

/*

 * Take care of architecture specific things when placing a new PTE into

 * a page table, or changing an existing PTE.  Basically, there are two

 * things that we need to take care of:

 *

 *  1. If PG_dcache_clean is not set for the page, we need to ensure

 *     that any cache entries for the kernels virtual memory

 *     range are written back to the page.

 *  2. If we have multiple shared mappings of the same space in

 *     an object, we need to deal with the cache aliasing issues.

 *

 * Note that the pte lock will be held.

	/*

	 * The zero page is never written to, so never has any dirty

	 * cache lines, and therefore never needs to be flushed.

 __LINUX_ARM_ARCH__ < 6 */

/*

 * Check whether the write buffer has physical address aliasing

 * issues.  If it has, we need to avoid them for the case where

 * we have several shared mappings of the same object in user

 * space.

 SPDX-License-Identifier: GPL-2.0

/*

 *  linux/arch/arm/mm/mmap.c

/*

 * We need to ensure that shared mappings are correctly aligned to

 * avoid aliasing issues with VIPT caches.  We need to ensure that

 * a specific page of an object is always mapped at a multiple of

 * SHMLBA bytes.

 *

 * We unconditionally provide this function for all cases, however

 * in the VIVT case, we optimise out the alignment rules.

	/*

	 * We only need to do colour alignment if either the I or D

	 * caches alias.

	/*

	 * We enforce the MAP_FIXED case.

	/*

	 * We only need to do colour alignment if either the I or D

	 * caches alias.

 requested length too big for entire address space */

 requesting a specific address */

	/*

	 * A failed mmap() very likely causes application failure,

	 * so fall back to the bottom-up function here. This scenario

	 * can happen with large stack limits and large mmap()

	 * allocations.

/*

 * You really shouldn't be using read() or write() on /dev/mem.  This

 * might go away in the future.

/*

 * Do not allow /dev/mem mappings beyond the supported physical range.

 SPDX-License-Identifier: GPL-2.0

 Requires no workaround */

 Other ARM CPUs require no workaround */

 Cortex A57/A72 require firmware workaround */

/*

 * Based on linux/arch/arm/pmsa-v7.c

 *

 * ARM PMSAv8 supporting functions.

			/*

			 * Initially only use memory continuous from

			/*

			 * memblock auto merges contiguous blocks, remove

			 * all blocks afterwards in one go (we can't remove

			 * blocks separately while iterating)

 Reserved region was set up early, we just need a record for secondaries */

 How many regions are supported ? */

 RAM: single chunk of memory */

 IO: cover full 4G range */

 RAM and IO: exclude kernel */

 RAM and IO: exclude xip */

 RAM and IO: exclude vectors */

 IO: exclude RAM */

 Now program MPU */

 ROM */

 Kernel */

 IO */

 RAM */

 Vectors */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014, The Linux Foundation. All rights reserved.

 SPDX-License-Identifier: GPL-2.0

	/*

	 * high_memory does not get immediately defined, and there

	 * are early callers of __pa() against PAGE_OFFSET

	/*

	 * MAX_DMA_ADDRESS is a virtual address that may not correspond to an

	 * actual physical address. Enough code relies on __pa(MAX_DMA_ADDRESS)

	 * that we just need to work around it and always return true.

	/* This is bounds checking against the kernel image only.

	 * __pa_symbol should only be used on kernel symbol addresses.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/init.c

 *

 *  Copyright (C) 1995-2005 Russell King

/*

 * The DMA mask corresponding to the maximum bus address allocatable

 * using GFP_DMA.  The default here places no restriction on DMA

 * allocations.  This must be the smallest DMA mask in the system,

 * so a successful GFP_DMA allocation will always satisfy this.

	/*

	 * If address less than pageblock_size bytes away from a present

	 * memory chunk there still will be a memory map entry for it

	 * because we round freed memory map to the pageblock boundaries.

	/*

	 * Round the memory region to page boundaries as per free_initrd_mem()

	 * This allows us to detect whether the pages overlapping the initrd

	 * are in use, but more importantly, reserves the entire set of pages

	 * as we don't want these pages allocated for other purposes.

 Now convert initrd to virtual addresses */

 Register the kernel text, kernel data and initrd with memblock. */

 reserve any platform specific memblock areas */

 reserve memory for DMA contiguous allocations */

	/*

	 * sparse_init() tries to allocate memory from memblock, so must be

	 * done after the fixed reservations

	/*

	 * Now free the memory - free_area_init needs

	 * the sparse mem_map arrays initialized by sparse_init()

	 * for memmap_init_zone(), otherwise all PFNs are invalid.

/*

 * Poison init memory with an undefined instruction (ARM) or a branch to an

 * undefined instruction (Thumb).

 set highmem page free */

 Ignore complete lowmem entries */

 Truncate partial highmem entries */

/*

 * mem_init() marks the free areas in the mem_map and tells us how much

 * memory is free.  This is done after various parts of the system have

 * claimed their memory after the kernel image.

 this will put all unused low memory onto the freelists */

 now that our DMA memory is actually so designated, we can free it */

	/*

	 * Check boundaries twice: Some fundamental inconsistencies can

	 * be detected at build time already.

 First section-aligned location at or after __start_rodata. */

 Make pages tables, etc before _stext RW (set NX). */

 Make init RW (set NX). */

 Make rodata NX (set RO in ro_perms below). */

 Make kernel code and rodata RX (set RO). */

/*

 * Updates section permissions only for the current mm (sections are

 * copied into each mm). During startup, this is the init_mm. Is only

 * safe to be called with preemption disabled, as under stop_machine().

 Make sure extended page tables are in use. */

/**

 * update_sections_early intended to be called only through stop_machine

 * framework and executed by only one CPU while all other CPUs will spin and

 * wait, so no locking is required in this function.

 CONFIG_STRICT_KERNEL_RWX */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/copypage-feroceon.S

 *

 *  Copyright (C) 2008 Marvell Semiconductors

 *

 * This handles copy_user_highpage and clear_user_page on Feroceon

 * more optimally than the generic implementations.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/alignment.c

 *

 *  Copyright (C) 1995  Linus Torvalds

 *  Modifications for ARM processor (c) 1995-2001 Russell King

 *  Thumb alignment fault fixups (c) 2004 MontaVista Software, Inc.

 *  - Adapted from gdb/sim/arm/thumbemu.c -- Thumb instruction emulation.

 *    Copyright (C) 1996, Cygnus Software Technologies Ltd.

/*

 * 32-bit misaligned trap handler (c) 1998 San Mehat (CCC) -July 1998

 * /proc/sys/debug/alignment, modified and integrated into

 * Linux 2.1 by Russell King

 *

 * Speed optimisations and better fault handling by Russell King.

 *

 * *** NOTE ***

 * This code is not portable to processors with late data abort handling.

 Immediate constant	*/

 Preindex		*/

 Add offset		*/

 Writeback		*/

 Load			*/

 double/half-word immed */

 write CPSR from SPSR	*/

 Rn			*/

 Rd			*/

 Rm			*/

 Thumb-2 32 bit format per ARMv7 DDI0406A A6.3, either f800h,e800h,f800h */

 Return true if and only if the ARMv6 unaligned access model is in use. */

	/*

	 * ARMv6 and later CPUs can perform unaligned accesses for

	 * most single load and store instructions up to word size.

	 * LDM, STM, LDRD and STRD still need to be handled.

	 *

	 * Ignoring the alignment fault is not an option on these

	 * CPUs since we spin re-faulting the instruction without

	 * making any progress.

 CONFIG_PROC_FS */

 signed half-word? */

 signed half-word? */

 ARMv7 Thumb-2 32-bit LDRD/STRD */

/*

 * LDM/STM alignment handler.

 *

 * There are 4 variants of this instruction:

 *

 * B = rn pointer before instruction, A = rn pointer after instruction

 *              ------ increasing address ----->

 *	        |    | r0 | r1 | ... | rx |    |

 * PU = 01             B                    A

 * PU = 11        B                    A

 * PU = 00        A                    B

 * PU = 10             A                    B

 processor implementation defined */

 count the number of registers in the mask to be transferred */

 U = P */

	/*

	 * For alignment faults on the ARM922T/ARM920T the MMU  makes

	 * the FSR (and hence addr) equal to the updated base address

	 * of the multiple access rather than the restored value.

	 * Switch this message off if we've got a ARM92[02], otherwise

	 * [ls]dm alignment faults are noisy!

	/*

	 * This is a "hint" - we already have eaddr worked out by the

	 * processor for us.

/*

 * Convert Thumb ld/st instruction forms to equivalent ARM instructions so

 * we can reuse ARM userland alignment fault fixups for Thumb.

 *

 * This implementation was initially based on the algorithm found in

 * gdb/sim/arm/thumbemu.c. It is basically just a code reduction of same

 * to convert only Thumb ld/st instruction forms to equivalent ARM forms.

 *

 * NOTES:

 * 1. Comments below refer to ARM ARM DDI0100E Thumb Instruction sections.

 * 2. If for some reason we're passed an non-ld/st Thumb instruction to

 *    decode, we return 0xdeadc0de. This should never happen under normal

 *    circumstances but if it does, we've got other problems to deal with

 *    elsewhere and we obviously can't fix those problems here.

 6.5.1 Format 1: */

 7.1.52 STR(1) */

 7.1.26 LDR(1) */

 7.1.55 STRB(1) */

 7.1.30 LDRB(1) */

 fixup */

 L==1? */

 Rd */

 Rn */

 immed_5 */

 7.1.57 STRH(1) */

 7.1.32 LDRH(1) */

 L==1? */

 Rd */

 Rn */

 immed_5[2:0] */

 immed_5[4:3] */

 6.5.1 Format 2: */

 7.1.53 STR(2) */

 7.1.58 STRH(2) */

 7.1.56 STRB(2) */

 7.1.34 LDRSB */

 7.1.27 LDR(2) */

 7.1.33 LDRH(2) */

 7.1.31 LDRB(2) */

 7.1.35 LDRSH */

 Rd */

 Rn */

 Rm */

 6.5.1 Format 3: */

 7.1.28 LDR(3) */

		/* NOTE: This case is not technically possible. We're

		 *	 loading 32-bit memory data via PC relative

		 *	 addressing mode. So we can and should eliminate

		 *	 this case. But I'll leave it here for now.

 Rd */

 immed_8 */

 6.5.1 Format 4: */

 7.1.54 STR(3) */

 7.1.29 LDR(4) */

 L==1? */

 Rd */

 immed_8 */

 6.6.1 Format 1: */

 7.1.51 STMIA */

 7.1.25 LDMIA */

 6.6.1 Format 2: */

 7.1.48 PUSH */

 7.1.47 POP */

 STMDB sp!,{registers} */

 STMDB sp!,{registers,lr} */

 LDMIA sp!,{registers} */

 LDMIA sp!,{registers,pc} */

 register_list */

 for illegal instruction case */

/*

 * Convert Thumb-2 32 bit LDM, STM, LDRD, STRD to equivalent instruction

 * handlable by ARM alignment handler, also find the corresponding handler,

 * so that we can reuse ARM userland alignment fault fixups for Thumb.

 *

 * @pinstr: original Thumb-2 instruction; returns new handlable instruction

 * @regs: register context.

 * @poffset: return offset from faulted addr for later writeback

 *

 * NOTES:

 * 1. Comments below refer to ARMv7 DDI0406A Thumb Instruction sections.

 * 2. Register name Rt from ARMv7 is same as Rd from ARMv6 (Rd is Rt)

 A6.3.5 Load/Store multiple */

 STM/STMIA/STMEA,LDM/LDMIA, PUSH/POP T2 */

 ...above writeback version */

 STMDB/STMFD, LDMDB/LDMEA */

 ...above writeback version */

 no need offset decision since handler calculates it */

 POP/PUSH T3 (single register) */

 STMDB sp!,{registers} */

 LDMIA sp!,{registers} */

 Else fall through for illegal instruction case */

 A6.3.6 Load/store double, STRD/LDRD(immed, lit, reg) */

	/*

	 * No need to handle load/store instructions up to word size

	 * since ARMv6 and later CPUs can perform unaligned accesses.

 Thumb-2 32-bit */

 3.13.4 load/store instruction extensions */

 LDRH, STRH */

 LDRSH */

 LDRD */

 STRD */

 SWP */

 ldr or str immediate */

 NEON VLDn, VSTn */

 ldr or str register */

 ldm or stm, or thumb-2 32bit instruction */

	/*

	 * We got a fault - fix it up, or die.

	/*

	 * Oops, we didn't handle the instruction.

		/*

		 * We're about to disable the alignment trap and return to

		 * user space.  But if an interrupt occurs before actually

		 * reaching user space, then the IRQ vector entry code will

		 * notice that we were still in kernel space and therefore

		 * the alignment trap won't be re-enabled in that case as it

		 * is presumed to be always on from kernel space.

		 * Let's prevent that race by disabling interrupts here (they

		 * are disabled on the way back to user space anyway in

		 * entry-common.S) and disable the alignment trap only if

		 * there is no work pending for this thread.

/*

 * This needs to be done after sysctl_init, otherwise sys/ will be

 * overwritten.  Actually, this shouldn't be in sys/ at all since

 * it isn't a sysctl, and it doesn't contain sysctl information.

 * We now locate it in /proc/cpu/alignment instead.

	/*

	 * ARMv6K and ARMv7 use fault status 3 (0b00011) as Access Flag section

	 * fault, not as alignment error.

	 *

	 * TODO: handle ARMv6K properly. Runtime check for 'K' extension is

	 * needed.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/lib/copypage-fa.S

 *

 *  Copyright (C) 2005 Faraday Corp.

 *  Copyright (C) 2008-2009 Paulius Zaleckas <paulius.zaleckas@teltonika.lt>

 *

 * Based on copypage-v4wb.S:

 *  Copyright (C) 1995-1999 Russell King

/*

 * Faraday optimised copy_user_page

/*

 * Faraday optimised clear_user_page

 *

 * Same story as above.

/*

 * arch/arm/mm/cache-feroceon-l2.c - Feroceon L2 cache controller support

 *

 * Copyright (C) 2008 Marvell Semiconductor

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * References:

 * - Unified Layer 2 Cache for Feroceon CPU Cores,

 *   Document ID MV-S104858-00, Rev. A, October 23 2007.

/*

 * Low-level cache maintenance operations.

 *

 * As well as the regular 'clean/invalidate/flush L2 cache line by

 * MVA' instructions, the Feroceon L2 cache controller also features

 * 'clean/invalidate L2 range by MVA' operations.

 *

 * Cache range operations are initiated by writing the start and

 * end addresses to successive cp15 registers, and process every

 * cache line whose first byte address lies in the inclusive range

 * [start:end].

 *

 * The cache range operations stall the CPU pipeline until completion.

 *

 * The range operations require two successive cp15 writes, in

 * between which we don't want to be preempted.

	/*

	 * Because range ops can't be done on physical addresses,

	 * we simply install a virtual mapping for it only for the

	 * TLB lookup to occur, hence no need to flush the untouched

	 * memory mapping afterwards (note: a cache flush may happen

	 * in some circumstances depending on the path taken in kunmap_atomic).

	/*

	 * Make sure 'start' and 'end' reference the same page, as

	 * L2 is PIPT and range operations only do a TLB lookup on

	 * the start address.

	/*

	 * Make sure 'start' and 'end' reference the same page, as

	 * L2 is PIPT and range operations only do a TLB lookup on

	 * the start address.

/*

 * Linux primitives.

 *

 * Note that the end addresses passed to Linux primitives are

 * noninclusive, while the hardware cache range operations use

 * inclusive start and end addresses.

	/*

	 * Try to process all cache lines between 'start' and 'end'.

	/*

	 * Limit the number of cache lines processed at once,

	 * since cache range operations stall the CPU pipeline

	 * until completion.

	/*

	 * Cache range operations can't straddle a page boundary.

	/*

	 * Clean and invalidate partial first cache line.

	/*

	 * Clean and invalidate partial last cache line.

	/*

	 * Invalidate all full cache lines between 'start' and 'end'.

	/*

	 * If L2 is forced to WT, the L2 will always be clean and we

	 * don't need to do anything here.

/*

 * Routines to disable and re-enable the D-cache and I-cache at run

 * time.  These are necessary because the L2 cache can only be enabled

 * or disabled while the L1 Dcache and Icache are both disabled.

	/*

	 * Read the CPU Extra Features register and verify that the

	 * Disable L2 Prefetch bit is set.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2015-2016 Socionext Inc.

 *   Author: Masahiro Yamada <yamada.masahiro@socionext.com>

 control registers */

 Control Register */

 UCWG burst read */

 Inst-Data separate */

 WT gathering on */

 enable pre-fetch */

 enable cache */

 Unified/Data Active Way Control */

 Instruction Active Way Control */

 revision registers */

 ID Register */

 operation registers */

 Cache Operation Primitive Entry */

 invalidate */

 clean */

 flush */

 sync (drain bufs) */

 flush p-fetch buf */

 Cache Operation Queue Mode */

 notify completion */

 invalidate */

 clean */

 flush */

 Cache Operation Queue Address */

 Cache Operation Queue Size */

 Cache Operation Queue Set Complete*/

 Cache Operation Queue Status */

 Is the operation region specified by address range? */

/**

 * uniphier_cache_data - UniPhier outer cache specific data

 *

 * @ctrl_base: virtual base address of control registers

 * @rev_base: virtual base address of revision registers

 * @op_base: virtual base address of operation registers

 * @way_mask: each bit specifies if the way is present

 * @nsets: number of associativity sets

 * @line_size: line size in bytes

 * @range_op_max_size: max size that can be handled by a single range operation

 * @list: list node to include this level in the whole cache hierarchy

/*

 * List of the whole outer cache hierarchy.  This list is only modified during

 * the early boot stage, so no mutex is taken for the access to the list.

/**

 * __uniphier_cache_sync - perform a sync point for a particular cache level

 *

 * @data: cache controller specific data

 This sequence need not be atomic.  Do not disable IRQ. */

 need a read back to confirm */

/**

 * __uniphier_cache_maint_common - run a queue operation for a particular level

 *

 * @data: cache controller specific data

 * @start: start address of range operation (don't care for "all" operation)

 * @size: data size of range operation (don't care for "all" operation)

 * @operation: flags to specify the desired cache operation

	/*

	 * No spin lock is necessary here because:

	 *

	 * [1] This outer cache controller is able to accept maintenance

	 * operations from multiple CPUs at a time in an SMP system; if a

	 * maintenance operation is under way and another operation is issued,

	 * the new one is stored in the queue.  The controller performs one

	 * operation after another.  If the queue is full, the status register,

	 * UNIPHIER_SSCOPPQSEF, indicates that the queue registration has

	 * failed.  The status registers, UNIPHIER_{SSCOPPQSEF, SSCOLPQS}, have

	 * different instances for each CPU, i.e. each CPU can track the status

	 * of the maintenance operations triggered by itself.

	 *

	 * [2] The cache command registers, UNIPHIER_{SSCOQM, SSCOQAD, SSCOQSZ,

	 * SSCOQWN}, are shared between multiple CPUs, but the hardware still

	 * guarantees the registration sequence is atomic; the write access to

	 * them are arbitrated by the hardware.  The first accessor to the

	 * register, UNIPHIER_SSCOQM, holds the access right and it is released

	 * by reading the status register, UNIPHIER_SSCOPPQSEF.  While one CPU

	 * is holding the access right, other CPUs fail to register operations.

	 * One CPU should not hold the access right for a long time, so local

	 * IRQs should be disabled while the following sequence.

 clear the complete notification flag */

 set cache operation */

 set address range if needed */

 wait until the operation is completed */

	/*

	 * If the start address is not aligned,

	 * perform a cache operation for the first cache-line

 this means cache operation for all range */

	/*

	 * If the end address is not aligned,

	 * perform a cache operation for the last cache-line

 sentinel */ }

		/*

		 * The size of range operation is limited to (1 << 22) or less

		 * for PH-sLD8 or older SoCs.

		/*

		 * Unfortunatly, the offset address of active way control base

		 * varies from SoC to SoC.

 sLD3 */

 LD4 */

 sld8 */

 no mutex */

	/*

	 * OK, this level has been successfully initialized.  Look for the next

	 * level cache.  Do not roll back even if the initialization of the

	 * next level cache fails because we want to continue with available

	 * cache levels.

 look for level 2 cache */

		/*

		 * Error out iif L2 initialization fails.  Continue with any

		 * error on L3 or outer because they are optional.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/flush.c

 *

 *  Copyright (C) 1995-2002 Russell King

 VIPT non-aliasing D-cache */

/*

 * Copy user data from/to a page which is mapped into a different

 * processes address space.  Really, we want to allow our "user

 * space" model to handle this.

 *

 * Note that this code needs to run on the current CPU.

	/*

	 * Writeback any data associated with the kernel mapping of this

	 * page.  This ensures that data in the physical page is mutually

	 * coherent with the kernels mapping.

	/*

	 * If this is a page cache page, and we have an aliasing VIPT cache,

	 * we only need to do one flush - which would be at the relevant

	 * userspace colour, which is congruent with page->index.

	/*

	 * There are possible user space mappings of this page:

	 * - VIVT cache: we need to also write back and invalidate all user

	 *   data in the current VM view associated with this page.

	 * - aliasing VIPT: we only need to find one mapping of this page.

		/*

		 * If this VMA is not in our MM, we can ignore it.

 only flush non-aliasing VIPT caches for exec mappings */

/*

 * Ensure cache coherency between kernel mapping and userspace mapping

 * of this page.

 *

 * We have three cases to consider:

 *  - VIPT non-aliasing cache: fully coherent so nothing required.

 *  - VIVT: fully aliasing, so we need to handle every alias in our

 *          current VM view.

 *  - VIPT aliasing: need to handle one alias in our current VM view.

 *

 * If we need to handle aliasing:

 *  If the page only exists in the page cache and there are no user

 *  space mappings, we can be lazy and remember that we may have dirty

 *  kernel cache lines for later.  Otherwise, we assume we have

 *  aliasing mappings.

 *

 * Note that we disable the lazy flush for SMP configurations where

 * the cache maintenance operations are not automatically broadcasted.

	/*

	 * The zero page is never written to, so never has any dirty

	 * cache lines, and therefore never needs to be flushed.

/*

 * Flush an anonymous page so that users of get_user_pages()

 * can safely access the data.  The expected sequence is:

 *

 *  get_user_pages()

 *    -> flush_anon_page

 *  memcpy() to/from page

 *  if written to page, flush_dcache_page()

 VIPT non-aliasing caches need do nothing */

	/*

	 * Write back and invalidate userspace mapping.

		/*

		 * For aliasing VIPT, we can flush an alias of the

		 * userspace address only.

	/*

	 * Invalidate kernel mapping.  No data should be contained

	 * in this mapping of the page.  FIXME: this is overkill

	 * since we actually ask for a write-back and invalidate.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/fault.c

 *

 *  Copyright (C) 1995  Linus Torvalds

 *  Modifications for ARM processor (c) 1995-2004 Russell King

/*

 * This is useful to dump out the page tables associated with

 * 'addr' in mm 'mm'.

 We must not map this if we have highmem enabled */

 CONFIG_MMU */

 CONFIG_MMU */

/*

 * Oops.  The kernel tried to access some page that wasn't present.

	/*

	 * Are we prepared to handle this kernel fault?

	/*

	 * No handler, we'll have to terminate things with extreme prejudice.

/*

 * Something tried to access memory that isn't in our memory map..

 * User mode accesses just cause a SIGSEGV

	/*

	 * If we are in kernel mode at this point, we

	 * have no context to handle this fault with.

	/*

	 * ok, we have a good vm_area for this memory access, check the

	 * permissions on the VMA allow for the fault which occurred.

 Enable interrupts if they were enabled in the parent context. */

	/*

	 * If we're in an interrupt or have no user

	 * context, we must not take the fault..

	/*

	 * As per x86, we may deadlock here.  However, since the kernel only

	 * validly references user space from well defined areas of the code,

	 * we can bug out early if this is from code which shouldn't.

		/*

		 * The above down_read_trylock() might have succeeded in

		 * which case, we'll have missed the might_sleep() from

		 * down_read()

	/* If we need to retry but a fatal signal is pending, handle the

	 * signal first. We do not need to release the mmap_lock because

	 * it would already be released in __lock_page_or_retry in

	/*

	 * Handle the "normal" case first - VM_FAULT_MAJOR

	/*

	 * If we are in kernel mode at this point, we

	 * have no context to handle this fault with.

		/*

		 * We ran out of memory, call the OOM killer, and return to

		 * userspace (which will retry the fault, or kill us if we

		 * got oom-killed)

		/*

		 * We had some memory, but were unable to

		 * successfully fix up this page fault.

		/*

		 * Something tried to access memory that

		 * isn't in our memory map..

 CONFIG_MMU */

 CONFIG_MMU */

/*

 * First Level Translation Fault Handler

 *

 * We enter here because the first level page table doesn't contain

 * a valid entry for the address.

 *

 * If the address is in kernel space (>= TASK_SIZE), then we are

 * probably faulting in the vmalloc() area.

 *

 * If the init_task's first level page tables contains the relevant

 * entry, we copy the it to this task.  If not, we send the process

 * a signal, fixup the exception, or oops the kernel.

 *

 * NOTE! We MUST NOT take any locks for this case. We may be in an

 * interrupt or a critical region, and should only copy the information

 * from the master page table, nothing more.

	/*

	 * Only one hardware entry per PMD with LPAE.

	/*

	 * On ARM one Linux PGD entry contains two hardware entries (see page

	 * tables layout in pgtable.h). We normally guarantee that we always

	 * fill both L1 entries. But create_mapping() doesn't follow the rule.

	 * It can create inidividual L1 entries, so here we have to call

	 * pmd_none() check for the entry really corresponded to address, not

	 * for the first of pair.

 CONFIG_MMU */

 CONFIG_MMU */

/*

 * Some section permission faults need to be handled gracefully.

 * They can happen due to a __{get,put}_user during an oops.

 CONFIG_ARM_LPAE */

/*

 * This abort handler always returns "fault".

 FSR definition */

/*

 * Dispatch a data abort to the relevant handler.

/*

 * Abort handler to be used only during first unmasking of asynchronous aborts

 * on the boot CPU. This makes sure that the machine will not die if the

 * firmware/bootloader left an imprecise abort pending for us to trip over.

		/*

		 * TODO: Access flag faults introduced in ARMv6K.

		 * Runtime check for 'K' extension is needed

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mm/hugetlbpage.c

 *

 * Copyright (C) 2012 ARM Ltd.

 *

 * Based on arch/x86/include/asm/hugetlb.h and Bill Carson's patches

/*

 * On ARM, huge pages are backed by pmd's rather than pte's, so we do a lot

 * of type casting from pmd_t * to pte_t *.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/dma-mapping.c

 *

 *  Copyright (C) 2000-2004 Russell King

 *

 *  DMA uncached mapping support.

/*

 * The DMA API is built upon the notion of "buffer ownership".  A buffer

 * is either exclusively owned by the CPU (and therefore may be accessed

 * by it) or exclusively owned by the DMA device.  These helper functions

 * represent the transitions between these two ownership states.

 *

 * Note, however, that on later ARMs, this notion does not work due to

 * speculative prefetches.  We model our approach on the assumption that

 * the CPU does do speculative prefetches, which means we clean caches

 * before transfers and delay cache invalidation until transfer completion.

 *

/**

 * arm_dma_map_page - map a portion of a page for streaming DMA

 * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices

 * @page: page that buffer resides in

 * @offset: offset into page for start of buffer

 * @size: size of buffer to map

 * @dir: DMA transfer direction

 *

 * Ensure that any data held in the cache is appropriately discarded

 * or written back.

 *

 * The device owns this memory once this call has completed.  The CPU

 * can regain ownership by calling dma_unmap_page().

/**

 * arm_dma_unmap_page - unmap a buffer previously mapped through dma_map_page()

 * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices

 * @handle: DMA address of buffer

 * @size: size of buffer (same as passed to dma_map_page)

 * @dir: DMA transfer direction (same as passed to dma_map_page)

 *

 * Unmap a page streaming mode DMA translation.  The handle and size

 * must match what was provided in the previous dma_map_page() call.

 * All other usages are undefined.

 *

 * After this call, reads by the CPU to the buffer are guaranteed to see

 * whatever the device wrote there.

/*

 * Return whether the given device DMA address mask can be supported

 * properly.  For example, if your device can only drive the low 24-bits

 * during bus mastering, then you would pass 0x00ffffff as the mask

 * to this function.

	/*

	 * Translate the device's DMA mask to a PFN limit.  This

	 * PFN number includes the page which we can DMA to.

	/*

	 * Ensure that the allocated pages are zeroed, and that any data

	 * lurking in the kernel direct-mapped region is invalidated.

/*

 * Allocate a DMA buffer for 'dev' of size 'size' using the

 * specified gfp mask.  Note that 'size' must be page aligned.

	/*

	 * Now split the huge page and free the excess pages

/*

 * Free a DMA buffer.  'size' must be page aligned.

/*

 * Initialise the coherent pool for atomic allocations.

	/*

	 * The atomic pool is only used for non-coherent allocations

	 * so we must pass NORMAL for coherent_flag.

/*

 * CMA is activated by core_initcall, so we must be called after it.

		/*

		 * Clear previous low-memory mapping to ensure that the

		 * TLB does not see any conflicting entries, then flush

		 * the TLB of the old entries before creating new mappings.

		 *

		 * This ensures that any speculatively loaded TLB entries

		 * (even though they may be rare) can not cause any problems,

		 * and ensures that this code is architecturally compliant.

	/*

	 * __alloc_remap_buffer is only called when the device is

	 * non-coherent

 __alloc_simple_buffer is only called when the device is coherent */

	/*

	 * Following is a work-around (a.k.a. hack) to prevent pages

	 * with __GFP_COMP being passed to split_page() which cannot

	 * handle them.  The real problem is that this flag probably

	 * should be 0 on ARM as it is not supported on this

	 * platform; see CONFIG_HUGETLBFS.

/*

 * Allocate DMA-coherent memory space and return both the kernel remapped

 * virtual and bus address for that space.

/*

 * Create userspace mapping for the DMA-coherent memory.

/*

 * Free a buffer as defined by the above mapping.

 If the PFN is not valid, we do not have a struct page */

	/*

	 * A single sg entry may refer to multiple physically contiguous

	 * pages.  But we still need to process highmem pages individually.

	 * If highmem is not configured then the bulk of this loop gets

	 * optimized out.

/*

 * Make an area consistent for devices.

 * Note: Drivers should NOT use this function directly, as it will break

 * platforms with CONFIG_DMABOUNCE.

 * Use the driver DMA support - see dma-mapping.h (dma_sync_*)

 FIXME: non-speculating: flush on bidirectional mappings? */

 FIXME: non-speculating: not required */

 in any case, don't bother invalidating if DMA to device */

	/*

	 * Mark the D-cache clean for these pages to avoid extra flushing.

/**

 * arm_dma_map_sg - map a set of SG buffers for streaming mode DMA

 * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices

 * @sg: list of buffers

 * @nents: number of buffers to map

 * @dir: DMA transfer direction

 *

 * Map a set of buffers described by scatterlist in streaming mode for DMA.

 * This is the scatter-gather version of the dma_map_single interface.

 * Here the scatter gather list elements are each tagged with the

 * appropriate dma address and length.  They are obtained via

 * sg_dma_{address,length}.

 *

 * Device ownership issues as mentioned for dma_map_single are the same

 * here.

/**

 * arm_dma_unmap_sg - unmap a set of SG buffers mapped by dma_map_sg

 * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices

 * @sg: list of buffers

 * @nents: number of buffers to unmap (same as was passed to dma_map_sg)

 * @dir: DMA transfer direction (same as was passed to dma_map_sg)

 *

 * Unmap a set of streaming mode DMA translations.  Again, CPU access

 * rules concerning calls here are the same as for dma_unmap_single().

/**

 * arm_dma_sync_sg_for_cpu

 * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices

 * @sg: list of buffers

 * @nents: number of buffers to map (returned from dma_map_sg)

 * @dir: DMA transfer direction (same as was passed to dma_map_sg)

/**

 * arm_dma_sync_sg_for_device

 * @dev: valid struct device pointer, or NULL for ISA and EISA-like devices

 * @sg: list of buffers

 * @nents: number of buffers to map (returned from dma_map_sg)

 * @dir: DMA transfer direction (same as was passed to dma_map_sg)

	/*

	 * When CONFIG_ARM_LPAE is set, physical address can extend above

	 * 32-bits, which then can't be addressed by devices that only support

	 * 32-bit DMA.

	 * Use the generic dma-direct / swiotlb ops code in that case, as that

	 * handles bounce buffering for us.

 IOMMU */

	/*

	 * No unused range found. Try to extend the existing mapping

	 * and perform a second attempt to reserve an IO virtual

	 * address range of size bytes.

		/*

		 * The address range to be freed reaches into the iova

		 * range of the next bitmap. This should not happen as

		 * we don't allow this in __alloc_iova (at the

		 * moment).

 We'll try 2M, 1M, 64K, and finally 4K; array must end with 0! */

 Go straight to 4K chunks if caller says it's OK. */

	/*

	 * IOMMU can map any pages, so himem can also be used here

 Drop down when we get small */

 See if it's easy to allocate a high-order chunk */

 Go down a notch at first sign of pressure */

/*

 * Create a mapping in device IO address space for specified pages

	/*

	 * add optional in-page offset from iova to size and align

	 * result to page size

	/*

	 * Following is a work-around (a.k.a. hack) to prevent pages

	 * with __GFP_COMP being passed to split_page() which cannot

	 * handle them.  The real problem is that this flag probably

	 * should be 0 on ARM as it is not supported on this

	 * platform; see CONFIG_HUGETLBFS.

/*

 * free a page as defined by the above mapping.

 * Must not be called with IRQs disabled.

/*

 * Map a part of the scatter-gather list into contiguous io address space

/**

 * arm_coherent_iommu_map_sg - map a set of SG buffers for streaming mode DMA

 * @dev: valid struct device pointer

 * @sg: list of buffers

 * @nents: number of buffers to map

 * @dir: DMA transfer direction

 *

 * Map a set of i/o coherent buffers described by scatterlist in streaming

 * mode for DMA. The scatter gather list elements are merged together (if

 * possible) and tagged with the appropriate dma address and length. They are

 * obtained via sg_dma_{address,length}.

/**

 * arm_iommu_map_sg - map a set of SG buffers for streaming mode DMA

 * @dev: valid struct device pointer

 * @sg: list of buffers

 * @nents: number of buffers to map

 * @dir: DMA transfer direction

 *

 * Map a set of buffers described by scatterlist in streaming mode for DMA.

 * The scatter gather list elements are merged together (if possible) and

 * tagged with the appropriate dma address and length. They are obtained via

 * sg_dma_{address,length}.

/**

 * arm_coherent_iommu_unmap_sg - unmap a set of SG buffers mapped by dma_map_sg

 * @dev: valid struct device pointer

 * @sg: list of buffers

 * @nents: number of buffers to unmap (same as was passed to dma_map_sg)

 * @dir: DMA transfer direction (same as was passed to dma_map_sg)

 *

 * Unmap a set of streaming mode DMA translations.  Again, CPU access

 * rules concerning calls here are the same as for dma_unmap_single().

/**

 * arm_iommu_unmap_sg - unmap a set of SG buffers mapped by dma_map_sg

 * @dev: valid struct device pointer

 * @sg: list of buffers

 * @nents: number of buffers to unmap (same as was passed to dma_map_sg)

 * @dir: DMA transfer direction (same as was passed to dma_map_sg)

 *

 * Unmap a set of streaming mode DMA translations.  Again, CPU access

 * rules concerning calls here are the same as for dma_unmap_single().

/**

 * arm_iommu_sync_sg_for_cpu

 * @dev: valid struct device pointer

 * @sg: list of buffers

 * @nents: number of buffers to map (returned from dma_map_sg)

 * @dir: DMA transfer direction (same as was passed to dma_map_sg)

/**

 * arm_iommu_sync_sg_for_device

 * @dev: valid struct device pointer

 * @sg: list of buffers

 * @nents: number of buffers to map (returned from dma_map_sg)

 * @dir: DMA transfer direction (same as was passed to dma_map_sg)

/**

 * arm_coherent_iommu_map_page

 * @dev: valid struct device pointer

 * @page: page that buffer resides in

 * @offset: offset into page for start of buffer

 * @size: size of buffer to map

 * @dir: DMA transfer direction

 *

 * Coherent IOMMU aware version of arm_dma_map_page()

/**

 * arm_iommu_map_page

 * @dev: valid struct device pointer

 * @page: page that buffer resides in

 * @offset: offset into page for start of buffer

 * @size: size of buffer to map

 * @dir: DMA transfer direction

 *

 * IOMMU aware version of arm_dma_map_page()

/**

 * arm_coherent_iommu_unmap_page

 * @dev: valid struct device pointer

 * @handle: DMA address of buffer

 * @size: size of buffer (same as passed to dma_map_page)

 * @dir: DMA transfer direction (same as passed to dma_map_page)

 *

 * Coherent IOMMU aware version of arm_dma_unmap_page()

/**

 * arm_iommu_unmap_page

 * @dev: valid struct device pointer

 * @handle: DMA address of buffer

 * @size: size of buffer (same as passed to dma_map_page)

 * @dir: DMA transfer direction (same as passed to dma_map_page)

 *

 * IOMMU aware version of arm_dma_unmap_page()

/**

 * arm_iommu_map_resource - map a device resource for DMA

 * @dev: valid struct device pointer

 * @phys_addr: physical address of resource

 * @size: size of resource to map

 * @dir: DMA transfer direction

/**

 * arm_iommu_unmap_resource - unmap a device DMA resource

 * @dev: valid struct device pointer

 * @dma_handle: DMA address to resource

 * @size: size of resource to map

 * @dir: DMA transfer direction

/**

 * arm_iommu_create_mapping

 * @bus: pointer to the bus holding the client device (for IOMMU calls)

 * @base: start address of the valid IO address space

 * @size: maximum size of the valid IO address space

 *

 * Creates a mapping structure which holds information about used/unused

 * IO address ranges, which is required to perform memory allocation and

 * mapping with IOMMU aware functions.

 *

 * The client device need to be attached to the mapping with

 * arm_iommu_attach_device function.

 currently only 32-bit DMA address space is supported */

/**

 * arm_iommu_attach_device

 * @dev: valid struct device pointer

 * @mapping: io address space mapping structure (returned from

 *	arm_iommu_create_mapping)

 *

 * Attaches specified io address space mapping to the provided device.

 * This replaces the dma operations (dma_map_ops pointer) with the

 * IOMMU aware version.

 *

 * More than one client might be attached to the same io address space

 * mapping.

/**

 * arm_iommu_detach_device

 * @dev: valid struct device pointer

 *

 * Detaches the provided device from a previously attached map.

 * This overwrites the dma_ops pointer with appropriate non-IOMMU ops.

 CONFIG_ARM_DMA_USE_IOMMU */

	/*

	 * Don't override the dma_ops if they have already been set. Ideally

	 * this should be the only location where dma_ops are set, remove this

	 * check when all other callers of set_dma_ops will have disappeared.

 Let arch_setup_dma_ops() start again from scratch upon re-probe */

 CONFIG_SWIOTLB */

 SPDX-License-Identifier: GPL-2.0

/*

 *  linux/arch/arm/mm/extable.c

 Clear the IT state to avoid nasty surprises in the fixup */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mm/cache-xsc3l2.c - XScale3 L2 cache controller support

 *

 * Copyright (C) 2007 ARM Limited

		/*

		 * Switching to a new page.  Because cache ops are

		 * using virtual addresses only, we must put a mapping

		 * in place for it.

 to force the first mapping */

	/*

	 * Clean and invalidate partial first cache line.

	/*

	 * Invalidate all full cache lines between 'start' and 'end'.

	/*

	 * Clean and invalidate partial last cache line.

 to force the first mapping */

/*

 * optimize L2 flush all operation by set/way format

 to force the first mapping */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/ioremap.c

 *

 * Re-map IO memory to kernel address space so that we can access it.

 *

 * (C) Copyright 1995 1996 Linus Torvalds

 *

 * Hacked for ARM by Phil Blundell <philb@gnu.org>

 * Hacked to allow all architectures to build, and various cleanups

 * by Russell King

 *

 * This allows a driver to remap an arbitrary region of bus memory into

 * virtual space.  One should *only* use readl, writel, memcpy_toio and

 * so on with such remapped areas.

 *

 * Because the ARM only has a 32-bit address space we can't address the

 * whole of the (physical) PCI space at once.  PCI huge-mode addressing

 * allows us to circumvent this restriction by splitting PCI space into

 * two 2GB chunks and mapping only one at a time into processor memory.

 * We use MMU protection domains to trap any attempt to access the bank

 * that is not currently mapped.  (This isn't fully implemented yet.)

 static_vmlist is ascending order */

/*

 * Section support is unsafe on SMP - If you iounmap and ioremap a region,

 * the other CPUs will not see this change until their next context switch.

 * Meanwhile, (eg) if an interrupt comes in on one of those other CPUs

 * which requires the new ioremap'd region to be referenced, the CPU will

 * reference the _old_ region.

 *

 * Note that get_vm_area_caller() allocates a guard 4K page, so we need to

 * mask the size back to 1MB aligned or we will overflow in the loop below.

			/*

			 * Clear the PMD from the page table, and

			 * increment the vmalloc sequence so others

			 * notice this change.

			 *

			 * Note: this is still racy on SMP machines.

			/*

			 * Free the page table, if there was one.

	/*

	 * Ensure that the active_mm is up to date - we want to

	 * catch any use-after-iounmap cases.

	/*

	 * Remove and free any PTE-based mapping, and

	 * sync the current kernel mapping.

	/*

	 * Remove and free any PTE-based mapping, and

	 * sync the current kernel mapping.

	/*

	 * High mappings must be supersection aligned

	/*

	 * Page align the mapping size, taking account of any offset.

	/*

	 * Try to reuse one of the static mapping whenever possible.

	/*

	 * Don't allow RAM to be mapped with mismatched attributes - this

	 * causes problems with ARMv6+

 	/*

 	 * Don't allow wraparound or zero size

/*

 * Remap an arbitrary physical address space into the kernel virtual

 * address space. Needed when the kernel wants to access high addresses

 * directly.

 *

 * NOTE! We need to allow non-page-aligned mappings too: we will obviously

 * have to convert them into an offset in a page-aligned mapping, but the

 * caller shouldn't need to know that small detail.

/*

 * Remap an arbitrary physical address space into the kernel virtual

 * address space as memory. Needed when the kernel wants to execute

 * code in external memory. This is needed for reprogramming source

 * clocks that would affect normal memory for example. Please see

 * CONFIG_GENERIC_ALLOCATOR for allocating external memory.

 If this is a static mapping, we must leave it alone */

		/*

		 * If this is a section based mapping we need to handle it

		 * specially as the VM subsystem does not know how to handle

		 * such a beast.

/*

 * Must be called after early_fixmap_init

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/copypage-v4wt.S

 *

 *  Copyright (C) 1995-1999 Russell King

 *

 *  This is for CPUs with a writethrough cache and 'flush ID cache' is

 *  the only supported cache operation.

/*

 * ARMv4 optimised copy_user_highpage

 *

 * Since we have writethrough caches, we don't have to worry about

 * dirty data in the cache.  However, we do have to ensure that

 * subsequent reads are up to date.

/*

 * ARMv4 optimised clear_user_page

 *

 * Same story as above.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Broadcom Brahma-B15 CPU read-ahead cache management functions

 *

 * Copyright (C) 2015-2016 Broadcom

 RAC register offsets, relative to the HIF_CPU_BIUCTRL register base */

 Brahma-B15 is a quad-core only design */

 Brahma-B53 is an octo-core design */

 Bitmask to enable instruction and data prefetching with a 256-bytes stride */

/* Special state where we want to bypass the spinlock and call directly

 * into the v7 cache maintenance operations during suspend/resume

/* Initialization flag to avoid checking for b15_rac_base, and to prevent

 * multi-platform kernels from crashing here as well.

		/* This dmb() is required to force the Bus Interface Unit

		 * to clean oustanding writes, and forces an idle cycle

		 * to be inserted.

 dsb() is required here to be consistent with __flush_icache_all() */

/* The readahead cache present in the Brahma-B15 CPU is a special piece of

 * hardware after the integrated L2 cache of the B15 CPU complex whose purpose

 * is to prefetch instruction and/or data with a line size of either 64 bytes

 * or 256 bytes. The rationale is that the data-bus of the CPU interface is

 * optimized for 256-bytes transactions, and enabling the readahead cache

 * provides a significant performance boost we want it enabled (typically

 * twice the performance for a memcpy benchmark application).

 *

 * The readahead cache is transparent for Modified Virtual Addresses

 * cache maintenance operations: ICIMVAU, DCIMVAC, DCCMVAC, DCCMVAU and

 * DCCIMVAC.

 *

 * It is however not transparent for the following cache maintenance

 * operations: DCISW, DCCSW, DCCISW, ICIALLUIS and ICIALLU which is precisely

 * what we are patching here with our BUILD_RAC_CACHE_OP here.

	/* During kexec, we are not yet migrated on the boot CPU, so we need to

	 * make sure we are SMP safe here. Once the RAC is disabled, flag it as

	 * suspended such that the hotplug notifier returns early.

/* The CPU hotplug case is the most interesting one, we basically need to make

 * sure that the RAC is disabled for the entire system prior to having a CPU

 * die, in particular prior to this dying CPU having exited the coherency

 * domain.

 *

 * Once this CPU is marked dead, we can safely re-enable the RAC for the

 * remaining CPUs in the system which are still online.

 *

 * Offlining a CPU is the problematic case, onlining a CPU is not much of an

 * issue since the CPU and its cache-level hierarchy will start filling with

 * the RAC disabled, so L1 and L2 only.

 *

 * In this function, we should NOT have to verify any unsafe setting/condition

 * b15_rac_base:

 *

 *   It is protected by the RAC_ENABLED flag which is cleared by default, and

 *   being cleared when initial procedure is done. b15_rac_base had been set at

 *   that time.

 *

 * RAC_ENABLED:

 *   There is a small timing windows, in b15_rac_init(), between

 *      cpuhp_setup_state_*()

 *      ...

 *      set RAC_ENABLED

 *   However, there is no hotplug activity based on the Linux booting procedure.

 *

 * Since we have to disable RAC for all cores, we keep RAC on as long as as

 * possible (disable it as late as possible) to gain the cache benefit.

 *

 * Thus, dying/dead states are chosen here

 *

 * We are choosing not do disable the RAC on a per-CPU basis, here, if we did

 * we would want to consider disabling it as early as possible to benefit the

 * other active CPUs.

 Running on the dying CPU */

	/* During kexec/reboot, the RAC is disabled via the reboot notifier

	 * return early here.

 Indicate that we are starting a hotplug procedure */

 Disable the readahead cache and save its value to a global */

 Running on a non-dying CPU */

	/* During kexec/reboot, the RAC is disabled via the reboot notifier

	 * return early here.

 And enable it */

	/* Suspend the read-ahead cache oeprations, forcing our cache

	 * implementation to fallback to the regular ARMv7 calls.

	 *

	 * We are guaranteed to be running on the boot CPU at this point and

	 * with every other CPU quiesced, so setting RAC_SUSPENDED is not racy

	 * here.

	/* Coming out of a S3 suspend/resume cycle, the read-ahead cache

	 * register RAC_CONFIG0_REG will be restored to its default value, make

	 * sure we re-enable it and set the enable flag, we are also guaranteed

	 * to run on the boot CPU, so not racy again.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/mmu.c

 *

 *  Copyright (C) 1995-2005 Russell King

/*

 * empty_zero_page is a special page that is used for

 * zero-initialized data and COW.

/*

 * The pmd table for the upper-most set of pages.

/*

 * Initialise the cache_policy variable with the initial state specified

 * via the "pmd" value.  This is used to ensure that on ARMv6 and later,

 * the C code sets the page tables up with the same policy as the head

 * assembly code, which avoids an illegal state where the TLBs can get

 * confused.  See comments in early_cachepolicy() for more information.

/*

 * These are useful for identifying cache coherency problems by allowing

 * the cache or the cache and writebuffer to be turned off.  (Note: the

 * write buffer should not be on and the cache off).

	/*

	 * This restriction is partly to do with the way we boot; it is

	 * unpredictable to have memory mapped using two different sets of

	 * memory attributes (shared, type, and cache attribs).  We can not

	 * change these attributes once the initial assembly has setup the

	 * page tables.

 ifdef CONFIG_CPU_CP15 */

 ifdef CONFIG_CPU_CP15 / else */

 Strongly ordered / ARMv6 shared device */

 ARMv6 non-shared device */

 ioremap_cache */

 ioremap_wc */

	/*

	 * The early fixmap range spans multiple pmds, for which

	 * we are not prepared:

/*

 * To avoid TLB flush broadcasts, this uses local_flush_tlb_kernel_range().

 * As a result, this can only be called with preemption disabled, as under

 * stop_machine().

 Make sure fixmap region does not exceed available allocation. */

 We support only device mappings before pgprot_kernel is set. */

/*

 * Adjust the PMD section entries according to the CPU in use.

	/*

	 * Strip out features not present on earlier architectures.

	 * Pre-ARMv5 CPUs don't have TEX bits.  Pre-ARMv6 CPUs or those

	 * without extended page tables don't have the 'Shared' bit.

	/*

	 * ARMv5 and lower, bit 4 must be set for page tables (was: cache

	 * "update-able on write" bit on ARM610).  However, Xscale and

	 * Xscale3 require this bit to be cleared.

	/*

	 * Mark the device areas according to the CPU/architecture.

			/*

			 * Mark device regions on ARMv6+ as execute-never

			 * to prevent speculative instruction fetches.

 Also setup NX memory mapping */

			/*

			 * For ARMv7 with TEX remapping,

			 * - shared device is SXCB=1100

			 * - nonshared device is SXCB=0100

			 * - write combine device mem is SXCB=0001

			 * (Uncached Normal memory)

			/*

			 * For Xscale3,

			 * - shared device is TEXCB=00101

			 * - nonshared device is TEXCB=01000

			 * - write combine device mem is TEXCB=00100

			 * (Inner/Outer Uncacheable in xsc3 parlance)

			/*

			 * For ARMv6 and ARMv7 without TEX remapping,

			 * - shared device is TEXCB=00001

			 * - nonshared device is TEXCB=01000

			 * - write combine device mem is TEXCB=00100

			 * (Uncached Normal in ARMv6 parlance).

		/*

		 * On others, write combining is "Uncached/Buffered"

	/*

	 * Now deal with the memory-type mappings

	/*

	 * We don't use domains on ARMv6 (since this causes problems with

	 * v6/v7 kernels), so we must use a separate memory type for user

	 * r/o, kernel r/w to map the vectors page.

	/*

	 * Check is it with support for the PXN bit

	 * in the Short-descriptor translation table format descriptors.

	/*

	 * ARMv6 and above have extended page tables.

		/*

		 * Mark cache clean areas and XIP ROM read only

		 * from SVC mode and no access from userspace.

		/*

		 * If the initial page tables were created with the S bit

		 * set, then we need to do the same here for the same

		 * reasons given in early_cachepolicy().

	/*

	 * Non-cacheable Normal - intended for memory areas that must

	 * not cause dirty cache line writebacks when used

 Non-cacheable Normal is XCB = 001 */

 For both ARMv6 and non-TEX-remapping ARMv7 */

	/*

	 * Do not generate access flag faults for the kernel mappings.

	/*

	 * Set PXN for user mappings

	/*

	 * In classic MMU format, puds and pmds are folded in to

	 * the pgds. pmd_offset gives the PGD entry. PGDs refer to a

	 * group of L1 entries making up one logical pointer to

	 * an L2 table (2MB), where as PMDs refer to the individual

	 * L1 entries (1MB). Hence increment to get the correct

	 * offset for odd 1MB sections.

	 * (See arch/arm/include/asm/pgtable-2level.h)

		/*

		 * With LPAE, we must loop over to map

		 * all the pmds for the given range.

		/*

		 * Try a section mapping - addr, next and phys must all be

		 * aligned to a section boundary.

	/* N.B.	ARMv6 supersections are only defined to work with domain 0.

	 *	Since domain assignments can in fact be arbitrary, the

	 *	'domain == 0' check below is required to insure that ARMv6

	 *	supersections are only allocated for domain 0 regardless

	 *	of the actual domain assignments in use.

	/*

	 * Shift bits [35:32] of address into bits [23:20] of PMD

	 * (See ARMv6 spec).

 !CONFIG_ARM_LPAE */

	/*

	 * Catch 36-bit addresses

/*

 * Create the page directory entries and any necessary

 * page tables for the mapping specified by `md'.  We

 * are able to cope here with varying sizes and address

 * offsets, and we take full advantage of sections and

 * supersections.

/*

 * Create the architecture specific mappings

/*

 * The Linux PMD is made of two consecutive section entries covering 2MB

 * (see definition in include/asm/pgtable-2level.h).  However a call to

 * create_mapping() may optimize static mappings by using individual

 * 1MB section mappings.  This leaves the actual PMD potentially half

 * initialized if the top or bottom section entry isn't used, leaving it

 * open to problems if a subsequent ioremap() or vmalloc() tries to use

 * the virtual space left free by that unused section entry.

 *

 * Let's avoid the issue by inserting dummy vm entries covering the unused

 * PMD halves once the static mappings are in place.

		/*

		 * Check if this vm starts on an odd section boundary.

		 * If so and the first section entry for this PMD is free

		 * then we block the corresponding virtual address.

		/*

		 * Then check if this vm ends on an odd section boundary.

		 * If so and the second section entry for this PMD is empty

		 * then we block the corresponding virtual address.

 no need to look at any vm entry until we hit the next PMD */

/*

 * vmalloc=size forces the vmalloc area to be exactly 'size'

 * bytes. This can be used to increase (or decrease) the vmalloc

 * area - the default is 240MiB.

	/*

	 * Let's use our own (unoptimized) equivalent of __pa() that is

	 * not affected by wrap-arounds when sizeof(phys_addr_t) == 4.

	 * The result is used as the upper bound on physical memory address

	 * and may itself be outside the valid range for which phys_addr_t

	 * and therefore __pa() is defined.

	/*

	 * The first usable region must be PMD aligned. Mark its start

	 * as MEMBLOCK_NOMAP if it isn't

				/*

				 * Compare as u64 to ensure vmalloc_limit does

				 * not get truncated. block_end should always

				 * fit in phys_addr_t so there should be no

				 * issue with assignment.

			/*

			 * Find the first non-pmd-aligned page, and point

			 * memblock_limit at it. This relies on rounding the

			 * limit down to be pmd-aligned, which happens at the

			 * end of this function.

			 *

			 * With this algorithm, the start or end of almost any

			 * bank can be non-pmd-aligned. The only exception is

			 * that the start of the bank 0 must be section-

			 * aligned, since otherwise memory would need to be

			 * allocated when mapping the start of bank 0, which

			 * occurs before any free memory is mapped.

	/*

	 * Round the memblock limit down to a pmd size.  This

	 * helps to ensure that we will allocate memory from the

	 * last full pmd, which should be mapped.

	/*

	 * Clear out all the mappings below the kernel image.

	/*

	 * KASan's shadow memory inserts itself between the TASK_SIZE

	 * and MODULES_VADDR. Do not clear the KASan shadow memory mappings.

	/*

	 * Skip over the KASan shadow area. KASAN_SHADOW_END is sometimes

	 * equal to MODULES_VADDR and then we exit the pmd clearing. If we

	 * are using a thumb-compiled kernel, there there will be 8MB more

	 * to clear as KASan always offset to 16 MB below MODULES_VADDR.

 The XIP kernel is mapped in the module area -- skip over it */

	/*

	 * Find the end of the first block of lowmem.

	/*

	 * Clear out all the kernel space mappings, except for the first

	 * memory bank, up to the vmalloc region.

 the first page is reserved for pgd */

/*

 * Reserve the special regions of memory

	/*

	 * Reserve the page tables.  These are already in use,

	 * and can only be in node 0.

	/*

	 * Because of the SA1111 DMA bug, we want to preserve our

	 * precious DMA-able memory...

/*

 * Set up the device mappings.  Since we clear out the page tables for all

 * mappings above VMALLOC_START, except early fixmap, we might remove debug

 * device mappings.  This means earlycon can be used to debug this function

 * Any other function or debugging method which may touch any device _will_

 * crash the kernel.

	/*

	 * Allocate the vector page early.

	/*

	 * Clear page table except top pmd used by early fixmaps

 create a read-only mapping of the device tree */

	/*

	 * Map the kernel if it is XIP.

	 * It is always first in the modulearea.

	/*

	 * Map the cache flushing regions.

	/*

	 * Create a mapping for the machine vectors at the high-vectors

	 * location (0xffff0000).  If we aren't using high-vectors, also

	 * create a mapping at the low-vectors virtual address.

 Now create a kernel read-only mapping */

	/*

	 * Ask the machine support to map in the statically mapped devices.

 Reserve fixed i/o space in VMALLOC region */

	/*

	 * Finally flush the caches and tlb to ensure that we're in a

	 * consistent state wrt the writebuffer.  This also ensures that

	 * any write-allocated cache lines in the vector page are written

	 * back.  After this point, we can start to touch devices again.

 Enable asynchronous aborts */

 Map all the lowmem memory banks. */

		/*

		 * If our kernel image is in the VMALLOC area we need to remove

		 * the kernel physical memory from lowmem since the kernel will

		 * be mapped separately.

		 *

		 * The kernel will typically be at the very start of lowmem,

		 * but any placement relative to memory ranges is possible.

		 *

		 * If the memblock contains the kernel, we have to chisel out

		 * the kernel memory from it and map each part separately. We

		 * get 6 different theoretical cases:

		 *

		 *                            +--------+ +--------+

		 *  +-- start --+  +--------+ | Kernel | | Kernel |

		 *  |           |  | Kernel | | case 2 | | case 5 |

		 *  |           |  | case 1 | +--------+ |        | +--------+

		 *  |  Memory   |  +--------+            |        | | Kernel |

		 *  |  range    |  +--------+            |        | | case 6 |

		 *  |           |  | Kernel | +--------+ |        | +--------+

		 *  |           |  | case 3 | | Kernel | |        |

		 *  +-- end ----+  +--------+ | case 4 | |        |

		 *                            +--------+ +--------+

 Case 5: kernel covers range, don't map anything, should be rare */

 Cases where the kernel is starting inside the range */

 Case 6: kernel is embedded in the range, we need two mappings */

 Map memory below the kernel */

 Map memory above the kernel */

 Case 1: kernel and range start at the same address, should be common */

 Case 3: kernel and range end at the same address, should be rare */

 Case 2: kernel ends inside range, starts below it */

 Case 4: kernel starts inside range, ends above it */

	/*

	 * We use the well known kernel section start and end and split the area in the

	 * middle like this:

	 *  .                .

	 *  | RW memory      |

	 *  +----------------+ kernel_x_start

	 *  | Executable     |

	 *  | kernel memory  |

	 *  +----------------+ kernel_x_end / kernel_nx_start

	 *  | Non-executable |

	 *  | kernel memory  |

	 *  +----------------+ kernel_nx_end

	 *  | RW memory      |

	 *  .                .

	 *

	 * Notice that we are dealing with section sized mappings here so all of this

	 * will be bumped to the closest section boundary. This means that some of the

	 * non-executable part of the kernel memory is actually mapped as executable.

	 * This will only persist until we turn on proper memory management later on

	 * and we remap the whole kernel with page granularity.

 If the nx part is small it may end up covered by the tail of the RWX section */

/*

 * early_paging_init() recreates boot time page table setup, allowing machines

 * to switch over to a high (>4G) address space on LPAE systems

	/*

	 * Offset the kernel section physical offsets so that the kernel

	 * mapping will work out later on.

	/*

	 * Get the address of the remap function in the 1:1 identity

	 * mapping setup by the early page table assembly code.  We

	 * must get this prior to the pv update.  The following barrier

	 * ensures that this is complete before we fixup any P:V offsets.

 Re-set the phys pfn offset, and the pv offset */

 Run the patch stub to update the constants */

	/*

	 * We changing not only the virtual to physical mapping, but also

	 * the physical addresses used to access memory.  We need to flush

	 * all levels of cache in the system with caching disabled to

	 * ensure that all data is written back, and nothing is prefetched

	 * into the caches.  We also need to prevent the TLB walkers

	 * allocating into the caches too.  Note that this is ARMv7 LPAE

	 * specific.

	/*

	 * Fixup the page tables - this must be in the idmap region as

	 * we need to disable the MMU to do this safely, and hence it

	 * needs to be assembly.  It's fairly simple, as we're using the

	 * temporary tables setup by the initial assembly code.

 Re-enable the caches and cacheable TLB walks */

 Only i/o device mappings are supported ATM */

/*

 * paging_init() sets up the page tables, initialises the zone memory

 * maps, and sets up the zero page, bad page and bad page tables.

	/*

	 * After this point early_alloc(), i.e. the memblock allocator, can

	 * be used

 allocate the zero page. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mm/proc-syms.c

 *

 *  Copyright (C) 2000-2002 Russell King

/*

 * No module should need to touch the TLB (and currently

 * no modules do.  We export this for "loadkernel" support

 * (booting a new kernel from within a running kernel.)

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  arch/arm/mach-socfpga/pm.c

 *

 * Copyright (C) 2014-2015 Altera Corporation. All rights reserved.

 *

 * with code from pm-imx6.c

 * Copyright 2011-2014 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

 Pointer to function copied to ocram */

 Copy the code that puts DDR in self refresh to ocram */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright Altera Corporation (C) 2016. All rights reserved.

 Find the OCRAM EDAC device tree node */

 Clear any pending OCRAM ECC interrupts, then enable ECC */

 Arria10 OCRAM Section */

 ECC Manager Defines */

/*

 * This function uses the memory initialization block in the Arria10 ECC

 * controller to initialize/clear the entire memory data and ECC data.

 Clear any pending ECC interrupts */

 Find the OCRAM EDAC device tree node */

 Map the ECC Block */

 Disable ECC */

 Ensure all writes complete */

 Use HW initialization block to initialize memory for ECC */

 Enable ECC */

 Ensure all writes complete */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright Altera Corporation (C) 2016. All rights reserved.

 A10 System Manager L2 ECC Control register */

 A10 System Manager Global IRQ Mask register */

 A10 System Manager L2 ECC IRQ Clear register */

 Enable ECC */

 Find the L2 EDAC device tree node */

 Clear any pending IRQs */

 Enable ECC */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2010-2011 Calxeda, Inc.

 * Copyright 2012 Pavel Machek <pavel@denx.de>

 * Based on platsmp.c, Copyright (C) 2002 ARM Ltd.

 * Copyright (C) 2012 Altera Corporation

 This will put CPU #1 into reset. */

 This will release CPU #1 out of reset. */

 This will release CPU #1 out of reset. */

/*

 * platform-specific code to shutdown a CPU

 *

 * Called with IRQs disabled

 Do WFI. If we wake up early, go back into WFI */

/*

 * We need a dummy function so that platform_can_cpu_hotplug() knows

 * we support CPU hotplug. However, the function does not need to do

 * anything, because CPUs going offline just do WFI. We could reset

 * the CPUs but it would increase power consumption.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2012-2015 Altera Corporation

 Ensure that socfpga_cpu1start_addr is visible to other CPUs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * DaVinci Power Management Routines

 *

 * Copyright (C) 2009 Texas Instruments, Inc. https://www.ti.com/

 Switch CPU PLL to bypass mode */

 Powerdown CPU PLL */

 Configure sleep count in deep sleep register */

 System goes to sleep in this call */

 put CPU PLL in reset */

 put CPU PLL in power down */

 wait for CPU PLL reset */

 bring CPU PLL out of reset */

 Wait for CPU PLL to lock */

 Remove CPU PLL from bypass mode */

/*

 * DM355 leopard board support

 *

 * Based on board-dm355-evm.c

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/* NOTE:  this is geared for the standard config, with a socketed

 * 2 GByte Micron NAND (MT29F16G08FAA) using 128KB sectors.  If you

 * swap chips, maybe with a different block size, partitioning may

 * need to be changed.

 UBL (a few copies) plus U-Boot */

 force read-only */

 U-Boot environment */

 two blocks with bad block table (and mirror) at the end */

 kHz */,

 usec */,

	/* we "know" these are input-only so we don't

	 * need to call gpio_direction_input()

 plus irq */ },

 { I2C_BOARD_INFO("tlv320aic3x", 0x1b), }, */

 { I2C_BOARD_INFO("tvp5146", 0x5d), }, */

 addr */

 data */

 rising (active high) */,

 low == card present */

 high == card's write protect switch active */

/* Don't connect anything to J10 unless you're only using USB host

 * mode *and* have to do so with some kind of gender-bender.  If

 * you have proper Mini-B or Mini-A cables (or Mini-A adapters)

 * the ID pin won't need any help.

 ID pulled low */

 at 3v3 */

	/* NOTE:  NAND flash timings set by the UBL are slower than

	 * needed by MT29F16G08FAA chips ... EMIF.A1CR is 0x40400204

	 * but could be 0x0400008c for about 25% faster page reads.

 irlml6401 switches over 1A in under 8 msec */

/*

 * Neuros Technologies OSD2 board support

 *

 * Modified from original 644X-EVM board support.

 * 2008 (c) Neuros Technology, LLC.

 * 2009 (c) Jorge Luis Zapata Muga <jorgeluis.zapata@gmail.com>

 * 2009 (c) Andrey A. Porodko <Andrey.Porodko@gmail.com>

 *

 * The Neuros OSD 2.0 is the hardware component of the Neuros Open

 * Internet Television Platform. Hardware is very close to TI

 * DM644X-EVM board. It has:

 * 	DM6446M02 module with 256MB NAND, 256MB RAM, TLV320AIC32 AIC,

 * 	USB, Ethernet, SD/MMC, UART, THS8200, TVP7000 for video.

 * 	Additionally realtime clock, IR remote control receiver,

 * 	IR Blaster based on MSP430 (firmware although is different

 * 	from used in DM644X-EVM), internal ATA-6 3.5 HDD drive

 * 	with PATA interface, two muxed red-green leds.

 *

 * For more information please refer to

 * 		http://wiki.neurostechnology.com/index.php/OSD_2.0_HD

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/* Neuros OSD2 has a Samsung 256 MByte NAND flash (Dev ID of 0xAA,

 * 2048 blocks in the device, 64 pages per block, 2048 bytes per

 * page.

 UBL (a few copies) plus U-Boot */

 force read-only */

 U-Boot environment */

 Kernel */

 File System */

 A few blocks at end hold a flash Bad Block Table. */

 only one device will be jumpered and detected */

	/*

	 * Mux the pins to be GPIOs, VLYNQEN is already done at startup.

	 * The AEAWx are five new AEAW pins that can be muxed by separately.

	 * They are a bitmask for GPIO management. According TI

	 * documentation (https://www.ti.com/lit/gpn/tms320dm6446) to employ

	 * gpio(10,11,12,13) for leds any combination of bits works except

	 * four last. So we are to reset all five.

 Maintainer: Neuros Technologies <neuros@groups.google.com> */

/*

 * Runtime PM support code for DaVinci

 *

 * Author: Kevin Hilman

 *

 * Copyright (C) 2012 Texas Instruments, Inc.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Use pm_clk as fallback if we're not using genpd. */

/*

 * Utility to set the DAVINCI MUX register from a table in mux.h

 *

 * Author: Vladimir Barinov, MontaVista Software, Inc. <source@mvista.com>

 *

 * Based on linux/arch/arm/plat-omap/mux.c:

 * Copyright (C) 2003 - 2005 Nokia Corporation

 *

 * Written by Tony Lindgren

 *

 * 2007 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

 *

 * Copyright (C) 2008 Texas Instruments.

/*

 * Sets the DAVINCI MUX register based on the table

 Update the mux register in question */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * mach-davinci/devices.c

 *

 * DaVinci platform device setup/initialization

	/*

	 * Throw a bug since a lot of board initialization code depends

	 * on system module availability. ioremap() failing this early

	 * need careful looking into anyway.

 IRQ_DM646X_IDE is the same as IRQ_IDE */

 different on dm355 */

 IRQs:  MMC/SD, then SDIO */

 different on dm355 */

 IRQs:  MMC/SD, then SDIO */

	/* REVISIT: update PINMUX, ARM_IRQMUX, and EDMA_EVTMUX here too;

	 * for example if MMCSD1 is used for SDIO, maybe DAT2 is unused.

	 *

	 * FIXME dm6441 (no MMC/SD), dm357 (one), and dm335 (two) are

	 * not handled right here ...

			/* REVISIT we may not need all these pins if e.g. this

			 * is a hard-wired SDIO device...

 Configure pull down control */

 expose all 6 MMC0 signals:  CLK, CMD, DATA[0..3] */

 enable RX EDMA */

 REVISIT: should this be in board-init code? */

 Power-on 3.3V IO cells */

Set up the pull regiter for MMC */

-------------------------------------------------------------------------*/

/*

 * TI DaVinci DM365 chip specific setup

 *

 * Copyright (C) 2009 Texas Instruments

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 24 MHz on the DM365 EVM */

 not all slaves will be wired up */

 registers */

 interrupt */

 Four Transfer Controllers on DM365 */

 {event queue no, Priority} */

 not using TC*_ERR */

 registers */

 interrupt */

 Contents of JTAG ID register used to identify exact cpu type */

/*

 * Bottom half of timer0 is used for clockevent, top half is used for

 * clocksource.

 all clocks are currently registered in dm365_init_time() */

 VPSS ISP5 Base address */

 VPSS CLK Base address */

 ISIF Base address */

 ISIF Linearization table 0 */

 ISIF Linearization table 1 */

 venc registers io space */

 vdaccfg registers io space */

 venc registers io space */

 set sysclk4 to output 74.25 MHz from pll1 */

/*

 * TI DaVinci DM646x chip specific setup

 *

 * Author: Kevin Hilman, Deep Root Systems, LLC

 *

 * 2007 (c) Deep Root Systems, LLC. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

/*

 * Device specific mux setup

 *

 *	soc	description	mux  mode   mode  mux	 dbg

 *				reg  offset mask  mode

 dma */

 dma */

 dma */

 dma */

 clockevent */

 clocksource */

 DSP timer */

 system tick */

----------------------------------------------------------------------*/

 Four Transfer Controllers on DM646x */

 {event queue no, Priority} */

 not using TC*_ERR */

 DIT mode only, rx is not supported */

 registers */

 interrupt */

----------------------------------------------------------------------*/

 Contents of JTAG ID register used to identify exact cpu type */

/*

 * Bottom half of timer0 is used for clockevent, top half is used for

 * clocksource.

 PLL1 and PSC are registered in dm646x_init_time() */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * mach-davinci/sram.c - DaVinci simple SRAM allocator

 *

 * Copyright (C) 2009 David Brownell

/*

 * REVISIT This supports CPU and DMA access to/from SRAM, but it

 * doesn't (yet?) support some other notable uses of SRAM:  as TCM

 * for data and/or instructions; and holding code needed to enter

 * and exit suspend states (while DRAM can't be used).

/*

 * TI DA850/OMAP-L138 EVM board

 *

 * Copyright (C) 2009 Texas Instruments Incorporated - https://www.ti.com/

 *

 * Derived from: arch/arm/mach-davinci/board-da830-evm.c

 * Original Copyrights follow:

 *

 * 2007, 2009 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

	/*

	 * The nvmem name differs from the partition name because of the

	 * internal works of the nvmem framework.

/* DA850/OMAP-L138 EVM includes a 512 MByte large-page NAND flash

 * (128K blocks). It may be used instead of the (default) SPI flash

 * to boot, using TI's tools to install the secondary boot loader

 * (UBL) and U-Boot.

/*

 * At 200ms polling interval it is possible to miss an

 * event by tapping very lightly on the push button but most

 * pushes do result in an event; longer intervals require the

 * user to hold the button whereas shorter intervals require

 * more CPU time for polling.

 assigned at runtime */

 assigned at runtime */

 assigned at runtime */

 deselect all functionalities */

 deselect all functionalities */

 assign the baseboard expander's GPIOs after the UI board's */

 assigned at runtime */

 assigned at runtime */

 assigned at runtime */

 assigned at runtime */

 assigned at runtime */

	/*

	 * Register the switches and pushbutton on the baseboard as a gpio-keys

	 * device.

 kHz */

 usec */

 davinci da850 evm audio machine driver */

 gpio chip 2 contains gpio range 64-95 */

 Dummy fixed regulator is 0 */

 Fixed regulator support */

 Baseboard 3.3V: 5V -> TPS73701DCQ -> 3.3V */

 Baseboard 1.8V: 5V -> TPS73701DCQ -> 1.8V */

 UI card 3.3V: 5V -> TPS73701DCQ -> 3.3V */

 TPS65070 voltage regulator support */

 3.3V */

 3.3V or 1.8V */

 1.2V */

 1.8V LDO */

 1.2V LDO */

 We take advantage of the fact that both defdcdc{2,3} are tied high */

 dcdc1 */

 dcdc2 */

 dcdc3 */

 ldo1 */

 ldo2 */

 ms between touch samples */

 minimum pressure to trigger touch */

 /sys/class/input/input?/id/vendor */

 /sys/class/input/input?/id/product */

 /sys/class/input/input?/id/version */

 dflags set in da850_evm_config_emac() */

 configure the CFGCHIP3 register for RMII or MII */

/*

 * The following EDMA channels/slots are not being used by drivers (for

 * example: Timer, GPIO, UART events etc) on da850/omap-l138 EVM, hence

 * they are being reserved for codecs on the DSP side.

 (offset, number) */

 (offset, number) */

 (offset, number) */

 (offset, number) */

 VPIF capture configuration */

 VPIF display configuration */

	/*

	 * shut down uart 0 and 1; they are not used on the board and

	 * accessing them causes endless "too much work in irq53" messages

	 * with arago fs

 Handle board specific muxing for LCD here */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * TI DaVinci serial driver

 *

 * Copyright (C) 2006 Texas Instruments.

 disable all interrupts */

 reset both transmitter and receiver: bits 14,13 = UTRST, URRST */

	/*

	 * Make sure the serial ports are muxed on at this point.

	 * You have to mux them off in device drivers later on if not needed.

/*

 * TI DaVinci EVM board support

 *

 * Author: Kevin Hilman, Deep Root Systems, LLC

 *

 * 2007 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

/* NOTE:  this is geared for the standard config, with a socketed

 * 2 GByte Micron NAND (MT29F16G08FAA) using 128KB sectors.  If you

 * swap chips, maybe with a different block size, partitioning may

 * need to be changed.

 UBL (a few copies) plus U-Boot */

 force read-only */

 U-Boot environment */

 two blocks with bad block table (and mirror) at the end */

 kHz */,

 usec */,

	/* we "know" these are input-only so we don't

	 * need to call gpio_direction_input()

 { plus irq  }, */

 addr */

 data */

 rising (active high) */,

 Inputs available at the TVP5146 */

/*

 * this is the route info for connecting each input to decoder

 * ouput that goes to vpfe. There is a one to one correspondence

 * with tvp5146_inputs

 venc standards timings */

/*

 * The outputs available from VPBE + ecnoders. Keep the

 * the order same as that of encoders. First those from venc followed by that

 * from encoders. Index in the output refers to index on a particular encoder.

 * Driver uses this index to pass it to encoder when it supports more than

 * one output. Application uses index of the array to set an output.

 low == card present */

 high == card's write protect switch active */

/* Don't connect anything to J10 unless you're only using USB host

 * mode *and* have to do so with some kind of gender-bender.  If

 * you have proper Mini-B or Mini-A cables (or Mini-A adapters)

 * the ID pin won't need any help.

 ID pulled low */

 at 3v3 */

	/* NOTE:  NAND flash timings set by the UBL are slower than

	 * needed by MT29F16G08FAA chips ... EMIF.A1CR is 0x40400204

	 * but could be 0x0400008c for about 25% faster page reads.

 irlml6401 switches over 1A in under 8 msec */

 DM335 EVM uses ASP1; line-out is a stereo mini-jack */

/*

 * Hawkboard.org based on TI's OMAP-L138 Platform

 *

 * Initial code: Syed Mohammed Khasim

 *

 * Copyright (C) 2009 Texas Instruments Incorporated - https://www.ti.com

 *

 * This file is licensed under the terms of the GNU General Public License

 * version 2. This program is licensed "as is" without any warranty of

 * any kind, whether express or implied.

 configure the CFGCHIP3 register for MII */

/*

 * The following EDMA channels/slots are not being used by drivers (for

 * example: Timer, GPIO, UART events etc) on da850/omap-l138 EVM/Hawkboard,

 * hence they are being reserved for codecs on the DSP side.

 (offset, number) */

 (offset, number) */

 (offset, number) */

 (offset, number) */

 TPS2087 switch @ 5V */

 3 ms max */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * DA8XX/OMAP L1XX platform device data

 *

 * Copyright (c) 2007-2009, MontaVista Software, Inc. <source@mvista.com>

 * Derived from code that was:

 *	Copyright (C) 2006 Komal Shah <komal_shah802003@yahoo.com>

 DA8XX_TIMER64P1_BASE */

 {event queue no, Priority} */

 {event queue no, Priority} */

 TX event */

 RX event */

 TX event */

 RX event */

 TX event */

 RX event */

 Valid for DA830/OMAP-L137 or DA850/OMAP-L138 */

 Valid for DA830/OMAP-L137 only */

 Valid for DA830/OMAP-L137 only */

 registers */

 interrupt */

 registers */

 interrupt */

 registers */

 interrupt */

 registers */

 interrupt */

 DSP boot address */

 DSP interrupt registers */

 DSP L2 RAM */

 DSP L1P RAM */

 DSP L1D RAM */

 dsp irq */

 timer irq */

 alarm irq */

 DA8XX devices support DDR2 power down */

/**

 * da8xx_get_cfgchip - Lazy gets CFGCHIP as regmap

 *

 * This is for use on non-DT boards only. For DT boards, use

 * syscon_regmap_lookup_by_compatible("ti,da830-cfgchip")

 *

 * Returns: Pointer to the CFGCHIP regmap or negative error code.

 SPDX-License-Identifier: GPL-2.0

/*

 * USB

 OTG requires a Mini-AB connector */

 physical address */

 placeholder for the dedicated CPPI IRQ */

 Override the defaults as DM6467 uses different IRQs. */

 other devices don't have dedicated CPPI IRQ */

 CONFIG_USB_MUSB_HDRC */

/*

 * TI DaVinci DM646X EVM board

 *

 * Derived from: arch/arm/mach-davinci/board-evm.c

 * Copyright (C) 2006 Texas Instruments.

 *

 * (C) 2007-2008, MontaVista Software, Inc.

 *

 * This file is licensed under the terms of the GNU General Public License

 * version 2. This program is licensed "as is" without any warranty of any

 * kind, whether express or implied.

 *

/**************************************************************************

 * Included Files

/* Note: We are setting first partition as 'bootloader' constituting UBL, U-Boot

 * and U-Boot environment this avoids dependency on any particular combination

 * of UBL, U-Boot or flashing tools etc.

 UBL, U-Boot with environment */

 force read-only */

 CPLD Register 0 bits to control ATA */

 CPLD Register 0 Client: used for I/O Control */

 Clear ATA_RSTn and ATA_PWD bits to enable ATA operation. */

 LEDS */

/* Most of this EEPROM is unused, but U-Boot uses some data:

 *  - 0x7f00, 6 bytes Ethernet Address

 *  - ... newer boards may have more

 kHz */,

 usec */,

 spin lock for updating above registers */

 disable the clock */

 enable the clock */

/**

 * setup_vpif_input_path()

 * @channel: channel id (0 - CH0, 1 - CH1)

 * @sub_dev_name: ptr sub device name

 *

 * This will set vpif input to capture data from tvp514x or

 * tvp7002.

 for channel 1, we don't do anything */

/**

 * setup_vpif_input_channel_mode()

 * @mux_mode:  mux mode. 0 - 1 channel or (1) - 2 channel

 *

 * This will setup input mode to one channel (TVP7002) or 2 channel (TVP5147)

/*

 * The following EDMA channels/slots are not being used by drivers (for

 * example: Timer, GPIO, UART events etc) on dm646x, hence they are being

 * reserved for codecs on the DSP side.

 (offset, number) */

 (offset, number) */

/*

 * TI DA830/OMAP L137 chip specific setup

 *

 * Author: Mark A. Greer <mgreer@mvista.com>

 *

 * 2009 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

 Offsets of the 8 compare registers on the da830 */

/*

 * Device specific mux setup

 *

 *	     soc      description	mux    mode    mode   mux	dbg

 *					reg   offset   mask   mode

 Contents of JTAG ID register used to identify exact cpu type */

 0x02f >> 1 */

/*

 * Bottom half of timer0 is used both for clock even and clocksource.

 * Top half is used by DSP.

 PLL is registered in da830_init_time() */

/*

 * TI DaVinci DM365 EVM board support

 *

 * Copyright (C) 2009 Texas Instruments Incorporated

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 REVISIT when it's supported, trigger via Kconfig */

 REVISIT when it's supported, trigger via Kconfig */

/*

 * A MAX-II CPLD is used for various board control functions.

 r/o */

 r/o */

 r/o */

 r/o */

/* NOTE:  this is geared for the standard config, with a socketed

 * 2 GByte Micron NAND (MT29F16G08FAA) using 128KB sectors.  If you

 * swap chips with a different block size, partitioning will

 * need to be changed. This NAND chip MT29F16G08FAA is the default

 * NAND shipped with the Spectrum Digital DM365 EVM

 UBL (a few copies) plus U-Boot */

 force read-only */

 U-Boot environment */

 two blocks with bad block table (and mirror) at the end */

 kHz */,

 usec */,

 Fixed regulator support */

 Baseboard 3.3V: 5V -> TPS767D301 -> 3.3V */

 Baseboard 1.8V: 5V -> TPS767D301 -> 1.8V */

 Scan period = strobe + interval */

 low == card present */

 high == card's write protect switch active */

	/*

	 * EMAC pins are multiplexed with GPIO and UART

	 * Further details are available at the DM365 ARM

	 * Subsystem Users Guide(sprufg5.pdf) pages 125 - 127

	/*

	 * EMAC interrupts are multiplexed with GPIO interrupts

	 * Details are available at the DM365 ARM

	 * Subsystem Users Guide(sprufg5.pdf) pages 133 - 134

	/*

	 * MMC/SD pins are multiplexed with GPIO and EMIF

	 * Further details are available at the DM365 ARM

	 * Subsystem Users Guide(sprufg5.pdf) pages 118, 128 - 131

 Inputs available at the TVP5146 */

/*

 * this is the route info for connecting each input to decoder

 * ouput that goes to vpfe. There is a one to one correspondence

 * with tvp5146_inputs

 venc standards timings */

 venc dv timings */

/*

 * The outputs available from VPBE + ecnoders. Keep the

 * the order same as that of encoders. First those from venc followed by that

 * from encoders. Index in the output refers to index on a particular

 * encoder.Driver uses this index to pass it to encoder when it supports more

 * than one output. Application uses index of the array to set an output.

/*

 * Amplifiers on the board

 setup LEDs */

 run after subsys_initcall() for LEDs */

	/* Make sure we can configure the CPLD through CS1.  Then

	 * leave it on for later access to MMC and LED registers.

 External muxing for some signals */

	/* Read SW5 to set up NAND + keypad _or_ OneNAND (sync read).

	 * NOTE:  SW4 bus width setting must match!

 external keypad mux */

 no OneNAND support yet */

 Leave external chips in reset when unused. */

	/* Static video input config with SN74CBT16214 1-of-3 mux:

	 *  - port b1 == tvp7002 (mux lowbits == 1 or 6)

	 *  - port b2 == imager (mux lowbits == 2 or 7)

	 *  - port b3 == tvp5146 (mux lowbits == 5)

	 *

	 * Runtime switching could work too, with limitations.

 externally mux MMC1/ENET/AIC33 to imager */

 we can use MMC1 ... */

 ... and ENET ... */

 ... and AIC33 */

 default to tvp5146 */

 REVISIT export switches: NTSC/PAL (SW5.6), EXTRA1 (SW5.2), etc */

 maybe setup mmc1/etc ... _after_ mmc0 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Lyrtech SFFSDR board support.

 *

 * Copyright (C) 2008 Philip Balister, OpenSDR <philip@opensdr.com>

 * Copyright (C) 2008 Lyrtech <www.lyrtech.com>

 *

 * Based on DV-EVM platform, original copyright follows:

 *

 * Copyright (C) 2007 MontaVista Software, Inc.

	/* U-Boot Environment: Block 0

	 * UBL:                Block 1

	 * U-Boot:             Blocks 6-7 (256 kb)

	 * Integrity Kernel:   Blocks 8-31 (3 Mb)

	 * Integrity Data:     Blocks 100-END

 2 Mb */

 Force read-only */

 32 Mb */

 R/W */

 Name of driver */

	/* Other I2C devices:

	 * MSP430,  addr 0x23 (not used)

	 * PCA9543, addr 0x70 (setup done by U-Boot)

	 * ADS7828, addr 0x48 (ADC for voltage monitoring.)

 kHz */,

 usec */,

 We support only peripheral mode. */

 mux VLYNQ pins */

/*

 * TI DA850/OMAP-L138 chip specific setup

 *

 * Copyright (C) 2009 Texas Instruments Incorporated - https://www.ti.com/

 *

 * Derived from: arch/arm/mach-davinci/da830.c

 * Original Copyrights follow:

 *

 * 2009 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

/*

 * Device specific mux setup

 *

 *		soc	description	mux	mode	mode	mux	dbg

 *					reg	offset	mask	mode

 UART0 function */

 UART1 function */

 UART2 function */

 I2C1 function */

 I2C0 function */

 EMAC function */

 McASP function */

 LCD function */

 MMC/SD0 function */

 MMC/SD1 function */

 EMIF2.5/EMIFA function */

 GPIO function */

 VPIF Capture */

 VPIF Display */

 Contents of JTAG ID register used to identify exact cpu type */

 0x02f >> 1 */

 0x02f >> 1 */

/*

 * Bottom half of timer 0 is used for clock_event, top half for

 * clocksource.

/*

 * Notes:

 * According to the TRM, minimum PLLM results in maximum power savings.

 * The OPP definitions below should keep the PLLM as low as possible.

 *

 * The output of the PLLM must be between 300 to 600 MHz.

 in KHz */

 in uV */

 in uV */

 cpufreq driver can help keep an "async" clock constant */

 VPIF resource, platform data */

 PLL0 is registered in da850_init_time() */

/*

 * TI DaVinci DM355 chip specific setup

 *

 * Author: Kevin Hilman, Deep Root Systems, LLC

 *

 * 2007 (c) Deep Root Systems, LLC. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

/*

 * Device specific clocks

 24 or 36 MHz */

 for now, assume we need MISO */

 not all slaves will be wired up */

----------------------------------------------------------------------*/

/*

 * Device specific mux setup

 *

 *	soc	description	mux  mode   mode  mux	 dbg

 *				reg  offset mask  mode

 dma */

 dma */

 dma */

 dma */

 clockevent */

 clocksource */

 DSP timer */

 system tick */

----------------------------------------------------------------------*/

 {event queue no, Priority} */

 not using (or muxing) TC*_ERR */

 VPSS BL Base address */

 VPSS CLK Base address */

 CCDC Base address */

 venc registers io space */

 VDAC config register io space */

 venc registers io space */

			/*

			 * For HD, use external clock source since we cannot

			 * support HD mode with internal clocks.

 registers */

 interrupt */

----------------------------------------------------------------------*/

 Contents of JTAG ID register used to identify exact cpu type */

/*

 * Bottom half of timer0 is used for clockevent, top half is used for

 * clocksource.

 we don't use ASP1 IRQs, or we'd need to mux them ... */

 PLL1 and PSC are registered in dm355_init_time() */

/*

 * Code commons to all DaVinci SoCs.

 *

 * Author: Mark A. Greer <mgreer@mvista.com>

 *

 * 2009 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

 Don't care about the manufacturer right now */

	/*

	 * Normally devicemaps_init() would flush caches and tlb after

	 * mdesc->map_io(), but we must also do it here because of the CPU

	 * revision check below.

	/*

	 * We want to check CPU revision early for cpu_is_xxxx() macros.

	 * IO space mapping must be initialized before we can do that.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Legacy platform_data quirks

 *

 * Copyright (C) 2016 BayLibre, Inc

 VPIF capture configuration */

 sentinel */ },

/*

 * Critical Link MityOMAP-L138 SoM

 *

 * Copyright (C) 2010 Critical Link LLC - https://www.criticallink.com

 *

 * This file is licensed under the terms of the GNU General Public License

 * version 2. This program is licensed "as is" without any warranty of

 * any kind, whether express or implied.

 Data Held in On-Board I2C device */

 part number string of interest */

 khz */

		/*

		 * the part number has additional characters beyond what is

		 * stored in the table.  This information is not needed for

		 * determining the speed grade, and would require several

		 * more table entries.  Only check the first N characters

		 * for a match.

 default maximum speed is valid for all platforms */

/*

 * We don't define a cell for factory config as it will be accessed from the

 * board file using the nvmem notifier chain.

 kHz */

 usec */

 TPS65023 voltage regulator support */

 1.2V Core */

 1.8V */

 1.2V */

 1.8V Aux LDO, not used */

 FPGA VCC Aux (2.5 or 3.3) LDO */

 dcdc1 */

 dcdc2 */

 dcdc3 */

 ldo1 */

 ldo2 */

/*

 * SPI Devices:

 *	SPI1_CS0: 8M Flash ST-M25P64-VME6G

/*

 * MityDSP-L138 includes a 256 MByte large-page NAND flash

 * (128K blocks).

 MTD_WRITEABLE, */

 4 bit mode is not supported with 16 bit NAND */

 hardcoded for now */

 configure the CFGCHIP3 register for RMII or MII */

 for now, no special EDMA channels are reserved */

/*

 * TI DaVinci DM644x chip specific setup

 *

 * Author: Kevin Hilman, Deep Root Systems, LLC

 *

 * 2007 (c) Deep Root Systems, LLC. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

/*

 * Device specific clocks

/*

 * Device specific mux setup

 *

 *	soc	description	mux  mode   mode  mux	 dbg

 *				reg  offset mask  mode

 FIQ are pri 0-1; otherwise 2-7, with 7 lowest priority */

 dma */

 dma */

 dma */

 dma */

 clockevent */

 clocksource */

 DSP timer */

 system tick */

----------------------------------------------------------------------*/

 {event queue no, Priority} */

 not using TC*_ERR */

 DM6446 EVM uses ASP0; line-out is a pair of RCA jacks */

 VPSS Base address */

 CCDC Base address */

			/*

			 * For HD, use external clock source since

			 * HD requires higher clock rate

 registers */

 interrupt */

----------------------------------------------------------------------*/

 Contents of JTAG ID register used to identify exact cpu type */

/*

 * Bottom half of timer0 is used for clockevent, top half is used for

 * clocksource.

 PLL1 and PSC are registered in dm644x_init_time() */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CPU idle for DaVinci SoCs

 *

 * Copyright (C) 2009 Texas Instruments Incorporated. https://www.ti.com/

 *

 * Derived from Marvell Kirkwood CPU idle code

 * (arch/arm/mach-kirkwood/cpuidle.c)

 Actual code that puts the SoC in different idle states */

/*

 * TI DA830/OMAP L137 EVM board

 *

 * Author: Mark A. Greer <mgreer@mvista.com>

 * Derived from: arch/arm/mach-davinci/board-dm644x-evm.c

 *

 * 2007, 2009 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

/*

 * USB1 VBUS is controlled by GPIO1[15], over-current is reported on GPIO2[4].

 TPS2065 switch @ 5V */

 3 ms max */

		/*

		 * TPS2065 switch @ 5V supplies 1 A (sustains 1.5 A),

		 * with the power on to power good time of 3 ms.

/*

 * GPIO2[1] is used as MMC_SD_WP and GPIO2[2] as MMC_SD_INS.

 gpio chip 1 contains gpio range 32-63 */

 bootloader (U-Boot, etc) in first sector */

 force read-only */

 bootloader params in the next sector */

 force read-only */

 kernel */

 file system */

 flash bbt descriptors */

 First memory resource is NAND I/O window */

 Second memory resource is AEMIF control registers */

/*

 * UI board NAND/NOR flashes only use 8-bit data bus.

 Drive mux mode low to match the default without UI card */

 kHz */

 usec */

/*

 * The following EDMA channels/slots are not being used by drivers (for

 * example: Timer, GPIO, UART events etc) on da830/omap-l137 EVM, hence

 * they are being reserved for codecs on the DSP side.

 (offset, number) */

 (offset, number) */

 SPDX-License-Identifier: GPL-2.0

/*

 * DA8xx USB

		/*

		 * Setting init_name so that clock lookup will work in

		 * da8xx_register_usb11_phy_clk() even if this device is not

		 * registered yet.

 OTG requires a Mini-AB connector */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Texas Instruments Incorporated - https://www.ti.com/

 *

 * Modified from mach-omap/omap2/board-generic.c

/*

 * TI DaVinci EVM board support

 *

 * Author: Kevin Hilman, MontaVista Software, Inc. <source@mvista.com>

 *

 * 2007 (c) MontaVista Software, Inc. This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

 bootloader (UBL, U-Boot, etc) in first 5 sectors */

 force read-only */

 bootloader params in the next 1 sectors */

 kernel */

 file system */

/* NOTE: CFI probe will correctly detect flash part as 32M, but EMIF

/* DM644x EVM includes a 64 MByte small-page NAND flash (16K blocks).

 * It may used instead of the (default) NOR chip to boot, using TI's

 * tools to install the secondary boot loader (UBL) and U-Boot.

	/* Bootloader layout depends on whose u-boot is installed, but we

	 * can hide all the details.

	 *  - block 0 for u-boot environment ... in mainline u-boot

	 *  - block 1 for UBL (plus up to four backup copies in blocks 2..5)

	 *  - blocks 6...? for u-boot

	 *  - blocks 16..23 for u-boot environment ... in TI's u-boot

 force read-only */

 Kernel */

 File system (older GIT kernels started this on the 5MB mark) */

	/* A few blocks at end hold a flash BBT ... created by TI's CCS

	 * using flashwriter_nand.out, but ignored by TI's versions of

	 * Linux and u-boot.  We boot faster by using them.

 Inputs available at the TVP5146 */

/*

 * this is the route info for connecting each input to decoder

 * ouput that goes to vpfe. There is a one to one correspondence

 * with tvp5146_inputs

----------------------------------------------------------------------*/

/*

 * I2C GPIO expanders

 U2 -- LEDs */

	/* what an extremely annoying way to be forced to handle

	 * device unregistration ...

 U18 - A/V clock generator and user switch */

 export dip switch option */

 audio PLL:  48 kHz (vs 44.1 or 32), single rate (vs double) */

 U35 - various I/O signals used to manage USB, CF, ATA, etc */

 p0 = nDRV_VBUS (initial:  don't supply it) */

 p1 = VDDIMX_EN */

 p2 = VLYNQ_EN */

 p3 = n3V3_CF_RESET (initial: stay in reset) */

 (p4 unused) */

 p5 = 1V8_WLAN_RESET (initial: stay in reset) */

 p6 = nATA_SEL (initial: select) */

 p7 = nCF_SEL (initial: deselect) */

----------------------------------------------------------------------*/

/* Most of this EEPROM is unused, but U-Boot uses some data:

 *  - 0x7f00, 6 bytes Ethernet Address

 *  - 0x0039, 1 byte NTSC vs PAL (bit 0x80 == PAL)

 *  - ... newer boards may have more

/*

 * MSP430 supports RTC, card detection, input from IR remote, and

 * a bit more.  It triggers interrupts on GPIO(7) from pressing

 * buttons on the IR remote, and for card detect switches.

 end of list */ },

	/* Command 4 == get input state, returns port 2 and port3 data

	 *   S Addr W [A] len=2 [A] cmd=4 [A]

	 *   RS Addr R [A] [len=4] A [cmd=4] A [port2] A [port3] N P

/* The msp430 uses a slow bitbanged I2C implementation (ergo 20 KHz),

 * which requires 100 usec of idle bus after i2c writes sent to it.

 kHz */,

 usec */,

 Fixed regulator support */

 Baseboard 3.3V: 5V -> TPS54310PWP -> 3.3V */

 Baseboard 1.8V: 5V -> TPS54310PWP -> 1.8V */

 venc standard timings */

 venc dv preset timings */

/*

 * The outputs available from VPBE + encoders. Keep the order same

 * as that of encoders. First those from venc followed by that from

 * encoders. Index in the output refers to index on a particular encoder.

 * Driver uses this index to pass it to encoder when it supports more

 * than one output. Userspace applications use index of the array to

 * set an output.

	/* CRITICAL: Fix for increasing PHY signal drive strength for

	 * TX lockup issue. On DaVinci EVM, the Intel LXT971 PHY

	 * signal strength was low causing  TX to fail randomly. The

	 * fix is to Set bit 11 (Increased MII drive strength) of PHY

 only one device will be jumpered and detected */

 irlml6401 switches over 1A, in under 8 msec */

 Register the fixup for PHY on DaVinci */

 Maintainer: MontaVista Software <source@mvista.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/process.c

 *

 *  Copyright (C) 1996-2000 Russell King - Converted to ARM.

 *  Original Copyright (C) 1995  Linus Torvalds

/*

 * This is our default idle handler.

/*

 * Called from the core idle loop.

 check for r0 - r12 only */

	/*

	 * Get the domain register for the parent context. In user

	 * mode, we don't save the DACR, so lets use what it should

	 * be. For other modes, we place it after the pt_regs struct.

/*

 * Free current thread data structures etc..

	/*

	 * Copy the initial value of the domain access control register

	 * from the current thread: thread->addr_limit will have been

	 * copied from the current thread via setup_thread_stack() in

	 * kernel/fork.c

 recovered from the stack */

/*

 * The vectors page is always readable from user space for the

 * atomic helpers. Insert it into the gate_vma so that it is visible

 * through ptrace and /proc/<pid>/mem.

/* If possible, provide a placement hint at a random offset from the

 * stack for the sigpage and vdso pages.

 No room after stack? */

 Just enough room? */

 for sigpage */

	/* Unlike the sigpage, failure to install the vdso is unlikely

	 * to be fatal to the process, so no error check needed

	 * here.

 SPDX-License-Identifier: GPL-2.0

 Make sure it's an ARM executable */

 Make sure the entry address is reasonable */

 APCS26 is only allowed if the CPU supports it */

 VFP requires the supporting code */

	/*

	 * We only support Linux ELF executables, so always set the

	 * personality to LINUX.

	/*

	 * APCS-26 is only valid for OABI executables

	/*

	 * Since the FPA coprocessor uses CP1 and CP2, and iWMMXt uses CP0

	 * and CP1, we only enable access to the iWMMXt coprocessor if the

	 * binary is EABI or softfloat (and thus, guaranteed not to use

	 * FPA instructions.)

/*

 * An executable for which elf_read_implies_exec() returns TRUE will

 * have the READ_IMPLIES_EXEC personality flag set automatically.

 *

 * The decision process for determining the results are:

 *

 *          CPU: | lacks NX* | has NX     |

 * ELF:          |      |       |

 * ---------------------|------------|------------|

 * missing PT_GNU_STACK | exec-all  | exec-all  |

 * PT_GNU_STACK == RWX | exec-all  | exec-stack|

 * PT_GNU_STACK == RW  | exec-all  | exec-none  |

 *

 *  exec-all  : all PROT_READ user mappings are executable, except when

 *              backed by files on a noexec-filesystem.

 *  exec-none : only PROT_EXEC user mappings are executable.

 *  exec-stack: only the stack and PROT_EXEC user mappings are executable.

 *

 *  *this column has no architectural effect: NX markings are ignored by

 *   hardware, but may have behavioral effects when "wants X" collides with

 *   "cannot be X" constraints in memory permission flags, as in

 *   https://lkml.kernel.org/r/20190418055759.GA3155@mellanox.com

 *

 SPDX-License-Identifier: GPL-2.0

/*

 *  linux/arch/arm/kernel/bios32.c

 *

 *  PCI bios-type initialisation for PCI machines

 *

 *  Bits taken from various places.

/*

 * We can't use pci_get_device() here since we are

 * called from interrupt context.

		/*

		 * ignore host bridge - we handle

		 * that separately

 clear the status errors */

/*

 * We don't use this to fix the device, but initialisation of it.

 * It's not the correct use for this, but it works.

 * Note that the arbiter/ISA bridge appears to be buggy, specifically in

 * the following area:

 * 1. park on CPU

 * 2. ISA bridge ping-pong

 * 3. ISA bridge master handling of target RETRY

 *

 * Bug 3 is responsible for the sound DMA grinding to a halt.  We now

 * live with bug 2.

	/*

	 * Set memory region to start at address 0, and enable IO

	/*

	 * All memory requests from ISA to be channelled to PCI

	/*

	 * Enable ping-pong on bus master to ISA bridge transactions.

	 * This improves the sound DMA substantially.  The fixed

	 * priority arbiter also helps (see below).

	/*

	 * Enable PCI retry

	/*

	 * We used to set the arbiter to "park on last master" (bit

	 * 1 set), but unfortunately the CyberPro does not park the

	 * bus.  We must therefore park on CPU.  Unfortunately, this

	 * may trigger yet another bug in the 553.

	/*

	 * Make the ISA DMA request lowest priority, and disable

	 * rotating priorities completely.

	/*

	 * Route INTA input to IRQ 11, and set IRQ11 to be level

	 * sensitive.

/*

 * Prevent the PCI layer from seeing the resources allocated to this device

 * if it is the host bridge by marking it as such.  These resources are of

 * no consequence to the PCI layer (they are handled elsewhere).

/*

 * PCI IDE controllers use non-standard I/O port decoding, respect it.

/*

 * Put the DEC21142 to sleep

/*

 * The CY82C693 needs some rather major fixups to ensure that it does

 * the right thing.  Idea from the Alpha people, with a few additions.

 *

 * We ensure that the IDE base registers are set to 1f0/3f4 for the

 * primary bus, and 170/374 for the secondary bus.  Also, hide them

 * from the PCI subsystem view as well so we won't try to perform

 * our own auto-configuration on them.

 *

 * In addition, we ensure that the PCI IDE interrupts are routed to

 * IRQ 14 and IRQ 15 respectively.

 *

 * The above gets us to a point where the IDE on this device is

 * functional.  However, The CY82C693U _does not work_ in bus

 * master mode without locking the PCI bus solid.

 primary */

 secondary */

		/*

		 * Setup IDE IRQ routing.

		/*

		 * Disable FREQACK handshake, enable USB.

		/*

		 * Enable PCI retry, and PCI post-write buffer.

		/*

		 * Enable ISA master and DMA post write buffering.

/*

 * If the bus contains any of these devices, then we must not turn on

 * parity checking of any kind.  Currently this is CyberPro 20x0 only.

/*

 * pcibios_fixup_bus - Called after each bus is probed,

 * but before its children are examined.

	/*

	 * Walk the devices on this bus, working out what we can

	 * and can't support.

		/*

		 * If any device on this bus does not support fast back

		 * to back transfers, then the bus as a whole is not able

		 * to support them.  Having fast back to back transfers

		 * on saves us one PCI cycle per transaction.

	/*

	 * Now walk the devices again, this time setting them up.

	/*

	 * Propagate the flags to the PCI bridge.

	/*

	 * Report what we did for this bus

/*

 * Swizzle the device pin each time we cross a bridge.  If a platform does

 * not provide a swizzle function, we perform the standard PCI swizzling.

 *

 * The default swizzling walks up the bus tree one level at a time, applying

 * the standard swizzle function at each step, stopping when it finds the PCI

 * root bus.  This will return the slot number of the bridge device on the

 * root bus and the interrupt pin on that device which should correspond

 * with the downstream device interrupt.

 *

 * Platforms may override this, in which case the slot and pin returned

 * depend entirely on the platform code.  However, please note that the

 * PCI standard swizzle is implemented on plug-in cards and Cardbus based

 * PCI extenders, so it can not be ignored.

/*

 * Map a slot/pin to an IRQ.

		/*

		 * We insert PCI resources into the iomem_resource and

		 * ioport_resource trees in either pci_bus_claim_resources()

		 * or pci_bus_assign_resources().

 No special bus mastering setup handling */

/*

 * From arch/i386/kernel/pci-i386.c:

 *

 * We need to avoid collisions with `mirrored' VGA ports

 * and other strange ISA hardware, so we always want the

 * addresses to be allocated in the 0x000-0x0ff region

 * modulo 0x400.

 *

 * Why? Because some silly external IO cards only decode

 * the low 10 bits of the IO address. The 0x00-0xff region

 * is reserved for motherboard devices that decode all 16

 * bits, so it's ok to allocate at, say, 0x2800-0x28ff,

 * but we want to try to avoid allocating at 0x2900-0x2bff

 * which might be mirrored at 0x0100-0x03ff..

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Tag parsing.

 *

 * Copyright (C) 1995-2001 Russell King

/*

 * This is the traditional way of passing data to the kernel at boot time.  Rather

 * than passing a fixed inflexible structure to the kernel, we pass a list

 * of variable-sized tags to the kernel.  The first tag must be a ATAG_CORE

 * tag for the list to be recognised (to distinguish the tagged list from

 * a param_struct).  The list is terminated with a zero-length tag (this tag

 * is not parsed in any way).

/*

 * Scan the tag table for this tag, and call its parse function.

 * The tag table is built by the linker from all the __tagtable

 * declarations.

/*

 * Parse all tags in the list, checking both the global and architecture

 * specific tag tables.

	/*

	 * locate machine in the list of supported machines.

	/*

	 * If we have the old style parameters, convert them to

	 * a tag list.

 parse_early_param needs a boot_command_line */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Unwind the current stack frame and store the new register values in the

 * structure passed as argument. Unwinding is equivalent to a function return,

 * hence the new PC value rather than LR should be used for backtrace.

 *

 * With framepointer enabled, a simple function prologue looks like this:

 *	mov	ip, sp

 *	stmdb	sp!, {fp, ip, lr, pc}

 *	sub	fp, ip, #4

 *

 * A simple function epilogue looks like this:

 *	ldm	sp, {fp, sp, pc}

 *

 * When compiled with clang, pc and sp are not pushed. A simple function

 * prologue looks like this when built with clang:

 *

 *	stmdb	{..., fp, lr}

 *	add	fp, sp, #x

 *	sub	sp, sp, #y

 *

 * A simple function epilogue looks like this when built with clang:

 *

 *	sub	sp, fp, #x

 *	ldm	{..., fp, pc}

 *

 *

 * Note that with framepointer enabled, even the leaf functions have the same

 * prologue and epilogue, therefore we can ignore the LR value in this case.

 only go to a higher address on the stack */

 check current frame pointer is within bounds */

 check current frame pointer is within bounds */

 restore the registers from the stack frame */

 This must be noinline to so that our skip calculation works correctly */

		/*

		 * What guarantees do we have here that 'tsk' is not

		 * running on another CPU?  For now, ignore it as we

		 * can't guarantee we won't explode.

 recovered from the stack */

 We don't want this function nor the caller */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2008-2009 ST-Ericsson AB

 * TCM memory handling for ARM systems

 *

 * Author: Linus Walleij <linus.walleij@stericsson.com>

 * Author: Rickard Andersson <rickard.andersson@stericsson.com>

 memcpy */

 TCM section definitions from the linker */

 These will be increased as we run */

/*

 * TCM memory resources

/*

 * Allocate a chunk of TCM memory

/*

 * Free a chunk of TCM memory

	/*

	 * If there are more than one TCM bank of this type,

	 * select the TCM bank to operate on in the TCM selection

	 * register.

 No output operands */

 Read the special TCM region register c9, 0 */

 Not much fun you can do with a size 0 bank */

 Force move the TCM bank to where we want it, enable */

 No output operands */

 No output operands */

 Increase offset */

/*

 * When we are running in the non-secure world and the secure world

 * has not explicitly given us access to the TCM we will get an

 * undefined error when reading the TCM region register in the

 * setup_tcm_bank function (above).

 *

 * There are two variants of this register read that we need to trap,

 * the read for the data TCM and the read for the instruction TCM:

 *  c0370628:       ee196f11        mrc     15, 0, r6, cr9, cr1, {0}

 *  c0370674:       ee196f31        mrc     15, 0, r6, cr9, cr1, {1}

 *

 * Our undef hook mask explicitly matches all fields of the encoded

 * instruction other than the destination register.  The mask also

 * only allows operand 2 to have the values 0 or 1.

 *

 * The undefined hook is defined as __init and __initdata, and therefore

 * must be removed before tcm_init returns.

 *

 * In this particular case (MRC with ARM condition code ALways) the

 * Thumb-2 and ARM instruction encoding are identical, so this hook

 * will work on a Thumb-2 kernel.

 *

 * See A8.8.107, DDI0406C_C ARM Architecture Reference Manual, Encoding

 * T1/A1 for the bit-by-bit details.

 *

 *  mrc   p15, 0, XX, c9, c1, 0

 *  mrc   p15, 0, XX, c9, c1, 1

 *   |  |  |   |   |   |   |  +---- opc2           0|1 = 000|001

 *   |  |  |   |   |   |   +------- CRm              0 = 0001

 *   |  |  |   |   |   +----------- CRn              0 = 1001

 *   |  |  |   |   +--------------- Rt               ? = ????

 *   |  |  |   +------------------- opc1             0 =  000

 *   |  |  +----------------------- coproc          15 = 1111

 *   |  +-------------------------- condition   ALways = 1110

 *   +----------------------------- instruction    MRC = 1110

 *

 * Encoding this as per A8.8.107 of DDI0406C, Encoding T1/A1, yields:

 *  1111 1111 1111 1111 0000 1111 1101 1111 Required Mask

 *  1110 1110 0001 1001 ???? 1111 0001 0001 mrc p15, 0, XX, c9, c1, 0

 *  1110 1110 0001 1001 ???? 1111 0011 0001 mrc p15, 0, XX, c9, c1, 1

 *  [  ] [  ] [ ]| [  ] [  ] [  ] [ ]| +--- CRm

 *    |    |   | |   |    |    |   | +----- SBO

 *    |    |   | |   |    |    |   +------- opc2

 *    |    |   | |   |    |    +----------- coproc

 *    |    |   | |   |    +---------------- Rt

 *    |    |   | |   +--------------------- CRn

 *    |    |   | +------------------------- SBO

 *    |    |   +--------------------------- opc1

 *    |    +------------------------------- instruction

 *    +------------------------------------ condition

/*

 * This initializes the TCM memory

	/*

	 * Prior to ARMv5 there is no TCM, and trying to read the status

	 * register will hang the processor.

	/*

	 * This code only supports v6-compatible TCMTR implementations.

 Values greater than 2 for D/ITCM banks are "reserved" */

 Setup DTCM if present */

 This means you compiled more code than fits into DTCM */

		/*

		 * This means that the DTCM sizes were 0 or the DTCM banks

		 * were inaccessible due to TrustZone configuration.

 Copy data from RAM to DTCM */

 Setup ITCM if present */

 This means you compiled more code than fits into ITCM */

		/*

		 * This means that the ITCM sizes were 0 or the ITCM banks

		 * were inaccessible due to TrustZone configuration.

 Copy code from RAM to ITCM */

/*

 * This creates the TCM memory pool and has to be done later,

 * during the core_initicalls, since the allocator is not yet

 * up and running when the first initialization runs.

	/*

	 * Set up malloc pool, 2^2 = 4 bytes granularity since

	 * the TCM is sometimes just 4 KiB. NB: pages and cache

	 * line alignments does not matter in TCM!

 Add the rest of DTCM to the TCM pool */

 Add the rest of ITCM to the TCM pool */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/traps.c

 *

 *  Copyright (C) 1995-2009 Russell King

 *  Fragments that appear the same as linux/arch/i386/kernel/traps.c (C) Linus Torvalds

 *

 *  'traps.c' handles hardware exceptions after we have saved some state in

 *  'linux/arch/arm/lib/traps.S'.  Mostly a debugging aid, but will probably

 *  kill the offending process.

/*

 * Stack pointers should always be within the kernels view of

 * physical memory.  If it is not there, then we can't dump

 * out any information relating to the stack.

/*

 * Dump out the contents of some memory nicely...

	/*

	 * Note that we now dump the code first, just in case the backtrace

	 * kills us.

 trap and error numbers are mostly meaningless on ARM */

 racy, but better than risking deadlock. */

 nested oops. should stop eventually */;

 Nest count reaches zero, release the lock. */

/*

 * This function is protected against re-entrancy.

/*

 * Handle FIQ similarly to NMI on x86 systems.

 *

 * The runtime environment for NMIs is extremely restrictive

 * (NMIs can pre-empt critical sections meaning almost all locking is

 * forbidden) meaning this default FIQ handling must only be used in

 * circumstances where non-maskability improves robustness, such as

 * watchdog or debug logic.

 *

 * This handler is not appropriate for general purpose use in drivers

 * platform code and can be overrideen using set_fiq_handler.

 nop. FIQ handlers for special arch/arm features can be added here. */

/*

 * bad_mode handles the impossible case in the vectors.  If you see one of

 * these, then it's extremely serious, and could mean you have buggy hardware.

 * It never returns, and never tries to sync.  We hope that we can at least

 * dump out some state information...

/*

 * Handle all unrecognised system calls.

 *  0x9f0000 - 0x9fffff are some more esoteric system calls

 branch through 0 */

 SWI BREAK_POINT */

	/*

	 * Flush a region from virtual address 'r0' to virtual address 'r1'

	 * _exclusive_.  There is no alignment requirement on either address;

	 * user space does not need to know the hardware cache layout.

	 *

	 * r2 contains flags.  It should ALWAYS be passed as ZERO until it

	 * is defined to be something else.  For now we ignore it, but may

	 * the fires of hell burn in your belly if you break this rule. ;)

	 *

	 * (at a later date, we may want to allow this call to not flush

	 * various aspects of the cache.  Passing '0' will guarantee that

	 * everything necessary gets flushed to maintain consistency in

	 * the specified region).

		/* Calls 9f00xx..9f07ff are defined to return -ENOSYS

		   if not implemented, rather than raising SIGILL.  This

		   way the calling program can gracefully determine whether

	/*

	 * experience shows that these seem to indicate that

	 * something catastrophic has happened

/*

 * We might be running on an ARMv6+ processor which should have the TLS

 * register but for some reason we can't use it, or maybe an SMP system

 * using a pre-ARMv6 processor (there are apparently a few prototypes like

 * that in existence) and therefore access to that register must be

 * emulated.

/*

 * A data abort trap was taken, but we did not handle the instruction.

 * Try to abort the user program, or panic if it was the kernel.

 if that doesn't kill us, halt */

	/*

	 * vectors + 0xfe0 = __kuser_get_tls

	 * vectors + 0xfe8 = hardware TLS instruction at 0xffff0fe8

	/*

	 * Poison the vectors page with an undefined instruction.  This

	 * instruction is chosen to be undefined for both ARM and Thumb

	 * ISAs.  The Thumb version is an undefined instruction with a

	 * branch back to the undefined instruction.

	/*

	 * Copy the vectors, stubs and kuser helpers (in entry-armv.S)

	 * into the vector page, mapped at 0xffff0000, and ensure these

	 * are visible to the instruction stream.

 ifndef CONFIG_CPU_V7M */

	/*

	 * on V7-M there is no need to copy the vector table to a dedicated

	 * memory area. The address is configurable and so a table in the kernel

	 * image can be used.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/dma-isa.c

 *

 *  Copyright (C) 1999-2000 Russell King

 *

 *  ISA DMA primitives

 *  Taken from various sources, including:

 *   linux/include/asm/dma.h: Defines for using and allocating dma channels.

 *     Written by Hennus Bergman, 1992.

 *     High DMA channel support & info by Hannu Savolainen and John Boyd,

 *     Nov. 1992.

 *   arch/arm/kernel/dma-ebsa285.c

 *   Copyright (C) 1998 Phil Blundell

 MASK   MODE   CLRFF  PAGE_HI PAGE_LO ADDR COUNT */

			/*

			 * Cope with ISA-style drivers which expect cache

			 * coherence.

/*

 * ISA DMA always starts at channel 0

	/*

	 * Try to autodetect presence of an ISA DMA controller.

	 * We do some minimal initialisation, and check that

	 * channel 0's DMA address registers are writeable.

	/*

	 * Write high and low address, and then read them back

	 * in the same order.

		/*

		 * Is this correct?  According to my documentation, it

		 * doesn't appear to be.  It should be:

		 *  outb(0x3f, 0x40b); outb(0x3f, 0x4d6);

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/setup.c

 *

 *  Copyright (C) 1995-2001 Russell King

/*

 * Cached cpu_architecture() result for use by assembler code.

 * C code should use the cpu_architecture() function instead of accessing this

 * variable directly.

/*

 * Standard memory resources

		/* Revised CPUID format. Read the Memory Model Feature

 PIPT caches never alias. */

 arch specifies the register format */

 I-cache aliases will be handled by D-cache aliasing code */

 ARMv7 register format */

/*

 * These functions re-use the assembly code in head.S, which

 * already provide the required functionality.

 "sdiv r0, r0, r1" */

 "sdiv r0, r0, r1" */

 "udiv r0, r0, r1" */

 "udiv r0, r0, r1" */

 "bx lr; nop" */

 "bx lr" */

 LPAE implies atomic ldrd/strd instructions */

 check for supported v8 Crypto instructions */

	/*

	 * HWCAP_TLS is available only on 1136 r1p0 and later,

	 * see also kuser_get_tls_init.

 Verify if CPUID scheme is implemented */

	/*

	 * If the CPU supports LDREX/STREX and LDREXB/STREXB,

	 * avoid advertising SWP; it may not be atomic with

	 * multiprocessing cores.

/*

 * cpu_init - initialise one CPU.

 *

 * cpu_init sets up the per-CPU stacks.

	/*

	 * This only works on resume and secondary cores. For booting on the

	 * boot cpu, smp_prepare_boot_cpu is called after percpu area setup.

	/*

	 * Define the placement constraint for the inline asm directive below.

	 * In Thumb-2, msr with an immediate value is not allowed.

	/*

	 * setup stacks for re-entrant exception handlers

	/*

	 * clear __my_cpu_offset on boot CPU to avoid hang caused by

	 * using percpu variable early, for example, lockdep will

	 * access percpu variable inside lock_release

/**

 * smp_build_mpidr_hash - Pre-compute shifts required at each affinity

 *			  level in order to build a linear index from an

 *			  MPIDR value. Resulting algorithm is a collision

 *			  free hash carried out through shifting and ORing

	/*

	 * Pre-scan the list of MPIDRS and filter out bits that do

	 * not contribute to affinity levels, ie they never toggle.

	/*

	 * Find and stash the last and first bit set at all affinity levels to

	 * check how many bits are required to represent them.

		/*

		 * Find the MSB bit and LSB bits position

		 * to determine how many bits are required

		 * to express the affinity level.

	/*

	 * An index can be created from the MPIDR by isolating the

	 * significant bits at each affinity level and by shifting

	 * them in order to compress the 24 bits values space to a

	 * compressed set of values. This is equivalent to hashing

	 * the MPIDR through shifting and ORing. It is a collision free

	 * hash though not minimal since some levels might contain a number

	 * of CPUs that is not an exact power of 2 and their bit

	 * representation might contain holes, eg MPIDR[7:0] = {0x2, 0x80}.

	/*

	 * 4x is an arbitrary value used to warn on a hash table much bigger

	 * than expected on most systems.

/*

 * locate processor in the list of supported processor types.  The linker

 * builds this table for us from the entries in arch/arm/mm/proc-*.S

 can't use cpu_relax() here as it may require MMU setup */;

 can't use cpu_relax() here as it may require MMU setup */;

	/*

	 * Ensure that start/size are aligned to a page boundary.

	 * Size is rounded down, start is rounded up.

		/*

		 * To ensure bank->start + bank->size is representable in

		 * 32 bits, we use ULONG_MAX as the upper limit rather than 4GB.

		 * This means we lose a page after masking.

	/*

	 * Check whether this memory region has non-zero size or

	 * invalid node number.

/*

 * Pick out the memory size.  We look for mem=size@start,

 * where start and size are "size[KkMm]"

	/*

	 * If the user specifies memory size, we

	 * blow away any automatically generated

	 * size.

		/*

		 * In memblock, end points to the first byte after the

		 * range while in resourses, end points to the last byte in

		 * the range.

		/*

		 * Some systems have a special memory alias which is only

		 * used for booting.  We need to advertise this region to

		 * kexec-tools so they know where bootable RAM is located.

	/*

	 * Some machines don't have the possibility of ever

	 * possessing lp0, lp1 or lp2

	/*

	 * customizes platform devices, or adds new ones

	 * On DT based machines, we fall back to populating the

	 * machine from the device tree, if no callback is provided,

	 * otherwise we would always need an init_machine callback.

/*

 * The crash region must be aligned to 128MB to avoid

 * zImage relocating below the reserved region.

/**

 * reserve_crashkernel() - reserves memory are for crash kernel

 *

 * This function reserves memory area given in "crashkernel=" kernel command

 * line parameter. The memory reserved is used by a dump capture kernel when

 * primary kernel is crashing.

 The crashk resource must always be located in normal mem */

		/*

		 * If we have a special RAM alias for use at boot, we

		 * need to advertise to kexec tools where the alias is.

 CONFIG_KEXEC */

 populate cmd_line too for later use, preserving boot_command_line */

	/*

	 * Make sure the calculation for lowmem/highmem is set appropriately

	 * before reserving/allocating any memory

 Memory may have been removed so recalculate the bounds. */

		/*

		 * glibc reads /proc/cpuinfo to determine the number of

		 * online processors, looking for lines beginning with

		 * "processor".  Give glibc what it expects.

 dump out the processor features */

 pre-ARM7 */

 ARM7 */

 post-ARM7 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Linaro Ltd <ard.biesheuvel@linaro.org>

	/*

	 * We can only use apply_to_page_range() if we can guarantee that the

	 * entire region was mapped using pages. This should be the case if the

	 * region does not cover any naturally aligned SECTION_SIZE sized

	 * blocks.

	/*

	 * Order is important here: memory regions may have all of the

	 * bits below set (and usually do), so we check them in order of

	 * preference.

	/*

	 * If stricter permissions were specified, apply them now.

 SPDX-License-Identifier: GPL-2.0

/*

 * Generic atomic MMIO modify.

 *

 * Allows thread-safe access to registers shared by unrelated subsystems.

 * The access is protected by a single MMIO-wide lock.

/*

 * Copy data from IO memory space to "real" memory space.

 * This needs to be optimized.

/*

 * Copy data from "real" memory space to IO memory space.

 * This needs to be optimized.

/*

 * "memset" on IO memory space.

 * This needs to be optimized.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hibernation support specific for ARM

 *

 * Derived from work on ARM hibernation support by:

 *

 * Ubuntu project, hibernation support for mach-dove

 * Copyright (C) 2010 Nokia Corporation (Hiroshi Doyu)

 * Copyright (C) 2010 Texas Instruments, Inc. (Teerth Reddy et al.)

 *  https://lkml.org/lkml/2010/6/18/4

 *  https://lists.linux-foundation.org/pipermail/linux-pm/2010-June/027422.html

 *  https://patchwork.kernel.org/patch/96442/

 *

 * Copyright (C) 2006 Rafael J. Wysocki <rjw@sisk.pl>

/*

 * Snapshot kernel memory and reset the system.

 *

 * swsusp_save() is executed in the suspend finisher so that the CPU

 * context pointer and memory are part of the saved image, which is

 * required by the resume kernel image to restart execution from

 * swsusp_arch_suspend().

 *

 * soft_restart is not technically needed, but is used to get success

 * returned from cpu_suspend.

 *

 * When soft reboot completes, the hibernation snapshot is written out.

/*

 * Save the current CPU state before suspend / poweroff.

/*

 * Restore page contents for physical pages that were in use during loading

 * hibernation image.  Switch to idmap_pgd so the physical page tables

 * are overwritten with the same contents.

/*

 * Resume from the hibernation image.

 * Due to the kernel heap / data restore, stack contents change underneath

 * and that would make function calls impossible; switch to a temporary

 * stack within the nosave region to avoid that problem.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/arch_timer.c

 *

 *  Copyright (C) 2011 ARM Ltd.

 *  All Rights Reserved

 Use the architected timer for the delay loop. */

 SPDX-License-Identifier: GPL-2.0

	/*

	 * This cannot go into save_atags() because kmalloc and proc don't work

	 * yet when it is called.

 include the terminating ATAG_NONE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/time.c

 *

 *  Copyright (C) 1991, 1992, 1995  Linus Torvalds

 *  Modifications for ARM (C) 1994-2001 Russell King

 *

 *  This file contains the ARM-specific time handling details:

 *  reading the RTC at bootup, etc...

 this needs a better home */

 pc-style 'CMOS' RTC support */

 change this if you have some constant time drift */

 Only allow the clockaccess functions to be registered once */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/sys_arm.c

 *

 *  Copyright (C) People who wrote linux/arch/i386/kernel/sys_i386.c

 *  Copyright (C) 1995, 1996 Russell King.

 *

 *  This file contains various random system calls that

 *  have a non-standard calling sequence on the Linux/arm

 *  platform.

/*

 * Since loff_t is a 64 bit type we avoid a lot of ABI hassle

 * with a different argument ordering.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (C) 2009, 2010 ARM Limited

 *

 * Author: Will Deacon <will.deacon@arm.com>

/*

 * HW_breakpoint: a unified kernel/user-space hardware breakpoint facility,

 * using the CPU's debug registers.

 Breakpoint currently in use for each BRP. */

 Watchpoint currently in use for each WRP. */

 Number of BRP/WRP registers on this CPU. */

 Debug architecture version. */

 Does debug architecture support OS Save and Restore? */

 Maximum supported watchpoint length. */

 Determine debug architecture. */

 Do we implement the extended CPUID interface? */

 We don't support the memory-mapped interface. */

 Can we determine the watchpoint access type from the fsr? */

 Determine number of WRP registers available. */

 Determine number of BRP registers available. */

 Does this core support mismatch breakpoints? */

 Determine number of usable WRPs available. */

	/*

	 * On debug architectures prior to 7.1, when a watchpoint fires, the

	 * only way to work out which watchpoint it was is by disassembling

	 * the faulting instruction and working out the address of the memory

	 * access.

	 *

	 * Furthermore, we can only do this if the watchpoint was precise

	 * since imprecise watchpoints prevent us from calculating register

	 * based addresses.

	 *

	 * Providing we have more than 1 breakpoint register, we only report

	 * a single watchpoint register for the time being. This way, we always

	 * know which watchpoint fired. In the future we can either add a

	 * disassembler and address generation emulator, or we can insert a

	 * check to see if the DFAR is set on watchpoint exception entry

	 * [the ARM ARM states that the DFAR is UNKNOWN, but experience shows

	 * that it is set on some implementations].

 Determine number of usable BRPs available. */

/*

 * In order to access the breakpoint/watchpoint control registers,

 * we must be running in debug monitor mode. Unfortunately, we can

 * be put into halting debug mode at any time by an external debugger

 * but there is nothing we can do to prevent that.

 If monitor mode is already enabled, just return. */

 Write to the corresponding DSCR. */

 Check that the write made it through. */

	/*

	 * We can be called early, so don't rely on

	 * our static variables being initialised.

/*

 * Check if 8-bit byte-address select is available.

 * This clobbers WRP 0.

/*

 * Install a perf counter breakpoint.

 Breakpoint */

 Watchpoint */

 Override the breakpoint data with the step data. */

 Setup the address register. */

 Setup the control register. */

 Breakpoint */

 Watchpoint */

 Remove the breakpoint. */

 Ensure that we disable the mismatch breakpoint. */

 Reset the control register. */

/*

 * Check whether bp virtual address is in kernel space.

/*

 * Extract generic type and length encodings from an arch_hw_breakpoint_ctrl.

 * Hopefully this will disappear when ptrace can bypass the conversion

 * to generic breakpoint descriptions.

 Type */

 Len */

/*

 * Construct an arch_hw_breakpoint from a perf_event.

 Type */

 Len */

	/*

	 * Breakpoints must be of length 2 (thumb) or 4 (ARM) bytes.

	 * Watchpoints can be of length 1, 2, 4 or 8 bytes if supported

	 * by the hardware and must be aligned to the appropriate number of

	 * bytes.

 Address */

 Privilege */

 Enabled? */

 Mismatch */

/*

 * Validate the arch-specific HW Breakpoint register settings.

 Ensure that we are in monitor debug mode. */

 Build the arch_hw_breakpoint. */

 Check address alignment. */

 Aligned */

 Allow halfword watchpoints and breakpoints. */

 Allow single byte watchpoint. */

		/*

		 * Mismatch breakpoints are required for single-stepping

		 * breakpoints.

 We don't allow mismatch breakpoints in kernel space. */

		/*

		 * Per-cpu breakpoints are not supported by our stepping

		 * mechanism.

		/*

		 * We only support specific access types if the fsr

		 * reports them.

/*

 * Enable/disable single-stepping over the breakpoint bp at address addr.

/*

 * Arm32 hardware does not always report a watchpoint hit address that matches

 * one of the watchpoints set. It can also report an address "near" the

 * watchpoint if a single instruction access both watched and unwatched

 * addresses. There is no straight-forward way, short of disassembling the

 * offending instruction, to map that address back to the watchpoint. This

 * function computes the distance of the memory access from the watchpoint as a

 * heuristic for the likelyhood that a given access triggered the watchpoint.

 *

 * See this same function in the arm64 platform code, which has the same

 * problem.

 *

 * The function returns the distance of the address from the bytes watched by

 * the watchpoint. In case of an exact match, it returns 0.

	/*

	 * Find all watchpoints that match the reported address. If no exact

	 * match is found. Attribute the hit to the closest watchpoint.

		/*

		 * The DFAR is an unknown value on debug architectures prior

		 * to 7.1. Since we only allow a single watchpoint on these

		 * older CPUs, we can set the trigger to the lowest possible

		 * faulting address.

 Check that the access type matches. */

 Is this an exact match? */

 We have a winner. */

		/*

		 * If we triggered a user watchpoint from a uaccess routine,

		 * then handle the stepping ourselves since userspace really

		 * can't help us with this.

		/*

		 * Defer stepping to the overflow handler if one is installed.

		 * Otherwise, insert a temporary mismatch breakpoint so that

		 * we can single-step over the watchpoint trigger.

 No exact match found. */

		/*

		 * Restore the original watchpoint if we've completed the

		 * single-step.

 The exception entry code places the amended lr in the PC. */

 Check the currently installed breakpoints first. */

 Check if the breakpoint value matches. */

 Possible match, check the byte address select to confirm. */

 If we're stepping a breakpoint, it can now be restored. */

 Handle any pending watchpoint single-step breakpoints. */

/*

 * Called from either the Data Abort Handler [watchpoint] or the

 * Prefetch Abort Handler [breakpoint] with interrupts disabled.

 We only handle watchpoints and hardware breakpoints. */

 Perform perf callbacks. */

 Unhandled fault. */

/*

 * One-time initialisation.

 Set the error flag for this CPU and skip the faulting instruction. */

 Does this core support OS Save and Restore? */

	/*

	 * v7 debug contains save and restore registers so that debug state

	 * can be maintained across low-power modes without leaving the debug

	 * logic powered up. It is IMPLEMENTATION DEFINED whether we can access

	 * the debug registers out of reset, so we must unlock the OS Lock

	 * Access Register to avoid taking undefined instruction exceptions

	 * later on.

 ARMv6 cores clear the registers out of reset. */

		/*

		 * Ensure sticky power-down is clear (i.e. debug logic is

		 * powered up).

		/*

		 * Ensure the OS double lock is clear.

	/*

	 * Unconditionally clear the OS lock by writing a value

	 * other than CS_LAR_KEY to the access register.

	/*

	 * Clear any configured vector-catch events before

	 * enabling monitor mode.

	/*

	 * The control/value register pairs are UNKNOWN out of reset so

	 * clear them to avoid spurious debug events.

	/*

	 * Have a crack at enabling monitor mode. We don't actually need

	 * it yet, but reporting an error early is useful if it fails.

	/*

	 * Scorpion CPUs (at least those in APQ8060) seem to set DBGPRSR.SPD

	 * whenever a WFI is issued, even if the core is not powered down, in

	 * violation of the architecture.  When DBGPRSR.SPD is set, accesses to

	 * breakpoint and watchpoint registers are treated as undefined, so

	 * this results in boot time and runtime failures when these are

	 * accessed and we unexpectedly take a trap.

	 *

	 * It's not clear if/how this can be worked around, so we blacklist

	 * Scorpion CPUs to avoid these issues.

 Determine how many BRPs/WRPs are available. */

	/*

	 * We need to tread carefully here because DBGSWENABLE may be

	 * driven low on this core and there isn't an architected way to

	 * determine that.

	/*

	 * Register CPU notifier which resets the breakpoint resources. We

	 * assume that a halting debugger will leave the world in a nice state

	 * for us.

 Work out the maximum supported watchpoint length. */

 Register debug fault handler. */

 Register PM notifiers. */

/*

 * Dummy function to register with die_notifier.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/dma.c

 *

 *  Copyright (C) 1995-2000 Russell King

 *

 *  Front-end to the DMA handling.  This handles the allocation/freeing

 *  of DMA channels, and provides a unified interface to the machines

 *  DMA facilities.

/*

 * Request DMA channel

 *

 * On certain platforms, we have to allocate an interrupt as well...

/*

 * Free DMA channel

 *

 * On certain platforms, we have to free interrupt as well...

/* Set DMA Scatter-Gather list

/* Set DMA address

 *

 * Copy address to the structure, and set the invalid bit

/* Set DMA byte count

 *

 * Copy address to the structure, and set the invalid bit

/* Set DMA direction mode

/* Enable DMA channel

/* Disable DMA channel

/*

 * Is the specified DMA channel active?

 SPDX-License-Identifier: GPL-2.0

/*

 * machine_kexec.c - handle transition of Linux booting another kernel

/*

 * Provide a dummy crash_notes definition while crash dump arrives to arm.

 * This prevents breakage of crash_notes attribute in kernel/ksysfs.c.

	/*

	 * Validate that if the current HW supports SMP, then the SW supports

	 * and implements CPU hotplug for the current HW. If not, we won't be

	 * able to kexec reliably, so fail the prepare operation.

	/*

	 * No segment at default ATAGs address. try to locate

	 * a dtb using magic.

 Wait at most a second for the other cpus to stop */

	/*

	 * This can only happen if machine_shutdown() failed to disable some

	 * CPU, and that can only happen if the checks in

	 * machine_kexec_prepare() were not correct. If this fails, we can't

	 * reliably kexec anyway, so BUG_ON is appropriate.

 copy our kernel relocation code to the control code page */

 get the identity mapping physical address for the reboot code */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/smp_tlb.c

 *

 *  Copyright (C) 2002 ARM Limited, All Rights Reserved.

*********************************************************************/

/*

 * TLB operations

	/* Brahma-B15 r0p0..r0p2 affected

	 * Cortex-A15 r0p0..r3p3 w/o ECO fix affected

	 * Fixes applied to A15 with respect to the revision and revidr are:

	 *

	 * r0p0-r2p1: No fixes applied

	 * r2p2,r2p3:

	 *	REVIDR[4]: 798181 Moving a virtual page that is being accessed

	 *		   by an active process can lead to unexpected behavior

	 *	REVIDR[9]: Not defined

	 * r2p4,r3p0,r3p1,r3p2:

	 *	REVIDR[4]: 798181 Moving a virtual page that is being accessed

	 *		   by an active process can lead to unexpected behavior

	 *	REVIDR[9]: 798181 Moving a virtual page that is being accessed

	 *		   by an active process can lead to unexpected behavior

	 *		   - This is an update to a previously released ECO.

	 * r3p3:

	 *	REVIDR[4]: Reserved

	 *	REVIDR[9]: 798181 Moving a virtual page that is being accessed

	 *		   by an active process can lead to unexpected behavior

	 *		   - This is an update to a previously released ECO.

	 *

	 * Handling:

	 *	REVIDR[9] set -> No WA

	 *	REVIDR[4] set, REVIDR[9] cleared -> Partial WA

	 *	Both cleared -> Full WA

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/early_printk.c

 *

 *  Copyright (C) 2009 Sascha Hauer <s.hauer@pengutronix.de>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/kernel/pj4-cp0.c

 *

 * PJ4 iWMMXt coprocessor context switching and handling

 *

 * Copyright (c) 2010 Marvell International Inc.

		/*

		 * flush_thread() zeroes thread->fpstate, so no need

		 * to do anything here.

		 *

		 * FALLTHROUGH: Ensure we don't try to overwrite our newly

		 * initialised state information on the first fault.

 check if coprocessor 0 and 1 are available */

 read iWMMXt coprocessor id register p1, c0 */

 iWMMXt v1 */

 iWMMXt v2 */

/*

 * Disable CP0/CP1 on boot, and let call_fpe() and the iWMMXt lazy

 * switch code handle iWMMXt context switching.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/smp_scu.c

 *

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

/*

 * Get the number of CPU cores from the SCU configuration

/*

 * Enable the SCU

 Cortex-A9 only */

 already enabled? */

 Cortex-A9 earlier than r2p0 has no standby bit in SCU */

	/*

	 * Ensure that the data accessed by CPU0 before the SCU was

	 * initialised is visible to the other CPUs.

/*

 * Set the executing CPUs power mode as defined.  This will be in

 * preparation for it executing a WFI instruction.

 *

 * This function must be called with preemption disabled, and as it

 * has the side effect of disabling coherency, caches must have been

 * flushed.  Interrupts must also have been disabled.

/*

 * Set the given (logical) CPU's power mode to SCU_PM_NORMAL.

/*

 * arch/arm/kernel/topology.c

 *

 * Copyright (C) 2011 Linaro Limited.

 * Written by: Vincent Guittot

 *

 * based on arch/sh/kernel/topology.c

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

/*

 * cpu capacity scale management

/*

 * cpu capacity table

 * This per cpu data structure describes the relative capacity of each core.

 * On a heteregenous system, cores don't have the same computation capacity

 * and we reflect that difference in the cpu_capacity field so the scheduler

 * can take this difference into account during load balance. A per cpu

 * structure is preferred because each CPU updates its own cpu_capacity field

 * during the load balance except for idle cores. One idle core is selected

 * to run the rebalance_domains for all idle cores and the cpu_capacity can be

 * updated during this sequence.

/*

 * Table of relative efficiency of each processors

 * The efficiency value must fit in 20bit and the final

 * cpu_scale value must be in the range

 *   0 < cpu_scale < 3*SCHED_CAPACITY_SCALE/2

 * in order to return at most 1 when DIV_ROUND_CLOSEST

 * is used to compute the capacity of a CPU.

 * Processors that are not defined in the table,

 * use the default SCHED_CAPACITY_SCALE value for cpu_scale.

/*

 * Iterate all CPUs' descriptor in DT and compute the efficiency

 * (as per table_efficiency). Also calculate a middle efficiency

 * as close as possible to  (max{eff_i} - min{eff_i}) / 2

 * This is later used to scale the cpu_capacity field such that an

 * 'average' CPU is of middle capacity. Also see the comments near

 * table_efficiency[] and update_cpu_capacity().

 too early to use cpu->of_node */

 Save min capacity of the system */

 Save max capacity of the system */

	/* If min and max capacities are equals, we bypass the update of the

	 * cpu_scale because all CPUs have the same capacity. Otherwise, we

	 * compute a middle_capacity factor that will ensure that the capacity

	 * of an 'average' CPU of the system will be as close as possible to

	 * SCHED_CAPACITY_SCALE, which is the default value, but with the

	 * constraint explained near table_efficiency[].

/*

 * Look for a customed capacity of a CPU in the cpu_capacity table during the

 * boot. The update of all CPUs is in O(n^2) for heteregeneous system but the

 * function returns directly for SMP system.

/*

 * store_cpu_topology is called at boot when only one cpu is running

 * and with the mutex cpu_hotplug.lock locked, when several cpus have booted,

 * which prevents simultaneous write access to cpu_topology array

 create cpu topology mapping */

		/*

		 * This is a multiprocessor system

		 * multiprocessor format & multiprocessor mode field are set

 core performance interdependency */

 largely independent cores */

		/*

		 * This is an uniprocessor system

		 * we are in multiprocessor format but uniprocessor system

		 * or in the old uniprocessor format

/*

 * init_cpu_topology is called at boot when only one cpu is running

 * which prevent simultaneous write access to cpu_topology array

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/atags_compat.c

 *

 *  Copyright (C) 2001 Russell King

 *

 * We keep the old params compatibility cruft in one place (here)

 * so we don't end up with lots of mess around other places.

 *

 * NOTE:

 *  The old struct param_struct is deprecated, but it will be kept in

 *  the kernel for 5 years from now (2001). This will allow boot loaders

 *  to convert to the new struct tag way.

/*

 * Usage:

 *  - do not go blindly adding fields, add them at the end

 *  - when adding fields, don't rely on the address until

 *    a patch from me has been released

 *  - unused fields should be zero (for future expansion)

 *  - this structure is relatively short-lived - only

 *    guaranteed to contain useful data in setup_arch()

 *

 * This is the old deprecated way to pass parameters to the kernel

  0 */

  4 */

  8 */

 12 */

 16 */

 20 */

 24 */

 28 */

 32 */

 36 */

 40 */

 41 */

 42 */

 43 */

 44 */

 60 */

 64 */

 68 */

 72 */

 76 */

 80 */

 84 */

 88 */

 16MB */

 SPDX-License-Identifier: GPL-2.0

/*

 * Dynamic function tracing support.

 *

 * Copyright (C) 2008 Abhishek Sagar <sagar.abhishek@gmail.com>

 * Copyright (C) 2010 Rabin Vincent <rabin@rab.in>

 *

 * For licencing details, see COPYING.

 *

 * Defines low-level handling of mcount calls when the kernel

 * is compiled with the -pg flag. When using dynamic ftrace, the

 * mcount call-sites get patched with NOP till they are enabled.

 * All code mutation routines here are called under stop_machine().

 pop.w {lr} */

 pop {lr} */

 Make sure any TLB misses during machine stop are cleared. */

 mod is only supplied during module loading */

 CONFIG_DYNAMIC_FTRACE */

 mov r0, r0 */

 CONFIG_DYNAMIC_FTRACE */

 CONFIG_FUNCTION_GRAPH_TRACER */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * XIP kernel .data segment decompressor

 *

 * Created by:	Nicolas Pitre, August 2017

 * Copyright:	(C) 2017  Linaro Limited

 for struct inflate_state */

/*

 * This code is called very early during the boot process to decompress

 * the .data segment stored compressed in ROM. Therefore none of the global

 * variables are valid yet, hence no kernel services such as memory

 * allocation is available. Everything must be allocated on the stack and

 * we must avoid any global data access. We use a temporary stack located

 * in the .bss area. The linker script makes sure the .bss is big enough

 * to hold our stack frame plus some room for called functions.

 *

 * We mimic the code in lib/decompress_inflate.c to use the smallest work

 * area possible. And because everything is statically allocated on the

 * stack then there is no need to clean up before returning.

 Check and skip gzip header (assume no filename) */

 upper bound */

 should be 0 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/kernel/xscale-cp0.c

 *

 * XScale DSP and iWMMXt coprocessor context switching and handling

		/*

		 * flush_thread() zeroes thread->fpstate, so no need

		 * to do anything here.

		 *

		 * FALLTHROUGH: Ensure we don't try to overwrite our newly

		 * initialised state information on the first fault.

/*

 * Detect whether we have a MAC coprocessor (40 bit register) or an

 * iWMMXt coprocessor (64 bit registers) by loading 00000100:00000000

 * into a coprocessor register and reading it back, and checking

 * whether the upper word survived intact.

	/*

	 * This sequence is interpreted by the DSP coprocessor as:

	 *	mar	acc0, %2, %3

	 *	mra	%0, %1, acc0

	 *

	 * And by the iWMMXt coprocessor as:

	 *	tmcrr	wR0, %2, %3

	 *	tmrrc	%0, %1, wR0

/*

 * If we detect that the CPU has iWMMXt (and CONFIG_IWMMXT=y), we

 * disable CP0/CP1 on boot, and let call_fpe() and the iWMMXt lazy

 * switch code handle iWMMXt context switching.  If on the other

 * hand the CPU has a DSP coprocessor, we keep access to CP0 enabled

 * all the time, and save/restore acc0 on context switch in non-lazy

 * fashion.

 do not attempt to probe iwmmxt on non-xscale family CPUs */

 SPDX-License-Identifier: GPL-2.0

/*

 * ARMv5 [xscale] Performance counter handling code.

 *

 * Copyright (C) 2010, ARM Ltd., Will Deacon <will.deacon@arm.com>

 *

 * Based on the previous xscale OProfile code.

 *

 * There are two variants of the xscale PMU that we support:

 * 	- xscale1pmu: 2 event counters and a cycle counter

 * 	- xscale2pmu: 4 event counters and a cycle counter

 * The two variants share event definitions, but have different

 * PMU structures.

 XSCALE_PERFCTR_CCNT is not hardware defined */

 upper 4bits and 7, 11 are write-as-0 */

	/*

	 * NOTE: there's an A stepping erratum that states if an overflow

	 *       bit already exists and another occurs, the previous

	 *       Overflow bit gets cleared. There's no workaround.

	 *	 Fixed in B stepping or later.

	/*

	 * Write the value back to clear the overflow flags. Overflow

	 * flags remain in pmnc for use below. We also disable the PMU

	 * while we process the interrupt.

	/*

	 * Re-enable the PMU.

 bits 1-2 and 4-23 are read-unpredictable */

 bits 4-23 are write-as-0, 24-31 are write ignored */

 Disable the PMU. */

 Check the overflow flag register. */

 Clear the overflow bits. */

	/*

	 * Re-enable the PMU.

 sentinel value */ }

 CONFIG_CPU_XSCALE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2013 Uwe Kleine-Koenig for Pengutronix

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/devtree.c

 *

 *  Copyright (C) 2009 Canonical Ltd. <jeremy.kerr@canonical.com>

/*

 * arm_dt_init_cpu_maps - Function retrieves cpu nodes from the device tree

 * and builds the cpu logical map array containing MPIDR values related to

 * logical cpus

 *

 * Updates the cpu possible mask with the number of parsed cpu nodes

	/*

	 * Temp logical map is initialized with UINT_MAX values that are

	 * considered invalid logical map entries since the logical map must

	 * contain a list of MPIDR[23:0] values where MPIDR[31:24] must

	 * read as 0.

		/*

		 * Bits n:24 must be set to 0 in the DT since the reg property

		 * defines the MPIDR[23:0].

		/*

		 * Duplicate MPIDRs are a recipe for disaster.

		 * Scan all initialized entries and check for

		 * duplicates. If any is found just bail out.

		 * temp values were initialized to UINT_MAX

		 * to avoid matching valid MPIDR[23:0] values.

		/*

		 * Build a stashed array of MPIDR values. Numbering scheme

		 * requires that if detected the boot CPU must be assigned

		 * logical id 0. Other CPUs get sequential indexes starting

		 * from 1. If a CPU node with a reg property matching the

		 * boot CPU MPIDR is detected, this is recorded so that the

		 * logical map built from DT is validated and can be used

		 * to override the map created in smp_setup_processor_id().

	/*

	 * Fallback to an enable-method in the cpus node if nothing found in

	 * a cpu node.

	/*

	 * Since the boot CPU node contains proper data, and all nodes have

	 * a reg property, the DT CPU list can be considered valid and the

	 * logical map created in smp_setup_processor_id() can be overridden

/**

 * setup_machine_fdt - Machine setup when an dtb was passed to the kernel

 * @dt_virt: virtual address of dt blob

 *

 * If a dtb was passed to the kernel in r2, then use it to choose the

 * correct machine_desc and to setup the system.

 does not return */

 We really don't want to do this, but sometimes firmware provides buggy data */

 Change machine number to match the mdesc we're using */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/opcodes.c

 *

 *  A32 condition code lookup feature moved from nwfpe/fpopcode.c

/*

 * condition code lookup table

 * index into the table is test code: EQ, NE, ... LT, GT, AL, NV

 *

 * bit position in short is condition code: NZCV

 EQ == Z set            */

 NE                     */

 CS == C set            */

 CC                     */

 MI == N set            */

 PL                     */

 VS == V set            */

 VC                     */

 HI == C set && Z clear */

 LS == C clear || Z set */

 GE == (N==V)           */

 LT == (N!=V)           */

 GT == (!Z && (N==V))   */

 LE == (Z || (N!=V))    */

 AL always              */

 NV                     */

/*

 * Returns:

 * ARM_OPCODE_CONDTEST_FAIL   - if condition fails

 * ARM_OPCODE_CONDTEST_PASS   - if condition passes (including AL)

 * ARM_OPCODE_CONDTEST_UNCOND - if NV condition, or separate unconditional

 *                              opcode space from v5 onwards

 *

 * Code that tests whether a conditional instruction would pass its condition

 * check should check that return value == ARM_OPCODE_CONDTEST_PASS.

 *

 * Code that tests if a condition means that the instruction would be executed

 * (regardless of conditional or unconditional) should instead check that the

 * return value != ARM_OPCODE_CONDTEST_FAIL.

 SPDX-License-Identifier: GPL-2.0

/*

 * ARMv6 Performance counter handling code.

 *

 * Copyright (C) 2009 picoChip Designs, Ltd., Jamie Iles

 *

 * ARMv6 has 2 configurable performance counters and a single cycle counter.

 * They all share a single reset bit but can be written to zero so we can use

 * that for a reset.

 *

 * The counters can't be individually enabled or disabled so when we remove

 * one event and replace it with another we could get spurious counts from the

 * wrong event. However, we can take advantage of the fact that the

 * performance counters can export events to the event bus, and the event bus

 * itself can be monitored. This requires that we *don't* export the events to

 * the event bus. The procedure for disabling a configurable counter is:

 *	- change the counter to count the ETMEXTOUT[0] signal (0x20). This

 *	  effectively stops the counter from counting.

 *	- disable the counter's interrupt generation (each counter has it's

 *	  own interrupt enable bit).

 * Once stopped, the counter value can be written as 0 to reset.

 *

 * To enable a counter:

 *	- enable the counter's interrupt generation.

 *	- set the new event type.

 *

 * Note: the dedicated cycle counter only counts cycles and can't be

 * enabled/disabled independently of the others. When we want to disable the

 * cycle counter, we have to just disable the interrupt reporting and start

 * ignoring that counter. When re-enabling, we have to reset the value and

 * enable the interrupt.

/*

 * The hardware events that we support. We do support cache operations but

 * we have harvard caches and no way to combine instruction and data

 * accesses/misses in hardware.

	/*

	 * The performance counters don't differentiate between read and write

	 * accesses/misses so this isn't strictly correct, but it's the best we

	 * can do. Writes and reads get combined.

	/*

	 * The ARM performance counters can count micro DTLB misses, micro ITLB

	 * misses and main TLB misses. There isn't an event for TLB misses, so

	 * use the micro misses here and if users want the main TLB misses they

	 * can use a raw counter.

/*

 * The hardware events that we support. We do support cache operations but

 * we have harvard caches and no way to combine instruction and data

 * accesses/misses in hardware.

	/*

	 * The ARM performance counters can count micro DTLB misses, micro ITLB

	 * misses and main TLB misses. There isn't an event for TLB misses, so

	 * use the micro misses here and if users want the main TLB misses they

	 * can use a raw counter.

	/*

	 * Mask out the current event and set the counter to count the event

	 * that we're interested in.

	/*

	 * The interrupts are cleared by writing the overflow flags back to

	 * the control register. All of the other bits don't have any effect

	 * if they are rewritten, so write the whole value back.

 Ignore if we don't have an event. */

		/*

		 * We have a single interrupt for all counters. Check that

		 * each counter has overflowed before we process it.

	/*

	 * Handle the pending perf events.

	 *

	 * Note: this call *must* be run with interrupts disabled. For

	 * platforms that can have the PMU interrupts raised as an NMI, this

	 * will not work.

 Always place a cycle counter into the cycle counter. */

		/*

		 * For anything other than a cycle counter, try and use

		 * counter0 and counter1.

 The counters are all in use. */

	/*

	 * Mask out the current event and set the counter to count the number

	 * of ETM bus signal assertion cycles. The external reporting should

	 * be disabled and so this should never increment.

	/*

	 * Unlike UP ARMv6, we don't have a way of stopping the counters. We

	 * simply disable the interrupt reporting.

/*

 * ARMv6mpcore is almost identical to single core ARMv6 with the exception

 * that some of the events have different enumerations and that there is no

 * *hack* to stop the programmable counters. To stop the counters we simply

 * disable the interrupt reporting and update the event. When unthrottling we

 * reset the period and enable the interrupt reporting.

 sentinel value */ }

 sentinel value */ }

 CONFIG_CPU_V6 || CONFIG_CPU_V6K */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/kernel/thumbee.c

 *

 * Copyright (C) 2008 ARM Limited

/*

 * Access to the ThumbEE Handler Base register

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014-2017 Linaro Ltd. <ard.biesheuvel@linaro.org>

 cache the address, ELF header is available only during module load */

	/*

	 * Look for an existing entry pointing to 'val'. Given that the

	 * relocations are sorted, this will be the last entry we allocated.

	 * (if one exists).

 Populate a new set of entries */

 sort by type and symbol index */

	/*

	 * Do a bitwise compare on the raw addend rather than fully decoding

	 * the offset and doing an arithmetic comparison.

	 * Note that a zero-addend jump/call relocation is encoded taking the

	 * PC bias into account, i.e., -8 for ARM and -4 for Thumb2.

	/*

	 * Entries are sorted by type and symbol index. That means that,

	 * if a duplicate entry exists, it must be in the preceding

	 * slot.

 Count how many PLT entries we may need */

			/*

			 * We only have to consider branch targets that resolve

			 * to symbols that are defined in a different section.

			 * This is not simply a heuristic, it is a fundamental

			 * limitation, since there is no guaranteed way to emit

			 * PLT entries sufficiently close to the branch if the

			 * section size exceeds the range of a branch

			 * instruction. So ignore relocations against defined

			 * symbols if they live in the same section as the

			 * relocation target.

			/*

			 * Jump relocations with non-zero addends against

			 * undefined symbols are supported by the ELF spec, but

			 * do not occur in practice (e.g., 'jump n bytes past

			 * the entry point of undefined function symbol f').

			 * So we need to support them, but there is no need to

			 * take them into consideration when trying to optimize

			 * this code. So let's only check for duplicates when

			 * the addend is zero. (Note that calls into the core

			 * module via init PLT entries could involve section

			 * relative symbol references with non-zero addends, for

			 * which we may end up emitting duplicates, but the init

			 * PLT is released along with the rest of the .init

			 * region as soon as module loading completes.)

	/*

	 * To store the PLTs, we expand the .text section for core module code

	 * and for initialization code.

 ignore relocations that operate on non-exec sections */

 sort by type and symbol index */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/smp.c

 *

 *  Copyright (C) 2002 ARM Limited, All Rights Reserved.

/*

 * as from 2.5, kernels no longer have an init_tasks structure

 * so we need some other way of telling a new secondary core

 * where to place its SVC stack

	/*

	 * CPU_BACKTRACE is special and not included in NR_IPI

	 * or tracable with trace_ipi_*

	/*

	 * SGI8-15 can be reserved by secure firmware, and thus may

	 * not be usable by the kernel. Please keep the above limited

	 * to at most 8 entries.

	/*

	 * We need to tell the secondary core where to find

	 * its stack and the page tables.

	/*

	 * Now bring the CPU into our world.

		/*

		 * CPU was successfully started, wait for it

		 * to come online or time out.

 platform specific SMP operations */

 cpu_die must be specified to support hotplug */

	/*

	 * By default, allow disabling all CPUs except the first one,

	 * since this is special on a lot of platforms, e.g. because

	 * of clock tick interrupts.

/*

 * __cpu_disable runs on the processor to be shutdown.

	/*

	 * Take this CPU offline.  Once we clear this, we can't return,

	 * and we must not schedule until we're ready to give up the cpu.

	/*

	 * OK - migrate IRQs away from this CPU

	/*

	 * Flush user cache and TLB mappings, and then remove this CPU

	 * from the vm mask set of all processes.

	 *

	 * Caches are flushed to the Level of Unification Inner Shareable

	 * to write-back dirty lines to unified caches shared by all CPUs.

/*

 * called on the thread which is asking for a CPU to be shutdown -

 * waits until shutdown has completed, or it is timed out.

	/*

	 * platform_cpu_kill() is generally expected to do the powering off

	 * and/or cutting of clocks to the dying CPU.  Optionally, this may

	 * be done by the CPU which is dying in preference to supporting

	 * this call, but that means there is _no_ synchronisation between

	 * the requesting CPU and the dying CPU actually losing power.

/*

 * Called from the idle thread for the CPU which has been shutdown.

 *

 * Note that we disable IRQs here, but do not re-enable them

 * before returning to the caller. This is also the behaviour

 * of the other hotplug-cpu capable cores, so presumably coming

 * out of idle fixes this.

	/*

	 * Flush the data out of the L1 cache for this CPU.  This must be

	 * before the completion to ensure that data is safely written out

	 * before platform_cpu_kill() gets called - which may disable

	 * *this* CPU and power down its cache.

	/*

	 * Tell __cpu_die() that this CPU is now safe to dispose of.  Once

	 * this returns, power and/or clocks can be removed at any point

	 * from this CPU and its cache by platform_cpu_kill().

	/*

	 * Ensure that the cache lines associated with that completion are

	 * written out.  This covers the case where _this_ CPU is doing the

	 * powering down, to ensure that the completion is visible to the

	 * CPU waiting for this one.

	/*

	 * The actual CPU shutdown procedure is at least platform (if not

	 * CPU) specific.  This may remove power, or it may simply spin.

	 *

	 * Platforms are generally expected *NOT* to return from this call,

	 * although there are some which do because they have no way to

	 * power down the CPU.  These platforms are the _only_ reason we

	 * have a return path which uses the fragment of assembly below.

	 *

	 * The return path should not be used for platforms which can

	 * power off the CPU.

	/*

	 * Do not return to the idle loop - jump back to the secondary

	 * cpu initialisation.  There's some initialisation which needs

	 * to be repeated to undo the effects of taking the CPU offline.

 CONFIG_HOTPLUG_CPU */

/*

 * Called by both boot and secondaries to move global data into

 * per-processor storage.

/*

 * This is the secondary CPU boot entry.  We're using this CPUs

 * idle thread stack, but a set of temporary page tables.

	/*

	 * The identity mapping is uncached (strongly ordered), so

	 * switch away from it before attempting any exclusive accesses.

	/*

	 * All kernel threads share the same mm context; grab a

	 * reference and switch to it.

	/*

	 * Give the platform a chance to do its own initialisation.

	/*

	 * OK, now it's safe to let the boot CPU continue.  Wait for

	 * the CPU migration code to notice that the CPU is online

	 * before we continue - which happens after __cpu_up returns.

	/*

	 * OK, it's off to the idle thread for us

	/*

	 * are we trying to boot more cores than exist?

		/*

		 * Initialise the present map, which describes the set of CPUs

		 * actually populated at the present time. A platform should

		 * re-initialize the map in the platforms smp_prepare_cpus()

		 * if present != possible (e.g. physical hotplug).

		/*

		 * Initialise the SCU if there are more than one CPU

		 * and let them know where to start.

/*

 * ipi_cpu_stop - handle IPI from smp_send_stop()

/*

 * Main handler for inter-processor interrupts

 Legacy version, should go away once all irqchips have been converted */

 Setup the boot CPU immediately */

 Wait up to one second for other CPUs to stop */

/* In case panic() and panic() called at the same time on CPU1 and CPU2,

 * and CPU 1 calls panic_smp_self_stop() before crash_smp_send_stop()

 * CPU1 can't receive the ipi irqs from CPU2, CPU1 will be always online,

 * kdump fails. So split out the panic_smp_self_stop() and add

 * set_cpu_online(smp_processor_id(), false).

/*

 * not supported here

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/kernel/unwind.c

 *

 * Copyright (C) 2008 ARM Limited

 *

 * Stack unwinding support for ARM

 *

 * An ARM EABI version of gcc is required to generate the unwind

 * tables. For information about the structure of the unwind tables,

 * see "Exception Handling ABI for the ARM Architecture" at:

 *

 * http://infocenter.arm.com/help/topic/com.arm.doc.subset.swdev.abi/index.html

 __CHECKER__ */

 Dummy functions to avoid linker complaints */

 virtual register set */

 pointer to the current instructions word */

 highest value of sp allowed */

	/*

	 * 1 : check for stack overflow for each register pop.

	 * 0 : save overhead if there is plenty of stack remaining.

 number of entries left to interpret */

 current byte number in the instructions word */

 Convert a prel31 symbol to an absolute address */

 sign-extend to 32 bits */			\

/*

 * Binary search in the unwind index. The entries are

 * guaranteed to be sorted in ascending order by the linker.

 *

 * start = first entry

 * origin = first entry with positive offset (or stop if there is no such entry)

 * stop - 1 = last entry

	/*

	 * only search in the section with the matching sign. This way the

	 * prel31 numbers can be compared as unsigned longs.

 negative offsets: [start; origin) */

 positive offsets: [origin; stop) */

 prel31 for address relavive to start */

		/*

		 * As addr_prel31 is relative to start an offset is needed to

		 * make it relative to mid.

 keep addr_prel31 relative to start */

 negative offset */

 positive offset */

 main unwind table */

 module unwind tables */

 Move-to-front to exploit common traces */

 Before poping a register check whether it is feasible or not */

	/* Use READ_ONCE_NOCHECK here to avoid this memory access

	 * from being tracked by KASAN.

 Helper functions to execute the instructions */

 pop R4-R[4+bbb] */

 pop R0-R3 according to mask */

/*

 * Execute the current unwind instruction.

 no further processing */

/*

 * Unwind a single frame starting with *sp for the symbol at *pc. It

 * updates the *pc and *sp with the new values.

 store the highest address on the stack to avoid crossing it*/

 can't unwind */

 prel31 to the unwind table */

 only personality routine 0 supported in the index */

 check the personality routine */

 check for infinite loop */

 PC might be corrupted, use LR in that case. */

 task blocked in __switch_to */

		/*

		 * The function calling __switch_to cannot be a leaf function

		 * so LR is recovered from the stack.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/swp_emulate.c

 *

 *  Copyright (C) 2009 ARM Limited

 *  __user_* functions adapted from include/asm/uaccess.h

 *

 *  Implements emulation of the SWP/SWPB instructions using load-exclusive and

 *  store-exclusive for processors that have them disabled (or future ones that

 *  might not implement them).

 *

 *  Syntax of SWP{B} instruction: SWP{B}<c> <Rt>, <Rt2>, [<Rn>]

 *  Where: Rt  = destination

 *	   Rt2 = source

 *	   Rn  = address

/*

 * Error-checking SWP macros implemented using ldrex{b}/strex{b}

/*

 * Macros/defines for extracting register numbers from instruction.

/*

 * Bit 22 of the instruction encoding distinguishes between

 * the SWP and SWPB variants (bit set means SWPB).

/*

 * Set up process info to signal segmentation fault - called on access error.

 SWP to unaligned address not permitted */

/*

 * swp_handler logs the id of calling process, dissects the instruction, sanity

 * checks the memory location, calls emulate_swpX for the actual operation and

 * deals with fixup/error handling before returning

 Condition failed - return to next instruction */

 If unconditional encoding - not a SWP, undef */

 Check access in reasonable access range for both SWP and SWPB */

		/*

		 * On successful emulation, revert the adjustment to the PC

		 * made in kernel/traps.c in order to resume execution at the

		 * instruction following the SWP{B}.

		/*

		 * Memory errors do not mean emulation failed.

		 * Set up signal info to return SEGV, then return OK

/*

 * Only emulate SWP/SWPB executed in ARM state/User mode.

 * The kernel must be SWP free and SWP{B} does not exist in Thumb/ThumbEE.

/*

 * Register handler and create status file in /proc/cpu

 * Invoked as late_initcall, since not needed before init spawned.

 CONFIG_PROC_FS */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/smp_twd.c

 *

 *  Copyright (C) 2002 ARM Ltd.

 *  All Rights Reserved

 set up by the platform code */

 period set, and timer enabled in 'next_event' hook */

/*

 * local_timer_ack: checks for a local timer interrupt.

 *

 * If a local timer interrupt has occurred, acknowledge and return 1.

 * Otherwise, return 0.

/*

 * Updates clockevent frequency when the cpu frequency changes.

 * Called on the cpu that is changing frequency with interrupts disabled.

	/*

	 * The twd clock events must be reprogrammed to account for the new

	 * frequency.  The timer is local to a cpu, so cross-call to the

	 * changing cpu.

	/*

	 * If this is the first time round, we need to work out how fast

	 * the timer ticks

 Wait for a tick to start */

 OK, now the tick has started, let's get the timer going */

 enable, no interrupt or reload */

 maximum value */

/*

 * Setup the local clock events for a CPU.

	/*

	 * If the basic setup for this CPU has been done before don't

	 * bother with the below.

	/*

	 * The following is done once per CPU the first time .setup() is

	 * called.

	/*

	 * Immediately configure the timer on the boot CPU, unless we need

	 * jiffies to be incrementing to calibrate the rate in which case

	 * setup the timer in late_time_init.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/signal.c

 *

 *  Copyright (C) 1995-2009 Russell King

 the iWMMXt context must be 64 bit aligned */

		/*

		 * For bug-compatibility with older kernels, some space

		 * has to be reserved for iWMMXt even if it's not used.

		 * Set the magic and size appropriately so that properly

		 * written userspace can skip it reliably:

 the iWMMXt context must be 64 bit aligned */

	/*

	 * For non-iWMMXt threads: a single iwmmxt_sigframe-sized dummy

	 * block is discarded for compatibility with setup_sigframe() if

	 * present, but we don't mandate its presence.  If some other

	 * magic is here, it's not for us:

/*

 * Do a signal return; undo the signal stack.  These are aligned to 64-bit.

 Always make any pending restarted system calls return -EINTR */

	/*

	 * Since we stacked the signal on a 64-bit boundary,

	 * then 'sp' should be word aligned here.  If it's

	 * not, then the user is trying to mess with us.

 Always make any pending restarted system calls return -EINTR */

	/*

	 * Since we stacked the signal on a 64-bit boundary,

	 * then 'sp' should be word aligned here.  If it's

	 * not, then the user is trying to mess with us.

	/*

	 * ATPCS B01 mandates 8-byte alignment

	/*

	 * Check that we can actually write to the signal frame.

	/*

	 * Maybe we need to deliver a 32-bit signal to a 26-bit task.

		/*

		 * The LSB of the handler determines if we're going to

		 * be using THUMB or ARM mode for this signal handler.

		/*

		 * Clear the If-Then Thumb-2 execution state.  ARM spec

		 * requires this to be all 000s in ARM mode.  Snapdragon

		 * S4/Krait misbehaves on a Thumb=>ARM signal transition

		 * without this.

		 *

		 * We must do this whenever we are running on a Thumb-2

		 * capable CPU, which includes ARMv6T2.  However, we elect

		 * to always do this to simplify the code; this field is

		 * marked UNK/SBZP for older architectures.

			/*

			 * We need code to load the function descriptor.

			 * That code follows the standard sigreturn code

			 * (6 words), and is made of 3 + 2 words for each

			 * variant. The 4th copied word is the actual FD

			 * address that the assembly code expects.

		/*

		 * Put the sigreturn code on the stack no matter which return

		 * mechanism we use in order to remain ABI compliant

			/*

			 * 32-bit code can use the signal return page

			 * except when the MPU has protected the vectors

			 * page from PL0

			/*

			 * Ensure that the instruction cache sees

			 * the return code written onto the stack.

	/*

	 * Set uc.uc_flags to a value which sc.trap_no would never have.

		/*

		 * For realtime signals we must also set the second and third

		 * arguments for the signal handler.

		 *   -- Peter Maydell <pmaydell@chiark.greenend.org.uk> 2000-12-06

/*

 * OK, we're invoking a handler

	/*

	 * Perform fixup for the pre-signal frame.

	/*

	 * Set up the stack frame

	/*

	 * Check that the resulting registers are actually sane.

/*

 * Note that 'init' is a special process: it doesn't get signals it doesn't

 * want to handle. Thus you cannot kill init even with a SIGKILL even by

 * mistake.

 *

 * Note that we go through the signals twice: once to check the signals that

 * the kernel can handle, and then we build all the user-level signal handling

 * stack-frames in one go after that.

	/*

	 * If we were from a system call, check for system call restarting...

		/*

		 * Prepare for system call restart.  We do this here so that a

		 * debugger will see the already changed PSW.

	/*

	 * Get the signal to deliver.  When running under ptrace, at this

	 * point the debugger may change all our registers ...

	/*

	 * Depending on the signal settings we may need to revert the

	 * decision to restart the system call.  But skip this if a

	 * debugger has chosen to restart at a different PC.

 handler */

 no handler */

	/*

	 * The assembly code enters us with IRQs off, but it hasn't

	 * informed the tracing code of that for efficiency reasons.

	 * Update the trace code with the current status.

					/*

					 * Restart without handlers.

					 * Deal with it without leaving

					 * the kernel space.

 Poison the entire page */

 Give the signal return code some randomness */

 Copy signal return handlers into the page */

 Flush out all instructions in this page */

/*

 * Compile-time assertions for siginfo_t offsets. Check NSIG* as well, as

 * changes likely come with new fields that should be added below.

 SPDX-License-Identifier: GPL-2.0

/*

 * ARMv7 Cortex-A8 and Cortex-A9 Performance Events handling code.

 *

 * ARMv7 support: Jean Pihet <jpihet@mvista.com>

 * 2010 (c) MontaVista Software, LLC.

 *

 * Copied from ARMv6 code, with the low level code inspired

 *  by the ARMv7 Oprofile code.

 *

 * Cortex-A8 has up to 4 configurable performance counters and

 *  a single cycle counter.

 * Cortex-A9 has up to 31 configurable performance counters and

 *  a single cycle counter.

 *

 * All counters can be enabled/disabled and IRQ masked separately. The cycle

 *  counter and all 4 performance counters together can be reset separately.

/*

 * Common ARMv7 event types

 *

 * Note: An implementation may not be able to count all of these events

 * but the encodings are considered to be `reserved' in the case that

 * they are not available.

/*

 * ARMV7_PERFCTR_PC_WRITE is equivalent to HW_BRANCH_INSTRUCTIONS.

 * It counts:

 *  - all (taken) branch instructions,

 *  - instructions that explicitly write the PC,

 *  - exception generating instructions.

 These events are defined by the PMUv2 supplement (ARM DDI 0457A). */

 ARMv7 Cortex-A8 specific event types */

 ARMv7 Cortex-A9 specific event types */

 ARMv7 Cortex-A5 specific event types */

 ARMv7 Cortex-A15 specific event types */

 ARMv7 Cortex-A12 specific event types */

 ARMv7 Krait specific event types */

 ARMv7 Scorpion specific event types */

/*

 * Cortex-A8 HW events mapping

 *

 * The hardware events that we support. We do support cache operations but

 * we have harvard caches and no way to combine instruction and data

 * accesses/misses in hardware.

	/*

	 * The performance counters don't differentiate between read and write

	 * accesses/misses so this isn't strictly correct, but it's the best we

	 * can do. Writes and reads get combined.

/*

 * Cortex-A9 HW events mapping

	/*

	 * The performance counters don't differentiate between read and write

	 * accesses/misses so this isn't strictly correct, but it's the best we

	 * can do. Writes and reads get combined.

/*

 * Cortex-A5 HW events mapping

	/*

	 * The prefetch counters don't differentiate between the I side and the

	 * D side.

/*

 * Cortex-A15 HW events mapping

	/*

	 * Not all performance counters differentiate between read and write

	 * accesses/misses so we're not always strictly correct, but it's the

	 * best we can do. Writes and reads get combined in these cases.

/*

 * Cortex-A7 HW events mapping

	/*

	 * The performance counters don't differentiate between read and write

	 * accesses/misses so this isn't strictly correct, but it's the best we

	 * can do. Writes and reads get combined.

/*

 * Cortex-A12 HW events mapping

	/*

	 * Not all performance counters differentiate between read and write

	 * accesses/misses so we're not always strictly correct, but it's the

	 * best we can do. Writes and reads get combined in these cases.

/*

 * Krait HW events mapping

	/*

	 * The performance counters don't differentiate between read and write

	 * accesses/misses so this isn't strictly correct, but it's the best we

	 * can do. Writes and reads get combined.

/*

 * Scorpion HW events mapping

	/*

	 * The performance counters don't differentiate between read and write

	 * accesses/misses so this isn't strictly correct, but it's the best we

	 * can do. Writes and reads get combined.

	/*

	 * Only ITLB misses and DTLB refills are supported.  If users want the

	 * DTLB refills misses a raw counter must be used.

/*

 * Perf Events' indices

/*

 * ARMv7 low level PMNC access

/*

 * Perf Event to low level counters mapping

/*

 * Per-CPU PMNC: config reg

 Enable all counters */

 Reset all counters */

 Cycle counter reset */

 CCNT counts every 64th cpu cycle */

 Export to ETM */

 Disable CCNT if non-invasive debug*/

 Number of counters supported */

 Mask for writable bits */

/*

 * FLAG: counters overflow flag status reg

 Mask for writable bits */

/*

 * PMXEVTYPER: Event selection reg

 Mask for writable bits */

 Mask for EVENT bits */

/*

 * Event filters for PMUv2

/*

 * Secure debug enable reg

 Permit non-invasive debug */

 Clear the overflow flag in case an interrupt is pending. */

 Read */

 Write to clear flags */

	/*

	 * Enable counter and interrupt, and set the counter to count

	 * the event that we're interested in.

	/*

	 * Disable counter

	/*

	 * Set event (if destined for PMNx counters)

	 * We only need to set the event for the cycle counter if we

	 * have the ability to perform event filtering.

	/*

	 * Enable interrupt for this counter

	/*

	 * Enable counter

	/*

	 * Disable counter and interrupt

	/*

	 * Disable counter

	/*

	 * Disable interrupt for this counter

	/*

	 * Get and reset the IRQ flags

	/*

	 * Did an overflow occur?

	/*

	 * Handle the counter(s) overflow(s)

 Ignore if we don't have an event. */

		/*

		 * We have a single interrupt for all counters. Check that

		 * each counter has overflowed before we process it.

	/*

	 * Handle the pending perf events.

	 *

	 * Note: this call *must* be run with interrupts disabled. For

	 * platforms that can have the PMU interrupts raised as an NMI, this

	 * will not work.

 Enable all counters */

 Disable all counters */

 Always place a cycle counter into the cycle counter. */

	/*

	 * For anything other than a cycle counter, try and use

	 * the events counters

 The counters are all in use. */

/*

 * Add an event filter to a given event. This will only work for PMUv2 PMUs.

	/*

	 * Install the filter into config_base as this is used to

	 * construct the event type.

 The counter and interrupt enable registers are unknown at reset. */

 Initialize & Reset PMNC: C and P bits */

 Read the nb of CNTx counters supported from PMNC */

 Add the CPU cycles counter */

/*

 * Krait Performance Monitor Region Event Selection Register (PMRESRn)

 *

 *            31   30     24     16     8      0

 *            +--------------------------------+

 *  PMRESR0   | EN |  CC  |  CC  |  CC  |  CC  |   N = 1, R = 0

 *            +--------------------------------+

 *  PMRESR1   | EN |  CC  |  CC  |  CC  |  CC  |   N = 1, R = 1

 *            +--------------------------------+

 *  PMRESR2   | EN |  CC  |  CC  |  CC  |  CC  |   N = 1, R = 2

 *            +--------------------------------+

 *  VPMRESR0  | EN |  CC  |  CC  |  CC  |  CC  |   N = 2, R = ?

 *            +--------------------------------+

 *              EN | G=3  | G=2  | G=1  | G=0

 *

 *  Event Encoding:

 *

 *      hwc->config_base = 0xNRCCG

 *

 *      N  = prefix, 1 for Krait CPU (PMRESRn), 2 for Venum VFP (VPMRESR)

 *      R  = region register

 *      CC = class of events the group G is choosing from

 *      G  = group or particular event

 *

 *  Example: 0x12021 is a Krait CPU event in PMRESR2's group 1 with code 2

 *

 *  A region (R) corresponds to a piece of the CPU (execution unit, instruction

 *  unit, etc.) while the event code (CC) corresponds to a particular class of

 *  events (interrupts for example). An event code is broken down into

 *  groups (G) that can be mapped into the PMU (irq, fiqs, and irq+fiqs for

 *  example).

 R */

 G */

 CC */

 N=2 */

 N=1 */

 Should be validated in krait_pmu_get_event_idx() */

 Should be validated in krait_pmu_get_event_idx() */

 CPACR Enable CP10 and CP11 access */

 Enable FPEXC */

 Restore FPEXC */

 Restore CPACR */

 Configure evtsel for the region and group */

 Mix in mode-exclusion bits */

 Don't clear enable bit if entire region isn't disabled */

 Disable counter and interrupt */

 Disable counter */

	/*

	 * Clear pmresr code (if destined for PMNx counters)

 Disable interrupt for this counter */

	/*

	 * Enable counter and interrupt, and set the counter to count

	 * the event that we're interested in.

 Disable counter */

	/*

	 * Set event (if destined for PMNx counters)

	 * We set the event for the cycle counter because we

	 * have the ability to perform event filtering.

 Enable interrupt for this counter */

 Enable counter */

 Clear all pmresrs */

 Reset PMxEVNCTCR to sane default */

	/*

	 * Lower bits are reserved for use by the counters (see

	 * armv7pmu_get_event_idx() for more info)

/*

 * We check for column exclusion constraints here.

 * Two events cant use the same group within a pmresr register.

 Ignore invalid events */

 Some early versions of Krait don't support PC write events */

/*

 * Scorpion Local Performance Monitor Register (LPMn)

 *

 *            31   30     24     16     8      0

 *            +--------------------------------+

 *  LPM0      | EN |  CC  |  CC  |  CC  |  CC  |   N = 1, R = 0

 *            +--------------------------------+

 *  LPM1      | EN |  CC  |  CC  |  CC  |  CC  |   N = 1, R = 1

 *            +--------------------------------+

 *  LPM2      | EN |  CC  |  CC  |  CC  |  CC  |   N = 1, R = 2

 *            +--------------------------------+

 *  L2LPM     | EN |  CC  |  CC  |  CC  |  CC  |   N = 1, R = 3

 *            +--------------------------------+

 *  VLPM      | EN |  CC  |  CC  |  CC  |  CC  |   N = 2, R = ?

 *            +--------------------------------+

 *              EN | G=3  | G=2  | G=1  | G=0

 *

 *

 *  Event Encoding:

 *

 *      hwc->config_base = 0xNRCCG

 *

 *      N  = prefix, 1 for Scorpion CPU (LPMn/L2LPM), 2 for Venum VFP (VLPM)

 *      R  = region register

 *      CC = class of events the group G is choosing from

 *      G  = group or particular event

 *

 *  Example: 0x12021 is a Scorpion CPU event in LPM2's group 1 with code 2

 *

 *  A region (R) corresponds to a piece of the CPU (execution unit, instruction

 *  unit, etc.) while the event code (CC) corresponds to a particular class of

 *  events (interrupts for example). An event code is broken down into

 *  groups (G) that can be mapped into the PMU (irq, fiqs, and irq+fiqs for

 *  example).

 Should be validated in scorpion_pmu_get_event_idx() */

 Should be validated in scorpion_pmu_get_event_idx() */

 Configure evtsel for the region and group */

 Mix in mode-exclusion bits */

 Disable counter and interrupt */

 Disable counter */

	/*

	 * Clear pmresr code (if destined for PMNx counters)

 Disable interrupt for this counter */

	/*

	 * Enable counter and interrupt, and set the counter to count

	 * the event that we're interested in.

 Disable counter */

	/*

	 * Set event (if destined for PMNx counters)

	 * We don't set the event for the cycle counter because we

	 * don't have the ability to perform event filtering.

 Enable interrupt for this counter */

 Enable counter */

 Clear all pmresrs */

 Reset PMxEVNCTCR to sane default */

	/*

	 * Lower bits are reserved for use by the counters (see

	 * armv7pmu_get_event_idx() for more info)

/*

 * We check for column exclusion constraints here.

 * Two events cant use the same group within a pmresr register.

 Ignore invalid events */

 sentinel value */ }

 CONFIG_CPU_V7 */

 SPDX-License-Identifier: GPL-2.0

/*

 * arch/arm/kernel/kgdb.c

 *

 * ARM KGDB support

 *

 * Copyright (c) 2002-2004 MontaVista Software, Inc

 * Copyright (c) 2008 Wind River Systems, Inc.

 *

 * Authors:  George Davis <davis_g@mvista.com>

 *           Deepak Saxena <dsaxena@plexity.net>

 Just making sure... */

 Initialize to zero */

 Otherwise, we have only some registers from switch_to() */

		/*

		 * Try to read optional parameter, pc unchanged if no parm.

		 * If this was a compiled breakpoint, we need to move

		 * to the next instruction or we will just breakpoint

		 * over and over again.

/**

 *	kgdb_arch_init - Perform any architecture specific initalization.

 *

 *	This function will handle the initalization of any architecture

 *	specific callbacks.

/**

 *	kgdb_arch_exit - Perform any architecture specific uninitalization.

 *

 *	This function will handle the uninitalization of any architecture

 *	specific callbacks, for dynamic registration and unregistration.

 patch_text() only supports int-sized breakpoints */

 Machine is already stopped, so we can use __patch_text() directly */

 Machine is already stopped, so we can use __patch_text() directly */

/*

 * Register our undef instruction hooks with ARM undef core.

 * We register a hook specifically looking for the KGB break inst

 * and we handle the normal undef case within the do_undefinstr

 * handler.

 ! __ARMEB__ */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/ptrace.c

 *

 *  By Ross Biro 1/23/92

 * edited by Linus Torvalds

 * ARM modifications Copyright (C) 2000 Russell King

/*

 * does not yet catch signals sent when the child dies.

 * in exit.c or in signal.c.

/*

 * Breakpoint SWI instruction: SWI &9F0001

 fill this in later */

/*

 * New breakpoints - use an undefined instruction.  The ARM architecture

 * reference manual guarantees that the following instruction space

 * will produce an undefined instruction exception on all CPUs:

 *

 *  ARM:   xxxx 0111 1111 xxxx xxxx xxxx 1111 xxxx

 *  Thumb: 1101 1110 xxxx xxxx

/**

 * regs_query_register_offset() - query register offset from its name

 * @name:	the name of a register

 *

 * regs_query_register_offset() returns the offset of a register in struct

 * pt_regs from its name. If the name is invalid, this returns -EINVAL;

/**

 * regs_query_register_name() - query register name from its offset

 * @offset:	the offset of a register in struct pt_regs.

 *

 * regs_query_register_name() returns the name of a register from its

 * offset in struct pt_regs. If the @offset is invalid, this returns NULL;

/**

 * regs_within_kernel_stack() - check the address in the stack

 * @regs:      pt_regs which contains kernel stack pointer.

 * @addr:      address which is checked.

 *

 * regs_within_kernel_stack() checks @addr is within the kernel stack page(s).

 * If @addr is within the kernel stack, it returns true. If not, returns false.

/**

 * regs_get_kernel_stack_nth() - get Nth entry of the stack

 * @regs:	pt_regs which contains kernel stack pointer.

 * @n:		stack entry number.

 *

 * regs_get_kernel_stack_nth() returns @n th entry of the kernel stack which

 * is specified by @regs. If the @n th entry is NOT in the kernel stack,

 * this returns 0.

/*

 * this routine will get a word off of the processes privileged stack.

 * the offset is how far from the base addr as stored in the THREAD.

 * this routine assumes that all the privileged stacks are in our

 * data space.

/*

 * this routine will put a word on the processes privileged stack.

 * the offset is how far from the base addr as stored in the THREAD.

 * this routine assumes that all the privileged stacks are in our

 * data space.

/*

 * Called by kernel/ptrace.c when detaching..

 Nothing to do. */

/*

 * Handle hitting a breakpoint.

/*

 * Read the word at offset "off" into the "struct user".  We

 * actually access the pt_regs stored on the kernel stack.

/*

 * Write the word at offset "off" into "struct user".  We

 * actually access the pt_regs stored on the kernel stack.

/*

 * Get the child iWMMXt state.

 force it to ram */

/*

 * Set the child iWMMXt state.

 force a reload */

/*

 * Convert a virtual register number into an index for a thread_info

 * breakpoint array. Breakpoints are identified using positive numbers

 * whilst watchpoints are negative. The registers are laid out as pairs

 * of (address, control), each pair mapping to a unique hw_breakpoint struct.

 * Register 0 is reserved for describing resource information.

/*

 * Returns the virtual register number for the address of the

 * breakpoint at index idx.

/*

 * Handle hitting a HW-breakpoint.

/*

 * Set ptrace breakpoint pointers to zero for this task.

 * This is required in order to prevent child processes from unregistering

 * breakpoints held by their parent.

/*

 * Unregister breakpoints from this task and reset the pointers in

 * the thread_struct.

 Initialise fields to sane defaults. */

		/*

		 * Fix up the len because we may have adjusted it

		 * to compensate for an unaligned address.

 Address */

 Control */

 regset get/set implementations */

/*

 * VFP register get/set implementations.

 *

 * With respect to the kernel, struct user_fp is divided into three chunks:

 * 16 or 32 real VFP registers (d0-d15 or d0-31)

 *	These are transferred to/from the real registers in the task's

 *	vfp_hard_struct.  The number of registers depends on the kernel

 *	configuration.

 *

 * 16 or 0 fake VFP registers (d16-d31 or empty)

 *	i.e., the user_vfp structure has space for 32 registers even if

 *	the kernel doesn't have them all.

 *

 *	vfp_get() reads this chunk as zero where applicable

 *	vfp_set() ignores this chunk

 *

 * 1 word for the FPSCR

/*

 * For vfp_set() a read-modify-write is done on the VFP registers,

 * in order to avoid writing back a half-modified set of registers on

 * failure.

 CONFIG_VFP */

		/*

		 * For the FPA regs in fpstate, the real fields are a mixture

		 * of sizes, so pretend that the registers are word-sized:

		/*

		 * Pretend that the VFP regs are word-sized, since the FPSCR is

		 * a single word dangling at the end of struct user_vfp:

 CONFIG_VFP */

	/*

	 * IP is used to denote syscall entry/exit:

	 * IP = 0 -> entry, =1 -> exit

 Do seccomp after ptrace; syscall may have changed. */

 XXX: remove this once OABI gets fixed */

 Tracer or seccomp may have changed syscall. */

	/*

	 * Audit the syscall before anything else, as a debugger may

	 * come in and change the current registers.

	/*

	 * Note that we haven't updated the ->syscall field for the

	 * current thread. This isn't a problem because it will have

	 * been set on syscall entry and there hasn't been an opportunity

	 * for a PTRACE_SET_SYSCALL since then.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (C) 2013 Citrix Systems

 *

 * Author: Stefano Stabellini <stefano.stabellini@eu.citrix.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  arch/arm/kernel/sys_oabi-compat.c

 *

 *  Compatibility wrappers for syscalls that are used from

 *  old ABI user space binaries with an EABI kernel.

 *

 *  Author:	Nicolas Pitre

 *  Created:	Oct 7, 2005

 *  Copyright:	MontaVista Software, Inc.

/*

 * The legacy ABI and the new ARM EABI have different rules making some

 * syscalls incompatible especially with structure arguments.

 * Most notably, Eabi says 64-bit members should be 64-bit aligned instead of

 * simply word aligned.  EABI also pads structures to the size of the largest

 * member it contains instead of the invariant 32-bit.

 *

 * The following syscalls are affected:

 *

 * sys_stat64:

 * sys_lstat64:

 * sys_fstat64:

 * sys_fstatat64:

 *

 *   struct stat64 has different sizes and some members are shifted

 *   Compatibility wrappers are needed for them and provided below.

 *

 * sys_fcntl64:

 *

 *   struct flock64 has different sizes and some members are shifted

 *   A compatibility wrapper is needed and provided below.

 *

 * sys_statfs64:

 * sys_fstatfs64:

 *

 *   struct statfs64 has extra padding with EABI growing its size from

 *   84 to 88.  This struct is now __attribute__((packed,aligned(4)))

 *   with a small assembly wrapper to force the sz argument to 84 if it is 88

 *   to avoid copying the extra padding over user space unexpecting it.

 *

 * sys_newuname:

 *

 *   struct new_utsname has no padding with EABI.  No problem there.

 *

 * sys_epoll_ctl:

 * sys_epoll_wait:

 *

 *   struct epoll_event has its second member shifted also affecting the

 *   structure size. Compatibility wrappers are needed and provided below.

 *

 * sys_ipc:

 * sys_semop:

 * sys_semtimedop:

 *

 *   struct sembuf loses its padding with EABI.  Since arrays of them are

 *   used they have to be copyed to remove the padding. Compatibility wrappers

 *   provided below.

 *

 * sys_bind:

 * sys_connect:

 * sys_sendmsg:

 * sys_sendto:

 * sys_socketcall:

 *

 *   struct sockaddr_un loses its padding with EABI.  Since the size of the

 *   structure is used as a validation test in unix_mkname(), we need to

 *   change the length argument to 110 whenever it is 112.  Compatibility

 *   wrappers provided below.

		/*

		 * HACK ALERT: there is a limit to how much backward bending

		 * we should do for what is actually a transitional

		 * compatibility layer.  This already has known flaws with

		 * a few ioctls that we don't intend to fix.  Therefore

		 * consider this blatent hack as another one... and take care

		 * to run for cover.  In most cases it will "just work fine".

		 * If it doesn't, well, tough.

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/kernel/crash_dump.c

 *

 * Copyright (C) 2010 Nokia Corporation.

 * Author: Mika Westerberg

 *

 * This code is taken from arch/x86/kernel/crash_dump_64.c

 *   Created by: Hariprasad Nellitheertha (hari@in.ibm.com)

 *   Copyright (C) IBM Corporation, 2004. All rights reserved

/**

 * copy_oldmem_page() - copy one page from old kernel memory

 * @pfn: page frame number to be copied

 * @buf: buffer where the copied page is placed

 * @csize: number of bytes to copy

 * @offset: offset in bytes into the page

 * @userbuf: if set, @buf is int he user address space

 *

 * This function copies one page from old kernel memory into buffer pointed by

 * @buf. If @buf is in userspace, set @userbuf to %1. Returns number of bytes

 * copied or negative error in case of failure.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/module.c

 *

 *  Copyright (C) 2002 Russell King.

 *  Modified for nommu by Hyok S. Choi

 *

 * Module allocation method suggested by Andi Kleen.

/*

 * The XIP kernel text is mapped in the module area for modules and

 * some other stuff to work without any indirect relocations.

 * MODULES_VADDR is redefined here and not in asm/memory.h to avoid

 * recompiling the whole kernel when CONFIG_XIP_KERNEL is turned on/off.

 Silence the initial allocation */

 ignore */

			/*

			 * Route through a PLT entry if 'offset' exceeds the

			 * supported range. Note that 'offset + loc + 8'

			 * contains the absolute jump target, i.e.,

			 * @sym + addend, corrected for the +8 PC bias.

		       /* Preserve Rm and the condition code. Alter

			* other bits to re-code instruction as

			* MOV PC,Rm.

 sign extend */

			/*

			 * For function symbols, only Thumb addresses are

			 * allowed (no interworking).

			 *

			 * For non-function symbols, the destination

			 * has no specific ARM/Thumb disposition, so

			 * the branch is resolved under the assumption

			 * that interworking is not required.

			/*

			 * 25 bit signed address range (Thumb-2 BL and B.W

			 * instructions):

			 *   S:I1:I2:imm10:imm11:0

			 * where:

			 *   S     = upper[10]   = offset[24]

			 *   I1    = ~(J1 ^ S)   = offset[23]

			 *   I2    = ~(J2 ^ S)   = offset[22]

			 *   imm10 = upper[9:0]  = offset[21:12]

			 *   imm11 = lower[10:0] = offset[11:1]

			 *   J1    = lower[13]

			 *   J2    = lower[11]

			/*

			 * Route through a PLT entry if 'offset' exceeds the

			 * supported range.

			/*

			 * MOVT/MOVW instructions encoding in Thumb-2:

			 *

			 * i	= upper[10]

			 * imm4	= upper[3:0]

			 * imm3	= lower[14:12]

			 * imm8	= lower[7:0]

			 *

			 * imm16 = imm4:i:imm3:imm8

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2012 Linaro Ltd.

/**

 * arm_cpuidle_simple_enter() - a wrapper to cpu_do_idle()

 * @dev: not used

 * @drv: not used

 * @index: not used

 *

 * A trivial wrapper to allow the cpu_do_idle function to be assigned as a

 * cpuidle callback by matching the function signature.

 *

 * Returns the index passed as parameter

/**

 * arm_cpuidle_suspend() - function to enter low power idle states

 * @index: an integer used as an identifier for the low level PM callbacks

 *

 * This function calls the underlying arch specific low level PM code as

 * registered at the init time.

 *

 * Returns the result of the suspend callback.

/**

 * arm_cpuidle_get_ops() - find a registered cpuidle_ops by name

 * @method: the method name

 *

 * Search in the __cpuidle_method_of_table array the cpuidle ops matching the

 * method name.

 *

 * Returns a struct cpuidle_ops pointer, NULL if not found.

/**

 * arm_cpuidle_read_ops() - Initialize the cpuidle ops with the device tree

 * @dn: a pointer to a struct device node corresponding to a cpu node

 * @cpu: the cpu identifier

 *

 * Get the method name defined in the 'enable-method' property, retrieve the

 * associated cpuidle_ops and do a struct copy. This copy is needed because all

 * cpuidle_ops are tagged __initconst and will be unloaded after the init

 * process.

 *

 * Return 0 on sucess, -ENOENT if no 'enable-method' is defined, -EOPNOTSUPP if

 * no cpuidle_ops is registered for the 'enable-method', or if either init or

 * suspend callback isn't defined.

 structure copy */

/**

 * arm_cpuidle_init() - Initialize cpuidle_ops for a specific cpu

 * @cpu: the cpu to be initialized

 *

 * Initialize the cpuidle ops with the device for the cpu and then call

 * the cpu's idle initialization callback. This may fail if the underlying HW

 * is not operational.

 *

 * Returns:

 *  0 on success,

 *  -ENODEV if it fails to find the cpu node in the device tree,

 *  -EOPNOTSUPP if it does not find a registered and valid cpuidle_ops for

 *  this cpu,

 *  -ENOENT if it fails to find an 'enable-method' property,

 *  -ENXIO if the HW reports a failure or a misconfiguration,

 *  -ENOMEM if the HW report an memory allocation failure 

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Adapted from arm64 version.

 *

 * Copyright (C) 2012 ARM Limited

 * Copyright (C) 2015 Mentor Graphics Corporation.

 Total number of pages needed for the data and text portions of the VDSO. */

/*

 * The VDSO data page.

 ptr to ELF */

 ptr to .dynsym section */

 size of .dynsym section */

 ptr to .dynstr section */

/* Cached result of boot-time check for whether the arch timer exists,

 * and if so, whether the virtual counter is useable.

	/* The arm_arch_timer core should export

	 * arch_timer_use_virtual or similar so we don't have to do

	 * this.

 Grab section headers and strings so we can tell who is who */

 Find the section they want */

	/* If the virtual counter is absent or non-functional we don't

	 * want programs to incur the slight additional overhead of

	 * dispatching through the VDSO only to fall back to syscalls.

 Allocate the VDSO text pagelist */

 Grab the VDSO data page. */

 Grab the VDSO text pages. */

 for the data/vvar page */

 assumes mmap_lock is write-locked */

 Account for vvar page. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/kernel/return_address.c

 *

 * Copyright (C) 2009 Uwe Kleine-Koenig <u.kleine-koenig@pengutronix.de>

 * for Pengutronix

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * Copyright (C) 2012 ARM Limited

 *

 * Author: Will Deacon <will.deacon@arm.com>

/*

 * psci_smp assumes that the following is true about PSCI:

 *

 * cpu_suspend   Suspend the execution on a CPU

 * @state        we don't currently describe affinity levels, so just pass 0.

 * @entry_point  the first instruction to be executed on return

 * returns 0  success, < 0 on failure

 *

 * cpu_off       Power down a CPU

 * @state        we don't currently describe affinity levels, so just pass 0.

 * no return on successful call

 *

 * cpu_on        Power up a CPU

 * @cpuid        cpuid of target CPU, as from MPIDR

 * @entry_point  the first instruction to be executed on return

 * returns 0  success, < 0 on failure

 *

 * migrate       Migrate the context to a different CPU

 * @cpuid        cpuid of target CPU, as from MPIDR

 * returns 0  success, < 0 on failure

 *

 Fail early if we don't have CPU_OFF support */

 Trusted OS will deny CPU_OFF */

 We should never return */

	/*

	 * cpu_kill could race with cpu_die and we can

	 * potentially end up declaring this cpu undead

	 * while it is dying. So, try again a few times.

 Make platform_cpu_kill() fail. */

 is cpu_on available at least? */

 SPDX-License-Identifier: GPL-2.0

/*

 * ARM callchain support

 *

 * Copyright (C) 2009 picoChip Designs, Ltd., Jamie Iles

 * Copyright (C) 2010 ARM Ltd., Will Deacon <will.deacon@arm.com>

 *

 * This code is based on the ARM OProfile backtrace code.

/*

 * The registers we're interested in are at the end of the variable

 * length saved register structure. The fp points at the end of this

 * structure so the address of this struct is:

 * (struct frame_tail *)(xxx->fp)-1

 *

 * This code has been adapted from the ARM OProfile support.

/*

 * Get the return address for a single stackframe and return a pointer to the

 * next frame tail.

	/*

	 * Frame pointers should strictly progress back up the stack

	 * (towards higher addresses).

 We don't support guest os callchain now */

/*

 * Gets called by walk_stackframe() for every stackframe. This will be called

 * whist unwinding the stackframe and is like a subroutine return so we use

 * the PC.

 We don't support guest os callchain now */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (C) 1996-2000 Russell King - Converted to ARM.

 *  Original Copyright (C) 1995  Linus Torvalds

/*

 * Function pointers to optional machine specific functions

/*

 * A temporary stack to use for CPU reset. This is static so that we

 * don't clobber it with the identity mapping. When running with this

 * stack, any references to the current task *will not work* so you

 * should really do as little as possible before jumping to your reset

 * code.

 Take out a flat memory mapping. */

 Clean and invalidate caches */

 Turn off caching */

 Push out any further dirty data, and ensure cache is empty */

 Switch to the identity mapping. */

 original stub should be restored by kvm */

 Should never get here. */

 Disable interrupts first */

 Disable the L2 if we're the last man standing. */

 Change to the new stack and continue with the reset. */

 Should never get here. */

/*

 * Called by kexec, immediately prior to machine_kexec().

 *

 * This must completely disable all secondary CPUs; simply causing those CPUs

 * to execute e.g. a RAM-based pin loop is not sufficient. This allows the

 * kexec'd kernel to use any and all RAM as it sees fit, without having to

 * avoid any code or data used by any SW CPU pin loop. The CPU hotplug

 * functionality embodied in smp_shutdown_nonboot_cpus() to achieve this.

/*

 * Halting simply requires that the secondary CPUs stop performing any

 * activity (executing tasks, handling interrupts). smp_send_stop()

 * achieves this.

/*

 * Power-off simply requires that the secondary CPUs stop performing any

 * activity (executing tasks, handling interrupts). smp_send_stop()

 * achieves this. When the system power is turned off, it will take all CPUs

 * with it.

/*

 * Restart requires that the secondary CPUs stop performing any activity

 * while the primary CPU resets the system. Systems with a single CPU can

 * use soft_restart() as their machine descriptor's .restart hook, since that

 * will cause the only available CPU to reset. Systems with multiple CPUs must

 * provide a HW restart implementation, to ensure that all CPUs reset at once.

 * This is required so that any code running after reset on the primary CPU

 * doesn't have to co-ordinate with other CPUs to ensure they aren't still

 * executing pre-reset code, and using RAM that the primary CPU's code wishes

 * to use. Implementing such co-ordination would be essentially impossible.

 Give a grace period for failure to restart of 1s */

 Whoops - the platform was unable to reboot. Tell the user! */

 SPDX-License-Identifier: GPL-2.0

/*

 *  linux/arch/arm/kernel/fiq.c

 *

 *  Copyright (C) 1998 Russell King

 *  Copyright (C) 1998, 1999 Phil Blundell

 *

 *  FIQ support written by Philip Blundell <philb@gnu.org>, 1998.

 *

 *  FIQ support re-written by Russell King to be more generic

 *

 * We now properly support a method by which the FIQ handlers can

 * be stacked onto the vector.  We still do not support sharing

 * the FIQ vector itself.

 *

 * Operation is as follows:

 *  1. Owner A claims FIQ:

 *     - default_fiq relinquishes control.

 *  2. Owner A:

 *     - inserts code.

 *     - sets any registers,

 *     - enables FIQ.

 *  3. Owner B claims FIQ:

 *     - if owner A has a relinquish function.

 *       - disable FIQs.

 *       - saves any registers.

 *       - returns zero.

 *  4. Owner B:

 *     - inserts code.

 *     - sets any registers,

 *     - enables FIQ.

 *  5. Owner B releases FIQ:

 *     - Owner A is asked to reacquire FIQ:

 *	 - inserts code.

 *	 - restores saved registers.

 *	 - enables FIQ.

 *  6. Goto 3

/* Default reacquire function

 * - we always relinquish FIQ control

 * - we always reacquire FIQ control

 Restore default handler and registers */

 FIXME: notify irq controller to standard enable FIQs */

 defined in fiqasm.S */

 defined in fiqasm.S */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/irq.c

 *

 *  Copyright (C) 1992 Linus Torvalds

 *  Modifications for ARM processor Copyright (C) 1995-2000 Russell King.

 *

 *  Support for Dynamic Tick Timer Copyright (C) 2004-2005 Nokia Corporation.

 *  Dynamic Tick Timer written by Tony Lindgren <tony@atomide.com> and

 *  Tuukka Tikkanen <tuukka.tikkanen@elektrobit.com>.

 *

 *  This file contains the code used by various IRQ handling routines:

 *  asking for different IRQ's should be done through these routines

 *  instead of just grabbing them. Thus setups with different IRQ numbers

 *  shouldn't result in any weird surprises, and installing new handlers

 *  should be easier.

 *

 *  IRQ's are in fact implemented a bit like signal handlers for the kernel.

 *  Naturally it's not a 1:1 relation, but there are similarities.

/*

 * handle_IRQ handles all hardware IRQ's.  Decoded IRQs should

 * not come via this function.  Instead, they should provide their

 * own 'handler'.  Used by platform code implementing C-based 1st

 * level decoding.

	/*

	 * Some hardware gives randomly wrong interrupts.  Rather

	 * than crashing, do something sensible.

/*

 * asm_do_IRQ is the interface to be used from assembly code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/kernel/armksyms.c

 *

 *  Copyright (C) 2000 Russell King

/*

 * libgcc functions - functions that are used internally by the

 * compiler...  (prototypes are not correct though, but that

 * doesn't really matter since they're not versioned).

 platform dependent support */

 networking */

 io */

 string / mem functions */

 gcc lib functions */

 bitops */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  linux/arch/arm/kernel/isa.c

 *

 *  Copyright (C) 1999 Phil Blundell

 *

 *  ISA shared memory and I/O port support, and is required to support

 *  iopl, inb, outb and friends in userspace via glibc emulation.

 SPDX-License-Identifier: GPL-2.0

	/*

	 * Function graph tracer state gets incosistent when the kernel

	 * calls functions that never return (aka suspend finishers) hence

	 * disable graph tracing during their execution.

	/*

	 * Provide a temporary page table with an identity mapping for

	 * the MMU-enable code, required for resuming.  On successful

	 * resume (indicated by a zero return code), we need to switch

	 * back to the correct page tables.

/*

 * This is called by __cpu_suspend() to save the state, and do whatever

 * flushing is required to ensure that when the CPU goes to sleep we have

 * the necessary data available when the caches are not searched.

 This must correspond to the LDM in cpu_resume() assembly */

	/*

	 * flush_cache_louis does not guarantee that

	 * save_ptr and ptr are cleaned to main memory,

	 * just up to the Level of Unification Inner Shareable.

	 * Since the context pointer and context itself

	 * are to be retrieved with the MMU off that

	 * data must be cleaned from all cache levels

	 * to main memory using "area" cache primitives.

 ctx_ptr is an array of physical addresses */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 1995-2003 Russell King

 *               2001-2002 Keith Owens

 *     

 * Generate definitions needed by assembly language modules.

 * This code generates raw asm output which is post-processed to extract

 * and format the required data.

/*

 * Make sure that the compiler and target are compatible.

 SPDX-License-Identifier: GPL-2.0

/*

 * arch/arm/mach-mv78x00/mpp.c

 *

 * MPP functions for Marvell MV78x00 SoCs

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * arch/arm/mach-mv78x00/rd78x00-masa-setup.c

 *

 * Marvell RD-78x00-mASA Development Board Setup

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Basic MV78x00 setup. Needs to be called early.

	/*

	 * Partition on-chip peripherals between the two CPU cores.

	/*

	 * Assign all PCIe devices to CPU core #0.

 Maintainer: Lennert Buytenhek <buytenh@marvell.com> */

/*

 * arch/arm/mach-mv78xx0/db78x00-bp-setup.c

 *

 * Marvell DB-78x00-BP Development Board Setup

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Basic MV78xx0 setup. Needs to be called early.

	/*

	 * Partition on-chip peripherals between the two CPU cores.

		/*

		 * Assign the x16 PCIe slot on the board to CPU core

		 * #0, and let CPU core #1 have the four x1 slots.

 Maintainer: Lennert Buytenhek <buytenh@marvell.com> */

/*

 * arch/arm/mach-mv78xx0/common.c

 *

 * Core functions for Marvell MV78xx0 SoCs

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*****************************************************************************

 * Common bits

	/*

	 * Read Extra Features register.

	/*

	 * HCLK tick rate is configured by DEV_D[7:5] pins.

	/*

	 * Core #0 PCLK/L2CLK is configured by bits [13:8], core #1

	 * PCLK/L2CLK by bits [19:14].

	/*

	 * Bits [11:8] ([17:14] for core #1) configure the PCLK:HCLK

	 * ratio (1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6).

	/*

	 * Bits [13:12] ([19:18] for core #1) configure the PCLK:L2CLK

	 * ratio (1, 2, 3).

	/*

	 * TCLK tick rate is configured by DEV_A[2:0] strap pins.

/*****************************************************************************

 * I/O Address Mapping

	/*

	 * Map the right set of per-core registers depending on

	 * which core we are running on.

/*****************************************************************************

 * CLK tree

/*****************************************************************************

 * EHCI

/*****************************************************************************

 * EHCI1

/*****************************************************************************

 * EHCI2

/*****************************************************************************

 * GE00

/*****************************************************************************

 * GE01

/*****************************************************************************

 * GE10

	/*

	 * On the Z0, ge10 and ge11 are internally connected back

	 * to back, and not brought out.

/*****************************************************************************

 * GE11

	/*

	 * On the Z0, ge10 and ge11 are internally connected back

	 * to back, and not brought out.

/*****************************************************************************

 * I2C

/*****************************************************************************

 * SATA

/*****************************************************************************

 * UART0

/*****************************************************************************

 * UART1

/*****************************************************************************

 * UART2

/*****************************************************************************

 * UART3

/*****************************************************************************

 * Time handling

/*****************************************************************************

 * General

 Setup root of clk tree */

	/*

	 * Enable soft reset to assert RSTOUTn.

	/*

	 * Assert soft reset.

/*

 * arch/arm/mach-mv78xx0/buffalo-wxl-setup.c

 *

 * Buffalo WXL (Terastation Duo) Setup routines

 *

 * sebastien requiem <sebastien@requiem.fr>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 This arch has 2 Giga Ethernet */

 2 SATA controller supporting HotPlug */

	/*

	 * Basic MV78xx0 setup. Needs to be called early.

	/*

	 * Partition on-chip peripherals between the two CPU cores.

		/*

		 * Assign the x16 PCIe slot on the board to CPU core

		 * #0, and let CPU core #1 have the four x1 slots.

 Maintainer: Sebastien Requiem <sebastien@requiem.fr> */

/*

 * arch/arm/mach-mv78xx0/irq.c

 *

 * MV78xx0 IRQ handling.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Initialize gpiolib for GPIOs 0-31.  (The GPIO interrupt mask

	 * registers for core #1 are at an offset of 0x18 from those of

	 * core #0.)

/*

 * arch/arm/mach-mv78xx0/pcie.c

 *

 * PCIe functions for Marvell MV78xx0 SoCs

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Generic PCIe unit setup.

	/*

	 * Don't go out when trying to access nonexisting devices

	 * on the local bus.

	/*

	 * Prevent enumeration of root complex.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Machine declaration for Alpine platforms.

 *

 * Copyright (C) 2015 Annapurna Labs Ltd.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * SMP operations for Alpine platform.

 *

 * Copyright (C) 2015 Annapurna Labs Ltd.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Low-level power-management support for Alpine platform.

 *

 * Copyright (C) 2015 Annapurna Labs Ltd.

 NB registers */

	/*

	 * Set CPU resume address -

	 * secure firmware running on boot will jump to this address

	 * after setting proper CPU mode, and initialiing e.g. secure

	 * regs (the same mode all CPUs are booted to - usually HYP)

 Power-up the CPU */

 SPDX-License-Identifier: GPL-2.0-only

 buffers in highmem or foreign pages cannot cross page boundaries */

/*

 * Dom0 is mapped 1:1, and while the Linux page can span across multiple Xen

 * pages, it is not possible for it to contain a mix of local and foreign Xen

 * pages.  Calling pfn_valid on a foreign mfn will always return false, so if

 * pfn_valid returns true the pages is local and we can use the native

 * dma-direct functions, otherwise we call the Xen specific version.

	/*

	 * The swiotlb buffer should be used if

	 *	- Xen doesn't have the cache flush hypercall

	 *	- The Linux page refers to foreign memory

	 *	- The device doesn't support coherent DMA request

	 *

	 * The Linux page may be spanned acrros multiple Xen page, although

	 * it's not possible to have a mix of local and foreign Xen page.

	 * Furthermore, range_straddles_page_boundary is already checking

	 * if buffer is physically contiguous in the host RAM.

	 *

	 * Therefore we only need to check the first Xen page to know if we

	 * require a bounce buffer because the device doesn't support coherent

	 * memory and we are not able to flush the cache.

 we assume that dom0 is mapped 1:1 for now */

 we can work with the default swiotlb */

/******************************************************************************

 * grant_table.c

 * ARM specific part

 *

 * Granting foreign access to our memory reservation.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License version 2

 * as published by the Free Software Foundation; or, when distributed

 * separately from the Linux kernel or incorporated into other

 * software packages, subject to the following license:

 *

 * Permission is hereby granted, free of charge, to any person obtaining a copy

 * of this source file (the "Software"), to deal in the Software without

 * restriction, including without limitation the rights to use, copy, modify,

 * merge, publish, distribute, sublicense, and/or sell copies of the Software,

 * and to permit persons to whom the Software is furnished to do so, subject to

 * the following conditions:

 *

 * The above copyright notice and this permission notice shall be included in

 * all copies or substantial portions of the Software.

 *

 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR

 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,

 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE

 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER

 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING

 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS

 * IN THE SOFTWARE.

 SPDX-License-Identifier: GPL-2.0-only

 Linux <-> Xen vCPU id mapping */

 These are unused until we support booting "pre-ballooned" */

 get wallclock at system boot */

 fetch version before time */

 fetch time before checking version */

 time since system boot */

 Protected by the calling core code serialization */

	/*

	 * We only take the expensive HV call when the clock was set

	 * or when the 11 minutes RTC synchronization time elapsed.

	/*

	 * Move the next drift compensation time 11 minutes

	 * ahead. That's emulating the sync_cmos_clock() update for

	 * the hardware RTC.

	/* 

	 * VCPUOP_register_vcpu_info cannot be called twice for the same

	 * vcpu, so if vcpu_info is already registered, just get out. This

	 * can happen with cpu-hotplug.

	/*

	 * Check if Xen supports EFI by checking whether there is the

	 * "/hypervisor/uefi" node in DT. If so, runtime services are available

	 * through proxy functions (e.g. in case of Xen dom0 EFI implementation

	 * they call special hypercall which executes relevant EFI functions)

	 * and that is why they are always enabled.

/*

 * see Documentation/devicetree/bindings/arm/xen.txt for the

 * documentation of the Xen Device Tree format.

	/*

	 * The fdt parsing codes have set EFI_RUNTIME_SERVICES if Xen EFI

	 * parameters are found. Force enable runtime services.

	/* xen_vcpu is a pointer to the vcpu_info struct in the shared_info

	 * page, we use it in the event channel upcall and in some pvclock

	 * related functions. 

	 * The shared info contains exactly 1 CPU (the boot CPU). The guest

	 * is required to use VCPUOP_register_vcpu_info to place vcpu info

	 * for secondary CPUs as they are brought up.

	 * For uniformity we use VCPUOP_register_vcpu_info even on cpu0.

 Direct vCPU id mapping for ARM guests. */

	/*

	 * Making sure board specific code will not set up ops for

	 * cpu idle and cpu freq.

 empty stubs */

 In the hypercall.S file. */

 SPDX-License-Identifier: GPL-2.0-only

		/*

		 * Signal an error for this slot. This in turn requires

		 * immediate unmapping.

		/*

		 * Pre-populate the status field, to be recognizable in

		 * the log message below.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2012-2018 ARM Limited

 *

 * This supplies .note.* sections to go into the PT_NOTE inside the vDSO text.

 * Here we can supply some information useful to userland.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2015 Mentor Graphics Corporation.

 *

 * vdsomunge - Host program which produces a shared object

 * architecturally specified to be usable by both soft- and hard-float

 * programs.

 *

 * The Procedure Call Standard for the ARM Architecture (ARM IHI

 * 0042E) says:

 *

 *	6.4.1 VFP and Base Standard Compatibility

 *

 *	Code compiled for the VFP calling standard is compatible with

 *	the base standard (and vice-versa) if no floating-point or

 *	containerized vector arguments or results are used.

 *

 * And ELF for the ARM Architecture (ARM IHI 0044E) (Table 4-2) says:

 *

 *	If both EF_ARM_ABI_FLOAT_XXXX bits are clear, conformance to the

 *	base procedure-call standard is implied.

 *

 * The VDSO is built with -msoft-float, as with the rest of the ARM

 * kernel, and uses no floating point arguments or results.  The build

 * process will produce a shared object that may or may not have the

 * EF_ARM_ABI_FLOAT_SOFT flag set (it seems to depend on the binutils

 * version; binutils starting with 2.24 appears to set it).  The

 * EF_ARM_ABI_FLOAT_HARD flag should definitely not be set, and this

 * program will error out if it is.

 *

 * If the soft-float flag is set, this program clears it.  That's all

 * it does.

/* Some of the ELF constants we'd like to use were added to <elf.h>

 * relatively recently.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARM userspace implementations of gettimeofday() and similar.

 *

 * Copyright 2015 Mentor Graphics Corporation.

 Avoid unresolved references emitted by GCC */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/lib/xor-neon.c

 *

 * Copyright (C) 2013 Linaro Ltd <ard.biesheuvel@linaro.org>

/*

 * Pull in the reference implementations while instructing GCC (through

 * -ftree-vectorize) to attempt to exploit implicit parallelism and emit

 * NEON instructions.

/*

 * While older versions of GCC do not generate incorrect code, they fail to

 * recognize the parallel nature of these functions, and emit plain ARM code,

 * which is known to be slower than the optimized ARM code in asm-arm/xor.h.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/lib/uaccess_with_memcpy.c

 *

 *  Written by: Lennert Buytenhek and Nicolas Pitre

 *  Copyright (C) 2009 Marvell Semiconductor

 for in_atomic() */

	/*

	 * A pmd can be bad if it refers to a HugeTLB or THP page.

	 *

	 * Both THP and HugeTLB pages have the same pmd layout

	 * and should not be manipulated by the pte functions.

	 *

	 * Lock the page table for the destination and check

	 * to see that it's still huge and whether or not we will

	 * need to fault on write.

 the mmap semaphore is taken only if not in an atomic context */

	/*

	 * This test is stubbed out of the main function above to keep

	 * the overhead for small copies low by avoiding a large

	 * register dump on the stack just to reload them right away.

	 * With frame pointer disabled, tail call optimization kicks in

	 * as well making this test almost invisible.

 See rational for this in __copy_to_user() above. */

/*

 * This code is disabled by default, but kept around in case the chosen

 * thresholds need to be revalidated.  Some overhead (small but still)

 * would be implied by a runtime determined variable threshold, and

 * so far the measurement on concerned targets didn't show a worthwhile

 * variation.

 *

 * Note that a fairly precise sched_clock() implementation is needed

 * for results to make some sense.

 warm up the src page dcache */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Delay loops based on the OpenRISC implementation.

 *

 * Copyright (C) 2012 ARM Limited

 *

 * Author: Will Deacon <will.deacon@arm.com>

/*

 * Default to the loop-based delay implementation.

 cpufreq may scale loops_per_jiffy, so keep a private copy */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Setup code for AT91SAM9

 *

 *  Copyright (C) 2011 Atmel,

 *                2011 Nicolas Ferre <nicolas.ferre@atmel.com>

 Maintainer: Atmel */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * arch/arm/mach-at91/pm.c

 * AT91 Power Management

 *

 * Copyright (C) 2005 David Brownell

/**

 * struct at91_pm_bu - AT91 power management backup unit data structure

 * @suspended: true if suspended to backup mode

 * @reserved: reserved

 * @canary: canary data for memory checking after exit from backup mode

 * @resume: resume API

 * @ddr_phy_calibration: DDR PHY calibration data: ZQ0CR0, first 8 words

 * of the memory

/*

 * struct at91_pm_sfrbu_offsets: registers mapping for SFRBU

 * @pswbu: power switch BU control registers

/**

 * struct at91_soc_pm - AT91 SoC power management data structure

 * @config_shdwc_ws: wakeup sources configuration function for SHDWC

 * @config_pmc_ws: wakeup srouces configuration function for PMC

 * @ws_ids: wakup sources of_device_id array

 * @data: PM data to be used on last phase of suspend

 * @sfrbu_regs: SFRBU registers mapping

 * @bu: backup unit mapped data (for backup mode)

 * @memcs: memory chip select

/**

 * enum at91_pm_iomaps:	IOs that needs to be mapped for different PM modes

 * @AT91_PM_IOMAP_SHDWC:	SHDWC controller

 * @AT91_PM_IOMAP_SFRBU:	SFRBU controller

 sentinel */ }

 sentinel */ }

 sentinel */ }

 SHDWC.MR */

 Loop through defined wakeup sources. */

 Check if enabled on SHDWC. */

 SHDWC.WUIR */

/*

 * Called after processes are frozen, but before we shutdown devices.

/*

 * Verify that all the clocks are correct before entering

 * slow-clock mode.

 USB must not be using PLLB */

 PCK0..PCK3 must be disabled, or configured to use clk32k */

/*

 * Call this from platform driver suspend() to see how deeply to suspend.

 * For example, some controllers (like OHCI) need one of the PLL clocks

 * in order to act as a wakeup source, and those are not available when

 * going into slow clock mode.

 *

 * REVISIT: generalize as clk_will_be_available(clk)?  Other platforms have

 * the very same problem (but not using at91 main_clk), and it'd be better

 * to add one generic API rather than lots of platform-specific ones.

		/*

		 * The 1st 8 words of memory might get corrupted in the process

		 * of DDR PHY recalibration; it is saved here in securam and it

		 * will be restored later, after recalibration, by bootloader

 Just for safety. */

 Already on VBAT. */

 Wait for update. */

 The SRAM is lost between suspend cycles */

/*

 * STANDBY mode has *all* drivers suspended; ignores irqs not marked as 'wakeup'

 * event sources; and reduces DRAM power.  But otherwise it's identical to

 * PM_SUSPEND_ON: cpu idle, and nothing fancy done with main or cpu clocks.

 *

 * AT91_PM_ULP0 is like STANDBY plus slow clock mode, so drivers must

 * suspend more deeply, the master clock switches to the clk32k and turns off

 * the main oscillator

 *

 * AT91_PM_BACKUP turns off the whole SoC after placing the DDR in self refresh

	/*

	 * FIXME: this is needed to communicate between the pinctrl driver and

	 * the PM implementation in the machine. Possibly part of the PM

	 * implementation should be moved down into the pinctrl driver and get

	 * called as part of the generic suspend/resume path.

		/*

		 * Ensure that clocks are in a valid state.

/*

 * Called right prior to thawing processes.

/*

 * The AT91RM9200 goes into self-refresh mode with this command, and will

 * terminate self-refresh automatically on the next SDRAM access.

 *

 * Self-refresh mode is exited as soon as a memory access is made, but we don't

 * know for sure when that happens. However, we need to restore the low-power

 * mode if it was enabled before going idle. Restoring low-power mode while

 * still in self-refresh is "not recommended", but seems to work.

/* We manage both DDRAM/SDRAM controllers, we need more than one value to

 * remember.

	/* Those two values allow us to delay self-refresh activation

 LPDDR1 --> force DDR2 mode during self-refresh */

 self-refresh mode now */

/* We manage both DDRAM/SDRAM controllers, we need more than one value to

 * remember.

 self-refresh mode now */

sentinel*/ }

 Sentinel. */ },

 Lookup for DDR PHY node, if any. */

	/*

	 * Disable the processor clock.  The processor will be automatically

	 * re-enabled by an interrupt or by a reset.

 Copy the pm suspend handler to SRAM */

 Memory node already located. */

 We are scanning "memory" nodes only. */

 DDR3PHY_ZQ0SR0 */

 sentinel. */ }

 Use ULP0 if it doesn't needs SHDWC.*/

			/*

			 * Use ULP0 if it doesn't need SHDWC or if SHDWC

			 * was already located.

 Unmap all unnecessary. */

 sentinel */ },

	/*

	 * Force STANDBY and ULP0 mode to avoid calling

	 * at91_pm_modes_validate() which may increase booting time.

	 * Platform supports anyway only STANDBY and ULP0 modes.

	/*

	 * AT91RM9200 SDRAM low-power mode cannot be used with self-refresh.

	/*

	 * Force STANDBY and ULP0 mode to avoid calling

	 * at91_pm_modes_validate() which may increase booting time.

	 * Platform supports anyway only STANDBY and ULP0 modes.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Setup code for SAMA5

 *

 *  Copyright (C) 2013 Atmel,

 *                2013 Ludovic Desroches <ludovic.desroches@atmel.com>

 Maintainer: Atmel */

 Maintainer: Atmel */

 Maintainer: Atmel */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Setup code for SAMA7

 *

 * Copyright (C) 2021 Microchip Technology, Inc. and its subsidiaries

 *

 Maintainer: Microchip */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Setup code for SAM9X60.

 *

 * Copyright (C) 2019 Microchip Technology Inc. and its subsidiaries

 *

 * Author: Claudiu Beznea <claudiu.beznea@microchip.com>

 Maintainer: Microchip */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Setup code for SAMv7x

 *

 *  Copyright (C) 2013 Atmel,

 *                2016 Andras Szemzo <szemzo.andras@gmail.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Setup code for AT91RM9200

 *

 *  Copyright (C) 2011 Atmel,

 *                2011 Nicolas Ferre <nicolas.ferre@atmel.com>

 *                2012 Joachim Eastwood <manabian@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PM domain driver for Keystone2 devices

 *

 * Copyright 2013 Texas Instruments, Inc.

 *	Santosh Shilimkar <santosh.shillimkar@ti.com>

 *

 * Based on Kevins work on DAVINCI SOCs

 *	Kevin Hilman <khilman@linaro.org>

 end of list */ },

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Keystone2 based boards and SOC related code.

 *

 * Copyright 2013 Texas Instruments, Inc.

 *	Cyril Chemparathy <cyril@ti.com>

 *	Santosh Shilimkar <santosh.shillimkar@ti.com>

 CONFIG_ARM_LPAE */

 nothing to do if we are running out of the <32-bit space */

 Populate the arch idmap hook */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Keystone SOC SMP platform code

 *

 * Copyright 2013 Texas Instruments, Inc.

 *	Cyril Chemparathy <cyril@ti.com>

 *	Santosh Shilimkar <santosh.shillimkar@ti.com>

 *

 * Based on platsmp.c, Copyright (C) 2002 ARM Ltd.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright STMicroelectronics, 2007.

/*

 * These are the only hard-coded address offsets we still have to use.

 FSMC registers */

 SDRAM Controller */

 CLCD Controller */

 MDIF */

 DMA0 Controller */

 Vectored Irq Controller */

 DMA1 Controller */

 USB-OTG conf reg base */

 Crypto processor */

 SHA-1 Processor */

 XTI */

 Random number generator */

 SRC base */

 Watchdog */

 Multiple Timer 0 */

 Multiple Timer 1 */

 GPIO0 */

 GPIO1 */

 GPIO2 */

 GPIO3 */

 Real Time Clock base */

 Power Management Unit */

 One wire master */

 Secure Control registers */

 MSP 2 interface */

 MSP 1 interface */

 UART 2 interface */

 SSI 8-ch rx interface */

 SSI 8-ch tx interface */

 Memory Stick(Pro) Host */

 SD-card/MM-Card */

 I2C1 interface */

 I2C0 interface */

 MSP 0 interface */

 FIrDA interface */

 UART 1 interface */

 SSP interface */

 UART 0 interface */

 SGA interface */

 L2 Cache controller */

 This is needed for LL-debug/earlyprintk/debug-macro.S */

 FIXME: use egpio when implemented */

 Write anything to Reset status register */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2008 Cavium Networks

 Wait for 300us for the PLL output clock locked. */

 write '1' to power down */

	/*

	 * bit 0, 28, 29 => program low to reset,

	 * the other else program low and then high

 SPI/I2C/GPIO use the same block, reset once. */

	/*

	 * To reset, we hit the on-board reset register

	 * in the system FPGA.

/*

 * cns3xxx_cpu_clock - return CPU/L2 clock

 *  aclk: cpu clock/2

 *  hclk: cpu clock/4

 *  pclk: cpu clock/8

 SPDX-License-Identifier: GPL-2.0-only

/*

 * CNS3xxx common devices

 *

 * Copyright 2008 Cavium Networks

 *		  Scott Shu

 * Copyright 2010 MontaVista Software, LLC.

 *		  Anton Vorontsov <avorontsov@mvista.com>

/*

 * AHCI

 Disable SATA PHY 0 from SLUMBER Mode */

 Disable SATA PHY 1 from SLUMBER Mode */

 Enable SATA PHY */

 Enable SATA Clock */

 De-Asscer SATA Reset */

/*

 * SDHCI

 MMC/SD pins share with GPIOA */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 1999 - 2003 ARM Limited

 * Copyright 2000 Deep Blue Solutions Ltd

 * Copyright 2008 Cavium Networks

 really 4 KiB at offset 32 KiB */

 really 4 KiB at offset 32 KiB */

 used by entry-macro.S */

 Hibernate */

/*

 * Timer

 period set, and timer enabled in 'next_event' hook */

/*

 * IRQ handler for the timer

 Clear the interrupt */

/*

 * Set up the clock source and clock events devices

	/*

	 * Initialise to a known state (all timers off)

 disable timer1 and timer2 */

 stop free running timer3 */

 timer1 */

 mask irq, non-mask timer1 overflow */

 down counter */

 timer2 */

 mask irq */

 down counter */

 Make irqs happen for the system timer */

	/*

	 * Tag RAM Control register

	 *

	 * bit[10:8]	- 1 cycle of write accesses latency

	 * bit[6:4]	- 1 cycle of read accesses latency

	 * bit[3:0]	- 1 cycle of setup latency

	 *

	 * 1 cycle of latency for setup, read and write accesses

	/*

	 * Data RAM Control register

	 *

	 * bit[10:8]	- 1 cycles of write accesses latency

	 * bit[6:4]	- 1 cycles of read accesses latency

	 * bit[3:0]	- 1 cycle of setup latency

	 *

	 * 1 cycle of latency for setup, read and write accesses

 32 KiB, 8-way, parity disable */

 CONFIG_CACHE_L2X0 */

	/*

	 * EHCI and OHCI share the same clock and power,

	 * resetting twice would cause the 1st controller been reset.

	 * Therefore only do power up  at the first up device, and

	 * power down at the last down device.

	 *

	 * Set USB AHB INCR length to 16

	/*

	 * EHCI and OHCI share the same clock and power,

	 * resetting twice would cause the 1st controller been reset.

	 * Therefore only do power up  at the first up device, and

	 * power down at the last down device.

 Disable SATA PHY 0 from SLUMBER Mode */

 Disable SATA PHY 1 from SLUMBER Mode */

 Enable SATA PHY */

 Enable SATA Clock */

 De-Asscer SATA Reset */

 MMC/SD pins share with GPIOA */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Cavium Networks CNS3420 Validation Board

 *

 * Copyright 2000 Deep Blue Solutions Ltd

 * Copyright 2008 ARM Limited

 * Copyright 2008 Cavium Networks

 *		  Scott Shu

 * Copyright 2010 MontaVista Software, LLC.

 *		  Anton Vorontsov <avorontsov@mvista.com>

/*

 * NOR Flash

/*

 * UART

/*

 * USB

	/*

	 * EHCI and OHCI share the same clock and power,

	 * resetting twice would cause the 1st controller been reset.

	 * Therefore only do power up  at the first up device, and

	 * power down at the last down device.

	 *

	 * Set USB AHB INCR length to 16

	/*

	 * EHCI and OHCI share the same clock and power,

	 * resetting twice would cause the 1st controller been reset.

	 * Therefore only do power up  at the first up device, and

	 * power down at the last down device.

/*

 * Initialization

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PCI-E support for CNS3xxx

 *

 * Copyright 2008 Cavium Networks

 *		  Richard Liu <richard.liu@caviumnetworks.com>

 * Copyright 2010 MontaVista Software, LLC.

 *		  Anton Vorontsov <avorontsov@mvista.com>

 PCI config registers for host bridge */

 PCI Type 0 config registers */

 PCI Type 1 config registers */

 If there is no link, just show the CNS PCI bridge. */

	/*

	 * The CNS PCI bridge doesn't fit into the PCI hierarchy, though

	 * we still want to access it.

	 * We place the host bridge on bus 0, and the directly connected

	 * device on bus 1, slot 0.

 internal PCIe bus, host bridge device */

 device# and function# are ignored by hw */

 no such device */

 directly connected PCIe device */

 device# is ignored by hw */

 no such device */

 remote PCI bus */

		/*

		 * RC's class is 0xb, but Linux PCI driver needs 0x604

		 * for a PCIe bridge. So we must fixup the class code

		 * to 0x604 here.

 16 MiB */

 176 MiB */

 16 MiB */

 176 MiB */

	/*

	 * Enable Application Request to 1, it will exit L1 automatically,

	 * but when chip back, it will use another clock, still can use 0x1.

 Set Device Max_Read_Request_Size to 128 byte */

 Disable PCIe0 Interrupt Mask INTA to INTD */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/plat-omap/sram.c

 *

 * OMAP SRAM detection and management

 *

 * Copyright (C) 2005 Nokia Corporation

 * Written by Tony Lindgren <tony@atomide.com>

 *

 * Copyright (C) 2009-2012 Texas Instruments

 * Added OMAP4/5 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

/*

 * Memory allocator for SRAM: calculates the new ceiling address

 * for pushing a function using the fncpy API.

 *

 * Note that fncpy requires the returned address to be aligned

 * to an 8-byte boundary.

/*

 * The SRAM context is lost during off-idle and stack

 * needs to be reset.

/*

 * Note that we cannot use ioremap for SRAM, as clock init needs SRAM early.

	/*

	 * Looks like we need to preserve some bootloader code at the

	 * beginning of SRAM for jumping to flash for reboot to work...

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/plat-omap/dma.c

 *

 * Copyright (C) 2003 - 2008 Nokia Corporation

 * Author: Juha Yrjl <juha.yrjola@nokia.com>

 * DMA channel linking for 1610 by Samuel Ortiz <samuel.ortiz@nokia.com>

 * Graphics DMA and LCD DMA graphics tranformations

 * by Imre Deak <imre.deak@nokia.com>

 * OMAP2/3 support Copyright (C) 2004-2007 Texas Instruments, Inc.

 * Merged to support both OMAP1 and OMAP2 by Tony Lindgren <tony@atomide.com>

 * Some functions based on earlier dma-omap.c Copyright (C) 2001 RidgeRun, Inc.

 *

 * Copyright (C) 2009 Texas Instruments

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * Support functions for the OMAP internal DMA channels.

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 * Converted DMA library into DMA platform driver.

 *	- G, Manjunath Kondaiah <manjugk@ti.com>

/*

 * MAX_LOGICAL_DMA_CH_COUNT: the maximum number of logical DMA

 * channels that an instance of the SDMA IP block can support.  Used

 * to size arrays.  (The actual maximum on a particular SoC may be less

 * than this -- for example, OMAP1 SDMA instances only support 17 logical

 * DMA channels.)

 Returns 1 if the DMA module is in OMAP1510-compatible mode, 0 otherwise */

 FFFECC00 */

 FFFECCD0 */

 FFFECC08 */

 FFFECC04 */

 DMA_SYNCHRO_CONTROL_UPPER depends on the channel number */

 dest synch */

 Prefetch */

 source synch */

 dest synch */

 Note that src_port is only for omap1 */

		/*

		 * not supported by current hardware on OMAP1

		 * w |= (0x03 << 7);

 OMAP1 don't support burst 16 */

 Note that dest_port is only for OMAP1 */

 OMAP1 don't support burst 16 */

 Clear CSR */

 Enable some nice interrupts. */

 disable channel interrupts */

 Clear CSR */

 Set the ENABLE_LNK bits */

 Disable interrupts */

 Set the STOP_LNK bit */

 Clear the ENABLE_LNK bit */

 Exit after first free channel found */

 If the sync device is set, configure it dynamically. */

		/*

		 * Disable the 1510 compatibility mode and set the sync device

		 * id.

 Disable all DMA interrupts for the channel. */

 Make sure the DMA transfer is stopped. */

/*

 * Clears any DMA state so the DMA engine is ready to restart with new buffers

 * through omap_start_dma(). Any buffers in flight are discarded.

	/*

	 * The CPC/CDAC register needs to be initialized to zero

	 * before starting dma transfer.

 Set the link register of the first channel */

 The loop case: we've been here already */

 Mark the current channel */

	/*

	 * As dma_write() uses IO accessors which are weakly ordered, there

	 * is no guarantee that data in coherent DMA memory will be visible

	 * to the DMA device.  Add a memory barrier here to ensure that any

	 * such data is visible prior to enabling DMA.

 Disable all interrupts on the channel */

 Configure No-Standby */

 Wait for sDMA FIFO drain */

 Restore OCP_SYSCONFIG */

	/*

	 * Ensure that data transferred by DMA is visible to any access

	 * after DMA has been disabled.  This is important for coherent

	 * DMA regions.

 The loop case: we've been here already */

 Mark the current channel */

/*

 * Allows changing the DMA callback function or data. This may be needed if

 * the driver shares a single DMA channel for multiple dma triggers.

/*

 * Returns current physical source address for the given DMA channel.

 * If the channel is running the caller must disable interrupts prior calling

 * this function and process the returned value before re-enabling interrupt to

 * prevent races with the interrupt handler. Note that in continuous mode there

 * is a chance for CSSA_L register overflow between the two reads resulting

 * in incorrect return value.

		/*

		 * CDAC == 0 indicates that the DMA transfer on the channel has

		 * not been started (no data has been transferred so far).

		 * Return the programmed source start address in this case.

/*

 * Returns current physical destination address for the given DMA channel.

 * If the channel is running the caller must disable interrupts prior calling

 * this function and process the returned value before re-enabling interrupt to

 * prevent races with the interrupt handler. Note that in continuous mode there

 * is a chance for CDSA_L register overflow between the two reads resulting

 * in incorrect return value.

	/*

	 * omap 3.2/3.3 erratum: sometimes 0 is returned if CSAC/CDAC is

	 * read before the DMA controller finished disabling the channel.

		/*

		 * CDAC == 0 indicates that the DMA transfer on the channel has

		 * not been started (no data has been transferred so far).

		 * Return the programmed destination start address in this case.

----------------------------------------------------------------------------*/

			/*

			 * request_irq() doesn't like dev_id (ie. ch) being

			 * zero, so we have to kludge around this.

 INT_DMA_LCD is handled in lcd_dma.c */

 reserve dma channels 0 and 1 in high security devices on 34xx */

/*

 * Reserve the omap SDMA channels using cmdline bootarg

 * "omap_dma_reserve_ch=". The valid range is 1 to 32

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP 32ksynctimer/counter_32k-related code

 *

 * Copyright (C) 2009 Texas Instruments

 * Copyright (C) 2010 Nokia Corporation

 * Tony Lindgren <tony@atomide.com>

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * NOTE: This timer is not the same timer as the old OMAP1 MPU timer.

 OMAP2_32KSYNCNT_CR_OFF: offset of 32ksync counter register */

/*

 * 32KHz clocksource ... always available, on pretty most chips except

 * OMAP 730 and 1510.  Other timers could be used as clocksources, with

 * higher resolution in free-running counter modes (e.g. 12 MHz xtal),

 * but systems won't necessarily want to spend resources that way.

/**

 * omap_read_persistent_clock64 -  Return time from a persistent clock.

 *

 * Reads the time from a source which isn't disabled during PM, the

 * 32k sync timer.  Convert the cycles elapsed since last read into

 * nsecs and adds to a monotonically increasing timespec64.

/**

 * omap_init_clocksource_32k - setup and register counter 32k as a

 * kernel clocksource

 * @pbase: base addr of counter_32k module

 * @size: size of counter_32k to map

 *

 * Returns 0 upon success or negative error code upon failure.

 *

	/*

	 * 32k sync Counter IP register offsets vary between the

	 * highlander version and the legacy ones.

	 * The 'SCHEME' bits(30-31) of the revision register is used

	 * to identify the version.

	/*

	 * 120000 rough estimate from the calculations in

	 * __clocksource_update_freq_scale.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/plat-omap/debug-leds.c

 *

 * Copyright 2011 by Bryan Wu <bryan.wu@canonical.com>

 * Copyright 2003 by Texas Instruments Incorporated

/* Many OMAP development platforms reuse the same "debug board"; these

 * platforms include H2, H3, H4, and Perseus2.  There are 16 LEDs on the

 * debug board (all green), accessed through FPGA registers.

 NOTE:  most boards don't have a static mapping for the FPGA ... */

 offset 0x00 */

 offset 0x10 */

 offset 0x18 */

 offset 0x20 */

 plus also 4 rs232 ports ... */

/*

 * The triggers lines up below will only be used if the

 * LED triggers are compiled in.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Zynq power management

 *

 *  Copyright (C) 2012 - 2014 Xilinx

 *

 *  Sren Brinkmann <soren.brinkmann@xilinx.com>

 register offsets */

 bitfields */

/**

 * zynq_pm_ioremap() - Create IO mappings

 * @comp:	DT compatible string

 * Return: Pointer to the mapped memory or NULL.

 *

 * Remap the memory region for a compatible DT node.

/**

 * zynq_pm_late_init() - Power management init

 *

 * Initialization of power management related features and infrastructure.

		/*

		 * Enable DDRC clock stop feature. The HW takes care of

		 * entering/exiting the correct mode depending

		 * on activity state.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This file contains Xilinx specific SMP code, used to start up

 * the second processor.

 *

 * Copyright (C) 2011-2013 Xilinx

 *

 * based on linux/arch/arm/mach-realview/platsmp.c

 *

 * Copyright (C) 2002 ARM Ltd.

/*

 * Store number of cores in the system

 * Because of scu_get_core_count() must be in __init section and can't

 * be called from zynq_cpun_start() because it is not in __init section.

 MS: Expectation that SLCR are directly map and accessible */

 Not possible to jump to non aligned address */

 Store pointer to ioremap area which points to address 0x0 */

			/*

			* This is elegant way how to jump to any address

			* 0x0: Load address at 0x8 to r0

			* 0x4: Jump by mov instruction

			* 0x8: Jumping address

/*

 * Initialise the CPU possible map early - this describes the CPUs

 * which may be present or become present in the system.

/**

 * zynq_secondary_init - Initialize secondary CPU cores

 * @cpu:	CPU that is initialized

 *

 * This function is in the hotplug path. Don't move it into the

 * init section!!

/**

 * zynq_cpu_die - Let a CPU core die

 * @cpu:	Dying CPU

 *

 * Platform-specific code to shutdown a CPU.

 * Called with IRQs disabled on the dying CPU.

	/*

	 * there is no power-control hardware on this platform, so all

	 * we can do is put the core into WFI; this is safe as the calling

	 * code will have already disabled interrupts

 SPDX-License-Identifier: GPL-2.0-only

/*

 * This file contains common code that is intended to be used across

 * boards so that it's not replicated.

 *

 *  Copyright (C) 2011 Xilinx

/**

 * zynq_memory_init - Initialize special memory

 *

 * We need to stop things allocating the low memory as DMA can't work in

 * the 1st 512K of memory.

/**

 * zynq_get_revision - Get Zynq silicon revision

 *

 * Return: Silicon version or -1 otherwise

/**

 * zynq_init_machine - System specific initialization, intended to be

 *		       called from board specific initialization.

	/*

	 * Finished with the static registrations now; fill in the missing

	 * devices

 Expected address is in vmalloc area that's why simple assign here */

/**

 * zynq_map_io - Create memory mappings needed for early I/O.

 64KB way size, 8-way associativity, parity disabled */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Xilinx SLCR driver

 *

 * Copyright (c) 2011-2013 Xilinx Inc.

 register offsets */

 SCLR unlock register */

 PS Software Reset Control */

 CPU Software Reset Control */

 PS Reboot Status */

 PS IDCODE */

 L2C_RAM in AR#54190 */

/**

 * zynq_slcr_write - Write to a register in SLCR block

 *

 * @val:	Value to write to the register

 * @offset:	Register offset in SLCR block

 *

 * Return:	a negative value on error, 0 on success

/**

 * zynq_slcr_read - Read a register in SLCR block

 *

 * @val:	Pointer to value to be read from SLCR

 * @offset:	Register offset in SLCR block

 *

 * Return:	a negative value on error, 0 on success

/**

 * zynq_slcr_unlock - Unlock SLCR registers

 *

 * Return:	a negative value on error, 0 on success

/**

 * zynq_slcr_get_device_id - Read device code id

 *

 * Return:	Device code id

/**

 * zynq_slcr_system_restart - Restart the entire system.

 *

 * @nb:		Pointer to restart notifier block (unused)

 * @action:	Reboot mode (unused)

 * @data:	Restart handler private data (unused)

 *

 * Return:	0 always

	/*

	 * Clear 0x0F000000 bits of reboot status register to workaround

	 * the FSBL not loading the bitstream after soft-reboot

	 * This is a temporary solution until we know more.

/**

 * zynq_slcr_cpu_start - Start cpu

 * @cpu:	cpu number

/**

 * zynq_slcr_cpu_stop - Stop cpu

 * @cpu:	cpu number

/**

 * zynq_slcr_cpu_state - Read/write cpu state

 * @cpu:	cpu number

 *

 * SLCR_REBOOT_STATUS save upper 2 bits (31/30 cpu states for cpu0 and cpu1)

 * 0 means cpu is running, 1 cpu is going to die.

 *

 * Return: true if cpu is running, false if cpu is going to die

/**

 * zynq_slcr_cpu_state - Read/write cpu state

 * @cpu:	cpu number

 * @die:	cpu state - true if cpu is going to die

 *

 * SLCR_REBOOT_STATUS save upper 2 bits (31/30 cpu states for cpu0 and cpu1)

 * 0 means cpu is running, 1 cpu is going to die.

/**

 * zynq_early_slcr_init - Early slcr init function

 *

 * Return:	0 on success, negative errno otherwise.

 *

 * Called very early during boot from platform code to unlock SLCR.

 unlock the SLCR so that registers can be changed */

 See AR#54190 design advisory */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2012 Sascha Hauer, Pengutronix

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Freescale Semiconductor, Inc.

 WFI */

 WAIT */

/*

 * i.MX6 Q/DL has an erratum (ERR006687) that prevents the FEC from waking the

 * CPUs when they are in wait(unclocked) state. As the hardware workaround isn't

 * applicable to all boards, disable the deeper idle state when the workaround

 * isn't present and the FEC is in use.

 Set INT_MEM_CLK_LPM bit to get a reliable WAIT mode support */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2018 Pengutronix, Oleksij Rempel <o.rempel@pengutronix.de>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) BitBox Ltd 2010

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 1999 ARM Limited

 * Copyright (C) 2000 Deep Blue Solutions Ltd

 * Copyright 2006-2007 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2008 Juergen Beisert, kernel@pengutronix.de

 * Copyright 2009 Ilya Yanok, Emcraft Systems Ltd, yanok@emcraft.com

/*

 * Reset the system. It is called by machine_restart().

 Assert SRS signal */

	/*

	 * Due to imx6q errata ERR004346 (WDOG: WDOG SRS bit requires to be

	 * written twice), we add another two writes to ensure there must be at

	 * least two writes happen in the same one 32kHz clock period.  We save

	 * the target check here, since the writes shouldn't be a huge burden

	 * for other platforms.

 wait for reset to assert... */

 delay to allow the serial port to show the message */

 we'll take a jump through zero as a poor second */

 Configure the L2 PREFETCH and POWER registers */

 Set perfetch offset to improve performance */

/*

 * i.MX27 Power Management Routines

 *

 * Based on Freescale's BSP

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License.

 Clear MPEN and SPEN to disable MPLL/SPLL */

 Executes WFI */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 1999,2000 Arm Limited

 *  Copyright (C) 2000 Deep Blue Solutions Ltd

 *  Copyright (C) 2002 Shane Nay (shane@minirl.com)

 *  Copyright 2005-2007 Freescale Semiconductor, Inc. All Rights Reserved.

 *    - add MX31 specific definitions

 disable I and D cache */

 invalidate I cache */

 clear and invalidate D cache */

 WFI */

 enable I and D cache */

		/*

		 * Access all peripherals below 0x80000000 as nonshared device

		 * on mx3, but leave l2cc alone.  Otherwise cache corruptions

		 * can occur.

/*

 * This function initializes the memory map. It is called during the

 * system startup to create static physical to virtual memory mappings

 * for the IO modules.

 ifdef CONFIG_SOC_IMX31 */

 ifdef CONFIG_SOC_IMX35 */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2011 Linaro Ltd.

/*

 * The MIPI HSC unit has been removed from the i.MX51 Reference Manual by

 * the Freescale marketing division. However this did not remove the

 * hardware from the chip which still needs to be configured for proper

 * IPU support.

 setup MIPI module to legacy mode */

 CSI mode: reserved; DI control mode: legacy (from Freescale BSP) */

	/*

	 * Configure VPU and IPU with higher priorities

	 * in order to avoid artifacts during video playback

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2013-2015 Freescale Semiconductor, Inc.

 * Copyright 2017-2018 NXP.

 Below MISC0_DISCON_HIGH_SNVS is only for i.MX6SL */

 can only be enabled when stop_mode_config is clear. */

	/*

	 * On i.MX7D digprog value match linux version format, so

	 * it needn't map again and we can use register value directly.

		/*

		 * MAJOR: [15:8], the major silicon revison;

		 * MINOR: [7: 0], the minor silicon revison;

		 *

		 * please refer to the i.MX RM for the detailed

		 * silicon revison bit define.

		 * format the major part and minor part to match the

		 * linux kernel soc version format.

 src_sbmr2 bit 6 is to identify if it is i.MX6ULZ */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011-2013 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

 Tell GPC to power off ARM core when suspend */

 Keep ARM core powered on for other low-power modes */

	/*

	 * Do *not* call into the parent, as the GIC doesn't have any

	 * wake-up facility...

 No PPI should point to this domain */

 Not GIC compliant */

 No PPI should point to this domain */

 Can't deal with this */

 Initially mask all interrupts */

	/*

	 * Clear the OF_POPULATED flag set in of_irq_init so that

	 * later the GPC power domain driver will not be skipped.

 map GPC, so that at least CPUidle and WARs keep working */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2012-2013 Freescale Semiconductor, Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * Set all MPROTx to be non-bufferable, trusted for R/W,

 * not forced to user-mode.

/*

 * Set all OPACRx to be non-bufferable, to not require

 * supervisor privilege level for access, allow for

 * write access and untrusted master access.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2012 Sascha Hauer, Pengutronix

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011-2014 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

/*

 * suspend ocram space layout:

 * ======================== high address ======================

 *                              .

 *                              .

 *                              .

 *                              ^

 *                              ^

 *                              ^

 *                      imx6_suspend code

 *              PM_INFO structure(imx6_cpu_pm_info)

 * ======================== low address =======================

 DQM0 ~ DQM3 */

 DQM4 ~ DQM7 */

 CAS, RAS, SDCLK_0, SDCLK_1 */

 SDQS0 ~ SDQS3 */

 SDQS4 ~ SDQS7 */

 GPR_B0DS ~ GPR_B3DS */

 GPR_B4DS ~ GPR_B7DS */

 SODT0, SODT1, MODE_CTL, MODE */

 GPR_ADDS */

 DQM0 ~ DQM3 */

 DQM4 ~ DQM7 */

 CAS, RAS, SDCLK_0, SDCLK_1 */

 DRAM_SDQS0 ~ DRAM_SDQS3 */

 DRAM_SDQS4 ~ DRAM_SDQS7 */

 GPR_B0DS ~ GPR_B3DS */

 GPR_B4DS ~ GPR_B7DS */

 SODT0, SODT1, MODE_CTL, MODE */

 GPR_ADDS */

 DQM0 ~ DQM3 */

 GPR_B0DS ~ GPR_B3DS */

 CAS, RAS, SDCLK_0, GPR_ADDS */

 SODT0, SODT1, MODE_CTL, MODE */

 SDCKE0, SDCKE1, RESET */

 DQM0 ~ DQM3 */

 GPR_B0DS ~ GPR_B3DS */

 MODE_CTL, MODE, SDCLK_0, GPR_ADDDS */

 SDCKE0, SDCKE1*/

 DQM0 ~ DQM3 */

 GPR_B0DS ~ GPR_B3DS */

 CAS, RAS, SDCLK_0, GPR_ADDS */

 SODT0, SODT1, MODE_CTL, MODE */

 SDQS0 ~ SDQS3 */

 DQM0, DQM1, RAS, CAS */

 SDCLK0, GPR_B0DS-B1DS, GPR_ADDS */

 SDQS0~1, SODT0, SODT1 */

 MODE_CTL, MODE, */

/*

 * This structure is for passing necessary data for low level ocram

 * suspend code(arch/arm/mach-imx/suspend-imx6.S), if this struct

 * definition is changed, the offset definition in

 * arch/arm/mach-imx/suspend-imx6.S must be also changed accordingly,

 * otherwise, the suspend to ocram function will be broken!

 The physical address of pm_info. */

 The physical resume address for asm code */

 Size of pm_info. */

 Number of MMDC IOs which need saved/restored. */

 To save offset and value */

	/*

	 * need to mask all interrupts in GPC before

	 * operating RBC configurations

 configure RBC enable bit */

 configure RBC count */

	/*

	 * need to delay at least 2 cycles of CKIL(32K)

	 * due to hardware design requirement, which is

	 * ~61us, here we use 65us for safe

 restore GPC interrupt mask settings */

 configure well bias enable bit */

 configure well bias count */

	/*

	 * ERR007265: CCM: When improper low-power sequence is used,

	 * the SoC enters low power mode before the ARM core executes WFI.

	 *

	 * Software workaround:

	 * 1) Software should trigger IRQ #32 (IOMUX) to be always pending

	 *    by setting IOMUX_GPR1_GINT.

	 * 2) Software should then unmask IRQ #32 in GPC before setting CCM

	 *    Low-Power mode.

	 * 3) Software should mask IRQ #32 right after CCM Low-Power mode

	 *    is set (set bits 0-1 of CCM_CLPCR).

	 *

	 * Note that IRQ #32 is GIC SPI #0.

		/*

		 * call low level suspend function in ocram,

		 * as we need to float DDR IO.

 check if need to flush internal L2 cache */

 Zzz ... */

		/*

		 * For suspend into ocram, asm code already take care of

		 * RBC setting, so we do NOT need to do that here.

 Zzz ... */

	/*

	 * ccm physical address is not used by asm code currently,

	 * so get ccm virtual address directly.

	/*

	 * This is for SW workaround step #1 of ERR007265, see comments

	 * in imx6_set_lpm for details of this errata.

	 * Force IOMUXC irq pending, so that the interrupt to GPC can be

	 * used to deassert dsm_request signal when the signal gets

	 * asserted unexpectedly.

	/*

	 * Initialize CCM_CLPCR_LPM into RUN mode to avoid ARM core

	 * clock being shut down unexpectedly by WAIT mode.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Freescale Semiconductor, Inc.

	/*

	 * for Cortex-A7 which has an internal L2

	 * cache, need to flush it before powering

	 * down ARM platform, since flushing L1 cache

	 * here again has very small overhead, compared

	 * to adding conditional code for L2 cache type,

	 * just call flush_cache_all() is fine.

 Need to notify there is a cpu pm operation. */

 WFI */

 WAIT */

 WAIT + ARM power off  */

			/*

			 * ARM gating 31us * 5 + RBC clear 65us

			 * and some margin for SW execution, here set it

			 * to 300us.

	/*

	 * set ARM power up/down timing to the fastest,

	 * sw2iso and sw can be set to one 32K cycle = 31us

	 * except for power up sw2iso which need to be

	 * larger than LDO ramp up time.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2011 Linaro Ltd.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * MX25 CPU type detection

 *

 * Copyright (c) 2009 Daniel Mack <daniel@caiaq.de>

 * Copyright (C) 2011 Freescale Semiconductor, Inc. All Rights Reserved

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * MX35 CPU type detection

 *

 * Copyright (c) 2009 Daniel Mack <daniel@caiaq.de>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

 .virtual and .pfn are run-time assigned */

 Get SCU base */

/*

 * Initialise the CPU possible map early - this describes the CPUs

 * which may be present or become present in the system.

	/*

	 * The diagnostic register holds the errata bits.  Mostly bootloader

	 * does not bring up secondary cores, so that when errata bits are set

	 * in bootloader, they are set only for boot cpu.  But on a SMP

	 * configuration, it should be equally done on every single core.

	 * Read the register from boot cpu here, and will replicate it into

	 * secondary cores when booting them.

/*

 * Initialise the CPU possible map early - this describes the CPUs

 * which may be present or become present in the system.

 The iMX7D SCU does not report core count, get it from DT */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2008-2010 Freescale Semiconductor, Inc. All Rights Reserved.

 *

 * This file contains the CPU initialization code.

/*

 * Returns:

 *	the silicon revision of the cpu

/*

 * All versions of the silicon before Rev. 3 have broken NEON implementations.

 * Dependent on link order - so the assumption is that vfp_init is called

 * before us.

/*

 * Returns:

 *	the silicon revision of the cpu

/*

 * This enables the DBGEN bit in ARM_GPC register, which is

 * required for accessing some performance counter features.

 * Technically it is only required while perf is used, but to

 * keep the source code simple we just enable it all the time

 * when the kernel configuration allows using the feature.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2012 Sascha Hauer, Pengutronix

 MX27 memory map definition */

	/*

	 * this fixed mapping covers:

	 * - AIPI1

	 * - AIPI2

	 * - AITC

	 * - ROM Patch

	 * - and some reserved space

	/*

	 * this fixed mapping covers:

	 * - CSI

	 * - ATA

	/*

	 * this fixed mapping covers:

	 * - EMI

/*

 * Initialize the memory map. It is called during the

 * system startup to create static physical to virtual

 * memory map for the IO modules.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

/*

 * platform-specific code to shutdown a CPU

 *

 * Called with IRQs disabled

	/*

	 * We use the cpu jumping argument register to sync with

	 * imx_cpu_kill() which is running on cpu0 and waiting for

	 * the register being cleared to kill the cpu.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2017 NXP

 * Copyright 2011,2016 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

 Enables, resets, freezes, overflow profiling*/

 sentinel */ }

/*

 * Polling period is set to one second, overflow of total-cycles (the fastest

 * increasing counter) takes ten seconds so one second is safe

/*

 * Each event has a single fixed-purpose counter, so we can only have a

 * single active event for each at any point in time. Here we just check

 * for duplicates, and rely on mmdc_pmu_event_init to verify that the HW

 * event numbers are valid.

	/*

	 * hrtimer is required because mmdc does not provide an interrupt so

	 * polling is necessary

	/*

	 * Write the AXI id parameter to MADPCR1.

 The first instance registers the hotplug state */

 Register the pmu instance for cpu hotplug */

 the ipg clock is optional */

 Get ddr type */

 Enable automatic power saving */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Freescale Semiconductor, Inc.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2004-2007 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2008 Juergen Beisert, kernel@pengutronix.de

 int control reg */

 int mask reg */

 int enable number reg */

 int disable number reg */

 int enable reg high */

 int enable reg low */

 int type reg high */

 int type reg low */

 int priority */

 norm int vector/status */

 fast int vector/status */

 int source reg high */

 int source reg low */

 int force reg high */

 int force reg low */

 norm int pending high */

 norm int pending low */

 fast int pending high */

 fast int pending low */

 low power interrupt mask registers */

 CONFIG_FIQ */

		/*

		 * The interrupts which are still enabled will be used as wakeup

		 * sources. Allow those interrupts in low-power mode.

		 * The LPIMR registers use 0 to allow an interrupt, the AVIC

		 * registers use 1.

/*

 * This function initializes the AVIC hardware and disables all the

 * interrupts. It registers the interrupt enable and disable functions

 * to the kernel for each interrupt source.

		/*

		 * By default, we mask all interrupts. We set the actual mask

		 * before we go into low-power mode.

	/* put the AVIC into the reset value with

	 * all interrupts disabled

 disable all interrupts */

 all IRQ no FIQ */

 Set default priority value (0) for all IRQ's */

 Initialize FIQ */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Freescale Semiconductor, Inc.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011-2013 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

 For imx6q sabrelite board: set KSZ9021RN RGMII pad skew */

 min rx data delay */

 max rx/tx clock delay, min rx/tx control delay */

/*

 * fixup for PLX PEX8909 bridge to configure GPIO1-7 as output High

 * as they are used for slots1-7 PERST#

 GPIO1-7 outputs

 GPIO1-7 output high

	/*

	 * If enet_ref from ANATOP/CCM is the PTP clock source, we need to

	 * set bit IOMUXC_GPR1[21].  Or the PTP clock must be from pad

	 * (external OSC), and we need to clear the bit.

		/*

		 * Enable the cacheable attribute of VPU and IPU

		 * AXI transactions.

 Increase IPU read QoS priority */

		/*

		 * SoCs that identify as i.MX6Q >= rev 2.0 are really i.MX6QP.

		 * Quirk: i.MX6QP revision = i.MX6Q revision - (1, 0),

		 * e.g. i.MX6QP rev 1.1 identifies as i.MX6Q rev 2.1.

	/*

	 * WAIT mode is broken on imx6 Dual/Quad revision 1.0 and 1.1 so

	 * there is no point to run cpuidle on them.

	 *

	 * It does work on imx6 Solo/DualLite starting from 1.1

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * MX31 CPU type detection

 *

 * Copyright (c) 2009 Daniel Mack <daniel@caiaq.de>

 read SREV register from IIM module */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2013 Greg Ungerer <gerg@uclinux.org>

 * Copyright 2011 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2011 Linaro Ltd.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Freescale Semiconductor, Inc.

 enable RXC skew select RGMII copper mode */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2013 Freescale Semiconductor, Inc.

 set FEC clock from internal PLL clock source */

 imx6sl reuses imx6q cpufreq driver */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2011 Freescale Semiconductor, Inc.

 * Copyright 2011 Linaro Ltd.

 below is for i.MX7D */

/*

 * The motivation for bringing up the second i.MX7D core inside the kernel

 * is that legacy vendor bootloaders usually do not implement PSCI support.

 * This is a significant blocker for systems in the field that are running old

 * bootloader versions to upgrade to a modern mainline kernel version, as only

 * one CPU of the i.MX7D would be brought up.

 * Bring up the second i.MX7D core inside the kernel to make the migration

 * path to mainline kernel easier for the existing iMX7D users.

	/*

	 * force warm reset sources to generate cold reset

	 * for a more reliable restart

 sentinel */ }

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2016 NXP Semiconductors

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2012 Steffen Trumtrar, Pengutronix

 *

 * based on imx27-dt.c

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Freescale Semiconductor, Inc.

	/*

	 * Software workaround for ERR005311, see function

	 * description for details.

 WFI */

 WAIT */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2011 Freescale Semiconductor, Inc. All Rights Reserved.

/*

 * The WAIT_UNCLOCKED_POWER_OFF state only requires <= 500ns to exit.

 * This is also the lowest power state possible without affecting

 * non-cpu parts of the system.  For these reasons, imx5 should default

 * to always using this state for cpu idling.  The PM_SUSPEND_STANDBY also

 * uses this state and needs to take no action when registers remain configured

 * for this state.

 DQM0 */

 DQM1 */

 DQM2 */

 DQM3 */

 CAS */

 RAS */

 SDCLK_0 */

 SDCLK_1 */

 SDODT0 */

 SDODT1 */

 SDQS0 */

 SDQS1 */

 SDQS2 */

 SDSQ3 */

 GRP_ADDS */

 GRP_BODS */

 GRP_B1DS */

 GRP_B2DS */

 GRP_B3DS */

 Controls the CKE signal which is required to leave self refresh */

 CTLDS */

/*

 * This structure is for passing necessary data for low level ocram

 * suspend code(arch/arm/mach-imx/suspend-imx53.S), if this struct

 * definition is changed, the offset definition in that file

 * must be also changed accordingly otherwise, the suspend to ocram

 * function will be broken!

/*

 * set cpu low power mode before WFI instruction. This function is called

 * mx5 because it can be used for mx51, and mx53.

 always allow platform to issue a deep sleep mode request */

 DEFAULT_IDLE_STATE already configured */

clear the EMPGC0/1 bits */

 return registers to default idle state */

 Copied from imx6: TODO factorize */

 Need this to avoid compile error due to const typeof in fncpy.h */

 Set the registers to the default cpu idle state. */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C)2004-2010 Freescale Semiconductor, Inc. All Rights Reserved.

/*

 *****************************************

 * TZIC Registers                        *

 *****************************************

 Control register */

 Controller Type register */

 Distributor Implementer Identification */

 Priority Mask Reg */

 Synchronizer Control register */

 DSM interrupt Holdoffregister */

 Interrupt Security Reg 0 */

 Enable Set Reg 0 */

 Enable Clear Reg 0 */

 Source Set Register 0 */

 Source Clear Register 0 */

 Priority Register 0 */

 Pending Register 0 */

 High Priority Pending Register */

 Wakeup Config Register */

 Software Interrupt Rigger Register */

 Indentification Register 0 */

/*

 * This function initializes the TZIC hardware and disables all the

 * interrupts. It registers the interrupt enable and disable functions

 * to the kernel for each interrupt source.

	/* put the TZIC into the reset value with

	 * all interrupts disabled

 disable all interrupts */

 all IRQ no FIQ Warning :: No selection */

 Initialize FIQ */

/**

 * tzic_enable_wake() - enable wakeup interrupt

 *

 * @return			0 if successful; non-zero otherwise

 *

 * This function provides an interrupt synchronization point that is required

 * by tzic enabled platforms before entering imx specific low power modes (ie,

 * those low power modes beyond the WAIT_CLOCKED basic ARM WFI only mode).

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2016 Freescale Semiconductor, Inc.

 * Copyright 2017-2018 NXP

 *   Anson Huang <Anson.Huang@nxp.com>

 WFI */

 WAIT */

 STOP */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2014 Freescale Semiconductor, Inc.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2007 Freescale Semiconductor, Inc. All Rights Reserved.

 * Copyright 2008 Juergen Beisert, kernel@pengutronix.de

/*

 * i.MX27 specific CPU detection code

 The offset of CHIP ID register */

 Offset from CCM base address */

	/*

	 * now we have access to the IO registers. As we need

	 * the silicon revision very early we read it here to

	 * avoid any further hooks

/*

 * Returns:

 *	the silicon revision of the cpu

 *	-EINVAL - not a mx27

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright 2013-2014 Freescale Semiconductor, Inc.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2016 Freescale Semiconductor, Inc.

 * Copyright 2017-2018 NXP

 *   Author: Dong Aisheng <aisheng.dong@nxp.com>

	/*

	 * bit[31:28] of JTAG_ID register defines revision as below from B0:

	 * 0001        B0

	 * 0010        B1

	 * 0011        B2

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2016 Freescale Semiconductor, Inc.

 * Copyright 2017-2018 NXP

 *   Author: Dong Aisheng <aisheng.dong@nxp.com>

 clear all */

 system/bus clock enabled */

 system clock disabled, bus clock enabled */

 system/bus clock disabled */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Copyright (C) 2014 Alexander Shiyan <shc_work@mail.ru>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Exported ksyms for the SSI FIQ handler

 *

 * Copyright (C) 2009, Sascha Hauer <s.hauer@pengutronix.de>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/ttc_dkb.c

 *

 *  Support for the Marvell PXA910-based TTC_DKB Development Platform.

/*

 * 16 board interrupts -- MAX7312 GPIO expander

 * 16 board interrupts -- PCA9575 GPIO expander

 * 24 board interrupts -- 88PM860x PMIC

 UART2 */

 DFI */

 path config */

 0x0 ~ 0xd */

 0x0 ~ 0x3 */

 link config */

 0x0 ~ 0x6*/

 on-chip devices */

 off-chip devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/aspenite.c

 *

 *  Support for the Marvell PXA168-based Aspenite and Zylonite2

 *  Development Platform.

 Data Flash Interface */

 Static Memory Controller */

 Ethernet IRQ */

 UART1 */

 SSP1 */

 LCD */

 Keypad */

 SW 4 */

 SW 5 */

 SW 6 */

 SW 7 */

 SW 8 */

 SW 9 */

 on-chip devices */

 off-chip devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/mmp2-dt.c

 *

 *  Copyright (C) 2012 Marvell Technology Group Ltd.

 *  Author: Haojian Zhuang <haojian.zhuang@marvell.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/avengers_lite.c

 *

 *  Support for the Marvell PXA168-based Avengers lite Development Platform.

 *

 *  Copyright (C) 2009-2010 Marvell International Ltd.

 Avengers lite MFP configurations */

 DEBUG_UART */

 on-chip devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-mmp/devices.c

/*****************************************************************************

 * The registers read/write routines

 Initialize the USB PHY power */

 UTMI_PLL settings */

 UTMI_TX */

 UTMI_RX */

 UTMI_IVREF */

		/* fixing Microsoft Altair board interface with NEC hub issue -

 toggle VCOCAL_START bit of UTMI_PLL */

 toggle REG_RCAL_START bit of UTMI_TX */

 Make sure PHY PLL is ready */

 Turn on UTMI PHY OTG extension */

 CONFIG_PHY_PXA_USB */

 regbase */

 phybase */

 CONFIG_USB_MV_UDC */

 regbase */

 phybase */

 CONFIG_USB_MV_OTG */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-mmp/time.c

 *

 *   Support for clocksource and clockevents

 *

 * Copyright (C) 2008 Marvell International Ltd.

 * All rights reserved.

 *

 *   2008-04-11: Jason Chagas <Jason.chagas@marvell.com>

 *   2008-10-08: Bin Yang <bin.yang@marvell.com>

 *

 * The timers module actually includes three timers, each timer with up to

 * three match comparators. Timer #0 is used here in free-running mode as

 * the clock source, and match comparator #1 used as clock event device.

/*

 * FIXME: the timer needs some delay to stablize the counter capture

	/*

	 * Clear pending interrupt status.

	/*

	 * Disable timer 0.

	/*

	 * Disable timer 0.

	/*

	 * Clear and enable timer match 0 interrupt.

	/*

	 * Setup new clockevent timer value.

	/*

	 * Enable timer 0.

 disable the matching interrupt */

 disable */

 set timer 0 to periodic mode, and timer 1 to free-running mode */

 periodic */

 clear status */

 free-running */

 clear status */

 enable timer 1 counter */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/pxa910.c

 *

 *  Code specific to PXA910

 system timer - clock enabled, 3.25MHz */

 reset and configure */

 on-chip devices */

/* NOTE: there are totally 3 UARTs on PXA910:

 *

 *   UART1   - Slow UART (can be used both by AP and CP)

 *   UART2/3 - Fast UART

 *

 * To be backward compatible with the legacy FFUART/BTUART/STUART sequence,

 * they are re-ordered as:

 *

 *   pxa910_device_uart1 - UART2 as FFUART

 *   pxa910_device_uart2 - UART3 as BTUART

 *

 * UART1 is not used by AP for the moment.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/sram.c

 *

 *  based on mach-davinci/sram.c - DaVinci simple SRAM allocator

 *

 *  Copyright (c) 2011 Marvell Semiconductors Inc.

 *  All Rights Reserved

 *

 *  Add for mmp sram support - Leo Yan <leoy@marvell.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/pxa168.c

 *

 *  Code specific to PXA168

 system timer - clock enabled, 3.25MHz */

	/* this is early, we have to initialize the CCU registers by

	 * ourselves instead of using clk_* API. Clock rate is defined

	 * by APBC_TIMERS_CLK_RST (3.25MHz) and enabled free-running

 3.25MHz, bus/functional clock enabled, release reset */

 wake event clear is needed in order to clear keypad interrupt */

 on-chip devices */

 USB Host conroller register base */

 USB PHY register base */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/mmp-dt.c

 *

 *  Copyright (C) 2012 Marvell Technology Group Ltd.

 *  Author: Haojian Zhuang <haojian.zhuang@marvell.com>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2019 Lubomir Rintel <lkundrak@v3.sk>

	/*

	 * Apparently, the boot ROM on the second core spins on this

	 * register becoming non-zero and then jumps to the address written

	 * there. No IPIs involved.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/teton_bga.c

 *

 *  Support for the Marvell PXA168 Teton BGA Development Platform.

 *

 *  Author: Mark F. Brown <mark.brown314@gmail.com>

 *

 *  This code is based on aspenite.c

 UART1 */

 Keypad */

 I2C Bus */

 RTC */

 on-chip devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/jasper.c

 *

 *  Support for the Marvell Jasper Development Platform.

 *

 *  Copyright (C) 2009-2010 Marvell International Ltd.

 UART1 */

 UART3 */

 DFI */

 PMIC */

 MMC1 */

 MMC2 */

 MMC3 */

 VID1 = 1, VID0 = 0 */

 can't detect battery by ID pin */

 on-chip devices */

 SD/MMC */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-mmp/mmp2.c

 *

 * code name MMP2

 *

 * Copyright (C) 2009 Marvell International Ltd.

	/*

	 * enable bus/functional clock, enable 6.5MHz (divider 4),

	 * release reset

 on-chip devices */

 0xd1000000 ~ 0xd101ffff is reserved for secure processor */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/brownstone.c

 *

 *  Support for the Marvell Brownstone Development Platform.

 *

 *  Copyright (C) 2009-2010 Marvell International Ltd.

 UART1 */

 UART3 */

 DFI */

 PMIC */

 MMC0 */

 MMC1 */

 MMC2 */

 5V regulator */

 VID1 = 1, VID0 = 0 */

 .id set to 1 above */

 on-chip devices */

 SD/MMC */

 eMMC */

 enable 5v regulator */

 Maintainer: Haojian Zhuang <haojian.zhuang@marvell.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MMP2 Power Management Routines

 *

 * (C) Copyright 2012 Marvell International Ltd.

 * All Rights Reserved

 enable wakeup sources */

 mmc use WAKEUP2, same as GPIO wakeup source */

 close AXI fabric clock gate */

 close MCB master clock gate */

 open AXI fabric clock gate */

 open MCB master clock gate */

	/*

	 * disable clocks in MPMU_CGR_PJ register

	 * except clock for APMU_PLL1, APMU_PLL1_2 and AP_26M

 set the SLPEN bit */

 set VCTCXOSD */

 set APBSD */

 set AXISDD bit */

 set DDRCORSD bit */

 PJ power down */

 set the IDLE bit */

 set reserve bits */

 finally write the registers back */

 0xfe086000 */

 enable clocks in MPMU */

 enable clocks in SCU */

/*

 * Called after processes are frozen, but before we shut down devices.

/*

 * Called after devices are re-setup, but before processes are thawed.

/*

 * Set to PM_DISK_FIRMWARE so we can quickly veto suspend-to-disk.

	/*

	 * Set bit 0, Slow clock Select 32K clock input instead of VCXO

	 * VCXO is chosen by default, which would be disabled in suspend

	/*

	 * Clear bit 23 of CIU_CPU_CONF

	 * direct PJ4 to DDR access through Memory Controller slow queue

	 * fast queue has issue and cause lcd will flick

 Clear default low power control bit */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/tavorevb.c

 *

 *  Support for the Marvell PXA910-based TavorEVB Development Platform.

 UART2 */

 SMC */

 DFI */

 on-chip devices */

 off-chip devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/common.c

 *

 *  Code common to PXA168 processor lines

 this is early, initialize mmp_chip_id here */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/gplugd.c

 *

 *  Support for the Marvell PXA168-based GuruPlug Display (gplugD) Platform.

 UART3 */

 USB OTG PEN */

 MMC2 */

 LCD & HDMI clock selection GPIO: 0: 74.176MHz, 1: 74.25 MHz */

 CEC Interrupt */

 MMC1 */

 LCD */

 GPIO */

 Fast-Ethernet*/

 Reset PHY */

 RTC interrupt */

 I2C */

 SPI NOR Flash on SSP2 */

 SPI_CSn */

 Select JTAG */

 I2S */

 Bring PHY out of reset by setting GPIO 104 */

 Autonagotiation */

 set GPIO 35 & clear GPIO 85 to set LCD External Clock to 74.25 MHz */

 on-chip devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Marvell MMP3 aka PXA2128 aka 88AP2128 support

 *

 *  Copyright (C) 2019 Lubomir Rintel <lkundrak@v3.sk>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * PXA910 Power Management Routines

 *

 * (C) Copyright 2009 Marvell International Ltd.

 * All Rights Reserved

 setting wakeup sources */

 wakeup line 2 */

 wakeup line 3 */

 wakeup line 4 */

 wakeup line 5 */

 wakeup line 6 */

 wakeup line 7 */

 FIXME: This should return a proper error code ! */

 only shutdown APB in UDR */

 set the SLPEN bit */

 set VCTCXOSD */

 set DDRCORSD */

 set AXISDD bit */

 program the memory controller hardware sleep type and auto wakeup */

 auto refresh */

 set DSPSD, DTCMSD, BBSD, MSASLPEN */

always set SLEPEN bit mainly for MSA*/

 finally write the registers back */

pmic thread not completed,exit;otherwise system can't be waked up*/

 disable L2 */

 wait for l2 idle */

 enable L2 */

 wait for l2 idle */

/*

 * Called after processes are frozen, but before we shut down devices.

/*

 * Called after devices are re-setup, but before processes are thawed.

 Set the following bits for MMP3 playback with VCTXO on */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-mmp/flint.c

 *

 *  Support for the Marvell Flint Development Platform.

 *

 *  Copyright (C) 2009 Marvell International Ltd.

 UART1 */

 UART2 */

 SMC */

Ethernet*/

 DFI */

 on-chip devices */

 off-chip devices */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for Conexant Digicolor SoCs

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  arch/arm/mach-vt8500/vt8500.c

 *

 *  Copyright (C) 2012 Tony Prisk <linux@prisktech.co.nz>

 Registers in GPIO Controller */

 Registers in Power Management Controller */

 SoC MMIO registers */

 max of all chip variants */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * MSDI IP block reset

 *

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 *

 * XXX What about pad muxing?

/*

 * MSDI_CON_OFFSET: offset in bytes of the MSDI IP block's CON register

 *     from the IP block's base address

 Register bitfields in the CON register */

 MSDI_TARGET_RESET_CLKD: clock divisor to use throughout the reset */

/**

 * omap_msdi_reset - reset the MSDI IP block

 * @oh: struct omap_hwmod *

 *

 * The MSDI IP block on OMAP2420 has to have both the POW and CLKD

 * fields set inside its CON register for a reset to complete

 * successfully.  This is not documented in the TRM.  For CLKD, we use

 * the value that results in the lowest possible clock rate, to attempt

 * to avoid disturbing any cards.

 Write to the SOFTRESET bit */

 Enable the MSDI core and internal clock */

 Poll on RESETDONE bit */

 Disable the MSDI internal clock */

/*

 * OMAP Voltage Controller (VC) interface

 *

 * Copyright (C) 2011 Texas Instruments, Inc.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/**

 * struct omap_vc_channel_cfg - describe the cfg_channel bitfield

 * @sa: bit for slave address

 * @rav: bit for voltage configuration register

 * @rac: bit for command configuration register

 * @racen: enable bit for RAC

 * @cmd: bit for command value set selection

 *

 * Channel configuration bits, common for OMAP3+

 * OMAP3 register: PRM_VC_CH_CONF

 * OMAP4 register: PRM_VC_CFG_CHANNEL

 * OMAP5 register: PRM_VC_SMPS_<voltdm>_CONFIG

/*

 * On OMAP3+, all VC channels have the above default bitfield

 * configuration, except the OMAP4 MPU channel.  This appears

 * to be a freak accident as every other VC channel has the

 * default configuration, thus creating a mutant channel config.

 Default I2C trace length on pcb, 6.3cm. Used for capacitance calculations. */

/**

 * omap_vc_config_channel - configure VC channel to PMIC mappings

 * @voltdm: pointer to voltagdomain defining the desired VC channel

 *

 * Configures the VC channel to PMIC mappings for the following

 * PMIC settings

 * - i2c slave address (SA)

 * - voltage configuration address (RAV)

 * - command configuration address (RAC) and enable bit (RACEN)

 * - command values for ON, ONLP, RET and OFF (CMD)

 *

 * This function currently only allows flexible configuration of the

 * non-default channel.  Starting with OMAP4, there are more than 2

 * channels, with one defined as the default (on OMAP4, it's MPU.)

 * Only the non-default channel can be configured.

	/*

	 * For default channel, the only configurable bit is RACEN.

	 * All others must stay at zero (see function comment above.)

 Voltage scale and accessory APIs */

 Check if sufficient pmic info is available for this vdd */

 Setting the ON voltage to the new target voltage */

 SMPS slew rate / step size. 2us added as buffer. */

 vc_bypass_scale - VC bypass method of voltage scaling */

	/*

	 * Loop till the bypass command is acknowledged from the SMPS.

	 * NOTE: This is legacy code. The loop count and retry count needs

	 * to be revisited.

 Convert microsecond value to number of 32kHz clock cycles */

/*

 * Configure signal polarity for sys_clkreq and sys_off_mode pins

 * as the default values are wrong and can cause the system to hang

 * if any twl4030 scripts are loaded.

	/*

	 * By default let's use I2C4 signaling for retention idle

	 * and sys_off_mode pin signaling for off idle. This way we

	 * have sys_clk_req pin go down for retention and both

	 * sys_clk_req and sys_off_mode pins will go down for off

	 * idle. And we can also scale voltages to zero for off-idle.

	 * Note that no actual voltage scaling during off-idle will

	 * happen unless the board specific twl4030 PMIC scripts are

	 * loaded. See also omap_vc_i2c_init for comments regarding

	 * erratum i531.

/**

 * omap3_set_i2c_timings - sets i2c sleep timings for a channel

 * @voltdm: channel to configure

 * @off_mode: select whether retention or off mode values used

 *

 * Calculates and sets up voltage controller to use I2C based

 * voltage scaling for sleep modes. This can be used for either off mode

 * or retention. Off mode has additionally an option to use sys_off_mode

 * pad, which uses a global signal to program the whole power IC to

 * off-mode.

 *

 * Note that pmic is not controlling the voltage scaling during

 * retention signaled over I2C4, so we can keep voltsetup2 as 0.

 * And the oscillator is not shut off over I2C4, so no need to

 * set clksetup.

 Configure PRWDM_POWER_OFF over I2C4 */

 Configure PRWDM_POWER_RET over I2C4 */

/**

 * omap3_set_off_timings - sets off-mode timings for a channel

 * @voltdm: channel to configure

 *

 * Calculates and sets up off-mode timings for a channel. Off-mode

 * can use either I2C based voltage scaling, or alternatively

 * sys_off_mode pad can be used to send a global command to power IC.n,

 * sys_off_mode has the additional benefit that voltages can be

 * scaled to zero volt level with TWL4030 / TWL5030, I2C can only

 * scale to 600mV.

 *

 * Note that omap is not controlling the voltage scaling during

 * off idle signaled by sys_off_mode, so we can keep voltsetup1

 * as 0.

	/*

	 * For twl4030 errata 27, we need to allow minimum ~488.32 us wait to

	 * switch from HFCLKIN to internal oscillator. That means timings

	 * have voltoffset fixed to 0xa in rounded up 32 KiHz cycles. And

	 * that means we can calculate the value based on the oscillator

	 * start-up time since voltoffset2 = clksetup - voltoffset.

/**

 * omap4_calc_volt_ramp - calculates voltage ramping delays on omap4

 * @voltdm: channel to calculate values for

 * @voltage_diff: voltage difference in microvolts

 *

 * Calculates voltage ramp prescaler + counter values for a voltage

 * difference on omap4. Returns a field value suitable for writing to

 * VOLTSETUP register for a channel in following format:

 * bits[8:9] prescaler ... bits[0:5] counter. See OMAP4 TRM for reference.

 shift to next prescaler until no overflow */

 scale for div 256 = 64 * 4 */

 scale for div 512 = 256 * 2 */

 scale for div 2048 = 512 * 4 */

 check for overflow => invalid ramp time */

/**

 * omap4_usec_to_val_scrm - convert microsecond value to SCRM module bitfield

 * @usec: microseconds

 * @shift: number of bits to shift left

 * @mask: bitfield mask

 *

 * Converts microsecond value to OMAP4 SCRM bitfield. Bitfield is

 * shifted to requested position, and checked agains the mask value.

 * If larger, forced to the max value of the field (i.e. the mask itself.)

 * Returns the SCRM bitfield value.

 Check for overflow, if yes, force to max value */

/**

 * omap4_set_timings - set voltage ramp timings for a channel

 * @voltdm: channel to configure

 * @off_mode: whether off-mode values are used

 *

 * Calculates and sets the voltage ramp up / down values for a channel.

 OMAP4 specific voltage init functions */

/**

 * omap4_vc_i2c_timing_init - sets up board I2C timing parameters

 * @voltdm: voltagedomain pointer to get data from

 *

 * Use PMIC + board supplied settings for calculating the total I2C

 * channel capacitance and set the timing parameters based on this.

 * Pre-calculated values are provided in data tables, as it is not

 * too straightforward to calculate these runtime.

 PCB trace capacitance, 0.125pF / mm => mm / 8 */

 OMAP pad capacitance */

 PMIC pad capacitance */

 Search for capacitance match in the table */

 Select proper values based on sysclk frequency */

 Loadbits define pull setup for the I2C channels */

 Write to SYSCTRL_PADCONF_WKUP_CTRL_I2C_2 to setup I2C pull */

 HSSCLH can always be zero */

 Write setup times to I2C config register */

/**

 * omap_vc_i2c_init - initialize I2C interface to PMIC

 * @voltdm: voltage domain containing VC data

 *

 * Use PMIC supplied settings for I2C high-speed mode and

 * master code (if set) and program the VC I2C configuration

 * register.

 *

 * The VC I2C configuration is common to all VC channels,

 * so this function only configures I2C for the first VC

 * channel registers.  All other VC channels will use the

 * same configuration.

	/*

	 * Note that for omap3 OMAP3430_SREN_MASK clears SREN to work around

	 * erratum i531 "Extra Power Consumed When Repeated Start Operation

	 * Mode Is Enabled on I2C Interface Dedicated for Smart Reflex (I2C4)".

	 * Otherwise I2C4 eventually leads into about 23mW extra power being

	 * consumed even during off idle using VMODE.

/**

 * omap_vc_calc_vsel - calculate vsel value for a channel

 * @voltdm: channel to calculate value for

 * @uvolt: microvolt value to convert to vsel

 *

 * Converts a microvolt value to vsel value for the used PMIC.

 * This checks whether the microvolt value is out of bounds, and

 * adjusts the value accordingly. If unsupported value detected,

 * warning is thrown.

 Lets try maximum value anyway */

/**

 * omap_pm_setup_sr_i2c_pcb_length - set length of SR I2C traces on PCB

 * @mm: length of the PCB trace in millimetres

 *

 * Sets the PCB trace length for the I2C channel. By default uses 63mm.

 * This is needed for properly calculating the capacitance value for

 * the PCB trace, and for setting the SR I2C channel timing parameters.

 get PMIC/board specific settings */

 Configure the i2c slave address for this VC */

	/*

	 * Configure the PMIC register addresses.

 Set up the on, inactive, retention and off voltage */

 Channel configuration */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/cpuidle34xx.c

 *

 * OMAP3 CPU IDLE Routines

 *

 * Copyright (C) 2008 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 *

 * Copyright (C) 2007 Texas Instruments, Inc.

 * Karthik Dasu <karthik-dp@ti.com>

 *

 * Copyright (C) 2006 Nokia Corporation

 * Tony Lindgren <tony@atomide.com>

 *

 * Copyright (C) 2005 Texas Instruments, Inc.

 * Richard Woodruff <r-woodruff2@ti.com>

 *

 * Based on pm.c for omap2

 Mach specific information to be recorded in the C-state driver_data */

/*

 * Possible flag bits for struct omap3_idle_statedata.flags:

 *

 * OMAP_CPUIDLE_CX_NO_CLKDM_IDLE: don't allow the MPU clockdomain to go

 *    inactive.  This in turn prevents the MPU DPLL from entering autoidle

 *    mode, so wakeup latency is greatly reduced, at the cost of additional

 *    energy consumption.  This also prevents the CORE clockdomain from

 *    entering idle.

/*

 * Prevent PER OFF if CORE is not in RETention or OFF as this would

 * disable PER wakeups completely.

 In C1 do not allow PER state lower than CORE state */

/**

 * omap3_enter_idle - Programs OMAP3 to enter the specified state

 * @dev: cpuidle device

 * @drv: cpuidle driver

 * @index: the index of state to be entered

 Deny idle for C1 */

	/*

	 * Call idle CPU PM enter notifier chain so that

	 * VFP context is saved.

 Execute ARM wfi */

	/*

	 * Call idle CPU PM enter notifier chain to restore

	 * VFP context.

 Re-allow idle for C1 */

/**

 * next_valid_state - Find next valid C-state

 * @dev: cpuidle device

 * @drv: cpuidle driver

 * @index: Index of currently selected c-state

 *

 * If the state corresponding to index is valid, index is returned back

 * to the caller. Else, this function searches for a lower c-state which is

 * still valid (as defined in omap3_power_states[]) and returns its index.

 *

 * A state is valid if the 'valid' field is enabled and

 * if it satisfies the enable_off_mode condition.

 C1 is the default value */

		/*

		 * Erratum i583: valable for ES rev < Es1.2 on 3630.

		 * CORE OFF mode is not supported in a stable form, restrict

		 * instead the CORE state to RET.

 Check if current state is valid */

	/*

	 * Drop to next valid state.

	 * Start search from the next (lower) state.

/**

 * omap3_enter_idle_bm - Checks for any bus activity

 * @dev: cpuidle device

 * @drv: cpuidle driver

 * @index: array index of target state to be programmed

 *

 * This function checks for any pending activity and then programs

 * the device to the specified or a safer state.

	/*

	 * Use only C1 if CAM is active.

	 * CAM does not have wakeup capability in OMAP3.

	/*

	 * FIXME: we currently manage device-specific idle states

	 *        for PER and CORE in combination with CPU-specific

	 *        idle states.  This is wrong, and device-specific

	 *        idle management needs to be separated out into

	 *        its own code.

 Program PER state */

 Restore original PER state if it was modified */

/*

 * Numbers based on measurements made in October 2009 for PM optimized kernel

 * with CPU freq enabled on device Nokia N900. Assumes OPP2 (main idle OPP,

 * and worst case latencies).

 Public functions */

/**

 * omap3_idle_init - Init routine for OMAP3 idle

 *

 * Registers the OMAP3 specific cpuidle driver to the cpuidle

 * framework with the valid set of states.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * pm.c - Common OMAP2+ power management-related code

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Copyright (C) 2010 Nokia Corporation

/*

 * omap_pm_suspend: points to a function that does the SoC-specific

 * suspend work

/**

 * struct omap2_oscillator - Describe the board main oscillator latencies

 * @startup_time: oscillator startup latency

 * @shutdown_time: oscillator shutdown latency

 XXX doublecheck */

/**

 * omap_common_suspend_init - Set common suspend routines for OMAP SoCs

 * @pm_suspend: function pointer to SoC specific suspend function

 CONFIG_SUSPEND */

 Init the voltage layer */

 Smartreflex device init */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2-specific DPLL control functions

 *

 * Copyright (C) 2011 Nokia Corporation

 * Paul Walmsley

 Private functions */

/**

 * _allow_idle - enable DPLL autoidle bits

 * @clk: struct clk * of the DPLL to operate on

 *

 * Enable DPLL automatic idle control.  The DPLL will enter low-power

 * stop when its downstream clocks are gated.  No return value.

 * REVISIT: DPLL can optionally enter low-power bypass by writing 0x1

 * instead.  Add some mechanism to optionally enter this mode.

/**

 * _deny_idle - prevent DPLL from automatically idling

 * @clk: struct clk * of the DPLL to operate on

 *

 * Disable DPLL automatic idle control.  No return value.

 Public data */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP5 Voltage Management Routines

 *

 * Based on voltagedomains44xx_data.c

 *

 * Copyright (C) 2013 Texas Instruments Incorporated - https://www.ti.com

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 Clock domains framework

 *

 * Copyright (C) 2009-2011 Texas Instruments, Inc.

 * Copyright (C) 2009-2011 Nokia Corporation

 *

 * Abhijit Pagare (abhijitpagare@ti.com)

 * Benoit Cousson (b-cousson@ti.com)

 * Paul Walmsley (paul@pwsan.com)

 *

 * This file is automatically generated from the OMAP hardware databases.

 * We respectfully ask that any modifications to this file be coordinated

 * with the public linux-omap@vger.kernel.org mailing list and the

 * authors above to ensure that the autogeneration scripts are kept

 * up-to-date with the file contents.

 Static Dependencies for OMAP4 Clock Domains */

 As clockdomains are added or removed above, this list must also be changed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Common powerdomain framework functions

 *

 * Copyright (C) 2010-2011 Texas Instruments, Inc.

 * Copyright (C) 2010 Nokia Corporation

 *

 * Derived from mach-omap2/powerdomain.c written by Paul Walmsley

/*

 * OMAP3 and OMAP4 specific register bit initialisations

 * Notice that the names here are not according to each power

 * domain but the bit mapping used applies to all of them

 OMAP3 and OMAP4 Memory Onstate Masks (common across all power domains) */

 OMAP3 and OMAP4 Memory Retstate Masks (common across all power domains) */

 OMAP3 and OMAP4 Memory Status bits */

 Common Internal functions used across OMAP rev's*/

 should never happen */

 should never happen */

 should never happen */

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP2420 clockdomains

 *

 * Copyright (C) 2008-2011 Texas Instruments, Inc.

 * Copyright (C) 2008-2010 Nokia Corporation

 *

 * Paul Walmsley, Jouni Hgander

 *

 * This file contains clockdomains and clockdomain wakeup dependencies

 * for OMAP2420 chips.  Some notes:

 *

 * A useful validation rule for struct clockdomain: Any clockdomain

 * referenced by a wkdep_srcs must have a dep_bit assigned.  So

 * wkdep_srcs are really just software-controllable dependencies.

 * Non-software-controllable dependencies do exist, but they are not

 * encoded below (yet).

 *

 * 24xx does not support programmable sleep dependencies (SLEEPDEP)

 *

 * The overly-specific dep_bit names are due to a bit name collision

 * with CM_FCLKEN_{DSP,IVA2}.  The DSP/IVA2 PM_WKDEP and CM_SLEEPDEP shift

 * value are the same for all powerdomains: 2

 *

 * XXX should dep_bit be a mask, so we can test to see if it is 0 as a

 * sanity check?

 * XXX encode hardware fixed wakeup dependencies -- esp. for 3430 CORE

/*

 * To-Do List

 * -> Port the Sleep/Wakeup dependencies for the domains

 *    from the Power domain framework

/*

 * Clockdomain dependencies for wkdeps

 *

 * XXX Hardware dependencies (e.g., dependencies that cannot be

 * changed in software) are not included here yet, but should be.

 Wakeup dependency source arrays */

 2420-specific possible wakeup dependencies */

 2420 PM_WKDEP_MPU: CORE, DSP, WKUP */

 2420 PM_WKDEP_CORE: DSP, GFX, MPU, WKUP */

/*

 * 2420-only clockdomains

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2+ common Clock Management (CM) IP block functions

 *

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 *

 * XXX This code should eventually be moved to a CM driver.

/*

 * cm_ll_data: function pointers to SoC-specific implementations of

 * common CM functions

 cm_base: base virtual address of the CM IP block */

 cm2_base: base virtual address of the CM2 IP block (OMAP44xx only) */

/**

 * cm_split_idlest_reg - split CM_IDLEST reg addr into its components

 * @idlest_reg: CM_IDLEST* virtual address

 * @prcm_inst: pointer to an s16 to return the PRCM instance offset

 * @idlest_reg_id: pointer to a u8 to return the CM_IDLESTx register ID

 *

 * Given an absolute CM_IDLEST register address @idlest_reg, passes

 * the PRCM instance offset and IDLEST register ID back to the caller

 * via the @prcm_inst and @idlest_reg_id.  Returns -EINVAL upon error,

 * or 0 upon success.  XXX This function is only needed until absolute

 * register addresses are removed from the OMAP struct clk records.

/**

 * omap_cm_wait_module_ready - wait for a module to leave idle or standby

 * @part: PRCM partition

 * @prcm_mod: PRCM module offset

 * @idlest_reg: CM_IDLESTx register

 * @idlest_shift: shift of the bit in the CM_IDLEST* register to check

 *

 * Wait for the PRCM to indicate that the module identified by

 * (@prcm_mod, @idlest_id, @idlest_shift) is clocked.  Return 0 upon

 * success, -EBUSY if the module doesn't enable in time, or -EINVAL if

 * no per-SoC wait_module_ready() function pointer has been registered

 * or if the idlest register is unknown on the SoC.

/**

 * omap_cm_wait_module_idle - wait for a module to enter idle or standby

 * @part: PRCM partition

 * @prcm_mod: PRCM module offset

 * @idlest_reg: CM_IDLESTx register

 * @idlest_shift: shift of the bit in the CM_IDLEST* register to check

 *

 * Wait for the PRCM to indicate that the module identified by

 * (@prcm_mod, @idlest_id, @idlest_shift) is no longer clocked.  Return

 * 0 upon success, -EBUSY if the module doesn't enable in time, or

 * -EINVAL if no per-SoC wait_module_idle() function pointer has been

 * registered or if the idlest register is unknown on the SoC.

/**

 * omap_cm_module_enable - enable a module

 * @mode: target mode for the module

 * @part: PRCM partition

 * @inst: PRCM instance

 * @clkctrl_offs: CM_CLKCTRL register offset for the module

 *

 * Enables clocks for a module identified by (@part, @inst, @clkctrl_offs)

 * making its IO space accessible. Return 0 upon success, -EINVAL if no

 * per-SoC module_enable() function pointer has been registered.

/**

 * omap_cm_module_disable - disable a module

 * @part: PRCM partition

 * @inst: PRCM instance

 * @clkctrl_offs: CM_CLKCTRL register offset for the module

 *

 * Disables clocks for a module identified by (@part, @inst, @clkctrl_offs)

 * makings its IO space inaccessible. Return 0 upon success, -EINVAL if

 * no per-SoC module_disable() function pointer has been registered.

/**

 * cm_register - register per-SoC low-level data with the CM

 * @cld: low-level per-SoC OMAP CM data & function pointers to register

 *

 * Register per-SoC low-level OMAP CM data and function pointers with

 * the OMAP CM common interface.  The caller must keep the data

 * pointed to by @cld valid until it calls cm_unregister() and

 * it returns successfully.  Returns 0 upon success, -EINVAL if @cld

 * is NULL, or -EEXIST if cm_register() has already been called

 * without an intervening cm_unregister().

/**

 * cm_unregister - unregister per-SoC low-level data & function pointers

 * @cld: low-level per-SoC OMAP CM data & function pointers to unregister

 *

 * Unregister per-SoC low-level OMAP CM data and function pointers

 * that were previously registered with cm_register().  The

 * caller may not destroy any of the data pointed to by @cld until

 * this function returns successfully.  Returns 0 upon success, or

 * -EINVAL if @cld is NULL or if @cld does not match the struct

 * cm_ll_data * previously registered by cm_register().

	/*

	 * IVA2 offset is a negative value, must offset the cm_base address

	 * by this to get it to positive side on the iomap

/**

 * omap2_cm_base_init - initialize iomappings for the CM drivers

 *

 * Detects and initializes the iomappings for the CM driver, based

 * on the DT data. Returns 0 in success, negative error value

 * otherwise.

/**

 * omap_cm_init - low level init for the CM drivers

 *

 * Initializes the low level clock infrastructure for CM drivers.

 * Returns 0 in success, negative error value in failure.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4+ Power Management Routines

 *

 * Copyright (C) 2010-2013 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Santosh Shilimkar <santosh.shilimkar@ti.com>

/**

 * struct static_dep_map - Static dependency map

 * @from:	from clockdomain

 * @to:		to clockdomain

 Save current powerdomain state */

 Set targeted power domain states by suspend */

	/*

	 * For MPUSS to hit power domain retention(CSWR or OSWR),

	 * CPU0 and CPU1 power domains need to be in OFF or DORMANT state,

	 * since CPU power domain CSWR is not supported by hardware

	 * Only master CPU follows suspend path. All other CPUs follow

	 * CPU hotplug path in system wide suspend. On OMAP4, CPU power

	 * domain CSWR is not supported by hardware.

	 * More details can be found in OMAP4430 TRM section 4.3.4.2.

 Restore next powerdomain state */

		/*

		 * OMAP4 chip PM currently works only with certain (newer)

		 * versions of bootloaders. This is due to missing code in the

		 * kernel to properly reset and initialize some devices.

		 * Warn the user about the bootloader version being one of the

		 * possible causes.

		 * http://www.spinics.net/lists/arm-kernel/msg218641.html

 CONFIG_SUSPEND */

	/*

	 * Skip CPU0 and CPU1 power domains. CPU1 is programmed

	 * through hotplug path and CPU0 explicitly programmed

	 * further down in the code path

/**

 * omap_default_idle - OMAP4 default ilde routine.'

 *

 * Implements OMAP4 memory, IO ordering requirements which can't be addressed

 * with default cpu_do_idle() hook. Used by all CPUs with !CONFIG_CPU_IDLE and

 * by secondary CPU with CONFIG_CPU_IDLE.

/*

 * The dynamic dependency between MPUSS -> MEMIF and

 * MPUSS -> L4_PER/L3_* and DUCATI -> L3_* doesn't work as

 * expected. The hardware recommendation is to enable static

 * dependencies for these to avoid system lock ups or random crashes.

 * The L4 wakeup depedency is added to workaround the OCP sync hardware

 * BUG with 32K synctimer which lead to incorrect timer value read

 * from the 32K counter. The BUG applies for GPTIMER1 and WDT2 which

 * are part of L4 wakeup clockdomain.

 TERMINATION */

 TERMINATION */

/**

 * omap4plus_init_static_deps() - Initialize a static dependency map

 * @map:	Mapping of clock domains

/**

 * omap4_pm_init_early - Does early initialization necessary for OMAP4+ devices

 *

 * Initializes basic stuff for power management functionality.

/**

 * omap4_pm_init - Init routine for OMAP4+ devices

 *

 * Initializes all powerdomain and clockdomain target states

 * and all PRCM settings.

 * Return: Returns the error code returned by called functions.

	/*

	 * OMAP4 chip PM currently works only with certain (newer)

	 * versions of bootloaders. This is due to missing code in the

	 * kernel to properly reset and initialize some devices.

	 * http://www.spinics.net/lists/arm-kernel/msg218641.html

 Overwrite the default cpu_do_idle() */

/*

 * OMAP IP block custom reset and preprogramming stubs

 *

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 *

 * A small number of IP blocks need custom reset and preprogramming

 * functions.  The stubs in this file provide a standard way for the

 * hwmod code to call these functions, which are to be located under

 * drivers/.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA

 * 02110-1301 USA

/**

 * omap_rtc_wait_not_busy - Wait for the RTC BUSY flag

 * @oh: struct omap_hwmod *

 *

 * For updating certain RTC registers, the MPU must wait

 * for the BUSY status in OMAP_RTC_STATUS_REG to become zero.

 * Once the BUSY status is zero, there is a 15 microseconds access

 * period in which the MPU can program.

 BUSY may stay active for 1/32768 second (~30 usec) */

 now we have ~15 microseconds to read/write various registers */

/**

 * omap_hwmod_rtc_unlock - Unlock the Kicker mechanism.

 * @oh: struct omap_hwmod *

 *

 * RTC IP have kicker feature. This prevents spurious writes to its registers.

 * In order to write into any of the RTC registers, KICK values has te be

 * written in respective KICK registers. This is needed for hwmod to write into

 * sysconfig register.

/**

 * omap_hwmod_rtc_lock - Lock the Kicker mechanism.

 * @oh: struct omap_hwmod *

 *

 * RTC IP have kicker feature. This prevents spurious writes to its registers.

 * Once the RTC registers are written, KICK mechanism needs to be locked,

 * in order to prevent any spurious writes. This function locks back the RTC

 * registers once hwmod completes its write into sysconfig register.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap2-restart.c - code common to all OMAP2xxx machines.

 *

 * Copyright (C) 2012 Texas Instruments

 * Paul Walmsley

/*

 * reset_virt_prcm_set_ck, reset_sys_ck: pointers to the virt_prcm_set

 * clock and the sys_ck.  Used during the reset process

 Reboot handling */

/**

 * omap2xxx_restart - Set DPLL to bypass mode for reboot to work

 *

 * Set the DPLL to bypass so that reboot completes successfully.  No

 * return value.

 XXX Should save the cmd argument for use after the reboot */

/**

 * omap2xxx_common_look_up_clks_for_reset - look up clocks needed for restart

 *

 * Some clocks need to be looked up in advance for the SoC restart

 * operation to work - see omap2xxx_restart().  Returns -EINVAL upon

 * error or 0 upon success.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2xxx PRM module functions

 *

 * Copyright (C) 2010-2012 Texas Instruments, Inc.

 * Copyright (C) 2010 Nokia Corporation

 * Benot Cousson

 * Paul Walmsley

 * Rajendra Nayak <rnayak@ti.com>

/*

 * OMAP24xx PM_PWSTCTRL_*.POWERSTATE and PM_PWSTST_*.LASTSTATEENTERED bits -

 * these are reversed from the bits used on OMAP3+

/*

 * omap2xxx_prm_reset_src_map - map from bits in the PRM_RSTST_WKUP

 *   hardware register (which are specific to the OMAP2xxx SoCs) to

 *   reset source ID bit shifts (which is an OMAP SoC-independent

 *   enumeration)

/**

 * omap2xxx_prm_read_reset_sources - return the last SoC reset source

 *

 * Return a u32 representing the last reset sources of the SoC.  The

 * returned reset source bits are standardized across OMAP SoCs.

/**

 * omap2xxx_pwrst_to_common_pwrst - convert OMAP2xxx pwrst to common pwrst

 * @omap2xxx_pwrst: OMAP2xxx hardware power state to convert

 *

 * Return the common power state bits corresponding to the OMAP2xxx

 * hardware power state bits @omap2xxx_pwrst, or -EINVAL upon error.

/**

 * omap2xxx_prm_dpll_reset - use DPLL reset to reboot the OMAP SoC

 *

 * Set the DPLL reset bit, which should reboot the SoC.  This is the

 * recommended way to restart the SoC.  No return value.

 OCP barrier */

/**

 * omap2xxx_prm_clear_mod_irqs - clear wakeup status bits for a module

 * @module: PRM module to clear wakeups from

 * @regs: register offset to clear

 * @wkst_mask: wakeup status mask to clear

 *

 * Clears wakeup status bits for a given module, so that the device can

 * re-enter idle.

/*

 *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 PRM module functions

 *

 * Copyright (C) 2011-2012 Texas Instruments, Inc.

 * Copyright (C) 2010 Nokia Corporation

 * Benot Cousson

 * Paul Walmsley

 * Rajendra Nayak <rnayak@ti.com>

 Static data */

/*

 * omap44xx_prm_reset_src_map - map from bits in the PRM_RSTST

 *   hardware register (which are specific to OMAP44xx SoCs) to reset

 *   source ID bit shifts (which is an OMAP SoC-independent

 *   enumeration)

 PRM low-level functions */

 Read a register in a CM/PRM instance in the PRM module */

 Write into a register in a CM/PRM instance in the PRM module */

 Read-modify-write a register in a PRM module. Caller must lock */

 PRM VP */

/*

 * struct omap4_vp - OMAP4 VP register access description.

 * @irqstatus_mpu: offset to IRQSTATUS_MPU register for VP

 * @tranxdone_status: VP_TRANXDONE_ST bitmask in PRM_IRQSTATUS_MPU reg

 XXX read mask from RAM? */

/**

 * omap44xx_prm_read_pending_irqs - read pending PRM MPU IRQs into @events

 * @events: ptr to two consecutive u32s, preallocated by caller

 *

 * Read PRM_IRQSTATUS_MPU* bits, AND'ed with the currently-enabled PRM

 * MPU IRQs, and store the result into the two u32s pointed to by @events.

 * No return value.

/**

 * omap44xx_prm_ocp_barrier - force buffered MPU writes to the PRM to complete

 *

 * Force any buffered writes to the PRM IP block to complete.  Needed

 * by the PRM IRQ handler, which reads and writes directly to the IP

 * block, to avoid race conditions after acknowledging or clearing IRQ

 * bits.  No return value.

/**

 * omap44xx_prm_save_and_clear_irqen - save/clear PRM_IRQENABLE_MPU* regs

 * @saved_mask: ptr to a u32 array to save IRQENABLE bits

 *

 * Save the PRM_IRQENABLE_MPU and PRM_IRQENABLE_MPU_2 registers to

 * @saved_mask.  @saved_mask must be allocated by the caller.

 * Intended to be used in the PRM interrupt handler suspend callback.

 * The OCP barrier is needed to ensure the write to disable PRM

 * interrupts reaches the PRM before returning; otherwise, spurious

 * interrupts might occur.  No return value.

 OCP barrier */

/**

 * omap44xx_prm_restore_irqen - set PRM_IRQENABLE_MPU* registers from args

 * @saved_mask: ptr to a u32 array of IRQENABLE bits saved previously

 *

 * Restore the PRM_IRQENABLE_MPU and PRM_IRQENABLE_MPU_2 registers from

 * @saved_mask.  Intended to be used in the PRM interrupt handler resume

 * callback to restore values saved by omap44xx_prm_save_and_clear_irqen().

 * No OCP barrier should be needed here; any pending PRM interrupts will fire

 * once the writes reach the PRM.  No return value.

/**

 * omap44xx_prm_reconfigure_io_chain - clear latches and reconfigure I/O chain

 *

 * Clear any previously-latched I/O wakeup events and ensure that the

 * I/O wakeup gates are aligned with the current mux settings.  Works

 * by asserting WUCLKIN, waiting for WUCLKOUT to be asserted, and then

 * deasserting WUCLKIN and waiting for WUCLKOUT to be deasserted.

 * No return value. XXX Are the final two steps necessary?

 Trigger WUCLKIN enable */

 Trigger WUCLKIN disable */

/**

 * omap44xx_prm_enable_io_wakeup - enable wakeup events from I/O wakeup latches

 *

 * Activates the I/O wakeup event latches and allows events logged by

 * those latches to signal a wakeup event to the PRCM.  For I/O wakeups

 * to occur, WAKEUPENABLE bits must be set in the pad mux registers, and

 * omap44xx_prm_reconfigure_io_chain() must be called.  No return value.

/**

 * omap44xx_prm_read_reset_sources - return the last SoC reset source

 *

 * Return a u32 representing the last reset sources of the SoC.  The

 * returned reset source bits are standardized across OMAP SoCs.

/**

 * omap44xx_prm_was_any_context_lost_old - was module hardware context lost?

 * @part: PRM partition ID (e.g., OMAP4430_PRM_PARTITION)

 * @inst: PRM instance offset (e.g., OMAP4430_PRM_MPU_INST)

 * @idx: CONTEXT register offset

 *

 * Return 1 if any bits were set in the *_CONTEXT_* register

 * identified by (@part, @inst, @idx), which means that some context

 * was lost for that module; otherwise, return 0.

/**

 * omap44xx_prm_clear_context_lost_flags_old - clear context loss flags

 * @part: PRM partition ID (e.g., OMAP4430_PRM_PARTITION)

 * @inst: PRM instance offset (e.g., OMAP4430_PRM_MPU_INST)

 * @idx: CONTEXT register offset

 *

 * Clear hardware context loss bits for the module identified by

 * (@part, @inst, @idx).  No return value.  XXX Writes to reserved bits;

 * is there a way to avoid this?

 Powerdomain low-level functions */

/**

 * omap4_pwrdm_read_prev_logic_pwrst - read the previous logic powerstate

 * @pwrdm: struct powerdomain * to read the state for

 *

 * Reads the previous logic powerstate for a powerdomain. This

 * function must determine the previous logic powerstate by first

 * checking the previous powerstate for the domain. If that was OFF,

 * then logic has been lost. If previous state was RETENTION, the

 * function reads the setting for the next retention logic state to

 * see the actual value.  In every other case, the logic is

 * retained. Returns either PWRDM_POWER_OFF or PWRDM_POWER_RET

 * depending whether the logic was retained or not.

/**

 * omap4_pwrdm_read_prev_mem_pwrst - reads the previous memory powerstate

 * @pwrdm: struct powerdomain * to read mem powerstate for

 * @bank: memory bank index

 *

 * Reads the previous memory powerstate for a powerdomain. This

 * function must determine the previous memory powerstate by first

 * checking the previous powerstate for the domain. If that was OFF,

 * then logic has been lost. If previous state was RETENTION, the

 * function reads the setting for the next memory retention state to

 * see the actual value.  In every other case, the logic is

 * retained. Returns either PWRDM_POWER_OFF or PWRDM_POWER_RET

 * depending whether logic was retained or not.

	/*

	 * REVISIT: pwrdm_wait_transition() may be better implemented

	 * via a callback and a periodic timer check -- how long do we expect

	 * powerdomain transitions to take?

 XXX Is this udelay() value meaningful? */

/**

 * omap4_pwrdm_save_context - Saves the powerdomain state

 * @pwrdm: pointer to individual powerdomain

 *

 * The function saves the powerdomain state control information.

 * This is needed in rtc+ddr modes where we lose powerdomain context.

	/*

	 * Do not save LOWPOWERSTATECHANGE, writing a 1 indicates a request,

	 * reading back a 1 indicates a request in progress.

/**

 * omap4_pwrdm_restore_context - Restores the powerdomain state

 * @pwrdm: pointer to individual powerdomain

 *

 * The function restores the powerdomain state control information.

 * This is needed in rtc+ddr modes where we lose powerdomain context.

 Make sure we only wait for a transition if there is one */

/*

 * XXX document

 Add AM437X specific differences */

 Only AM43XX can lose prm context during rtc-ddr suspend */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/mcbsp.c

 *

 * Copyright (C) 2008 Instituto Nokia de Tecnologia

 * Contact: Eduardo Valentin <eduardo.valentin@indt.org.br>

 *

 * Multichannel mode not supported.

/*

 * FIXME: Find a mechanism to enable/disable runtime the McBSP ICLK autoidle.

 * Sidetone needs non-gated ICLK and sidetone autoidle is broken.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/io.c

 *

 * OMAP2 I/O mapping code

 *

 * Copyright (C) 2005 Nokia Corporation

 * Copyright (C) 2007-2009 Texas Instruments

 *

 * Author:

 *	Juha Yrjola <juha.yrjola@nokia.com>

 *	Syed Khasim <x0khasim@ti.com>

 *

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

/*

 * omap_clk_soc_init: points to a function that does the SoC-specific

 * clock initializations

/*

 * The machine specific code may provide the extra mapping besides the

 * default mapping provided here.

/*

 * omap2_init_reprogram_sdrc - reprogram SDRC timing parameters

 *

 * Sets the CORE DPLL3 M2 divider to the same value that it's at

 * currently.  This has the effect of setting the SDRC SDRAM AC timing

 * registers to the values currently defined by the kernel.  Currently

 * only defined for OMAP3; will return 0 if called on OMAP2.  Returns

 * -EINVAL if the dpll3_m2_ck cannot be found, 0 if called on OMAP2,

 * or passes along the return value of clk_set_rate().

 Set the default postsetup state for all hwmods */

/*

 * Currently only board-omap3beagle.c should call this because of the

 * same machine_id for 34xx and 36xx beagle.. Will get fixed with DT.

 SPDX-License-Identifier: GPL-2.0

/*

 * opp2430_data.c - old-style "OPP" table for OMAP2430

 *

 * Copyright (C) 2005-2009 Texas Instruments, Inc.

 * Copyright (C) 2004-2009 Nokia Corporation

 *

 * Richard Woodruff <r-woodruff2@ti.com>

 *

 * The OMAP2 processor can be run at several discrete 'PRCM configurations'.

 * These configurations are characterized by voltage and speed for clocks.

 * The device is only validated for certain combinations. One way to express

 * these combinations is via the 'ratios' which the clocks operate with

 * respect to each other. These ratio sets are for a given voltage/DPLL

 * setting. All configurations can be described by a DPLL setting and a ratio.

 *

 * 2430 differs from 2420 in that there are no more phase synchronizers used.

 * They both have a slightly different clock domain setup. 2420(iva1,dsp) vs

 * 2430 (iva2.1, NOdsp, mdm)

 *

 * XXX Missing voltage data.

 * XXX Missing 19.2MHz sys_clk rate sets.

 *

 * THe format described in this file is deprecated.  Once a reasonable

 * OPP API exists, the data in this file should be converted to use it.

 *

 * This is technically part of the OMAP2xxx clock code.

/*

 * Key dividers which make up a PRCM set. Ratios for a PRCM are mandated.

 * xtal_speed, dpll_speed, mpu_speed, CM_CLKSEL_MPU,

 * CM_CLKSEL_DSP, CM_CLKSEL_GFX, CM_CLKSEL1_CORE, CM_CLKSEL1_PLL,

 * CM_CLKSEL2_PLL, CM_CLKSEL_MDM

 *

 * Filling in table based on 2430-SDPs variants available.  There are

 * quite a few more rate combinations which could be defined.

 *

 * When multiple values are defined the start up will try and choose

 * the fastest one. If a 'fast' value is defined, then automatically,

 * the /2 one should be included as it can be used.  Generally having

 * more than one fast set does not make sense, as static timings need

 * to be changed to change the set.  The exception is the bypass

 * setting which is available for low power bypass.

 *

 * Note: This table needs to be sorted, fastest to slowest.

 PRCM #4 - ratio2 (ES2.1) - FAST */

 399MHz ARM */

 PRCM #2 - ratio1 (ES2) - FAST */

 330MHz ARM */

 PRCM #5a - ratio1 - FAST */

 266MHz ARM */

 PRCM #5b - ratio1 - FAST */

 200MHz ARM */

 PRCM #4 - ratio1 (ES2.1) - SLOW */

 200MHz ARM */

 PRCM #2 - ratio1 (ES2) - SLOW */

 165MHz ARM */

 PRCM #5a - ratio1 - SLOW */

 133MHz ARM */

 PRCM #5b - ratio1 - SLOW*/

 100MHz ARM */

 PRCM-boot/bypass */

 13MHz */

 PRCM-boot/bypass */

 12MHz */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Smart reflex Class 3 specific implementations

 *

 * Author: Thara Gopinath       <thara@ti.com>

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Thara Gopinath <thara@ti.com>

 SR class3 structure */

 Smartreflex Class3 init API to be called from board file */

/*

 * OMAP2plus display device setup / initialization.

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 *	Senthilvadivu Guruswamy

 *	Sumit Semwal

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * FRAMEDONE_IRQ_TIMEOUT: how long (in milliseconds) to wait during DISPC

 *     reset before deciding that something has gone wrong

 create vrfb device */

 create FB device */

 create V4L2 display device */

 add DSI info for omap4 */

 only create dss helper devices if dss is enabled in the .dts */

 CONFIG_FB_OMAP2 */

 store value of LCDENABLE and DIGITENABLE bits */

 store value of LCDENABLE for LCD2 */

 store value of LCDENABLE for LCD3 */

 no managers currently enabled */

	/*

	 * If any manager was enabled, we need to disable it before

	 * DSS clocks are disabled or DISPC module is reset

	/*

	 * clear any previous FRAMEDONE, FRAMEDONETV,

	 * EVSYNC_EVEN/ODD, FRAMEDONE2 or FRAMEDONE3 interrupts

 disable LCD and TV managers */

 disable LCD2 manager */

 disable LCD3 manager */

 clear SDI registers */

	/*

	 * clear DSS_CONTROL register to switch DSS clock sources to

	 * PRCM clock, if any

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * OMAP2+ MPU WD_TIMER-specific code

 *

 * Copyright (C) 2012 Texas Instruments, Inc.

/*

 * In order to avoid any assumptions from bootloader regarding WDT

 * settings, WDT module is reset during init. This enables the watchdog

 * timer. Hence it is required to disable the watchdog after the WDT reset

 * during init. Otherwise the system would reboot as per the default

 * watchdog timer registers settings.

 sequence required to disable watchdog */

/**

 * omap2_wdtimer_reset - reset and disable the WDTIMER IP block

 * @oh: struct omap_hwmod *

 *

 * After the WDTIMER IP blocks are reset on OMAP2/3, we must also take

 * care to execute the special watchdog disable sequence.  This is

 * because the watchdog is re-armed upon OCP softreset.  (On OMAP4,

 * this behavior was apparently changed and the watchdog is no longer

 * re-armed after an OCP soft-reset.)  Returns -ETIMEDOUT if the reset

 * did not complete, or 0 upon success.

 *

 * XXX Most of this code should be moved to the omap_hwmod.c layer

 * during a normal merge window.  omap_hwmod_softreset() should be

 * renamed to omap_hwmod_set_ocp_softreset(), and omap_hwmod_softreset()

 * should call the hwmod _ocp_softreset() code.

 Write to the SOFTRESET bit */

 Poll on RESETDONE bit */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * linux/arch/arm/mach-omap2/devices.c

 *

 * OMAP2 platform device setup/initialization

-------------------------------------------------------------------------*/

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-omap2/clock.c

 *

 *  Copyright (C) 2005-2008 Texas Instruments, Inc.

 *  Copyright (C) 2004-2010 Nokia Corporation

 *

 *  Contacts:

 *  Richard Woodruff <r-woodruff2@ti.com>

 *  Paul Walmsley

 DPLL valid Fint frequency band limits - from 34xx TRM Section 4.7.6.2 */

/*

 * DPLL valid Fint frequency range for OMAP36xx and OMAP4xxx.

 * From device data manual section 4.3 "DPLL and DLL Specifications".

/**

 * omap2_clk_setup_ll_ops - setup clock driver low-level ops

 *

 * Sets up clock driver low-level platform ops. These are needed

 * for register accesses and various other misc platform operations.

 * Returns 0 on success, -EBUSY if low level ops have been registered

 * already.

/*

 * OMAP2+ specific clock functions

/**

 * ti_clk_init_features - init clock features struct for the SoC

 *

 * Initializes the clock features struct based on the SoC type.

 Fint setup for DPLLs */

 Bypass value setup for DPLLs */

 Jitter correction only available on OMAP343X */

	/* Idlest value for interface clocks.

	 * 24xx uses 0 to indicate not ready, and 1 to indicate ready.

	 * 34xx reverses this, just to keep us on our toes

	 * AM35xx uses both, depending on the module.

 On OMAP3430 ES1.0, DPLL4 can't be re-programmed */

 Errata I810 for omap5 / dra7 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP powerdomain control

 *

 * Copyright (C) 2007-2008, 2011 Texas Instruments, Inc.

 * Copyright (C) 2007-2011 Nokia Corporation

 *

 * Written by Paul Walmsley

 * Added OMAP4 specific support by Abhijit Pagare <abhijitpagare@ti.com>

 * State counting code by Tero Kristo <tero.kristo@nokia.com>

/*

 * Types of sleep_switch used internally in omap_set_pwrdm_state()

 * and its associated static functions

 *

 * XXX Better documentation is needed here

 pwrdm_list contains all registered struct powerdomains */

 Private functions */

/**

 * _pwrdm_register - register a powerdomain

 * @pwrdm: struct powerdomain * to register

 *

 * Adds a powerdomain to the internal powerdomain list.  Returns

 * -EINVAL if given a null pointer, -EEXIST if a powerdomain is

 * already registered by the provided name, or 0 upon success.

 Initialize the powerdomain's state counter */

		/*

		 * If the power domain did not hit the desired state,

		 * generate a trace event with both the desired and hit states

/**

 * _pwrdm_save_clkdm_state_and_activate - prepare for power state change

 * @pwrdm: struct powerdomain * to operate on

 * @curr_pwrst: current power state of @pwrdm

 * @pwrst: power state to switch to

 *

 * Determine whether the powerdomain needs to be turned on before

 * attempting to switch power states.  Called by

 * omap_set_pwrdm_state().  NOTE that if the powerdomain contains

 * multiple clockdomains, this code assumes that the first clockdomain

 * supports software-supervised wakeup mode - potentially a problem.

 * Returns the power state switch mode currently in use (see the

 * "Types of sleep_switch" comment above).

/**

 * _pwrdm_restore_clkdm_state - restore the clkdm hwsup state after pwrst change

 * @pwrdm: struct powerdomain * to operate on

 * @sleep_switch: return value from _pwrdm_save_clkdm_state_and_activate()

 *

 * Restore the clockdomain state perturbed by

 * _pwrdm_save_clkdm_state_and_activate(), and call the power state

 * bookkeeping code.  Called by omap_set_pwrdm_state().  NOTE that if

 * the powerdomain contains multiple clockdomains, this assumes that

 * the first associated clockdomain supports either

 * hardware-supervised idle control in the register, or

 * software-supervised sleep.  No return value.

 Public functions */

/**

 * pwrdm_register_platform_funcs - register powerdomain implementation fns

 * @po: func pointers for arch specific implementations

 *

 * Register the list of function pointers used to implement the

 * powerdomain functions on different OMAP SoCs.  Should be called

 * before any other pwrdm_register*() function.  Returns -EINVAL if

 * @po is null, -EEXIST if platform functions have already been

 * registered, or 0 upon success.

/**

 * pwrdm_register_pwrdms - register SoC powerdomains

 * @ps: pointer to an array of struct powerdomain to register

 *

 * Register the powerdomains available on a particular OMAP SoC.  Must

 * be called after pwrdm_register_platform_funcs().  May be called

 * multiple times.  Returns -EACCES if called before

 * pwrdm_register_platform_funcs(); -EINVAL if the argument @ps is

 * null; or 0 upon success.

/**

 * pwrdm_complete_init - set up the powerdomain layer

 *

 * Do whatever is necessary to initialize registered powerdomains and

 * powerdomain code.  Currently, this programs the next power state

 * for each powerdomain to ON.  This prevents powerdomains from

 * unexpectedly losing context or entering high wakeup latency modes

 * with non-power-management-enabled kernels.  Must be called after

 * pwrdm_register_pwrdms().  Returns -EACCES if called before

 * pwrdm_register_pwrdms(), or 0 upon success.

 Only AM43XX can lose pwrdm context during rtc-ddr suspend */

/**

 * pwrdm_lock - acquire a Linux spinlock on a powerdomain

 * @pwrdm: struct powerdomain * to lock

 *

 * Acquire the powerdomain spinlock on @pwrdm.  No return value.

/**

 * pwrdm_unlock - release a Linux spinlock on a powerdomain

 * @pwrdm: struct powerdomain * to unlock

 *

 * Release the powerdomain spinlock on @pwrdm.  No return value.

/**

 * pwrdm_lookup - look up a powerdomain by name, return a pointer

 * @name: name of powerdomain

 *

 * Find a registered powerdomain by its name @name.  Returns a pointer

 * to the struct powerdomain if found, or NULL otherwise.

/**

 * pwrdm_for_each - call function on each registered clockdomain

 * @fn: callback function *

 *

 * Call the supplied function @fn for each registered powerdomain.

 * The callback function @fn can return anything but 0 to bail out

 * early from the iterator.  Returns the last return value of the

 * callback function, which should be 0 for success or anything else

 * to indicate failure; or -EINVAL if the function pointer is null.

/**

 * pwrdm_add_clkdm - add a clockdomain to a powerdomain

 * @pwrdm: struct powerdomain * to add the clockdomain to

 * @clkdm: struct clockdomain * to associate with a powerdomain

 *

 * Associate the clockdomain @clkdm with a powerdomain @pwrdm.  This

 * enables the use of pwrdm_for_each_clkdm().  Returns -EINVAL if

 * presented with invalid pointers; -ENOMEM if memory could not be allocated;

 * or 0 upon success.

/**

 * pwrdm_get_mem_bank_count - get number of memory banks in this powerdomain

 * @pwrdm: struct powerdomain *

 *

 * Return the number of controllable memory banks in powerdomain @pwrdm,

 * starting with 1.  Returns -EINVAL if the powerdomain pointer is null.

/**

 * pwrdm_set_next_pwrst - set next powerdomain power state

 * @pwrdm: struct powerdomain * to set

 * @pwrst: one of the PWRDM_POWER_* macros

 *

 * Set the powerdomain @pwrdm's next power state to @pwrst.  The powerdomain

 * may not enter this state immediately if the preconditions for this state

 * have not been satisfied.  Returns -EINVAL if the powerdomain pointer is

 * null or if the power state is invalid for the powerdomin, or returns 0

 * upon success.

 Trace the pwrdm desired target state */

 Program the pwrdm desired target state */

/**

 * pwrdm_read_next_pwrst - get next powerdomain power state

 * @pwrdm: struct powerdomain * to get power state

 *

 * Return the powerdomain @pwrdm's next power state.  Returns -EINVAL

 * if the powerdomain pointer is null or returns the next power state

 * upon success.

/**

 * pwrdm_read_pwrst - get current powerdomain power state

 * @pwrdm: struct powerdomain * to get power state

 *

 * Return the powerdomain @pwrdm's current power state.	Returns -EINVAL

 * if the powerdomain pointer is null or returns the current power state

 * upon success. Note that if the power domain only supports the ON state

 * then just return ON as the current state.

/**

 * pwrdm_read_prev_pwrst - get previous powerdomain power state

 * @pwrdm: struct powerdomain * to get previous power state

 *

 * Return the powerdomain @pwrdm's previous power state.  Returns -EINVAL

 * if the powerdomain pointer is null or returns the previous power state

 * upon success.

/**

 * pwrdm_set_logic_retst - set powerdomain logic power state upon retention

 * @pwrdm: struct powerdomain * to set

 * @pwrst: one of the PWRDM_POWER_* macros

 *

 * Set the next power state @pwrst that the logic portion of the

 * powerdomain @pwrdm will enter when the powerdomain enters retention.

 * This will be either RETENTION or OFF, if supported.  Returns

 * -EINVAL if the powerdomain pointer is null or the target power

 * state is not supported, or returns 0 upon success.

/**

 * pwrdm_set_mem_onst - set memory power state while powerdomain ON

 * @pwrdm: struct powerdomain * to set

 * @bank: memory bank number to set (0-3)

 * @pwrst: one of the PWRDM_POWER_* macros

 *

 * Set the next power state @pwrst that memory bank @bank of the

 * powerdomain @pwrdm will enter when the powerdomain enters the ON

 * state.  @bank will be a number from 0 to 3, and represents different

 * types of memory, depending on the powerdomain.  Returns -EINVAL if

 * the powerdomain pointer is null or the target power state is not

 * supported for this memory bank, -EEXIST if the target memory

 * bank does not exist or is not controllable, or returns 0 upon

 * success.

/**

 * pwrdm_set_mem_retst - set memory power state while powerdomain in RET

 * @pwrdm: struct powerdomain * to set

 * @bank: memory bank number to set (0-3)

 * @pwrst: one of the PWRDM_POWER_* macros

 *

 * Set the next power state @pwrst that memory bank @bank of the

 * powerdomain @pwrdm will enter when the powerdomain enters the

 * RETENTION state.  Bank will be a number from 0 to 3, and represents

 * different types of memory, depending on the powerdomain.  @pwrst

 * will be either RETENTION or OFF, if supported.  Returns -EINVAL if

 * the powerdomain pointer is null or the target power state is not

 * supported for this memory bank, -EEXIST if the target memory

 * bank does not exist or is not controllable, or returns 0 upon

 * success.

/**

 * pwrdm_read_logic_pwrst - get current powerdomain logic retention power state

 * @pwrdm: struct powerdomain * to get current logic retention power state

 *

 * Return the power state that the logic portion of powerdomain @pwrdm

 * will enter when the powerdomain enters retention.  Returns -EINVAL

 * if the powerdomain pointer is null or returns the logic retention

 * power state upon success.

/**

 * pwrdm_read_prev_logic_pwrst - get previous powerdomain logic power state

 * @pwrdm: struct powerdomain * to get previous logic power state

 *

 * Return the powerdomain @pwrdm's previous logic power state.  Returns

 * -EINVAL if the powerdomain pointer is null or returns the previous

 * logic power state upon success.

/**

 * pwrdm_read_logic_retst - get next powerdomain logic power state

 * @pwrdm: struct powerdomain * to get next logic power state

 *

 * Return the powerdomain pwrdm's logic power state.  Returns -EINVAL

 * if the powerdomain pointer is null or returns the next logic

 * power state upon success.

/**

 * pwrdm_read_mem_pwrst - get current memory bank power state

 * @pwrdm: struct powerdomain * to get current memory bank power state

 * @bank: memory bank number (0-3)

 *

 * Return the powerdomain @pwrdm's current memory power state for bank

 * @bank.  Returns -EINVAL if the powerdomain pointer is null, -EEXIST if

 * the target memory bank does not exist or is not controllable, or

 * returns the current memory power state upon success.

/**

 * pwrdm_read_prev_mem_pwrst - get previous memory bank power state

 * @pwrdm: struct powerdomain * to get previous memory bank power state

 * @bank: memory bank number (0-3)

 *

 * Return the powerdomain @pwrdm's previous memory power state for

 * bank @bank.  Returns -EINVAL if the powerdomain pointer is null,

 * -EEXIST if the target memory bank does not exist or is not

 * controllable, or returns the previous memory power state upon

 * success.

/**

 * pwrdm_read_mem_retst - get next memory bank power state

 * @pwrdm: struct powerdomain * to get mext memory bank power state

 * @bank: memory bank number (0-3)

 *

 * Return the powerdomain pwrdm's next memory power state for bank

 * x.  Returns -EINVAL if the powerdomain pointer is null, -EEXIST if

 * the target memory bank does not exist or is not controllable, or

 * returns the next memory power state upon success.

/**

 * pwrdm_clear_all_prev_pwrst - clear previous powerstate register for a pwrdm

 * @pwrdm: struct powerdomain * to clear

 *

 * Clear the powerdomain's previous power state register @pwrdm.

 * Clears the entire register, including logic and memory bank

 * previous power states.  Returns -EINVAL if the powerdomain pointer

 * is null, or returns 0 upon success.

	/*

	 * XXX should get the powerdomain's current state here;

	 * warn & fail if it is not ON.

/**

 * pwrdm_enable_hdwr_sar - enable automatic hardware SAR for a pwrdm

 * @pwrdm: struct powerdomain *

 *

 * Enable automatic context save-and-restore upon power state change

 * for some devices in the powerdomain @pwrdm.  Warning: this only

 * affects a subset of devices in a powerdomain; check the TRM

 * closely.  Returns -EINVAL if the powerdomain pointer is null or if

 * the powerdomain does not support automatic save-and-restore, or

 * returns 0 upon success.

/**

 * pwrdm_disable_hdwr_sar - disable automatic hardware SAR for a pwrdm

 * @pwrdm: struct powerdomain *

 *

 * Disable automatic context save-and-restore upon power state change

 * for some devices in the powerdomain @pwrdm.  Warning: this only

 * affects a subset of devices in a powerdomain; check the TRM

 * closely.  Returns -EINVAL if the powerdomain pointer is null or if

 * the powerdomain does not support automatic save-and-restore, or

 * returns 0 upon success.

/**

 * pwrdm_has_hdwr_sar - test whether powerdomain supports hardware SAR

 * @pwrdm: struct powerdomain *

 *

 * Returns 1 if powerdomain @pwrdm supports hardware save-and-restore

 * for some devices, or 0 if it does not.

/**

 * pwrdm_get_valid_lp_state() - Find best match deep power state

 * @pwrdm:	power domain for which we want to find best match

 * @is_logic_state: Are we looking for logic state match here? Should

 *		    be one of PWRDM_xxx macro values

 * @req_state:	requested power state

 *

 * Returns: closest match for requested power state. default fallback

 * is RET for logic state and ON for power state.

 *

 * This does a search from the power domain data looking for the

 * closest valid power domain state that the hardware can achieve.

 * PRCM definitions for PWRSTCTRL allows us to program whatever

 * configuration we'd like, and PRCM will actually attempt such

 * a transition, however if the powerdomain does not actually support it,

 * we endup with a hung system. The valid power domain states are already

 * available in our powerdomain data files. So this function tries to do

 * the following:

 * a) find if we have an exact match to the request - no issues.

 * b) else find if a deeper power state is possible.

 * c) failing which, it tries to find closest higher power state for the

 * request.

 For logic, ret is highest and others, ON is highest */

 If it is already supported, nothing to search */

	/*

	 * So, we dont have a exact match

	 * Can we get a deeper power state match?

 No match even at OFF? Not available */

 OK, no deeper ones, can we get a higher match? */

/**

 * omap_set_pwrdm_state - change a powerdomain's current power state

 * @pwrdm: struct powerdomain * to change the power state of

 * @pwrst: power state to change to

 *

 * Change the current hardware power state of the powerdomain

 * represented by @pwrdm to the power state represented by @pwrst.

 * Returns -EINVAL if @pwrdm is null or invalid or if the

 * powerdomain's current power state could not be read, or returns 0

 * upon success or if @pwrdm does not support @pwrst or any

 * lower-power state.  XXX Should not return 0 if the @pwrdm does not

 * support @pwrst or any lower-power state: this should be an error.

/**

 * pwrdm_get_context_loss_count - get powerdomain's context loss count

 * @pwrdm: struct powerdomain * to wait for

 *

 * Context loss count is the sum of powerdomain off-mode counter, the

 * logic off counter and the per-bank memory off counter.  Returns negative

 * (and WARNs) upon error, otherwise, returns the context loss count.

	/*

	 * Context loss count has to be a non-negative value. Clear the sign

	 * bit to get a value range from 0 to INT_MAX.

/**

 * pwrdm_can_ever_lose_context - can this powerdomain ever lose context?

 * @pwrdm: struct powerdomain *

 *

 * Given a struct powerdomain * @pwrdm, returns 1 if the powerdomain

 * can lose either memory or logic context or if @pwrdm is invalid, or

 * returns 0 otherwise.  This function is not concerned with how the

 * powerdomain registers are programmed (i.e., to go off or not); it's

 * concerned with whether it's ever possible for this powerdomain to

 * go off while some other part of the chip is active.  This function

 * assumes that every powerdomain can go to either ON or INACTIVE.

/**

 * pwrdm_save_context - save powerdomain registers

 *

 * Register state is going to be lost due to a suspend or hibernate

 * event. Save the powerdomain registers.

/**

 * pwrdm_save_context - restore powerdomain registers

 *

 * Restore powerdomain control registers after a suspend or resume

 * event.

	/*

	 * Power has been lost across all powerdomains, increment the

	 * counter.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * pmic-cpcap.c - CPCAP-specific functions for the OPP code

 *

 * Adapted from Motorola Mapphone Android Linux kernel

 * Copyright (C) 2011 Motorola, Inc.

/**

 * omap_cpcap_vsel_to_vdc - convert CPCAP VSEL value to microvolts DC

 * @vsel: CPCAP VSEL value to convert

 *

 * Returns the microvolts DC that the CPCAP PMIC should generate when

 * programmed with @vsel.

/**

 * omap_cpcap_uv_to_vsel - convert microvolts DC to CPCAP VSEL value

 * @uv: microvolts DC to convert

 *

 * Returns the VSEL value necessary for the CPCAP PMIC to

 * generate an output voltage equal to or greater than @uv microvolts DC.

/**

 * omap_max8952_vsel_to_vdc - convert MAX8952 VSEL value to microvolts DC

 * @vsel: MAX8952 VSEL value to convert

 *

 * Returns the microvolts DC that the MAX8952 Regulator should generate when

 * programmed with @vsel.

/**

 * omap_max8952_uv_to_vsel - convert microvolts DC to MAX8952 VSEL value

 * @uv: microvolts DC to convert

 *

 * Returns the VSEL value necessary for the MAX8952 Regulator to

 * generate an output voltage equal to or greater than @uv microvolts DC.

/**

 * omap_fan5355_vsel_to_vdc - convert FAN535503 VSEL value to microvolts DC

 * @vsel: FAN535503 VSEL value to convert

 *

 * Returns the microvolts DC that the FAN535503 Regulator should generate when

 * programmed with @vsel.

 Extract bits[5:0] */

/**

 * omap_fan535508_vsel_to_vdc - convert FAN535508 VSEL value to microvolts DC

 * @vsel: FAN535508 VSEL value to convert

 *

 * Returns the microvolts DC that the FAN535508 Regulator should generate when

 * programmed with @vsel.

 Extract bits[5:0] */

/**

 * omap_fan535503_uv_to_vsel - convert microvolts DC to FAN535503 VSEL value

 * @uv: microvolts DC to convert

 *

 * Returns the VSEL value necessary for the MAX8952 Regulator to

 * generate an output voltage equal to or greater than @uv microvolts DC.

/**

 * omap_fan535508_uv_to_vsel - convert microvolts DC to FAN535508 VSEL value

 * @uv: microvolts DC to convert

 *

 * Returns the VSEL value necessary for the MAX8952 Regulator to

 * generate an output voltage equal to or greater than @uv microvolts DC.

 fan5335-core */

 fan5335 iva */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *

 * OMAP SRAM detection and management

 *

 * Copyright (C) 2005 Nokia Corporation

 * Written by Tony Lindgren <tony@atomide.com>

 *

 * Copyright (C) 2009-2012 Texas Instruments

 * Added OMAP4/5 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

/*

 * Depending on the target RAMFS firewall setup, the public usable amount of

 * SRAM varies.  The default accessible size for all device types is 2k. A GP

 * device allows ARM11 but not other initiators for full size. This

 * functionality seems ok until some nice security API happens.

 RAMFW: R/W access to all initiators for all qualifier sets */

 all q-vects */

 all i-read */

 all i-write */

 all q-vects */

 all i-read */

 all i-write */

 assume locked with no PPA or security driver */

/*

 * The amount of SRAM depends on the core type.

 * Note that we cannot try to test for SRAM here because writes

 * to secure SRAM will hang the system. Also the SRAM is not

 * yet mapped at this point.

 28K */

 32K */

 2K */

 64K */

 640K */

 64K */

/*

 * Note that we cannot use ioremap for SRAM, as clock init needs SRAM early.

		/*

		 * SRAM must be marked as non-cached on OMAP3 since the

		 * CORE DPLL M2 divider change code (in SRAM) runs with the

		 * SDRAM controller disabled, and if it is marked cached,

		 * the ARM may attempt to write cache lines back to SDRAM

		 * which will cause the system to hang.

 CONFIG_ARCH_OMAP3 */

/*

 * AM33XX Power domain data

 *

 * Copyright (C) 2011-2012 Texas Instruments Incorporated - https://www.ti.com/

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 gfx_mem */

 gfx_mem */

 gfx_mem */

 gfx_mem */

 gfx_mem */

 gfx_mem */

 pruss_mem */

 per_mem */

 ram_mem */

 pruss_mem */

 per_mem */

 ram_mem */

 pruss_mem */

 per_mem */

 ram_mem */

 pruss_mem */

 per_mem */

 ram_mem */

 pruss_mem */

 per_mem */

 ram_mem */

 pruss_mem */

 per_mem */

 ram_mem */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

  * This file configures the internal USB PHY in OMAP4430. Used

  * with TWL6030 transceiver and MUSB on OMAP4430.

  *

  * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com

  * Author: Hema HK <hemahk@ti.com>

/**

 * omap4430_phy_power_down: disable MUSB PHY during early init

 *

 * OMAP4 MUSB PHY module is enabled by default on reset, but this will

 * prevent core retention if not disabled by SW. USB driver will

 * later on enable this, once and if the driver needs it.

 Power down the phy */

 Reset the musb interface */

		/*

		 * Start the on-chip PHY and its PLL.

		/*

		 * Power down the on-chip PHY.

 Force VBUS valid, ID = 0 */

 Force VBUS valid, ID = 1 */

 Don't override the VBUS/ID comparators */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod common data structures

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Thara Gopinath <thara@ti.com>

 * Benot Cousson

 *

 * Copyright (C) 2010 Nokia Corporation

 * Paul Walmsley

 *

 * This data/structures are to be used while defining OMAP on-chip module

 * data and their integration with other OMAP modules and Linux.

/**

 * struct omap_hwmod_sysc_type1 - TYPE1 sysconfig scheme.

 *

 * To be used by hwmod structure to specify the sysconfig offsets

 * if the device ip is compliant with the original PRCM protocol

 * defined for OMAP2420.

/**

 * struct omap_hwmod_sysc_type2 - TYPE2 sysconfig scheme.

 *

 * To be used by hwmod structure to specify the sysconfig offsets if the

 * device ip is compliant with the new PRCM protocol defined for new

 * OMAP4 IPs.

/**

 * struct omap_hwmod_sysc_type3 - TYPE3 sysconfig scheme.

 * Used by some IPs on AM33xx

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3 Power Management Routines

 *

 * Copyright (C) 2006-2008 Nokia Corporation

 * Tony Lindgren <tony@atomide.com>

 * Jouni Hogander

 *

 * Copyright (C) 2007 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 *

 * Copyright (C) 2005 Texas Instruments, Inc.

 * Richard Woodruff <r-woodruff2@ti.com>

 *

 * Based on pm.c for omap1

 pm34xx errata defined in pm.h */

	/*

	 * Force write last pad into memory, as this can fail in some

	 * cases according to errata 1.157, 1.185

 Save the Interrupt controller context */

 Save the system control module context, padconf already save above*/

 Restore the control module context, padconf restored by h/w */

 Restore the interrupt controller context */

/*

 * FIXME: This function should be called before entering off-mode after

 * OMAP3 secure services have been accessed. Currently it is only called

 * once during boot sequence, but this works as we are not using secure

 * services.

		/*

		 * MPU next state must be set to POWER_ON temporarily,

		 * otherwise the WFI executed inside the ROM code

		 * will hang the system.

 Following is for error tracking, it should not happen */

	/*

	 * Clear all except ST_IO and ST_IO_CHAIN for wkup module,

	 * these are handled in a separate handler to avoid acking

	 * IO events before parsing in mux code

 Read Auxiliary Control Register */

 Read L2 AUX ctrl register */

	/* Variable to tell what needs to be saved and restored

 save_state = 0 => Nothing to save and restored */

 save_state = 1 => Only L1 and logic lost */

 save_state = 2 => Only L2 lost */

 save_state = 3 => L1, L2 and logic lost */

 No need to save context */

 Invalid state */

 NEON control */

 Enable IO-PAD and IO-CHAIN wakeups */

 PER */

 CORE */

 Configure PMIC signaling for I2C4 or sys_off_mode */

	/*

	 * On EMU/HS devices ROM code restores a SRDC value

	 * from scratchpad which has automatic self refresh on timeout

	 * of AUTO_CNT = 1 enabled. This takes care of erratum ID i443.

	 * Hence store/restore the SDRC_POWER register here.

	/*

	 * omap3_arm_context is the location where some ARM context

	 * get saved. The rest is placed on the stack, and restored

	 * from there before resuming.

 Restore normal SDRC POWER settings */

 CORE */

		/*

		 * In off-mode resume path above, omap3_core_restore_context

		 * also handles the INTC autoidle restore done here so limit

		 * this to non-off mode resume paths so we don't do it twice.

 PER */

 Read current next_pwrsts */

 Set ones wanted by suspend */

 Restore next_pwrsts */

 CONFIG_SUSPEND */

/*

 * Push functions to SRAM

 *

 * The minimum set of functions is pushed to SRAM for execution:

 * - omap3_do_wfi for erratum i581 WA,

 Enable the l2 cache toggling in sleep logic */

	/* XXX prcm_setup_regs needs to be before enabling hw

 IO interrupt is shared with mux code */

	/*

	 * RTA is disabled during initialization as per erratum i608

	 * it is safer to disable RTA by the bootloader, but we would like

	 * to be doubly sure here and prevent any mishaps.

	/*

	 * The UART3/4 FIFO and the sidetone memory in McBSP2/3 are

	 * not correctly reset when the PER powerdomain comes back

	 * from OFF or OSWR when the CORE powerdomain is kept active.

	 * See OMAP36xx Erratum i582 "PER Domain reset issue after

	 * Domain-OFF/OSWR Wakeup".  This wakeup dependency is not a

	 * complete workaround.  The kernel must also prevent the PER

	 * powerdomain from going to OSWR/OFF while the CORE

	 * powerdomain is not going to OSWR/OFF.  And if PER last

	 * power state was off while CORE last power state was ON, the

	 * UART3/4 and McBSP2/3 SIDETONE devices need to run a

	 * self-test using their loopback tests; if that fails, those

	 * devices are unusable until the PER/CORE can complete a transition

	 * from ON to OSWR/OFF and then back to ON.

	 *

	 * XXX Technically this workaround is only needed if off-mode

	 * or OSWR is enabled.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4+ CPU idle Routines

 *

 * Copyright (C) 2011-2013 Texas Instruments, Inc.

 * Santosh Shilimkar <santosh.shilimkar@ti.com>

 * Rajendra Nayak <rnayak@ti.com>

 Machine specific information */

 Private functions */

/**

 * omap_enter_idle_[simple/coupled] - OMAP4PLUS cpuidle entry functions

 * @dev: cpuidle device

 * @drv: cpuidle driver

 * @index: the index of state to be entered

 *

 * Called from the CPUidle framework to program the device to the

 * specified low power state selected by the governor.

 * Returns the amount of time spent in the low power state.

	/*

	 * CPU0 has to wait and stay ON until CPU1 is OFF state.

	 * This is necessary to honour hardware recommondation

	 * of triggeing all the possible low power modes once CPU1 is

	 * out of coherency and in OFF mode.

			/*

			 * CPU1 could have already entered & exited idle

			 * without hitting off because of a wakeup

			 * or a failed attempt to hit off mode.  Check for

			 * that here, otherwise we could spin forever

			 * waiting for CPU1 off.

 Enter broadcast mode for periodic timers */

 Enter broadcast mode for one-shot timers */

	/*

	 * Call idle CPU PM enter notifier chain so that

	 * VFP and per CPU interrupt context is saved.

		/*

		 * Call idle CPU cluster PM enter notifier chain

		 * to save GIC and wakeupgen context.

 Wakeup CPU1 only if it is not offlined */

	/*

	 * Call idle CPU cluster PM exit notifier chain

	 * to restore GIC and wakeupgen context.

	/*

	 * Call idle CPU PM exit notifier chain to restore

	 * VFP and per CPU IRQ context.

 C1 - CPU0 ON + CPU1 ON + MPU ON */

 C2 - CPU0 OFF + CPU1 OFF + MPU CSWR */

 C3 - CPU0 OFF + CPU1 OFF + MPU OSWR */

 C1 - CPU0 ON + CPU1 ON + MPU ON */

 C2 - CPU0 RET + CPU1 RET + MPU CSWR */

 Public functions */

/**

 * omap4_idle_init - Init routine for OMAP4+ idle

 *

 * Registers the OMAP4+ specific cpuidle driver to the cpuidle

 * framework with the valid set of states.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2+ DMA driver

 *

 * Copyright (C) 2003 - 2008 Nokia Corporation

 * Author: Juha Yrjl <juha.yrjola@nokia.com>

 * DMA channel linking for 1610 by Samuel Ortiz <samuel.ortiz@nokia.com>

 * Graphics DMA and LCD DMA graphics tranformations

 * by Imre Deak <imre.deak@nokia.com>

 * OMAP2/3 support Copyright (C) 2004-2007 Texas Instruments, Inc.

 * Some functions based on earlier dma-omap.c Copyright (C) 2001 RidgeRun, Inc.

 *

 * Copyright (C) 2009 Texas Instruments

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * Copyright (C) 2010 Texas Instruments Incorporated - https://www.ti.com/

 * Converted DMA library into platform driver

 *	- G, Manjunath Kondaiah <manjugk@ti.com>

 Common register offsets */

 Channel specific register offsets */

 OMAP4 specific registers */

	/*

	 * Errata applicable for OMAP2430ES1.0 and all omap2420

	 *

	 * I.

	 * Erratum ID: Not Available

	 * Inter Frame DMA buffering issue DMA will wrongly

	 * buffer elements if packing and bursting is enabled. This might

	 * result in data gets stalled in FIFO at the end of the block.

	 * Workaround: DMA channels must have BUFFERING_DISABLED bit set to

	 * guarantee no data will stay in the DMA FIFO in case inter frame

	 * buffering occurs

	 *

	 * II.

	 * Erratum ID: Not Available

	 * DMA may hang when several channels are used in parallel

	 * In the following configuration, DMA channel hanging can occur:

	 * a. Channel i, hardware synchronized, is enabled

	 * b. Another channel (Channel x), software synchronized, is enabled.

	 * c. Channel i is disabled before end of transfer

	 * d. Channel i is reenabled.

	 * e. Steps 1 to 4 are repeated a certain number of times.

	 * f. A third channel (Channel y), software synchronized, is enabled.

	 * Channel x and Channel y may hang immediately after step 'f'.

	 * Workaround:

	 * For any channel used - make sure NextLCH_ID is set to the value j.

	/*

	 * Erratum ID: i378: OMAP2+: sDMA Channel is not disabled

	 * after a transaction error.

	 * Workaround: SW should explicitely disable the channel.

	/*

	 * Erratum ID: i541: sDMA FIFO draining does not finish

	 * If sDMA channel is disabled on the fly, sDMA enters standby even

	 * through FIFO Drain is still in progress

	 * Workaround: Put sDMA in NoStandby more before a logical channel is

	 * disabled, then put it back to SmartStandby right after the channel

	 * finishes FIFO draining.

	/*

	 * Erratum ID: i88 : Special programming model needed to disable DMA

	 * before end of block.

	 * Workaround: software must ensure that the DMA is configured in No

	 * Standby mode(DMAx_OCP_SYSCONFIG.MIDLEMODE = "01")

	/*

	 * Erratum 3.2/3.3: sometimes 0 is returned if CSAC/CDAC is

	 * read before the DMA controller finished disabling the channel.

	/*

	 * Erratum ID: Not Available

	 * A bug in ROM code leaves IRQ status for channels 0 and 1 uncleared

	 * after secure sram context save and restore.

	 * Work around: Hence we need to manually clear those IRQs to avoid

	 * spurious interrupts. This affects only secure devices.

 external DMA requests when tusb6010 is used */

 OMAP2420 only */

 OMAP2420 only */

 OMAP2420 only */

 OMAP2420 only */

 One time initializations */

 DMA slave map for drivers not yet converted to DT */

 SPDX-License-Identifier: GPL-2.0

/*

 * TI AM33XX and AM43XX PM Assembly Offsets

 *

 * Copyright (C) 2017-2018 Texas Instruments Inc.

 SPDX-License-Identifier: GPL-2.0

/*

 * AM33XX Arch Power Management Routines

 *

 * Copyright (C) 2016-2018 Texas Instruments Incorporated - https://www.ti.com/

 *	Dave Gerlach

 off mode not supported on am335x so return 0 always */

	/*

	 * Check for am437x-gp-evm which has the right Hardware design to

	 * support this mode reliably.

 CEFUSE domain can be turned off post bootup */

	/*

	 * Because gfx_pwrdm is the only one under MPU control,

	 * comment on transition status

	/*

	 * BUG: GFX_L4LS clock domain needs to be woken up to

	 * ensure thet L4LS clock domain does not get stuck in

	 * transition. If that happens L3 module does not get

	 * disabled, thereby leading to PER power domain

	 * transition failing

 Suspend secure side on HS devices */

	/*

	 * Resume secure side on HS devices.

	 *

	 * Note that even on systems with OP-TEE available this resume call is

	 * issued to the ROM. This is because upon waking from suspend the ROM

	 * is restored as the secure monitor. On systems with OP-TEE ROM will

	 * restore OP-TEE during this call.

	/*

	 * HACK: restore dpll_per_clkdcoldo register contents, to avoid

	 * breaking suspend-resume

/*

 * Block system suspend initially. Later on pm33xx sets up it's own

 * platform_suspend_ops after probe. That depends also on loaded

 * wkup_m3_ipc and booted am335x-pm-firmware.elf.

 CONFIG_SUSPEND */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2005 Nokia Corporation

 * Author: Paul Mundt <paul.mundt@nokia.com>

 *

 * Copyright (C) 2011 Texas Instruments Incorporated - https://www.ti.com/

 *

 * Modified from the original mach-omap/omap2/board-generic.c did by Paul

 * to support the OMAP2+ device tree boards with an unique board file.

 Clocks are needed early, see drivers/clocksource for the rest */

 Used by am437x for ARM timer in non-SMP configurations */

 Some boards need board name for legacy userspace in /proc/cpuinfo */

 Set system_rev from atags */

/* Legacy userspace on Nokia N900 needs ATAGS exported in /proc/atags,

 * save them while the data is still not overwritten

 Generic omap3 boards, most boards can use these */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP Secure API infrastructure.

 *

 * Copyright (C) 2011 Texas Instruments, Inc.

 *	Santosh Shilimkar <santosh.shilimkar@ti.com>

 * Copyright (C) 2012 Ivaylo Dimitrov <freemangordon@abv.bg>

 * Copyright (C) 2013 Pali Rohr <pali@kernel.org>

	/*

	 * We only check that the OP-TEE node is present and available. The

	 * OP-TEE kernel driver is not needed for the type of interaction made

	 * with OP-TEE here so the driver's status is not checked.

/**

 * omap_sec_dispatcher: Routine to dispatch low power secure

 * service routines

 * @idx: The HAL API index

 * @flag: The flag indicating criticality of operation

 * @nargs: Number of valid arguments out of four.

 * @arg1, arg2, arg3 args4: Parameters passed to secure API

 *

 * Return the non-zero error value on failure.

	/*

	 * Secure API needs physical address

	 * pointer for the parameters

	/*

	 * If this platform has OP-TEE installed we use ARM SMC calls

	 * otherwise fall back to the OMAP ROM style calls.

 Allocate the memory to save secure ram */

 Number of arguments */

 Physical address for saving */

/**

 * rx51_secure_dispatcher: Routine to dispatch secure PPA API calls

 * @idx: The PPA API index

 * @process: Process ID

 * @flag: The flag indicating criticality of operation

 * @nargs: Number of valid arguments out of four.

 * @arg1, arg2, arg3 args4: Parameters passed to secure API

 *

 * Return the non-zero error value on failure.

 *

 * NOTE: rx51_secure_dispatcher differs from omap_secure_dispatcher because

 *       it calling omap_smc3() instead omap_smc2() and param[0] is nargs+1

 RX-51 needs number of arguments + 1 */

	/*

	 * Secure API needs physical address

	 * pointer for the parameters

/**

 * rx51_secure_update_aux_cr: Routine to modify the contents of Auxiliary Control Register

 *  @set_bits: bits to set in ACR

 *  @clr_bits: bits to clear in ACR

 *

 * Return the non-zero error value on failure.

 Read ACR */

/**

 * rx51_secure_rng_call: Routine for HW random generator

/*

 * Dummy dispatcher call after core OSWR and MPU off. Updates the ROM return

 * address after MMU has been re-enabled after CPU1 has been woken up again.

 * Otherwise the ROM code will attempt to use the earlier physical return

 * address that got set with MMU off when waking up CPU1. Only used on secure

 * devices.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP MPUSS low power code

 *

 * Copyright (C) 2011 Texas Instruments, Inc.

 *	Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * OMAP4430 MPUSS mainly consists of dual Cortex-A9 with per-CPU

 * Local timer and Watchdog, GIC, SCU, PL310 L2 cache controller,

 * CPU0 and CPU1 LPRM modules.

 * CPU0, CPU1 and MPUSS each have there own power domain and

 * hence multiple low power combinations of MPUSS are possible.

 *

 * The CPU0 and CPU1 can't support Closed switch Retention (CSWR)

 * because the mode is not supported by hw constraints of dormant

 * mode. While waking up from the dormant mode, a reset  signal

 * to the Cortex-A9 processor must be asserted by the external

 * power controller.

 *

 * With architectural inputs and hardware recommendations, only

 * below modes are supported from power gain vs latency point of view.

 *

 *	CPU0		CPU1		MPUSS

 *	----------------------------------------------

 *	ON		ON		ON

 *	ON(Inactive)	OFF		ON(Inactive)

 *	OFF		OFF		CSWR

 *	OFF		OFF		OSWR

 *	OFF		OFF		OFF(Device OFF *TBD)

 *	----------------------------------------------

 *

 * Note: CPU0 is the master core and it is the last CPU to go down

 * and first to wake-up when MPUSS low power states are excercised

/**

 * struct cpu_pm_ops - CPU pm operations

 * @finish_suspend:	CPU suspend finisher function pointer

 * @resume:		CPU resume function pointer

 * @scu_prepare:	CPU Snoop Control program function pointer

 * @hotplug_restart:	CPU restart function pointer

 *

 * Structure holds functions pointer for CPU low power operations like

 * suspend, resume and scu programming.

/*

 * Program the wakeup routine address for the CPU0 and CPU1

 * used for OFF or DORMANT wakeup.

/*

 * Store the SCU power status value to scratchpad memory

 Helper functions for MPUSS OSWR */

/*

 * Store the CPU cluster state for L2X0 low power operations.

/*

 * Save the L2X0 AUXCTRL and POR value to SAR memory. Its used to

 * in every restore MPUSS OFF path.

/**

 * omap4_enter_lowpower: OMAP4 MPUSS Low Power Entry Function

 * The purpose of this function is to manage low power programming

 * of OMAP4 MPUSS subsystem

 * @cpu : CPU ID

 * @power_state: Low power state.

 *

 * MPUSS states for the context save:

 * save_state =

 *	0 - Nothing lost and no need to save: MPUSS INACTIVE

 *	1 - CPUx L1 and logic lost: MPUSS CSWR

 *	2 - CPUx L1 and logic lost + GIC lost: MPUSS OSWR

 *	3 - CPUx L1 and logic lost + GIC + L2 lost: DEVICE OFF

		/*

		 * CPUx CSWR is invalid hardware state. Also CPUx OSWR

		 * doesn't make much scense, since logic is lost and $L1

		 * needs to be cleaned because of coherency. This makes

		 * CPUx OSWR equivalent to CPUX OFF and hence not supported

	/*

	 * Check MPUSS next state and save interrupt controller if needed.

	 * In MPUSS OSWR or device OFF, interrupt controller  contest is lost.

	/*

	 * Call low level function  with targeted low power state.

	/*

	 * Restore the CPUx power state to ON otherwise CPUx

	 * power domain can transitions to programmed low power

	 * state while doing WFI outside the low powe code. On

	 * secure devices, CPUx does WFI which can result in

	 * domain transition

/**

 * omap4_hotplug_cpu: OMAP4 CPU hotplug entry

 * @cpu : CPU ID

 * @power_state: CPU low power state.

 Use the achievable power state for the domain */

	/*

	 * CPU never retuns back if targeted power state is OFF mode.

	 * CPU ONLINE follows normal CPU ONLINE ptah via

	 * omap4_secondary_startup().

/*

 * Enable Mercury Fast HG retention mode by default.

 Enable HG_EN, HG_RAMPUP = fast mode */

/*

 * Initialise OMAP4 MPUSS

 Initilaise per CPU PM information */

 Clear CPU previous power domain state */

 Initialise CPU0 power domain state to ON */

 Clear CPU previous power domain state */

 Initialise CPU1 power domain state to ON */

 Save device type on scratchpad for low level code to use */

/*

 * For kexec, we must set CPU1_WAKEUP_NS_PA_ADDR to point to

 * current kernel's secondary_startup() early before

 * clockdomains_init(). Otherwise clockdomain_init() can

 * wake CPU1 and cause a hang.

 Save old NS_PA_ADDR for validity checks later on */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod_2xxx_3xxx_ipblock_data.c - common IP block data for OMAP2/3

 *

 * Copyright (C) 2011 Nokia Corporation

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 UART */

/*

 * 'venc' class

 * video encoder

/*

 * omap_hwmod class data

/*

 * TI81XX Clock Domain data.

 *

 * Copyright (C) 2010 Texas Instruments, Inc. - https://www.ti.com/

 * Copyright (C) 2013 SKTB SKiT, http://www.skitlab.ru/

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * Note that 814x seems to have HWSUP_SWSUP for many clockdomains

 * while 816x does not. According to the TRM, 816x only has HWSUP

 * for ALWON_L3_FAST. Also note that the TI tree clockdomains81xx.h

 * seems to have the related ifdef the wrong way around claiming

 * 816x supports HWSUP while 814x does not. For now, we only set

 * HWSUP for ALWON_L3_FAST as that seems to be supported for both

 * dm814x and dm816x.

 Common for 81xx */

 816x only */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 SMP cpu-hotplug support

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Author:

 *      Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * Platform file needed for the OMAP4 SMP. This file is based on arm

 * realview smp platform.

 * Copyright (c) 2002 ARM Limited.

/*

 * platform-specific code to shutdown a CPU

 * Called with IRQs disabled

	/*

	 * we're ready for shutdown now, so do it

		/*

		 * Enter into low power state

			/*

			 * OK, proper wakeup, we're done

 Needed by kexec and platform_can_cpu_hotplug() */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap4-restart.c - Common to OMAP4 and OMAP5

/**

 * omap44xx_restart - trigger a software restart of the SoC

 * @mode: the "reboot mode", see arch/arm/kernel/{setup,process}.c

 * @cmd: passed from the userspace program rebooting the system (if provided)

 *

 * Resets the SoC.  For @cmd, see the 'reboot' syscall in

 * kernel/sys.c.  No return value.

 XXX Should save 'cmd' into scratchpad for use after reboot */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3 Voltage Processor (VP) data

 *

 * Copyright (C) 2007, 2010 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Lesly A M <x0080970@ti.com>

 * Thara Gopinath <thara@ti.com>

 *

 * Copyright (C) 2008, 2011 Nokia Corporation

 * Kalle Jokiniemi

 * Paul Walmsley

/*

 * VP data common to 34xx/36xx chips

 * XXX This stuff presumably belongs in the vp3xxx.c or vp.c file.

/*

 * OMAP3 OPP table definitions.

 *

 * Copyright (C) 2009-2010 Texas Instruments Incorporated - https://www.ti.com/

 *	Nishanth Menon

 *	Kevin Hilman

 * Copyright (C) 2010-2011 Nokia Corporation.

 *      Eduardo Valentin

 *      Paul Walmsley

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 34xx */

 VDD1 */

 VDD2 */

 36xx */

 VDD1 */

 VDD2 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2/3 PRM module functions

 *

 * Copyright (C) 2010-2011 Texas Instruments, Inc.

 * Copyright (C) 2010 Nokia Corporation

 * Benot Cousson

 * Paul Walmsley

/**

 * omap2_prm_is_hardreset_asserted - read the HW reset line state of

 * submodules contained in the hwmod module

 * @shift: register bit shift corresponding to the reset line to check

 * @part: PRM partition, ignored for OMAP2

 * @prm_mod: PRM submodule base (e.g. CORE_MOD)

 * @offset: register offset, ignored for OMAP2

 *

 * Returns 1 if the (sub)module hardreset line is currently asserted,

 * 0 if the (sub)module hardreset line is not currently asserted, or

 * -EINVAL if called while running on a non-OMAP2/3 chip.

/**

 * omap2_prm_assert_hardreset - assert the HW reset line of a submodule

 * @shift: register bit shift corresponding to the reset line to assert

 * @part: PRM partition, ignored for OMAP2

 * @prm_mod: PRM submodule base (e.g. CORE_MOD)

 * @offset: register offset, ignored for OMAP2

 *

 * Some IPs like dsp or iva contain processors that require an HW

 * reset line to be asserted / deasserted in order to fully enable the

 * IP.  These modules may have multiple hard-reset lines that reset

 * different 'submodules' inside the IP block.  This function will

 * place the submodule into reset.  Returns 0 upon success or -EINVAL

 * upon an argument error.

/**

 * omap2_prm_deassert_hardreset - deassert a submodule hardreset line and wait

 * @prm_mod: PRM submodule base (e.g. CORE_MOD)

 * @rst_shift: register bit shift corresponding to the reset line to deassert

 * @st_shift: register bit shift for the status of the deasserted submodule

 * @part: PRM partition, not used for OMAP2

 * @prm_mod: PRM submodule base (e.g. CORE_MOD)

 * @rst_offset: reset register offset, not used for OMAP2

 * @st_offset: reset status register offset, not used for OMAP2

 *

 * Some IPs like dsp or iva contain processors that require an HW

 * reset line to be asserted / deasserted in order to fully enable the

 * IP.  These modules may have multiple hard-reset lines that reset

 * different 'submodules' inside the IP block.  This function will

 * take the submodule out of reset and wait until the PRCM indicates

 * that the reset has completed before returning.  Returns 0 upon success or

 * -EINVAL upon an argument error, -EEXIST if the submodule was already out

 * of reset, or -EBUSY if the submodule did not exit reset promptly.

 Check the current status to avoid de-asserting the line twice */

 Clear the reset status by writing 1 to the status bit */

 de-assert the reset control line */

 wait the status to be set */

 Powerdomain low-level functions */

 Common functions across OMAP2 and OMAP3 */

	/*

	 * REVISIT: pwrdm_wait_transition() may be better implemented

	 * via a callback and a periodic timer check -- how long do we expect

	 * powerdomain transitions to take?

 XXX Is this udelay() value meaningful? */

 XXX Caller must hold the clkdm's powerdomain lock */

 only happens if data is erroneous */

 PRM accesses are slow, so minimize them */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * DRA7xx Power domains framework

 *

 * Copyright (C) 2009-2013 Texas Instruments, Inc.

 * Copyright (C) 2009-2011 Nokia Corporation

 *

 * Generated by code originally written by:

 * Abhijit Pagare (abhijitpagare@ti.com)

 * Benoit Cousson (b-cousson@ti.com)

 * Paul Walmsley (paul@pwsan.com)

 *

 * This file is automatically generated from the OMAP hardware databases.

 * We respectfully ask that any modifications to this file be coordinated

 * with the public linux-omap@vger.kernel.org mailing list and the

 * authors above to ensure that the autogeneration scripts are kept

 * up-to-date with the file contents.

 iva_7xx_pwrdm: IVA-HD power domain */

 hwa_mem */

 sl2_mem */

 tcm1_mem */

 tcm2_mem */

 rtc_7xx_pwrdm:  */

 custefuse_7xx_pwrdm: Customer efuse controller power domain */

 custefuse_aon_7xx_pwrdm: Customer efuse controller power domain */

 ipu_7xx_pwrdm: Audio back end power domain */

 aessmem */

 periphmem */

 dss_7xx_pwrdm: Display subsystem power domain */

 dss_mem */

 l4per_7xx_pwrdm: Target peripherals power domain */

 nonretained_bank */

 retained_bank */

 gpu_7xx_pwrdm: 3D accelerator power domain */

 gpu_mem */

 wkupaon_7xx_pwrdm: Wake-up power domain */

 wkup_bank */

 core_7xx_pwrdm: CORE power domain */

 core_nret_bank */

 core_ocmram */

 core_other_bank */

 ipu_l2ram */

 ipu_unicache */

 coreaon_7xx_pwrdm: Always ON logic that sits in VDD_CORE voltage domain */

 cpu0_7xx_pwrdm: MPU0 processor and Neon coprocessor power domain */

 cpu0_l1 */

 cpu0_l1 */

 cpu1_7xx_pwrdm: MPU1 processor and Neon coprocessor power domain */

 cpu1_l1 */

 cpu1_l1 */

 vpe_7xx_pwrdm:  */

 vpe_bank */

 mpu_7xx_pwrdm: Modena processor and the Neon coprocessor power domain */

 mpu_l2 */

 mpu_ram */

 mpu_l2 */

 mpu_ram */

 l3init_7xx_pwrdm: L3 initators pheripherals power domain  */

 gmac_bank */

 l3init_bank1 */

 l3init_bank2 */

 eve3_7xx_pwrdm:  */

 eve3_bank */

 emu_7xx_pwrdm: Emulation power domain */

 emu_bank */

 dsp2_7xx_pwrdm:  */

 dsp2_edma */

 dsp2_l1 */

 dsp2_l2 */

 dsp1_7xx_pwrdm: Tesla processor power domain */

 dsp1_edma */

 dsp1_l1 */

 dsp1_l2 */

 cam_7xx_pwrdm: Camera subsystem power domain */

 vip_bank */

 eve4_7xx_pwrdm:  */

 eve4_bank */

 eve2_7xx_pwrdm:  */

 eve2_bank */

 eve1_7xx_pwrdm:  */

 eve1_bank */

/*

 * The following power domains are not under SW control

 *

 * mpuaon

 * mmaon

 As powerdomains are added or removed above, this list must also be changed */

 SPDX-License-Identifier: GPL-2.0-only

/**

 * ti81xx_restart - trigger a software restart of the SoC

 * @mode: the "reboot mode", see arch/arm/kernel/{setup,process}.c

 * @cmd: passed from the userspace program rebooting the system (if provided)

 *

 * Resets the SoC.  For @cmd, see the 'reboot' syscall in

 * kernel/sys.c.  No return value.

 *

 * NOTE: Warm reset does not seem to work, may require resetting

 * clocks to bypass mode.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 PRM instance functions

 *

 * Copyright (C) 2009 Nokia Corporation

 * Copyright (C) 2011 Texas Instruments, Inc.

 * Paul Walmsley

/**

 * omap_prm_base_init - Populates the prm partitions

 *

 * Populates the base addresses of the _prm_bases

 * array used for read/write of prm module registers.

 Read a register in a PRM instance */

 Write into a register in a PRM instance */

 Read-modify-write a register in PRM. Caller must lock */

/**

 * omap4_prminst_is_hardreset_asserted - read the HW reset line state of

 * submodules contained in the hwmod module

 * @rstctrl_reg: RM_RSTCTRL register address for this module

 * @shift: register bit shift corresponding to the reset line to check

 *

 * Returns 1 if the (sub)module hardreset line is currently asserted,

 * 0 if the (sub)module hardreset line is not currently asserted, or

 * -EINVAL upon parameter error.

/**

 * omap4_prminst_assert_hardreset - assert the HW reset line of a submodule

 * @rstctrl_reg: RM_RSTCTRL register address for this module

 * @shift: register bit shift corresponding to the reset line to assert

 *

 * Some IPs like dsp, ipu or iva contain processors that require an HW

 * reset line to be asserted / deasserted in order to fully enable the

 * IP.  These modules may have multiple hard-reset lines that reset

 * different 'submodules' inside the IP block.  This function will

 * place the submodule into reset.  Returns 0 upon success or -EINVAL

 * upon an argument error.

/**

 * omap4_prminst_deassert_hardreset - deassert a submodule hardreset line and

 * wait

 * @shift: register bit shift corresponding to the reset line to deassert

 * @st_shift: status bit offset corresponding to the reset line

 * @part: PRM partition

 * @inst: PRM instance offset

 * @rstctrl_offs: reset register offset

 * @rstst_offs: reset status register offset

 *

 * Some IPs like dsp, ipu or iva contain processors that require an HW

 * reset line to be asserted / deasserted in order to fully enable the

 * IP.  These modules may have multiple hard-reset lines that reset

 * different 'submodules' inside the IP block.  This function will

 * take the submodule out of reset and wait until the PRCM indicates

 * that the reset has completed before returning.  Returns 0 upon success or

 * -EINVAL upon an argument error, -EEXIST if the submodule was already out

 * of reset, or -EBUSY if the submodule did not exit reset promptly.

 Check the current status to avoid de-asserting the line twice */

 Clear the reset status by writing 1 to the status bit */

 de-assert the reset control line */

 wait the status to be set */

 OCP barrier */

 SPDX-License-Identifier: GPL-2.0

/*

 * opp2420_data.c - old-style "OPP" table for OMAP2420

 *

 * Copyright (C) 2005-2009 Texas Instruments, Inc.

 * Copyright (C) 2004-2009 Nokia Corporation

 *

 * Richard Woodruff <r-woodruff2@ti.com>

 *

 * The OMAP2 processor can be run at several discrete 'PRCM configurations'.

 * These configurations are characterized by voltage and speed for clocks.

 * The device is only validated for certain combinations. One way to express

 * these combinations is via the 'ratios' which the clocks operate with

 * respect to each other. These ratio sets are for a given voltage/DPLL

 * setting. All configurations can be described by a DPLL setting and a ratio.

 *

 * XXX Missing voltage data.

 * XXX Missing 19.2MHz sys_clk rate sets (needed for N800/N810)

 *

 * THe format described in this file is deprecated.  Once a reasonable

 * OPP API exists, the data in this file should be converted to use it.

 *

 * This is technically part of the OMAP2xxx clock code.

 *

 * Considerable work is still needed to fully support dynamic frequency

 * changes on OMAP2xxx-series chips.  Readers interested in such a

 * project are encouraged to review the Maemo Diablo RX-34 and RX-44

 * kernel source at:

 *     http://repository.maemo.org/pool/diablo/free/k/kernel-source-diablo/

/*

 * Key dividers which make up a PRCM set. Ratios for a PRCM are mandated.

 * xtal_speed, dpll_speed, mpu_speed, CM_CLKSEL_MPU,

 * CM_CLKSEL_DSP, CM_CLKSEL_GFX, CM_CLKSEL1_CORE, CM_CLKSEL1_PLL,

 * CM_CLKSEL2_PLL, CM_CLKSEL_MDM

 *

 * Filling in table based on H4 boards available.  There are quite a

 * few more rate combinations which could be defined.

 *

 * When multiple values are defined the start up will try and choose

 * the fastest one. If a 'fast' value is defined, then automatically,

 * the /2 one should be included as it can be used.  Generally having

 * more than one fast set does not make sense, as static timings need

 * to be changed to change the set.  The exception is the bypass

 * setting which is available for low power bypass.

 *

 * Note: This table needs to be sorted, fastest to slowest.

 PRCM I - FAST */

 330MHz ARM */

 PRCM II - FAST */

 300MHz ARM */

 300MHz ARM */

 PRCM III - FAST */

 266MHz ARM */

 266MHz ARM */

 PRCM II - SLOW */

 150MHz ARM */

 150MHz ARM */

 PRCM III - SLOW */

 133MHz ARM */

 133MHz ARM */

 PRCM-VII (boot-bypass) */

 12MHz ARM*/

 PRCM-VII (boot-bypass) */

 13MHz ARM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap3-restart.c - Code common to all OMAP3xxx machines.

 *

 * Copyright (C) 2009, 2012 Texas Instruments

 * Copyright (C) 2010 Nokia Corporation

 * Tony Lindgren <tony@atomide.com>

 * Santosh Shilimkar <santosh.shilimkar@ti.com>

 Global address base setup code */

/**

 * omap3xxx_restart - trigger a software restart of the SoC

 * @mode: the "reboot mode", see arch/arm/kernel/{setup,process}.c

 * @cmd: passed from the userspace program rebooting the system (if provided)

 *

 * Resets the SoC.  For @cmd, see the 'reboot' syscall in

 * kernel/sys.c.  No return value.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3 Voltage Controller (VC) data

 *

 * Copyright (C) 2007, 2010 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Lesly A M <x0080970@ti.com>

 * Thara Gopinath <thara@ti.com>

 *

 * Copyright (C) 2008, 2011 Nokia Corporation

 * Kalle Jokiniemi

 * Paul Walmsley

/*

 * VC data common to 34xx/36xx chips

 * XXX This stuff presumably belongs in the vc3xxx.c or vc.c file.

/*

 * Voltage levels for different operating modes: on, sleep, retention and off

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AM43xx Power domains framework

 *

 * Copyright (C) 2013 Texas Instruments, Inc.

 gfx_mem */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 debugss_mem */

 icss_mem */

 per_mem */

 ram1_mem */

 ram2_mem */

 icss_mem */

 per_mem */

 ram1_mem */

 ram2_mem */

/*

 * linux/arch/arm/mach-omap2/timer.c

 *

 * OMAP2 GP timer support.

 *

 * Copyright (C) 2009 Nokia Corporation

 *

 * Update to use new clocksource/clockevent layers

 * Author: Kevin Hilman, MontaVista Software, Inc. <source@mvista.com>

 * Copyright (C) 2007 MontaVista Software, Inc.

 *

 * Original driver:

 * Copyright (C) 2005 Nokia Corporation

 * Author: Paul Mundt <paul.mundt@nokia.com>

 *         Juha Yrjl <juha.yrjola@nokia.com>

 * OMAP Dual-mode timer framework support by Timo Teras

 *

 * Some parts based off of TI's 24xx code:

 *

 * Copyright (C) 2004-2009 Texas Instruments, Inc.

 *

 * Roughly modelled after the OMAP1 MPU timer code.

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License. See the file "COPYING" in the main directory of this archive

 * for more details.

/*

 * The realtime counter also called master counter, is a free-running

 * counter, which is related to real time. It produces the count used

 * by the CPU local timer peripherals in the MPU cluster. The timer counts

 * at a rate of 6.144 MHz. Because the device operates on different clocks

 * in different power modes, the master counter shifts operation between

 * clocks, adjusting the increment per clock in hardware accordingly to

 * maintain a constant count rate.

		/*

		 * Errata i856 says the 32.768KHz crystal does not start at

		 * power on, so the CPU falls back to an emulated 32KHz clock

		 * based on sysclk / 610 instead. This causes the master counter

		 * frequency to not be 6.144MHz but at sysclk / 610 * 375 / 2

		 * (OR sysclk * 75 / 244)

		 *

		 * This affects at least the DRA7/AM572x 1.0, 1.1 revisions.

		 * Of course any board built without a populated 32.768KHz

		 * crystal would also need this fix even if the CPU is fixed

		 * later.

		 *

		 * Either case can be detected by using the two speedselect bits

		 * If they are not 0, then the 32.768KHz clock driving the

		 * coarse counter that corrects the fine counter every time it

		 * ticks is actually rate/610 rather than 32.768KHz and we

		 * should compensate to avoid the 570ppm (at 20MHz, much worse

		 * at other rates) too fast system time.

 Numerator/denumerator values refer TRM Realtime Counter section */

 Program it for 38.4 MHz */

 Program numerator and denumerator registers */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2xxx DVFS virtual clock functions

 *

 * Copyright (C) 2005-2008, 2012 Texas Instruments, Inc.

 * Copyright (C) 2004-2010 Nokia Corporation

 *

 * Contacts:

 * Richard Woodruff <r-woodruff2@ti.com>

 * Paul Walmsley

 *

 * Based on earlier work by Tuukka Tikkanen, Tony Lindgren,

 * Gordon McNutt and RidgeRun, Inc.

 *

 * XXX Some of this code should be replaceable by the upcoming OPP layer

 * code.  However, some notion of "rate set" is probably still necessary

 * for OMAP2xxx at least.  Rate sets should be generalized so they can be

 * used for any OMAP chip, not just OMAP2xxx.  In particular, Richard Woodruff

 * has in the past expressed a preference to use rate sets for OPP changes,

 * rather than dynamically recalculating the clock tree, so if someone wants

 * this badly enough to write the code to handle it, we should support it

 * as an option.

/*

 * sys_ck_rate: the rate of the external high-frequency clock

 * oscillator on the board.  Set by the SoC-specific clock init code.

 * Once set during a boot, will not change.

/**

 * omap2_table_mpu_recalc - just return the MPU speed

 * @clk: virt_prcm_set struct clk

 *

 * Set virt_prcm_set's rate to the mpu_speed field of the current PRCM set.

/*

 * Look for a rate equal or less than the target rate given a configuration set.

 *

 * What's not entirely clear is "which" field represents the key field.

 * Some might argue L3-DDR, others ARM, others IVA. This code is simple and

 * just uses the ARM rates.

 Can check only after xtal frequency check */

 Sets basic clocks based on the specified rate */

 x2 to enter omap2xxx_sdrc_init_params() */

/**

 * omap2xxx_clkt_vps_check_bootloader_rate - determine which of the rate

 * table sets matches the current CORE DPLL hardware rate

 *

 * Check the MPU rate set by bootloader.  Sets the 'curr_prcm_set'

 * global to point to the active rate set when found; otherwise, sets

 * it to NULL.  No return value;

/**

 * omap2xxx_clkt_vps_late_init - store a copy of the sys_ck rate

 *

 * Store a copy of the sys_ck rate for later use by the OMAP2xxx DVFS

 * code.  (The sys_ck rate does not -- or rather, must not -- change

 * during kernel runtime.)  Must be called after we have a valid

 * sys_ck rate, but before the virt_prcm_set clock rate is

 * recalculated.  No return value.

/**

 * omap2xxx_clkt_vps_init - initialize virt_prcm_set clock

 *

 * Does a manual init for the virtual prcm DVFS clock for OMAP2. This

 * function is called only from omap2 DT clock init, as the virtual

 * node is not modelled in the DT clock data.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3 voltage domain data

 *

 * Copyright (C) 2011 Texas Instruments, Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3/OMAP4 Voltage Management Routines

 *

 * Author: Thara Gopinath	<thara@ti.com>

 *

 * Copyright (C) 2007 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Lesly A M <x0080970@ti.com>

 *

 * Copyright (C) 2008, 2011 Nokia Corporation

 * Kalle Jokiniemi

 * Paul Walmsley

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Thara Gopinath <thara@ti.com>

 Public functions */

/**

 * voltdm_get_voltage() - Gets the current non-auto-compensated voltage

 * @voltdm:	pointer to the voltdm for which current voltage info is needed

 *

 * API to get the current non-auto-compensated voltage for a voltage domain.

 * Returns 0 in case of error else returns the current voltage.

/**

 * voltdm_scale() - API to scale voltage of a particular voltage domain.

 * @voltdm: pointer to the voltage domain which is to be scaled.

 * @target_volt: The target voltage of the voltage domain

 *

 * This API should be called by the kernel to do the voltage scaling

 * for a particular voltage domain during DVFS.

 Adjust voltage to the exact voltage from the OPP table */

/**

 * voltdm_reset() - Resets the voltage of a particular voltage domain

 *		    to that of the current OPP.

 * @voltdm: pointer to the voltage domain whose voltage is to be reset.

 *

 * This API finds out the correct voltage the voltage domain is supposed

 * to be at and resets the voltage to that level. Should be used especially

 * while disabling any voltage compensation modules.

/**

 * omap_voltage_get_volttable() - API to get the voltage table associated with a

 *				particular voltage domain.

 * @voltdm:	pointer to the VDD for which the voltage table is required

 * @volt_data:	the voltage table for the particular vdd which is to be

 *		populated by this API

 *

 * This API populates the voltage table associated with a VDD into the

 * passed parameter pointer. Returns the count of distinct voltages

 * supported by this vdd.

 *

/**

 * omap_voltage_get_voltdata() - API to get the voltage table entry for a

 *				particular voltage

 * @voltdm:	pointer to the VDD whose voltage table has to be searched

 * @volt:	the voltage to be searched in the voltage table

 *

 * This API searches through the voltage table for the required voltage

 * domain and tries to find a matching entry for the passed voltage volt.

 * If a matching entry is found volt_data is populated with that entry.

 * This API searches only through the non-compensated voltages int the

 * voltage table.

 * Returns pointer to the voltage table entry corresponding to volt on

 * success. Returns -ENODATA if no voltage table exisits for the passed voltage

 * domain or if there is no matching entry.

/**

 * omap_voltage_register_pmic() - API to register PMIC specific data

 * @voltdm:	pointer to the VDD for which the PMIC specific data is

 *		to be registered

 * @pmic:	the structure containing pmic info

 *

 * This API is to be called by the SOC/PMIC file to specify the

 * pmic specific info as present in omap_voltdm_pmic structure.

/**

 * omap_voltage_late_init() - Init the various voltage parameters

 *

 * This API is to be called in the later stages of the

 * system boot to init the voltage controller and

 * voltage processors.

/**

 * voltdm_lookup - look up a voltagedomain by name, return a pointer

 * @name: name of voltagedomain

 *

 * Find a registered voltagedomain by its name @name.  Returns a pointer

 * to the struct voltagedomain if found, or NULL otherwise.

/**

 * voltdm_init - set up the voltagedomain layer

 * @voltdm_list: array of struct voltagedomain pointers to register

 *

 * Loop through the array of voltagedomains @voltdm_list, registering all

 * that are available on the current CPU. If voltdm_list is supplied

 * and not null, all of the referenced voltagedomains will be

 * registered.  No return value.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3 voltage domain data

 *

 * Copyright (C) 2007, 2010 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Lesly A M <x0080970@ti.com>

 * Thara Gopinath <thara@ti.com>

 *

 * Copyright (C) 2008, 2011 Nokia Corporation

 * Kalle Jokiniemi

 * Paul Walmsley

/*

 * VDD data

 OMAP3-common voltagedomain data */

 34xx/36xx voltagedomain data */

 AM35xx voltagedomain data */

	/*

	 * XXX Will depend on the process, validation, and binning

	 * for the currently-running IC

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Framebuffer device registration for TI OMAP platforms

 *

 * Copyright (C) 2006 Nokia Corporation

 * Author: Imre Deak <imre.deak@nokia.com>

/*

 * The first memory resource is the register region for VRFB,

 * the rest are VRFB virtual memory areas for each VRFB context.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 specific common source file.

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Author:

 *	Santosh Shilimkar <santosh.shilimkar@ti.com>

 Used to implement memory barrier on DRAM path */

/*

 * The OMAP4 bus structure contains asynchronous bridges which can buffer

 * data writes from the MPU. These asynchronous bridges can be found on

 * paths between the MPU to EMIF, and the MPU to L3 interconnects.

 *

 * We need to be careful about re-ordering which can happen as a result

 * of different accesses being performed via different paths, and

 * therefore different asynchronous bridges.

/*

 * OMAP4 interconnect barrier which is called for each mb() and wmb().

 * This is to ensure that normal paths to DRAM (normal memory, cacheable

 * accesses) are properly synchronised with writes to DMA coherent memory

 * (normal memory, uncacheable) and device writes.

 *

 * The mb() and wmb() barriers only operate only on the MPU->MA->EMIF

 * path, as we need to ensure that data is visible to other system

 * masters prior to writes to those system masters being seen.

 *

 * Note: the SRAM path is not synchronised via mb() and wmb().

/*

 * OMAP4 Errata i688 - asynchronous bridge corruption when entering WFI.

 *

 * If a data is stalled inside asynchronous bridge because of back

 * pressure, it may be accepted multiple times, creating pointer

 * misalignment that will corrupt next transfers on that data path until

 * next reset of the system. No recovery procedure once the issue is hit,

 * the path remains consistently broken.

 *

 * Async bridges can be found on paths between MPU to EMIF and MPU to L3

 * interconnects.

 *

 * This situation can happen only when the idle is initiated by a Master

 * Request Disconnection (which is trigged by software when executing WFI

 * on the CPU).

 *

 * The work-around for this errata needs all the initiators connected

 * through an async bridge to ensure that data path is properly drained

 * before issuing WFI. This condition will be met if one Strongly ordered

 * access is performed to the target right before executing the WFI.

 *

 * In MPU case, L3 T2ASYNC FIFO and DDR T2ASYNC FIFO needs to be drained.

 * IO barrier ensure that there is no synchronisation loss on initiators

 * operating on both interconnect port simultaneously.

 *

 * This is a stronger version of the OMAP4 memory barrier below, and

 * operates on both the MPU->MA->EMIF path but also the MPU->OCP path

 * as well, and is necessary prior to executing a WFI.

 Steal one page physical memory for barrier implementation */

		/*

		 * The local timer interrupt got lost while the distributor was

		 * disabled.  Ack the pending interrupt, and retrigger it.

 Static mapping, never released */

/*

 * SAR RAM used to save and restore the HW context in low power modes.

 * Note that we need to initialize this very early for kexec. See

 * omap4_mpuss_early_init().

	/*

	 * To avoid code running on other OMAPs in

	 * multi-omap builds

 Static mapping, never released */

 Extract GIC distributor and TWD bases for OMAP4460 ROM Errata WA */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod_2430_data.c - hardware modules present on the OMAP2430 chips

 *

 * Copyright (C) 2009-2011 Nokia Corporation

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 *

 * XXX handle crossbar/shared link difference for L3?

 * XXX these should be marked initdata for multi-OMAP kernels

/*

 * OMAP2430 hardware module integration data

 *

 * All of the data in this section should be autogeneratable from the

 * TI hardware database or other technical documentation.  Data that

 * is driver-specific or driver-kernel integration-specific belongs

 * elsewhere.

/*

 * IP blocks

 IVA2 (IVA2) */

 I2C common */

 I2C1 */

			/*

			 * NOTE: The CM_FCLKEN* and CM_ICLKEN* for

			 * I2CHS IP's do not follow the usual pattern.

			 * prcm_reg_id alone cannot be used to program

			 * the iclk and fclk. Needs to be handled using

			 * additional flags when clk handling is moved

			 * to hwmod framework.

 I2C2 */

 gpio5 */

 mailbox */

 mcspi3 */

 usbhsotg */

 usb_otg_hs */

	/*

	 * Erratum ID: i479  idle_req / idle_ack mechanism potentially

	 * broken when autoidle is enabled

	 * workaround is to disable the autoidle bit at module level.

/*

 * 'mcbsp' class

 * multi channel buffered serial port controller

 mcbsp1 */

 mcbsp2 */

 mcbsp3 */

 mcbsp4 */

 mcbsp5 */

 MMC/SD/SDIO common */

 MMC/SD/SDIO1 */

 MMC/SD/SDIO2 */

 HDQ1W/1-wire */

/*

 * interfaces

 L3 -> L4_CORE interface */

 l3_core -> usbhsotg  interface */

 L4 CORE -> I2C1 interface */

 L4 CORE -> I2C2 interface */

  l4_core ->usbhsotg  interface */

 L4 CORE -> MMC1 interface */

 L4 CORE -> MMC2 interface */

 l4 core -> mcspi3 interface */

 IVA2 <- L3 interface */

 l4_wkup -> wd_timer2 */

 l4_wkup -> gpio1 */

 l4_wkup -> gpio2 */

 l4_wkup -> gpio3 */

 l4_wkup -> gpio4 */

 l4_core -> gpio5 */

 l4_core -> mailbox */

 l4_core -> mcbsp1 */

 l4_core -> mcbsp2 */

 l4_core -> mcbsp3 */

 l4_core -> mcbsp4 */

 l4_core -> mcbsp5 */

 l4_core -> hdq1w */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2xxx CM module functions

 *

 * Copyright (C) 2009 Nokia Corporation

 * Copyright (C) 2008-2010, 2012 Texas Instruments, Inc.

 * Paul Walmsley

 * Rajendra Nayak <rnayak@ti.com>

 CM_AUTOIDLE_PLL.AUTO_* bit values for DPLLs */

 CM_AUTOIDLE_PLL.AUTO_* bit values for APLLs (OMAP2xxx only) */

 CM_IDLEST_PLL bit value offset for APLLs (OMAP2xxx only) */

/*

 *

/*

 * DPLL autoidle control

/*

 * APLL control

 Enable an APLL if off */

 apll already enabled */

	/*

	 * REVISIT: Should we return an error code if

	 * omap2xxx_cm_wait_module_ready() fails?

 Stop APLL */

 Enable an APLL if off */

 Enable an APLL if off */

 Stop APLL */

 Stop APLL */

/**

 * omap2xxx_cm_split_idlest_reg - split CM_IDLEST reg addr into its components

 * @idlest_reg: CM_IDLEST* virtual address

 * @prcm_inst: pointer to an s16 to return the PRCM instance offset

 * @idlest_reg_id: pointer to a u8 to return the CM_IDLESTx register ID

 *

 * XXX This function is only needed until absolute register addresses are

 * removed from the OMAP struct clk records.

/*

 *

/**

 * omap2xxx_cm_wait_module_ready - wait for a module to leave idle or standby

 * @part: PRCM partition, ignored for OMAP2

 * @prcm_mod: PRCM module offset

 * @idlest_id: CM_IDLESTx register ID (i.e., x = 1, 2, 3)

 * @idlest_shift: shift of the bit in the CM_IDLEST* register to check

 *

 * Wait for the PRCM to indicate that the module identified by

 * (@prcm_mod, @idlest_id, @idlest_shift) is clocked.  Return 0 upon

 * success or -EBUSY if the module doesn't enable in time.

 Clockdomain low-level functions */

 Check for MMC, UART2, UART1, McSPI2, McSPI1 and DSS1. */

 Check for UART3. */

/*

 *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 Power domains framework

 *

 * Copyright (C) 2009-2011 Texas Instruments, Inc.

 * Copyright (C) 2009-2011 Nokia Corporation

 *

 * Abhijit Pagare (abhijitpagare@ti.com)

 * Benoit Cousson (b-cousson@ti.com)

 * Paul Walmsley (paul@pwsan.com)

 *

 * This file is automatically generated from the OMAP hardware databases.

 * We respectfully ask that any modifications to this file be coordinated

 * with the public linux-omap@vger.kernel.org mailing list and the

 * authors above to ensure that the autogeneration scripts are kept

 * up-to-date with the file contents.

 core_44xx_pwrdm: CORE power domain */

 core_nret_bank */

 core_ocmram */

 core_other_bank */

 ducati_l2ram */

 ducati_unicache */

 core_nret_bank */

 core_ocmram */

 core_other_bank */

 ducati_l2ram */

 ducati_unicache */

 gfx_44xx_pwrdm: 3D accelerator power domain */

 gfx_mem */

 gfx_mem */

 abe_44xx_pwrdm: Audio back end power domain */

 aessmem */

 periphmem */

 aessmem */

 periphmem */

 dss_44xx_pwrdm: Display subsystem power domain */

 dss_mem */

 dss_mem */

 tesla_44xx_pwrdm: Tesla processor power domain */

 tesla_edma */

 tesla_l1 */

 tesla_l2 */

 tesla_edma */

 tesla_l1 */

 tesla_l2 */

 wkup_44xx_pwrdm: Wake-up power domain */

 wkup_bank */

 wkup_bank */

 cpu0_44xx_pwrdm: MPU0 processor and Neon coprocessor power domain */

 cpu0_l1 */

 cpu0_l1 */

 cpu1_44xx_pwrdm: MPU1 processor and Neon coprocessor power domain */

 cpu1_l1 */

 cpu1_l1 */

 emu_44xx_pwrdm: Emulation power domain */

 emu_bank */

 emu_bank */

 mpu_44xx_pwrdm: Modena processor and the Neon coprocessor power domain */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 mpu_l1 */

 mpu_l2 */

 mpu_ram */

 ivahd_44xx_pwrdm: IVA-HD power domain */

 hwa_mem */

 sl2_mem */

 tcm1_mem */

 tcm2_mem */

 hwa_mem */

 sl2_mem */

 tcm1_mem */

 tcm2_mem */

 cam_44xx_pwrdm: Camera subsystem power domain */

 cam_mem */

 cam_mem */

 l3init_44xx_pwrdm: L3 initators pheripherals power domain  */

 l3init_bank1 */

 l3init_bank1 */

 l4per_44xx_pwrdm: Target peripherals power domain */

 nonretained_bank */

 retained_bank */

 nonretained_bank */

 retained_bank */

/*

 * always_on_core_44xx_pwrdm: Always ON logic that sits in VDD_CORE voltage

 * domain

 cefuse_44xx_pwrdm: Customer efuse controller power domain */

/*

 * The following power domains are not under SW control

 *

 * always_on_iva

 * always_on_mpu

 * stdefuse

 As powerdomains are added or removed above, this list must also be changed */

/*

 * AM33XX PRM functions

 *

 * Copyright (C) 2011-2012 Texas Instruments Incorporated - https://www.ti.com/

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 Read a register in a PRM instance */

 Write into a register in a PRM instance */

 Read-modify-write a register in PRM. Caller must lock */

/**

 * am33xx_prm_is_hardreset_asserted - read the HW reset line state of

 * submodules contained in the hwmod module

 * @shift: register bit shift corresponding to the reset line to check

 * @part: PRM partition, ignored for AM33xx

 * @inst: CM instance register offset (*_INST macro)

 * @rstctrl_offs: RM_RSTCTRL register address offset for this module

 *

 * Returns 1 if the (sub)module hardreset line is currently asserted,

 * 0 if the (sub)module hardreset line is not currently asserted, or

 * -EINVAL upon parameter error.

/**

 * am33xx_prm_assert_hardreset - assert the HW reset line of a submodule

 * @shift: register bit shift corresponding to the reset line to assert

 * @part: CM partition, ignored for AM33xx

 * @inst: CM instance register offset (*_INST macro)

 * @rstctrl_reg: RM_RSTCTRL register address for this module

 *

 * Some IPs like dsp, ipu or iva contain processors that require an HW

 * reset line to be asserted / deasserted in order to fully enable the

 * IP.  These modules may have multiple hard-reset lines that reset

 * different 'submodules' inside the IP block.  This function will

 * place the submodule into reset.  Returns 0 upon success or -EINVAL

 * upon an argument error.

/**

 * am33xx_prm_deassert_hardreset - deassert a submodule hardreset line and

 * wait

 * @shift: register bit shift corresponding to the reset line to deassert

 * @st_shift: reset status register bit shift corresponding to the reset line

 * @part: PRM partition, not used for AM33xx

 * @inst: CM instance register offset (*_INST macro)

 * @rstctrl_reg: RM_RSTCTRL register address for this module

 * @rstst_reg: RM_RSTST register address for this module

 *

 * Some IPs like dsp, ipu or iva contain processors that require an HW

 * reset line to be asserted / deasserted in order to fully enable the

 * IP.  These modules may have multiple hard-reset lines that reset

 * different 'submodules' inside the IP block.  This function will

 * take the submodule out of reset and wait until the PRCM indicates

 * that the reset has completed before returning.  Returns 0 upon success or

 * -EINVAL upon an argument error, -EEXIST if the submodule was already out

 * of reset, or -EBUSY if the submodule did not exit reset promptly.

 Check the current status to avoid  de-asserting the line twice */

 Clear the reset status by writing 1 to the status bit */

 de-assert the reset control line */

 wait the status to be set */

	/*

	 * REVISIT: pwrdm_wait_transition() may be better implemented

	 * via a callback and a periodic timer check -- how long do we expect

	 * powerdomain transitions to take?

 XXX Is this udelay() value meaningful? */

 No VC/VP on am33xx devices */

/**

 * am33xx_prm_global_warm_sw_reset - reboot the device via warm reset

 *

 * Immediately reboots the device through warm reset.

 OCP barrier */

	/*

	 * Do not save LOWPOWERSTATECHANGE, writing a 1 indicates a request,

	 * reading back a 1 indicates a request in progress.

 Make sure we only wait for a transition if there is one */

/*

 * AM33XX Clock Domain data.

 *

 * Copyright (C) 2011-2012 Texas Instruments Incorporated - https://www.ti.com/

 * Vaibhav Hiremath <hvaibhav@ti.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP and TWL PMIC specific initializations.

 *

 * Copyright (C) 2010 Texas Instruments Incorporated.

 * Thara Gopinath

 * Copyright (C) 2009 Texas Instruments Incorporated.

 * Nishanth Menon

 * Copyright (C) 2009 Nokia Corporation

 * Paul Walmsley

	/*

	 * In TWL6030 depending on the value of SMPS_OFFSET

	 * efuse register the voltage range supported in

	 * standard mode can be either between 0.6V - 1.3V or

	 * 0.7V - 1.4V. In TWL6030 ES1.0 SMPS_OFFSET efuse

	 * is programmed to all 0's where as starting from

	 * TWL6030 ES1.1 the efuse is programmed to 1

	/*

	 * There is no specific formula for voltage to vsel

	 * conversion above 1.3V. There are special hardcoded

	 * values for voltages above 1.3V. Currently we are

	 * hardcoding only for 1.35 V which is used for 1GH OPP for

	 * OMAP4430.

	/*

	 * In TWL6030 depending on the value of SMPS_OFFSET

	 * efuse register the voltage range supported in

	 * standard mode can be either between 0.6V - 1.3V or

	 * 0.7V - 1.4V. In TWL6030 ES1.0 SMPS_OFFSET efuse

	 * is programmed to all 0's where as starting from

	 * TWL6030 ES1.1 the efuse is programmed to 1

	/*

	 * There is no specific formula for voltage to vsel

	 * conversion above 1.3V. There are special hardcoded

	 * values for voltages above 1.3V. Currently we are

	 * hardcoding only for 1.35 V which is used for 1GH OPP for

	 * OMAP4430.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2 Power Management Routines

 *

 * Copyright (C) 2005 Texas Instruments, Inc.

 * Copyright (C) 2006-2008 Nokia Corporation

 *

 * Written by:

 * Richard Woodruff <r-woodruff2@ti.com>

 * Tony Lindgren

 * Juha Yrjola

 * Amit Kucheria <amit.kucheria@nokia.com>

 * Igor Stoppa <igor.stoppa@nokia.com>

 *

 * Based on pm.c for omap1

	/* There is 1 reference hold for all children of the oscillator

	 * clock, the following will remove it. If no one else uses the

	 * oscillator itself it will be disabled if/when we enter retention

	 * mode.

 Clear old wake-up events */

 REVISIT: These write to reserved bits? */

 Workaround to kill USB */

	/* One last check for pending IRQs to avoid extra latency due

 Jump to SRAM suspend code */

 clear CORE wake-up events */

 wakeup domain events - bit 1: GPT1, bit5 GPIO */

 MPU domain wake events */

	/* The peripherals seem not to be able to wake up the MPU when

 REVISIT: These write to reserved bits? */

 Try to enter MPU retention */

 Block MPU retention */

 WFI */

	/*

	 * Enable autoidle

	 * XXX This should be handled by hwmod code or PRCM init code

	/*

	 * Set CORE powerdomain memory banks to retain their contents

	 * during RETENTION

 Force-power down DSP, GFX powerdomains */

 Enable hardware-supervised idle for all clkdms */

	/* REVISIT: Configure number of 32 kHz clock cycles for sys_clk

 Configure automatic voltage transition */

 Enable wake-up events */

 Enable SYS_CLKEN control when all domains idle */

 Look up important powerdomains */

 Look up important clockdomains */

	/*

	 * We copy the assembler sleep/wakeup routines to SRAM.

	 * These routines need to be in SRAM as that's the only

	 * memory the MPU can see when it wakes up after the entire

	 * chip enters idle.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3/OMAP4 Voltage Management Routines

 *

 * Author: Thara Gopinath	<thara@ti.com>

 *

 * Copyright (C) 2007 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Lesly A M <x0080970@ti.com>

 *

 * Copyright (C) 2008 Nokia Corporation

 * Kalle Jokiniemi

 *

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Thara Gopinath <thara@ti.com>

	/*

	 * XXX Will depend on the process, validation, and binning

	 * for the currently-running IC

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod_3xxx_data.c - hardware modules present on the OMAP3xxx chips

 *

 * Copyright (C) 2009-2011 Nokia Corporation

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 *

 * The data in this file should be completely autogeneratable from

 * the TI hardware database or other technical documentation.

 *

 * XXX these should be marked initdata for multi-OMAP kernels

/*

 * OMAP3xxx hardware module integration data

 *

 * All of the data in this section should be autogeneratable from the

 * TI hardware database or other technical documentation.  Data that

 * is driver-specific or driver-kernel integration-specific belongs

 * elsewhere.

/*

 * IP blocks

 L3 */

 L4 CORE */

 L4 PER */

 L4 WKUP */

 L4 SEC */

 MPU */

 IVA2 (IVA2) */

/*

 * 'debugss' class

 * debug and emulation sub system

 debugss */

 timer class */

 timer3 */

 timer4 */

 timer5 */

 timer6 */

 timer7 */

 timer8 */

 timer9 */

 timer10 */

 timer11 */

/*

 * 'wd_timer' class

 * 32-bit watchdog upward counter that generates a pulse on the reset pin on

 * overflow condition

 I2C common */

	/*

	 * XXX: Use software supervised mode, HW supervised smartidle seems to

	 * block CORE power domain idle transitions. Maybe a HW bug in wdt2?

 UART1 */

 UART2 */

 UART3 */

 UART4 */

/*

 * XXX AM35xx UART4 cannot complete its softreset without uart1_fck or

 * uart2_fck being enabled.  So we add uart1_fck as an optional clock,

 * below, and set the HWMOD_CONTROL_OPT_CLKS_IN_RESET.  This really

 * should not be needed.  The functional clock structure of the AM35xx

 * UART4 is extremely unclear and opaque; it is unclear what the role

 * of uart1/2_fck is for the UART4.  Any clarification from either

 * empirical testing or the AM3505/3517 hardware designers would be

 * most welcome.

 dss */

	/*

	 * The DSS HW needs all DSS clocks enabled during reset. The dss_core

	 * driver does not use these clocks.

 required only on OMAP3430 */

 instead of dss_fck */

 instead of dss_fck */

/*

 * 'dispc' class

 * display controller

/*

 * 'dsi' class

 * display serial interface controller

 dss_dsi1 */

 required only on OMAP3430 */

 I2C1 */

 I2C2 */

 I2C3 */

/*

 * 'gpio' class

 * general purpose io module

 gpio1 */

 gpio2 */

 gpio3 */

 gpio4 */

 gpio5 */

 gpio6 */

/*

 * 'mcbsp' class

 * multi channel buffered serial port controller

 McBSP functional clock mapping */

 mcbsp1 */

 mcbsp2 */

 mcbsp3 */

 mcbsp4 */

 mcbsp5 */

 'mcbsp sidetone' class */

 mcbsp2_sidetone */

 mcbsp3_sidetone */

 SR common */

 SR1 */

 SR2 */

/*

 * 'mailbox' class

 * mailbox module allowing communication between the on-chip processors

 * using a queued mailbox-interrupt mechanism.

/*

 * 'mcspi' class

 * multichannel serial port interface (mcspi) / master/slave synchronous serial

 * bus

 mcspi1 */

 mcspi2 */

 mcspi3 */

 mcspi4 */

 usbhsotg */

 usb_otg_hs */

	/*

	 * Erratum ID: i479  idle_req / idle_ack mechanism potentially

	 * broken when autoidle is enabled

	 * workaround is to disable the autoidle bit at module level.

	 *

	 * Enabling the device in any other MIDLEMODE setting but force-idle

	 * causes core_pwrdm not enter idle states at least on OMAP3630.

	 * Note that musb has OTG_FORCESTDBY register that controls MSTANDBY

	 * signal when MIDLEMODE is set to force-idle.

 usb_otg_hs */

 MMC/SD/SDIO common */

 MMC/SD/SDIO1 */

 See 35xx errata 2.1.1.128 in SPRZ278F */

 MMC/SD/SDIO2 */

 See 35xx errata 2.1.1.128 in SPRZ278F */

 MMC/SD/SDIO3 */

/*

 * 'usb_host_hs' class

 * high-speed multi-port usb host controller

	/*

	 * Errata: USBHOST Configured In Smart-Idle Can Lead To a Deadlock

	 * id: i660

	 *

	 * Description:

	 * In the following configuration :

	 * - USBHOST module is set to smart-idle mode

	 * - PRCM asserts idle_req to the USBHOST module ( This typically

	 *   happens when the system is going to a low power mode : all ports

	 *   have been suspended, the master part of the USBHOST module has

	 *   entered the standby state, and SW has cut the functional clocks)

	 * - an USBHOST interrupt occurs before the module is able to answer

	 *   idle_ack, typically a remote wakeup IRQ.

	 * Then the USB HOST module will enter a deadlock situation where it

	 * is no more accessible nor functional.

	 *

	 * Workaround:

	 * Don't use smart idle; use only force idle, hence HWMOD_SWSUP_SIDLE

	/*

	 * Errata: USB host EHCI may stall when entering smart-standby mode

	 * Id: i571

	 *

	 * Description:

	 * When the USBHOST module is set to smart-standby mode, and when it is

	 * ready to enter the standby state (i.e. all ports are suspended and

	 * all attached devices are in suspend mode), then it can wrongly assert

	 * the Mstandby signal too early while there are still some residual OCP

	 * transactions ongoing. If this condition occurs, the internal state

	 * machine may go to an undefined state and the USB link may be stuck

	 * upon the next resume.

	 *

	 * Workaround:

	 * Don't use smart standby; use only force standby,

	 * hence HWMOD_SWSUP_MSTANDBY

/*

 * 'usb_tll_hs' class

 * usb_tll_hs module is the adapter on the usb_host_hs ports

 SAD2D */

/*

 * 'gpmc' class

 * general purpose memory controller

 Skip reset for CONFIG_OMAP_GPMC_DEBUG for bootloader timings */

/*

 * interfaces

 L3 -> L4_CORE interface */

 L3 -> L4_PER interface */

 MPU -> L3 interface */

 l3 -> debugss */

 DSS -> l3 */

 l3_core -> usbhsotg interface */

 l3_core -> am35xx_usbhsotg interface */

 l3_core -> sad2d interface */

 L4_CORE -> L4_WKUP interface */

 L4 CORE -> MMC1 interface */

 L4 CORE -> MMC2 interface */

 L4 CORE -> MMC3 interface */

 L4 CORE -> UART1 interface */

 L4 CORE -> UART2 interface */

 L4 PER -> UART3 interface */

 L4 PER -> UART4 interface */

 AM35xx: L4 CORE -> UART4 interface */

 L4 CORE -> I2C1 interface */

 L4 CORE -> I2C2 interface */

 L4 CORE -> I2C3 interface */

 L4 CORE -> SR1 interface */

 L4 CORE -> SR2 interface */

 l4_core -> usbhsotg  */

 l4_core -> usbhsotg  */

 L4_WKUP -> L4_SEC interface */

 IVA2 <- L3 interface */

 l4_per -> timer3 */

 l4_per -> timer4 */

 l4_per -> timer5 */

 l4_per -> timer6 */

 l4_per -> timer7 */

 l4_per -> timer8 */

 l4_per -> timer9 */

 l4_core -> timer10 */

 l4_core -> timer11 */

 l4_wkup -> wd_timer2 */

 l4_core -> dss */

 l4_core -> dss_dispc */

 l4_core -> dss_dsi1 */

 l4_core -> dss_rfbi */

 l4_core -> dss_venc */

 l4_wkup -> gpio1 */

 l4_per -> gpio2 */

 l4_per -> gpio3 */

/*

 * 'mmu' class

 * The memory management unit performs virtual to physical address translation

 * for its requestors.

 mmu isp */

 l4_core -> mmu isp */

 mmu iva */

 l3_main -> iva mmu */

 l4_per -> gpio4 */

 l4_per -> gpio5 */

 l4_per -> gpio6 */

 l4_core -> mcbsp1 */

 l4_per -> mcbsp2 */

 l4_per -> mcbsp3 */

 l4_per -> mcbsp4 */

 l4_core -> mcbsp5 */

 l4_per -> mcbsp2_sidetone */

 l4_per -> mcbsp3_sidetone */

 l4_core -> mailbox */

 l4 core -> mcspi1 interface */

 l4 core -> mcspi2 interface */

 l4 core -> mcspi3 interface */

 l4 core -> mcspi4 interface */

 l4_core -> hdq1w interface */

 am35xx has Davinci MDIO & EMAC */

/*

 * XXX Should be connected to an IPSS hwmod, not the L3 directly;

 * but this will probably require some additional hwmod core support,

 * so is left as a future to-do item.

 l4_core -> davinci mdio  */

/*

 * XXX Should be connected to an IPSS hwmod, not the L4_CORE directly;

 * but this will probably require some additional hwmod core support,

 * so is left as a future to-do item.

	/*

	 * According to Mark Greer, the MPU will not return from WFI

	 * when the EMAC signals an interrupt.

	 * http://www.spinics.net/lists/arm-kernel/msg174734.html

 l3_core -> davinci emac interface */

/*

 * XXX Should be connected to an IPSS hwmod, not the L3 directly;

 * but this will probably require some additional hwmod core support,

 * so is left as a future to-do item.

 l4_core -> davinci emac  */

/*

 * XXX Should be connected to an IPSS hwmod, not the L4_CORE directly;

 * but this will probably require some additional hwmod core support,

 * so is left as a future to-do item.

 l4_core -> SHAM2 (SHA1/MD5) (similar to omap24xx) */

/*

 * 'ssi' class

 * synchronous serial interface (multichannel and full-duplex serial if)

 L4 CORE -> SSI */

 crypto hwmod links */

/*

 * Apparently the SHA/MD5 and AES accelerator IP blocks are

 * only present on some AM35xx chips, and no one knows which

 * ones.  See

 * http://www.spinics.net/lists/arm-kernel/msg215466.html So

 * if you need these IP blocks on an AM35xx, try uncommenting

 * the following lines.

 &omap3xxx_l4_core__sham, */

 3430ES1-only hwmod links */

 3430ES2+-only hwmod links */

 <= 3430ES3-only hwmod links */

 3430ES3+-only hwmod links */

 34xx-only hwmod links (all ES revisions) */

 36xx-only hwmod links (all ES revisions) */

/**

 * omap3xxx_hwmod_is_hs_ip_block_usable - is a security IP block accessible?

 * @bus: struct device_node * for the top-level OMAP DT data

 * @dev_name: device name used in the DT file

 *

 * Determine whether a "secure" IP block @dev_name is usable by Linux.

 * There doesn't appear to be a 100% reliable way to determine this,

 * so we rely on heuristics.  If @bus is null, meaning there's no DT

 * data, then we only assume the IP block is accessible if the OMAP is

 * fused as a 'general-purpose' SoC.  If however DT data is present,

 * test to see if the IP block is described in the DT data and set to

 * 'status = "okay"'.  If so then we assume the ODM has configured the

 * OMAP firewalls to allow access to the IP block.

 *

 * Return: 0 if device named @dev_name is not likely to be accessible,

 * or 1 if it is likely to be accessible.

 Register hwmod links common to all OMAP3 */

	/*

	 * Register hwmod links common to individual OMAP3 families, all

	 * silicon revisions (e.g., 34xx, or AM3505/3517, or 36xx)

	 * All possible revisions should be included in this conditional.

	/*

	 * Register crypto hwmod links only if they are not disabled in DT.

	 * If DT information is missing, enable them only for GP devices.

	/*

	 * Register hwmod links specific to certain ES levels of a

	 * particular family of silicon (e.g., 34xx ES1.0)

	/*

	 * DSS code presumes that dss_core hwmod is handled first,

	 * _before_ any other DSS related hwmods so register common

	 * DSS hwmod links last to ensure that dss_core is already

	 * registered.  Otherwise some change things may happen, for

	 * ex. if dispc is handled before dss_core and DSS is enabled

	 * in bootloader DISPC will be reset with outputs enabled

	 * which sometimes leads to unrecoverable L3 error.  XXX The

	 * long-term fix to this is to ensure hwmods are set up in

	 * dependency order in the hwmod core code.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3xxx PRM module functions

 *

 * Copyright (C) 2010-2012 Texas Instruments, Inc.

 * Copyright (C) 2010 Nokia Corporation

 * Benot Cousson

 * Paul Walmsley

 * Rajendra Nayak <rnayak@ti.com>

/*

 * omap3_prm_reset_src_map - map from bits in the PRM_RSTST hardware

 *   register (which are specific to OMAP3xxx SoCs) to reset source ID

 *   bit shifts (which is an OMAP SoC-independent enumeration)

 PRM VP */

/*

 * struct omap3_vp - OMAP3 VP register access description.

 * @tranxdone_status: VP_TRANXDONE_ST bitmask in PRM_IRQSTATUS_MPU reg

/**

 * omap3xxx_prm_dpll3_reset - use DPLL3 reset to reboot the OMAP SoC

 *

 * Set the DPLL3 reset bit, which should reboot the SoC.  This is the

 * recommended way to restart the SoC, considering Errata i520.  No

 * return value.

 OCP barrier */

/**

 * omap3xxx_prm_read_pending_irqs - read pending PRM MPU IRQs into @events

 * @events: ptr to a u32, preallocated by caller

 *

 * Read PRM_IRQSTATUS_MPU bits, AND'ed with the currently-enabled PRM

 * MPU IRQs, and store the result into the u32 pointed to by @events.

 * No return value.

 XXX Can the mask read be avoided (e.g., can it come from RAM?) */

/**

 * omap3xxx_prm_ocp_barrier - force buffered MPU writes to the PRM to complete

 *

 * Force any buffered writes to the PRM IP block to complete.  Needed

 * by the PRM IRQ handler, which reads and writes directly to the IP

 * block, to avoid race conditions after acknowledging or clearing IRQ

 * bits.  No return value.

/**

 * omap3xxx_prm_save_and_clear_irqen - save/clear PRM_IRQENABLE_MPU reg

 * @saved_mask: ptr to a u32 array to save IRQENABLE bits

 *

 * Save the PRM_IRQENABLE_MPU register to @saved_mask.  @saved_mask

 * must be allocated by the caller.  Intended to be used in the PRM

 * interrupt handler suspend callback.  The OCP barrier is needed to

 * ensure the write to disable PRM interrupts reaches the PRM before

 * returning; otherwise, spurious interrupts might occur.  No return

 * value.

 OCP barrier */

/**

 * omap3xxx_prm_restore_irqen - set PRM_IRQENABLE_MPU register from args

 * @saved_mask: ptr to a u32 array of IRQENABLE bits saved previously

 *

 * Restore the PRM_IRQENABLE_MPU register from @saved_mask.  Intended

 * to be used in the PRM interrupt handler resume callback to restore

 * values saved by omap3xxx_prm_save_and_clear_irqen().  No OCP

 * barrier should be needed here; any pending PRM interrupts will fire

 * once the writes reach the PRM.  No return value.

/**

 * omap3xxx_prm_clear_mod_irqs - clear wake-up events from PRCM interrupt

 * @module: PRM module to clear wakeups from

 * @regs: register set to clear, 1 or 3

 * @wkst_mask: wkst bits to clear

 *

 * The purpose of this function is to clear any wake-up events latched

 * in the PRCM PM_WKST_x registers. It is possible that a wake-up event

 * may occur whilst attempting to clear a PM_WKST_x register and thus

 * set another bit in this register. A while loop is used to ensure

 * that any peripheral wake-up events occurring while attempting to

 * clear the PM_WKST_x are detected and cleared.

			/*

			 * For USBHOST, we don't know whether HOST1 or

			 * HOST2 woke us up, so enable both f-clocks

/**

 * omap3_prm_reset_modem - toggle reset signal for modem

 *

 * Toggles the reset signal to modem IP block. Required to allow

 * OMAP3430 without stacked modem to idle properly.

/**

 * omap3_prm_init_pm - initialize PM related registers for PRM

 * @has_uart4: SoC has UART4

 * @has_iva: SoC has IVA

 *

 * Initializes PRM registers for PM use. Called from PM init.

	/*

	 * Enable control of expternal oscillator through

	 * sys_clkreq. In the long run clock framework should

	 * take care of this.

 setup wakup source */

 No need to write EN_IO, that is always enabled */

 Enable PM_WKEN to support DSS LPR */

 Enable wakeups in PER */

 and allow them to wake up MPU */

 Don't attach IVA interrupts */

 Clear any pending 'reset' flags */

 Clear any pending PRCM interrupts */

 We need to idle iva2_pwrdm even on am3703 with no iva2. */

/**

 * omap3430_pre_es3_1_reconfigure_io_chain - restart wake-up daisy chain

 *

 * The ST_IO_CHAIN bit does not exist in 3430 before es3.1. The only

 * thing we can do is toggle EN_IO bit for earlier omaps.

/**

 * omap3_prm_reconfigure_io_chain - clear latches and reconfigure I/O chain

 *

 * Clear any previously-latched I/O wakeup events and ensure that the

 * I/O wakeup gates are aligned with the current mux settings.  Works

 * by asserting WUCLKIN, waiting for WUCLKOUT to be asserted, and then

 * deasserting WUCLKIN and clearing the ST_IO_CHAIN WKST bit.  No

 * return value. These registers are only available in 3430 es3.1 and later.

/**

 * omap3xxx_prm_enable_io_wakeup - enable wakeup events from I/O wakeup latches

 *

 * Activates the I/O wakeup event latches and allows events logged by

 * those latches to signal a wakeup event to the PRCM.  For I/O

 * wakeups to occur, WAKEUPENABLE bits must be set in the pad mux

 * registers, and omap3xxx_prm_reconfigure_io_chain() must be called.

 * No return value.

/**

 * omap3xxx_prm_read_reset_sources - return the last SoC reset source

 *

 * Return a u32 representing the last reset sources of the SoC.  The

 * returned reset source bits are standardized across OMAP SoCs.

/**

 * omap3xxx_prm_iva_idle - ensure IVA is in idle so it can be put into retention

 *

 * In cases where IVA2 is activated by bootcode, it may prevent

 * full-chip retention or off-mode because it is not idle.  This

 * function forces the IVA2 into idle state so it can go

 * into retention/off and thus allow full-chip retention/off.

 ensure IVA2 clock is disabled */

 if no clock activity, nothing else to do */

 Reset IVA2 */

 Enable IVA2 clock */

 Un-reset IVA2 */

 Disable IVA2 clock */

 Reset IVA2 */

/**

 * omap3xxx_prm_clear_global_cold_reset - checks the global cold reset status

 *					  and clears it if asserted

 *

 * Checks if cold-reset has occurred and clears the status bit if yes. Returns

 * 1 if cold-reset has occurred, 0 otherwise.

 Powerdomain low-level functions */

 Applicable only for OMAP3. Not supported on OMAP2 */

 should never happen */

/*

 *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3 Voltage Processor (VP) data

 *

 * Copyright (C) 2007, 2010 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Lesly A M <x0080970@ti.com>

 * Thara Gopinath <thara@ti.com>

 *

 * Copyright (C) 2008, 2011 Nokia Corporation

 * Kalle Jokiniemi

 * Paul Walmsley

/*

 * VP data common to 44xx chips

 * XXX This stuff presumably belongs in the vp44xx.c or vp.c file.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod_common_ipblock_data.c - common IP block data for OMAP2+

 *

 * Copyright (C) 2011 Nokia Corporation

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

/*

 * 'dss' class

 * display sub-system

/*

 * 'rfbi' class

 * remote frame buffer interface

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP IOMMU quirks for various TI SoCs

 *

 * Copyright (C) 2015-2019 Texas Instruments Incorporated - https://www.ti.com/

 *      Suman Anna <s-anna@ti.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP54XX Power domains framework

 *

 * Copyright (C) 2013 Texas Instruments, Inc.

 *

 * Abhijit Pagare (abhijitpagare@ti.com)

 * Benoit Cousson (b-cousson@ti.com)

 * Paul Walmsley (paul@pwsan.com)

 *

 * This file is automatically generated from the OMAP hardware databases.

 * We respectfully ask that any modifications to this file be coordinated

 * with the public linux-omap@vger.kernel.org mailing list and the

 * authors above to ensure that the autogeneration scripts are kept

 * up-to-date with the file contents.

 core_54xx_pwrdm: CORE power domain */

 core_nret_bank */

 core_ocmram */

 core_other_bank */

 ipu_l2ram */

 ipu_unicache */

 core_nret_bank */

 core_ocmram */

 core_other_bank */

 ipu_l2ram */

 ipu_unicache */

 abe_54xx_pwrdm: Audio back end power domain */

 aessmem */

 periphmem */

 aessmem */

 periphmem */

 coreaon_54xx_pwrdm: Always ON logic that sits in VDD_CORE voltage domain */

 dss_54xx_pwrdm: Display subsystem power domain */

 dss_mem */

 dss_mem */

 cpu0_54xx_pwrdm: MPU0 processor and Neon coprocessor power domain */

 cpu0_l1 */

 cpu0_l1 */

 cpu1_54xx_pwrdm: MPU1 processor and Neon coprocessor power domain */

 cpu1_l1 */

 cpu1_l1 */

 emu_54xx_pwrdm: Emulation power domain */

 emu_bank */

 emu_bank */

 mpu_54xx_pwrdm: Modena processor and the Neon coprocessor power domain */

 mpu_l2 */

 mpu_ram */

 mpu_l2 */

 mpu_ram */

 custefuse_54xx_pwrdm: Customer efuse controller power domain */

 dsp_54xx_pwrdm: Tesla processor power domain */

 dsp_edma */

 dsp_l1 */

 dsp_l2 */

 dsp_edma */

 dsp_l1 */

 dsp_l2 */

 cam_54xx_pwrdm: Camera subsystem power domain */

 cam_mem */

 cam_mem */

 l3init_54xx_pwrdm: L3 initators pheripherals power domain  */

 l3init_bank1 */

 l3init_bank2 */

 l3init_bank1 */

 l3init_bank2 */

 gpu_54xx_pwrdm: 3D accelerator power domain */

 gpu_mem */

 gpu_mem */

 wkupaon_54xx_pwrdm: Wake-up power domain */

 wkup_bank */

 iva_54xx_pwrdm: IVA-HD power domain */

 hwa_mem */

 sl2_mem */

 tcm1_mem */

 tcm2_mem */

 hwa_mem */

 sl2_mem */

 tcm1_mem */

 tcm2_mem */

/*

 * The following power domains are not under SW control

 *

 * mpuaon

 * mmaon

 As powerdomains are added or removed above, this list must also be changed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2/3 common powerdomain definitions

 *

 * Copyright (C) 2007-2008, 2011 Texas Instruments, Inc.

 * Copyright (C) 2007-2011 Nokia Corporation

 *

 * Paul Walmsley, Jouni Hgander

/*

 * The names for the DSP/IVA2 powerdomains are confusing.

 *

 * Most OMAP chips have an on-board DSP.

 *

 * On the 2420, this is a 'C55 DSP called, simply, the DSP.  Its

 * powerdomain is called the "DSP power domain."  On the 2430, the

 * on-board DSP is a 'C64 DSP, now called (along with its hardware

 * accelerators) the IVA2 or IVA2.1.  Its powerdomain is still called

 * the "DSP power domain." On the 3430, the DSP is a 'C64 DSP like the

 * 2430, also known as the IVA2; but its powerdomain is now called the

 * "IVA2 power domain."

 *

 * The 2420 also has something called the IVA, which is a separate ARM

 * core, and has nothing to do with the DSP/IVA2.

 *

 * Ideally the DSP/IVA2 could just be the same powerdomain, but the PRCM

 * address offset is different between the C55 and C64 DSPs.

 OMAP2/3-common powerdomains */

/*

 * The GFX powerdomain is not present on 3430ES2, but currently we do not

 * have a macro to filter it out at compile-time.

 MEMRETSTATE */

 MEMONSTATE */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 Voltage Controller (VC) data

 *

 * Copyright (C) 2007, 2010 Texas Instruments, Inc.

 * Rajendra Nayak <rnayak@ti.com>

 * Lesly A M <x0080970@ti.com>

 * Thara Gopinath <thara@ti.com>

 *

 * Copyright (C) 2008, 2011 Nokia Corporation

 * Kalle Jokiniemi

 * Paul Walmsley

/*

 * VC data common to 44xx chips

 * XXX This stuff presumably belongs in the vc3xxx.c or vc.c file.

 VC instance data for each controllable voltage line */

/*

 * Voltage levels for different operating modes: on, sleep, retention and off

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP3xxx clockdomains

 *

 * Copyright (C) 2008-2011 Texas Instruments, Inc.

 * Copyright (C) 2008-2010 Nokia Corporation

 *

 * Paul Walmsley, Jouni Hgander

 *

 * This file contains clockdomains and clockdomain wakeup/sleep

 * dependencies for the OMAP3xxx chips.  Some notes:

 *

 * A useful validation rule for struct clockdomain: Any clockdomain

 * referenced by a wkdep_srcs or sleepdep_srcs array must have a

 * dep_bit assigned.  So wkdep_srcs/sleepdep_srcs are really just

 * software-controllable dependencies.  Non-software-controllable

 * dependencies do exist, but they are not encoded below (yet).

 *

 * The overly-specific dep_bit names are due to a bit name collision

 * with CM_FCLKEN_{DSP,IVA2}.  The DSP/IVA2 PM_WKDEP and CM_SLEEPDEP shift

 * value are the same for all powerdomains: 2

 *

 * XXX should dep_bit be a mask, so we can test to see if it is 0 as a

 * sanity check?

 * XXX encode hardware fixed wakeup dependencies -- esp. for 3430 CORE

/*

 * To-Do List

 * -> Port the Sleep/Wakeup dependencies for the domains

 *    from the Power domain framework

/*

 * Clockdomain dependencies for wkdeps/sleepdeps

 *

 * XXX Hardware dependencies (e.g., dependencies that cannot be

 * changed in software) are not included here yet, but should be.

 OMAP3-specific possible dependencies */

/*

 * 3430ES1 PM_WKDEP_GFX: adds IVA2, removes CORE

 * 3430ES2 PM_WKDEP_SGX: adds IVA2, removes CORE

 3430: PM_WKDEP_PER: CORE, IVA2, MPU, WKUP */

 3430ES2: PM_WKDEP_USBHOST: CORE, IVA2, MPU, WKUP */

 3430 PM_WKDEP_MPU: CORE, IVA2, DSS, PER */

 3430 PM_WKDEP_IVA2: CORE, MPU, WKUP, DSS, PER */

 3430 PM_WKDEP_CAM: IVA2, MPU, WKUP */

 3430 PM_WKDEP_DSS: IVA2, MPU, WKUP */

 3430: PM_WKDEP_NEON: MPU */

 Sleep dependency source arrays for OMAP3-specific clkdms */

 3430: CM_SLEEPDEP_DSS: MPU, IVA */

 3430: CM_SLEEPDEP_PER: MPU, IVA */

 3430ES2: CM_SLEEPDEP_USBHOST: MPU, IVA */

 3430: CM_SLEEPDEP_CAM: MPU */

/*

 * 3430ES1: CM_SLEEPDEP_GFX: MPU

 * 3430ES2: CM_SLEEPDEP_SGX: MPU

 * These can share data since they will never be present simultaneously

 * on the same device.

/*

 * OMAP3 clockdomains

/*

 * The die-to-die clockdomain was documented in the 34xx ES1 TRM, but

 * then that information was removed from the 34xx ES2+ TRM.  It is

 * unclear whether the core is still there, but the clockdomain logic

 * is there, and must be programmed to an appropriate state if the

 * CORE clockdomain is to become inactive.

/*

 * XXX add usecounting for clkdm dependencies, otherwise the presence

 * of a single dep bit for core_l3_3xxx_clkdm and core_l4_3xxx_clkdm

 * could cause trouble

/*

 * XXX add usecounting for clkdm dependencies, otherwise the presence

 * of a single dep bit for core_l3_3xxx_clkdm and core_l4_3xxx_clkdm

 * could cause trouble

 Another case of bit name collisions between several registers: EN_DSS */

/*

 * Clockdomain hwsup dependencies

/*

 *

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP2xxx clockdomains

 *

 * Copyright (C) 2008-2009 Texas Instruments, Inc.

 * Copyright (C) 2008-2010 Nokia Corporation

 *

 * Paul Walmsley, Jouni Hgander

 *

 * This file contains clockdomains and clockdomain wakeup dependencies

 * for OMAP2xxx chips.  Some notes:

 *

 * A useful validation rule for struct clockdomain: Any clockdomain

 * referenced by a wkdep_srcs must have a dep_bit assigned.  So

 * wkdep_srcs are really just software-controllable dependencies.

 * Non-software-controllable dependencies do exist, but they are not

 * encoded below (yet).

 *

 * 24xx does not support programmable sleep dependencies (SLEEPDEP)

 *

 * The overly-specific dep_bit names are due to a bit name collision

 * with CM_FCLKEN_{DSP,IVA2}.  The DSP/IVA2 PM_WKDEP and CM_SLEEPDEP shift

 * value are the same for all powerdomains: 2

 *

 * XXX should dep_bit be a mask, so we can test to see if it is 0 as a

 * sanity check?

 * XXX encode hardware fixed wakeup dependencies -- esp. for 3430 CORE

/*

 * To-Do List

 * -> Port the Sleep/Wakeup dependencies for the domains

 *    from the Power domain framework

/*

 * Clockdomain dependencies for wkdeps

 *

 * XXX Hardware dependencies (e.g., dependencies that cannot be

 * changed in software) are not included here yet, but should be.

 Wakeup dependency source arrays */

 2430-specific possible wakeup dependencies */

 2430 PM_WKDEP_CORE: DSP, GFX, MPU, WKUP, MDM */

 2430 PM_WKDEP_MPU: CORE, DSP, WKUP, MDM */

 2430 PM_WKDEP_MDM: CORE, MPU, WKUP */

/*

 * 2430-only clockdomains

 Another case of bit name collisions between several registers: EN_MDM */

/*

 * XXX add usecounting for clkdm dependencies, otherwise the presence

 * of a single dep bit for core_l3_24xx_clkdm and core_l4_24xx_clkdm

 * could cause trouble

/*

 * XXX add usecounting for clkdm dependencies, otherwise the presence

 * of a single dep bit for core_l3_24xx_clkdm and core_l4_24xx_clkdm

 * could cause trouble

 SPDX-License-Identifier: GPL-2.0

 Trigger initVDD value copy to voltage processor */

 Clear initVDD copy trigger bit */

 Generic voltage init functions */

 Divide to avoid overflow */

	/*

	 * VP_CONFIG: error gain is not set here, it will be updated

	 * on each scale, based on OPP.

 VSTEPMIN */

 VSTEPMAX */

 VLIMITTO */

 Get volt_data corresponding to target_volt */

 Setting vp errorgain based on the voltage */

 VP force update method of voltage scaling */

	/*

	 * Clear all pending TransactionDone interrupt/status. Typical latency

	 * is <3us

 Force update of voltage */

	/*

	 * Wait for TransactionDone. Typical latency is <200us.

	 * Depends on SMPSWAITTIMEMIN/MAX and voltage change

	/*

	 * Disable TransactionDone interrupt , clear all status, clear

	 * control registers

 Clear force bit */

/**

 * omap_vp_enable() - API to enable a particular VP

 * @voltdm:	pointer to the VDD whose VP is to be enabled.

 *

 * This API enables a particular voltage processor. Needed by the smartreflex

 * class drivers.

 If VP is already enabled, do nothing. Return */

 Enable VP */

/**

 * omap_vp_disable() - API to disable a particular VP

 * @voltdm:	pointer to the VDD whose VP is to be disabled.

 *

 * This API disables a particular voltage processor. Needed by the smartreflex

 * class drivers.

 If VP is already disabled, do nothing. Return */

 Disable VP */

	/*

	 * Wait for VP idle Typical latency is <2us. Maximum latency is ~100us

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod_2xxx_interconnect_data.c - common interconnect data for OMAP2xxx

 *

 * Copyright (C) 2009-2011 Nokia Corporation

 * Paul Walmsley

 *

 * XXX handle crossbar/shared link difference for L3?

 * XXX these should be marked initdata for multi-OMAP kernels

/*

 * Common interconnect data

 L3 -> L4_CORE interface */

 MPU -> L3 interface */

 DSS -> l3 */

 L4_CORE -> L4_WKUP interface */

 L4 CORE -> UART1 interface */

 L4 CORE -> UART2 interface */

 L4 PER -> UART3 interface */

 l4 core -> mcspi1 interface */

 l4 core -> mcspi2 interface */

 l4_core -> timer3 */

 l4_core -> timer4 */

 l4_core -> timer5 */

 l4_core -> timer6 */

 l4_core -> timer7 */

 l4_core -> timer8 */

 l4_core -> timer9 */

 l4_core -> timer10 */

 l4_core -> timer11 */

 l4_core -> timer12 */

 l4_core -> dss */

 l4_core -> dss_dispc */

 l4_core -> dss_rfbi */

 l4_core -> dss_venc */

 l4_core -> rng */

 l4 core -> sham interface */

 l4 core -> aes interface */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3 powerdomain definitions

 *

 * Copyright (C) 2007-2008, 2011 Texas Instruments, Inc.

 * Copyright (C) 2007-2011 Nokia Corporation

 *

 * Paul Walmsley, Jouni Hgander

/*

 * 34XX-specific powerdomains, dependencies

/*

 * Powerdomains

/*

 * The USBTLL Save-and-Restore mechanism is broken on

 * 3430s up to ES3.0 and 3630ES1.0. Hence this feature

 * needs to be disabled on these chips.

 * Refer: 3430 errata ID i459 and 3630 errata ID i579

 *

 * Note: setting the SAR flag could help for errata ID i478

 *  which applies to 3430 <= ES3.1, but since the SAR feature

 *  is broken, do not use it.

 MEM1RETSTATE */

 MEM2RETSTATE */

 MEM1ONSTATE */

 MEM2ONSTATE */

	/*

	 * Setting the SAR flag for errata ID i478 which applies

	 *  to 3430 <= ES3.1

 for USBTLL only */

 MEM1RETSTATE */

 MEM2RETSTATE */

 MEM1ONSTATE */

 MEM2ONSTATE */

 MEM1RETSTATE */

 MEM2RETSTATE */

 MEM1ONSTATE */

 MEM2ONSTATE */

 MEMRETSTATE */

 MEMONSTATE */

 MEMRETSTATE */

 MEMONSTATE */

/*

 * Although the 34XX TRM Rev K Table 4-371 notes that retention is a

 * possible SGX powerstate, the SGX device itself does not support

 * retention.

 XXX This is accurate for 3430 SGX, but what about GFX? */

 MEMRETSTATE */

 MEMONSTATE */

 MEMRETSTATE */

 MEMONSTATE */

 MEMRETSTATE */

 MEMONSTATE */

 MEMRETSTATE */

 MEMONSTATE */

 MEMRETSTATE */

 MEMONSTATE */

	/*

	 * REVISIT: Enabling usb host save and restore mechanism seems to

	 * leave the usb host domain permanently in ACTIVE mode after

	 * changing the usb host power domain state from OFF to active once.

	 * Disabling for now.

.flags	  = PWRDM_HAS_HDWR_SAR,*/ 
 MEMRETSTATE */

 MEMONSTATE */

 As powerdomains are added or removed above, this list must also be changed */

 also includes 3630ES1.0 */

 also includes 3630ES1.1+ */

 TI81XX specific ops */

 For dm814x we need to fix up fix GFX pwstst and rstctrl reg offsets */

 Only 81xx needs custom pwrdm_operations */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP Power Management debug routines

 *

 * Copyright (C) 2005 Texas Instruments, Inc.

 * Copyright (C) 2006-2008 Nokia Corporation

 *

 * Written by:

 * Richard Woodruff <r-woodruff2@ti.com>

 * Tony Lindgren

 * Juha Yrjola

 * Amit Kucheria <amit.kucheria@nokia.com>

 * Igor Stoppa <igor.stoppa@nokia.com>

 * Jouni Hogander

 *

 * Based on pm.c for omap2

 Update timer for previous state */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2XXX powerdomain definitions

 *

 * Copyright (C) 2007-2008, 2011 Texas Instruments, Inc.

 * Copyright (C) 2007-2011 Nokia Corporation

 *

 * Paul Walmsley, Jouni Hgander

 24XX powerdomains and dependencies */

 Powerdomains */

 MEM1RETSTATE */

 MEM2RETSTATE */

 MEM3RETSTATE */

 MEM1ONSTATE */

 MEM2ONSTATE */

 MEM3ONSTATE */

/*

 * 2430-specific powerdomains

 XXX 2430 KILLDOMAINWKUP bit?  No current users apparently */

 MEMRETSTATE */

 MEMONSTATE */

/*

 *

/*

 * AM33XX CM functions

 *

 * Copyright (C) 2011-2012 Texas Instruments Incorporated - https://www.ti.com/

 * Vaibhav Hiremath <hvaibhav@ti.com>

 *

 * Reference taken from from OMAP4 cminst44xx.c

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * CLKCTRL_IDLEST_*: possible values for the CM_*_CLKCTRL.IDLEST bitfield:

 *

 *   0x0 func:     Module is fully functional, including OCP

 *   0x1 trans:    Module is performing transition: wakeup, or sleep, or sleep

 *                 abortion

 *   0x2 idle:     Module is in Idle mode (only OCP part). It is functional if

 *                 using separate functional clock

 *   0x3 disabled: Module is disabled and cannot be accessed

 *

 Private functions */

 Read a register in a CM instance */

 Write into a register in a CM */

 Read-modify-write a register in CM */

/**

 * _clkctrl_idlest - read a CM_*_CLKCTRL register; mask & shift IDLEST bitfield

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * Return the IDLEST bitfield of a CM_*_CLKCTRL register, shifted down to

 * bit 0.

/**

 * _is_module_ready - can module registers be accessed without causing an abort?

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * Returns true if the module's CM_*_CLKCTRL.IDLEST bitfield is either

 * *FUNCTIONAL or *INTERFACE_IDLE; false otherwise.

/**

 * _clktrctrl_write - write @c to a CM_CLKSTCTRL.CLKTRCTRL register bitfield

 * @c: CLKTRCTRL register bitfield (LSB = bit 0, i.e., unshifted)

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * @c must be the unshifted value for CLKTRCTRL - i.e., this function

 * will handle the shift itself.

 Public functions */

/**

 * am33xx_cm_is_clkdm_in_hwsup - is a clockdomain in hwsup idle mode?

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Returns true if the clockdomain referred to by (@inst, @cdoffs)

 * is in hardware-supervised idle mode, or 0 otherwise.

/**

 * am33xx_cm_clkdm_enable_hwsup - put a clockdomain in hwsup-idle mode

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Put a clockdomain referred to by (@inst, @cdoffs) into

 * hardware-supervised idle mode.  No return value.

/**

 * am33xx_cm_clkdm_disable_hwsup - put a clockdomain in swsup-idle mode

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Put a clockdomain referred to by (@inst, @cdoffs) into

 * software-supervised idle mode, i.e., controlled manually by the

 * Linux OMAP clockdomain code.  No return value.

/**

 * am33xx_cm_clkdm_force_sleep - try to put a clockdomain into idle

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Put a clockdomain referred to by (@inst, @cdoffs) into idle

 * No return value.

/**

 * am33xx_cm_clkdm_force_wakeup - try to take a clockdomain out of idle

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Take a clockdomain referred to by (@inst, @cdoffs) out of idle,

 * waking it up.  No return value.

/*

 *

/**

 * am33xx_cm_wait_module_ready - wait for a module to be in 'func' state

 * @part: PRCM partition, ignored for AM33xx

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 * @bit_shift: bit shift for the register, ignored for AM33xx

 *

 * Wait for the module IDLEST to be functional. If the idle state is in any

 * the non functional state (trans, idle or disabled), module and thus the

 * sysconfig cannot be accessed and will probably lead to an "imprecise

 * external abort"

/**

 * am33xx_cm_wait_module_idle - wait for a module to be in 'disabled'

 * state

 * @part: CM partition, ignored for AM33xx

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 * @bit_shift: bit shift for the register, ignored for AM33xx

 *

 * Wait for the module IDLEST to be disabled. Some PRCM transition,

 * like reset assertion or parent clock de-activation must wait the

 * module to be fully disabled.

/**

 * am33xx_cm_module_enable - Enable the modulemode inside CLKCTRL

 * @mode: Module mode (SW or HW)

 * @part: CM partition, ignored for AM33xx

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * No return value.

/**

 * am33xx_cm_module_disable - Disable the module inside CLKCTRL

 * @part: CM partition, ignored for AM33xx

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * No return value.

/*

 * Clockdomain low-level functions

/**

 * am33xx_clkdm_save_context - Save the clockdomain transition context

 * @clkdm: The clockdomain pointer whose context needs to be saved

 *

 * Save the clockdomain transition context.

/**

 * am33xx_restore_save_context - Restore the clockdomain transition context

 * @clkdm: The clockdomain pointer whose context needs to be restored

 *

 * Restore the clockdomain transition context.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/usb-tusb6010.c

 *

 * Copyright (C) 2006 Nokia Corporation

 NOTE:  timings are from tusb 6010 datasheet Rev 1.8, 12-Sept 2006 */

 tusb driver calls this when it changes the chip's clocking */

	/* Order is significant!  The start/end fields

	 * are updated during setup..

 Asynchronous access */

 Synchronous access */

 IRQ */

 this may be called only from board-*.c setup code */

 ASYNC region, primarily for PIO */

 SYNC region, primarily for DMA */

 IRQ */

 set up memory timings ... can speed them up later */

 finish device setup ... */

 so far so good ... register the device */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3/OMAP4 smartreflex device file

 *

 * Author: Thara Gopinath	<thara@ti.com>

 *

 * Based originally on code from smartreflex.c

 * Copyright (C) 2010 Texas Instruments, Inc.

 * Thara Gopinath <thara@ti.com>

 *

 * Copyright (C) 2008 Nokia Corporation

 * Kalle Jokiniemi

 *

 * Copyright (C) 2007 Texas Instruments, Inc.

 * Lesly A M <x0080970@ti.com>

 Read EFUSE values from control registers for OMAP3430 */

		/*

		 * In OMAP4 the efuse registers are 24 bit aligned.

		 * A readl_relaxed will fail for non-32 bit aligned address

		 * and hence the 8-bit read and shift.

		/*

		 * Many OMAP SoCs don't have the eFuse values set.

		 * For example, pretty much all OMAP3xxx before

		 * ES3.something.

		 *

		 * XXX There needs to be some way for board files or

		 * userspace to add these in.

/*

 * API to be called from board files to enable smartreflex

 * autocompensation at init.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SMS/SDRC (SDRAM controller) common code for OMAP2/3

 *

 * Copyright (C) 2005, 2008 Texas Instruments Inc.

 * Copyright (C) 2005, 2008 Nokia Corporation

 *

 * Tony Lindgren <tony@atomide.com>

 * Paul Walmsley

 * Richard Woodruff <r-woodruff2@ti.com>

 SDRC_POWER register bits */

/**

 * omap2_sms_save_context - Save SMS registers

 *

 * Save SMS registers that need to be restored after off mode.

/**

 * omap2_sms_restore_context - Restore SMS registers

 *

 * Restore SMS registers that need to be Restored after off mode.

/**

 * omap2_sdrc_get_params - return SDRC register values for a given clock rate

 * @r: SDRC clock rate (in Hz)

 * @sdrc_cs0: chip select 0 ram timings **

 * @sdrc_cs1: chip select 1 ram timings **

 *

 * Return pre-calculated values for the SDRC_ACTIM_CTRLA,

 *  SDRC_ACTIM_CTRLB, SDRC_RFR_CTRL and SDRC_MR registers in sdrc_cs[01]

 *  structs,for a given SDRC clock rate 'r'.

 * These parameters control various timing delays in the SDRAM controller

 *  that are expressed in terms of the number of SDRC clock cycles to

 *  wait; hence the clock rate dependency.

 *

 * Supports 2 different timing parameters for both chip selects.

 *

 * Note 1: the sdrc_init_params_cs[01] must be sorted rate descending.

 * Note 2: If sdrc_init_params_cs_1 is not NULL it must be of same size

 *  as sdrc_init_params_cs_0.

 *

 * Fills in the struct omap_sdrc_params * for each chip select.

 * Returns 0 upon success or -1 upon failure.

/**

 * omap2_sdrc_init - initialize SMS, SDRC devices on boot

 * @sdrc_cs[01]: pointers to a null-terminated list of struct omap_sdrc_params

 *  Support for 2 chip selects timings

 *

 * Turn on smart idle modes for SDRAM scheduler and controller.

 * Program a known-good configuration for the SDRC to deal with buggy

 * bootloaders.

 XXX Enable SRFRONIDLEREQ here also? */

	/*

	 * PWDENA should not be set due to 34xx erratum 1.150 - PWDENA

	 * can cause random memory corruption

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 PRCM_MPU module functions

 *

 * Copyright (C) 2009 Nokia Corporation

 * Paul Walmsley

/*

 * prcm_mpu_base: the virtual address of the start of the PRCM_MPU IP

 *   block registers

 PRCM_MPU low-level functions */

/**

 * omap2_set_globals_prcm_mpu - set the MPU PRCM base address (for early use)

 * @prcm_mpu: PRCM_MPU base virtual address

 *

 * XXX Will be replaced when the PRM/CM drivers are completed.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * DPLL + CORE_CLK composite clock functions

 *

 * Copyright (C) 2005-2008 Texas Instruments, Inc.

 * Copyright (C) 2004-2010 Nokia Corporation

 *

 * Contacts:

 * Richard Woodruff <r-woodruff2@ti.com>

 * Paul Walmsley

 *

 * Based on earlier work by Tuukka Tikkanen, Tony Lindgren,

 * Gordon McNutt and RidgeRun, Inc.

 *

 * XXX The DPLL and CORE clocks should be split into two separate clock

 * types.

 #define DOWN_VARIABLE_DPLL 1 */		
/*

 * dpll_core_ck: pointer to the combined dpll_ck + core_ck on OMAP2xxx

 * (currently defined as "dpll_ck" in the OMAP2xxx clock tree).  Set

 * during dpll_ck init and used later by omap2xxx_clk_get_core_rate().

/**

 * omap2xxx_clk_get_core_rate - return the CORE_CLK rate

 *

 * Returns the CORE_CLK rate.  CORE_CLK can have one of three rate

 * sources on OMAP2xxx: the DPLL CLKOUT rate, DPLL CLKOUTX2, or 32KHz

 * (the latter is unusual).  This currently should be called with

 * struct clk *dpll_ck, which is a composite clock of dpll_ck and

 * core_ck.

/*

 * Uses the current prcm set to tell if a rate is valid.

 * You can go slower, but not faster within a given rate set.

 DPLL clockout */

 DPLL clockout x 2 */

 Worst case */

 If asking for 1-1 */

 For omap2xxx_sdrc_init_params() */

 Force dll lock mode */

 Errata: ret dll entry state */

/**

 * omap2xxx_clkt_dpllcore_init - clk init function for dpll_ck

 * @clk: struct clk *dpll_ck

 *

 * Store a local copy of @clk in dpll_core_ck so other code can query

 * the core rate without having to clk_get(), which can sleep.  Must

 * only be called once.  No return value.  XXX If the clock

 * registration process is ever changed such that dpll_ck is no longer

 * statically defined, this code may need to change to increment some

 * kind of use count on dpll_ck.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_device implementation

 *

 * Copyright (C) 2009-2010 Nokia Corporation

 * Paul Walmsley, Kevin Hilman

 *

 * Developed in collaboration with (alphabetical order): Benoit

 * Cousson, Thara Gopinath, Tony Lindgren, Rajendra Nayak, Vikram

 * Pandita, Sakari Poussa, Anand Sawant, Santosh Shilimkar, Richard

 * Woodruff

 *

 * This code provides a consistent interface for OMAP device drivers

 * to control power management and interconnect properties of their

 * devices.

 *

 * In the medium- to long-term, this code should be implemented as a

 * proper omap_bus/omap_device in Linux, no more platform_data func

 * pointers

 Private functions */

/**

 * _add_hwmod_clocks_clkdev - Add clkdev entry for hwmod optional clocks

 * and main clock

 * @od: struct omap_device *od

 * @oh: struct omap_hwmod *oh

 *

 * For the main clock and every optional clock present per hwmod per

 * omap_device, this function adds an entry in the clkdev table of the

 * form <dev-id=dev_name, con-id=role> if it does not exist already.

 *

 * The function is called from inside omap_device_build_ss(), after

 * omap_device_register.

 *

 * This allows drivers to get a pointer to its optional clocks based on its role

 * by calling clk_get(<dev*>, <role>).

 * In the case of the main clock, a "fck" alias is used.

 *

 * No return value.

/**

 * omap_device_build_from_dt - build an omap_device with multiple hwmods

 * @pdev: The platform device to update.

 *

 * Function for building an omap_device already registered from device-tree

 *

 * Returns 0 or PTR_ERR() on error.

 SDMA still needs special handling for omap_device_build() */

 Use ti-sysc driver instead of omap_device? */

 Fix up missing resource names */

 if data/we are at fault.. load up a fail handler */

/**

 * _omap_device_enable_hwmods - call omap_hwmod_enable() on all hwmods

 * @od: struct omap_device *od

 *

 * Enable all underlying hwmods.  Returns 0.

/**

 * _omap_device_idle_hwmods - call omap_hwmod_idle() on all hwmods

 * @od: struct omap_device *od

 *

 * Idle all underlying hwmods.  Returns 0.

 Public functions for use by core code */

/**

 * omap_device_get_context_loss_count - get lost context count

 * @pdev: The platform device to update.

 *

 * Using the primary hwmod, query the context loss count for this

 * device.

 *

 * Callers should consider context for this device lost any time this

 * function returns a value different than the value the caller got

 * the last time it called this function.

 *

 * If any hwmods exist for the omap_device associated with @pdev,

 * return the context loss counter for that hwmod, otherwise return

 * zero.

/**

 * omap_device_alloc - allocate an omap_device

 * @pdev: platform_device that will be included in this omap_device

 * @ohs: ptr to the omap_hwmod for this omap_device

 * @oh_cnt: the size of the ohs list

 *

 * Convenience function for allocating an omap_device structure and filling

 * hwmods, and resources.

 *

 * Returns an struct omap_device pointer or ERR_PTR() on error;

 Don't attempt late suspend on a driver that is not bound */

/**

 * omap_device_register - register an omap_device with one omap_hwmod

 * @pdev: the platform device (omap_device) to register.

 *

 * Register the omap_device structure.  This currently just calls

 * platform_device_register() on the underlying platform_device.

 * Returns the return value of platform_device_register().

 Public functions for use by device drivers through struct platform_data */

/**

 * omap_device_enable - fully activate an omap_device

 * @pdev: the platform device to activate

 *

 * Do whatever is necessary for the hwmods underlying omap_device @od

 * to be accessible and ready to operate.  This generally involves

 * enabling clocks, setting SYSCONFIG registers; and in the future may

 * involve remuxing pins.  Device drivers should call this function

 * indirectly via pm_runtime_get*().  Returns -EINVAL if called when

 * the omap_device is already enabled, or passes along the return

 * value of _omap_device_enable_hwmods().

/**

 * omap_device_idle - idle an omap_device

 * @pdev: The platform_device (omap_device) to idle

 *

 * Idle omap_device @od.  Device drivers call this function indirectly

 * via pm_runtime_put*().  Returns -EINVAL if the omap_device is not

 * currently enabled, or passes along the return value of

 * _omap_device_idle_hwmods().

/**

 * omap_device_assert_hardreset - set a device's hardreset line

 * @pdev: struct platform_device * to reset

 * @name: const char * name of the reset line

 *

 * Set the hardreset line identified by @name on the IP blocks

 * associated with the hwmods backing the platform_device @pdev.  All

 * of the hwmods associated with @pdev must have the same hardreset

 * line linked to them for this to work.  Passes along the return value

 * of omap_hwmod_assert_hardreset() in the event of any failure, or

 * returns 0 upon success.

/**

 * omap_device_deassert_hardreset - release a device's hardreset line

 * @pdev: struct platform_device * to reset

 * @name: const char * name of the reset line

 *

 * Release the hardreset line identified by @name on the IP blocks

 * associated with the hwmods backing the platform_device @pdev.  All

 * of the hwmods associated with @pdev must have the same hardreset

 * line linked to them for this to work.  Passes along the return

 * value of omap_hwmod_deassert_hardreset() in the event of any

 * failure, or returns 0 upon success.

/**

 * omap_device_get_by_hwmod_name() - convert a hwmod name to

 * device pointer.

 * @oh_name: name of the hwmod device

 *

 * Returns back a struct device * pointer associated with a hwmod

 * device represented by a hwmod_name

/**

 * omap_device_late_idle - idle devices without drivers

 * @dev: struct device * associated with omap_device

 * @data: unused

 *

 * Check the driver bound status of this device, and idle it

 * if there is no driver attached.

	/*

	 * If omap_device state is enabled, but has no driver bound,

	 * idle it.

	/*

	 * Some devices (like memory controllers) are always kept

	 * enabled, and should not be idled even with no drivers.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AM43xx Clock domains framework

 *

 * Copyright (C) 2013 Texas Instruments, Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP54XX Clock domains framework

 *

 * Copyright (C) 2013 Texas Instruments, Inc.

 *

 * Abhijit Pagare (abhijitpagare@ti.com)

 * Benoit Cousson (b-cousson@ti.com)

 * Paul Walmsley (paul@pwsan.com)

 *

 * This file is automatically generated from the OMAP hardware databases.

 * We respectfully ask that any modifications to this file be coordinated

 * with the public linux-omap@vger.kernel.org mailing list and the

 * authors above to ensure that the autogeneration scripts are kept

 * up-to-date with the file contents.

 Static Dependencies for OMAP4 Clock Domains */

 As clockdomains are added or removed above, this list must also be changed */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 CM instance functions

 *

 * Copyright (C) 2009 Nokia Corporation

 * Copyright (C) 2008-2011 Texas Instruments, Inc.

 * Paul Walmsley

 * Rajendra Nayak <rnayak@ti.com>

 *

 * This is needed since CM instances can be in the PRM, PRCM_MPU, CM1,

 * or CM2 hardware modules.  For example, the EMU_CM CM instance is in

 * the PRM hardware module.  What a mess...

/*

 * CLKCTRL_IDLEST_*: possible values for the CM_*_CLKCTRL.IDLEST bitfield:

 *

 *   0x0 func:     Module is fully functional, including OCP

 *   0x1 trans:    Module is performing transition: wakeup, or sleep, or sleep

 *                 abortion

 *   0x2 idle:     Module is in Idle mode (only OCP part). It is functional if

 *                 using separate functional clock

 *   0x3 disabled: Module is disabled and cannot be accessed

 *

/**

 * omap_cm_base_init - Populates the cm partitions

 *

 * Populates the base addresses of the _cm_bases

 * array used for read/write of cm module registers.

 Private functions */

/**

 * _clkctrl_idlest - read a CM_*_CLKCTRL register; mask & shift IDLEST bitfield

 * @part: PRCM partition ID that the CM_CLKCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * Return the IDLEST bitfield of a CM_*_CLKCTRL register, shifted down to

 * bit 0.

/**

 * _is_module_ready - can module registers be accessed without causing an abort?

 * @part: PRCM partition ID that the CM_CLKCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * Returns true if the module's CM_*_CLKCTRL.IDLEST bitfield is either

 * *FUNCTIONAL or *INTERFACE_IDLE; false otherwise.

 Read a register in a CM instance */

 Write into a register in a CM instance */

 Read-modify-write a register in CM1. Caller must lock */

/*

 *

/**

 * _clktrctrl_write - write @c to a CM_CLKSTCTRL.CLKTRCTRL register bitfield

 * @c: CLKTRCTRL register bitfield (LSB = bit 0, i.e., unshifted)

 * @part: PRCM partition ID that the CM_CLKSTCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * @c must be the unshifted value for CLKTRCTRL - i.e., this function

 * will handle the shift itself.

/**

 * omap4_cminst_is_clkdm_in_hwsup - is a clockdomain in hwsup idle mode?

 * @part: PRCM partition ID that the CM_CLKSTCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Returns true if the clockdomain referred to by (@part, @inst, @cdoffs)

 * is in hardware-supervised idle mode, or 0 otherwise.

/**

 * omap4_cminst_clkdm_enable_hwsup - put a clockdomain in hwsup-idle mode

 * @part: PRCM partition ID that the clockdomain registers exist in

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Put a clockdomain referred to by (@part, @inst, @cdoffs) into

 * hardware-supervised idle mode.  No return value.

/**

 * omap4_cminst_clkdm_disable_hwsup - put a clockdomain in swsup-idle mode

 * @part: PRCM partition ID that the clockdomain registers exist in

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Put a clockdomain referred to by (@part, @inst, @cdoffs) into

 * software-supervised idle mode, i.e., controlled manually by the

 * Linux OMAP clockdomain code.  No return value.

/**

 * omap4_cminst_clkdm_force_sleep - try to take a clockdomain out of idle

 * @part: PRCM partition ID that the clockdomain registers exist in

 * @inst: CM instance register offset (*_INST macro)

 * @cdoffs: Clockdomain register offset (*_CDOFFS macro)

 *

 * Take a clockdomain referred to by (@part, @inst, @cdoffs) out of idle,

 * waking it up.  No return value.

/*

 *

/**

 * omap4_cminst_wait_module_ready - wait for a module to be in 'func' state

 * @part: PRCM partition ID that the CM_CLKCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 * @bit_shift: bit shift for the register, ignored for OMAP4+

 *

 * Wait for the module IDLEST to be functional. If the idle state is in any

 * the non functional state (trans, idle or disabled), module and thus the

 * sysconfig cannot be accessed and will probably lead to an "imprecise

 * external abort"

/**

 * omap4_cminst_wait_module_idle - wait for a module to be in 'disabled'

 * state

 * @part: PRCM partition ID that the CM_CLKCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 * @bit_shift: Bit shift for the register, ignored for OMAP4+

 *

 * Wait for the module IDLEST to be disabled. Some PRCM transition,

 * like reset assertion or parent clock de-activation must wait the

 * module to be fully disabled.

/**

 * omap4_cminst_module_enable - Enable the modulemode inside CLKCTRL

 * @mode: Module mode (SW or HW)

 * @part: PRCM partition ID that the CM_CLKCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * No return value.

/**

 * omap4_cminst_module_disable - Disable the module inside CLKCTRL

 * @part: PRCM partition ID that the CM_CLKCTRL register exists in

 * @inst: CM instance register offset (*_INST macro)

 * @clkctrl_offs: Module clock control register offset (*_CLKCTRL macro)

 *

 * No return value.

/*

 * Clockdomain low-level functions

 only happens if data is erroneous */

	/*

	 * The CLKDM_MISSING_IDLE_REPORTING flag documentation has

	 * more details on the unpleasant problem this is working

	 * around

/**

 * omap4_clkdm_save_context - Save the clockdomain modulemode context

 * @clkdm: The clockdomain pointer whose context needs to be saved

 *

 * Save the clockdomain modulemode context.

/**

 * omap4_clkdm_restore_context - Restore the clockdomain modulemode context

 * @clkdm: The clockdomain pointer whose context needs to be restored

 *

 * Restore the clockdomain modulemode context.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/common.c

 *

 * Code common to all OMAP2+ machines.

 *

 * Copyright (C) 2009 Texas Instruments

 * Copyright (C) 2010 Nokia Corporation

 * Tony Lindgren <tony@atomide.com>

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

/*

 * Stub function for OMAP2 so that common files

 * continue to build when custom builds are used

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Legacy platform_data quirks

 *

 * Copyright (C) 2013 Texas Instruments

/*

 * Configures GPIOs 126, 127 and 129 to 1.8V mode instead of 3.0V

 * mode for MMC1 in case bootloader did not configure things.

 * Note that if the pins are used for MMC1, pbias-regulator

 * manages the IO voltage.

 OCP barrier */

 OCP barrier */

 OCP barrier */

 set IBE to 1 */

 omap3pandora legacy devices */

 CONFIG_ARCH_OMAP3 */

/**

 * ti_sysc_clkdm_init - find clockdomain based on clock

 * @fck: device functional clock

 * @ick: device interface clock

 * @dev: struct device

 *

 * Populate clockdomain based on clock. It is needed for

 * clkdm_deny_idle() and clkdm_allow_idle() for blocking clockdomain

 * clockdomain idle during reset, enable and idle.

 *

 * Note that we assume interconnect driver manages the clocks

 * and do not need to populate oh->_clk for dynamically

 * allocated modules.

 CONFIG_OMAP_HWMOD */

/*

 * GPIOs for TWL are initialized by the I2C bus and need custom

 * handing until DSS has device tree bindings.

/*

 * Few boards still need auxdata populated before we populate

 * the dev entries in of_platform_populate().

 sentinel */ },

 Only on am3517 */

 McBSP modules with sidetone core */

 Common auxdata */

 sentinel */ },

/*

 * Few boards still need to initialize some legacy devices with

 * platform data until the drivers support device tree.

 sentinel */ },

	/*

	 * We still need this for omap2420 and omap3 PM to work, others are

	 * using drivers/misc/sram.c already.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/board-n8x0.c

 *

 * Copyright (C) 2005-2009 Nokia Corporation

 * Author: Juha Yrjola <juha.yrjola@nokia.com>

 *

 * Modified from mach-omap2/board-generic.c

/*

 * Enable or disable power to TUSB6010. When enabling, turn on 3.3 V and

 * 1.5 V voltage regulators of PM companion chip. Companion chip will then

 * provide then PGOOD signal to TUSB6010 which will release it from reset.

 Wait until TUSB6010 pulls INT pin down */

 x2 = 50 mA drawn from VBUS as peripheral */

 Max 100 mA VBUS for host mode */

 PM companion chip power control pin */

CONFIG_USB_MUSB_TUSB6010 */

/*

 * On both N800 and N810, only the first of the two MMC controllers is in use.

 * The two MMC slots are multiplexed via Menelaus companion chip over I2C.

 * On N800, both slots are powered via Menelaus. On N810, only one of the

 * slots is powered via Menelaus. The N810 EMMC is powered via GPIO.

 *

 * VMMC				slot 1 on both N800 and N810

 * VDCDC3_APE and VMCS2_APE	slot 2 on N800

 * GPIO23 and GPIO9		slot 2 EMMC on N810

 *

 MMC_VDD_28_29 */

 All slot pin bits seem to be inversed until first switch change */

/*

 * MMC controller1 has two slots that are multiplexed via I2C.

 * MMC controller2 is not in use.

		/*

		 * Some Samsung Movinand chips do not like open-ended

		 * multi-block reads and fall to braind-dead state

		 * while doing so. Reducing the number of blocks in

		 * the transfer or delays in clock disable do not help

 CONFIG_MMC_OMAP */

/*

 * Legacy init pdata init for n8x0. Note that we want to follow the

 * I2C bus numbering starting at 0 for device tree like other omaps.

/*

 * OMAP4 OPP table definitions.

 *

 * Copyright (C) 2010-2012 Texas Instruments Incorporated - https://www.ti.com/

 *	Nishanth Menon

 *	Kevin Hilman

 *	Thara Gopinath

 * Copyright (C) 2010-2011 Nokia Corporation.

 *      Eduardo Valentin

 *      Paul Walmsley

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * Structures containing OMAP4430 voltage supported and various

 * voltage dependent data for each VDD.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP4 SMP source file. It contains platform specific functions

 * needed for the linux smp kernel.

 *

 * Copyright (C) 2009 Texas Instruments, Inc.

 *

 * Author:

 *      Santosh Shilimkar <santosh.shilimkar@ti.com>

 *

 * Platform file needed for the OMAP4 SMP. This file is based on arm

 * realview smp platform.

 * * Copyright (c) 2002 ARM Limited.

 REVIDR[3] indicates erratum fix available on silicon */

	/*

	 * BIT(27) - Disables streaming. All write-allocate lines allocate in

	 * the L1 or L2 cache.

	 * BIT(25) - Disables streaming. All write-allocate lines allocate in

	 * the L1 cache.

 do we already have it done.. if yes, skip expensive smc */

/*

 * Configure ACR and enable ACTLR[0] (Enable invalidates of BTB with

 * ICIALLU) to activate the workaround for secondary Core.

 * NOTE: it is assumed that the primary core's configuration is done

 * by the boot loader (kernel will detect a misconfiguration and complain

 * if this is not done).

 *

 * In General Purpose(GP) devices, ACR bit settings can only be done

 * by ROM code in "secure world" using the smc call and there is no

 * option to update the "firmware" on such devices. This also works for

 * High security(HS) devices, as a backup option in case the

 * "update" is not done in the "security firmware".

	/*

	 * ACTLR[0] (Enable invalidates of BTB with ICIALLU)

 Do we already have it done.. if yes, skip expensive smc */

	/*

	 * Configure ACTRL and enable NS SMP bit access on CPU1 on HS device.

	 * OMAP44XX EMU/HS devices - CPU0 SMP bit access is enabled in PPA

	 * init and for CPU1, a secure PPA API provided. CPU0 must be ON

	 * while executing NS_SMP API on CPU1 and PPA version must be 1.4.0+.

	 * OMAP443X GP devices- SMP bit isn't accessible.

	 * OMAP446X GP devices - SMP bit access is enabled on both CPUs.

		/*

		 * Configure the CNTFRQ register for the secondary cpu's which

		 * indicates the frequency of the cpu local timers.

 Configure ACR to disable streaming WA for 801819 */

 Enable ACR to allow for ICUALLU workaround */

	/*

	 * Update the AuxCoreBoot0 with boot state for secondary core.

	 * omap4_secondary_startup() routine will hold the secondary core till

	 * the AuxCoreBoot1 register is updated with cpu state

	 * A barrier is added to ensure that write buffer is drained

	/*

	 * The SGI(Software Generated Interrupts) are not wakeup capable

	 * from low power states. This is known limitation on OMAP4 and

	 * needs to be worked around by using software forced clockdomain

	 * wake-up. To wakeup CPU1, CPU0 forces the CPU1 clockdomain to

	 * software force wakeup. The clockdomain is then put back to

	 * hardware supervised mode.

	 * More details can be found in OMAP4430 TRM - Version J

	 * Section :

	 *	4.3.4.2 Power States of CPU0 and CPU1

		/*

		 * GIC distributor control register has changed between

		 * CortexA9 r1pX and r2pX. The Control Register secure

		 * banked version is now composed of 2 bits:

		 * bit 0 == Secure Enable

		 * bit 1 == Non-Secure Enable

		 * The Non-Secure banked register has not changed

		 * Because the ROM Code is based on the r1pX GIC, the CPU1

		 * GIC restoration will cause a problem to CPU0 Non-Secure SW.

		 * The workaround must be:

		 * 1) Before doing the CPU1 wakeup, CPU0 must disable

		 * the GIC distributor

		 * 2) CPU1 must re-enable the GIC distributor on

		 * it's wakeup path.

		/*

		 * Ensure that CPU power state is set to ON to avoid CPU

		 * powerdomain transition on wfi

/*

 * Initialise the CPU possible map early - this describes the CPUs

 * which may be present or become present in the system.

 Use ARM cpuid check here, as SoC detection will not work so early */

		/*

		 * Currently we can't call ioremap here because

		 * SoC detection won't work until after init_early.

 sanity check */

/*

 * For now, just make sure the start-up address is not within the booting

 * kernel space as that means we just overwrote whatever secondary_startup()

 * code there was.

/*

 * We may need to reset CPU1 before configuring, otherwise kexec boot can end

 * up trying to use old kernel startup address or suspend-resume will

 * occasionally fail to bring up CPU1 on 4430 if CPU1 fails to enter deeper

 * idle states.

 Did the configured secondary_startup() get overwritten? */

	/*

	 * If omap4 or 5 has NS_PA_ADDR configured, CPU1 may be in a

	 * deeper idle state in WFI and will wake to an invalid address.

 Must preserve cfg.scu_base set earlier */

	/*

	 * Initialise the SCU and wake up the secondary core using

	 * wakeup_secondary().

	/*

	 * Write the address of secondary startup routine into the

	 * AuxCoreBoot1 where ROM code will jump and start executing

	 * on secondary core once out of WFE

	 * A barrier is added to ensure that write buffer is drained

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP WakeupGen Source file

 *

 * OMAP WakeupGen is the interrupt controller extension used along

 * with ARM GIC to wake the CPU out from low power states on

 * external interrupts. It is responsible for generating wakeup

 * event from the incoming interrupts and enable bits. It is

 * implemented in MPU always ON power domain. During normal operation,

 * WakeupGen delivers external interrupts directly to the GIC.

 *

 * Copyright (C) 2011 Texas Instruments, Inc.

 *	Santosh Shilimkar <santosh.shilimkar@ti.com>

/*

 * Static helper functions.

	/*

	 * Each WakeupGen register controls 32 interrupt.

	 * i.e. 1 bit per SPI IRQ

/*

 * Architecture specific Mask extension

/*

 * Architecture specific Unmask extension

/*

 * The sys_nirq pins bypass peripheral modules and are wired directly

 * to MPUSS wakeupgen. They get automatically inverted for GIC.

/*

 * Mask or unmask all interrupts on given CPU.

 *	0 = Mask all interrupts on the 'cpu'

 *	1 = Unmask all interrupts on the 'cpu'

 * Ensure that the initial mask is maintained. This is faster than

 * iterating through GIC registers to arrive at the correct masks.

 Save the CPUx interrupt mask for IRQ 0 to 127 */

		/*

		 * Disable the secure interrupts for CPUx. The restore

		 * code blindly restores secure and non-secure interrupt

		 * masks from SAR RAM. Secure interrupts are not suppose

		 * to be enabled from HLOS. So overwrite the SAR location

		 * so that the secure interrupt remains disabled.

 Save AuxBoot* registers */

 Save SyncReq generation logic */

 Set the Backup Bit Mask status */

 Save the CPUx interrupt mask for IRQ 0 to 159 */

 Save AuxBoot* registers */

 Set the Backup Bit Mask status */

/*

 * Save WakeupGen interrupt context in SAR BANK3. Restore is done by

 * ROM code. WakeupGen IP is integrated along with GIC to manage the

 * interrupt wakeups from CPU low power states. It manages

 * masking/unmasking of Shared peripheral interrupts(SPI). So the

 * interrupt enable/disable control should be in sync and consistent

 * at WakeupGen and GIC so that interrupts are not lost.

 DRA7 has no SAR to save */

/*

 * Clear WakeupGen SAR backup status.

 DRA7 has no SAR to save */

/*

 * Save GIC and Wakeupgen interrupt context using secure API

 * for HS/EMU devices.

 Define ops for context save and restore for each SoC */

 FIXME: Remove this when MPU OSWR support is added */

 No PPI should point to this domain */

 Not GIC compliant */

 No PPI should point to this domain */

 Can't deal with this */

/*

 * Initialise the wakeupgen module.

 Not supported on OMAP4 ES1.0 silicon */

 Static mapping, never released */

 Clear all IRQ bitmasks at wakeupGen level */

	/*

	 * FIXME: Add support to set_smp_affinity() once the core

	 * GIC code has necessary hooks in place.

 Associate all the IRQs to boot CPU like GIC init does. */

	/*

	 * Enables OMAP5 ES2 PM Mode using ES2_PM_MODE in AMBA_IF_MODE

	 * 0x0:	ES1 behavior, CPU cores would enter and exit OFF mode together.

	 * 0x1:	ES2 behavior, CPU cores are allowed to enter/exit OFF mode

	 * independently.

	 * This needs to be set one time thanks to always ON domain.

	 *

	 * We do not support ES1 behavior anymore. OMAP5 is assumed to be

	 * ES2.0, and the same is applicable for DRA7.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod_2420_data.c - hardware modules present on the OMAP2420 chips

 *

 * Copyright (C) 2009-2011 Nokia Corporation

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 *

 * XXX handle crossbar/shared link difference for L3?

 * XXX these should be marked initdata for multi-OMAP kernels

/*

 * OMAP2420 hardware module integration data

 *

 * All of the data in this section should be autogeneratable from the

 * TI hardware database or other technical documentation.  Data that

 * is driver-specific or driver-kernel integration-specific belongs

 * elsewhere.

/*

 * IP blocks

 IVA1 (IVA1) */

 DSP */

 I2C common */

 I2C1 */

	/*

	 * From mach-omap2/pm24xx.c: "Putting MPU into the WFI state

	 * while a transfer is active seems to cause the I2C block to

	 * timeout. Why? Good question."

 I2C2 */

 mailbox */

/*

 * 'mcbsp' class

 * multi channel buffered serial port controller

 mcbsp1 */

 mcbsp2 */

 msdi1 */

 HDQ1W/1-wire */

/*

 * interfaces

 L4 CORE -> I2C1 interface */

 L4 CORE -> I2C2 interface */

 IVA <- L3 interface */

 DSP <- L3 interface */

 l4_wkup -> wd_timer2 */

 l4_wkup -> gpio1 */

 l4_wkup -> gpio2 */

 l4_wkup -> gpio3 */

 l4_wkup -> gpio4 */

 l4_core -> mailbox */

 l4_core -> mcbsp1 */

 l4_core -> mcbsp2 */

 l4_core -> msdi1 */

 l4_core -> hdq1w interface */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * IP block integration code for the HDQ1W/1-wire IP block

 *

 * Copyright (C) 2012 Texas Instruments, Inc.

 * Paul Walmsley

 *

 * Based on the I2C reset code in arch/arm/mach-omap2/i2c.c by

 *     Avinash.H.M <avinashhm@ti.com>

/**

 * omap_hdq1w_reset - reset the OMAP HDQ1W module

 * @oh: struct omap_hwmod *

 *

 * OCP soft reset the HDQ1W IP block.  Section 20.6.1.4 "HDQ1W/1-Wire

 * Software Reset" of the OMAP34xx Technical Reference Manual Revision

 * ZR (SWPU223R) does not include the rather important fact that, for

 * the reset to succeed, the HDQ1W module's internal clock gate must be

 * programmed to allow the clock to propagate to the rest of the

 * module.  In this sense, it's rather similar to the I2C custom reset

 * function.  Returns 0.

 Write to the SOFTRESET bit */

 Enable the module's internal clocks */

 Poll on RESETDONE bit */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/sdrc2xxx.c

 *

 * SDRAM timing related functions for OMAP2xxx

 *

 * Copyright (C) 2005, 2008 Texas Instruments Inc.

 * Copyright (C) 2005, 2008 Nokia Corporation

 *

 * Tony Lindgren <tony@atomide.com>

 * Paul Walmsley

 * Richard Woodruff <r-woodruff2@ti.com>

 Memory timing, DLL mode flags */

/*

 * Check the DLL lock state, and return tue if running in unlock mode.

 * This is needed to compensate for the shifted DLL value in unlock mode.

 dlla and dllb are a set */

/*

 * 'level' is the value to store to CM_CLKSEL2_PLL.CORE_CLK_SRC.

 * Practical values are CORE_CLK_SRC_DPLL (for CORE_CLK = DPLL_CLK) or

 * CORE_CLK_SRC_DPLL_X2 (for CORE_CLK = * DPLL_CLK * 2)

 *

 * Used by the clock framework during CORE DPLL changes

	/*

	 * XXX These calls should be abstracted out through a

	 * prm2xxx.c function

 Used by the clock framework during CORE DPLL changes */

 DDR = 1, SDR = 0 */

	/* 2422 es2.05 and beyond has a single SIP DDR instead of 2 like others.

	 * In the case of 2422, its ok to use CS1 instead of CS0.

 With DDR we need to determine the low frequency DLL value */

 Current lock mode */

 set fast timings with DLL filter disabled */

 No disruptions, DDR will be offline & C-ABI not followed */

 Keep lock value */

 Turn status into unlock ctrl */

 90 degree phase for anything below 133MHz + disable DLL filter */

 SPDX-License-Identifier: GPL-2.0

/*

 * OMAP2/3 clockdomain common data

 *

 * Copyright (C) 2008-2011 Texas Instruments, Inc.

 * Copyright (C) 2008-2010 Nokia Corporation

 *

 * Paul Walmsley, Jouni Hgander

 *

 * This file contains clockdomains and clockdomain wakeup/sleep

 * dependencies for the OMAP2/3 chips.  Some notes:

 *

 * A useful validation rule for struct clockdomain: Any clockdomain

 * referenced by a wkdep_srcs or sleepdep_srcs array must have a

 * dep_bit assigned.  So wkdep_srcs/sleepdep_srcs are really just

 * software-controllable dependencies.  Non-software-controllable

 * dependencies do exist, but they are not encoded below (yet).

 *

 * 24xx does not support programmable sleep dependencies (SLEEPDEP)

 *

 * The overly-specific dep_bit names are due to a bit name collision

 * with CM_FCLKEN_{DSP,IVA2}.  The DSP/IVA2 PM_WKDEP and CM_SLEEPDEP shift

 * value are the same for all powerdomains: 2

 *

 * XXX should dep_bit be a mask, so we can test to see if it is 0 as a

 * sanity check?

 * XXX encode hardware fixed wakeup dependencies -- esp. for 3430 CORE

/*

 * To-Do List

 * -> Port the Sleep/Wakeup dependencies for the domains

 *    from the Power domain framework

/*

 * Clockdomain dependencies for wkdeps/sleepdeps

 *

 * XXX Hardware dependencies (e.g., dependencies that cannot be

 * changed in software) are not included here yet, but should be.

 Wakeup dependency source arrays */

 2xxx-specific possible dependencies */

 2xxx PM_WKDEP_GFX: CORE, MPU, WKUP */

 2xxx PM_WKDEP_DSP: CORE, MPU, WKUP */

/*

 * OMAP2/3-common clockdomains

 *

 * Even though the 2420 has a single PRCM module from the

 * interconnect's perspective, internally it does appear to have

 * separate PRM and CM clockdomains.  The usual test case is

 * sys_clkout/sys_clkout2.

 This is an implicit clockdomain - it is never defined as such in TRM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2+ common Power & Reset Management (PRM) IP block functions

 *

 * Copyright (C) 2011 Texas Instruments, Inc.

 * Tero Kristo <t-kristo@ti.com>

 *

 * For historical purposes, the API used to configure the PRM

 * interrupt handler refers to it as the "PRCM interrupt."  The

 * underlying registers are located in the PRM on OMAP3/4.

 *

 * XXX This code should eventually be moved to a PRM driver.

/*

 * OMAP_PRCM_MAX_NR_PENDING_REG: maximum number of PRM_IRQ*_MPU regs

 * XXX this is technically not needed, since

 * omap_prcm_register_chain_handler() could allocate this based on the

 * actual amount of memory needed for the SoC

/*

 * prcm_irq_chips: an array of all of the "generic IRQ chips" in use

 * by the PRCM interrupt handler code.  There will be one 'chip' per

 * PRM_{IRQSTATUS,IRQENABLE}_MPU register pair.  (So OMAP3 will have

 * one "chip" and OMAP4 will have two.)

/*

 * prcm_irq_setup: the PRCM IRQ parameters for the hardware the code

 * is currently running on.  Defined and passed by initialization code

 * that calls omap_prcm_register_chain_handler().

 prm_base: base virtual address of the PRM IP block */

/*

 * prm_ll_data: function pointers to SoC-specific implementations of

 * common PRM functions

 Private functions */

/*

 * Move priority events from events to priority_events array

/*

 * PRCM Interrupt Handler

 *

 * This is a common handler for the OMAP PRCM interrupts. Pending

 * interrupts are detected by a call to prcm_pending_events and

 * dispatched accordingly. Clearing of the wakeup events should be

 * done by the SoC specific individual handlers.

	/*

	 * If we are suspended, mask all interrupts from PRCM level,

	 * this does not ack them, and they will be pending until we

	 * re-enable the interrupts, at which point the

	 * omap_prcm_irq_handler will be executed again.  The

	 * _save_and_clear_irqen() function must ensure that the PRM

	 * write to disable all IRQs has reached the PRM before

	 * returning, or spurious PRCM interrupts may occur during

	 * suspend.

	/*

	 * Loop until all pending irqs are handled, since

	 * generic_handle_irq() can cause new irqs to come

 No bit set, then all IRQs are handled */

		/*

		 * Loop on all currently pending irqs so that new irqs

		 * cannot starve previously pending irqs

 Serve priority events first */

 Serve normal events next */

 avoid spurious IRQs */

 Public functions */

/**

 * omap_prcm_event_to_irq - given a PRCM event name, returns the

 * corresponding IRQ on which the handler should be registered

 * @name: name of the PRCM interrupt bit to look up - see struct omap_prcm_irq

 *

 * Returns the Linux internal IRQ ID corresponding to @name upon success,

 * or -ENOENT upon failure.

/**

 * omap_prcm_irq_cleanup - reverses memory allocated and other steps

 * done by omap_prcm_register_chain_handler()

 *

 * No return value.

 If we have not saved the masks, do not attempt to restore */

	/*

	 * Re-enable all masked PRCM irq sources, this causes the PRCM

	 * interrupt to fire immediately if the events were masked

	 * previously in the chain handler

/**

 * omap_prcm_register_chain_handler - initializes the prcm chained interrupt

 * handler based on provided parameters

 * @irq_setup: hardware data about the underlying PRM/PRCM

 *

 * Set up the PRCM chained interrupt handler on the PRCM IRQ.  Sets up

 * one generic IRQ chip per PRM interrupt status/enable register pair.

 * Returns 0 upon success, -EINVAL if called twice or if invalid

 * arguments are passed, or -ENOMEM on any other error.

/**

 * omap2_set_globals_prm - set the PRM base address (for early use)

 * @prm: PRM base virtual address

 *

 * XXX Will be replaced when the PRM/CM drivers are completed.

/**

 * prm_read_reset_sources - return the sources of the SoC's last reset

 *

 * Return a u32 bitmask representing the reset sources that caused the

 * SoC to reset.  The low-level per-SoC functions called by this

 * function remap the SoC-specific reset source bits into an

 * OMAP-common set of reset source bits, defined in

 * arch/arm/mach-omap2/prm.h.  Returns the standardized reset source

 * u32 bitmask from the hardware upon success, or returns (1 <<

 * OMAP_UNKNOWN_RST_SRC_ID_SHIFT) if no low-level read_reset_sources()

 * function was registered.

/**

 * prm_was_any_context_lost_old - was device context lost? (old API)

 * @part: PRM partition ID (e.g., OMAP4430_PRM_PARTITION)

 * @inst: PRM instance offset (e.g., OMAP4430_PRM_MPU_INST)

 * @idx: CONTEXT register offset

 *

 * Return 1 if any bits were set in the *_CONTEXT_* register

 * identified by (@part, @inst, @idx), which means that some context

 * was lost for that module; otherwise, return 0.  XXX Deprecated;

 * callers need to use a less-SoC-dependent way to identify hardware

 * IP blocks.

/**

 * prm_clear_context_lost_flags_old - clear context loss flags (old API)

 * @part: PRM partition ID (e.g., OMAP4430_PRM_PARTITION)

 * @inst: PRM instance offset (e.g., OMAP4430_PRM_MPU_INST)

 * @idx: CONTEXT register offset

 *

 * Clear hardware context loss bits for the module identified by

 * (@part, @inst, @idx).  No return value.  XXX Deprecated; callers

 * need to use a less-SoC-dependent way to identify hardware IP

 * blocks.

/**

 * omap_prm_assert_hardreset - assert hardreset for an IP block

 * @shift: register bit shift corresponding to the reset line

 * @part: PRM partition

 * @prm_mod: PRM submodule base or instance offset

 * @offset: register offset

 *

 * Asserts a hardware reset line for an IP block.

/**

 * omap_prm_deassert_hardreset - deassert hardreset for an IP block

 * @shift: register bit shift corresponding to the reset line

 * @st_shift: reset status bit shift corresponding to the reset line

 * @part: PRM partition

 * @prm_mod: PRM submodule base or instance offset

 * @offset: register offset

 * @st_offset: status register offset

 *

 * Deasserts a hardware reset line for an IP block.

/**

 * omap_prm_is_hardreset_asserted - check the hardreset status for an IP block

 * @shift: register bit shift corresponding to the reset line

 * @part: PRM partition

 * @prm_mod: PRM submodule base or instance offset

 * @offset: register offset

 *

 * Checks if a hardware reset line for an IP block is enabled or not.

/**

 * omap_prm_reconfigure_io_chain - clear latches and reconfigure I/O chain

 *

 * Clear any previously-latched I/O wakeup events and ensure that the

 * I/O wakeup gates are aligned with the current mux settings.

 * Calls SoC specific I/O chain reconfigure function if available,

 * otherwise does nothing.

/**

 * omap_prm_reset_system - trigger global SW reset

 *

 * Triggers SoC specific global warm reset to reboot the device.

/**

 * omap_prm_clear_mod_irqs - clear wake-up events from PRCM interrupt

 * @module: PRM module to clear wakeups from

 * @regs: register to clear

 * @wkst_mask: wkst bits to clear

 *

 * Clears any wakeup events for the module and register set defined.

 * Uses SoC specific implementation to do the actual wakeup status

 * clearing.

/**

 * omap_prm_vp_check_txdone - check voltage processor TX done status

 *

 * Checks if voltage processor transmission has been completed.

 * Returns non-zero if a transmission has completed, 0 otherwise.

/**

 * omap_prm_vp_clear_txdone - clears voltage processor TX done status

 *

 * Clears the status bit for completed voltage processor transmission

 * returned by prm_vp_check_txdone.

/**

 * prm_register - register per-SoC low-level data with the PRM

 * @pld: low-level per-SoC OMAP PRM data & function pointers to register

 *

 * Register per-SoC low-level OMAP PRM data and function pointers with

 * the OMAP PRM common interface.  The caller must keep the data

 * pointed to by @pld valid until it calls prm_unregister() and

 * it returns successfully.  Returns 0 upon success, -EINVAL if @pld

 * is NULL, or -EEXIST if prm_register() has already been called

 * without an intervening prm_unregister().

/**

 * prm_unregister - unregister per-SoC low-level data & function pointers

 * @pld: low-level per-SoC OMAP PRM data & function pointers to unregister

 *

 * Unregister per-SoC low-level OMAP PRM data and function pointers

 * that were previously registered with prm_register().  The

 * caller may not destroy any of the data pointed to by @pld until

 * this function returns successfully.  Returns 0 upon success, or

 * -EINVAL if @pld is NULL or if @pld does not match the struct

 * prm_ll_data * previously registered by prm_register().

	/*

	 * IVA2 offset is a negative value, must offset the prm_base

	 * address by this to get it to positive

/**

 * omap2_prm_base_init - initialize iomappings for the PRM driver

 *

 * Detects and initializes the iomappings for the PRM driver, based

 * on the DT data. Returns 0 in success, negative error value

 * otherwise.

/**

 * omap_prcm_init - low level init for the PRCM drivers

 *

 * Initializes the low level clock infrastructure for PRCM drivers.

 * Returns 0 in success, negative error value in failure.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2/3 System Control Module register access

 *

 * Copyright (C) 2007, 2012 Texas Instruments, Inc.

 * Copyright (C) 2007 Nokia Corporation

 *

 * Written by Paul Walmsley

 Used by omap3_ctrl_save_padconf() */

/*

 * This is used to store ARM registers in SDRAM before attempting

 * an MPU OFF. The save and restore happens from the SRAM sleep code.

 * The address is stored in scratchpad, so that it can be used

 * during the restore path.

 CONFIG_ARCH_OMAP3 && CONFIG_PM */

/**

 * omap3_ctrl_write_boot_mode - set scratchpad boot mode for the next boot

 * @bootmode: 8-bit value to pass to some boot code

 *

 * Set the bootmode in the scratchpad RAM.  This is used after the

 * system restarts.  Not sure what actually uses this - it may be the

 * bootloader, rather than the boot ROM - contrary to the preserved

 * comment below.  No return value.

	/*

	 * Reserve the first word in scratchpad for communicating

	 * with the boot ROM. A pointer to a data structure

	 * describing the boot process can be stored there,

	 * cf. OMAP34xx TRM, Initialization / Software Booting

	 * Configuration.

	 *

	 * XXX This should use some omap_ctrl_writel()-type function

/**

 * omap_ctrl_write_dsp_boot_addr - set boot address for a remote processor

 * @bootaddr: physical address of the boot loader

 *

 * Set boot address for the boot loader of a supported processor

 * when a power ON sequence occurs.

/**

 * omap_ctrl_write_dsp_boot_mode - set boot mode for a remote processor

 * @bootmode: 8-bit value to pass to some boot code

 *

 * Sets boot mode for the boot loader of a supported processor

 * when a power ON sequence occurs.

/*

 * Clears the scratchpad contents in case of cold boot-

 * called during bootup

 Populate the scratchpad structure with restore structure */

	/*

	 * Populate the Scratchpad contents

	 *

	 * The "get_*restore_pointer" functions are used to provide a

	 * physical restore address where the ROM code jumps while waking

	 * up from MPU OFF/OSWR state.

	 * The restore pointer is stored into the scratchpad.

 Populate the PRCM block contents */

 Populate the SDRC block contents */

	/*

	 * Due to a OMAP3 errata (1.142), on EMU/HS devices SRDC should

	 * be programed to issue automatic self refresh on timeout

	 * of AUTO_CNT = 1 prior to any transition to OFF mode.

 Copy all the contents to the scratchpad location */

 Scratchpad contents being 32 bits, a divide by 4 done here */

	/*

	 * Copies the address of the location in SDRAM where ARM

	 * registers get saved during a MPU OFF transition.

/**

 * omap3_ctrl_save_padconf - save padconf registers to scratchpad RAM

 *

 * Tell the SCM to start saving the padconf registers, then wait for

 * the process to complete.  Returns 0 unconditionally, although it

 * should also eventually be able to return -ETIMEDOUT, if the save

 * does not complete.

 *

 * XXX This function is missing a timeout.  What should it be?

 Save the padconf registers */

 wait for the save to complete */

/**

 * omap3_ctrl_set_iva_bootmode_idle - sets the IVA2 bootmode to idle

 *

 * Sets the bootmode for IVA2 to idle. This is needed by the PM code to

 * force disable IVA2 so that it does not prevent any low-power states.

/**

 * omap3_ctrl_setup_d2d_padconf - setup stacked modem pads for idle

 *

 * Sets up the pads controlling the stacked modem in such way that the

 * device can enter idle.

	/*

	 * In a stand alone OMAP3430 where there is not a stacked

	 * modem for the D2D Idle Ack and D2D MStandby must be pulled

	 * high. S CONTROL_PADCONF_SAD2D_IDLEACK and

	 * CONTROL_PADCONF_SAD2D_MSTDBY to have a pull up.

 pull-up, enabled */

/**

 * omap3_ctrl_init - does static initializations for control module

 *

 * Initializes system control module. This sets up the sysconfig autoidle,

 * and sets up modem and iva2 so that they can be idled properly.

 CONFIG_ARCH_OMAP3 && CONFIG_PM */

/**

 * am43xx_control_save_context - Save the wakeup domain registers

 *

 * Save the wkup domain registers

/**

 * am43xx_control_restore_context - Restore the wakeup domain registers

 *

 * Restore the wkup domain registers

/**

 * omap2_control_base_init - initialize iomappings for the control driver

 *

 * Detects and initializes the iomappings for the control driver, based

 * on the DT data. Returns 0 in success, negative error value

 * otherwise.

/**

 * omap_control_init - low level init for the control driver

 *

 * Initializes the low level clock infrastructure for control driver.

 * Returns 0 in success, negative error value in failure.

		/*

		 * Check if we have scm_conf node, if yes, use this to

		 * access clock registers.

 No scm_conf found, direct access */

 Only AM43XX can lose ctrl registers context during rtc-ddr suspend */

/**

 * omap3_control_legacy_iomap_init - legacy iomap init for clock providers

 *

 * Legacy iomap init for clock provider. Needed only by legacy boot mode,

 * where the base addresses are not parsed from DT, but still required

 * by the clock driver to be setup properly.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP3xxx CM module functions

 *

 * Copyright (C) 2009 Nokia Corporation

 * Copyright (C) 2008-2010, 2012 Texas Instruments, Inc.

 * Paul Walmsley

 * Rajendra Nayak <rnayak@ti.com>

/*

 *

/*

 *

/**

 * omap3xxx_cm_wait_module_ready - wait for a module to leave idle or standby

 * @part: PRCM partition, ignored for OMAP3

 * @prcm_mod: PRCM module offset

 * @idlest_id: CM_IDLESTx register ID (i.e., x = 1, 2, 3)

 * @idlest_shift: shift of the bit in the CM_IDLEST* register to check

 *

 * Wait for the PRCM to indicate that the module identified by

 * (@prcm_mod, @idlest_id, @idlest_shift) is clocked.  Return 0 upon

 * success or -EBUSY if the module doesn't enable in time.

/**

 * omap3xxx_cm_split_idlest_reg - split CM_IDLEST reg addr into its components

 * @idlest_reg: CM_IDLEST* virtual address

 * @prcm_inst: pointer to an s16 to return the PRCM instance offset

 * @idlest_reg_id: pointer to a u8 to return the CM_IDLESTx register ID

 *

 * XXX This function is only needed until absolute register addresses are

 * removed from the OMAP struct clk records.

 Clockdomain low-level operations */

 only happens if data is erroneous */

	/*

	 * The CLKDM_MISSING_IDLE_REPORTING flag documentation has

	 * more details on the unpleasant problem this is working

	 * around

 Disable HW transitions when we are changing deps */

	/*

	 * The CLKDM_MISSING_IDLE_REPORTING flag documentation has

	 * more details on the unpleasant problem this is working

	 * around

 Disable HW transitions when we are changing deps */

/*

 * Context save/restore code - OMAP3 only

	/*

	 * As per erratum i671, ROM code does not respect the PER DPLL

	 * programming scheme if CM_AUTOIDLE_PLL.AUTO_PERIPH_DPLL == 1.

	 * In this case, even though this register has been saved in

	 * scratchpad contents, we need to restore AUTO_PERIPH_DPLL

	 * by ourselves. So, we need to save it anyway.

	/*

	 * As per erratum i671, ROM code does not respect the PER DPLL

	 * programming scheme if CM_AUTOIDLE_PLL.AUTO_PERIPH_DPLL == 1.

	 * In this case, we need to restore AUTO_PERIPH_DPLL by ourselves.

	/*

	 * As per erratum i671, ROM code does not respect the PER DPLL

	 * programming scheme if CM_AUTOIDLE_PLL..AUTO_PERIPH_DPLL == 1.

	 * Then,  in any case, clear these bits to avoid extra latencies.

/*

 *

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod implementation for OMAP2/3/4

 *

 * Copyright (C) 2009-2011 Nokia Corporation

 * Copyright (C) 2011-2012 Texas Instruments, Inc.

 *

 * Paul Walmsley, Benot Cousson, Kevin Hilman

 *

 * Created in collaboration with (alphabetical order): Thara Gopinath,

 * Tony Lindgren, Rajendra Nayak, Vikram Pandita, Sakari Poussa, Anand

 * Sawant, Santosh Shilimkar, Richard Woodruff

 *

 * Introduction

 * ------------

 * One way to view an OMAP SoC is as a collection of largely unrelated

 * IP blocks connected by interconnects.  The IP blocks include

 * devices such as ARM processors, audio serial interfaces, UARTs,

 * etc.  Some of these devices, like the DSP, are created by TI;

 * others, like the SGX, largely originate from external vendors.  In

 * TI's documentation, on-chip devices are referred to as "OMAP

 * modules."  Some of these IP blocks are identical across several

 * OMAP versions.  Others are revised frequently.

 *

 * These OMAP modules are tied together by various interconnects.

 * Most of the address and data flow between modules is via OCP-based

 * interconnects such as the L3 and L4 buses; but there are other

 * interconnects that distribute the hardware clock tree, handle idle

 * and reset signaling, supply power, and connect the modules to

 * various pads or balls on the OMAP package.

 *

 * OMAP hwmod provides a consistent way to describe the on-chip

 * hardware blocks and their integration into the rest of the chip.

 * This description can be automatically generated from the TI

 * hardware database.  OMAP hwmod provides a standard, consistent API

 * to reset, enable, idle, and disable these hardware blocks.  And

 * hwmod provides a way for other core code, such as the Linux device

 * code or the OMAP power management and address space mapping code,

 * to query the hardware database.

 *

 * Using hwmod

 * -----------

 * Drivers won't call hwmod functions directly.  That is done by the

 * omap_device code, and in rare occasions, by custom integration code

 * in arch/arm/ *omap*.  The omap_device code includes functions to

 * build a struct platform_device using omap_hwmod data, and that is

 * currently how hwmod data is communicated to drivers and to the

 * Linux driver model.  Most drivers will call omap_hwmod functions only

 * indirectly, via pm_runtime*() functions.

 *

 * From a layering perspective, here is where the OMAP hwmod code

 * fits into the kernel software stack:

 *

 *            +-------------------------------+

 *            |      Device driver code       |

 *            |      (e.g., drivers/)         |

 *            +-------------------------------+

 *            |      Linux driver model       |

 *            |     (platform_device /        |

 *            |  platform_driver data/code)   |

 *            +-------------------------------+

 *            | OMAP core-driver integration  |

 *            |(arch/arm/mach-omap2/devices.c)|

 *            +-------------------------------+

 *            |      omap_device code         |

 *            | (../plat-omap/omap_device.c)  |

 *            +-------------------------------+

 *   ---->    |    omap_hwmod code/data       |    <-----

 *            | (../mach-omap2/omap_hwmod*)   |

 *            +-------------------------------+

 *            | OMAP clock/PRCM/register fns  |

 *            | ({read,write}l_relaxed, clk*) |

 *            +-------------------------------+

 *

 * Device drivers should not contain any OMAP-specific code or data in

 * them.  They should only contain code to operate the IP block that

 * the driver is responsible for.  This is because these IP blocks can

 * also appear in other SoCs, either from TI (such as DaVinci) or from

 * other manufacturers; and drivers should be reusable across other

 * platforms.

 *

 * The OMAP hwmod code also will attempt to reset and idle all on-chip

 * devices upon boot.  The goal here is for the kernel to be

 * completely self-reliant and independent from bootloaders.  This is

 * to ensure a repeatable configuration, both to ensure consistent

 * runtime behavior, and to make it easier for others to reproduce

 * bugs.

 *

 * OMAP module activity states

 * ---------------------------

 * The hwmod code considers modules to be in one of several activity

 * states.  IP blocks start out in an UNKNOWN state, then once they

 * are registered via the hwmod code, proceed to the REGISTERED state.

 * Once their clock names are resolved to clock pointers, the module

 * enters the CLKS_INITED state; and finally, once the module has been

 * reset and the integration registers programmed, the INITIALIZED state

 * is entered.  The hwmod code will then place the module into either

 * the IDLE state to save power, or in the case of a critical system

 * module, the ENABLED state.

 *

 * OMAP core integration code can then call omap_hwmod*() functions

 * directly to move the module between the IDLE, ENABLED, and DISABLED

 * states, as needed.  This is done during both the PM idle loop, and

 * in the OMAP core integration code's implementation of the PM runtime

 * functions.

 *

 * References

 * ----------

 * This is a partial list.

 * - OMAP2420 Multimedia Processor Silicon Revision 2.1.1, 2.2 (SWPU064)

 * - OMAP2430 Multimedia Device POP Silicon Revision 2.1 (SWPU090)

 * - OMAP34xx Multimedia Device Silicon Revision 3.1 (SWPU108)

 * - OMAP4430 Multimedia Device Silicon Revision 1.0 (SWPU140)

 * - Open Core Protocol Specification 2.2

 *

 * To do:

 * - handle IO mapping

 * - bus throughput & module latency measurement code

 *

 * XXX add tests at the beginning of each function to ensure the hwmod is

 * in the appropriate state

 * XXX error return values should be checked to ensure that they are

 * appropriate

 Name of the OMAP hwmod for the MPU */

/*

 * Number of struct omap_hwmod_link records per struct

 * omap_hwmod_ocp_if record (master->slave and slave->master)

/*

 * Address offset (in bytes) between the reset control and the reset

 * status registers: 4 bytes on OMAP4

/*

 * Maximum length for module clock handle names

/**

 * struct clkctrl_provider - clkctrl provider mapping data

 * @num_addrs: number of base address ranges for the provider

 * @addr: base address(es) for the provider

 * @size: size(s) of the provider address space(s)

 * @node: device node associated with the provider

 * @link: list link

/**

 * struct omap_hwmod_reset - IP specific reset functions

 * @match: string to match against the module name

 * @len: number of characters to match

 * @reset: IP specific reset function

 *

 * Used only in cases where struct omap_hwmod is dynamically allocated.

/**

 * struct omap_hwmod_soc_ops - fn ptrs for some SoC-specific operations

 * @enable_module: function to enable a module (via MODULEMODE)

 * @disable_module: function to disable a module (via MODULEMODE)

 *

 * XXX Eventually this functionality will be hidden inside the PRM/CM

 * device drivers.  Until then, this should avoid huge blocks of cpu_is_*()

 * conditionals in this code.

 soc_ops: adapts the omap_hwmod code to the currently-booted SoC */

 omap_hwmod_list contains all registered struct omap_hwmods */

 mpu_oh: used to add/remove MPU initiator from sleepdep list */

 inited: set to true once the hwmod code is initialized */

 Private functions */

/**

 * _update_sysc_cache - return the module OCP_SYSCONFIG register, keep copy

 * @oh: struct omap_hwmod *

 *

 * Load the current value of the hwmod OCP_SYSCONFIG register into the

 * struct omap_hwmod for later use.  Returns -EINVAL if the hwmod has no

 * OCP_SYSCONFIG register or 0 upon success.

 XXX ensure module interface clock is up */

/**

 * _write_sysconfig - write a value to the module's OCP_SYSCONFIG register

 * @v: OCP_SYSCONFIG value to write

 * @oh: struct omap_hwmod *

 *

 * Write @v into the module class' OCP_SYSCONFIG register, if it has

 * one.  No return value.

 XXX ensure module interface clock is up */

 Module might have lost context, always update cache and register */

	/*

	 * Some IP blocks (such as RTC) require unlocking of IP before

	 * accessing its registers. If a function pointer is present

	 * to unlock, then call it before accessing sysconfig and

	 * call lock after writing sysconfig.

/**

 * _set_master_standbymode: set the OCP_SYSCONFIG MIDLEMODE field in @v

 * @oh: struct omap_hwmod *

 * @standbymode: MIDLEMODE field bits

 * @v: pointer to register contents to modify

 *

 * Update the master standby mode bits in @v to be @standbymode for

 * the @oh hwmod.  Does not write to the hardware.  Returns -EINVAL

 * upon error or 0 upon success.

/**

 * _set_slave_idlemode: set the OCP_SYSCONFIG SIDLEMODE field in @v

 * @oh: struct omap_hwmod *

 * @idlemode: SIDLEMODE field bits

 * @v: pointer to register contents to modify

 *

 * Update the slave idle mode bits in @v to be @idlemode for the @oh

 * hwmod.  Does not write to the hardware.  Returns -EINVAL upon error

 * or 0 upon success.

/**

 * _set_clockactivity: set OCP_SYSCONFIG.CLOCKACTIVITY bits in @v

 * @oh: struct omap_hwmod *

 * @clockact: CLOCKACTIVITY field bits

 * @v: pointer to register contents to modify

 *

 * Update the clockactivity mode bits in @v to be @clockact for the

 * @oh hwmod.  Used for additional powersaving on some modules.  Does

 * not write to the hardware.  Returns -EINVAL upon error or 0 upon

 * success.

/**

 * _set_softreset: set OCP_SYSCONFIG.SOFTRESET bit in @v

 * @oh: struct omap_hwmod *

 * @v: pointer to register contents to modify

 *

 * Set the SOFTRESET bit in @v for hwmod @oh.  Returns -EINVAL upon

 * error or 0 upon success.

/**

 * _clear_softreset: clear OCP_SYSCONFIG.SOFTRESET bit in @v

 * @oh: struct omap_hwmod *

 * @v: pointer to register contents to modify

 *

 * Clear the SOFTRESET bit in @v for hwmod @oh.  Returns -EINVAL upon

 * error or 0 upon success.

/**

 * _wait_softreset_complete - wait for an OCP softreset to complete

 * @oh: struct omap_hwmod * to wait on

 *

 * Wait until the IP block represented by @oh reports that its OCP

 * softreset is complete.  This can be triggered by software (see

 * _ocp_softreset()) or by hardware upon returning from off-mode (one

 * example is HSMMC).  Waits for up to MAX_MODULE_SOFTRESET_WAIT

 * microseconds.  Returns the number of microseconds waited.

/**

 * _set_dmadisable: set OCP_SYSCONFIG.DMADISABLE bit in @v

 * @oh: struct omap_hwmod *

 *

 * The DMADISABLE bit is a semi-automatic bit present in sysconfig register

 * of some modules. When the DMA must perform read/write accesses, the

 * DMADISABLE bit is cleared by the hardware. But when the DMA must stop

 * for power management, software must set the DMADISABLE bit back to 1.

 *

 * Set the DMADISABLE bit in @v for hwmod @oh.  Returns -EINVAL upon

 * error or 0 upon success.

 clocks must be on for this operation */

/**

 * _set_module_autoidle: set the OCP_SYSCONFIG AUTOIDLE field in @v

 * @oh: struct omap_hwmod *

 * @autoidle: desired AUTOIDLE bitfield value (0 or 1)

 * @v: pointer to register contents to modify

 *

 * Update the module autoidle bit in @v to be @autoidle for the @oh

 * hwmod.  The autoidle bit controls whether the module can gate

 * internal clocks automatically when it isn't doing anything; the

 * exact function of this bit varies on a per-module basis.  This

 * function does not write to the hardware.  Returns -EINVAL upon

 * error or 0 upon success.

/**

 * _enable_wakeup: set OCP_SYSCONFIG.ENAWAKEUP bit in the hardware

 * @oh: struct omap_hwmod *

 *

 * Allow the hardware module @oh to send wakeups.  Returns -EINVAL

 * upon error or 0 upon success.

 XXX test pwrdm_get_wken for this hwmod's subsystem */

/**

 * _add_initiator_dep: prevent @oh from smart-idling while @init_oh is active

 * @oh: struct omap_hwmod *

 *

 * Prevent the hardware module @oh from entering idle while the

 * hardare module initiator @init_oh is active.  Useful when a module

 * will be accessed by a particular initiator (e.g., if a module will

 * be accessed by the IVA, there should be a sleepdep between the IVA

 * initiator and the module).  Only applies to modules in smart-idle

 * mode.  If the clockdomain is marked as not needing autodeps, return

 * 0 without doing anything.  Otherwise, returns -EINVAL upon error or

 * passes along clkdm_add_sleepdep() value upon success.

/**

 * _del_initiator_dep: allow @oh to smart-idle even if @init_oh is active

 * @oh: struct omap_hwmod *

 *

 * Allow the hardware module @oh to enter idle while the hardare

 * module initiator @init_oh is active.  Useful when a module will not

 * be accessed by a particular initiator (e.g., if a module will not

 * be accessed by the IVA, there should be no sleepdep between the IVA

 * initiator and the module).  Only applies to modules in smart-idle

 * mode.  If the clockdomain is marked as not needing autodeps, return

 * 0 without doing anything.  Returns -EINVAL upon error or passes

 * along clkdm_del_sleepdep() value upon success.

/**

 * _init_main_clk - get a struct clk * for the hwmod's main functional clk

 * @oh: struct omap_hwmod *

 *

 * Called from _init_clocks().  Populates the @oh _clk (main

 * functional clock pointer) if a clock matching the hwmod name is found,

 * or a main_clk is present.  Returns 0 on success or -EINVAL on error.

	/*

	 * HACK: This needs a re-visit once clk_prepare() is implemented

	 * to do something meaningful. Today its just a no-op.

	 * If clk_prepare() is used at some point to do things like

	 * voltage scaling etc, then this would have to be moved to

	 * some point where subsystems like i2c and pmic become

	 * available.

/**

 * _init_interface_clks - get a struct clk * for the hwmod's interface clks

 * @oh: struct omap_hwmod *

 *

 * Called from _init_clocks().  Populates the @oh OCP slave interface

 * clock pointers.  Returns 0 on success or -EINVAL on error.

		/*

		 * HACK: This needs a re-visit once clk_prepare() is implemented

		 * to do something meaningful. Today its just a no-op.

		 * If clk_prepare() is used at some point to do things like

		 * voltage scaling etc, then this would have to be moved to

		 * some point where subsystems like i2c and pmic become

		 * available.

/**

 * _init_opt_clk - get a struct clk * for the hwmod's optional clocks

 * @oh: struct omap_hwmod *

 *

 * Called from _init_clocks().  Populates the @oh omap_hwmod_opt_clk

 * clock pointers.  Returns 0 on success or -EINVAL on error.

		/*

		 * HACK: This needs a re-visit once clk_prepare() is implemented

		 * to do something meaningful. Today its just a no-op.

		 * If clk_prepare() is used at some point to do things like

		 * voltage scaling etc, then this would have to be moved to

		 * some point where subsystems like i2c and pmic become

		 * available.

/**

 * _enable_clocks - enable hwmod main clock and interface clocks

 * @oh: struct omap_hwmod *

 *

 * Enables all clocks necessary for register reads and writes to succeed

 * on the hwmod @oh.  Returns 0.

 The opt clocks are controlled by the device driver. */

/**

 * _omap4_clkctrl_managed_by_clkfwk - true if clkctrl managed by clock framework

 * @oh: struct omap_hwmod *

/**

 * _omap4_has_clkctrl_clock - returns true if a module has clkctrl clock

 * @oh: struct omap_hwmod *

/**

 * _disable_clocks - disable hwmod main clock and interface clocks

 * @oh: struct omap_hwmod *

 *

 * Disables the hwmod @oh main functional and interface clocks.  Returns 0.

 The opt clocks are controlled by the device driver. */

/**

 * _omap4_enable_module - enable CLKCTRL modulemode on OMAP4

 * @oh: struct omap_hwmod *

 *

 * Enables the PRCM module mode related to the hwmod @oh.

 * No return value.

/**

 * _omap4_wait_target_disable - wait for a module to be disabled on OMAP4

 * @oh: struct omap_hwmod *

 *

 * Wait for a module @oh to enter slave idle.  Returns 0 if the module

 * does not have an IDLEST bit or if the module successfully enters

 * slave idle; otherwise, pass along the return value of the

 * appropriate *_cm*_wait_module_idle() function.

/**

 * _save_mpu_port_index - find and save the index to @oh's MPU port

 * @oh: struct omap_hwmod *

 *

 * Determines the array index of the OCP slave port that the MPU uses

 * to address the device, and saves it into the struct omap_hwmod.

 * Intended to be called during hwmod registration only. No return

 * value.

/**

 * _find_mpu_rt_port - return omap_hwmod_ocp_if accessible by the MPU

 * @oh: struct omap_hwmod *

 *

 * Given a pointer to a struct omap_hwmod record @oh, return a pointer

 * to the struct omap_hwmod_ocp_if record that is used by the MPU to

 * communicate with the IP block.  This interface need not be directly

 * connected to the MPU (and almost certainly is not), but is directly

 * connected to the IP block represented by @oh.  Returns a pointer

 * to the struct omap_hwmod_ocp_if * upon success, or returns NULL upon

 * error or if there does not appear to be a path from the MPU to this

 * IP block.

/**

 * _enable_sysc - try to bring a module out of idle via OCP_SYSCONFIG

 * @oh: struct omap_hwmod *

 *

 * Ensure that the OCP_SYSCONFIG register for the IP block represented

 * by @oh is set to indicate to the PRCM that the IP block is active.

 * Usually this means placing the module into smart-idle mode and

 * smart-standby, but if there is a bug in the automatic idle handling

 * for the IP block, it may need to be placed into the force-idle or

 * no-idle variants of these modes.  No return value.

	/*

	 * Wait until reset has completed, this is needed as the IP

	 * block is reset automatically by hardware in some cases

	 * (off-mode for example), and the drivers require the

	 * IP to be ready when they access it

		/*

		 * This is special handling for some IPs like

		 * 32k sync timer. Force them to idle!

	/*

	 * XXX The clock framework should handle this, by

	 * calling into this code.  But this must wait until the

	 * clock structures are tagged with omap_hwmod entries

	/*

	 * Set the autoidle bit only after setting the smartidle bit

	 * Setting this will not have any impact on the other modules.

/**

 * _idle_sysc - try to put a module into idle via OCP_SYSCONFIG

 * @oh: struct omap_hwmod *

 *

 * If module is marked as SWSUP_SIDLE, force the module into slave

 * idle; otherwise, configure it for smart-idle.  If module is marked

 * as SWSUP_MSUSPEND, force the module into master standby; otherwise,

 * configure it for smart-standby.  No return value.

 If the cached value is the same as the new value, skip the write */

/**

 * _shutdown_sysc - force a module into idle via OCP_SYSCONFIG

 * @oh: struct omap_hwmod *

 *

 * Force the module into slave idle and master suspend. No return

 * value.

/**

 * _lookup - find an omap_hwmod by name

 * @name: find an omap_hwmod by name

 *

 * Return a pointer to an omap_hwmod by name, or NULL if not found.

/**

 * _init_clkdm - look up a clockdomain name, store pointer in omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Convert a clockdomain name stored in a struct omap_hwmod into a

 * clockdomain pointer, and save it into the struct omap_hwmod.

 * Return -EINVAL if the clkdm_name lookup failed.

/**

 * _init_clocks - clk_get() all clocks associated with this hwmod. Retrieve as

 * well the clockdomain.

 * @oh: struct omap_hwmod *

 * @np: device_node mapped to this hwmod

 *

 * Called by omap_hwmod_setup_*() (after omap2_clk_init()).

 * Resolves all clock names embedded in the hwmod.  Returns 0 on

 * success, or a negative error code on failure.

/**

 * _lookup_hardreset - fill register bit info for this hwmod/reset line

 * @oh: struct omap_hwmod *

 * @name: name of the reset line in the context of this hwmod

 * @ohri: struct omap_hwmod_rst_info * that this function will fill in

 *

 * Return the bit position of the reset line that match the

 * input name. Return -ENOENT if not found.

/**

 * _assert_hardreset - assert the HW reset line of submodules

 * contained in the hwmod module.

 * @oh: struct omap_hwmod *

 * @name: name of the reset line to lookup and assert

 *

 * Some IP like dsp, ipu or iva contain processor that require an HW

 * reset line to be assert / deassert in order to enable fully the IP.

 * Returns -EINVAL if @oh is null, -ENOSYS if we have no way of

 * asserting the hardreset line on the currently-booted SoC, or passes

 * along the return value from _lookup_hardreset() or the SoC's

 * assert_hardreset code.

/**

 * _deassert_hardreset - deassert the HW reset line of submodules contained

 * in the hwmod module.

 * @oh: struct omap_hwmod *

 * @name: name of the reset line to look up and deassert

 *

 * Some IP like dsp, ipu or iva contain processor that require an HW

 * reset line to be assert / deassert in order to enable fully the IP.

 * Returns -EINVAL if @oh is null, -ENOSYS if we have no way of

 * deasserting the hardreset line on the currently-booted SoC, or passes

 * along the return value from _lookup_hardreset() or the SoC's

 * deassert_hardreset code.

		/*

		 * A clockdomain must be in SW_SUP otherwise reset

		 * might not be completed. The clockdomain can be set

		 * in HW_AUTO only when the module become ready.

		/*

		 * Set the clockdomain to HW_AUTO, assuming that the

		 * previous state was HW_AUTO.

/**

 * _read_hardreset - read the HW reset line state of submodules

 * contained in the hwmod module

 * @oh: struct omap_hwmod *

 * @name: name of the reset line to look up and read

 *

 * Return the state of the reset line.  Returns -EINVAL if @oh is

 * null, -ENOSYS if we have no way of reading the hardreset line

 * status on the currently-booted SoC, or passes along the return

 * value from _lookup_hardreset() or the SoC's is_hardreset_asserted

 * code.

/**

 * _are_all_hardreset_lines_asserted - return true if the @oh is hard-reset

 * @oh: struct omap_hwmod *

 *

 * If all hardreset lines associated with @oh are asserted, then return true.

 * Otherwise, if part of @oh is out hardreset or if no hardreset lines

 * associated with @oh are asserted, then return false.

 * This function is used to avoid executing some parts of the IP block

 * enable/disable sequence if its hardreset line is set.

/**

 * _are_any_hardreset_lines_asserted - return true if any part of @oh is

 * hard-reset

 * @oh: struct omap_hwmod *

 *

 * If any hardreset lines associated with @oh are asserted, then

 * return true.  Otherwise, if no hardreset lines associated with @oh

 * are asserted, or if @oh has no hardreset lines, then return false.

 * This function is used to avoid executing some parts of the IP block

 * enable/disable sequence if any hardreset line is set.

/**

 * _omap4_disable_module - enable CLKCTRL modulemode on OMAP4

 * @oh: struct omap_hwmod *

 *

 * Disable the PRCM module mode related to the hwmod @oh.

 * Return EINVAL if the modulemode is not supported and 0 in case of success.

	/*

	 * Since integration code might still be doing something, only

	 * disable if all lines are under hardreset.

/**

 * _ocp_softreset - reset an omap_hwmod via the OCP_SYSCONFIG bit

 * @oh: struct omap_hwmod *

 *

 * Resets an omap_hwmod @oh via the OCP_SYSCONFIG bit.  hwmod must be

 * enabled for this to work.  Returns -ENOENT if the hwmod cannot be

 * reset this way, -EINVAL if the hwmod is in the wrong state,

 * -ETIMEDOUT if the module did not reset in time, or 0 upon success.

 *

 * In OMAP3 a specific SYSSTATUS register is used to get the reset status.

 * Starting in OMAP4, some IPs do not have SYSSTATUS registers and instead

 * use the SYSCONFIG softreset bit to provide the status.

 *

 * Note that some IP like McBSP do have reset control but don't have

 * reset status.

 clocks must be on for this operation */

 For some modules, all optionnal clocks need to be enabled as well */

	/*

	 * XXX add _HWMOD_STATE_WEDGED for modules that don't come back from

	 * _wait_target_ready() or _reset()

/**

 * _reset - reset an omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Resets an omap_hwmod @oh.  If the module has a custom reset

 * function pointer defined, then call it to reset the IP block, and

 * pass along its return value to the caller.  Otherwise, if the IP

 * block has an OCP_SYSCONFIG register with a SOFTRESET bitfield

 * associated with it, call a function to reset the IP block via that

 * method, and pass along the return value to the caller.  Finally, if

 * the IP block has some hardreset lines associated with it, assert

 * all of those, but do _not_ deassert them. (This is because driver

 * authors have expressed an apparent requirement to control the

 * deassertion of the hardreset lines themselves.)

 *

 * The default software reset mechanism for most OMAP IP blocks is

 * triggered via the OCP_SYSCONFIG.SOFTRESET bit.  However, some

 * hwmods cannot be reset via this method.  Some are not targets and

 * therefore have no OCP header registers to access.  Others (like the

 * IVA) have idiosyncratic reset sequences.  So for these relatively

 * rare cases, custom reset code can be supplied in the struct

 * omap_hwmod_class .reset function pointer.

 *

 * _set_dmadisable() is called to set the DMADISABLE bit so that it

 * does not prevent idling of the system. This is necessary for cases

 * where ROMCODE/BOOTLOADER uses dma and transfers control to the

 * kernel without disabling dma.

 *

 * Passes along the return value from either _ocp_softreset() or the

 * custom reset function - these must return -EINVAL if the hwmod

 * cannot be reset this way or if the hwmod is in the wrong state,

 * -ETIMEDOUT if the module did not reset in time, or 0 upon success.

	/*

	 * OCP_SYSCONFIG bits need to be reprogrammed after a

	 * softreset.  The _enable() function should be split to avoid

	 * the rewrite of the OCP_SYSCONFIG register.

/**

 * _omap4_update_context_lost - increment hwmod context loss counter if

 * hwmod context was lost, and clear hardware context loss reg

 * @oh: hwmod to check for context loss

 *

 * If the PRCM indicates that the hwmod @oh lost context, increment

 * our in-memory context loss counter, and clear the RM_*_CONTEXT

 * bits. No return value.

/**

 * _omap4_get_context_lost - get context loss counter for a hwmod

 * @oh: hwmod to get context loss counter for

 *

 * Returns the in-memory context loss counter for a hwmod.

/**

 * _enable - enable an omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Enables an omap_hwmod @oh such that the MPU can access the hwmod's

 * register target.  Returns -EINVAL if the hwmod is in the wrong

 * state or passes along the return value of _wait_target_ready().

	/*

	 * hwmods with HWMOD_INIT_NO_IDLE flag set are left in enabled

	 * state at init.

	/*

	 * If an IP block contains HW reset lines and all of them are

	 * asserted, we let integration code associated with that

	 * block handle the enable.  We've received very little

	 * information on what those driver authors need, and until

	 * detailed information is provided and the driver code is

	 * posted to the public lists, this is probably the best we

	 * can do.

		/*

		 * A clockdomain must be in SW_SUP before enabling

		 * completely the module. The clockdomain can be set

		 * in HW_AUTO only when the module become ready.

 Access the sysconfig only if the target is ready */

/**

 * _idle - idle an omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Idles an omap_hwmod @oh.  This should be called once the hwmod has

 * no further work.  Returns -EINVAL if the hwmod is in the wrong

 * state or returns 0.

	/*

	 * If HWMOD_CLKDM_NOAUTO is set then we don't

	 * deny idle the clkdm again since idle was already denied

	 * in _enable()

	/*

	 * The module must be in idle mode before disabling any parents

	 * clocks. Otherwise, the parent clock might be disabled before

	 * the module transition is done, and thus will prevent the

	 * transition to complete properly.

/**

 * _shutdown - shutdown an omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Shut down an omap_hwmod @oh.  This should be called when the driver

 * used for the hwmod is removed or unloaded or if the driver is not

 * used by the system.  Returns -EINVAL if the hwmod is in the wrong

 * state or returns 0.

 clocks and deps are already disabled in idle */

 XXX what about the other system initiators here? dma, dsp */

 XXX Should this code also force-disable the optional clocks? */

/**

 * of_dev_hwmod_lookup - look up needed hwmod from dt blob

 * @np: struct device_node *

 * @oh: struct omap_hwmod *

 * @index: index of the entry found

 * @found: struct device_node * found or NULL

 *

 * Parse the dt blob and find out needed hwmod. Recursive function is

 * implemented to take care hierarchical dt blob parsing.

 * Return: Returns 0 on success, -ENODEV when not found.

/**

 * omap_hwmod_fix_mpu_rt_idx - fix up mpu_rt_idx register offsets

 *

 * @oh: struct omap_hwmod *

 * @np: struct device_node *

 *

 * Fix up module register offsets for modules with mpu_rt_idx.

 * Only needed for cpsw with interconnect target module defined

 * in device tree while still using legacy hwmod platform data

 * for rev, sysc and syss registers.

 *

 * Can be removed when all cpsw hwmod platform data has been

 * dropped.

/**

 * omap_hwmod_parse_module_range - map module IO range from device tree

 * @oh: struct omap_hwmod *

 * @np: struct device_node *

 *

 * Parse the device tree range an interconnect target module provides

 * for it's child device IP blocks. This way we can support the old

 * "ti,hwmods" property with just dts data without a need for platform

 * data for IO resources. And we don't need all the child IP device

 * nodes available in the dts.

/**

 * _init_mpu_rt_base - populate the virtual address for a hwmod

 * @oh: struct omap_hwmod * to locate the virtual address

 * @data: (unused, caller should pass NULL)

 * @index: index of the reg entry iospace in device tree

 * @np: struct device_node * of the IP block's device node in the DT data

 *

 * Cache the virtual address used by the MPU to access this IP block's

 * registers.  This address is needed early so the OCP registers that

 * are part of the device's address space can be ioremapped properly.

 *

 * If SYSC access is not needed, the registers will not be remapped

 * and non-availability of MPU access is not treated as an error.

 *

 * Returns 0 on success, -EINVAL if an invalid hwmod is passed, and

 * -ENXIO on absent or invalid register target address space.

 if we don't need sysc access we don't need to ioremap */

 we can't continue without MPU PORT if we need sysc access */

 Do we have a dts range for the interconnect target module? */

 No ranges, rely on device reg entry */

/**

 * _init - initialize internal data for the hwmod @oh

 * @oh: struct omap_hwmod *

 * @n: (unused)

 *

 * Look up the clocks and the address space used by the MPU to access

 * registers belonging to the hwmod @oh.  @oh must already be

 * registered at this point.  This is the first of two phases for

 * hwmod initialization.  Code called here does not touch any hardware

 * registers, it simply prepares internal data structures.  Returns 0

 * upon success or if the hwmod isn't registered or if the hwmod's

 * address space is not defined, or -EINVAL upon failure.

/**

 * _setup_iclk_autoidle - configure an IP block's interface clocks

 * @oh: struct omap_hwmod *

 *

 * Set up the module's interface clocks.  XXX This function is still mostly

 * a stub; implementing this properly requires iclk autoidle usecounting in

 * the clock code.   No return value.

			/*

			 * we might have multiple users of one iclk with

			 * different requirements, disable autoidle when

			 * the module is enabled, e.g. dss iclk

 we are enabling autoidle afterwards anyways */

/**

 * _setup_reset - reset an IP block during the setup process

 * @oh: struct omap_hwmod *

 *

 * Reset the IP block corresponding to the hwmod @oh during the setup

 * process.  The IP block is first enabled so it can be successfully

 * reset.  Returns 0 upon success or a negative error code upon

 * failure.

/**

 * _setup_postsetup - transition to the appropriate state after _setup

 * @oh: struct omap_hwmod *

 *

 * Place an IP block represented by @oh into a "post-setup" state --

 * either IDLE, ENABLED, or DISABLED.  ("post-setup" simply means that

 * this function is called at the end of _setup().)  The postsetup

 * state for an IP block can be changed by calling

 * omap_hwmod_enter_postsetup_state() early in the boot process,

 * before one of the omap_hwmod_setup*() functions are called for the

 * IP block.

 *

 * The IP block stays in this state until a PM runtime-based driver is

 * loaded for that IP block.  A post-setup state of IDLE is

 * appropriate for almost all IP blocks with runtime PM-enabled

 * drivers, since those drivers are able to enable the IP block.  A

 * post-setup state of ENABLED is appropriate for kernels with PM

 * runtime disabled.  The DISABLED state is appropriate for unusual IP

 * blocks such as the MPU WDTIMER on kernels without WDTIMER drivers

 * included, since the WDTIMER starts running on reset and will reset

 * the MPU if left active.

 *

 * This post-setup mechanism is deprecated.  Once all of the OMAP

 * drivers have been converted to use PM runtime, and all of the IP

 * block data and interconnect data is available to the hwmod code, it

 * should be possible to replace this mechanism with a "lazy reset"

 * arrangement.  In a "lazy reset" setup, each IP block is enabled

 * when the driver first probes, then all remaining IP blocks without

 * drivers are either shut down or enabled after the drivers have

 * loaded.  However, this cannot take place until the above

 * preconditions have been met, since otherwise the late reset code

 * has no way of knowing which IP blocks are in use by drivers, and

 * which ones are unused.

 *

 * No return value.

	/*

	 * XXX HWMOD_INIT_NO_IDLE does not belong in hwmod data -

	 * it should be set by the core code as a runtime flag during startup

/**

 * _setup - prepare IP block hardware for use

 * @oh: struct omap_hwmod *

 * @n: (unused, pass NULL)

 *

 * Configure the IP block represented by @oh.  This may include

 * enabling the IP block, resetting it, and placing it into a

 * post-setup state, depending on the type of IP block and applicable

 * flags.  IP blocks are reset to prevent any previous configuration

 * by the bootloader or previous operating system from interfering

 * with power management or other parts of the system.  The reset can

 * be avoided; see omap_hwmod_no_setup_reset().  This is the second of

 * two phases for hwmod initialization.  Code called here generally

 * affects the IP block hardware, or system integration hardware

 * associated with the IP block.  Returns 0.

/**

 * _register - register a struct omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Registers the omap_hwmod @oh.  Returns -EEXIST if an omap_hwmod

 * already has been registered by the same name; -EINVAL if the

 * omap_hwmod is in the wrong state, if @oh is NULL, if the

 * omap_hwmod's class field is NULL; if the omap_hwmod is missing a

 * name, or if the omap_hwmod's class is missing a name; or 0 upon

 * success.

 *

 * XXX The data should be copied into bootmem, so the original data

 * should be marked __initdata and freed after init.  This would allow

 * unneeded omap_hwmods to be freed on multi-OMAP configurations.  Note

 * that the copy process would be relatively complex due to the large number

 * of substructures.

	/*

	 * XXX Rather than doing a strcmp(), this should test a flag

	 * set in the hwmod data, inserted by the autogenerator code.

/**

 * _add_link - add an interconnect between two IP blocks

 * @oi: pointer to a struct omap_hwmod_ocp_if record

 *

 * Add struct omap_hwmod_link records connecting the slave IP block

 * specified in @oi->slave to @oi.  This code is assumed to run before

 * preemption or SMP has been enabled, thus avoiding the need for

 * locking in this code.  Changes to this assumption will require

 * additional locking.  Returns 0.

/**

 * _register_link - register a struct omap_hwmod_ocp_if

 * @oi: struct omap_hwmod_ocp_if *

 *

 * Registers the omap_hwmod_ocp_if record @oi.  Returns -EEXIST if it

 * has already been registered; -EINVAL if @oi is NULL or if the

 * record pointed to by @oi is missing required fields; or 0 upon

 * success.

 *

 * XXX The data should be copied into bootmem, so the original data

 * should be marked __initdata and freed after init.  This would allow

 * unneeded omap_hwmods to be freed on multi-OMAP configurations.

	/*

	 * Register the connected hwmods, if they haven't been

	 * registered already

 Static functions intended only for use in soc_ops field function pointers */

/**

 * _omap2xxx_3xxx_wait_target_ready - wait for a module to leave slave idle

 * @oh: struct omap_hwmod *

 *

 * Wait for a module @oh to leave slave idle.  Returns 0 if the module

 * does not have an IDLEST bit or if the module successfully leaves

 * slave idle; otherwise, pass along the return value of the

 * appropriate *_cm*_wait_module_ready() function.

 XXX check module SIDLEMODE, hardreset status, enabled clocks */

/**

 * _omap4_wait_target_ready - wait for a module to leave slave idle

 * @oh: struct omap_hwmod *

 *

 * Wait for a module @oh to leave slave idle.  Returns 0 if the module

 * does not have an IDLEST bit or if the module successfully leaves

 * slave idle; otherwise, pass along the return value of the

 * appropriate *_cm*_wait_module_ready() function.

 XXX check module SIDLEMODE, hardreset status */

/**

 * _omap2_assert_hardreset - call OMAP2 PRM hardreset fn with hwmod args

 * @oh: struct omap_hwmod * to assert hardreset

 * @ohri: hardreset line data

 *

 * Call omap2_prm_assert_hardreset() with parameters extracted from

 * the hwmod @oh and the hardreset line data @ohri.  Only intended for

 * use as an soc_ops function pointer.  Passes along the return value

 * from omap2_prm_assert_hardreset().  XXX This function is scheduled

 * for removal when the PRM code is moved into drivers/.

/**

 * _omap2_deassert_hardreset - call OMAP2 PRM hardreset fn with hwmod args

 * @oh: struct omap_hwmod * to deassert hardreset

 * @ohri: hardreset line data

 *

 * Call omap2_prm_deassert_hardreset() with parameters extracted from

 * the hwmod @oh and the hardreset line data @ohri.  Only intended for

 * use as an soc_ops function pointer.  Passes along the return value

 * from omap2_prm_deassert_hardreset().  XXX This function is

 * scheduled for removal when the PRM code is moved into drivers/.

/**

 * _omap2_is_hardreset_asserted - call OMAP2 PRM hardreset fn with hwmod args

 * @oh: struct omap_hwmod * to test hardreset

 * @ohri: hardreset line data

 *

 * Call omap2_prm_is_hardreset_asserted() with parameters extracted

 * from the hwmod @oh and the hardreset line data @ohri.  Only

 * intended for use as an soc_ops function pointer.  Passes along the

 * return value from omap2_prm_is_hardreset_asserted().  XXX This

 * function is scheduled for removal when the PRM code is moved into

 * drivers/.

/**

 * _omap4_assert_hardreset - call OMAP4 PRM hardreset fn with hwmod args

 * @oh: struct omap_hwmod * to assert hardreset

 * @ohri: hardreset line data

 *

 * Call omap4_prminst_assert_hardreset() with parameters extracted

 * from the hwmod @oh and the hardreset line data @ohri.  Only

 * intended for use as an soc_ops function pointer.  Passes along the

 * return value from omap4_prminst_assert_hardreset().  XXX This

 * function is scheduled for removal when the PRM code is moved into

 * drivers/.

/**

 * _omap4_deassert_hardreset - call OMAP4 PRM hardreset fn with hwmod args

 * @oh: struct omap_hwmod * to deassert hardreset

 * @ohri: hardreset line data

 *

 * Call omap4_prminst_deassert_hardreset() with parameters extracted

 * from the hwmod @oh and the hardreset line data @ohri.  Only

 * intended for use as an soc_ops function pointer.  Passes along the

 * return value from omap4_prminst_deassert_hardreset().  XXX This

 * function is scheduled for removal when the PRM code is moved into

 * drivers/.

/**

 * _omap4_is_hardreset_asserted - call OMAP4 PRM hardreset fn with hwmod args

 * @oh: struct omap_hwmod * to test hardreset

 * @ohri: hardreset line data

 *

 * Call omap4_prminst_is_hardreset_asserted() with parameters

 * extracted from the hwmod @oh and the hardreset line data @ohri.

 * Only intended for use as an soc_ops function pointer.  Passes along

 * the return value from omap4_prminst_is_hardreset_asserted().  XXX

 * This function is scheduled for removal when the PRM code is moved

 * into drivers/.

/**

 * _omap4_disable_direct_prcm - disable direct PRCM control for hwmod

 * @oh: struct omap_hwmod * to disable control for

 *

 * Disables direct PRCM clkctrl done by hwmod core. Instead, the hwmod

 * will be using its main_clk to enable/disable the module. Returns

 * 0 if successful.

/**

 * _am33xx_deassert_hardreset - call AM33XX PRM hardreset fn with hwmod args

 * @oh: struct omap_hwmod * to deassert hardreset

 * @ohri: hardreset line data

 *

 * Call am33xx_prminst_deassert_hardreset() with parameters extracted

 * from the hwmod @oh and the hardreset line data @ohri.  Only

 * intended for use as an soc_ops function pointer.  Passes along the

 * return value from am33xx_prminst_deassert_hardreset().  XXX This

 * function is scheduled for removal when the PRM code is moved into

 * drivers/.

 Public functions */

/**

 * omap_hwmod_softreset - reset a module via SYSCONFIG.SOFTRESET bit

 * @oh: struct omap_hwmod *

 *

 * This is a public function exposed to drivers. Some drivers may need to do

 * some settings before and after resetting the device.  Those drivers after

 * doing the necessary settings could use this function to start a reset by

 * setting the SYSCONFIG.SOFTRESET bit.

/**

 * omap_hwmod_lookup - look up a registered omap_hwmod by name

 * @name: name of the omap_hwmod to look up

 *

 * Given a @name of an omap_hwmod, return a pointer to the registered

 * struct omap_hwmod *, or NULL upon error.

/**

 * omap_hwmod_for_each - call function for each registered omap_hwmod

 * @fn: pointer to a callback function

 * @data: void * data to pass to callback function

 *

 * Call @fn for each registered omap_hwmod, passing @data to each

 * function.  @fn must return 0 for success or any other value for

 * failure.  If @fn returns non-zero, the iteration across omap_hwmods

 * will stop and the non-zero return value will be passed to the

 * caller of omap_hwmod_for_each().  @fn is called with

 * omap_hwmod_for_each() held.

/**

 * omap_hwmod_register_links - register an array of hwmod links

 * @ois: pointer to an array of omap_hwmod_ocp_if to register

 *

 * Intended to be called early in boot before the clock framework is

 * initialized.  If @ois is not null, will register all omap_hwmods

 * listed in @ois that are valid for this chip.  Returns -EINVAL if

 * omap_hwmod_init() hasn't been called before calling this function,

 * -ENOMEM if the link memory area can't be allocated, or 0 upon

 * success.

 Empty list */

/**

 * _ensure_mpu_hwmod_is_setup - ensure the MPU SS hwmod is init'ed and set up

 * @oh: pointer to the hwmod currently being set up (usually not the MPU)

 *

 * If the hwmod data corresponding to the MPU subsystem IP block

 * hasn't been initialized and set up yet, do so now.  This must be

 * done first since sleep dependencies may be added from other hwmods

 * to the MPU.  Intended to be called only by omap_hwmod_setup*().  No

 * return value.

/**

 * omap_hwmod_setup_one - set up a single hwmod

 * @oh_name: const char * name of the already-registered hwmod to set up

 *

 * Initialize and set up a single hwmod.  Intended to be used for a

 * small number of early devices, such as the timer IP blocks used for

 * the scheduler clock.  Must be called after omap2_clk_init().

 * Resolves the struct clk names to struct clk pointers for each

 * registered omap_hwmod.  Also calls _setup() on each hwmod.  Returns

 * -EINVAL upon error or 0 upon success.

/**

 * omap_hwmod_check_sysc - check sysc against platform sysc

 * @dev: struct device

 * @data: module data

 * @sysc_fields: new sysc configuration

/**

 * omap_hwmod_init_regbits - init sysconfig specific register bits

 * @dev: struct device

 * @oh: module

 * @data: module data

 * @sysc_fields: new sysc configuration

/**

 * omap_hwmod_init_reg_offs - initialize sysconfig register offsets

 * @dev: struct device

 * @data: module data

 * @rev_offs: revision register offset

 * @sysc_offs: sysc register offset

 * @syss_offs: syss register offset

/**

 * omap_hwmod_init_sysc_flags - initialize sysconfig features

 * @dev: struct device

 * @data: module data

 * @sysc_flags: module configuration

 See SYSC_OMAP2_* in include/dt-bindings/bus/ti-sysc.h */

 See SYSC_OMAP4_* in include/dt-bindings/bus/ti-sysc.h */

 See SYSC_OMAP3_SR_* in include/dt-bindings/bus/ti-sysc.h */

/**

 * omap_hwmod_init_idlemodes - initialize module idle modes

 * @dev: struct device

 * @data: module data

 * @idlemodes: module supported idle modes

/**

 * omap_hwmod_check_module - check new module against platform data

 * @dev: struct device

 * @oh: module

 * @data: new module data

 * @sysc_fields: sysc register bits

 * @rev_offs: revision register offset

 * @sysc_offs: sysconfig register offset

 * @syss_offs: sysstatus register offset

 * @sysc_flags: sysc specific flags

 * @idlemodes: sysc supported idlemodes

/**

 * omap_hwmod_allocate_module - allocate new module

 * @dev: struct device

 * @oh: module

 * @sysc_fields: sysc register bits

 * @clockdomain: clockdomain

 * @rev_offs: revision register offset

 * @sysc_offs: sysconfig register offset

 * @syss_offs: sysstatus register offset

 * @sysc_flags: sysc specific flags

 * @idlemodes: sysc supported idlemodes

 *

 * Note that the allocations here cannot use devm as ti-sysc can rebind.

	/*

	 * We may need a new oh->class as the other devices in the same class

	 * may not yet have ioremapped their registers.

		/*

		 * Note that we assume interconnect interface clocks will be

		 * managed by the interconnect driver for OCPIF_SWSUP_IDLE case

		 * on omap24xx and omap3.

/**

 * omap_hwmod_init_module - initialize new module

 * @dev: struct device

 * @data: module data

 * @cookie: cookie for the caller to use for later calls

 Unused, can be handled by PRM driver handling resets */

/**

 * omap_hwmod_setup_earlycon_flags - set up flags for early console

 *

 * Enable DEBUG_OMAPUART_FLAGS for uart hwmod that is being used as

 * early concole so that hwmod core doesn't reset and keep it in idle

 * that specific uart.

/**

 * omap_hwmod_setup_all - set up all registered IP blocks

 *

 * Initialize and set up all IP blocks registered with the hwmod code.

 * Must be called after omap2_clk_init().  Resolves the struct clk

 * names to struct clk pointers for each registered omap_hwmod.  Also

 * calls _setup() on each hwmod.  Returns 0 upon success.

/**

 * omap_hwmod_enable - enable an omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Enable an omap_hwmod @oh.  Intended to be called by omap_device_enable().

 * Returns -EINVAL on error or passes along the return value from _enable().

/**

 * omap_hwmod_idle - idle an omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Idle an omap_hwmod @oh.  Intended to be called by omap_device_idle().

 * Returns -EINVAL on error or passes along the return value from _idle().

/**

 * omap_hwmod_shutdown - shutdown an omap_hwmod

 * @oh: struct omap_hwmod *

 *

 * Shutdown an omap_hwmod @oh.  Intended to be called by

 * omap_device_shutdown().  Returns -EINVAL on error or passes along

 * the return value from _shutdown().

/*

 * IP block data retrieval functions

/**

 * omap_hwmod_get_pwrdm - return pointer to this module's main powerdomain

 * @oh: struct omap_hwmod *

 *

 * Return the powerdomain pointer associated with the OMAP module

 * @oh's main clock.  If @oh does not have a main clk, return the

 * powerdomain associated with the interface clock associated with the

 * module's MPU port. (XXX Perhaps this should use the SDMA port

 * instead?)  Returns NULL on error, or a struct powerdomain * on

 * success.

/**

 * omap_hwmod_get_mpu_rt_va - return the module's base address (for the MPU)

 * @oh: struct omap_hwmod *

 *

 * Returns the virtual address corresponding to the beginning of the

 * module's register target, in the address range that is intended to

 * be used by the MPU.  Returns the virtual address upon success or NULL

 * upon error.

/*

 * XXX what about functions for drivers to save/restore ocp_sysconfig

 * for context save/restore operations?

/**

 * omap_hwmod_assert_hardreset - assert the HW reset line of submodules

 * contained in the hwmod module.

 * @oh: struct omap_hwmod *

 * @name: name of the reset line to lookup and assert

 *

 * Some IP like dsp, ipu or iva contain processor that require

 * an HW reset line to be assert / deassert in order to enable fully

 * the IP.  Returns -EINVAL if @oh is null or if the operation is not

 * yet supported on this OMAP; otherwise, passes along the return value

 * from _assert_hardreset().

/**

 * omap_hwmod_deassert_hardreset - deassert the HW reset line of submodules

 * contained in the hwmod module.

 * @oh: struct omap_hwmod *

 * @name: name of the reset line to look up and deassert

 *

 * Some IP like dsp, ipu or iva contain processor that require

 * an HW reset line to be assert / deassert in order to enable fully

 * the IP.  Returns -EINVAL if @oh is null or if the operation is not

 * yet supported on this OMAP; otherwise, passes along the return value

 * from _deassert_hardreset().

/**

 * omap_hwmod_for_each_by_class - call @fn for each hwmod of class @classname

 * @classname: struct omap_hwmod_class name to search for

 * @fn: callback function pointer to call for each hwmod in class @classname

 * @user: arbitrary context data to pass to the callback function

 *

 * For each omap_hwmod of class @classname, call @fn.

 * If the callback function returns something other than

 * zero, the iterator is terminated, and the callback function's return

 * value is passed back to the caller.  Returns 0 upon success, -EINVAL

 * if @classname or @fn are NULL, or passes back the error code from @fn.

/**

 * omap_hwmod_set_postsetup_state - set the post-_setup() state for this hwmod

 * @oh: struct omap_hwmod *

 * @state: state that _setup() should leave the hwmod in

 *

 * Sets the hwmod state that @oh will enter at the end of _setup()

 * (called by omap_hwmod_setup_*()).  See also the documentation

 * for _setup_postsetup(), above.  Returns 0 upon success or

 * -EINVAL if there is a problem with the arguments or if the hwmod is

 * in the wrong state.

/**

 * omap_hwmod_get_context_loss_count - get lost context count

 * @oh: struct omap_hwmod *

 *

 * Returns the context loss count of associated @oh

 * upon success, or zero if no context loss data is available.

 *

 * On OMAP4, this queries the per-hwmod context loss register,

 * assuming one exists.  If not, or on OMAP2/3, this queries the

 * enclosing powerdomain context loss count.

/**

 * omap_hwmod_init - initialize the hwmod code

 *

 * Sets up some function pointers needed by the hwmod code to operate on the

 * currently-booted SoC.  Intended to be called once during kernel init

 * before any hwmods are registered.  No return value.

/**

 * omap_hwmod_get_main_clk - get pointer to main clock name

 * @oh: struct omap_hwmod *

 *

 * Returns the main clock name assocated with @oh upon success,

 * or NULL if @oh is NULL.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-omap2/id.c

 *

 * OMAP2 CPU identification code

 *

 * Copyright (C) 2005 Nokia Corporation

 * Written by Tony Lindgren <tony@atomide.com>

 *

 * Copyright (C) 2009-11 Texas Instruments

 * Added OMAP4 support - Santosh Shilimkar <santosh.shilimkar@ti.com>

----------------------------------------------------------------------------*/

 Silicon type (Hawkeye id) */

 Device type from production_id reg */

 Combined type id copied to omap_revision */

 Register values to detect the OMAP version */

 Throw the die ID into the entropy pool at boot */

 Check hawkeye ids */

	/*

	 * OMAP3430 and OMAP3530 are assumed to be same.

	 *

	 * OMAP3525, OMAP3515 and OMAP3503 can be detected only based

	 * on available features. Upon detection, update the CPU id

	 * and CPU class bits.

 OMAP3430, OMAP3525, OMAP3515, OMAP3503 devices */

 Print verbose information */

	/*

	 * am35x fixups:

	 * - The am35x Chip ID register has bits 12, 7:5, and 3:2 marked as

	 *   reserved and therefore return 0 when read.  Unfortunately,

	 *   OMAP3_CHECK_FEATURE() will interpret some of those zeroes to

	 *   mean that a feature is present even though it isn't so clear

	 *   the incorrectly set feature bits.

	/*

	 * TODO: Get additional info (where applicable)

	 *       e.g. Size of L2 cache.

	/*

	 * We cannot access revision registers on ES1.0.

	 * If the processor type is Cortex-A8 and the revision is 0x0

	 * it means its Cortex r0p0 which is 3430 ES1.0.

	/*

	 * Detection for 34xx ES2.0 and above can be done with just

	 * hawkeye and rev. See TRM 1.5.2 Device Identification.

	 * Note that rev does not map directly to our defined processor

	 * revision numbers as ES1.0 uses value 0.

 Handle 34xx/35xx devices */

 Take care of early samples */

 Use the latest known revision as default */

		/*

		 * Handle OMAP/AM 3505/3517 devices

		 *

		 * Set the device to be OMAP3517 here. Actual device

		 * is identified later based on the features.

 Handle 36xx devices */

 Take care of early samples */

 Unknown default to latest silicon rev as default */

	/*

	 * The IC rev detection is done with hawkeye and rev.

	 * Note that rev does not map directly to defined processor

	 * revision numbers as ES1.0 uses value 0.

	/*

	 * Few initial 4430 ES2.0 samples IDCODE is same as ES1.0

	 * Use ARM register to detect the correct ES version

 Unknown default to latest silicon rev as default */

 No support for ES1.0 Test chip */

 No support for ES1.0 Test chip */

 Unknown default to latest silicon rev as default*/

 Unknown default to latest silicon rev as default*/

/*

 * Set up things for map_io and processor detection later on. Gets called

 * pretty much first thing from board init. For multi-omap, this gets

 * cpu_is_omapxxxx() working accurately enough for map_io. Then we'll try to

 * detect the exact revision later on in omap2_detect_revision() once map_io

 * is done.

 XXX What is this intended to do? */

 CONFIG_SOC_BUS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Helper module for board specific I2C bus registration

 *

 * Copyright (C) 2009 Nokia Corporation.

 In register I2C_CON, Bit 15 is the I2C enable bit */

/**

 * omap_i2c_reset - reset the omap i2c module.

 * @oh: struct omap_hwmod *

 *

 * The i2c moudle in omap2, omap3 had a special sequence to reset. The

 * sequence is:

 * - Disable the I2C.

 * - Write to SOFTRESET bit.

 * - Enable the I2C.

 * - Poll on the RESETDONE bit.

 * The sequence is implemented in below function. This is called for 2420,

 * 2430 and omap3.

 Disable I2C */

 Write to the SOFTRESET bit */

 Enable I2C */

 Poll on RESETDONE bit */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * omap_hwmod_2xxx_ipblock_data.c - common IP block data for OMAP2xxx

 *

 * Copyright (C) 2011 Nokia Corporation

 * Paul Walmsley

/*

 * 'dispc' class

 * display controller

 OMAP2xxx Timer Common */

/*

 * 'wd_timer' class

 * 32-bit watchdog upward counter that generates a pulse on the reset pin on

 * overflow condition

/*

 * 'gpio' class

 * general purpose io module

/*

 * 'mailbox' class

 * mailbox module allowing communication between the on-chip processors

 * using a queued mailbox-interrupt mechanism.

/*

 * 'mcspi' class

 * multichannel serial port interface (mcspi) / master/slave synchronous serial

 * bus

/*

 * 'gpmc' class

 * general purpose memory controller

/*

 * IP blocks

 L3 */

 L4 CORE */

 L4 WKUP */

 MPU */

 IVA2 */

 timer3 */

 timer4 */

 timer5 */

 timer6 */

 timer7 */

 timer8 */

 timer9 */

 timer10 */

 timer11 */

 timer12 */

 wd_timer2 */

 UART1 */

 UART2 */

 UART3 */

 dss */

	/*

	 * The DSS HW needs all DSS clocks enabled during reset. The dss_core

	 * driver does not use these clocks.

 instead of dss_fck */

 gpio1 */

 gpio2 */

 gpio3 */

 gpio4 */

 mcspi1 */

 mcspi2 */

 gpmc */

 Skip reset for CONFIG_OMAP_GPMC_DEBUG for bootloader timings */

 RNG */

	/*

	 * XXX The first read from the SYSSTATUS register of the RNG

	 * after the SYSCONFIG SOFTRESET bit is set triggers an

	 * imprecise external abort.  It's unclear why this happens.

	 * Until this is analyzed, skip the IP block reset.

 SHAM */

 AES */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * DRA7xx Clock domains framework

 *

 * Copyright (C) 2009-2013 Texas Instruments, Inc.

 * Copyright (C) 2009-2011 Nokia Corporation

 *

 * Generated by code originally written by:

 * Abhijit Pagare (abhijitpagare@ti.com)

 * Benoit Cousson (b-cousson@ti.com)

 * Paul Walmsley (paul@pwsan.com)

 *

 * This file is automatically generated from the OMAP hardware databases.

 * We respectfully ask that any modifications to this file be coordinated

 * with the public linux-omap@vger.kernel.org mailing list and the

 * authors above to ensure that the autogeneration scripts are kept

 * up-to-date with the file contents.

 Static Dependencies for DRA7xx Clock Domains */

 As clockdomains are added or removed above, this list must also be changed */

/*

 * DM81xx hwmod data.

 *

 * Copyright (C) 2010 Texas Instruments, Inc. - https://www.ti.com/

 * Copyright (C) 2013 SKTB SKiT, http://www.skitlab.ru/

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 *

/*

 * DM816X hardware modules integration data

 *

 * Note: This is incomplete and at present, not generated from h/w database.

/*

 * Common alwon .clkctrl_offs from dm814x TRM "Table 2-278. CM_ALWON REGISTERS"

 * also dm816x TRM 18.7.17 CM_ALWON device register values minus 0x1400.

 Registers specific to dm814x */

 Registers specific to dm816x */

/*

 * The default .clkctrl_offs field is offset from CM_DEFAULT, that's

 * TRM 18.7.6 CM_DEFAULT device register values minus 0x500

 L3 Interconnect entries clocked at 125, 250 and 500MHz */

/*

 * L4 standard peripherals, see TRM table 1-12 for devices using this.

 * See TRM table 1-73 for devices using the 125MHz SYSCLK6 clock.

/*

 * L4 high-speed peripherals. For devices using this, please see the TRM

 * table 1-13. On dm816x, only EMAC, MDIO and SATA use this. See also TRM

 * table 1-73 for devices using 250MHz SYSCLK5 clock.

 L3 slow -> L4 ls peripheral interface running at 125MHz */

 L3 med -> L4 fast peripheral interface running at 250MHz */

 MPU */

 L3 med peripheral interface running at 200MHz */

 L3 med peripheral interface running at 250MHz */

 RTC */

 UART common */

 I2C common */

 Skip reset for CONFIG_OMAP_GPMC_DEBUG for bootloader timings */

 USB needs udelay 1 after reset at least on hp t410, use 2 for margin */

 481c5260.adpll.dcoclkldo */

 EMAC Ethernet */

/*

 * On dm816x the MDIO is within EMAC0. As the MDIO driver is a separate

 * driver probed before EMAC0, we let MDIO do the clock idling.

	/*

	 * REVISIT: This should be moved to the emac0_hwmod

	 * once we have a better way to handle device slaves.

/*

 * REVISIT: Test and enable the following once clocks work:

 * dm81xx_l4_ls__mailbox

 *

 * Also note that some devices share a single clkctrl_offs..

 * For example, i2c1 and 3 share one, and i2c2 and 4 share one.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * am33xx-restart.c - Code common to all AM33xx machines.

/**

 * am3xx_restart - trigger a software restart of the SoC

 * @mode: the "reboot mode", see arch/arm/kernel/{setup,process}.c

 * @cmd: passed from the userspace program rebooting the system (if provided)

 *

 * Resets the SoC.  For @cmd, see the 'reboot' syscall in

 * kernel/sys.c.  No return value.

 TODO: Handle mode and cmd if necessary */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OMAP2/3/4 clockdomain framework functions

 *

 * Copyright (C) 2008-2011 Texas Instruments, Inc.

 * Copyright (C) 2008-2011 Nokia Corporation

 *

 * Written by Paul Walmsley and Jouni Hgander

 * Added OMAP4 specific support by Abhijit Pagare <abhijitpagare@ti.com>

 clkdm_list contains all registered struct clockdomains */

 array of clockdomain deps to be added/removed when clkdm in hwsup mode */

 Private functions */

/**

 * _clkdm_register - register a clockdomain

 * @clkdm: struct clockdomain * to register

 *

 * Adds a clockdomain to the internal clockdomain list.

 * Returns -EINVAL if given a null pointer, -EEXIST if a clockdomain is

 * already registered by the provided name, or 0 upon success.

 Verify that the clockdomain is not already registered */

 _clkdm_deps_lookup - look up the specified clockdomain in a clkdm list */

/**

 * _autodep_lookup - resolve autodep clkdm names to clkdm pointers; store

 * @autodep: struct clkdm_autodep * to resolve

 *

 * Resolve autodep clockdomain names to clockdomain pointers via

 * clkdm_lookup() and store the pointers in the autodep structure.  An

 * "autodep" is a clockdomain sleep/wakeup dependency that is

 * automatically added and removed whenever clocks in the associated

 * clockdomain are enabled or disabled (respectively) when the

 * clockdomain is in hardware-supervised mode.	Meant to be called

 * once at clockdomain layer initialization, since these should remain

 * fixed for a particular architecture.  No return value.

 *

 * XXX autodeps are deprecated and should be removed at the earliest

 * opportunity

/**

 * _resolve_clkdm_deps() - resolve clkdm_names in @clkdm_deps to clkdms

 * @clkdm: clockdomain that we are resolving dependencies for

 * @clkdm_deps: ptr to array of struct clkdm_deps to resolve

 *

 * Iterates through @clkdm_deps, looking up the struct clockdomain named by

 * clkdm_name and storing the clockdomain pointer in the struct clkdm_dep.

 * No return value.

/**

 * _clkdm_add_wkdep - add a wakeup dependency from clkdm2 to clkdm1 (lockless)

 * @clkdm1: wake this struct clockdomain * up (dependent)

 * @clkdm2: when this struct clockdomain * wakes up (source)

 *

 * When the clockdomain represented by @clkdm2 wakes up, wake up

 * @clkdm1. Implemented in hardware on the OMAP, this feature is

 * designed to reduce wakeup latency of the dependent clockdomain @clkdm1.

 * Returns -EINVAL if presented with invalid clockdomain pointers,

 * -ENOENT if @clkdm2 cannot wake up clkdm1 in hardware, or 0 upon

 * success.

/**

 * _clkdm_del_wkdep - remove a wakeup dep from clkdm2 to clkdm1 (lockless)

 * @clkdm1: wake this struct clockdomain * up (dependent)

 * @clkdm2: when this struct clockdomain * wakes up (source)

 *

 * Remove a wakeup dependency causing @clkdm1 to wake up when @clkdm2

 * wakes up.  Returns -EINVAL if presented with invalid clockdomain

 * pointers, -ENOENT if @clkdm2 cannot wake up clkdm1 in hardware, or

 * 0 upon success.

/**

 * _clkdm_add_sleepdep - add a sleep dependency from clkdm2 to clkdm1 (lockless)

 * @clkdm1: prevent this struct clockdomain * from sleeping (dependent)

 * @clkdm2: when this struct clockdomain * is active (source)

 *

 * Prevent @clkdm1 from automatically going inactive (and then to

 * retention or off) if @clkdm2 is active.  Returns -EINVAL if

 * presented with invalid clockdomain pointers or called on a machine

 * that does not support software-configurable hardware sleep

 * dependencies, -ENOENT if the specified dependency cannot be set in

 * hardware, or 0 upon success.

/**

 * _clkdm_del_sleepdep - remove a sleep dep from clkdm2 to clkdm1 (lockless)

 * @clkdm1: prevent this struct clockdomain * from sleeping (dependent)

 * @clkdm2: when this struct clockdomain * is active (source)

 *

 * Allow @clkdm1 to automatically go inactive (and then to retention or

 * off), independent of the activity state of @clkdm2.  Returns -EINVAL

 * if presented with invalid clockdomain pointers or called on a machine

 * that does not support software-configurable hardware sleep dependencies,

 * -ENOENT if the specified dependency cannot be cleared in hardware, or

 * 0 upon success.

 Public functions */

/**

 * clkdm_register_platform_funcs - register clockdomain implementation fns

 * @co: func pointers for arch specific implementations

 *

 * Register the list of function pointers used to implement the

 * clockdomain functions on different OMAP SoCs.  Should be called

 * before any other clkdm_register*() function.  Returns -EINVAL if

 * @co is null, -EEXIST if platform functions have already been

 * registered, or 0 upon success.

/**

 * clkdm_register_clkdms - register SoC clockdomains

 * @cs: pointer to an array of struct clockdomain to register

 *

 * Register the clockdomains available on a particular OMAP SoC.  Must

 * be called after clkdm_register_platform_funcs().  May be called

 * multiple times.  Returns -EACCES if called before

 * clkdm_register_platform_funcs(); -EINVAL if the argument @cs is

 * null; or 0 upon success.

/**

 * clkdm_register_autodeps - register autodeps (if required)

 * @ia: pointer to a static array of struct clkdm_autodep to register

 *

 * Register clockdomain "automatic dependencies."  These are

 * clockdomain wakeup and sleep dependencies that are automatically

 * added whenever the first clock inside a clockdomain is enabled, and

 * removed whenever the last clock inside a clockdomain is disabled.

 * These are currently only used on OMAP3 devices, and are deprecated,

 * since they waste energy.  However, until the OMAP2/3 IP block

 * enable/disable sequence can be converted to match the OMAP4

 * sequence, they are needed.

 *

 * Must be called only after all of the SoC clockdomains are

 * registered, since the function will resolve autodep clockdomain

 * names into clockdomain pointers.

 *

 * The struct clkdm_autodep @ia array must be static, as this function

 * does not copy the array elements.

 *

 * Returns -EACCES if called before any clockdomains have been

 * registered, -EINVAL if called with a null @ia argument, -EEXIST if

 * autodeps have already been registered, or 0 upon success.

/**

 * clkdm_complete_init - set up the clockdomain layer

 *

 * Put all clockdomains into software-supervised mode; PM code should

 * later enable hardware-supervised mode as appropriate.  Must be

 * called after clkdm_register_clkdms().  Returns -EACCES if called

 * before clkdm_register_clkdms(), or 0 upon success.

 Only AM43XX can lose clkdm context during rtc-ddr suspend */

/**

 * clkdm_lookup - look up a clockdomain by name, return a pointer

 * @name: name of clockdomain

 *

 * Find a registered clockdomain by its name @name.  Returns a pointer

 * to the struct clockdomain if found, or NULL otherwise.

/**

 * clkdm_for_each - call function on each registered clockdomain

 * @fn: callback function *

 *

 * Call the supplied function @fn for each registered clockdomain.

 * The callback function @fn can return anything but 0 to bail

 * out early from the iterator.  The callback function is called with

 * the clkdm_mutex held, so no clockdomain structure manipulation

 * functions should be called from the callback, although hardware

 * clockdomain control functions are fine.  Returns the last return

 * value of the callback function, which should be 0 for success or

 * anything else to indicate failure; or -EINVAL if the function pointer

 * is null.

/**

 * clkdm_get_pwrdm - return a ptr to the pwrdm that this clkdm resides in

 * @clkdm: struct clockdomain *

 *

 * Return a pointer to the struct powerdomain that the specified clockdomain

 * @clkdm exists in, or returns NULL if @clkdm is NULL.

 Hardware clockdomain control */

/**

 * clkdm_add_wkdep - add a wakeup dependency from clkdm2 to clkdm1

 * @clkdm1: wake this struct clockdomain * up (dependent)

 * @clkdm2: when this struct clockdomain * wakes up (source)

 *

 * When the clockdomain represented by @clkdm2 wakes up, wake up

 * @clkdm1. Implemented in hardware on the OMAP, this feature is

 * designed to reduce wakeup latency of the dependent clockdomain @clkdm1.

 * Returns -EINVAL if presented with invalid clockdomain pointers,

 * -ENOENT if @clkdm2 cannot wake up clkdm1 in hardware, or 0 upon

 * success.

/**

 * clkdm_del_wkdep - remove a wakeup dependency from clkdm2 to clkdm1

 * @clkdm1: wake this struct clockdomain * up (dependent)

 * @clkdm2: when this struct clockdomain * wakes up (source)

 *

 * Remove a wakeup dependency causing @clkdm1 to wake up when @clkdm2

 * wakes up.  Returns -EINVAL if presented with invalid clockdomain

 * pointers, -ENOENT if @clkdm2 cannot wake up clkdm1 in hardware, or

 * 0 upon success.

/**

 * clkdm_read_wkdep - read wakeup dependency state from clkdm2 to clkdm1

 * @clkdm1: wake this struct clockdomain * up (dependent)

 * @clkdm2: when this struct clockdomain * wakes up (source)

 *

 * Return 1 if a hardware wakeup dependency exists wherein @clkdm1 will be

 * awoken when @clkdm2 wakes up; 0 if dependency is not set; -EINVAL

 * if either clockdomain pointer is invalid; or -ENOENT if the hardware

 * is incapable.

 *

 * REVISIT: Currently this function only represents software-controllable

 * wakeup dependencies.  Wakeup dependencies fixed in hardware are not

 * yet handled here.

 XXX It's faster to return the wkdep_usecount */

/**

 * clkdm_clear_all_wkdeps - remove all wakeup dependencies from target clkdm

 * @clkdm: struct clockdomain * to remove all wakeup dependencies from

 *

 * Remove all inter-clockdomain wakeup dependencies that could cause

 * @clkdm to wake.  Intended to be used during boot to initialize the

 * PRCM to a known state, after all clockdomains are put into swsup idle

 * and woken up.  Returns -EINVAL if @clkdm pointer is invalid, or

 * 0 upon success.

/**

 * clkdm_add_sleepdep - add a sleep dependency from clkdm2 to clkdm1

 * @clkdm1: prevent this struct clockdomain * from sleeping (dependent)

 * @clkdm2: when this struct clockdomain * is active (source)

 *

 * Prevent @clkdm1 from automatically going inactive (and then to

 * retention or off) if @clkdm2 is active.  Returns -EINVAL if

 * presented with invalid clockdomain pointers or called on a machine

 * that does not support software-configurable hardware sleep

 * dependencies, -ENOENT if the specified dependency cannot be set in

 * hardware, or 0 upon success.

/**

 * clkdm_del_sleepdep - remove a sleep dependency from clkdm2 to clkdm1

 * @clkdm1: prevent this struct clockdomain * from sleeping (dependent)

 * @clkdm2: when this struct clockdomain * is active (source)

 *

 * Allow @clkdm1 to automatically go inactive (and then to retention or

 * off), independent of the activity state of @clkdm2.  Returns -EINVAL

 * if presented with invalid clockdomain pointers or called on a machine

 * that does not support software-configurable hardware sleep dependencies,

 * -ENOENT if the specified dependency cannot be cleared in hardware, or

 * 0 upon success.

/**

 * clkdm_read_sleepdep - read sleep dependency state from clkdm2 to clkdm1

 * @clkdm1: prevent this struct clockdomain * from sleeping (dependent)

 * @clkdm2: when this struct clockdomain * is active (source)

 *

 * Return 1 if a hardware sleep dependency exists wherein @clkdm1 will

 * not be allowed to automatically go inactive if @clkdm2 is active;

 * 0 if @clkdm1's automatic power state inactivity transition is independent

 * of @clkdm2's; -EINVAL if either clockdomain pointer is invalid or called

 * on a machine that does not support software-configurable hardware sleep

 * dependencies; or -ENOENT if the hardware is incapable.

 *

 * REVISIT: Currently this function only represents software-controllable

 * sleep dependencies.	Sleep dependencies fixed in hardware are not

 * yet handled here.

 XXX It's faster to return the sleepdep_usecount */

/**

 * clkdm_clear_all_sleepdeps - remove all sleep dependencies from target clkdm

 * @clkdm: struct clockdomain * to remove all sleep dependencies from

 *

 * Remove all inter-clockdomain sleep dependencies that could prevent

 * @clkdm from idling.  Intended to be used during boot to initialize the

 * PRCM to a known state, after all clockdomains are put into swsup idle

 * and woken up.  Returns -EINVAL if @clkdm pointer is invalid, or

 * 0 upon success.

/**

 * clkdm_sleep_nolock - force clockdomain sleep transition (lockless)

 * @clkdm: struct clockdomain *

 *

 * Instruct the CM to force a sleep transition on the specified

 * clockdomain @clkdm.  Only for use by the powerdomain code.  Returns

 * -EINVAL if @clkdm is NULL or if clockdomain does not support

 * software-initiated sleep; 0 upon success.

/**

 * clkdm_sleep - force clockdomain sleep transition

 * @clkdm: struct clockdomain *

 *

 * Instruct the CM to force a sleep transition on the specified

 * clockdomain @clkdm.  Returns -EINVAL if @clkdm is NULL or if

 * clockdomain does not support software-initiated sleep; 0 upon

 * success.

/**

 * clkdm_wakeup_nolock - force clockdomain wakeup transition (lockless)

 * @clkdm: struct clockdomain *

 *

 * Instruct the CM to force a wakeup transition on the specified

 * clockdomain @clkdm.  Only for use by the powerdomain code.  Returns

 * -EINVAL if @clkdm is NULL or if the clockdomain does not support

 * software-controlled wakeup; 0 upon success.

/**

 * clkdm_wakeup - force clockdomain wakeup transition

 * @clkdm: struct clockdomain *

 *

 * Instruct the CM to force a wakeup transition on the specified

 * clockdomain @clkdm.  Returns -EINVAL if @clkdm is NULL or if the

 * clockdomain does not support software-controlled wakeup; 0 upon

 * success.

/**

 * clkdm_allow_idle_nolock - enable hwsup idle transitions for clkdm

 * @clkdm: struct clockdomain *

 *

 * Allow the hardware to automatically switch the clockdomain @clkdm

 * into active or idle states, as needed by downstream clocks.  If the

 * clockdomain has any downstream clocks enabled in the clock

 * framework, wkdep/sleepdep autodependencies are added; this is so

 * device drivers can read and write to the device.  Only for use by

 * the powerdomain code.  No return value.

/**

 * clkdm_allow_idle - enable hwsup idle transitions for clkdm

 * @clkdm: struct clockdomain *

 *

 * Allow the hardware to automatically switch the clockdomain @clkdm into

 * active or idle states, as needed by downstream clocks.  If the

 * clockdomain has any downstream clocks enabled in the clock

 * framework, wkdep/sleepdep autodependencies are added; this is so

 * device drivers can read and write to the device.  No return value.

/**

 * clkdm_deny_idle - disable hwsup idle transitions for clkdm

 * @clkdm: struct clockdomain *

 *

 * Prevent the hardware from automatically switching the clockdomain

 * @clkdm into inactive or idle states.  If the clockdomain has

 * downstream clocks enabled in the clock framework, wkdep/sleepdep

 * autodependencies are removed.  Only for use by the powerdomain

 * code.  No return value.

/**

 * clkdm_deny_idle - disable hwsup idle transitions for clkdm

 * @clkdm: struct clockdomain *

 *

 * Prevent the hardware from automatically switching the clockdomain

 * @clkdm into inactive or idle states.  If the clockdomain has

 * downstream clocks enabled in the clock framework, wkdep/sleepdep

 * autodependencies are removed.  No return value.

/**

 * clkdm_in_hwsup - is clockdomain @clkdm have hardware-supervised idle enabled?

 * @clkdm: struct clockdomain *

 *

 * Returns true if clockdomain @clkdm currently has

 * hardware-supervised idle enabled, or false if it does not or if

 * @clkdm is NULL.  It is only valid to call this function after

 * clkdm_init() has been called.  This function does not actually read

 * bits from the hardware; it instead tests an in-memory flag that is

 * changed whenever the clockdomain code changes the auto-idle mode.

/**

 * clkdm_missing_idle_reporting - can @clkdm enter autoidle even if in use?

 * @clkdm: struct clockdomain *

 *

 * Returns true if clockdomain @clkdm has the

 * CLKDM_MISSING_IDLE_REPORTING flag set, or false if not or @clkdm is

 * null.  More information is available in the documentation for the

 * CLKDM_MISSING_IDLE_REPORTING macro.

 Public autodep handling functions (deprecated) */

/**

 * clkdm_add_autodeps - add auto sleepdeps/wkdeps to clkdm upon clock enable

 * @clkdm: struct clockdomain *

 *

 * Add the "autodep" sleep & wakeup dependencies to clockdomain 'clkdm'

 * in hardware-supervised mode.  Meant to be called from clock framework

 * when a clock inside clockdomain 'clkdm' is enabled.	No return value.

 *

 * XXX autodeps are deprecated and should be removed at the earliest

 * opportunity

/**

 * clkdm_del_autodeps - remove auto sleepdeps/wkdeps from clkdm

 * @clkdm: struct clockdomain *

 *

 * Remove the "autodep" sleep & wakeup dependencies from clockdomain 'clkdm'

 * in hardware-supervised mode.  Meant to be called from clock framework

 * when a clock inside clockdomain 'clkdm' is disabled.  No return value.

 *

 * XXX autodeps are deprecated and should be removed at the earliest

 * opportunity

 Clockdomain-to-clock/hwmod framework interface code */

/**

 * clkdm_clk_enable - add an enabled downstream clock to this clkdm

 * @clkdm: struct clockdomain *

 * @clk: struct clk * of the enabled downstream clock

 *

 * Increment the usecount of the clockdomain @clkdm and ensure that it

 * is awake before @clk is enabled.  Intended to be called by

 * clk_enable() code.  If the clockdomain is in software-supervised

 * idle mode, force the clockdomain to wake.  If the clockdomain is in

 * hardware-supervised idle mode, add clkdm-pwrdm autodependencies, to

 * ensure that devices in the clockdomain can be read from/written to

 * by on-chip processors.  Returns -EINVAL if passed null pointers;

 * returns 0 upon success or if the clockdomain is in hwsup idle mode.

	/*

	 * For arch's with no autodeps, clkcm_clk_enable

	 * should be called for every clock instance or hwmod that is

	 * enabled, so the clkdm can be force woken up.

/**

 * clkdm_clk_disable - remove an enabled downstream clock from this clkdm

 * @clkdm: struct clockdomain *

 * @clk: struct clk * of the disabled downstream clock

 *

 * Decrement the usecount of this clockdomain @clkdm when @clk is

 * disabled.  Intended to be called by clk_disable() code.  If the

 * clockdomain usecount goes to 0, put the clockdomain to sleep

 * (software-supervised mode) or remove the clkdm autodependencies

 * (hardware-supervised mode).  Returns -EINVAL if passed null

 * pointers; -ERANGE if the @clkdm usecount underflows; or returns 0

 * upon success or if the clockdomain is in hwsup idle mode.

 corner case: disabling unused clocks */

 underflow */

/**

 * clkdm_hwmod_enable - add an enabled downstream hwmod to this clkdm

 * @clkdm: struct clockdomain *

 * @oh: struct omap_hwmod * of the enabled downstream hwmod

 *

 * Increment the usecount of the clockdomain @clkdm and ensure that it

 * is awake before @oh is enabled. Intended to be called by

 * module_enable() code.

 * If the clockdomain is in software-supervised idle mode, force the

 * clockdomain to wake.  If the clockdomain is in hardware-supervised idle

 * mode, add clkdm-pwrdm autodependencies, to ensure that devices in the

 * clockdomain can be read from/written to by on-chip processors.

 * Returns -EINVAL if passed null pointers;

 * returns 0 upon success or if the clockdomain is in hwsup idle mode.

 The clkdm attribute does not exist yet prior OMAP4 */

	/*

	 * XXX Rewrite this code to maintain a list of enabled

	 * downstream hwmods for debugging purposes?

/**

 * clkdm_hwmod_disable - remove an enabled downstream hwmod from this clkdm

 * @clkdm: struct clockdomain *

 * @oh: struct omap_hwmod * of the disabled downstream hwmod

 *

 * Decrement the usecount of this clockdomain @clkdm when @oh is

 * disabled. Intended to be called by module_disable() code.

 * If the clockdomain usecount goes to 0, put the clockdomain to sleep

 * (software-supervised mode) or remove the clkdm autodependencies

 * (hardware-supervised mode).

 * Returns -EINVAL if passed null pointers; -ERANGE if the @clkdm usecount

 * underflows; or returns 0 upon success or if the clockdomain is in hwsup

 * idle mode.

 The clkdm attribute does not exist yet prior OMAP4 */

/**

 * _clkdm_save_context - save the context for the control of this clkdm

 *

 * Due to a suspend or hibernation operation, the state of the registers

 * controlling this clkdm will be lost, save their context.

/**

 * _clkdm_restore_context - restore context for control of this clkdm

 *

 * Restore the register values for this clockdomain.

/**

 * clkdm_save_context - Saves the context for each registered clkdm

 *

 * Save the context for each registered clockdomain.

/**

 * clkdm_restore_context - Restores the context for each registered clkdm

 *

 * Restore the context for each registered clockdomain.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2016 Neil Armstrong <narmstrong@baylibre.com>

 * Copyright (C) 2013 Ma Haijun <mahaijuns@gmail.com>

 * Copyright (C) 2002 ARM Ltd.

 * All Rights Reserved

	/*

	 * Write the address of secondary startup into the

	 * system-wide flags register. The BootMonitor waits

	 * until it receives a soft interrupt, and then the

	 * secondary CPU branches to this address.

	/*

	 * Enable GIC cpu interface in CPU Interface Control Register

	/*

	 * Send the secondary CPU a soft interrupt, thereby causing

	 * the boot monitor to read the system wide flags register,

	 * and branch to the address found there.

 Remap CPU Interrupt Interface Registers */

 SPDX-License-Identifier: GPL-2.0-or-later

 Copyright (C) ASPEED Technology Inc.

 Copyright IBM Corp.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) Maxime Coquelin 2015

 * Copyright (C) STMicroelectronics 2017

 * Author:  Maxime Coquelin <mcoquelin.stm32@gmail.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for Compaq iPAQ H3100 and H3600 handheld computers (common code)

 *

 * Copyright (c) 2000,1 Compaq Computer Corporation. (Author: Jamey Hicks)

 * Copyright (c) 2009 Dmitry Artamonow <mad_soft@inbox.ru>

/*

 * H3xxx flash support

 force read-only */

/*

 * H3xxx uart support

/*

 * Enable/Disable wake up events for this serial port.

 * Obviously, we only support this on the normal COM port.

 DCD and CTS */

 DCD and CTS */

/*

 * EGPIO

 H3XXX_EGPIO_RS232_ON */

/*

 * GPIO keys

 static memory bank 2  CS#2 */

 static memory bank 4  CS#4 */

 EGPIO 0		CS#5 */

/*

 * Common map_io initialization

 Common serial port */

	sa1100_register_uart(1, 1); /* Microcontroller on 3100/3600 */

 Ensure those pins are outputs and driving low  */

 Configure suspend conditions */

 All outputs are set low by default */

 Configure all GPIOs as input */

/*

 * SA1100 Power Management Routines

 *

 * Copyright (c) 2001 Cliff Brake <cbrake@accelent.com>

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License.

 *

 * History:

 *

 * 2001-02-06:	Cliff Brake         Initial code

 *

 * 2001-02-25:	Sukjae Cho <sjcho@east.isi.edu> &

 * 		Chester Kuo <chester@linux.org.tw>

 * 			Save more value for the resume function! Support

 * 			Bitsy/Assabet/Freebird board

 *

 * 2001-08-29:	Nicolas Pitre <nico@fluxnic.net>

 * 			Cleaned up, pushed platform dependent stuff

 * 			in the platform specific files.

 *

 * 2002-05-27:	Nicolas Pitre	Killed sleep.h and the kmalloced save array.

 * 				Storage is local on the stack now.

/*

 * List of global SA11x0 peripheral registers to preserve.

 * More ones like CP and general purpose register values are preserved

 * on the stack and then the stack pointer is stored last in sleep.S.

 save vital registers */

 Clear previous reset status */

 set resume return address */

 go zzz */

	/*

	 * Ensure not to come back here if it wasn't intended

	/*

	 * Ensure interrupt sources are disabled; we will re-init

	 * the interrupt subsystem via the device manager.

 restore registers */

	/*

	 * Clear the peripheral sleep-hold bit.

 SPDX-License-Identifier: GPL-2.0

/*

 * linux/arch/arm/mach-sa1100/lart.c

 main flash memory */

 main flash, alternative location */

 LEDs */

 SPDX-License-Identifier: GPL-2.0

/*

 *  linux/arch/arm/mach-sa1100/clock.c

	/*

	 * First, set up the 3.6864MHz clock on GPIO 27 for the SA-1111:

	 * (SA-1110 Developer's Manual, section 9.1.2.1)

/*

 * Derived from the table 8-1 in the SA1110 manual, the MPLL appears to

 * multiply its input rate by 4 x (4 + PPCR).  This calculation gives

 * the exact rate.  The figures given in the table are the rates rounded

 * to 100kHz.  Stick with sa11x0_getspeed() for the time being.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-sa1100/hackkit.c

 *

 * Copyright (C) 2002 Stefan Eletzhofer <stefan.eletzhofer@eletztrick.de>

 *

 * This file contains all HackKit tweaks. Based on original work from

 * Nicolas Pitre's assabet fixes

/**********************************************************************

 *  prototypes

 init funcs */

/**********************************************************************

 *  global data

/**********************************************************************

 *  static data

 Flash bank 0 */

/**********************************************************************

 *  Static functions

 com port */

 radio module */

/**

 *	hackkit_uart_pm - powermgmt callback function for system 3 UART

 *	@port: uart port structure

 *	@state: pm state

 *	@oldstate: old pm state

 *

 TODO: switch on/off uart in powersave mode */

 force read-only */

 LEDs */

/**********************************************************************

 *  Exported Functions

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for Compaq iPAQ H3100 handheld computer

 *

 * Copyright (c) 2000,1 Compaq Computer Corporation. (Author: Jamey Hicks)

 * Copyright (c) 2009 Dmitry Artamonow <mad_soft@inbox.ru>

/*

 * helper for sa1100fb

	/* Older bootldrs put GPIO2-9 in alternate mode on the

/*

 * This turns the IRDA power on or off on the Compaq H3100

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-sa1100/cerf.c

 *

 * Apr-2003 : Removed some old PDA crud [FB]

 * Oct-2003 : Added uart2 resource [FB]

 * Jan-2004 : Removed io map for flash [FB]

 Compact Flash */

 LEDs */

 Crystal Ethernet Chip */

 disable this and the uart2 device for sa1100_fir */

 Maintainer: support@intrinsyc.com */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-sa1100/badge4.c

 *

 * BadgePAD 4 specific initialization

 *

 *   Tim Connors <connors@hpl.hp.com>

 *   Christopher Hoover <ch@hpl.hp.com>

 *

 * Copyright (C) 2002 Hewlett-Packard Company

 LEDs */

	/*

	 * Ensure that the memory bus request/grant signals are setup,

	 * and the grant is held in its inactive state

	/*

	 * Probe for SA1111.

/*

 * 1 x Intel 28F320C3 Advanced+ Boot Block Flash (32 Mi bit)

 *   Eight 4 KiW Parameter Bottom Blocks (64 KiB)

 *   Sixty-three 32 KiW Main Blocks (4032 Ki b)

 *

 * <or>

 *

 * 1 x Intel 28F640C3 Advanced+ Boot Block Flash (64 Mi bit)

 *   Eight 4 KiW Parameter Bottom Blocks (64 KiB)

 *   One-hundred-twenty-seven 32 KiW Main Blocks (8128 Ki b)

 LCD */

 SDRAM SPD i2c */

 uart */

 CPLD muxsel0 input for mux/adc chip select */

 test points: J5, J6 as inputs, J7 outputs */

 5V supply rail. */

 initially off */

 CPLD sdram type inputs; set up by blob */

GPDR |= (BADGE4_GPIO_SDTYP1 | BADGE4_GPIO_SDTYP0);

 SA1111 reset pin; set up by blob */

GPSR  = BADGE4_GPIO_SA1111_NRST;

GPDR |= BADGE4_GPIO_SA1111_NRST;

 power management cruft */

 wake up on an edge from TESTPT_J5 */

 wake up if rtc fires */

 drive sa1111_nrst during sleep */

 drive CPLD as is during sleep */

 Now bring up the SA-1111. */

 maybe turn on 5v0 from the start */

 detect on->off and off->on transitions */

 was off, now on */

 was on, now off */

 SRAM  bank 1 */

 SRAM  bank 2 */

 SPDX-License-Identifier: GPL-2.0

/*

 * linux/arch/arm/mach-sa1100/simpad.c

/*

 * CS3 support

 MQ200 */

 Simpad CS3 */

 Initialize CS3 */

 Spinlocks not yet initialized */

 serial interface */

 DECT             */

 Reassign UART 1 pins

	/*

	 * Set up registers for sleep mode.

 Bypass spinlock here */

 disable internal oscillator, float CS lines */

 enable wake-up on GPIO0 */

	/*

	 * set scratchpad to zero, just in case it is used as a

	 * restart address by the bootloader.

 enter sleep mode */

 we won't ever call it */

/*

 * gpio_keys

/*

 * GPIO LEDs

/*

 * i2c

/*

 * MediaQ Video Device

 Compact Flash */

 Maintainer: Holger Freyther */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-sa1100/generic.c

 *

 * Author: Nicolas Pitre

 *

 * Code common to all SA11x0 machines.

/*

 * This table is setup for a 3.6864MHz Crystal.

  59.0 MHz */},

  73.7 MHz */},

  88.5 MHz */},

 103.2 MHz */},

 118.0 MHz */},

 132.7 MHz */},

 147.5 MHz */},

 162.2 MHz */},

 176.9 MHz */},

 191.7 MHz */},

 206.4 MHz */},

 221.2 MHz */},

 235.9 MHz */},

 250.7 MHz */},

 265.4 MHz */},

 280.2 MHz */},

/*

 * Default power-off for SA1100

 disable internal oscillator, float CS lines */

 enable wake-up on GPIO0 (Assabet...) */

	/*

	 * set scratchpad to zero, just in case it is used as a

	 * restart address by the bootloader.

 enter sleep mode */

 Jump into ROM at address 0 */

 Use on-chip reset capability */

 Setup the PPC unit for the MCP */

/*

 * Common I/O mapping:

 *

 * Typically, static virtual address mappings are as follow:

 *

 * 0xf0000000-0xf3ffffff:	miscellaneous stuff (CPLDs, etc.)

 * 0xf4000000-0xf4ffffff:	SA-1111

 * 0xf5000000-0xf5ffffff:	reserved (used by cache flushing area)

 * 0xf6000000-0xfffeffff:	reserved (internal SA1100 IO defined above)

 * 0xffff0000-0xffff0fff:	SA1100 exception vectors

 * 0xffff2000-0xffff2fff:	Minicache copy_user_page area

 *

 * Below 0xe8000000 is reserved for vm allocation.

 *

 * The machine specific code must provide the extra mapping beside the

 * default mapping provided here.

 PCM */

 SCM */

 MER */

 LCD + DMA */

/*

 * Disable the memory bus request/grant signals on the SA1110 to

 * ensure that we don't receive spurious memory requests.  We set

 * the MBGNT signal false to ensure the SA1111 doesn't own the

 * SDRAM bus.

/*

 * If the system is going to use the SA-1111 DMA engines, set up

 * the memory bus request/grant pins.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-sa1100/nanoengine.c

 *

 * Bright Star Engineering's nanoEngine board init code.

 *

 * Copyright (C) 2010 Marcelo Roberto Jimenez <mroberto@cpti.cetuc.puc-rio.br>

 Flash bank 0 */

 32K */

 System Registers */

 Internal PCI Memory Read/Write */

 Internal PCI Config Space */

 disable IRDA -- UART2 is used as a normal serial port */

 SPDX-License-Identifier: GPL-2.0-only

/**

 *  arch/arm/mac-sa1100/jornada720_ssp.c

 *

 *  Copyright (C) 2006/2007 Kristoffer Ericson <Kristoffer.Ericson@gmail.com>

 *   Copyright (C) 2006 Filip Zyzniewski <filip.zyzniewski@tefnet.pl>

 *

 *  SSP driver for the HP Jornada 710/720/728

/**

 * jornada_ssp_reverse - reverses input byte

 *

 * we need to reverse all data we receive from the mcu due to its physical location

 * returns : 01110111 -> 11101110

/**

 * jornada_ssp_byte - waits for ready ssp bus and sends byte

 *

 * waits for fifo buffer to clear and then transmits, if it doesn't then we will

 * timeout after <timeout> rounds. Needs mcu running before its called.

 *

 * returns : %mcu output on success

 *	   : %-ETIMEDOUT on timeout

/**

 * jornada_ssp_inout - decide if input is command or trading byte

 *

 * returns : (jornada_ssp_byte(byte)) on success

 *         : %-ETIMEDOUT on timeout failure

 true means command byte */

 Proper return to commands is TxDummy */

 flushing bus */

 Exchange TxDummy for data */

/**

 * jornada_ssp_start - enable mcu

 *

/**

 * jornada_ssp_end - disable mcu and turn off lock

 *

 worked fine, lets not bother with anything else */

 init of Serial 4 port */

 clear out any left over data */

 enable MCU */

 see if return value makes sense */

 seems like it worked, just feed it with TxDummy to get rid of data */

 failed, lets just kill everything */

 all fine */

	/* Note that this doesn't actually remove the driver, since theres nothing to remove

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * linux/arch/arm/mach-sa1100/pci-nanoengine.c

 *

 * PCI functions for BSE nanoEngine PCI

 *

 * Copyright (C) 2010 Marcelo Roberto Jimenez <mroberto@cpti.cetuc.puc-rio.br>

	/* nanoEngine documentation says there is a 1 Megabyte window here,

	.end	= NANO_PCI_MEM_RW_PHYS + SZ_128K + SZ_8K - 1,*/

/*

 * nanoEngine PCI reports 1 Megabyte of prefetchable memory, but it

 * overlaps with previously defined memory.

 *

 * Here is what happens:

 *

# dmesg

...

pci 0000:00:00.0: [8086:1209] type 0 class 0x000200

pci 0000:00:00.0: reg 10: [mem 0x00021000-0x00021fff]

pci 0000:00:00.0: reg 14: [io  0x0000-0x003f]

pci 0000:00:00.0: reg 18: [mem 0x00000000-0x0001ffff]

pci 0000:00:00.0: reg 30: [mem 0x00000000-0x000fffff pref]

pci 0000:00:00.0: supports D1 D2

pci 0000:00:00.0: PME# supported from D0 D1 D2 D3hot

pci 0000:00:00.0: PME# disabled

PCI: bus0: Fast back to back transfers enabled

pci 0000:00:00.0: BAR 6: can't assign mem pref (size 0x100000)

pci 0000:00:00.0: BAR 2: assigned [mem 0x18600000-0x1861ffff]

pci 0000:00:00.0: BAR 2: set to [mem 0x18600000-0x1861ffff] (PCI address [0x0-0x1ffff])

pci 0000:00:00.0: BAR 0: assigned [mem 0x18620000-0x18620fff]

pci 0000:00:00.0: BAR 0: set to [mem 0x18620000-0x18620fff] (PCI address [0x20000-0x20fff])

pci 0000:00:00.0: BAR 1: assigned [io  0x0400-0x043f]

pci 0000:00:00.0: BAR 1: set to [io  0x0400-0x043f] (PCI address [0x0-0x3f])

 *

 * On the other hand, if we do not request the prefetchable memory resource,

 * linux will alloc it first and the two non-prefetchable memory areas that

 * are our real interest will not be mapped. So we choose to map it to an

 * unused area. It gets recognized as expansion ROM, but becomes disabled.

 *

 * Here is what happens then:

 *

# dmesg

...

pci 0000:00:00.0: [8086:1209] type 0 class 0x000200

pci 0000:00:00.0: reg 10: [mem 0x00021000-0x00021fff]

pci 0000:00:00.0: reg 14: [io  0x0000-0x003f]

pci 0000:00:00.0: reg 18: [mem 0x00000000-0x0001ffff]

pci 0000:00:00.0: reg 30: [mem 0x00000000-0x000fffff pref]

pci 0000:00:00.0: supports D1 D2

pci 0000:00:00.0: PME# supported from D0 D1 D2 D3hot

pci 0000:00:00.0: PME# disabled

PCI: bus0: Fast back to back transfers enabled

pci 0000:00:00.0: BAR 6: assigned [mem 0x78000000-0x780fffff pref]

pci 0000:00:00.0: BAR 2: assigned [mem 0x18600000-0x1861ffff]

pci 0000:00:00.0: BAR 2: set to [mem 0x18600000-0x1861ffff] (PCI address [0x0-0x1ffff])

pci 0000:00:00.0: BAR 0: assigned [mem 0x18620000-0x18620fff]

pci 0000:00:00.0: BAR 0: set to [mem 0x18620000-0x18620fff] (PCI address [0x20000-0x20fff])

pci 0000:00:00.0: BAR 1: assigned [io  0x0400-0x043f]

pci 0000:00:00.0: BAR 1: set to [io  0x0400-0x043f] (PCI address [0x0-0x3f])



# lspci -vv -s 0000:00:00.0

00:00.0 Class 0200: Device 8086:1209 (rev 09)

        Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- DisINTx-

        Status: Cap+ 66MHz- UDF- FastB2B+ ParErr- DEVSEL=medium >TAbort- <TAbort- <MAbort- >SERR+ <PERR+ INTx-

        Latency: 0 (2000ns min, 14000ns max), Cache Line Size: 32 bytes

        Interrupt: pin A routed to IRQ 0

        Region 0: Memory at 18620000 (32-bit, non-prefetchable) [size=4K]

        Region 1: I/O ports at 0400 [size=64]

        Region 2: [virtual] Memory at 18600000 (32-bit, non-prefetchable) [size=128K]

        [virtual] Expansion ROM at 78000000 [disabled] [size=1M]

        Capabilities: [dc] Power Management version 2

                Flags: PMEClk- DSI+ D1+ D2+ AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-)

                Status: D0 NoSoftRst- PME-Enable- DSel=0 DScale=2 PME-

        Kernel driver in use: e100

        Kernel modules: e100

 *

		/* Enable alternate memory bus master mode, see

		 * "Intel StrongARM SA1110 Developer's Manual",

 SPDX-License-Identifier: GPL-2.0

/*

 * linux/arch/arm/mach-sa1100/pleb.c

/*

 * Ethernet IRQ mappings

 Ethernet 0 in PCMCIA0 IO */

 Autoprobe instead, to get rising/falling edge characteristic right */

/*

 * Pleb's memory map

 * has flash memory (typically 4 or 8 meg) selected by

 * the two SA1100 lowest chip select outputs.

	/*

	 * Fix expansion memory timing for network card

	/*

	 * Enable the SMC ethernet controller

 set to output */

 clear MCLK (enable smc) */

/*

 * linux/arch/arm/mach-sa1100/collie.c

 *

 * May be copied or modified under the terms of the GNU General Public

 * License.  See linux/COPYING for more information.

 *

 * This file contains all Collie-specific tweaks.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License version 2 as

 * published by the Free Software Foundation.

 *

 * ChangeLog:

 *  2006 Pavel Machek <pavel@ucw.cz>

 *  03-06-2004 John Lenz <lenz@cs.wisc.edu>

 *  06-04-2002 Chris Larson <kergoth@digitalnemesis.net>

 *  04-16-2001 Lineo Japan,Inc. ...

 Battery management GPIOs */

 the MCP codec mcp0 has the ucb1x00 as attached device */

 This is found on the main GPIO on the SA1100 */

		/*

		 * This is GPIO 0 on the Scoop expander, which is registered

		 * from common/scoop.c with this gpio chip label.

/*

 * Collie AC IN

/*

 * low-level UART features.

 cpu initialize */

 32M main flash (cs0) */

 32M boot flash (cs1) */

 SPDX-License-Identifier: GPL-2.0

/*

 * linux/arch/arm/mach-sa1100/shannon.c

 reset the codec */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-sa1100/ssp.c

 *

 *  Copyright (C) 2003 Russell King.

 *

 *  Generic SSP driver.  This provides the generic core for simple

 *  IO-based SSP applications.

/**

 * ssp_write_word - write a word to the SSP port

 * @data: 16-bit, MSB justified data to write.

 *

 * Wait for a free entry in the SSP transmit FIFO, and write a data

 * word to the SSP port.  Wait for the SSP port to start sending

 * the data.

 *

 * The caller is expected to perform the necessary locking.

 *

 * Returns:

 *   %-ETIMEDOUT	timeout occurred

 *   0			success

/**

 * ssp_read_word - read a word from the SSP port

 *

 * Wait for a data word in the SSP receive FIFO, and return the

 * received data.  Data is LSB justified.

 *

 * Note: Currently, if data is not expected to be received, this

 * function will wait for ever.

 *

 * The caller is expected to perform the necessary locking.

 *

 * Returns:

 *   %-ETIMEDOUT	timeout occurred

 *   16-bit data	success

/**

 * ssp_flush - flush the transmit and receive FIFOs

 *

 * Wait for the SSP to idle, and ensure that the receive FIFO

 * is empty.

 *

 * The caller is expected to perform the necessary locking.

 *

 * Returns:

 *   %-ETIMEDOUT	timeout occurred

 *   0			success

/**

 * ssp_enable - enable the SSP port

 *

 * Turn on the SSP port.

/**

 * ssp_disable - shut down the SSP port

 *

 * Turn off the SSP port, optionally powering it down.

/**

 * ssp_save_state - save the SSP configuration

 * @ssp: pointer to structure to save SSP configuration

 *

 * Save the configured SSP state for suspend.

/**

 * ssp_restore_state - restore a previously saved SSP configuration

 * @ssp: pointer to configuration saved by ssp_save_state

 *

 * Restore the SSP configuration saved previously by ssp_save_state.

/**

 * ssp_init - setup the SSP port

 *

 * initialise and claim resources for the SSP port.

 *

 * Returns:

 *   %-ENODEV	if the SSP port is unavailable

 *   %-EBUSY	if the resources are already in use

 *   %0		on success

/**

 * ssp_exit - undo the effects of ssp_init

 *

 * release and free resources for the SSP port.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for Compaq iPAQ H3600 handheld computer

 *

 * Copyright (c) 2000,1 Compaq Computer Corporation. (Author: Jamey Hicks)

 * Copyright (c) 2009 Dmitry Artamonow <mad_soft@inbox.ru>

/*

 * helper for sa1100fb

/*

 * This turns the IRDA power on or off on the Compaq H3600

 SPDX-License-Identifier: GPL-2.0

/*

 * linux/arch/arm/mach-sa1100/neponset.c

/*

 * Install handler for Neponset IRQ.  Note that we have to loop here

 * since the ETHERNET and USAR IRQs are level based, and we need to

 * ensure that the IRQ signal is deasserted before returning.  This

 * is rather unfortunate.

		/*

		 * Acknowledge the parent IRQ.

		/*

		 * Read the interrupt reason register.  Let's have all

		 * active IRQ bits high.  Note: there is a typo in the

		 * Neponset user's guide for the SA1111 IRR level.

		/*

		 * Since there is no individual mask, we have to

		 * mask the parent IRQ.  This is safe, since we'll

		 * recheck the register for any pending IRQs.

			/*

			 * Ack the interrupt now to prevent re-entering

			 * this neponset handler.  Again, this is safe

			 * since we'll check the IRR register prior to

			 * leaving.

 Yes, we really do not have any kind of masking or unmasking */

 Disable GPIO 0/1 drivers so the buttons work on the Assabet */

	/*

	 * We would set IRQ_GPIO25 to be a wake-up IRQ, but unfortunately

	 * something on the Neponset activates this IRQ on sleep (eth?)

 Ensure that the memory bus request/grant signals are setup */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-sa1100/jornada720.c

 *

 * HP Jornada720 init code

 *

 * Copyright (C) 2007 Kristoffer Ericson <Kristoffer.Ericson@gmail.com>

 * Copyright (C) 2006 Filip Zyzniewski <filip.zyzniewski@tefnet.pl>

 *  Copyright (C) 2005 Michael Gernoth <michael@gernoth.net>

/*

 * HP Documentation referred in this file:

 * http://www.jlime.com/downloads/development/docs/jornada7xx/jornada720.txt

 line 110 of HP's doc */

 memory space (line 52 of HP's doc) */

 512kB framebuffer */

 line 344 of HP's doc */

 Miscellaneous Register

 Display Mode Register

 General IO Pins Configuration Register 0

 General IO Pins Configuration Register 1

 General IO Pins Control Register 0

 General IO Pins Control Register 1

 Memory Clock Configuration Register

 LCD Pixel Clock Configuration Register

 CRT/TV Pixel Clock Configuration Register

 MediaPlug Clock Configuration Register

 CPU To Memory Wait State Select Register

 Memory Configuration Register

 DRAM Refresh Rate Register

 DRAM Timings Control Register 0

 DRAM Timings Control Register 1

 Panel Type Register

 MOD Rate Register

 LCD Horizontal Display Width Register

 LCD Horizontal Non-Display Period Register

 TFT FPLINE Start Position Register

 TFT FPLINE Pulse Width Register

 LCD Vertical Display Height Register 0

 LCD Vertical Display Height Register 1

 LCD Vertical Non-Display Period Register

 TFT FPFRAME Start Position Register

 TFT FPFRAME Pulse Width Register

 LCD Display Mode Register (2:4bpp,3:8bpp,5:16bpp)

 LCD Miscellaneous Register

 LCD Display Start Address Register 0

 LCD Display Start Address Register 1

 LCD Display Start Address Register 2

 LCD Memory Address Offset Register 0

 LCD Memory Address Offset Register 1

 LCD Pixel Panning Register

 LCD Display FIFO High Threshold Control Register

 LCD Display FIFO Low Threshold Control Register

 CRT/TV Horizontal Display Width Register

 CRT/TV Horizontal Non-Display Period Register

 CRT/TV HRTC Start Position Register

 CRT/TV HRTC Pulse Width Register

 CRT/TV Vertical Display Height Register 0

 CRT/TV Vertical Display Height Register 1

 CRT/TV Vertical Non-Display Period Register

 CRT/TV VRTC Start Position Register

 CRT/TV VRTC Pulse Width Register

 TV Output Control Register

 CRT/TV Display Mode Register (2:4bpp,3:8bpp,5:16bpp)

 CRT/TV Display Start Address Register 0

 CRT/TV Display Start Address Register 1

 CRT/TV Display Start Address Register 2

 CRT/TV Memory Address Offset Register 0

 CRT/TV Memory Address Offset Register 1

 CRT/TV Pixel Panning Register

 CRT/TV Display FIFO High Threshold Control Register

 CRT/TV Display FIFO Low Threshold Control Register

 LCD Ink/Cursor Control Register

 LCD Ink/Cursor Start Address Register

 LCD Cursor X Position Register 0

 LCD Cursor X Position Register 1

 LCD Cursor Y Position Register 0

 LCD Cursor Y Position Register 1

 LCD Ink/Cursor Blue Color 0 Register

 LCD Ink/Cursor Green Color 0 Register

 LCD Ink/Cursor Red Color 0 Register

 LCD Ink/Cursor Blue Color 1 Register

 LCD Ink/Cursor Green Color 1 Register

 LCD Ink/Cursor Red Color 1 Register

 LCD Ink/Cursor FIFO Threshold Register

 CRT/TV Ink/Cursor Control Register

 CRT/TV Ink/Cursor Start Address Register

 CRT/TV Cursor X Position Register 0

 CRT/TV Cursor X Position Register 1

 CRT/TV Cursor Y Position Register 0

 CRT/TV Cursor Y Position Register 1

 CRT/TV Ink/Cursor Blue Color 0 Register

 CRT/TV Ink/Cursor Green Color 0 Register

 CRT/TV Ink/Cursor Red Color 0 Register

 CRT/TV Ink/Cursor Blue Color 1 Register

 CRT/TV Ink/Cursor Green Color 1 Register

 CRT/TV Ink/Cursor Red Color 1 Register

 CRT/TV Ink/Cursor FIFO Threshold Register

 BitBlt Control Register 0

 BitBlt Control Register 1

 BitBlt ROP Code/Color Expansion Register

 BitBlt Operation Register

 BitBlt Source Start Address Register 0

 BitBlt Source Start Address Register 1

 BitBlt Source Start Address Register 2

 BitBlt Destination Start Address Register 0

 BitBlt Destination Start Address Register 1

 BitBlt Destination Start Address Register 2

 BitBlt Memory Address Offset Register 0

 BitBlt Memory Address Offset Register 1

 BitBlt Width Register 0

 BitBlt Width Register 1

 BitBlt Height Register 0

 BitBlt Height Register 1

 BitBlt Background Color Register 0

 BitBlt Background Color Register 1

 BitBlt Foreground Color Register 0

 BitBlt Foreground Color Register 1

 Look-Up Table Mode Register

 Look-Up Table Address Register

 not sure, wouldn't like to mess with the driver */

 Look-Up Table Data Register

 jornada doc says 0x00, but I trust the driver */

 Power Save Configuration Register

 Power Save Status Register

 CPU-to-Memory Access Watchdog Timer Register

 Display Mode Register(0x01:LCD, 0x02:CRT, 0x03:LCD&CRT)

 we want to use gpio20 as input to drive the clock of our uart 3 */

 Clear gpio20 pin as input */

 start gpio20 pin */

 stop gpio20 */

 restart gpio20 */

 give it some time to restart */

 Epson registers */

 Epson frame buffer */

 force read-only */

 will expand to the end of the flash */

 enabling flash write (line 470 of HP's doc) */

 disabling flash write (line 470 of HP's doc) */

 Maintainer: Kristoffer Ericson <Kristoffer.Ericson@gmail.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-sa1100/assabet.c

 *

 * Author: Nicolas Pitre

 *

 * This file contains all Assabet-specific tweaks.

 The old deprecated interface */

/*

 * The codec reset goes to three devices, so we need to release

 * the rest when any one of these requests it.  However, that

 * causes the ADV7171 to consume around 100mA - more than half

 * the LCD-blanked power.

 *

 * With the ADV7171, LCD and backlight enabled, we go over

 * budget on the MAX846 Li-Ion charger, and if no Li-Ion battery

 * is connected, the Assabet crashes.

 clear L3 mode to ensure UDA1341 doesn't respond */

 Restore GPIO state for L3 bus */

 Put the ADV7171 into sleep mode */

/*

 * Assabet flash support code.

/*

 * Phase 4 Assabet has two 28F160B3 flash parts in bank 0:

/*

 * Phase 5 Assabet has two 28F128J3A flash parts in bank 0:

/*

 * Assabet IrDA support code.

 phase 4 or newer Assabet's

 older Assabet's

/*

 * Turn on/off the backlight.  When turning the backlight on, we wait

 * 500us after turning it on so we don't cause the supplies to droop

 * when we enable the LCD controller (and cause a hard reset.)

/*

 * The assabet uses a sharp LQ039Q2DS54 LCD module.  It is actually

 * takes an RGB666 signal, but we provide it with an RGB565 signal

 * instead (def_rgb_16).

	/*

	 * Ensure that the power supply is in "high power" mode.

	/*

	 * Ensure that these pins are set as outputs and are driving

	 * logic 0.  This ensures that we won't inadvertently toggle

	 * the WS latch in the CPLD, and we don't float causing

	 * excessive power drain.  --rmk

	/*

	 * Also set GPIO27 as an output; this is used to clock UART3

	 * via the FPGA and as otherwise has no pullups or pulldowns,

	 * so stop it floating.

	/*

	 * Set up registers for sleep mode.

/*

 * On Assabet, we must probe for the Neponset board _before_

 * paging_init() has occurred to actually determine the amount

 * of RAM available.  To do so, we map the appropriate IO section

 * in the page table here in order to access GPIO registers.

/*

 * Read System Configuration "Register"

 * (taken from "Intel StrongARM SA-1110 Microprocessor Development Board

 * User's Guide", section 4.4.1)

 *

 * This same scan is performed in arch/arm/boot/compressed/head-sa1100.S

 * to set up the serial port for decompression status messages. We

 * repeat it here because the kernel may not be loaded as a zImage, and

 * also because it's a hassle to communicate the SCR value to the kernel

 * from the decompressor.

 *

 * Note that IRQs are guaranteed to be disabled.

 Configure GPIO 9:2 as outputs */

 Write 0xFF to GPIO 9:2 */

 Configure GPIO 9:2 as inputs */

 Read GPIO 9:2 */

  restore correct pin direction */

 save as system configuration byte. */

 This must be done before any call to machine_has_neponset() */

 Board Control Register */

 MQ200 */

	/*

	 * Set SUS bit in SDCR0 so serial port 1 functions.

	 * Its called GPCLKR0 in my SA1110 manual.

	/*

	 * When Neponset is attached, the first UART should be

	 * UART3.  That's what Angel is doing and many documents

	 * are stating this.

	 *

	 * We do the Neponset mapping even if Neponset support

	 * isn't compiled in so the user will still get something on

	 * the expected physical serial port.

	 *

	 * We no longer do this; not all boot loaders support it,

	 * and UART3 appears to be somewhat unreliable with blob.

	/*

	 * Angel sets this, but other bootloaders may not.

	 *

	 * This must precede any driver calls to BCR_set() or BCR_clear().

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Versatile board support using the device tree

 *

 *  Copyright (C) 2010 Secret Lab Technologies Ltd.

 *  Copyright (C) 2009 Jeremy Kerr <jeremy.kerr@canonical.com>

 *  Copyright (C) 2004 ARM Limited

 *  Copyright (C) 2000 Deep Blue Solutions Ltd

 macro to get at MMIO space when running virtually */

/*

 * ------------------------------------------------------------------------

 *  Versatile Registers

 * ------------------------------------------------------------------------

/*

 * VERSATILE peripheral addresses

 MMC interface */

 MMC Interface */

 System controller */

/*

 * System controller bit assignment

/*

 * Lookup table for attaching a specific name and platform_data pointer to

 * devices as they get created by of_platform_populate().  Ideally this table

 * would not exist, but the current clock implementation depends on some devices

 * having a specific name.

	/*

	 * set clock frequency:

	 *	VERSATILE_REFCLK is 32KHz

	 *	VERSATILE_TIMCLK is 1MHz

 Check if PCI backplane is detected */

		/*

		 * Enable PCI accesses. Note that the documentaton is

		 * inconsistent whether or not this is needed, but the old

		 * driver had it so we will keep it.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2015 Carlo Caione <carlo@endlessm.com>

 * Copyright (C) 2017 Martin Blumenstingl <martin.blumenstingl@googlemail.com>

 keep bit 0 always enabled */

 SMP SRAM */

 PMU */

 SCU */

	/*

	 * Set the entry point before powering on the CPU through the SCU. This

	 * is needed if the CPU is in "warm" state (= after rebooting the

	 * system without power-cycling, or when taking the CPU offline and

	 * then taking it online again.

	/*

	 * SCU Power on CPU (needs to be done before starting the CPU,

	 * otherwise the secondary CPU will not start).

 Reset enable */

 CPU power ON */

 Isolation disable */

 Reset disable */

 CPU power UP */

 Reset enable */

 Memory power UP */

 Wake up CPU */

 Isolation disable */

 Reset disable */

 we should never get here */

 Isolation enable */

 CPU power OFF */

 CPU power DOWN */

 Isolation enable */

 Sleep status */

 Memory power DOWN */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (C) 2014 Carlo Caione <carlo@caione.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Just-In-Time compiler for eBPF filters on 32bit ARM

 *

 * Copyright (c) 2017 Shubham Bansal <illusionist.neo@gmail.com>

 * Copyright (c) 2011 Mircea Gherzan <mgherzan@gmail.com>

/*

 * eBPF prog stack layout:

 *

 *                         high

 * original ARM_SP =>     +-----+

 *                        |     | callee saved registers

 *                        +-----+ <= (BPF_FP + SCRATCH_SIZE)

 *                        | ... | eBPF JIT scratch space

 * eBPF fp register =>    +-----+

 *   (BPF_FP)             | ... | eBPF prog stack

 *                        +-----+

 *                        |RSVD | JIT scratchpad

 * current ARM_SP =>      +-----+ <= (BPF_FP - STACK_SIZE + SCRATCH_SIZE)

 *                        | ... | caller-saved registers

 *                        +-----+

 *                        | ... | arguments passed on stack

 * ARM_SP during call =>  +-----|

 *                        |     |

 *                        | ... | Function call stack

 *                        |     |

 *                        +-----+

 *                          low

 *

 * The callee saved registers depends on whether frame pointers are enabled.

 * With frame pointers (to be compliant with the ABI):

 *

 *                              high

 * original ARM_SP =>     +--------------+ \

 *                        |      pc      | |

 * current ARM_FP =>      +--------------+ } callee saved registers

 *                        |r4-r9,fp,ip,lr| |

 *                        +--------------+ /

 *                              low

 *

 * Without frame pointers:

 *

 *                              high

 * original ARM_SP =>     +--------------+

 *                        |  r4-r9,fp,lr | callee saved registers

 * current ARM_FP =>      +--------------+

 *                              low

 *

 * When popping registers off the stack at the end of a BPF function, we

 * reference them via the current ARM_FP register.

 *

 * Some eBPF operations are implemented via a call to a helper function.

 * Such calls are "invisible" in the eBPF code, so it is up to the calling

 * program to preserve any caller-saved ARM registers during the call. The

 * JIT emits code to push and pop those registers onto the stack, immediately

 * above the callee stack frame.

 Stack layout - these are offsets from (top of stack - 4) */

	/* Stack space for BPF_REG_2, BPF_REG_3, BPF_REG_4,

	 * BPF_REG_5, BPF_REG_7, BPF_REG_8, BPF_REG_9,

	 * BPF_REG_FP and Tail call counts.

/*

 * Negative "register" values indicate the register is stored on the stack

 * and are the offset from the top of the eBPF JIT scratch space.

 TEMP Register 1 */

 TEMP Register 2 */

 Tail Call Count */

/*

 * Map eBPF registers to ARM 32bit registers or stack scratch space.

 *

 * 1. First argument is passed using the arm 32bit registers and rest of the

 * arguments are passed on stack scratch space.

 * 2. First callee-saved argument is mapped to arm 32 bit registers and rest

 * arguments are mapped to scratch space on stack.

 * 3. We need two 64 bit temp registers to do complex operations on eBPF

 * registers.

 *

 * As the eBPF registers are all 64 bit registers and arm has only 32 bit

 * registers, we have to map each eBPF registers with two arm 32 bit regs or

 * scratch memory space and we have to build eBPF 64 bit register from those.

 *

 return value from in-kernel function, and exit value from eBPF */

 arguments from eBPF program to in-kernel function */

 Stored on stack scratch space */

 callee saved registers that in-kernel function will preserve */

 Stored on stack scratch space */

 Read only Frame Pointer to access Stack */

	/* Temporary Register for internal BPF JIT, can be used

	 * for constant blindings and others.

 Tail call count. Stored on stack scratch space. */

	/* temporary register for blinding constants.

	 * Stored on stack scratch space.

/*

 * JIT Context:

 *

 * prog			:	bpf_prog

 * idx			:	index of current last JITed instruction.

 * prologue_bytes	:	bytes used in prologue.

 * epilogue_offset	:	offset of epilogue starting.

 * offsets		:	array of eBPF instruction offsets in

 *				JITed code.

 * target		:	final JITed code.

 * epilogue_bytes	:	no of bytes used in epilogue.

 * imm_count		:	no of immediate counts used for global

 *				variables.

 * imms			:	array of global variable addresses.

/*

 * Wrappers which handle both OABI and EABI and assures Thumb2 interworking

 * (where the assembly routines like __aeabi_uidiv could cause problems).

/*

 * Emit an instruction that will be executed unconditionally.

/*

 * This is rather horrid, but necessary to convert an integer constant

 * to an immediate operand for the opcodes, and be able to detect at

 * build time whether the constant can't be converted (iow, usable in

 * BUILD_BUG_ON()).

/*

 * Checks if immediate value can be converted to imm12(12 bits) value.

/*

 * Initializes the JIT space with undefined instructions.

 We are guaranteed to have aligned memory. */

 EABI requires the stack to be aligned to 64-bit boundaries */

 Stack must be aligned to 32-bit boundaries */

 total stack size used in JITed code */

 on the "fake" run we just count them (duplicates included) */

 constants go just after the epilogue */

 PC in ARM mode == address of the instruction + 8 */

		/*

		 * literal pool is too far, signal it into flags. we

		 * can only detect it on the second pass unfortunately.

 __LINUX_ARM_ARCH__ */

/*

 * Move an immediate that's not an imm8m to a core register.

 No need for 1st dummy run */

	/*

	 * For BPF_ALU | BPF_DIV | BPF_K instructions

	 * As ARM_R1 and ARM_R0 contains 1st argument of bpf

	 * function, we need to save it on caller side to save

	 * it from getting destroyed within callee.

	 * After the return from the callee, we restore ARM_R0

	 * ARM_R1.

 Push caller-saved registers on stack */

 Call appropriate function */

 Restore caller-saved registers from stack */

 Save return value */

 Restore ARM_R0 and ARM_R1 */

 Is the translated BPF register on stack? */

/* If a BPF register is on the stack (stk is true), load it to the

 * supplied temporary register and return the temporary register

 * for subsequent operations, otherwise just use the CPU register.

/* If a BPF register is on the stack (stk is true), save the register

 * back to the stack.  If the source register is not the same, then

 * move it into the correct register.

 Sign extended move */

	/* 64 bit :

	 *	adds dst_lo, dst_lo, src_lo

	 *	adc dst_hi, dst_hi, src_hi

	 * 32 bit :

	 *	add dst_lo, dst_lo, src_lo

	/* 64 bit :

	 *	subs dst_lo, dst_lo, src_lo

	 *	sbc dst_hi, dst_hi, src_hi

	 * 32 bit :

	 *	sub dst_lo, dst_lo, src_lo

 dst = dst + src */

 dst = dst - src */

 dst = dst | src */

 dst = dst & src */

 dst = dst ^ src */

 dst = dst * src */

 dst = dst << src */

 dst = dst >> src */

 dst = dst >> src (signed)*/

/* ALU operation (32 bit)

 * dst = dst (op) src

 ALU operation */

 ALU operation (64 bit) */

 ALU operation */

 ALU operation */

 dst = src (4 bytes)*/

 dst = src */

 Zero out high 4 bytes */

 complete 8 byte move */

 Shift operations */

 Do shift operation */

 dst = ~dst (64 bit) */

 Setup Operand */

 Do Negate Operation */

 dst = dst << src */

 Setup Operands */

 Do LSH operation */

 dst = dst >> src (signed)*/

 Setup Operands */

 Do the ARSH operation */

 dst = dst >> src */

 Setup Operands */

 Do RSH operation */

 dst = dst << val */

 Setup operands */

 Do LSH operation */

 dst = dst >> val */

 Setup operands */

 Do LSR operation */

		/* An immediate value of 0 encodes a shift amount of 32

		 * for LSR. To shift by 0, don't do anything.

 dst = dst >> val (signed) */

 Setup operands */

 Do ARSH operation */

		/* An immediate value of 0 encodes a shift amount of 32

		 * for ASR. To shift by 0, don't do anything.

 Setup operands for multiplication */

 Do Multiplication */

 Need to make sure off+4 does not overflow. */

 *(size *)(dst + off) = src */

 Store a Byte */

 Store a HalfWord */

 Store a Word */

 Store a Double Word */

 dst = *(size*)(src + off) */

 Load a Byte */

 Load a HalfWord */

 Load a Word */

 Load a Double Word */

 Arithmatic Operation */

 Only compare low halve if high halve are equal. */

 initialized on the first pass of build_body() */

 bpf_tail_call(void *prog_ctx, struct bpf_array *array, u64 index) */

	/* if (index >= array->map.max_entries)

	 *	goto out;

 index is 32-bit for arrays */

 array->map.max_entries */

 index >= array->map.max_entries */

 tmp2[0] = array, tmp2[1] = index */

	/* if (tail_call_cnt > MAX_TAIL_CALL_CNT)

	 *	goto out;

	 * tail_call_cnt++;

	/* prog = array->ptrs[index]

	 * if (prog == NULL)

	 *	goto out;

 goto *(prog->bpf_func + prologue_size); */

 out: */

 0xabcd => 0xcdab */

 ARMv6+ */

 0xabcdefgh => 0xghefcdab */

 ARMv6+ */

 push the scratch stack register on top of the stack

 Save callee saved registers. */

 mov r3, #0 */

 sub r2, sp, #SCRATCH_SIZE */

 Set up function call stack */

 Set up BPF prog stack base register */

 Initialize Tail Count */

 Move BPF_CTX to BPF_R1 */

 end of prologue */

 restore callee saved registers. */

	/* When using frame pointers, some additional registers need to

 Restore callee saved registers. */

/*

 * Convert an eBPF instruction to native instruction, i.e

 * JITs an eBPF instruction.

 * Returns :

 *	0  - Successfully JITed an 8-byte eBPF instruction

 *	>0 - Successfully JITed a 16-byte eBPF instruction

 *	<0 - Failed to JIT.

 ALU operations */

 dst = src */

 Special mov32 for zext */

 Sign-extend immediate value to destination reg */

 dst = dst + src/imm */

 dst = dst - src/imm */

 dst = dst | src/imm */

 dst = dst & src/imm */

 dst = dst ^ src/imm */

 dst = dst * src/imm */

 dst = dst << src */

 dst = dst >> src */

			/* Move immediate value to the temporary register

			 * and then do the ALU operation on the temporary

			 * register as this will sign-extend the immediate

			 * value into temporary reg and then it would be

			 * safe to do the operation on it.

 dst = dst / src(imm) */

 dst = dst % src(imm) */

 dst = dst << imm */

 dst = dst >> imm */

 dst = dst >> imm (signed) */

 dst = dst << imm */

 dst = dst >> imm */

 dst = dst << src */

 dst = dst >> src */

 dst = dst >> src (signed) */

 dst = dst >> imm (signed) */

 dst = ~dst */

 dst = ~dst (64 bit) */

 dst = dst * src/imm */

			/* Move immediate value to the temporary register

			 * and then do the multiplication on it as this

			 * will sign-extend the immediate value into temp

			 * reg then it would be safe to do the operation

			 * on it.

 dst = htole(dst) */

 dst = htobe(dst) */

 zero-extend 16 bits into 64 bits */

 ARMv6+ */

 zero-extend 32 bits into 64 bits */

 nop */

 dst = imm64 */

 LDX: dst = *(size *)(src + off) */

 speculation barrier */

 ST: *(size *)(dst + off) = imm */

 Sign-extend immediate value into temp reg */

 Atomic ops */

 STX: *(size *)(dst + off) = src */

 PC += off if dst == src */

 PC += off if dst > src */

 PC += off if dst >= src */

 PC += off if dst < src */

 PC += off if dst <= src */

 PC += off if dst != src */

 PC += off if dst > src (signed) */

 PC += off if dst >= src (signed) */

 PC += off if dst < src (signed) */

 PC += off if dst <= src (signed) */

 PC += off if dst & src */

 Setup source registers */

 PC += off if dst == imm */

 PC += off if dst > imm */

 PC += off if dst >= imm */

 PC += off if dst < imm */

 PC += off if dst <= imm */

 PC += off if dst != imm */

 PC += off if dst > imm (signed) */

 PC += off if dst >= imm (signed) */

 PC += off if dst < imm (signed) */

 PC += off if dst <= imm (signed) */

 PC += off if dst & imm */

 Sign-extend immediate value */

 Setup destination register */

 Check for the condition */

 Setup JUMP instruction */

 JMP OFF */

 tail call */

 function call */

 callee clean

 function return */

		/* Optimization: when last instruction is EXIT

		 * simply fallthrough to epilogue.

		/*

		 * this instruction generated an overflow when

		 * trying to access the literal pool, so

		 * delegate this filter to the kernel interpreter.

 It's used with loading the 64 bit immediate value. */

 If unsuccesfull, return with error code */

	/* If BPF JIT was not enabled then we must fall back to

	 * the interpreter.

	/* If constant blinding was enabled and we failed during blinding

	 * then we must fall back to the interpreter. Otherwise, we save

	 * the new JITed code.

	/* Not able to allocate memory for offsets[] , then

	 * we must fall back to the interpreter

	/* 1) fake pass to find in the length of the JITed code,

	 * to compute ctx->offsets and other context variables

	 * needed to compute final JITed code.

	 * Also, calculate random starting pointer/start of JITed code

	 * which is prefixed by random number of fault instructions.

	 *

	 * If the first pass fails then there is no chance of it

	 * being successful in the second pass, so just fall back

	 * to the interpreter.

 there's nothing about the epilogue on ARMv7 */

	/* Now we can get the actual image size of the JITed arm code.

	 * Currently, we are not considering the THUMB-2 instructions

	 * for jit, although it can decrease the size of the image.

	 *

	 * As each arm instruction is of length 32bit, we are translating

	 * number of JITed intructions into the size required to store these

	 * JITed code.

 Now we know the size of the structure to make */

	/* Not able to allocate memory for the structure then

	 * we must fall back to the interpretation

 2.) Actual pass to generate final JIT code */

	/* If building the body of the JITed code fails somehow,

	 * we fall back to the interpretation.

 3.) Extra pass to validate JITed Code */

 there are 2 passes here */

/*

 * arch/arm/plat-orion/mpp.c

 *

 * MPP functions for Marvell orion SoCs

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Address of the ith MPP control register */

/*

 * arch/arm/plat-orion/time.c

 *

 * Marvell Orion SoC timer handling.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 *

 * Timer 0 is used as free-running clocksource, while timer 1 is

 * used as clock_event_device.

/*

 * MBus bridge block registers.

/*

 * Timer block registers.

/*

 * SoC-specific data.

/*

 * Number of timer ticks per jiffy.

/*

 * Orion's sched_clock implementation. It has a resolution of

 * at least 7.5ns (133MHz TCLK).

/*

 * Clockevent handling.

	/*

	 * Clear and enable clockevent timer interrupt.

	/*

	 * Setup new clockevent timer value.

	/*

	 * Enable the timer.

 Disable timer */

 Disable timer interrupt */

 ACK pending timer interrupt */

 Setup timer to fire at 1/HZ intervals */

 Enable timer interrupt */

 Enable timer */

	/*

	 * ACK timer interrupt and call event handler.

	/*

	 * Set SoC-specific data.

	/*

	 * Set scale and timer for sched_clock.

	/*

	 * Setup free-running clocksource timer (interrupts

	 * disabled).

	/*

	 * Setup clockevent timer (interrupt-driven).

/*

 * arch/arm/plat-orion/gpio.c

 *

 * Marvell Orion SoC GPIO handling.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * GPIO unit register offsets.

/*

 * GPIO primitives.

/*

 * Orion-specific GPIO API extensions.

 Configure as output, drive low. */

 ms */

/*****************************************************************************

 * Orion GPIO IRQ

 *

 * GPIO_IN_POL register controls whether GPIO_DATA_IN will hold the same

 * value of the line or the opposite value.

 *

 * Level IRQ handlers: DATA_IN is used directly as cause register.

 *                     Interrupt are masked by LEVEL_MASK registers.

 * Edge IRQ handlers:  Change in DATA_IN are latched in EDGE_CAUSE.

 *                     Interrupt are masked by EDGE_MASK registers.

 * Both-edge handlers: Similar to regular Edge handlers, but also swaps

 *                     the polarity to catch the next line transaction.

 *                     This is a race condition that might not perfectly

 *                     work on some use cases.

 *

 * Every eight GPIO lines are grouped (OR'ed) before going up to main

 * cause register.

 *

 *                    EDGE  cause    mask

 *        data-in   /--------| |-----| |----\

 *     -----| |-----                         ---- to main cause reg

 *           X      \----------------| |----/

 *        polarity    LEVEL          mask

 *

 Check if we need to change chip and handler */

	/*

	 * Configure interrupt polarity.

		/*

		 * set initial polarity based on current input level

 falling */

 rising */

 Swap polarity (race with GPIO line) */

	/*

	 * Mask and clear GPIO interrupts.

	/* Setup the interrupt handlers. Each chip can have up to 4

	 * interrupt handlers, with each handler dealing with 8 GPIO

 Setup irq domain on top of the generic chip. */

/*

 * arch/arm/plat-orion/common.c

 *

 * Marvell Orion SoC common setup code used by multiple mach-/common.c

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 Create a clkdev entry for a given device/clk */

/* Create clkdev entries for all orion platforms except kirkwood.

   Kirkwood has gated clocks for some of its peripherals, so creates

   its own clkdev entries. For all the other orion devices, create

/* Fill in the resources structure and link it into the platform

   device structure. There is always a memory region, and nearly

/*****************************************************************************

 * UART

/*****************************************************************************

 * UART0

/*****************************************************************************

 * UART1

/*****************************************************************************

 * UART2

/*****************************************************************************

 * UART3

/*****************************************************************************

 * SoC RTC

/*****************************************************************************

 * GE

/*****************************************************************************

 * GE00

/*****************************************************************************

 * GE01

/*****************************************************************************

 * GE10

/*****************************************************************************

 * GE11

/*****************************************************************************

 * Ethernet switch

/*****************************************************************************

 * I2C

 Default timeout of 1 second */

 Default timeout of 1 second */

/*****************************************************************************

 * SPI

/* Note: The SPI silicon core does have interrupts. However the

/*****************************************************************************

 * XOR

/*****************************************************************************

 * XOR0

/*****************************************************************************

 * XOR1

/*****************************************************************************

 * EHCI

/*****************************************************************************

 * EHCI0

/*****************************************************************************

 * EHCI1

/*****************************************************************************

 * EHCI2

/*****************************************************************************

 * SATA

/*****************************************************************************

 * Cryptographic Engines and Security Accelerator (CESA)

/*

 * arch/arm/plat-orion/irq.c

 *

 * Marvell Orion SoC IRQ handling.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

	/*

	 * Mask all interrupts initially.

/*

 * arch/arm/plat-orion/pcie.c

 *

 * Marvell Orion SoC PCIe handling.

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2.  This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

/*

 * PCIe unit register offsets.

	/*

	 * MV-S104860-U0, Rev. C:

	 * PCI Express Unit Soft Reset

	 * When set, generates an internal reset in the PCI Express unit.

	 * This bit should be cleared after the link is re-established.

/*

 * Setup PCIE BARs and Address Decode Wins:

 * BAR[0,2] -> disabled, BAR[1] -> covers all DRAM banks

 * WIN[0-3] -> DRAM bank[0-3]

	/*

	 * First, disable and clear BARs and windows.

	/*

	 * Setup windows for DDR banks.  Count total DDR size on the fly.

	/*

	 * Round up 'size' to the nearest power of two.

	/*

	 * Setup BAR[1] to all DRAM banks.

	/*

	 * Point PCIe unit MBUS decode windows to DRAM space.

	/*

	 * Master + slave enable.

	/*

	 * Enable interrupt lines A-D.

 SPDX-License-Identifier: GPL-2.0

/*

 * SMP support for Allwinner SoCs

 *

 * Copyright (C) 2013 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 *

 * Based on code

 *  Copyright (C) 2012-2013 Allwinner Ltd.

 *

 Set CPU boot address */

 Assert the CPU core in reset */

 Assert the L1 cache in reset */

 Disable external debug access */

 Power up the CPU */

 Clear CPU power-off gating */

 Deassert the CPU core reset */

 Enable back the external debug accesses */

 Set CPU boot address */

 Assert the CPU core in reset */

 Assert the L1 cache in reset */

 Clear CPU power-off gating */

 Deassert the CPU core reset */

 SPDX-License-Identifier: GPL-2.0

/*

 * Device Tree support for Allwinner A1X SoCs

 *

 * Copyright (C) 2012 Maxime Ripard

 *

 * Maxime Ripard <maxime.ripard@free-electrons.com>

 *

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2018 Chen-Yu Tsai

 *

 * Chen-Yu Tsai <wens@csie.org>

 *

 * arch/arm/mach-sunxi/mc_smp.c

 *

 * Based on Allwinner code, arch/arm/mach-exynos/mcpm-exynos.c, and

 * arch/arm/mach-hisi/platmcpm.c

 * Cluster cache enable trampoline code adapted from MCPM framework

 The power off register for clusters are different from a80 and a83t */

 R_CPUCFG registers, specific to sun8i-a83t */

 In case of_cpu_device_node_get fails */

		/*

		 * There's no point in returning an error, since we

		 * would be mid way in a core or cluster power sequence.

 control sequence from Allwinner A80 user manual v1.2 PRCM section */

 Set hotplug support magic flags for cpu0 */

 assert processor power-on reset */

 assert cpu power-on reset */

 Cortex-A7: hold L1 reset disable signal low */

 assert processor related resets */

	/*

	 * Allwinner code also asserts resets for NEON on A15. According

	 * to ARM manuals, asserting power-on reset is sufficient.

 open power switch */

 Handle A83T bit swap */

 clear processor power gate */

 Handle A83T bit swap */

 de-assert processor power-on reset */

 de-assert all processor resets */

 NEON */

 For A83T, assert cluster cores resets */

 Core Reset    */

 assert ACINACTM */

 assert cluster processor power-on resets */

 assert cluster cores resets */

 assert cluster resets */

	/*

	 * Allwinner code also asserts resets for NEON on A15. According

	 * to ARM manuals, asserting power-on reset is sufficient.

 hold L1/L2 reset disable signals low */

 Cortex-A15: hold L2RSTDISABLE low */

 Cortex-A7: hold L1RSTDISABLE and L2RSTDISABLE low */

 clear cluster power gate */

 de-assert cluster resets */

 de-assert ACINACTM */

/*

 * This bit is shared between the initial nocache_trampoline call to

 * enable CCI-400 and proper cluster cache disable before power down.

		/*

		 * On the Cortex-A15 we need to disable

		 * L2 prefetching before flushing the cache.

 Flush all cache levels for this cluster. */

	/*

	 * Disable cluster-level coherency by masking

	 * incoming snoops and DVM messages:

 Clear hotplug support magic flags for cpu0 */

 This is read by incoming CPUs with their cache and MMU disabled */

 last man standing, assert ACINACTM */

 A power_up request went ahead of us. */

 gate processor power */

 close power switch */

 assert cluster resets or system will hang */

 gate cluster power */

 This should never happen */

 wait for CPU core to die and enter WFI */

		/*

		 * If the user turns off a bunch of cores at the same

		 * time, the kernel might call cpu_kill before some of

		 * them are ready. This is because boot_lock serializes

		 * both cpu_die and cpu_kill callbacks. Either one could

		 * run first. We should wait for cpu_die to complete.

 power down CPU core */

 wait for cluster L2 WFI */

		/*

		 * Ignore timeout on the cluster. Leaving the cluster on

		 * will not affect system execution, just use a bit more

		 * power. But returning an error here will only confuse

		 * the user as the CPU has already been shutdown.

 Power down cluster */

 CPU0 hotplug not handled for sun8i-a83t */

/*

 * Adapted from arch/arm/common/mc_smp_entry.c

 *

 * We need the trampoline code to enable CCI-400 on the first cluster

	/*

	 * We're going to soft-restart the current CPU through the

	 * low-level MCPM code by leveraging the suspend/resume

	 * infrastructure. Let's play it safe by using cpu_pm_enter()

	 * in case the CPU init code path resets the VFP or similar.

/*

 * This holds any device nodes that we requested resources for,

 * so that we may easily release resources in the error path.

 This structure holds SoC-specific bits tied to an enable-method string. */

	/*

	 * Don't bother checking the "cpus" node, as an enable-method

	 * property in that node is undocumented.

	/*

	 * We can't actually use the enable-method magic in the kernel.

	 * Our loopback / trampoline code uses the CPU suspend framework,

	 * which requires the identity mapping be available. It would not

	 * yet be available if we used the .init_cpus or .prepare_cpus

	 * callbacks in smp_operations, which we would use if we were to

	 * use CPU_METHOD_OF_DECLARE

 Get needed device tree nodes */

	/*

	 * Unfortunately we can not request the I/O region for the PRCM.

	 * It is shared with the PRCM clock.

 Configure CCI-400 for boot cluster */

 We don't need the device nodes anymore */

 Set the hardware entry point address */

 Actually enable multi cluster SMP */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (HiSilicon's SoC based) flattened device tree enabled machine

 *

 * Copyright (c) 2012-2013 HiSilicon Ltd.

 * Copyright (c) 2012-2013 Linaro Ltd.

 *

 * Author: Haojian Zhuang <haojian.zhuang@linaro.org>

/*

 * This table is only for optimization. Since ioremap() could always share

 * the same mapping if it's defined as static IO mapping.

 *

 * Without this table, system could also work. The cost is some virtual address

 * spaces wasted since ioremap() may be called multi times for the same

 * IO space.

 sysctrl */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013-2014 Linaro Ltd.

 * Copyright (c) 2013-2014 HiSilicon Limited.

/* bits definition in SC_CPU_RESET_REQ[x]/SC_CPU_RESET_DREQ[x]

 * 1 -- unreset; 0 -- reset

/*

 * bits definition in SC_CPU_RESET_STATUS[x]

 * 1 -- reset status; 0 -- unreset status

 reset */

 unreset */

 bits definition in FB_SF_INVLD */

/*

 * [0]: bootwrapper physical address

 * [1]: bootwrapper size

 * [2]: relocation address

 * [3]: relocation size

	/*

	 * We may fail to power up core again without this delay.

	 * It's not mentioned in document. It's found by test.

 A power_up request went ahead of us. */

 Since it's Cortex A15, disable L2 prefetching. */

 Wait for clean L2 when the whole cluster is down. */

	/*

	 * Fill the instruction address that is used after secondary core

	 * out of reset.

 magic number */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Linaro Ltd.

 * Copyright (c) 2013 HiSilicon Limited.

 * Based on arch/arm/mach-vexpress/platsmp.c, Copyright (C) 2002 ARM Ltd.

 ldr pc, [pc, #-4] */

 pc jump phy address */

 set the secondary core boot from DDR */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2013 Linaro Ltd.

 * Copyright (c) 2013 HiSilicon Limited.

 Sysctrl registers in Hi3620 SoC */

/*

 * bit definition in SCISOEN/SCPERPWREN/...

 *

 * CPU2_ISO_CTRL	(1 << 5)

 * CPU3_ISO_CTRL	(1 << 6)

 * ...

/*

 * bit definition in SCPERCTRL0

 *

 * CPU0_WFI_MASK_CFG	(1 << 28)

 * CPU1_WFI_MASK_CFG	(1 << 29)

 * ...

/*

 * bit definition in SCCPURSTEN/...

 *

 * CPU0_SRST_REQ_EN	(1 << 0)

 * CPU1_SRST_REQ_EN	(1 << 1)

 * ...

 MTCMOS set */

 Enable core */

 unreset */

 reset */

 ISO disable */

 WFI Mask */

 Unreset */

 wfi mask */

 disable core*/

 iso enable */

 reset */

 MTCMOS unset */

 power on cpu1 */

 unreset */

 power down cpu1 */

 reset */

 reset on CPU1  */

 unreset on CPU1 */

	/*

	 * Turn off coherency and L1 D-cache

 We should have never returned from idle */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2011 Calxeda, Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2011 Calxeda, Inc.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright 2010-2011 Calxeda, Inc.

 Get SCU base */

 Map system registers */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Device Tree support for Mediatek SoCs

 *

 * Copyright (c) 2014 MundoReader S.L.

 * Author: Matthias Brugger <matthias.bgg@gmail.com>

 turn on GPT6 which ungates arch timer clocks */

 enable clock and set to free-run */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/arm/mach-mediatek/platsmp.c

 *

 * Copyright (c) 2014 Mediatek Inc.

 * Author: Shunli Wang <shunli.wang@mediatek.com>

 *         Yingjoe Chen <yingjoe.chen@mediatek.com>

 Find smp boot info for this SoC */

 smp_base(trustzone-bootinfo) is reserved by device tree */

	/*

	 * write the address of slave startup address into the system-wide

	 * jump register

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/income.c

 *

 * Support for Income s.r.o. SH-Dmaster PXA270 SBC

 *

 * Copyright (C) 2010

 * Marek Vasut <marek.vasut@gmail.com>

 * Pavel Revak <palo@bielyvlk.sk>

/******************************************************************************

 * SD/MMC card controller

 Card detect on GPIO 0 */

 Write protect on GPIO 1 */

/******************************************************************************

 * USB Host

/******************************************************************************

 * LED

/******************************************************************************

 * I2C

/******************************************************************************

 * Framebuffer

/******************************************************************************

 * Backlight

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for HTC Magician PDA phones:

 * i-mate JAM, O2 Xda mini, Orange SPV M500, Qtek s100, Qtek s110

 * and T-Mobile MDA Compact.

 *

 * Copyright (c) 2006-2007 Philipp Zabel

 *

 * Based on hx4700.c, spitz.c and others.

 SDRAM and Static Memory I/O Signals */

 PASIC3 */

 EGPIO CPLD */

 I2C UDA1380 + OV9640 */

 PWM 0 - LCD backlight */

 I2S UDA1380 capture */

 SSP 1 UDA1380 playback */

 SSP 2 TSC2046 touchscreen */

 frame as GPIO */

 MMC/SD/SDHC slot */

 LCD */

 QCI camera interface */

 Magician specific input GPIOs */

 unknown */

 GSM_IRQ */

 CPLD_IRQ */

 DS1WM_IRQ */

 GSM_READY */

 nPEN_IRQ */

/*

 * IrDA

/*

 * GPIO Keys

/*

 * EGPIO (Xilinx CPLD)

 *

 * 32-bit aligned 8-bit registers

 * 16 possible registers (reg windows size), only 7 used:

 * 3x output, 1x irq, 3x input

		/*

		 * Depends on modules configuration

 EGPIO_MAGICIAN_GSM_RESET */

/*

 * PXAFB LCD - Toppoly TD028STEB1 or Samsung LTP280QV

 FIXME: enable LCDC here */

 Avdd -> Voff >5ms */

 Voff -> Von >(5+10)ms */

/*

 * Backlight

 /*

 * fixed regulator for pwm_backlight

/*

 * LCD PWM backlight (main)

 *

 * MP1521 frequency should be:

 *	100-400 Hz = 2.5*10^6 - 10*10^6 ns

/*

 * GPIO LEDs, Phone keys backlight, vibra

/*

 * PASIC3 with DS1WM

 No IRQ handler in the PASIC3, DS1WM needs an external IRQ */

/*

 * PXA UDC

/*

 * USB device VBus detection

		/*

		 * EGPIO on register 4 index 1, the second EGPIO chip

		 * starts at register 4 so this will be at index 1 on that

		 * chip.

/*

 * External power

 AC=1 */

 USB=0 */

/*

 * Battery charger

/*

 * fixed regulator for ads7846

 probably */

/*

 * Vcore regulator MAX1587A

	/*

	 * NOTICE measured directly on the PCB (board_id == 0x3a), but

	 * if R24 is present, it will boost the voltage

	 * (write 1.475V, get 1.645V and smoke)

/*

 * MMC/SD

/*

 * Write protect on EGPIO register 5 index 4, this is on the second HTC

 * EGPIO chip which starts at register 4, so we need offset 8+4=12 on that

 * particular chip.

/*

 * Power on EGPIO register 2 index 0, so this is on the first HTC EGPIO chip

 * starting at register 0 so we need offset 2*8+0 = 16 on that chip.

/*

 * USB OHCI

 port1: CSR Bluetooth, port2: OTG with UDC */

/*

 * StrataFlash

 EXPERIMENTAL */

/*

 * physmap-flash driver

/*

 * PXA I2C main controller

 OV9640 I2C device doesn't support fast mode */

/*

 * PXA I2C power controller

/*

 * Touchscreen

 with x plate ohms it will overflow 255 */

 first readout is always bad */

 NOTICE must be GPIO, incompatibility with hw PXA SPI framing */

/*

 * Platform devices

 NOTICE valid LCD init sequence */

 Check LCD type we have */

 NOTICE valid LCD init sequence */

 SPDX-License-Identifier: GPL-2.0

/*

 * PXA250/210 Power Management Routines

 *

 * Original code for the SA11x0:

 * Copyright (c) 2001 Cliff Brake <cbrake@accelent.com>

 *

 * Modified for the PXA250 by Nicolas Pitre:

 * Copyright (c) 2002 Monta Vista Software, Inc.

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License.

 force any iWMMXt context to ram **/

 skip registers saving for standby */

 before sleeping, calculate and save a checksum */

 *** go zzz *** */

 after sleeping, validate the checksum */

 if invalid, display message and wait for a hardware reset */

/*

 * Hardware definitions for the Toshiba eseries PDAs

 *

 * Copyright (c) 2003 Ian Molton <spyro@f2s.com>

 *

 * This file is licensed under

 * the terms of the GNU General Public License version 2. This program

 * is licensed "as is" without any warranty of any kind, whether express

 * or implied.

 *

 Only e800 has 128MB RAM */

 Reset - bring SUSPEND high before PCLR */

 TMIO controller uses the same resources on all e-series machines. */

 Some e-series hardware cannot control the 32K clock */

 -------------------- e330 tc6387xb parameters -------------------- */

 --------------------------------------------------------------- */

 Maintainer: Ian Molton (spyro@f2s.com) */

 -------------------- e350 t7l66xb parameters -------------------- */

 ---------------------------------------------------------- */

 Maintainer: Ian Molton (spyro@f2s.com) */

 ------------------------ E400 LCD definitions ------------------------ */

 ------------------------ E400 MFP config ----------------------------- */

 Chip selects */

 CS1 - Flash */

 CS4 - TMIO */

 Clocks */

 BTUART */

 TMIO controller */

 t7l66xb #PCLR */

 t7l66xb #SUSPEND (NOT BTUART!) */

 wakeup */

 ---------------------------------------------------------------------- */

 ---------------------------------------------------------- */

 Fixme - e400 may have a switched clock */

 Maintainer: Ian Molton (spyro@f2s.com) */

 ------------------------ e740 video support --------------------------- */

 --------------------------- MFP Pin config -------------------------- */

 Chip selects */

 CS1 - Flash */

 CS3 - IMAGEON */

 CS4 - TMIO */

 Clocks */

 BTUART */

 TMIO controller */

 t7l66xb #PCLR */

 t7l66xb #SUSPEND (NOT BTUART!) */

 UDC */

 IrDA */

 AC97 */

 Audio power control */

 AC97 codec AVDD2 supply (analogue power) */

 Mic amp power */

 Headphone amp power */

 PC Card */

 CD0 */

 CD1 */

 IRQ0 */

 IRQ1 */

 RST0 */

 RST1 */

 PWR0 */

 PWR1 */

 wakeup */

 -------------------- e740 t7l66xb parameters -------------------- */

 ----------------------------------------------------------------------- */

 Maintainer: Ian Molton (spyro@f2s.com) */

 ---------------------- E750 LCD definitions -------------------- */

 -------------------- e750 MFP parameters -------------------- */

 Chip selects */

 CS1 - Flash */

 CS3 - IMAGEON */

 CS4 - TMIO */

 Clocks */

 BTUART */

 TMIO controller */

 t7l66xb #PCLR */

 t7l66xb #SUSPEND (NOT BTUART!) */

 UDC */

 IrDA */

 AC97 */

 Audio power control */

 Headphone amp power */

 Speaker amp power */

 Headphone detect */

 PC Card */

 CD0 */

 CD1 */

 GPIO11_GPIO,  IRQ0 */

 IRQ1 */

 RST0 */

 RST1 */

 PWR0 */

 PWR1 */

 wakeup */

 ----------------- e750 tc6393xb parameters ------------------ */

 ------------------------------------------------------------- */

 Maintainer: Ian Molton (spyro@f2s.com) */

 ------------------------ e800 LCD definitions ------------------------- */

 AC97 */

 tc6393xb */

 Wince uses 14 which gives a */

 7MHz Pclk. We use a 14MHz one */

 --------------------------- UDC definitions --------------------------- */

 ----------------- e800 tc6393xb parameters ------------------ */

 ----------------------------------------------------------------------- */

 Maintainer: Ian Molton (spyro@f2s.com) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/mfp-pxa2xx.c

 *

 *  PXA2xx pin mux configuration support

 *

 *  The GPIOs on PXA2xx can be configured as one of many alternate

 *  functions, this is by concept samilar to the MFP configuration

 *  on PXA3xx,  what's more important, the low power pin state and

 *  wakeup detection are also supported by the same framework.

 bit mask in PWER or PKWR */

 bit mask of muxed gpio bits, 0 if no mux */

 GAFRx_U or GAFRx_L ? */

 alternate function and direction at run-time */

 alternate function and direction at low power mode */

 warning and fall through, treat as MFP_LPM_DEFAULT */

	/* give early warning if MFP_LPM_CAN_WAKEUP is set on the

	 * configurations of those pins not able to wakeup

	/* Allow keypad GPIOs to wakeup system when

	 * configured as generic GPIOs.

 running before pxa_gpio_probe() */

	/* PXA26x has additional 4 GPIOs (86/87/88/89) which has the

	 * direction bit inverted in GPDR2. See PXA26x DM 4.1.1.

 CONFIG_PXA25x */

 skip if configured as generic GPIO */

 running before pxa_gpio_probe() */

		/* skip GPIO2, 5, 6, 7, 8, they are not

		 * valid pins allow configuration

 Keypad GPIOs */

 Overwrite GPIO13 as a PWER wakeup source */

 skip GPIO2, 5, 6, 7, 8 */

 CONFIG_PXA27x */

 set corresponding PGSR bit of those marked MFP_LPM_KEEP_OUTPUT */

 set GPDR bits taking into account MFP_LPM_KEEP_OUTPUT */

 clear RDH bit to enable GPIO receivers after reset/sleep exit */

 initialize gafr_run[], pgsr_lpm[] from existing values */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/pxa930.c

 *

 * Code specific to PXA930

 *

 * Copyright (C) 2007-2008 Marvell Internation Ltd.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  arch/arm/mach-pxa/colibri-pxa300.c

 *

 *  Support for Toradex PXA300/310 based Colibri module

 *

 *  Daniel Mack <daniel@caiaq.de>

 *  Matthias Meier <matthias.j.meier@gmx.net>

 MMC */

 GPIO13_COLIBRI_PXA300_SD_DETECT */

 UHC */

 I2C */

/*

 * Asix AX88796 Ethernet

 defined later */

 AX88796 chip select */

 AX88796 IRQ */

 CONFIG_AX88796 */

 CONFIG_FB_PXA || CONFIG_FB_PXA_MODULE */

 no AC97 codec on Colibri PXA300 */

 Evalboard init */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/lpd270.c

 *

 * Support for the LogicPD PXA270 Card Engine.

 * Derived from the mainstone code, which carries these notices:

 *

 * Author:	Nicolas Pitre

 * Created:	Nov 05, 2002

 * Copyright:	MontaVista Software Inc.

 Chip Selects */

 Mainboard Flash */

 CPLD + Ethernet */

 LCD - 16bpp Active TFT */

 Backlight */

 USB Host */

 AC97 */

 clear useless edge notification */

 setup extra LogicPD PXA270 irqs */

 force read-only */

 5.7" TFT QVGA (LoLo display number 1) */

 12.1" TFT SVGA (LoLo display number 2) */

 3.6" TFT QVGA (LoLo display number 3) */

 6.4" TFT VGA (LoLo display number 5) */

 10.4" TFT VGA (LoLo display number 7) */

 3.5" TFT QVGA (LoLo display number 8) */

	/*

	 * System bus arbiter setting:

	 * - Core_Park

	 * - LCD_wt:DMA_wt:CORE_Wt = 2:3:4

 for use I SRAM as framebuffer.  */

 Maintainer: Peter Barada */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Hardware definitions for HP iPAQ h5xxx Handheld Computers

 *

 * Copyright 2000-2003  Hewlett-Packard Company.

 * Copyright 2002       Jamey Hicks <jamey.hicks@hp.com>

 * Copyright 2004-2005  Phil Blundell <pb@handhelds.org>

 * Copyright 2007-2008  Anton Vorontsov <cbouatmailru@gmail.com>

 *

 * COMPAQ COMPUTER CORPORATION MAKES NO WARRANTIES, EXPRESSED OR IMPLIED,

 * AS TO THE USEFULNESS OR CORRECTNESS OF THIS CODE OR ITS

 * FITNESS FOR ANY PARTICULAR PURPOSE.

 *

 * Author: Jamey Hicks.

/*

 * Flash

/*

 * USB Device Controller

/*

 * GPIO setup

 Crystal and Clock Signals */

 SDRAM and Static Memory I/O Signals */

 FFUART */

 BTUART */

 SSP1 */

 I2S */

/*

 * Localbus setup:

 * CS0: Flash;

 * CS1: MediaQ chip, select 16-bit bus and vlio;

 * CS5: SAMCOP.

/*

 * Platform devices

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hardware definitions for Palm LifeDrive

 *

 * Author:     Marek Vasut <marek.vasut@gmail.com>

 *

 * Based on work of:

 *		Alex Osborne <ato@meshy.org>

 *

 * (find more info at www.hackndev.com)

/******************************************************************************

 * Pin configuration

 MMC */

 SD detect */

 SD power */

 SD r/o switch */

 AC97 */

 IrDA */

 ir disable */

 MATRIX KEYPAD */

 LCD */

 PWM */

 GPIO KEYS */

 hotsync button */

 power switch */

 lock switch */

 LEDs */

 green led */

 orange led */

 PCMCIA */

 wifi power */

 wifi ready */

 wifi reset */

 FFUART */

 HDD */

 HDD reset */

 HDD power */

 MISC */

 earphone detect */

/******************************************************************************

 * NOR Flash

 bankwidth in bytes */

/******************************************************************************

 * GPIO keyboard

/******************************************************************************

 * GPIO keys

/******************************************************************************

 * LEDs

/******************************************************************************

 * HDD

/******************************************************************************

 * Machine init

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/mxm8x10.c

 *

 * Support for the Embedian MXM-8x10 Computer on Module

 *

 * Copyright (C) 2006 Marvell International Ltd.

 * Copyright (C) 2009 Embedian Inc.

 * Copyright (C) 2009 TMT Services & Supplies (Pty) Ltd.

 *

 * 2007-09-04: eric miao <eric.y.miao@gmail.com>

 *             rewrite to align with latest kernel

 *

 * 2010-01-09: Edwin Peer <epeer@tmtservices.co.za>

 * 	       Hennie van der Merwe <hvdmerwe@tmtservices.co.za>

 *             rework for upstream merge

/* GPIO pin definition



External device stuff   - Leave unconfigured for now...

---------------------

GPIO0   -   DREQ    (External DMA Request)

GPIO3   -   nGCS2   (External Chip Select) Where is nGCS0; nGCS1; nGCS4; nGCS5 ?

GPIO4   -   nGCS3

GPIO15  -   EXT_GPIO1

GPIO16  -   EXT_GPIO2

GPIO17  -   EXT_GPIO3

GPIO24  -   EXT_GPIO4

GPIO25  -   EXT_GPIO5

GPIO26  -   EXT_GPIO6

GPIO27  -   EXT_GPIO7

GPIO28  -   EXT_GPIO8

GPIO29  -   EXT_GPIO9

GPIO30  -   EXT_GPIO10

GPIO31  -   EXT_GPIO11

GPIO57  -   EXT_GPIO12

GPIO74  -   EXT_IRQ1

GPIO75  -   EXT_IRQ2

GPIO76  -   EXT_IRQ3

GPIO77  -   EXT_IRQ4

GPIO78  -   EXT_IRQ5

GPIO79  -   EXT_IRQ6

GPIO80  -   EXT_IRQ7

GPIO81  -   EXT_IRQ8

GPIO87  -   VCCIO_PWREN (External Device PWREN)



Dallas 1-Wire   - Leave unconfigured for now...

-------------

GPIO0_2 -   DS - 1Wire



Ethernet

--------

GPIO1   -   DM9000 PWR

GPIO9   -   DM9K_nIRQ

GPIO36  -   DM9K_RESET



Keypad  - Leave unconfigured by for now...

------

GPIO1_2 -   KP_DKIN0

GPIO5_2 -   KP_MKOUT7

GPIO82  -   KP_DKIN1

GPIO85  -   KP_DKIN2

GPIO86  -   KP_DKIN3

GPIO113 -   KP_MKIN0

GPIO114 -   KP_MKIN1

GPIO115 -   KP_MKIN2

GPIO116 -   KP_MKIN3

GPIO117 -   KP_MKIN4

GPIO118 -   KP_MKIN5

GPIO119 -   KP_MKIN6

GPIO120 -   KP_MKIN7

GPIO121 -   KP_MKOUT0

GPIO122 -   KP_MKOUT1

GPIO122 -   KP_MKOUT2

GPIO123 -   KP_MKOUT3

GPIO124 -   KP_MKOUT4

GPIO125 -   KP_MKOUT5

GPIO127 -   KP_MKOUT6



Data Bus    - Leave unconfigured for now...

--------

GPIO2   -   nWait (Data Bus)



USB Device

----------

GPIO4_2 -   USBD_PULLUP

GPIO10  -   UTM_CLK (USB Device UTM Clk)

GPIO49  -   USB 2.0 Device UTM_DATA0

GPIO50  -   USB 2.0 Device UTM_DATA1

GPIO51  -   USB 2.0 Device UTM_DATA2

GPIO52  -   USB 2.0 Device UTM_DATA3

GPIO53  -   USB 2.0 Device UTM_DATA4

GPIO54  -   USB 2.0 Device UTM_DATA5

GPIO55  -   USB 2.0 Device UTM_DATA6

GPIO56  -   USB 2.0 Device UTM_DATA7

GPIO58  -   UTM_RXVALID (USB 2.0 Device)

GPIO59  -   UTM_RXACTIVE (USB 2.0 Device)

GPIO60  -   UTM_RXERROR

GPIO61  -   UTM_OPMODE0

GPIO62  -   UTM_OPMODE1

GPIO71  -   USBD_INT    (USB Device?)

GPIO73  -   UTM_TXREADY (USB 2.0 Device)

GPIO83  -   UTM_TXVALID (USB 2.0 Device)

GPIO98  -   UTM_RESET   (USB 2.0 device)

GPIO99  -   UTM_XCVR_SELECT

GPIO100 -   UTM_TERM_SELECT

GPIO101 -   UTM_SUSPENDM_X

GPIO102 -   UTM_LINESTATE0

GPIO103 -   UTM_LINESTATE1



Card-Bus Interface  - Leave unconfigured for now...

------------------

GPIO5   -   nPIOR (I/O space output enable)

GPIO6   -   nPIOW (I/O space write enable)

GPIO7   -   nIOS16 (Input from I/O space telling size of data bus)

GPIO8   -   nPWAIT (Input for inserting wait states)



LCD

---

GPIO6_2     -   LDD0

GPIO7_2     -   LDD1

GPIO8_2     -   LDD2

GPIO9_2     -   LDD3

GPIO11_2    -   LDD5

GPIO12_2    -   LDD6

GPIO13_2    -   LDD7

GPIO14_2    -   VSYNC

GPIO15_2    -   HSYNC

GPIO16_2    -   VCLK

GPIO17_2    -   HCLK

GPIO18_2    -   VDEN

GPIO63      -   LDD8    (CPU LCD)

GPIO64      -   LDD9    (CPU LCD)

GPIO65      -   LDD10   (CPU LCD)

GPIO66      -   LDD11   (CPU LCD)

GPIO67      -   LDD12   (CPU LCD)

GPIO68      -   LDD13   (CPU LCD)

GPIO69      -   LDD14   (CPU LCD)

GPIO70      -   LDD15   (CPU LCD)

GPIO88      -   VCCLCD_PWREN (LCD Panel PWREN)

GPIO97      -   BACKLIGHT_EN

GPIO104     -   LCD_PWREN



PWM   - Leave unconfigured for now...

---

GPIO11  -   PWM0

GPIO12  -   PWM1

GPIO13  -   PWM2

GPIO14  -   PWM3



SD-CARD

-------

GPIO18  -   SDDATA0

GPIO19  -   SDDATA1

GPIO20  -   SDDATA2

GPIO21  -   SDDATA3

GPIO22  -   SDCLK

GPIO23  -   SDCMD

GPIO72  -   SD_WP

GPIO84  -   SD_nIRQ_CD  (SD-Card)



I2C

---

GPIO32  -   I2CSCL

GPIO33  -   I2CSDA



AC97

----

GPIO35  -   AC97_SDATA_IN

GPIO37  -   AC97_SDATA_OUT

GPIO38  -   AC97_SYNC

GPIO39  -   AC97_BITCLK

GPIO40  -   AC97_nRESET



UART1

-----

GPIO41  -   UART_RXD1

GPIO42  -   UART_TXD1

GPIO43  -   UART_CTS1

GPIO44  -   UART_DCD1

GPIO45  -   UART_DSR1

GPIO46  -   UART_nRI1

GPIO47  -   UART_DTR1

GPIO48  -   UART_RTS1



UART2

-----

GPIO109 -   RTS2

GPIO110 -   RXD2

GPIO111 -   TXD2

GPIO112 -   nCTS2



UART3

-----

GPIO105 -   nCTS3

GPIO106 -   nRTS3

GPIO107 -   TXD3

GPIO108 -   RXD3



SSP3    - Leave unconfigured for now...

----

GPIO89  -   SSP3_CLK

GPIO90  -   SSP3_SFRM

GPIO91  -   SSP3_TXD

GPIO92  -   SSP3_RXD



SSP4

GPIO93  -   SSP4_CLK

GPIO94  -   SSP4_SFRM

GPIO95  -   SSP4_TXD

GPIO96  -   SSP4_RXD

 USB */

 USBD_INT */

 UTM_PULLUP */

 DM9000 */

 AC97 */

 UARTS */

 I2C */

 MMC */

 Card Detect */

 Write Protect */

 IRQ */

 EXT_IRQ1 */

 EXT_IRQ2 */

 EXT_IRQ3 */

 EXT_IRQ4 */

 EXT_IRQ5 */

 EXT_IRQ6 */

 EXT_IRQ7 */

 EXT_IRQ8 */

 MMC/MCI Support */

 Card detect on GPIO 72 */

 Write protect on GPIO 84 */

 USB Open Host Controller Interface */

 AC97 Sound Support */

 NAND flash Support */

 IS_ENABLED(CONFIG_MTD_NAND_MARVELL) */

 Ethernet support: Davicom DM9000 */

 PXA UARTs */

 I2C and Real Time Clock */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/pxa27x.c

 *

 *  Author:	Nicolas Pitre

 *  Created:	Nov 05, 2002

 *  Copyright:	MontaVista Software Inc.

 *

 * Code specific to PXA27x aka Bulverde.

	/*

	 * This helper function is used to work around a bug in the pxa27x's

	 * ac97 controller during a warm reset.  The configuration of the

	 * reset_gpio is changed as follows:

	 * to_gpio == true: configured to generic output gpio and driven high

	 * to_gpio == false: configured to ac97 controller alt fn AC97_nRESET

/*

 * allow platforms to override default PWRMODE setting used for PM_SUSPEND_MEM

/*

 * List of global PXA peripheral registers to preserve.

 * More ones like CP and general purpose register values are preserved

 * with the stack pointer in sleep.S.

 ensure voltage-change sequencer not initiated, which hangs */

 Clear edge-detect status register. */

 Clear reset status */

 set resume return address */

 ensure not to come back here if it wasn't intended */

/* PXA27x:  Various gpios can issue wakeup events.  This logic only

 * handles the simple cases, not the WEMUX2 and WEMUX3 options

 Mem Ctl */

 UNCACHED_PHYS_0 */

/*

 * device registration specific to PXA27x.

 PXA25x, PXA27x and PXA3xx common entries */

 PXA27x specific map */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Support for Sharp SL-C6000x PDAs

 *  Model: (Tosa)

 *

 *  Copyright (c) 2005 Dirk Opfer

 *

 *	Based on code written by Sharp/Lineo for 2.4 kernels

 Scoop */

 tg6393xb */

 Scoop */

 GPIO76 CARD_VCC_ON1

 Reset out */

 WAKE_UP */

 AC_IN */

 RECORD */

 SYNC */

 EAR_IN */

 On */

 USB_IN */

 Pen IRQ */

 Jacket Detect */

 BAT0_CRG */

 BAT1_CRG */

 BAT0_LOW */

 BAT1_LOW */

 BAT_LOCK */

 TC6393XB IRQ */

 LCD Sync */

 MMC */

 Detect */

 nSD_INT */

 CF */

 CD_IRQ */

 Main Slot IRQ */

 Jacket Slot IRQ */

 AC97 */

 GPIO79 nAUD_IRQ

 FFUART */

 BTUART */

 Keybd */

 Column 0 */

 Column 1 */

 Column 2 */

 Column 3 */

 Column 4 */

 Column 5 */

 Column 6 */

 Column 7 */

 Column 8 */

 Column 9 */

 Column 10 */

 Row 0 */

 Row 1 */

 Row 2 */

 Row 3 */

 Row 4 */

 Row 5 */

 Row 6 */

 SPI */

 IrDA is managed in other way */

/*

 * SCOOP Device

/*

 * SCOOP Device Jacket

/*

 * PCMCIA

/*

 * USB Device Controller

/*

 * MMC/SD Device

/*

 * Irda

/*

 * Tosa AC IN

/*

 * Tosa Keyboard

	/*

	 * Two following keys are directly tied to "ON" button of tosa. Why?

	 * The first one can be used as a wakeup source, the second can't;

	 * also the first one is OR of ac_powered and on_button.

		/*

		 * can't be used as wakeup

		 * .wakeup	= 1,

/*

 * Tosa LEDs

/*

 * Toshiba Mobile IO Controller

 PLL divisor */

 PLL divisor */

 .platform_data

 Bootloader magic for a reboot */

 We can't pass to gpio-keys since it will drop the Reset altfunc */

 enable batt_fault */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/trizeps4.c

 *

 *  Support for the Keith und Koep Trizeps4 Module Platform.

 *

 *  Author:	Jrgen Schindele

 *  Created:	20 02, 2006

 *  Copyright:	Jrgen Schindele

/*	comment out the following line if you want to use the

 *	Standard UART from PXA for serial / irda transmission

/*****************************************************************************

 * MultiFunctionPins of CPU

 Chip Selects */

 DiskOnChip CS */

 TRIZEPS4_DOC_IRQ */

 DOC lock */

 DM9000 CS */

 TRIZEPS4_ETH_IRQ */

 Logic CS */

 Logic irq */

 AC97 */

 LCD - 16bpp Active TFT */

 UART */

 PCMCIA */

 TRIZEPS4_CD_IRQ */

 TRIZEPS4_READY_NINT */

 MultiMediaCard */

 TRIZEPS4_MMC_IRQ */

 USB OHCI */

 USBHPWR1 */

 USBHPEN1 */

 I2C */

 SSP 2 */

 TRIZEPS4_SPI_IRQ */

/****************************************************************************

 * ONBOARD FLASH

 force read-only */

 bankwidth in bytes */

/****************************************************************************

 * DAVICOM DM9000 Ethernet

/****************************************************************************

 * LED's on GPIO pins of PXA

 */

 */

 PCCARD power switching supports only 3,3V */

 switch power on, put in reset and enable buffers */

 wait a little */

 take reset away */

 put in reset */

 switch power off */

 backlight power switching for LCD panel */

 a I2C based RTC is known on CONXS board */

/****************************************************************************

 * MMC card slot external to module

 write-protection not supported */

 power-switching not supported */

/****************************************************************************

 * IRDA mode switching on stuart

 Switch mode */

 Slow mode */

 Fast mode */

 Switch power */

/****************************************************************************

 * OHCI USB port

 ConXS CFSR */

 ConXS BCR */

 ConXS IRCR */

 ConXS DCR */

 ConXS UPSR */

 dont know how to determine LCD */

 this is the reset value */

 if flash is 16 bit wide its a Trizeps4 WL */

 if flash is 32 bit wide its a Trizeps4 */

 MAINTAINER("Jrgen Schindele") */

 MAINTAINER("Jrgen Schindele") */

 SPDX-License-Identifier: GPL-2.0

/*

 * Static Memory Controller

 CSMSADRCFG wakes up in its default state (0), so we need to set it */

		/*

		 * The only documentation we have on the

		 * Chip Select Configuration Register (CSMSADRCFG) is that

		 * it must be programmed to 0x2.

		 * Moreover, in the bit definitions, the second bit

		 * (CSMSADRCFG[1]) is called "SETALWAYS".

		 * Other bits are reserved in this register.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/balloon3.c

 *

 *  Support for Balloonboard.org Balloon3 board.

 *

 *  Author:	Nick Bane, Wookey, Jonathan McDowell

 *  Created:	June, 2006

 *  Copyright:	Toby Churchill Ltd

 *  Derived from mainstone.c, by Nico Pitre

/******************************************************************************

 * Pin configuration

 Select BTUART 'COM1/ttyS0' as IO option for pins 42/43/44/45 */

 Reset, configured as GPIO wakeup source */

/******************************************************************************

 * Compatibility: Parameter parsing

/******************************************************************************

 * Compact Flash slot

/******************************************************************************

 * NOR Flash

 bankwidth in bytes */

/******************************************************************************

 * Audio and Touchscreen

/******************************************************************************

 * Framebuffer

/******************************************************************************

 * SD/MMC card controller

/******************************************************************************

 * USB Gadget

/******************************************************************************

 * IrDA

/******************************************************************************

 * USB Host

/******************************************************************************

 * LEDs

 NAND activity LED */

 Heartbeat LED */

/******************************************************************************

 * FPGA IRQ

 clear useless edge notification */

 setup extra Balloon3 irqs */

/******************************************************************************

 * GPIO expander

/******************************************************************************

 * NAND

 Assert all nCE lines */

 Deassert correct nCE line */

 Power up the NAND chips */

 Deassert all nCE lines and write protect line */

 Power down the NAND chips */

/******************************************************************************

 * Core power regulator

 730..1550 mV */

/******************************************************************************

 * Machine init

 CPLD/FPGA */

 Maintainer: Nick Bane. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Battery and Power Management code for the Sharp SL-C7xx

 *

 * Copyright (c) 2005 Richard Purdie

 2.9V */

 2.9V */

 6V */

 2V */

 3.45V */

 3.40V */

/*

 * Check what brought us out of the suspend.

 * Return: 0 to sleep, otherwise wake

 charge on */

 charge off */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/saar.c

 *

 *  Support for the Marvell PXA930 Handheld Platform (aka SAAR)

 *

 *  Copyright (C) 2007-2008 Marvell International Ltd.

 SAAR MFP configurations */

 LCD */

 LCD reset */

 Ethernet */

 DFI */

 single frame */

 calibration control */

Power-On Init sequence*/

 output ctrl */

 wave ctrl */

 entry mode */

 display ctrl 2 */

 display ctrl 3 */

 display ctrl 4 */

 Frame Marker position */

 Driver output control */

 Base image display control */

 Y settings 30h-3Dh */

 Timing(3), ASW HOLD=0.5CLK */

 Timing(4), CKV ST=0CLK, CKV ED=1CLK */

 Display control 1 */

 Power control 5 */

 Power control 1 */

 Power control 2 */

 Power control 3 */

 Power control 4 */

 Power control 3 */

 display mode : 240*320 */

 RAM address set(H) 0*/

 RAM address set(V)   4*/

 Start of Window RAM address set(H) 8*/

 End of Window RAM address set(H) 12*/

 Start of Window RAM address set(V) 16*/

 End of Window RAM address set(V) 20*/

 Panel interface control 1 */

 Panel interface control 2 */

 Panel interface control 3 */

 set display ram: 240*320 */

 RAM address set(H) 0*/

 RAM address set(V) 4*/

 Start of Window RAM address set(H) 8 */

 End of Window RAM address set(H) 12 */

 Start of Window RAM address set(V) 16 */

 End of Window RAM address set(V) 20 */

 wait for vsync cmd before transferring frame data */

 write ram */

 write frame data */

 L_LCLK_A0 and L_LCLK_RD active low */

 4mA */

 initialize MFP configurations */

 Maintainer: Eric Miao <eric.miao@marvell.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Support for Cogent CSB726

 *

 *  Copyright (c) 2008 Dmitry Eremin-Solenikov

/*

 * n/a: 2, 5, 6, 7, 8, 23, 24, 25, 26, 27, 87, 88, 89,

 * nu: 58 -- 77, 90, 91, 93, 102, 105-108, 114-116,

 * XXX: 21,

 * XXX: 79 CS_3 for LAN9215 or PSKTSEL on R2, R3

 * XXX: 33 CS_5 for LAN9215 on R1

 EXP_CS */

 SMSC9215 */

 SM501 */

 #SMSC9251 int */

 SM501 int */

 GPIO0 */

 GPIO1 */

 GPIO2 */

 GPIO3 */

 or GPIO4 */

 or GPIO5 */

 GPIO6 */

 GPIO7 */

 GPIO8 */

 GPIO9 */

 EXP_IRQ */

 EXP_WAIT */

 PWR_INT */

 PWR_OFF */

 touch irq */

 SSP2_SYSCLK */

 SDIO int */

 SD CD */

 SD WP */

 maybe unused */

 CF IRQ */

 CF CD */

 Reset */

 FIXME setpower */

 Card detect on GPIO 100 */

 Write protect on GPIO 101 */

 force read-only */

	.devices	= SM501_USE_USB_HOST, */

* LAN9215/EXP_CS */
 LAN9215/EXP_CS */

* none/SM501 */
 none/SM501 */

 SM501 */

 SPDX-License-Identifier: GPL-2.0

 CONFIG_PXA3xx */

 ASSP is basically equivalent to NSSP */

 CONFIG_PXA25x */

 This is used to put cameras on this interface */

 Register a fixed-rate clock for camera sensors. */

 CONFIG_PXA27x || CONFIG_PXA3xx */

 CONFIG_PXA27x || CONFIG_PXA3xx */

 CONFIG_PXA3xx */

/*

 * PXA3xx SSP is basically equivalent to PXA27x.

 * However, we need to register the device by the correct name in order to

 * make the driver set the correct internal type, hence we provide specific

 * platform_devices for each of them.

 CONFIG_PXA3xx */

/* pxa2xx-spi platform-device ID equals respective SSP platform-device ID + 1.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/poodle.c

 *

 *  Support for the SHARP Poodle Board.

 *

 * Based on:

 *  linux/arch/arm/mach-pxa/lubbock.c Author:	Nicolas Pitre

 *

 * Change Log

 *  12-Dec-2002 Sharp Corporation for Poodle

 *  John Lenz <lenz@cs.wisc.edu> updates to 2.6

 I/O */

 Clock */

 SSP1 */

 POODLE_GPIO_TP_CS - SFRM as chip select */

 I2S */

 Infra-Red */

 FFUART */

 LCD */

 PC Card */

 MMC */

 GPIO */

 POODLE_GPIO_nSD_DETECT */

 POODLE_GPIO_nSD_WP */

 POODLE_GPIO_SD_PWR */

 POODLE_GPIO_SD_PWR1 */

 POODLE_GPIO_USB_PULLUP */

 POODLE_GPIO_IR_ON */

 LoCoMo device */

/*

 * MMC/SD Device

 *

 * The card detect interrupt isn't debounced so we delay it by 250ms

 * to give the card a chance to fully insert/eject.

/*

 * Irda

/*

 * USB Device Controller

 no connect GPIO; poodle can't tell connection status */

 PXAFB device */

 4 for LoCoMo */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hardware definitions for PalmTX

 *

 * Author:     Marek Vasut <marek.vasut@gmail.com>

 *

 * Based on work of:

 *		Alex Osborne <ato@meshy.org>

 *		Cristiano P. <cristianop@users.sourceforge.net>

 *		Jan Herman <2hp@seznam.cz>

 *		Michal Hrusecky

 *

 * (find more info at www.hackndev.com)

/******************************************************************************

 * Pin configuration

 MMC */

 SD detect */

 SD power */

 SD r/o switch */

 AC97 */

 IrDA */

 ir disable */

 PWM */

 USB */

 usb detect */

 usb power */

 PCMCIA */

 wifi power 1 */

 wifi power 2 */

 wifi ready */

 MATRIX KEYPAD */

 LCD */

 FFUART */

 NAND */

 MISC. */

 hotsync button */

 power detect */

 earphone detect */

/******************************************************************************

 * NOR Flash

 bankwidth in bytes */

/******************************************************************************

 * GPIO keyboard

/******************************************************************************

 * GPIO keys

/******************************************************************************

 * NAND Flash

/******************************************************************************

 * Machine init

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  arch/arm/mach-pxa/colibri-pxa3xx.c

 *

 *  Common functions for all Toradex PXA3xx modules

 *

 *  Daniel Mack <daniel@caiaq.de>

	/*

	 * If the bootloader passed in a serial boot tag, which contains a

	 * valid ethernet MAC, pass it to the interface. Toradex ships the

	 * modules with their own bootloader which provides a valid MAC

	 * this way.

/*

 * LCD panel (Sharp LQ043T3DX02)

 force read-only */

 force read-only */

 force read-only */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/idp.c

 *

 *  Copyright (c) 2001 Cliff Brake, Accelent Systems Inc.

 *

 *  2001-09-13: Cliff Brake <cbrake@accelent.com>

 *              Initial code

 *

 *  2005-02-15: Cliff Brake <cliff.brake@gmail.com>

 *  		<http://www.vibren.com> <http://bec-systems.com>

 *              Updated for 2.6 kernel

/* TODO:

 * - add pxa2xx_audio_ops_t device structure

 * - Ethernet interrupt

 LCD */

 BTUART */

 STUART */

 MMC */

 Ethernet */

 Ethernet CS */

 Ethernet IRQ */

	/* call idp_vlcd for now as core driver does not support

	 * both power and vlcd hooks.  Note, this is not technically

	 * the correct sequence, but seems to work.  Disclaimer:

	 * this may eventually damage the display.

platform_device_register(&mst_audio_device);

 LEDs */

/*

 * The triggers lines up below will only be used if the

 * LED triggers are compiled in.

/*

 * Since we may have triggers on any subsystem, defer registration

 * until after subsystem_init.

 Maintainer: Vibren Technologies */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Handles the Mitac Mio A701 Board

 *

 * Copyright (C) 2008 Robert Jarzmik

 Mio global */

 Backlight PWM 0 */

 MMC */

 USB */

 LCD */

 QCI */

 Bluetooth */

 GPS */

 GSM */

 Sound */

 Leds */

 Keyboard */

 I2C */

 Unknown */

 LCD Screen and Backlight */

/*

 * LTM0305A776C LCD panel timings

 *

 * see:

 *  - the LTM0305A776C datasheet,

 *  - and the PXA27x Programmers' manual

 CLK=4.545 MHz */

/*

 * Keyboard configuration

 GPS key */

 Phone Green key */

 Camera key */

/*

 * GPIO Key Configuration

/*

 * Leds and vibrator

/*

 * GSM Sagem XS200 chip

 *

 * GSM handling was purged from kernel. For history, this is the way to go :

 *   - init : GPIO24_GSM_MOD_RESET_CMD = 0, GPIO114_GSM_nMOD_DTE_UART_STATE = 1

 *            GPIO88_GSM_nMOD_ON_CMD = 1, GPIO90_GSM_nMOD_OFF_CMD = 1

 *   - reset : GPIO24_GSM_MOD_RESET_CMD = 1, msleep(100),

 *             GPIO24_GSM_MOD_RESET_CMD = 0

 *   - turn on  : GPIO88_GSM_nMOD_ON_CMD = 0, msleep(1000),

 *                GPIO88_GSM_nMOD_ON_CMD = 1

 *   - turn off : GPIO90_GSM_nMOD_OFF_CMD = 0, msleep(1000),

 *                GPIO90_GSM_nMOD_OFF_CMD = 1

/*

 * Bluetooth BRF6150 chip

 *

 * BT handling was purged from kernel. For history, this is the way to go :

 * - turn on  : GPIO83_BT_ON = 1

 * - turn off : GPIO83_BT_ON = 0

/*

 * GPS Sirf Star III chip

 *

 * GPS handling was purged from kernel. For history, this is the way to go :

 * - init : GPIO23_GPS_UNKNOWN1 = 1, GPIO26_GPS_ON = 0, GPIO27_GPS_RESET = 0

 *          GPIO106_GPS_UNKNOWN2 = 0, GPIO107_GPS_UNKNOWN3 = 0

 * - turn on  : GPIO27_GPS_RESET = 1, GPIO26_GPS_ON = 1

 * - turn off : GPIO26_GPS_ON = 0, GPIO27_GPS_RESET = 0

/*

 * USB UDC

/*

 * SDIO/MMC Card controller

/**

 * The card detect interrupt isn't debounced so we delay it by 250ms

 * to give the card a chance to fully insert/eject.

 Card detect on GPIO 15 */

 Write protect on GPIO 78 */

 Power on GPIO 91 */

 FlashRAM */

/*

 * Suspend/Resume bootstrap management

 *

 * MIO A701 reboot sequence is highly ROM dependent. From the one dissassembled,

 * this sequence is as follows :

 *   - disables interrupts

 *   - initialize SDRAM (self refresh RAM into active RAM)

 *   - initialize GPIOs (depends on value at 0xa020b020)

 *   - initialize coprossessors

 *   - if edge detect on PWR_SCL(GPIO3), then proceed to cold start

 *   - or if value at 0xa020b000 not equal to 0x0f0f0f0f, proceed to cold start

 *   - else do a resume, ie. jump to addr 0xa0100000

 Devices prepare suspend */

/*

 * Power Supply

/*

 * Voltage regulation

 700..1475 mV */

/*

 * Camera interface

 Board I2C devices. */

/*

 * Mio global

 Devices */

 SYSDEL=125ms, PWRDEL=125ms, PSLR_SL_ROD=1 */

 Reset crazy WinCE value */

	/*

	 * Set up the flash memory : DiskOnChip G3 on first static memory bank

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Battery and Power Management code for the Sharp SL-C7xx and SL-Cxx00

 * series of PDAs

 *

 * Copyright (c) 2004-2005 Richard Purdie

 *

 * Based on code written by Sharp for 2.4 kernels

/*

 * Constants

 1 min */

 10 min */

 15 sec */

 10 min */

 15 sec */

 100 msec */

 10 msec */

 10 msec */

 10 msec */

 15 msec */

 5 msec */

 eqv. 10 min */

/*

 * Prototypes

/*

 * Variables

 MAX1111 Commands */

/*

 * Read MAX1111 ADC

 Ugly, better move this function into another module */

	/* max1111 accepts channels from 0-3, however,

	 * it is encoded from 0-7 here in the code.

 Corgi cannot confirm when battery fully charged so periodically kick! */

	/* At low battery voltages, the voltage has a tendency to start

 Suspend if critical battery level */

 Delay the event slightly to debounce */

 Must be a smaller delay than the chrg_full_isr below */

 Charging Finished Interrupt (Not present on Corgi) */

/* Can trigger at the same time as an AC status change so

 delay until after any ac interrupt */

/*

 * Maintain an average of the last 10 readings

/*

 * Take an array of 5 integers, remove the maximum and minimum values

 * and return the average.

 Find MAX val */

 Find MIN val */

 Check battery temperature */

 disable charge, enable discharge */

 Check battery voltage */

 Clear the reset source indicators as they break the bootloader upon reboot */

 not charging and AC-IN! */

 clear it */

/*

 * Charging Control while suspended

 * Return 1 - go straight to sleep

 * Return 0 - sleep or wakeup depending on other factors

 AC Check */

 Start Charging */

 Check if any wakeup event had occurred */

 Check for timeout */

 Check if any wakeup event had occurred */

 Check for timeout */

 Register interrupt handlers */

 Register interrupt handler. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/lubbock.c

 *

 *  Support for the Intel DBPXA250 Development Platform.

 *

 *  Author:	Nicolas Pitre

 *  Created:	Jun 15, 2001

 *  Copyright:	MontaVista Software Inc.

 CS1 - Flash */

 CS2 - Baseboard FGPA */

 CS3 - SMC ethernet */

 CS4 - SA1111 */

 SSP data pins */

 AC97 */

 LCD - 16bpp DSTN */

 BTUART */

 PC Card */

 MMC */

 SA1111 chip */

 wakeup */

 no D+ pullup; lubbock can't connect/disconnect in software

 GPIOs for SA1111 PCMCIA */

 Add an alias for the SA1111 PCMCIA clock */

/* ADS7846 is connected through SSP ... and if your board has J5 populated,

 * you can select it to replace the ucb1400 by switching the touchscreen cable

 * (to J5) and poking board registers (as done below).  Else it's only useful

 * for the temperature sensors.

 TS_BUSY is bit 8 in LUB_MISC_RD, but pendown is irq-only */

 internal, no cap */

 .x_plate_ohms		= 500,	/* GUESS! */

 .y_plate_ohms		= 500,	/* GUESS! */

 max sample rate at 3V */

 command + data + overhead */,

 force read-only */

 clear any previous irq state, then ... */

 poll until mmc/sd card is removed */

 IRQ is level triggered; disable, and poll for removal */

 detect card insert/eject */

 Compensate for the nROMBT switch which swaps the flash banks */

 CPLD */

/*

 * Driver for the 8 discrete LEDs available for general use:

 * Note: bits [15-8] are used to enable/blank the 8 7 segment hex displays

 * so be sure to not monkey with them here.

/*

 * The triggers lines up below will only be used if the

 * LED triggers are compiled in.

 All ON */

/*

 * Since we may have triggers on any subsystem, defer registration

 * until after subsystem_init.

 Maintainer: MontaVista Software Inc. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/zylonite.c

 *

 * Support for the PXA3xx Development Platform (aka Zylonite)

 *

 * Copyright (C) 2006 Marvell International Ltd.

 *

 * 2007-09-04: eric miao <eric.miao@marvell.com>

 *             rewrite to align with latest kernel

 for run-time assignment */

	/* legacy LCD panels, it would be handy here if LCD panel type can

	 * be decided at run-time

 KEY(row, col, key_code) */

 * */

 #" */

 KEY_LEFTSHIFT), */

 scroll push */

 keypad action */

 soft1 */

 soft2 */

 contact */

 force read-only */

 force read-only */

 48M - rootfs */

 force read-only */

	/* NOTE: we reserve some blocks at the end of the NAND flash for

	 * bad block management, and the max number of relocation blocks

	 * differs on different platforms. Please take care with it when

	 * defining the partition table.

 IS_ENABLED(CONFIG_MTD_NAND_MARVELL) */

 CONFIG_USB_OHCI_HCD || CONFIG_USB_OHCI_HCD_MODULE */

 board-processor specific initialization */

	/*

	 * Note: We depend that the bootloader set

	 * the correct value to MSC register for SMC91x.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/pxa300.c

 *

 * Code specific to PXA300/PXA310

 *

 * Copyright (C) 2007 Marvell Internation Ltd.

 *

 * 2007-08-21: eric miao <eric.miao@marvell.com>

 *             initial version

 override pxa300 MFP register addresses */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/pxa3xx.c

 *

 * code specific to pxa3xx aka Monahans

 *

 * Copyright (C) 2006 Marvell International Ltd.

 *

 * 2007-09-02: eric miao <eric.miao@marvell.com>

 *             initial version

/*

 * NAND NFC: DFI bus arbitration subset

/*

 * Enter a standby mode (S0D1C2 or S0D2C2).  Upon wakeup, the dynamic

 * memory controller has to be reinitialised, so we place some code

 * in the SRAM to perform this function.

 *

 * We disable FIQs across the standby - otherwise, we might receive a

 * FIQ while the SDRAM is unavailable.

/*

 * NOTE:  currently, the OBM (OEM Boot Module) binary comes along with

 * PXA3xx development kits assumes that the resuming process continues

 * with the address stored within the first 4 bytes of SDRAM. The PSPR

 * register is used privately by BootROM and OBM, and _must_ be set to

 * 0x5c014000 for the moment.

 resuming from D2 requires the HSIO2/BOOT/TPM clocks enabled */

 clear and setup wakeup source */

 L1_DIS */

 L0_EN | SL_ROD */

 overwrite with the resume address */

	/*

	 * Don't sleep if no wakeup sources are defined

	/*

	 * Since we copy wakeup code into the SRAM, we need to ensure

	 * that it is preserved over the low power modes.  Note: bit 8

	 * is undocumented in the developer manual, but must be set.

	/*

	 * Clear the resume enable registers.

 enable CP6 access */

 CONFIG_OF */

 Mem Ctl */

/*

 * device registration specific to PXA3xx.

 PXA25x, PXA27x and PXA3xx common entries */

 PXA3xx specific map */

		/*

		 * clear RDH bit every time after reset

		 *

		 * Note: the last 3 bits DxS are write-1-to-clear so carefully

		 * preserve them here in case they will be referenced later

		/*

		 * Disable DFI bus arbitration, to prevent a system bus lock if

		 * somebody disables the NAND clock (unused clock) while this

		 * bit remains set.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/palmtc.c

 *

 * Support for the Palm Tungsten|C

 *

 * Author:	Marek Vasut <marek.vasut@gmail.com>

 *

 * Based on work of:

 *		Petr Blaha <p3t3@centrum.cz>

 *		Chetan S. Kumar <shivakumar.chetan@gmail.com>

/******************************************************************************

 * Pin configuration

 MMC */

 detect */

 power */

 r/o switch */

 PCMCIA */

 AC97 */

 IrDA */

 ir disable */

 PWM */

 USB */

 detect */

 pullup */

 LCD */

 MATRIX KEYPAD */

 in 0 */

 in 1 */

 in 2 */

 in 3 */

 out 0 */

 out 1 */

 out 2 */

 out 3 */

 out 4 */

 out 5 */

 out 6 */

 out 7 */

 out 8 */

 out 9 */

 out 10 */

 out 11 */

 PXA GPIO KEYS */

 hotsync button on cradle */

 MISC */

 reset */

 earphone detect */

 backlight switch */

/******************************************************************************

 * SD/MMC card controller

/******************************************************************************

 * GPIO keys

/******************************************************************************

 * Backlight

/******************************************************************************

 * IrDA

/******************************************************************************

 * Keyboard

/******************************************************************************

 * UDC

/******************************************************************************

 * Touchscreen / Battery / GPIO-extender

/******************************************************************************

 * LEDs

/******************************************************************************

 * NOR Flash

/******************************************************************************

 * Framebuffer

/******************************************************************************

 * Machine init

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Bluetooth built-in chip control

 *

 * Copyright (c) 2008 Dmitry Baryshkov

/*

 * am300epd.c -- Platform device for AM300 EPD kit

 *

 * Copyright (C) 2008, Jaya Kumar

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License. See the file COPYING in the main directory of this archive for

 * more details.

 *

 * This work was made possible by help and equipment support from E-Ink

 * Corporation. http://support.eink.com/community

 *

 * This driver is written to be used with the Broadsheet display controller.

 * on the AM300 EPD prototype kit/development kit with an E-Ink 800x600

 * Vizplex EPD on a Gumstix board using the Broadsheet interface board.

 *

 this is the 16-bit hdb bus 58-73 */

 register offsets for gpio control */

 hdb bus */

 todo: improve err recovery */

 we also need to take care of the hdb bus */

 setup the outputs and init values */

 setup the inputs */

 start the hdb bus as an input */

 go into command mode */

 request our platform independent driver */

 the am300_board that will be seen by broadsheetfb is a copy */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/viper.c

 *

 *  Support for the Arcom VIPER SBC.

 *

 *  Author:	Ian Campbell

 *  Created:    Feb 03, 2003

 *  Copyright:  Arcom Control Systems

 *

 *  Maintained by Marc Zyngier <maz@misterjones.org>

 *                             <marc.zyngier@altran.com>

 *

 * Based on lubbock.c:

 *  Author:	Nicolas Pitre

 *  Created:	Jun 15, 2001

 *  Copyright:	MontaVista Software Inc.

 This function is used from the pcmcia module to reset the CF */

/*

 * The CPLD version register was not present on VIPER boards prior to

 * v2i1. On v1 boards where the version register is not present we

 * will just read back the previous value from the databus.

 *

 * Therefore we do two reads. The first time we write 0 to the

 * (read-only) register before reading and the second time we write

 * 0xff first. If the two reads do not match or they read back as 0xff

 * or 0x00 then we have version 1 hardware.

 CPU system core operations. */

/*

 * If force is not true then step from existing to new divisor. If

 * force is true then jump straight to the new divisor. Stepping is

 * used because if the jump in voltage is too large, the VCC can dip

 * too low and the regulator cuts out.

 *

 * force can be used to initialize the divisor to a know state by

 * setting the value for the current clock speed, since we are already

 * running at that speed we know the voltage should be pretty close so

 * the jump won't be too large

 Interrupt handling */

 ISA irq #0, invalid */

 ISA irq #1, invalid */

 ISA irq #2, invalid */

 ISA irq #3 */

 ISA irq #4 */

 ISA irq #5 */

 ISA irq #6 */

 ISA irq #7 */

 ISA irq #8, invalid */

 ISA irq #9 */

 ISA irq #10 */

 ISA irq #11 */

 ISA irq #12 */

 ISA irq #13, invalid */

 ISA irq #14 */

 ISA irq #15 */

		/* we're in a chained irq handler,

 setup ISA IRQs */

 Flat Panel */

 GPIO9 and 10 control FB backlight. Initialise to off */

 Ethernet */

 i2c */

 pxa2xx-i2c is bus 0, so start at 1 */

/*

 * Serial configuration:

 * You can either have the standard PXA ports driven by the PXA driver,

 * or all the ports (PXA + 16850) driven by the 8250 driver.

 * Choose your poison.

 Internal UARTs */

 External UARTs */

 USB */

 DATA */

 ADDR */

 (DataBusWidth16|AnalogOCEnable|DREQOutputPolarity|DownstreamPort15KRSel ) */

 Enable internal resistors on downstream ports */

 On-chip overcurrent protection */

 INT output polarity */

 INT edge or level triggered */

 WAKEUP pin connected - NOT SUPPORTED  */

 .remote_wakeup_connected = 0, */

 Wakeup by devices on usb bus enabled */

 MTD */

 RedBoot config + filesystem flash */

 Boot flash */

	[2] = { /*

		 * SRAM size is actually 256KB, 8bits, with a sparse mapping

		 * (each byte is on a 16bit boundary).

 force R/O */

 Chip selects */

 AC97 */

 FP Backlight */

 VIPER_BCKLIGHT_EN_GPIO */

 VIPER_LCD_EN_GPIO */

 Ethernet PHY Ready */

 Serial shutdown */

 VIPER_UART_SHDN_GPIO */

 Compact-Flash / PC104 */

 VIPER_CF_RDY_GPIO */

 VIPER_CF_CD_GPIO */

 VIPER_CF_POWER_GPIO */

 Integrated UPS control */

 VIPER_UPS_GPIO */

 Vcc regulator control */

 VIPER_PSU_DATA_GPIO */

 VIPER_PSU_CLK_GPIO */

 VIPER_PSU_nCS_LD_GPIO */

 i2c busses */

 VIPER_TPM_I2C_SDA_GPIO */

 VIPER_TPM_I2C_SCL_GPIO */

 VIPER_RTC_I2C_SDA_GPIO */

 VIPER_RTC_I2C_SCL_GPIO */

 PC/104 Interrupt */

 VIPER_CPLD_GPIO */

 Allocate TPM i2c bus if requested */

 c/should assume redboot set the correct level ??? */

 TODO: Adjust timings??? */

			/* we are getting faster so raise the voltage

			/* we are slowing down so drop the power

 ignore */

 Spin to death... */

 Wake-up serial console */

 v1 hardware cannot use the datacs line */

 Maintainer: Marc Zyngier <maz@misterjones.org> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/z2.c

 *

 *  Support for the Zipit Z2 Handheld device.

 *

 *  Copyright (C) 2009-2010 Marek Vasut <marek.vasut@gmail.com>

 *

 *  Based on research and code by: Ken McGuire

 *  Based on mainstone.c as modified for the Zipit Z2.

/******************************************************************************

 * Pin configuration

 LCD - 16bpp Active TFT */

 LCD reset */

 LCD chipselect */

 PWM */

 Keypad Backlight */

 LCD Backlight */

 MMC */

 SD detect */

 STUART */

 Keypad */

 I2C */

 SSP1 */

 SSP1_SCK */

 SSP1_TXD */

 SSP1_RXD */

 SSP2 */

 SSP2_SCK */

 SSP2_TXD */

 SSP2_RXD */

 LEDs */

 WiFi LED */

 Charging LED */

 Charged LED */

 I2S */

 MISC */

 AC power detect */

 Power button */

 Headphone detect */

 Lid switch */

 WiFi Power */

 WiFi CS */

 WiFi IRQ */

 LCD CS */

/******************************************************************************

 * NOR Flash

/******************************************************************************

 * Backlight

 Keypad Backlight */

 LCD Backlight */

/******************************************************************************

 * Framebuffer

/******************************************************************************

 * SD/MMC card controller

/******************************************************************************

 * LEDs

/******************************************************************************

 * GPIO keyboard

/******************************************************************************

 * GPIO keys

/******************************************************************************

 * Battery

/******************************************************************************

 * SSP Devices - WiFi and LCD control

 WiFi */

 Wait until card is powered on */

 LCD */

 SPI bus 2 chip select 0 */

/******************************************************************************

 * Core power regulator

	/* We're using deep sleep as poweroff, so clear PSPR to ensure that

	 * bootloader will jump to its entry point in resume handler

/******************************************************************************

 * Machine init

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/pxa-dt.c

 *

 *  Copyright (C) 2012 Daniel Mack

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/generic.c

 *

 *  Author:	Nicolas Pitre

 *  Created:	Jun 15, 2001

 *  Copyright:	MontaVista Software Inc.

 *

 * Code common to all PXA machines.

 *

 * Since this file should be linked before any other machine specific file,

 * the __initcall() here will be executed first.  This serves as default

 * initialization stuff for PXA machines which can be overridden later if

 * need be.

 RESET_STATUS_* has a 1:1 mapping with ARSR */

/*

 * For non device-tree builds, keep legacy timer init

/*

 * Get the clock frequency as reflected by CCCR and the turbo flag.

 * We assume these values have been applied via a fcs.

 * If info is not 0 we also display the current settings.

/*

 * Intel PXA2xx internal register mapping.

 *

 * Note: virtual 0xfffe0000-0xffffffff is reserved for the vector table

 *       and cache flush area.

 Devs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Support for the Arcom ZEUS.

 *

 *  Copyright (C) 2006 Arcom Control Systems Ltd.

 *

 *  Loosely based on Arcom's 2.6.16.28.

 *  Maintained by Marc Zyngier <maz@misterjones.org>

/*

 * Interrupt handling

 ISA irq #0, invalid */

 ISA irq #1, invalid */

 ISA irq #2, invalid */

 ISA irq #3 */

 ISA irq #4 */

 ISA irq #5 */

 ISA irq #6 */

 ISA irq #7 */

 ISA irq #8, invalid */

 ISA irq #9, invalid */

 ISA irq #10 */

 ISA irq #11 */

 ISA irq #12 */

		/* we're in a chained irq handler,

	/* Peripheral IRQs. It would be nice to move those inside driver

 Setup ISA IRQs */

/*

 * Platform devices

 Flash */

 NOR Flash (up to 64MB) */

 SRAM */

 Serial */

 External UARTs */

 FIXME: Shared IRQs on COM1-COM4 will not work properly on v1i1 hardware. */

 COM1 */

 COM2 */

 COM3 */

 COM4 */

 Internal UARTs */

 FFUART */

 BTUART */

 STUART */

 Ethernet */

 External SRAM */

 SPI interface on SSP3 */

 CAN bus on SPI */

 Leds */

 AC'97 */

/*

 * USB host

 5.0V */

	/* Clear Power Control Polarity Low and set Power Sense

 Port 2 is shared between host and client interface. */

/*

 * Flat Panel

/*

 * MMC/SD Device

 *

 * The card detect interrupt isn't debounced so we delay it by 250ms

 * to give the card a chance to fully insert/eject.

/*

 * USB Device Controller

 Power supply is always present */

 AC97 */

 CF CD */

 CF PWREN */

 CF RDY */

/*

 * DM9k MSCx settings:	SRAM, 16 bits

 *			17 cycles delay first access

 *			 5 cycles delay next access

 *			13 cycles recovery time

 *			faster device

 Fix timings for dm9000s (CS1/CS2)*/

 Clear PSPR to ensure a full restart on wake-up. */

 enable internal 32.768Khz oscillator (ignore OSCC_OOK) */

	/* Some clock cycles later (from OSCC_ON), programme PCFR (OPDE...).

 Maintainer: Marc Zyngier <maz@misterjones.org> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  arch/arm/mach-pxa/pcm990-baseboard.c

 *  Support for the Phytec phyCORE-PXA270 Development Platform (PCM-990).

 *

 *  Refer

 *   http://www.phytec.com/products/rdk/ARM-XScale/phyCORE-XScale-PXA270.html

 *  for additional hardware info

 *

 *  Author:	Juergen Kilb

 *  Created:	April 05, 2005

 *  Copyright:	Phytec Messtechnik GmbH

 *  e-Mail:	armlinux@phytec.de

 *

 *  based on Intel Mainstone Board

 *

 *  Copyright 2007 Juergen Beisert @ Pengutronix (j.beisert@pengutronix.de)

 MMC */

 USB */

 PWM0 */

 I2C */

 AC97 */

/*

 * pcm990_lcd_power - control power supply to the LCD

 * @on: 0 = switch off, 1 = switch on

 *

 * Called by the pxafb driver

		/* enable LCD-Latches

		 * power on LCD

		/* disable LCD-Latches

		 * power off LCD

/*

 * The PCM-990 development baseboard uses PCM-027's hardware in the

 * following way:

 *

 * - LCD support is in use

 *  - GPIO16 is output for back light on/off with PWM

 *  - GPIO58 ... GPIO73 are outputs for display data

 *  - GPIO74 is output output for LCDFCLK

 *  - GPIO75 is output for LCDLCLK

 *  - GPIO76 is output for LCDPCLK

 *  - GPIO77 is output for LCDBIAS

 * - MMC support is in use

 *  - GPIO32 is output for MMCCLK

 *  - GPIO92 is MMDAT0

 *  - GPIO109 is MMDAT1

 *  - GPIO110 is MMCS0

 *  - GPIO111 is MMCS1

 *  - GPIO112 is MMCMD

 * - IDE/CF card is in use

 *  - GPIO48 is output /POE

 *  - GPIO49 is output /PWE

 *  - GPIO50 is output /PIOR

 *  - GPIO51 is output /PIOW

 *  - GPIO54 is output /PCE2

 *  - GPIO55 is output /PREG

 *  - GPIO56 is input /PWAIT

 *  - GPIO57 is output /PIOS16

 *  - GPIO79 is output PSKTSEL

 *  - GPIO85 is output /PCE1

 * - FFUART is in use

 *  - GPIO34 is input FFRXD

 *  - GPIO35 is input FFCTS

 *  - GPIO36 is input FFDCD

 *  - GPIO37 is input FFDSR

 *  - GPIO38 is input FFRI

 *  - GPIO39 is output FFTXD

 *  - GPIO40 is output FFDTR

 *  - GPIO41 is output FFRTS

 * - BTUART is in use

 *  - GPIO42 is input BTRXD

 *  - GPIO43 is output BTTXD

 *  - GPIO44 is input BTCTS

 *  - GPIO45 is output BTRTS

 * - IRUART is in use

 *  - GPIO46 is input STDRXD

 *  - GPIO47 is output STDTXD

 * - AC97 is in use*)

 *  - GPIO28 is input AC97CLK

 *  - GPIO29 is input AC97DatIn

 *  - GPIO30 is output AC97DatO

 *  - GPIO31 is output AC97SYNC

 *  - GPIO113 is output AC97_RESET

 * - SSP is in use

 *  - GPIO23 is output SSPSCLK

 *  - GPIO24 is output chip select to Max7301

 *  - GPIO25 is output SSPTXD

 *  - GPIO26 is input SSPRXD

 *  - GPIO27 is input for Max7301 IRQ

 *  - GPIO53 is input SSPSYSCLK

 * - SSP3 is in use

 *  - GPIO81 is output SSPTXD3

 *  - GPIO82 is input SSPRXD3

 *  - GPIO83 is output SSPSFRM

 *  - GPIO84 is output SSPCLK3

 *

 * Otherwise claimed GPIOs:

 * GPIO1 -> IRQ from user switch

 * GPIO9 -> IRQ from power management

 * GPIO10 -> IRQ from WML9712 AC97 controller

 * GPIO11 -> IRQ from IDE controller

 * GPIO12 -> IRQ from CF controller

 * GPIO13 -> IRQ from CF controller

 * GPIO14 -> GPIO free

 * GPIO15 -> /CS1 selects baseboard's Control CPLD (U7, 16 bit wide data path)

 * GPIO19 -> GPIO free

 * GPIO20 -> /SDCS2

 * GPIO21 -> /CS3 PC card socket select

 * GPIO33 -> /CS5  network controller select

 * GPIO78 -> /CS2  (16 bit wide data path)

 * GPIO80 -> /CS4  (16 bit wide data path)

 * GPIO86 -> GPIO free

 * GPIO87 -> GPIO free

 * GPIO90 -> LED0 on CPU module

 * GPIO91 -> LED1 on CPI module

 * GPIO117 -> SCL

 * GPIO118 -> SDA

 the irq can be acknowledged only if deasserted, so it's done here */

 clear our parent IRQ */

 setup extra PCM990 irqs */

 disable all Interrupts */

/*

 * system init for baseboard usage. Will be called by pcm027 init.

 *

 * Add platform devices present on this baseboard and init

 * them from CPU side as far as required to use them later on

 register CPLD's IRQ controller */

 MMC */

 USB host */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for Sharp SL-Cxx00 Series of PDAs

 * Models: SL-C3000 (Spitz), SL-C1000 (Akita) and SL-C3100 (Borzoi)

 *

 * Copyright (c) 2005 Richard Purdie

 *

 * Based on Sharp's 2.4 kernel patches/lubbock.c

 symbol_get ; symbol_put */

/******************************************************************************

 * Pin configuration

 Chip Selects */

 SCOOP #2 */

 NAND */

 SCOOP #1 */

 LCD - 16bpp Active TFT */

 PC Card */

 I2S */

 MMC */

 GPIOs */

 SPITZ_GPIO_nSD_DETECT */

 SPITZ_GPIO_SYNC */

 SPITZ_GPIO_nSD_WP */

 SPITZ_GPIO_USB_CONNECT */

 SPITZ_GPIO_USB_HOST */

 SPITZ_GPIO_USB_DEVICE */

 SPITZ_GPIO_HSYNC */

 SPITZ_GPIO_CF_CD */

 SPITZ_GPIO_CF_IRQ */

 SPITZ_GPIO_CF2_IRQ */

 GPIO matrix keypad */

 column 0 */

 column 1 */

 column 2 */

 column 3 */

 column 4 */

 column 5 */

 column 6 */

 column 7 */

 column 8 */

 column 9 */

 column 10 */

 row 0 */

 row 1 */

 row 2 */

 row 3 */

 row 4 */

 row 5 */

 row 6 */

 I2C */

 SPITZ_GPIO_KEY_INT */

 SPITZ_GPIO_RESET */

/******************************************************************************

 * Scoop GPIO expander

 SCOOP Device #1 */

 SCOOP Device #2 */

 Akita doesn't have the second SCOOP chip */

 Power control is shared with between one of the CF slots and SD */

/******************************************************************************

 * PCMCIA

 Only need to override behaviour for slot 0 */

 Akita has only one PCMCIA slot used */

/******************************************************************************

 * GPIO keyboard

 EXOK */

 EXCANCEL */

 EXJOGDOWN */

 EXJOGUP */

 ADDRESS */

 CALENDAR */

 MAIL */

 FN */

 JAP1 */

 JAP2 */

 CANCEL */

 OK */

 MENU */

/******************************************************************************

 * GPIO keys

 Two buttons detecting the lid state */

/******************************************************************************

 * LEDs

/******************************************************************************

 * SSP Devices

/******************************************************************************

 * SD/MMC card controller

/*

 * NOTE: The card detect interrupt isn't debounced so we delay it by 250ms to

 * give the card a chance to fully insert/eject.

/******************************************************************************

 * USB Host

 Only Port 2 is connected, setup USB Port 2 Output Control Register */

/******************************************************************************

 * IrDA

/******************************************************************************

 * Framebuffer

/******************************************************************************

 * NAND Flash

/******************************************************************************

 * NOR Flash

/******************************************************************************

 * I2C devices

 Only Akita has the max7310 chip */

/******************************************************************************

 * Audio devices

/******************************************************************************

 * Machine init

 Bootloader magic for a reboot */

 Stop 3.6MHz and drive HIGH to PCMCIA and CS */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hardware definitions for Palm Treo smartphones

 *

 * currently supported:

 *     Palm Treo 680 (GSM)

 *     Palm Centro 685 (GSM)

 *

 * Author:     Tomas Cech <sleep_walker@suse.cz>

 *

 * (find more info at www.hackndev.com)

/******************************************************************************

 * Pin configuration

 MMC */

 SD detect */

 AC97 */

 IrDA */

 PWM */

 USB */

 usb detect */

 MATRIX KEYPAD */

 Hotsync button */

 Quick Capture Interface */

 I2C */

 GSM */

 GSM host wake up */

 MISC. */

 external power detect */

 silent switch */

 headphone detect */

 bluetooth host wake up */

 SD read only */

 MATRIX KEYPAD - different wake up source */

 LCD... L_BIAS alt fn not configured on Treo680; is GPIO instead */

 CONFIG_MACH_TREO680 */

 Bluetooth attached to BT UART*/

 power: LOW = off */

 MATRIX KEYPAD - different wake up source */

 LCD */

 CONFIG_MACH_CENTRO */

/******************************************************************************

 * GPIO keyboard

 Red/Off/Power */

 Alternate */

 Menu */

 Left shift */

 Phone */

 Calendar */

 Mail */

 Alt */

 Home */

 Side up */

 Side Activate */

 Side down */

 Green/Call */

 Home */

 Alternate */

 Menu */

 Left shift */

 Phone */

 Calendar */

 Mail */

 Alt */

 Red/Off/Power */

 Side up */

 Side Activate */

 Side down */

 Green/Call */

/******************************************************************************

 * USB host

/******************************************************************************

 * Vibra and LEDs

/******************************************************************************

 * Machine init

 drive all three lcd gpios high initially */

	/*

	 * LCD GPIO initialization...

	/*

	 * This is likely the power to the lcd.  Toggling it low/high appears to

	 * turn the lcd off/on.  Can be toggled after lcd is initialized without

	 * any apparent adverse effects to the lcd operation.  Note that this

	 * gpio line is used by the lcd controller as the L_BIAS signal, but

	 * treo680 configures it as gpio.

	/*

	 * These two are called "enables", for lack of a better understanding.

	 * If either of these are toggled after the lcd is initialized, the

	 * image becomes degraded.  N.B. The IPL shipped with the treo

	 * configures GPIO_NR_TREO680_LCD_EN_N as output and drives it high.  If

	 * the IPL is ever reprogrammed, this initialization may be need to be

	 * revisited.

 driving this low turns LCD on */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for HP iPAQ hx4700 PDAs.

 *

 * Copyright (c) 2008-2009 Philipp Zabel

 *

 * Based on code:

 *    Copyright (c) 2004 Hewlett-Packard Company.

 *    Copyright (c) 2005 SDG Systems, LLC

 *    Copyright (c) 2006 Anton Vorontsov <cbou@mail.ru>

 Physical address space information */

 ATI Imageon 3220 Graphics */

 SDRAM and Static Memory I/O Signals */

 W3220 */

 ASIC3 */

 EGPIO, WLAN */

 PC CARD */

 I2C */

 FFUART (RS-232) */

 BTUART */

 STUART (IRDA) */

 PWM 1 (Backlight) */

 I2S */

 SSP 1 (NavPoint) */

 SSP 2 (TSC2046) */

 TSC2046_CS */

 BQ24022 Regulator */

 BQ24022_nCHARGE_EN */

 BQ24022_ISET2 */

 HX4700 specific input GPIOs */

 ASIC3_IRQ */

 W3220_IRQ */

 nWLAN_IRQ */

 HX4700 specific output GPIOs */

 W3220_nRESET */

 ASIC3_nRESET */

 CPU_GP_nRESET */

 CPU_HW_nRESET */

 SYNAPTICS_POWER_ON */

 GSM_IRQ */

 CPLD_IRQ */

 DS1WM_IRQ */

 GSM_READY */

 TSC2046_nPENIRQ */

 nSDIO_IRQ */

/*

 * IRDA

/*

 * GPIO Keys

/*

 * Synaptics NavPoint connected to SSP1

/*

 * ASIC3

	/* ASIC3 GPIO banks A and B along with some of C and D

 GPIOC - CF, LEDs, SD */

 red */

 green */

 blue */

 GPIOD: input GPIOs, CF */

 GPIO part */

 SD part */

/*

 * EGPIO

/*

 * LCD - Sony display connected to ATI Imageon w3220

 FIXME: init w3220 registers here */

  				 W3220_VGA		QVGA */

 0x00fff003 */

 0x21ff01f9 */

 0x40000000 */

 0x41060010 */

 0x15001545 */

 GPIO_DATA */

 GPIO_CNTL1 */

 GPIO_CNTL2 */

 GPIO_DATA2 */

 GPIO_CNTL3 */

 GPIO_CNTL4 */

/*

 * Backlight

/*

 * USB "Transceiver"

 This GPIO is on ASIC3 */

 Convert to a local offset on the ASIC3 */

 This one is on the primary SOC GPIO */

/*

 * Touchscreen - TSC2046 connected to SSP2

 100 kHz sample rate */

/*

 * External power

/*

 * Battery charger

/*

 * StrataFlash

/*

 * Maxim MAX1587A on PI2C

 730..1550 mV */

/*

 * Asahi Kasei AK4641 on I2C

/*

 * Platform devices

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/gumstix.c

 *

 *  Support for the Gumstix motherboards.

 *

 *  Original Author:	Craig Hughes

 *  Created:	Feb 14, 2008

 *  Copyright:	Craig Hughes

 *

 *  Implemented based on lubbock.c by Nicolas Pitre and code from Craig

 *  Hughes

 force read-only */

/* Normally, the bootloader would have enabled this 32kHz clock but many

** boards still have u-boot 1.1.4 so we check if it has been turned on and

 BTUART */

 MMC */

	/*

	 * put carrier/expansion board init here if

	 * they cannot be detected programatically

 match u-boot bi_boot_params */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/pcm027.c

 *  Support for the Phytec phyCORE-PXA270 CPU card (aka PCM-027).

 *

 *  Refer

 *   http://www.phytec.com/products/sbc/ARM-XScale/phyCORE-XScale-PXA270.html

 *  for additional hardware info

 *

 *  Author:	Juergen Kilb

 *  Created:	April 05, 2005

 *  Copyright:	Phytec Messtechnik GmbH

 *  e-Mail:	armlinux@phytec.de

 *

 *  based on Intel Mainstone Board

 *

 *  Copyright 2007 Juergen Beisert @ Pengutronix (j.beisert@pengutronix.de)

/*

 * ABSTRACT:

 *

 * The PXA270 processor comes with a bunch of hardware on its silicon.

 * Not all of this hardware can be used at the same time and not all

 * is routed to module's connectors. Also it depends on the baseboard, what

 * kind of hardware can be used in which way.

 * -> So this file supports the main devices on the CPU card only!

 * Refer pcm990-baseboard.c how to extend this features to get a full

 * blown system with many common interfaces.

 *

 * The PCM-027 supports the following interfaces through its connectors and

 * will be used in pcm990-baseboard.c:

 *

 * - LCD support

 * - MMC support

 * - IDE/CF card

 * - FFUART

 * - BTUART

 * - IRUART

 * - AC97

 * - SSP

 * - SSP3

 *

 * Claimed GPIOs:

 * GPIO0 -> IRQ input from RTC

 * GPIO2 -> SYS_ENA*)

 * GPIO3 -> PWR_SCL

 * GPIO4 -> PWR_SDA

 * GPIO5 -> PowerCap0*)

 * GPIO6 -> PowerCap1*)

 * GPIO7 -> PowerCap2*)

 * GPIO8 -> PowerCap3*)

 * GPIO15 -> /CS1

 * GPIO20 -> /CS2

 * GPIO21 -> /CS3

 * GPIO33 -> /CS5 network controller select

 * GPIO52 -> IRQ from network controller

 * GPIO78 -> /CS2

 * GPIO80 -> /CS4

 * GPIO90 -> LED0

 * GPIO91 -> LED1

 * GPIO114 -> IRQ from CAN controller

 * GPIO117 -> SCL

 * GPIO118 -> SDA

 *

 * *) CPU internal use only

 Chip Selects */

 Ethernet */

 I2C */

 GPIO */

 IRQ from network controller */

 PCM027_LED_CPU */

 PCM027_LED_HEART_BEAT */

 IRQ from CAN controller */

/*

 * SMC91x network controller specific stuff

 note: smc91x's driver doesn't use the trigger bits yet */

/*

 * SPI host and devices

 bus_num must match id in pxa2xx_set_spi_info() call */

/*

 * NOR flash

 FIXME */

 FIXME */

 CONFIG_LEDS_GPIO */

/*

 * declare the available device resources on this board

/*

 * pcm027_init - breath some life into the board

	/* system bus arbiter setting

	 * - Core_Park

	 * - LCD_wt:DMA_wt:CORE_Wt = 2:3:4

 at last call the baseboard to initialize itself */

 initialize sleep mode regs (wake-up sources, etc) */

 Maintainer: Pengutronix */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  ezx.c - Common code for the EZX platform.

 *

 *  Copyright (C) 2005-2006 Harald Welte <laforge@openezx.org>,

 *		  2007-2008 Daniel Ribeiro <drwyrm@gmail.com>,

 *		  2007-2008 Stefan Schmidt <stefan@datenfreihafen.org>

 PWM backlight */

 BTUART */

 I2C */

 PCAP SSP */

 pcap chip select */

 pcap interrupt */

 WDI_AP */

 SYS_RESTART */

 MMC */

 mmc detect */

 usb to external transceiver */

 usb to Neptune GSM chip */

 flip / lockswitch */

 bluetooth (bcm2035) */

 HOSTWAKE */

 RESET */

 WAKEUP */

 Neptune handshake */

 BP_RDY */

 AP_RDY */

 WDI */

 WDI2 */

 RESET */

 TC_MM_EN */

 sound */

 ssp2 pins to in */

 SSP2_SCLK */

 SSP2_SFRM */

 SSP2_TXD */

 SSP2_RXD */

 camera */

 CAM_EN */

 CAM_RST */

 EMU */

 EMU_MUX1 */

 EMU_MUX2 */

 SNP_INT_CTL */

 SNP_INT_IN */

 flip / lockswitch */

 EOC */

 bluetooth (bcm2045) */

 HOSTWAKE */

 RESET */

 WAKEUP */

 Neptune handshake */

 BP_RDY */

 AP_RDY */

 WDI */

 RESET */

 BP_FLASH */

 sound */

 ssp2 pins to in */

 SSP2_SCLK */

 SSP2_SFRM */

 SSP2_TXD */

 SSP2_RXD */

 camera */

 CAM_EN */

 CAM_RST */

 CAM_FLASH */

 keypad */

 attenuate sound */

 keypad */

 MIDI */

 VA_SEL_BUL */

 FLT_SEL_BUL */

 MIDI_RESET */

 MIDI_CS */

 MIDI_IRQ */

 MIDI_NPWE */

 MIDI_RDY */

 leds */

 keypad */

 keypad */

 WLAN */

 RESET */

 WAKEUP */

 HOSTWAKE */

 MMC CS */

 keypad */

 keypad */

 KEYPAD */

 CONFIG_MACH_EZX_A780 */

 CONFIG_MACH_EZX_E680 */

 CONFIG_MACH_EZX_A1200 */

 CONFIG_MACH_EZX_E6 */

 Left SoftKey */

 Right SoftKey */

 CONFIG_MACH_EZX_A910 */

 Left SoftKey */

 Right SoftKey */

 Music SoftKey */

 CONFIG_MACH_EZX_E2 */

 camera */

 gpio_keys */

 camera */

	/*

	 * GPIO50_nCAM_EN is active low

	 * GPIO19_GEN1_CAM_RST is active on rising edge

 gpio_keys */

 gpio_keys */

 gpio_keys */

 camera */

	/*

	 * GPIO50_nCAM_EN is active low

	 * GPIO28_GEN2_CAM_RST is active on rising edge

 leds-lp3944 */

 Leds 3 and 4 are used as display power switches */

 gpio_keys */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hardware definitions for Palm Zire72

 *

 * Authors:

 *	Vladimir "Farcaller" Pouzanov <farcaller@gmail.com>

 *	Sergey Lapin <slapin@ossfans.org>

 *	Alex Osborne <bobofdoom@gmail.com>

 *	Jan Herman <2hp@seznam.cz>

 *

 * Rewrite for mainline:

 *	Marek Vasut <marek.vasut@gmail.com>

 *

 * (find more info at www.hackndev.com)

/******************************************************************************

 * Pin configuration

 MMC */

 SD detect */

 SD RO */

 SD power */

 AC97 */

 IrDA */

 ir disable */

 PWM */

 USB */

 usb detect */

 usb pullup */

 Matrix keypad */

 LCD */

 bl power */

 LCD border switch */

 LCD border color */

 lcd power */

 PXA Camera */

 OV9640 Powerdown */

 OV9640 Reset */

 OV9640 Power */

 I2C */

 I2C_SCL */

 I2C_SDA */

 Misc. */

 power detect */

 green led */

 WM9712 IRQ */

/******************************************************************************

 * GPIO keyboard

/******************************************************************************

 * LEDs

/* We have some black magic here

 * PalmOS ROM on recover expects special struct physical address

 * to be transferred via PSPR. Using this struct PalmOS restores

 * its state after sleep. As for Linux, we need to setup it the

 * same way. More than that, PalmOS ROM changes some values in memory.

 * For now only one location is found, which needs special treatment.

 * Thanks to Alex Osborne, Andrzej Zaborowski, and lots of other people

 * for reading backtraces for me :)

 reset state, MMU off etc */

 syscore_ops for Palm Zire 72 PM */

 setup the resume_info struct for the original bootloader */

 Storing memory touched by ROM */

 Setting PSPR to a proper value */

/******************************************************************************

 * Machine init

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/pxa25x.c

 *

 *  Author:	Nicolas Pitre

 *  Created:	Jun 15, 2001

 *  Copyright:	MontaVista Software Inc.

 *

 * Code specific to PXA21x/25x/26x variants.

 *

 * Since this file should be linked before any other machine specific file,

 * the __initcall() here will be executed first.  This serves as default

 * initialization stuff for PXA machines which can be overridden later if

 * need be.

/*

 * Various clock factors driven by the CCCR register.

/*

 * List of global PXA peripheral registers to preserve.

 * More ones like CP and general purpose register values are preserved

 * with the stack pointer in sleep.S.

 Clear reset status */

 set resume return address */

 ensure not to come back here if it wasn't intended */

/* PXA25x: supports wakeup from GPIO0..GPIO15 and RTC alarm

 Mem Ctl */

 UNCACHED_PHYS_0 */

 PXA25x, PXA27x and PXA3xx common entries */

 PXA25x specific map */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  arch/arm/mach-pxa/colibri-pxa320.c

 *

 *  Support for Toradex PXA320/310 based Colibri module

 *

 *  Daniel Mack <daniel@caiaq.de>

 *  Matthias Meier <matthias.j.meier@gmx.net>

 MMC */

 SD detect */

 UART 1 configuration (may be set by bootloader) */

 UART 2 configuration */

 UART 3 configuration */

 UHC */

 I2C */

 PCMCIA */

 PRST ; AF7 to tristate */

 PCE1 ; AF7 to tristate */

 PCE2 ; AF7 to tristate */

 PCD ; AF7 to tristate */

 PSKTSEL ; AF7 to tristate */

 RDnWR ; input/tristate */

 PREG ; input/tristate */

 PRDY (READY GPIO) */

 PPEN (POWER GPIO) */

 PCD (DETECT GPIO) */

 PRST (RESET GPIO) */

 PBVD1 */

 PBVD2 */

 POE */

/*

 * Asix AX88796 Ethernet

 defined later */

 AX88796 chip select */

 AX88796 IRQ */

 CONFIG_AX88796 */

 Evalboard init */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Intel Reference Systems cplds

 *

 * Copyright (C) 2014 Robert Jarzmik

 *

 * Cplds motherboard driver, supporting lubbock and mainstone SoC board.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/zylonite_pxa300.c

 *

 * PXA300/PXA310 specific support code for the

 * PXA3xx Development Platform (aka Zylonite)

 *

 * Copyright (C) 2007 Marvell Internation Ltd.

 * 2007-08-21: eric miao <eric.miao@marvell.com>

 *             initial version

 PXA300/PXA310 common configurations */

 LCD */

 backlight */

 BTUART */

 STUART */

 AC97 */

 SDATA_IN_1 but unused - configure to GPIO */

 SSP3 */

 WM9713 IRQ */

 Keypad */

 MMC1 */

 CMD0 for slot 0 */

 CMD1 default as GPIO for slot 0 */

 MMC2 */

 USB Host */

 Standard I2C */

 GPIO */

 GPIO Expander #0 INT_N */

 GPIO Expander #1 INT_N */

 FFUART */

 Ethernet */

 FFUART */

 Ethernet */

 MMC3 */

 LCD_LDD_17 - ORIENT */

 LCD_LDD_16 - LCDID[5] */

 LCD_BIAS   - LCDID[4] */

 LCD_LCLK   - LCDID[3] */

 LCD_FCLK   - LCDID[2] */

 LCD_CS_N   - LCDID[1] */

 LCD_VSYNC  - LCDID[0] */

	/* save the original MFP settings of these pins and configure

	 * them as GPIO Input, DS01X, Pull Neither, Edge Clear

 lcd id, flush out bit 1 */

 lcd orientation, portrait or landscape */

 restore the original MFP settings */

 initialize MFP */

 detect LCD panel */

 WM9713 IRQ */

 GPIOs for Debug LEDs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/icontrol.c

 *

 * Support for the iControl and SafeTcam platforms from TMT Services

 * using the Embedian MXM-8x10 Computer on Module

 *

 * Copyright (C) 2009 TMT Services & Supplies (Pty) Ltd.

 *

 * 2010-01-21 Hennie van der Merve <hvdmerwe@tmtservies.co.za>

 CAN CS lines */

 SPI (SSP3) lines */

 SPI (SSP4) lines */

 CAN nIRQ lines */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/pxa320.c

 *

 * Code specific to PXA320

 *

 * Copyright (C) 2007 Marvell Internation Ltd.

 *

 * 2007-08-21: eric miao <eric.miao@marvell.com>

 *             initial version

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/littleton.c

 *

 *  Support for the Marvell Littleton Development Platform.

 *

 *  Author:	Jason Chagas (largely modified code)

 *  Created:	Nov 20, 2006

 *  Copyright:	(C) Copyright 2006 Marvell International Ltd.

 *

 *  2007-11-22  modified to align with latest kernel

 *              eric miao <eric.miao@marvell.com>

 Littleton MFP configurations */

 LCD */

 SSP2 */

 SFRM as chip-select */

 Debug Ethernet */

 Keypad */

 MMC1 */

 card detect */

 UART3 */

 VGA */

 QVGA */

 CONFIG_FB_PXA || CONFIG_FB_PXA_MODULE */

 KEY(row, col, key_code) */

 * */

 # */

 soft1 */

 soft2 */

 Card detect on MFP (gpio-pxa) GPIO 15 */

 force read-only */

 force read-only */

 48M - rootfs */

 force read-only */

	/* NOTE: we reserve some blocks at the end of the NAND flash for

	 * bad block management, and the max number of relocation blocks

	 * differs on different platforms. Please take care with it when

	 * defining the partition table.

 IS_ENABLED(CONFIG_MTD_NAND_MARVELL) */

 CONFIG_I2C_PXA || CONFIG_I2C_PXA_MODULE */

 initialize MFP configurations */

	/*

	 * Note: we depend bootloader set the correct

	 * value to MSC register for SMC91x.

 SPDX-License-Identifier: GPL-2.0-only

/*  linux/arch/arm/mach-pxa/xcep.c

 *

 *  Support for the Iskratel Electronics XCEP platform as used in

 *  the Libera instruments from Instrumentation Technologies.

 *

 *  Author:     Ales Bardorfer <ales@i-tech.si>

 *  Contributions by: Abbott, MG (Michael) <michael.abbott@diamond.ac.uk>

 *  Contributions by: Matej Kenda <matej.kenda@i-tech.si>

 *  Created:    June 2006

 *  Copyright:  (C) 2006-2009 Instrumentation Technologies

  XCEP CPLD base */

 Flash partitions. */

 bankwidth in bytes */

 SMC LAN91C111 network controller. */

/* We have to state that there are HWMON devices on the I2C bus on XCEP.

 * Drivers for HWMON verify capabilities of the adapter when loading and

 SMC 91C111 chip select. */

 CPLD chip select. */

 SSP communication to MSP430 */

 See Intel XScale Developer's Guide for details */

 Set RDF and RDN to appropriate values (chip select 3 (smc91x)) */

 Set RDF and RDN to appropriate values (chip select 5 (fpga)) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/capc7117.c

 *

 * Support for the Embedian CAPC-7117 Evaluation Kit

 * based on the Embedian MXM-8x10 Computer on Module

 *

 * Copyright (C) 2009 Embedian Inc.

 * Copyright (C) 2009 TMT Services & Supplies (Pty) Ltd.

 *

 * 2007-09-04: eric miao <eric.y.miao@gmail.com>

 *             rewrite to align with latest kernel

 *

 * 2010-01-09: Edwin Peer <epeer@tmtservices.co.za>

 *             Hennie van der Merwe <hvdmerwe@tmtservices.co.za>

 *             rework for upstream merge

 IDE (PATA) Support */

 grumble */

 TI16C752 UART support */

 end of array */

 Init CoM */

 Init evaluation board peripherals */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/pxa2xx.c

 *

 * code specific to pxa2xx

 *

 * Copyright (C) 2008 Dmitry Baryshkov

 RESET_STATUS_* has a 1:1 mapping with RCSR */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/pxa3xx-ulpi.c

 *

 * code specific to pxa3xx aka Monahans

 *

 * Copyright (C) 2010 CompuLab Ltd.

 *

 * 2010-13-07: Igor Grinberg <grinberg@compulab.co.il>

 *             initial version: pxa310 USB Host mode support

 put PHY to sync mode */

 setup OTG sync mode */

 disable USB device controller */

 set xceiver mode */

 start OTG host controller */

 CONFIG_PXA310_ULPI */

 In case the PXA3xx ULPI isn't used, do nothing. */

 In case the PXA3xx ULPI isn't used, do nothing. */

 Only PXA310 U2D has OTG functionality */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/zylonite_pxa320.c

 *

 * PXA320 specific support code for the

 * PXA3xx Development Platform (aka Zylonite)

 *

 * Copyright (C) 2007 Marvell Internation Ltd.

 * 2007-08-21: eric miao <eric.miao@marvell.com>

 *             initial version

 LCD */

 backlight */

 FFUART */

 AC97 */

 SDATA_IN_1 but unused - configure to GPIO */

 SSP3 */

 WM9713 IRQ */

 I2C */

 Keypad */

 Ethernet */

 MMC1 */

 CMD0 for slot 0 */

 CMD1 default as GPIO for slot 0 */

 MMC2 */

 USB Host */

 Debug LEDs */

 LCD_LDD_17 - ORIENT */

 LCD_LDD_16 - LCDID[5] */

 LCD_BIAS   - LCDID[4] */

 LCD_LCLK   - LCDID[3] */

 LCD_FCLK   - LCDID[2] */

 LCD_CS_N   - LCDID[1] */

 LCD_VSYNC  - LCDID[0] */

	/*

	 * set the MFP_PIN_GPIO 14/15/17 to alternate function other than

	 * GPIO to avoid input level confliction with 14_2, 15_2, 17_2

 AF0, DS 1X, Pull Neither, Edge Clear */

 Backlight, Pull-Up, AF2 */

 AF5 */

 AF5 */

	/* save the original MFP settings of these pins and configure them

	 * as GPIO Input, DS01X, Pull Neither, Edge Clear

 lcd id, flush out bit 1 */

 lcd orientation, portrait or landscape */

 restore the original MFP settings */

 initialize MFP */

 detect LCD panel */

 GPIO pin assignment */

 WM9713 IRQ */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/himalaya.c

 *

 * Hardware definitions for the HTC Himalaya

 *

 * Based on 2.6.21-hh20's himalaya.c and himalaya_lcd.c

 *

 * Copyright (c) 2008 Zbynek Michl <Zbynek.Michl@seznam.cz>

 ---------------------- Himalaya LCD definitions -------------------- */

 GPIO_DATA  */

 GPIO_CNTL1 */

 GPIO_CNTL2 */

 GPIO_DATA2 */

 GPIO_CNTL3 */

 GPIO_CNTL4 */

 ----------------------------------------------------------------------- */

 hardcoded (detection needs ASIC3 functions) */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hardware definitions for Palm Tungsten|T5

 *

 * Author:	Marek Vasut <marek.vasut@gmail.com>

 *

 * Based on work of:

 *		Ales Snuparek <snuparek@atlas.cz>

 *		Justin Kendrick <twilightsentry@gmail.com>

 *		RichardT5 <richard_t5@users.sourceforge.net>

 *

 * (find more info at www.hackndev.com)

/******************************************************************************

 * Pin configuration

 MMC */

 SD detect */

 SD power */

 SD r/o switch */

 AC97 */

 IrDA */

 ir disable */

 USB */

 usb detect */

 usb power */

 MATRIX KEYPAD */

 LCD */

 PWM */

 FFUART */

 MISC */

 hotsync button */

 power detect */

 earphone detect */

/******************************************************************************

 * GPIO keyboard

/******************************************************************************

 * GPIO keys

/******************************************************************************

 * Machine init

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Support for Sharp SL-C7xx PDAs

 * Models: SL-C700 (Corgi), SL-C750 (Shepherd), SL-C760 (Husky)

 *

 * Copyright (c) 2004-2005 Richard Purdie

 *

 * Based on Sharp's 2.4 kernel patches/lubbock.c

 symbol_get ; symbol_put */

 Static Memory I/O */

 w100fb */

 scoop */

 SSP1 */

 CORGI_GPIO_ADS7846_CS - SFRM as chip select */

 I2S */

 Infra-Red */

 FFUART */

 PC Card */

 MMC */

 GPIO Matrix Keypad */

 column 0 */

 column 1 */

 column 2 */

 column 3 */

 column 4 */

 column 5 */

 column 6 */

 column 7 */

 column 8 */

 column 9 */

 column 10 */

 column 11 */

 row 0 */

 row 1 */

 row 2 */

 row 3 */

 row 4 */

 row 5 */

 row 6 */

 row 7 */

 GPIO */

 CORGI_GPIO_nSD_DETECT */

 CORGI_GPIO_nSD_WP */

 CORGI_GPIO_MAIN_BAT_{LOW,COVER} */

 CORGI_GPIO_LED_ORANGE */

 CORGI_GPIO_ADC_TEMP */

 CORGI_GPIO_IR_ON */

 CORGI_GPIO_SD_PWR */

 CORGI_GPIO_CHRG_ON */

 CORGI_GPIO_CHRG_UKN */

 CORGI_GPIO_HSYNC */

 CORGI_GPIO_KEY_INT */

 CORGI_GPIO_AC_IN */

 CORGI_GPIO_WAKEUP */

/*

 * Corgi SCOOP Device

/*

 * Corgi Keyboard Device

/*

 * Corgi LEDs

/*

 * Corgi Audio

/*

 * MMC/SD Device

 *

 * The card detect interrupt isn't debounced so we delay it by 250ms

 * to give the card a chance to fully insert/eject.

 Card detect on GPIO 9 */

 Write protect on GPIO 7 */

 Power on GPIO 33 */

/*

 * Irda

/*

 * USB Device Controller

 no connect GPIO; corgi can't tell connection status */

 Green LED off tells the bootloader to halt */

 Green LED on tells the bootloader to reboot */

 Stop 3.6MHz and drive HIGH to PCMCIA and CS */

 allow wakeup from various GPIOs */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/tavorevb.c

 *

 *  Support for the Marvell PXA930 Evaluation Board

 *

 *  Copyright (C) 2007-2008 Marvell International Ltd.

 Tavor EVB MFP configurations */

 Ethernet */

 LCD */

 LCD Backlight */

 primary backlight */

 secondary backlight */

 Keypad */

 KEY(row, col, key_code) */

 * */

 # */

 KEY_LEFTSHIFT), */

 scroll push */

 keypad action */

 soft1 */

 soft2 */

 CONFIG_KEYBOARD_PXA27x || CONFIG_KEYBOARD_PXA27x_MODULE */

 primary backlight */

 secondary backlight */

 DSTB OUT */

 STB OUT */

 P-ON Init sequence */

 OSC ON */

 SOURCE DRIVER SHIFT DIRECTION and display RAM setting */

 LINE INV */

 IF mode(1) */

 8bit smart mode(8-8),high speed write mode */

 RAM Write Mode */

 DISPLAY Setting,  262K, fixed(NO scroll), no split screen */

 16/18/19 BPP */

 BP, FP Seting, BP=2H, FP=3H */

 IF mode(2), using internal clock & MPU */

 Frame setting, 1Min. Frequence, 16CLK */

 Timing(1),ASW W=4CLK, ASW ST=1CLK */

 Timing(2),OEV ST=0.5CLK, OEV ED=1CLK */

 Timing(3), ASW HOLD=0.5CLK */

 Timing(4), CKV ST=0CLK, CKV ED=1CLK */

 DISP RAM setting: 240*320 */

 HADDR, START 0 */

 x1,3 */

 HADDR,  END   4 */

 x2, 7 */

 VADDR, START 8 */

 y1, 10 */

 y1, 11 */

 VADDR, END 12 */

 y2, 14 */

 y2, 15 */

 RAM ADDR SETTING 16 */

 x1, 19 */

 RAM ADDR SETTING 20 */

 y1, 22 */

 y1, 23 */

 Power-IC ON */

 DISP ON */

 write ram */

 write frame data */

 L_LCLK_A0 and L_LCLK_RD active low */

 CONFIG_FB_PXA || CONFIG_FB_PXA_MODULE */

 initialize MFP configurations */

 Maintainer: Eric Miao <eric.miao@marvell.com> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/mp900.c

 *

 *  Support for the NEC MobilePro900/C platform

 *

 *  Based on mach-pxa/gumstix.c

 *

 *  2007, 2008 Kristoffer Ericson <kristoffer.ericson@gmail.com>

 *  2007, 2008 Michael Petchkovsky <mkpetch@internode.on.net>

 400MHz PXA2 = 2.5ns / instruction */

 4 Instructions = 4 x 2.5ns = 10ns */

 Maintainer - Michael Petchkovsky <mkpetch@internode.on.net> */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/stargate2.c

 *

 *  Author:	Ed C. Epp

 *  Created:	Nov 05, 2002

 *  Copyright:	Intel Corp.

 *

 *  Modified 2009:  Jonathan Cameron <jic23@cam.ac.uk>

 Bluetooth */

 SD */

 Device Identification for wakeup*/

 DA9030 */

 MMC */

 802.15.4 radio - driver out of mainline */

 CC_RSTN */

 CC_FIFO */

 CC_CCA */

 CC_FIFOP */

 CCSFD */

 Power enable */

 I2C */

 SSP 3 - 802.15.4 radio */

 Chip Select */

 SSP 2 to daughter boards */

 chip select */

 SSP 1 - to daughter boards */

 Chip Select */

 BTUART Basic Connector*/

 STUART  - IM2 via debug board not sure on SG2*/

 Basic sensor board */

 accelerometer interrupt */

 ADC interrupt */

 SHT15 */

 Basic sensor board */

 accelerometer interrupt */

 ADC interrupt */

 Connector pins specified as gpios */

 large basic connector pin 14 */

 large basic connector pin 23 */

 FIXME: should this have |GPIO_OPEN_DRAIN set? */

 a mote connector? */

 the CSR bluecore chip */

 The two voltages available to sensor boards */

 directly connected to the pxa27x */

 Reference voltage for certain gpios */

Dc-Dc buck not yet supported */

not sure!*/

 cc2420 802.15.4 radio and pxa vcc_io ?*/

/* The values of the various regulator constraints are obviously dependent

 * on exactly what is wired to each ldo.  Unfortunately this information is

 * not generally available.  More information has been requested from Xbow.

 board default 1.8V */

 board default 2.8V */

 default is 1.8V */

 also vcc_io */

 board default is 2.8V */

 Reference for what? */

 default 1.8V */

 default 2.8V */

 default 2.8V */

 default 2.8V */

 default 2.8V */

	[vcc_io] = { /* Same or higher than everything

 default 2.8V */

 default 1.8V */

 curiously default 2.8V */

 1.17V - 1.43V, default 1.3V*/

 default 1.8V */

 default 1.8V */

/* An upcoming kernel change will scrap SFRM usage so these

 8MHz max spi frequency at 3V */

/* As the the imote2 doesn't currently have a conventional SD slot

 * there is no option to hotplug cards, making all this rather simple

 Rather simple case as hotplugging not possible */

 default anyway */

pxa vcc i/o and cc2420 vcc i/o */

 UCAM sensor board */

 ITS400 Sensor board only */

		/* Through a nand gate - Also beware, on V2 sensor board the

		 * pull up resistors are missing.

 ITS400 Sensor board only */

		/* Through a nand gate - Also beware, on V2 sensor board the

		 * pull up resistors are missing.

 ITS400 Sensor board only */

 IMB400 Multimedia board */

 Button */

 LEDS */

 red led */

 green led */

 blue led */

 SRAM */

 SMC91x */

cable detect?*/

 Button */

 Compact Flash */

 Buff ctrl */

 Power ctrl */

 Reset */

 SG2_S0_GPIO_DETECT */

 MMC not shared with imote2 */

 nSD detect */

 SD_POWER_ENABLE */

 Bluetooth */

 reset */

/*

 * The card detect interrupt isn't debounced so we delay it by 250ms

 * to give the card a chance to fully insert / eject.

/**

 * stargate2_mci_setpower() - set state of mmc power supply

 *

 * Very simple control. Either it is on or off and is controlled by

/*

 * SRAM - The Stargate 2 has 32MB of SRAM.

 *

 * Here it is made available as an MTD. This will then

 * typically have a cifs filesystem created on it to provide

 * fast temporary storage.

/**

 * stargate2_reset_bluetooth() reset the bluecore to ensure consistent state

 now reset it - 5 msec minimum */

pxa vcc i/o and cc2420 vcc i/o */

	/* Techically this a pca9500 - but it's compatible with the 8574

	 * for gpio expansion and the 24c02 for eeprom access.

 ITS400 Sensor board only */

		/* Through a nand gate - Also beware, on V2 sensor board the

		 * pull up resistors are missing.

 ITS400 Sensor board only */

		/* Through a nand gate - Also beware, on V2 sensor board the

		 * pull up resistors are missing.

 ITS400 Sensor board only */

/* Board doesn't support cable detection - so always lie and say

 * something is there.

	/* This is probably a board specific hack as this must be set

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/colibri-pxa270.c

 *

 *  Support for Toradex PXA270 based Colibri module

 *  Daniel Mack <daniel@caiaq.de>

 *  Marek Vasut <marek.vasut@gmail.com>

/******************************************************************************

 * Evaluation board MFP

 MMC */

 SD detect */

 FFUART */

 UHC */

 PCMCIA */

 RESET */

 BVD1 */

 BVD2 */

 READY */

 DETECT */

 PPEN */

 I2C */

 MMC */

 SD detect */

 SD read-only */

 FFUART */

 BFUART */

 STUART */

 UHC */

 LCD */

 PWM */

 I2C */

 LED */

 LED A */

 LED B */

/******************************************************************************

 * Pin configuration

 Ethernet */

 Ethernet CS */

 Ethernet IRQ */

 AC97 */

 Touchscreen IRQ */

/******************************************************************************

 * NOR Flash

 force read-only */

 bankwidth in bytes */

/******************************************************************************

 * Ethernet

/******************************************************************************

 * Audio and Touchscreen

/* The "Income s.r.o. SH-Dmaster PXA270 SBC" board can be booted either

 * with the INCOME mach type or with COLIBRI and the kernel parameter

 * "colibri_pxa270_baseboard=1"

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hardware definitions for Palm Tungsten|E2

 *

 * Author:

 *	Carlos Eduardo Medaglia Dyonisio <cadu@nerdfeliz.com>

 *

 * Rewrite for mainline:

 *	Marek Vasut <marek.vasut@gmail.com>

 *

 * (find more info at www.hackndev.com)

/******************************************************************************

 * Pin configuration

 MMC */

 SD detect */

 SD power */

 SD r/o switch */

 AC97 */

 PWM */

 USB */

 usb detect */

 usb power */

 IrDA */

 ir disable */

 LCD */

 GPIO KEYS */

 notes */

 tasks */

 calendar */

 contacts */

 center */

 left */

 right */

 down */

 up */

 MISC */

 reset */

 Hotsync button */

 power detect */

 earphone detect */

 LCD power */

 Backlight power */

/******************************************************************************

 * SD/MMC card controller

/******************************************************************************

 * GPIO keys

/******************************************************************************

 * Backlight

/******************************************************************************

 * IrDA

/******************************************************************************

 * UDC

/******************************************************************************

 * Power supply

/******************************************************************************

 * WM97xx audio, battery

/******************************************************************************

 * Framebuffer

/******************************************************************************

 * Machine init

 setup udc GPIOs initial state */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Battery and Power Management code for the Sharp SL-Cxx00

 *

 * Copyright (c) 2005 Richard Purdie

 2.9V */

 2.9V */

 6V */

 2V */

 3.45V */

 3.40V */

/* HACK - For unknown reasons, accurate voltage readings are only made with a load

 GPIO Sleep Register */

 clear */

 nRESET_OUT Disable */

 Stop 3.6MHz and drive HIGH to PCMCIA and CS */

 charge on */

 charge off */

 Return to suspend as this must be what we were woken for */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Common code for Palm LD, T5, TX, Z72

 *

 * Copyright (C) 2010-2011 Marek Vasut <marek.vasut@gmail.com>

/******************************************************************************

 * SD/MMC card controller

/******************************************************************************

 * Power management - standby

 mov	r0,	#0x40000000 */

 orr	r0, r0, #0x00f00000 */

 ldr	pc, [r0, #0x08] */

	/*

	 * Copy the bootloader.

	 * NOTE: PalmZ72 uses a different wakeup method!

/******************************************************************************

 * Framebuffer

/******************************************************************************

 * USB Gadget

 The actual GPIO offsets get filled in in the palm27x_udc_init() call */

/******************************************************************************

 * IrDA

/******************************************************************************

 * WM97xx audio, battery

/******************************************************************************

 * Backlight

/******************************************************************************

 * Power supply

/******************************************************************************

 * Core power regulator

 730..1550 mV */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/mainstone.c

 *

 *  Support for the Intel HCDDBBVA0 Development Platform.

 *  (go figure how they came up with such name...)

 *

 *  Author:	Nicolas Pitre

 *  Created:	Nov 05, 2002

 *  Copyright:	MontaVista Software Inc.

 Chip Select */

 LCD - 16bpp Active TFT */

 Backlight */

 MMC */

 USB Host Port 1 */

 PC Card */

 AC97 */

 Keypad */

 I2C */

 GPIO */

 force read-only */

	/* make sure SD/Memory Stick multiplexer's signals

	 * are routed to MMC controller

 . */

 @ */

 FIXME: get from SCR (Mst doc section 3.2.1.1) */

 Register board control register(s) as GPIOs */

 Compensate for SW7 which swaps the flash banks */

	/* system bus arbiter setting

	 * - Core_Park

	 * - LCD_wt:DMA_wt:CORE_Wt = 2:3:4

	/* reading Mainstone's "Virtual Configuration Register"

 CPLD */

	for use I SRAM as framebuffer.	*/

/*

 * Driver for the 8 discrete LEDs available for general use:

 * Note: bits [15-8] are used to enable/blank the 8 7 segment hex displays

 * so be sure to not monkey with them here.

/*

 * The triggers lines up below will only be used if the

 * LED triggers are compiled in.

 All ON */

/*

 * Since we may have triggers on any subsystem, defer registration

 * until after subsystem_init.

 Maintainer: MontaVista Software Inc. */

 BLOB boot parameter setting */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Trigger GPIO reset.

 * This covers various types of logic connecting gpio pin

 * to RESET pins (nRESET or GPIO_RESET):

 drive it low */

 rising edge or drive high */

 falling edge */

 give it some time */

 fallback */

 Initialize the watchdog and let it fire */

 ... in 100 ms */

	/*

	 * SDRAM hangs on watchdog reset on Marvell PXA270 (erratum 71)

	 * we put SDRAM into self-refresh to prevent that

 Jump into ROM at address 0 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/irq.c

 *

 *  Generic PXA IRQ handling

 *

 *  Author:	Nicolas Pitre

 *  Created:	Jun 15, 2001

 *  Copyright:	MontaVista Software Inc.

/*

 * This is for peripheral IRQs internal to the PXA chip.

 initialize interrupt priority */

 disable all IRQs */

 all IRQs are IRQ, not FIQ */

 only unmasked interrupts kick us out of idle */

 CONFIG_OF */

/*

 * am200epd.c -- Platform device for AM200 EPD kit

 *

 * Copyright (C) 2008, Jaya Kumar

 *

 * This file is subject to the terms and conditions of the GNU General Public

 * License. See the file COPYING in the main directory of this archive for

 * more details.

 *

 * Layout is based on skeletonfb.c by James Simmons and Geert Uytterhoeven.

 *

 * This work was made possible by help and equipment support from E-Ink

 * Corporation. http://support.eink.com/community

 *

 * This driver is written to be used with the Metronome display controller.

 * on the AM200 EPD prototype kit/development kit with an E-Ink 800x600

 * Vizplex EPD on a Gumstix board using the Lyre interface board.

 *

 register offsets for gpio control */

 rough check if this is our desired fb and not something else */

 we've now been notified that we have our new fb */

 try to refcount host drv since we are the consumer after this */

/* this gets called as part of our init. these steps must be done now so

	/* the frame buffer is divided as follows:

	command | CRC | padding

	16kb waveform data | CRC | padding

	image data | CRC

 waveform must be 16k + 2 for checksum */

 total is 1 cmd , 1 wfm, padding and image */

	/* save this off because we're manipulating fw after this and

	/* the reason we do this adjustment is because we want to acquire

	 * more framebuffer memory without imposing custom awareness on the

 we divide since we told the LCD controller we're 16bpp */

/* this gets called by metronomefb as part of its init, in our case, we

 * have already completed initial framebuffer init in presetup_fb so we

	/* metromem was set up by the notifier in share_video_mem so now

	/*

	 * Before anything else, we request notification for any fb

	 * creation events.

	 *

	 * FIXME: This is terrible and needs to be nuked. The notifier is used

	 * to get at the fb base address from the boot splash fb driver, which

	 * is then passed to metronomefb. Instaed of metronomfb or this board

	 * support file here figuring this out on their own.

	 *

	 * See also the #ifdef in fbmem.c.

 request our platform independent driver */

 the am200_board that will be seen by metronomefb is a copy */

 this _add binds metronomefb to am200. metronomefb refcounts am200 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Hardware definitions for Voipac PXA270

 *

 * Copyright (C) 2010

 * Marek Vasut <marek.vasut@gmail.com>

/******************************************************************************

 * Pin configuration

 MMC */

 SD detect */

 SD r/o switch */

 GPIO KEYS */

 USER BTN */

 LEDs */

 orange led */

 FFUART */

 LCD */

 PCMCIA */

 PCMCIA CD */

 PCMCIA RDY */

 PCMCIA PPEN */

 PCMCIA RESET */

 CF CD */

 CF RDY */

 CF RESET */

 UHC */

 UDC */

 Ethernet */

 IRQ */

 AC97 */

 TS IRQ */

 I2C */

 IDE */

 IDE IRQ */

/******************************************************************************

 * NOR Flash

 bankwidth in bytes */

/******************************************************************************

 * OneNAND Flash

/******************************************************************************

 * SD/MMC card controller

/******************************************************************************

 * GPIO keys

/******************************************************************************

 * LED

/******************************************************************************

 * USB Host

/******************************************************************************

 * USB Gadget

/******************************************************************************

 * Ethernet

/******************************************************************************

 * Audio and Touchscreen

/******************************************************************************

 * RTC

/******************************************************************************

 * Framebuffer

 CRT 640x480 */

 CRT 800x600 H=30kHz V=48HZ */

 CRT 1024x768 H=40kHz V=50Hz */

/******************************************************************************

 * PATA IDE

 I/O Base address */

 CTL Base address */

 DMA Base address */

 IDE IRQ pin */

/******************************************************************************

 * Core power regulator

 730..1550 mV */

/******************************************************************************

 * Machine init

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/colibri-evalboard.c

 *

 *  Support for Toradex Colibri Evaluation Carrier Board

 *  Daniel Mack <daniel@caiaq.de>

 *  Marek Vasut <marek.vasut@gmail.com>

/******************************************************************************

 * SD/MMC card controller

 PXA270 Colibri */

 PXA300 Colibri */

 PXA320 Colibri */

/******************************************************************************

 * USB Host

 Colibri PXA270 has two usb ports, TBA for 320 */

/******************************************************************************

 * I2C RTC

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/mfp.c

 *

 * PXA3xx Multi-Function Pin Support

 *

 * Copyright (C) 2007 Marvell Internation Ltd.

 *

 * 2007-08-21: eric miao <eric.miao@marvell.com>

 *             initial version

/*

 * Configure the MFPs appropriately for suspend/resume.

 * FIXME: this should probably depend on which system state we're

 * entering - for instance, we might not want to place MFP pins in

 * a pull-down mode if they're an active low chip select, and we're

 * just entering standby.

	/* clear RDH bit when MFP settings are restored

	 *

	 * NOTE: the last 3 bits DxS are write-1-to-clear so carefully

	 * preserve them here in case they will be referenced later

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/mach-pxa/cm-x300.c

 *

 * Support for the CompuLab CM-X300 modules

 *

 * Copyright (C) 2008,2009 CompuLab Ltd.

 *

 * Mike Rapoport <mike@compulab.co.il>

 * Igor Grinberg <grinberg@compulab.co.il>

 LCD */

 BTUART */

 STUART */

 AC97 */

 Keypad */

 MMC1 */

 CMD0 for slot 0 */

 MMC2 */

 FFUART */

 GPIOs */

 MMC CD */

 MMC WP */

 Ethernet IRQ */

 RTC GPIOs */

 RTC CS */

 RTC WR */

 RTC RD */

 RTC IO */

 Standard I2C */

 PWM Backlight */

 GPIOs */

 LED */

 WiFi reset */

 BT reset */

 GPIOs */

 LED */

 WiFi reset */

 BT reset */

 USB PORT 2 */

 external PHY reset pin */

 USB PORT 3 */

 LCD */

 aux_gpio3_0 */

 aux_gpio3_1 */

 aux_gpio3_2 */

 aux_gpio3_3 */

 force read-only */

 force read-only */

 force read-only */

 Card detect on GPIO 82 */

 Write protect on GPIO 85 */

/* The second MMC slot of CM-X300 is hardwired to Libertas card and has

 reset the PHY */

 CLK_POUT is connected to the ULPI PHY */

 PCA9555 */

 Battery */

 DA9030 */

 wi2wi gpio setting for system_rev >= 130 */

 wlan en */

 bt reset */

 Libertas and CSR reset */

 MFP */

 board-processor specific GPIO initialization */

 Make sure that mi->bank[0].start = PHYS_ADDR */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Realtek RTD1195

 *

 * Copyright (c) 2017-2019 Andreas Frber

 Exclude boot ROM from RAM */

 Exclude peripheral register spaces from RAM */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	linux/arch/arm/mach-nspire/nspire.c

 *

 *	Copyright (C) 2013 Daniel Tang <tangrs@tangrs.id.au>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (c) 2014, Fuzhou Rockchip Electronics Co., Ltd

 * Author: Tony Xie <tony.xie@rock-chips.com>

 These enum are option of low power mode */

	/*

	 * if any usb phy is still on(GRF_SIDDQ==0), that means we need the

	 * function of usb wakeup, so do not switch to 32khz, since the usb phy

	 * clk does not connect to 32khz osc

	/*

	 * SGRF_FAST_BOOT_EN - system to boot from FAST_BOOT_ADDR

	 * PCLK_WDT_GATE - disable WDT during suspend.

	/*

	 * The dapswjdp can not auto reset before resume, that cause it may

	 * access some illegal address during resume. Let's disable it before

	 * suspend, and the MASKROM will enable it back.

 booting address of resuming system is from this register value */

 arm off, logic deep sleep */

		/*

		 * In deep suspend we use PMU_PMU_USE_LF to let the rk3288

		 * switch its main clock supply to the alternative 32kHz

		 * source. Therefore set 30ms on a 32kHz clock for pmic

		 * stabilization. Similar 30ms on 24MHz for the other

		 * mode below.

 only wait for stabilization, if we turned the osc off */

		/*

		 * arm off, logic normal

		 * if pmu_clk_core_src_gate_en is not set,

		 * wakeup will be error

 30ms on a 24MHz clock for pmic stabilization */

 oscillator is still running, so no need to wait */

 copy resume code and data to bootsram */

 sentinel */ },

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Copyright (c) 2013 MundoReader S.L.

 * Author: Heiko Stuebner <heiko@sntech.de>

 The cpu device is only available after the initial core bringup */

	/*

	 * We need to soft reset the cpu when we turn off the cpu power domain,

	 * or else the active processors might be stalled when the individual

	 * processor is powered down.

/*

 * Handling of CPU cores

 start the core */

		/*

		 * We communicate with the bootrom to active the cpus other

		 * than cpu0, after a blob of initialize code, they will

		 * stay at wfe state, once they are actived, they will check

		 * the mailbox:

		 * sram_base_addr + 4: 0xdeadbeaf

		 * sram_base_addr + 8: start address for pc

		 * The cpu0 need to wait the other cpus other than cpu0 entering

		 * the wfe state.The wait time is affected by many aspects.

		 * (e.g: cpu frequency, bootrom frequency, sram frequency, ...)

 ensure the cpus other than cpu0 to startup */

/**

 * rockchip_smp_prepare_sram - populate necessary sram block

 * Starting cores execute the code residing at the start of the on-chip sram

 * after power-on. Therefore make sure, this sram region is reserved and

 * big enough. After this check, copy the trampoline code that directs the

 * core to the real startup code in ram into the sram-region.

 * @node: mmio-sram device node

 set the boot function for the sram code */

 copy the trampoline to sram, that runs during startup of the core */

	/*

	 * This function is only called via smp_ops->smp_prepare_cpu().

	 * That only happens if a "/cpus" device tree node exists

	 * and has an "enable-method" property that selects the SMP

	 * operations defined herein.

 fallback, create our own regmap for the pmu area */

 enable the SCU power domain */

		/*

		 * While the number of cpus is gathered from dt, also get the

		 * number of cores from the scu to verify this value when

		 * booting the cores.

 Make sure that all cores except the first are really off */

	/*

	 * We need a delay here to ensure that the dying CPU can finish

	 * executing v7_coherency_exit() and reach the WFI/WFE state

	 * prior to having the power domain disabled.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Device Tree support for Rockchip SoCs

 *

 * Copyright (c) 2013 MundoReader S.L.

 * Author: Heiko Stuebner <heiko@sntech.de>

		/*

		 * Most/all uboot versions for rk3288 don't enable timer7

		 * which is needed for the architected timer to work.

		 * So make sure it is running during early boot.

 SPDX-License-Identifier: GPL-2.0

/*

 * R-Car Generation 2 da9063(L)/da9210 regulator quirk

 *

 * Certain Gen2 development boards have an da9063 and one or more da9210

 * regulators. All of these regulators have their interrupt request lines

 * tied to the same interrupt pin (IRQ2) on the SoC.

 *

 * After cold boot or da9063-induced restart, both the da9063 and da9210 seem

 * to assert their interrupt request lines.  Hence as soon as one driver

 * requests this irq, it gets stuck in an interrupt storm, as it only manages

 * to deassert its own interrupt request line, and the other driver hasn't

 * installed an interrupt handler yet.

 *

 * To handle this, install a quirk that masks the interrupts in both the

 * da9063 and da9210.  This quirk has to run after the i2c master driver has

 * been initialized, but before the i2c slave drivers are initialized.

 *

 * Copyright (C) 2015 Glider bvba

 IRQn Signal Level Monitor Register */

 IRQ2, active low */

 start of DA9210 System Control and Event Registers */

 IRQ line is shared */

 first byte sets the memory pointer, following are consecutive reg values */

	/*

	 * Send message to all PMICs that share an IRQ line to deassert it.

	 *

	 * WARNING: This works only if all the PMICs are on the same I2C bus.

 Skip invalid entry and continue */

 Skip invalid entry and continue */

 SPDX-License-Identifier: GPL-2.0

/*

 * SMP support for R-Mobile / SH-Mobile - sh73a0 portion

 *

 * Copyright (C) 2010  Magnus Damm

 * Copyright (C) 2010  Takashi Yoshii

 System-CPU Wake Up Control Register */

 System-CPU Software Reset Control Register */

 System-CPU Power Status Register */

 SYS Boot Address Register */

 Address Translation Area Register */

 wake up */

 reset */

 Map the reset vector (in headsmp.S) */

 4k */

 setup sh73a0 specific SCU bits */

 SPDX-License-Identifier: GPL-2.0

/*

 * R-Car Generation 2 support

 *

 * Copyright (C) 2013  Renesas Solutions Corp.

 * Copyright (C) 2013  Magnus Damm

 * Copyright (C) 2014  Ulrich Hecht

 sentinel */ }

	/*

	 * If PSCI is available then most likely we are running on PSCI-enabled

	 * U-Boot which, we assume, has already taken care of resetting CNTVOFF

	 * and updating counter module before switching to non-secure mode

	 * and we don't need to.

 ZS / 8 */

		/* At Linux boot time the r8a7790 arch timer comes up

		 * with the counter disabled. Moreover, it may also report

		 * a potentially incorrect fixed 13 MHz frequency. To be

		 * correct these registers need to be updated to use the

		 * frequency EXTAL / 2.

 Remap "armgcnt address map" space */

	/*

	 * Update the timer if it is either not running, or is not at the

	 * right frequency. The timer is only configurable in secure mode

	 * so this avoids an abort if the loader started the timer and

	 * entered the kernel in non-secure mode.

 Update registers with correct frequency */

 make sure arch timer is started by setting bit 0 of CNTCR */

 We are scanning "memory" nodes only */

 keep the area at top near the 32-bit legacy limit */

 reserve 256 MiB at the top of the physical legacy 32-bit space */

 SPDX-License-Identifier: GPL-2.0

/*

 * SMP support for R-Mobile / SH-Mobile - r8a7779 portion

 *

 * Copyright (C) 2011  Renesas Solutions Corp.

 * Copyright (C) 2011  Magnus Damm

 ARM Reset Vector Address Register */

 Map the reset vector (in headsmp-scu.S, headsmp.S) */

 setup r8a7779 specific SCU bits */

 CONFIG_HOTPLUG_CPU */

 SPDX-License-Identifier: GPL-2.0

/*

 * SMP support for R-Mobile / SH-Mobile

 *

 * Copyright (C) 2010  Magnus Damm

 * Copyright (C) 2011  Paul Mundt

 *

 * Based on vexpress, Copyright (C) 2002 ARM Ltd, All Rights Reserved

 Hotplug of any CPU is supported */

 SPDX-License-Identifier: GPL-2.0

/*

 * SH-Mobile Timer

 *

 * Copyright (C) 2010  Magnus Damm

 * Copyright (C) 2002 - 2009  Paul Mundt

	/*

	 * Calculate a worst-case loops-per-jiffy value

	 * based on maximum cpu core hz setting and the

	 * __delay() implementation in arch/arm/lib/delay.S.

	 *

	 * This will result in a longer delay than expected

	 * when the cpu core runs on lower frequencies.

 SPDX-License-Identifier: GPL-2.0

/*

 * r8a73a4 processor support

 *

 * Copyright (C) 2013  Renesas Solutions Corp.

 * Copyright (C) 2013  Magnus Damm

 SPDX-License-Identifier: GPL-2.0

/*

 * r8a7779 processor support

 *

 * Copyright (C) 2011, 2013  Renesas Solutions Corp.

 * Copyright (C) 2011  Magnus Damm

 * Copyright (C) 2013  Cogent Embedded, Inc.

 IRQ */

 Interrupt Submask Clear Register 0 */

 Interrupt Submask Clear Register 1 */

 Interrupt Submask Clear Register 2 */

 Interrupt Submask Clear Register 3 */

 Interrupt Submask Clear Register 4 */

 Interrupt Notification Select Register 0 */

 Interrupt Notification Select Register 1 */

 route all interrupts to ARM */

 unmask all known interrupts in INTCS2 */

 SPDX-License-Identifier: GPL-2.0

/*

 * SMP support for SoCs with SCU covered by mach-shmobile

 *

 * Copyright (C) 2013  Magnus Damm

 For this particular CPU register SCU SMP boot vector */

 install boot code shared by all CPUs */

 enable SCU and cache coherency on booting CPU */

 Use CPU notifier for reset vector control */

 For this particular CPU deregister boot vector */

 disable cache coherency */

 jump to shared mach-shmobile sleep / reset code */

	/* this function is running on another CPU than the offline target,

	 * here we need wait for shutdown code in platform_cpu_die() to

	 * finish before asking SoC-specific code to power off the CPU core.

 SPDX-License-Identifier: GPL-2.0

/*

 * R-Car Generation 2 Power management support

 *

 * Copyright (C) 2013 - 2015  Renesas Electronics Corporation

 * Copyright (C) 2011  Renesas Solutions Corp.

 * Copyright (C) 2011  Magnus Damm

 RST */

 CA15 Boot Address Register */

 CA7 Boot Address Register */

 CA15 Reset Control Register */

 CA7 Reset Control Register */

 SYS Boot Address Register */

 SBAR is valid */

 Reset Control Registers */

 CPU0-3 */

 CPU0-3 */

 On-chip RAM */

 Inter Connect RAM1 (4 KiB) */

 No smp-sram in DT, fall back to hardcoded address */

 RAM for jump stub, because BAR requires 256KB aligned address */

	/*

	 * install the reset vector, use the largest version if we have enough

	 * memory available

 setup reset vectors */

 de-assert reset for CA15 CPUs */

 de-assert reset for CA7 CPUs */

 SPDX-License-Identifier: GPL-2.0

/*

 * Emma Mobile EV2 processor support

 *

 * Copyright (C) 2012  Magnus Damm

 SPDX-License-Identifier: GPL-2.0

/*

 * SMP support for Emma Mobile EV2

 *

 * Copyright (C) 2012  Renesas Solutions Corp.

 * Copyright (C) 2012  Magnus Damm

 Tell ROM loader about our vector (in headsmp.S) */

 setup EMEV2 specific SCU bits */

 SPDX-License-Identifier: GPL-2.0

/*

 * r8a7778 processor support

 *

 * Copyright (C) 2013  Renesas Solutions Corp.

 * Copyright (C) 2013  Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>

 * Copyright (C) 2013  Cogent Embedded, Inc.

 0xfe782288 */

 0xfe78228c */

 0xfe700018 */

 0xfe70002c */

 route all interrupts to ARM */

 unmask all known interrupts in INTCS2 */

 SPDX-License-Identifier: GPL-2.0

/*

 * SMP support for SoCs with APMU

 *

 * Copyright (C) 2014  Renesas Electronics Corporation

 * Copyright (C) 2013  Magnus Damm

 Wake Up Control Register */

 Power Status Register */

 CPUn Power Status Control Register */

 Debug Resource Reset Control Reg. */

 Power Status Register */

 CPUn Status Bit */

 Run Mode */

 CoreStandby Mode */

 Debug Resource Reset Control Register */

 CPU Other Reset Request Enable */

 CPUn Reset Request Enable */

 CPU Peripheral Reset Req. Enable */

 request power on */

 wait for APMU to finish */

 request Core Standby for next WFI */

 nicked from arch/arm/mach-exynos/hotplug.c */

	/*

	 * Turn off coherency

 Select next sleep mode using the APMU */

 Do ARM specific CPU shutdown */

 For this particular CPU deregister boot vector */

 Shutdown CPU core */

 jump to shared mach-shmobile sleep / reset code */

 WFI selects Core Standby */

 Setup for debug mode */

sentinel*/ }

 only enable the cluster that includes the boot CPU */

 install boot code shared by all CPUs */

 For this particular CPU register boot vector */

 CONFIG_SMP */

 SPDX-License-Identifier: GPL-2.0

/*

 * r7s9210 processor support

 *

 * Copyright (C) 2018  Renesas Electronics Corporation

 * Copyright (C) 2018  Chris Brandt

 *

 SPDX-License-Identifier: GPL-2.0

/*

 * R8A7740 processor support

 *

 * Copyright (C) 2011  Renesas Solutions Corp.

 * Copyright (C) 2011  Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>

/*

 * r8a7740 chip has lasting errata on MERAM buffer.

 * this is work-around for it.

 * see

 *	"Media RAM (MERAM)" on r8a7740 documentation

 route signals to GIC */

	/*

	 * To mask the shared interrupt to SPI 149 we must ensure to set

	 * PRIO *and* MASK. Else we run into IRQ floods when registering

	 * the intc_irqpin devices

 SPDX-License-Identifier: GPL-2.0

/*

 * r7s72100 processor support

 *

 * Copyright (C) 2013  Renesas Solutions Corp.

 * Copyright (C) 2013  Magnus Damm

 SPDX-License-Identifier: GPL-2.0

/*

 * Suspend-to-RAM support code for SH-Mobile ARM

 *

 *  Copyright (C) 2011 Magnus Damm

 SPDX-License-Identifier: GPL-2.0

/*

 * sh73a0 processor support

 *

 * Copyright (C) 2010  Takashi Yoshii

 * Copyright (C) 2010  Magnus Damm

 * Copyright (C) 2008  Yoshihiro Shimoda

 Shared attribute override enable, 64K*8way */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Broadcom BCM63138 PMB initialization for secondary CPU(s)

 *

 * Copyright (C) 2015 Broadcom Corporation

 * Author: Florian Fainelli <f.fainelli@gmail.com>

 ARM Control register definitions */

 CPU Power control register definitions */

/* Perform a value write, then spin until the value shifted by

 * shift is seen, masked with mask and is different from cond.

/* Global lock to serialize accesses to the PMB registers while we

 * are bringing up the secondary CPU

 We do not need the number of zones */

 We would not know how to enable a third and greater CPU */

	/* Check if the CPU is already on and save the ARM_CONTROL register

	 * value since we will use it later for CPU de-assert once done with

	 * the CPU-specific power sequence

 Power on PLL */

 Power on CPU<N> RAM */

 De-assert CPU reset */

/*

 * Copyright (C) 2016 Broadcom

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * Copyright (C) 2013 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 physical address */

 virtual address */

 deprecated name */

 Map in the args buffer area */

 Read buffer addr and size from the device tree node */

 We assume space for four 32-bit arguments */

/*

 * int bcm_kona_do_smc(u32 service_id, u32 buffer_addr)

 *

 * Only core 0 can run the secure monitor code.  If an "smc" request

 * is initiated on a different core it must be redirected to core 0

 * for execution.  We rely on the caller to handle this.

 *

 * Each "smc" request supplies a service id and the address of a

 * buffer containing parameters related to the service to be

 * performed.  A flags value defines the behavior of the level 2

 * cache and interrupt handling while the secure monitor executes.

 *

 * Parameters to the "smc" request are passed in r4-r6 as follows:

 *     r4	service id

 *     r5	flags (SEC_ROM_*)

 *     r6	physical address of buffer with other parameters

 *

 * Execution of an "smc" request produces two distinct results.

 *

 * First, the secure monitor call itself (regardless of the specific

 * service request) can succeed, or can produce an error.  When an

 * "smc" request completes this value is found in r12; it should

 * always be SEC_EXIT_NORMAL.

 *

 * In addition, the particular service performed produces a result.

 * The values that should be expected depend on the service.  We

 * therefore return this value to the caller, so it can handle the

 * request result appropriately.  This result value is found in r0

 * when the "smc" request completes.

 Also called r12 */

 Keep IRQ and FIQ off in SM */

 Make sure we got the registers we want */

 __bcm_kona_smc() should only run on CPU 0, with pre-emption disabled */

 Copy the four 32 bit argument values into the bounce area */

 Flush caches for input data passed to Secure Monitor */

 Trap into Secure Monitor and record the request result */

	/*

	 * Due to a limitation of the secure monitor, we must use the SMP

	 * infrastructure to forward all secure monitor calls to Core 0.

/*

 * Copyright (C) 2015 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * Copyright (C) 2012-2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

	/*

	 * The aux_val and aux_mask have no effect since L2 cache is already

	 * enabled.  Pass 0s for aux_val and 1s for aux_mask for default value.

/*

 * Copyright (C) 2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2014-2015 Broadcom Corporation

 * Copyright 2014 Linaro Limited

 Size of mapped Cortex A9 SCU address space */

 1 msec (in nanoseconds) */

 Name of device node property defining secondary boot register location */

/*

 * Enable the Cortex A9 Snoop Control Unit

 *

 * By the time this is called we already know there are multiple

 * cores present.  We assume we're running on a Cortex A9 processor,

 * so any trouble getting the base address register or getting the

 * SCU base is a problem.

 *

 * Return 0 if successful or an error code otherwise.

 Config base address register value is zero for uniprocessor */

 That's the last we'll need of this */

 Ensure the write is visible to the secondary core */

 Enable the SCU on Cortex A9 based SoCs */

 Update the CPU present map to reflect uniprocessor mode */

/*

 * The ROM code has the secondary cores looping, waiting for an event.

 * When an event occurs each core examines the bottom two bits of the

 * secondary boot register.  When a core finds those bits contain its

 * own core id, it performs initialization, including computing its boot

 * address by clearing the boot register value's bottom two bits.  The

 * core signals that it is beginning its execution by writing its boot

 * address back to the secondary boot register, and finally jumps to

 * that address.

 *

 * So to start a core executing we need to:

 * - Encode the (hardware) CPU id with the bottom bits of the secondary

 *   start address.

 * - Write that value into the secondary boot register.

 * - Generate an event to wake up the secondary CPU(s).

 * - Wait for the secondary boot register to be re-written, which

 *   indicates the secondary core has started.

	/*

	 * Secondary cores will start in secondary_startup(),

	 * defined in "arch/arm/kernel/head.S"

 The core to start is encoded in the low bits */

 The low bits will be cleared once the core has started */

 Cluster Dormant Control command to bring CPU into a running state */

/*

 * BCM23550 has a Cluster Dormant Control block that keeps the core in

 * idle state. A command needs to be sent to the block to bring the CPU

 * into running state.

	/* Make sure a CDC node exists before booting the

	 * secondary core.

 Boot the secondary core */

	/* Bring this CPU to RUN state so that nIRQ nFIQ

	 * signals are unblocked.

	/*

	 * After wake up, secondary core branches to the startup

	 * address programmed at SKU ROM LUT location.

 Send a CPU wakeup interrupt to the secondary core */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Broadcom BCM63138 DSL SoCs SMP support code

 *

 * Copyright (C) 2015, Broadcom Corporation

 Size of mapped Cortex A9 SCU address space */

/*

 * Enable the Cortex A9 Snoop Control Unit

 *

 * By the time this is called we already know there are multiple

 * cores present.  We assume we're running on a Cortex A9 processor,

 * so any trouble getting the base address register or getting the

 * SCU base is a problem.

 *

 * Return 0 if successful or an error code otherwise.

 Config base address register value is zero for uniprocessor */

	/* The BCM63138 SoC has two Cortex-A9 CPUs, CPU0 features a complete

	 * and fully functional VFP unit that can be used, but CPU1 does not.

	 * Since we will not be able to trap kernel-mode NEON to force

	 * migration to CPU0, just do not advertise VFP support at all.

	 *

	 * This will make vfp_init bail out and do not attempt to use VFP at

	 * all, for kernel-mode NEON, we do not want to introduce any

	 * conditionals in hot-paths, so we just restrict the system to UP.

 That's the last we'll need of this */

 sentinel */ },

 Locate the secondary CPU node */

 Write the secondary init routine to the BootLUT reset vector */

	/* Power up the core, will jump straight to its reset vector when we

	 * return

/*

 * Copyright (C) 2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * Copyright (C) 2012-2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 Enable watchdog with short timeout (244us). */

 Wait for reset */

 Have to use the first number upstreamed */

/*

 * Broadcom BCM470X / BCM5301X ARM platform code.

 *

 * Copyright 2013 Hauke Mehrtens <hauke@hauke-m.de>

 *

 * Licensed under the GNU/GPL. See COPYING for details.

	/*

	 * We want to ignore aborts forwarded from the PCIe bus that are

	 * expected and shouldn't really be passed by the PCIe controller.

	 * The biggest disadvantage is the same FSR code may be reported when

	 * reading non-existing APB register and we shouldn't ignore that.

/*

 * Copyright (C) 2013-2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * Storage for debug-macro.S's state.

 *

 * This must be in .data not .bss so that it gets initialized each time the

 * kernel is loaded. The data is declared here rather than debug-macro.S so

 * that multiple inclusions of debug-macro.S point at the same data.

 Debug UART initialization required */

 Debug UART physical address */

 Debug UART virtual address */

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2010 Broadcom

/*

 * Copyright (C) 2017 Broadcom

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * Broadcom STB CPU SMP and hotplug support for ARM

 *

 * Copyright (C) 2013-2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

/*

 * We must quiesce a dying CPU before it can be killed by the boot CPU. Because

 * one or more cache may be disabled, we must flush to ensure coherency. We

 * cannot use traditionl completion structures or spinlocks as they rely on

 * coherency.

 Mark this CPU as "up" */

	/*

	 * Set the reset vector to point to the secondary_startup

	 * routine

 Unhalt the cpu */

	/*

	 * The secondary cores power was cut, so we must go through

	 * power-on initialization.

 Sit and wait to die */

 We should never get here... */

	/*

	 * Ordinarily, the hardware forbids power-down of CPU0 (which is good

	 * because it is the boot CPU), but this is not true when using BPCM

	 * manual mode.  Consequently, we must avoid turning off CPU0 here to

	 * ensure that TI2C master reset will work.

 Flush pipeline before resetting CPU */

 Assert reset on the CPU */

 CONFIG_HOTPLUG_CPU */

 Offset is at top of hif_cont_block */

 Missing the brcm,brcmstb-smpboot DT node? */

 Bring up power to the core if necessary */

/*

 * Copyright (C) 2014 Broadcom Corporation

 *

 * This program is free software; you can redistribute it and/or

 * modify it under the terms of the GNU General Public License as

 * published by the Free Software Foundation version 2.

 *

 * This program is distributed "as is" WITHOUT ANY WARRANTY of any

 * kind, whether express or implied; without even the implied warranty

 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the

 * GNU General Public License for more details.

 SPDX-License-Identifier: GPL-2.0+

/*

 * Copyright (C) 2019 Stefan Wahren

 SPDX-License-Identifier: GPL-2.0

/*

 * Device Tree support for MStar/Sigmastar Armv7 SoCs

 *

 * Copyright (c) 2020 thingy.jp

 * Author: Daniel Palmer <daniel@thingy.jp>

/*

 * In the u-boot code the area these registers are in is

 * called "L3 bridge" and there are register descriptions

 * for something in the same area called "AXI".

 *

 * It's not exactly known what this is but the vendor code

 * for both u-boot and linux share calls to "flush the miu pipe".

 * This seems to be to force pending CPU writes to memory so that

 * the state is right before DMA capable devices try to read

 * descriptors and data the CPU has prepared. Without doing this

 * ethernet doesn't work reliably for example.

/*

 * This may need locking to deal with situations where an interrupt

 * happens while we are in here and mb() gets called by the interrupt handler.

 *

 * The vendor code did have a spin lock but it doesn't seem to be needed and

 * removing it hasn't caused any side effects so far.

 *

 * [writel|readl]_relaxed have to be used here because otherwise

 * we'd end up right back in here.

 toggle the flush miu pipe fire bit */

 wait for flush to complete */

	/*

	 * right now we don't know how to boot anything except

	 * cpu 1.

 set the boot address for the second cpu */

 unlock the second cpu */

 and away we go...*/

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/arm/plat-pxa/mfp.c

 *

 *   Multi-Function Pin Support

 *

 * Copyright (C) 2007 Marvell Internation Ltd.

 *

 * 2007-08-21: eric miao <eric.miao@marvell.com>

 *             initial version

 MFPR register bit definitions */

/*

 * Table that determines the low power modes outputs, with actual settings

 * used in parentheses for don't-care values. Except for the float output,

 * the configured driven and pulled levels match, so if there is a need for

 * non-LPM pulled output, the same configuration could probably be used.

 *

 * Output value  sleep_oe_n  sleep_data  pullup_en  pulldown_en  pull_sel

 *                 (bit 7)    (bit 8)    (bit 14)     (bit 13)   (bit 15)

 *

 * Input            0          X(0)        X(0)        X(0)       0

 * Drive 0          0          0           0           X(1)       0

 * Drive 1          0          1           X(1)        0	  0

 * Pull hi (1)      1          X(1)        1           0	  0

 * Pull lo (0)      1          X(0)        0           1	  0

 * Z (float)        1          X(0)        0           0	  0

/*

 * The pullup and pulldown state of the MFP pin at run mode is by default

 * determined by the selected alternate function. In case that some buggy

 * devices need to override this default behavior,  the definitions below

 * indicates the setting of corresponding MFPR bits

 *

 * Definition       pull_sel  pullup_en  pulldown_en

 * MFPR_PULL_NONE       0         0        0

 * MFPR_PULL_LOW        1         0        1

 * MFPR_PULL_HIGH       1         1        0

 * MFPR_PULL_BOTH       1         1        1

 * MFPR_PULL_FLOAT	1         0        0

/* mfp_spin_lock is used to ensure that MFP register configuration

 * (most likely a read-modify-write operation) is atomic, and that

 * mfp_table[] is consistent

 -1 for not configured */

 MFPRxx Register offset */

 Run-Mode Register Value */

 Low Power Mode Register Value */

 mapping of MFP_LPM_* definitions to MFPR_LPM_* register bits */

 mapping of MFP_PULL_* definitions to MFPR_PULL_* register bits */

 mapping of MFP_LPM_EDGE_* definitions to MFPR_EDGE_* register bits */

/*

 * perform a read-back of any valid MFPR register to make sure the

 * previous writings are finished

		/* run-mode pull settings will conflict with MFPR bits of

		 * low power mode state,  calculate mfpr_run and mfpr_lpm

		 * individually if pull != MFP_PULL_NONE

 initialize the table with default - unconfigured */

 mfp offset for readback */

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  linux/arch/arm/mach-pxa/ssp.c

 *

 *  based on linux/arch/arm/mach-sa1100/ssp.c by Russell King

 *

 *  Copyright (C) 2003 Russell King.

 *  Copyright (C) 2003 Wolfson Microelectronics PLC

 *

 *  PXA2xx SSP driver.  This provides the generic core for simple

 *  IO-based SSP applications and allows easy port setup for DMA access.

 *

 *  Author: Liam Girdwood <liam.girdwood@wolfsonmicro.com>

		/* PXA2xx/3xx SSP ports starts from 1 and the internal pdev->id

		 * starts from 0, do a translation here

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARTPEC-6 device support.

		/* Use PL011 DMA Burst Request signal instead of DMA

		 *  Single Request

 SPDX-License-Identifier: GPL-2.0-only

 default */

/*

 * Check the start of physical memory

 *

 * Traditionally, the start address of physical memory is obtained by masking

 * the program counter.  However, this does require that this address is a

 * multiple of 128 MiB, precluding booting Linux on platforms where this

 * requirement is not fulfilled.

 * Hence validate the calculated address against the memory information in the

 * DTB, and, if out-of-range, replace it by the real start address.

 * To preserve backwards compatibility (systems reserving a block of memory

 * at the start of physical memory, kdump, ...), the traditional method is

 * used if it yields a valid address, unless the "linux,usable-memory-range"

 * property is present.

 *

 * Return value: start address of physical memory to use

 There may be multiple cells on LPAE platforms */

	/*

	 * Usable memory in case of a crash dump kernel

	 * This property describes a limitation: memory within this range is

	 * only valid when also described through another mechanism

 Outside 32-bit address space */

 Walk all memory nodes and regions */

 Outside 32-bit address space, skipping */

				/*

				 * Clip to usable range, which takes precedence

				 * over mem_start

 Calculated address is valid, use it */

 No usable memory found, falling back to default */

	/*

	 * The calculated address is not usable, or was overridden by the

	 * "linux,usable-memory-range" property.

	 * Use the lowest usable physical memory address from the DTB instead,

	 * and make sure this is a multiple of 2 MiB for phys/virt patching.

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0

 for inline */

 for size_t */

 for NULL */

 non-static please */

 Diagnostic functions */

 Not needed, but used in some headers pulled in by decompressors */

 Prevent KASAN override of string helpers in decompressor */

 SPDX-License-Identifier: GPL-2.0

/*

 * misc.c

 * 

 * This is a collection of several routines from gzip-1.0.3 

 * adapted for Linux.

 *

 * malloc by Hannu Savolainen 1993 and Matthias Urlichs 1994

 *

 * Modified for ARM Linux by Russell King

 *

 * Nicolas Pitre <nico@visuaide.com>  1999/04/14 :

 *  For this code to run directly from Flash, all constant variables must

 *  be marked with 'const' and all other variables initialized at run-time 

 *  only.  This way all non constant variables will end up in the bss segment,

 *  which should point to addresses in RAM and cleared to 0 on start.

 *  This allows for a much quicker boot time.

 for inline */

/*

 * gzip declarations

 Halt */

 SPDX-License-Identifier: GPL-2.0

 Add the node to root if not found, dropping the leading '/' */

 copy the fdt command line into the buffer */

			/* len is the length of the string

 and append the ATAG_CMDLINE */

/*

 * Convert and fold provided ATAGs into the provided FDT.

 *

 * Return values:

 *    = 0 -> pretend success

 *    = 1 -> bad ATAG (may retry with another possible ATAG pointer)

 *    < 0 -> error from libfdt

	/* In the case of 64 bits memory size, need to reserve 2 cells for

 make sure we've got an aligned pointer */

 if we get a DTB here we're done already */

 validate the ATAG */

 let's give it all the room it could need */

			/* Append the ATAGS command line to the device tree

			 * command line.

			 * NB: This means that if the same parameter is set in

			 * the device tree and in the tags, the one from the

			 * tags will be chosen.

				/* if memsize is 2, that means that

				 * each data needs 2 cells of 32 bits,

 SPDX-License-Identifier: GPL-2.0

/*

 * arch/arm/boot/compressed/string.c

 *

 * Small subset of simple string routines

/*

 * The decompressor is built without KASan but uses the same redirects as the

 * rest of the kernel when CONFIG_KASAN is enabled, defining e.g. memcpy()

 * to __memcpy() but since we are not linking with the main kernel string

 * library in the decompressor, that will lead to link failures.

 *

 * Undefine KASan's versions, define the wrapped functions and alias them to

 * the right names so that when e.g. __memcpy() appear in the code, it will

 * still be linked to this local version of memcpy().

 nothing */;

 SPDX-License-Identifier: GPL-2.0-only

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Device Tree board file for NXP LPC18xx/43xx

 *

 * Copyright (C) 2015 Joachim Eastwood <manabian@gmail.com>

 *

 * This file is licensed under the terms of the GNU General Public

 * License version 2. This program is licensed "as is" without any

 * warranty of any kind, whether express or implied.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * BLAKE2b digest algorithm, NEON accelerated

 *

 * Copyright 2020 Google LLC

 SPDX-License-Identifier: GPL-2.0

/*

 * ARM NEON accelerated ChaCha and XChaCha stream ciphers,

 * including ChaCha20 (RFC7539)

 *

 * Copyright (C) 2016-2019 Linaro, Ltd. <ard.biesheuvel@linaro.org>

 * Copyright (C) 2015 Martin Willi

			/*

			 * The Cortex-A7 and Cortex-A5 do not perform well with

			 * the NEON implementation but do incredibly with the

			 * scalar one and use less power.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * sha2-ce-glue.c - SHA-224/SHA-256 using ARMv8 Crypto Extensions

 *

 * Copyright (C) 2015 Linaro Ltd <ard.biesheuvel@linaro.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * sha1-ce-glue.c - SHA-1 secure hash using ARMv8 Crypto Extensions

 *

 * Copyright (C) 2015 Linaro Ltd <ard.biesheuvel@linaro.org>

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Cryptographic API.

 * Glue code for the SHA1 Secure Hash Algorithm assembler implementation

 *

 * This file is based on sha1_generic.c and sha1_ssse3_glue.c

 *

 * Copyright (c) Alan Smithee.

 * Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>

 * Copyright (c) Jean-Francois Dive <jef@linuxbe.org>

 * Copyright (c) Mathias Krause <minipli@googlemail.com>

 make sure casting to sha1_block_fn() is safe */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Scalar AES core transform

 *

 * Copyright (C) 2017 Linaro Ltd.

 * Author: Ard Biesheuvel <ard.biesheuvel@linaro.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Accelerated CRC32(C) using ARM CRC, NEON and Crypto Extensions instructions

 *

 * Copyright (C) 2016 Linaro Ltd <ard.biesheuvel@linaro.org>

#define PMULL_MIN_LEN		64L	/* minimum size of buffer

 size of NEON register */

 SPDX-License-Identifier: GPL-2.0 OR MIT

/*

 * Copyright (C) 2015-2019 Jason A. Donenfeld <Jason@zx2c4.com>. All Rights Reserved.

 *

 * Based on public domain code from Daniel J. Bernstein and Peter Schwabe. This

 * began from SUPERCOP's curve25519/neon2/scalarmult.s, but has subsequently been

 * manually reworked for use in kernel space.

 might want less than we've got */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * BLAKE2s digest algorithm, ARM scalar implementation

 *

 * Copyright 2020 Google LLC

 defined in blake2s-core.S */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Bit sliced AES using NEON instructions

 *

 * Copyright (C) 2017 Linaro Ltd <ard.biesheuvel@linaro.org>

 must be first member */

	/*

	 * Temporarily disable interrupts to avoid races where

	 * cachelines are evicted when the CPU is interrupted

	 * to do something else.

 handle ciphertext stealing */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * sha512-neon-glue.c - accelerated SHA-384/512 for ARM NEON

 *

 * Copyright (C) 2015 Linaro Ltd <ard.biesheuvel@linaro.org>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * aes-ce-glue.c - wrapper code for ARMv8 AES

 *

 * Copyright (C) 2015 Linaro Ltd <ard.biesheuvel@linaro.org>

 defined in aes-ce-core.S */

	/*

	 * # of rounds specified by AES:

	 * 128 bit key		10 rounds

	 * 192 bit key		12 rounds

	 * 256 bit key		14 rounds

	 * => n byte key	=> 6 + (n/4) rounds

	/*

	 * The AES key schedule round constants

	/*

	 * Generate the decryption keys for the Equivalent Inverse Cipher.

	 * This involves reversing the order of the round keys, and applying

	 * the Inverse Mix Columns transformation on all but the first and

	 * the last one.

 handle ciphertext stealing */

 handle ciphertext stealing */

		/*

		 * Tell aes_ctr_encrypt() to process a tail block.

	/*

	 * Temporarily disable interrupts to avoid races where

	 * cachelines are evicted when the CPU is interrupted

	 * to do something else.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Glue code for the SHA1 Secure Hash Algorithm assembler implementation using

 * ARM NEON instructions.

 *

 * Copyright  2014 Jussi Kivilinna <jussi.kivilinna@iki.fi>

 *

 * This file is based on sha1_generic.c and sha1_ssse3_glue.c:

 *  Copyright (c) Alan Smithee.

 *  Copyright (c) Andrew McDonald <andrew@mcdonald.org.uk>

 *  Copyright (c) Jean-Francois Dive <jef@linuxbe.org>

 *  Copyright (c) Mathias Krause <minipli@googlemail.com>

 *  Copyright (c) Chandramouli Narayanan <mouli@linux.intel.com>

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Accelerated GHASH implementation with ARMv8 vmull.p64 instructions.

 *

 * Copyright (C) 2015 - 2018 Linaro Ltd. <ard.biesheuvel@linaro.org>

 needed for the fallback */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Glue code for the SHA256 Secure Hash Algorithm assembly implementation

 * using NEON instructions.

 *

 * Copyright  2015 Google Inc.

 *

 * This file is based on sha512_neon_glue.c:

 *   Copyright  2014 Jussi Kivilinna <jussi.kivilinna@iki.fi>

 SPDX-License-Identifier: GPL-2.0

/*

 * OpenSSL/Cryptogams accelerated Poly1305 transform for ARM

 *

 * Copyright (C) 2019 Linaro Ltd. <ard.biesheuvel@linaro.org>

 register only the first entry */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Glue code for the SHA256 Secure Hash Algorithm assembly implementation

 * using optimized ARM assembler and NEON instructions.

 *

 * Copyright  2015 Google Inc.

 *

 * This file is based on sha256_ssse3_glue.c:

 *   Copyright (C) 2013 Intel Corporation

 *   Author: Tim Chen <tim.c.chen@linux.intel.com>

 make sure casting to sha256_block_fn() is safe */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * sha512-glue.c - accelerated SHA-384/512 for ARM

 *

 * Copyright (C) 2015 Linaro Ltd <ard.biesheuvel@linaro.org>

 SPDX-License-Identifier: GPL-2.0

/*

 * NHPoly1305 - -almost--universal hash function for Adiantum

 * (NEON accelerated version)

 *

 * Copyright 2018 Google LLC

 wrapper to avoid indirect call to assembly, which doesn't work with CFI */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Accelerated CRC-T10DIF using ARM NEON and Crypto Extensions instructions

 *

 * Copyright (C) 2016 Linaro Ltd <ard.biesheuvel@linaro.org>

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * SGI UV Core Functions

 *

 * Copyright (C) 2008 Silicon Graphics, Inc. All rights reserved.

 ZZZ */

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * Copyright (C) 1998-2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *	Stephane Eranian <eranian@hpl.hp.com>

 * Copyright (C) 2000, Rohit Seth <rohit.seth@intel.com>

 * Copyright (C) 1999 VA Linux Systems

 * Copyright (C) 1999 Walt Drummond <drummond@valinux.com>

 * Copyright (C) 2003 Silicon Graphics, Inc. All rights reserved.

 *

 * Routines used by ia64 machines with contiguous (or virtually contiguous)

 * memory.

 physical address where the bootmem map is located */

/**

 * per_cpu_init - setup per-cpu variables

 *

 * Allocate and setup per-cpu data areas.

	/*

	 * get_free_pages() cannot be used before cpu_init() done.

	 * BSP allocates PERCPU_PAGE_SIZE bytes for all possible CPUs

	 * to avoid that AP calls get_zeroed_page().

		/*

		 * percpu area for cpu0 is moved from the __init area

		 * which is setup by head.S and used till this point.

		 * Update ar.k3.  This move is ensures that percpu

		 * area for cpu0 is on the correct node and its

		 * virtual address isn't insanely far from other

		 * percpu areas which is important for congruent

		 * percpu allocator.

/**

 * setup_per_cpu_areas - setup percpu areas

 *

 * Arch code has already allocated and initialized percpu areas.  All

 * this function has to do is to teach the determined layout to the

 * dynamic percpu allocator, which happens to be more complex than

 * creating whole new ones using helpers.

 units are assigned consecutively to possible cpus */

 set parameters */

 CONFIG_SMP */

/**

 * find_memory - setup memory map

 *

 * Walk the EFI memory map and find usable memory for the system, taking

 * into account reserved areas.

 first find highest page frame number */

 NOTE: this algorithm assumes efi memmap table is ordered */

 Forbid FLATMEM if hole is > than 1G */

/*

 * Set up the page tables.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TLB support routines.

 *

 * Copyright (C) 1998-2001, 2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * 08/02/00 A. Mallick <asit.k.mallick@intel.com>

 *		Modified RID allocation for SMP

 *          Goutham Rao <goutham.rao@intel.com>

 *              IPI based ptc implementation and A-step IPI implementation.

 * Rohit Seth <rohit.seth@intel.com>

 * Ken Chen <kenneth.w.chen@intel.com>

 * Christophe de Dinechin <ddd@hp.com>: Avoid ptc.e on memory allocation

 * Copyright (C) 2007 Intel Corp

 *	Fenghua Yu <fenghua.yu@intel.com>

 *	Add multiple ptc.g/ptc.ga instruction support in global tlb purge.

 mask of supported purge page-sizes */

 log2 of largest supported purge page-size */

Number of TR slots in current processor*/

Max Slot number used by kernel*/

/*

 * Initializes the ia64_ctx.bitmap array based on max_ctx+1.

 * Called after cpu_init() has setup ia64_ctx.max_ctx based on

 * maximum RID that is supported by boot CPU.

/*

 * Acquire the ia64_ctx.lock before calling this function!

 use offset at 300 to skip daemons */

	/*

	 * can't call flush_tlb_all() here because of race condition

	 * with O(1) scheduler [EF]

 prevent preemption/migration */

/*

 * Implement "spinaphores" ... like counting semaphores, but they

 * spin instead of sleeping.  If there are ever any other users for

 * this primitive it can be moved up to a spinaphore.h header.

/*

 * Kernel parameter "nptcg=" overrides max number of concurrent global TLB

 * purges which is reported from either PAL or SAL PALO.

 *

 * We don't have sanity checking for nptcg value. It's the user's responsibility

 * for valid nptcg value on the platform. Otherwise, kernel may hang in some

 * cases.

/*

 * Maximum number of simultaneous ptc.g purges in the system can

 * be defined by PAL_VM_SUMMARY (in which case we should take

 * the smallest value for any cpu in the system) or by the PAL

 * override table (in which case we should ignore the value from

 * PAL_VM_SUMMARY).

 *

 * Kernel parameter "nptcg=" overrides maximum number of simultanesous ptc.g

 * purges defined in either PAL_VM_SUMMARY or PAL override table. In this case,

 * we should ignore the value from either PAL_VM_SUMMARY or PAL override table.

 *

 * Complicating the logic here is the fact that num_possible_cpus()

 * isn't fully setup until we start bringing cpus online.

 In PALO max_purges == 0 really means it! */

 In PAL_VM_SUMMARY max_purges == 0 actually means 1 */

 Restore region IDs for mm */

		/*

		 * Flush ALAT entries also.

 CONFIG_SMP */

 srlz.i implies srlz.d */

 srlz.i implies srlz.d */

		/*

		 * If we flush more than a tera-byte or across regions, we're

		 * probably better off just flushing the entire TLB(s).  This

		 * should be very rare and is not worth optimizing for.

 flush the address range from the tlb */

 flush the virt. page-table area mapping the addr range */

 nuke left overs from bootstrapping... */

/*

 * is_tr_overlap

 *

 * Check overlap with inserted TRs.

/*

 * ia64_insert_tr in virtual mode. Allocate a TR slot

 *

 * target_mask : 0x1 : itr, 0x2 : dtr, 0x3 : idtr

 *

 * va 	: virtual address.

 * pte 	: pte entries inserted.

 * log_size: range to be covered.

 *

 * Return value:  <0 :  error No.

 *

 *		  >=0 : slot number allocated for TR.

 * Must be called with preemption disabled.

Check overlap with existing TR entries*/

Record tr info for mca hander use!*/

/*

 * ia64_purge_tr

 *

 * target_mask: 0x1: purge itr, 0x2 : purge dtr, 0x3 purge idtr.

 * slot: slot number to be freed.

 *

 * Must be called with preemption disabled.

 SPDX-License-Identifier: GPL-2.0

/*

 * Initialize MMU support.

 *

 * Copyright (C) 1998-2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 map entry for zero page */

 i-cache is already coherent with d-cache */

 mark page as clean */

/*

 * Since DMA is i-cache coherent, any (complete) pages that were written via

 * DMA can be marked as "clean" so that lazy_mmu_prot_update() doesn't have to

 * flush them when they get mapped into an executable vm-area.

/*

 * This performs some platform-dependent address space initialization.

 * On IA-64, we want to setup the VM area for the register backing

 * store (which grows upwards) and install the gateway page which is

 * used for signal trampolines, etc.

	/*

	 * If we're out of memory and kmem_cache_alloc() returns NULL, we simply ignore

	 * the problem.  When the process attempts to write to the register backing store

	 * for the first time, it will get a SEGFAULT in this case.

 map NaT-page at address zero to speed up speculative dereferencing of NULL: */

	/*

	 * EFI uses 4KB pages while the kernel can use 4KB or bigger.

	 * Thus EFI and the kernel may have different page sizes. It is

	 * therefore possible to have the initrd share the same page as

	 * the end of the kernel (given current setup).

	 *

	 * To avoid freeing/using the wrong page (kernel sized) we:

	 *	- align up the beginning of initrd

	 *	- align down the end of initrd

	 *

	 *  |             |

	 *  |=============| a000

	 *  |             |

	 *  |             |

	 *  |             | 9000

	 *  |/////////////|

	 *  |/////////////|

	 *  |=============| 8000

	 *  |///INITRD////|

	 *  |/////////////|

	 *  |/////////////| 7000

	 *  |             |

	 *  |KKKKKKKKKKKKK|

	 *  |=============| 6000

	 *  |KKKKKKKKKKKKK|

	 *  |KKKKKKKKKKKKK|

	 *  K=kernel using 8KB pages

	 *

	 * In this example, we must free page 8000 ONLY. So we must align up

	 * initrd_start and keep initrd_end as is.

/*

 * This installs a clean page in the kernel's page table.

 note: this is NOT pgd_offset()! */

 no need for flush_tlb */

	/*

	 * Map the gate page twice: once read-only to export the ELF

	 * headers etc. and once execute-only page to enable

	 * privilege-promotion via "epc":

 Fill in the holes (if any) with read-only zero pages: */

	/*

	 * Check if the virtually mapped linear page table (VMLPT) overlaps with a mapped

	 * address space.  The IA-64 architecture guarantees that at least 50 bits of

	 * virtual address space are implemented but if we pick a large enough page size

	 * (e.g., 64KB), the mapped address space is big enough that it will overlap with

	 * VMLPT.  I assume that once we run on machines big enough to warrant 64KB pages,

	 * IMPL_VA_MSB will be significantly bigger, so this is unlikely to become a

	 * problem in practice.  Alternatively, we could truncate the top of the mapped

	 * address space to not permit mappings that would overlap with the VMLPT.

	 * --davidm 00/12/06

	/*

	 * The virtual page table has to cover the entire implemented address space within

	 * a region even though not all of this space may be mappable.  The reason for

	 * this is that the Access bit and Dirty bit fault handlers perform

	 * non-speculative accesses to the virtual page table, so the address range of the

	 * virtual page table itself needs to be covered by virtual page table.

	/*

	 * mapped_space_bits - PAGE_SHIFT is the total number of ptes we need,

	 * which must fit into "vmlpt_bits - pte_bits" slots. Second half of

	 * the test makes sure that our mapped space doesn't overlap the

	 * unimplemented hole in the middle of the region.

 place the VMLPT at the end of each page-table mapped region: */

	/*

	 * Set the (virtually mapped linear) page table address.  Bit

	 * 8 selects between the short and long format, bits 2-7 the

	 * size of the table, and bit 0 whether the VHPT walker is

	 * enabled.

/*

 * Boot command-line option "nolwsys" can be used to disable the use of any light-weight

 * system call handler.  When this option is in effect, all fsyscalls will end up bubbling

 * down into the kernel and calling the normal (heavy-weight) syscall handler.  This is

 * useful for performance testing, but conceivably could also come in handy for debugging

 * purposes.

	/*

	 * This needs to be called _after_ the command line has been parsed but

	 * _before_ any drivers that may need the PCI DMA interface are

	 * initialized or bootmem has been freed.

	/*

	 * For fsyscall entrpoints with no light-weight handler, use the ordinary

	 * (heavy-weight) handler, but mark it by setting bit 0, so the fsyscall entry

	 * code can tell them apart.

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * This file contains NUMA specific variables and functions which are used on

 * NUMA machines with contiguous memory.

 * 

 *                         2002/08/07 Erich Focht <efocht@ess.nec.de>

/*

 * The following structures are usually initialized by ACPI or

 * similar mechanisms and describe the NUMA characteristics of the machine.

/*

 * This is a matrix with "distances" between nodes, they should be

 * proportional to the memory access latency ratios.

 Identify which cnode a physical address resides on */

/*

 *  SRAT information is stored in node_memblk[], then we can use SRAT

 *  information at memory-hot-add if necessary.

 SPDX-License-Identifier: GPL-2.0

/*

 * MMU fault handling support.

 *

 * Copyright (C) 1998-2002 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

/*

 * Return TRUE if ADDRESS points at a page in the kernel's mapped segment

 * (inside region 5, on ia64) and that page is present.

 mmap_lock is performance critical.... */

	/*

	 * If we're in an interrupt or have no user context, we must not take the fault..

	/*

	 * This is to handle the kprobes on user space access instructions

        /*

         * find_vma_prev() returns vma such that address < vma->vm_end or NULL

         *

         * May find no vma, but could be that the last vm area is the

         * register backing store that needs to expand upwards, in

         * this case vma will be null, but prev_vma will ne non-null

 OK, we've got a good vm_area for this memory area.  Check the access permissions: */

	/*

	 * If for any reason at all we couldn't handle the fault, make

	 * sure we exit gracefully rather than endlessly redo the

	 * fault.

		/*

		 * We ran out of memory, or some other thing happened

		 * to us that made us unable to handle the page fault

		 * gracefully.

			 /* No need to mmap_read_unlock(mm) as we would

			 * have already released it in __lock_page_or_retry

			 * in mm/filemap.c.

		/*

		 * Since the register backing store is accessed sequentially,

		 * we disallow growing it by more than a page at a time.

		/*

		 * This fault was due to a speculative load or lfetch.fault, set the "ed"

		 * bit in the psr to ensure forward progress.  (Target register will get a

		 * NaT for ld.s, lfetch will be canceled.)

		/*

		 * This fault was due to a speculative load or lfetch.fault, set the "ed"

		 * bit in the psr to ensure forward progress.  (Target register will get a

		 * NaT for ld.s, lfetch will be canceled.)

	/*

	 * Since we have no vma's for region 5, we might get here even if the address is

	 * valid, due to the VHPT walker inserting a non present translation that becomes

	 * stale. If that happens, the non present fault handler already purged the stale

	 * translation, which fixed the problem. So, we check to see if the translation is

	 * valid, and return if it is.

	/*

	 * Oops. The kernel tried to access some bad page. We'll have to terminate things

	 * with extreme prejudice.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2000, 2003 Silicon Graphics, Inc.  All rights reserved.

 * Copyright (c) 2001 Intel Corp.

 * Copyright (c) 2001 Tony Luck <tony.luck@intel.com>

 * Copyright (c) 2002 NEC Corp.

 * Copyright (c) 2002 Kimio Suganuma <k-suganuma@da.jp.nec.com>

 * Copyright (c) 2004 Silicon Graphics, Inc

 *	Russ Anderson <rja@sgi.com>

 *	Jesse Barnes <jbarnes@sgi.com>

 *	Jack Steiner <steiner@sgi.com>

/*

 * Platform initialization for Discontig Memory

/*

 * Track per-node information needed to setup the boot memory allocator, the

 * per-node areas, and the real VM.

/*

 * To prevent cache aliasing effects, align per-node structures so that they

 * start at addresses that are strided by node number.

/**

 * build_node_maps - callback to setup mem_data structs for each node

 * @start: physical start of range

 * @len: length of range

 * @node: node where this range resides

 *

 * Detect extents of each piece of memory that we wish to

 * treat as a virtually contiguous block (i.e. each node). Each such block

 * must start on an %IA64_GRANULE_SIZE boundary, so we round the address down

 * if necessary.  Any non-existent pages will simply be part of the virtual

 * memmap.

/**

 * early_nr_cpus_node - return number of cpus on a given node

 * @node: node to check

 *

 * Count the number of cpus on @node.  We can't use nr_cpus_node() yet because

 * acpi_boot_init() (which builds the node_to_cpu_mask array) hasn't been

 * called yet.  Note that node 0 will also count all non-existent cpus.

/**

 * compute_pernodesize - compute size of pernode data

 * @node: the node id.

/**

 * per_cpu_node_setup - setup per-cpu areas on each node

 * @cpu_data: per-cpu area on this node

 * @node: node to setup

 *

 * Copy the static per-cpu data into the region we just set aside and then

 * setup __per_cpu_offset for each CPU on this node.  Return a pointer to

 * the end of the area.

		/*

		 * percpu area for cpu0 is moved from the __init area

		 * which is setup by head.S and used till this point.

		 * Update ar.k3.  This move is ensures that percpu

		 * area for cpu0 is on the correct node and its

		 * virtual address isn't insanely far from other

		 * percpu areas which is important for congruent

		 * percpu allocator.

/**

 * setup_per_cpu_areas - setup percpu areas

 *

 * Arch code has already allocated and initialized percpu areas.  All

 * this function has to do is to teach the determined layout to the

 * dynamic percpu allocator, which happens to be more complex than

 * creating whole new ones using helpers.

 determine base */

 build cpu_map, units are grouped by node */

 set basic parameters */

	/*

	 * CPUs are put into groups according to node.  Walk cpu_map

	 * and create new groups at node boundaries.

/**

 * fill_pernode - initialize pernode data.

 * @node: the node id.

 * @pernode: physical address of pernode data

 * @pernodesize: size of the pernode data

/**

 * find_pernode_space - allocate memory for memory map and per-node structures

 * @start: physical start of range

 * @len: length of range

 * @node: node where this range resides

 *

 * This routine reserves space for the per-cpu data struct, the list of

 * pg_data_ts and the per-node data struct.  Each node will have something like

 * the following in the first chunk of addr. space large enough to hold it.

 *

 *    ________________________

 *   |                        |

 *   |~~~~~~~~~~~~~~~~~~~~~~~~| <-- NODEDATA_ALIGN(start, node) for the first

 *   |    PERCPU_PAGE_SIZE *  |     start and length big enough

 *   |    cpus_on_this_node   | Node 0 will also have entries for all non-existent cpus.

 *   |------------------------|

 *   |   local pg_data_t *    |

 *   |------------------------|

 *   |  local ia64_node_data  |

 *   |------------------------|

 *   |          ???           |

 *   |________________________|

 *

 * Once this space has been set aside, the bootmem maps are initialized.  We

 * could probably move the allocation of the per-cpu and ia64_node_data space

 * outside of this function and use alloc_bootmem_node(), but doing it here

 * is straightforward and we get the alignments we want so...

	/*

	 * Make sure this memory falls within this node's usable memory

	 * since we may have thrown some away in build_maps().

 Don't setup this node's local space twice... */

	/*

	 * Calculate total size needed, incl. what's necessary

	 * for good alignment and alias prevention.

 Is this range big enough for what we want to store here? */

/**

 * reserve_pernode_space - reserve memory for per-node space

 *

 * Reserve the space used by the bootmem maps & per-node space in the boot

 * allocator so that when we actually create the real mem maps we don't

 * use their memory.

 Now the per-node space */

	/*

	 * for_each_online_node() can't be used at here.

	 * node_online_map is not set for hot-added nodes at this time,

	 * because we are halfway through initialization of the new node's

	 * structures.  If for_each_online_node() is used, a new node's

	 * pg_data_ptrs will be not initialized. Instead of using it,

	 * pgdat_list[] is checked.

/**

 * initialize_pernode_data - fixup per-cpu & per-node pointers

 *

 * Each node's per-node area has a copy of the global pg_data_t list, so

 * we copy that to each node here, as well as setting the per-cpu pointer

 * to the local node data structure.

 Set the node_data pointer for each per-cpu struct */

 CONFIG_SMP */

/**

 * memory_less_node_alloc - * attempt to allocate memory on the best NUMA slit

 * 	node but fall back to any other node when __alloc_bootmem_node fails

 *	for best.

 * @nid: node id

 * @pernodesize: size of this node's pernode data

/**

 * memory_less_nodes - allocate and initialize CPU only nodes pernode

 *	information.

/**

 * find_memory - walk the EFI memory map and setup the bootmem allocator

 *

 * Called early in boot to setup the bootmem allocator, and to

 * allocate the per-cpu and per-node structures.

 These actually end up getting called by call_pernode_memory() */

/**

 * per_cpu_init - setup per-cpu variables

 *

 * find_pernode_space() does most of this already, we just need to set

 * local_per_cpu_offset

 CONFIG_SMP */

/**

 * call_pernode_memory - use SRAT to call callback functions with node info

 * @start: physical start of range

 * @len: length of range

 * @arg: function to call for each range

 *

 * efi_memmap_walk() knows nothing about layout of memory across nodes. Find

 * out to which node a block of memory belongs.  Ignore memory that we cannot

 * identify, and split blocks that run across multiple nodes.

 *

 * Take this opportunity to round the start address up and the end address

 * down to page boundaries.

 No SRAT table, so assume one node (node 0) */

/**

 * paging_init - setup page tables

 *

 * paging_init() sets up the page tables for each node of the system and frees

 * the bootmem allocator memory for general use.

 SPDX-License-Identifier: GPL-2.0

/*

 * IA-64 Huge TLB Page Support for Kernel.

 *

 * Copyright (C) 2002-2004 Rohit Seth <rohit.seth@intel.com>

 * Copyright (C) 2003-2004 Ken Chen <kenneth.w.chen@intel.com>

 *

 * Sep, 2003: add numa support

 * Feb, 2004: dynamic hugetlb page size via boot parameter

/*

 * Don't actually need to do any preparation, but need to make sure

 * the address is in the right region.

	/*

	 * This is called to free hugetlb page tables.

	 *

	 * The offset of these addresses from the base of the hugetlb

	 * region must be scaled down by HPAGE_SIZE/PAGE_SIZE so that

	 * the standard free_pgd_range will free the right page tables.

	 *

	 * If floor and ceiling are also in the hugetlb region, they

	 * must likewise be scaled down; but if outside, left unchanged.

 Handle MAP_FIXED */

 This code assumes that RGN_HPAGE != 0. */

		/*

		 * shouldn't happen, but just in case.

	/*

	 * boot cpu already executed ia64_mmu_init, and has HPAGE_SHIFT_DEFAULT

	 * override here with new page shift.

 SPDX-License-Identifier: GPL-2.0

/*

 * Kernel exception handling table support.  Derived from arch/alpha/mm/extable.c.

 *

 * Copyright (C) 1998, 1999, 2001-2002, 2004 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 set continuation slot number */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (c) Copyright 2006, 2007 Hewlett-Packard Development Company, L.P.

 *	Bjorn Helgaas <bjorn.helgaas@hp.com>

	/*

	 * For things in kern_memmap, we must use the same attribute

	 * as the rest of the kernel.  For more details, see

	 * Documentation/ia64/aliasing.rst.

	/*

	 * Some chipsets don't support UC access to memory.  If

	 * WB is supported for the whole granule, we prefer that.

	/*

	 * WB is not supported for the whole granule, so we can't use

	 * the region 7 identity mapping.  If we can safely cover the

	 * area with kernel page table mappings, we can use those

	 * instead.

		/*

		 * Mappings have to be page-aligned

		/*

		 * Ok, go for it..

 SPDX-License-Identifier: GPL-2.0

/*

 * Architecture-specific setup.

 *

 * Copyright (C) 1998-2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 * 04/11/17 Ashok Raj	<ashok.raj@intel.com> Added CPU Hotplug Support

 *

 * 2005-10-07 Keith Owens <kaos@sgi.com>

 *	      Add notify_die() hooks.

 print the stacked registers */

 size of frame */

 local support for deprecated console_print */

		/*

		 * defer signal-handling etc. until we return to

		 * privilege-level 0.

 deal with pending signal delivery */

 force interrupt enable */

 force interrupt enable */

 copy user rbs to kernel rbs */

 force interrupt enable */

 force interrupt disable */

 We don't actually take CPU down, just spin without interrupts. */

 Ack it */

	/*

	 * The above is a point of no-return, the processor is

	 * expected to be in SAL loop now.

 CONFIG_HOTPLUG_CPU */

/*

 * Copy the state of an ia-64 thread.

 *

 * We get here through the following  call chain:

 *

 *	from user-level:	from kernel:

 *

 *	<clone syscall>	        <some kernel call frames>

 *	sys_clone		   :

 *	kernel_clone		kernel_clone

 *	copy_thread		copy_thread

 *

 * This means that the stack layout is as follows:

 *

 *	+---------------------+ (highest addr)

 *	|   struct pt_regs    |

 *	+---------------------+

 *	| struct switch_stack |

 *	+---------------------+

 *	|                     |

 *	|    memory stack     |

 *	|                     | <-- sp (lowest addr)

 *	+---------------------+

 *

 * Observe that we copy the unat values that are in pt_regs and switch_stack.  Spilling an

 * integer to address X causes bit N in ar.unat to be set to the NaT bit of the register,

 * with N=(X & 0x1ff)/8.  Thus, copying the unat value preserves the NaT bits ONLY if the

 * pt_regs structure in the parent is congruent to that of the child, modulo 512.  Since

 * the stack is page aligned and the page size is at least 4KB, this is always the case,

 * so there is nothing to worry about.

 copy parts of thread_struct: */

	/*

	 * NOTE: The calling convention considers all floating point

	 * registers in the high partition (fph) to be scratch.  Since

	 * the only way to get to this point is through a system call,

	 * we know that the values in fph are all dead.  Hence, there

	 * is no need to inherit the fph state from the parent to the

	 * child and all we have to do is to make sure that

	 * IA64_THREAD_FPH_VALID is cleared in the child.

	 *

	 * XXX We could push this optimization a bit further by

	 * clearing IA64_THREAD_FPH_VALID on ANY system call.

	 * However, it's not clear this is worth doing.  Also, it

	 * would be a slight deviation from the normal Linux system

	 * call behavior where scratch registers are preserved across

	 * system calls (unless used by the system call itself).

 don't pick up stale state from a CPU's fph */

 fork_idle() called us */

 payload */

 argument */

		/*

		 * Preserve PSR bits, except for bits 32-34 and 37-45,

		 * which we can't read.

 mark as valid, empty frame */

		/* stop some PSR bits from being inherited.

		 * the psr.up/psr.pp bits must be cleared on fork but inherited on execve()

		 * therefore we must specify them explicitly here and not include them in

		 * IA64_PSR_BITS_TO_CLEAR.

 copy parent's switch_stack & pt_regs to child: */

 copy the parent's register backing store to the child: */

	/* stop some PSR bits from being inherited.

	 * the psr.up/psr.pp bits must be cleared on fork but inherited on execve()

	 * therefore we must specify them explicitly here and not include them in

	 * IA64_PSR_BITS_TO_CLEAR.

 don't leak any kernel bits to user-level */

	/*

	 * coredump format:

	 *	r0-r31

	 *	NaT bits (for r0-r31; bit N == 1 iff rN is a NaT)

	 *	predicate registers (p0-p63)

	 *	b0-b7

	 *	ip cfm user-mask

	 *	ar.rsc ar.bsp ar.bspstore ar.rnat

	 *	ar.ccv ar.unat ar.fpsr ar.pfs ar.lc ar.ec

 r0 is zero */

	/*

	 * For bsp and bspstore, unw_get_ar() would return the kernel

	 * addresses, but we need the user-level addresses instead:

 note: by convention PT_AR_BSP points to the end of the urbs! */

 UNW_AR_PFS is == to pt->cr_ifs for interrupt frames */

/*

 * Flush thread state.  This is called when a thread does an execve().

 drop floating-point and debug-register state if it exists: */

/*

 * Clean up state associated with a thread.  This is called when

 * the thread calls exit().

	/*

	 * Note: p may not be a blocked task (it could be current or

	 * another process running on some other CPU.  Rather than

	 * trying to determine if p is really blocked, we just assume

	 * it's blocked and rely on the unwind routines to fail

	 * gracefully if the process wasn't really blocked after all.

	 * --davidm 99/12/15

 SPDX-License-Identifier: GPL-2.0-only

/*

 * System Abstraction Layer (SAL) interface routines.

 *

 * Copyright (C) 1998, 1999, 2001, 2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 * Copyright (C) 1999 VA Linux Systems

 * Copyright (C) 1999 Walt Drummond <drummond@valinux.com>

 function entry point */

 gp value to use */

 fill in the SAL procedure descriptor and point ia64_sal to it: */

 Check for broken firmware */

		/*

		 * Old firmware for zx2000 prototypes have this weird version number,

		 * reset it to something sane.

	/*

	 * For CPU Hotplug we dont want to do any chipset supported

	 * interrupt redirection. The reason is this would require that

	 * All interrupts be stopped and hard bind the irq to a cpu.

	 * Later when the interrupt is fired we need to set the redir hint

	 * on again in the vector. This is cumbersome for something that the

	 * user mode irq balancer will solve anyways.

/*

 * HP rx5670 firmware polls for interrupts during SAL_CACHE_FLUSH by reading

 * cr.ivr, but it never writes cr.eoi.  This leaves any interrupt marked as

 * "in-service" and masks other interrupts of equal or lower priority.

 *

 * HP internal defect reports: F1859, F2775, F3031.

	/*

	 * Send ourselves a timer interrupt, wait until it's reported, and see

	 * if SAL_CACHE_FLUSH drops it.

 revisions are coded in BCD, so %x does the job for us */

		/*

		 * The first byte of each entry type contains the type

		 * descriptor.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SMP boot-related support

 *

 * Copyright (C) 1998-2003, 2005 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 * Copyright (C) 2001, 2004-2005 Intel Corp

 * 	Rohit Seth <rohit.seth@intel.com>

 * 	Suresh Siddha <suresh.b.siddha@intel.com>

 * 	Gordon Jin <gordon.jin@intel.com>

 *	Ashok Raj  <ashok.raj@intel.com>

 *

 * 01/05/16 Rohit Seth <rohit.seth@intel.com>	Moved SMP booting functions from smp.c to here.

 * 01/04/27 David Mosberger <davidm@hpl.hp.com>	Added ITC synching code.

 * 02/07/31 David Mosberger <davidm@hpl.hp.com>	Switch over to hotplug-CPU boot-sequence.

 *						smp_boot_cpus()/smp_commence() is replaced by

 *						smp_prepare_cpus()/__cpu_up()/smp_cpus_done().

 * 04/06/21 Ashok Raj		<ashok.raj@intel.com> Added CPU Hotplug Support

 * 04/12/26 Jin Gordon <gordon.jin@intel.com>

 * 04/12/26 Rohit Seth <rohit.seth@intel.com>

 *						Add multi-threading and multi-core detection

 * 05/01/30 Suresh Siddha <suresh.b.siddha@intel.com>

 *						Setup cpu_sibling_map and cpu_core_map

/*

 * Global array allocated for NR_CPUS at boot time

/*

 * start_ap in head.S uses this to store current booting cpu

 * info.

/*

 * ITC synchronization related stuff:

 magic value */

 likewise */

/*

 * State for each CPU

 which logical CPU number maps to which CPU (physical APIC ID) */

 External Int use to wakeup APs */

 are INT and IPI redirectable by the chipset? */

	/*

	 * Cache the b0 value on the first AP that comes up

/*

 * Return the number of cycles by which our itc differs from the itc on the master

 * (time-keeper) CPU.  A positive number indicates our itc is ahead of the master,

 * negative that it is behind.

 average best_t0 and best_t1 without overflow: */

/*

 * Synchronize ar.itc of the current (slave) CPU with the ar.itc of the MASTER CPU

 * (normally the time-keeper CPU).  We use a closed loop to eliminate the possibility of

 * unaccounted-for errors (such as getting a machine check in the middle of a calibration

 * step).  The basic idea is for the slave to ask the master what itc value it has and to

 * read its own itc before and after the master responds.  Each iteration gives us three

 * timestamps:

 *

 *	slave		master

 *

 *	t0 ---\

 *             ---\

 *		   --->

 *			tm

 *		   /---

 *	       /---

 *	t1 <---

 *

 *

 * The goal is to adjust the slave's ar.itc such that tm falls exactly half-way between t0

 * and t1.  If we achieve this, the clocks are synchronized provided the interconnect

 * between the slave and the master is symmetric.  Even if the interconnect were

 * asymmetric, we would still know that the synchronization error is smaller than the

 * roundtrip latency (t0 - t1).

 *

 * When the interconnect is quiet and symmetric, this lets us synchronize the itc to

 * within one or two cycles.  However, we can only *guarantee* that the synchronization is

 * accurate to within a round-trip time, which is typically in the range of several

 * hundred cycles (e.g., ~500 cycles).  In practice, this means that the itc's are usually

 * almost perfectly synchronized, but we shouldn't assume that the accuracy is much better

 * than half a micro second or so.

 roundtrip time */

 master's timestamp */

 difference between midpoint and master's timestamp */

 estimate of itc adjustment latency */

	/*

	 * Make sure local timer ticks are disabled while we sync.  If

	 * they were enabled, we'd have to worry about nasty issues

	 * like setting the ITC ahead of (or a long time before) the

	 * next scheduled tick.

 wait for master to be ready */

 let's lock on to this... */

/*

 * Ideally sets up per-cpu profiling hooks.  Doesn't do much now...

	/*

	 * numa_node_id() works after this.

 Setup the per cpu irq handling data structures */

 Setup vector on AP */

		/*

		 * Synchronize the ITC with the BP.  Need to do this after irqs are

		 * enabled because ia64_sync_itc() calls smp_call_function_single(), which

		 * calls spin_unlock_bh(), which calls spin_unlock_bh(), which calls

		 * local_bh_enable(), which bugs out if irqs are not enabled...

	/*

	 * Get our bogomips.

	/*

	 * Delay calibration can be skipped if new processor is identical to the

	 * previous processor.

	/*

	 * Allow the master to continue.

/*

 * Activate a secondary processor.  head.S calls this.

 Early console may use I/O ports */

	/*

	 * Wait 10s total for the AP to start

 It has booted */

 Make sure we re-read cpu_callin_map */

 was set in smp_callin() */

/*

 * Initialize the logical CPU number to SAPICID mapping

/*

 * Cycle through the APs sending Wakeup IPIs to boot each.

	/*

	 * Initialize the per-CPU profiling counter/multiplier

	/*

	 * If SMP should be disabled, then really disable it!

 remove it from all sibling map's */

	/*

	 * dont permit CPEI target to removed.

			/*

			 * Now re-target the CPEI to a different processor

			/*

			 * Switch for now, immediately, we need to do fake intr

			 * as other interrupts, but need to study CPEI behaviour with

			 * polling before making changes.

 must be called with cpucontrol mutex held */

	/*

	 * dont permit boot processor for now

 They ack this in play_dead by setting CPU_DEAD */

 CONFIG_HOTPLUG_CPU */

	/*

	 * Allow the user to impress friends.

	/*

	 * Already booted cpu? not valid anymore since we dont

	 * do idle loop tightspin anymore.

 Processor goes to start_secondary(), sets online flag */

/*

 * Assume that CPUs have been discovered by some platform-dependent interface.  For

 * SoftSDV/Lion, that would be ACPI.

 *

 * Setup of the IPI irq handler is done in irq.c:init_IRQ_SMP().

 Tell SAL where to drop the APs.  */

/*

 * identify_siblings(cpu) gets called from identify_cpu. This populates the 

 * information related to logical execution units in per_cpu_data structure.

/*

 * returns non zero, if multi-threading is enabled

 * on at least one physical package. Due to hotplug cpu

 * and (maxcpus=), all threads may not necessarily be enabled

 * even though the processor supports multi-threading.

 SPDX-License-Identifier: GPL-2.0

/*

 * arch/ia64/kernel/stacktrace.c

 *

 * Stack trace management functions

 *

/*

 * Save stack-backtrace addresses into a stack_trace buffer.

 SPDX-License-Identifier: GPL-2.0

/*

 * Architecture-specific trap handling.

 *

 * Copyright (C) 1998-2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * 05/12/00 grao <goutham.rao@intel.com> : added isr in siginfo for SIGFPE

 For unblank_screen() */

 for ssleep() */

 FPSWA fixup: make the interface pointer a kernel virtual address: */

 unknown error (used by GCC for __builtin_abort()) */

 integer divide by zero */

 integer overflow */

 range check/bounds check */

 null pointer dereference */

 misaligned data */

 decimal overflow */

 decimal divide by zero */

 packed decimal error */

 invalid ASCII digit */

 invalid decimal digit */

 paragraph stack overflow */

 bundle-update in progress */

 clear __ISR_VALID */, 0);

/*

 * disabled_fph_fault() is called when a user-level process attempts to access f32..f127

 * and it doesn't own the fp-high register partition.  When this happens, we save the

 * current fph partition in the task_struct of the fpu-owner (if necessary) and then load

 * the fp-high partition of the current task (if necessary).  Note that the kernel has

 * access to fph by the time we get here, as the IVT's "Disabled FP-Register" handler takes

 * care of clearing psr.dfh.

 first, grant user-level access to fph partition: */

	/*

	 * Make sure that no other task gets in on this processor

	 * while we're claiming the FPU

 !CONFIG_SMP */

		/*

		 * Set mfh because the state in thread.fph does not match the state in

		 * the fph partition.

	/*

	 * compute fp_state.  only FP registers f6 - f11 are used by the

	 * kernel, so set those bits in the mask and set the low volatile

	 * pointer to point to these registers.

 bit6..bit11 */

	/*

	 * unsigned long (*EFI_FPSWA) (

	 *      unsigned long    trap_type,

	 *	void             *Bundle,

	 *	unsigned long    *pipsr,

	 *	unsigned long    *pfsr,

	 *	unsigned long    *pisr,

	 *	unsigned long    *ppreds,

	 *	unsigned long    *pifs,

	 *	void             *fp_state);

/*

 * Handle floating-point assist faults and traps.

 minimize races by grabbing a copy of count BEFORE checking last.time. */

			/*

			 * Lower 4 bits are used as a count. Upper bits are a sequence

			 * number that is updated when count is reset. The cmpxchg will

			 * fail is seqno has changed. This minimizes mutiple cpus

			 * resetting the count.

 used fetchadd to atomically update the count */

 emulation was successful */

 is next instruction a trap? */

 default code */

				/* denormal operand gets the same si_code as underflow 

 raise exception */

 default code */

		/*

		 * This fault was due to lfetch.fault, set "ed" bit in the psr to cancel

		 * the lfetch.

 General Exception */

 Disabled FP-Register */

 NaT Consumption */

 NaT page consumption */

 register NaT consumption */

 Unsupported Data Reference */

 Debug */

 Taken Branch Trap */

 Single Step Trap */

			/*

			 * Got a trap in fsys-mode: Taken Branch Trap

			 * and Single Step trap need special handling;

			 * Debug trap is ignored (we disable it here

			 * and re-enable it in the lower-privilege trap).

 re-do the system call via break 0x100000: */

			/*

			 * Erratum 10 (IFA may contain incorrect address) now has

			 * "NoFix" status.  There are no plans for fixing this.

 fp fault */

 fp trap */

 Lower-Privilege Transfer Trap */

			/* If we disabled debug traps during an fsyscall,

			 * re-enable them here.

			/*

			 * Just clear PSR.lp and then return immediately:

			 * all the interesting work (e.g., signal delivery)

			 * is done in the kernel exit path.

 Unimplemented Instr. Address Trap */

 SPDX-License-Identifier: GPL-2.0

/*

 * Architecture-specific setup.

 *

 * Copyright (C) 1998-2001, 2003-2004 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *	Stephane Eranian <eranian@hpl.hp.com>

 * Copyright (C) 2000, 2004 Intel Corp

 * 	Rohit Seth <rohit.seth@intel.com>

 * 	Suresh Siddha <suresh.b.siddha@intel.com>

 * 	Gordon Jin <gordon.jin@intel.com>

 * Copyright (C) 1999 VA Linux Systems

 * Copyright (C) 1999 Walt Drummond <drummond@valinux.com>

 *

 * 12/26/04 S.Siddha, G.Jin, R.Seth

 *			Add multi-threading and multi-core detection

 * 11/12/01 D.Mosberger Convert get_cpuinfo() to seq_file based show_cpuinfo().

 * 04/04/00 D.Mosberger renamed cpu_initialized to cpu_online_map

 * 03/31/00 R.Seth	cpu_initialized and current->processor fixes

 * 02/04/00 D.Mosberger	some more get_cpuinfo fixes...

 * 02/01/00 R.Seth	fixed get_cpuinfo for SMP

 * 01/07/99 S.Eranian	added the support for command line argument

 * 06/24/99 W.Drummond	added boot_cpu_data.

 * 05/28/05 Z. Menyhart	Dynamic stride size for "flush_icache_range()"

 virtual address for I/O accesses */

/*

 * "flush_icache_range()" needs to know what processor dependent stride size to use

 * when it makes i-cache(s) coherent with d-caches.

 Safest way to go: 32 bytes by 32 bytes */

/*

 * "clflush_cache_range()" needs to know what processor dependent stride size to

 * use when it flushes cache lines including both d-cache and i-cache.

 Safest way to go: 32 bytes by 32 bytes */

/*

 * We use a special marker for the end of memory and it uses the extra (+1) slot

/*

 * Filter incoming memory segments based on the primitive map created from the boot

 * parameters. Segments contained in the map are removed from the memory ranges. A

 * caller-specified function is called with the memory ranges that remain after filtering.

 * This routine does not assume the incoming segments are sorted.

	/*

	 * lowest possible address(walker uses virtual)

 nothing more available in this segment */

 end of memory marker allows full processing inside loop body */

/*

 * Similar to "filter_rsvd_memory()", but the reserved memory ranges

 * are not filtered out.

 simple bubble sorting */

 merge overlaps */

/*

 * Request address space for all standard resources

/*

 * This function checks if the reserved crashkernel is allowed on the specific

 * IA64 machine flavour. Machines without an IO TLB use swiotlb and require

 * some memory below 4 GB (i.e. in 32 bit area), see the implementation of

 * kernel/dma/swiotlb.c. The hpzx1 architecture has an IO TLB but cannot use that

 * in kdump case. See the comment in sba_init() in sba_iommu.c.

 *

 * So, the only machvec that really supports loading the kdump kernel

 * over 4 GB is "uv".

	/* We get the address using the kernel command line,

	 * but the size is extracted from the EFI tables.

	 * Both address and size are required for reservation

	 * to work properly.

 CONFIG_CRASH_DUMP */

/**

 * reserve_memory - setup reserved memory areas

 *

 * Setup the reserved memory areas set aside for the boot parameters,

 * initrd, etc.  There are currently %IA64_MAX_RSVD_REGIONS defined,

 * see arch/ia64/include/asm/meminit.h if you need to define more.

	/*

	 * none of the entries in this table overlap

 end of memory marker */

 reserve all regions except the end of memory marker with memblock */

/**

 * find_initrd - get initrd parameters from the boot parameter structure

 *

 * Grab the initrd start and end from the boot parameter struct given us by

 * the boot loader.

	/*

	 * Set `iobase' based on the EFI memory map or, failing that, the

	 * value firmware left in ar.k0.

	 *

	 * Note that in ia32 mode, IN/OUT instructions use ar.k0 to compute

	 * the port's virtual address, so ia32_load_state() loads it with a

	 * user virtual address.  But in ia64 mode, glibc uses the

	 * *physical* address in ar.k0 to mmap the appropriate area from

	 * /dev/mem, and the inX()/outX() interfaces use MMIO.  In both

	 * cases, user-mode can only use the legacy 0-64K I/O port space.

	 *

	 * ar.k0 is not involved in kernel I/O port accesses, which can use

	 * any of the I/O port spaces and are done via MMIO using the

	 * virtual mmio_base from the appropriate io_space[].

 setup legacy IO port space */

/**

 * early_console_setup - setup debugging console

 *

 * Consoles started here require little enough setup that we can start using

 * them very early in the boot process, either right after the machine

 * vector initialization, or even before if the drivers can detect their hw.

 *

 * Returns non-zero if a console couldn't be setup.

 XXX fake */

 XXX fake */

 XXX fake */

 If we register an early console, allow CPU 0 to printk */

 Initialize the ACPI boot-time table parser */

 CONFIG_ACPI_NUMA */

 process SAL system table: */

 initialize the bootstrap CPU */

 initialize context_id bitmap */

		/*

		 * Non-legacy systems may route legacy VGA MMIO range to system

		 * memory.  vga_con probes the MMIO hole, so memory looks like

		 * a VGA device to it.  The EFI memory map can tell us if it's

		 * memory so we can avoid this problem.

 enable IA-64 Machine Check Abort Handling unless disabled */

	/*

	 * Default to /dev/sda2.  This assumes that the EFI partition

	 * is physical disk 1 partition 1 and the Linux root disk is

	 * physical disk 1 partition 2.

 default to second partition on first drive */

/*

 * Display cpu info for all CPUs.

 build the feature string: */

 print unknown features as a hex value */

 id 0 & 1: */

 id 2 */

 processor serial number */

 id 3: */

 id 4: */

 Itanium defaults */

	/* below default values will be overwritten  by identify_siblings() 

	 * for Multi-Threading/Multi-Core capable CPUs

/*

 * Do the following calculations:

 *

 * 1. the max. cache line size.

 * 2. the minimum of the i-cache stride sizes for "flush_icache_range()".

 * 3. the minimum of the cache stride sizes for "clflush_cache_range()".

 Safest setup for "flush_icache_range()" */

 Safest setup for "clflush_cache_range()" */

 cache_type (data_or_unified)=2 */

 The safest setup for "flush_icache_range()" */

 The safest setup for "clflush_cache_range()" */

 cache_type (instruction)=1*/

 The safest setup for flush_icache_range() */

/*

 * cpu_init() initializes state that is per-CPU.  This function acts

 * as a 'CPU state barrier', nothing should get across.

	/*

	 * insert boot cpu into sibling and core mapes

	 * (must be done after per_cpu area is setup)

		/*

		 * Set ar.k3 so that assembly code in MCA handler can compute

		 * physical addresses of per cpu variables with a simple:

		 *   phys = ar.k3 + &per_cpu_var

		 * and the alt-dtlb-miss handler can set per-cpu mapping into

		 * the TLB when needed. head.S already did this for cpu0.

	/*

	 * We can't pass "local_cpu_data" to identify_cpu() because we haven't called

	 * ia64_mmu_init() yet.  And we can't call ia64_mmu_init() first because it

	 * depends on the data returned by identify_cpu().  We break the dependency by

	 * accessing cpu_data() through the canonical per-CPU address.

 Clear the stack memory reserved for pt_regs: */

	/*

	 * Initialize the page-table base register to a global

	 * directory with all zeroes.  This ensure that we can handle

	 * TLB-misses to user address-space even before we created the

	 * first user address-space.  This may happen, e.g., due to

	 * aggressive use of lfetch.fault.

	/*

	 * Initialize default control register to defer speculative faults except

	 * for those arising from TLB misses, which are not deferred.  The

	 * kernel MUST NOT depend on a particular setting of these bits (in other words,

	 * the kernel must have recovery code for all speculative accesses).  Turn on

	 * dcr.lc as per recommendation by the architecture team.  Most IA-32 apps

	 * shouldn't be affected by this (moral: keep your ia32 locks aligned and you'll

	 * be fine).

 Clear ITC to eliminate sched_clock() overflows in human time.  */

 disable all local interrupt sources: */

 clear TPR & XTP to enable all interrupt classes: */

 Clear any pending interrupts left by SAL/EFI */

 set ia64_ctx.max_rid to the maximum RID that is supported by all CPUs: */

 use architected minimum */

 size of physical stacked register partition plus 8 bytes: */

 SPDX-License-Identifier: GPL-2.0

/*

 * Extensible Firmware Interface

 *

 * Based on Extensible Firmware Interface Specification version 0.9

 * April 30, 1999

 *

 * Copyright (C) 1999 VA Linux Systems

 * Copyright (C) 1999 Walt Drummond <drummond@valinux.com>

 * Copyright (C) 1999-2003 Hewlett-Packard Co.

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *	Stephane Eranian <eranian@hpl.hp.com>

 * (c) Copyright 2006 Hewlett-Packard Development Company, L.P.

 *	Bjorn Helgaas <bjorn.helgaas@hp.com>

 *

 * All EFI Runtime Services are not implemented yet as EFI only

 * supports physical mode addressing on SoftSDV. This is to be fixed

 * in a future version.  --drummond 1999-07-20

 *

 * Implemented EFI runtime services and virtual mode calls.  --davidm

 *

 * Goutham Rao: <goutham.rao@intel.com>

 *	Skip non-WB memory and ignore empty memory ranges.

 should not return, but just in case... */			       \

/*

 * Walk the EFI memory map and call CALLBACK once for each EFI memory

 * descriptor that has memory that is available for OS use.

/*

 * Walk the EFI memory map and call CALLBACK once for each EFI memory

 * descriptor that has memory that is available for uncached allocator.

/*

 * Look for the PAL_CODE region reported by EFI and map it using an

 * ITR to enable safe PAL calls in virtual mode.  See IA-64 Processor

 * Abstraction Layer chapter 11 in ADAG

		/*

		 * The only ITLB entry in region 7 that is used is the one

		 * installed by __start().  That entry covers a 64MB range.

		/*

		 * We must check that the PAL mapping won't overlap with the

		 * kernel mapping.

		 *

		 * PAL code is guaranteed to be aligned on a power of 2 between

		 * 4k and 256KB and that only one ITR is needed to map it. This

		 * implies that the PAL code is always aligned on its size,

		 * i.e., the closest matching page size supported by the TLB.

		 * Therefore PAL code is guaranteed never to cross a 64MB unless

		 * it is bigger than 64MB (very unlikely!).  So for now the

		 * following test is enough to determine whether or not we need

		 * a dedicated ITR for the PAL code.

/*

 * Parse and handle PALO table which is published at:

 * http://www.dig64.org/home/DIG64_PALO_R1_0.pdf

	/*

	 * Cannot write to CRx with PSR.ic=1

 restore psr */

	/*

	 * It's too early to be able to use the standard kernel command line

	 * support...

	/*

	 * Verify the EFI Table

 print EFI memory map: */

			/*

			 * Some descriptors have multiple bits set, so the

			 * order of the tests is relevant.

	/*

	 * Now that EFI is in virtual mode, we call the EFI functions more

	 * efficiently:

/*

 * Walk the EFI memory map looking for the I/O port range.  There can only be

 * one entry of this type, other I/O port ranges should be described via ACPI.

	/*

	 * EFI_MEMORY_RUNTIME is not a memory attribute; it just tells

	 * the kernel that firmware needs this region mapped.

 never reached */

	/*

	 * This is a hack for ioremap calls before we set up kern_memmap.

	 * Maybe we should do efi_memmap_init() earlier instead.

 never reached */

	/*

	 * /dev/mem reads and writes use copy_to_user(), which implicitly

	 * uses a granule-sized kernel identity mapping.  It's really

	 * only safe to do this for regions in kern_memmap.  For more

	 * details, see Documentation/ia64/aliasing.rst.

	/*

	 * /dev/mem mmap uses normal user pages, so we don't need the entire

	 * granule, but the entire region we're mapping must support the same

	 * attribute.

	/*

	 * Intel firmware doesn't tell us about all the MMIO regions, so

	 * in general we have to allow mmap requests.  But if EFI *does*

	 * tell us about anything inside this region, we should deny it.

	 * The user can always map a smaller region to avoid the overlap.

	/*

	 * For /dev/mem mmap, we use user mappings, but if the region is

	 * in kern_memmap (and hence may be covered by a kernel mapping),

	 * we must use the same attribute as the kernel mapping.

	/*

	 * Some chipsets don't support UC access to memory.  If

	 * WB is supported, we prefer that.

 Convert to UTF-16 */

/*

 * Look for the first granule aligned memory descriptor memory

 * that is big enough to hold EFI memory map. Make sure this

 * descriptor is at least granule sized so it does not get trimmed

	/*

	 * Worst case: we need 3 kernel descriptors for each efi descriptor

	 * (if every entry has a WB part in the middle, and UC head and tail),

	 * plus one for the end marker.

 Round ends inward to granule boundaries */

 keep within max_addr= and min_addr= command line arg */

 avoid going over mem= command line arg */

/*

 * Walk the EFI memory map and gather all memory available for kernel

 * to use.  We can allocate partial granules only if the unavailable

 * parts exist, and are WB.

		/*

		 * Round ends inward to granule boundaries

		 * Give trimmings to uncached allocator

 keep within max_addr= and min_addr= command line arg */

 avoid going over mem= command line arg */

 end-marker */

 reserve the memory we are using for kern_memmap */

 should not happen */

			/*

			 * We don't know which region contains

			 * kernel data so we try it repeatedly and

			 * let the resource manager test it.

/* find a block of memory aligned to 64M exclude reserved regions

   rsvd_regions are sorted

 locate the size find a the descriptor at a certain address */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * palinfo.c

 *

 * Prints processor specific information reported by PAL.

 * This code is based on specification of PAL as of the

 * Intel IA-64 Architecture Software Developer's Manual v1.0.

 *

 *

 * Copyright (C) 2000-2001, 2003 Hewlett-Packard Co

 *	Stephane Eranian <eranian@hpl.hp.com>

 * Copyright (C) 2004 Intel Corporation

 *  Ashok Raj <ashok.raj@intel.com>

 *

 * 05/26/2000	S.Eranian	initial release

 * 08/21/2000	S.Eranian	updated to July 2000 PAL specs

 * 02/05/2001   S.Eranian	fixed module support

 * 10/23/2001	S.Eranian	updated pal_perf_mon_info bug fixes

 * 03/24/2004	Ashok Raj	updated to work with CPU Hotplug

 * 10/26/2006   Russ Anderson	updated processor features to rev 2.2 spec

 name of the proc entry */

 function to call for reading */

 registered entry (removal) */

/*

 *  A bunch of string array to get pretty printing

 not used */

 unified */

 reserved */

 reserved */

 000 */

 001 */

 010 */

 011 */

 100 */

 101 */

 110 */

 111 */

/*

 * Take a 64bit vector and produces a string such that

 * if bit n is set then 2^n in clear text is generated. The adjustment

 * to the right unit is also done.

 *

 * Input:

 *	- a pointer to a buffer to hold the string

 *	- a 64-bit vector

 * Ouput:

 *	- a pointer to the end of the buffer

 *

/*

 * Take a 64bit vector and produces a string such that

 * if bit n is set then register n is present. The function

 * takes into account consecutive registers and prints out ranges.

 *

 * Input:

 *	- a pointer to a buffer to hold the string

 *	- a 64-bit vector

 * Ouput:

 *	- a pointer to the end of the buffer

 *

 even without unification some level may not be present */

 when unified, data(j=2) is enough */

 just in case */

 even without unification, some levels may not be present */

 when unified date (j=2) is enough */

 Feature set 0 */

 Feature set 16 */

 No remaining bits set */

 Print only bits that are available */

/*

 * List {name,function} pairs for every entry in /proc/palinfo/cpu*

/*

 * This data structure is used to pass which cpu,function is being requested

 * It must fit in a 64bit quantity to be passed to the proc callback routine

 *

 * In SMP mode, when we get a request for another CPU, we must call that

 * other CPU using IPI and wait for the result before returning.

 for which CPU this info is */

 which function is requested */

/*

 * used to hold information about final function to call

 pointer to function to call */

 buffer to store results */

 return value from call */

/*

 * this function does the actual final call and he called

 * from the smp code, i.e., this is the palinfo callback routine

/*

 * function called to trigger the IPI, we need to access a remote CPU

 * Return:

 *	0 : error or nothing to output

 *	otherwise how many bytes in the "page" buffer were written

 just in case */

 will send IPI to other CPU and wait for completion of remote call */

 ! CONFIG_SMP */

 CONFIG_SMP */

/*

 * Entry point routine: all calls go through this function

	/*

	 * in SMP mode, we may need to call another CPU to get correct

	 * information. PAL, by definition, is processor specific

 cpu numbers are up to 4095 on itanic */

 cpu numbers are up to 4095 on itanic */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * linux/arch/ia64/kernel/time.c

 *

 * Copyright (C) 1998-2003 Hewlett-Packard Co

 *	Stephane Eranian <eranian@hpl.hp.com>

 *	David Mosberger <davidm@hpl.hp.com>

 * Copyright (C) 1999 Don Dugger <don.dugger@intel.com>

 * Copyright (C) 1999-2000 VA Linux Systems

 * Copyright (C) 1999-2000 Walt Drummond <drummond@valinux.com>

 smp_processor_id() of time-keeper */

/*

 * Called from the context switch with interrupts disabled, to charge all

 * accumulated times to the current process, and to prepare accounting on

 * the next process.

/*

 * Account time for a transition between system, hard irq or soft irq state.

 * Note that this function is called with interrupts enabled.

 CONFIG_VIRT_CPU_ACCOUNTING_NATIVE */

		/*

		 * Allow IPIs to interrupt the timer loop.

		/*

		 * If we're too close to the next clock tick for

		 * comfort, we increase the safety margin by

		 * intentionally dropping the next tick(s).  We do NOT

		 * update itm.next because that would force us to call

		 * xtime_update() which in turn would let our clock run

		 * too fast (with the potentially devastating effect

		 * of losing monotony of time).

 double check, in case we got hit by a (slow) PMI: */

/*

 * Encapsulate access to the itm structure for SMP.

 arrange for the cycle counter to generate a timer interrupt: */

	/*

	 * Stagger the timer tick for each CPU so they don't occur all at (almost) the

	 * same time:

	/*

	 * According to SAL v2.6, we need to use a SAL call to determine the platform base

	 * frequency and then a PAL call to determine the frequency ratio between the ITC

	 * and the base frequency.

 invent "random" values */

 no drift info */

 avoid division by zero */

 avoid division by zero */

		/* On IA64 in an SMP configuration ITCs are never accurately synchronized.

		 * Jitter compensation requires a cmpxchg which may limit

		 * the scalability of the syscalls for retrieving time.

		 * The ITC synchronization is usually successful to within a few

		 * ITC ticks but this is not a sure thing. If you need to improve

		 * timer performance in SMP situations then boot the kernel with the

		 * "nojitter" option. However, doing so may result in time fluctuating (maybe

		 * even going backward) if the ITC offsets between the individual CPUs

		 * are too large.

		/*

		 * ITC is drifty and we have not synchronized the ITCs in smpboot.c.

		 * ITC values may fluctuate significantly between processors.

		 * Clock should not be used for hrtimers. Mark itc as only

		 * useful for boot and testing.

		 *

		 * Note that jitter compensation is off! There is no point of

		 * synchronizing ITCs since they may be large differentials

		 * that change over time.

		 *

		 * The only way to fix this would be to repeatedly sync the

		 * ITCs. Until that time we have to avoid ITC.

 avoid softlock up message when cpu is unplug and plugged again. */

 Setup the CPU local timer tick */

	/*

	 * Keep track of the last timer value returned.

	 * In an SMP environment, you could lose out in contention of

	 * cmpxchg. If so, your cmpxchg returns new value which the

	 * winner of contention updated to. Use the new value instead.

/*

 * Generic udelay assumes that if preemption is allowed and the thread

 * migrates to another CPU, that the ITC values are synchronized across

 * all CPUs.

 IA64 doesn't cache the timezone */

 copy vsyscall data */

 normalize */

 SPDX-License-Identifier: GPL-2.0

/*

 * linux/arch/ia64/kernel/irq_ia64.c

 *

 * Copyright (C) 1998-2001 Hewlett-Packard Co

 *	Stephane Eranian <eranian@hpl.hp.com>

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *

 *  6/10/99: Updated to bring in sync with x86 version to facilitate

 *	     support for SMP and different interrupt controllers.

 *

 * 09/15/00 Goutham Rao <goutham.rao@intel.com> Implemented pci_irq_to_vector

 *                      PCI to vector allocation routine.

 * 04/14/2004 Ashok Raj <ashok.raj@intel.com>

 *						Added CPU Hotplug handling for IPF.

 default base addr of IPI table */

/*

 * Legacy IRQ to IA-64 vector translation table.

 8259 IRQ translation, first 16 entries */

/*

 * Initialize vector_irq on a new cpu. This function must be called

 * with vector_lock held.

 Clear vector_irq */

 Mark the inuse vectors */

/*

 * Dynamic irq allocate and deallocation for MSI

/*

 * That's where the IVT branches when we get an external

 * interrupt. This branches to the correct hardware IRQ handler via

 * function ptr.

		/*

		 * Note: if the interrupt happened while executing in

		 * the context switch routine (ia64_switch_to), we may

		 * get a spurious stack overflow here.  This is

		 * because the register and the memory stack are not

		 * switched atomically.

 IRQ_DEBUG */

	/*

	 * Always set TPR to limit maximum interrupt nesting depth to

	 * 16 (without this, it would be ~240, which could easily lead

	 * to kernel stack overflows).

			/*

			 * Disable interrupts and send EOI:

	/*

	 * This must be done *after* the ia64_eoi().  For example, the keyboard softirq

	 * handler needs to be able to wait for further keyboard interrupts, which can't

	 * come through until ia64_eoi() has been done.

/*

 * This function emulates a interrupt processing when a cpu is about to be

 * brought down.

	 /*

	  * Perform normal interrupt style processing

			/*

			 * Now try calling normal ia64_handle_irq as it would have got called

			 * from a real intr handler. Try passing null for pt_regs, hopefully

			 * it will work. I hope it works!.

			 * Probably could shared code.

			/*

			 * Disable interrupts and send EOI

/*

 * KVM uses this interrupt to force a cpu out of guest mode

	/*

	 * cpu number is in 8bit ID and 8bit EID

 SPDX-License-Identifier: GPL-2.0-only

/*

 * salinfo.c

 *

 * Creates entries in /proc/sal for various system features.

 *

 * Copyright (c) 2003, 2006 Silicon Graphics, Inc.  All rights reserved.

 * Copyright (c) 2003 Hewlett-Packard Co

 *	Bjorn Helgaas <bjorn.helgaas@hp.com>

 *

 * 10/30/2001	jbarnes@sgi.com		copied much of Stephane's palinfo

 *					code to create this file

 * Oct 23 2003	kaos@sgi.com

 *   Replace IPI with set_cpus_allowed() to read a record from the required cpu.

 *   Redesign salinfo log processing to separate interrupt and user space

 *   contexts.

 *   Cache the record across multi-block reads from user space.

 *   Support > 64 cpus.

 *   Delete module_exit and MOD_INC/DEC_COUNT, salinfo cannot be a module.

 *

 * Jan 28 2004	kaos@sgi.com

 *   Periodically check for outstanding MCA or INIT records.

 *

 * Dec  5 2004	kaos@sgi.com

 *   Standardize which records are cleared automatically.

 *

 * Aug 18 2005	kaos@sgi.com

 *   mca.c may not pass a buffer, a NULL buffer just indicates that a new

 *   record is available in SAL.

 *   Replace some NR_CPUS by cpus_online, for hotplug cpu.

 *

 * Jan  5 2006        kaos@sgi.com

 *   Handle hotplug cpus coming online.

 *   Handle hotplug cpus going offline while they still have outstanding records.

 *   Use the cpu_* macros consistently.

 *   Replace the counting semaphore with a mutex and a test if the cpumask is non-empty.

 *   Modify the locking to make the test for "work to do" an atomic operation.

 name of the proc entry */

 feature bit */

 registered entry (removal) */

/*

 * List {name,feature} pairs for every entry in /proc/sal/<feature>

 * that this module exports

 /proc/sal/bus_lock */

 /proc/sal/{mca,...} */

 /proc/sal/mca/{event,data} */

 /proc/sal */

/* Some records we get ourselves, some are accessed as saved data in buffers

 * that are owned by mca.c.

/* State transitions.  Actions are :-

 *   Write "read <cpunum>" to the data file.

 *   Write "clear <cpunum>" to the data file.

 *   Write "oemdata <cpunum> <offset> to the data file.

 *   Read from the data file.

 *   Close the data file.

 *

 * Start state is NO_DATA.

 *

 * NO_DATA

 *    write "read <cpunum>" -> NO_DATA or LOG_RECORD.

 *    write "clear <cpunum>" -> NO_DATA or LOG_RECORD.

 *    write "oemdata <cpunum> <offset> -> return -EINVAL.

 *    read data -> return EOF.

 *    close -> unchanged.  Free record areas.

 *

 * LOG_RECORD

 *    write "read <cpunum>" -> NO_DATA or LOG_RECORD.

 *    write "clear <cpunum>" -> NO_DATA or LOG_RECORD.

 *    write "oemdata <cpunum> <offset> -> format the oem data, goto OEMDATA.

 *    read data -> return the INIT/MCA/CMC/CPE record.

 *    close -> unchanged.  Keep record areas.

 *

 * OEMDATA

 *    write "read <cpunum>" -> NO_DATA or LOG_RECORD.

 *    write "clear <cpunum>" -> NO_DATA or LOG_RECORD.

 *    write "oemdata <cpunum> <offset> -> format the oem data, goto OEMDATA.

 *    read data -> return the formatted oemdata.

 *    close -> unchanged.  Keep record areas.

 *

 * Closing the data file does not change the state.  This allows shell scripts

 * to manipulate salinfo data, each shell redirection opens the file, does one

 * action then closes it again.  The record areas are only freed at close when

 * the state is NO_DATA.

 which cpus have outstanding events */

 decoded oem data */

 single-open to prevent races */

 using a saved record? */

 processing state */

 next CPU to check */

 save last 5 records from mca.c, must be < 255 */

/** salinfo_platform_oemdata - optional callback to decode oemdata from an error

 * record.

 * @sect_header: pointer to the start of the section to decode.

 * @oemdata: returns vmalloc area containing the decoded output.

 * @oemdata_size: returns length of decoded output (strlen).

 *

 * Description: If user space asks for oem data to be decoded by the kernel

 * and/or prom and the platform has set salinfo_platform_oemdata to the address

 * of a platform specific routine then call that routine.  salinfo_platform_oemdata

 * vmalloc's and formats its output area, returning the address of the text

 * and its strlen.  Returns 0 for success, -ve for error.  The callback is

 * invoked on the cpu that generated the error record.

/* This routine is invoked in interrupt context.  Note: mca.c enables

 * interrupts before calling this code for CMC/CPE.  MCA and INIT events are

 * not irq safe, do not call any routines that use spinlocks, they may deadlock.

 * MCA and INIT records are recorded, a timer event will look for any

 * outstanding events and wake up the user space code.

 *

 * The buffer passed from mca.c points to the output from ia64_log_get. This is

 * a persistent buffer but its contents can change between the interrupt and

 * when user space processes the record.  Save the record id to identify

 * changes.  If the buffer is NULL then just update the bitmap.

 Check for outstanding MCA/INIT records every minute (arbitrary) */

 for next read, start checking at next CPU */

 Clear corrected errors as they are read from SAL */

 id check must not be moved */

 saved record changed by mca.c since interrupt, discard it */

 Corrected errors have already been cleared from SAL */

 clearing a record may make a new record visible */

/*

 * 'data' contains an integer that corresponds to the feature we're

 * testing

 /proc/sal dir entry */

 keeps track of every entry */

 pass the feature bit in question as misc data */

 SPDX-License-Identifier: GPL-2.0

/*

 * LSAPIC Interrupt Controller

 *

 * This takes care of interrupts that are generated by the CPU's

 * internal Streamlined Advanced Programmable Interrupt Controller

 * (LSAPIC), such as the ITC and IPI interrupts.

    *

 * Copyright (C) 1999 VA Linux Systems

 * Copyright (C) 1999 Walt Drummond <drummond@valinux.com>

 * Copyright (C) 2000 Hewlett-Packard Co

 * Copyright (C) 2000 David Mosberger-Tang <davidm@hpl.hp.com>

 nothing to do... */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arch/ia64/kernel/machine_kexec.c

 *

 * Handle transition of Linux booting another kernel

 * Copyright (C) 2005 Hewlett-Packard Development Comapny, L.P.

 * Copyright (C) 2005 Khalid Aziz <khalid.aziz@hp.com>

 * Copyright (C) 2006 Intel Corp, Zou Nan hai <nanhai.zou@intel.com>

/*

 * Do what every setup is needed on image and the

 * reboot code buffer to allow us to avoid allocations

 * later.

 Pre-load control code buffer to minimize work in kexec path */

/*

 * Do not allocate memory (or fail in any way) in machine_kexec().

 * We are past the point of no return, committed to rebooting now.

 Register noop init handler */

 Unregister init handlers of current kernel */

 Unregister mca handler - No more recovery on current kernel */

 Interrupts aren't acceptable while we reboot */

 Mask CMC and Performance Monitor interrupts */

 Mask ITV and Local Redirect Registers */

 terminate possible nested in-service interrupts */

 unmask TPR and clear any pending interrupts */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * (c) Copyright 2003, 2006 Hewlett-Packard Development Company, L.P.

 *	Alex Williamson <alex.williamson@hp.com>

 *	Bjorn Helgaas <bjorn.helgaas@hp.com>

/*

 * Device CSRs that do not appear in PCI config space should be described

 * via ACPI.  This would normally be done with Address Space Descriptors

 * marked as "consumer-only," but old versions of Windows and Linux ignore

 * the producer/consumer flag, so HP invented a vendor-defined resource to

 * describe the location and size of CSR space.

 keep looking */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File:	mca_drv.c

 * Purpose:	Generic MCA handling layer

 *

 * Copyright (C) 2004 FUJITSU LIMITED

 * Copyright (C) 2004 Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>

 * Copyright (C) 2005 Silicon Graphics, Inc

 * Copyright (C) 2005 Keith Owens <kaos@sgi.com>

 * Copyright (C) 2006 Russ Anderson <rja@sgi.com>

 max size of SAL error record (default) */

 from mca_drv_asm.S */

/*

 *  This pool keeps pointers to the section part of SAL error record

 section pointer list pool */

 Current index of section pointer list pool */

 Maximum index of section pointer list pool */

/**

 * mca_page_isolate - isolate a poisoned page in order not to use it later

 * @paddr:	poisoned memory location

 *

 * Return value:

 *	one of isolate_status_t, ISOLATE_OK/NG/NONE.

 whether physical address is valid or not */

 convert physical address to physical page number */

 check whether a page number have been already registered or not */

 already listed */

 limitation check */

 kick pages having attribute 'SLAB' or 'Reserved' */

 add attribute 'Reserved' and register the page */

/**

 * mca_hanlder_bh - Kill the process which occurred memory read error

 * @paddr:	poisoned address received from MCA Handler

 This process is about to be killed itself */

/**

 * mca_make_peidx - Make index of processor error section

 * @slpi:	pointer to record of processor error section

 * @peidx:	pointer to index of processor error section

	/*

	 * calculate the start address of

	 *   "struct cpuid_info" and "sal_processor_static_info_t".

/**

 * mca_make_slidx -  Make index of SAL error record

 * @buffer:	pointer to SAL error record

 * @slidx:	pointer to index of SAL error record

 *

 * Return value:

 *	1 if record has platform error / 0 if not

	/*

	 * Initialize index referring current record

	/*

	 * Extract a Record Header

	/*

	 * Extract each section records

	 * (arranged from "int ia64_log_platform_info_print()")

/**

 * init_record_index_pools - Initialize pool of lists for SAL record index

 *

 * Return value:

 *	0 on Success / -ENOMEM on Failure

 Maximum size of SAL error records */

 Minimum size of SAL error sections */

 minimum size table of each section */

	/*

	 * MCA handler cannot allocate new memory on flight,

	 * so we preallocate enough memory to handle a SAL record.

	 *

	 * Initialize a handling set of slidx_pool:

	 *   1. Pick up the max size of SAL error records

	 *   2. Pick up the min size of SAL error sections

	 *   3. Allocate the pool as enough to 2 SAL records

	 *     (now we can estimate the maxinum of section in a record.)

 - 1 - */

 - 2 - */

 - 3 - */

/*****************************************************************************

 * Recovery functions                                                        *

/**

 * is_mca_global - Check whether this MCA is global or not

 * @peidx:	pointer of index of processor error section

 * @pbci:	pointer to pal_bus_check_info_t

 * @sos:	pointer to hand off struct between SAL and OS

 *

 * Return value:

 *	MCA_IS_LOCAL / MCA_IS_GLOBAL

	/*

	 * PAL can request a rendezvous, if the MCA has a global scope.

	 * If "rz_always" flag is set, SAL requests MCA rendezvous

	 * in spite of global MCA.

	 * Therefore it is local MCA when rendezvous has not been requested.

	 * Failed to rendezvous, the system must be down.

 SAL rendezvous unsuccessful */

 SAL rendezvous not required */

 SAL rendezvous successful int */

 SAL rendezvous successful int with init */

	/*

	 * If One or more Cache/TLB/Reg_File/Uarch_Check is here,

	 * it would be a local MCA. (i.e. processor internal error)

	/*

	 * Bus_Check structure with Bus_Check.ib (internal bus error) flag set

	 * would be a global MCA. (e.g. a system bus address parity error)

	/*

	 * Bus_Check structure with Bus_Check.eb (external bus error) flag set

	 * could be either a local MCA or a global MCA.

	 *

	 * Referring Bus_Check.bsi:

	 *   0: Unknown/unclassified

	 *   1: BERR#

	 *   2: BINIT#

	 *   3: Hard Fail

	 * (FIXME: Are these SGI specific or generic bsi values?)

 e.g. a load from poisoned memory */

/**

 * get_target_identifier - Get the valid Cache or Bus check target identifier.

 * @peidx:	pointer of index of processor error section

 *

 * Return value:

 *	target address on Success / 0 on Failure

	/*

	 * Look through the cache checks for a valid target identifier

	 * If more than one valid target identifier, return the one

	 * with the lowest cache level.

	/*

	 * Look at the bus check for a valid target identifier

/**

 * recover_from_read_error - Try to recover the errors which type are "read"s.

 * @slidx:	pointer of index of SAL error record

 * @peidx:	pointer of index of processor error section

 * @pbci:	pointer of pal_bus_check_info

 * @sos:	pointer to hand off struct between SAL and OS

 *

 * Return value:

 *	1 on Success / 0 on Failure

 Is target address valid? */

	/*

	 * cpu read or memory-mapped io read

	 *

	 *    offending process  affected process  OS MCA do

	 *     kernel mode        kernel mode       down system

	 *     kernel mode        user   mode       kill the process

	 *     user   mode        kernel mode       down system (*)

	 *     user   mode        user   mode       kill the process

	 *

	 * (*) You could terminate offending user-mode process

	 *    if (pbci->pv && pbci->pl != 0) *and* if you sure

	 *    the process not have any locks of kernel.

 Is minstate valid? */

	/*

	 *  Check the privilege level of interrupted context.

	 *   If it is user-mode, then terminate affected process.

		/*

		 *  setup for resume to bottom half of MCA,

		 * "mca_handler_bhhook"

 pass to bhhook as argument (gr8, ...) */

 set interrupted return address (but no use) */

 change resume address to bottom half */

 set cpl with kernel mode */

/**

 * recover_from_platform_error - Recover from platform error.

 * @slidx:	pointer of index of SAL error record

 * @peidx:	pointer of index of processor error section

 * @pbci:	pointer of pal_bus_check_info

 * @sos:	pointer to hand off struct between SAL and OS

 *

 * Return value:

 *	1 on Success / 0 on Failure

 partial read */

 full line(cpu) read */

 I/O space read */

 unknown */

 partial write */

 full line write */

 implicit or explicit write-back operation */

 snoop probe */

 incoming or outgoing ptc.g */

 write coalescing transactions */

 I/O space write */

 inter-processor interrupt message(IPI) */

		case 12: /* interrupt acknowledge or

 Cache error */

/*

 * recover_from_tlb_check

 * @peidx:	pointer of index of processor error section

 *

 * Return value:

 *	1 on Success / 0 on Failure

	/*

	 * Look for signature of a duplicate TLB DTC entry, which is

	 * a SW bug and always fatal.

/**

 * recover_from_processor_error

 * @platform:	whether there are some platform error section or not

 * @slidx:	pointer of index of SAL error record

 * @peidx:	pointer of index of processor error section

 * @pbci:	pointer of pal_bus_check_info

 * @sos:	pointer to hand off struct between SAL and OS

 *

 * Return value:

 *	1 on Success / 0 on Failure

	/*

	 * Processor recovery status must key off of the PAL recovery

	 * status in the Processor State Parameter.

	/*

	 * The machine check is corrected.

	/*

	 * The error was not contained.  Software must be reset.

	/*

	 * Look for recoverable TLB check

	/*

	 * The cache check and bus check bits have four possible states

	 *   cc bc

	 *    1  1	Memory error, attempt recovery

	 *    1  0	Cache error, attempt recovery

	 *    0  1	I/O error, attempt recovery

	 *    0  0	Other error type, not recovered

	/*

	 * Cannot handle more than one bus check.

	/*

	 * This is a local MCA and estimated as a recoverable error.

	/*

	 * On account of strange SAL error record, we cannot recover.

/**

 * mca_try_to_recover - Try to recover from MCA

 * @rec:	pointer to a SAL error record

 * @sos:	pointer to hand off struct between SAL and OS

 *

 * Return value:

 *	1 on Success / 0 on Failure

 Make index of SAL error record */

 Count processor error sections */

 Now, OS can recover when there is one processor error section */

 Weird SAL record ... We can't do anything */

 Make index of processor error section */

 Extract Processor BUS_CHECK[0] */

 Check whether MCA is global or not */

 Try to recover a processor error */

/*

 * =============================================================================

 register external mca handlers */

 unregister external mca handlers */

/*

 * This file is subject to the terms and conditions of the GNU General Public

 * License.  See the file "COPYING" in the main directory of this archive

 * for more details.

 *

 * This file contains NUMA specific variables and functions which are used on

 * NUMA machines with contiguous memory.

 * 		2002/08/07 Erich Focht <efocht@ess.nec.de>

 * Populate cpu entries in sysfs for non-numa systems as well

 *  	Intel Corporation - Ashok Raj

 * 02/27/2006 Zhang, Yanmin

 *	Populate cpu cache entries in sysfs for cpu cache info

	/*

	 * If CPEI can be re-targeted or if this is not

	 * CPEI target, then it is hotpluggable

CONFIG_HOTPLUG_CPU*/

	/*

	 * MCD - Do we want to register all ONLINE nodes, or all POSSIBLE nodes?

/*

 * Export cpu cache information through sysfs

/*

 *  A bunch of string array to get pretty printing

 not used */

 unified */

 reserved */

 reserved */

 Add cache interface for CPU device */

 Remove cache interface for CPU device */

 SPDX-License-Identifier: GPL-2.0

 match other core phdrs */

/*

 * Dynamic function tracing support.

 *

 * Copyright (C) 2008 Shaohua Li <shaohua.li@intel.com>

 *

 * For licencing details, see COPYING.

 *

 * Defines low-level handling of mcount calls when the kernel

 * is compiled with the -pg flag. When using dynamic ftrace, the

 * mcount call-sites get patched lazily with NOP till they are

 * enabled. All code mutation routines here take effect atomically.

 In IA64, each function will be added below two bundles with -pg option */

 alloc r40=ar.pfs,12,8,0 */

 mov r43=r0;; */

 mov r42=b0 */

 mov r41=r1 */

 nop.i 0x0 */

 br.call.sptk.many b0 = _mcount;; */

 mcount stub will be converted below for nop */

 [MII] nop.m 0x0 */

 mov r3=ip */

 nop.i 0x0 */

 [MLX] nop.m 0x0 */

 nop.x 0x0;; */

/*

 * mcount stub will be converted below for call

 * Note: Just the last instruction is changed against nop

 [MII] nop.m 0x0 */

 mov r3=ip */

 nop.i 0x0 */

 [MLX] nop.m 0x0 */

 brl.many .;;*/

	/*

	 * Note:

	 * We are paranoid about modifying text, as if a bug was to happen, it

	 * could cause us to read or write to someplace that could cause harm.

	 * Carefully read and modify the code with probe_kernel_*(), and make

	 * sure what we read is what we expected it to be before modifying it.

 read the text we want to modify */

 Make sure it is what we expect it to be */

 replace the text with the new text */

 in IA64, _mcount can't directly call ftrace_stub. Only jump is ok */

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0

/*

 * MSI hooks for standard x86 apic

 CONFIG_SMP */

/*

 * Generic ops used on most IA64 platforms.

 CONFIG_SMP */

 CONFIG_INTEL_IOMMU */

 SPDX-License-Identifier: GPL-2.0

/*

 * Dynamic DMA mapping support.

 Must execute after PCI subsystem */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2001-2008 Silicon Graphics, Inc.  All rights reserved.

 *

 * A simple uncached page allocator using the generic allocator. This

 * allocator first utilizes the spare (spill) pages found in the EFI

 * memmap and will then start converting cached pages to uncached ones

 * at a granule at a time. Node awareness is implemented by having a

 * pool of pages per node.

 serialize adding a converted chunk */

 #of converted chunks added to pool */

 smp called function's return status*/

/*

 * Add a new chunk of uncached memory pages to the specified pool.

 *

 * @pool: pool to add new chunk of uncached memory to

 * @nid: node id of node to allocate memory from, or -1

 *

 * This is accomplished by first allocating a granule of cached memory pages

 * and then converting them to uncached memory pages.

 interrupted by a signal */

 someone added a new chunk while we were waiting */

 attempt to allocate a granule's worth of cached memory pages */

 convert the memory pages from cached to uncached */

	/*

	 * There's a small race here where it's possible for someone to

	 * access the page through /dev/mem halfway through the conversion

	 * to uncached - not sure it's really worth bothering about

 flush the just introduced uncached translation from the TLB */

	/*

	 * The chunk of memory pages has been converted to uncached so now we

	 * can add it to the pool.

 failed to convert or add the chunk so give it back to the kernel */

/*

 * uncached_alloc_page

 *

 * @starting_nid: node id of node to start with, or -1

 * @n_pages: number of contiguous pages to allocate

 *

 * Allocate the specified number of contiguous uncached pages on the

 * the requested node. If not enough contiguous uncached pages are available

 * on the requested node, roundrobin starting with the next higher node.

/*

 * uncached_free_page

 *

 * @uc_addr: uncached address of first page to free

 * @n_pages: number of contiguous pages to free

 *

 * Free the specified number of uncached pages.

/*

 * uncached_build_memmap,

 *

 * @uc_start: uncached starting address of a chunk of uncached memory

 * @uc_end: uncached ending address of a chunk of uncached memory

 * @arg: ignored, (NULL argument passed in on call to efi_memmap_walk_uc())

 *

 * Called at boot time to build a map of pages that can be used for

 * memory special operations.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *

 * ia64 kernel NUMA specific stuff

 *

 * Copyright (C) 2002 Erich Focht <efocht@ess.nec.de>

 * Copyright (C) 2004 Silicon Graphics, Inc.

 *   Jesse Barnes <jbarnes@sgi.com>

 just initialize by zero */

 sanity check first */

 nothing to do */

	/* we don't have cpu-driven node hot add yet...

/**

 * build_cpu_to_node_map - setup cpu to node and node to cpumask arrays

 *

 * Build cpu to node mapping and initialize the per node cpu masks using

 * info from the node_cpuid array handed to us by ACPI.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * File:	mca.c

 * Purpose:	Generic MCA handling layer

 *

 * Copyright (C) 2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * Copyright (C) 2002 Dell Inc.

 * Copyright (C) Matt Domsch <Matt_Domsch@dell.com>

 *

 * Copyright (C) 2002 Intel

 * Copyright (C) Jenna Hall <jenna.s.hall@intel.com>

 *

 * Copyright (C) 2001 Intel

 * Copyright (C) Fred Lewis <frederick.v.lewis@intel.com>

 *

 * Copyright (C) 2000 Intel

 * Copyright (C) Chuck Fleckenstein <cfleck@co.intel.com>

 *

 * Copyright (C) 1999, 2004-2008 Silicon Graphics, Inc.

 * Copyright (C) Vijay Chander <vijay@engr.sgi.com>

 *

 * Copyright (C) 2006 FUJITSU LIMITED

 * Copyright (C) Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>

 *

 * 2000-03-29 Chuck Fleckenstein <cfleck@co.intel.com>

 *	      Fixed PAL/SAL update issues, began MCA bug fixes, logging issues,

 *	      added min save state dump, added INIT handler.

 *

 * 2001-01-03 Fred Lewis <frederick.v.lewis@intel.com>

 *	      Added setup of CMCI and CPEI IRQs, logging of corrected platform

 *	      errors, completed code for logging of corrected & uncorrected

 *	      machine check errors, and updated for conformance with Nov. 2000

 *	      revision of the SAL 3.0 spec.

 *

 * 2002-01-04 Jenna Hall <jenna.s.hall@intel.com>

 *	      Aligned MCA stack to 16 bytes, added platform vs. CPU error flag,

 *	      set SAL default return values, changed error record structure to

 *	      linked list, added init call to sal_get_state_info_size().

 *

 * 2002-03-25 Matt Domsch <Matt_Domsch@dell.com>

 *	      GUID cleanups.

 *

 * 2003-04-15 David Mosberger-Tang <davidm@hpl.hp.com>

 *	      Added INIT backtrace support.

 *

 * 2003-12-08 Keith Owens <kaos@sgi.com>

 *	      smp_call_function() must not be called from interrupt context

 *	      (can deadlock on tasklist_lock).

 *	      Use keventd to call smp_call_function().

 *

 * 2004-02-01 Keith Owens <kaos@sgi.com>

 *	      Avoid deadlock when using printk() for MCA and INIT records.

 *	      Delete all record printing code, moved to salinfo_decode in user

 *	      space.  Mark variables and functions static where possible.

 *	      Delete dead variables and functions.  Reorder to remove the need

 *	      for forward declarations and to consolidate related code.

 *

 * 2005-08-12 Keith Owens <kaos@sgi.com>

 *	      Convert MCA/INIT handlers to use per event stacks and SAL/OS

 *	      state.

 *

 * 2005-10-07 Keith Owens <kaos@sgi.com>

 *	      Add notify_die() hooks.

 *

 * 2006-09-15 Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>

 *	      Add printing support for MCA/INIT.

 *

 * 2007-04-27 Russ Anderson <rja@sgi.com>

 *	      Support multiple cpus going through OS_MCA in the same event.

 Used by mca_asm.S */

 == __per_cpu_mca[smp_processor_id()] */

 PTE to map per-CPU area */

 PTE to map PAL code */

 vaddr PAL code granule */

 Flag for TR reload */

 In mca_asm.S */

 15 minutes */

 2 minutes */

 1 minute */

/*

 * This variable tells whether we are currently in polling mode.

 * Start with this in the wrong state so we won't play w/ timers

 * before the system is ready.

/*

 * Clearing this variable prevents CPE polling from getting activated

 * in mca_late_init.  Use it if your system doesn't provide a CPEI,

 * but encounters problems retrieving CPE logs.  This should only be

 * necessary for debugging.

/*

 * limited & delayed printing support for MCA/INIT handler

 mca context only */

 normal context only */

/*

 * Push messages into buffer, print them later if not urgent.

 Copy the output into mlogbuf */

 mlogbuf was abandoned, use printk directly instead. */

 buffer full */

/*

 * Print buffered messages.

 *  NOTE: call this after returning normal context. (ex. from salinfod)

 Get output from mlogbuf */

/*

 * Call this if system is going to down or if immediate flushing messages to

 * console is required. (ex. recovery was failed, crash dump is going to be

 * invoked, long-wait rendezvous etc.)

 *  NOTE: this should be called from monarch.

 wait for console */

/*

 * Print buffered messages from INIT context.

/*

 * IA64_MCA log support

 Double-buffering for nested MCAs */

 MCA, INIT, CMC, CPE */

 need space to store header + error log */

/*

 * ia64_log_init

 *	Reset the OS ia64 log buffer

 * Inputs   :   info_type   (SAL_INFO_TYPE_{MCA,INIT,CMC,CPE})

 * Outputs	:	None

 SAL will tell us the maximum size of any error record of this type

 alloc_bootmem() doesn't like zero-sized allocations! */

 set up OS data structures to hold error info

/*

 * ia64_log_get

 *

 *	Get the current MCA log from SAL and copy it into the OS log buffer.

 *

 *  Inputs  :   info_type   (SAL_INFO_TYPE_{MCA,INIT,CMC,CPE})

 *              irq_safe    whether you can use printk at this point

 *  Outputs :   size        (total record length)

 *              *buffer     (ptr to error record)

 *

 Get the process state information */

/*

 *  ia64_mca_log_sal_error_record

 *

 *  This function retrieves a specified error record type from SAL

 *  and wakes up any processes waiting for error records.

 *

 *  Inputs  :   sal_info_type   (Type of error record MCA/CMC/CPE)

 *              FIXME: remove MCA and irq_safe.

 Clear logs from corrected errors in case there's no user-level logger */

/*

 * search_mca_table

 *  See if the MCA surfaced in an instruction range

 *  that has been tagged as recoverable.

 *

 *  Inputs

 *	first	First address range to check

 *	last	Last address range to check

 *	ip	Instruction pointer, address we are looking for

 *

 * Return value:

 *      1 on Success (in the table)/ 0 on Failure (not in the  table)

 Given an address, look for it in the mca tables. */

 SAL spec states this should run w/ interrupts enabled */

 we know 1 happened now */

			/*

			 * Corrected errors will still be corrected, but

			 * make sure there's a log somewhere that indicates

			 * something is generating more than we can handle.

 lock already released, get out now */

 Get the CPE error record and log it */

/*

 * ia64_mca_register_cpev

 *

 *  Register the corrected platform error vector with SAL.

 *

 *  Inputs

 *      cpev        Corrected Platform Error Vector number

 *

 *  Outputs

 *      None

 Register the CPE interrupt vector with SAL */

/*

 * ia64_mca_cmc_vector_setup

 *

 *  Setup the corrected machine check vector register in the processor.

 *  (The interrupt is masked on boot. ia64_mca_late_init unmask this.)

 *  This function is invoked on a per-processor basis.

 *

 * Inputs

 *      None

 *

 * Outputs

 *	None

 Mask/disable interrupt at first */

/*

 * ia64_mca_cmc_vector_disable

 *

 *  Mask the corrected machine check vector register in the processor.

 *  This function is invoked on a per-processor basis.

 *

 * Inputs

 *      dummy(unused)

 *

 * Outputs

 *	None

 Mask/disable interrupt */

/*

 * ia64_mca_cmc_vector_enable

 *

 *  Unmask the corrected machine check vector register in the processor.

 *  This function is invoked on a per-processor basis.

 *

 * Inputs

 *      dummy(unused)

 *

 * Outputs

 *	None

 Unmask/enable interrupt */

/*

 * ia64_mca_cmc_vector_disable_keventd

 *

 * Called via keventd (smp_call_function() is not safe in interrupt context) to

 * disable the cmc interrupt vector.

/*

 * ia64_mca_cmc_vector_enable_keventd

 *

 * Called via keventd (smp_call_function() is not safe in interrupt context) to

 * enable the cmc interrupt vector.

/*

 * ia64_mca_wakeup

 *

 *	Send an inter-cpu interrupt to wake-up a particular cpu.

 *

 *  Inputs  :   cpuid

 *  Outputs :   None

/*

 * ia64_mca_wakeup_all

 *

 *	Wakeup all the slave cpus which have rendez'ed previously.

 *

 *  Inputs  :   None

 *  Outputs :   None

 Clear the Rendez checkin flag for all cpus */

/*

 * ia64_mca_rendez_interrupt_handler

 *

 *	This is handler used to put slave processors into spinloop

 *	while the monarch processor does the mca handling and later

 *	wake each slave up once the monarch is done.  The state

 *	IA64_MCA_RENDEZ_CHECKIN_DONE indicates the cpu is rendez'ed

 *	in SAL.  The state IA64_MCA_RENDEZ_CHECKIN_NOTDONE indicates

 *	the cpu has come out of OS rendezvous.

 *

 *  Inputs  :   None

 *  Outputs :   None

 Mask all interrupts */

	/* Register with the SAL monarch that the slave has

	 * reached SAL

 Wait for the monarch cpu to exit. */

 spin until monarch leaves */

 Enable all interrupts */

/*

 * ia64_mca_wakeup_int_handler

 *

 *	The interrupt handler for processing the inter-cpu interrupt to the

 *	slave cpu which was spinning in the rendez loop.

 *	Since this spinning is done by turning off the interrupts and

 *	polling on the wakeup-interrupt bit in the IRR, there is

 *	nothing useful to be done in the handler.

 *

 *  Inputs  :   wakeup_irq  (Wakeup-interrupt bit)

 *	arg		(Interrupt handler specific argument)

 *  Outputs :   None

 *

 Function pointer for extra MCA recovery */

/* Change the comm field on the MCA/INT task to include the pid that

 * was interrupted, it makes for easier debugging.  If that pid was 0

 * (swapper or nested MCA/INIT) then use the start of the previous comm

 * field suffixed with its cpu.

	/* If ipsr.ic then use pmsa_{iip,ipsr,ifs}, else use

	 * pmsa_{xip,xpsr,xfs}

/* On entry to this routine, we are running on the per cpu stack, see

 * mca_asm.h.  The original stack has not been touched by this event.  Some of

 * the original stack's registers will be in the RBS on this stack.  This stack

 * also contains a partial pt_regs and switch_stack, the rest of the data is in

 * PAL minstate.

 *

 * The first thing to do is modify the original stack to look like a blocked

 * task so we can run backtrace on the original task.  Also mark the per cpu

 * stack as current to ensure that we use the correct task state, it also means

 * that we can do backtrace on the MCA/INIT handler code itself.

 Need asm address, not function descriptor */

	/* Best effort attempt to cope with MCA/INIT delivered while in

	 * physical mode.

	/* mca_asm.S ia64_old_stack() cannot assume that the dirty registers

	 * have been copied to the old stack, the old stack may fail the

	 * validation tests below.  So ia64_old_stack() must restore the dirty

	 * registers from the new stack.  The old and new bspstore probably

	 * have different alignments, so loadrs calculated on the old bsp

	 * cannot be used to restore from the new bsp.  Calculate a suitable

	 * loadrs for the new stack and save it in the new pt_regs, where

	 * ia64_old_stack() can get it.

 Verify the previous stack state before we change it */

		/* previous_current is guaranteed to be valid when the task was

		 * in user space, so ...

	/* Make the original task look blocked.  First stack a struct pt_regs,

	 * describing the state at the time of interrupt.  mca_asm.S built a

	 * partial pt_regs, copy it and fill in the blanks using minstate.

	/* Next stack a struct switch_stack.  mca_asm.S built a partial

	 * switch_stack, copy it and fill in the blanks using pt_regs and

	 * minstate.

	 *

	 * In the synthesized switch_stack, b0 points to ia64_leave_kernel,

	 * ar.pfs is set to 0.

	 *

	 * unwind.c::unw_unwind() does special processing for interrupt frames.

	 * It checks if the PRED_NON_SYSCALL predicate is set, if the predicate

	 * is clear then unw_unwind() does _not_ adjust bsp over pt_regs.  Not

	 * that this is documented, of course.  Set PRED_NON_SYSCALL in the

	 * switch_stack on the original stack so it will unwind correctly when

	 * unwind.c reads pt_regs.

	 *

	 * thread.ksp is updated to point to the synthesized switch_stack.

	/* Finally copy the original stack's registers back to its RBS.

	 * Registers from ar.bspstore through ar.bsp at the time of the event

	 * are in the current RBS, copy them back to the original stack.  The

	 * copy must be done register by register because the original bspstore

	 * and the current one have different alignments, so the saved RNAT

	 * data occurs at different places.

	 *

	 * mca_asm does cover, so the old_bsp already includes all registers at

	 * the time of MCA/INIT.  It also does flushrs, so all registers before

	 * this function have been written to backing store on the MCA/INIT

	 * stack.

/* The monarch/slave interaction is based on monarch_cpu and requires that all

 * slaves have entered rendezvous before the monarch leaves.  If any cpu has

 * not entered rendezvous yet then wait a bit.  The assumption is that any

 * slave that has not rendezvoused after a reasonable time is never going to do

 * so.  In this context, slave includes cpus that respond to the MCA rendezvous

 * interrupt, as well as cpus that receive the INIT slave event.

	/*

	 * wait 5 seconds total for slaves (arbitrary)

 short wait */

	/*

	 * Maybe slave(s) dead. Print buffered messages immediately.

/*  mca_insert_tr

 *

 *  Switch rid when TR reload and needed!

 *  iord: 1: itr, 2: itr;

 *

/*

 * ia64_mca_handler

 *

 *	This is uncorrectable machine check handler called from OS_MCA

 *	dispatch code which is in turn called from SAL_CHECK().

 *	This is the place where the core of OS MCA handling is done.

 *	Right now the logs are extracted and displayed in a well-defined

 *	format. This handler code is supposed to be run only on the

 *	monarch processor. Once the monarch is done with MCA handling

 *	further MCA logging is enabled by clearing logs.

 *	Monarch also has the duty of sending wakeup-IPIs to pull the

 *	slave processors out of rendezvous spinloop.

 *

 *	If multiple processors call into OS_MCA, the first will become

 *	the monarch.  Subsequent cpus will be recorded in the mca_cpu

 *	bitmask.  After the first monarch has processed its MCA, it

 *	will wake up the next cpu in the mca_cpu bitmask and then go

 *	into the rendezvous loop.  When all processors have serviced

 *	their MCA, the last monarch frees up the rest of the processors.

		/* Wakeup all the processors which are spinning in the

		 * rendezvous loop.  They will leave SAL, then spin in the OS

		 * with interrupts disabled until this monarch cpu leaves the

		 * MCA handler.  That gets control back to the OS so we can

		 * backtrace the other cpus, backtrace when spinning in SAL

		 * does not work.

 spin until monarch wakes us */

 Get the MCA error record and log it */

 MCA error recovery */

 Dump buffered message to console */

Reload dynamic itrs*/

Reload dynamic itrs*/

		/* wake up the next monarch cpu,

		 * and put this cpu in the rendez loop.

 wake next cpu */

 spin until last cpu leaves */

 This frees the slaves and previous monarchs */

/*

 * ia64_mca_cmc_int_handler

 *

 *  This is corrected machine check interrupt handler.

 *	Right now the logs are extracted and displayed in a well-defined

 *	format.

 *

 * Inputs

 *      interrupt number

 *      client data arg ptr

 *

 * Outputs

 *	None

 SAL spec states this should run w/ interrupts enabled */

 we know 1 happened now */

			/* If we're being hit with CMC interrupts, we won't

			 * ever execute the schedule_work() below.  Need to

			 * disable CMC interrupts on this processor now.

			/*

			 * Corrected errors will still be corrected, but

			 * make sure there's a log somewhere that indicates

			 * something is generating more than we can handle.

 lock already released, get out now */

 Get the CMC error record and log it */

/*

 *  ia64_mca_cmc_int_caller

 *

 * 	Triggered by sw interrupt from CMC polling routine.  Calls

 * 	real interrupt handler and either triggers a sw interrupt

 * 	on the next cpu or does cleanup at the end.

 *

 * Inputs

 *	interrupt number

 *	client data arg ptr

 * Outputs

 * 	handled

 If first cpu, update count */

 If no log record, switch out of polling mode */

/*

 *  ia64_mca_cmc_poll

 *

 *	Poll for Corrected Machine Checks (CMCs)

 *

 * Inputs   :   dummy(unused)

 * Outputs  :   None

 *

 Trigger a CMC interrupt cascade  */

/*

 *  ia64_mca_cpe_int_caller

 *

 * 	Triggered by sw interrupt from CPE polling routine.  Calls

 * 	real interrupt handler and either triggers a sw interrupt

 * 	on the next cpu or does cleanup at the end.

 *

 * Inputs

 *	interrupt number

 *	client data arg ptr

 * Outputs

 * 	handled

 If first cpu, update count */

		/*

		 * If a log was recorded, increase our polling frequency,

		 * otherwise, backoff or return to interrupt mode.

/*

 *  ia64_mca_cpe_poll

 *

 *	Poll for Corrected Platform Errors (CPEs), trigger interrupt

 *	on first cpu, from there it will trickle through all the cpus.

 *

 * Inputs   :   dummy(unused)

 * Outputs  :   None

 *

 Trigger a CPE interrupt cascade  */

	/*

	 * FIXME: mlogbuf will brim over with INIT stack dumps.

	 * To enable show_stack from INIT, we use oops_in_progress which should

	 * be used in real oops. This would cause something wrong after INIT.

 FIXME: This will not restore zapped printk locks. */

/*

 * C portion of the OS INIT handler

 *

 * Called from ia64_os_init_dispatch

 *

 * Inputs: pointer to pt_regs where processor info was saved.  SAL/OS state for

 * this event.  This code is used for both monarch and slave INIT events, see

 * sos->monarch.

 *

 * All INIT events switch to the INIT stack and change the previous process to

 * blocked status.  If one of the INIT events is the monarch then we are

 * probably processing the nmi button/command.  Use the monarch cpu to dump all

 * the processes.  The slave INIT events all spin until the monarch cpu

 * returns.  We can also get INIT slave events for MCA, in which case the MCA

 * process is the monarch.

	/* FIXME: Workaround for broken proms that drive all INIT events as

	 * slaves.  The last slave that enters is promoted to be a monarch.

	 * Remove this code in September 2006, that gives platforms a year to

	 * fix their proms and get their customers updated.

	/* FIXME: Workaround for broken proms that drive all INIT events as

	 * monarchs.  Second and subsequent monarchs are demoted to slaves.

	 * Remove this code in September 2006, that gives platforms a year to

	 * fix their proms and get their customers updated.

 spin until monarch enters */

 spin until monarch leaves */

	/*

	 * Wait for a bit.  On some machines (e.g., HP's zx2000 and zx6000, INIT can be

	 * generated via the BMC's command-line interface, but since the console is on the

	 * same serial line, the user will need some time to switch out of the BMC before

	 * the dump begins.

	/* If nobody intercepts DIE_INIT_MONARCH_PROCESS then we drop through

	 * to default_monarch_init_process() above and just print all the

	 * tasks.

/* Minimal format of the MCA/INIT stacks.  The pseudo processes that run on

 * these stacks can never sleep, they cannot return from the kernel to user

 * space, they do not appear in a normal ps listing.  So there is no need to

 * format most of the fields.

 Caller prevents this from being called after init */

 Do per-CPU MCA-related initialization.  */

	/*

	 * Structure will already be allocated if cpu has been online,

	 * then offlined.

	/*

	 * Stash away a copy of the PTE needed to map the per-CPU page.

	 * We may need it during MCA recovery.

	/*

	 * Also, stash away a copy of the PAL address and the PTE

	 * needed to map it.

/*

 * ia64_mca_init

 *

 *  Do all the system level mca specific initialization.

 *

 *	1. Register spinloop and wakeup request interrupt vectors

 *

 *	2. Register OS_MCA handler entry point

 *

 *	3. Register OS_INIT handler entry point

 *

 *  4. Initialize MCA/CMC/INIT related log buffers maintained by the OS.

 *

 *  Note that this initialization is done very early before some kernel

 *  services are available.

 *

 *  Inputs  :   None

 *

 *  Outputs :   None

 platform specific */

 we need to notified last */

 Clear the Rendez checkin flag for all cpus */

	/*

	 * Register the rendezvous spinloop and wakeup mechanism with SAL

 Register the rendezvous interrupt vector with SAL */

 Register the wakeup interrupt vector with SAL */

	/*

	 * XXX - disable SAL checksum by setting size to 0; should be

	 *	ia64_tpa(ia64_os_mca_dispatch_end) - ia64_tpa(ia64_os_mca_dispatch);

 Register the os mca handler with SAL */

	/*

	 * XXX - disable SAL checksum by setting size to 0, should be

	 * size of the actual init handler in mca_asm.S.

 Register the os init handler with SAL */

	/* Initialize the areas set aside by the OS to buffer the

	 * platform/processor error states for MCA/INIT/CMC

	 * handling.

/*

 * These pieces cannot be done in ia64_mca_init() because it is called before

 * early_irq_init() which would wipe out our percpu irq registrations. But we

 * cannot leave them until ia64_mca_late_init() because by then all the other

 * processors have been brought online and have set their own CMC vectors to

 * point at a non-existant action. Called from arch_early_irq_init().

	/*

	 *  Configure the CMCI/P vector and handler. Interrupts for CMC are

	 *  per-processor, so AP CMC interrupts are setup in smp_callin() (smpboot.c).

 Setup vector on BSP */

 Setup the MCA rendezvous interrupt vector */

 Setup the MCA wakeup interrupt vector */

 Setup the CPEI/P handler */

/*

 * ia64_mca_late_init

 *

 *	Opportunity to setup things that require initialization later

 *	than ia64_mca_init.  Setup a timer to poll for CPEs if the

 *	platform doesn't support an interrupt driven mechanism.

 *

 *  Inputs  :   None

 *  Outputs :   Status

 Setup the CMCI/P vector and handler */

 Unmask/enable the vector */

 Setup the CPEI/P vector and handler */

 If platform supports CPEI, enable the irq. */

 If platform doesn't support CPEI, get the timer going. */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Extensible SAL Interface (ESI) support routines.

 *

 * Copyright (C) 2006 Hewlett-Packard Co

 * 	Alex Williamson <alex.williamson@hp.com>

/*

 * Entry type:	Size:

 *	0	48

		/*

		 * The first byte of each entry type contains the type

		 * descriptor.

 makes module removable... */

 SPDX-License-Identifier: GPL-2.0

/*

 * arch/ia64/kernel/crash.c

 *

 * Architecture specific (ia64) functions for kexec based crash dumps.

 *

 * Created by: Khalid Aziz <khalid.aziz@hp.com>

 * Copyright (C) 2005 Hewlett-Packard Development Company, L.P.

 * Copyright (C) 2005 Intel Corp	Zou Nan hai <nanhai.zou@intel.com>

 *

	/* This function is only called after the system

	 * has paniced or is otherwise in a critical state.

	 * The minimum amount of code to allow a kexec'd kernel

	 * to run successfully needs to happen here.

	 *

	 * In practice this means shooting down the other cpus in

	 * an SMP system.

	/*

	 * If kdump_on_init is set and an INIT is asserted here, kdump will

	 * be started again via INIT monarch.

 mask MCA/INIT */

	/*

	 * Now this cpu is ready for kdump.

	 * Stop all others by IPI or INIT.  They could receive INIT from

	 * outside and might be INIT monarch, but only thing they have to

	 * do is falling into kdump_cpu_freeze().

	 *

	 * If an INIT is asserted here:

	 * - All receivers might be slaves, since some of cpus could already

	 *   be frozen and INIT might be masked on monarch.  In this case,

	 *   all slaves will be frozen soon since kdump_in_progress will let

	 *   them into DIE_INIT_SLAVE_LEAVE.

	 * - One might be a monarch, but INIT rendezvous will fail since

	 *   at least this cpu already have INIT masked so it never join

	 *   to the rendezvous.  In this case, all slaves and monarch will

	 *   be frozen soon with no wait since the INIT rendezvous is skipped

	 *   by kdump_in_progress.

 not all cpu response to IPI, send INIT to freeze them */

 wait again, don't go ahead if possible */

 mask MCA/INIT and stop reentrance */

 Reason code 1 means machine check rendezvous*/

 Reason code 1 means machine check rendezvous*/

 *(nd->data) indicate if MCA is recoverable */

 We got fatal MCA while kdump!? No way!! */

 be notified before default_monarch_init_process */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2000 Hewlett-Packard Co

 * Copyright (C) 2000 David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * Generic IA-64 unwind info decoder.

 *

 * This file is used both by the Linux kernel and objdump.  Please keep

 * the two copies of this file in sync.

 *

 * You need to customize the decoder by defining the following

 * macros/constants before including this file:

 *

 *  Types:

 *	unw_word	Unsigned integer type with at least 64 bits 

 *

 *  Register names:

 *	UNW_REG_BSP

 *	UNW_REG_BSPSTORE

 *	UNW_REG_FPSR

 *	UNW_REG_LC

 *	UNW_REG_PFS

 *	UNW_REG_PR

 *	UNW_REG_RNAT

 *	UNW_REG_PSP

 *	UNW_REG_RP

 *	UNW_REG_UNAT

 *

 *  Decoder action macros:

 *	UNW_DEC_BAD_CODE(code)

 *	UNW_DEC_ABI(fmt,abi,context,arg)

 *	UNW_DEC_BR_GR(fmt,brmask,gr,arg)

 *	UNW_DEC_BR_MEM(fmt,brmask,arg)

 *	UNW_DEC_COPY_STATE(fmt,label,arg)

 *	UNW_DEC_EPILOGUE(fmt,t,ecount,arg)

 *	UNW_DEC_FRGR_MEM(fmt,grmask,frmask,arg)

 *	UNW_DEC_FR_MEM(fmt,frmask,arg)

 *	UNW_DEC_GR_GR(fmt,grmask,gr,arg)

 *	UNW_DEC_GR_MEM(fmt,grmask,arg)

 *	UNW_DEC_LABEL_STATE(fmt,label,arg)

 *	UNW_DEC_MEM_STACK_F(fmt,t,size,arg)

 *	UNW_DEC_MEM_STACK_V(fmt,t,arg)

 *	UNW_DEC_PRIUNAT_GR(fmt,r,arg)

 *	UNW_DEC_PRIUNAT_WHEN_GR(fmt,t,arg)

 *	UNW_DEC_PRIUNAT_WHEN_MEM(fmt,t,arg)

 *	UNW_DEC_PRIUNAT_WHEN_PSPREL(fmt,pspoff,arg)

 *	UNW_DEC_PRIUNAT_WHEN_SPREL(fmt,spoff,arg)

 *	UNW_DEC_PROLOGUE(fmt,body,rlen,arg)

 *	UNW_DEC_PROLOGUE_GR(fmt,rlen,mask,grsave,arg)

 *	UNW_DEC_REG_PSPREL(fmt,reg,pspoff,arg)

 *	UNW_DEC_REG_REG(fmt,src,dst,arg)

 *	UNW_DEC_REG_SPREL(fmt,reg,spoff,arg)

 *	UNW_DEC_REG_WHEN(fmt,reg,t,arg)

 *	UNW_DEC_RESTORE(fmt,t,abreg,arg)

 *	UNW_DEC_RESTORE_P(fmt,qp,t,abreg,arg)

 *	UNW_DEC_SPILL_BASE(fmt,pspoff,arg)

 *	UNW_DEC_SPILL_MASK(fmt,imaskp,arg)

 *	UNW_DEC_SPILL_PSPREL(fmt,t,abreg,pspoff,arg)

 *	UNW_DEC_SPILL_PSPREL_P(fmt,qp,t,abreg,pspoff,arg)

 *	UNW_DEC_SPILL_REG(fmt,t,abreg,x,ytreg,arg)

 *	UNW_DEC_SPILL_REG_P(fmt,qp,t,abreg,x,ytreg,arg)

 *	UNW_DEC_SPILL_SPREL(fmt,t,abreg,spoff,arg)

 *	UNW_DEC_SPILL_SPREL_P(fmt,qp,t,abreg,pspoff,arg)

 p8 */

 p10 */

 prologue table: */

 0 */

 4 */

 0 */

 4 */

/*

 * Decode one descriptor and return address of next descriptor.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * SMP Support

 *

 * Copyright (C) 1999 Walt Drummond <drummond@valinux.com>

 * Copyright (C) 1999, 2001, 2003 David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * Lots of stuff stolen from arch/alpha/kernel/smp.c

 *

 * 01/05/16 Rohit Seth <rohit.seth@intel.com>  IA64-SMP functions. Reorganized

 * the existing code (on the lines of x86 port).

 * 00/09/11 David Mosberger <davidm@hpl.hp.com> Do loops_per_jiffy

 * calibration on each CPU.

 * 00/08/23 Asit Mallick <asit.k.mallick@intel.com> fixed logical processor id

 * 00/03/31 Rohit Seth <rohit.seth@intel.com>	Fixes for Bootstrap Processor

 * & cpu_online_map now gets done here (instead of setup.c)

 * 99/10/05 davidm	Update to bring it in sync with new command-line processing

 *  scheme.

 * 10/13/00 Goutham Rao <goutham.rao@intel.com> Updated smp_call_function and

 *		smp_call_function_single to resend IPI on timeouts

/*

 * Note: alignment of 4 entries/cacheline was empirically determined

 * to be a good tradeoff between hot cachelines & spreading the array

 * across too many cacheline.

 This needs to be cacheline aligned because it is written to by *other* CPUs.  */

	/*

	 * Remove this CPU:

 Should never be here */

 Order interrupt and bit testing. */

 Order bit clearing and data access. */

 Order data access and bit testing. */

/*

 * Called with preemption disabled.

/*

 * Called with preemption disabled.

/*

 * Called with preemption disabled.

/*

 * Called with preemption disabled.

/*

 * Called with preemption disabled.

/*

 * Called with preemption disabled.

/*

 * Called with preemption disabled.

	/*

	 * Use atomic ops. Otherwise, the load/increment/store sequence from

	 * a "++" operation can have the line stolen between the load & store.

	 * The overhead of the atomic op in negligible in this case & offers

	 * significant benefit for the brief periods where lots of cpus

	 * are simultaneously flushing TLBs.

 Usec backoff to eliminate excessive cacheline bouncing */

 this happens for the common case of a single-threaded fork():  */

/*

 * this function calls the 'stop' function on all other CPUs in the system.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 1999-2004 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 * Copyright (C) 2003 Fenghua Yu <fenghua.yu@intel.com>

 * 	- Change pt_regs_off() to make it less dependent on pt_regs structure.

/*

 * This file implements call frame unwind support for the Linux

 * kernel.  Parsing and processing the unwind information is

 * time-consuming, so this implementation translates the unwind

 * descriptors into unwind scripts.  These scripts are very simple

 * (basically a sequence of assignments) and efficient to execute.

 * They are cached for later re-use.  Each script is specific for a

 * given instruction pointer address and the set of predicate values

 * that the script depends on (most unwind descriptors are

 * unconditional and scripts often do not depend on predicates at

 * all).  This code is based on the unwind conventions described in

 * the "IA-64 Software Conventions and Runtime Architecture" manual.

 *

 * SMP conventions:

 *	o updates to the global unwind data (in structure "unw") are serialized

 *	  by the unw.lock spinlock

 *	o each unwind script has its own read-write lock; a thread must acquire

 *	  a read lock before executing a script and must acquire a write lock

 *	  before modifying a script

 *	o if both the unw.lock spinlock and a script's read-write lock must be

 *	  acquired, then the read-write lock must be acquired first.

 each unw_script is ~256 bytes in size */

 WARNING: this disabled interrupts for long time-spans!! */

 Do not code a printk level, not all debug lines end in newline */

 !UNW_DEBUG */

 UNW_DEBUG */

 spinlock for unwind data */

 list of unwind tables (one per load-module) */

 constant 0 for r0 */

 table of registers that prologues can save (and order in which they're saved): */

 maps a preserved register index (preg_index) to corresponding switch_stack offset: */

 index of lead-recently used script */

 index of most-recently used script */

 index into unw_frame_info for preserved register i */

 unwind table for the kernel: */

 unwind table describing the gate page (kernel code that is mapped into user space): */

 hash table that maps instruction pointer to script index: */

 script cache: */

 PRI_UNAT_GR */

 PRI_UNAT_MEM */

/*

 * Returns offset of rREG in struct pt_regs.

 This should not happen with valid unwind info.  */

 Unwind accessors.  */

 read r0 always returns 0 */

 access a preserved register */

 simulate getf.sig/setf.sig */

 write NaTVal and be done with it */

 return NaT and be done with it */

 access a scratch register */

 access a stacked register */

 if register is a NaT, *addr may contain kernel data! */

 scratch: */

 preserved: */

 Routines to manipulate the state stack.  */

 Make a copy of the state stack.  Non-recursive to avoid stack overflows.  */

 Free all stacked register states (but not RS itself).  */

 Unwind decoder routines */

	/*

	 * First, resolve implicit register save locations (see Section "11.4.2.3 Rules

	 * for Using Unwind Descriptors", rule 3):

	/*

	 * Next, compute when the fp, general, and branch registers get

	 * saved.  This must come before alloc_spill_area() because

	 * we need to know which registers are spilled to their home

	 * locations.

	/*

	 * Next, lay out the memory stack spill area:

/*

 * Region header descriptors.

 check if we're done: */

 default to psp+16 */

/*

 * Prologue descriptors.

/*

 * Body descriptors.

 insert into list of labeled states: */

/*

 * General descriptors.

/*

 * region headers:

/*

 * prologue descriptors:

/*

 * body descriptors:

/*

 * general unwind descriptors:

 Unwind scripts. */

 magic number = ((sqrt(5)-1)/2)*2^64 */

 keep the read lock... */

 Always regenerate scripts in debug mode */

 update hint; no locking required as single-word writes are atomic */

/*

 * On returning, a write lock for the SCRIPT is still being held.

	/*

	 * Can't (easily) use cmpxchg() here because of ABA problem

	 * that is intrinsic in cmpxchg()...

	/*

	 * We'd deadlock here if we interrupted a thread that is holding a read lock on

	 * script->lock.  Thus, if the write_trylock() fails, we simply bail out.  The

	 * alternative would be to disable interrupts whenever we hold a read-lock, but

	 * that seems silly.

 re-insert script at the tail of the LRU chain: */

 remove the old script from the hash table (if it's there): */

 old script wasn't in the hash-table */

 enter new script in the hash table */

 set new IP while we're holding the locks */

	/*

	 * We could down-grade our write-lock on script->lock here but

	 * the rwlock API doesn't offer atomic lock downgrading, so

	 * we'll just keep the write-lock and release it later when

	 * we're done using the script.

 register got spilled to a stacked register */

 register got spilled to a scratch register */

 register got spilled to a scratch register */

		/*

		 * info->psp must contain the _value_ of the previous

		 * sp, not it's save location.  We get this by

		 * dereferencing the value we just stored in

		 * info->psp:

 do a binary search for right entry: */

/*

 * Build an unwind script that unwinds from state OLD_STATE to the

 * entrypoint of the function that called OLD_STATE.

 build state record */

 search the kernels and the modules' unwind tables for IP: */

			/*

			 * Leave the kernel unwind table at the very front,

			 * lest moving it breaks some assumption elsewhere.

			 * Otherwise, move the matching table to the second

			 * position in the list so that traversals can benefit

			 * from commonality in backtrace paths.

 unw is safe - we're already spinlocked */

 no info, return default unwinder (leaf proc, no mem stack, no saved regs)  */

		/*

		 * sp has been restored and all values on the memory stack below

		 * psp also have been restored.

	/*

	 * If RP did't get saved, generate entry for the return link

	 * register.

 translate state record into unwinder instructions: */

	/*

	 * First, set psp if we're dealing with a fixed-size frame;

	 * subsequent instructions may depend on this value.

 new psp is sp plus frame size */

 frame size */

 determine where the primary UNaT is: */

 free labeled register states & stack: */

/*

 * Apply the unwinding actions represented by OPS and update SR to

 * reflect the state that existed upon entry to the function that this

 * unwinder represents.

 register off. is a multiple of 8, so the least 3 bits (type) are 0 */

		/*

		 * We're initializing a general register: init NaT info, too.  Note that

		 * the offset is a multiple of 8 which gives us the 3 bits needed for

		 * the type field.

 don't let obviously bad addresses pollute the cache */

 FIXME: should really be level 0 but it occurs too often. KAO */

 validate the return IP pointer */

 FIXME: should really be level 0 but it occurs too often. KAO */

 restore the ip */

 validate the previous stack frame pointer */

 restore the cfm: */

 restore the bsp: */

 size of frame */

 size of locals */

 restore the sp: */

 as we unwind, the saved ar.unat becomes the primary unat: */

 finally, restore the predicates: */

	/*

	 * Subtle stuff here: we _could_ unwind through the switch_stack frame but we

	 * don't want to do that because it would be slow as each preserved register would

	 * have to be processed.  Instead, what we do here is zero out the frame info and

	 * start the unwind process at the function that created the switch_stack frame.

	 * When a preserved value in switch_stack needs to be accessed, run_script() will

	 * initialize the appropriate pointer on demand.

 keep kernel unwind table at the front (it's searched most commonly): */

 first, delete the table: */

 next, remove hash table entries for this table */

 reserve space for "end of table" marker */

 start */

 end */

 info */

 end-of-table marker */

/*

 * DEPRECATED DEPRECATED DEPRECATED DEPRECATED DEPRECATED DEPRECATED DEPRECATED

 *

 *	This system call has been deprecated.  The new and improved way to get

 *	at the kernel's unwind info is via the gate DSO.  The address of the

 *	ELF header for this DSO is passed to user-level via AT_SYSINFO_EHDR.

 *

 * DEPRECATED DEPRECATED DEPRECATED DEPRECATED DEPRECATED DEPRECATED DEPRECATED

 *

 * This system call copies the unwind data into the buffer pointed to by BUF and returns

 * the size of the unwind data.  If BUF_SIZE is smaller than the size of the unwind data

 * or if BUF is NULL, nothing is copied, but the system call still returns the size of the

 * unwind data.

 *

 * The first portion of the unwind data contains an unwind table and rest contains the

 * associated unwind info (in no particular order).  The unwind table consists of a table

 * of entries of the form:

 *

 *	u64 start;	(64-bit address of start of function)

 *	u64 end;	(64-bit address of start of function)

 *	u64 info;	(BUF-relative offset to unwind info)

 *

 * The end of the unwind table is indicated by an entry with a START address of zero.

 *

 * Please see the IA-64 Software Conventions and Runtime Architecture manual for details

 * on the format of the unwind info.

 *

 * ERRORS

 *	EFAULT	BUF points outside your accessible address space.

 SPDX-License-Identifier: GPL-2.0

/*

 * Architecture-specific signal handling support.

 *

 * Copyright (C) 1999-2004 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * Derived from i386 and Alpha versions.

 minimal alignment for stack pointer */

 Always make any pending restarted system calls return -EINTR */

 restore scratch that always needs gets updated during signal delivery: */

 instruction pointer */

 user mask */

 predicates */

 b0 (rp) */

 b6 */

 r1 */

 r8-r11 */

 r12-r13 */

 r15 */

 force PL3 */

 establish new instruction pointer: */

 Restore most scratch-state only when not in syscall. */

 ar.ccv */

 b7 */

 r14 */

 ar.csd & ar.ssd */

 r2-r3 */

 r16-r31 */

 drop signal handler's fph contents... */

 We already own the local fph, otherwise psr->dfh wouldn't be 0.  */

	/*

	 * When we return to the previously executing context, r8 and r10 have already

	 * been setup the way we want them.  Indeed, if the signal wasn't delivered while

	 * in a system call, we must not touch r8 or r10 as otherwise user-level state

	 * could be corrupted.

		/*

		 * strace expects to be notified after sigreturn returns even though the

		 * context to which we return may not be in the middle of a syscall.

		 * Thus, the return-value that strace displays for sigreturn is

		 * meaningless.

/*

 * This does just the minimum required setup of sigcontext.

 * Specifically, it only installs data that is either not knowable at

 * the user-level or that gets modified before execution in the

 * trampoline starts.  Everything else is done at the user-level.

 if cr_ifs doesn't have the valid bit set, we got here through a syscall */

 ar.unat */

 ar.fpsr */

 predicates */

 b0 (rp) */

 b6 */

 r1 */

 r8-r11 */

 r12-r13 */

 r15 */

 Copy scratch regs to sigcontext if the signal didn't interrupt a syscall. */

 ar.ccv */

 b7 */

 r14 */

 ar.csd & ar.ssd */

 r2-r3 */

 r16-r31 */

/*

 * Check whether the register-backing store is already on the signal stack.

			/*

			 * We need to check for the register stack being on the

			 * signal stack separately, because it's switched

			 * separately (memory stack is switched in the kernel,

			 * register stack is switched in the signal trampoline).

			/*

			 * If we are on the alternate signal stack and would

			 * overflow it, don't. Return an always-bogus address

			 * instead so we will die with SIGSEGV.

 initialize to zero */

 new stack pointer */

 reset fpsr for signal handler */

 start executing in first slot */

 force little-endian byte-order */

	/*

	 * Force the interruption function mask to zero.  This has no effect when a

	 * system-call got interrupted by a signal (since, in that case, scr->pt_cr_ifs is

	 * ignored), but it has the desirable effect of making it possible to deliver a

	 * signal with an incomplete register frame (which happens when a mandatory RSE

	 * load faults).  Furthermore, it has no negative effect on the getting the user's

	 * dirty partition preserved, because that's governed by scr->pt.loadrs.

	/*

	 * Note: this affects only the NaT bits of the scratch regs (the ones saved in

	 * pt_regs), which is exactly what we want.

 ensure NaT bits of r12 is clear */

/*

 * Note that `init' is a special process: it doesn't get signals it doesn't want to

 * handle.  Thus you cannot kill init even with a SIGKILL even by mistake.

	/*

	 * This only loops in the rare cases of handle_signal() failing, in which case we

	 * need to push through a forced SIGSEGV.

		/*

		 * get_signal() may have run a debugger (via notify_parent())

		 * and the debugger may have modified the state (e.g., to arrange for an

		 * inferior call), thus it's important to check for restarting _after_

		 * get_signal().

			/*

			 * A system calls has to be restarted only if one of the error codes

			 * ERESTARTNOHAND, ERESTARTSYS, or ERESTARTNOINTR is returned.  If r10

			 * isn't -1 then r8 doesn't hold an error code and we don't need to

			 * restart the syscall, so we can clear the "restart" flag here.

 note: scr->pt.r10 is already -1 */

 note: scr->pt.r10 is already -1 */

 don't restart twice if handle_signal() fails... */

		/*

		 * Whee!  Actually deliver the signal.  If the delivery failed, we need to

		 * continue to iterate in this loop so we can deliver the SIGSEGV...

 Did we come from a system call? */

 Restart the system call - no handlers present */

			/*

			 * Note: the syscall number is in r15 which is saved in

			 * pt_regs so all we need to do here is adjust ip so that

			 * the "break" instruction gets re-executed.

	/* if there's no signal to deliver, we just put the saved sigmask

 SPDX-License-Identifier: GPL-2.0

/*

 * I/O SAPIC support.

 *

 * Copyright (C) 1999 Intel Corp.

 * Copyright (C) 1999 Asit Mallick <asit.k.mallick@intel.com>

 * Copyright (C) 2000-2002 J.I. Lee <jung-ik.lee@intel.com>

 * Copyright (C) 1999-2000, 2002-2003 Hewlett-Packard Co.

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 * Copyright (C) 1999 VA Linux Systems

 * Copyright (C) 1999,2000 Walt Drummond <drummond@valinux.com>

 *

 * 00/04/19	D. Mosberger	Rewritten to mirror more closely the x86 I/O

 *				APIC code.  In particular, we now have separate

 *				handlers for edge and level triggered

 *				interrupts.

 * 00/10/27	Asit Mallick, Goutham Rao <goutham.rao@intel.com> IRQ vector

 *				allocation PCI to vector mapping, shared PCI

 *				interrupts.

 * 00/10/27	D. Mosberger	Document things a bit more to make them more

 *				understandable.  Clean up much of the old

 *				IOSAPIC cruft.

 * 01/07/27	J.I. Lee	PCI irq routing, Platform/Legacy interrupts

 *				and fixes for ACPI S5(SoftOff) support.

 * 02/01/23	J.I. Lee	iosapic pgm fixes for PCI irq routing from _PRT

 * 02/01/07     E. Focht        <efocht@ess.nec.de> Redirectable interrupt

 *				vectors in iosapic_set_affinity(),

 *				initializations for /proc/irq/#/smp_affinity

 * 02/04/02	P. Diefenbaugh	Cleaned up ACPI PCI IRQ routing.

 * 02/04/18	J.I. Lee	bug fix in iosapic_init_pci_irq

 * 02/04/30	J.I. Lee	bug fix in find_iosapic to fix ACPI PCI IRQ to

 *				IOSAPIC mapping error

 * 02/07/29	T. Kochi	Allocate interrupt vectors dynamically

 * 02/08/04	T. Kochi	Cleaned up terminology (irq, global system

 *				interrupt, vector, etc.)

 * 02/09/20	D. Mosberger	Simplified by taking advantage of ACPI's

 *				pci_irq code.

 * 03/02/19	B. Helgaas	Make pcat_compat system-wide, not per-IOSAPIC.

 *				Remove iosapic_address & gsi_base from

 *				external interfaces.  Rationalize

 *				__init/__devinit attributes.

 * 04/12/04 Ashok Raj	<ashok.raj@intel.com> Intel Corporation 2004

 *				Updated to work with irq migration necessary

 *				for CPU Hotplug

/*

 * Here is what the interrupt logic between a PCI device and the kernel looks

 * like:

 *

 * (1) A PCI device raises one of the four interrupt pins (INTA, INTB, INTC,

 *     INTD).  The device is uniquely identified by its bus-, and slot-number

 *     (the function number does not matter here because all functions share

 *     the same interrupt lines).

 *

 * (2) The motherboard routes the interrupt line to a pin on a IOSAPIC

 *     controller.  Multiple interrupt lines may have to share the same

 *     IOSAPIC pin (if they're level triggered and use the same polarity).

 *     Each interrupt line has a unique Global System Interrupt (GSI) number

 *     which can be calculated as the sum of the controller's base GSI number

 *     and the IOSAPIC pin number to which the line connects.

 *

 * (3) The IOSAPIC uses an internal routing table entries (RTEs) to map the

 * IOSAPIC pin into the IA-64 interrupt vector.  This interrupt vector is then

 * sent to the CPU.

 *

 * (4) The kernel recognizes an interrupt as an IRQ.  The IRQ interface is

 *     used as architecture-independent interrupt handling mechanism in Linux.

 *     As an IRQ is a number, we have to have

 *     IA-64 interrupt vector number <-> IRQ number mapping.  On smaller

 *     systems, we use one-to-one mapping between IA-64 vector and IRQ.

 *

 * To sum up, there are three levels of mappings involved:

 *

 *	PCI pin -> global system interrupt (GSI) -> IA-64 vector <-> IRQ

 *

 * Note: The term "IRQ" is loosely used everywhere in Linux kernel to

 * describe interrupts.  Now we use "IRQ" only for Linux IRQ's.  ISA IRQ

 * (isa_irq) is the only exception in this source code.

/*

 * These tables map IA-64 vectors to the IOSAPIC pin that generates this

 * vector.

 base address of IOSAPIC */

 GSI base */

 # of RTEs on this IOSAPIC */

 # of RTEs in use on this IOSAPIC */

 numa node association via pxm */

 lock for indirect reg access */

 RTEs sharing the same vector */

 IOSAPIC RTE index */

 reference counter */

	struct list_head rtes;		/* RTEs using this vector (empty =>

 # of registered RTEs */

	u32		low32;		/* current value of low word of

 destination CPU physical ID */

 delivery mode (see iosapic.h) */

	unsigned char 	polarity: 1;	/* interrupt polarity

 trigger mode (see iosapic.h) */

 8259 compatibility flag */

/*

 * Find an IOSAPIC associated with a GSI

 not an IOSAPIC interrupt */

 dest contains both id and eid */

 do nothing... */

 not an IOSAPIC interrupt! */

 set only the mask bit */

 not an IOSAPIC interrupt! */

 not an IOSAPIC interrupt */

 dest contains both id and eid */

 change delivery mode to lowest priority */

 change delivery mode to fixed */

/*

 * Handlers for level-triggered interrupts.

/*

 * Handlers for edge-triggered interrupts.

	/*

	 * IOSAPIC simply drops interrupts pended while the

	 * corresponding pin was masked, so we can't know if an

	 * interrupt is pending already.  Let's hope not...

	/*

	 * IOSAPIC Version Register return 32 bit structure like:

	 * {

	 *	unsigned int version   : 8;

	 *	unsigned int reserved1 : 8;

	 *	unsigned int max_redir : 8;

	 *	unsigned int reserved2 : 8;

	 * }

	/*

	 * shared vectors for edge-triggered interrupts are not

	 * supported yet

/*

 * if the given vector is already owned by other,

 *  assign a new vector for the other and make the vector available

	/*

	 * In case of vector shared by multiple RTEs, all RTEs that

	 * share the vector need to use the same destination CPU.

	/*

	 * If the platform supports redirection via XTP, let it

	 * distribute interrupts.

	/*

	 * Some interrupts (ACPI SCI, for instance) are registered

	 * before the BSP is marked as online.

 Use irq assignment to distribute across cpus in node */

	/*

	 * Otherwise, round-robin interrupt vectors across all the

	 * processors.  (It'd be nice if we could be smarter in the

	 * case of NUMA.)

 CONFIG_SMP */

/*

 * ACPI can describe IOSAPIC interrupts via static tables and namespace

 * methods.  This provides an interface to register those interrupts and

 * program the IOSAPIC RTE.

	/*

	 * If this GSI has already been registered (i.e., it's a

	 * shared interrupt, or we lost a race to register it),

	 * don't touch the RTE.

 If vector is running out, we try to find a sharable vector */

	/*

	 * If the vector is shared and already unmasked for other

	 * interrupt sources, don't mask it.

	/*

	 * If the irq associated with the gsi is not found,

	 * iosapic_unregister_intr() is unbalanced. We need to check

	 * this again after getting locks.

 Mask the interrupt */

 Clear affinity */

 Clear the interrupt information */

 Destroy and reserve IRQ */

/*

 * ACPI calls this when it finds an entry for a platform interrupt.

		/*

		 * since PMI vector is alloc'd by FW(ACPI) not by kernel,

		 * we need to make sure the vector is available

/*

 * ACPI calls this when it finds an entry for a legacy ISA IRQ override.

		/*

		 * Disable the compatibility mode interrupts (8259 style),

		 * needs IN/OUT support enabled.

 mark as unused */

 check gsi range */

 OK */

	/*

	 * The MAX_REDIR register holds the highest input pin number

	 * (starting from 0).  We add 1 so that we can use it for

	 * number of pins (= RTEs)

		/*

		 * Map the legacy ISA devices into the IOSAPIC data.  Some of

		 * these may get reprogrammed later on with data from the ACPI

		 * Interrupt Source Override table.

 SPDX-License-Identifier: GPL-2.0

/*

 * Kernel support for the ptrace() and syscall tracing interfaces.

 *

 * Copyright (C) 1999-2005 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 * Copyright (C) 2006 Intel Co

 *  2006-08-12	- IA64 Native Utrace implementation support added by

 *	Anil S Keshavamurthy <anil.s.keshavamurthy@intel.com>

 *

 * Derived from the x86 and Alpha versions.

/*

 * Bits in the PSR that we allow ptrace() to change:

 *	be, up, ac, mfl, mfh (the user mask; five bits total)

 *	db (debug breakpoint fault; one bit)

 *	id (instruction debug fault disable; one bit)

 *	dd (data debug fault disable; one bit)

 *	ri (restart instruction; two bits)

 *	is (instruction set; one bit)

 mask with NBITS bits set */

 Return TRUE if PT was created due to kernel-entry via a system-call.  */

/*

 * Collect the NaT bits for r1-r31 from scratch_unat and return a NaT

 * bitset where bit i is set iff the NaT bit of register i is set.

	/*

	 * Registers that are stored consecutively in struct pt_regs

	 * can be handled in parallel.  If the register order in

	 * struct_pt_regs changes, this code MUST be updated.

/*

 * Set the NaT bits for the scratch registers according to NAT and

 * return the resulting unat (assuming the scratch registers are

 * stored in PT).

	/*

	 * Registers that are stored consecutively in struct pt_regs

	 * can be handled in parallel.  If the register order in

	 * struct_pt_regs changes, this code MUST be updated.

			/*

			 * rfi'ing to slot 2 of an MLX bundle causes

			 * an illegal operation fault.  We don't want

			 * that to happen...

			/*

			 * rfi'ing to slot 2 of an MLX bundle causes

			 * an illegal operation fault.  We don't want

			 * that to happen...

/*

 * This routine is used to read an rnat bits that are stored on the

 * kernel backing store.  Since, in general, the alignment of the user

 * and kernel are different, this is not completely trivial.  In

 * essence, we need to construct the user RNAT based on up to two

 * kernel RNAT values and/or the RNAT value saved in the child's

 * pt_regs.

 *

 * user rbs

 *

 * +--------+ <-- lowest address

 * | slot62 |

 * +--------+

 * |  rnat  | 0x....1f8

 * +--------+

 * | slot00 | \

 * +--------+ |

 * | slot01 | > child_regs->ar_rnat

 * +--------+ |

 * | slot02 | /				kernel rbs

 * +--------+				+--------+

 *	    <- child_regs->ar_bspstore	| slot61 | <-- krbs

 * +- - - - +				+--------+

 *					| slot62 |

 * +- - - - +				+--------+

 *					|  rnat	 |

 * +- - - - +				+--------+

 *   vrnat				| slot00 |

 * +- - - - +				+--------+

 *					=	 =

 *					+--------+

 *					| slot00 | \

 *					+--------+ |

 *					| slot01 | > child_stack->ar_rnat

 *					+--------+ |

 *					| slot02 | /

 *					+--------+

 *						  <--- child_stack->ar_bspstore

 *

 * The way to think of this code is as follows: bit 0 in the user rnat

 * corresponds to some bit N (0 <= N <= 62) in one of the kernel rnat

 * value.  The kernel rnat value holding this bit is stored in

 * variable rnat0.  rnat1 is loaded with the kernel rnat value that

 * form the upper bits of the user rnat value.

 *

 * Boundary cases:

 *

 * o when reading the rnat "below" the first rnat slot on the kernel

 *   backing store, rnat0/rnat1 are set to 0 and the low order bits are

 *   merged in from pt->ar_rnat.

 *

 * o when reading the rnat "above" the last rnat slot on the kernel

 *   backing store, rnat0/rnat1 gets its value from sw->ar_rnat.

	/*

	 * First, figure out which bit number slot 0 in user-land maps

	 * to in the kernel rnat.  Do this by figuring out how many

	 * register slots we're beyond the user's backingstore and

	 * then computing the equivalent address in kernel space.

 some bits need to be merged in from pt->ar_rnat */

/*

 * The reverse of get_rnat.

		/*

		 * If entered via syscall, don't allow user to set rnat bits

		 * for syscall args.

	/*

	 * First, figure out which bit number slot 0 in user-land maps

	 * to in the kernel rnat.  Do this by figuring out how many

	 * register slots we're beyond the user's backingstore and

	 * then computing the equivalent address in kernel space.

 some bits need to be place in pt->ar_rnat: */

	/*

	 * Note: Section 11.1 of the EAS guarantees that bit 63 of an

	 * rnat slot is ignored. so we don't have to clear it here.

/*

 * Read a word from the user-level backing store of task CHILD.  ADDR

 * is the user-level address to read the word from, VAL a pointer to

 * the return value, and USER_BSP gives the end of the user-level

 * backing store (i.e., it's the address that would be in ar.bsp after

 * the user executed a "cover" instruction).

 *

 * This routine takes care of accessing the kernel register backing

 * store for those registers that got spilled there.  It also takes

 * care of calculating the appropriate RNaT collection words.

		/*

		 * Attempt to read the RBS in an area that's actually

		 * on the kernel RBS => read the corresponding bits in

		 * the kernel RBS.

 return NaT collection word itself */

			/*

			 * It is implementation dependent whether the

			 * data portion of a NaT value gets saved on a

			 * st8.spill or RSE spill (e.g., see EAS 2.6,

			 * 4.4.4.6 Register Spill and Fill).  To get

			 * consistent behavior across all possible

			 * IA-64 implementations, we return zero in

			 * this case.

			/*

			 * The desired word is on the kernel RBS and

			 * is not a NaT.

		/*

		 * Attempt to write the RBS in an area that's actually

		 * on the kernel RBS => write the corresponding bits

		 * in the kernel RBS.

/*

 * Calculate the address of the end of the user-level register backing

 * store.  This is the address that would have been stored in ar.bsp

 * if the user had executed a "cover" instruction right before

 * entering the kernel.  If CFMP is not NULL, it is used to return the

 * "current frame mask" that was active at the time the kernel was

 * entered.

 clear valid bit */

/*

 * Synchronize (i.e, write) the RSE backing store living in kernel

 * space to the VM of the CHILD task.  SW and PT are the pointers to

 * the switch_stack and pt_regs structures, respectively.

 * USER_RBS_END is the user-level address at which the backing store

 * ends.

 now copy word for word from kernel rbs to user rbs: */

 now copy word for word from user rbs to kernel rbs: */

/*

 * when a thread is stopped (ptraced), debugger might change thread's user

 * stack (change memory directly), and we must avoid the RSE stored in kernel

 * to override user stack (user space's RSE is newer than kernel's in the

 * case). To workaround the issue, we copy kernel RSE to user RSE before the

 * task is stopped, so user RSE has updated data.  we then copy user RSE to

 * kernel after the task is resummed from traced stop and kernel will use the

 * newer RSE to return to user. TIF_RESTORE_RSE is the flag to indicate we need

 * synchronize user RSE to kernel.

/*

 * This is called to read back the register backing store.

/*

 * After PTRACE_ATTACH, a thread's register backing store area in user

 * space is assumed to contain correct data whenever the thread is

 * stopped.  arch_ptrace_stop takes care of this on tracing stops.

 * But if the child was already stopped for job control when we attach

 * to it, then it might not ever get into ptrace_stop by the time we

 * want to examine the user memory containing the RBS.

	/*

	 * If the child is in TASK_STOPPED, we need to change that to

	 * TASK_TRACED momentarily while we operate on it.  This ensures

	 * that the child won't be woken up and return to user mode while

	 * we are doing the sync.  (It can only be woken up for SIGKILL.)

	/*

	 * Now move the child back into TASK_STOPPED if it should be in a

	 * job control stop, so that SIGCONT can be used to wake it up.

/*

 * Write f32-f127 back to task->thread.fph if it has been modified.

	/*

	 * Prevent migrating this task while

	 * we're fiddling with the FPU state

/*

 * Sync the fph state of the task so that it can be manipulated

 * through thread.fph.  If necessary, f32-f127 are written back to

 * thread.fph or, if the fph state hasn't been used before, thread.fph

 * is cleared to zeroes.  Also, access to f32-f127 is disabled to

 * ensure that the task picks up the state from thread.fph when it

 * executes again.

/*

 * Change the machine-state of CHILD such that it will return via the normal

 * kernel exit-path, rather than the syscall-exit path.

	/*

	 * Note: at the time of this call, the target task is blocked

	 * in notify_resume_user() and by clearling PRED_LEAVE_SYSCALL

	 * (aka, "pLvSys") we redirect execution from

	 * .work_pending_syscall_end to .work_processed_kernel.

	/*

	 * Clear the memory that is NOT written on syscall-entry to

	 * ensure we do not leak kernel-state to user when execution

	 * resumes.

 clear r16-r31 */

 clear f6-f11 */

 control regs */

 app regs */

 gr1-gr3 */

 gr4-gr7 */

 gr8-gr11 */

 gr12-gr15 */

 gr16-gr31 */

 b0 */

 b1-b5 */

 b6-b7 */

 fr2-fr5 */

 fr6-fr11 */

 fp scratch regs(12-15) */

 fr16-fr31 */

 fph */

  preds */

 nat bits */

 control regs */

 app regs */

 gr1-gr3 */

 gr4-gr7 */

 NaT bit will be set via PT_NAT_BITS: */

 gr8-gr11 */

 gr12-gr15 */

 gr16-gr31 */

 b0 */

 b1-b5 */

 b6-b7 */

 fr2-fr5 */

 fr6-fr11 */

 fp scratch regs(12-15) */

 fr16-fr31 */

 fph */

 preds */

 nat bits */

 make sure the single step/taken-branch trap bits are not set: */

/*

 * Called by kernel/ptrace.c when detaching..

 *

 * Make sure the single step bit is not set.

 read word at location addr */

 ensure return value is not mistaken for error code */

	/* PTRACE_POKETEXT and PTRACE_POKEDATA is handled

	 * by the generic ptrace_request().

 read the word at addr in the USER area */

 ensure return value is not mistaken for error code */

 write the word at addr in the USER area */

 for backwards-compatibility */

 for backwards-compatibility */

 "asmlinkage" so the input arguments are preserved... */

 copy user rbs to kernel rbs */

 "asmlinkage" so the input arguments are preserved... */

 copy user rbs to kernel rbs */

 Utrace implementation starts here */

 read NaT bit first: */

 force PL3 */

			/*

			 * By convention, we use PT_AR_BSP to refer to

			 * the end of the user-level backing store.

			 * Use ia64_rse_skip_regs(PT_AR_BSP, -CFM.sof)

			 * to get the real value of ar.bsp at the time

			 * the kernel was entered.

			 *

			 * Furthermore, when changing the contents of

			 * PT_AR_BSP (or PT_CFM) while the task is

			 * blocked in a system call, convert the state

			 * so that the non-system-call exit

			 * path is used.  This ensures that the proper

			 * state will be picked up when resuming

			 * execution.  However, it *also* means that

			 * once we write PT_AR_BSP/PT_CFM, it won't be

			 * possible to modify the syscall arguments of

			 * the pending system call any longer.  This

			 * shouldn't be an issue because modifying

			 * PT_AR_BSP/PT_CFM generally implies that

			 * we're either abandoning the pending system

			 * call or that we defer it's re-execution

			 * (e.g., due to GDB doing an inferior

			 * function call).

					/*

					 * Simulate user-level write

					 * of ar.bsp:

 psr.ri==3 is a reserved value: SDM 2:25 */

	/*

	 * coredump format:

	 *      r0-r31

	 *      NaT bits (for r0-r31; bit N == 1 iff rN is a NaT)

	 *      predicate registers (p0-p63)

	 *      b0-b7

	 *      ip cfm user-mask

	 *      ar.rsc ar.bsp ar.bspstore ar.rnat

	 *      ar.ccv ar.unat ar.fpsr ar.pfs ar.lc ar.ec

 Skip r0 */

 Skip r0 */

 get up to 16 values */

 now copy them into registers */

 Skip pos 0 and 1 */

 fr2-fr31 */

 fph */

 Skip pos 0 and 1 */

 fr2-fr31 */

 only write high part */

 only write low part */

 fph */

/*

 * This is called to write back the register backing store.

 * ptrace does this before it stops, so that a tracer reading the user

 * memory after the thread stops will get the current register data.

 an invalid value */

 fr2-fr31 */

 fph */

 access debug registers */

 don't let the user set kernel-level breakpoints: */

	/*

	 * We get here via a few paths:

	 * - break instruction: cfm is shared with caller.

	 *   syscall args are in out= regs, locals are non-empty.

	 * - epsinstruction: cfm is set by br.call

	 *   locals don't exist.

	 *

	 * For both cases argguments are reachable in cfm.sof - cfm.sol.

	 * CFM: [ ... | sor: 17..14 | sol : 13..7 | sof : 6..0 ]

 aka sol */

 aka sof - sol */

 Iterate over outs. */

 SPDX-License-Identifier: GPL-2.0

 IBM Summit (EXA) Cyclone counter code*/

 saved cyclone base address */

 offset from pageaddr to cyclone_timer register */

 Cyclone MPMC0 register */

 find base address */

 setup PMCC */

 setup MPCS */

 map in cyclone_timer */

quick test to make sure its ticking*/

 initialize last tick */

 SPDX-License-Identifier: GPL-2.0

/*

 * Instruction-patching support.

 *

 * Copyright (C) 2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

/*

 * This was adapted from code written by Tony Luck:

 *

 * The 64-bit value in a "movl reg=value" is scattered between the two words of the bundle

 * like this:

 *

 * 6  6         5         4         3         2         1

 * 3210987654321098765432109876543210987654321098765432109876543210

 * ABBBBBBBBBBBBBBBBBBBBBBBCCCCCCCCCCCCCCCCCCDEEEEEFFFFFFFFFGGGGGGG

 *

 * CCCCCCCCCCCCCCCCCCxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

 * xxxxAFFFFFFFFFEEEEEDxGGGGGGGxxxxxxxxxxxxxBBBBBBBBBBBBBBBBBBBBBBB

 mask out slot number */

A*/

B*/

C*/

D*/

E*/

F*/

G*/

 Patch instruction with "val" where "mask" has 1 bits. */

 5 bits of template, then 3 x 41-bit instructions */

	/* The assembler may generate offset pointing to either slot 1

	   or slot 2 for a long (2-slot) instruction, occupying slots 1

 bit 63 -> 36 */

 bit 21 -> 21 */

 bit 16 -> 22 */

 bit  7 -> 27 */

 bit  0 -> 13 */));

	/* The assembler may generate offset pointing to either slot 1

	   or slot 2 for a long (2-slot) instruction, occupying slots 1

 bit 59 -> 36 */

 bit  0 -> 13 */));

/*

 * We need sometimes to load the physical address of a kernel

 * object.  Often we can convert the virtual address to physical

 * at execution time, but sometimes (either for performance reasons

 * or during error recovery) we cannot to this.  Patch the marked

 * bundles to load the physical address.

 replace virtual address with corresponding physical address: */

/*

 * Disable the RSE workaround by turning the conditional branch

 * that we tagged in each place the workaround was used into an

 * unconditional branch.

 nop.m 0; nop.i 0; br.ret.sptk.many b6 */

 nop.m 0; nop.i 0; nop.i 0 */

 see instruction format A4: adds r1 = imm13, r3 */

 SPDX-License-Identifier: GPL-2.0

 Set this to 1 if there is a HW IOMMU in the system */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  acpi.c - Architecture-Specific Low-Level ACPI Support

 *

 *  Copyright (C) 1999 VA Linux Systems

 *  Copyright (C) 1999,2000 Walt Drummond <drummond@valinux.com>

 *  Copyright (C) 2000, 2002-2003 Hewlett-Packard Co.

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *  Copyright (C) 2000 Intel Corp.

 *  Copyright (C) 2000,2001 J.I. Lee <jung-ik.lee@intel.com>

 *  Copyright (C) 2001 Paul Diefenbaugh <paul.s.diefenbaugh@intel.com>

 *  Copyright (C) 2001 Jenna Hall <jenna.s.hall@intel.com>

 *  Copyright (C) 2001 Takayoshi Kochi <t-kochi@bq.jp.nec.com>

 *  Copyright (C) 2002 Erich Focht <efocht@ess.nec.de>

 *  Copyright (C) 2004 Ashok Raj <ashok.raj@intel.com>

 Array to record platform interrupt vectors for generic interrupt routing. */

/*

 * Interrupt routing API for device drivers.  Provides interrupt vector for

 * a generic platform event.  Currently only CPEI is implemented.

 corrected platform error interrupt */

/* --------------------------------------------------------------------------

                            Boot-time Table Parsing

Skip BAD_MADT_ENTRY check, as lsapic size could vary */

 TBD: Support lapic_nmi entries */

	/*

	 * Get vector assignment for this interrupt, set attributes,

	 * and program the IOSAPIC routing table.

	/*

	 * Save the physical id, so we can check when its being removed

	/*

	 * Only if CPEI is supported and the override flag

	 * is present, otherwise return that its re-targettable

	 * if we are in polling mode.

 TBD: Support nimsrc entries */

		/*

		 * Unfortunately ITC_DRIFT is not yet part of the

		 * official SAL spec, so the ITC_DRIFT bit is not

		 * set by the BIOS on this hardware.

 remember the value for reference after free_initmem() */

 Firmware on old Itanium systems is broken */

 Get base address of IPI Message Block */

 number of cpus */

/*

 * ACPI 2.0 SLIT (System Locality Information Table)

 * http://devresource.hp.com/devresource/Docs/TechPapers/IA64/slit.pdf

 record this node in proximity bitmap */

 nid should be overridden as logical node id later */

 fill node memory chunk structure */

 Ignore disabled entries */

 record this node in proximity bitmap */

 Insertion sort based on base address */

 If there's no SRAT, fix the phys_id and mark node 0 online */

	/*

	 * MCD - This can probably be dropped now.  No need for pxm ID to node ID

	 * mapping with sparse node numbering iff MAX_PXM_DOMAINS <= MAX_NUMNODES.

 set logical node id in memory chunk structure */

 assign memory bank numbers for each chunk on each node */

 set logical node id in cpu structure */

 CONFIG_ACPI_NUMA */

/*

 * success: return IRQ number (>=0)

 * failure: return < 0

 Only deal with ACPI 2.0 FADT */

	/*

	 * do a partial walk of MADT to determine how many CPUs

	 * we have including offline CPUs

 We've got at least one of these, no? */

 Make boot-up look pretty */

	/*

	 * MADT

	 * ----

	 * Parse the Multiple APIC Description Table (MADT), if exists.

	 * Note that this table provides platform SMP configuration

	 * information -- the successor to MPS tables.

 Local APIC */

 I/O APIC */

 System-Level Interrupt Routing */

	/*

	 * FADT says whether a legacy keyboard controller is present.

	 * The FADT also contains an SCI_INT line, by which the system

	 * gets interrupts such as power and sleep buttons.  If it's not

	 * on a Legacy interrupt, it needs to be setup.

/*

 *  ACPI based hotplug CPU support

	/*

	 * We don't have cpu-only-node hotadd. But if the system equips

	 * SRAT table, pxm is already found and node is ready.

  	 * So, just pxm_to_nid(pxm) is OK.

	 * This code here is for the system which doesn't have full SRAT

  	 * table for possible cpus.

/*

 * cpu_possible_mask should be static, it cannot change as CPUs

 * are onlined, or offlined. The reason is per-cpu data-structures

 * are allocated by some modules at init time, and dont expect to

 * do this dynamically on cpu arrival/departure.

 * cpu_present_mask on the other hand can change dynamically.

 * In case when cpu_hotplug is not compiled, then we resort to current

 * behaviour, which is cpu_possible == cpu_present.

 * - Ashok Raj

 *

 * Three ways to find out the number of additional hotplug CPUs:

 * - If the BIOS specified disabled CPUs in ACPI/mptables use that.

 * - The user can overwrite it with additional_cpus=NUM

 * - Otherwise don't reserve additional CPUs.

 wrapper to silence section mismatch warning */

 NUMA specific cleanup's */

 CONFIG_ACPI_HOTPLUG_CPU */

 Only care about objects w/ a method that returns the MADT */

 OK, it's an IOSAPIC MADT entry; associate it with a node */

 We know a gsi to node mapping! */

 CONFIG_ACPI_NUMA */

 CONFIG_ACPI_NUMA */

/*

 * acpi_suspend_lowlevel() - save kernel state and suspend.

 *

 * TBD when IA64 starts to support suspend...

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 *  Kernel Probes (KProbes)

 *  arch/ia64/kernel/kprobes.c

 *

 * Copyright (C) IBM Corporation, 2002, 2004

 * Copyright (C) Intel Corporation, 2005

 *

 * 2005-Apr     Rusty Lynch <rusty.lynch@intel.com> and Anil S Keshavamurthy

 *              <anil.s.keshavamurthy@intel.com> adapted from i386

 00 */

 01 */

 02 */

 03 */

 04 */

 05 */

 06 */

 07 */

 08 */

 09 */

 0A */

 0B */

 0C */

 0D */

 0E */

 0F */

 10 */

 11 */

 12 */

 13 */

 14 */

 15 */

 16 */

 17 */

 18 */

 19 */

 1A */

 1B */

 1C */

 1D */

 1E */

 1F */

 Insert a long branch code */

 [MLX](stop) */

 nop.m 0x0 */

 brl.cond.sptk.many.clr rel<<4 (qp=0) */

/*

 * In this function we check to see if the instruction

 * is IP relative instruction and update the kprobe

 * inst flag accordingly

	/* Check for Break instruction

	 * Bits 37:40 Major opcode to be zero

	 * Bits 27:32 X6 to be zero

	 * Bits 32:35 X3 to be zero

 is a break instruction */

/*

 * In this function we check to see if the instruction

 * (qp) cmpx.crel.ctype p1,p2=r2,r3

 * on which we are inserting kprobe is cmp instruction

 * with ctype as unc.

 Integer compare - Register Register (A6 type)*/

 Integer compare - Immediate Register (A8 type)*/

/*

 * In this function we check to see if the instruction

 * on which we are inserting kprobe is supported.

 * Returns qp value if supported

 * Returns -EINVAL if unsupported

			/*

			 * Check for Integer speculation instruction

			 * - Bit 33-35 to be equal to 0x1

			/*

			 * IP relative mov instruction

			 *  - Bit 27-35 to be equal to 0x30

			/* test bit instructions, tbit,tnat,tf

			 * bit 33-36 to be equal to 0

			 * bit 12 to be equal to 1

 IP-Relative Predict major code is 7 */

			/* Indirect Predict, major code is 2

			 * bit 27-32 to be equal to 10 or 11

	/* kernel does not use float instruction, here for safety kprobe

	 * will judge whether it is fcmp/flass/float approximation instruction

 fcmp/fclass unc instruction */

 float Approximation instruction */

/*

 * In this function we override the bundle with

 * the break instruction at the given slot.

	/*

	 * Copy the original kprobe_inst qualifying predicate(qp)

	 * to the break instruction

	/*

	 * Update the instruction flag, so that we can

	 * emulate the instruction properly after we

	 * single step on original instruction

 Returns non-zero if the addr is in the Interrupt Vector Table */

	/*

	 * By returning a non-zero value, we are telling

	 * kprobe_handler() that we don't want the post_handler

	 * to run (and have re-enabled preemption)

 Replace the return addr with trampoline addr */

 Check the instruction in the slot is break */

 Move to slot 2, if bundle is MLX type and kprobe slot is 1 */

 Get Kprobe probe instruction at given slot*/

	/* For break instruction,

	 * Bits 37:40 Major opcode to be zero

	 * Bits 27:32 X6 to be zero

	 * Bits 32:35 X3 to be zero

 Not a break instruction */

 Is a break instruction */

/*

 * In this function, we check whether the target bundle modifies IP or

 * it triggers an exception. If so, it cannot be boostable.

 exception may occur in this bundle*/

 including B unit */ ||

 including X unit */ ||

 undefined */

 Prepare long jump bundle and disables other boosters if need */

 disables boosters in previous slots */

 Move to slot 2, if bundle is MLX type and kprobe slot is 1 */

 Get kprobe_inst and major_opcode from the bundle */

 p->ainsn.insn contains the original unaltered kprobe_opcode_t */

/*

 * We are resuming execution after a single step fault, so the pt_regs

 * structure reflects the register state after we executed the instruction

 * located in the kprobe (p->ainsn.insn->bundle).  We still need to adjust

 * the ip to point back to the original stack address. To set the IP address

 * to original stack address, handle the case where we need to fixup the

 * relative IP address and/or fixup branch register.

 Fix relative IP address */

		/*

		 * Fix target branch register, software convention is

		 * to use either b0 or b6 or b7, so just checking

		 * only those registers

 end switch */

 Turn off Single Step bit */

 single step inline if break instruction */

 turn on single stepping */

	/*

	 * We don't want to be preempted for the entire

	 * duration of kprobe processing

 Handle recursion cases */

			/* We have reentered the pre_kprobe_handler(), since

			 * another probe was hit while within the handler.

			 * We here save the original kprobes variables and

			 * just single step on the instruction of the new probe

			 * without calling any user handlers.

			/* The breakpoint instruction was removed by

			 * another cpu right after we hit, no further

			 * handling of this interrupt is appropriate

 Not our break */

			/*

			 * The breakpoint instruction was removed right

			 * after we hit it.  Another cpu has removed

			 * either a probepoint or a debugger breakpoint

			 * at this address.  In either case, no further

			 * handling of this interrupt is appropriate.

 Not one of our break, let kernel handle it */

 Boost up -- we can execute copied instructions directly */

 turn single stepping off */

Restore back the original saved kprobes variables and continue. */

		/*

		 * We are here because the instruction being single

		 * stepped caused a page fault. We reset the current

		 * kprobe and the instruction pointer points back to

		 * the probe address and allow the page fault handler

		 * to continue as a normal page fault.

		/*

		 * In case the user-specified fault handler returned

		 * zero, try to fix up.

		/*

		 * Let ia64_do_page_fault() fix it.

 err is break number from ia64_bad_break() */

 err is vector number from ia64_fault() */

 SPDX-License-Identifier: GPL-2.0

/*

 *	kernel/crash_dump.c - Memory preserving reboot related code.

 *

 *	Created by: Simon Horman <horms@verge.net.au>

 *	Original code moved from kernel/crash.c

 *	Original code comment copied from the i386 version of this file

/**

 * copy_oldmem_page - copy one page from "oldmem"

 * @pfn: page frame number to be copied

 * @buf: target memory address for the copy; this can be in kernel address

 *	space or user address space (see @userbuf)

 * @csize: number of bytes to copy

 * @offset: offset in bytes into the page (based on pfn) to begin the copy

 * @userbuf: if set, @buf is in user address space, use copy_to_user(),

 *	otherwise @buf is in kernel address space, use memcpy().

 *

 * Copy a page from "oldmem". For this page, there is no pte mapped

 * in the current kernel. We stitch up a pte, similar to kmap_atomic.

 *

 * Calling copy_to_user() in atomic context is not desirable. Hence first

 * copying the data to a pre-allocated kernel page and then copying to user

 * space in non-atomic context.

 SPDX-License-Identifier: GPL-2.0

/*

 * IA-64-specific support for kernel module loader.

 *

 * Copyright (C) 2003 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * Loosely based on patch by Rusty Russell.

/* relocs tested so far:



   DIR64LSB

   FPTR64LSB

   GPREL22

   LDXMOV

   LDXMOV

   LTOFF22

   LTOFF22X

   LTOFF22X

   LTOFF_FPTR22

   PCREL21B	(for br.call only; br.cond is not supported out of modules!)

   PCREL60B	(for brl.cond only; brl.call is not supported for modules!)

   PCREL64LSB

   SECREL32LSB

   SEGREL64LSB

 max. allowable linkage-table offset */

 Define some relocation helper macros/types: */

 direct encoded formats: */

 formats that cannot be directly decoded: */

 imm21 form 1 */

 imm21 form 2 */

 imm21 form 3 */

 S + A */

 @gprel(S + A) */

 @ltoff(S + A) */

 @pltoff(S + A) */

 @fptr(S + A) */

 S + A - P */

 @ltoff(@fptr(S + A)) */

 @segrel(S + A) */

 @secrel(S + A) */

 BD + A */

 S + A (like RV_DIRECT, except frozen at static link-time) */

 S + A - P */

 various (see below) */

 @tprel(S + A) */

 @ltoff(@tprel(S + A)) */

 @dtpmod(S + A) */

 @ltoff(@dtpmod(S + A)) */

 @dtprel(S + A) */

 @ltoff(@dtprel(S + A)) */

 28-31 reserved for implementation-specific purposes.  */

 Opaque struct for insns, to protect against derefs. */

 bit 21 -> 36 */

 bit 16 -> 22 */

 bit  7 -> 27 */

 bit  0 -> 13 */));

 bit 20 -> 36 */

 bit  0 -> 13 */));

 Three instruction bundles in PLT. */

 [MLX] nop.m 0 */

	     movl gp=TARGET_GP */

 [MLX] nop.m 0 */

	     brl.many gp=TARGET_GP */

 imm20b -> bit 0 */

 imm39 -> bit 20 */

 i -> bit 59 */

 !USE_BRL */

 Three instruction bundles in PLT. */

 [MLX] nop.m 0 */

	     movl r16=TARGET_IP */

 [MLX] nop.m 0 */

	     movl gp=TARGET_GP */

 [MIB] nop.m 0 */

	     mov b6=r16 */

	     br.few b6 */

 imm7b -> bit 0 */

 imm9d -> bit 7 */

 imm5c -> bit 16 */

 ic -> bit 21 */

 imm41 -> bit 22 */

 i -> bit 63 */

 !USE_BRL */

 Have we already seen one of these relocations? */

 FIXME: we could look in other sections, too --RR */

 Count how many GOT entries we may need */

	/* Sure, this is order(n^2), but it's usually short, and not

 Count how many PLT entries we may need */

	/* Sure, this is order(n^2), but it's usually short, and not

/* We need to create an function-descriptors for any internal function

 Sure, this is order(n^2), but it's usually short, and not time critical.  */

			/*

			 * Jumps to static functions sometimes go straight to their

			 * offset.  Of course, that may not be possible if the jump is

			 * from init -> core or vice. versa, so we need to generate an

			 * FDESC (and PLT etc) for that.

	/*

	 * To store the PLTs and function-descriptors, we expand the .text section for

	 * core module-code and the .init.text section for initialization code.

 GOT and PLTs can occur in any relocated section... */

/*

 * Get gp-relative offset for the linkage-table entry of VALUE.

 Not enough GOT entries? */

 Get PC-relative PLT entry for this value.  Returns 0 on failure. */

 "value" is a pointer to a function-descriptor; fetch the target ip/gp from it: */

 Look for existing PLT entry. */

 Get function descriptor for VALUE. */

		/*

		 * If it's not a module-local entry-point, "value" already points to a

		 * function-descriptor.

 Look for existing function descriptor. */

 Create new one */

 segment base is arbitrarily chosen to be 0 for kernel modules */

				/*

				 * Init section may have been allocated far away from core,

				 * if the branch won't reach, then allocate a plt for it.

 can link-time value relocs happen here?  */

 turn "ld8" into "mov": */

 ia64 Linux is little-endian... */

 ia64 Linux is little-endian... */

 must be within-module, i.e., resolved by "ld -r" */

 must be within-module, i.e., resolved by "ld -r" */

 must be within-module, i.e., resolved by "ld -r" */

		/*

		 * If target section wasn't allocated, we don't need to relocate it.

		 * Happens, e.g., for debug sections.

		/*

		 * XXX Should have an arch-hook for running this after final section

		 *     addresses have been selected...

			/*

			 * This takes advantage of fact that SHF_ARCH_SMALL gets allocated

			 * at the end of the module.

/*

 * Modules contain a single unwind table which covers both the core and the init text

 * sections but since the two are not contiguous, we need to split this table up such that

 * we can register (and unregister) each "segment" separately.  Fortunately, this sounds

 * more complicated than it really is.

 First, count how many init and core unwind-table entries there are.  */

	/*

	 * Second, sort the table such that all unwind-table entries for the init and core

	 * text sections are nicely separated.  We do this with a stupid bubble sort

	 * (unwind tables don't get ridiculously huge).

	/*

	 * Third, locate the init and core segments in the unwind table:

	/*

	 * Fourth, register both tables (if not empty).

	/*

	 * ".opd" was already relocated to the final destination. Store

	 * it's address for use in symbolizer.

	/*

	 * Module relocation was already done at this point. Section

	 * headers are about to be deleted. Wipe out load-time context.

/*

 * err_inject.c -

 *	1.) Inject errors to a processor.

 *	2.) Query error injection capabilities.

 * This driver along with user space code can be acting as an error

 * injection tool.

 *

 * This program is free software; you can redistribute it and/or modify

 * it under the terms of the GNU General Public License as published by

 * the Free Software Foundation; either version 2 of the License, or

 * (at your option) any later version.

 *

 * This program is distributed in the hope that it will be useful, but

 * WITHOUT ANY WARRANTY; without even the implied warranty of

 * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or

 * NON INFRINGEMENT.  See the GNU General Public License for more

 * details.

 *

 * You should have received a copy of the GNU General Public License

 * along with this program; if not, write to the Free Software

 * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.

 *

 * Written by: Fenghua Yu <fenghua.yu@intel.com>, Intel Corporation

 * Copyright (C) 2006, Intel Corp.  All rights reserved.

 *

 Three 8-byte;

/* It's user's responsibility to call the PAL procedure on a specific

 * processor. The cpu number in driver is only used for storing data.

 Do nothing. */

 Call pal_mc_error_inject in physical mode. */

 Call pal_mc_error_inject in virtual mode. */

 Add/Remove err_inject interface for CPU device */

 SPDX-License-Identifier: GPL-2.0

/*

 *	linux/arch/ia64/kernel/irq.c

 *

 *	Copyright (C) 1992, 1998 Linus Torvalds, Ingo Molnar

 *

 * This file contains the code used by various IRQ handling routines:

 * asking for different IRQs should be done through these routines

 * instead of just grabbing them. Thus setups with different IRQ numbers

 * shouldn't result in any weird surprises, and installing new handlers

 * should be easier.

 *

 * Copyright (C) Ashok Raj<ashok.raj@intel.com>, Intel Corporation 2004

 *

 * 4/14/2004: Added code to handle cpu migration and do safe irq

 *			migration without losing interrupts for iosapic

 *			architecture.

/*

 * 'what should we do if we get a hw irq event on an illegal vector'.

 * each architecture has to answer this themselves.

/*

 * Interrupt statistics:

/*

 * /proc/interrupts printing:

 = { [0 ... NR_IRQS-1] = 1 };

 CONFIG_SMP */

/*

 * Since cpu_online_mask is already updated, we just need to check for

 * affinity that has zeros

		/*

		 * No handling for now.

		 * TBD: Implement a disable function so we can now

		 * tell CPU not to respond to these local intr sources.

		 * such as ITV,CPEI,MCA etc.

			/*

			 * Save it for phase 2 processing

			/*

			 * Al three are essential, currently WARN_ON.. maybe panic?

 Mask ITV to disable timer */

	/*

	 * Find a new timesync master

	/*

	 * Phase 1: Locate IRQs bound to this cpu and

	 * relocate them for cpu removal.

	/*

	 * Phase 2: Perform interrupt processing for all entries reported in

	 * local APIC.

	/*

	 * Phase 3: Now handle any interrupts not captured in local APIC.

	 * This is to account for cases that device interrupted during the time the

	 * rte was being disabled and re-programmed.

	/*

	 * Now let processor die. We do irq disable and max_xtp() to

	 * ensure there is no more interrupts routed to this processor.

	 * But the local timer interrupt can have 1 pending which we

	 * take care in timer_interrupt().

 SPDX-License-Identifier: GPL-2.0

/*

 * This file contains various system calls that have different calling

 * conventions on different platforms.

 *

 * Copyright (C) 1999-2000, 2002-2003, 2005 Hewlett-Packard Co

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 doh, must come after sched.h... */

 handle fixed mapping: prevent overlap with huge pages */

		/*

		 * For 64-bit tasks, align shared segments to 1MB to avoid potential

		 * performance penalty due to virtual aliasing (see ASDM).  For 32-bit

		 * tasks, we prefer to avoid exhausting the address space too quickly by

		 * limiting alignment to a single page.

 XXX obsolete, but leave it here until the old libc is gone... */

/*

 * On IA-64, we return the two file descriptors in ret0 and ret1 (r8

 * and r9) as this is faster than doing a copy_to_user().

	/*

	 * Don't permit mappings into unmapped space, the virtual page table

	 * of a region, or across a region boundary.  Note: RGN_MAP_LIMIT is

	 * equal to 2^n-PAGE_SIZE (for some integer n <= 61) and len > 0.

/*

 * mmap2() is like mmap() except that the offset is expressed in units

 * of PAGE_SIZE (instead of bytes).  This allows to mmap2() (pieces

 * of) files that are larger than the address space of the CPU.

 SPDX-License-Identifier: GPL-2.0

/*

 * Architecture-specific unaligned trap handling.

 *

 * Copyright (C) 1999-2002, 2004 Hewlett-Packard Co

 *	Stephane Eranian <eranian@hpl.hp.com>

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *

 * 2002/12/09   Fix rotating register handling (off-by-1 error, missing fr-rotation).  Fix

 *		get_rse_reg() to not leak kernel bits to user-level (reading an out-of-frame

 *		stacked register returns an undefined value; it does NOT trigger a

 *		"rsvd register fault").

 * 2001/10/11	Fix unaligned access to rotating registers in s/w pipelined loops.

 * 2001/08/13	Correct size of extended floats (float_fsz) from 16 to 10 bytes.

 * 2001/01/17	Add support emulation of unaligned kernel accesses.

/*

 *  sysctl settable hook which tells the kernel whether to honor the

 *  IA64_THREAD_UAC_NOPRINT prctl.  Because this is user settable, we want

 *  to allow the super user to enable/disable this for security reasons

 *  (i.e. don't allow attacker to fill up logs with unaligned accesses).

/*

 * For M-unit:

 *

 *  opcode |   m  |   x6    |

 * --------|------|---------|

 * [40-37] | [36] | [35:30] |

 * --------|------|---------|

 *     4   |   1  |    6    | = 11 bits

 * --------------------------

 * However bits [31:30] are not directly useful to distinguish between

 * load/store so we can use [35:32] instead, which gives the following

 * mask ([40:32]) using 9 bits. The 'e' comes from the fact that we defer

 * checking the m-bit until later in the load/store emulation.

/*

 * Table C-28 Integer Load/Store

 *

 * We ignore [35:32]= 0x6, 0x7, 0xE, 0xF

 *

 * ld8.fill, st8.fill  MUST be aligned because the RNATs are based on

 * the address (bits [8:3]), so we must failed.

 0x086, 0x087 are not relevant */

 0x08e,0x8f are not relevant */

/*

 * Table C-29 Integer Load +Reg

 *

 * we use the ld->m (bit [36:36]) field to determine whether or not we have

 * a load/store of this form.

/*

 * Table C-30 Integer Load/Store +Imm

 *

 * We ignore [35:32]= 0x6, 0x7, 0xE, 0xF

 *

 * ld8.fill, st8.fill  must be aligned because the Nat register are based on

 * the address, so we must fail and the program must be fixed.

 0x0a6, 0xa7 are not relevant */

 0x0ae,0xaf are not relevant */

/*

 * Table C-32 Floating-point Load/Store

 0x0c6 is irrelevant */

 0x0cb is irrelevant  */

/*

 * Table C-33 Floating-point Load +Reg

 *

 * we use the ld->m (bit [36:36]) field to determine whether or not we have

 * a load/store of this form.

/*

 * Table C-34 Floating-point Load/Store +Imm

 0x0e6 is irrelevant */

 [0:5]   */

 [6:12]  */

 [13:19] */

 [20:26] */

 [27:27] */

 [28:29] */

 [30:31] */

 [32:35], x6 = x6_sz|x6_op */

 [36:36] */

 [37:40] */

 [41:63] */

 ldXZ r1=[r3],imm(9) */

 ldXZ r1=[r3],r2     */

/*

 * We use tables to keep track of the offsets of registers in the saved state.

 * This way we save having big switch/case statements.

 *

 * We use bit 0 to indicate switch_stack or pt_regs.

 * The offset is simply shifted by 1 bit.

 * A 2-byte value should be enough to hold any kind of offset

 *

 * In case the calling convention changes (and thus pt_regs/switch_stack)

 * simply use RSW instead of RPT or vice-versa.

 r0 is read-only : WE SHOULD NEVER GET THIS */

 constant : WE SHOULD NEVER GET THIS */

 constant : WE SHOULD NEVER GET THIS */

 Invalidate ALAT entry for integer register REGNO.  */

 Invalidate ALAT entry for floating-point register REGNO.  */

 this should never happen, as the "rsvd register fault" has higher priority */

 the register is on the kernel backing store: easy... */

 read of out-of-frame register returns an undefined value; 0 in our case.  */

 the register is on the kernel backing store: easy... */

	/*

	 * First takes care of stacked registers

	/*

	 * Using r0 as a target raises a General Exception fault which has higher priority

	 * than the Unaligned Reference fault.

	/*

	 * Now look at registers in [0-31] range and init correct UNAT

	/*

	 * add offset from base of struct

	 * and do it !

	/*

	 * We need to clear the corresponding UNAT bit to fully emulate the load

	 * UNAT bit_pos = GR[r3]{8:3} form EAS-2.4

/*

 * Return the (rotated) index for floating point register REGNUM (REGNUM must be in the

 * range from 32-127, result is in the range from 0-95.

	/*

	 * From EAS-2.5: FPDisableFault has higher priority than Unaligned

	 * Fault. Thus, when we get here, we know the partition is enabled.

	 * To update f32-f127, there are three choices:

	 *

	 *	(1) save f32-f127 to thread.fph and update the values there

	 *	(2) use a gigantic switch statement to directly access the registers

	 *	(3) generate code on the fly to update the desired register

	 *

	 * For now, we are using approach (1).

		/*

		 * pt_regs or switch_stack ?

		/*

		 * mark the low partition as being used now

		 *

		 * It is highly unlikely that this bit is not already set, but

		 * let's do it for safety.

/*

 * Those 2 inline functions generate the spilled versions of the constant floating point

 * registers which can be used with stfX

	/*

	 * From EAS-2.5: FPDisableFault has higher priority than

	 * Unaligned Fault. Thus, when we get here, we know the partition is

	 * enabled.

	 *

	 * When regnum > 31, the register is still live and we need to force a save

	 * to current->thread.fph to get access to it.  See discussion in setfpreg()

	 * for reasons and other ways of doing this.

		/*

		 * f0 = 0.0, f1= 1.0. Those registers are constant and are thus

		 * not saved, we must generate their spilled form on the fly

			/*

			 * pt_regs or switch_stack ?

	/*

	 * take care of r0 (read-only always evaluate to 0)

	/*

	 * Now look at registers in [0-31] range and init correct UNAT

	/*

	 * do it only when requested

	/*

	 * IMPORTANT:

	 * Given the way we handle unaligned speculative loads, we should

	 * not get to this point in the code but we keep this sanity check,

	 * just in case.

	/*

	 * at this point, we know that the base register to update is valid i.e.,

	 * it's not r0

		/*

		 * Load +Imm: ldXZ r1=[r3],imm(9)

		 *

		 *

		 * form imm9: [13:19] contain the first 7 bits

		/*

		 * sign extend (1+8bits) if m set

		/*

		 * ifa == r3 and we know that the NaT bit on r3 was clear so

		 * we can directly use ifa.

		/*

		 * Load +Reg Opcode: ldXZ r1=[r3],r2

		 *

		 * Note: that we update r3 even in the case of ldfX.a

		 * (where the load does not happen)

		 *

		 * The way the load algorithm works, we know that r3 does not

		 * have its NaT bit set (would have gotten NaT consumption

		 * before getting the unaligned fault). So we can use ifa

		 * which equals r3 at this point.

		 *

		 * IMPORTANT:

		 * The above statement holds ONLY because we know that we

		 * never reach this code when trying to do a ldX.s.

		 * If we ever make it to here on an ldfX.s then

		/*

		 * propagate Nat r2 -> r3

	/*

	 * r0, as target, doesn't need to be checked because Illegal Instruction

	 * faults have higher priority than unaligned faults.

	 *

	 * r0 cannot be found as the base as it would never generate an

	 * unaligned reference.

	/*

	 * ldX.a we will emulate load and also invalidate the ALAT entry.

	 * See comment below for explanation on how we handle ldX.a

 this assumes little-endian byte-order: */

	/*

	 * check for updates on any kind of loads

	/*

	 * handling of various loads (based on EAS2.4):

	 *

	 * ldX.acq (ordered load):

	 *	- acquire semantics would have been used, so force fence instead.

	 *

	 * ldX.c.clr (check load and clear):

	 *	- if we get to this handler, it's because the entry was not in the ALAT.

	 *	  Therefore the operation reverts to a normal load

	 *

	 * ldX.c.nc (check load no clear):

	 *	- same as previous one

	 *

	 * ldX.c.clr.acq (ordered check load and clear):

	 *	- same as above for c.clr part. The load needs to have acquire semantics. So

	 *	  we use the fence semantics which is stronger and thus ensures correctness.

	 *

	 * ldX.a (advanced load):

	 *	- suppose ldX.a r1=[r3]. If we get to the unaligned trap it's because the

	 *	  address doesn't match requested size alignment. This means that we would

	 *	  possibly need more than one load to get the result.

	 *

	 *	  The load part can be handled just like a normal load, however the difficult

	 *	  part is to get the right thing into the ALAT. The critical piece of information

	 *	  in the base address of the load & size. To do that, a ld.a must be executed,

	 *	  clearly any address can be pushed into the table by using ld1.a r1=[r3]. Now

	 *	  if we use the same target register, we will be okay for the check.a instruction.

	 *	  If we look at the store, basically a stX [r3]=r1 checks the ALAT  for any entry

	 *	  which would overlap within [r3,r3+X] (the size of the load was store in the

	 *	  ALAT). If such an entry is found the entry is invalidated. But this is not good

	 *	  enough, take the following example:

	 *		r3=3

	 *		ld4.a r1=[r3]

	 *

	 *	  Could be emulated by doing:

	 *		ld1.a r1=[r3],1

	 *		store to temporary;

	 *		ld1.a r1=[r3],1

	 *		store & shift to temporary;

	 *		ld1.a r1=[r3],1

	 *		store & shift to temporary;

	 *		ld1.a r1=[r3]

	 *		store & shift to temporary;

	 *		r1=temporary

	 *

	 *	  So in this case, you would get the right value is r1 but the wrong info in

	 *	  the ALAT.  Notice that you could do it in reverse to finish with address 3

	 *	  but you would still get the size wrong.  To get the size right, one needs to

	 *	  execute exactly the same kind of load. You could do it from a aligned

	 *	  temporary location, but you would get the address wrong.

	 *

	 *	  So no matter what, it is not possible to emulate an advanced load

	 *	  correctly. But is that really critical ?

	 *

	 *	  We will always convert ld.a into a normal load with ALAT invalidated.  This

	 *	  will enable compiler to do optimization where certain code path after ld.a

	 *	  is not required to have ld.c/chk.a, e.g., code path with no intervening stores.

	 *

	 *	  If there is a store after the advanced load, one must either do a ld.c.* or

	 *	  chk.a.* to reuse the value stored in the ALAT. Both can "fail" (meaning no

	 *	  entry found in ALAT), and that's perfectly ok because:

	 *

	 *		- ld.c.*, if the entry is not present a  normal load is executed

	 *		- chk.a.*, if the entry is not present, execution jumps to recovery code

	 *

	 *	  In either case, the load can be potentially retried in another form.

	 *

	 *	  ALAT must be invalidated for the register (so that chk.a or ld.c don't pick

	 *	  up a stale entry later). The register base update MUST also be performed.

	/*

	 * when the load has the .acq completer then

	 * use ordering fence.

	/*

	 * invalidate ALAT entry in case of advanced load

	/*

	 * if we get to this handler, Nat bits on both r3 and r2 have already

	 * been checked. so we don't need to do it

	 *

	 * extract the value to be stored

	/*

	 * we rely on the macros in unaligned.h for now i.e.,

	 * we let the compiler figure out how to read memory gracefully.

	 *

	 * We need this switch/case because the way the inline function

	 * works. The code is optimized by the compiler and looks like

	 * a single switch/case.

 this assumes little-endian byte-order: */

	/*

	 * stX [r3]=r2,imm(9)

	 *

	 * NOTE:

	 * ld.r3 can never be r0, because r0 would not generate an

	 * unaligned access.

		/*

		 * form imm9: [12:6] contain first 7bits

		/*

		 * sign extend (8bits) if m set

		/*

		 * ifa == r3 (NaT is necessarily cleared)

	/*

	 * we don't have alat_invalidate_multiple() so we need

	 * to do the complete flush :-<<

	/*

	 * stX.rel: use fence instead of release

/*

 * floating point operations sizes in bytes

 extended precision (e) */

 integer (8)            */

 single precision (s)   */

 double precision (d)   */

	/*

	 * fr0 & fr1 don't need to be checked because Illegal Instruction faults have

	 * higher priority than unaligned faults.

	 *

	 * r0 cannot be found as the base as it would never generate an unaligned

	 * reference.

	/*

	 * make sure we get clean buffers

	/*

	 * ldfpX.a: we don't try to emulate anything but we must

	 * invalidate the ALAT entry and execute updates, if any.

		/*

		 * This assumes little-endian byte-order.  Note that there is no "ldfpe"

		 * instruction:

		/*

		 * XXX fixme

		 * Could optimize inlines by using ldfpX & 2 spills

		/*

		 * XXX fixme

		 *

		 * A possible optimization would be to drop fpr_final and directly

		 * use the storage from the saved context i.e., the actual final

		 * destination (pt_regs, switch_stack or thread structure).

	/*

	 * Check for updates: only immediate updates are available for this

	 * instruction.

		/*

		 * the immediate is implicit given the ldsz of the operation:

		 * single: 8 (2x4) and for  all others it's 16 (2x8)

		/*

		 * IMPORTANT:

		 * the fact that we force the NaT of r3 to zero is ONLY valid

		 * as long as we don't come here with a ldfpX.s.

		 * For this reason we keep this sanity check

	/*

	 * Invalidate ALAT entries, if any, for both registers.

	/*

	 * fr0 & fr1 don't need to be checked because Illegal Instruction

	 * faults have higher priority than unaligned faults.

	 *

	 * r0 cannot be found as the base as it would never generate an

	 * unaligned reference.

	/*

	 * make sure we get clean buffers

	/*

	 * ldfX.a we don't try to emulate anything but we must

	 * invalidate the ALAT entry.

	 * See comments in ldX for descriptions on how the various loads are handled.

		/*

		 * we only do something for x6_op={0,8,9}

		/*

		 * XXX fixme

		 *

		 * A possible optimization would be to drop fpr_final and directly

		 * use the storage from the saved context i.e., the actual final

		 * destination (pt_regs, switch_stack or thread structure).

	/*

	 * check for updates on any loads

	/*

	 * invalidate ALAT entry in case of advanced floating point loads

	/*

	 * make sure we get clean buffers

	/*

	 * if we get to this handler, Nat bits on both r3 and r2 have already

	 * been checked. so we don't need to do it

	 *

	 * extract the value to be stored

	/*

	 * during this step, we extract the spilled registers from the saved

	 * context i.e., we refill. Then we store (no spill) to temporary

	 * aligned location

	/*

	 * stfX [r3]=r2,imm(9)

	 *

	 * NOTE:

	 * ld.r3 can never be r0, because r0 would not generate an

	 * unaligned access.

		/*

		 * form imm9: [12:6] contain first 7bits

		/*

		 * sign extend (8bits) if m set

		/*

		 * ifa == r3 (NaT is necessarily cleared)

	/*

	 * we don't have alat_invalidate_multiple() so we need

	 * to do the complete flush :-<<

/*

 * Make sure we log the unaligned access, so that user/sysadmin can notice it and

 * eventually fix the program.  However, we don't want to do that for every access so we

 * pace it with jiffies.

 we don't support big-endian accesses */

	/*

	 * Treat kernel accesses for which there is an exception handler entry the same as

	 * user-level unaligned accesses.  Otherwise, a clever program could trick this

	 * handler into reading an arbitrary kernel addresses...

 comm[] is at most 16 bytes... */

			/*

			 * Don't call tty_write_message() if we're in the kernel; we might

			 * be holding locks...

 drop '\r' */

 watch for command names containing %s */

	/*

	 * extract the instruction from the bundle given the slot number

	/*

	 * IMPORTANT:

	 * Notice that the switch statement DOES not cover all possible instructions

	 * that DO generate unaligned references. This is made on purpose because for some

	 * instructions it DOES NOT make sense to try and emulate the access. Sometimes it

	 * is WRONG to try and emulate. Here is a list of instruction we don't emulate i.e.,

	 * the program will get a signal and die:

	 *

	 *	load/store:

	 *		- ldX.spill

	 *		- stX.spill

	 *	Reason: RNATs are based on addresses

	 *		- ld16

	 *		- st16

	 *	Reason: ld16 and st16 are supposed to occur in a single

	 *		memory op

	 *

	 *	synchronization:

	 *		- cmpxchg

	 *		- fetchadd

	 *		- xchg

	 *	Reason: ATOMIC operations cannot be emulated properly using multiple

	 *	        instructions.

	 *

	 *	speculative loads:

	 *		- ldX.sZ

	 *	Reason: side effects, code must be ready to deal with failure so simpler

	 *		to let the load fail.

	 * ---------------------------------------------------------------------------------

	 * XXX fixme

	 *

	 * I would like to get rid of this switch case and do something

	 * more elegant.

 oops, really a semaphore op (cmpxchg, etc) */

		/*

		 * The instruction will be retried with deferred exceptions turned on, and

		 * we should get Nat bit installed

		 *

		 * IMPORTANT: When PSR_ED is set, the register & immediate update forms

		 * are actually executed even though the operation failed. So we don't

		 * need to take care of this.

 oops, really a semaphore op (cmpxchg, etc) */

 oops, really a semaphore op (cmpxchg, etc) */

		/*

		 * given today's architecture this case is not likely to happen because a

		 * memory access instruction (M) can never be in the last slot of a

		 * bundle. But let's keep it for now.

 restore original address limit */

 something went wrong... */

 NOT_REACHED */

 SPDX-License-Identifier: GPL-2.0

/*

 * Generate definitions needed by assembly language modules.

 * This code generates raw asm output which is post-processed

 * to extract and format the required data.

 for assembly files which can't include sched.h: */

 used by fsys_gettimeofday in arch/ia64/kernel/fsys.S */

 SPDX-License-Identifier: GPL-2.0

/*

 *  Emulation of the "brl" instruction for IA64 processors that

 *  don't support it in hardware.

 *  Author: Stephan Zeisset, Intel Corp. <Stephan.Zeisset@intel.com>

 *

 *    02/22/02	D. Mosberger	Clear si_flgs, si_isr, and si_imm to avoid

 *				leaking kernel bits.

/*

 *  The unimplemented bits of a virtual address must be set

 *  to the value of the most significant implemented bit.

 *  unimpl_va_mask includes all unimplemented bits and

 *  the most significant implemented bit, so the result

 *  of an and operation with the mask must be all 0's

 *  or all 1's for the address to be valid.

/*

 *  The unimplemented bits of a physical address must be 0.

 *  unimpl_pa_mask includes all unimplemented bits, so the result

 *  of an and operation with the mask must be all 0's for the

 *  address to be valid.

/*

 *  Handle an illegal operation fault that was caused by an

 *  unimplemented "brl" instruction.

 *  If we are not successful (e.g because the illegal operation

 *  wasn't caused by a "brl" after all), we return -1.

 *  If we are successful, we return either 0 or the address

 *  of a "fixup" function for manipulating preserved register

 *  state.

	/*

	 *  Decode the instruction bundle.

 "brl" must be in slot 2. */

 Must be "mlx" template */

			/*

			 *  Long Branch.

				/*

				 *  Qualifying predicate is 0.

				 *  Skip instruction.

			/*

			 *  Long Call.

				/*

				 *  Qualifying predicate is 0.

				 *  Skip instruction.

			/*

			 *  BR[btype] = IP+16

			/*

			 *  AR[PFS].pfm = CFM

			 *  AR[PFS].pec = AR[EC]

			 *  AR[PFS].ppl = PSR.cpl

			/*

			 *  CFM.sof -= CFM.sol

			 *  CFM.sol = 0

			 *  CFM.sor = 0

			 *  CFM.rrb.gr = 0

			 *  CFM.rrb.fr = 0

			 *  CFM.rrb.pr = 0

			/*

			 *  Unknown opcode.

		/*

		 *  The target address contains unimplemented bits.

		/*

		 *  Branch Tracing is enabled.

		 *  Force a taken branch signal.

		/*

		 *  Single Step is enabled.

		 *  Force a trace signal.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * OpRegion handler to allow AML to call native firmware

 *

 * (c) Copyright 2007 Hewlett-Packard Development Company, L.P.

 *	Bjorn Helgaas <bjorn.helgaas@hp.com>

 *

 * This driver implements HP Open Source Review Board proposal 1842,

 * which was approved on 9/20/2006.

 *

 * For technical documentation, see the HP SPPA Firmware EAS, Appendix F.

 *

 * ACPI does not define a mechanism for AML methods to call native firmware

 * interfaces such as PAL or SAL.  This OpRegion handler adds such a mechanism.

 * After the handler is installed, an AML method can call native firmware by

 * storing the arguments and firmware entry point to specific offsets in the

 * OpRegion.  When AML reads the "return value" offset from the OpRegion, this

 * handler loads up the arguments, makes the firmware call, and returns the

 * result.

/*

 * N.B.  The layout of this structure is defined in the HP SPPA FW EAS, and

 *	 the member offsets are embedded in AML methods.

	/*

	 * We would normally allocate a new context structure and install

	 * the address space handler for the specific device we found.

	 * But the HP-UX implementation shares a single global context

	 * and always puts the handler at the root, so we'll do the same.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

**  IA64 System Bus Adapter (SBA) I/O MMU manager

**

**	(c) Copyright 2002-2005 Alex Williamson

**	(c) Copyright 2002-2003 Grant Grundler

**	(c) Copyright 2002-2005 Hewlett-Packard Company

**

**	Portions (c) 2000 Grant Grundler (from parisc I/O MMU code)

**	Portions (c) 1999 Dave S. Miller (from sparc64 I/O MMU code)

**

**

**

** This module initializes the IOC (I/O Controller) found on HP

** McKinley machines and their successors.

**

 hweight64() */

 ia64_get_itc() */

 PAGE_OFFSET */

/*

** Enabling timing search of the pdir resource map.  Output in /proc.

** Disabled by default to optimize performance.

/*

** This option allows cards capable of 64bit DMA to bypass the IOMMU.  If

** not defined, all DMA will be 32bit and go through the TLB.

** There's potentially a conflict in the bio merge code with us

** advertising an iommu, but then bypassing it.  Since I/O MMU bypassing

** appears to give more performance than bio-level virtual merging, we'll

** do the former for now.  NOTE: BYPASS_SG also needs to be undef'd to

** completely restrict DMA to the IOMMU.

/*

** This option specifically allows/disallows bypassing scatterlists with

** multiple entries.  Coalescing these entries can allow better DMA streaming

** and in some cases shows better performance than entirely bypassing the

** IOMMU.  Performance increase on the order of 1-2% sequential output/input

** using bonnie++ on a RAID0 MD device (sym2 & mpt).

/*

** If a device prefetches beyond the end of a valid pdir entry, it will cause

** a hard failure, ie. MCA.  Version 3.0 and later of the zx1 LBA should

** disconnect on 4k boundaries and prevent such issues.  If the device is

** particularly aggressive, this option will keep the entire pdir valid such

** that prefetching will hit a valid address.  This could severely impact

** error containment, and is therefore off by default.  The page that is

** used for spill-over is poisoned, so that should help debugging somewhat.

/*

** The number of debug flags is a clue - this code is fragile.  NOTE: since

** tightening the use of res_lock the resource bitmap and actual pdir are no

** longer guaranteed to stay in sync.  The sanity checking code isn't going to

** like that.

 #define SBA_INLINE */

/*

** The number of pdir entries to "free" before issuing

** a read to PCOM register to flush out PCOM writes.

** Interacts with allocation granularity (ie 4 or 8 entries

** allocated and free'd/purged at a time might make this

** less interesting).

 ACPI reports SBA, we want IOC */

 function class, bist, header, rev... */

 IO TLB */

 Allow "Relaxed Ordering" */

 AGP GART driver looks for this */

/*

** The zx1 IOC supports 4/8/16/64KB page sizes (see TCNFG register)

**

** Some IOCs (sx1000) can run at the above pages sizes, but are

** really only supported using the IOC at a 4k page size.

**

** iovp_size could only be greater than PAGE_SIZE if we are

** confident the drivers really only touch the next physical

** page iff that driver instance owns it.

 I/O MMU base address */

 resource map, bit == pdir entry */

 physical base address */

 pdir IOV Space base */

 pdir IOV Space mask */

 next avail IOVP - circular search */

 protects the resource bitmap, but must be held when */

 clearing pdir to prevent races with allocations. */

 from the RIGHT! */

 size of resource map in bytes */

 node where this IOC lives */

 may want to try to get this on a separate cacheline */

 than res_lock for bigger systems. */

 current index into avg_search */

 Stuff we don't need in performance path */

 list of IOC's in system */

 for multiple IOC's */

 HW revision of chip */

 in bytes, determined by IOV Space size */

/*

** DMA_CHUNK_SIZE is used by the SCSI mid-layer to break up

** (or rather not merge) DMAs into manageable chunks.

** On parisc, this is more of the software/tuning constraint

** rather than the HW. I/O MMU allocation algorithms can be

** faster with smaller sizes (to some degree).

/************************************

** SBA register read and write support

**

** BE WARNED: register writes are posted.

**  (ie follow writes which must reach HW with a read)

**

/**

 * sba_dump_tlb - debugging only - print IOMMU operating parameters

 * @hpa: base address of the IOMMU

 *

 * Print the size/location of the IO MMU PDIR.

/**

 * sba_dump_pdir_entry - debugging only - print one IOMMU PDIR entry

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @msg: text to print ont the output line.

 * @pide: pdir index.

 *

 * Print one entry of the IO MMU PDIR in human readable form.

 start printing from lowest pde in rval */

/**

 * sba_check_pdir - debugging only - consistency checker

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @msg: text to print ont the output line.

 *

 * Verify the resource map and pdir state is consistent

 resource map ptr */

 pdir ptr */

 number of bits we might check */

 Get last byte and highest bit from that */

				/*

				** BUMMER!  -- res_map != pdir --

				** Dump rval and matching pdir entries

 try the next bit */

 look at next word of res_map */

 It'd be nice if we always got here :^) */

/**

 * sba_dump_sg - debugging only - print Scatter-Gather list

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @startsg: head of the SG list

 * @nents: number of entries in SG list

 *

 * print the SG list so we can verify it's correct by hand.

 ASSERT_PDIR_SANITY */

/**************************************************************

*

*   I/O Pdir Resource Management

*

*   Bits set in the resource map are in use.

*   Each bit can represent a number of pages.

*   LSbs represent lower addresses (IOVA's).

*

 could increase this to 4 or 8 if needed */

 Convert from IOVP to IOVA and vice versa. */

/**

 * For most cases the normal get_order is sufficient, however it limits us

 * to PAGE_SIZE being the minimum mapping alignment and TC flush granularity.

 * It only incurs about 1 clock cycle to use this one with the static variable

 * and makes the code more intuitive.

/**

 * sba_search_bitmap - find free space in IO PDIR resource bitmap

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @bits_wanted: number of entries we need.

 * @use_hint: use res_hint to indicate where to start looking

 *

 * Find consecutive free bits in resource bitmap.

 * Each bit represents one entry in the IO Pdir.

 * Cool perf optimization: search for log2(size) bits at a time.

 Allow caller to force a search through the entire resource space */

	/*

	 * N.B.  REO/Grande defect AR2305 can cause TLB fetch timeouts

	 * if a TLB entry is purged while in use.  sba_mark_invalid()

	 * purges IOTLB entries in power-of-two sizes, so we also

	 * allocate IOVA space in power-of-two sizes.

		/*

		** Search the resource bit map on well-aligned values.

		** "o" is the alignment.

		** We need the alignment to invalidate I/O TLB using

		** SBA HW features in the unmap path.

 mark resources busy! */

 /64 */

 Found it, mark it */

/**

 * sba_alloc_range - find free bits and mark them in IO PDIR resource bitmap

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @size: number of bytes to create a mapping for

 *

 * Given a size, find consecutive unmarked and then mark those bits in the

 * resource bit map.

	/*

	** "seek and ye shall find"...praying never hurts either...

			/*

			** With delayed resource freeing, we can give this one more shot.  We're

			** getting close to being in trouble here, so do what we can to make this

			** one count.

 flush purges */

 verify the first enable bit is clear */

/**

 * sba_free_range - unmark bits in IO PDIR resource bitmap

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @iova: IO virtual address which was previously allocated.

 * @size: number of bytes to create a mapping for

 *

 * clear bits in the ioc's resource map

 convert bit to byte address */

 Round up to power-of-two size: see AR2305 note above */

 these mappings start 64bit aligned */

 3-bits "bit" address plus 2 (or 3) bits for "byte" == bit in word */

 verify same bits are set */

/**************************************************************

*

*   "Dynamic DMA Mapping" support (aka "Coherent I/O")

*

/**

 * sba_io_pdir_entry - fill in one IO PDIR entry

 * @pdir_ptr:  pointer to IO PDIR entry

 * @vba: Virtual CPU address of buffer to map

 *

 * SBA Mapping Routine

 *

 * Given a virtual address (vba, arg1) sba_io_pdir_entry()

 * loads the I/O PDIR entry pointed to by pdir_ptr (arg0).

 * Each IO Pdir entry consists of 8 bytes as shown below

 * (LSB == bit 0):

 *

 *  63                    40                                 11    7        0

 * +-+---------------------+----------------------------------+----+--------+

 * |V|        U            |            PPN[39:12]            | U  |   FF   |

 * +-+---------------------+----------------------------------+----+--------+

 *

 *  V  == Valid Bit

 *  U  == Unused

 * PPN == Physical Page Number

 *

 * The physical address fields are filled with the results of virt_to_phys()

 * on the vba.

/**

 * Since DMA is i-cache coherent, any (complete) pages that were written via

 * DMA can be marked as "clean" so that lazy_mmu_prot_update() doesn't have to

 * flush them when they get mapped into an executable vm-area.

/**

 * sba_mark_invalid - invalidate one or more IO PDIR entries

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @iova:  IO Virtual Address mapped earlier

 * @byte_cnt:  number of bytes this mapping covers.

 *

 * Marking the IO PDIR entry(ies) as Invalid and invalidate

 * corresponding IO TLB entry. The PCOM (Purge Command Register)

 * is to purge stale entries in the IO TLB when unmapping entries.

 *

 * The PCOM register supports purging of multiple pages, with a minium

 * of 1 page and a maximum of 2GB. Hardware requires the address be

 * aligned to the size of the range being purged. The size of the range

 * must be a power of 2. The "Cool perf optimization" in the

 * allocation routine helps keep that true.

 Must be non-zero and rounded up */

 Assert first pdir entry is set */

 set "size" field for PCOM */

		/*

		** clear I/O PDIR entry "valid" bit

		** Do NOT clear the rest - save it for debugging.

		** We should only clear bits that have previously

		** been enabled.

		/*

  		** If we want to maintain the PDIR as valid, put in

		** the spill page so devices prefetching won't

		** cause a hard fail.

 2GB! Max value of "size" field */

 verify this pdir entry is enabled */

 clear I/O Pdir entry "valid" bit first */

/**

 * sba_map_page - map one buffer and return IOVA for DMA

 * @dev: instance of PCI owned by the driver that's asking.

 * @page: page to map

 * @poff: offset into page

 * @size: number of bytes to map

 * @dir: dma direction

 * @attrs: optional dma attributes

 *

 * See Documentation/core-api/dma-api-howto.rst

	/*

 	** Check if the PCI device can DMA to ptr... if so, just return ptr

		/*

 		** Device is bit capable of DMA'ing to the buffer...

		** just return the PCI address of ptr

 save offset bits */

 round up to nearest iovp_size */

 verify availability */

 force pdir update */

 form complete address */

/**

 * sba_unmap_page - unmap one IOVA and free resources

 * @dev: instance of PCI owned by the driver that's asking.

 * @iova:  IOVA of driver buffer previously mapped.

 * @size:  number of bytes mapped in driver buffer.

 * @dir:  R/W or both.

 * @attrs: optional dma attributes

 *

 * See Documentation/core-api/dma-api-howto.rst

		/*

		** Address does not fall w/in IOVA, must be bypassing

 clear offset bits */

 flush purges */

 DELAYED_RESOURCE_CNT == 0 */

 flush purges */

 DELAYED_RESOURCE_CNT == 0 */

/**

 * sba_alloc_coherent - allocate/map shared mem for DMA

 * @dev: instance of PCI owned by the driver that's asking.

 * @size:  number of bytes mapped in driver buffer.

 * @dma_handle:  IOVA of new buffer.

 *

 * See Documentation/core-api/dma-api-howto.rst

	/*

 	** Check if the PCI device can DMA to ptr... if so, just return ptr

	/*

	 * If device can't bypass or bypass is disabled, pass the 32bit fake

	 * device to map single to get an iova mapping.

/**

 * sba_free_coherent - free/unmap shared mem for DMA

 * @dev: instance of PCI owned by the driver that's asking.

 * @size:  number of bytes mapped in driver buffer.

 * @vaddr:  virtual address IOVA of "consistent" buffer.

 * @dma_handler:  IO virtual address of "consistent" buffer.

 *

 * See Documentation/core-api/dma-api-howto.rst

/*

** Since 0 is a valid pdir_base index value, can't use that

** to determine if a value is valid or not. Use a flag to indicate

** the SG list entry contains a valid pdir index.

/**

 * sba_fill_pdir - write allocated SG entries into IO PDIR

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @startsg:  list of IOVA/size pairs

 * @nents: number of entries in startsg list

 *

 * Take preprocessed SG list and write corresponding entries

 * in the IO PDIR.

 pointer to current DMA */

		/*

		** Look for the start of a new DMA stream

		/*

		** Look for a VCONTIG chunk

			/* Since multiple Vcontig blocks could make up

			** one DMA stream, *add* cnt to dma_len.

 only want offset on first chunk */

 force pdir update */

/*

** Two address ranges are DMA contiguous *iff* "end of prev" and

** "start of next" are both on an IOV page boundary.

**

** (shift left is a quick trick to mask off upper bits)

/**

 * sba_coalesce_chunks - preprocess the SG list

 * @ioc: IO MMU structure which owns the pdir we are interested in.

 * @startsg:  list of IOVA/size pairs

 * @nents: number of entries in startsg list

 *

 * First pass is to walk the SG list and determine where the breaks are

 * in the DMA stream. Allocates PDIR entries but does not fill them.

 * Returns the number of DMA chunks.

 *

 * Doing the fill separate from the coalescing/allocation keeps the

 * code simpler. Future enhancement could make one pass through

 * the sglist do both.

 VCONTIG chunk head */

 len of VCONTIG chunk */

 next DMA stream head */

 start/len of DMA stream */

		/*

		** Prepare for first/next DMA stream

 PARANOID: clear entries */

		/*

		** This loop terminates one iteration "early" since

		** it's always looking one "ahead".

 tmp */

 PARANOID */

 catch brokenness in SCSI layer */

			/*

			** First make sure current dma stream won't

			** exceed DMA_CHUNK_SIZE if we coalesce the

			** next entry.

			/*

			** Then look for virtually contiguous blocks.

			**

			** append the next transaction?

			/*

			** Not virtually contiguous.

			** Terminate prev chunk.

			** Start a new chunk.

			**

			** Once we start a new VCONTIG chunk, dma_offset

			** can't change. And we need the offset from the first

			** chunk - not the last one. Ergo Successive chunks

			** must start on page boundaries and dove tail

			** with it's predecessor.

			/*

			** 3) do the entries end/start on page boundaries?

			**    Don't update vcontig_end until we've checked.

		/*

		** End of DMA Stream

		** Terminate last VCONTIG block.

		** Allocate space for DMA stream.

/**

 * sba_map_sg - map Scatter/Gather list

 * @dev: instance of PCI owned by the driver that's asking.

 * @sglist:  array of buffer/length pairs

 * @nents:  number of entries in list

 * @dir:  R/W or both.

 * @attrs: optional dma attributes

 *

 * See Documentation/core-api/dma-api-howto.rst

 Fast path single entry scatterlists. */

	/*

	** First coalesce the chunks and allocate I/O pdir space

	**

	** If this is one DMA stream, we can properly map using the

	** correct virtual address associated with each DMA page.

	** w/o this association, we wouldn't have coherent DMA!

	** Access to the virtual address is what forces a two pass algorithm.

	/*

	** Program the I/O Pdir

	**

	** map the virtual addresses to the I/O Pdir

	** o dma_address will contain the pdir index

	** o dma_len will contain the number of bytes to map

	** o address contains the virtual address.

/**

 * sba_unmap_sg_attrs - unmap Scatter/Gather list

 * @dev: instance of PCI owned by the driver that's asking.

 * @sglist:  array of buffer/length pairs

 * @nents:  number of entries in list

 * @dir:  R/W or both.

 * @attrs: optional dma attributes

 *

 * See Documentation/core-api/dma-api-howto.rst

/**************************************************************

*

*   Initialization and claim

*

	/*

	** Firmware programs the base and size of a "safe IOVA space"

	** (one that doesn't overlap memory or LMMIO space) in the

	** IBASE and IMASK registers.

	/*

	** If an AGP device is present, only use half of the IOV space

	** for PCI DMA.  Unfortunately we can't know ahead of time

	** whether GART support will actually be used, for now we

	** can just key on an AGP device found in the system.

	** We program the next pdir index after we stop w/ a key for

	** the GART code to handshake on.

	/*

  	** Check to see if the spill page has been allocated, we don't need more than

	** one across multiple SBAs.

	/*

  	** Set all the PDIR entries valid w/ the spill page as the target

 Clear I/O TLB of any possible entries */

 Enable IOVA translation */

 resource map size dictated by pdir_size */

 entries */

 convert bit count to byte count */

 next available IOVP - circular search */

 Mark first bit busy - ie no IOVA 0 */

 Mark the last resource used so we don't prefetch beyond IOVA space */

 res_map is chars */

	/*

	 * pci_alloc_coherent() must return a DMA address which is

	 * SAC (single address cycle) addressable, so allocate a

	 * pseudo-device to enforce that.

 38 bit memory controller + extra bit for range displaced by MMIO */

	/*

	** Clear ROPE(N)_CONFIG AO bit.

	** Disables "NT Ordering" (~= !"Relaxed Ordering")

	** Overrides bit 1 in DMA Hint Sets.

	** Improves netperf UDP_STREAM by ~10% for tg3 on bcm5701.

 conservative */

/**************************************************************************

**

**   SBA initialization code (HW and SW)

**

**   o identify SBA chip itself

**   o FIXME: initialize DMA hints for reasonable defaults

**

	/*

	 * The IOC scope encloses PCI root bridges in the ACPI

	 * namespace, so work our way out until we find an IOC we

	 * claimed previously.

	/*

	 * For HWP0001, only SBA appears in ACPI namespace.  It encloses the PCI

	 * root bridges, and its CSR space includes the IOC function.

 zx1 based systems default to kernel page size iommu pages */

	/*

	 * default anything not caught above or specified on cmdline to 4k

	 * iommu page size

 setup NUMA node association */

 This has to run before acpi_scan_init(). */

 make sure it's at least 32bit capable */

	/*

	 * If we are booting a kdump kernel, the sba_iommu will cause devices

	 * that were not shutdown properly to MCA as soon as they are turned

	 * back on.  Our only option for a successful kdump kernel boot is to

	 * use swiotlb.

	/*

	 * ioc_found should be populated by the acpi_sba_ioc_handler's .attach()

	 * routine, but that only happens if acpi_scan_init() has already run.

 no need for swiotlb with the iommu */

 must be initialized after ACPI etc., but before any drivers... */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copy data from IO memory space to "real" memory space.

 * This needs to be optimized.

/*

 * Copy data from "real" memory space to IO memory space.

 * This needs to be optimized.

/*

 * "memset" on IO memory space.

 * This needs to be optimized.

 SPDX-License-Identifier: GPL-2.0

/*

 * Network Checksum & Copy routine

 *

 * Copyright (C) 1999, 2003-2004 Hewlett-Packard Co

 *	Stephane Eranian <eranian@hpl.hp.com>

 *

 * Most of the code has been imported from Linux/Alpha

/*

 * XXX Fixme: those 2 inlines are meant for debugging and will go away

 add up 32-bit words for 33 bits */

 add up 16-bit and 17-bit words for 17+c bits */

 add up 16-bit and 2-bit for 16+c bit */

 add up carry.. */

 nr of 16-bit words.. */

 nr of 32-bit words.. */

 nr of 64-bit words.. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Network checksum routines

 *

 * Copyright (C) 1999, 2003 Hewlett-Packard Co

 *	Stephane Eranian <eranian@hpl.hp.com>

 *

 * Most of the code coming from arch/alpha/lib/checksum.c

 *

 * This file contains network checksum routines that are better done

 * in an architecture-specific manner due to speed..

 add up 32-bit words for 33 bits */

 add up 16-bit and 17-bit words for 17+c bits */

 add up 16-bit and 2-bit for 16+c bit */

 add up carry.. */

/*

 * computes the checksum of the TCP/UDP pseudo-header

 * returns a 16-bit checksum, already complemented.

 Fold down to 32-bits so we don't lose in the typedef-less network stack.  */

 64 to 33 */

 33 to 32 */

/*

 * computes the checksum of a memory block at buff, length len,

 * and adds in "sum" (32-bit)

 *

 * returns a 32-bit number suitable for feeding into itself

 * or csum_tcpudp_magic

 *

 * this function must be called with even lengths, except

 * for the last fragment, which may be odd

 *

 * it's best to have buff aligned on a 32-bit boundary

 add in old sum, and carry.. */

 32+c bits -> 32 bits */

/*

 * this routine is used for miscellaneous IP-like checksums, mainly

 * in icmp.c

 SPDX-License-Identifier: GPL-2.0-only

/*

 * pci.c - Low-Level PCI Access in IA-64

 *

 * Derived from bios32.c of i386 tree.

 *

 * (c) Copyright 2002, 2005 Hewlett-Packard Development Company, L.P.

 *	David Mosberger-Tang <davidm@hpl.hp.com>

 *	Bjorn Helgaas <bjorn.helgaas@hp.com>

 * Copyright (C) 2004 Silicon Graphics, Inc.

 *

 * Note: Above list of copyright holders is incomplete...

/*

 * Low-level SAL-based PCI configuration access functions. Note that SAL

 * calls are already serialized (via sal_lock), so we don't need another

 * synchronization mechanism here.

 SAL 3.2 adds support for extended config space. */

 legacy I/O port space */

	/*

	 * The SDM guarantees the legacy 0-64K space is sparse, but if the

	 * mapping is done by the processor (not the bridge), ACPI may not

	 * mark it as sparse.

/*

 * An IO port or MMIO resource assigned to a PCI host bridge may be

 * consumed by the host bridge itself or available to its child

 * bus/devices. The ACPI specification defines a bit (Producer/Consumer)

 * to tell whether the resource is consumed by the host bridge itself,

 * but firmware hasn't used that bit consistently, so we can't rely on it.

 *

 * On x86 and IA64 platforms, all IO port and MMIO resources are assumed

 * to be available to child bus/devices except one special case:

 *     IO port [0xCF8-0xCFF] is consumed by the host bridge itself

 *     to access PCI configuration space.

 *

 * So explicitly filter out PCI CFG IO ports[0xCF8-0xCFF].

				/*

				 * HP's firmware has a hack to work around a

				 * Windows bug. Ignore these tiny memory ranges.

	/*

	 * We pass NULL as parent to pci_create_root_bus(), so if it is not NULL

	 * here, pci_create_root_bus() has been called by someone else and

	 * sysdata is likely to be different from what we expect.  Let it go in

	 * that case.

/*

 *  Called after each bus is probed, but before its children are examined.

 No special bus mastering setup handling */

/**

 * pci_get_legacy_mem - generic legacy mem routine

 * @bus: bus to get legacy memory base address for

 *

 * Find the base of legacy memory for @bus.  This is typically the first

 * megabyte of bus address space for @bus or is simply 0 on platforms whose

 * chipsets support legacy I/O and memory routing.  Returns the base address

 * or an error pointer if an error occurred.

 *

 * This is the ia64 generic version of this routine.  Other platforms

 * are free to override it with a machine vector.

/**

 * pci_mmap_legacy_page_range - map legacy memory space to userland

 * @bus: bus whose legacy space we're mapping

 * @vma: vma passed in by mmap

 *

 * Map legacy memory space for this device back to userspace using a machine

 * vector to get the base address.

 We only support mmap'ing of legacy memory space */

	/*

	 * Avoid attribute aliasing.  See Documentation/ia64/aliasing.rst

	 * for more details.

/**

 * pci_legacy_read - read from legacy I/O space

 * @bus: bus to read

 * @port: legacy port value

 * @val: caller allocated storage for returned value

 * @size: number of bytes to read

 *

 * Simply reads @size bytes from @port and puts the result in @val.

 *

 * Again, this (and the write routine) are generic versions that can be

 * overridden by the platform.  This is necessary on platforms that don't

 * support legacy I/O routing or that hard fail on legacy I/O timeouts.

/**

 * pci_legacy_write - perform a legacy I/O write

 * @bus: bus pointer

 * @port: port to write

 * @val: value to write

 * @size: number of bytes to write from @val

 *

 * Simply writes @size bytes of @val to @port.

/**

 * set_pci_cacheline_size - determine cacheline size for PCI devices

 *

 * We want to use the line-size of the outer-most cache.  We assume

 * that this line-size is the same for all CPUs.

 *

 * Code mostly taken from arch/ia64/kernel/palinfo.c:cache_info().

 cache_type (data_or_unified)= */ 2, &cci);

 SPDX-License-Identifier: GPL-2.0

/*

 * Exceptions for specific devices. Usually work-arounds for fatal design flaws.

 * Derived from fixup.c of i386 tree.

/*

 * Fixup to mark boot BIOS video selected by BIOS before it changes

 *

 * From information provided by "Jon Smirl" <jonsmirl@gmail.com>

 *

 * The standard boot ROM sequence for an x86 machine uses the BIOS

 * to select an initial video card for boot display. This boot video

 * card will have its BIOS copied to 0xC0000 in system RAM.

 * IORESOURCE_ROM_SHADOW is used to associate the boot video

 * card with this copy. On laptops this copy has to be used since

 * the main ROM may be compressed or combined with another image.

 * See pci_map_rom() for use of this flag. Before marking the device

 * with IORESOURCE_ROM_SHADOW check if a vga_default_device is already set

 * by either arch code or vga-arbitration; if so only apply the fixup to this

 * already-determined primary video card.

 Maybe, this machine supports legacy memory map. */

 Is VGA routed to us? */

		/*

		 * From information provided by

		 * "David Miller" <davem@davemloft.net>

		 * The bridge control register is valid for PCI header

		 * type BRIDGE, or CARDBUS. Host to PCI controllers use

		 * PCI header type NORMAL.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * AXS101/AXS103 Software Development Platform

 *

 * Copyright (C) 2013-15 Synopsys, Inc. (www.synopsys.com)

	/*

	 * Peripherals on CPU Card and Mother Board are wired to cpu intc via

	 * intermediate DW APB GPIO blocks (mainly for debouncing)

	 *

	 *         ---------------------

	 *        |  snps,arc700-intc |

	 *        ---------------------

	 *          | #7          | #15

	 * -------------------   -------------------

	 * | snps,dw-apb-gpio |  | snps,dw-apb-gpio |

	 * -------------------   -------------------

	 *        | #12                     |

	 *        |                 [ Debug UART on cpu card ]

	 *        |

	 * ------------------------

	 * | snps,dw-apb-intc (MB)|

	 * ------------------------

	 *  |      |       |      |

	 * [eth] [uart]        [... other perip on Main Board]

	 *

	 * Current implementation of "irq-dw-apb-ictl" driver doesn't work well

	 * with stacked INTCs. In particular problem happens if its master INTC

	 * not yet instantiated. See discussion here -

	 * https://lkml.org/lkml/2015/3/4/755

	 *

	 * So setup the first gpio block as a passive pass thru and hide it from

	 * DT hardware topology - connect MB intc directly to cpu intc

	 * The GPIO "wire" needs to be init nevertheless (here)

	 *

	 * One side adv is that peripheral interrupt handling avoids one nested

	 * intc ISR hop

 Determine motherboard version */

 HT-3 (rev3.0) */

 HT-2 (rev2.0) */

/*

 * Set up System Memory Map for ARC cpu / peripherals controllers

 *

 * Each AXI master has a 4GB memory map specified as 16 apertures of 256MB, each

 * of which maps to a corresponding 256MB aperture in Target slave memory map.

 *

 * e.g. ARC cpu AXI Master's aperture 8 (0x8000_0000) is mapped to aperture 0

 * (0x0000_0000) of DDR Port 0 (slave #1)

 *

 * Access from cpu to MB controllers such as GMAC is setup using AXI Tunnel:

 * which has master/slaves on both ends.

 * e.g. aperture 14 (0xE000_0000) of ARC cpu is mapped to aperture 14

 * (0xE000_0000) of CPU Card AXI Tunnel slave (slave #3) which is mapped to

 * MB AXI Tunnel Master, which also has a mem map setup

 *

 * In the reverse direction, MB AXI Masters (e.g. GMAC) mem map is setup

 * to map to MB AXI Tunnel slave which connects to CPU Card AXI Tunnel Master

 CPU Card target slaves */

 MB AXI Target slaves */

 MB AXI masters */

/*

 * memmap for ARC core on CPU Card

 0x2000_0000: Local SRAM */

 0x8000_0000: DDR   0..256M */

 0x9000_0000: DDR 256..512M */

 MB: CREG, CGU... */

 CPU Card local CREG, CGU... */

/*

 * memmap for CPU Card AXI Tunnel Master (for access by MB controllers)

 * GMAC (MB) -> MB AXI Tunnel slave -> CPU Card AXI Tunnel Master -> DDR

/*

 * memmap for MB AXI Masters

 * Same mem map for all perip controllers as well as MB AXI Tunnel Master

 DDR on CPU Card */

 DDR on CPU Card */

 MB Local CREG, CGU... */

 SLV0 */

 OFFSET0 */

 SLV1 */

 OFFSET1 */

 ARC 770D memory view */

 AXI tunnel memory map (incoming traffic from MB into CPU Card */

 MB peripherals memory map */

 Update */

 GPIO pins 18 and 19 are used as UART rx and tx, respectively. */

 Set up the MB interrupt system: mux interrupts to GPIO7) */

 reset ethernet and ULPI interfaces */

 map GPIO 14:10 to ARC 9:5 (IRQ mux change for MB v2 onwards) */

 CONFIG_AXS101 */

	/*

	 * AXS103 configurations for SMP/QUAD configurations share device tree

	 * which defaults to 100 MHz. However recent failures of Quad config

	 * revealed P&R timing violations so clamp it down to safe 50 MHz

	 * Instead of duplicating defconfig/DT for SMP/QUAD, add a small hack

	 * of fudging the freq in DT

 Patching .dtb in-place with new core clock value */

 Memory maps already config in pre-bootloader */

 set GPIO mux to UART */

 Set up the AXS_MB interrupt system.*/

 connect ICTL - Main Board with GPIO line */

 CONFIG_AXS101 */

/*

 * For the VDK OS-kit, to get the offset to pid and command fields

 CONFIG_AXS103 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARC HSDK Platform support code

 *

 * Copyright (C) 2017 Synopsys, Inc. (www.synopsys.com)

	/*

	 * Peripherals on CPU Card are wired to cpu intc via intermediate

	 * DW APB GPIO blocks (mainly for debouncing)

	 *

	 *         ---------------------

	 *        |  snps,archs-intc  |

	 *        ---------------------

	 *                  |

	 *        ----------------------

	 *        | snps,archs-idu-intc |

	 *        ----------------------

	 *         |   |     |   |    |

	 *         | [eth] [USB]    [... other peripherals]

	 *         |

	 * -------------------

	 * | snps,dw-apb-intc |

	 * -------------------

	 *  |      |   |   |

	 * [Bt] [HAPS]   [... other peripherals]

	 *

	 * Current implementation of "irq-dw-apb-ictl" driver doesn't work well

	 * with stacked INTCs. In particular problem happens if its master INTC

	 * not yet instantiated. See discussion here -

	 * https://lkml.org/lkml/2015/3/4/755

	 *

	 * So setup the first gpio block as a passive pass thru and hide it from

	 * DT hardware topology - connect intc directly to cpu intc

	 * The GPIO "wire" needs to be init nevertheless (here)

	 *

	 * One side adv is that peripheral interrupt handling avoids one nested

	 * intc ISR hop

	 *

	 * According to HSDK User's Manual [1], "Table 2 Interrupt Mapping"

	 * we have the following GPIO input lines used as sources of interrupt:

	 * - GPIO[0] - Bluetooth interrupt of RS9113 module

	 * - GPIO[2] - HAPS interrupt (on HapsTrak 3 connector)

	 * - GPIO[3] - Audio codec (MAX9880A) interrupt

	 * - GPIO[8-23] - Available on Arduino and PMOD_x headers

	 * For now there's no use of Arduino and PMOD_x headers in Linux

	 * use-case so we only enable lines 0, 2 and 3.

	 *

	 * [1] https://github.com/foss-for-synopsys-dwc-arc-processors/ARC-Development-Systems-Forum/wiki/docs/ARC_HSDK_User_Guide.pdf

 need to remove "dma-coherent" property */

 need to set "dma-coherent" property */

/*

 * This is modified configuration of AXI bridge. Default settings

 * are specified in "Table 111 CREG Address Decoder register reset values".

 *

 * AXI_M_m_SLV{0|1} - Slave Select register for master 'm'.

 * Possible slaves are:

 *  - 0  => no slave selected

 *  - 1  => DDR controller port #1

 *  - 2  => SRAM controller

 *  - 3  => AXI tunnel

 *  - 4  => EBI controller

 *  - 5  => ROM controller

 *  - 6  => AXI2APB bridge

 *  - 7  => DDR controller port #2

 *  - 8  => DDR controller port #3

 *  - 9  => HS38x4 IOC

 *  - 10 => HS38x4 DMI

 * AXI_M_m_OFFSET{0|1} - Addr Offset register for master 'm'

 *

 * Please read ARC HS Development IC Specification, section 17.2 for more

 * information about apertures configuration.

 *

 * m	master		AXI_M_m_SLV0	AXI_M_m_SLV1	AXI_M_m_OFFSET0	AXI_M_m_OFFSET1

 * 0	HS (CBU)	0x11111111	0x63111111	0xFEDCBA98	0x0E543210

 * 1	HS (RTT)	0x77777777	0x77777777	0xFEDCBA98	0x76543210

 * 2	AXI Tunnel	0x88888888	0x88888888	0xFEDCBA98	0x76543210

 * 3	HDMI-VIDEO	0x77777777	0x77777777	0xFEDCBA98	0x76543210

 * 4	HDMI-ADUIO	0x77777777	0x77777777	0xFEDCBA98	0x76543210

 * 5	USB-HOST	0x77777777	0x77999999	0xFEDCBA98	0x76DCBA98

 * 6	ETHERNET	0x77777777	0x77999999	0xFEDCBA98	0x76DCBA98

 * 7	SDIO		0x77777777	0x77999999	0xFEDCBA98	0x76DCBA98

 * 8	GPU		0x77777777	0x77777777	0xFEDCBA98	0x76543210

 * 9	DMAC (port #1)	0x77777777	0x77777777	0xFEDCBA98	0x76543210

 * 10	DMAC (port #2)	0x77777777	0x77777777	0xFEDCBA98	0x76543210

 * 11	DVFS		0x00000000	0x60000000	0x00000000	0x00000000

	/*

	 * Don't tweak memory bridge configuration if we failed to tweak DTB

	 * as we will end up in a inconsistent state.

	/*

	 * M_HS_CORE has one unique register - BOOT.

	 * We need to clean boot mirror (BOOT[1:0]) bits in them to avoid first

	 * aperture to be masked by 'boot mirror'.

	/*

	 * PAE remapping for DMA clients does not work due to an RTL bug, so

	 * CREG_PAE register must be programmed to all zeroes, otherwise it

	 * will cause problems with DMA to/from peripherals even if PAE40 is

	 * not used.

	/*

	 * Switch SDIO external ciu clock divider from default div-by-8 to

	 * minimum possible div-by-2.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2015 Synopsys, Inc. (www.synopsys.com)

/*

 * HIGHMEM API:

 *

 * kmap() API provides sleep semantics hence referred to as "permanent maps"

 * It allows mapping LAST_PKMAP pages, using @last_pkmap_nr as the cursor

 * for book-keeping

 *

 * kmap_atomic() can't sleep (calls pagefault_disable()), thus it provides

 * shortlived ala "temporary mappings" which historically were implemented as

 * fixmaps (compile time addr etc). Their book-keeping is done per cpu.

 *

 *	Both these facts combined (preemption disabled and per-cpu allocation)

 *	means the total number of concurrent fixmaps will be limited to max

 *	such allocations in a single control path. Thus KM_TYPE_NR (another

 *	historic relic) is a small'ish number which caps max percpu fixmaps

 *

 * ARC HIGHMEM Details

 *

 * - the kernel vaddr space from 0x7z to 0x8z (currently used by vmalloc/module)

 *   is now shared between vmalloc and kmap (non overlapping though)

 *

 * - Both fixmap/pkmap use a dedicated page table each, hooked up to swapper PGD

 *   This means each only has 1 PGDIR_SIZE worth of kvaddr mappings, which means

 *   2M of kvaddr space for typical config (8K page and 11:8:13 traversal split)

 *

 * - The fixed KMAP slots for kmap_local/atomic() require KM_MAX_IDX slots per

 *   CPU. So the number of CPUs sharing a single PTE page is limited.

 *

 * - pkmap being preemptible, in theory could do with more than 256 concurrent

 *   mappings. However, generic pkmap code: map_new_virtual(), doesn't traverse

 *   the PGD and only works with a single page table @pkmap_page_table, hence

 *   sets the limit

 Due to recursive include hell, we can't do this in processor.h */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

/*

 * ARCH specific callbacks for generic noncoherent DMA ops

 *  - hardware IOC not available (or "dma-coherent" not set for device in DT)

 *  - But still handle both coherent and non-coherent requests from caller

 *

 * For DMA coherent hardware (IOC) generic code suffices

	/*

	 * Evict any existing L1 and/or L2 lines for the backing page

	 * in case it was used earlier as a normal "cached" page.

	 * Yeah this bit us - STAR 9000898266

	 *

	 * Although core does call flush_cache_vmap(), it gets kvaddr hence

	 * can't be used to efficiently flush L1 and/or L2 which need paddr

	 * Currently flush_cache_vmap nukes the L1 cache completely which

	 * will be optimized as a separate commit

/*

 * Cache operations depending on function and direction argument, inspired by

 * https://lkml.org/lkml/2018/5/18/979

 * "dma_sync_*_for_cpu and direction=TO_DEVICE (was Re: [PATCH 02/20]

 * dma-mapping: provide a generic dma-noncoherent implementation)"

 *

 *          |   map          ==  for_device     |   unmap     ==  for_cpu

 *          |----------------------------------------------------------------

 * TO_DEV   |   writeback        writeback      |   none          none

 * FROM_DEV |   invalidate       invalidate     |   invalidate*   invalidate*

 * BIDIR    |   writeback+inv    writeback+inv  |   invalidate    invalidate

 *

 *     [*] needed for CPU speculative prefetches

 *

 * NOTE: we don't check the validity of direction argument as it is done in

 * upper layer functions (in include/linux/dma-mapping.h)

 FROM_DEVICE invalidate needed if speculative CPU prefetch only */

/*

 * Plug in direct dma map ops.

	/*

	 * IOC hardware snoops all DMA traffic keeping the caches consistent

	 * with memory - eliding need for any explicit cache maintenance of

	 * DMA buffers.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * TLB Management (flush/create/diagnostics) for MMUv3 and MMUv4

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 A copy of the ASID from the PID reg is kept in asid_cache */

/*

 * Utility Routine to erase a J-TLB entry

 * Caller needs to setup Index Reg (manually or via getIndex)

 Locate the TLB entry for this vaddr + ASID */

 No error means entry found, zero it out */

 Duplicate entry error */

	/*

	 * First verify if entry for this vaddr+ASID already exists

	 * This also sets up PD0 (vaddr, ASID..) for final commit

	/*

	 * If Not already present get a free slot from MMU.

	 * Otherwise, Probe would have located the entry and set INDEX Reg

	 * with existing location. This will cause Write CMD to over-write

	 * existing entry with new PD0 and PD1

 setup the other half of TLB entry (pfn, rwx..) */

	/*

	 * Commit the Entry to MMU

	 * It doesn't sound safe to use the TLBWriteNI cmd here

	 * which doesn't flush uTLBs. I'd rather be safe than sorry.

 MMUv4 */

/*

 * Un-conditionally (without lookup) erase the entire MMU contents

 Load PD0 and PD1 with template for a Blank Entry */

 write this entry to the TLB */

 Blank sTLB entry */

/*

 * Flush the entire MM for userland. The fastest way is to move to Next ASID

	/*

	 * Small optimisation courtesy IA64

	 * flush_mm called during fork,exit,munmap etc, multiple times as well.

	 * Only for fork( ) do we need to move parent to a new MMU ctxt,

	 * all other cases are NOPs, hence this check.

	/*

	 * - Move to a new ASID, but only if the mm is still wired in

	 *   (Android Binder ended up calling this for vma->mm != tsk->mm,

	 *    causing h/w - s/w ASID to get out of sync)

	 * - Also get_new_mmu_context() new implementation allocates a new

	 *   ASID only if it is not allocated already - so unallocate first

/*

 * Flush a Range of TLB entries for userland.

 * @start is inclusive, while @end is exclusive

 * Difference between this and Kernel Range Flush is

 *  -Here the fastest way (if range is too large) is to move to next ASID

 *      without doing any explicit Shootdown

 *  -In case of kernel Flush, entry has to be shot down explicitly

	/* If range @start to @end is more than 32 TLB entries deep,

	 * its better to move to a new ASID rather than searching for

	 * individual entries and then shooting them down

	 *

	 * The calc above is rough, doesn't account for unaligned parts,

	 * since this is heuristics based anyways

	/*

	 * @start moved to page start: this alone suffices for checking

	 * loop end condition below, w/o need for aligning @end to end

	 * e.g. 2000 to 4001 will anyhow loop twice

/* Flush the kernel TLB entries - vmalloc/modules (Global from MMU perspective)

 *  @start, @end interpreted as kvaddr

 * Interestingly, shared TLB entries can also be flushed using just

 * @start,@end alone (interpreted as user vaddr), although technically SASID

 * is also needed. However our smart TLbProbe lookup takes care of that.

 exactly same as above, except for TLB entry not taking ASID */

/*

 * Delete TLB entry in MMU for a given page (??? address)

 * NOTE One TLB entry contains translation for single PAGE

	/* Note that it is critical that interrupts are DISABLED between

	 * checking the ASID and using it flush the TLB entry

/*

 * Routine to create a TLB entry

	/*

	 * create_tlb() assumes that current->mm == vma->mm, since

	 * -it ASID for TLB entry is fetched from MMU ASID reg (valid for curr)

	 * -completes the lazy write to SASID reg (again valid for curr tsk)

	 *

	 * Removing the assumption involves

	 * -Using vma->mm->context{ASID,SASID}, as opposed to MMU reg.

	 * -More importantly it makes this handler inconsistent with fast-path

	 *  TLB Refill handler which always deals with "current"

	 *

	 * Lets see the use cases when current->mm != vma->mm and we land here

	 *  1. execve->copy_strings()->__get_user_pages->handle_mm_fault

	 *     Here VM wants to pre-install a TLB entry for user stack while

	 *     current->mm still points to pre-execve mm (hence the condition).

	 *     However the stack vaddr is soon relocated (randomization) and

	 *     move_page_tables() tries to undo that TLB entry.

	 *     Thus not creating TLB entry is not any worse.

	 *

	 *  2. ptrace(POKETEXT) causes a CoW - debugger(current) inserting a

	 *     breakpoint in debugged task. Not creating a TLB now is not

	 *     performance critical.

	 *

	 * Both the cases above are not good enough for code churn.

 update this PTE credentials */

 Create HW TLB(PD0,PD1) from PTE  */

 ASID for this task */

	/*

	 * ARC MMU provides fully orthogonal access bits for K/U mode,

	 * however Linux only saves 1 set to save PTE real-estate

	 * Here we convert 3 PTE bits into 6 MMU bits:

	 * -Kernel only entries have Kr Kw Kx 0 0 0

	 * -User entries have mirrored K and U bits

 r w x => Kr Kw Kx 0 0 0 */

 r w x => Kr Kw Kx Ur Uw Ux */

/*

 * Called at the end of pagefault, for a userspace mapped page

 *  -pre-install the corresponding TLB entry into MMU

 *  -Finalize the delayed D-cache flush of kernel mapping of page due to

 *  	flush_dcache_page(), copy_user_page()

 *

 * Note that flush (when done) involves both WBACK - so physical page is

 * in sync as well as INV - so any non-congruent aliases don't remain

	/*

	 * Exec page : Independent of aliasing/page-color considerations,

	 *	       since icache doesn't snoop dcache on ARC, any dirty

	 *	       K-mapping of a code page needs to be wback+inv so that

	 *	       icache fetch by userspace sees code correctly.

	 * !EXEC page: If K-mapping is NOT congruent to U-mapping, flush it

	 *	       so userspace sees the right data.

	 *  (Avoids the flush for Non-exec + congruent mapping case)

 wback + inv dcache lines (K-mapping) */

 invalidate any existing icache lines (U-mapping) */

/*

 * MMUv4 in HS38x cores supports Super Pages which are basis for Linux THP

 * support.

 *

 * Normal and Super pages can co-exist (ofcourse not overlap) in TLB with a

 * new bit "SZ" in TLB page descriptor to distinguish between them.

 * Super Page size is configurable in hardware (4K to 16M), but fixed once

 * RTL builds.

 *

 * The exact THP size a Linux configuration will support is a function of:

 *  - MMU page size (typical 8K, RTL fixed)

 *  - software page walker address split between PGD:PTE:PFN (typical

 *    11:8:13, but can be changed with 1 line)

 * So for above default, THP size supported is 8K * (2^8) = 2M

 *

 * Default Page Walker is 2 levels, PGD:PTE:PFN, which in THP regime

 * reduces to 1 level (as PTE is folded into PGD and canonically referred

 * to as PMD).

 * Thus THP PMD accessors are implemented in terms of PTE (just like sparc)

 No need to loop here: this will always be for 1 Huge Page */

/* Read the Cache Build Configuration Registers, Decode them and save into

 * the cpuinfo structure for later use.

 * No Validation is done here, simply read/convert the BCRs

           DTLB      ITLB      JES        JE         JA      */

	/*

	 * Can't be done in processor.h due to header include dependencies

	/*

	 * stack top size sanity check,

	 * Can't be done in processor.h due to header include dependencies

	/*

	 * Ensure that MMU features assumed by kernel exist in hardware.

	 *  - For older ARC700 cpus, only v3 supported

	 *  - For HS cpus, v4 was baseline and v5 is backwards compatible

	 *    (will run older software).

 Enable the MMU with ASID 0 */

 cache the pgd pointer in MMU SCRATCH reg (ARCv2 only) */

/*

 * TLB Programmer's Model uses Linear Indexes: 0 to {255, 511} for 128 x {2,4}

 * The mapping is Column-first.

 *		---------------------	-----------

 *		|way0|way1|way2|way3|	|way0|way1|

 *		---------------------	-----------

 * [set0]	|  0 |  1 |  2 |  3 |	|  0 |  1 |

 * [set1]	|  4 |  5 |  6 |  7 |	|  2 |  3 |

 *		~		    ~	~	  ~

 * [set127]	| 508| 509| 510| 511|	| 254| 255|

 *		---------------------	-----------

 * For normal operations we don't(must not) care how above works since

 * MMU cmd getIndex(vaddr) abstracts that out.

 * However for walking WAYS of a SET, we need to know this

/* Handling of Duplicate PD (TLB entry) in MMU.

 * -Could be due to buggy customer tapeouts or obscure kernel bugs

 * -MMU complaints not at the time of duplicate PD installation, but at the

 *      time of lookup matching multiple ways.

 * -Ideally these should never happen - but if they do - workaround by deleting

 *      the duplicate one.

 * -Knob to be verbose abt it.(TODO: hook them up to debugfs)

 Be silent abt it or complain (default) */

 loop thru all sets of TLB */

 read out all the ways of current set */

 If all the WAYS in SET are empty, skip to next SET */

 Scan the set for duplicate ways: needs a nested loop */

				/*

				 * clear entry @way and not @n.

				 * This is critical to our optimised loop

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARC700 mmap

 *

 * (started from arm version - for VIPT alias handling)

 *

 * Copyright (C) 2013 Synopsys, Inc. (www.synopsys.com)

/*

 * Ensure that shared mappings are correctly aligned to

 * avoid aliasing issues with VIPT caches.

 * We need to ensure that

 * a specific page of an object is always mapped at a multiple of

 * SHMLBA bytes.

	/*

	 * We only need to do colour alignment if D cache aliases.

	/*

	 * We enforce the MAP_FIXED case.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 User can over-ride above with "mem=nnn[KkMm]" in cmdline */

 early console might not be setup yet - it will show up later */

/*

 * First memory setup routine called from setup_arch()

 * 1. setup swapper's mm @init_mm

 * 2. Count the pages we have and setup bootmem allocator

 * 3. zone setup

 first page of system - kernel .vector starts here */

 Last usable page of low mem */

------------- bootmem allocator setup -----------------------*/

	/*

	 * seed the bootmem allocator after any DT memory node parsing or

	 * "mem=xxx" cmdline overrides have potentially updated @arc_mem_sz

	 *

	 * Only low mem is added, otherwise we have crashes when allocating

	 * mem_map[] itself. NO_BOOTMEM allocates mem_map[] at the end of

	 * avail memory, ending in highmem with a > 32-bit address. However

	 * it then tries to memset it with a truncaed 32-bit handle, causing

	 * the crash

----------------- node/zones setup --------------------------*/

	/*

	 * On ARC (w/o PAE) HIGHMEM addresses are actually smaller (0 based)

	 * than addresses in normal aka low memory (0x8000_0000 based).

	 * Even with PAE, the huge peripheral space hole would waste a lot of

	 * mem with single contiguous mem_map[].

	 * Thus when HIGHMEM on ARC is enabled the memory map corresponding

	 * to the hole is freed and ARC specific version of pfn_valid()

	 * handles the hole in the memory map.

	/*

	 * max_high_pfn should be ok here for both HIGHMEM and HIGHMEM+PAE.

	 * For HIGHMEM without PAE max_high_pfn should be less than

	 * min_low_pfn to guarantee that these two regions don't overlap.

	 * For PAE case highmem is greater than lowmem, so it is natural

	 * to use max_high_pfn.

	 *

	 * In both cases, holes should be handled by pfn_valid().

 CONFIG_HIGHMEM */

 pfn_valid() uses this when FLATMEM=y and HIGHMEM=n */

 CONFIG_HIGHMEM */

/*

 * mem_init - initializes memory

 *

 * Frees up bootmem

 * Calculates and displays memory available/used

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARC Cache Management

 *

 * Copyright (C) 2014-15 Synopsys, Inc. (www.synopsys.com)

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 legacy value for boot */

 legacy value */

/*

 * Read the Cache Build Confuration Registers, Decode them and save into

 * the cpuinfo structure for later use.

 * No Validation done here, simply read/convert the BCRs

		/*

		 * As for today we don't support both IOC and ZONE_HIGHMEM enabled

		 * simultaneously. This happens because as of today IOC aperture covers

		 * only ZONE_NORMAL (low mem) and any dma transactions outside this

		 * region won't be HW coherent.

		 * If we want to use both IOC and ZONE_HIGHMEM we can use

		 * bounce_buffer to handle dma transactions to HIGHMEM.

		 * Also it is possible to modify dma_direct cache ops or increase IOC

		 * aperture size if we are planning to use HIGHMEM without PAE.

 HS 2.0 didn't have AUX_VOL */

 HS 3.0 has limit and strict-ordering fields */

 Fixed to 2w set assoc */

 1,2,4,8 */

 Fixed to 4w set assoc */

 1,2,4,8 */

 PIPT so can't VIPT alias */

/*

 * Line Operation on {I,D}-Cache

/*

 * Cache Flush programming model

 *

 * ARC700 MMUv3 I$ and D$ are both VIPT and can potentially alias.

 * Programming model requires both paddr and vaddr irrespecive of aliasing

 * considerations:

 *  - vaddr in {I,D}C_IV?L

 *  - paddr in {I,D}C_PTAG

 *

 * In HS38x (MMUv4), D$ is PIPT, I$ is VIPT and can still alias.

 * Programming model is different for aliasing vs. non-aliasing I$

 *  - D$ / Non-aliasing I$: only paddr in {I,D}C_IV?L

 *  - Aliasing I$: same as ARC700 above (so MMUv3 routine used for MMUv4 I$)

 *

 *  - If PAE40 is enabled, independent of aliasing considerations, the higher

 *    bits needs to be written into PTAG_HI

	/* Ensure we properly floor/ceil the non-line aligned/sized requests

	 * and have @paddr - aligned to cache line and integral @num_lines.

	 * This however can be avoided for page sized since:

	 *  -@paddr will be cache-line aligned already (being page aligned)

	 *  -@sz will be integral multiple of line size (being page sized).

	/*

	 * MMUv3, cache ops require paddr in PTAG reg

	 * if V-P const for loop, PTAG can be written once outside loop

	/*

	 * This is technically for MMU v4, using the MMU v3 programming model

	 * Special work for HS38 aliasing I-cache configuration with PAE40

	 *   - upper 8 bits of paddr need to be written into PTAG_HI

	 *   - (and needs to be written before the lower 32 bits)

	 * Note that PTAG_HI is hoisted outside the line loop

/*

 d$ cmd: INV (discard or wback-n-discard) OR FLUSH (wback) */

	/* Ensure we properly floor/ceil the non-line aligned/sized requests

	 * and have @paddr - aligned to cache line and integral @num_lines.

	 * This however can be avoided for page sized since:

	 *  -@paddr will be cache-line aligned already (being page aligned)

	 *  -@sz will be integral multiple of line size (being page sized).

	/*

	 * For HS38 PAE40 configuration

	 *   - upper 8 bits of paddr need to be written into PTAG_HI

	 *   - (and needs to be written before the lower 32 bits)

			/*

			 * Non aliasing I-cache in HS38,

			 * aliasing I-cache handled in __cache_line_loop_v3()

/*

 * optimized flush operation which takes a region as opposed to iterating per line

 Only for Non aliasing I-cache in HS38 */

 for any leading gap between @paddr and start of cache line */

		/*

		 *  account for any trailing gap to end of cache line

		 *  this is equivalent to DIV_ROUND_UP() in line ops above

 TBD: check if crossing 4TB boundary */

 ENDR needs to be set ahead of START */

 ENDR is exclusive */

 caller waits on DC_CTRL.FS */

/***************************************************************

 * Machine specific helpers for Entire D-Cache or Per Line ops

/*

 * this version avoids extra read/write of DC_CTRL for flush or invalid ops

 * in the non region flush regime (such as for ARCompact)

		/* Dcache provides 2 cmd: FLUSH or INV

		 * INV inturn has sub-modes: DISCARD or FLUSH-BEFORE

		 * flush-n-inv is achieved by INV cmd but with IM=1

		 * So toggle INV sub-mode depending on op request and default

		/*

		 * Flush / Invalidate is provided by DC_CTRL.RNG_OP 0 or 1

		 * combined Flush-n-invalidate uses DC_CTRL.IM = 1 set above

 flush / flush-n-inv both wait */

 Switch back to default Invalidate mode */

/*

 * Operation on Entire D-Cache

 * @op = {OP_INV, OP_FLUSH, OP_FLUSH_N_INV}

 * Note that constant propagation ensures all the checks are gone

 * in generated code

 Inv or flush-n-inv use same cmd reg */

 For kernel mappings cache operation: index is same as paddr */

/*

 * D-Cache Line ops: Per Line INV (discard or wback+discard) or FLUSH (wback)

 CONFIG_ARC_HAS_DCACHE */

 blocks */

 CONFIG_SMP */

 !CONFIG_ARC_HAS_ICACHE */

 CONFIG_ARC_HAS_ICACHE */

	/*

	 * SLC is shared between all cores and concurrent aux operations from

	 * multiple cores need to be serialized using a spinlock

	 * A concurrent operation can be silently ignored and/or the old/new

	 * operation can remain incomplete forever (lockup in SLC_CTRL_BUSY loop

	 * below)

	/*

	 * The Region Flush operation is specified by CTRL.RGN_OP[11..9]

	 *  - b'000 (default) is Flush,

	 *  - b'001 is Invalidate if CTRL.IM == 0

	 *  - b'001 is Flush-n-Invalidate if CTRL.IM == 1

 Don't rely on default value of IM bit */

 i.e. OP_INV */

 clear IM: Disable flush before Inv */

 Inv or flush-n-inv */

	/*

	 * Lower bits are ignored, no need to clip

	 * END needs to be setup before START (latter triggers the operation)

	 * END can't be same as START, so add (l2_line_sz - 1) to sz

 Make sure "busy" bit reports correct stataus, see STAR 9001165532 */

	/*

	 * SLC is shared between all cores and concurrent aux operations from

	 * multiple cores need to be serialized using a spinlock

	 * A concurrent operation can be silently ignored and/or the old/new

	 * operation can remain incomplete forever (lockup in SLC_CTRL_BUSY loop

	 * below)

 Don't rely on default value of IM bit */

 i.e. OP_INV */

 clear IM: Disable flush before Inv */

 Make sure "busy" bit reports correct stataus, see STAR 9001165532 */

 i.e. OP_INV */

 clear IM: Disable flush before Inv */

 Inv or flush-n-inv use same cmd reg */

 Make sure "busy" bit reports correct stataus, see STAR 9001165532 */

 Important to wait for flush to complete */

/***********************************************************

 * Exported APIs

/*

 * Handle cache congruency of kernel and userspace mappings of page when kernel

 * writes-to/reads-from

 *

 * The idea is to defer flushing of kernel mapping after a WRITE, possible if:

 *  -dcache is NOT aliasing, hence any U/K-mappings of page are congruent

 *  -U-mapping doesn't exist yet for page (finalised in update_mmu_cache)

 *  -In SMP, if hardware caches are coherent

 *

 * There's a corollary case, where kernel READs from a userspace mapped page.

 * If the U-mapping is not congruent to to K-mapping, former needs flushing.

 don't handle anon pages here */

	/*

	 * pagecache page, file not yet mapped to userspace

	 * Make a note that K-mapping is dirty

 kernel reading from page with U-mapping */

/*

 * DMA ops for systems with L1 cache only

 * Make memory coherent with L1 cache by flushing/invalidating L1 lines

/*

 * DMA ops for systems with both L1 and L2 caches, but without IOC

 * Both L1 and L2 lines need to be explicitly flushed/invalidated

/*

 * Exported DMA API

/*

 * This is API for making I/D Caches consistent when modifying

 * kernel code (loadable modules, kprobes, kgdb...)

 * This is called on insmod, with kernel virtual address for CODE of

 * the module. ARC cache maintenance ops require PHY address thus we

 * need to convert vmalloc addr to PHY addr

	/* Shortcut for bigger flush ranges.

	 * Here we don't care if this was kernel virtual or phy addr

 Case: Kernel Phy addr (0x8000_0000 onwards) */

		/*

		 * The 2nd arg despite being paddr will be used to index icache

		 * This is OK since no alternate virtual mappings will exist

		 * given the callers for this case: kprobe/kgdb in built-in

		 * kernel code only.

	/*

	 * Case: Kernel Vaddr (0x7000_0000 to 0x7fff_ffff)

	 * (1) ARC Cache Maintenance ops only take Phy addr, hence special

	 *     handling of kernel vaddr.

	 *

	 * (2) Despite @tot_sz being < PAGE_SIZE (bigger cases handled already),

	 *     it still needs to handle  a 2 page scenario, where the range

	 *     straddles across 2 virtual pages and hence need for loop

/*

 * General purpose helper to make I and D cache lines consistent.

 * @paddr is phy addr of region

 * @vaddr is typically user vaddr (breakpoint) or kernel vaddr (vmalloc)

 *    However in one instance, when called by kprobe (for a breakpt in

 *    builtin kernel code) @vaddr will be paddr only, meaning CDU operation will

 *    use a paddr to index the cache (despite VIPT). This is fine since since a

 *    builtin kernel page will not have any virtual mappings.

 *    kprobe on loadable module will be kernel vaddr.

 wrapper to compile time eliminate alignment checks in flush loop */

/*

 * wrapper to clearout kernel or userspace mappings of a page

 * For kernel mappings @vaddr == @paddr

 TBD: do we really need to clear the kernel mapping */

	/*

	 * If SRC page was already mapped in userspace AND it's U-mapping is

	 * not congruent with K-mapping, sync former to physical page so that

	 * K-mapping in memcpy below, sees the right data

	 *

	 * Note that while @u_vaddr refers to DST page's userspace vaddr, it is

	 * equally valid for SRC page as well

	 *

	 * For !VIPT cache, all of this gets compiled out as

	 * addr_not_cache_congruent() is 0

	/*

	 * Mark DST page K-mapping as dirty for a later finalization by

	 * update_mmu_cache(). Although the finalization could have been done

	 * here as well (given that both vaddr/paddr are available).

	 * But update_mmu_cache() already has code to do that for other

	 * non copied user pages (e.g. read faults which wire in pagecache page

	 * directly).

	/*

	 * if SRC was already usermapped and non-congruent to kernel mapping

	 * sync the kernel mapping back to physical page

/**********************************************************************

 * Explicit Cache flush request from user space via syscall

 * Needed for JITs which generate code on the fly

 TBD: optimize this */

/*

 * IO-Coherency (IOC) setup rules:

 *

 * 1. Needs to be at system level, so only once by Master core

 *    Non-Masters need not be accessing caches at that time

 *    - They are either HALT_ON_RESET and kick started much later or

 *    - if run on reset, need to ensure that arc_platform_smp_wait_to_boot()

 *      doesn't perturb caches or coherency unit

 *

 * 2. caches (L1 and SLC) need to be purged (flush+inv) before setting up IOC,

 *    otherwise any straggler data might behave strangely post IOC enabling

 *

 * 3. All Caches need to be disabled when setting up IOC to elide any in-flight

 *    Coherency transactions

	/*

	 * If IOC was already enabled (due to bootloader) it technically needs to

	 * be reconfigured with aperture base,size corresponding to Linux memory map

	 * which will certainly be different than uboot's. But disabling and

	 * reenabling IOC when DMA might be potentially active is tricky business.

	 * To avoid random memory issues later, just panic here and ask user to

	 * upgrade bootloader to one which doesn't enable IOC

 Flush + invalidate + disable L1 dcache */

 Flush + invalidate SLC */

	/*

	 * currently IOC Aperture covers entire DDR

	 * TBD: fix for PGU + 1GB of low mem

	 * TBD: fix for PAE

	/*

	 * IOC Aperture size decoded as 2 ^ (SIZE + 2) KB,

	 * so setting 0x11 implies 512MB, 0x12 implies 1GB...

 for now assume kernel base is start of IOC aperture */

 Re-enable L1 dcache */

/*

 * Cache related boot time checks/setups only needed on master CPU:

 *  - Geometry checks (kernel build and hardware agree: e.g. L1_CACHE_BYTES)

 *    Assume SMP only, so all cores will have same cache config. A check on

 *    one core suffices for all

 *  - IOC setup / dma callbacks only need to be done once

		/*

		 * In MMU v4 (HS38x) the aliasing icache config uses IVIL/PTAG

		 * pair to provide vaddr/paddr respectively, just as in MMU v3

 check for D-Cache aliasing on ARCompact: ARCv2 has PIPT */

	/*

	 * Check that SMP_CACHE_BYTES (and hence ARCH_DMA_MINALIGN) is larger

	 * or equal to any cache line length.

 Note that SLC disable not formally supported till HS 3.0 */

	/*

	 * In case of IOC (say IOC+SLC case), pointers above could still be set

	 * but end up not being relevant as the first function in chain is not

	 * called at all for devices using coherent DMA.

	 *     arch_sync_dma_for_cpu() -> dma_cache_*() -> __dma_cache_*()

	/*

	 * In PAE regime, TLB and cache maintenance ops take wider addresses

	 * And even if PAE is not enabled in kernel, the upper 32-bits still need

	 * to be zeroed to keep the ops sane.

	 * As an optimization for more common !PAE enabled case, zero them out

	 * once at init, rather than checking/setting to 0 for every runtime op

 SPDX-License-Identifier: GPL-2.0-only

/* Page Fault Handling for ARC (TLB Miss / ProtV)

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

/*

 * kernel virtual address is required to implement vmalloc/pkmap/fixmap

 * Refer to asm/processor.h for System Memory Map

 *

 * It simply copies the PMD entry (pointer to 2nd level page table or hugepage)

 * from swapper pgdir to task pgdir. The 2nd level table/page is thus shared

	/*

	 * Synchronize this task's top level page-table

	 * with the 'reference' page table.

 XXX: create the TLB entry here */

 handle_mm_fault() output */

 handle_mm_fault() input */

	/*

	 * NOTE! We MUST NOT take any locks for this case. We may

	 * be in an interrupt or a critical region, and should

	 * only copy the information from the master page table,

	 * nothing more.

	/*

	 * If we're in an interrupt or have no user

	 * context, we must not take the fault..

 ST/EX */

	/*

	 * vm_area is good, now check permissions for this memory access

 Quick path to respond to signals */

	/*

	 * Fault retry nuances, mmap_lock already relinquished by core mm

	/*

	 * Major/minor page fault accounting

	 * (in case of retry we only land here once)

 Normal return path: fault Handled Gracefully */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 * Borrowed heavily from MIPS

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 Don't allow wraparound or zero size */

	/*

	 * If the region is h/w uncached, MMU mapping can be elided as optim

	 * The cast to u32 is fine as this region can only be inside 4GB

/*

 * ioremap with access flags

 * Cache semantics wise it is same as ioremap - "forced" uncached.

 * However unlike vanilla ioremap which bypasses ARC MMU for addresses in

 * ARC hardware uncached region, this one still goes thru the MMU as caller

 * might need finer access control (R/W/X)

 Don't allow wraparound, zero size */

 An early platform driver might end up here */

 force uncached */

 Mappings have to be page-aligned */

	/*

	 * Ok, go for it..

 weird double cast to handle phys_addr_t > 32 bits */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 * Amit Bhor, Kanika Nema: Codito Technologies 2004

/*

 * We return the user space TLS data ptr as sys-call return code

 * Ideally it should be copy to user.

 * However we can cheat by the fact that some sys-calls do return

 * absurdly high values

 * Since the tls dat aptr is not going to be in range of 0xFFFF_xxxx

 * it won't be considered a sys-call error

 * and it will be loads better than copy-to-user, which is a definite

 * D-TLB Miss

	/*

	 * This is only for old cores lacking LLOCK/SCOND, which by definition

	 * can't possibly be SMP. Thus doesn't need to be SMP safe.

	 * And this also helps reduce the overhead for serializing in

	 * the UP case

 Z indicates to userspace if operation succeeded */

 Re-enable interrupts <= default irq priority before committing SLEEP */

 can't be "r" has to be embedded const */

 ARC700 */

 sleep, but enable both set E1/E2 (levels of interrupts) before committing */

/*

 * Copy architecture-specific thread state

 *

 * Layout of Child kernel mode stack as setup at the end of this function is

 *

 * |     ...        |

 * |     ...        |

 * |    unused      |

 * |                |

 * ------------------

 * |     r25        |   <==== top of Stack (thread.ksp)

 * ~                ~

 * |    --to--      |   (CALLEE Regs of kernel mode)

 * |     r13        |

 * ------------------

 * |     fp         |

 * |    blink       |   @ret_from_fork

 * ------------------

 * |                |

 * ~                ~

 * ~                ~

 * |                |

 * ------------------

 * |     r12        |

 * ~                ~

 * |    --to--      |   (scratch Regs of user mode)

 * |     r0         |

 * ------------------

 * |      SP        |

 * |    orig_r0     |

 * |    event/ECR   |

 * |    user_r25    |

 * ------------------  <===== END of PAGE

 child's pt_regs */

 to unwind out of __switch_to() */

 child's callee regs */

 paren't callee */

 Mark the specific anchors to begin with (see pic above) */

 2 words for FP/BLINK */

	/*

	 * __switch_to() uses thread.ksp to start unwinding stack

	 * For kernel threads we don't need to create callee regs, the

	 * stack layout nevertheless needs to remain the same.

	 * Also, since __switch_to anyways unwinds callee regs, we use

	 * this to populate kernel thread entry-pt/args into callee regs,

	 * so that ret_from_kernel_thread() becomes simpler.

 THREAD_KSP */

 __switch_to expects FP(0), BLINK(return addr) at top */

 fp */

 blink */

 function */

--------- User Task Only --------------*/

 __switch_to expects FP(0), BLINK(return addr) at top of stack */

 for POP fp */

 for POP blink */

 Copy parents pt regs on child's kernel mode stack */

 fork returns 0 in child */

		/*

		 * set task's userland tls data ptr from 4th arg

		 * clone C-lib call is difft from clone sys-call

 Normal fork case: set parent's TLS ptr in child */

	/*

	 * setup usermode thread pointer #1:

	 * when child is picked by scheduler, __switch_to() uses @c_callee to

	 * populate usermode callee regs: this works (despite being in a kernel

	 * function) since special return path for child @ret_from_fork()

	 * ensures those regs are not clobbered all the way to RTIE to usermode

	/*

	 * setup usermode thread pointer #2:

	 * however for this special use of r25 in kernel, __switch_to() sets

	 * r25 for kernel needs and only in the final return path is usermode

	 * r25 setup, from pt_regs->user_r25. So set that up as well

/*

 * Do necessary setup to start up a new user task

	/*

	 * [U]ser Mode bit set

	 * [L] ZOL loop inhibited to begin with - cleared by a LP insn

	 * Interrupts enabled

 bogus seed values for debugging */

/*

 * Some archs flush debug and FPU info here

 SPDX-License-Identifier: GPL-2.0

 SPDX-License-Identifier: GPL-2.0-only

/*

 *	stacktrace.c : stacktracing APIs needed by rest of kernel

 *			(wrappers over ARC dwarf based unwinder)

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 *  vineetg: aug 2009

 *  -Implemented CONFIG_STACKTRACE APIs, primarily save_stack_trace_tsk( )

 *   for displaying task's kernel mode call stack in /proc/<pid>/stack

 *  -Iterator based approach to have single copy of unwinding core and APIs

 *   needing unwinding, implement the logic in iterator regarding:

 *      = which frame onwards to start capture

 *      = which frame to stop capturing (wchan)

 *      = specifics of data structs where trace is saved(CONFIG_STACKTRACE etc)

 *

 *  vineetg: March 2009

 *  -Implemented correct versions of thread_saved_pc() and __get_wchan()

 *

 *  rajeshwarr: 2008

 *  -Initial implementation

/*-------------------------------------------------------------------------

 *              Unwinder Iterator

 *-------------------------------------------------------------------------

		/*

		 * Asynchronous unwinding of intr/exception

		 *  - Just uses the pt_regs passed

		/*

		 * synchronous unwinding (e.g. dump_stack)

		 *  - uses current values of SP and friends

		/*

		 * Asynchronous unwinding of a likely sleeping task

		 *  - first ensure it is actually sleeping

		 *  - if so, it will be in __switch_to, kernel mode SP of task

		 *    is safe-kept and BLINK at a well known location in there

		/* In the prologue of __switch_to, first FP is saved on stack

		 * and then SP is copied to FP. Dwarf assumes cfa as FP based

		 * but we didn't save FP. The value retrieved above is FP's

		 * state in previous frame.

		 * As a work around for this, we unwind from __switch_to start

		 * and adjust SP accordingly. The other limitation is that

		 * __switch_to macro is dwarf rules are not generated for inline

		 * assembly code

 return the last address it saw */

	/* On ARC, only Dward based unwinder works. fp based backtracing is

	 * not possible (-fno-omit-frame-pointer) because of the way function

	 * prologue is setup (callee regs saved and then fp set and not other

	 * way around

/*-------------------------------------------------------------------------

 * callbacks called by unwinder iterator to implement kernel APIs

 *

 * The callback can return -1 to force the iterator to stop, which by default

 * keeps going till the bottom-most frame.

 *-------------------------------------------------------------------------

/* Call-back which plugs into unwinding core to dump the stack in

 * case of panic/OOPs/BUG etc

/* Call-back which plugs into unwinding core to capture the

 * traces needed by kernel on /proc/<pid>/stack

/*-------------------------------------------------------------------------

 *              APIs expected by various kernel sub-systems

 *-------------------------------------------------------------------------

 Expected by sched Code */

/* Another API expected by schedular, shows up in "ps" as Wait Channel

 * Of course just returning schedule( ) would be pointless so unwind until

 * the function is not in schedular code

/*

 * API required by CONFIG_STACKTRACE, CONFIG_LATENCYTOP.

 * A typical use is when /proc/<pid>/stack is queried by userland

 Assumes @tsk is sleeping so unwinds from __switch_to */

 Pass NULL for task so it unwinds the current call frame */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Traps/Non-MMU Exception handling for ARC

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 * vineetg: May 2011

 *  -user-space unaligned access emulation

 *

 * Rahul Trivedi: Codito Technologies 2004

 DEAD END */

/*

 * Helper called for bulk of exceptions NOT needing specific handling

 *  -for user faults enqueues requested signal

 *  -for kernel, chk if due to copy_(to|from)_user, otherwise die()

 If not due to copy_(to|from)_user, we are doomed */

/*

 * Entry points for exceptions NOT needing specific handling

/*

 * Entry Point for Misaligned Data access Exception, for emulating in software

 If emulation not enabled, or failed, kill the task */

/*

 * Entry point for miscll errors such as Nested Exceptions

 *  -Duplicate TLB entry is handled seperately though

/*

 * Entry point for traps induced by ARCompact TRAP_S <n> insn

 * This is same family as TRAP0/SWI insn (use the same vector).

 * The only difference being SWI insn take no operand, while TRAP_S does

 * which reflects in ECR Reg as 8 bit param.

 * Thus TRAP_S <n> can be used for specific purpose

 *  -1 used for software breakpointing (gdb)

 *  -2 used by kprobes

 *  -5 __builtin_trap() generated by gcc (2018.03 onwards) for toggle such as

 *     -fno-isolate-erroneous-paths-dereference

/*

 * Entry point for Instruction Error Exception

 *  -For a corner case, ARC kprobes implementation resorts to using

 *   this exception, hence the check

 Check if this exception is caused by kprobes */

/*

 * abort() call generated by older gcc for __builtin_trap()

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 Part of U-boot ABI: see head.S */

 For stack switching */

 ID.ARCVER,	Release */

 UARCH.MAJOR,	Release */

 8K to 512K */

 2K to 256K */

 512B to 16M */

 includes arc700 */

	/*

	 * Initial HS cores bumped AUX IDENTITY.ARCVER for each release until

	 * ARCVER 0x54 which introduced AUX MICRO_ARCH_BUILD and subsequent

	 * releases only update it.

 Read CCM BCRs for boot reporting even if not enabled in Kconfig */

 if dual issue hardware, is it enabled ? */

 some hacks for lack of feature BCR info in old ARC700 cores */

 ISA BCR absent, use Kconfig info */

 ARC700_BUILD only has 2 bits of isa info */

 there's no direct way to distinguish 750 vs. 770 */

 stock MPY/MPYH */

 OPT 7-9 */

 Error Protection: ECC/Parity */

 inverted bits: 0 means enabled */

	/*

	 * DCCM can be arbit placed in hardware.

	 * Make sure it's placement/sz matches what Linux is built with

	/*

	 * FP hardware/software config sanity

	 * -If hardware present, kernel needs to save/restore FPU state

	 * -If not, it will crash trying to save/restore the non-existant regs

 only DPDP checked since SP has no arch visible regs */

 Accumulator Low:High pair (r58:59) present if DSP MPY or FPU */

/*

 * Initialize and setup the processor core

 * This is called by all the CPUs thus should not do special case stuff

 *    such as only for boot CPU etc

	/*

	 * Check that it is a untranslated address (although MMU is not enabled

	 * yet, it being a high address ensures this is not by fluke)

 Check that address doesn't clobber resident kernel image */

 uboot_tag values for U-boot - kernel ABI revision 0; see head.S */

 We always pass 0 as magic from U-boot */

 check that we know this tag */

 see if U-boot passed an external Device Tree blob */

 external Device Tree blob is invalid - use embedded one */

	/*

	 * NOTE: @boot_command_line is populated by setup_machine_fdt() so this

	 * append processing can only happen after.

 Ensure a whitespace between the 2 cmdlines */

 Save unparsed command line copy for /proc/cmdline */

 To force early parsing of things like mem=xxx */

 Platform/board specific: e.g. early console registration */

 copy flat DT out of .init and then unflatten it */

	/* Can be issue if someone passes cmd line arg "ro"

	 * But that is unlikely so keeping it as it is

/*

 * Called from start_kernel() - boot CPU only

/*

 *  Get CPU information for use by the procfs.

	/*

	 * Callback returns cpu-id to iterator for show routine, NULL to stop.

	 * However since NULL is also a valid cpu-id (0), we use a round-about

	 * way to pass it w/o having to kmalloc/free a 2 byte string.

	 * Encode cpu-id as 0xFFcccc, which is decoded by show routine.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * several functions that help interpret ARC instructions

 * used for unaligned accesses, kprobes and kgdb

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

/* disasm_instr: Analyses instruction at addr, stores

 * findings in *state

	/* This fetches the upper part of the 32 bit instruction

 Check if the instruction is 32 bit or 16 bit instruction */

 Read the second word in case of limm */

 unconditional branch s25, conditional branch s21 */

 Branch and Link*/

 unconditional branch s25, conditional branch s21 */

Branch On Compare */

 LD<zz> a,[b,s9] */

 Jcc */

 Jcc.D */

 JLcc */

 JLcc.D */

 op_format == 2 */

 LPcc */

 Conditional LPcc u7 */

			/* For Unconditional lp, next pc is the fall through

 LD a,[b,c] */

 MOV */

 still need to check for limm to extract instr len */

 MOV is special case because it only takes 2 args */

 OP a,b,c */

 OP a,b,u6 */

 OP b,b,s12 */

 OP.cc b,b,c/u6 */

 Not a Load, Jump or Loop instruction */

 still need to check for limm to extract instr len */

 OP a,b,c */

 OP a,b,u6 */

 OP b,b,s12 */

 OP.cc b,b,c/u6 */

 16 Bit Instructions */

 LD_S|LDB_S|LDW_S a,[b,c] */

 check for limm, ignore mov_s h,b (== mov_s 0,b) */

 j_s */

 j_s.d */

 jl_s */

 jl_s.d */

 jeq_s [blink] */

 jne_s [blink] */

 j_s [blink] */

 j_s.d [blink] */

 LD_S c, [b, u7] */

		/* no further handling required as byte accesses should not

 LDWX_S c, [b, u6] */

 LDW_S c, [b, u6] */

 ST_S c, [b, u7] */

 STW_S c,[b,u6] */

 LD_S|LDB_S b,[sp,u7], ST_S|STB_S b,[sp,u7] */

		/* note: we are ignoring possibility of:

		 * ADD_S, SUB_S, PUSH_S, POP_S as these should not

 byte accesses should not come here */

 LD_S|LDB_S|LDW_S r0,[gp,s11/s9/s10] */

 note: ADD_S r0, gp, s11 is ignored */

 LD_S b,[pcl,u10] */

/*

 * Disassembles the insn at @pc and sets @next_pc to next PC (which could be

 * @pc +2/4/6 (ARCompact ISA allows free intermixing of 16/32 bit insns).

 *

 * If @pc is a branch

 *	-@tgt_if_br is set to branch target.

 *	-If branch has delay slot, @next_pc updated with actual next PC.

 Instruction with possible two targets branch, jump and loop */

	/* For the instructions with delay slots, the fall through is the

	 * instruction following the instruction in delay slot.

 Zero Overhead Loop - end of the loop */

 CONFIG_KGDB || CONFIG_ARC_EMUL_UNALIGNED || CONFIG_KPROBES */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2014 Synopsys, Inc. (www.synopsys.com)

/*

 * Early Hardware specific Interrupt setup

 * -Called very early (start_kernel -> setup_arch -> setup_processor)

 * -Platform Independent (must for any ARC Core)

 * -Needed for each CPU (hence not foldable into init_IRQ)

 r0 to r11 (r12 saved manually) */

 LP_COUNT, LP_START, LP_END */

 user ctxt saved on kernel stack */

 JLI, LDI, EI */

	/*

	 * ARCv2 core intc provides multiple interrupt priorities (upto 16).

	 * Typical builds though have only two levels (0-high, 1-low)

	 * Linux by default uses lower prio 1 for most irqs, reserving 0 for

	 * NMI style interrupts in future (say perf)

 Encoded as N-1 for N levels */

	/*

	 * Set a default priority for all available interrupts to prevent

	 * switching of register banks if Fast IRQ and multiple register banks

	 * are supported by CPU.

	 * Also disable private-per-core IRQ lines so faulty external HW won't

	 * trigger interrupt that kernel is not ready to handle.

		/*

		 * Only mask cpu private IRQs here.

		 * "common" interrupts are masked at IDU, otherwise it would

		 * need to be unmasked at each cpu, with IPIs

 setup status32, don't enable intr yet as kernel doesn't want */

 set default priority */

	/*

	 * hw auto enables (linux unmask) all by default

	 * So no need to do IRQ_ENABLE here

	 * XXX: However OSCI LAN need it

	/*

	 * core intc IRQs [16, 23]:

	 * Statically assigned always private-per-core (Timers, WDT, IPI, PCT)

		/*

		 * A subsequent request_percpu_irq() fails if percpu_devid is

		 * not set. That in turns sets NOAUTOEN, meaning each core needs

		 * to call enable_percpu_irq()

	/*

	 * Needed for primary domain lookup to succeed

	 * This is a primary irqchip, and can never have a parent

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arc_hostlink.c: Pseudo-driver for Metaware provided "hostlink" facility

 *

 * Allows Linux userland access to host in absence of any peripherals.

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 file_operations */

 VM_IO */

 we only support, returning the physical addr to mmap in user space */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * fpu.c - save/restore of Floating Point Unit Registers on task switch

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

/*

 * To save/restore FPU regs, simplest scheme would use LR/SR insns.

 * However since SR serializes the pipeline, an alternate "hack" can be used

 * which uses the FPU Exchange insn (DEXCL) to r/w FPU regs.

 *

 * Store to 64bit dpfp1 reg from a pair of core regs:

 *   dexcl1 0, r1, r0  ; where r1:r0 is the 64 bit val

 *

 * Read from dpfp1 into pair of core regs (w/o clobbering dpfp1)

 *   mov_s    r3, 0

 *   daddh11  r1, r3, r3   ; get "hi" into r1 (dpfp1 unchanged)

 *   dexcl1   r0, r1, r3   ; get "low" into r0 (dpfp1 low clobbered)

 *   dexcl1    0, r1, r0   ; restore dpfp1 to orig value

 *

 * However we can tweak the read, so that read-out of outgoing task's FPU regs

 * and write of incoming task's regs happen in one shot. So all the work is

 * done before context switch

 early clobber must here */

 early clobber must here */

 default rounding mode */

 Initialize to zero: setting requires FWE be set */

 SPDX-License-Identifier: GPL-2.0

 Halt system on fatal error to make debug easier */

 1x 32bit NOP in middle endian */

/*

 * Atomic update of patched instruction is only available if this

 * instruction doesn't cross L1 cache line boundary. You can read about

 * the way we achieve this in arc/include/asm/jump_label.h

/*

 * ARCv2 'Branch unconditionally' instruction:

 * 00000ssssssssss1SSSSSSSSSSNRtttt

 * s S[n:0] lower bits signed immediate (number is bitfield size)

 * S S[m:n+1] upper bits signed immediate (number is bitfield size)

 * t S[24:21] upper bits signed immediate (branch unconditionally far)

 * N N <.d> delay slot mode

 * R R Reserved

	/*

	 * Offset in 32-bit branch instruction must to fit into s25.

	 * Something is terribly broken if we get such huge offset within one

	 * function.

	/*

	 * All instructions are aligned by 2 bytes so we should never get offset

	 * here which is not 2 bytes aligned.

 00000ssssssssss1 */

 SSSSSSSSSSNRtttt */

	/*

	 * We use only one NOP type (1x, 4 byte) in arch_static_branch, so

	 * there's no need to patch an identical NOP over the top of it here.

	 * The generic code calls 'arch_jump_label_transform' if the NOP needs

	 * to be replaced by a branch, so 'arch_jump_label_transform_static' is

	 * never called with type other than JUMP_LABEL_NOP.

/*

 * Offset field in branch instruction is not continuous. Test all

 * available offset field and sign combinations. Test data is generated

 * from real working code.

 tiny (-52) offs */

 tiny (-574) offs */

 tiny (-1178) offs */

 small (-3034) offs */

 big  (-30892) offs */

 huge (-443616) offs */

 tiny (+24) offs */

 tiny (+514) offs */

 tiny (+1884) offs */

 small (+3072) offs */

 big  (+194568) offs */

 huge (+5701180) offs */

 CONFIG_ARC_DBG_JUMP_LABEL */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

	/* can't use print_vma_addr() yet as it doesn't check for

	 * non-inclusive vma

	/* Lookup the vma at the address and report if the container VMA is not

	 * found

 For Data fault, this is data address not instruction addr */

 For DTLB Miss or ProtV, display the memory involved too */

/************************************************************************

 *  API called by rest of kernel

	/*

	 * generic code calls us with preemption disabled, but some calls

	 * here could sleep, so re-enable to avoid lockdep splat

 faulting code, not data */

 Show fault description */

 Caller and Callee regs */

 Show stack trace if this Fatality happened in kernel mode */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * arcksyms.c - Exporting symbols not exportable from their own sources

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 libgcc functions, not part of kernel sources */

 ARC optimised assembler routines */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2012 Synopsys, Inc. (www.synopsys.com)

 *

 * Based on reduced version of METAG

 Fixed 166.6MHz clk (TB10x) */

 Fixed 33MHz clk (AXS10x & HSDK) */

 Fixed default 50MHz */

/**

 * setup_machine_fdt - Machine setup when an dtb was passed to the kernel

 * @dt:		virtual address pointer to dt blob

 *

 * If a dtb was passed to the kernel, then use it to choose the correct

 * machine_desc and to setup the system.

 SPDX-License-Identifier: GPL-2.0+



 Linux performance counter support for ARC CPUs.

 This code is inspired by the perf support of various other architectures.



 Copyright (C) 2013-2018 Synopsys, Inc. (www.synopsys.com)

 HW holds 8 symbols + one for null terminator */

	/*

	 * A 1 bit for an index indicates that the counter is being used for

	 * an event. A 0 means that the counter can be used.

	/*

	 * The events that are active on the PMU for the given index.

	/*

	 * User stack can't be unwound trivially with kernel dwarf unwinder

	 * So for now just record the user PC

 read counter #idx; note that counter# != event# on ARC! */

	/*

	 * ARC supports making 'snapshots' of the counters, so we don't

	 * need to care about counters wrapping to 0 underneath our feet

	/*

	 * We aren't afraid of hwc->prev_count changing beneath our feet

	 * because there's no way for us to re-enter this function anytime.

 initializes hw_perf_event structure if event is supported */

 "exclude user" means "count only kernel" */

 "exclude kernel" means "count only user" */

 starts all counters */

 stops all counters */

 left underflowed by more than period. */

 left underflowed by less than period. */

 Select counter */

 Write value */

/*

 * Assigns hardware counter to hardware condition.

 * Note that there is no separate start/stop mechanism;

 * stopping is achieved by assigning the 'never' condition

 Enable interrupt for this counter */

 enable ARC pmu here */

 counter # */

 condition */

 Disable interrupt for this counter */

		/*

		 * Reset interrupt flag by writing of 1. This is required

		 * to make sure pending interrupt was not left.

 stop ARC pmu here */

 condition code #0 is always "never" */

 allocate hardware counter and optionally start counting */

 Mimic full counter overflow as other arches do */

 Reset interrupt flag by writing of 1 */

		/*

		 * On reset of "interrupt active" bit corresponding

		 * "interrupt enable" bit gets automatically reset as well.

		 * Now we need to re-enable interrupt for the counter.

 CONFIG_ISA_ARCV2 */

 Clear all pending interrupt flags */

 Event field occupies the bottom 15 bits of our config field */

/*

 * We don't add attrs here as we don't have pre-defined list of perf events.

 * We will generate and add attrs dynamically in probe() after we read HW

 * configuration.

 See if HW condition has been mapped to a perf event_id */

 in bits */

 loop thru all available h/w condition indexes */

 intc map function ensures irq_set_percpu_devid() called */

	/*

	 * perf parser doesn't really like '-' symbol in events name, so let's

	 * use '_' in arc pct name as it goes to kernel PMU event prefix.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARC ARConnect (MultiCore IP) support (formerly known as MCIP)

 *

 * Copyright (C) 2013 Synopsys, Inc. (www.synopsys.com)

/*

 * Set mask to halt GFRC if any online core in SMP cluster is halted.

 * Only works for ARC HS v3.0+, on earlier versions has no effect.

	/*

	 * CMD_GFRC_SET_CORE and CMD_GFRC_READ_CORE commands were added in

	 * GFRC 0x3 version.

	/*

	 * mcip_mask is same for CMD_DEBUG_SET_SELECT and CMD_DEBUG_SET_MASK

	 * commands. So read it once instead of reading both CMD_DEBUG_READ_MASK

	 * and CMD_DEBUG_READ_SELECT.

	/*

	 * Parameter specified halt cause:

	 * STATUS32[H]/actionpoint/breakpoint/self-halt

	 * We choose all of them (0xF).

 Update GFRC halt mask as new CPU came online */

 Update MCIP debug mask as new CPU came online */

 ARConnect can only send IPI to others */

	/*

	 * If receiver already has a pending interrupt, elide sending this one.

	 * Linux cross core calling works well with concurrent IPIs

	 * coalesced into one

	 * see arch/arc/kernel/smp.c: ipi_send_msg_one()

 Who sent the IPI */

 1,2,4,8... */

	/*

	 * In rare case, multiple concurrent IPIs sent to same target can

	 * possibly be coalesced by MCIP into 1 asserted IRQ, so @cpus can be

	 * "vectored" (multiple bits sets) as opposed to typical single bit

 0,1,2,3 */

/***************************************************************************

 * ARCv2 Interrupt Distribution Unit (IDU)

 *

 * Connects external "COMMON" IRQs to core intc, providing:

 *  -dynamic routing (IRQ affinity)

 *  -load balancing (Round Robin interrupt distribution)

 *  -1:N distribution

 *

 * It physically resides in the MCIP hw block

/*

 * Set the DEST for @cmn_irq to @cpu_mask (1 bit per core)

 errout if no online cpu per @cpumask */

	/*

	 * ARCv2 IDU HW does not support inverse polarity, so these are the

	 * only interrupt types supported.

	/*

	 * By default send all common interrupts to all available online CPUs.

	 * The affinity of common interrupts in IDU must be set manually since

	 * in some cases the kernel will not call irq_set_affinity() by itself:

	 *   1. When the kernel is not configured with support of SMP.

	 *   2. When the kernel is configured with support of SMP but upper

	 *      interrupt controllers does not support setting of the affinity

	 *      and cannot propagate it to IDU.

/*

 * [16, 23]: Statically assigned always private-per-core (Timers, WDT, IPI)

 * [24, 23+C]: If C > 0 then "C" common IRQs

 * [24+C, N]: Not statically assigned, private-per-core

 Parent interrupts (core-intc) are already mapped */

 Mask all common interrupts by default */

		/*

		 * Return parent uplink IRQs (towards core intc) 24,25,.....

		 * this step has been done before already

		 * however we need it to get the parent virq and set IDU handler

		 * as first level isr

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 * Vineetg: Aug 2009

 *  -"C" version of lowest level context switch asm macro called by schedular

 *   gcc doesn't generate the dward CFI info for hand written asm, hence can't

 *   backtrace out of it (e.g. tasks sleeping in kernel).

 *   So we cheat a bit by writing almost similar code in inline-asm.

 *  -This is a hacky way of doing things, but there is no other simple way.

 *   I don't want/intend to extend unwinding code to understand raw asm

 FP/BLINK save generated by gcc (standard function prologue */

 usual r25 placeholder */

 set ksp of outgoing task in tsk->thread.ksp */

		/*

		 * Workaround for NR_CPUS=4k

		 * %1 is bigger than 255 (S9 offset for st.as)

		/*

		 * setup _current_task with incoming tsk.

		 * optionally, set r25 to that as well

		 * For SMP extra work to get to &_current_task[cpu]

		 * (open coded SET_CURR_TASK_ON_CPU)

 get ksp of incoming task from tsk->thread.ksp */

 start loading it's CALLEE reg file */

 last (ret value) = prev : although for ARC it mov r0, r0 */

 FP/BLINK restore generated by gcc (standard func epilogue */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2011-12 Synopsys, Inc. (www.synopsys.com)

 number of irq lines coming in */

 Fixed by ISA */

/*

 * Early Hardware specific Interrupt setup

 * -Platform independent, needed for each CPU (not foldable into init_IRQ)

 * -Called very early (start_kernel -> setup_arch -> setup_processor)

 *

 * what it does ?

 * -Optionally, setup the High priority Interrupts as Level 2 IRQs

 Is timer high priority Interrupt (Level2 in ARCompact jargon) */

	/*

	 * Write to register, even if no LV2 IRQs configured to reset it

	 * in case bootloader had mucked with it

	/*

	 * Disable all IRQ lines so faulty external hardware won't

	 * trigger interrupt that kernel is not ready to handle.

/*

 * ARC700 core includes a simple on-chip intc supporting

 * -per IRQ enable/disable

 * -2 levels of interrupts (high/low)

 * -all interrupts being level triggered

 *

 * To reduce platform code, we assume all IRQs directly hooked-up into intc.

 * Platforms with external intc, hence cascaded IRQs, are free to over-ride

 * below, per IRQ.

	/*

	 * Needed for primary domain lookup to succeed

	 * This is a primary irqchip, and can never have a parent

/*

 * arch_local_irq_enable - Enable interrupts.

 *

 * 1. Explicitly called to re-enable interrupts

 * 2. Implicitly called from spin_unlock_irq, write_unlock_irq etc

 *    which maybe in hard ISR itself

 *

 * Semantics of this function change depending on where it is called from:

 *

 * -If called from hard-ISR, it must not invert interrupt priorities

 *  e.g. suppose TIMER is high priority (Level 2) IRQ

 *    Time hard-ISR, timer_interrupt( ) calls spin_unlock_irq several times.

 *    Here local_irq_enable( ) shd not re-enable lower priority interrupts

 * -If called from soft-ISR, it must re-enable all interrupts

 *    soft ISR are low priority jobs which can be very slow, thus all IRQs

 *    must be enabled while they run.

 *    Now hardware context wise we may still be in L2 ISR (not done rtie)

 *    still we must re-enable both L1 and L2 IRQs

 *  Another twist is prev scenario with flow being

 *     L1 ISR ==> interrupted by L2 ISR  ==> L2 soft ISR

 *     here we must not re-enable Ll as prev Ll Interrupt's h/w context will get

 *     over-written (this is deficiency in ARC700 Interrupt mechanism)

 Complex version for 2 IRQ levels */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 * RajeshwarR: Dec 11, 2007

 *   -- Added support for Inter Processor Interrupts

 *

 * Vineetg: Nov 1st, 2007

 *    -- Initial Write (Borrowed heavily from ARM)

 XXX: per cpu ? Only needed once in early seconday boot */

 Called from start_kernel */

/*

 * Read from DeviceTree and setup cpu possible mask. If there is no

 * "possible-cpus" property in DeviceTree pretend all [0..NR_CPUS-1] exist.

/*

 * Called from setup_arch() before calling setup_processor()

 *

 * - Initialise the CPU possible map early - this describes the CPUs

 *   which may be present or become present in the system.

 * - Call early smp init hook. This can initialize a specific multi-core

 *   IP which is say common to several platforms (hence not part of

 *   platform specific int_early() hook)

 called from init ( ) =>  process 1 */

	/*

	 * if platform didn't set the present map already, do it now

	 * boot cpu is set to present already by init/main.c

/*

 * Default smp boot helper for Run-on-reset case where all cores start off

 * together. Non-masters need to wait for Master to start running.

 * This is implemented using a flag in memory, which Non-masters spin-wait on.

 * Master sets it to cpu-id of core to "ungate" it.

 for halt-on-reset, we've waited already */

/*

 * The very first "C" code executed by secondary

 * Called from asm stub in head.S

 * "current"/R25 already setup by low level boot code

 MMU, Caches, Vector Table, Interrupts etc */

 Some SMP H/w setup - for each cpu */

/*

 * Called from kernel_init( ) -> smp_init( ) - for each CPU

 *

 * At this point, Secondary Processor  is "HALT"ed:

 *  -It booted, but was halted in head.S

 *  -It was configured to halt-on-reset

 *  So need to wake it up.

 *

 * Essential requirements being where to run from (PC) and stack (SP)

 wait for 1 sec after kicking the secondary */

/*

 * not supported here

****************************************************************************/

              Inter Processor Interrupt Handling                           */

****************************************************************************/

/*

 * In arches with IRQ for each msg type (above), receiver can use IRQ-id  to

 * figure out what msg was sent. For those which don't (ARC has dedicated IPI

 * IRQ), the msg-type needs to be conveyed via per-cpu data

	/*

	 * Atomically write new msg bit (in case others are writing too),

	 * and read back old value

	/*

	 * Call the platform specific IPI kick function, but avoid if possible:

	 * Only do so if there's no pending msg from other concurrent sender(s).

	 * Otherwise, receiver will see this msg as well when it takes the

	 * IPI corresponding to that msg. This is true, even if it is already in

	 * IPI handler, because !@old means it has not yet dequeued the msg(s)

	 * so @new msg can be a free-loader

/*

 * ipi_cpu_stop - handle IPI from smp_send_stop()

/*

 * arch-common ISR to handle for inter-processor interrupts

 * Has hooks for platform specific IPI

	/*

	 * "dequeue" the msg corresponding to this IPI (and possibly other

	 * piggybacked msg from elided IPIs: see ipi_send_msg_one() above)

/*

 * API called by platform code to hookup arch-common ISR to their IPI IRQ

 *

 * Note: If IPI is provided by platform (vs. say ARC MCIP), their intc setup/map

 * function needs to call call irq_set_percpu_devid() for IPI IRQ, otherwise

 * request_percpu_irq() below will fail

 Boot cpu calls request, all call enable */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 * Copyright (C) 2002-2006 Novell, Inc.

 *	Jan Beulich <jbeulich@novell.com>

 *

 * A simple API for unwinding kernel stacks.  This is used for

 * debugging and error reporting purposes.  The kernel doesn't need

 * full-blown stack unwinding with all the bells and whistles, so there

 * is not much point in implementing the full Dwarf2 unwind API.

 extern const u8 __start_unwind_hdr[], __end_unwind_hdr[];*/

 #define UNWIND_DEBUG */

/*

 * wrappers for header alloc (vs. calling one vs. other at call site)

 * to elide section mismatches warnings

 To avoid the pointer addition with NULL pointer.*/

 See if the linker provided table looks valid. */

__start_unwind_hdr, __end_unwind_hdr - __start_unwind_hdr);*/

			/* FIXME_Rajesh We have 4 instances of null addresses

			 * instead of the initial loc addr

			 * return;

 this is a CIE */

 Must be called with module_mutex held. */

 Must be called with module_mutex held. */

 XXX: SMP */

 CONFIG_MODULES */

 this is a CIE */

 || fde[1] > (unsigned long)(fde + 1) - (unsigned long)table->address) */

 this is not a valid FDE */

 this is not a (valid) CIE */

 check if augmentation size is first (and thus present) */

 check if augmentation string is nul-terminated */

 skip terminator */

 skip code alignment */

 skip data alignment */

 skip return address column */

 augmentation length */

	/* FIXME_Rajesh: Probably we are defining for the initial range as well;

	   return delta > 0;

 && advance_loc(*ptr.p16++, state); */

todo case DW_CFA_def_cfa_expression: */

todo case DW_CFA_expression: */

todo case DW_CFA_val_expression: */

		/*todo While in theory this should apply, gcc in practice omits

		  everything past the function prolog, and hence the location

		  never reaches the end of the function.

/* Unwind to previous to frame.  Returns 0 if successful, negative

 keep here temporarily */

 check if augmentation size is first (thus present) */

					/* chk for ignorable or already handled

 get code alignment factor */

 get data alignment factor */

 skip augmentation */

 skip augmentation */

	/* process instructions

	 * For ARC, we optimize by having blink(retAddrReg) with

	 * the sameValue in the leaf function, so we should not check

	 * state.regs[retAddrReg].where == Nowhere

	   || state.regs[retAddrReg].where == Nowhere */

 update frame */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Signal Handling for ARC

 *

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 *

 * vineetg: Jan 2010 (Restarting of timer related syscalls)

 *

 * vineetg: Nov 2009 (Everything needed for TIF_RESTORE_SIGMASK)

 *  -do_signal() supports TIF_RESTORE_SIGMASK

 *  -do_signal() no loner needs oldset, required by OLD sys_sigsuspend

 *  -sys_rt_sigsuspend() now comes from generic code, so discard arch implemen

 *  -sys_sigsuspend() no longer needs to fudge ptregs, hence that arg removed

 *  -sys_sigsuspend() no longer loops for do_signal(), sets TIF_xxx and leaves

 *   the job to do_signal()

 *

 * vineetg: July 2009

 *  -Modified Code to support the uClibc provided userland sigreturn stub

 *   to avoid kernel synthesing it on user stack at runtime, costing TLB

 *   probes and Cache line flushes.

 *

 * vineetg: July 2009

 *  -In stash_usr_regs( ) and restore_usr_regs( ), save/restore of user regs

 *   in done in block copy rather than one word at a time.

 *   This saves around 2K of code and improves LMBench lat_sig <catch>

 *

 * rajeshwarr: Feb 2009

 *  - Support for Realtime Signals

 *

 * vineetg: Aug 11th 2008: Bug #94183

 *  -ViXS were still seeing crashes when using insmod to load drivers.

 *   It turned out that the code to change Execute permssions for TLB entries

 *   of user was not guarded for interrupts (mod_tlb_permission)

 *   This was causing TLB entries to be overwritten on unrelated indexes

 *

 * Vineetg: July 15th 2008: Bug #94183

 *  -Exception happens in Delay slot of a JMP, and before user space resumes,

 *   Signal is delivered (Ctrl + C) = >SIGINT.

 *   setup_frame( ) sets up PC,SP,BLINK to enable user space signal handler

 *   to run, but doesn't clear the Delay slot bit from status32. As a result,

 *   on resuming user mode, signal handler branches off to BTA of orig JMP

 *  -FIX: clear the DE bit from status32 in setup_frame( )

 *

 * Rahul Trivedi, Kanika Nema: Codito Technologies 2004

 Always make any pending restarted system calls return -EINTR */

	/* Since we stacked the signal on a word boundary,

	 * then 'sp' should be word aligned here.  If it's

	 * not, then the user is trying to mess with us.

 Don't restart from sigreturn */

	/*

	 * Ensure that sigreturn always returns to user mode (in case the

	 * regs saved on user stack got fudged between save and sigreturn)

	 * Otherwise it is easy to panic the kernel with a custom

	 * signal handler and/or restorer which clobberes the status32/ret

	 * to return to a bogus location in kernel mode.

/*

 * Determine which stack to use..

	/* No matter what happens, 'sp' must be word

	 * aligned otherwise nasty things could happen

 ATPCS B01 mandates 8-byte alignment */

 Check that we can actually write to the signal frame */

	/*

	 * w/o SA_SIGINFO, struct ucontext is partially populated (only

	 * uc_mcontext/uc_sigmask) for kernel's normal user state preservation

	 * during signal handler execution. This works for SA_SIGINFO as well

	 * although the semantics are now overloaded (the same reg state can be

	 * inspected by userland: but are they allowed to fiddle with it ?

	/*

	 * SA_SIGINFO requires 3 args to signal handler:

	 *  #1: sig-no (common to any handler)

	 *  #2: struct siginfo

	 *  #3: struct ucontext (completely populated)

 setup args 2 and 3 for user mode handler */

		/*

		 * small optim to avoid unconditionally calling do_sigaltstack

		 * in sigreturn path, now that we only have rt_sigreturn

 #1 arg to the user Signal handler */

 setup PC of user space signal handler */

	/*

	 * handler returns using sigreturn stub provided already by userpsace

	 * If not, nuke the process right away

 User Stack for signal handler will be above the frame just carved */

	/*

	 * Bug 94183, Clear the DE bit, so that when signal handler

	 * starts to run, it doesn't use BTA

		/*

		 * ERESTARTNOHAND means that the syscall should

		 * only be restarted if there was no handler for

		 * the signal, and since we only get here if there

		 * is a handler, we don't restart

 ERESTART_xxx is internal */

		/*

		 * ERESTARTSYS means to restart the syscall if

		 * there is no handler or the handler was

		 * registered with SA_RESTART

		/*

		 * ERESTARTNOINTR means that the syscall should

		 * be called again after the signal handler returns.

		 * Setup reg state just as it was before doing the trap

		 * r0 has been clobbered with sys call ret code thus it

		 * needs to be reloaded with orig first arg to syscall

		 * in orig_r0. Rest of relevant reg-file:

		 * r8 (syscall num) and (r1 - r7) will be reset to

		 * their orig user space value when we ret from kernel

/*

 * OK, we're invoking a handler

 Set up the stack frame */

 No more restarts */

 No handler for syscall: restart it */

 No more restarts */

 If there's no signal to deliver, restore the saved sigmask back */

	/*

	 * ASM glue guarantees that this is only called when returning to

	 * user mode

 SPDX-License-Identifier: GPL-2.0-only

/*

 * kgdb support for ARC

 *

 * Copyright (C) 2012 Synopsys, Inc. (www.synopsys.com)

	/* trap_s 3 is used for breakpoints that overwrite existing

	 * instructions, while trap_s 4 is used for compiled breakpoints.

	 *

	 * with trap_s 3 breakpoints the original instruction needs to be

	 * restored and continuation needs to start at the location of the

	 * breakpoint.

	 *

	 * with trap_s 4 (compiled) breakpoints, continuation needs to

	 * start after the breakpoint.

 Default implementation passes get_irq_regs() but we don't */

 breakpoint instruction: TRAP_S 0x3 */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 pad

 gp

 pad2

 efa

 stop_pc

 efa update invalid */

 PC updated via @ret */

		/*

		 * itemized copy not needed like above as layout of regs (r30,r58,r59)

		 * is exactly same in kernel (pt_regs) and userspace (user_regs_arcv2)

 r30 only */

 r30 only */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 Attempt to probe at unaligned address */

 Address should not be in exception handling code */

 Can we remove the kprobe in the middle of kprobe handling? */

	/* Remove the trap instructions inserted for single step and

	 * restore the original instructions

	/* Copy the opcode back to the kprobe location and execute the

	 * instruction. Because of this we will not be able to get into the

	 * same kprobe until this kprobe is done

	/* Now we insert the trap at the next location after this instruction to

	 * single step. If it is a branch we insert the trap at possible branch

	 * targets

 We are in a delay slot with the branch taken */

 Branch not taken */

				/* next pc is taken from bta after executing the

				 * delay slot instruction

		/*

		 * We have reentered the kprobe_handler, since another kprobe

		 * was hit while within the handler, we save the original

		 * kprobes and single step on the instruction of the new probe

		 * without calling any user handlers to avoid recursive

		 * kprobes.

		/* If we have no pre-handler or it returned 0, we continue with

		 * normal processing. If we have a pre-handler and it returned

		 * non-zero - which means user handler setup registers to exit

		 * to another instruction, we must skip the single stepping.

 no_kprobe: */

 Rearm the kprobe */

	/*

	 * When we return from trap instruction we go to the next instruction

	 * We restored the actual instruction in resume_exectuiont and we to

	 * return to the same address and execute it

/*

 * Fault can be for the instruction being single stepped or for the

 * pre/post handlers in the module.

 * This is applicable for applications like user probes, where we have the

 * probe in user space and the handlers in the kernel

		/*

		 * We are here because the instruction being single stepped

		 * caused the fault. We reset the current kprobe and allow the

		 * exception handler as if it is regular exception. In our

		 * case it doesn't matter because the system will be halted

		/*

		 * We are here because the instructions in the pre/post handler

		 * caused the fault.

		/*

		 * In case the user-specified fault handler returned zero,

		 * try to fix up.

		/*

		 * fixup_exception() could not handle it,

		 * Let do_page_fault() fix it.

 Replace the return addr with trampoline addr */

	/* By returning a non zero value, we are telling the kprobe handler

	 * that we don't want the post_handler to run

 Registering the trampoline code for the kret probe */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

/*

 * This gets called before relocation loop in generic loader

 * Make a note of the section index of unwinding section

 sec index for sym tbl */

 sec index for relo sec */

	/*

	 * @relsec has relocations e.g. .rela.init.text

	 * @tgtsec is section to patch e.g. .init.text

 Loop thru entries in relocation section */

 This is where to make the change */

		/* This is the symbol it is referring to.  Note that all

		/* This assumes modules are built with -mlong-calls

		 * so any branches/jumps are absolute 32 bit jmps

		 * global data access again is abs 32 bit.

		 * Both of these are handled by same relocation type

 ME ( S + A ) */

 ( S + A ) */

 ( S + A ) - PDATA ) */

/* Just before lift off: After sections have been relocated, we add the

 * dwarf section to unwinder table pool

 * This couldn't be done in module_frob_arch_sections() because

 * relocations had not been applied by then

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2011-2012 Synopsys, Inc. (www.synopsys.com)

 Halt the processor */

 Soft reset : jump to reset vector */

 FIXME ::  power off ??? */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2011-12 Synopsys, Inc. (www.synopsys.com)

/*

 * Late Interrupt system init called from start_kernel for Boot CPU only

 *

 * Since slab must already be initialized, platforms can start doing any

 * needed request_irq( )s

	/*

	 * process the entire interrupt tree in one go

	 * Any external intc will be setup provided DT chains them

	 * properly

 a SMP H/w block could do IPI IRQ request here */

/*

 * "C" Entry point for any ARC ISR, called from low level vector handler

 * @irq is the vector number read from ICAUSE reg of on-chip intc

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2011-2012 Synopsys (www.synopsys.com)

 *

 * vineetg : May 2011

 *  -Adapted (from .26 to .35)

 *  -original contribution by Tim.yao@amlogic.com

 sysctl hooks */

 Enabled by default */

 Only 1 warning by default */

 register write back */

 register write back */

 write fix-up */

/*

 * Handle an unaligned access

 * Returns 0 if successfully handled, 1 if some error happened

 handle user mode only and only if enabled by sysadmin */

 Add rate limiting if it gets down to it */

 ldb/stb should not have unaligned exception */

 clear any remanants of delay slot */

 handle zero-overhead-loop */

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 2004, 2007-2010, 2011-2012 Synopsys, Inc. (www.synopsys.com)

 SPDX-License-Identifier: GPL-2.0-only

/*

 * ARC simulation Platform support code

 *

 * Copyright (C) 2012 Synopsys, Inc. (www.synopsys.com)

/*----------------------- Machine Descriptions ------------------------------

 *

 * Machine description is simply a set of platform/board specific callbacks

 * This is not directly related to DeviceTree based dynamic device creation,

 * however as part of early device tree scan, we also select the right

 * callback set, by matching the DT compatible name.

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Abilis Systems TB10x platform initialisation

 *

 * Copyright (C) Abilis Systems 2012

 *

 * Author: Christian Ruppert <christian.ruppert@abilis.com>

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to io context handling

/*

 * For io context allocations

/**

 * get_io_context - increment reference count to io_context

 * @ioc: io_context to get

 *

 * Increment reference count to @ioc.

/*

 * Exit an icq. Called with ioc locked for blk-mq, and with both ioc

 * and queue locked for legacy.

/*

 * Release an icq. Called with ioc locked for blk-mq, and with both ioc

 * and queue locked for legacy.

	/*

	 * Both setting lookup hint to and clearing it from @icq are done

	 * under queue_lock.  If it's not pointing to @icq now, it never

	 * will.  Hint assignment itself can race safely.

	/*

	 * @icq->q might have gone away by the time RCU callback runs

	 * making it impossible to determine icq_cache.  Record it in @icq.

/*

 * Slow path for ioc release in put_io_context().  Performs double-lock

 * dancing to unlink all icq's and then frees ioc.

 Make sure q and icq cannot be freed. */

 Re-acquire the locks in the correct order. */

			/*

			 * The icq may have been destroyed when the ioc lock

			 * was released.

/**

 * put_io_context - put a reference of io_context

 * @ioc: io_context to put

 *

 * Decrement reference count of @ioc and release it if the count reaches

 * zero.

	/*

	 * Releasing ioc requires reverse order double locking and we may

	 * already be holding a queue_lock.  Do it asynchronously from wq.

/**

 * put_io_context_active - put active reference on ioc

 * @ioc: ioc of interest

 *

 * Undo get_io_context_active().  If active reference reaches zero after

 * put, @ioc can never issue further IOs and ioscheds are notified.

 Called by the exiting task */

/**

 * ioc_clear_queue - break any ioc association with the specified queue

 * @q: request_queue being cleared

 *

 * Walk @q->icq_list and exit all io_cq's.

 initialize */

	/*

	 * Try to install.  ioc shouldn't be installed if someone else

	 * already did or @task, which isn't %current, is exiting.  Note

	 * that we need to allow ioc creation on exiting %current as exit

	 * path may issue IOs from e.g. exit_files().  The exit path is

	 * responsible for not issuing IO after exit_io_context().

/**

 * get_task_io_context - get io_context of a task

 * @task: task of interest

 * @gfp_flags: allocation flags, used if allocation is necessary

 * @node: allocation node, used if allocation is necessary

 *

 * Return io_context of @task.  If it doesn't exist, it is created with

 * @gfp_flags and @node.  The returned io_context has its reference count

 * incremented.

 *

 * This function always goes through task_lock() and it's better to use

 * %current->io_context + get_io_context() for %current.

/**

 * ioc_lookup_icq - lookup io_cq from ioc

 * @ioc: the associated io_context

 * @q: the associated request_queue

 *

 * Look up io_cq associated with @ioc - @q pair from @ioc.  Must be called

 * with @q->queue_lock held.

	/*

	 * icq's are indexed from @ioc using radix tree and hint pointer,

	 * both of which are protected with RCU.  All removals are done

	 * holding both q and ioc locks, and we're holding q lock - if we

	 * find a icq which points to us, it's guaranteed to be valid.

 allowed to race */

/**

 * ioc_create_icq - create and link io_cq

 * @ioc: io_context of interest

 * @q: request_queue of interest

 * @gfp_mask: allocation mask

 *

 * Make sure io_cq linking @ioc and @q exists.  If icq doesn't exist, they

 * will be created using @gfp_mask.

 *

 * The caller is responsible for ensuring @ioc won't go away and @q is

 * alive and will stay alive until this function returns.

 allocate stuff */

 lock both q and ioc and try to link @icq */

 SPDX-License-Identifier: GPL-2.0

/*

 * fs/ioprio.c

 *

 * Copyright (C) 2004 Jens Axboe <axboe@kernel.dk>

 *

 * Helper functions for setting/querying io priorities of processes. The

 * system calls closely mimmick getpriority/setpriority, see the man page for

 * those. The prio argument is a composite of prio class and prio data, where

 * the data argument has meaning within that class. The standard scheduling

 * classes have 8 distinct prio levels, with 0 being the highest prio and 7

 * being the lowest.

 *

 * IOW, setting BE scheduling class with prio 2 is done ala:

 *

 * unsigned int prio = (IOPRIO_CLASS_BE << IOPRIO_CLASS_SHIFT) | 2;

 *

 * ioprio_set(PRIO_PROCESS, pid, prio);

 *

 * See also Documentation/block/ioprio.rst

 *

			/*

			 * Originally this only checked for CAP_SYS_ADMIN,

			 * which was implicitly allowed for pid 0 by security

			 * modules such as SELinux. Make sure we check

			 * CAP_SYS_ADMIN first to avoid a denial/avc for

			 * possibly missing CAP_SYS_NICE permission.

 rt has prio field too */

 SPDX-License-Identifier: GPL-2.0

/*

 * CPU <-> hardware queue mapping helpers

 *

 * Copyright (C) 2013-2014 Jens Axboe

	/*

	 * Spread queues among present CPUs first for minimizing

	 * count of dead queues which are mapped by all un-present CPUs

		/*

		 * First do sequential mapping between CPUs and queues.

		 * In case we still have CPUs to map, and we have some number of

		 * threads per cores then map sibling threads to the same queue

		 * for performance optimizations.

/**

 * blk_mq_hw_queue_to_node - Look up the memory node for a hardware queue index

 * @qmap: CPU to hardware queue map.

 * @index: hardware queue index.

 *

 * We have no quick way of doing reverse lookups. This is only used at

 * queue init time, so runtime isn't important.

 SPDX-License-Identifier: GPL-2.0

 check if partition is aligned to blocksize */

	/*

	 * Reopen the device to revalidate the driver state and force a

	 * partition rescan.

 Invalidate the page cache, including dirty pages */

/*

 * This is the equivalent of compat_ptr_ioctl(), to be used by block

 * drivers that implement only commands that are completely compatible

 * between 32-bit and 64-bit user space

	/*

	 * We need to set the startsect first, the driver may

	 * want to override it.

	/*

	 * We need to set the startsect first, the driver may

	 * want to override it.

 set the logical block size */

/*

 * Common commands that are handled the same way on native and compat

 * user space. Note the separate arg/argp parameters that are needed

 * to deal with the compat_ptr() conversion.

 get block device logical block size */

 get block device physical block size */

/*

 * Always keep this in sync with compat_blkdev_ioctl()

 * to handle all incompatible commands in both functions.

 *

 * New commands must be compatible and go into blkdev_common_ioctl

	/*

	 * O_NDELAY can be altered using fcntl(.., F_SETFL, ..), so we have

	 * to updated it before every ioctl.

 These need separate implementations for the data structure */

 Compat mode returns 32-bit data instead of 'long' */

 The data is compatible, but the command number is different */

 get block device soft block size (cf. BLKSSZGET) */

 Incompatible alignment on i386 */

/* Most of the generic ioctls are handled in the normal fallback path.

   This assumes the blkdev's low level compat_ioctl always returns

	/*

	 * O_NDELAY can be altered using fcntl(.., F_SETFL, ..), so we have

	 * to updated it before every ioctl.

 These need separate implementations for the data structure */

 Compat mode returns 32-bit data instead of 'long' */

 The data is compatible, but the command number is different */

 get the logical block size (cf. BLKSSZGET) */

 Incompatible alignment on i386 */

 SPDX-License-Identifier: GPL-2.0

/* bounce buffer handling for block devices

 *

 * - Split from highmem.c

/*

 * Simple bounce buffer support for highmem pages. Depending on the

 * queue gfp mask set, *to may or may not be a highmem page. kmap it

 * always, it will do the Right Thing

	/*

	 * The bio of @from is created by bounce, so we can iterate

	 * its bvec from start to end, but the @from->bi_iter can't be

	 * trusted because it might be changed by splitting.

			/*

			 * fromvec->bv_offset and fromvec->bv_len might have

			 * been modified by the block layer, so use the original

			 * copy, bounce_copy_vec already uses tovec->bv_len

	/*

	 * free up bounce indirect pages used

	/*

	 * Pre immutable biovecs, __bio_clone() used to just do a memcpy from

	 * bio_src->bi_io_vec to bio->bi_io_vec.

	 *

	 * We can't do that anymore, because:

	 *

	 *  - The point of cloning the biovec is to produce a bio with a biovec

	 *    the caller can modify: bi_idx and bi_bvec_done should be 0.

	 *

	 *  - The original bio could've had more than BIO_MAX_VECS biovecs; if

	 *    we tried to clone the whole thing bio_alloc_bioset() would fail.

	 *    But the clone should succeed as long as the number of biovecs we

	 *    actually need to allocate is fewer than BIO_MAX_VECS.

	 *

	 *  - Lastly, bi_vcnt should not be looked at or relied upon by code

	 *    that does not own the bio - reason being drivers don't use it for

	 *    iterating over the biovec anymore, so expecting it to be kept up

	 *    to date (i.e. for clones that share the parent biovec) is just

	 *    asking for trouble and would force extra work on

	 *    __bio_clone_fast() anyways.

	/*

	 * Bvec table can't be updated by bio_for_each_segment_all(),

	 * so retrieve bvec from the table directly. This way is safe

	 * because the 'bio' is single-page bvec.

 SPDX-License-Identifier: GPL-2.0

/*

 * Block stat tracking code

 *

 * Copyright (C) 2016 Jens Axboe

 src is a per-cpu stat, mean isn't initialized */

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to generic helpers functions

 In case the discard granularity isn't set by buggy device driver */

 In case the discard request is in a partition */

		/*

		 * Check whether the discard bio starts at a discard_granularity

		 * aligned LBA,

		 * - If no: set (granularity_aligned_lba - sector_mapped) to

		 *   bi_size of the first split bio, then the second bio will

		 *   start at a discard_granularity aligned LBA on the device.

		 * - If yes: use bio_aligned_discard_max_sectors() as the max

		 *   possible bi_size of the first split bio. Then when this bio

		 *   is split in device drive, the split ones are very probably

		 *   to be aligned to discard_granularity of the device's queue.

		/*

		 * We can loop for a long time in here, if someone does

		 * full device discards (like mkfs). Be nice and allow

		 * us to schedule out to avoid softlocking if preempt

		 * is disabled.

/**

 * blkdev_issue_discard - queue a discard

 * @bdev:	blockdev to issue discard for

 * @sector:	start sector

 * @nr_sects:	number of sectors to discard

 * @gfp_mask:	memory allocation flags (for bio_alloc)

 * @flags:	BLKDEV_DISCARD_* flags to control behaviour

 *

 * Description:

 *    Issue a discard request for the sectors in question.

/**

 * __blkdev_issue_write_same - generate number of bios with same page

 * @bdev:	target blockdev

 * @sector:	start sector

 * @nr_sects:	number of sectors to write

 * @gfp_mask:	memory allocation flags (for bio_alloc)

 * @page:	page containing data to write

 * @biop:	pointer to anchor bio

 *

 * Description:

 *  Generate and issue number of bios(REQ_OP_WRITE_SAME) with same page.

 Ensure that max_write_same_sectors doesn't overflow bi_size */

/**

 * blkdev_issue_write_same - queue a write same operation

 * @bdev:	target blockdev

 * @sector:	start sector

 * @nr_sects:	number of sectors to write

 * @gfp_mask:	memory allocation flags (for bio_alloc)

 * @page:	page containing data

 *

 * Description:

 *    Issue a write same request for the sectors in question.

 Ensure that max_write_zeroes_sectors doesn't overflow bi_size */

/*

 * Convert a number of 512B sectors to a number of pages.

 * The result is limited to a number of pages that can fit into a BIO.

 * Also make sure that the result is always at least 1 (page) for the cases

 * where nr_sects is lower than the number of sectors in a page.

/**

 * __blkdev_issue_zeroout - generate number of zero filed write bios

 * @bdev:	blockdev to issue

 * @sector:	start sector

 * @nr_sects:	number of sectors to write

 * @gfp_mask:	memory allocation flags (for bio_alloc)

 * @biop:	pointer to anchor bio

 * @flags:	controls detailed behavior

 *

 * Description:

 *  Zero-fill a block range, either using hardware offload or by explicitly

 *  writing zeroes to the device.

 *

 *  If a device is using logical block provisioning, the underlying space will

 *  not be released if %flags contains BLKDEV_ZERO_NOUNMAP.

 *

 *  If %flags contains BLKDEV_ZERO_NOFALLBACK, the function will return

 *  -EOPNOTSUPP if no explicit hardware offload for zeroing is provided.

/**

 * blkdev_issue_zeroout - zero-fill a block range

 * @bdev:	blockdev to write

 * @sector:	start sector

 * @nr_sects:	number of sectors to write

 * @gfp_mask:	memory allocation flags (for bio_alloc)

 * @flags:	controls detailed behavior

 *

 * Description:

 *  Zero-fill a block range, either using hardware offload or by explicitly

 *  writing zeroes to the device.  See __blkdev_issue_zeroout() for the

 *  valid values for %flags.

 No zeroing offload support */

			/*

			 * Zeroing offload support was indicated, but the

			 * device reported ILLEGAL REQUEST (for some devices

			 * there is no non-destructive way to verify whether

			 * WRITE ZEROES is actually supported).

 SPDX-License-Identifier: GPL-2.0

/*

 * Block rq-qos policy for assigning an I/O priority class to requests.

 *

 * Using an rq-qos policy for assigning I/O priority class has two advantages

 * over using the ioprio_set() system call:

 *

 * - This policy is cgroup based so it has all the advantages of cgroups.

 * - While ioprio_set() does not affect page cache writeback I/O, this rq-qos

 *   controller affects page cache writeback I/O for filesystems that support

 *   assiociating a cgroup with writeback I/O. See also

 *   Documentation/admin-guide/cgroup-v2.rst.

/**

 * enum prio_policy - I/O priority class policy.

 * @POLICY_NO_CHANGE: (default) do not modify the I/O priority class.

 * @POLICY_NONE_TO_RT: modify IOPRIO_CLASS_NONE into IOPRIO_CLASS_RT.

 * @POLICY_RESTRICT_TO_BE: modify IOPRIO_CLASS_NONE and IOPRIO_CLASS_RT into

 *		IOPRIO_CLASS_BE.

 * @POLICY_ALL_TO_IDLE: change the I/O priority class into IOPRIO_CLASS_IDLE.

 *

 * See also <linux/ioprio.h>.

/**

 * struct ioprio_blkg - Per (cgroup, request queue) data.

 * @pd: blkg_policy_data structure.

/**

 * struct ioprio_blkcg - Per cgroup data.

 * @cpd: blkcg_policy_data structure.

 * @prio_policy: One of the IOPRIO_CLASS_* values. See also <linux/ioprio.h>.

 kernfs_fop_write_iter() terminates 'buf' with '\0'. */

 sentinel */

 cgroup v2 attributes */

 cgroup v1 attributes */

	/*

	 * Except for IOPRIO_CLASS_NONE, higher I/O priority numbers

	 * correspond to a lower priority. Hence, the max_t() below selects

	 * the lower priority of bi_ioprio and the cgroup I/O priority class.

	 * If the cgroup policy has been set to POLICY_NO_CHANGE == 0, the

	 * bio I/O priority is not modified. If the bio I/O priority equals

	 * IOPRIO_CLASS_NONE, the cgroup I/O priority is assigned to the bio.

	/*

	 * Registering the rq-qos policy after activating the blk-cgroup

	 * policy guarantees that ioprio_blkcg_from_bio(bio) != NULL in the

	 * rq-qos callbacks.

 SPDX-License-Identifier: GPL-2.0

/*

 * Disk events - monitor disk events like media change and eject request.

 all disk_event's */

 the associated disk */

 protects blocking */

 event blocking depth */

 events already sent out */

 events being cleared */

 interval, -1 for default */

 list of all disk_events */

 disable in-kernel polling by default */

	/*

	 * If device-specific poll interval is set, always use it.  If

	 * the default is being used, poll if the POLL flag is set.

/**

 * disk_block_events - block and flush disk event checking

 * @disk: disk to block events for

 *

 * On return from this function, it is guaranteed that event checking

 * isn't in progress and won't happen until unblocked by

 * disk_unblock_events().  Events blocking is counted and the actual

 * unblocking happens after the matching number of unblocks are done.

 *

 * Note that this intentionally does not block event checking from

 * disk_clear_events().

 *

 * CONTEXT:

 * Might sleep.

	/*

	 * Outer mutex ensures that the first blocker completes canceling

	 * the event work before further blockers are allowed to finish.

/**

 * disk_unblock_events - unblock disk event checking

 * @disk: disk to unblock events for

 *

 * Undo disk_block_events().  When the block count reaches zero, it

 * starts events polling if configured.

 *

 * CONTEXT:

 * Don't care.  Safe to call from irq context.

/**

 * disk_flush_events - schedule immediate event checking and flushing

 * @disk: disk to check and flush events for

 * @mask: events to flush

 *

 * Schedule immediate event checking on @disk if not blocked.  Events in

 * @mask are scheduled to be cleared from the driver.  Note that this

 * doesn't clear the events from @disk->ev.

 *

 * CONTEXT:

 * If @mask is non-zero must be called with disk->open_mutex held.

/*

 * Tell userland about new events.  Only the events listed in @disk->events are

 * reported, and only if DISK_EVENT_FLAG_UEVENT is set.  Otherwise, events are

 * processed internally but never get reported to userland.

 check events */

 accumulate pending events and schedule next poll if necessary */

/**

 * disk_clear_events - synchronously check, clear and return pending events

 * @disk: disk to fetch and clear events from

 * @mask: mask of events to be fetched and cleared

 *

 * Disk events are synchronously checked and pending events in @mask

 * are cleared and returned.  This ignores the block count.

 *

 * CONTEXT:

 * Might sleep.

	/*

	 * store the union of mask and ev->clearing on the stack so that the

	 * race with disk_flush_events does not cause ambiguity (ev->clearing

	 * can still be modified even if events are blocked).

	/*

	 * if ev->clearing is not 0, the disk_flush_events got called in the

	 * middle of this function, so we want to run the workfn without delay.

 then, fetch and clear pending events */

/**

 * bdev_check_media_change - check if a removable media has been changed

 * @bdev: block device to check

 *

 * Check whether a removable media has been changed, and attempt to free all

 * dentries and inodes and invalidates all block device page cache entries in

 * that case.

 *

 * Returns %true if the block device changed, or %false if not.

/**

 * disk_force_media_change - force a media change event

 * @disk: the disk which will raise the event

 * @events: the events to raise

 *

 * Generate uevents for the disk. If DISK_EVENT_MEDIA_CHANGE is present,

 * attempt to free all dentries and inodes and invalidates all block

 * device page cache entries in that case.

 *

 * Returns %true if DISK_EVENT_MEDIA_CHANGE was raised, or %false if not.

/*

 * Separate this part out so that a different pointer for clearing_ptr can be

 * passed in for disk_clear_events.

/*

 * A disk events enabled device has the following sysfs nodes under

 * its /sys/block/X/ directory.

 *

 * events		: list of all supported events

 * events_async		: list of events which can be detected w/o polling

 *			  (always empty, only for backwards compatibility)

 * events_poll_msecs	: polling interval, 0: disable, -1: system default

/*

 * The default polling interval can be specified by the kernel

 * parameter block.events_dfl_poll_msecs which defaults to 0

 * (disable).  This can also be modified runtime by writing to

 * /sys/module/block/parameters/events_dfl_poll_msecs.

/*

 * disk_{alloc|add|del|release}_events - initialize and destroy disk_events.

	/*

	 * Block count is initialized to 1 and the following initial

	 * unblock kicks it into action.

 the block count should be 1 from disk_del_events() */

 SPDX-License-Identifier: GPL-2.0

/*

 * Bad block management

 *

 * - Heavily based on MD badblocks code from Neil Brown

 *

 * Copyright (c) 2015, Intel Corporation.

/**

 * badblocks_check() - check a given range for bad sectors

 * @bb:		the badblocks structure that holds all badblock information

 * @s:		sector (start) at which to check for badblocks

 * @sectors:	number of sectors to check for badblocks

 * @first_bad:	pointer to store location of the first badblock

 * @bad_sectors: pointer to store number of badblocks after @first_bad

 *

 * We can record which blocks on each device are 'bad' and so just

 * fail those blocks, or that stripe, rather than the whole device.

 * Entries in the bad-block table are 64bits wide.  This comprises:

 * Length of bad-range, in sectors: 0-511 for lengths 1-512

 * Start of bad-range, sector offset, 54 bits (allows 8 exbibytes)

 *  A 'shift' can be set so that larger blocks are tracked and

 *  consequently larger devices can be covered.

 * 'Acknowledged' flag - 1 bit. - the most significant bit.

 *

 * Locking of the bad-block table uses a seqlock so badblocks_check

 * might need to retry if it is very unlucky.

 * We will sometimes want to check for bad blocks in a bi_end_io function,

 * so we use the write_seqlock_irq variant.

 *

 * When looking for a bad block we specify a range and want to

 * know if any block in the range is bad.  So we binary-search

 * to the last range that starts at-or-before the given endpoint,

 * (or "before the sector after the target range")

 * then see if it ends after the given start.

 *

 * Return:

 *  0: there are no known bad blocks in the range

 *  1: there are known bad block which are all acknowledged

 * -1: there are bad blocks which have not yet been acknowledged in metadata.

 * plus the start/length of the first bad section we overlap.

 round the start down, and the end up */

 'target' is now the first block after the bad range */

	/* Binary search between lo and hi for 'target'

	 * i.e. for the last range that starts before 'target'

	/* INVARIANT: ranges before 'lo' and at-or-after 'hi'

	 * are known not to be the last range before target.

	 * VARIANT: hi-lo is the number of possible

	 * ranges, and decreases until it reaches 1

			/* This could still be the one, earlier ranges

			 * could not.

 This and later ranges are definitely out. */

 'lo' might be the last that started before target, but 'hi' isn't */

		/* need to check all range that end after 's' to see if

		 * any are unacknowledged.

				/* starts before the end, and finishes after

				 * the start, so they must overlap

/**

 * badblocks_set() - Add a range of bad blocks to the table.

 * @bb:		the badblocks structure that holds all badblock information

 * @s:		first sector to mark as bad

 * @sectors:	number of sectors to mark as bad

 * @acknowledged: weather to mark the bad sectors as acknowledged

 *

 * This might extend the table, or might contract it if two adjacent ranges

 * can be merged. We binary-search to find the 'insertion' point, then

 * decide how best to handle it.

 *

 * Return:

 *  0: success

 *  1: failed to set badblocks (out of space)

 badblocks are disabled */

 round the start down, and the end up */

 Find the last range that starts at-or-before 's' */

		/* we found a range that might merge with the start

		 * of our new range

 Yes, we can merge with a previous range */

 new range covers old */

				/* does not all fit in one range,

				 * make p[lo] maximal

		/* 'hi' points to the first range that starts after 's'.

		 * Maybe we can merge with the start of that range

 merging is possible */

 full overlap */

 we might be able to combine lo and hi */

 Note: 's' is at the end of 'lo' */

 yes, we can combine them */

		/* didn't merge (it all).

		 * Need to add a range just before 'hi'

 No room for more */

/**

 * badblocks_clear() - Remove a range of bad blocks to the table.

 * @bb:		the badblocks structure that holds all badblock information

 * @s:		first sector to mark as bad

 * @sectors:	number of sectors to mark as bad

 *

 * This may involve extending the table if we spilt a region,

 * but it must not fail.  So if the table becomes full, we just

 * drop the remove request.

 *

 * Return:

 *  0: success

 *  1: failed to clear badblocks

		/* When clearing we round the start up and the end down.

		 * This should not matter as the shift should align with

		 * the block size and no rounding should ever be needed.

		 * However it is better the think a block is bad when it

		 * isn't than to think a block is not bad when it is.

 Find the last range that starts before 'target' */

		/* p[lo] is the last range that could overlap the

		 * current range.  Earlier ranges could also overlap,

		 * but only this one can overlap the end of the range.

 Partial overlap, leave the tail of this range */

 we need to split this range */

 there is no longer an overlap */

 This range does overlap */

 Keep the early parts of this range. */

 now low doesn't overlap, so.. */

		/* 'lo' is strictly before, 'hi' is strictly after,

		 * anything between needs to be discarded

/**

 * ack_all_badblocks() - Acknowledge all bad blocks in a list.

 * @bb:		the badblocks structure that holds all badblock information

 *

 * This only succeeds if ->changed is clear.  It is used by

 * in-kernel metadata updates

 no point even trying */

/**

 * badblocks_show() - sysfs access to bad-blocks list

 * @bb:		the badblocks structure that holds all badblock information

 * @page:	buffer received from sysfs

 * @unack:	weather to show unacknowledged badblocks

 *

 * Return:

 *  Length of returned data

/**

 * badblocks_store() - sysfs access to bad-blocks list

 * @bb:		the badblocks structure that holds all badblock information

 * @page:	buffer received from sysfs

 * @len:	length of data received from sysfs

 * @unack:	weather to show unacknowledged badblocks

 *

 * Return:

 *  Length of the buffer processed or -ve error.

/**

 * badblocks_init() - initialize the badblocks structure

 * @bb:		the badblocks structure that holds all badblock information

 * @enable:	weather to enable badblocks accounting

 *

 * Return:

 *  0: success

 *  -ve errno: on error

/**

 * badblocks_exit() - free the badblocks structure

 * @bb:		the badblocks structure that holds all badblock information

 SPDX-License-Identifier: GPL-2.0-only

/*

 * Copyright (C) 1991, 1992  Linus Torvalds

 * Copyright (C) 2001  Andrea Arcangeli <andrea@suse.de> SuSE

 * Copyright (C) 2016 - 2020 Christoph Hellwig

 avoid the need for a I/O completion work item */

	/*

	 * Grab an extra reference to ensure the dio structure which is embedded

	 * into the first bio stays around.

		/*

		 * Users don't rely on the iterator being in any particular

		 * state for async I/O returning -EIOCBQUEUED, hence we can

		 * avoid expensive iov_iter_advance(). Bypass

		 * bio_iov_iter_get_pages() and set the bvec directly.

/*

 * for a block special file file_inode(file)->i_size is zero

 * so we compute the size by hand (just as in block_read/write above)

	/*

	 * There is no need to serialise calls to blkdev_issue_flush with

	 * i_mutex and doing so causes performance issues with concurrent

	 * O_SYNC writers to a block device.

	/*

	 * Preserve backwards compatibility and allow large file access

	 * even if userspace doesn't ask for it explicitly. Some mkfs

	 * binary needs it. We might want to drop this workaround

	 * during an unstable branch.

/*

 * Write data to the block device.  Only intended for the block device itself

 * and the raw driver which basically is a fake block device.

 *

 * Does not take i_mutex for the write and thus is not for general purpose

 * use.

 Fail if we don't recognize the flags. */

 Don't go off the end of the device. */

	/*

	 * Don't allow IO that isn't aligned to logical block size.

 Invalidate the page cache, including dirty pages. */

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to generic timeout handling of requests.

 CONFIG_FAIL_IO_TIMEOUT */

/**

 * blk_abort_request - Request recovery for the specified command

 * @req:	pointer to the request of interest

 *

 * This function requests that the block layer start recovery for the

 * request by deleting the timer and calling the q's timeout function.

 * LLDDs who implement their own error recovery MAY ignore the timeout

 * event if they generated blk_abort_request.

	/*

	 * All we need to ensure is that timeout scan takes place

	 * immediately and that scan sees the new timeout value.

	 * No need for fancy synchronizations.

/*

 * Just a rough estimate, we don't care about specific values for timeouts.

/**

 * blk_add_timer - Start timeout timer for a single request

 * @req:	request that is about to start running.

 *

 * Notes:

 *    Each request has its own timer, and as it is added to the queue, we

 *    set up the timer. When the request completes, we cancel the timer.

	/*

	 * Some LLDs, like scsi, peek at the timeout to prevent a

	 * command from being retried forever.

	/*

	 * If the timer isn't already pending or this timeout is earlier

	 * than an existing one, modify the timer. Round up to next nearest

	 * second.

		/*

		 * Due to added timer slack to group timers, the timer

		 * will often be a little in front of what we asked for.

		 * So apply some tolerance here too, otherwise we keep

		 * modifying the timer because expires for value X

		 * will be X + something.

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to setting various queue properties from drivers

/**

 * blk_set_default_limits - reset limits to default values

 * @lim:  the queue_limits structure to reset

 *

 * Description:

 *   Returns a queue_limit struct to its default state.

/**

 * blk_set_stacking_limits - set default limits for stacking devices

 * @lim:  the queue_limits structure to reset

 *

 * Description:

 *   Returns a queue_limit struct to its default state. Should be used

 *   by stacking drivers like DM that have no internal limits.

 Inherit limits from component devices */

/**

 * blk_queue_bounce_limit - set bounce buffer limit for queue

 * @q: the request queue for the device

 * @bounce: bounce limit to enforce

 *

 * Description:

 *    Force bouncing for ISA DMA ranges or highmem.

 *

 *    DEPRECATED, don't use in new code.

/**

 * blk_queue_max_hw_sectors - set max sectors for a request for this queue

 * @q:  the request queue for the device

 * @max_hw_sectors:  max hardware sectors in the usual 512b unit

 *

 * Description:

 *    Enables a low level driver to set a hard upper limit,

 *    max_hw_sectors, on the size of requests.  max_hw_sectors is set by

 *    the device driver based upon the capabilities of the I/O

 *    controller.

 *

 *    max_dev_sectors is a hard limit imposed by the storage device for

 *    READ/WRITE requests. It is set by the disk driver.

 *

 *    max_sectors is a soft limit imposed by the block layer for

 *    filesystem type requests.  This value can be overridden on a

 *    per-device basis in /sys/block/<device>/queue/max_sectors_kb.

 *    The soft limit can not exceed max_hw_sectors.

/**

 * blk_queue_chunk_sectors - set size of the chunk for this queue

 * @q:  the request queue for the device

 * @chunk_sectors:  chunk sectors in the usual 512b unit

 *

 * Description:

 *    If a driver doesn't want IOs to cross a given chunk size, it can set

 *    this limit and prevent merging across chunks. Note that the block layer

 *    must accept a page worth of data at any offset. So if the crossing of

 *    chunks is a hard limitation in the driver, it must still be prepared

 *    to split single page bios.

/**

 * blk_queue_max_discard_sectors - set max sectors for a single discard

 * @q:  the request queue for the device

 * @max_discard_sectors: maximum number of sectors to discard

/**

 * blk_queue_max_write_same_sectors - set max sectors for a single write same

 * @q:  the request queue for the device

 * @max_write_same_sectors: maximum number of sectors to write per command

/**

 * blk_queue_max_write_zeroes_sectors - set max sectors for a single

 *                                      write zeroes

 * @q:  the request queue for the device

 * @max_write_zeroes_sectors: maximum number of sectors to write per command

/**

 * blk_queue_max_zone_append_sectors - set max sectors for a single zone append

 * @q:  the request queue for the device

 * @max_zone_append_sectors: maximum number of sectors to write per command

	/*

	 * Signal eventual driver bugs resulting in the max_zone_append sectors limit

	 * being 0 due to a 0 argument, the chunk_sectors limit (zone size) not set,

	 * or the max_hw_sectors limit not set.

/**

 * blk_queue_max_segments - set max hw segments for a request for this queue

 * @q:  the request queue for the device

 * @max_segments:  max number of segments

 *

 * Description:

 *    Enables a low level driver to set an upper limit on the number of

 *    hw data segments in a request.

/**

 * blk_queue_max_discard_segments - set max segments for discard requests

 * @q:  the request queue for the device

 * @max_segments:  max number of segments

 *

 * Description:

 *    Enables a low level driver to set an upper limit on the number of

 *    segments in a discard request.

/**

 * blk_queue_max_segment_size - set max segment size for blk_rq_map_sg

 * @q:  the request queue for the device

 * @max_size:  max size of segment in bytes

 *

 * Description:

 *    Enables a low level driver to set an upper limit on the size of a

 *    coalesced segment

 see blk_queue_virt_boundary() for the explanation */

/**

 * blk_queue_logical_block_size - set logical block size for the queue

 * @q:  the request queue for the device

 * @size:  the logical block size, in bytes

 *

 * Description:

 *   This should be set to the lowest possible block size that the

 *   storage device can address.  The default of 512 covers most

 *   hardware.

/**

 * blk_queue_physical_block_size - set physical block size for the queue

 * @q:  the request queue for the device

 * @size:  the physical block size, in bytes

 *

 * Description:

 *   This should be set to the lowest possible sector size that the

 *   hardware can operate on without reverting to read-modify-write

 *   operations.

/**

 * blk_queue_zone_write_granularity - set zone write granularity for the queue

 * @q:  the request queue for the zoned device

 * @size:  the zone write granularity size, in bytes

 *

 * Description:

 *   This should be set to the lowest possible size allowing to write in

 *   sequential zones of a zoned block device.

/**

 * blk_queue_alignment_offset - set physical block alignment offset

 * @q:	the request queue for the device

 * @offset: alignment offset in bytes

 *

 * Description:

 *   Some devices are naturally misaligned to compensate for things like

 *   the legacy DOS partition table 63-sector offset.  Low-level drivers

 *   should call this function for devices whose first sector is not

 *   naturally aligned.

	/*

	 * For read-ahead of large files to be effective, we need to read ahead

	 * at least twice the optimal I/O size.

/**

 * blk_limits_io_min - set minimum request size for a device

 * @limits: the queue limits

 * @min:  smallest I/O size in bytes

 *

 * Description:

 *   Some devices have an internal block size bigger than the reported

 *   hardware sector size.  This function can be used to signal the

 *   smallest I/O the device can perform without incurring a performance

 *   penalty.

/**

 * blk_queue_io_min - set minimum request size for the queue

 * @q:	the request queue for the device

 * @min:  smallest I/O size in bytes

 *

 * Description:

 *   Storage devices may report a granularity or preferred minimum I/O

 *   size which is the smallest request the device can perform without

 *   incurring a performance penalty.  For disk drives this is often the

 *   physical block size.  For RAID arrays it is often the stripe chunk

 *   size.  A properly aligned multiple of minimum_io_size is the

 *   preferred request size for workloads where a high number of I/O

 *   operations is desired.

/**

 * blk_limits_io_opt - set optimal request size for a device

 * @limits: the queue limits

 * @opt:  smallest I/O size in bytes

 *

 * Description:

 *   Storage devices may report an optimal I/O size, which is the

 *   device's preferred unit for sustained I/O.  This is rarely reported

 *   for disk drives.  For RAID arrays it is usually the stripe width or

 *   the internal track size.  A properly aligned multiple of

 *   optimal_io_size is the preferred request size for workloads where

 *   sustained throughput is desired.

/**

 * blk_queue_io_opt - set optimal request size for the queue

 * @q:	the request queue for the device

 * @opt:  optimal request size in bytes

 *

 * Description:

 *   Storage devices may report an optimal I/O size, which is the

 *   device's preferred unit for sustained I/O.  This is rarely reported

 *   for disk drives.  For RAID arrays it is usually the stripe width or

 *   the internal track size.  A properly aligned multiple of

 *   optimal_io_size is the preferred request size for workloads where

 *   sustained throughput is desired.

/**

 * blk_stack_limits - adjust queue_limits for stacked devices

 * @t:	the stacking driver limits (top device)

 * @b:  the underlying queue limits (bottom, component device)

 * @start:  first data sector within component device

 *

 * Description:

 *    This function is used by stacking drivers like MD and DM to ensure

 *    that all component devices have compatible block sizes and

 *    alignments.  The stacking driver must provide a queue_limits

 *    struct (top) and then iteratively call the stacking function for

 *    all component (bottom) devices.  The stacking function will

 *    attempt to combine the values and ensure proper alignment.

 *

 *    Returns 0 if the top and bottom queue_limits are compatible.  The

 *    top device's block sizes and alignment offsets may be adjusted to

 *    ensure alignment with the bottom device. If no compatible sizes

 *    and alignments exist, -1 is returned and the resulting top

 *    queue_limits will have the misaligned flag set to indicate that

 *    the alignment_offset is undefined.

	/* Bottom device has different alignment.  Check that it is

	 * compatible with the current top alignment.

 Verify that top and bottom intervals line up */

 Set non-power-of-2 compatible chunk_sectors boundary */

 Physical block size a multiple of the logical block size? */

 Minimum I/O a multiple of the physical block size? */

 Optimal I/O a multiple of the physical block size? */

 chunk_sectors a multiple of the physical block size? */

 Find lowest common alignment_offset */

 Verify that new alignment_offset is on a logical block boundary */

 Discard alignment and granularity */

 Verify that top and bottom intervals line up */

/**

 * disk_stack_limits - adjust queue limits for stacked drivers

 * @disk:  MD/DM gendisk (top)

 * @bdev:  the underlying block device (bottom)

 * @offset:  offset to beginning of data within component device

 *

 * Description:

 *    Merges the limits for a top level gendisk and a bottom level

 *    block_device.

/**

 * blk_queue_update_dma_pad - update pad mask

 * @q:     the request queue for the device

 * @mask:  pad mask

 *

 * Update dma pad mask.

 *

 * Appending pad buffer to a request modifies the last entry of a

 * scatter list such that it includes the pad buffer.

/**

 * blk_queue_segment_boundary - set boundary rules for segment merging

 * @q:  the request queue for the device

 * @mask:  the memory boundary mask

/**

 * blk_queue_virt_boundary - set boundary rules for bio merging

 * @q:  the request queue for the device

 * @mask:  the memory boundary mask

	/*

	 * Devices that require a virtual boundary do not support scatter/gather

	 * I/O natively, but instead require a descriptor list entry for each

	 * page (which might not be idential to the Linux PAGE_SIZE).  Because

	 * of that they are not limited by our notion of "segment size".

/**

 * blk_queue_dma_alignment - set dma length and memory alignment

 * @q:     the request queue for the device

 * @mask:  alignment mask

 *

 * description:

 *    set required memory and length alignment for direct dma transactions.

 *    this is used when building direct io requests for the queue.

 *

/**

 * blk_queue_update_dma_alignment - update dma length and memory alignment

 * @q:     the request queue for the device

 * @mask:  alignment mask

 *

 * description:

 *    update required memory and length alignment for direct dma transactions.

 *    If the requested alignment is larger than the current alignment, then

 *    the current queue alignment is updated to the new value, otherwise it

 *    is left alone.  The design of this is to allow multiple objects

 *    (driver, device, transport etc) to set their respective

 *    alignments without having them interfere.

 *

/**

 * blk_set_queue_depth - tell the block layer about the device queue depth

 * @q:		the request queue for the device

 * @depth:		queue depth

 *

/**

 * blk_queue_write_cache - configure queue's write cache

 * @q:		the request queue for the device

 * @wc:		write back cache on or off

 * @fua:	device supports FUA writes, if true

 *

 * Tell the block layer about the write cache of @q.

/**

 * blk_queue_required_elevator_features - Set a queue required elevator features

 * @q:		the request queue for the target device

 * @features:	Required elevator features OR'ed together

 *

 * Tell the block layer that for the device controlled through @q, only the

 * only elevators that can be used are those that implement at least the set of

 * features specified by @features.

/**

 * blk_queue_can_use_dma_map_merging - configure queue for merging segments.

 * @q:		the request queue for the device

 * @dev:	the device pointer for dma

 *

 * Tell the block layer about merging the segments by dma map of @q.

 No need to update max_segment_size. see blk_queue_virt_boundary() */

/**

 * blk_queue_set_zoned - configure a disk queue zoned model.

 * @disk:	the gendisk of the queue to configure

 * @model:	the zoned model to set

 *

 * Set the zoned model of the request queue of @disk according to @model.

 * When @model is BLK_ZONED_HM (host managed), this should be called only

 * if zoned block device support is enabled (CONFIG_BLK_DEV_ZONED option).

 * If @model specifies BLK_ZONED_HA (host aware), the effective model used

 * depends on CONFIG_BLK_DEV_ZONED settings and on the existence of partitions

 * on the disk.

		/*

		 * Host managed devices are supported only if

		 * CONFIG_BLK_DEV_ZONED is enabled.

		/*

		 * Host aware devices can be treated either as regular block

		 * devices (similar to drive managed devices) or as zoned block

		 * devices to take advantage of the zone command set, similarly

		 * to host managed devices. We try the latter if there are no

		 * partitions and zoned block device support is enabled, else

		 * we do nothing special as far as the block layer is concerned.

		/*

		 * Set the zone write granularity to the device logical block

		 * size by default. The driver can change this value if needed.

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to segment and merge handling

 this bio only has a single bvec */

 in the middle of bvec */

	/*

	 * iter.bi_bvec_done records actual length of the last bvec

	 * if this bio ends in the middle of one io vector

	/*

	 * Don't merge if the 1st bio starts with non-zero offset, otherwise it

	 * is quite difficult to respect the sg gap limit.  We work hard to

	 * merge a huge number of small single bios in case of mkfs.

	/*

	 * We don't need to worry about the situation that the merged segment

	 * ends in unaligned virt boundary:

	 *

	 * - if 'pb' ends aligned, the merged segment ends aligned

	 * - if 'pb' ends unaligned, the next bio must include

	 *   one single bvec of 'nb', otherwise the 'nb' can't

	 *   merge with 'pb'

 Zero-sector (unknown) and one-sector granularities are the same.  */

 XXX: warn */

	/*

	 * If the next starting sector would be misaligned, stop the discard at

	 * the previous aligned sector.

/*

 * Return the maximum number of sectors from the start of a bio that may be

 * submitted as a single request to a block device. If enough sectors remain,

 * align the end to the physical block size. Otherwise align the end to the

 * logical block size. This approach minimizes the number of non-aligned

 * requests that are submitted to a block device if the start of a bio is not

 * aligned to a physical block boundary.

	/*

	 * overflow may be triggered in case of zero page physical address

	 * on 32bit arch, use queue's max segment size when that happens.

/**

 * bvec_split_segs - verify whether or not a bvec should be split in the middle

 * @q:        [in] request queue associated with the bio associated with @bv

 * @bv:       [in] bvec to examine

 * @nsegs:    [in,out] Number of segments in the bio being built. Incremented

 *            by the number of segments from @bv that may be appended to that

 *            bio without exceeding @max_segs

 * @sectors:  [in,out] Number of sectors in the bio being built. Incremented

 *            by the number of sectors from @bv that may be appended to that

 *            bio without exceeding @max_sectors

 * @max_segs: [in] upper bound for *@nsegs

 * @max_sectors: [in] upper bound for *@sectors

 *

 * When splitting a bio, it can happen that a bvec is encountered that is too

 * big to fit in a single segment and hence that it has to be split in the

 * middle. This function verifies whether or not that should happen. The value

 * %true is returned if and only if appending the entire @bv to a bio with

 * *@nsegs segments and *@sectors sectors would make that bio unacceptable for

 * the block driver.

 tell the caller to split the bvec if it is too big to fit */

/**

 * blk_bio_segment_split - split a bio in two bios

 * @q:    [in] request queue pointer

 * @bio:  [in] bio to be split

 * @bs:	  [in] bio set to allocate the clone from

 * @segs: [out] number of segments in the bio with the first half of the sectors

 *

 * Clone @bio, update the bi_iter of the clone to represent the first sectors

 * of @bio and update @bio->bi_iter to represent the remaining sectors. The

 * following is guaranteed for the cloned bio:

 * - That it has at most get_max_io_size(@q, @bio) sectors.

 * - That it has at most queue_max_segments(@q) segments.

 *

 * Except for discard requests the cloned bio will point at the bi_io_vec of

 * the original bio. It is the responsibility of the caller to ensure that the

 * original bio is not freed before the cloned bio. The caller is also

 * responsible for ensuring that @bs is only destroyed after processing of the

 * split bio has finished.

		/*

		 * If the queue doesn't support SG gaps and adding this

		 * offset would create a gap, disallow it.

	/*

	 * Bio splitting may cause subtle trouble such as hang when doing sync

	 * iopoll in direct IO routine. Given performance gain of iopoll for

	 * big IO can be trival, disable iopoll when split needed.

/**

 * __blk_queue_split - split a bio and submit the second half

 * @q:       [in] request_queue new bio is being queued at

 * @bio:     [in, out] bio to be split

 * @nr_segs: [out] number of segments in the first bio

 *

 * Split a bio into two bios, chain the two bios, submit the second half and

 * store a pointer to the first half in *@bio. If the second bio is still too

 * big it will be split by a recursive call to this function. Since this

 * function may allocate a new bio from q->bio_split, it is the responsibility

 * of the caller to ensure that q->bio_split is only released after processing

 * of the split bio has finished.

 there isn't chance to merge the splitted bio */

/**

 * blk_queue_split - split a bio and submit the second half

 * @bio: [in, out] bio to be split

 *

 * Split a bio into two bios, chains the two bios, submit the second half and

 * store a pointer to the first half in *@bio. Since this function may allocate

 * a new bio from q->bio_split, it is the responsibility of the caller to ensure

 * that q->bio_split is only released after processing of the split bio has

 * finished.

	/*

	 * If the driver previously mapped a shorter list, we could see a

	 * termination bit prematurely unless it fully inits the sg table

	 * on each mapping. We KNOW that there must be more entries here

	 * or the driver would be buggy, so force clear the termination bit

	 * to avoid doing a full sg_init_table() in drivers for each command.

		/*

		 * Unfortunately a fair number of drivers barf on scatterlists

		 * that have an offset larger than PAGE_SIZE, despite other

		 * subsystems dealing with that invariant just fine.  For now

		 * stick to the legacy format where we never present those from

		 * the block layer, but the code below should be removed once

		 * these offenders (mostly MMC/SD drivers) are fixed.

 only try to merge bvecs into one sg if they are from two bios */

			/*

			 * Only try to merge bvecs from two bios given we

			 * have done bio internal merge when adding pages

			 * to bio

/*

 * map a request to scatterlist, return number of sg entries setup. Caller

 * must make sure sg can hold rq->nr_phys_segments entries

	/*

	 * Something must have been wrong if the figured number of

	 * segment is bigger than number of req's physical segments

 discard request merge won't add new segment */

	/*

	 * This will form the start of a new hw segment.  Bump both

	 * counters.

	/*

	 * Will it become too large?

 Merge is OK... */

/**

 * blk_rq_set_mixed_merge - mark a request as mixed merge

 * @rq: request to mark as mixed merge

 *

 * Description:

 *     @rq is about to be mixed merged.  Make sure the attributes

 *     which can be mixed are set in each bio and mark @rq as mixed

 *     merged.

	/*

	 * @rq will no longer represent mixable attributes for all the

	 * contained bios.  It will just track those of the first one.

	 * Distributes the attributs to each bio.

/*

 * For non-mq, this has to be called with the request spinlock acquired.

 * For mq with scheduling, the appropriate queue wide lock should be held.

	/*

	 * Don't allow merge of different write hints, or for a hint with

	 * non-hint IO.

	/*

	 * If we are allowed to merge, then append bio list

	 * from next to rq and release next. merge_requests_fn

	 * will have updated segment counts, update sector

	 * counts here. Handle DISCARDs separately, as they

	 * have separate settings.

	/*

	 * If failfast settings disagree or any of the two is already

	 * a mixed merge, mark both as mixed before proceeding.  This

	 * makes sure that all involved bios have mixable attributes

	 * set properly.

	/*

	 * At this point we have either done a back merge or front merge. We

	 * need the smaller start_time_ns of the merged requests to be the

	 * current request for accounting purposes.

	/*

	 * 'next' is going away, so update stats accordingly

	/*

	 * ownership of bio passed from next to req, return 'next' for

	 * the caller to free

/*

 * Try to merge 'next' into 'rq'. Return true if the merge happened, false

 * otherwise. The caller is responsible for freeing 'next' if the merge

 * happened.

 different data direction or already started, don't merge */

 must be same device */

 only merge integrity protected bio into ditto rq */

 Only merge if the crypt contexts are compatible */

 must be using the same buffer */

	/*

	 * Don't allow merge of different write hints, or for a hint with

	 * non-hint IO.

/**

 * blk_attempt_plug_merge - try to merge with %current's plugged list

 * @q: request_queue new bio is being queued at

 * @bio: new bio being queued

 * @nr_segs: number of segments in @bio

 * @same_queue_rq: output value, will be true if there's an existing request

 * from the passed in @q already in the plug list

 *

 * Determine whether @bio being queued on @q can be merged with the previous

 * request on %current's plugged list.  Returns %true if merge was successful,

 * otherwise %false.

 *

 * Plugging coalesces IOs from the same issuer for the same purpose without

 * going through @q->queue_lock.  As such it's more of an issuing mechanism

 * than scheduling, and the request, while may have elvpriv data, is not

 * added on the elevator at this point.  In addition, we don't have

 * reliable access to the elevator outside queue lock.  Only check basic

 * merging parameters without querying the elevator.

 *

 * Caller must ensure !blk_queue_nomerges(q) beforehand.

 check the previously added entry for a quick merge attempt */

		/*

		 * Only blk-mq multiple hardware queues case checks the rq in

		 * the same queue, there should be only one such rq in a queue

/*

 * Iterate list of requests and see if we can merge this bio with any

 * of them.

 SPDX-License-Identifier: GPL-2.0-only

/*

 *  Copyright (C) 1991, 1992  Linus Torvalds

 *  Copyright (C) 2001  Andrea Arcangeli <andrea@suse.de> SuSE

 *  Copyright (C) 2016 - 2020 Christoph Hellwig

 Kill _all_ buffers and pagecache , dirty or not.. */

 Invalidate clean unused buffers and pagecache. */

 make sure all lru add caches are flushed */

	/* 99% of the time, we don't need to flush the cleancache on the bdev.

	 * But, for the strange corners, lets be cautious

/*

 * Drop all buffers & page cache for given bdev range. This function bails

 * with error if bdev has other exclusive owner (such as filesystem).

	/*

	 * If we don't hold exclusive handle for the device, upgrade to it

	 * while we discard the buffer cache to avoid discarding buffers

	 * under live filesystem.

	/*

	 * Someone else has handle exclusively open. Try invalidating instead.

	 * The 'end' argument is inclusive so the rounding is safe.

 Size must be a power of two, and between 512 and PAGE_SIZE */

 Size cannot be smaller than the size supported by the device */

 Don't change the size if it is same as current */

	/* If we get here, we know size is power of two

/*

 * Write out and wait upon all the dirty data associated with a block

 * device via its mapping.  Does not take the superblock lock.

/*

 * Write out and wait upon all dirty data associated with this

 * device.   Filesystem data as well as the underlying block

 * device.  Takes the superblock lock.

/**

 * freeze_bdev  --  lock a filesystem and force it into a consistent state

 * @bdev:	blockdevice to lock

 *

 * If a superblock is found on this device, we take the s_umount semaphore

 * on it to make sure nobody unmounts until the snapshot creation is done.

 * The reference counter (bd_fsfreeze_count) guarantees that only the last

 * unfreeze process can unfreeze the frozen filesystem actually when multiple

 * freeze requests arrive simultaneously. It counts up in freeze_bdev() and

 * count down in thaw_bdev(). When it becomes 0, thaw_bdev() will unfreeze

 * actually.

/**

 * thaw_bdev  -- unlock filesystem

 * @bdev:	blockdevice to unlock

 *

 * Unlocks the filesystem and marks it writeable again after freeze_bdev().

/**

 * bdev_read_page() - Start reading a page from a block device

 * @bdev: The device to read the page from

 * @sector: The offset on the device to read the page to (need not be aligned)

 * @page: The page to read

 *

 * On entry, the page should be locked.  It will be unlocked when the page

 * has been read.  If the block driver implements rw_page synchronously,

 * that will be true on exit from this function, but it need not be.

 *

 * Errors returned by this function are usually "soft", eg out of memory, or

 * queue full; callers should try a different route to read this page rather

 * than propagate an error back up the stack.

 *

 * Return: negative errno if an error occurs, 0 if submission was successful.

/**

 * bdev_write_page() - Start writing a page to a block device

 * @bdev: The device to write the page to

 * @sector: The offset on the device to write the page to (need not be aligned)

 * @page: The page to write

 * @wbc: The writeback_control for the write

 *

 * On entry, the page should be locked and not currently under writeback.

 * On exit, if the write started successfully, the page will be unlocked and

 * under writeback.  If the write failed already (eg the driver failed to

 * queue the page to the device), the page will still be locked.  If the

 * caller is a ->writepage implementation, it will need to unlock the page.

 *

 * Errors returned by this function are usually "soft", eg out of memory, or

 * queue full; callers should try a different route to write this page rather

 * than propagate an error back up the stack.

 *

 * Return: negative errno if an error occurs, 0 if submission was successful.

/*

 * pseudo-fs

 is it needed here? */

 For writeback */

/**

 * bd_may_claim - test whether a block device can be claimed

 * @bdev: block device of interest

 * @whole: whole block device containing @bdev, may equal @bdev

 * @holder: holder trying to claim @bdev

 *

 * Test whether @bdev can be claimed by @holder.

 *

 * CONTEXT:

 * spin_lock(&bdev_lock).

 *

 * RETURNS:

 * %true if @bdev can be claimed, %false otherwise.

 already a holder */

 held by someone else */

 is a whole device which isn't held */

 is a partition of a device that is being partitioned */

 is a partition of a held device */

 is a partition of an un-held device */

/**

 * bd_prepare_to_claim - claim a block device

 * @bdev: block device of interest

 * @holder: holder trying to claim @bdev

 *

 * Claim @bdev.  This function fails if @bdev is already claimed by another

 * holder and waits if another claiming is in progress. return, the caller

 * has ownership of bd_claiming and bd_holder[s].

 *

 * RETURNS:

 * 0 if @bdev can be claimed, -EBUSY otherwise.

 if someone else claimed, fail */

 if claiming is already in progress, wait for it to finish */

 yay, all mine */

 only for the loop driver */

 tell others that we're done */

/**

 * bd_finish_claiming - finish claiming of a block device

 * @bdev: block device of interest

 * @holder: holder that has claimed @bdev

 *

 * Finish exclusive open of a block device. Mark the device as exlusively

 * open by the holder and wake up all waiters for exclusive open to finish.

	/*

	 * Note that for a whole device bd_holders will be incremented twice,

	 * and bd_holder will be set to bd_may_claim before being set to holder

/**

 * bd_abort_claiming - abort claiming of a block device

 * @bdev: block device of interest

 * @holder: holder that has claimed @bdev

 *

 * Abort claiming of a block device when the exclusive open failed. This can be

 * also used when exclusive open is not actually desired and we just needed

 * to block other exclusive openers for a while.

 avoid ghost partitions on a removed medium */

 switch from the inode reference to a device mode one: */

/**

 * blkdev_get_by_dev - open a block device by device number

 * @dev: device number of block device to open

 * @mode: FMODE_* mask

 * @holder: exclusive holder identifier

 *

 * Open the block device described by device number @dev. If @mode includes

 * %FMODE_EXCL, the block device is opened with exclusive access.  Specifying

 * %FMODE_EXCL with a %NULL @holder is invalid.  Exclusive opens may nest for

 * the same @holder.

 *

 * Use this interface ONLY if you really do not have anything better - i.e. when

 * you are behind a truly sucky interface and all you are given is a device

 * number.  Everything else should use blkdev_get_by_path().

 *

 * CONTEXT:

 * Might sleep.

 *

 * RETURNS:

 * Reference to the block_device on success, ERR_PTR(-errno) on failure.

		/*

		 * Block event polling for write claims if requested.  Any write

		 * holder makes the write_holder state stick until all are

		 * released.  This is good enough and tracking individual

		 * writeable reference is too fragile given the way @mode is

		 * used in blkdev_get/put().

/**

 * blkdev_get_by_path - open a block device by name

 * @path: path to the block device to open

 * @mode: FMODE_* mask

 * @holder: exclusive holder identifier

 *

 * Open the block device described by the device file at @path.  If @mode

 * includes %FMODE_EXCL, the block device is opened with exclusive access.

 * Specifying %FMODE_EXCL with a %NULL @holder is invalid.  Exclusive opens may

 * nest for the same @holder.

 *

 * CONTEXT:

 * Might sleep.

 *

 * RETURNS:

 * Reference to the block_device on success, ERR_PTR(-errno) on failure.

	/*

	 * Sync early if it looks like we're the last one.  If someone else

	 * opens the block device between now and the decrement of bd_openers

	 * then we did a sync that we didn't need to, but that's not the end

	 * of the world and we want to avoid long (could be several minute)

	 * syncs while holding the mutex.

		/*

		 * Release a claim on the device.  The holder fields

		 * are protected with bdev_lock.  open_mutex is to

		 * synchronize disk_holder unlinking.

		/*

		 * If this was the last claim, remove holder link and

		 * unblock evpoll if it was a write holder.

	/*

	 * Trigger event checking and tell drivers to flush MEDIA_CHANGE

	 * event.  This is to ensure detection of media removal commanded

	 * from userland - e.g. eject(1).

/**

 * lookup_bdev  - lookup a struct block_device by name

 * @pathname:	special file representing the block device

 * @dev:	return value of the block device's dev_t

 *

 * Lookup the block device's dev_t at @pathname in the current

 * namespace if possible and return it by @dev.

 *

 * RETURNS:

 * 0 if succeeded, errno otherwise.

		/*

		 * no need to lock the super, get_super holds the

		 * read mutex so the filesystem cannot go away

		 * under us (->put_super runs with the write lock

		 * hold).

		/*

		 * We hold a reference to 'inode' so it couldn't have been

		 * removed from s_inodes list while we dropped the

		 * s_inode_list_lock  We cannot iput the inode now as we can

		 * be holding the last reference and we cannot iput it under

		 * s_inode_list_lock. So we keep the reference and iput it

		 * later.

 skip */

			/*

			 * We keep the error status of individual mapping so

			 * that applications can catch the writeback error using

			 * fsync(2). See filemap_fdatawait_keep_errors() for

			 * details.

 SPDX-License-Identifier: GPL-2.0

 ctx->ctxs won't be released until all ctx are freed */

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Hierarchical Budget Worst-case Fair Weighted Fair Queueing

 * (B-WF2Q+): hierarchical scheduling algorithm by which the BFQ I/O

 * scheduler schedules generic entities. The latter can represent

 * either single bfq queues (associated with processes) or groups of

 * bfq queues (associated with cgroups).

/**

 * bfq_gt - compare two timestamps.

 * @a: first ts.

 * @b: second ts.

 *

 * Return @a > @b, dealing with wrapping correctly.

/**

 * bfq_update_next_in_service - update sd->next_in_service

 * @sd: sched_data for which to perform the update.

 * @new_entity: if not NULL, pointer to the entity whose activation,

 *		requeueing or repositioning triggered the invocation of

 *		this function.

 * @expiration: id true, this function is being invoked after the

 *             expiration of the in-service entity

 *

 * This function is called to update sd->next_in_service, which, in

 * its turn, may change as a consequence of the insertion or

 * extraction of an entity into/from one of the active trees of

 * sd. These insertions/extractions occur as a consequence of

 * activations/deactivations of entities, with some activations being

 * 'true' activations, and other activations being requeueings (i.e.,

 * implementing the second, requeueing phase of the mechanism used to

 * reposition an entity in its active tree; see comments on

 * __bfq_activate_entity and __bfq_requeue_entity for details). In

 * both the last two activation sub-cases, new_entity points to the

 * just activated or requeued entity.

 *

 * Returns true if sd->next_in_service changes in such a way that

 * entity->parent may become the next_in_service for its parent

 * entity.

	/*

	 * If this update is triggered by the activation, requeueing

	 * or repositioning of an entity that does not coincide with

	 * sd->next_in_service, then a full lookup in the active tree

	 * can be avoided. In fact, it is enough to check whether the

	 * just-modified entity has the same priority as

	 * sd->next_in_service, is eligible and has a lower virtual

	 * finish time than sd->next_in_service. If this compound

	 * condition holds, then the new entity becomes the new

	 * next_in_service. Otherwise no change is needed.

		/*

		 * Flag used to decide whether to replace

		 * sd->next_in_service with new_entity. Tentatively

		 * set to true, and left as true if

		 * sd->next_in_service is NULL.

		/*

		 * If there is already a next_in_service candidate

		 * entity, then compare timestamps to decide whether

		 * to replace sd->service_tree with new_entity.

 lookup needed */

/*

 * Returns true if this budget changes may let next_in_service->parent

 * become the next_in_service entity for its parent entity.

	/*

	 * bfq_group's my_entity field is not NULL only if the group

	 * is not the root group. We must not touch the root entity

	 * as it must never become an in-service entity.

/*

 * This function tells whether entity stops being a candidate for next

 * service, according to the restrictive definition of the field

 * next_in_service. In particular, this function is invoked for an

 * entity that is about to be set in service.

 *

 * If entity is a queue, then the entity is no longer a candidate for

 * next service according to the that definition, because entity is

 * about to become the in-service queue. This function then returns

 * true if entity is a queue.

 *

 * In contrast, entity could still be a candidate for next service if

 * it is not a queue, and has more than one active child. In fact,

 * even if one of its children is about to be set in service, other

 * active children may still be the next to serve, for the parent

 * entity, even according to the above definition. As a consequence, a

 * non-queue entity is not a candidate for next-service only if it has

 * only one active child. And only if this condition holds, then this

 * function returns true for a non-queue entity.

	/*

	 * The field active_entities does not always contain the

	 * actual number of active children entities: it happens to

	 * not account for the in-service entity in case the latter is

	 * removed from its active tree (which may get done after

	 * invoking the function bfq_no_longer_next_in_service in

	 * bfq_get_next_queue). Fortunately, here, i.e., while

	 * bfq_no_longer_next_in_service is not yet completed in

	 * bfq_get_next_queue, bfq_active_extract has not yet been

	 * invoked, and thus active_entities still coincides with the

	 * actual number of active entities.

 CONFIG_BFQ_GROUP_IOSCHED */

 CONFIG_BFQ_GROUP_IOSCHED */

/*

 * Shift for timestamp calculations.  This actually limits the maximum

 * service allowed in one timestamp delta (small shift values increase it),

 * the maximum total weight that can be used for the queues in the system

 * (big shift values increase it), and the period of virtual time

 * wraparounds.

/**

 * bfq_delta - map service into the virtual time domain.

 * @service: amount of service.

 * @weight: scale factor (weight of an entity or weight sum).

/**

 * bfq_calc_finish - assign the finish time to an entity.

 * @entity: the entity to act upon.

 * @service: the service to be charged to the entity.

/**

 * bfq_entity_of - get an entity from a node.

 * @node: the node field of the entity.

 *

 * Convert a node pointer to the relative entity.  This is used only

 * to simplify the logic of some functions and not as the generic

 * conversion mechanism because, e.g., in the tree walking functions,

 * the check for a %NULL value would be redundant.

/**

 * bfq_extract - remove an entity from a tree.

 * @root: the tree root.

 * @entity: the entity to remove.

/**

 * bfq_idle_extract - extract an entity from the idle tree.

 * @st: the service tree of the owning @entity.

 * @entity: the entity being removed.

/**

 * bfq_insert - generic tree insertion.

 * @root: tree root.

 * @entity: entity to insert.

 *

 * This is used for the idle and the active tree, since they are both

 * ordered by finish time.

/**

 * bfq_update_min - update the min_start field of a entity.

 * @entity: the entity to update.

 * @node: one of its children.

 *

 * This function is called when @entity may store an invalid value for

 * min_start due to updates to the active tree.  The function  assumes

 * that the subtree rooted at @node (which may be its left or its right

 * child) has a valid min_start value.

/**

 * bfq_update_active_node - recalculate min_start.

 * @node: the node to update.

 *

 * @node may have changed position or one of its children may have moved,

 * this function updates its min_start value.  The left and right subtrees

 * are assumed to hold a correct min_start value.

/**

 * bfq_update_active_tree - update min_start for the whole active tree.

 * @node: the starting node.

 *

 * @node must be the deepest modified node after an update.  This function

 * updates its min_start using the values held by its children, assuming

 * that they did not change, and then updates all the nodes that may have

 * changed in the path to the root.  The only nodes that may have changed

 * are the ones in the path or their siblings.

/**

 * bfq_active_insert - insert an entity in the active tree of its

 *                     group/device.

 * @st: the service tree of the entity.

 * @entity: the entity being inserted.

 *

 * The active tree is ordered by finish time, but an extra key is kept

 * per each node, containing the minimum value for the start times of

 * its children (and the node itself), so it's possible to search for

 * the eligible node with the lowest finish time in logarithmic time.

/**

 * bfq_ioprio_to_weight - calc a weight from an ioprio.

 * @ioprio: the ioprio value to convert.

/**

 * bfq_weight_to_ioprio - calc an ioprio from a weight.

 * @weight: the weight value to convert.

 *

 * To preserve as much as possible the old only-ioprio user interface,

 * 0 is used as an escape ioprio value for weights (numerically) equal or

 * larger than IOPRIO_NR_LEVELS * BFQ_WEIGHT_CONVERSION_COEFF.

/**

 * bfq_find_deepest - find the deepest node that an extraction can modify.

 * @node: the node being removed.

 *

 * Do the first step of an extraction in an rb tree, looking for the

 * node that will replace @node, and returning the deepest node that

 * the following modifications to the tree can touch.  If @node is the

 * last node in the tree return %NULL.

/**

 * bfq_active_extract - remove an entity from the active tree.

 * @st: the service_tree containing the tree.

 * @entity: the entity being removed.

/**

 * bfq_idle_insert - insert an entity into the idle tree.

 * @st: the service tree containing the tree.

 * @entity: the entity to insert.

/**

 * bfq_forget_entity - do not consider entity any longer for scheduling

 * @st: the service tree.

 * @entity: the entity being removed.

 * @is_in_service: true if entity is currently the in-service entity.

 *

 * Forget everything about @entity. In addition, if entity represents

 * a queue, and the latter is not in service, then release the service

 * reference to the queue (the one taken through bfq_get_entity). In

 * fact, in this case, there is really no more service reference to

 * the queue, as the latter is also outside any service tree. If,

 * instead, the queue is in service, then __bfq_bfqd_reset_in_service

 * will take care of putting the reference when the queue finally

 * stops being served.

/**

 * bfq_put_idle_entity - release the idle tree ref of an entity.

 * @st: service tree for the entity.

 * @entity: the entity being released.

/**

 * bfq_forget_idle - update the idle tree if necessary.

 * @st: the service tree to act upon.

 *

 * To preserve the global O(log N) complexity we only remove one entry here;

 * as the idle tree will not grow indefinitely this can be done safely.

		/*

		 * Forget the whole idle tree, increasing the vtime past

		 * the last finish time of idle entities.

/*

 * Update weight and priority of entity. If update_class_too is true,

 * then update the ioprio_class of entity too.

 *

 * The reason why the update of ioprio_class is controlled through the

 * last parameter is as follows. Changing the ioprio class of an

 * entity implies changing the destination service trees for that

 * entity. If such a change occurred when the entity is already on one

 * of the service trees for its previous class, then the state of the

 * entity would become more complex: none of the new possible service

 * trees for the entity, according to bfq_entity_service_tree(), would

 * match any of the possible service trees on which the entity

 * is. Complex operations involving these trees, such as entity

 * activations and deactivations, should take into account this

 * additional complexity.  To avoid this issue, this function is

 * invoked with update_class_too unset in the points in the code where

 * entity may happen to be on some tree.

 Matches the smp_wmb() in bfq_group_set_weight. */

		/*

		 * Reset prio_changed only if the ioprio_class change

		 * is not pending any longer.

		/*

		 * NOTE: here we may be changing the weight too early,

		 * this will cause unfairness.  The correct approach

		 * would have required additional complexity to defer

		 * weight changes to the proper time instants (i.e.,

		 * when entity->finish <= old_st->vtime).

		/*

		 * If the weight of the entity changes, and the entity is a

		 * queue, remove the entity from its old weight counter (if

		 * there is a counter associated with the entity).

		/*

		 * Add the entity, if it is not a weight-raised queue,

		 * to the counter associated with its new weight.

 If we get here, root has been initialized. */

/**

 * bfq_bfqq_served - update the scheduler status after selection for

 *                   service.

 * @bfqq: the queue being served.

 * @served: bytes to transfer.

 *

 * NOTE: this can be optimized, as the timestamps of upper level entities

 * are synchronized every time a new bfqq is selected for service.  By now,

 * we keep it to better check consistency.

/**

 * bfq_bfqq_charge_time - charge an amount of service equivalent to the length

 *			  of the time interval during which bfqq has been in

 *			  service.

 * @bfqd: the device

 * @bfqq: the queue that needs a service update.

 * @time_ms: the amount of time during which the queue has received service

 *

 * If a queue does not consume its budget fast enough, then providing

 * the queue with service fairness may impair throughput, more or less

 * severely. For this reason, queues that consume their budget slowly

 * are provided with time fairness instead of service fairness. This

 * goal is achieved through the BFQ scheduling engine, even if such an

 * engine works in the service, and not in the time domain. The trick

 * is charging these queues with an inflated amount of service, equal

 * to the amount of service that they would have received during their

 * service slot if they had been fast, i.e., if their requests had

 * been dispatched at a rate equal to the estimated peak rate.

 *

 * It is worth noting that time fairness can cause important

 * distortions in terms of bandwidth distribution, on devices with

 * internal queueing. The reason is that I/O requests dispatched

 * during the service slot of a queue may be served after that service

 * slot is finished, and may have a total processing time loosely

 * correlated with the duration of the service slot. This is

 * especially true for short service slots.

 Increase budget to avoid inconsistencies */

	/*

	 * When this function is invoked, entity is not in any service

	 * tree, then it is safe to invoke next function with the last

	 * parameter set (see the comments on the function).

	/*

	 * If some queues enjoy backshifting for a while, then their

	 * (virtual) finish timestamps may happen to become lower and

	 * lower than the system virtual time.	In particular, if

	 * these queues often happen to be idle for short time

	 * periods, and during such time periods other queues with

	 * higher timestamps happen to be busy, then the backshifted

	 * timestamps of the former queues can become much lower than

	 * the system virtual time. In fact, to serve the queues with

	 * higher timestamps while the ones with lower timestamps are

	 * idle, the system virtual time may be pushed-up to much

	 * higher values than the finish timestamps of the idle

	 * queues. As a consequence, the finish timestamps of all new

	 * or newly activated queues may end up being much larger than

	 * those of lucky queues with backshifted timestamps. The

	 * latter queues may then monopolize the device for a lot of

	 * time. This would simply break service guarantees.

	 *

	 * To reduce this problem, push up a little bit the

	 * backshifted timestamps of the queue associated with this

	 * entity (only a queue can happen to have the backshifted

	 * flag set): just enough to let the finish timestamp of the

	 * queue be equal to the current value of the system virtual

	 * time. This may introduce a little unfairness among queues

	 * with backshifted timestamps, but it does not break

	 * worst-case fairness guarantees.

	 *

	 * As a special case, if bfqq is weight-raised, push up

	 * timestamps much less, to keep very low the probability that

	 * this push up causes the backshifted finish timestamps of

	 * weight-raised queues to become higher than the backshifted

	 * finish timestamps of non weight-raised queues.

/**

 * __bfq_activate_entity - handle activation of entity.

 * @entity: the entity being activated.

 * @non_blocking_wait_rq: true if entity was waiting for a request

 *

 * Called for a 'true' activation, i.e., if entity is not active and

 * one of its children receives a new request.

 *

 * Basically, this function updates the timestamps of entity and

 * inserts entity into its active tree, after possibly extracting it

 * from its idle tree.

 See comments on bfq_fqq_update_budg_for_activation */

		/*

		 * Must be on the idle tree, bfq_idle_extract() will

		 * check for that.

		/*

		 * The finish time of the entity may be invalid, and

		 * it is in the past for sure, otherwise the queue

		 * would have been on the idle tree.

		/*

		 * entity is about to be inserted into a service tree,

		 * and then set in service: get a reference to make

		 * sure entity does not disappear until it is no

		 * longer in service or scheduled for service.

 bfq_group */

/**

 * __bfq_requeue_entity - handle requeueing or repositioning of an entity.

 * @entity: the entity being requeued or repositioned.

 *

 * Requeueing is needed if this entity stops being served, which

 * happens if a leaf descendant entity has expired. On the other hand,

 * repositioning is needed if the next_inservice_entity for the child

 * entity has changed. See the comments inside the function for

 * details.

 *

 * Basically, this function: 1) removes entity from its active tree if

 * present there, 2) updates the timestamps of entity and 3) inserts

 * entity back into its active tree (in the new, right position for

 * the new values of the timestamps).

		/*

		 * We are requeueing the current in-service entity,

		 * which may have to be done for one of the following

		 * reasons:

		 * - entity represents the in-service queue, and the

		 *   in-service queue is being requeued after an

		 *   expiration;

		 * - entity represents a group, and its budget has

		 *   changed because one of its child entities has

		 *   just been either activated or requeued for some

		 *   reason; the timestamps of the entity need then to

		 *   be updated, and the entity needs to be enqueued

		 *   or repositioned accordingly.

		 *

		 * In particular, before requeueing, the start time of

		 * the entity must be moved forward to account for the

		 * service that the entity has received while in

		 * service. This is done by the next instructions. The

		 * finish time will then be updated according to this

		 * new value of the start time, and to the budget of

		 * the entity.

		/*

		 * In addition, if the entity had more than one child

		 * when set in service, then it was not extracted from

		 * the active tree. This implies that the position of

		 * the entity in the active tree may need to be

		 * changed now, because we have just updated the start

		 * time of the entity, and we will update its finish

		 * time in a moment (the requeueing is then, more

		 * precisely, a repositioning in this case). To

		 * implement this repositioning, we: 1) dequeue the

		 * entity here, 2) update the finish time and requeue

		 * the entity according to the new timestamps below.

 The entity is already active, and not in service */

		/*

		 * In this case, this function gets called only if the

		 * next_in_service entity below this entity has

		 * changed, and this change has caused the budget of

		 * this entity to change, which, finally implies that

		 * the finish time of this entity must be

		 * updated. Such an update may cause the scheduling,

		 * i.e., the position in the active tree, of this

		 * entity to change. We handle this change by: 1)

		 * dequeueing the entity here, 2) updating the finish

		 * time and requeueing the entity according to the new

		 * timestamps below. This is the same approach as the

		 * non-extracted-entity sub-case above.

		 /*

		  * in service or already queued on the active tree,

		  * requeue or reposition

		/*

		 * Not in service and not queued on its active tree:

		 * the activity is idle and this is a true activation.

/**

 * bfq_activate_requeue_entity - activate or requeue an entity representing a

 *				 bfq_queue, and activate, requeue or reposition

 *				 all ancestors for which such an update becomes

 *				 necessary.

 * @entity: the entity to activate.

 * @non_blocking_wait_rq: true if this entity was waiting for a request

 * @requeue: true if this is a requeue, which implies that bfqq is

 *	     being expired; thus ALL its ancestors stop being served and must

 *	     therefore be requeued

 * @expiration: true if this function is being invoked in the expiration path

 *             of the in-service queue

/**

 * __bfq_deactivate_entity - update sched_data and service trees for

 * entity, so as to represent entity as inactive

 * @entity: the entity being deactivated.

 * @ins_into_idle_tree: if false, the entity will not be put into the

 *			idle tree.

 *

 * If necessary and allowed, puts entity into the idle tree. NOTE:

 * entity may be on no tree if in service.

	if (!entity->on_st_or_in_serv) /*

					* entity never activated, or

					* already inactive

	/*

	 * If we get here, then entity is active, which implies that

	 * bfq_group_set_parent has already been invoked for the group

	 * represented by entity. Therefore, the field

	 * entity->sched_data has been set, and we can safely use it.

		/*

		 * Non in-service entity: nobody will take care of

		 * resetting its service counter on expiration. Do it

		 * now.

/**

 * bfq_deactivate_entity - deactivate an entity representing a bfq_queue.

 * @entity: the entity to deactivate.

 * @ins_into_idle_tree: true if the entity can be put into the idle tree

 * @expiration: true if this function is being invoked in the expiration path

 *             of the in-service queue

			/*

			 * entity is not in any tree any more, so

			 * this deactivation is a no-op, and there is

			 * nothing to change for upper-level entities

			 * (in case of expiration, this can never

			 * happen).

			/*

			 * entity was the next_in_service entity,

			 * then, since entity has just been

			 * deactivated, a new one must be found.

			/*

			 * The parent entity is still active, because

			 * either next_in_service or in_service_entity

			 * is not NULL. So, no further upwards

			 * deactivation must be performed.  Yet,

			 * next_in_service has changed.	Then the

			 * schedule does need to be updated upwards.

			 *

			 * NOTE If in_service_entity is not NULL, then

			 * next_in_service may happen to be NULL,

			 * although the parent entity is evidently

			 * active. This happens if 1) the entity

			 * pointed by in_service_entity is the only

			 * active entity in the parent entity, and 2)

			 * according to the definition of

			 * next_in_service, the in_service_entity

			 * cannot be considered as

			 * next_in_service. See the comments on the

			 * definition of next_in_service for details.

		/*

		 * If we get here, then the parent is no more

		 * backlogged and we need to propagate the

		 * deactivation upwards. Thus let the loop go on.

		/*

		 * Also let parent be queued into the idle tree on

		 * deactivation, to preserve service guarantees, and

		 * assuming that who invoked this function does not

		 * need parent entities too to be removed completely.

	/*

	 * If the deactivation loop is fully executed, then there are

	 * no more entities to touch and next loop is not executed at

	 * all. Otherwise, requeue remaining entities if they are

	 * about to stop receiving service, or reposition them if this

	 * is not the case.

		/*

		 * Invoke __bfq_requeue_entity on entity, even if

		 * already active, to requeue/reposition it in the

		 * active tree (because sd->next_in_service has

		 * changed)

			/*

			 * next_in_service unchanged or not causing

			 * any change in entity->parent->sd, and no

			 * requeueing needed for expiration: stop

			 * here.

/**

 * bfq_calc_vtime_jump - compute the value to which the vtime should jump,

 *                       if needed, to have at least one entity eligible.

 * @st: the service tree to act upon.

 *

 * Assumes that st is not empty.

/**

 * bfq_first_active_entity - find the eligible entity with

 *                           the smallest finish time

 * @st: the service tree to select from.

 * @vtime: the system virtual to use as a reference for eligibility

 *

 * This function searches the first schedulable entity, starting from the

 * root of the tree and going on the left every time on this side there is

 * a subtree with at least one eligible (start <= vtime) entity. The path on

 * the right is followed only if a) the left subtree contains no eligible

 * entities and b) no eligible entity has been found yet.

/**

 * __bfq_lookup_next_entity - return the first eligible entity in @st.

 * @st: the service tree.

 *

 * If there is no in-service entity for the sched_data st belongs to,

 * then return the entity that will be set in service if:

 * 1) the parent entity this st belongs to is set in service;

 * 2) no entity belonging to such parent entity undergoes a state change

 * that would influence the timestamps of the entity (e.g., becomes idle,

 * becomes backlogged, changes its budget, ...).

 *

 * In this first case, update the virtual time in @st too (see the

 * comments on this update inside the function).

 *

 * In contrast, if there is an in-service entity, then return the

 * entity that would be set in service if not only the above

 * conditions, but also the next one held true: the currently

 * in-service entity, on expiration,

 * 1) gets a finish time equal to the current one, or

 * 2) is not eligible any more, or

 * 3) is idle.

	/*

	 * Get the value of the system virtual time for which at

	 * least one entity is eligible.

	/*

	 * If there is no in-service entity for the sched_data this

	 * active tree belongs to, then push the system virtual time

	 * up to the value that guarantees that at least one entity is

	 * eligible. If, instead, there is an in-service entity, then

	 * do not make any such update, because there is already an

	 * eligible entity, namely the in-service one (even if the

	 * entity is not on st, because it was extracted when set in

	 * service).

/**

 * bfq_lookup_next_entity - return the first eligible entity in @sd.

 * @sd: the sched_data.

 * @expiration: true if we are on the expiration path of the in-service queue

 *

 * This function is invoked when there has been a change in the trees

 * for sd, and we need to know what is the new next entity to serve

 * after this change.

	/*

	 * Choose from idle class, if needed to guarantee a minimum

	 * bandwidth to this class (and if there is some active entity

	 * in idle class). This should also mitigate

	 * priority-inversion problems in case a low priority task is

	 * holding file system resources.

 About to be served if backlogged, or not yet backlogged */

	/*

	 * Find the next entity to serve for the highest-priority

	 * class, unless the idle class needs to be served.

		/*

		 * If expiration is true, then bfq_lookup_next_entity

		 * is being invoked as a part of the expiration path

		 * of the in-service queue. In this case, even if

		 * sd->in_service_entity is not NULL,

		 * sd->in_service_entity at this point is actually not

		 * in service any more, and, if needed, has already

		 * been properly queued or requeued into the right

		 * tree. The reason why sd->in_service_entity is still

		 * not NULL here, even if expiration is true, is that

		 * sd->in_service_entity is reset as a last step in the

		 * expiration path. So, if expiration is true, tell

		 * __bfq_lookup_next_entity that there is no

		 * sd->in_service_entity.

/*

 * Get next queue for service.

	/*

	 * Traverse the path from the root to the leaf entity to

	 * serve. Set in service all the entities visited along the

	 * way.

		/*

		 * WARNING. We are about to set the in-service entity

		 * to sd->next_in_service, i.e., to the (cached) value

		 * returned by bfq_lookup_next_entity(sd) the last

		 * time it was invoked, i.e., the last time when the

		 * service order in sd changed as a consequence of the

		 * activation or deactivation of an entity. In this

		 * respect, if we execute bfq_lookup_next_entity(sd)

		 * in this very moment, it may, although with low

		 * probability, yield a different entity than that

		 * pointed to by sd->next_in_service. This rare event

		 * happens in case there was no CLASS_IDLE entity to

		 * serve for sd when bfq_lookup_next_entity(sd) was

		 * invoked for the last time, while there is now one

		 * such entity.

		 *

		 * If the above event happens, then the scheduling of

		 * such entity in CLASS_IDLE is postponed until the

		 * service of the sd->next_in_service entity

		 * finishes. In fact, when the latter is expired,

		 * bfq_lookup_next_entity(sd) gets called again,

		 * exactly to update sd->next_in_service.

 Make next_in_service entity become in_service_entity */

		/*

		 * If entity is no longer a candidate for next

		 * service, then it must be extracted from its active

		 * tree, so as to make sure that it won't be

		 * considered when computing next_in_service. See the

		 * comments on the function

		 * bfq_no_longer_next_in_service() for details.

		/*

		 * Even if entity is not to be extracted according to

		 * the above check, a descendant entity may get

		 * extracted in one of the next iterations of this

		 * loop. Such an event could cause a change in

		 * next_in_service for the level of the descendant

		 * entity, and thus possibly back to this level.

		 *

		 * However, we cannot perform the resulting needed

		 * update of next_in_service for this level before the

		 * end of the whole loop, because, to know which is

		 * the correct next-to-serve candidate entity for each

		 * level, we need first to find the leaf entity to set

		 * in service. In fact, only after we know which is

		 * the next-to-serve leaf entity, we can discover

		 * whether the parent entity of the leaf entity

		 * becomes the next-to-serve, and so on.

	/*

	 * We can finally update all next-to-serve entities along the

	 * path from the leaf entity just set in service to the root.

 returns true if the in-service queue gets freed */

	/*

	 * When this function is called, all in-service entities have

	 * been properly deactivated or requeued, so we can safely

	 * execute the final step: reset in_service_entity along the

	 * path from entity to the root.

	/*

	 * in_serv_entity is no longer in service, so, if it is in no

	 * service tree either, then release the service reference to

	 * the queue it represents (taken with bfq_get_entity).

		/*

		 * If no process is referencing in_serv_bfqq any

		 * longer, then the service reference may be the only

		 * reference to the queue. If this is the case, then

		 * bfqq gets freed here.

/*

 * Called when the bfqq no longer has requests pending, remove it from

 * the service tree. As a special case, it can be invoked during an

 * expiration.

/*

 * Called when an inactive queue receives a new request.

 Move bfqq to the head of the woken list of its waker */

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to sysfs handling

	/*

	 * Ensure that the queue is idled, in case the latency update

	 * ends up either enabling or disabling wbt completely. We can't

	 * have IO inflight if that happens.

 legacy alias for logical_block_size: */

 Unconfigure the I/O scheduler and dissociate from the cgroup controller. */

	/*

	 * Since the I/O scheduler exit code may access cgroup information,

	 * perform I/O scheduler exit before disassociating from the block

	 * cgroup controller.

	/*

	 * Remove all references to @q from the block cgroup controller before

	 * restoring @q->queue_lock to avoid that restoring this pointer causes

	 * e.g. blkcg_print_blkgs() to crash.

/**

 * blk_release_queue - releases all allocated resources of the request_queue

 * @kobj: pointer to a kobject, whose container is a request_queue

 *

 * This function releases all allocated resources of the request queue.

 *

 * The struct request_queue refcount is incremented with blk_get_queue() and

 * decremented with blk_put_queue(). Once the refcount reaches 0 this function

 * is called.

 *

 * For drivers that have a request_queue on a gendisk and added with

 * __device_add_disk() the refcount to request_queue will reach 0 with

 * the last put_disk() called by the driver. For drivers which don't use

 * __device_add_disk() this happens with blk_cleanup_queue().

 *

 * Drivers exist which depend on the release of the request_queue to be

 * synchronous, it should not be deferred.

 *

 * Context: can sleep

/**

 * blk_register_queue - register a block layer queue with sysfs

 * @disk: Disk of which the request queue should be registered with sysfs.

 Now everything is ready and send out KOBJ_ADD uevent */

	/*

	 * SCSI probing may synchronously create and destroy a lot of

	 * request_queues for non-existent devices.  Shutting down a fully

	 * functional queue takes measureable wallclock time as RCU grace

	 * periods are involved.  To avoid excessive latency in these

	 * cases, a request_queue starts out in a degraded mode which is

	 * faster to shut down and is made fully functional here as

	 * request_queues for non-existent devices never get registered.

/**

 * blk_unregister_queue - counterpart of blk_register_queue()

 * @disk: Disk of which the request queue should be unregistered from sysfs.

 *

 * Note: the caller is responsible for guaranteeing that this function is called

 * after blk_register_queue() has finished.

 Return early if disk->queue was never registered. */

	/*

	 * Since sysfs_remove_dir() prevents adding new directory entries

	 * before removal of existing entries starts, protect against

	 * concurrent elv_iosched_store() calls.

	/*

	 * Remove the sysfs attributes before unregistering the queue data

	 * structures that can be modified through sysfs.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 Google LLC

/**

 * DOC: blk-crypto profiles

 *

 * 'struct blk_crypto_profile' contains all generic inline encryption-related

 * state for a particular inline encryption device.  blk_crypto_profile serves

 * as the way that drivers for inline encryption hardware expose their crypto

 * capabilities and certain functions (e.g., functions to program and evict

 * keys) to upper layers.  Device drivers that want to support inline encryption

 * construct a crypto profile, then associate it with the disk's request_queue.

 *

 * If the device has keyslots, then its blk_crypto_profile also handles managing

 * these keyslots in a device-independent way, using the driver-provided

 * functions to program and evict keys as needed.  This includes keeping track

 * of which key and how many I/O requests are using each keyslot, getting

 * keyslots for I/O requests, and handling key eviction requests.

 *

 * For more information, see Documentation/block/inline-encryption.rst.

	/*

	 * Calling into the driver requires profile->lock held and the device

	 * resumed.  But we must resume the device first, since that can acquire

	 * and release profile->lock via blk_crypto_reprogram_all_keys().

/**

 * blk_crypto_profile_init() - Initialize a blk_crypto_profile

 * @profile: the blk_crypto_profile to initialize

 * @num_slots: the number of keyslots

 *

 * Storage drivers must call this when starting to set up a blk_crypto_profile,

 * before filling in additional fields.

 *

 * Return: 0 on success, or else a negative error code.

 Initialize keyslot management data. */

	/*

	 * hash_ptr() assumes bits != 0, so ensure the hash table has at least 2

	 * buckets.  This only makes a difference when there is only 1 keyslot.

/**

 * devm_blk_crypto_profile_init() - Resource-managed blk_crypto_profile_init()

 * @dev: the device which owns the blk_crypto_profile

 * @profile: the blk_crypto_profile to initialize

 * @num_slots: the number of keyslots

 *

 * Like blk_crypto_profile_init(), but causes blk_crypto_profile_destroy() to be

 * called automatically on driver detach.

 *

 * Return: 0 on success, or else a negative error code.

 Took first reference to this slot; remove it from LRU list */

/**

 * blk_crypto_keyslot_index() - Get the index of a keyslot

 * @slot: a keyslot that blk_crypto_get_keyslot() returned

 *

 * Return: the 0-based index of the keyslot within the device's keyslots.

/**

 * blk_crypto_get_keyslot() - Get a keyslot for a key, if needed.

 * @profile: the crypto profile of the device the key will be used on

 * @key: the key that will be used

 * @slot_ptr: If a keyslot is allocated, an opaque pointer to the keyslot struct

 *	      will be stored here; otherwise NULL will be stored here.

 *

 * If the device has keyslots, this gets a keyslot that's been programmed with

 * the specified key.  If the key is already in a slot, this reuses it;

 * otherwise this waits for a slot to become idle and programs the key into it.

 *

 * This must be paired with a call to blk_crypto_put_keyslot().

 *

 * Context: Process context. Takes and releases profile->lock.

 * Return: BLK_STS_OK on success, meaning that either a keyslot was allocated or

 *	   one wasn't needed; or a blk_status_t error on failure.

	/*

	 * If the device has no concept of "keyslots", then there is no need to

	 * get one.

		/*

		 * If we're here, that means there wasn't a slot that was

		 * already programmed with the key. So try to program it.

 Move this slot to the hash list for the new key. */

/**

 * blk_crypto_put_keyslot() - Release a reference to a keyslot

 * @slot: The keyslot to release the reference of (may be NULL).

 *

 * Context: Any context.

/**

 * __blk_crypto_cfg_supported() - Check whether the given crypto profile

 *				  supports the given crypto configuration.

 * @profile: the crypto profile to check

 * @cfg: the crypto configuration to check for

 *

 * Return: %true if @profile supports the given @cfg.

/**

 * __blk_crypto_evict_key() - Evict a key from a device.

 * @profile: the crypto profile of the device

 * @key: the key to evict.  It must not still be used in any I/O.

 *

 * If the device has keyslots, this finds the keyslot (if any) that contains the

 * specified key and calls the driver's keyslot_evict function to evict it.

 *

 * Otherwise, this just calls the driver's keyslot_evict function if it is

 * implemented, passing just the key (without any particular keyslot).  This

 * allows layered devices to evict the key from their underlying devices.

 *

 * Context: Process context. Takes and releases profile->lock.

 * Return: 0 on success or if there's no keyslot with the specified key, -EBUSY

 *	   if the keyslot is still in use, or another -errno value on other

 *	   error.

/**

 * blk_crypto_reprogram_all_keys() - Re-program all keyslots.

 * @profile: The crypto profile

 *

 * Re-program all keyslots that are supposed to have a key programmed.  This is

 * intended only for use by drivers for hardware that loses its keys on reset.

 *

 * Context: Process context. Takes and releases profile->lock.

 This is for device initialization, so don't resume the device */

/**

 * blk_crypto_intersect_capabilities() - restrict supported crypto capabilities

 *					 by child device

 * @parent: the crypto profile for the parent device

 * @child: the crypto profile for the child device, or NULL

 *

 * This clears all crypto capabilities in @parent that aren't set in @child.  If

 * @child is NULL, then this clears all parent capabilities.

 *

 * Only use this when setting up the crypto profile for a layered device, before

 * it's been exposed yet.

/**

 * blk_crypto_has_capabilities() - Check whether @target supports at least all

 *				   the crypto capabilities that @reference does.

 * @target: the target profile

 * @reference: the reference profile

 *

 * Return: %true if @target supports all the crypto capabilities of @reference.

/**

 * blk_crypto_update_capabilities() - Update the capabilities of a crypto

 *				      profile to match those of another crypto

 *				      profile.

 * @dst: The crypto profile whose capabilities to update.

 * @src: The crypto profile whose capabilities this function will update @dst's

 *	 capabilities to.

 *

 * Blk-crypto requires that crypto capabilities that were

 * advertised when a bio was created continue to be supported by the

 * device until that bio is ended. This is turn means that a device cannot

 * shrink its advertised crypto capabilities without any explicit

 * synchronization with upper layers. So if there's no such explicit

 * synchronization, @src must support all the crypto capabilities that

 * @dst does (i.e. we need blk_crypto_has_capabilities(@src, @dst)).

 *

 * Note also that as long as the crypto capabilities are being expanded, the

 * order of updates becoming visible is not important because it's alright

 * for blk-crypto to see stale values - they only cause blk-crypto to

 * believe that a crypto capability isn't supported when it actually is (which

 * might result in blk-crypto-fallback being used if available, or the bio being

 * failed).

 SPDX-License-Identifier: GPL-2.0

/*

 * bio-integrity.c - bio data integrity extensions

 *

 * Copyright (C) 2007, 2008, 2009 Oracle Corporation

 * Written by: Martin K. Petersen <martin.petersen@oracle.com>

/**

 * bio_integrity_alloc - Allocate integrity payload and attach it to bio

 * @bio:	bio to attach integrity metadata to

 * @gfp_mask:	Memory allocation mask

 * @nr_vecs:	Number of integrity metadata scatter-gather elements

 *

 * Description: This function prepares a bio for attaching integrity

 * metadata.  nr_vecs specifies the maximum number of pages containing

 * integrity metadata that can be attached.

/**

 * bio_integrity_free - Free bio integrity payload

 * @bio:	bio containing bip to be freed

 *

 * Description: Used to free the integrity portion of a bio. Usually

 * called from bio_free().

/**

 * bio_integrity_add_page - Attach integrity metadata

 * @bio:	bio to update

 * @page:	page containing integrity metadata

 * @len:	number of bytes of integrity metadata in page

 * @offset:	start offset within page

 *

 * Description: Attach a page containing integrity metadata to bio.

/**

 * bio_integrity_process - Process integrity metadata for a bio

 * @bio:	bio to generate/verify integrity metadata for

 * @proc_iter:  iterator to process

 * @proc_fn:	Pointer to the relevant processing function

/**

 * bio_integrity_prep - Prepare bio for integrity I/O

 * @bio:	bio to prepare

 *

 * Description:  Checks if the bio already has an integrity payload attached.

 * If it does, the payload has been generated by another kernel subsystem,

 * and we just pass it through. Otherwise allocates integrity payload.

 * The bio must have data direction, target device and start sector set priot

 * to calling.  In the WRITE case, integrity metadata will be generated using

 * the block device's integrity function.  In the READ case, the buffer

 * will be prepared for DMA and a suitable end_io handler set up.

 Already protected? */

 Allocate kernel buffer for protection data */

 Allocate bio integrity payload and integrity vectors */

 Map it */

 Auto-generate integrity metadata if this is a write */

/**

 * bio_integrity_verify_fn - Integrity I/O completion worker

 * @work:	Work struct stored in bio to be verified

 *

 * Description: This workqueue function is called to complete a READ

 * request.  The function verifies the transferred integrity metadata

 * and then calls the original bio end_io function.

	/*

	 * At the moment verify is called bio's iterator was advanced

	 * during split and completion, we need to rewind iterator to

	 * it's original position.

/**

 * __bio_integrity_endio - Integrity I/O completion function

 * @bio:	Protected bio

 *

 * Description: Completion for integrity I/O

 *

 * Normally I/O completion is done in interrupt context.  However,

 * verifying I/O integrity is a time-consuming task which must be run

 * in process context.	This function postpones completion

 * accordingly.

/**

 * bio_integrity_advance - Advance integrity vector

 * @bio:	bio whose integrity vector to update

 * @bytes_done:	number of data bytes that have been completed

 *

 * Description: This function calculates how many integrity bytes the

 * number of completed data bytes correspond to and advances the

 * integrity vector accordingly.

/**

 * bio_integrity_trim - Trim integrity vector

 * @bio:	bio whose integrity vector to update

 *

 * Description: Used to trim the integrity vector in a cloned bio.

/**

 * bio_integrity_clone - Callback for cloning bios with integrity metadata

 * @bio:	New bio

 * @bio_src:	Original bio

 * @gfp_mask:	Memory allocation mask

 *

 * Description:	Called to allocate a bip when cloning a bio

	/*

	 * kintegrityd won't block much but may burn a lot of CPU cycles.

	 * Make it highpri CPU intensive wq with max concurrency of 1.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * Budget Fair Queueing (BFQ) I/O scheduler.

 *

 * Based on ideas and code from CFQ:

 * Copyright (C) 2003 Jens Axboe <axboe@kernel.dk>

 *

 * Copyright (C) 2008 Fabio Checconi <fabio@gandalf.sssup.it>

 *		      Paolo Valente <paolo.valente@unimore.it>

 *

 * Copyright (C) 2010 Paolo Valente <paolo.valente@unimore.it>

 *                    Arianna Avanzini <avanzini@google.com>

 *

 * Copyright (C) 2017 Paolo Valente <paolo.valente@linaro.org>

 *

 * BFQ is a proportional-share I/O scheduler, with some extra

 * low-latency capabilities. BFQ also supports full hierarchical

 * scheduling through cgroups. Next paragraphs provide an introduction

 * on BFQ inner workings. Details on BFQ benefits, usage and

 * limitations can be found in Documentation/block/bfq-iosched.rst.

 *

 * BFQ is a proportional-share storage-I/O scheduling algorithm based

 * on the slice-by-slice service scheme of CFQ. But BFQ assigns

 * budgets, measured in number of sectors, to processes instead of

 * time slices. The device is not granted to the in-service process

 * for a given time slice, but until it has exhausted its assigned

 * budget. This change from the time to the service domain enables BFQ

 * to distribute the device throughput among processes as desired,

 * without any distortion due to throughput fluctuations, or to device

 * internal queueing. BFQ uses an ad hoc internal scheduler, called

 * B-WF2Q+, to schedule processes according to their budgets. More

 * precisely, BFQ schedules queues associated with processes. Each

 * process/queue is assigned a user-configurable weight, and B-WF2Q+

 * guarantees that each queue receives a fraction of the throughput

 * proportional to its weight. Thanks to the accurate policy of

 * B-WF2Q+, BFQ can afford to assign high budgets to I/O-bound

 * processes issuing sequential requests (to boost the throughput),

 * and yet guarantee a low latency to interactive and soft real-time

 * applications.

 *

 * In particular, to provide these low-latency guarantees, BFQ

 * explicitly privileges the I/O of two classes of time-sensitive

 * applications: interactive and soft real-time. In more detail, BFQ

 * behaves this way if the low_latency parameter is set (default

 * configuration). This feature enables BFQ to provide applications in

 * these classes with a very low latency.

 *

 * To implement this feature, BFQ constantly tries to detect whether

 * the I/O requests in a bfq_queue come from an interactive or a soft

 * real-time application. For brevity, in these cases, the queue is

 * said to be interactive or soft real-time. In both cases, BFQ

 * privileges the service of the queue, over that of non-interactive

 * and non-soft-real-time queues. This privileging is performed,

 * mainly, by raising the weight of the queue. So, for brevity, we

 * call just weight-raising periods the time periods during which a

 * queue is privileged, because deemed interactive or soft real-time.

 *

 * The detection of soft real-time queues/applications is described in

 * detail in the comments on the function

 * bfq_bfqq_softrt_next_start. On the other hand, the detection of an

 * interactive queue works as follows: a queue is deemed interactive

 * if it is constantly non empty only for a limited time interval,

 * after which it does become empty. The queue may be deemed

 * interactive again (for a limited time), if it restarts being

 * constantly non empty, provided that this happens only after the

 * queue has remained empty for a given minimum idle time.

 *

 * By default, BFQ computes automatically the above maximum time

 * interval, i.e., the time interval after which a constantly

 * non-empty queue stops being deemed interactive. Since a queue is

 * weight-raised while it is deemed interactive, this maximum time

 * interval happens to coincide with the (maximum) duration of the

 * weight-raising for interactive queues.

 *

 * Finally, BFQ also features additional heuristics for

 * preserving both a low latency and a high throughput on NCQ-capable,

 * rotational or flash-based devices, and to get the job done quickly

 * for applications consisting in many I/O-bound processes.

 *

 * NOTE: if the main or only goal, with a given device, is to achieve

 * the maximum-possible throughput at all times, then do switch off

 * all low-latency heuristics for that device, by setting low_latency

 * to 0.

 *

 * BFQ is described in [1], where also a reference to the initial,

 * more theoretical paper on BFQ can be found. The interested reader

 * can find in the latter paper full details on the main algorithm, as

 * well as formulas of the guarantees and formal proofs of all the

 * properties.  With respect to the version of BFQ presented in these

 * papers, this implementation adds a few more heuristics, such as the

 * ones that guarantee a low latency to interactive and soft real-time

 * applications, and a hierarchical extension based on H-WF2Q+.

 *

 * B-WF2Q+ is based on WF2Q+, which is described in [2], together with

 * H-WF2Q+, while the augmented tree used here to implement B-WF2Q+

 * with O(log N) complexity derives from the one introduced with EEVDF

 * in [3].

 *

 * [1] P. Valente, A. Avanzini, "Evolution of the BFQ Storage I/O

 *     Scheduler", Proceedings of the First Workshop on Mobile System

 *     Technologies (MST-2015), May 2015.

 *     http://algogroup.unimore.it/people/paolo/disk_sched/mst-2015.pdf

 *

 * [2] Jon C.R. Bennett and H. Zhang, "Hierarchical Packet Fair Queueing

 *     Algorithms", IEEE/ACM Transactions on Networking, 5(5):675-689,

 *     Oct 1997.

 *

 * http://www.cs.cmu.edu/~hzhang/papers/TON-97-Oct.ps.gz

 *

 * [3] I. Stoica and H. Abdel-Wahab, "Earliest Eligible Virtual Deadline

 *     First: A Flexible and Accurate Mechanism for Proportional Share

 *     Resource Allocation", technical report.

 *

 * http://www.cs.berkeley.edu/~istoica/papers/eevdf-tr-95.pdf

 Expiration time of async (0) and sync (1) requests, in ns. */

 Maximum backwards seek (magic number lifted from CFQ), in KiB. */

 Penalty of a backwards seek, in number of sectors. */

 Idling period duration, in ns. */

 Minimum number of assigned budgets for which stats are safe to compute. */

 Default maximum budget values, in sectors and number of requests. */

/*

 * When a sync request is dispatched, the queue that contains that

 * request, and all the ancestor entities of that queue, are charged

 * with the number of sectors of the request. In contrast, if the

 * request is async, then the queue and its ancestor entities are

 * charged with the number of sectors of the request, multiplied by

 * the factor below. This throttles the bandwidth for async I/O,

 * w.r.t. to sync I/O, and it is done to counter the tendency of async

 * writes to steal I/O throughput to reads.

 *

 * The current value of this parameter is the result of a tuning with

 * several hardware and software configurations. We tried to find the

 * lowest value for which writes do not cause noticeable problems to

 * reads. In fact, the lower this parameter, the stabler I/O control,

 * in the following respect.  The lower this parameter is, the less

 * the bandwidth enjoyed by a group decreases

 * - when the group does writes, w.r.t. to when it does reads;

 * - when other groups do reads, w.r.t. to when they do writes.

 Default timeout values, in jiffies, approximating CFQ defaults. */

/*

 * Time limit for merging (see comments in bfq_setup_cooperator). Set

 * to the slowest value that, in our tests, proved to be effective in

 * removing false positives, while not causing true positives to miss

 * queue merging.

 *

 * As can be deduced from the low time limit below, queue merging, if

 * successful, happens at the very beginning of the I/O of the involved

 * cooperating processes, as a consequence of the arrival of the very

 * first requests from each cooperator.  After that, there is very

 * little chance to find cooperators.

 Below this threshold (in ns), we consider thinktime immediate. */

 hw_tag detection: parallel requests threshold and min samples needed. */

/*

 * Sync random I/O is likely to be confused with soft real-time I/O,

 * because it is characterized by limited throughput and apparently

 * isochronous arrival pattern. To avoid false positives, queues

 * containing only random (seeky) I/O are prevented from being tagged

 * as soft real-time.

 Min number of samples required to perform peak-rate update */

 Min observation time interval required to perform a peak-rate update (ns) */

 Target observation time interval for a peak-rate update (ns) */

/*

 * Shift used for peak-rate fixed precision calculations.

 * With

 * - the current shift: 16 positions

 * - the current type used to store rate: u32

 * - the current unit of measure for rate: [sectors/usec], or, more precisely,

 *   [(sectors/usec) / 2^BFQ_RATE_SHIFT] to take into account the shift,

 * the range of rates that can be stored is

 * [1 / 2^BFQ_RATE_SHIFT, 2^(32 - BFQ_RATE_SHIFT)] sectors/usec =

 * [1 / 2^16, 2^16] sectors/usec = [15e-6, 65536] sectors/usec =

 * [15, 65G] sectors/sec

 * Which, assuming a sector size of 512B, corresponds to a range of

 * [7.5K, 33T] B/sec

/*

 * When configured for computing the duration of the weight-raising

 * for interactive queues automatically (see the comments at the

 * beginning of this file), BFQ does it using the following formula:

 * duration = (ref_rate / r) * ref_wr_duration,

 * where r is the peak rate of the device, and ref_rate and

 * ref_wr_duration are two reference parameters.  In particular,

 * ref_rate is the peak rate of the reference storage device (see

 * below), and ref_wr_duration is about the maximum time needed, with

 * BFQ and while reading two files in parallel, to load typical large

 * applications on the reference device (see the comments on

 * max_service_from_wr below, for more details on how ref_wr_duration

 * is obtained).  In practice, the slower/faster the device at hand

 * is, the more/less it takes to load applications with respect to the

 * reference device.  Accordingly, the longer/shorter BFQ grants

 * weight raising to interactive applications.

 *

 * BFQ uses two different reference pairs (ref_rate, ref_wr_duration),

 * depending on whether the device is rotational or non-rotational.

 *

 * In the following definitions, ref_rate[0] and ref_wr_duration[0]

 * are the reference values for a rotational device, whereas

 * ref_rate[1] and ref_wr_duration[1] are the reference values for a

 * non-rotational device. The reference rates are not the actual peak

 * rates of the devices used as a reference, but slightly lower

 * values. The reason for using slightly lower values is that the

 * peak-rate estimator tends to yield slightly lower values than the

 * actual peak rate (it can yield the actual peak rate only if there

 * is only one process doing I/O, and the process does sequential

 * I/O).

 *

 * The reference peak rates are measured in sectors/usec, left-shifted

 * by BFQ_RATE_SHIFT.

/*

 * To improve readability, a conversion function is used to initialize

 * the following array, which entails that the array can be

 * initialized only in a function.

/*

 * BFQ uses the above-detailed, time-based weight-raising mechanism to

 * privilege interactive tasks. This mechanism is vulnerable to the

 * following false positives: I/O-bound applications that will go on

 * doing I/O for much longer than the duration of weight

 * raising. These applications have basically no benefit from being

 * weight-raised at the beginning of their I/O. On the opposite end,

 * while being weight-raised, these applications

 * a) unjustly steal throughput to applications that may actually need

 * low latency;

 * b) make BFQ uselessly perform device idling; device idling results

 * in loss of device throughput with most flash-based storage, and may

 * increase latencies when used purposelessly.

 *

 * BFQ tries to reduce these problems, by adopting the following

 * countermeasure. To introduce this countermeasure, we need first to

 * finish explaining how the duration of weight-raising for

 * interactive tasks is computed.

 *

 * For a bfq_queue deemed as interactive, the duration of weight

 * raising is dynamically adjusted, as a function of the estimated

 * peak rate of the device, so as to be equal to the time needed to

 * execute the 'largest' interactive task we benchmarked so far. By

 * largest task, we mean the task for which each involved process has

 * to do more I/O than for any of the other tasks we benchmarked. This

 * reference interactive task is the start-up of LibreOffice Writer,

 * and in this task each process/bfq_queue needs to have at most ~110K

 * sectors transferred.

 *

 * This last piece of information enables BFQ to reduce the actual

 * duration of weight-raising for at least one class of I/O-bound

 * applications: those doing sequential or quasi-sequential I/O. An

 * example is file copy. In fact, once started, the main I/O-bound

 * processes of these applications usually consume the above 110K

 * sectors in much less time than the processes of an application that

 * is starting, because these I/O-bound processes will greedily devote

 * almost all their CPU cycles only to their target,

 * throughput-friendly I/O operations. This is even more true if BFQ

 * happens to be underestimating the device peak rate, and thus

 * overestimating the duration of weight raising. But, according to

 * our measurements, once transferred 110K sectors, these processes

 * have no right to be weight-raised any longer.

 *

 * Basing on the last consideration, BFQ ends weight-raising for a

 * bfq_queue if the latter happens to have received an amount of

 * service at least equal to the following constant. The constant is

 * set to slightly more than 110K, to have a minimum safety margin.

 *

 * This early ending of weight-raising reduces the amount of time

 * during which interactive false positives cause the two problems

 * described at the beginning of these comments.

/*

 * Maximum time between the creation of two queues, for stable merge

 * to be activated (in ms)

/*

 * Minimum time to be waited before evaluating delayed stable merge (in ms)

	/*

	 * If bfqq != NULL, then a non-stable queue merge between

	 * bic->bfqq and bfqq is happening here. This causes troubles

	 * in the following case: bic->bfqq has also been scheduled

	 * for a possible stable merge with bic->stable_merge_bfqq,

	 * and bic->stable_merge_bfqq == bfqq happens to

	 * hold. Troubles occur because bfqq may then undergo a split,

	 * thereby becoming eligible for a stable merge. Yet, if

	 * bic->stable_merge_bfqq points exactly to bfqq, then bfqq

	 * would be stably merged with itself. To avoid this anomaly,

	 * we cancel the stable merge if

	 * bic->stable_merge_bfqq == bfqq.

		/*

		 * Actually, these same instructions are executed also

		 * in bfq_setup_cooperator, in case of abort or actual

		 * execution of a stable merge. We could avoid

		 * repeating these instructions there too, but if we

		 * did so, we would nest even more complexity in this

		 * function.

/**

 * icq_to_bic - convert iocontext queue structure to bfq_io_cq.

 * @icq: the iocontext queue.

 bic->icq is the first member, %NULL will convert to %NULL */

/**

 * bfq_bic_lookup - search into @ioc a bic associated to @bfqd.

 * @bfqd: the lookup key.

 * @ioc: the io_context of the process doing I/O.

 * @q: the request queue.

/*

 * Scheduler run of queue, if there are requests pending and no one in the

 * driver that will restart queueing.

/*

 * Lifted from AS - choose which of rq1 and rq2 that is best served now.

 * We choose the request that is closer to the head right now.  Distance

 * behind the head is penalized and only allowed to a certain extent.

 request 1 wraps */

 request 2 wraps */

 bit mask: requests behind the disk head? */

	/*

	 * By definition, 1KiB is 2 sectors.

	/*

	 * Strict one way elevator _except_ in the case where we allow

	 * short backward seeks which are biased as twice the cost of a

	 * similar forward seek.

 Found required data */

	/*

	 * By doing switch() on the bit mask "wrap" we avoid having to

	 * check two variables for all permutations: --> faster!

 common case for CFQ: rq1 and rq2 not wrapped */

 both rqs wrapped */

		/*

		 * Since both rqs are wrapped,

		 * start with the one that's further behind head

		 * (--> only *one* back seek required),

		 * since back seek takes more time than forward.

/*

 * Async I/O can easily starve sync I/O (both sync reads and sync

 * writes), by consuming all tags. Similarly, storms of sync writes,

 * such as those that sync(2) may trigger, can starve sync reads.

 * Limit depths of async I/O and sync writes so as to counter both

 * problems.

		/*

		 * Sort strictly based on sector. Smallest to the left,

		 * largest to the right.

/*

 * The following function is not marked as __cold because it is

 * actually cold, but for the same performance goal described in the

 * comments on the likely() at the beginning of

 * bfq_setup_cooperator(). Unexpectedly, to reach an even lower

 * execution time for the case where this function is not invoked, we

 * had to add an unlikely() in each involved if().

 oom_bfqq does not participate in queue merging */

	/*

	 * bfqq cannot be merged any longer (see comments in

	 * bfq_setup_cooperator): no point in adding bfqq into the

	 * position tree.

/*

 * The following function returns false either if every active queue

 * must receive the same share of the throughput (symmetric scenario),

 * or, as a special case, if bfqq must receive a share of the

 * throughput lower than or equal to the share that every other active

 * queue must receive.  If bfqq does sync I/O, then these are the only

 * two cases where bfqq happens to be guaranteed its share of the

 * throughput even if I/O dispatching is not plugged when bfqq remains

 * temporarily empty (for more details, see the comments in the

 * function bfq_better_to_idle()). For this reason, the return value

 * of this function is used to check whether I/O-dispatch plugging can

 * be avoided.

 *

 * The above first case (symmetric scenario) occurs when:

 * 1) all active queues have the same weight,

 * 2) all active queues belong to the same I/O-priority class,

 * 3) all active groups at the same level in the groups tree have the same

 *    weight,

 * 4) all active groups at the same level in the groups tree have the same

 *    number of children.

 *

 * Unfortunately, keeping the necessary state for evaluating exactly

 * the last two symmetry sub-conditions above would be quite complex

 * and time consuming. Therefore this function evaluates, instead,

 * only the following stronger three sub-conditions, for which it is

 * much easier to maintain the needed state:

 * 1) all active queues have the same weight,

 * 2) all active queues belong to the same I/O-priority class,

 * 3) there are no active groups.

 * In particular, the last condition is always true if hierarchical

 * support or the cgroups interface are not enabled, thus no state

 * needs to be maintained in this case.

	/*

	 * For queue weights to differ, queue_weights_tree must contain

	 * at least two nodes.

/*

 * If the weight-counter tree passed as input contains no counter for

 * the weight of the input queue, then add that counter; otherwise just

 * increment the existing counter.

 *

 * Note that weight-counter trees contain few nodes in mostly symmetric

 * scenarios. For example, if all queues have the same weight, then the

 * weight-counter tree for the queues may contain at most one node.

 * This holds even if low_latency is on, because weight-raised queues

 * are not inserted in the tree.

 * In most scenarios, the rate at which nodes are created/destroyed

 * should be low too.

	/*

	 * Do not insert if the queue is already associated with a

	 * counter, which happens if:

	 *   1) a request arrival has caused the queue to become both

	 *      non-weight-raised, and hence change its weight, and

	 *      backlogged; in this respect, each of the two events

	 *      causes an invocation of this function,

	 *   2) this is the invocation of this function caused by the

	 *      second event. This second invocation is actually useless,

	 *      and we handle this fact by exiting immediately. More

	 *      efficient or clearer solutions might possibly be adopted.

	/*

	 * In the unlucky event of an allocation failure, we just

	 * exit. This will cause the weight of queue to not be

	 * considered in bfq_asymmetric_scenario, which, in its turn,

	 * causes the scenario to be deemed wrongly symmetric in case

	 * bfqq's weight would have been the only weight making the

	 * scenario asymmetric.  On the bright side, no unbalance will

	 * however occur when bfqq becomes inactive again (the

	 * invocation of this function is triggered by an activation

	 * of queue).  In fact, bfq_weights_tree_remove does nothing

	 * if !bfqq->weight_counter.

/*

 * Decrement the weight counter associated with the queue, and, if the

 * counter reaches 0, remove the counter from the tree.

 * See the comments to the function bfq_weights_tree_add() for considerations

 * about overhead.

/*

 * Invoke __bfq_weights_tree_remove on bfqq and decrement the number

 * of active groups for each queue's inactive parent entity.

			/*

			 * entity is still active, because either

			 * next_in_service or in_service_entity is not

			 * NULL (see the comments on the definition of

			 * next_in_service for details on why

			 * in_service_entity must be checked too).

			 *

			 * As a consequence, its parent entities are

			 * active as well, and thus this loop must

			 * stop here.

		/*

		 * The decrement of num_groups_with_pending_reqs is

		 * not performed immediately upon the deactivation of

		 * entity, but it is delayed to when it also happens

		 * that the first leaf descendant bfqq of entity gets

		 * all its pending requests completed. The following

		 * instructions perform this delayed decrement, if

		 * needed. See the comments on

		 * num_groups_with_pending_reqs for details.

	/*

	 * Next function is invoked last, because it causes bfqq to be

	 * freed if the following holds: bfqq is not in service and

	 * has no dispatched request. DO NOT use bfqq after the next

	 * function invocation.

/*

 * Return expired entry, or NULL to just start from scratch in rbtree.

 Follow expired path, else get first next available. */

 see the definition of bfq_async_charge_factor for details */

/**

 * bfq_updated_next_req - update the queue after a new next_rq selection.

 * @bfqd: the device data the queue belongs to.

 * @bfqq: the queue to update.

 *

 * If the first request of a queue changes we make sure that the queue

 * has enough budget to serve at least its first request (if the

 * request has grown).  We do this because if the queue has not enough

 * budget for its first request, it has to go through two dispatch

 * rounds to actually get it dispatched.

		/*

		 * In order not to break guarantees, budgets cannot be

		 * changed after an entity has been selected.

	/*

	 * Limit duration between 3 and 25 seconds. The upper limit

	 * has been conservatively set after the following worst case:

	 * on a QEMU/KVM virtual machine

	 * - running in a slow PC

	 * - with a virtual disk stacked on a slow low-end 5400rpm HDD

	 * - serving a heavy I/O workload, such as the sequential reading

	 *   of several files

	 * mplayer took 23 seconds to start, if constantly weight-raised.

	 *

	 * As for higher values than that accommodating the above bad

	 * scenario, tests show that higher values would often yield

	 * the opposite of the desired result, i.e., would worsen

	 * responsiveness by allowing non-interactive applications to

	 * preserve weight raising for too long.

	 *

	 * On the other end, lower values than 3 seconds make it

	 * difficult for most interactive tasks to complete their jobs

	 * before weight-raising finishes.

 switch back from soft real-time to interactive weight raising */

	/*

	 * Restore weight coefficient only if low_latency is on

 make sure weight will be updated, however we got here */

 Empty burst list and add just bfqq (see comments on bfq_handle_burst) */

	/*

	 * Start the creation of a new burst list only if there is no

	 * active queue. See comments on the conditional invocation of

	 * bfq_handle_burst().

 Add bfqq to the list of queues in current burst (see bfq_handle_burst) */

 Increment burst size to take into account also bfqq */

		/*

		 * Enough queues have been activated shortly after each

		 * other to consider this burst as large.

		/*

		 * We can now mark all queues in the burst list as

		 * belonging to a large burst.

		/*

		 * From now on, and until the current burst finishes, any

		 * new queue being activated shortly after the last queue

		 * was inserted in the burst can be immediately marked as

		 * belonging to a large burst. So the burst list is not

		 * needed any more. Remove it.

	} else /*

		* Burst not yet large: add bfqq to the burst list. Do

		* not increment the ref counter for bfqq, because bfqq

		* is removed from the burst list before freeing bfqq

		* in put_queue.

/*

 * If many queues belonging to the same group happen to be created

 * shortly after each other, then the processes associated with these

 * queues have typically a common goal. In particular, bursts of queue

 * creations are usually caused by services or applications that spawn

 * many parallel threads/processes. Examples are systemd during boot,

 * or git grep. To help these processes get their job done as soon as

 * possible, it is usually better to not grant either weight-raising

 * or device idling to their queues, unless these queues must be

 * protected from the I/O flowing through other active queues.

 *

 * In this comment we describe, firstly, the reasons why this fact

 * holds, and, secondly, the next function, which implements the main

 * steps needed to properly mark these queues so that they can then be

 * treated in a different way.

 *

 * The above services or applications benefit mostly from a high

 * throughput: the quicker the requests of the activated queues are

 * cumulatively served, the sooner the target job of these queues gets

 * completed. As a consequence, weight-raising any of these queues,

 * which also implies idling the device for it, is almost always

 * counterproductive, unless there are other active queues to isolate

 * these new queues from. If there no other active queues, then

 * weight-raising these new queues just lowers throughput in most

 * cases.

 *

 * On the other hand, a burst of queue creations may be caused also by

 * the start of an application that does not consist of a lot of

 * parallel I/O-bound threads. In fact, with a complex application,

 * several short processes may need to be executed to start-up the

 * application. In this respect, to start an application as quickly as

 * possible, the best thing to do is in any case to privilege the I/O

 * related to the application with respect to all other

 * I/O. Therefore, the best strategy to start as quickly as possible

 * an application that causes a burst of queue creations is to

 * weight-raise all the queues created during the burst. This is the

 * exact opposite of the best strategy for the other type of bursts.

 *

 * In the end, to take the best action for each of the two cases, the

 * two types of bursts need to be distinguished. Fortunately, this

 * seems relatively easy, by looking at the sizes of the bursts. In

 * particular, we found a threshold such that only bursts with a

 * larger size than that threshold are apparently caused by

 * services or commands such as systemd or git grep. For brevity,

 * hereafter we call just 'large' these bursts. BFQ *does not*

 * weight-raise queues whose creation occurs in a large burst. In

 * addition, for each of these queues BFQ performs or does not perform

 * idling depending on which choice boosts the throughput more. The

 * exact choice depends on the device and request pattern at

 * hand.

 *

 * Unfortunately, false positives may occur while an interactive task

 * is starting (e.g., an application is being started). The

 * consequence is that the queues associated with the task do not

 * enjoy weight raising as expected. Fortunately these false positives

 * are very rare. They typically occur if some service happens to

 * start doing I/O exactly when the interactive task starts.

 *

 * Turning back to the next function, it is invoked only if there are

 * no active queues (apart from active queues that would belong to the

 * same, possible burst bfqq would belong to), and it implements all

 * the steps needed to detect the occurrence of a large burst and to

 * properly mark all the queues belonging to it (so that they can then

 * be treated in a different way). This goal is achieved by

 * maintaining a "burst list" that holds, temporarily, the queues that

 * belong to the burst in progress. The list is then used to mark

 * these queues as belonging to a large burst if the burst does become

 * large. The main steps are the following.

 *

 * . when the very first queue is created, the queue is inserted into the

 *   list (as it could be the first queue in a possible burst)

 *

 * . if the current burst has not yet become large, and a queue Q that does

 *   not yet belong to the burst is activated shortly after the last time

 *   at which a new queue entered the burst list, then the function appends

 *   Q to the burst list

 *

 * . if, as a consequence of the previous step, the burst size reaches

 *   the large-burst threshold, then

 *

 *     . all the queues in the burst list are marked as belonging to a

 *       large burst

 *

 *     . the burst list is deleted; in fact, the burst list already served

 *       its purpose (keeping temporarily track of the queues in a burst,

 *       so as to be able to mark them as belonging to a large burst in the

 *       previous sub-step), and now is not needed any more

 *

 *     . the device enters a large-burst mode

 *

 * . if a queue Q that does not belong to the burst is created while

 *   the device is in large-burst mode and shortly after the last time

 *   at which a queue either entered the burst list or was marked as

 *   belonging to the current large burst, then Q is immediately marked

 *   as belonging to a large burst.

 *

 * . if a queue Q that does not belong to the burst is created a while

 *   later, i.e., not shortly after, than the last time at which a queue

 *   either entered the burst list or was marked as belonging to the

 *   current large burst, then the current burst is deemed as finished and:

 *

 *        . the large-burst mode is reset if set

 *

 *        . the burst list is emptied

 *

 *        . Q is inserted in the burst list, as Q may be the first queue

 *          in a possible new burst (then the burst list contains just Q

 *          after this step).

	/*

	 * If bfqq is already in the burst list or is part of a large

	 * burst, or finally has just been split, then there is

	 * nothing else to do.

	/*

	 * If bfqq's creation happens late enough, or bfqq belongs to

	 * a different group than the burst group, then the current

	 * burst is finished, and related data structures must be

	 * reset.

	 *

	 * In this respect, consider the special case where bfqq is

	 * the very first queue created after BFQ is selected for this

	 * device. In this case, last_ins_in_burst and

	 * burst_parent_entity are not yet significant when we get

	 * here. But it is easy to verify that, whether or not the

	 * following condition is true, bfqq will end up being

	 * inserted into the burst list. In particular the list will

	 * happen to contain only bfqq. And this is exactly what has

	 * to happen, as bfqq may be the first queue of the first

	 * burst.

	/*

	 * If we get here, then bfqq is being activated shortly after the

	 * last queue. So, if the current burst is also large, we can mark

	 * bfqq as belonging to this large burst immediately.

	/*

	 * If we get here, then a large-burst state has not yet been

	 * reached, but bfqq is being activated shortly after the last

	 * queue. Then we add bfqq to the burst.

	/*

	 * At this point, bfqq either has been added to the current

	 * burst or has caused the current burst to terminate and a

	 * possible new burst to start. In particular, in the second

	 * case, bfqq has become the first queue in the possible new

	 * burst.  In both cases last_ins_in_burst needs to be moved

	 * forward.

/*

 * If enough samples have been computed, return the current max budget

 * stored in bfqd, which is dynamically updated according to the

 * estimated disk peak rate; otherwise return the default max budget

/*

 * Return min budget, which is a fraction of the current or default

 * max budget (trying with 1/32)

/*

 * The next function, invoked after the input queue bfqq switches from

 * idle to busy, updates the budget of bfqq. The function also tells

 * whether the in-service queue should be expired, by returning

 * true. The purpose of expiring the in-service queue is to give bfqq

 * the chance to possibly preempt the in-service queue, and the reason

 * for preempting the in-service queue is to achieve one of the two

 * goals below.

 *

 * 1. Guarantee to bfqq its reserved bandwidth even if bfqq has

 * expired because it has remained idle. In particular, bfqq may have

 * expired for one of the following two reasons:

 *

 * - BFQQE_NO_MORE_REQUESTS bfqq did not enjoy any device idling

 *   and did not make it to issue a new request before its last

 *   request was served;

 *

 * - BFQQE_TOO_IDLE bfqq did enjoy device idling, but did not issue

 *   a new request before the expiration of the idling-time.

 *

 * Even if bfqq has expired for one of the above reasons, the process

 * associated with the queue may be however issuing requests greedily,

 * and thus be sensitive to the bandwidth it receives (bfqq may have

 * remained idle for other reasons: CPU high load, bfqq not enjoying

 * idling, I/O throttling somewhere in the path from the process to

 * the I/O scheduler, ...). But if, after every expiration for one of

 * the above two reasons, bfqq has to wait for the service of at least

 * one full budget of another queue before being served again, then

 * bfqq is likely to get a much lower bandwidth or resource time than

 * its reserved ones. To address this issue, two countermeasures need

 * to be taken.

 *

 * First, the budget and the timestamps of bfqq need to be updated in

 * a special way on bfqq reactivation: they need to be updated as if

 * bfqq did not remain idle and did not expire. In fact, if they are

 * computed as if bfqq expired and remained idle until reactivation,

 * then the process associated with bfqq is treated as if, instead of

 * being greedy, it stopped issuing requests when bfqq remained idle,

 * and restarts issuing requests only on this reactivation. In other

 * words, the scheduler does not help the process recover the "service

 * hole" between bfqq expiration and reactivation. As a consequence,

 * the process receives a lower bandwidth than its reserved one. In

 * contrast, to recover this hole, the budget must be updated as if

 * bfqq was not expired at all before this reactivation, i.e., it must

 * be set to the value of the remaining budget when bfqq was

 * expired. Along the same line, timestamps need to be assigned the

 * value they had the last time bfqq was selected for service, i.e.,

 * before last expiration. Thus timestamps need to be back-shifted

 * with respect to their normal computation (see [1] for more details

 * on this tricky aspect).

 *

 * Secondly, to allow the process to recover the hole, the in-service

 * queue must be expired too, to give bfqq the chance to preempt it

 * immediately. In fact, if bfqq has to wait for a full budget of the

 * in-service queue to be completed, then it may become impossible to

 * let the process recover the hole, even if the back-shifted

 * timestamps of bfqq are lower than those of the in-service queue. If

 * this happens for most or all of the holes, then the process may not

 * receive its reserved bandwidth. In this respect, it is worth noting

 * that, being the service of outstanding requests unpreemptible, a

 * little fraction of the holes may however be unrecoverable, thereby

 * causing a little loss of bandwidth.

 *

 * The last important point is detecting whether bfqq does need this

 * bandwidth recovery. In this respect, the next function deems the

 * process associated with bfqq greedy, and thus allows it to recover

 * the hole, if: 1) the process is waiting for the arrival of a new

 * request (which implies that bfqq expired for one of the above two

 * reasons), and 2) such a request has arrived soon. The first

 * condition is controlled through the flag non_blocking_wait_rq,

 * while the second through the flag arrived_in_time. If both

 * conditions hold, then the function computes the budget in the

 * above-described special way, and signals that the in-service queue

 * should be expired. Timestamp back-shifting is done later in

 * __bfq_activate_entity.

 *

 * 2. Reduce latency. Even if timestamps are not backshifted to let

 * the process associated with bfqq recover a service hole, bfqq may

 * however happen to have, after being (re)activated, a lower finish

 * timestamp than the in-service queue.	 That is, the next budget of

 * bfqq may have to be completed before the one of the in-service

 * queue. If this is the case, then preempting the in-service queue

 * allows this goal to be achieved, apart from the unpreemptible,

 * outstanding requests mentioned above.

 *

 * Unfortunately, regardless of which of the above two goals one wants

 * to achieve, service trees need first to be updated to know whether

 * the in-service queue must be preempted. To have service trees

 * correctly updated, the in-service queue must be expired and

 * rescheduled, and bfqq must be scheduled too. This is one of the

 * most costly operations (in future versions, the scheduling

 * mechanism may be re-designed in such a way to make it possible to

 * know whether preemption is needed without needing to update service

 * trees). In addition, queue preemptions almost always cause random

 * I/O, which may in turn cause loss of throughput. Finally, there may

 * even be no in-service queue when the next function is invoked (so,

 * no queue to compare timestamps with). Because of these facts, the

 * next function adopts the following simple scheme to avoid costly

 * operations, too frequent preemptions and too many dependencies on

 * the state of the scheduler: it requests the expiration of the

 * in-service queue (unconditionally) only for queues that need to

 * recover a hole. Then it delegates to other parts of the code the

 * responsibility of handling the above case 2.

	/*

	 * In the next compound condition, we check also whether there

	 * is some budget left, because otherwise there is no point in

	 * trying to go on serving bfqq with this same budget: bfqq

	 * would be expired immediately after being selected for

	 * service. This would only cause useless overhead.

		/*

		 * We do not clear the flag non_blocking_wait_rq here, as

		 * the latter is used in bfq_activate_bfqq to signal

		 * that timestamps need to be back-shifted (and is

		 * cleared right after).

		/*

		 * In next assignment we rely on that either

		 * entity->service or entity->budget are not updated

		 * on expiration if bfqq is empty (see

		 * __bfq_bfqq_recalc_budget). Thus both quantities

		 * remain unchanged after such an expiration, and the

		 * following statement therefore assigns to

		 * entity->budget the remaining budget on such an

		 * expiration.

		/*

		 * At this point, we have used entity->service to get

		 * the budget left (needed for updating

		 * entity->budget). Thus we finally can, and have to,

		 * reset entity->service. The latter must be reset

		 * because bfqq would otherwise be charged again for

		 * the service it has received during its previous

		 * service slot(s).

	/*

	 * We can finally complete expiration, by setting service to 0.

/*

 * Return the farthest past time instant according to jiffies

 * macros.

 start a weight-raising period */

			/*

			 * No interactive weight raising in progress

			 * here: assign minus infinity to

			 * wr_start_at_switch_to_srt, to make sure

			 * that, at the end of the soft-real-time

			 * weight raising periods that is starting

			 * now, no interactive weight-raising period

			 * may be wrongly considered as still in

			 * progress (and thus actually started by

			 * mistake).

		/*

		 * If needed, further reduce budget to make sure it is

		 * close to bfqq's backlog, so as to reduce the

		 * scheduling-error component due to a too large

		 * budget. Do not care about throughput consequences,

		 * but only about latency. Finally, do not assign a

		 * too small budget either, to avoid increasing

		 * latency by causing too frequent expirations.

 update wr coeff and duration */

			/*

			 * The application is now or still meeting the

			 * requirements for being deemed soft rt.  We

			 * can then correctly and safely (re)charge

			 * the weight-raising duration for the

			 * application with the weight-raising

			 * duration for soft rt applications.

			 *

			 * In particular, doing this recharge now, i.e.,

			 * before the weight-raising period for the

			 * application finishes, reduces the probability

			 * of the following negative scenario:

			 * 1) the weight of a soft rt application is

			 *    raised at startup (as for any newly

			 *    created application),

			 * 2) since the application is not interactive,

			 *    at a certain time weight-raising is

			 *    stopped for the application,

			 * 3) at that time the application happens to

			 *    still have pending requests, and hence

			 *    is destined to not have a chance to be

			 *    deemed soft rt before these requests are

			 *    completed (see the comments to the

			 *    function bfq_bfqq_softrt_next_start()

			 *    for details on soft rt detection),

			 * 4) these pending requests experience a high

			 *    latency because the application is not

			 *    weight-raised while they are pending.

/*

 * Return true if bfqq is in a higher priority class, or has a higher

 * weight than the in-service queue.

		/*

		 * See the comments on

		 * bfq_bfqq_update_budg_for_activation for

		 * details on the usage of the next variable.

	/*

	 * bfqq deserves to be weight-raised if:

	 * - it is sync,

	 * - it does not belong to a large burst,

	 * - it has been idle for enough time or is soft real-time,

	 * - is linked to a bfq_io_cq (it is not shared in any sense),

	 * - has a default weight (otherwise we assume the user wanted

	 *   to control its weight explicitly)

	/*

	 * Merged bfq_queues are kept out of weight-raising

	 * (low-latency) mechanisms. The reason is that these queues

	 * are usually created for non-interactive and

	 * non-soft-real-time tasks. Yet this is not the case for

	 * stably-merged queues. These queues are merged just because

	 * they are created shortly after each other. So they may

	 * easily serve the I/O of an interactive or soft-real time

	 * application, if the application happens to spawn multiple

	 * processes. So let also stably-merged queued enjoy weight

	 * raising.

	/*

	 * Using the last flag, update budget and check whether bfqq

	 * may want to preempt the in-service queue.

	/*

	 * If bfqq happened to be activated in a burst, but has been

	 * idle for much more than an interactive queue, then we

	 * assume that, in the overall I/O initiated in the burst, the

	 * I/O associated with bfqq is finished. So bfqq does not need

	 * to be treated as a queue belonging to a burst

	 * anymore. Accordingly, we reset bfqq's in_large_burst flag

	 * if set, and remove bfqq from the burst list if it's

	 * there. We do not decrement burst_size, because the fact

	 * that bfqq does not need to belong to the burst list any

	 * more does not invalidate the fact that bfqq was created in

	 * a burst.

 wraparound */

	/*

	 * Expire in-service queue if preemption may be needed for

	 * guarantees or throughput. As for guarantees, we care

	 * explicitly about two cases. The first is that bfqq has to

	 * recover a service hole, as explained in the comments on

	 * bfq_bfqq_update_budg_for_activation(), i.e., that

	 * bfqq_wants_to_preempt is true. However, if bfqq does not

	 * carry time-critical I/O, then bfqq's bandwidth is less

	 * important than that of queues that carry time-critical I/O.

	 * So, as a further constraint, we consider this case only if

	 * bfqq is at least as weight-raised, i.e., at least as time

	 * critical, as the in-service queue.

	 *

	 * The second case is that bfqq is in a higher priority class,

	 * or has a higher weight than the in-service queue. If this

	 * condition does not hold, we don't care because, even if

	 * bfqq does not start to be served immediately, the resulting

	 * delay for bfqq's I/O is however lower or much lower than

	 * the ideal completion time to be guaranteed to bfqq's I/O.

	 *

	 * In both cases, preemption is needed only if, according to

	 * the timestamps of both bfqq and of the in-service queue,

	 * bfqq actually is the next queue to serve. So, to reduce

	 * useless preemptions, the return value of

	 * next_queue_may_preempt() is considered in the next compound

	 * condition too. Yet next_queue_may_preempt() just checks a

	 * simple, necessary condition for bfqq to be the next queue

	 * to serve. In fact, to evaluate a sufficient condition, the

	 * timestamps of the in-service queue would need to be

	 * updated, and this operation is quite costly (see the

	 * comments on bfq_bfqq_update_budg_for_activation()).

	 *

	 * As for throughput, we ask bfq_better_to_idle() whether we

	 * still need to plug I/O dispatching. If bfq_better_to_idle()

	 * says no, then plugging is not needed any longer, either to

	 * boost throughput or to perserve service guarantees. Then

	 * the best option is to stop plugging I/O, as not doing so

	 * would certainly lower throughput. We may end up in this

	 * case if: (1) upon a dispatch attempt, we detected that it

	 * was better to plug I/O dispatch, and to wait for a new

	 * request to arrive for the currently in-service queue, but

	 * (2) this switch of bfqq to busy changes the scenario.

 invalidate baseline total service time */

	/*

	 * Reset pointer in case we are waiting for

	 * some request completion.

	/*

	 * If bfqq has a short think time, then start by setting the

	 * inject limit to 0 prudentially, because the service time of

	 * an injected I/O request may be higher than the think time

	 * of bfqq, and therefore, if one request was injected when

	 * bfqq remains empty, this injected request might delay the

	 * service of the next I/O request for bfqq significantly. In

	 * case bfqq can actually tolerate some injection, then the

	 * adaptive update will however raise the limit soon. This

	 * lucky circumstance holds exactly because bfqq has a short

	 * think time, and thus, after remaining empty, is likely to

	 * get new I/O enqueued---and then completed---before being

	 * expired. This is the very pattern that gives the

	 * limit-update algorithm the chance to measure the effect of

	 * injection on request service times, and then to update the

	 * limit accordingly.

	 *

	 * However, in the following special case, the inject limit is

	 * left to 1 even if the think time is short: bfqq's I/O is

	 * synchronized with that of some other queue, i.e., bfqq may

	 * receive new I/O only after the I/O of the other queue is

	 * completed. Keeping the inject limit to 1 allows the

	 * blocking I/O to be served while bfqq is in service. And

	 * this is very convenient both for bfqq and for overall

	 * throughput, as explained in detail in the comments in

	 * bfq_update_has_short_ttime().

	 *

	 * On the opposite end, if bfqq has a long think time, then

	 * start directly by 1, because:

	 * a) on the bright side, keeping at most one request in

	 * service in the drive is unlikely to cause any harm to the

	 * latency of bfqq's requests, as the service time of a single

	 * request is likely to be lower than the think time of bfqq;

	 * b) on the downside, after becoming empty, bfqq is likely to

	 * expire before getting its next request. With this request

	 * arrival pattern, it is very hard to sample total service

	 * times and update the inject limit accordingly (see comments

	 * on bfq_update_inject_limit()). So the limit is likely to be

	 * never, or at least seldom, updated.  As a consequence, by

	 * setting the limit to 1, we avoid that no injection ever

	 * occurs with bfqq. On the downside, this proactive step

	 * further reduces chances to actually compute the baseline

	 * total service time. Thus it reduces chances to execute the

	 * limit-update algorithm and possibly raise the limit to more

	 * than 1.

	/*

	 * Must be busy for at least about 80% of the time to be

	 * considered I/O bound.

	/*

	 * Keep an observation window of at most 200 ms in the past

	 * from now.

/*

 * Detect whether bfqq's I/O seems synchronized with that of some

 * other queue, i.e., whether bfqq, after remaining empty, happens to

 * receive new I/O only right after some I/O request of the other

 * queue has been completed. We call waker queue the other queue, and

 * we assume, for simplicity, that bfqq may have at most one waker

 * queue.

 *

 * A remarkable throughput boost can be reached by unconditionally

 * injecting the I/O of the waker queue, every time a new

 * bfq_dispatch_request happens to be invoked while I/O is being

 * plugged for bfqq.  In addition to boosting throughput, this

 * unblocks bfqq's I/O, thereby improving bandwidth and latency for

 * bfqq. Note that these same results may be achieved with the general

 * injection mechanism, but less effectively. For details on this

 * aspect, see the comments on the choice of the queue for injection

 * in bfq_select_queue().

 *

 * Turning back to the detection of a waker queue, a queue Q is deemed

 * as a waker queue for bfqq if, for three consecutive times, bfqq

 * happens to become non empty right after a request of Q has been

 * completed. In this respect, even if bfqq is empty, we do not check

 * for a waker if it still has some in-flight I/O. In fact, in this

 * case bfqq is actually still being served by the drive, and may

 * receive new I/O on the completion of some of the in-flight

 * requests. In particular, on the first time, Q is tentatively set as

 * a candidate waker queue, while on the third consecutive time that Q

 * is detected, the field waker_bfqq is set to Q, to confirm that Q is

 * a waker queue for bfqq. These detection steps are performed only if

 * bfqq has a long think time, so as to make it more likely that

 * bfqq's I/O is actually being blocked by a synchronization. This

 * last filter, plus the above three-times requirement, make false

 * positives less likely.

 *

 * NOTE

 *

 * The sooner a waker queue is detected, the sooner throughput can be

 * boosted by injecting I/O from the waker queue. Fortunately,

 * detection is likely to be actually fast, for the following

 * reasons. While blocked by synchronization, bfqq has a long think

 * time. This implies that bfqq's inject limit is at least equal to 1

 * (see the comments in bfq_update_inject_limit()). So, thanks to

 * injection, the waker queue is likely to be served during the very

 * first I/O-plugging time interval for bfqq. This triggers the first

 * step of the detection mechanism. Thanks again to injection, the

 * candidate waker queue is then likely to be confirmed no later than

 * during the next I/O-plugging interval for bfqq.

 *

 * ISSUE

 *

 * On queue merging all waker information is lost.

		/*

		 * First synchronization detected with a

		 * candidate waker queue, or with a different

		 * candidate waker queue from the current one.

 Same tentative waker queue detected again */

		/*

		 * If the waker queue disappears, then

		 * bfqq->waker_bfqq must be reset. To

		 * this goal, we maintain in each

		 * waker queue a list, woken_list, of

		 * all the queues that reference the

		 * waker queue through their

		 * waker_bfqq pointer. When the waker

		 * queue exits, the waker_bfqq pointer

		 * of all the queues in the woken_list

		 * is reset.

		 *

		 * In addition, if bfqq is already in

		 * the woken_list of a waker queue,

		 * then, before being inserted into

		 * the woken_list of a new waker

		 * queue, bfqq must be removed from

		 * the woken_list of the old waker

		 * queue.

		/*

		 * Periodically reset inject limit, to make sure that

		 * the latter eventually drops in case workload

		 * changes, see step (3) in the comments on

		 * bfq_update_inject_limit().

		/*

		 * The following conditions must hold to setup a new

		 * sampling of total service time, and then a new

		 * update of the inject limit:

		 * - bfqq is in service, because the total service

		 *   time is evaluated only for the I/O requests of

		 *   the queues in service;

		 * - this is the right occasion to compute or to

		 *   lower the baseline total service time, because

		 *   there are actually no requests in the drive,

		 *   or

		 *   the baseline total service time is available, and

		 *   this is the right occasion to compute the other

		 *   quantity needed to update the inject limit, i.e.,

		 *   the total service time caused by the amount of

		 *   injection allowed by the current value of the

		 *   limit. It is the right occasion because injection

		 *   has actually been performed during the service

		 *   hole, and there are still in-flight requests,

		 *   which are very likely to be exactly the injected

		 *   requests, or part of them;

		 * - the minimum interval for sampling the total

		 *   service time and updating the inject limit has

		 *   elapsed.

			/*

			 * Start the state machine for measuring the

			 * total service time of rq: setting

			 * wait_dispatch will cause bfqd->waited_rq to

			 * be set when rq will be dispatched.

			/*

			 * If there is no I/O in service in the drive,

			 * then possible injection occurred before the

			 * arrival of rq will not affect the total

			 * service time of rq. So the injection limit

			 * must not be updated as a function of such

			 * total service time, unless new injection

			 * occurs before rq is completed. To have the

			 * injection limit updated only in the latter

			 * case, reset rqs_injected here (rqs_injected

			 * will be set in case injection is performed

			 * on bfqq before rq is completed).

	/*

	 * Check if this request is a better next-serve candidate.

	/*

	 * Adjust priority tree position, if next_rq changes.

	 * See comments on bfq_pos_tree_add_move() for the unlikely().

 switching to busy ... */

	/*

	 * Assign jiffies to last_wr_start_finish in the following

	 * cases:

	 *

	 * . if bfqq is not going to be weight-raised, because, for

	 *   non weight-raised queues, last_wr_start_finish stores the

	 *   arrival time of the last request; as of now, this piece

	 *   of information is used only for deciding whether to

	 *   weight-raise async queues

	 *

	 * . if bfqq is not weight-raised, because, if bfqq is now

	 *   switching to weight-raised, then last_wr_start_finish

	 *   stores the time when weight-raising starts

	 *

	 * . if bfqq is interactive, because, regardless of whether

	 *   bfqq is currently weight-raised, the weight-raising

	 *   period must start or restart (this case is considered

	 *   separately because it is not detected by the above

	 *   conditions, if bfqq is already weight-raised)

	 *

	 * last_wr_start_finish has to be updated also if bfqq is soft

	 * real-time, because the weight-raising period is constantly

	 * restarted on idle-to-busy transitions for these queues, but

	 * this is already done in bfq_bfqq_handle_idle_busy_switch if

	 * needed.

 Still not clear if we can do without next two functions */

			/*

			 * bfqq emptied. In normal operation, when

			 * bfqq is empty, bfqq->entity.service and

			 * bfqq->entity.budget must contain,

			 * respectively, the service received and the

			 * budget used last time bfqq emptied. These

			 * facts do not hold in this case, as at least

			 * this last removal occurred while bfqq is

			 * not in service. To avoid inconsistencies,

			 * reset both bfqq->entity.service and

			 * bfqq->entity.budget, if bfqq has still a

			 * process that may issue I/O requests to it.

		/*

		 * Remove queue from request-position tree as it is empty.

 see comments on bfq_pos_tree_add_move() for the unlikely() */

	/*

	 * bfq_bic_lookup grabs the queue_lock: invoke it now and

	 * store its return value for later use, to avoid nesting

	 * queue_lock inside the bfqd->lock. We assume that the bic

	 * returned by bfq_bic_lookup does not go away before

	 * bfqd->lock is taken.

 Reposition request in its sort_list */

 Choose next request to be served for bfqq */

		/*

		 * If next_rq changes, update both the queue's budget to

		 * fit the new request and the queue's position in its

		 * rq_pos_tree.

			/*

			 * See comments on bfq_pos_tree_add_move() for

			 * the unlikely().

/*

 * This function is called to notify the scheduler that the requests

 * rq and 'next' have been merged, with 'next' going away.  BFQ

 * exploits this hook to address the following issue: if 'next' has a

 * fifo_time lower that rq, then the fifo_time of rq must be set to

 * the value of 'next', to not forget the greater age of 'next'.

 *

 * NOTE: in this function we assume that rq is in a bfq_queue, basing

 * on that rq is picked from the hash table q->elevator->hash, which,

 * in its turn, is filled only with I/O requests present in

 * bfq_queues, while BFQ is in use for the request queue q. In fact,

 * the function that fills this hash table (elv_rqhash_add) is called

 * only by bfq_insert_request.

	/*

	 * If next and rq belong to the same bfq_queue and next is older

	 * than rq, then reposition rq in the fifo (by substituting next

	 * with rq). Otherwise, if next and rq belong to different

	 * bfq_queues, never reposition rq: in fact, we would have to

	 * reposition it with respect to next's position in its own fifo,

	 * which would most certainly be too expensive with respect to

	 * the benefits.

 Merged request may be in the IO scheduler. Remove it. */

 Must be called with bfqq != NULL */

	/*

	 * If bfqq has been enjoying interactive weight-raising, then

	 * reset soft_rt_next_start. We do it for the following

	 * reason. bfqq may have been conveying the I/O needed to load

	 * a soft real-time application. Such an application actually

	 * exhibits a soft real-time I/O pattern after it finishes

	 * loading, and finally starts doing its job. But, if bfqq has

	 * been receiving a lot of bandwidth so far (likely to happen

	 * on a fast device), then soft_rt_next_start now contains a

	 * high value that. So, without this reset, bfqq would be

	 * prevented from being possibly considered as soft_rt for a

	 * very long time.

	/*

	 * Trigger a weight change on the next invocation of

	 * __bfq_entity_update_weight_prio.

	/*

	 * First, if we find a request starting at the end of the last

	 * request, choose it.

	/*

	 * If the exact sector wasn't found, the parent of the NULL leaf

	 * will contain the closest sector (rq_pos_tree sorted by

	 * next_request position).

	/*

	 * We shall notice if some of the queues are cooperating,

	 * e.g., working closely on the same area of the device. In

	 * that case, we can group them together and: 1) don't waste

	 * time idling, and 2) serve the union of their requests in

	 * the best possible order for throughput.

	/*

	 * If there are no process references on the new_bfqq, then it is

	 * unsafe to follow the ->new_bfqq chain as other bfqq's in the chain

	 * may have dropped their last reference (not just their last process

	 * reference).

 Avoid a circular list and skip interim queue merges. */

	/*

	 * If the process for the bfqq has gone away, there is no

	 * sense in merging the queues.

	/*

	 * Merging is just a redirection: the requests of the process

	 * owning one of the two queues are redirected to the other queue.

	 * The latter queue, in its turn, is set as shared if this is the

	 * first time that the requests of some process are redirected to

	 * it.

	 *

	 * We redirect bfqq to new_bfqq and not the opposite, because

	 * we are in the context of the process owning bfqq, thus we

	 * have the io_cq of this process. So we can immediately

	 * configure this io_cq to redirect the requests of the

	 * process to new_bfqq. In contrast, the io_cq of new_bfqq is

	 * not available any more (new_bfqq->bic == NULL).

	 *

	 * Anyway, even in case new_bfqq coincides with the in-service

	 * queue, redirecting requests the in-service queue is the

	 * best option, as we feed the in-service queue with new

	 * requests close to the last request served and, by doing so,

	 * are likely to increase the throughput.

	/*

	 * If either of the queues has already been detected as seeky,

	 * then merging it with the other queue is unlikely to lead to

	 * sequential I/O.

	/*

	 * Interleaved I/O is known to be done by (some) applications

	 * only for reads, so it does not make sense to merge async

	 * queues.

/*

 * Attempt to schedule a merge of bfqq with the currently in-service

 * queue or with a close queue among the scheduled queues.  Return

 * NULL if no merge was scheduled, a pointer to the shared bfq_queue

 * structure otherwise.

 *

 * The OOM queue is not allowed to participate to cooperation: in fact, since

 * the requests temporarily redirected to the OOM queue could be redirected

 * again to dedicated queues at any time, the state needed to correctly

 * handle merging with the OOM queue would be quite complex and expensive

 * to maintain. Besides, in such a critical condition as an out of memory,

 * the benefits of queue merging may be little relevant, or even negligible.

 *

 * WARNING: queue merging may impair fairness among non-weight raised

 * queues, for at least two reasons: 1) the original weight of a

 * merged queue may change during the merged state, 2) even being the

 * weight the same, a merged queue may be bloated with many more

 * requests than the ones produced by its originally-associated

 * process.

	/*

	 * Check delayed stable merge for rotational or non-queueing

	 * devs. For this branch to be executed, bfqq must not be

	 * currently merged with some other queue (i.e., bfqq->bic

	 * must be non null). If we considered also merged queues,

	 * then we should also check whether bfqq has already been

	 * merged with bic->stable_merge_bfqq. But this would be

	 * costly and complicated.

		/*

		 * Make sure also that bfqq is sync, because

		 * bic->stable_merge_bfqq may point to some queue (for

		 * stable merging) also if bic is associated with a

		 * sync queue, but this bfqq is async

 deschedule stable merge, because done or aborted here */

 next function will take at least one ref */

	/*

	 * Do not perform queue merging if the device is non

	 * rotational and performs internal queueing. In fact, such a

	 * device reaches a high speed through internal parallelism

	 * and pipelining. This means that, to reach a high

	 * throughput, it must have many requests enqueued at the same

	 * time. But, in this configuration, the internal scheduling

	 * algorithm of the device does exactly the job of queue

	 * merging: it reorders requests so as to obtain as much as

	 * possible a sequential I/O pattern. As a consequence, with

	 * the workload generated by processes doing interleaved I/O,

	 * the throughput reached by the device is likely to be the

	 * same, with and without queue merging.

	 *

	 * Disabling merging also provides a remarkable benefit in

	 * terms of throughput. Merging tends to make many workloads

	 * artificially more uneven, because of shared queues

	 * remaining non empty for incomparably more time than

	 * non-merged queues. This may accentuate workload

	 * asymmetries. For example, if one of the queues in a set of

	 * merged queues has a higher weight than a normal queue, then

	 * the shared queue may inherit such a high weight and, by

	 * staying almost always active, may force BFQ to perform I/O

	 * plugging most of the time. This evidently makes it harder

	 * for BFQ to let the device reach a high throughput.

	 *

	 * Finally, the likely() macro below is not used because one

	 * of the two branches is more likely than the other, but to

	 * have the code path after the following if() executed as

	 * fast as possible for the case of a non rotational device

	 * with queueing. We want it because this is the fastest kind

	 * of device. On the opposite end, the likely() may lengthen

	 * the execution time of BFQ for the case of slower devices

	 * (rotational or at least without queueing). But in this case

	 * the execution time of BFQ matters very little, if not at

	 * all.

	/*

	 * Prevent bfqq from being merged if it has been created too

	 * long ago. The idea is that true cooperating processes, and

	 * thus their associated bfq_queues, are supposed to be

	 * created shortly after each other. This is the case, e.g.,

	 * for KVM/QEMU and dump I/O threads. Basing on this

	 * assumption, the following filtering greatly reduces the

	 * probability that two non-cooperating processes, which just

	 * happen to do close I/O for some short time interval, have

	 * their queues merged by mistake.

 If there is only one backlogged queue, don't search. */

	/*

	 * Check whether there is a cooperator among currently scheduled

	 * queues. The only thing we need is that the bio/request is not

	 * NULL, as we need it to establish whether a cooperator exists.

	/*

	 * If !bfqq->bic, the queue is already shared or its requests

	 * have already been redirected to a shared queue; both idle window

	 * and weight raising state have already been saved. Do nothing.

		/*

		 * bfqq being merged right after being created: bfqq

		 * would have deserved interactive weight raising, but

		 * did not make it to be set in a weight-raised state,

		 * because of this early merge.	Store directly the

		 * weight-raising state that would have been assigned

		 * to bfqq, so that to avoid that bfqq unjustly fails

		 * to enjoy weight raising if split soon.

	/*

	 * To prevent bfqq's service guarantees from being violated,

	 * bfqq may be left busy, i.e., queued for service, even if

	 * empty (see comments in __bfq_bfqq_expire() for

	 * details). But, if no process will send requests to bfqq any

	 * longer, then there is no point in keeping bfqq queued for

	 * service. In addition, keeping bfqq queued for service, but

	 * with no process ref any longer, may have caused bfqq to be

	 * freed when dequeued from service. But this is assumed to

	 * never happen.

 Save weight raising and idle window of the merged queues */

	/*

	 * The processes associated with bfqq are cooperators of the

	 * processes associated with new_bfqq. So, if bfqq has a

	 * waker, then assume that all these processes will be happy

	 * to let bfqq's waker freely inject I/O when they have no

	 * I/O.

		/*

		 * If the waker queue disappears, then

		 * new_bfqq->waker_bfqq must be reset. So insert

		 * new_bfqq into the woken_list of the waker. See

		 * bfq_check_waker for details.

	/*

	 * If bfqq is weight-raised, then let new_bfqq inherit

	 * weight-raising. To reduce false positives, neglect the case

	 * where bfqq has just been created, but has not yet made it

	 * to be weight-raised (which may happen because EQM may merge

	 * bfqq even before bfq_add_request is executed for the first

	 * time for bfqq). Handling this case would however be very

	 * easy, thanks to the flag just_created.

 bfqq has given its wr to new_bfqq */

	/*

	 * Merge queues (that is, let bic redirect its requests to new_bfqq)

	/*

	 * new_bfqq now belongs to at least two bics (it is a shared queue):

	 * set new_bfqq->bic to NULL. bfqq either:

	 * - does not belong to any bic any more, and hence bfqq->bic must

	 *   be set to NULL, or

	 * - is a queue whose owning bics have already been redirected to a

	 *   different queue, hence the queue is destined to not belong to

	 *   any bic soon and bfqq->bic is already NULL (therefore the next

	 *   assignment causes no harm).

	/*

	 * If the queue is shared, the pid is the pid of one of the associated

	 * processes. Which pid depends on the exact sequence of merge events

	 * the queue underwent. So printing such a pid is useless and confusing

	 * because it reports a random pid between those of the associated

	 * processes.

	 * We mark such a queue with a pid -1, and then print SHARED instead of

	 * a pid in logging messages.

	/*

	 * Disallow merge of a sync bio into an async request.

	/*

	 * Lookup the bfqq that this bio will be queued with. Allow

	 * merge only if rq is queued there.

	/*

	 * We take advantage of this function to perform an early merge

	 * of the queues of possible cooperating processes.

		/*

		 * bic still points to bfqq, then it has not yet been

		 * redirected to some other bfq_queue, and a queue

		 * merge between bfqq and new_bfqq can be safely

		 * fulfilled, i.e., bic can be redirected to new_bfqq

		 * and bfqq can be put.

		/*

		 * If we get here, bio will be queued into new_queue,

		 * so use new_bfqq to decide whether bio and rq can be

		 * merged.

		/*

		 * Change also bqfd->bio_bfqq, as

		 * bfqd->bio_bic now points to new_bfqq, and

		 * this function may be invoked again (and then may

		 * use again bqfd->bio_bfqq).

/*

 * Set the maximum time for the in-service queue to consume its

 * budget. This prevents seeky processes from lowering the throughput.

 * In practice, a time-slice service scheme is used with seeky

 * processes.

			/*

			 * For soft real-time queues, move the start

			 * of the weight-raising period forward by the

			 * time the queue has not received any

			 * service. Otherwise, a relatively long

			 * service delay is likely to cause the

			 * weight-raising period of the queue to end,

			 * because of the short duration of the

			 * weight-raising period of a soft real-time

			 * queue.  It is worth noting that this move

			 * is not so dangerous for the other queues,

			 * because soft real-time queues are not

			 * greedy.

			 *

			 * To not add a further variable, we use the

			 * overloaded field budget_timeout to

			 * determine for how long the queue has not

			 * received service, i.e., how much time has

			 * elapsed since the queue expired. However,

			 * this is a little imprecise, because

			 * budget_timeout is set to jiffies if bfqq

			 * not only expires, but also remains with no

			 * request.

/*

 * Get and set a new queue for service.

	/*

	 * We don't want to idle for seeks, but we do want to allow

	 * fair distribution of slice time for a process doing back-to-back

	 * seeks. So allow a little bit of time for him to submit a new rq.

	/*

	 * Unless the queue is being weight-raised or the scenario is

	 * asymmetric, grant only minimum idle time if the queue

	 * is seeky. A long idling is preserved for a weight-raised

	 * queue, or, more in general, in an asymmetric scenario,

	 * because a long idling is needed for guaranteeing to a queue

	 * its reserved share of the throughput (in particular, it is

	 * needed if the queue has a higher weight than some other

	 * queue).

/*

 * In autotuning mode, max_budget is dynamically recomputed as the

 * amount of sectors transferred in timeout at the estimated peak

 * rate. This enables BFQ to utilize a full timeslice with a full

 * budget, even if the in-service queue is served at peak rate. And

 * this maximises throughput with sequential workloads.

/*

 * Update parameters related to throughput and responsiveness, as a

 * function of the estimated peak rate. See comments on

 * bfq_calc_max_budget(), and on the ref_wr_duration array.

 new rq dispatch now, reset accordingly */

 no new rq dispatched, just reset the number of samples */

 full re-init on next disp. */

	/*

	 * For the convergence property to hold (see comments on

	 * bfq_update_peak_rate()) and for the assessment to be

	 * reliable, a minimum number of samples must be present, and

	 * a minimum amount of time must have elapsed. If not so, do

	 * not compute new rate. Just reset parameters, to get ready

	 * for a new evaluation attempt.

	/*

	 * If a new request completion has occurred after last

	 * dispatch, then, to approximate the rate at which requests

	 * have been served by the device, it is more precise to

	 * extend the observation interval to the last completion.

	/*

	 * Rate computed in sects/usec, and not sects/nsec, for

	 * precision issues.

	/*

	 * Peak rate not updated if:

	 * - the percentage of sequential dispatches is below 3/4 of the

	 *   total, and rate is below the current estimated peak rate

	 * - rate is unreasonably high (> 20M sectors/sec)

	/*

	 * We have to update the peak rate, at last! To this purpose,

	 * we use a low-pass filter. We compute the smoothing constant

	 * of the filter as a function of the 'weight' of the new

	 * measured rate.

	 *

	 * As can be seen in next formulas, we define this weight as a

	 * quantity proportional to how sequential the workload is,

	 * and to how long the observation time interval is.

	 *

	 * The weight runs from 0 to 8. The maximum value of the

	 * weight, 8, yields the minimum value for the smoothing

	 * constant. At this minimum value for the smoothing constant,

	 * the measured rate contributes for half of the next value of

	 * the estimated peak rate.

	 *

	 * So, the first step is to compute the weight as a function

	 * of how sequential the workload is. Note that the weight

	 * cannot reach 9, because bfqd->sequential_samples cannot

	 * become equal to bfqd->peak_rate_samples, which, in its

	 * turn, holds true because bfqd->sequential_samples is not

	 * incremented for the first sample.

	/*

	 * Second step: further refine the weight as a function of the

	 * duration of the observation interval.

	/*

	 * Divisor ranging from 10, for minimum weight, to 2, for

	 * maximum weight.

	/*

	 * Finally, update peak rate:

	 *

	 * peak_rate = peak_rate * (divisor-1) / divisor  +  rate / divisor

 smoothing constant alpha = 1/divisor */

	/*

	 * For a very slow device, bfqd->peak_rate can reach 0 (see

	 * the minimum representable values reported in the comments

	 * on BFQ_RATE_SHIFT). Push to 1 if this happens, to avoid

	 * divisions by zero where bfqd->peak_rate is used as a

	 * divisor.

/*

 * Update the read/write peak rate (the main quantity used for

 * auto-tuning, see update_thr_responsiveness_params()).

 *

 * It is not trivial to estimate the peak rate (correctly): because of

 * the presence of sw and hw queues between the scheduler and the

 * device components that finally serve I/O requests, it is hard to

 * say exactly when a given dispatched request is served inside the

 * device, and for how long. As a consequence, it is hard to know

 * precisely at what rate a given set of requests is actually served

 * by the device.

 *

 * On the opposite end, the dispatch time of any request is trivially

 * available, and, from this piece of information, the "dispatch rate"

 * of requests can be immediately computed. So, the idea in the next

 * function is to use what is known, namely request dispatch times

 * (plus, when useful, request completion times), to estimate what is

 * unknown, namely in-device request service rate.

 *

 * The main issue is that, because of the above facts, the rate at

 * which a certain set of requests is dispatched over a certain time

 * interval can vary greatly with respect to the rate at which the

 * same requests are then served. But, since the size of any

 * intermediate queue is limited, and the service scheme is lossless

 * (no request is silently dropped), the following obvious convergence

 * property holds: the number of requests dispatched MUST become

 * closer and closer to the number of requests completed as the

 * observation interval grows. This is the key property used in

 * the next function to estimate the peak service rate as a function

 * of the observed dispatch rate. The function assumes to be invoked

 * on every request dispatch.

 first dispatch */

 will add one sample */

	/*

	 * Device idle for very long: the observation interval lasting

	 * up to this dispatch cannot be a valid observation interval

	 * for computing a new peak rate (similarly to the late-

	 * completion event in bfq_completed_request()). Go to

	 * update_rate_and_reset to have the following three steps

	 * taken:

	 * - close the observation interval at the last (previous)

	 *   request dispatch or completion

	 * - compute rate, if possible, for that observation interval

	 * - start a new observation interval with this dispatch

 Update sampling information */

 Reset max observed rq size every 32 dispatches */

 Target observation interval not yet reached, go on sampling */

/*

 * Remove request from internal lists.

	/*

	 * For consistency, the next instruction should have been

	 * executed after removing the request from the queue and

	 * dispatching it.  We execute instead this instruction before

	 * bfq_remove_request() (and hence introduce a temporary

	 * inconsistency), for efficiency.  In fact, should this

	 * dispatch occur for a non in-service bfqq, this anticipated

	 * increment prevents two counters related to bfqq->dispatched

	 * from risking to be, first, uselessly decremented, and then

	 * incremented again when the (new) value of bfqq->dispatched

	 * happens to be taken into account.

/*

 * There is a case where idling does not have to be performed for

 * throughput concerns, but to preserve the throughput share of

 * the process associated with bfqq.

 *

 * To introduce this case, we can note that allowing the drive

 * to enqueue more than one request at a time, and hence

 * delegating de facto final scheduling decisions to the

 * drive's internal scheduler, entails loss of control on the

 * actual request service order. In particular, the critical

 * situation is when requests from different processes happen

 * to be present, at the same time, in the internal queue(s)

 * of the drive. In such a situation, the drive, by deciding

 * the service order of the internally-queued requests, does

 * determine also the actual throughput distribution among

 * these processes. But the drive typically has no notion or

 * concern about per-process throughput distribution, and

 * makes its decisions only on a per-request basis. Therefore,

 * the service distribution enforced by the drive's internal

 * scheduler is likely to coincide with the desired throughput

 * distribution only in a completely symmetric, or favorably

 * skewed scenario where:

 * (i-a) each of these processes must get the same throughput as

 *	 the others,

 * (i-b) in case (i-a) does not hold, it holds that the process

 *       associated with bfqq must receive a lower or equal

 *	 throughput than any of the other processes;

 * (ii)  the I/O of each process has the same properties, in

 *       terms of locality (sequential or random), direction

 *       (reads or writes), request sizes, greediness

 *       (from I/O-bound to sporadic), and so on;



 * In fact, in such a scenario, the drive tends to treat the requests

 * of each process in about the same way as the requests of the

 * others, and thus to provide each of these processes with about the

 * same throughput.  This is exactly the desired throughput

 * distribution if (i-a) holds, or, if (i-b) holds instead, this is an

 * even more convenient distribution for (the process associated with)

 * bfqq.

 *

 * In contrast, in any asymmetric or unfavorable scenario, device

 * idling (I/O-dispatch plugging) is certainly needed to guarantee

 * that bfqq receives its assigned fraction of the device throughput

 * (see [1] for details).

 *

 * The problem is that idling may significantly reduce throughput with

 * certain combinations of types of I/O and devices. An important

 * example is sync random I/O on flash storage with command

 * queueing. So, unless bfqq falls in cases where idling also boosts

 * throughput, it is important to check conditions (i-a), i(-b) and

 * (ii) accurately, so as to avoid idling when not strictly needed for

 * service guarantees.

 *

 * Unfortunately, it is extremely difficult to thoroughly check

 * condition (ii). And, in case there are active groups, it becomes

 * very difficult to check conditions (i-a) and (i-b) too.  In fact,

 * if there are active groups, then, for conditions (i-a) or (i-b) to

 * become false 'indirectly', it is enough that an active group

 * contains more active processes or sub-groups than some other active

 * group. More precisely, for conditions (i-a) or (i-b) to become

 * false because of such a group, it is not even necessary that the

 * group is (still) active: it is sufficient that, even if the group

 * has become inactive, some of its descendant processes still have

 * some request already dispatched but still waiting for

 * completion. In fact, requests have still to be guaranteed their

 * share of the throughput even after being dispatched. In this

 * respect, it is easy to show that, if a group frequently becomes

 * inactive while still having in-flight requests, and if, when this

 * happens, the group is not considered in the calculation of whether

 * the scenario is asymmetric, then the group may fail to be

 * guaranteed its fair share of the throughput (basically because

 * idling may not be performed for the descendant processes of the

 * group, but it had to be).  We address this issue with the following

 * bi-modal behavior, implemented in the function

 * bfq_asymmetric_scenario().

 *

 * If there are groups with requests waiting for completion

 * (as commented above, some of these groups may even be

 * already inactive), then the scenario is tagged as

 * asymmetric, conservatively, without checking any of the

 * conditions (i-a), (i-b) or (ii). So the device is idled for bfqq.

 * This behavior matches also the fact that groups are created

 * exactly if controlling I/O is a primary concern (to

 * preserve bandwidth and latency guarantees).

 *

 * On the opposite end, if there are no groups with requests waiting

 * for completion, then only conditions (i-a) and (i-b) are actually

 * controlled, i.e., provided that conditions (i-a) or (i-b) holds,

 * idling is not performed, regardless of whether condition (ii)

 * holds.  In other words, only if conditions (i-a) and (i-b) do not

 * hold, then idling is allowed, and the device tends to be prevented

 * from queueing many requests, possibly of several processes. Since

 * there are no groups with requests waiting for completion, then, to

 * control conditions (i-a) and (i-b) it is enough to check just

 * whether all the queues with requests waiting for completion also

 * have the same weight.

 *

 * Not checking condition (ii) evidently exposes bfqq to the

 * risk of getting less throughput than its fair share.

 * However, for queues with the same weight, a further

 * mechanism, preemption, mitigates or even eliminates this

 * problem. And it does so without consequences on overall

 * throughput. This mechanism and its benefits are explained

 * in the next three paragraphs.

 *

 * Even if a queue, say Q, is expired when it remains idle, Q

 * can still preempt the new in-service queue if the next

 * request of Q arrives soon (see the comments on

 * bfq_bfqq_update_budg_for_activation). If all queues and

 * groups have the same weight, this form of preemption,

 * combined with the hole-recovery heuristic described in the

 * comments on function bfq_bfqq_update_budg_for_activation,

 * are enough to preserve a correct bandwidth distribution in

 * the mid term, even without idling. In fact, even if not

 * idling allows the internal queues of the device to contain

 * many requests, and thus to reorder requests, we can rather

 * safely assume that the internal scheduler still preserves a

 * minimum of mid-term fairness.

 *

 * More precisely, this preemption-based, idleless approach

 * provides fairness in terms of IOPS, and not sectors per

 * second. This can be seen with a simple example. Suppose

 * that there are two queues with the same weight, but that

 * the first queue receives requests of 8 sectors, while the

 * second queue receives requests of 1024 sectors. In

 * addition, suppose that each of the two queues contains at

 * most one request at a time, which implies that each queue

 * always remains idle after it is served. Finally, after

 * remaining idle, each queue receives very quickly a new

 * request. It follows that the two queues are served

 * alternatively, preempting each other if needed. This

 * implies that, although both queues have the same weight,

 * the queue with large requests receives a service that is

 * 1024/8 times as high as the service received by the other

 * queue.

 *

 * The motivation for using preemption instead of idling (for

 * queues with the same weight) is that, by not idling,

 * service guarantees are preserved (completely or at least in

 * part) without minimally sacrificing throughput. And, if

 * there is no active group, then the primary expectation for

 * this device is probably a high throughput.

 *

 * We are now left only with explaining the two sub-conditions in the

 * additional compound condition that is checked below for deciding

 * whether the scenario is asymmetric. To explain the first

 * sub-condition, we need to add that the function

 * bfq_asymmetric_scenario checks the weights of only

 * non-weight-raised queues, for efficiency reasons (see comments on

 * bfq_weights_tree_add()). Then the fact that bfqq is weight-raised

 * is checked explicitly here. More precisely, the compound condition

 * below takes into account also the fact that, even if bfqq is being

 * weight-raised, the scenario is still symmetric if all queues with

 * requests waiting for completion happen to be

 * weight-raised. Actually, we should be even more precise here, and

 * differentiate between interactive weight raising and soft real-time

 * weight raising.

 *

 * The second sub-condition checked in the compound condition is

 * whether there is a fair amount of already in-flight I/O not

 * belonging to bfqq. If so, I/O dispatching is to be plugged, for the

 * following reason. The drive may decide to serve in-flight

 * non-bfqq's I/O requests before bfqq's ones, thereby delaying the

 * arrival of new I/O requests for bfqq (recall that bfqq is sync). If

 * I/O-dispatching is not plugged, then, while bfqq remains empty, a

 * basically uncontrolled amount of I/O from other queues may be

 * dispatched too, possibly causing the service of bfqq's I/O to be

 * delayed even longer in the drive. This problem gets more and more

 * serious as the speed and the queue depth of the drive grow,

 * because, as these two quantities grow, the probability to find no

 * queue busy but many requests in flight grows too. By contrast,

 * plugging I/O dispatching minimizes the delay induced by already

 * in-flight I/O, and enables bfqq to recover the bandwidth it may

 * lose because of this delay.

 *

 * As a side note, it is worth considering that the above

 * device-idling countermeasures may however fail in the following

 * unlucky scenario: if I/O-dispatch plugging is (correctly) disabled

 * in a time period during which all symmetry sub-conditions hold, and

 * therefore the device is allowed to enqueue many requests, but at

 * some later point in time some sub-condition stops to hold, then it

 * may become impossible to make requests be served in the desired

 * order until all the requests already queued in the device have been

 * served. The last sub-condition commented above somewhat mitigates

 * this problem for weight-raised queues.

 *

 * However, as an additional mitigation for this problem, we preserve

 * plugging for a special symmetric case that may suddenly turn into

 * asymmetric: the case where only bfqq is busy. In this case, not

 * expiring bfqq does not cause any harm to any other queues in terms

 * of service guarantees. In contrast, it avoids the following unlucky

 * sequence of events: (1) bfqq is expired, (2) a new queue with a

 * lower weight than bfqq becomes busy (or more queues), (3) the new

 * queue is served until a new request arrives for bfqq, (4) when bfqq

 * is finally served, there are so many requests of the new queue in

 * the drive that the pending requests for bfqq take a lot of time to

 * be served. In particular, event (2) may case even already

 * dispatched requests of bfqq to be delayed, inside the drive. So, to

 * avoid this series of events, the scenario is preventively declared

 * as asymmetric also if bfqq is the only busy queues

 No point in idling for bfqq if it won't get requests any longer */

	/*

	 * If this bfqq is shared between multiple processes, check

	 * to make sure that those processes are still issuing I/Os

	 * within the mean seek distance. If not, it may be time to

	 * break the queues apart again.

	/*

	 * Consider queues with a higher finish virtual time than

	 * bfqq. If idling_needed_for_service_guarantees(bfqq) returns

	 * true, then bfqq's bandwidth would be violated if an

	 * uncontrolled amount of I/O from these queues were

	 * dispatched while bfqq is waiting for its new I/O to

	 * arrive. This is exactly what may happen if this is a forced

	 * expiration caused by a preemption attempt, and if bfqq is

	 * not re-scheduled. To prevent this from happening, re-queue

	 * bfqq if it needs I/O-dispatch plugging, even if it is

	 * empty. By doing so, bfqq is granted to be served before the

	 * above queues (provided that bfqq is of course eligible).

			/*

			 * Overloading budget_timeout field to store

			 * the time at which the queue remains with no

			 * backlog and no outstanding request; used by

			 * the weight-raising mechanism.

		/*

		 * Resort priority tree of potential close cooperators.

		 * See comments on bfq_pos_tree_add_move() for the unlikely().

	/*

	 * All in-service entities must have been properly deactivated

	 * or requeued before executing the next function, which

	 * resets all in-service entities as no more in service. This

	 * may cause bfqq to be freed. If this happens, the next

	 * function returns true.

/**

 * __bfq_bfqq_recalc_budget - try to adapt the budget to the @bfqq behavior.

 * @bfqd: device data.

 * @bfqq: queue to update.

 * @reason: reason for expiration.

 *

 * Handle the feedback on @bfqq budget at queue expiration.

 * See the body for detailed comments.

	else /*

	      * Use a constant, low budget for weight-raised queues,

	      * to help achieve a low latency. Keep it slightly higher

	      * than the minimum possible budget, to cause a little

	      * bit fewer expirations.

		/*

		 * Caveat: in all the following cases we trade latency

		 * for throughput.

			/*

			 * This is the only case where we may reduce

			 * the budget: if there is no request of the

			 * process still waiting for completion, then

			 * we assume (tentatively) that the timer has

			 * expired because the batch of requests of

			 * the process could have been served with a

			 * smaller budget.  Hence, betting that

			 * process will behave in the same way when it

			 * becomes backlogged again, we reduce its

			 * next budget.  As long as we guess right,

			 * this budget cut reduces the latency

			 * experienced by the process.

			 *

			 * However, if there are still outstanding

			 * requests, then the process may have not yet

			 * issued its next request just because it is

			 * still waiting for the completion of some of

			 * the still outstanding ones.  So in this

			 * subcase we do not reduce its budget, on the

			 * contrary we increase it to possibly boost

			 * the throughput, as discussed in the

			 * comments to the BUDGET_TIMEOUT case.

 still outstanding reqs */

			/*

			 * We double the budget here because it gives

			 * the chance to boost the throughput if this

			 * is not a seeky process (and has bumped into

			 * this timeout because of, e.g., ZBR).

			/*

			 * The process still has backlog, and did not

			 * let either the budget timeout or the disk

			 * idling timeout expire. Hence it is not

			 * seeky, has a short thinktime and may be

			 * happy with a higher budget too. So

			 * definitely increase the budget of this good

			 * candidate to boost the disk throughput.

			/*

			 * For queues that expire for this reason, it

			 * is particularly important to keep the

			 * budget close to the actual service they

			 * need. Doing so reduces the timestamp

			 * misalignment problem described in the

			 * comments in the body of

			 * __bfq_activate_entity. In fact, suppose

			 * that a queue systematically expires for

			 * BFQQE_NO_MORE_REQUESTS and presents a

			 * new request in time to enjoy timestamp

			 * back-shifting. The larger the budget of the

			 * queue is with respect to the service the

			 * queue actually requests in each service

			 * slot, the more times the queue can be

			 * reactivated with the same virtual finish

			 * time. It follows that, even if this finish

			 * time is pushed to the system virtual time

			 * to reduce the consequent timestamp

			 * misalignment, the queue unjustly enjoys for

			 * many re-activations a lower finish time

			 * than all newly activated queues.

			 *

			 * The service needed by bfqq is measured

			 * quite precisely by bfqq->entity.service.

			 * Since bfqq does not enjoy device idling,

			 * bfqq->entity.service is equal to the number

			 * of sectors that the process associated with

			 * bfqq requested to read/write before waiting

			 * for request completions, or blocking for

			 * other reasons.

		/*

		 * Async queues get always the maximum possible

		 * budget, as for them we do not care about latency

		 * (in addition, their ability to dispatch is limited

		 * by the charging factor).

	/*

	 * If there is still backlog, then assign a new budget, making

	 * sure that it is large enough for the next request.  Since

	 * the finish time of bfqq must be kept in sync with the

	 * budget, be sure to call __bfq_bfqq_expire() *after* this

	 * update.

	 *

	 * If there is no backlog, then no need to update the budget;

	 * it will be updated on the arrival of a new request.

/*

 * Return true if the process associated with bfqq is "slow". The slow

 * flag is used, in addition to the budget timeout, to reduce the

 * amount of service provided to seeky processes, and thus reduce

 * their chances to lower the throughput. More details in the comments

 * on the function bfq_bfqq_expire().

 *

 * An important observation is in order: as discussed in the comments

 * on the function bfq_update_peak_rate(), with devices with internal

 * queues, it is hard if ever possible to know when and for how long

 * an I/O request is processed by the device (apart from the trivial

 * I/O pattern where a new request is dispatched only after the

 * previous one has been completed). This makes it hard to evaluate

 * the real rate at which the I/O requests of each bfq_queue are

 * served.  In fact, for an I/O scheduler like BFQ, serving a

 * bfq_queue means just dispatching its requests during its service

 * slot (i.e., until the budget of the queue is exhausted, or the

 * queue remains idle, or, finally, a timeout fires). But, during the

 * service slot of a bfq_queue, around 100 ms at most, the device may

 * be even still processing requests of bfq_queues served in previous

 * service slots. On the opposite end, the requests of the in-service

 * bfq_queue may be completed after the service slot of the queue

 * finishes.

 *

 * Anyway, unless more sophisticated solutions are used

 * (where possible), the sum of the sizes of the requests dispatched

 * during the service slot of a bfq_queue is probably the only

 * approximation available for the service received by the bfq_queue

 * during its service slot. And this sum is the quantity used in this

 * function to evaluate the I/O speed of a process.

 if delta too short, use seekyness */

 don't use too short time intervals */

			 /*

			  * give same worst-case guarantees as idling

			  * for seeky

 charge at least one seek */

	/*

	 * Use only long (> 20ms) intervals to filter out excessive

	 * spikes in service rate estimation.

		/*

		 * Caveat for rotational devices: processes doing I/O

		 * in the slower disk zones tend to be slow(er) even

		 * if not seeky. In this respect, the estimated peak

		 * rate is likely to be an average over the disk

		 * surface. Accordingly, to not be too harsh with

		 * unlucky processes, a process is deemed slow only if

		 * its rate has been lower than half of the estimated

		 * peak rate.

/*

 * To be deemed as soft real-time, an application must meet two

 * requirements. First, the application must not require an average

 * bandwidth higher than the approximate bandwidth required to playback or

 * record a compressed high-definition video.

 * The next function is invoked on the completion of the last request of a

 * batch, to compute the next-start time instant, soft_rt_next_start, such

 * that, if the next request of the application does not arrive before

 * soft_rt_next_start, then the above requirement on the bandwidth is met.

 *

 * The second requirement is that the request pattern of the application is

 * isochronous, i.e., that, after issuing a request or a batch of requests,

 * the application stops issuing new requests until all its pending requests

 * have been completed. After that, the application may issue a new batch,

 * and so on.

 * For this reason the next function is invoked to compute

 * soft_rt_next_start only for applications that meet this requirement,

 * whereas soft_rt_next_start is set to infinity for applications that do

 * not.

 *

 * Unfortunately, even a greedy (i.e., I/O-bound) application may

 * happen to meet, occasionally or systematically, both the above

 * bandwidth and isochrony requirements. This may happen at least in

 * the following circumstances. First, if the CPU load is high. The

 * application may stop issuing requests while the CPUs are busy

 * serving other processes, then restart, then stop again for a while,

 * and so on. The other circumstances are related to the storage

 * device: the storage device is highly loaded or reaches a low-enough

 * throughput with the I/O of the application (e.g., because the I/O

 * is random and/or the device is slow). In all these cases, the

 * I/O of the application may be simply slowed down enough to meet

 * the bandwidth and isochrony requirements. To reduce the probability

 * that greedy applications are deemed as soft real-time in these

 * corner cases, a further rule is used in the computation of

 * soft_rt_next_start: the return value of this function is forced to

 * be higher than the maximum between the following two quantities.

 *

 * (a) Current time plus: (1) the maximum time for which the arrival

 *     of a request is waited for when a sync queue becomes idle,

 *     namely bfqd->bfq_slice_idle, and (2) a few extra jiffies. We

 *     postpone for a moment the reason for adding a few extra

 *     jiffies; we get back to it after next item (b).  Lower-bounding

 *     the return value of this function with the current time plus

 *     bfqd->bfq_slice_idle tends to filter out greedy applications,

 *     because the latter issue their next request as soon as possible

 *     after the last one has been completed. In contrast, a soft

 *     real-time application spends some time processing data, after a

 *     batch of its requests has been completed.

 *

 * (b) Current value of bfqq->soft_rt_next_start. As pointed out

 *     above, greedy applications may happen to meet both the

 *     bandwidth and isochrony requirements under heavy CPU or

 *     storage-device load. In more detail, in these scenarios, these

 *     applications happen, only for limited time periods, to do I/O

 *     slowly enough to meet all the requirements described so far,

 *     including the filtering in above item (a). These slow-speed

 *     time intervals are usually interspersed between other time

 *     intervals during which these applications do I/O at a very high

 *     speed. Fortunately, exactly because of the high speed of the

 *     I/O in the high-speed intervals, the values returned by this

 *     function happen to be so high, near the end of any such

 *     high-speed interval, to be likely to fall *after* the end of

 *     the low-speed time interval that follows. These high values are

 *     stored in bfqq->soft_rt_next_start after each invocation of

 *     this function. As a consequence, if the last value of

 *     bfqq->soft_rt_next_start is constantly used to lower-bound the

 *     next value that this function may return, then, from the very

 *     beginning of a low-speed interval, bfqq->soft_rt_next_start is

 *     likely to be constantly kept so high that any I/O request

 *     issued during the low-speed interval is considered as arriving

 *     to soon for the application to be deemed as soft

 *     real-time. Then, in the high-speed interval that follows, the

 *     application will not be deemed as soft real-time, just because

 *     it will do I/O at a high speed. And so on.

 *

 * Getting back to the filtering in item (a), in the following two

 * cases this filtering might be easily passed by a greedy

 * application, if the reference quantity was just

 * bfqd->bfq_slice_idle:

 * 1) HZ is so low that the duration of a jiffy is comparable to or

 *    higher than bfqd->bfq_slice_idle. This happens, e.g., on slow

 *    devices with HZ=100. The time granularity may be so coarse

 *    that the approximation, in jiffies, of bfqd->bfq_slice_idle

 *    is rather lower than the exact value.

 * 2) jiffies, instead of increasing at a constant rate, may stop increasing

 *    for a while, then suddenly 'jump' by several units to recover the lost

 *    increments. This seems to happen, e.g., inside virtual machines.

 * To address this issue, in the filtering in (a) we do not use as a

 * reference time interval just bfqd->bfq_slice_idle, but

 * bfqd->bfq_slice_idle plus a few jiffies. In particular, we add the

 * minimum number of jiffies for which the filter seems to be quite

 * precise also in embedded systems and KVM/QEMU virtual machines.

/**

 * bfq_bfqq_expire - expire a queue.

 * @bfqd: device owning the queue.

 * @bfqq: the queue to expire.

 * @compensate: if true, compensate for the time spent idling.

 * @reason: the reason causing the expiration.

 *

 * If the process associated with bfqq does slow I/O (e.g., because it

 * issues random requests), we charge bfqq with the time it has been

 * in service instead of the service it has received (see

 * bfq_bfqq_charge_time for details on how this goal is achieved). As

 * a consequence, bfqq will typically get higher timestamps upon

 * reactivation, and hence it will be rescheduled as if it had

 * received more service than what it has actually received. In the

 * end, bfqq receives less service in proportion to how slowly its

 * associated process consumes its budgets (and hence how seriously it

 * tends to lower the throughput). In addition, this time-charging

 * strategy guarantees time fairness among slow processes. In

 * contrast, if the process associated with bfqq is not slow, we

 * charge bfqq exactly with the service it has received.

 *

 * Charging time to the first type of queues and the exact service to

 * the other has the effect of using the WF2Q+ policy to schedule the

 * former on a timeslice basis, without violating service domain

 * guarantees among the latter.

	/*

	 * Check whether the process is slow (see bfq_bfqq_is_slow).

	/*

	 * As above explained, charge slow (typically seeky) and

	 * timed-out queues with the time and not the service

	 * received, to favor sequential workloads.

	 *

	 * Processes doing I/O in the slower disk zones will tend to

	 * be slow(er) even if not seeky. Therefore, since the

	 * estimated peak rate is actually an average over the disk

	 * surface, these processes may timeout just for bad luck. To

	 * avoid punishing them, do not charge time to processes that

	 * succeeded in consuming at least 2/3 of their budget. This

	 * allows BFQ to preserve enough elasticity to still perform

	 * bandwidth, and not time, distribution with little unlucky

	 * or quasi-sequential processes.

		/*

		 * If we get here, and there are no outstanding

		 * requests, then the request pattern is isochronous

		 * (see the comments on the function

		 * bfq_bfqq_softrt_next_start()). Therefore we can

		 * compute soft_rt_next_start.

		 *

		 * If, instead, the queue still has outstanding

		 * requests, then we have to wait for the completion

		 * of all the outstanding requests to discover whether

		 * the request pattern is actually isochronous.

			/*

			 * Schedule an update of soft_rt_next_start to when

			 * the task may be discovered to be isochronous.

	/*

	 * bfqq expired, so no total service time needs to be computed

	 * any longer: reset state machine for measuring total service

	 * times.

	/*

	 * Increase, decrease or leave budget unchanged according to

	 * reason.

 bfqq is gone, no more actions on it */

 mark bfqq as waiting a request only if a bic still points to it */

		/*

		 * Not setting service to 0, because, if the next rq

		 * arrives in time, the queue will go on receiving

		 * service with this same budget (as if it never expired)

	/*

	 * Reset the received-service counter for every parent entity.

	 * Differently from what happens with bfqq->entity.service,

	 * the resetting of this counter never needs to be postponed

	 * for parent entities. In fact, in case bfqq may have a

	 * chance to go on being served using the last, partially

	 * consumed budget, bfqq->entity.service needs to be kept,

	 * because if bfqq then actually goes on being served using

	 * the same budget, the last value of bfqq->entity.service is

	 * needed to properly decrement bfqq->entity.budget by the

	 * portion already consumed. In contrast, it is not necessary

	 * to keep entity->service for parent entities too, because

	 * the bubble up of the new value of bfqq->entity.budget will

	 * make sure that the budgets of parent entities are correct,

	 * even in case bfqq and thus parent entities go on receiving

	 * service with the same budget.

/*

 * Budget timeout is not implemented through a dedicated timer, but

 * just checked on request arrivals and completions, as well as on

 * idle timer expirations.

/*

 * If we expire a queue that is actively waiting (i.e., with the

 * device idled) for the arrival of a new request, then we may incur

 * the timestamp misalignment problem described in the body of the

 * function __bfq_activate_entity. Hence we return true only if this

 * condition does not hold, or if the queue is slow enough to deserve

 * only to be kicked off for preserving a high throughput.

 No point in idling for bfqq if it won't get requests any longer */

	/*

	 * The next variable takes into account the cases where idling

	 * boosts the throughput.

	 *

	 * The value of the variable is computed considering, first, that

	 * idling is virtually always beneficial for the throughput if:

	 * (a) the device is not NCQ-capable and rotational, or

	 * (b) regardless of the presence of NCQ, the device is rotational and

	 *     the request pattern for bfqq is I/O-bound and sequential, or

	 * (c) regardless of whether it is rotational, the device is

	 *     not NCQ-capable and the request pattern for bfqq is

	 *     I/O-bound and sequential.

	 *

	 * Secondly, and in contrast to the above item (b), idling an

	 * NCQ-capable flash-based device would not boost the

	 * throughput even with sequential I/O; rather it would lower

	 * the throughput in proportion to how fast the device

	 * is. Accordingly, the next variable is true if any of the

	 * above conditions (a), (b) or (c) is true, and, in

	 * particular, happens to be false if bfqd is an NCQ-capable

	 * flash-based device.

	/*

	 * The return value of this function is equal to that of

	 * idling_boosts_thr, unless a special case holds. In this

	 * special case, described below, idling may cause problems to

	 * weight-raised queues.

	 *

	 * When the request pool is saturated (e.g., in the presence

	 * of write hogs), if the processes associated with

	 * non-weight-raised queues ask for requests at a lower rate,

	 * then processes associated with weight-raised queues have a

	 * higher probability to get a request from the pool

	 * immediately (or at least soon) when they need one. Thus

	 * they have a higher probability to actually get a fraction

	 * of the device throughput proportional to their high

	 * weight. This is especially true with NCQ-capable drives,

	 * which enqueue several requests in advance, and further

	 * reorder internally-queued requests.

	 *

	 * For this reason, we force to false the return value if

	 * there are weight-raised busy queues. In this case, and if

	 * bfqq is not weight-raised, this guarantees that the device

	 * is not idled for bfqq (if, instead, bfqq is weight-raised,

	 * then idling will be guaranteed by another variable, see

	 * below). Combined with the timestamping rules of BFQ (see

	 * [1] for details), this behavior causes bfqq, and hence any

	 * sync non-weight-raised queue, to get a lower number of

	 * requests served, and thus to ask for a lower number of

	 * requests from the request pool, before the busy

	 * weight-raised queues get served again. This often mitigates

	 * starvation problems in the presence of heavy write

	 * workloads and NCQ, thereby guaranteeing a higher

	 * application and system responsiveness in these hostile

	 * scenarios.

/*

 * For a queue that becomes empty, device idling is allowed only if

 * this function returns true for that queue. As a consequence, since

 * device idling plays a critical role for both throughput boosting

 * and service guarantees, the return value of this function plays a

 * critical role as well.

 *

 * In a nutshell, this function returns true only if idling is

 * beneficial for throughput or, even if detrimental for throughput,

 * idling is however necessary to preserve service guarantees (low

 * latency, desired throughput distribution, ...). In particular, on

 * NCQ-capable devices, this function tries to return false, so as to

 * help keep the drives' internal queues full, whenever this helps the

 * device boost the throughput without causing any service-guarantee

 * issue.

 *

 * Most of the issues taken into account to get the return value of

 * this function are not trivial. We discuss these issues in the two

 * functions providing the main pieces of information needed by this

 * function.

 No point in idling for bfqq if it won't get requests any longer */

	/*

	 * Idling is performed only if slice_idle > 0. In addition, we

	 * do not idle if

	 * (a) bfqq is async

	 * (b) bfqq is in the idle io prio class: in this case we do

	 * not idle because we want to minimize the bandwidth that

	 * queues in this class can steal to higher-priority queues

	/*

	 * We have now the two components we need to compute the

	 * return value of the function, which is true only if idling

	 * either boosts the throughput (without issues), or is

	 * necessary to preserve service guarantees.

/*

 * If the in-service queue is empty but the function bfq_better_to_idle

 * returns true, then:

 * 1) the queue must remain in service and cannot be expired, and

 * 2) the device must be idled to wait for the possible arrival of a new

 *    request for the queue.

 * See the comments on the function bfq_better_to_idle for the reasons

 * why performing device idling is the best choice to boost the throughput

 * and preserve service guarantees when bfq_better_to_idle itself

 * returns true.

/*

 * This function chooses the queue from which to pick the next extra

 * I/O request to inject, if it finds a compatible queue. See the

 * comments on bfq_update_inject_limit() for details on the injection

 * mechanism, and for the definitions of the quantities mentioned

 * below.

	/*

	 * If

	 * - bfqq is not weight-raised and therefore does not carry

	 *   time-critical I/O,

	 * or

	 * - regardless of whether bfqq is weight-raised, bfqq has

	 *   however a long think time, during which it can absorb the

	 *   effect of an appropriate number of extra I/O requests

	 *   from other queues (see bfq_update_inject_limit for

	 *   details on the computation of this number);

	 * then injection can be performed without restrictions.

	/*

	 * If

	 * - the baseline total service time could not be sampled yet,

	 *   so the inject limit happens to be still 0, and

	 * - a lot of time has elapsed since the plugging of I/O

	 *   dispatching started, so drive speed is being wasted

	 *   significantly;

	 * then temporarily raise inject limit to one request.

	/*

	 * Linear search of the source queue for injection; but, with

	 * a high probability, very few steps are needed to find a

	 * candidate queue, i.e., a queue with enough budget left for

	 * its next request. In fact:

	 * - BFQ dynamically updates the budget of every queue so as

	 *   to accommodate the expected backlog of the queue;

	 * - if a queue gets all its requests dispatched as injected

	 *   service, then the queue is removed from the active list

	 *   (and re-added only if it gets new requests, but then it

	 *   is assigned again enough budget for its new backlog).

			/*

			 * Allow for only one large in-flight request

			 * on non-rotational devices, for the

			 * following reason. On non-rotationl drives,

			 * large requests take much longer than

			 * smaller requests to be served. In addition,

			 * the drive prefers to serve large requests

			 * w.r.t. to small ones, if it can choose. So,

			 * having more than one large requests queued

			 * in the drive may easily make the next first

			 * request of the in-service queue wait for so

			 * long to break bfqq's service guarantees. On

			 * the bright side, large requests let the

			 * drive reach a very high throughput, even if

			 * there is only one in-flight large request

			 * at a time.

/*

 * Select a queue for service.  If we have a current queue in service,

 * check whether to continue servicing it, or retrieve and set a new one.

	/*

	 * Do not expire bfqq for budget timeout if bfqq may be about

	 * to enjoy device idling. The reason why, in this case, we

	 * prevent bfqq from expiring is the same as in the comments

	 * on the case where bfq_bfqq_must_idle() returns true, in

	 * bfq_completed_request().

	/*

	 * This loop is rarely executed more than once. Even when it

	 * happens, it is much more convenient to re-execute this loop

	 * than to return NULL and trigger a new dispatch to get a

	 * request served.

	/*

	 * If bfqq has requests queued and it has enough budget left to

	 * serve them, keep the queue, otherwise expire it.

			/*

			 * Expire the queue for budget exhaustion,

			 * which makes sure that the next budget is

			 * enough to serve the next request, even if

			 * it comes from the fifo expired path.

			/*

			 * The idle timer may be pending because we may

			 * not disable disk idling even when a new request

			 * arrives.

				/*

				 * If we get here: 1) at least a new request

				 * has arrived but we have not disabled the

				 * timer because the request was too small,

				 * 2) then the block layer has unplugged

				 * the device, causing the dispatch to be

				 * invoked.

				 *

				 * Since the device is unplugged, now the

				 * requests are probably large enough to

				 * provide a reasonable throughput.

				 * So we disable idling.

	/*

	 * No requests pending. However, if the in-service queue is idling

	 * for a new request, or has requests waiting for a completion and

	 * may idle after their completion, then keep it anyway.

	 *

	 * Yet, inject service from other queues if it boosts

	 * throughput and is possible.

		/*

		 * The next four mutually-exclusive ifs decide

		 * whether to try injection, and choose the queue to

		 * pick an I/O request from.

		 *

		 * The first if checks whether the process associated

		 * with bfqq has also async I/O pending. If so, it

		 * injects such I/O unconditionally. Injecting async

		 * I/O from the same process can cause no harm to the

		 * process. On the contrary, it can only increase

		 * bandwidth and reduce latency for the process.

		 *

		 * The second if checks whether there happens to be a

		 * non-empty waker queue for bfqq, i.e., a queue whose

		 * I/O needs to be completed for bfqq to receive new

		 * I/O. This happens, e.g., if bfqq is associated with

		 * a process that does some sync. A sync generates

		 * extra blocking I/O, which must be completed before

		 * the process associated with bfqq can go on with its

		 * I/O. If the I/O of the waker queue is not served,

		 * then bfqq remains empty, and no I/O is dispatched,

		 * until the idle timeout fires for bfqq. This is

		 * likely to result in lower bandwidth and higher

		 * latencies for bfqq, and in a severe loss of total

		 * throughput. The best action to take is therefore to

		 * serve the waker queue as soon as possible. So do it

		 * (without relying on the third alternative below for

		 * eventually serving waker_bfqq's I/O; see the last

		 * paragraph for further details). This systematic

		 * injection of I/O from the waker queue does not

		 * cause any delay to bfqq's I/O. On the contrary,

		 * next bfqq's I/O is brought forward dramatically,

		 * for it is not blocked for milliseconds.

		 *

		 * The third if checks whether there is a queue woken

		 * by bfqq, and currently with pending I/O. Such a

		 * woken queue does not steal bandwidth from bfqq,

		 * because it remains soon without I/O if bfqq is not

		 * served. So there is virtually no risk of loss of

		 * bandwidth for bfqq if this woken queue has I/O

		 * dispatched while bfqq is waiting for new I/O.

		 *

		 * The fourth if checks whether bfqq is a queue for

		 * which it is better to avoid injection. It is so if

		 * bfqq delivers more throughput when served without

		 * any further I/O from other queues in the middle, or

		 * if the service times of bfqq's I/O requests both

		 * count more than overall throughput, and may be

		 * easily increased by injection (this happens if bfqq

		 * has a short think time). If none of these

		 * conditions holds, then a candidate queue for

		 * injection is looked for through

		 * bfq_choose_bfqq_for_injection(). Note that the

		 * latter may return NULL (for example if the inject

		 * limit for bfqq is currently 0).

		 *

		 * NOTE: motivation for the second alternative

		 *

		 * Thanks to the way the inject limit is updated in

		 * bfq_update_has_short_ttime(), it is rather likely

		 * that, if I/O is being plugged for bfqq and the

		 * waker queue has pending I/O requests that are

		 * blocking bfqq's I/O, then the fourth alternative

		 * above lets the waker queue get served before the

		 * I/O-plugging timeout fires. So one may deem the

		 * second alternative superfluous. It is not, because

		 * the fourth alternative may be way less effective in

		 * case of a synchronization. For two main

		 * reasons. First, throughput may be low because the

		 * inject limit may be too low to guarantee the same

		 * amount of injected I/O, from the waker queue or

		 * other queues, that the second alternative

		 * guarantees (the second alternative unconditionally

		 * injects a pending I/O request of the waker queue

		 * for each bfq_dispatch_request()). Second, with the

		 * fourth alternative, the duration of the plugging,

		 * i.e., the time before bfqq finally receives new I/O,

		 * may not be minimized, because the waker queue may

		 * happen to be served only after other queues.

 queue is being weight-raised */

		/*

		 * If the queue was activated in a burst, or too much

		 * time has elapsed from the beginning of this

		 * weight-raising period, then end weight raising.

				/*

				 * Either in interactive weight

				 * raising, or in soft_rt weight

				 * raising with the

				 * interactive-weight-raising period

				 * elapsed (so no switch back to

				 * interactive weight raising).

			} else { /*

				  * soft_rt finishing while still in

				  * interactive period, switch back to

				  * interactive weight raising

 see comments on max_service_from_wr */

	/*

	 * To improve latency (for this or other queues), immediately

	 * update weight both if it must be raised and if it must be

	 * lowered. Since, entity may be on some active tree here, and

	 * might have a pending change of its ioprio class, invoke

	 * next function with the last parameter unset (see the

	 * comments on the function).

/*

 * Dispatch next request from bfqq.

	/*

	 * If weight raising has to terminate for bfqq, then next

	 * function causes an immediate update of bfqq's weight,

	 * without waiting for next activation. As a consequence, on

	 * expiration, bfqq will be timestamped as if has never been

	 * weight-raised during this service slot, even if it has

	 * received part or even most of the service as a

	 * weight-raised queue. This inflates bfqq's timestamps, which

	 * is beneficial, as bfqq is then more willing to leave the

	 * device immediately to possible other weight-raised queues.

	/*

	 * Expire bfqq, pretending that its budget expired, if bfqq

	 * belongs to CLASS_IDLE and other queues are waiting for

	 * service.

	/*

	 * Avoiding lock: a race on bfqd->busy_queues should cause at

	 * most a call to dispatch for nothing

			/*

			 * Increment counters here, because this

			 * dispatch does not follow the standard

			 * dispatch flow (where counters are

			 * incremented)

		/*

		 * We exploit the bfq_finish_requeue_request hook to

		 * decrement rq_in_driver, but

		 * bfq_finish_requeue_request will not be invoked on

		 * this request. So, to avoid unbalance, just start

		 * this request, without incrementing rq_in_driver. As

		 * a negative consequence, rq_in_driver is deceptively

		 * lower than it should be while this request is in

		 * service. This may cause bfq_schedule_dispatch to be

		 * invoked uselessly.

		 *

		 * As for implementing an exact solution, the

		 * bfq_finish_requeue_request hook, if defined, is

		 * probably invoked also on this request. So, by

		 * exploiting this hook, we could 1) increment

		 * rq_in_driver here, and 2) decrement it in

		 * bfq_finish_requeue_request. Such a solution would

		 * let the value of the counter be always accurate,

		 * but it would entail using an extra interface

		 * function. This cost seems higher than the benefit,

		 * being the frequency of non-elevator-private

		 * requests very low.

	/*

	 * Force device to serve one request at a time if

	 * strict_guarantees is true. Forcing this service scheme is

	 * currently the ONLY way to guarantee that the request

	 * service order enforced by the scheduler is respected by a

	 * queueing device. Otherwise the device is free even to make

	 * some unlucky request wait for as long as the device

	 * wishes.

	 *

	 * Of course, serving one request at a time may cause loss of

	 * throughput.

	/*

	 * rq and bfqq are guaranteed to exist until this function

	 * ends, for the following reasons. First, rq can be

	 * dispatched to the device, and then can be completed and

	 * freed, only after this function ends. Second, rq cannot be

	 * merged (and thus freed because of a merge) any longer,

	 * because it has already started. Thus rq cannot be freed

	 * before this function ends, and, since rq has a reference to

	 * bfqq, the same guarantee holds for bfqq too.

	 *

	 * In addition, the following queue lock guarantees that

	 * bfqq_group(bfqq) exists as well.

		/*

		 * Since the idle timer has been disabled,

		 * in_serv_queue contained some request when

		 * __bfq_dispatch_request was invoked above, which

		 * implies that rq was picked exactly from

		 * in_serv_queue. Thus in_serv_queue == bfqq, and is

		 * therefore guaranteed to exist because of the above

		 * arguments.

 CONFIG_BFQ_CGROUP_DEBUG */

/*

 * Task holds one reference to the queue, dropped when task exits.  Each rq

 * in-flight on this queue also holds a reference, dropped when rq is freed.

 *

 * Scheduler lock must be held here. Recall not to use bfqq after calling

 * this function on it.

		/*

		 * Decrement also burst size after the removal, if the

		 * process associated with bfqq is exiting, and thus

		 * does not contribute to the burst any longer. This

		 * decrement helps filter out false positives of large

		 * bursts, when some short-lived process (often due to

		 * the execution of commands by some service) happens

		 * to start and exit while a complex application is

		 * starting, and thus spawning several processes that

		 * do I/O (and that *must not* be treated as a large

		 * burst, see comments on bfq_handle_burst).

		 *

		 * In particular, the decrement is performed only if:

		 * 1) bfqq is not a merged queue, because, if it is,

		 * then this free of bfqq is not triggered by the exit

		 * of the process bfqq is associated with, but exactly

		 * by the fact that bfqq has just been merged.

		 * 2) burst_size is greater than 0, to handle

		 * unbalanced decrements. Unbalanced decrements may

		 * happen in te following case: bfqq is inserted into

		 * the current burst list--without incrementing

		 * bust_size--because of a split, but the current

		 * burst list is not the burst list bfqq belonged to

		 * (see comments on the case of a split in

		 * bfq_set_request).

	/*

	 * bfqq does not exist any longer, so it cannot be woken by

	 * any other queue, and cannot wake any other queue. Then bfqq

	 * must be removed from the woken list of its possible waker

	 * queue, and all queues in the woken list of bfqq must stop

	 * having a waker queue. Strictly speaking, these updates

	 * should be performed when bfqq remains with no I/O source

	 * attached to it, which happens before bfqq gets freed. In

	 * particular, this happens when the last process associated

	 * with bfqq exits or gets associated with a different

	 * queue. However, both events lead to bfqq being freed soon,

	 * and dangling references would come out only after bfqq gets

	 * freed. So these updates are done here, as a simple and safe

	 * way to handle all cases.

 remove bfqq from woken list */

 reset waker for all queues in woken list */

	/*

	 * If this queue was scheduled to merge with another queue, be

	 * sure to drop the reference taken on that queue (and others in

	 * the merge chain). See bfq_setup_merge and bfq_merge_bfqqs.

 NULL if scheduler already exited */

		/*

		 * bfqd is NULL if scheduler already exited, and in

		 * that case this is the last time bfqq is accessed.

/*

 * Update the entity prio values; note that the new values will not

 * be used until the next (re)activation.

		/*

		 * No prio set, inherit CPU scheduling settings.

	/*

	 * This condition may trigger on a newly created bic, be sure to

	 * drop the lock before returning.

		/*

		 * No need to mark as has_short_ttime if in

		 * idle_class, because no device idling is performed

		 * for queues in idle class

 tentatively mark as has_short_ttime */

 set end request to minus infinity from now */

 Tentative initial value to trade off between thr and lat */

	/*

	 * To not forget the possibly high bandwidth consumed by a

	 * process/queue in the recent past,

	 * bfq_bfqq_softrt_next_start() returns a value at least equal

	 * to the current value of bfqq->soft_rt_next_start (see

	 * comments on bfq_bfqq_softrt_next_start).  Set

	 * soft_rt_next_start to now, to mean that bfqq has consumed

	 * no bandwidth so far.

 first request is almost certainly seeky */

	/*

	 * Reusing merge functions. This implies that

	 * bfqq->bic must be set too, for

	 * bfq_merge_bfqqs to correctly save bfqq's

	 * state before killing it.

/*

 * Many throughput-sensitive workloads are made of several parallel

 * I/O flows, with all flows generated by the same application, or

 * more generically by the same task (e.g., system boot). The most

 * counterproductive action with these workloads is plugging I/O

 * dispatch when one of the bfq_queues associated with these flows

 * remains temporarily empty.

 *

 * To avoid this plugging, BFQ has been using a burst-handling

 * mechanism for years now. This mechanism has proven effective for

 * throughput, and not detrimental for service guarantees. The

 * following function pushes this mechanism a little bit further,

 * basing on the following two facts.

 *

 * First, all the I/O flows of a the same application or task

 * contribute to the execution/completion of that common application

 * or task. So the performance figures that matter are total

 * throughput of the flows and task-wide I/O latency.  In particular,

 * these flows do not need to be protected from each other, in terms

 * of individual bandwidth or latency.

 *

 * Second, the above fact holds regardless of the number of flows.

 *

 * Putting these two facts together, this commits merges stably the

 * bfq_queues associated with these I/O flows, i.e., with the

 * processes that generate these IO/ flows, regardless of how many the

 * involved processes are.

 *

 * To decide whether a set of bfq_queues is actually associated with

 * the I/O flows of a common application or task, and to merge these

 * queues stably, this function operates as follows: given a bfq_queue,

 * say Q2, currently being created, and the last bfq_queue, say Q1,

 * created before Q2, Q2 is merged stably with Q1 if

 * - very little time has elapsed since when Q1 was created

 * - Q2 has the same ioprio as Q1

 * - Q2 belongs to the same group as Q1

 *

 * Merging bfq_queues also reduces scheduling overhead. A fio test

 * with ten random readers on /dev/nullb shows a throughput boost of

 * 40%, with a quadcore. Since BFQ's execution time amounts to ~50% of

 * the total per-request processing time, the above throughput boost

 * implies that BFQ's overhead is reduced by more than 50%.

 *

 * This new mechanism most certainly obsoletes the current

 * burst-handling heuristics. We keep those heuristics for the moment.

	/*

	 * If last_bfqq_created has not been set yet, then init it. If

	 * it has been set already, but too long ago, then move it

	 * forward to bfqq. Finally, move also if bfqq belongs to a

	 * different group than last_bfqq_created, or if bfqq has a

	 * different ioprio or ioprio_class. If none of these

	 * conditions holds true, then try an early stable merge or

	 * schedule a delayed stable merge.

	 *

	 * A delayed merge is scheduled (instead of performing an

	 * early merge), in case bfqq might soon prove to be more

	 * throughput-beneficial if not merged. Currently this is

	 * possible only if bfqd is rotational with no queueing. For

	 * such a drive, not merging bfqq is better for throughput if

	 * bfqq happens to contain sequential I/O. So, we wait a

	 * little bit for enough I/O to flow through bfqq. After that,

	 * if such an I/O is sequential, then the merge is

	 * canceled. Otherwise the merge is finally performed.

			/*

			 * With this type of drive, leaving

			 * bfqq alone may provide no

			 * throughput benefits compared with

			 * merging bfqq. So merge bfqq now.

 schedule tentative stable merge */

			/*

			 * get reference on last_bfqq_created,

			 * to prevent it from being freed,

			 * until we decide whether to merge

			/*

			 * need to keep track of stable refs, to

			 * compute process refs correctly

			/*

			 * Record the bfqq to merge to.

	/*

	 * Pin the queue now that it's allocated, scheduler exit will

	 * prune it.

		bfqq->ref++; /*

			      * Extra group reference, w.r.t. sync

			      * queue. This extra reference is removed

			      * only if bfqq->bfqg disappears, to

			      * guarantee that this queue is not freed

			      * until its group goes away.

 get a process reference to this queue */

	/*

	 * We are really interested in how long it takes for the queue to

	 * become busy when there is no outstanding IO for this queue. So

	 * ignore cases when the bfq queue has already IO queued.

			/*

			 * In soft_rt weight raising with the

			 * interactive-weight-raising period

			 * elapsed (so no switch back to

			 * interactive weight raising).

		} else { /*

			  * stopping soft_rt weight raising

			  * while still in interactive period,

			  * switch back to interactive weight

			  * raising

	/*

	 * No need to update has_short_ttime if bfqq is async or in

	 * idle io prio class, or if bfq_slice_idle is zero, because

	 * no device idling is performed for bfqq in this case.

 Idle window just restored, statistics are meaningless. */

	/* Think time is infinite if no process is linked to

	 * bfqq. Otherwise check average think time to decide whether

	 * to mark as has_short_ttime. To this goal, compare average

	 * think time with half the I/O-plugging timeout.

	/*

	 * Until the base value for the total service time gets

	 * finally computed for bfqq, the inject limit does depend on

	 * the think-time state (short|long). In particular, the limit

	 * is 0 or 1 if the think time is deemed, respectively, as

	 * short or long (details in the comments in

	 * bfq_update_inject_limit()). Accordingly, the next

	 * instructions reset the inject limit if the think-time state

	 * has changed and the above base value is still to be

	 * computed.

	 *

	 * However, the reset is performed only if more than 100 ms

	 * have elapsed since the last update of the inject limit, or

	 * (inclusive) if the change is from short to long think

	 * time. The reason for this waiting is as follows.

	 *

	 * bfqq may have a long think time because of a

	 * synchronization with some other queue, i.e., because the

	 * I/O of some other queue may need to be completed for bfqq

	 * to receive new I/O. Details in the comments on the choice

	 * of the queue for injection in bfq_select_queue().

	 *

	 * As stressed in those comments, if such a synchronization is

	 * actually in place, then, without injection on bfqq, the

	 * blocking I/O cannot happen to served while bfqq is in

	 * service. As a consequence, if bfqq is granted

	 * I/O-dispatch-plugging, then bfqq remains empty, and no I/O

	 * is dispatched, until the idle timeout fires. This is likely

	 * to result in lower bandwidth and higher latencies for bfqq,

	 * and in a severe loss of total throughput.

	 *

	 * On the opposite end, a non-zero inject limit may allow the

	 * I/O that blocks bfqq to be executed soon, and therefore

	 * bfqq to receive new I/O soon.

	 *

	 * But, if the blocking gets actually eliminated, then the

	 * next think-time sample for bfqq may be very low. This in

	 * turn may cause bfqq's think time to be deemed

	 * short. Without the 100 ms barrier, this new state change

	 * would cause the body of the next if to be executed

	 * immediately. But this would set to 0 the inject

	 * limit. Without injection, the blocking I/O would cause the

	 * think time of bfqq to become long again, and therefore the

	 * inject limit to be raised again, and so on. The only effect

	 * of such a steady oscillation between the two think-time

	 * states would be to prevent effective injection on bfqq.

	 *

	 * In contrast, if the inject limit is not reset during such a

	 * long time interval as 100 ms, then the number of short

	 * think time samples can grow significantly before the reset

	 * is performed. As a consequence, the think time state can

	 * become stable before the reset. Therefore there will be no

	 * state change when the 100 ms elapse, and no reset of the

	 * inject limit. The inject limit remains steadily equal to 1

	 * both during and after the 100 ms. So injection can be

	 * performed at all times, and throughput gets boosted.

	 *

	 * An inject limit equal to 1 is however in conflict, in

	 * general, with the fact that the think time of bfqq is

	 * short, because injection may be likely to delay bfqq's I/O

	 * (as explained in the comments in

	 * bfq_update_inject_limit()). But this does not happen in

	 * this special case, because bfqq's low think time is due to

	 * an effective handling of a synchronization, through

	 * injection. In this special case, bfqq's I/O does not get

	 * delayed by injection; on the contrary, bfqq's I/O is

	 * brought forward, because it is not blocked for

	 * milliseconds.

	 *

	 * In addition, serving the blocking I/O much sooner, and much

	 * more frequently than once per I/O-plugging timeout, makes

	 * it much quicker to detect a waker queue (the concept of

	 * waker queue is defined in the comments in

	 * bfq_add_request()). This makes it possible to start sooner

	 * to boost throughput more effectively, by injecting the I/O

	 * of the waker queue unconditionally on every

	 * bfq_dispatch_request().

	 *

	 * One last, important benefit of not resetting the inject

	 * limit before 100 ms is that, during this time interval, the

	 * base value for the total service time is likely to get

	 * finally computed for bfqq, freeing the inject limit from

	 * its relation with the think time.

/*

 * Called when a new fs request (rq) is added to bfqq.  Check if there's

 * something we should do about it.

		/*

		 * There is just this request queued: if

		 * - the request is small, and

		 * - we are idling to boost throughput, and

		 * - the queue is not to be expired,

		 * then just exit.

		 *

		 * In this way, if the device is being idled to wait

		 * for a new request from the in-service queue, we

		 * avoid unplugging the device and committing the

		 * device to serve just a small request. In contrast

		 * we wait for the block layer to decide when to

		 * unplug the device: hopefully, new requests will be

		 * merged to this one quickly, then the device will be

		 * unplugged and larger requests will be dispatched.

		/*

		 * A large enough request arrived, or idling is being

		 * performed to preserve service guarantees, or

		 * finally the queue is to be expired: in all these

		 * cases disk idling is to be stopped, so clear

		 * wait_request flag and reset timer.

		/*

		 * The queue is not empty, because a new request just

		 * arrived. Hence we can safely expire the queue, in

		 * case of budget timeout, without risking that the

		 * timestamps of the queue are not updated correctly.

		 * See [1] for more details.

 returns true if it causes the idle timer to be disabled */

		/*

		 * Release the request's reference to the old bfqq

		 * and make sure one is taken to the shared queue.

		/*

		 * If the bic associated with the process

		 * issuing this request still points to bfqq

		 * (and thus has not been already redirected

		 * to new_bfqq or even some other bfq_queue),

		 * then complete the merge and redirect it to

		 * new_bfqq.

		/*

		 * rq is about to be enqueued into new_bfqq,

		 * release rq reference on bfqq

	/*

	 * bfqq still exists, because it can disappear only after

	 * either it is merged with another queue, or the process it

	 * is associated with exits. But both actions must be taken by

	 * the same process currently executing this flow of

	 * instructions.

	 *

	 * In addition, the following queue lock guarantees that

	 * bfqq_group(bfqq) exists as well.

 CONFIG_BFQ_CGROUP_DEBUG */

	/*

	 * Reqs with at_head or passthrough flags set are to be put

	 * directly into dispatch list. Additional case for putting rq

	 * directly into the dispatch queue: the only active

	 * bfq_queues are bfqq and either its waker bfq_queue or one

	 * of its woken bfq_queues. The rationale behind this

	 * additional condition is as follows:

	 * - consider a bfq_queue, say Q1, detected as a waker of

	 *   another bfq_queue, say Q2

	 * - by definition of a waker, Q1 blocks the I/O of Q2, i.e.,

	 *   some I/O of Q1 needs to be completed for new I/O of Q2

	 *   to arrive.  A notable example of waker is journald

	 * - so, Q1 and Q2 are in any respect the queues of two

	 *   cooperating processes (or of two cooperating sets of

	 *   processes): the goal of Q1's I/O is doing what needs to

	 *   be done so that new Q2's I/O can finally be

	 *   issued. Therefore, if the service of Q1's I/O is delayed,

	 *   then Q2's I/O is delayed too.  Conversely, if Q2's I/O is

	 *   delayed, the goal of Q1's I/O is hindered.

	 * - as a consequence, if some I/O of Q1/Q2 arrives while

	 *   Q2/Q1 is the only queue in service, there is absolutely

	 *   no point in delaying the service of such an I/O. The

	 *   only possible result is a throughput loss

	 * - so, when the above condition holds, the best option is to

	 *   have the new I/O dispatched as soon as possible

	 * - the most effective and efficient way to attain the above

	 *   goal is to put the new I/O directly in the dispatch

	 *   list

	 * - as an additional restriction, Q1 and Q2 must be the only

	 *   busy queues for this commit to put the I/O of Q2/Q1 in

	 *   the dispatch list.  This is necessary, because, if also

	 *   other queues are waiting for service, then putting new

	 *   I/O directly in the dispatch list may evidently cause a

	 *   violation of service guarantees for the other queues

		/*

		 * Update bfqq, because, if a queue merge has occurred

		 * in __bfq_insert_request, then rq has been

		 * redirected into a new queue.

	/*

	 * Cache cmd_flags before releasing scheduler lock, because rq

	 * may disappear afterwards (for example, because of a request

	 * merge).

	/*

	 * This sample is valid if the number of outstanding requests

	 * is large enough to allow a queueing behavior.  Note that the

	 * sum is not exact, as it's not taking into account deactivated

	 * requests.

	/*

	 * If active queue hasn't enough requests and can idle, bfq might not

	 * dispatch sufficient requests to hardware. Don't zero hw_tag in this

	 * case

		/*

		 * Set budget_timeout (which we overload to store the

		 * time at which the queue remains with no backlog and

		 * no outstanding request; used by the weight-raising

		 * mechanism).

	/*

	 * Using us instead of ns, to get a reasonable precision in

	 * computing rate in next check.

	/*

	 * If the request took rather long to complete, and, according

	 * to the maximum request size recorded, this completion latency

	 * implies that the request was certainly served at a very low

	 * rate (less than 1M sectors/sec), then the whole observation

	 * interval that lasts up to this time instant cannot be a

	 * valid time interval for computing a new peak rate.  Invoke

	 * bfq_update_rate_reset to have the following three steps

	 * taken:

	 * - close the observation interval at the last (previous)

	 *   request dispatch or completion

	 * - compute rate, if possible, for that observation interval

	 * - reset to zero samples, which will trigger a proper

	 *   re-initialization of the observation interval on next

	 *   dispatch

	/*

	 * Shared queues are likely to receive I/O at a high

	 * rate. This may deceptively let them be considered as wakers

	 * of other queues. But a false waker will unjustly steal

	 * bandwidth to its supposedly woken queue. So considering

	 * also shared queues in the waking mechanism may cause more

	 * control troubles than throughput benefits. Then reset

	 * last_completed_rq_bfqq if bfqq is a shared queue.

	/*

	 * If we are waiting to discover whether the request pattern

	 * of the task associated with the queue is actually

	 * isochronous, and both requisites for this condition to hold

	 * are now satisfied, then compute soft_rt_next_start (see the

	 * comments on the function bfq_bfqq_softrt_next_start()). We

	 * do not compute soft_rt_next_start if bfqq is in interactive

	 * weight raising (see the comments in bfq_bfqq_expire() for

	 * an explanation). We schedule this delayed update when bfqq

	 * expires, if it still has in-flight requests.

	/*

	 * If this is the in-service queue, check if it needs to be expired,

	 * or if we want to idle in case it has no pending requests.

			/*

			 * If we get here, we do not expire bfqq, even

			 * if bfqq was in budget timeout or had no

			 * more requests (as controlled in the next

			 * conditional instructions). The reason for

			 * not expiring bfqq is as follows.

			 *

			 * Here bfqq->dispatched > 0 holds, but

			 * bfq_bfqq_must_idle() returned true. This

			 * implies that, even if no request arrives

			 * for bfqq before bfqq->dispatched reaches 0,

			 * bfqq will, however, not be expired on the

			 * completion event that causes bfqq->dispatch

			 * to reach zero. In contrast, on this event,

			 * bfqq will start enjoying device idling

			 * (I/O-dispatch plugging).

			 *

			 * But, if we expired bfqq here, bfqq would

			 * not have the chance to enjoy device idling

			 * when bfqq->dispatched finally reaches

			 * zero. This would expose bfqq to violation

			 * of its reserved service guarantees.

/*

 * The processes associated with bfqq may happen to generate their

 * cumulative I/O at a lower rate than the rate at which the device

 * could serve the same I/O. This is rather probable, e.g., if only

 * one process is associated with bfqq and the device is an SSD. It

 * results in bfqq becoming often empty while in service. In this

 * respect, if BFQ is allowed to switch to another queue when bfqq

 * remains empty, then the device goes on being fed with I/O requests,

 * and the throughput is not affected. In contrast, if BFQ is not

 * allowed to switch to another queue---because bfqq is sync and

 * I/O-dispatch needs to be plugged while bfqq is temporarily

 * empty---then, during the service of bfqq, there will be frequent

 * "service holes", i.e., time intervals during which bfqq gets empty

 * and the device can only consume the I/O already queued in its

 * hardware queues. During service holes, the device may even get to

 * remaining idle. In the end, during the service of bfqq, the device

 * is driven at a lower speed than the one it can reach with the kind

 * of I/O flowing through bfqq.

 *

 * To counter this loss of throughput, BFQ implements a "request

 * injection mechanism", which tries to fill the above service holes

 * with I/O requests taken from other queues. The hard part in this

 * mechanism is finding the right amount of I/O to inject, so as to

 * both boost throughput and not break bfqq's bandwidth and latency

 * guarantees. In this respect, the mechanism maintains a per-queue

 * inject limit, computed as below. While bfqq is empty, the injection

 * mechanism dispatches extra I/O requests only until the total number

 * of I/O requests in flight---i.e., already dispatched but not yet

 * completed---remains lower than this limit.

 *

 * A first definition comes in handy to introduce the algorithm by

 * which the inject limit is computed.  We define as first request for

 * bfqq, an I/O request for bfqq that arrives while bfqq is in

 * service, and causes bfqq to switch from empty to non-empty. The

 * algorithm updates the limit as a function of the effect of

 * injection on the service times of only the first requests of

 * bfqq. The reason for this restriction is that these are the

 * requests whose service time is affected most, because they are the

 * first to arrive after injection possibly occurred.

 *

 * To evaluate the effect of injection, the algorithm measures the

 * "total service time" of first requests. We define as total service

 * time of an I/O request, the time that elapses since when the

 * request is enqueued into bfqq, to when it is completed. This

 * quantity allows the whole effect of injection to be measured. It is

 * easy to see why. Suppose that some requests of other queues are

 * actually injected while bfqq is empty, and that a new request R

 * then arrives for bfqq. If the device does start to serve all or

 * part of the injected requests during the service hole, then,

 * because of this extra service, it may delay the next invocation of

 * the dispatch hook of BFQ. Then, even after R gets eventually

 * dispatched, the device may delay the actual service of R if it is

 * still busy serving the extra requests, or if it decides to serve,

 * before R, some extra request still present in its queues. As a

 * conclusion, the cumulative extra delay caused by injection can be

 * easily evaluated by just comparing the total service time of first

 * requests with and without injection.

 *

 * The limit-update algorithm works as follows. On the arrival of a

 * first request of bfqq, the algorithm measures the total time of the

 * request only if one of the three cases below holds, and, for each

 * case, it updates the limit as described below:

 *

 * (1) If there is no in-flight request. This gives a baseline for the

 *     total service time of the requests of bfqq. If the baseline has

 *     not been computed yet, then, after computing it, the limit is

 *     set to 1, to start boosting throughput, and to prepare the

 *     ground for the next case. If the baseline has already been

 *     computed, then it is updated, in case it results to be lower

 *     than the previous value.

 *

 * (2) If the limit is higher than 0 and there are in-flight

 *     requests. By comparing the total service time in this case with

 *     the above baseline, it is possible to know at which extent the

 *     current value of the limit is inflating the total service

 *     time. If the inflation is below a certain threshold, then bfqq

 *     is assumed to be suffering from no perceivable loss of its

 *     service guarantees, and the limit is even tentatively

 *     increased. If the inflation is above the threshold, then the

 *     limit is decreased. Due to the lack of any hysteresis, this

 *     logic makes the limit oscillate even in steady workload

 *     conditions. Yet we opted for it, because it is fast in reaching

 *     the best value for the limit, as a function of the current I/O

 *     workload. To reduce oscillations, this step is disabled for a

 *     short time interval after the limit happens to be decreased.

 *

 * (3) Periodically, after resetting the limit, to make sure that the

 *     limit eventually drops in case the workload changes. This is

 *     needed because, after the limit has gone safely up for a

 *     certain workload, it is impossible to guess whether the

 *     baseline total service time may have changed, without measuring

 *     it again without injection. A more effective version of this

 *     step might be to just sample the baseline, by interrupting

 *     injection only once, and then to reset/lower the limit only if

 *     the total service time with the current limit does happen to be

 *     too large.

 *

 * More details on each step are provided in the comments on the

 * pieces of code that implement these steps: the branch handling the

 * transition from empty to non empty in bfq_add_request(), the branch

 * handling injection in bfq_select_queue(), and the function

 * bfq_choose_bfqq_for_injection(). These comments also explain some

 * exceptions, made by the injection mechanism in some special cases.

	/*

	 * Either we still have to compute the base value for the

	 * total service time, and there seem to be the right

	 * conditions to do it, or we can lower the last base value

	 * computed.

	 *

	 * NOTE: (bfqd->rq_in_driver == 1) means that there is no I/O

	 * request in flight, because this function is in the code

	 * path that handles the completion of a request of bfqq, and,

	 * in particular, this function is executed before

	 * bfqd->rq_in_driver is decremented in such a code path.

			/*

			 * Now we certainly have a base value: make sure we

			 * start trying injection.

		/*

		 * No I/O injected and no request still in service in

		 * the drive: these are the exact conditions for

		 * computing the base value of the total service time

		 * for bfqq. So let's update this value, because it is

		 * rather variable. For example, it varies if the size

		 * or the spatial locality of the I/O requests in bfqq

		 * change.

 update complete, not waiting for any request completion any longer */

/*

 * Handle either a requeue or a finish for rq. The things to do are

 * the same in both cases: all references to rq are to be dropped. In

 * particular, rq is considered completed from the point of view of

 * the scheduler.

	/*

	 * rq either is not associated with any icq, or is an already

	 * requeued request that has not (yet) been re-inserted into

	 * a bfq_queue.

	/*

	 * Reset private fields. In case of a requeue, this allows

	 * this function to correctly do nothing if it is spuriously

	 * invoked again on this same request (see the check at the

	 * beginning of the function). Probably, a better general

	 * design would be to prevent blk-mq from invoking the requeue

	 * or finish hooks of an elevator, for a request that is not

	 * referred by that elevator.

	 *

	 * Resetting the following fields would break the

	 * request-insertion logic if rq is re-inserted into a bfq

	 * internal queue, without a re-preparation. Here we assume

	 * that re-insertions of requeued requests, without

	 * re-preparation, can happen only for pass_through or at_head

	 * requests (which are not re-inserted into bfq internal

	 * queues).

/*

 * Removes the association between the current task and bfqq, assuming

 * that bic points to the bfq iocontext of the task.

 * Returns NULL if a new bfqq should be allocated, or the old bfqq if this

 * was the last process referring to that bfqq.

				/*

				 * If bfqq was in the current

				 * burst list before being

				 * merged, then we have to add

				 * it back. And we do not need

				 * to increase burst_size, as

				 * we did not decrement

				 * burst_size when we removed

				 * bfqq from the burst list as

				 * a consequence of a merge

				 * (see comments in

				 * bfq_put_queue). In this

				 * respect, it would be rather

				 * costly to know whether the

				 * current burst list is still

				 * the same burst list from

				 * which bfqq was removed on

				 * the merge. To avoid this

				 * cost, if bfqq was in a

				 * burst list, then we add

				 * bfqq to the current burst

				 * list without any further

				 * check. This can cause

				 * inappropriate insertions,

				 * but rarely enough to not

				 * harm the detection of large

				 * bursts significantly.

/*

 * Only reset private fields. The actual request preparation will be

 * performed by bfq_init_rq, when rq is either inserted or merged. See

 * comments on bfq_init_rq for the reason behind this delayed

 * preparation.

	/*

	 * Regardless of whether we have an icq attached, we have to

	 * clear the scheduler pointers, as they might point to

	 * previously allocated bic/bfqq structs.

/*

 * If needed, init rq, allocate bfq data structures associated with

 * rq, and increment reference counters in the destination bfq_queue

 * for rq. Return the destination bfq_queue for rq, or NULL is rq is

 * not associated with any bfq_queue.

 *

 * This function is invoked by the functions that perform rq insertion

 * or merging. One may have expected the above preparation operations

 * to be performed in bfq_prepare_request, and not delayed to when rq

 * is inserted or merged. The rationale behind this delayed

 * preparation is that, after the prepare_request hook is invoked for

 * rq, rq may still be transformed into a request with no icq, i.e., a

 * request not associated with any queue. No bfq hook is invoked to

 * signal this transformation. As a consequence, should these

 * preparation operations be performed when the prepare_request hook

 * is invoked, and should rq be transformed one moment later, bfq

 * would end up in an inconsistent state, because it would have

 * incremented some queue counters for an rq destined to

 * transformation, without any chance to correctly lower these

 * counters back. In contrast, no transformation can still happen for

 * rq after rq has been inserted or merged. So, it is safe to execute

 * these preparation operations when rq is finally inserted or merged.

	/*

	 * Assuming that elv.priv[1] is set only if everything is set

	 * for this rq. This holds true, because this function is

	 * invoked only for insertion or merging, and, after such

	 * events, a request cannot be manipulated any longer before

	 * being removed from bfq.

 If the queue was seeky for too long, break it apart. */

 Update bic before losing reference to bfqq */

				/*

				 * If the waker queue disappears, then

				 * new_bfqq->waker_bfqq must be

				 * reset. So insert new_bfqq into the

				 * woken_list of the waker. See

				 * bfq_check_waker for details.

	/*

	 * If a bfq_queue has only one process reference, it is owned

	 * by only this bic: we can then set bfqq->bic = bic. in

	 * addition, if the queue has also just been split, we have to

	 * resume its state.

			/*

			 * The queue has just been split from a shared

			 * queue: restore the idle window and the

			 * possible weight raising period.

	/*

	 * Consider bfqq as possibly belonging to a burst of newly

	 * created queues only if:

	 * 1) A burst is actually happening (bfqd->burst_size > 0)

	 * or

	 * 2) There is no other active queue. In fact, if, in

	 *    contrast, there are active queues not belonging to the

	 *    possible burst bfqq may belong to, then there is no gain

	 *    in considering bfqq as belonging to a burst, and

	 *    therefore in not weight-raising bfqq. See comments on

	 *    bfq_handle_burst().

	 *

	 * This filtering also helps eliminating false positives,

	 * occurring when bfqq does not belong to an actual large

	 * burst, but some background task (e.g., a service) happens

	 * to trigger the creation of new queues very close to when

	 * bfqq and its possible companion queues are created. See

	 * comments on bfq_handle_burst() for further details also on

	 * this issue.

	/*

	 * Considering that bfqq may be in race, we should firstly check

	 * whether bfqq is in service before doing something on it. If

	 * the bfqq in race is not in service, it has already been expired

	 * through __bfq_bfqq_expire func and its wait_request flags has

	 * been cleared in __bfq_bfqd_reset_in_service func.

		/*

		 * Also here the queue can be safely expired

		 * for budget timeout without wasting

		 * guarantees

		/*

		 * The queue may not be empty upon timer expiration,

		 * because we may not disable the timer when the

		 * first request of the in-service queue arrives

		 * during disk idling.

/*

 * Handler of the expiration of the timer running if the in-service queue

 * is idling inside its time slice.

	/*

	 * Theoretical race here: the in-service queue can be NULL or

	 * different from the queue that was idling if a new request

	 * arrives for the current queue and there is a full dispatch

	 * cycle that changes the in-service queue.  This can hardly

	 * happen, but in the worst case we just expire a queue too

	 * early.

/*

 * Release all the bfqg references to its async queues.  If we are

 * deallocating the group these queues may still contain requests, so

 * we reparent them to the root cgroup (i.e., the only one that will

 * exist for sure until all the requests on a device are gone).

/*

 * See the comments on bfq_limit_depth for the purpose of

 * the depths set in the function. Return minimum shallow depth we'll use.

	/*

	 * In-word depths if no bfq_queue is being weight-raised:

	 * leaving 25% of tags only for sync reads.

	 *

	 * In next formulas, right-shift the value

	 * (1U<<bt->sb.shift), instead of computing directly

	 * (1U<<(bt->sb.shift - something)), to be robust against

	 * any possible value of bt->sb.shift, without having to

	 * limit 'something'.

 no more than 50% of tags for async I/O */

	/*

	 * no more than 75% of tags for sync writes (25% extra tags

	 * w.r.t. async I/O, to prevent async I/O from starving sync

	 * writes)

	/*

	 * In-word depths in case some bfq_queue is being weight-

	 * raised: leaving ~63% of tags for sync reads. This is the

	 * highest percentage for which, in our tests, application

	 * start-up times didn't suffer from any regression due to tag

	 * shortage.

 no more than ~18% of tags for async I/O */

 no more than ~37% of tags for sync writes (~20% extra tags) */

 release oom-queue reference to root group */

	/*

	 * Our fallback bfqq if bfq_find_alloc_queue() runs into OOM issues.

	 * Grab a permanent reference to it, so that the normal code flow

	 * will not attempt to free it.

 oom_bfqq does not participate to bursts */

	/*

	 * Trigger weight initialization, according to ioprio, at the

	 * oom_bfqq's first activation. The oom_bfqq's ioprio and ioprio

	 * class won't be changed any more.

	/*

	 * Trade-off between responsiveness and fairness.

	bfqd->bfq_wr_max_softrt_rate = 7000; /*

					      * Approximate rate required

					      * to playback or record a

					      * high-definition compressed

					      * video.

	/*

	 * Begin by assuming, optimistically, that the device peak

	 * rate is equal to 2/3 of the highest reference rate.

	/*

	 * The invocation of the next bfq_create_group_hierarchy

	 * function is the head of a chain of function calls

	 * (bfq_create_group_hierarchy->blkcg_activate_policy->

	 * blk_mq_freeze_queue) that may lead to the invocation of the

	 * has_work hook function. For this reason,

	 * bfq_create_group_hierarchy is invoked only after all

	 * scheduler data has been initialized, apart from the fields

	 * that can be initialized only after invoking

	 * bfq_create_group_hierarchy. This, in particular, enables

	 * has_work to correctly return false. Of course, to avoid

	 * other inconsistencies, the blk-mq stack must then refrain

	 * from invoking further scheduler hooks before this init

	 * function is finished.

/*

 * Leaving this name to preserve name compatibility with cfq

 * parameters, but this timeout is used for both sync and async.

	/*

	 * Times to load large popular applications for the typical

	 * systems installed on the reference devices (see the

	 * comments before the definition of the next

	 * array). Actually, we use slightly lower values, as the

	 * estimated peak rate tends to be smaller than the actual

	 * peak rate.  The reason for this last fact is that estimates

	 * are computed over much shorter time intervals than the long

	 * intervals typically used for benchmarking. Why? First, to

	 * adapt more quickly to variations. Second, because an I/O

	 * scheduler cannot rely on a peak-rate-evaluation workload to

	 * be run for a long time.

 actually 8 sec */

 actually 3 sec */

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to setting various queue properties from drivers

/**

 * blk_end_sync_rq - executes a completion event on a request

 * @rq: request to complete

 * @error: end I/O status of the request

	/*

	 * complete last, if this is a stack request the process (and thus

	 * the rq pointer) could be invalid right after this complete()

/**

 * blk_execute_rq_nowait - insert a request to I/O scheduler for execution

 * @bd_disk:	matching gendisk

 * @rq:		request to insert

 * @at_head:    insert request at head or tail of queue

 * @done:	I/O completion handler

 *

 * Description:

 *    Insert a fully prepared request at the back of the I/O scheduler queue

 *    for execution.  Don't wait for completion.

 *

 * Note:

 *    This function will invoke @done directly if the queue is dead.

	/*

	 * don't check dying flag for MQ because the request won't

	 * be reused after dying flag is set

/**

 * blk_execute_rq - insert a request into queue for execution

 * @bd_disk:	matching gendisk

 * @rq:		request to insert

 * @at_head:    insert request at head or tail of queue

 *

 * Description:

 *    Insert a fully prepared request at the back of the I/O scheduler queue

 *    for execution and wait for completion.

 * Return: The blk_status_t result provided to blk_mq_end_request().

 Prevent hang_check timer from firing at us during very long I/O */

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Western Digital Corporation or its affiliates.

 SPDX-License-Identifier: GPL-2.0

/**

 * blk_pm_runtime_init - Block layer runtime PM initialization routine

 * @q: the queue of the device

 * @dev: the device the queue belongs to

 *

 * Description:

 *    Initialize runtime-PM-related fields for @q and start auto suspend for

 *    @dev. Drivers that want to take advantage of request-based runtime PM

 *    should call this function after @dev has been initialized, and its

 *    request queue @q has been allocated, and runtime PM for it can not happen

 *    yet(either due to disabled/forbidden or its usage_count > 0). In most

 *    cases, driver should call this function before any I/O has taken place.

 *

 *    This function takes care of setting up using auto suspend for the device,

 *    the autosuspend delay is set to -1 to make runtime suspend impossible

 *    until an updated value is either set by user or by driver. Drivers do

 *    not need to touch other autosuspend settings.

 *

 *    The block layer runtime PM is request based, so only works for drivers

 *    that use request as their IO unit instead of those directly use bio's.

/**

 * blk_pre_runtime_suspend - Pre runtime suspend check

 * @q: the queue of the device

 *

 * Description:

 *    This function will check if runtime suspend is allowed for the device

 *    by examining if there are any requests pending in the queue. If there

 *    are requests pending, the device can not be runtime suspended; otherwise,

 *    the queue's status will be updated to SUSPENDING and the driver can

 *    proceed to suspend the device.

 *

 *    For the not allowed case, we mark last busy for the device so that

 *    runtime PM core will try to autosuspend it some time later.

 *

 *    This function should be called near the start of the device's

 *    runtime_suspend callback.

 *

 * Return:

 *    0		- OK to runtime suspend the device

 *    -EBUSY	- Device should not be runtime suspended

	/*

	 * Increase the pm_only counter before checking whether any

	 * non-PM blk_queue_enter() calls are in progress to avoid that any

	 * new non-PM blk_queue_enter() calls succeed before the pm_only

	 * counter is decreased again.

 Switch q_usage_counter from per-cpu to atomic mode. */

	/*

	 * Wait until atomic mode has been reached. Since that

	 * involves calling call_rcu(), it is guaranteed that later

	 * blk_queue_enter() calls see the pm-only state. See also

	 * http://lwn.net/Articles/573497/.

 Switch q_usage_counter back to per-cpu mode. */

/**

 * blk_post_runtime_suspend - Post runtime suspend processing

 * @q: the queue of the device

 * @err: return value of the device's runtime_suspend function

 *

 * Description:

 *    Update the queue's runtime status according to the return value of the

 *    device's runtime suspend function and mark last busy for the device so

 *    that PM core will try to auto suspend the device at a later time.

 *

 *    This function should be called near the end of the device's

 *    runtime_suspend callback.

/**

 * blk_pre_runtime_resume - Pre runtime resume processing

 * @q: the queue of the device

 *

 * Description:

 *    Update the queue's runtime status to RESUMING in preparation for the

 *    runtime resume of the device.

 *

 *    This function should be called near the start of the device's

 *    runtime_resume callback.

/**

 * blk_post_runtime_resume - Post runtime resume processing

 * @q: the queue of the device

 * @err: return value of the device's runtime_resume function

 *

 * Description:

 *    Update the queue's runtime status according to the return value of the

 *    device's runtime_resume function. If the resume was successful, call

 *    blk_set_runtime_active() to do the real work of restarting the queue.

 *

 *    This function should be called near the end of the device's

 *    runtime_resume callback.

/**

 * blk_set_runtime_active - Force runtime status of the queue to be active

 * @q: the queue of the device

 *

 * If the device is left runtime suspended during system suspend the resume

 * hook typically resumes the device and corrects runtime status

 * accordingly. However, that does not affect the queue runtime PM status

 * which is still "suspended". This prevents processing requests from the

 * queue.

 *

 * This function can be used in driver's resume hook to correct queue

 * runtime PM status and re-enable peeking requests from the queue. It

 * should be called before first request is added to the queue.

 *

 * This function is also called by blk_post_runtime_resume() for successful

 * runtime resumes.  It does everything necessary to restart the queue.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 1991, 1992 Linus Torvalds

 * Copyright (C) 1994,      Karl Keyte: Added support for disk statistics

 * Elevator latency, (C) 2000  Andrea Arcangeli <andrea@suse.de> SuSE

 * Queue request tables / lock, selectable elevator, Jens Axboe <axboe@suse.de>

 * kernel-doc documentation started by NeilBrown <neilb@cse.unsw.edu.au>

 *	-  July2000

 * bio rewrite, highmem i/o, etc, Jens Axboe <axboe@suse.de> - may 2001

/*

 * This handles all read/write requests to block devices

/*

 * For queue allocation

/*

 * Controlling structure to kblockd

/**

 * blk_queue_flag_set - atomically set a queue flag

 * @flag: flag to be set

 * @q: request queue

/**

 * blk_queue_flag_clear - atomically clear a queue flag

 * @flag: flag to be cleared

 * @q: request queue

/**

 * blk_queue_flag_test_and_set - atomically test and set a queue flag

 * @flag: flag to be set

 * @q: request queue

 *

 * Returns the previous value of @flag - 0 if the flag was not set and 1 if

 * the flag was already set.

/**

 * blk_op_str - Return string XXX in the REQ_OP_XXX.

 * @op: REQ_OP_XXX.

 *

 * Description: Centralize block layer function to convert REQ_OP_XXX into

 * string format. Useful in the debugging and tracing bio or request. For

 * invalid REQ_OP_XXX it returns string "UNKNOWN".

 device mapper special case, should not leak out: */

 zone device specific errors */

 everything else not covered above: */

/**

 * blk_sync_queue - cancel any pending callbacks on a queue

 * @q: the queue

 *

 * Description:

 *     The block layer may perform asynchronous callback activity

 *     on a queue, such as calling the unplug function after a timeout.

 *     A block device may call blk_sync_queue to ensure that any

 *     such activity is cancelled, thus allowing it to release resources

 *     that the callbacks might use. The caller must already have made sure

 *     that its ->submit_bio will not re-add plugging prior to calling

 *     this function.

 *

 *     This function does not cancel any asynchronous activity arising

 *     out of elevator or throttling code. That would require elevator_exit()

 *     and blkcg_exit_queue() to be called with queue lock initialized.

 *

/**

 * blk_set_pm_only - increment pm_only counter

 * @q: request queue pointer

/**

 * blk_put_queue - decrement the request_queue refcount

 * @q: the request_queue structure to decrement the refcount for

 *

 * Decrements the refcount of the request_queue kobject. When this reaches 0

 * we'll have blk_release_queue() called.

 *

 * Context: Any context, but the last reference must not be dropped from

 *          atomic context.

	/*

	 * When queue DYING flag is set, we need to block new req

	 * entering queue, so we call blk_freeze_queue_start() to

	 * prevent I/O from crossing blk_queue_enter().

 Make blk_queue_enter() reexamine the DYING flag. */

/**

 * blk_cleanup_queue - shutdown a request queue

 * @q: request queue to shutdown

 *

 * Mark @q DYING, drain all pending requests, mark @q DEAD, destroy and

 * put it.  All future requests will be failed immediately with -ENODEV.

 *

 * Context: can sleep

 cannot be called from atomic context */

 mark @q DYING, no new request or merges will be allowed afterwards */

	/*

	 * Drain all requests queued before DYING marking. Set DEAD flag to

	 * prevent that blk_mq_run_hw_queues() accesses the hardware queues

	 * after draining finished.

	/*

	 * In theory, request pool of sched_tags belongs to request queue.

	 * However, the current implementation requires tag_set for freeing

	 * requests, so free the pool now.

	 *

	 * Queue has become frozen, there can't be any in-queue requests, so

	 * it is safe to free requests now.

 @q is and will stay empty, shutdown and put */

/**

 * blk_queue_enter() - try to increase q->q_usage_counter

 * @q: request queue pointer

 * @flags: BLK_MQ_REQ_NOWAIT and/or BLK_MQ_REQ_PM

		/*

		 * read pair of barrier in blk_freeze_queue_start(), we need to

		 * order reading __PERCPU_REF_DEAD flag of .q_usage_counter and

		 * reading .mq_freeze_depth or queue dying flag, otherwise the

		 * following wait may never return if the two reads are

		 * reordered.

		/*

		 * read pair of barrier in blk_freeze_queue_start(), we need to

		 * order reading __PERCPU_REF_DEAD flag of .q_usage_counter and

		 * reading .mq_freeze_depth or queue dying flag, otherwise the

		 * following wait may never return if the two reads are

		 * reordered.

	/*

	 * Init percpu_ref in atomic mode so that it's faster to shutdown.

	 * See blk_register_queue() for details.

/**

 * blk_get_queue - increment the request_queue refcount

 * @q: the request_queue structure to increment the refcount for

 *

 * Increment the refcount of the request_queue kobject.

 *

 * Context: Any context.

 CONFIG_FAIL_MAKE_REQUEST */

 CONFIG_FAIL_MAKE_REQUEST */

 Older lvm-tools actually trigger this */

/*

 * Check whether this bio extends beyond the end of the device or partition.

 * This may well happen - the kernel calls bread() without checking the size of

 * the device, e.g., when mounting a file system.

/*

 * Remap block n of partition p to block n+start(p) of the disk.

/*

 * Check write append to a zoned block device.

 Only applicable to zoned block devices */

 The bio sector must point to the start of a sequential zone */

	/*

	 * Not allowed to cross zone boundaries. Otherwise, the BIO will be

	 * split and could result in non-contiguous sectors being written in

	 * different zones.

 Make sure the BIO is small enough and will not get split */

	/*

	 * For a REQ_NOWAIT based request, return -EOPNOTSUPP

	 * if queue does not support NOWAIT.

	/*

	 * Filter flush bio's early so that bio based drivers without flush

	 * support don't have to worry about them.

	/*

	 * Various block parts want %current->io_context, so allocate it up

	 * front rather than dealing with lots of pain to allocate it only

	 * where needed. This may fail and the block layer knows how to live

	 * with it.

		/* Now that enqueuing has been traced, we need to trace

		 * completion as well.

/*

 * The loop in this function may be a bit non-obvious, and so deserves some

 * explanation:

 *

 *  - Before entering the loop, bio->bi_next is NULL (as all callers ensure

 *    that), so we have a list with a single bio.

 *  - We pretend that we have just taken it off a longer list, so we assign

 *    bio_list to a pointer to the bio_list_on_stack, thus initialising the

 *    bio_list of new bios to be added.  ->submit_bio() may indeed add some more

 *    bios through a recursive call to submit_bio_noacct.  If it did, we find a

 *    non-NULL value in bio_list and re-enter the loop from the top.

 *  - In this case we really did just take the bio of the top of the list (no

 *    pretending) and so remove it from bio_list, and call into ->submit_bio()

 *    again.

 *

 * bio_list_on_stack[0] contains bios submitted by the current ->submit_bio.

 * bio_list_on_stack[1] contains bios that were submitted before the current

 *	->submit_bio_bio, but that haven't been processed yet.

		/*

		 * Create a fresh bio_list for all subordinate requests.

		/*

		 * Sort new bios into those for a lower level and those for the

		 * same level.

		/*

		 * Now assemble so we handle the lowest level first.

/**

 * submit_bio_noacct - re-submit a bio to the block device layer for I/O

 * @bio:  The bio describing the location in memory and on the device.

 *

 * This is a version of submit_bio() that shall only be used for I/O that is

 * resubmitted to lower level drivers by stacking block drivers.  All file

 * systems and other upper level users of the block layer should use

 * submit_bio() instead.

	/*

	 * We only want one ->submit_bio to be active at a time, else stack

	 * usage with stacked devices could be a problem.  Use current->bio_list

	 * to collect a list of requests submited by a ->submit_bio method while

	 * it is active, and then process them after it returned.

/**

 * submit_bio - submit a bio to the block device layer for I/O

 * @bio: The &struct bio which describes the I/O

 *

 * submit_bio() is used to submit I/O requests to block devices.  It is passed a

 * fully set up &struct bio that describes the I/O that needs to be done.  The

 * bio will be send to the device described by the bi_bdev field.

 *

 * The success/failure status of the request, along with notification of

 * completion, is delivered asynchronously through the ->bi_end_io() callback

 * in @bio.  The bio must NOT be touched by thecaller until ->bi_end_io() has

 * been called.

	/*

	 * If it's a regular read/write or a barrier with data attached,

	 * go through the normal accounting stuff before submission.

	/*

	 * If we're reading data that is part of the userspace workingset, count

	 * submission time as memory stall.  When the device is congested, or

	 * the submitting cgroup IO-throttled, submission can be a significant

	 * part of overall IO time.

/**

 * bio_poll - poll for BIO completions

 * @bio: bio to poll for

 * @flags: BLK_POLL_* flags that control the behavior

 *

 * Poll for completions on queue associated with the bio. Returns number of

 * completed entries found.

 *

 * Note: the caller must either be the context that submitted @bio, or

 * be in a RCU critical section to prevent freeing of @bio.

 not yet implemented, should not happen */

/*

 * Helper to implement file_operations.iopoll.  Requires the bio to be stored

 * in iocb->private, and cleared before freeing the bio.

	/*

	 * Note: the bio cache only uses SLAB_TYPESAFE_BY_RCU, so bio can

	 * point to a freshly allocated bio at this point.  If that happens

	 * we have a few cases to consider:

	 *

	 *  1) the bio is beeing initialized and bi_bdev is NULL.  We can just

	 *     simply nothing in this case

	 *  2) the bio points to a not poll enabled device.  bio_poll will catch

	 *     this and return 0

	 *  3) the bio points to a poll capable device, including but not

	 *     limited to the one that the original bio pointed to.  In this

	 *     case we will call into the actual poll method and poll for I/O,

	 *     even if we don't need to, but it won't cause harm either.

	 *

	 * For cases 2) and 3) above the RCU grace period ensures that bi_bdev

	 * is still allocated. Because partitions hold a reference to the whole

	 * device bdev and thus disk, the disk is also still valid.  Grabbing

	 * a reference to the queue in bio_poll() ensures the hctxs and requests

	 * are still valid as well.

/**

 * blk_cloned_rq_check_limits - Helper function to check a cloned request

 *                              for the new queue limits

 * @q:  the queue

 * @rq: the request being checked

 *

 * Description:

 *    @rq may have been made based on weaker limitations of upper-level queues

 *    in request stacking drivers, and it may violate the limitation of @q.

 *    Since the block layer and the underlying device driver trust @rq

 *    after it is inserted to @q, it should be checked against @q before

 *    the insertion using this generic function.

 *

 *    Request stacking drivers like request-based dm may change the queue

 *    limits when retrying requests on other queues. Those requests need

 *    to be checked against the new queue limits again during dispatch.

		/*

		 * SCSI device does not have a good way to return if

		 * Write Same/Zero is actually supported. If a device rejects

		 * a non-read/write command (discard, write same,etc.) the

		 * low-level device driver will set the relevant queue limit to

		 * 0 to prevent blk-lib from issuing more of the offending

		 * operations. Commands queued prior to the queue limit being

		 * reset need to be completed with BLK_STS_NOTSUPP to avoid I/O

		 * errors being propagated to upper layers.

	/*

	 * The queue settings related to segment counting may differ from the

	 * original queue.

/**

 * blk_insert_cloned_request - Helper for stacking drivers to submit a request

 * @q:  the queue to submit the request

 * @rq: the request being queued

	/*

	 * Since we have a scheduler attached on the top device,

	 * bypass a potential scheduler on the bottom device for

	 * insert.

/**

 * blk_rq_err_bytes - determine number of bytes till the next failure boundary

 * @rq: request to examine

 *

 * Description:

 *     A request could be merge of IOs which require different failure

 *     handling.  This function determines the number of bytes which

 *     can be failed from the beginning of the request without

 *     crossing into area which need to be retried further.

 *

 * Return:

 *     The number of bytes to fail.

	/*

	 * Currently the only 'mixing' which can happen is between

	 * different fastfail types.  We can safely fail portions

	 * which have all the failfast bits that the first one has -

	 * the ones which are at least as eager to fail as the first

	 * one.

 this could lead to infinite loop */

 passthrough requests can hold bios that do not have ->bi_bdev set */

/**

 * bio_start_io_acct - start I/O accounting for bio based drivers

 * @bio:	bio to start account for

 *

 * Returns the start time that should be passed back to bio_end_io_acct().

/*

 * Steal bios from a request and add them to a bio list.

 * The request must not have been partially completed before.

/**

 * rq_flush_dcache_pages - Helper function to flush all pages in a request

 * @rq: the request to be flushed

 *

 * Description:

 *     Flush all pages in @rq.

/**

 * blk_lld_busy - Check if underlying low-level drivers of a device are busy

 * @q : the queue of the device being checked

 *

 * Description:

 *    Check if underlying low-level drivers of a device are busy.

 *    If the drivers want to export their busy state, they must set own

 *    exporting function using blk_queue_lld_busy() first.

 *

 *    Basically, this function is used only by request stacking drivers

 *    to stop dispatching requests to underlying devices when underlying

 *    devices are busy.  This behavior helps more I/O merging on the queue

 *    of the request stacking driver and prevents I/O throughput regression

 *    on burst I/O load.

 *

 * Return:

 *    0 - Not busy (The request stacking driver should dispatch request)

 *    1 - Busy (The request stacking driver should stop dispatching request)

/**

 * blk_rq_unprep_clone - Helper function to free all bios in a cloned request

 * @rq: the clone request to be cleaned up

 *

 * Description:

 *     Free all bios in @rq for a cloned request.

/**

 * blk_rq_prep_clone - Helper function to setup clone request

 * @rq: the request to be setup

 * @rq_src: original request to be cloned

 * @bs: bio_set that bios for clone are allocated from

 * @gfp_mask: memory allocation mask for bio

 * @bio_ctr: setup function to be called for each clone bio.

 *           Returns %0 for success, non %0 for failure.

 * @data: private data to be passed to @bio_ctr

 *

 * Description:

 *     Clones bios in @rq_src to @rq, and copies attributes of @rq_src to @rq.

 *     Also, pages which the original bios are pointing to are not copied

 *     and the cloned bios just point same pages.

 *     So cloned bios must be completed before original bios, which means

 *     the caller must complete @rq before @rq_src.

 Copy attributes of the original request to the clone request. */

	/*

	 * If this is a nested plug, don't actually assign it.

	/*

	 * Store ordering should not be needed here, since a potential

	 * preempt will imply a full memory barrier

/**

 * blk_start_plug - initialize blk_plug and track it inside the task_struct

 * @plug:	The &struct blk_plug that needs to be initialized

 *

 * Description:

 *   blk_start_plug() indicates to the block layer an intent by the caller

 *   to submit multiple I/O requests in a batch.  The block layer may use

 *   this hint to defer submitting I/Os from the caller until blk_finish_plug()

 *   is called.  However, the block layer may choose to submit requests

 *   before a call to blk_finish_plug() if the number of queued I/Os

 *   exceeds %BLK_MAX_REQUEST_COUNT, or if the size of the I/O is larger than

 *   %BLK_PLUG_FLUSH_SIZE.  The queued I/Os may also be submitted early if

 *   the task schedules (see below).

 *

 *   Tracking blk_plug inside the task_struct will help with auto-flushing the

 *   pending I/O should the task end up blocking between blk_start_plug() and

 *   blk_finish_plug(). This is important from a performance perspective, but

 *   also ensures that we don't deadlock. For instance, if the task is blocking

 *   for a memory allocation, memory reclaim could end up wanting to free a

 *   page belonging to that request that is currently residing in our private

 *   plug. By flushing the pending I/O when the process goes to sleep, we avoid

 *   this kind of deadlock.

 Not currently on the callback list */

	/*

	 * Unconditionally flush out cached requests, even if the unplug

	 * event came from schedule. Since we know hold references to the

	 * queue for cached requests, we don't want a blocked task holding

	 * up a queue freeze/quiesce event.

/**

 * blk_finish_plug - mark the end of a batch of submitted I/O

 * @plug:	The &struct blk_plug passed to blk_start_plug()

 *

 * Description:

 * Indicate that a batch of I/O submissions is complete.  This function

 * must be paired with an initial call to blk_start_plug().  The intent

 * is to allow the block layer to optimize I/O submission.  See the

 * documentation for blk_start_plug() for more information.

 Prevent hang_check timer from firing at us during very long I/O */

 used for unplugging and affects IO latency/throughput - HIGHPRI */

 SPDX-License-Identifier: GPL-2.0

/*

 * Increment 'v', if 'v' is below 'below'. Returns true if we succeeded,

 * false if 'v' + 1 would be bigger than 'below'.

/*

 * Return true, if we can't increase the depth further by scaling

	/*

	 * For QD=1 devices, this is a special case. It's important for those

	 * to have one request ready when one completes, so force a depth of

	 * 2 for those devices. On the backend, it'll be a depth of 1 anyway,

	 * since the device can't have more than that in flight. If we're

	 * scaling down, then keep a setting of 1/1/1.

		/*

		 * scale_step == 0 is our default state. If we have suffered

		 * latency spikes, step will be > 0, and we shrink the

		 * allowed write depths. If step is < 0, we're only doing

		 * writes, and we allow a temporarily higher depth to

		 * increase performance.

 Returns true on success and false if scaling up wasn't possible */

	/*

	 * Hit max in previous round, stop here

/*

 * Scale rwb down. If 'hard_throttle' is set, do it quicker, since we

 * had a latency violation. Returns true on success and returns false if

 * scaling down wasn't possible.

	/*

	 * Stop scaling down when we've hit the limit. This also prevents

	 * ->scale_step from going to crazy values, if the device can't

	 * keep up.

	/*

	 * If we fail to get a budget, return -1 to interrupt the wake up loop

	 * in __wake_up_common.

/**

 * rq_qos_wait - throttle on a rqw if we need to

 * @rqw: rqw to throttle on

 * @private_data: caller provided specific data

 * @acquire_inflight_cb: inc the rqw->inflight counter if we can

 * @cleanup_cb: the callback to cleanup in case we race with a waker

 *

 * This provides a uniform place for the rq_qos users to do their throttling.

 * Since you can end up with a lot of things sleeping at once, this manages the

 * waking up based on the resources available.  The acquire_inflight_cb should

 * inc the rqw->inflight if we have the ability to do so, or return false if not

 * and then we will sleep until the room becomes available.

 *

 * cleanup_cb is in case that we race with a waker and need to cleanup the

 * inflight count accordingly.

 The memory barrier in set_task_state saves us here. */

			/*

			 * We raced with wbt_wake_function() getting a token,

			 * which means we now have two. Put our local token

			 * and wake anyone else potentially waiting for one.

 SPDX-License-Identifier: GPL-2.0

/*

 * buffered writeback throttling. loosely based on CoDel. We can't drop

 * packets for IO scheduling, so the logic is something like this:

 *

 * - Monitor latencies in a defined window of time.

 * - If the minimum latency in the above window exceeds some target, increment

 *   scaling step and scale down queue depth by a factor of 2x. The monitoring

 *   window is then shrunk to 100 / sqrt(scaling step + 1).

 * - For any window where we don't have solid data on what the latencies

 *   look like, retain status quo.

 * - If latencies look good, decrement scaling step.

 * - If we're only doing writes, allow the scaling step to go negative. This

 *   will temporarily boost write performance, snapping back to a stable

 *   scaling step of 0 if reads show up or the heavy writers finish. Unlike

 *   positive scaling steps where we shrink the monitoring window, a negative

 *   scaling step retains the default step==0 window size.

 *

 * Copyright (C) 2016 Jens Axboe

 *

	/*

	 * Default setting, we'll scale up (to 75% of QD max) or down (min 1)

	 * from here depending on device stats

	/*

	 * 100msec window

	/*

	 * Disregard stats, if we don't meet this minimum

	/*

	 * If we have this number of consecutive windows with not enough

	 * information to scale up or down, scale up.

/*

 * If a task was rate throttled in balance_dirty_pages() within the last

 * second or so, use that to indicate a higher cleaning rate.

	/*

	 * wbt got disabled with IO in flight. Wake up any potential

	 * waiters, we don't have to do more than that.

	/*

	 * For discards, our limit is always the background. For writes, if

	 * the device does write back caching, drop further down before we

	 * wake people up.

	/*

	 * Don't wake anyone up if we are above the normal limit.

/*

 * Called on completion of a request. Note that it's also called when

 * a request is merged, when the request gets freed.

	/*

	 * We need at least one read sample, and a minimum of

	 * RWB_MIN_WRITE_SAMPLES. We require some write samples to know

	 * that it's writes impacting us, and not just some sole read on

	 * a device that is in a lower power state.

	/*

	 * If our stored sync issue exceeds the window size, or it

	 * exceeds our min target AND we haven't logged any entries,

	 * flag the latency as exceeded. wbt works off completion latencies,

	 * but for a flooded device, a single sync IO can take a long time

	 * to complete after being issued. If this time exceeds our

	 * monitoring window AND we didn't see any other completions in that

	 * window, then count that sync IO as a violation of the latency.

	/*

	 * No read/write mix, if stat isn't valid

		/*

		 * If we had writes in this stat window and the window is

		 * current, we're only doing writes. If a task recently

		 * waited or still has writes in flights, consider us doing

		 * just writes as well.

	/*

	 * If the 'min' latency exceeds our target, step down.

		/*

		 * We should speed this up, using some variant of a fast

		 * integer inverse square root calculation. Since we only do

		 * this for every window expiration, it's not a huge deal,

		 * though.

		/*

		 * For step < 0, we don't want to increase/decrease the

		 * window size.

	/*

	 * If we exceeded the latency target, step down. If we did not,

	 * step one level up. If we don't know enough to say either exceeded

	 * or ok, then don't do anything.

		/*

		 * We started a the center step, but don't have a valid

		 * read/write sample, but we do have writes going on.

		 * Allow step to go negative, to increase write perf.

		/*

		 * We get here when previously scaled reduced depth, and we

		 * currently don't have a valid read/write sample. For that

		 * case, slowly return to center state (step == 0).

	/*

	 * Re-arm timer, if we have IO in flight

	/*

	 * If we got disabled, just return UINT_MAX. This ensures that

	 * we'll properly inc a new IO, and dec+wakeup at the end.

	/*

	 * At this point we know it's a buffered write. If this is

	 * kswapd trying to free memory, or REQ_SYNC is set, then

	 * it's WB_SYNC_ALL writeback, and we'll use the max limit for

	 * that. If the write is marked as a background write, then use

	 * the idle limit, or go to normal if we haven't had competing

	 * IO for a bit.

		/*

		 * If less than 100ms since we completed unrelated IO,

		 * limit us to half the depth for background writeback.

/*

 * Block if we will exceed our limit, or if we are currently waiting for

 * the timer to kick off queuing again.

		/*

		 * Don't throttle WRITE_ODIRECT

/*

 * May sleep, if we have exceeded the writeback limits. Caller can pass

 * in an irq held spinlock, if it holds one when calling this function.

 * If we do sleep, we'll release and re-grab it.

	/*

	 * Track sync issue, in case it takes a long time to complete. Allows us

	 * to react quicker, if a sync IO takes a long time to complete. Note

	 * that this is just a hint. The request can go away when it completes,

	 * so it's important we never dereference it. We only use the address to

	 * compare with, which is why we store the sync_issue time locally.

/*

 * Enable wbt if defaults are configured that way

 Throttling already enabled? */

 Queue not registered? Maybe shutting down... */

	/*

	 * We default to 2msec for non-rotational storage, and 75msec

	 * for rotational storage.

 don't account */

/*

 * Disable wbt, if enabled by default.

	/*

	 * Assign rwb and add the stats callback.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright 2019 Google LLC

/*

 * Refer to Documentation/block/inline-encryption.rst for detailed explanation.

/*

 * This number needs to be at least (the number of threads doing IO

 * concurrently) * (maximum recursive depth of a bio), so that we don't

 * deadlock on crypt_ctx allocations. The default is chosen to be the same

 * as the default number of post read contexts in both EXT4 and F2FS.

 This is assumed in various places. */

 Sanity check that no algorithm exceeds the defined limits. */

	/*

	 * The caller must use a gfp_mask that contains __GFP_DIRECT_RECLAIM so

	 * that the mempool_alloc() can't fail.

 Increments @dun by @inc, treating @dun as a multi-limb integer. */

		/*

		 * If the addition in this limb overflowed, then we need to

		 * carry 1 into the next limb. Else the carry is 0.

/*

 * Returns true if @bc->bc_dun plus @bytes converted to data units is equal to

 * @next_dun, treating the DUNs as multi-limb integers.

		/*

		 * If the addition in this limb overflowed, then we need to

		 * carry 1 into the next limb. Else the carry is 0.

 If the DUN wrapped through 0, don't treat it as contiguous. */

/*

 * Checks that two bio crypt contexts are compatible - i.e. that

 * they are mergeable except for data_unit_num continuity.

/*

 * Checks that two bio crypt contexts are compatible, and also

 * that their data_unit_nums are continuous (and can hence be merged)

 * in the order @bc1 followed by @bc2.

 Check that all I/O segments are data unit aligned. */

/**

 * __blk_crypto_free_request - Uninitialize the crypto fields of a request.

 *

 * @rq: The request whose crypto fields to uninitialize.

 *

 * Completely uninitializes the crypto fields of a request. If a keyslot has

 * been programmed into some inline encryption hardware, that keyslot is

 * released. The rq->crypt_ctx is also freed.

/**

 * __blk_crypto_bio_prep - Prepare bio for inline encryption

 *

 * @bio_ptr: pointer to original bio pointer

 *

 * If the bio crypt context provided for the bio is supported by the underlying

 * device's inline encryption hardware, do nothing.

 *

 * Otherwise, try to perform en/decryption for this bio by falling back to the

 * kernel crypto API. When the crypto API fallback is used for encryption,

 * blk-crypto may choose to split the bio into 2 - the first one that will

 * continue to be processed and the second one that will be resubmitted via

 * submit_bio_noacct. A bounce bio will be allocated to encrypt the contents

 * of the aforementioned "first one", and *bio_ptr will be updated to this

 * bounce bio.

 *

 * Caller must ensure bio has bio_crypt_ctx.

 *

 * Return: true on success; false on error (and bio->bi_status will be set

 *	   appropriately, and bio_endio() will have been called so bio

 *	   submission should abort).

 Error if bio has no data. */

	/*

	 * Success if device supports the encryption context, or if we succeeded

	 * in falling back to the crypto API.

/**

 * blk_crypto_init_key() - Prepare a key for use with blk-crypto

 * @blk_key: Pointer to the blk_crypto_key to initialize.

 * @raw_key: Pointer to the raw key. Must be the correct length for the chosen

 *	     @crypto_mode; see blk_crypto_modes[].

 * @crypto_mode: identifier for the encryption algorithm to use

 * @dun_bytes: number of bytes that will be used to specify the DUN when this

 *	       key is used

 * @data_unit_size: the data unit size to use for en/decryption

 *

 * Return: 0 on success, -errno on failure.  The caller is responsible for

 *	   zeroizing both blk_key and raw_key when done with them.

/*

 * Check if bios with @cfg can be en/decrypted by blk-crypto (i.e. either the

 * request queue it's submitted to supports inline crypto, or the

 * blk-crypto-fallback is enabled and supports the cfg).

/**

 * blk_crypto_start_using_key() - Start using a blk_crypto_key on a device

 * @key: A key to use on the device

 * @q: the request queue for the device

 *

 * Upper layers must call this function to ensure that either the hardware

 * supports the key's crypto settings, or the crypto API fallback has transforms

 * for the needed mode allocated and ready to go. This function may allocate

 * an skcipher, and *should not* be called from the data path, since that might

 * cause a deadlock

 *

 * Return: 0 on success; -ENOPKG if the hardware doesn't support the key and

 *	   blk-crypto-fallback is either disabled or the needed algorithm

 *	   is disabled in the crypto API; or another -errno code.

/**

 * blk_crypto_evict_key() - Evict a key from any inline encryption hardware

 *			    it may have been programmed into

 * @q: The request queue who's associated inline encryption hardware this key

 *     might have been programmed into

 * @key: The key to evict

 *

 * Upper layers (filesystems) must call this function to ensure that a key is

 * evicted from any hardware that it might have been programmed into.  The key

 * must not be in use by any in-flight IO when this function is called.

 *

 * Return: 0 on success or if the key wasn't in any keyslot; -errno on error.

	/*

	 * If the request_queue didn't support the key, then blk-crypto-fallback

	 * may have been used, so try to evict the key from blk-crypto-fallback.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Block device elevator/IO-scheduler.

 *

 *  Copyright (C) 2000 Andrea Arcangeli <andrea@suse.de> SuSE

 *

 * 30042000 Jens Axboe <axboe@kernel.dk> :

 *

 * Split the elevator a bit so that it is possible to choose a different

 * one or even write a new "plug in". There are three pieces:

 * - elevator_fn, inserts a new request in the queue list

 * - elevator_merge_fn, decides whether a new buffer can be merged with

 *   an existing request

 * - elevator_dequeue_fn, called when a request is taken off the active list

 *

 * 20082000 Dave Jones <davej@suse.de> :

 * Removed tests for max-bomb-segments, which was breaking elvtune

 *  when run without -bN

 *

 * Jens:

 * - Rework again to work with bio instead of buffer_heads

 * - loose bi_dev comparisons, partition handling is right now

 * - completely modularize elevator setup and teardown

 *

/*

 * Merge hash stuff.

/*

 * Query io scheduler to see if the current process issuing bio may be

 * merged with rq.

/*

 * can we safely merge with this request?

/**

 * elevator_match - Test an elevator name and features

 * @e: Scheduler to test

 * @name: Elevator name to test

 * @required_features: Features that the elevator must provide

 *

 * Return true if the elevator @e name matches @name and if @e provides all

 * the features specified by @required_features.

/**

 * elevator_find - Find an elevator

 * @name: Name of the elevator to find

 * @required_features: Features that the elevator must provide

 *

 * Return the first registered scheduler with name @name and supporting the

 * features @required_features and NULL otherwise.

/*

 * RB-tree support functions for inserting/lookup/removal of requests

 * in a sorted RB tree.

	/*

	 * Levels of merges:

	 * 	nomerges:  No merges at all attempted

	 * 	noxmerges: Only simple one-hit cache try

	 * 	merges:	   All merge tries attempted

	/*

	 * First try one-hit cache.

	/*

	 * See if our hash lookup can find a potential backmerge.

/*

 * Attempt to do an insertion back merge. Only check for the case where

 * we can append 'rq' to an existing request, so we can throw 'rq' away

 * afterwards.

 *

 * Returns true if we merged, false otherwise. 'free' will contain all

 * requests that need to be freed.

	/*

	 * First try one-hit cache.

	/*

	 * See if our hash lookup can find a potential backmerge.

 The merged request could be merged with others, try again */

 Re-enable throttling in case elevator disabled it */

 insert_requests and dispatch_request are mandatory */

 create icq_cache if requested */

 register, don't allow duplicate names */

 unregister */

	/*

	 * Destroy icq_cache if it exists.  icq's are RCU managed.  Make

	 * sure all RCU operations are complete before proceeding.

/*

 * For single queue devices, default to using mq-deadline. If we have multiple

 * queues or mq-deadline is not available, default to "none".

/*

 * Get the first elevator providing the features required by the request queue.

 * Default to "none" if no matching elevator is found.

/*

 * For a device queue that has no required features, use the default elevator

 * settings. Otherwise, use the first elevator available matching the required

 * features. If no suitable elevator is find or if the chosen elevator

 * initialization fails, fall back to the "none" elevator (no elevator).

	/*

	 * We are called before adding disk, when there isn't any FS I/O,

	 * so freezing queue plus canceling dispatch work is enough to

	 * drain any dispatch activities originated from passthrough

	 * requests, then no need to quiesce queue which may add long boot

	 * latency, especially when lots of disks are involved.

/*

 * switch to new_e io scheduler. be careful not to introduce deadlocks -

 * we don't free the old io scheduler, before we have allocated what we

 * need for the new one. this way we have a chance of going back to the old

 * one, if the new one fails init for some reason.

/*

 * Switch this queue to the given IO scheduler.

 Make sure queue is not in the middle of being removed */

	/*

	 * Special case for mq, turn off scheduling

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (c) 2017 Sagi Grimberg.

/**

 * blk_mq_rdma_map_queues - provide a default queue mapping for rdma device

 * @map:	CPU to hardware queue map.

 * @dev:	rdma device to provide a mapping for.

 * @first_vec:	first interrupt vectors to use for queues (usually 0)

 *

 * This function assumes the rdma device @dev has at least as many available

 * interrupt vetors as @set has queues.  It will then query it's affinity mask

 * and built queue mapping that maps a queue to the CPUs that have irq affinity

 * for the corresponding vector.

 *

 * In case either the driver passed a @dev with less vectors than

 * @set->nr_hw_queues, or @dev does not provide an affinity mask for a

 * vector, we fallback to the naive mapping.

 SPDX-License-Identifier: GPL-2.0

/*

 * Common Block IO controller cgroup interface

 *

 * Based on ideas and code from CFQ, CFS and BFQ:

 * Copyright (C) 2003 Jens Axboe <axboe@kernel.dk>

 *

 * Copyright (C) 2008 Fabio Checconi <fabio@gandalf.sssup.it>

 *		      Paolo Valente <paolo.valente@unimore.it>

 *

 * Copyright (C) 2009 Vivek Goyal <vgoyal@redhat.com>

 * 	              Nauman Rafique <nauman@google.com>

 *

 * For policy-specific per-blkcg data:

 * Copyright (C) 2015 Paolo Valente <paolo.valente@unimore.it>

 *                    Arianna Avanzini <avanzini.arianna@gmail.com>

/*

 * blkcg_pol_mutex protects blkcg_policy[] and policy [de]activation.

 * blkcg_pol_register_mutex nests outside of it and synchronizes entire

 * policy [un]register operations including cgroup file additions /

 * removals.  Putting cgroup file registration outside blkcg_pol_mutex

 * allows grabbing it from cgroup callbacks.

 protected by blkcg_pol_mutex */

/**

 * blkg_free - free a blkg

 * @blkg: blkg to free

 *

 * Free @blkg which may be partially allocated.

 release the blkcg and parent blkg refs this blkg has been holding */

/*

 * A group is RCU protected, but having an rcu lock does not mean that one

 * can access all the fields of blkg and assume these are valid.  For

 * example, don't try to follow throtl_data and request queue links.

 *

 * Having a reference to blkg under an rcu allows accesses to only values

 * local to groups like group stats and group rate limits.

 as long as there are pending bios, @blkg can't go away */

 start plug only when bio_list contains at least 2 bios */

/**

 * blkg_alloc - allocate a blkg

 * @blkcg: block cgroup the new blkg is associated with

 * @q: request_queue the new blkg is associated with

 * @gfp_mask: allocation mask to use

 *

 * Allocate a new blkg assocating @blkcg and @q.

 alloc and init base part */

 alloc per-policy data and attach it to blkg */

	/*

	 * Hint didn't match.  Look up from the radix tree.  Note that the

	 * hint can only be updated under queue_lock as otherwise @blkg

	 * could have already been removed from blkg_tree.  The caller is

	 * responsible for grabbing queue_lock if @update_hint.

/*

 * If @new_blkg is %NULL, this function tries to allocate a new one as

 * necessary using %GFP_NOWAIT.  @new_blkg is always consumed on return.

 request_queue is dying, do not create/recreate a blkg */

 blkg holds a reference to blkcg */

 allocate */

 link parent */

 invoke per-policy init */

 insert */

 @blkg failed fully initialized, use the usual release path */

/**

 * blkg_lookup_create - lookup blkg, try to create one if not there

 * @blkcg: blkcg of interest

 * @q: request_queue of interest

 *

 * Lookup blkg for the @blkcg - @q pair.  If it doesn't exist, try to

 * create one.  blkg creation is performed recursively from blkcg_root such

 * that all non-root blkg's have access to the parent blkg.  This function

 * should be called under RCU read lock and takes @q->queue_lock.

 *

 * Returns the blkg or the closest blkg if blkg_create() fails as it walks

 * down from root.

	/*

	 * Create blkgs walking down from blkcg_root to @blkcg, so that all

	 * non-root blkgs have access to their parents.  Returns the closest

	 * blkg to the intended blkg should blkg_create() fail.

 remember closest blkg */

 Something wrong if we are trying to remove same group twice */

	/*

	 * Both setting lookup hint to and clearing it from @blkg are done

	 * under queue_lock.  If it's not pointing to @blkg now, it never

	 * will.  Hint assignment itself can race safely.

	/*

	 * Put the reference taken at the time of creation so that when all

	 * queues are gone, group can be destroyed.

/**

 * blkg_destroy_all - destroy all blkgs associated with a request_queue

 * @q: request_queue of interest

 *

 * Destroy all blkgs associated with @q.

		/*

		 * in order to avoid holding the spin lock for too long, release

		 * it when a batch of blkgs are destroyed.

	/*

	 * Note that stat reset is racy - it doesn't synchronize against

	 * stat updates.  This is a debug feature which shouldn't exist

	 * anyway.  If you get hit by a race, retry.

/**

 * blkcg_print_blkgs - helper for printing per-blkg data

 * @sf: seq_file to print to

 * @blkcg: blkcg of interest

 * @prfill: fill function to print out a blkg

 * @pol: policy in question

 * @data: data to be passed to @prfill

 * @show_total: to print out sum of prfill return values or not

 *

 * This function invokes @prfill on each blkg of @blkcg if pd for the

 * policy specified by @pol exists.  @prfill is invoked with @sf, the

 * policy data and @data and the matching queue lock held.  If @show_total

 * is %true, the sum of the return values from @prfill is printed with

 * "Total" label at the end.

 *

 * This is to be used to construct print functions for

 * cftype->read_seq_string method.

/**

 * __blkg_prfill_u64 - prfill helper for a single u64 value

 * @sf: seq_file to print to

 * @pd: policy private data of interest

 * @v: value to print

 *

 * Print @v to @sf for the device assocaited with @pd.

 Performs queue bypass and policy enabled checks then looks up blkg. */

 update_hint */);

/**

 * blkcg_conf_open_bdev - parse and open bdev for per-blkg config update

 * @inputp: input string pointer

 *

 * Parse the device node prefix part, MAJ:MIN, of per-blkg config update

 * from @input and get and return the matching bdev.  *@inputp is

 * updated to point past the device node prefix.  Returns an ERR_PTR()

 * value on error.

 *

 * Use this function iff blkg_conf_prep() can't be used for some reason.

/**

 * blkg_conf_prep - parse and prepare for per-blkg config update

 * @blkcg: target block cgroup

 * @pol: target policy

 * @input: input string

 * @ctx: blkg_conf_ctx to be filled

 *

 * Parse per-blkg config update from @input and initialize @ctx with the

 * result.  @ctx->blkg points to the blkg to be updated and @ctx->body the

 * part of @input following MAJ:MIN.  This function returns with RCU read

 * lock and queue lock held and must be paired with blkg_conf_finish().

	/*

	 * blkcg_deactivate_policy() requires queue to be frozen, we can grab

	 * q_usage_counter to prevent concurrent with blkcg_deactivate_policy().

	/*

	 * Create blkgs walking down from blkcg_root to @blkcg, so that all

	 * non-root blkgs have access to their parents.

 Drop locks to do new blkg allocation with GFP_KERNEL. */

	/*

	 * If queue was bypassing, we should retry.  Do so after a

	 * short msleep().  It isn't strictly necessary but queue

	 * can be bypassing for some time and it's always nice to

	 * avoid busy looping.

/**

 * blkg_conf_finish - finish up per-blkg config update

 * @ctx: blkg_conf_ctx intiailized by blkg_conf_prep()

 *

 * Finish up after per-blkg config update.  This function must be paired

 * with blkg_conf_prep().

 Root-level stats are sourced from system-wide IO stats */

 fetch the current per-cpu values */

 propagate percpu delta to global */

 propagate global delta to parent (unless that's root) */

/*

 * We source root cgroup stats from the system-wide stats to avoid

 * tracking the same information twice and incurring overhead when no

 * cgroups are defined. For that reason, cgroup_rstat_flush in

 * blkcg_print_stat does not actually fill out the iostat in the root

 * cgroup's blkcg_gq.

 *

 * However, we would like to re-use the printing code between the root and

 * non-root cgroups to the extent possible. For that reason, we simulate

 * flushing the root cgroup's stats by explicitly filling in the iostat

 * with disk level statistics.

 convert sectors to bytes

 terminate */

 terminate */

/*

 * blkcg destruction is a three-stage process.

 *

 * 1. Destruction starts.  The blkcg_css_offline() callback is invoked

 *    which offlines writeback.  Here we tie the next stage of blkg destruction

 *    to the completion of writeback associated with the blkcg.  This lets us

 *    avoid punting potentially large amounts of outstanding writeback to root

 *    while maintaining any ongoing policies.  The next stage is triggered when

 *    the nr_cgwbs count goes to zero.

 *

 * 2. When the nr_cgwbs count goes to zero, blkcg_destroy_blkgs() is called

 *    and handles the destruction of blkgs.  Here the css reference held by

 *    the blkg is put back eventually allowing blkcg_css_free() to be called.

 *    This work may occur in cgwb_release_workfn() on the cgwb_release

 *    workqueue.  Any submitted ios that fail to get the blkg ref will be

 *    punted to the root_blkg.

 *

 * 3. Once the blkcg ref count goes to zero, blkcg_css_free() is called.

 *    This finally frees the blkcg.

/**

 * blkcg_css_offline - cgroup css_offline callback

 * @css: css of interest

 *

 * This function is called when @css is about to go away.  Here the cgwbs are

 * offlined first and only once writeback associated with the blkcg has

 * finished do we start step 2 (see above).

 this prevents anyone from attaching or migrating to this blkcg */

 put the base online pin allowing step 2 to be triggered */

/**

 * blkcg_destroy_blkgs - responsible for shooting down blkgs

 * @blkcg: blkcg of interest

 *

 * blkgs should be removed while holding both q and blkcg locks.  As blkcg lock

 * is nested inside q lock, this function performs reverse double lock dancing.

 * Destroying the blkgs releases the reference held on the blkcg's css allowing

 * blkcg_css_free to eventually be called.

 *

 * This is the blkcg counterpart of ioc_release_fn().

			/*

			 * Given that the system can accumulate a huge number

			 * of blkgs in pathological cases, check to see if we

			 * need to rescheduling to avoid softlockup.

		/*

		 * If the policy hasn't been attached yet, wait for it

		 * to be attached before doing anything else. Otherwise,

		 * check if the policy requires any specific per-cgroup

		 * data: if it does, allocate and initialize it.

	/*

	 * blkcg_pin_online() is used to delay blkcg offline so that blkgs

	 * don't go offline while cgwbs are still active on them.  Pin the

	 * parent so that offline always happens towards the root.

/**

 * blkcg_init_queue - initialize blkcg part of request queue

 * @q: request_queue to initialize

 *

 * Called from blk_alloc_queue(). Responsible for initializing blkcg

 * part of new request_queue @q.

 *

 * RETURNS:

 * 0 on success, -errno on failure.

 Make sure the root blkg exists. */

/**

 * blkcg_exit_queue - exit and release blkcg part of request_queue

 * @q: request_queue being released

 *

 * Called from blk_exit_queue().  Responsible for exiting blkcg part.

	/*

	 * This ensures that, if available, memcg is automatically enabled

	 * together on the default hierarchy so that the owner cgroup can

	 * be retrieved from writeback pages.

/**

 * blkcg_activate_policy - activate a blkcg policy on a request_queue

 * @q: request_queue of interest

 * @pol: blkcg policy to activate

 *

 * Activate @pol on @q.  Requires %GFP_KERNEL context.  @q goes through

 * bypass mode to populate its blkgs with policy_data for @pol.

 *

 * Activation happens with @q bypassed, so nobody would be accessing blkgs

 * from IO path.  Update of each blkg is protected by both queue and blkcg

 * locks so that holding either lock and testing blkcg_policy_enabled() is

 * always enough for dereferencing policy data.

 *

 * The caller is responsible for synchronizing [de]activations and policy

 * [un]registerations.  Returns 0 on success, -errno on failure.

 blkg_list is pushed at the head, reverse walk to allocate parents first */

 If prealloc matches, use it; otherwise try GFP_NOWAIT */

			/*

			 * GFP_NOWAIT failed.  Free the existing one and

			 * prealloc for @blkg w/ GFP_KERNEL.

 all allocated, init in the same order */

 alloc failed, nothing's initialized yet, free everything */

/**

 * blkcg_deactivate_policy - deactivate a blkcg policy on a request_queue

 * @q: request_queue of interest

 * @pol: blkcg policy to deactivate

 *

 * Deactivate @pol on @q.  Follows the same synchronization rules as

 * blkcg_activate_policy().

/**

 * blkcg_policy_register - register a blkcg policy

 * @pol: blkcg policy to register

 *

 * Register @pol with blkcg core.  Might sleep and @pol may be modified on

 * successful registration.  Returns 0 on success and -errno on failure.

 find an empty slot */

 Make sure cpd/pd_alloc_fn and cpd/pd_free_fn in pairs */

 register @pol */

 allocate and install cpd's */

 everything is in place, add intf files for the new policy */

/**

 * blkcg_policy_unregister - unregister a blkcg policy

 * @pol: blkcg policy to unregister

 *

 * Undo blkcg_policy_register(@pol).  Might sleep.

 kill the intf files first */

 remove cpds and unregister */

 consume the flag first */

 never bounce for the root cgroup */

/*

 * Scale the accumulated delay based on how long it has been since we updated

 * the delay.  We only call this when we are adding delay, in case it's been a

 * while since we added delay, and when we are checking to see if we need to

 * delay a task, to account for any delays that may have occurred.

 negative use_delay means no scaling, see blkcg_set_delay() */

	/*

	 * We only want to scale down every second.  The idea here is that we

	 * want to delay people for min(delay_nsec, NSEC_PER_SEC) in a certain

	 * time window.  We only want to throttle tasks for recent delay that

	 * has occurred, in 1 second time windows since that's the maximum

	 * things can be throttled.  We save the current delay window in

	 * blkg->last_delay so we know what amount is still left to be charged

	 * to the blkg from this point onward.  blkg->last_use keeps track of

	 * the use_delay counter.  The idea is if we're unthrottling the blkg we

	 * are ok with whatever is happening now, and we can take away more of

	 * the accumulated delay as we've already throttled enough that

	 * everybody is happy with their IO latencies.

		/*

		 * We've been unthrottled, subtract a larger chunk of our

		 * accumulated delay.

		/*

		 * This shouldn't happen, but handle it anyway.  Our delay_nsec

		 * should only ever be growing except here where we subtract out

		 * min(last_delay, 1 second), but lord knows bugs happen and I'd

		 * rather not end up with negative numbers.

/*

 * This is called when we want to actually walk up the hierarchy and check to

 * see if we need to throttle, and then actually throttle if there is some

 * accumulated delay.  This should only be called upon return to user space so

 * we're not holding some lock that would induce a priority inversion.

	/*

	 * Let's not sleep for all eternity if we've amassed a huge delay.

	 * Swapping or metadata IO can accumulate 10's of seconds worth of

	 * delay, and we want userspace to be able to do _something_ so cap the

	 * delays at 0.25s. If there's 10's of seconds worth of delay then the

	 * tasks will be delayed for 0.25 second for every syscall. If

	 * blkcg_set_delay() was used as indicated by negative use_delay, the

	 * caller is responsible for regulating the range.

/**

 * blkcg_maybe_throttle_current - throttle the current task if it has been marked

 *

 * This is only called if we've been marked with set_notify_resume().  Obviously

 * we can be set_notify_resume() for reasons other than blkcg throttling, so we

 * check to see if current->throttle_queue is set and if not this doesn't do

 * anything.  This should only ever be called by the resume code, it's not meant

 * to be called by people willy-nilly as it will actually do the work to

 * throttle the task if it is setup for throttling.

/**

 * blkcg_schedule_throttle - this task needs to check for throttling

 * @q: the request queue IO was submitted on

 * @use_memdelay: do we charge this to memory delay for PSI

 *

 * This is called by the IO controller when we know there's delay accumulated

 * for the blkg for this task.  We do not pass the blkg because there are places

 * we call this that may not have that information, the swapping code for

 * instance will only have a request_queue at that point.  This set's the

 * notify_resume for the task to check and see if it requires throttling before

 * returning to user space.

 *

 * We will only schedule once per syscall.  You can call this over and over

 * again and it will only do the check once upon return to user space, and only

 * throttle once.  If the task needs to be throttled again it'll need to be

 * re-set at the next time we see the task.

/**

 * blkcg_add_delay - add delay to this blkg

 * @blkg: blkg of interest

 * @now: the current time in nanoseconds

 * @delta: how many nanoseconds of delay to add

 *

 * Charge @delta to the blkg's current delay accumulation.  This is used to

 * throttle tasks if an IO controller thinks we need more throttling.

/**

 * blkg_tryget_closest - try and get a blkg ref on the closet blkg

 * @bio: target bio

 * @css: target css

 *

 * As the failure mode here is to walk up the blkg tree, this ensure that the

 * blkg->parent pointers are always valid.  This returns the blkg that it ended

 * up taking a reference on or %NULL if no reference was taken.

/**

 * bio_associate_blkg_from_css - associate a bio with a specified css

 * @bio: target bio

 * @css: target css

 *

 * Associate @bio with the blkg found by combining the css's blkg and the

 * request_queue of the @bio.  An association failure is handled by walking up

 * the blkg tree.  Therefore, the blkg associated can be anything between @blkg

 * and q->root_blkg.  This situation only happens when a cgroup is dying and

 * then the remaining bios will spill to the closest alive blkg.

 *

 * A reference will be taken on the blkg and will be released when @bio is

 * freed.

/**

 * bio_associate_blkg - associate a bio with a blkg

 * @bio: target bio

 *

 * Associate @bio with the blkg found from the bio's css and request_queue.

 * If one is not found, bio_lookup_blkg() creates the blkg.  If a blkg is

 * already associated, the css is reused and association redone as the

 * request_queue may have changed.

/**

 * bio_clone_blkg_association - clone blkg association from src to dst bio

 * @dst: destination bio

 * @src: source bio

	/*

	 * If the bio is flagged with BIO_CGROUP_ACCT it means this is a split

	 * bio and we would have already accounted for the size of the bio.

 SPDX-License-Identifier: GPL-2.0

/*

 * blk-mq scheduling framework

 *

 * Copyright (C) 2016 Jens Axboe

	/*

	 * May not have an IO context if it's a passthrough request

/*

 * Mark a hardware queue as needing a restart. For shared queues, maintain

 * a count of how many hardware queues are marked for restart.

	/*

	 * Order clearing SCHED_RESTART and list_empty_careful(&hctx->dispatch)

	 * in blk_mq_run_hw_queue(). Its pair is the barrier in

	 * blk_mq_dispatch_rq_list(). So dispatch code won't see SCHED_RESTART,

	 * meantime new request added to hctx->dispatch is missed to check in

	 * blk_mq_run_hw_queue().

 ms units */

/*

 * Only SCSI implements .get_budget and .put_budget, and SCSI restarts

 * its queue by itself in its completion handler, so we don't need to

 * restart queue if .get_budget() returns BLK_STS_NO_RESOURCE.

 *

 * Returns -EAGAIN if hctx->dispatch was found non-empty and run_work has to

 * be run again.  This is necessary to avoid starving flushes.

			/*

			 * We're releasing without dispatching. Holding the

			 * budget could have blocked any "hctx"s with the

			 * same queue and if we didn't dispatch then there's

			 * no guarantee anyone will kick the queue.  Kick it

			 * ourselves.

		/*

		 * Now this rq owns the budget which has to be released

		 * if this rq won't be queued to driver via .queue_rq()

		 * in blk_mq_dispatch_rq_list().

		/*

		 * If we cannot get tag for the request, stop dequeueing

		 * requests from the IO scheduler. We are unlikely to be able

		 * to submit them anyway and it creates false impression for

		 * scheduling heuristics that the device can take more IO.

		/*

		 * Requests from different hctx may be dequeued from some

		 * schedulers, such as bfq and deadline.

		 *

		 * Sort the requests in the list according to their hctx,

		 * dispatch batching requests from same hctx at a time.

/*

 * Only SCSI implements .get_budget and .put_budget, and SCSI restarts

 * its queue by itself in its completion handler, so we don't need to

 * restart queue if .get_budget() returns BLK_STS_NO_RESOURCE.

 *

 * Returns -EAGAIN if hctx->dispatch was found non-empty and run_work has to

 * be run again.  This is necessary to avoid starving flushes.

			/*

			 * We're releasing without dispatching. Holding the

			 * budget could have blocked any "hctx"s with the

			 * same queue and if we didn't dispatch then there's

			 * no guarantee anyone will kick the queue.  Kick it

			 * ourselves.

		/*

		 * Now this rq owns the budget which has to be released

		 * if this rq won't be queued to driver via .queue_rq()

		 * in blk_mq_dispatch_rq_list().

 round robin for fair dispatch */

	/*

	 * If we have previous entries on our dispatch list, grab them first for

	 * more fair dispatch.

	/*

	 * Only ask the scheduler for requests, if we didn't have residual

	 * requests from the dispatch list. This is to avoid the case where

	 * we only ever dispatch a fraction of the requests available because

	 * of low device queue depth. Once we pull requests out of the IO

	 * scheduler, we can no longer merge or sort them. So it's best to

	 * leave them there for as long as we can. Mark the hw queue as

	 * needing a restart in that case.

	 *

	 * We want to dispatch from the scheduler if there was nothing

	 * on the dispatch list or we were able to dispatch from the

	 * dispatch list.

 dequeue request one by one from sw queue if queue is busy */

 RCU or SRCU read lock is needed before checking quiesced flag */

	/*

	 * A return of -EAGAIN is an indication that hctx->dispatch is not

	 * empty and we must run again in order to avoid starving flushes.

 default per sw-queue merge */

	/*

	 * Reverse check our software queue for entries that we could

	 * potentially merge with. Currently includes a hand-wavy stop

	 * count of 8, to not spend too much time checking for merges.

	/*

	 * dispatch flush and passthrough rq directly

	 *

	 * passthrough request has to be added to hctx->dispatch directly.

	 * For some reason, device may be in one situation which can't

	 * handle FS request, so STS_RESOURCE is always returned and the

	 * FS request will be added to hctx->dispatch. However passthrough

	 * request may be required at that time for fixing the problem. If

	 * passthrough request is added to scheduler queue, there isn't any

	 * chance to dispatch it given we prioritize requests in hctx->dispatch.

		/*

		 * Firstly normal IO request is inserted to scheduler queue or

		 * sw queue, meantime we add flush request to dispatch queue(

		 * hctx->dispatch) directly and there is at most one in-flight

		 * flush request for each hw queue, so it doesn't matter to add

		 * flush request to tail or front of the dispatch queue.

		 *

		 * Secondly in case of NCQ, flush request belongs to non-NCQ

		 * command, and queueing it will fail when there is any

		 * in-flight normal IO request(NCQ command). When adding flush

		 * rq to the front of hctx->dispatch, it is easier to introduce

		 * extra time to flush rq's latency because of S_SCHED_RESTART

		 * compared with adding to the tail of dispatch queue, then

		 * chance of flush merge is increased, and less flush requests

		 * will be issued to controller. It is observed that ~10% time

		 * is saved in blktests block/004 on disk attached to AHCI/NCQ

		 * drive when adding flush rq to the front of hctx->dispatch.

		 *

		 * Simply queue flush rq to the front of hctx->dispatch so that

		 * intensive flush workloads can benefit in case of NCQ HW.

	/*

	 * blk_mq_sched_insert_requests() is called from flush plug

	 * context only, and hold one usage counter to prevent queue

	 * from being released.

		/*

		 * try to issue requests directly if the hw queue isn't

		 * busy in case of 'none' scheduler, and this way may save

		 * us one extra enqueue & dequeue to sw queue.

 called in queue's release handler, tagset has gone away */

	/*

	 * Set initial depth at max so that we don't need to reallocate for

	 * updating nr_requests.

	/*

	 * Default to double of smaller one between hw queue_depth and 128,

	 * since we don't split into sync/async like the old code did.

	 * Additionally, this is a per-hw queue depth.

/*

 * called in either blk_queue_cleanup or elevator_switch, tagset

 * is required for freeing requests

 SPDX-License-Identifier: GPL-2.0

/*

 * Block rq-qos base io controller

 *

 * This works similar to wbt with a few exceptions

 *

 * - It's bio based, so the latency covers the whole block layer in addition to

 *   the actual io.

 * - We will throttle all IO that comes in here if we need to.

 * - We use the mean latency over the 100ms window.  This is because writes can

 *   be particularly fast, which could give us a false sense of the impact of

 *   other workloads on our protected workload.

 * - By default there's no throttling, we set the queue_depth to UINT_MAX so

 *   that we can have as many outstanding bio's as we're allowed to.  Only at

 *   throttle time do we pay attention to the actual queue depth.

 *

 * The hierarchy works like the cpu controller does, we track the latency at

 * every configured node, and each configured node has it's own independent

 * queue depth.  This means that we only care about our latency targets at the

 * peer level.  Some group at the bottom of the hierarchy isn't going to affect

 * a group at the end of some other path if we're only configred at leaf level.

 *

 * Consider the following

 *

 *                   root blkg

 *             /                     \

 *        fast (target=5ms)     slow (target=10ms)

 *         /     \                  /        \

 *       a        b          normal(15ms)   unloved

 *

 * "a" and "b" have no target, but their combined io under "fast" cannot exceed

 * an average latency of 5ms.  If it does then we will throttle the "slow"

 * group.  In the case of "normal", if it exceeds its 15ms target, we will

 * throttle "unloved", but nobody else.

 *

 * In this example "fast", "slow", and "normal" will be the only groups actually

 * accounting their io latencies.  We have to walk up the heirarchy to the root

 * on every submit and complete so we can do the appropriate stat recording and

 * adjust the queue depth of ourselves if needed.

 *

 * There are 2 ways we throttle IO.

 *

 * 1) Queue depth throttling.  As we throttle down we will adjust the maximum

 * number of IO's we're allowed to have in flight.  This starts at (u64)-1 down

 * to 1.  If the group is only ever submitting IO for itself then this is the

 * only way we throttle.

 *

 * 2) Induced delay throttling.  This is for the case that a group is generating

 * IO that has to be issued by the root cg to avoid priority inversion. So think

 * REQ_META or REQ_SWAP.  If we are already at qd == 1 and we're getting a lot

 * of work done for us on behalf of the root cg and are being asked to scale

 * down more then we induce a latency at userspace return.  We accumulate the

 * total amount of time we need to be punished by doing

 *

 * total_time += min_lat_nsec - actual_io_completion

 *

 * and then at throttle time will do

 *

 * throttle_time = min(total_time, NSEC_PER_SEC)

 *

 * This induced delay will throttle back the activity that is generating the

 * root cg issued io's, wethere that's some metadata intensive operation or the

 * group is using so much memory that it is pushing us into swap.

 *

 * Copyright (C) 2018 Josef Bacik

 Last time we adjusted the scale of everybody. */

 The latency that we missed. */

 Total io's from all of our children for the last summation. */

 The guy who actually changed the latency numbers. */

 Cookie to tell if we need to scale up or down. */

 total running average of our io latency. */

 Our current number of IO's for the last summation. */

/*

 * These are the constants used to fake the fixed-point moving average

 * calculation just like load average.  The call to calc_load() folds

 * (FIXED_1 (2048) - exp_factor) * new_sample into lat_avg.  The sampling

 * window size is bucketed to try to approximately calculate average

 * latency such that 1/exp (decay rate) is [1 min, 2.5 min) when windows

 * elapse immediately.  Note, windows only elapse with IO activity.  Idle

 * periods extend the most recent window.

 exp(1/600) - 600 samples

 exp(1/240) - 240 samples

 exp(1/120) - 120 samples

 exp(1/80)  - 80 samples

 exp(1/60)  - 60 samples

	/*

	 * calc_load() takes in a number stored in fixed point representation.

	 * Because we are using this for IO time in ns, the values stored

	 * are significantly larger than the FIXED_1 denominator (2048).

	 * Therefore, rounding errors in the calculation are negligible and

	 * can be ignored.

	/*

	 * To avoid priority inversions we want to just take a slot if we are

	 * issuing as root.  If we're being killed off there's no point in

	 * delaying things, we may have been killed by OOM so throttling may

	 * make recovery take even longer, so just let the IO's through so the

	 * task can go away.

/*

 * We scale the qd down faster than we scale up, so we need to use this helper

 * to adjust the scale_cookie accordingly so we don't prematurely get

 * scale_cookie at DEFAULT_SCALE_COOKIE and unthrottle too much.

 *

 * Each group has their own local copy of the last scale cookie they saw, so if

 * the global scale cookie goes up or down they know which way they need to go

 * based on their last knowledge of it.

		/*

		 * We don't want to dig a hole so deep that it takes us hours to

		 * dig out of it.  Just enough that we don't throttle/unthrottle

		 * with jagged workloads but can still unthrottle once pressure

		 * has sufficiently dissipated.

/*

 * Change the queue depth of the iolatency_grp.  We add/subtract 1/16th of the

 * queue depth at a time so we don't get wild swings and hopefully dial in to

 * fairer distribution of the overall queue depth.

 Check our parent and see if the scale cookie has changed. */

 Somebody beat us to the punch, just bail. */

		/*

		 * Sometimes high priority groups are their own worst enemy, so

		 * instead of taking it out on some poor other group that did 5%

		 * or less of the IO's for the last summation just skip this

		 * scale down event.

 We're as low as we can go. */

 We're back to the default cookie, unthrottle all the things. */

	/*

	 * Have to do this so we are truncated to the correct time that our

	 * issue is truncated to.

	/*

	 * We don't want to count issue_as_root bio's in the cgroups latency

	 * statistics as it could skew the numbers downwards.

 Everything is ok and we don't need to adjust the scale. */

 Somebody beat us to the punch, just bail. */

		/*

		 * If bi_status is BLK_STS_AGAIN, the bio wasn't actually

		 * submitted, so do not account for it.

		/*

		 * We could be exiting, don't access the pd unless we have a

		 * ref on the blkg.

		/*

		 * We scaled down but don't have a scale_grp, scale up and carry

		 * on.

		/*

		 * It's been 5 seconds since our last scale event, clear the

		 * scale grp in case the group that needed the scale down isn't

		 * doing any IO currently.

/*

 * return 1 for enabling iolatency, return -1 for disabling iolatency, otherwise

 * return 0.

 18446744073709551616 */

 Walk up the tree to see if our new val is lower than it should be. */

	/*

	 * We init things in list order, so the pd for the parent may not be

	 * init'ed yet for whatever reason.

/* SPDX-License-Identifier: GPL-2.0

 *

 * Legacy blkg rwstat helpers enabled by CONFIG_BLK_CGROUP_RWSTAT.

 * Do not use in new code.

/**

 * __blkg_prfill_rwstat - prfill helper for a blkg_rwstat

 * @sf: seq_file to print to

 * @pd: policy private data of interest

 * @rwstat: rwstat to print

 *

 * Print @rwstat to @sf for the device assocaited with @pd.

/**

 * blkg_prfill_rwstat - prfill callback for blkg_rwstat

 * @sf: seq_file to print to

 * @pd: policy private data of interest

 * @off: offset to the blkg_rwstat in @pd

 *

 * prfill callback for printing a blkg_rwstat.

/**

 * blkg_rwstat_recursive_sum - collect hierarchical blkg_rwstat

 * @blkg: blkg of interest

 * @pol: blkcg_policy which contains the blkg_rwstat

 * @off: offset to the blkg_rwstat in blkg_policy_data or @blkg

 * @sum: blkg_rwstat_sample structure containing the results

 *

 * Collect the blkg_rwstat specified by @blkg, @pol and @off and all its

 * online descendants and their aux counts.  The caller must be holding the

 * queue lock for online tests.

 *

 * If @pol is NULL, blkg_rwstat is at @off bytes into @blkg; otherwise, it

 * is at @off bytes into @blkg's blkg_policy_data of the policy.

 SPDX-License-Identifier: GPL-2.0

/*

 * Functions related to mapping data to requests

/**

 * bio_copy_from_iter - copy all pages from iov_iter to bio

 * @bio: The &struct bio which describes the I/O as destination

 * @iter: iov_iter as source

 *

 * Copy all pages from iov_iter to bio.

 * Returns 0 on success, or error on failure.

/**

 * bio_copy_to_iter - copy all pages from bio to iov_iter

 * @bio: The &struct bio which describes the I/O as source

 * @iter: iov_iter as destination

 *

 * Copy all pages from bio to iov_iter.

 * Returns 0 on success, or error on failure.

/**

 *	bio_uncopy_user	-	finish previously mapped bio

 *	@bio: bio being terminated

 *

 *	Free pages allocated from bio_copy_user_iov() and write back data

 *	to user space in case of a read.

		/*

		 * if we're in a workqueue, the request is orphaned, so

		 * don't copy into a random user address space, just free

		 * and return -EINTR so user space doesn't expect any data.

	/*

	 * We need to do a deep copy of the iov_iter including the iovecs.

	 * The caller provided iov might point to an on-stack or otherwise

	 * shortlived one.

	/*

	 * success

		/*

		 * release the pages we didn't map into the bio, if any

 couldn't stuff something into bio? */

/**

 *	bio_map_kern	-	map kernel address into bio

 *	@q: the struct request_queue for the bio

 *	@data: pointer to buffer to map

 *	@len: length in bytes

 *	@gfp_mask: allocation flags for bio allocation

 *

 *	Map the kernel address into a bio suitable for io to a block

 *	device. Returns an error pointer in case of error.

 we don't support partial mappings */

/**

 *	bio_copy_kern	-	copy kernel address into bio

 *	@q: the struct request_queue for the bio

 *	@data: pointer to buffer to copy

 *	@len: length in bytes

 *	@gfp_mask: allocation flags for bio and page allocation

 *	@reading: data direction is READ

 *

 *	copy the kernel address into a bio suitable for io to a block

 *	device. Returns an error pointer in case of error.

	/*

	 * Overflow, abort

/*

 * Append a bio to a passthrough request.  Only works if the bio can be merged

 * into the request based on the driver constraints.

/**

 * blk_rq_map_user_iov - map user data to a request, for passthrough requests

 * @q:		request queue where request should be inserted

 * @rq:		request to map data to

 * @map_data:   pointer to the rq_map_data holding pages (if necessary)

 * @iter:	iovec iterator

 * @gfp_mask:	memory allocation flags

 *

 * Description:

 *    Data will be mapped directly for zero copy I/O, if possible. Otherwise

 *    a kernel bounce buffer is used.

 *

 *    A matching blk_rq_unmap_user() must be issued at the end of I/O, while

 *    still in process context.

/**

 * blk_rq_unmap_user - unmap a request with user data

 * @bio:	       start of bio list

 *

 * Description:

 *    Unmap a rq previously mapped by blk_rq_map_user(). The caller must

 *    supply the original rq->bio from the blk_rq_map_user() return, since

 *    the I/O completion may have changed rq->bio.

/**

 * blk_rq_map_kern - map kernel data to a request, for passthrough requests

 * @q:		request queue where request should be inserted

 * @rq:		request to fill

 * @kbuf:	the kernel buffer

 * @len:	length of user data

 * @gfp_mask:	memory allocation flags

 *

 * Description:

 *    Data will be mapped directly if possible. Otherwise a bounce

 *    buffer is used. Can be called multiple times to append multiple

 *    buffers.

 SPDX-License-Identifier: GPL-2.0

/*

 *  Block device concurrent positioning ranges.

 *

 *  Copyright (C) 2021 Western Digital Corporation or its Affiliates.

/*

 * Independent access range entries are not freed individually, but alltogether

 * with struct blk_independent_access_ranges and its array of ranges. Since

 * kobject_add() takes a reference on the parent kobject contained in

 * struct blk_independent_access_ranges, the array of independent access range

 * entries cannot be freed until kobject_del() is called for all entries.

 * So we do not need to do anything here, but still need this no-op release

 * operation to avoid complaints from the kobject code.

/*

 * This will be executed only after all independent access range entries are

 * removed with kobject_del(), at which point, it is safe to free everything,

 * including the array of ranges.

/**

 * disk_register_independent_access_ranges - register with sysfs a set of

 *		independent access ranges

 * @disk:	Target disk

 * @new_iars:	New set of independent access ranges

 *

 * Register with sysfs a set of independent access ranges for @disk.

 * If @new_iars is not NULL, this set of ranges is registered and the old set

 * specified by q->ia_ranges is unregistered. Otherwise, q->ia_ranges is

 * registered if it is not already.

 If a new range set is specified, unregister the old one */

	/*

	 * At this point, iars is the new set of sector access ranges that needs

	 * to be registered with sysfs.

	/*

	 * While sorting the ranges in increasing LBA order, check that the

	 * ranges do not overlap, that there are no sector holes and that all

	 * sectors belong to one range.

/**

 * disk_alloc_independent_access_ranges - Allocate an independent access ranges

 *                                        data structure

 * @disk:		target disk

 * @nr_ia_ranges:	Number of independent access ranges

 *

 * Allocate a struct blk_independent_access_ranges structure with @nr_ia_ranges

 * access range descriptors.

/**

 * disk_set_independent_access_ranges - Set a disk independent access ranges

 * @disk:	target disk

 * @iars:	independent access ranges structure

 *

 * Set the independent access ranges information of the request queue

 * of @disk to @iars. If @iars is NULL and the independent access ranges

 * structure already set is cleared. If there are no differences between

 * @iars and the independent access ranges structure already set, @iars

 * is freed.

	/*

	 * This may be called for a registered queue. E.g. during a device

	 * revalidation. If that is the case, we need to unregister the old

	 * set of independent access ranges and register the new set. If the

	 * queue is not registered, registration of the device request queue

	 * will register the independent access ranges, so only swap in the

	 * new set and free the old one.

 SPDX-License-Identifier: GPL-2.0-or-later

/*

 * cgroups support for the BFQ I/O scheduler.

/**

 * bfq_stat_add - add a value to a bfq_stat

 * @stat: target bfq_stat

 * @val: value to add

 *

 * Add @val to @stat.  The caller must ensure that IRQ on the same CPU

 * don't re-enter this function for the same counter.

/**

 * bfq_stat_read - read the current value of a bfq_stat

 * @stat: bfq_stat to read

/**

 * bfq_stat_reset - reset a bfq_stat

 * @stat: bfq_stat to reset

/**

 * bfq_stat_add_aux - add a bfq_stat into another's aux count

 * @to: the destination bfq_stat

 * @from: the source

 *

 * Add @from's count including the aux one to @to's aux count.

/**

 * blkg_prfill_stat - prfill callback for bfq_stat

 * @sf: seq_file to print to

 * @pd: policy private data of interest

 * @off: offset to the bfq_stat in @pd

 *

 * prfill callback for printing a bfq_stat.

 bfqg stats flags */

 This should be called with the scheduler lock held. */

 This should be called with the scheduler lock held. */

 This should be called with the scheduler lock held. */

	/*

	 * group is already marked empty. This can happen if bfqq got new

	 * request in parent group and moved to this group while being added

	 * to service tree. Just ignore the event and move on.

 CONFIG_BFQ_CGROUP_DEBUG */

 CONFIG_BFQ_CGROUP_DEBUG */

/*

 * blk-cgroup policy-related handlers

 * The following functions help in converting between blk-cgroup

 * internal structures and BFQ-specific structures.

/*

 * bfq_group handlers

 * The following functions help in navigating the bfq_group hierarchy

 * by allowing to find the parent of a bfq_group or the bfq_group

 * associated to a bfq_queue.

/*

 * The following two functions handle get and put of a bfq_group by

 * wrapping the related blk-cgroup hooks.

 see comments in bfq_bic_update_cgroup for why refcounting bfqg */

 @stats = 0 */

 queued stats shouldn't be cleared */

 @to += @from */

 queued stats shouldn't be cleared */

/*

 * Transfer @bfqg's stats to its parent's aux counts so that the ancestors'

 * recursive stats can still account for the amount used by this bfqg after

 * it's gone.

 root_group */

		/*

		 * Make sure that bfqg and its associated blkg do not

		 * disappear before entity.

 NULL for root group */

 see comments in bfq_bic_update_cgroup for why refcounting */

	bfqg->my_entity = entity; /*

				   * the root_group's will be set to NULL

				   * in bfq_init_queue()

	/*

	 * Update chain of bfq_groups as we might be handling a leaf group

	 * which, along with some of its relatives, has not been hooked yet

	 * to the private hierarchy of BFQ.

/**

 * bfq_bfqq_move - migrate @bfqq to @bfqg.

 * @bfqd: queue descriptor.

 * @bfqq: the queue to move.

 * @bfqg: the group to move to.

 *

 * Move @bfqq to @bfqg, deactivating it from its old group and reactivating

 * it on the new one.  Avoid putting the entity on the old group idle tree.

 *

 * Must be called under the scheduler lock, to make sure that the blkg

 * owning @bfqg does not disappear (see comments in

 * bfq_bic_update_cgroup on guaranteeing the consistency of blkg

 * objects).

	/*

	 * Get extra reference to prevent bfqq from being freed in

	 * next possible expire or deactivate.

	/* If bfqq is empty, then bfq_bfqq_expire also invokes

	 * bfq_del_bfqq_busy, thereby removing bfqq and its entity

	 * from data structures related to current group. Otherwise we

	 * need to remove bfqq explicitly with bfq_deactivate_bfqq, as

	 * we do below.

 pin down bfqg and its associated blkg  */

 release extra ref taken above, bfqq may happen to be freed now */

/**

 * __bfq_bic_change_cgroup - move @bic to @cgroup.

 * @bfqd: the queue descriptor.

 * @bic: the bic to move.

 * @blkcg: the blk-cgroup to move to.

 *

 * Move bic to blkcg, assuming that bfqd->lock is held; which makes

 * sure that the reference to cgroup is valid across the call (see

 * comments in bfq_bic_update_cgroup on this issue)

 *

 * NOTE: an alternative approach might have been to store the current

 * cgroup in bfqq and getting a reference to it, reducing the lookup

 * time here, at the price of slightly more complex code.

	/*

	 * Check whether blkcg has changed.  The condition may trigger

	 * spuriously on a newly created cic but there's no harm.

	/*

	 * Update blkg_path for bfq_log_* functions. We cache this

	 * path, and update it here, for the following

	 * reasons. Operations on blkg objects in blk-cgroup are

	 * protected with the request_queue lock, and not with the

	 * lock that protects the instances of this scheduler

	 * (bfqd->lock). This exposes BFQ to the following sort of

	 * race.

	 *

	 * The blkg_lookup performed in bfq_get_queue, protected

	 * through rcu, may happen to return the address of a copy of

	 * the original blkg. If this is the case, then the

	 * bfqg_and_blkg_get performed in bfq_get_queue, to pin down

	 * the blkg, is useless: it does not prevent blk-cgroup code

	 * from destroying both the original blkg and all objects

	 * directly or indirectly referred by the copy of the

	 * blkg.

	 *

	 * On the bright side, destroy operations on a blkg invoke, as

	 * a first step, hooks of the scheduler associated with the

	 * blkg. And these hooks are executed with bfqd->lock held for

	 * BFQ. As a consequence, for any blkg associated with the

	 * request queue this instance of the scheduler is attached

	 * to, we are guaranteed that such a blkg is not destroyed, and

	 * that all the pointers it contains are consistent, while we

	 * are holding bfqd->lock. A blkg_lookup performed with

	 * bfqd->lock held then returns a fully consistent blkg, which

	 * remains consistent until this lock is held.

	 *

	 * Thanks to the last fact, and to the fact that: (1) bfqg has

	 * been obtained through a blkg_lookup in the above

	 * assignment, and (2) bfqd->lock is being held, here we can

	 * safely use the policy data for the involved blkg (i.e., the

	 * field bfqg->pd) to get to the blkg associated with bfqg,

	 * and then we can safely use any field of blkg. After we

	 * release bfqd->lock, even just getting blkg through this

	 * bfqg may cause dangling references to be traversed, as

	 * bfqg->pd may not exist any more.

	 *

	 * In view of the above facts, here we cache, in the bfqg, any

	 * blkg data we may need for this bic, and for its associated

	 * bfq_queue. As of now, we need to cache only the path of the

	 * blkg, which is used in the bfq_log_* functions.

	 *

	 * Finally, note that bfqg itself needs to be protected from

	 * destruction on the blkg_free of the original blkg (which

	 * invokes bfq_pd_free). We use an additional private

	 * refcounter for bfqg, to let it disappear only after no

	 * bfq_queue refers to it any longer.

/**

 * bfq_flush_idle_tree - deactivate any entity on the idle tree of @st.

 * @st: the service tree being flushed.

/**

 * bfq_reparent_leaf_entity - move leaf entity to the root_group.

 * @bfqd: the device data structure with the root group.

 * @entity: the entity to move, if entity is a leaf; or the parent entity

 *	    of an active leaf entity to move, if entity is not a leaf.

 leaf not reached yet */

/**

 * bfq_reparent_active_queues - move to the root group all active queues.

 * @bfqd: the device data structure with the root group.

 * @bfqg: the group to move from.

 * @st: the service tree to start the search from.

/**

 * bfq_pd_offline - deactivate the entity associated with @pd,

 *		    and reparent its children entities.

 * @pd: descriptor of the policy going offline.

 *

 * blkio already grabs the queue_lock for us, so no need to use

 * RCU-based magic

 root group */

	/*

	 * Empty all service_trees belonging to this group before

	 * deactivating the group itself.

		/*

		 * It may happen that some queues are still active

		 * (busy) upon group destruction (if the corresponding

		 * processes have been forced to terminate). We move

		 * all the leaf entities corresponding to these queues

		 * to the root_group.

		 * Also, it may happen that the group has an entity

		 * in service, which is disconnected from the active

		 * tree: it must be moved, too.

		 * There is no need to put the sync queues, as the

		 * scheduler has taken no reference.

		/*

		 * The idle tree may still contain bfq_queues

		 * belonging to exited task because they never

		 * migrated to a different cgroup from the one being

		 * destroyed now. In addition, even

		 * bfq_reparent_active_queues() may happen to add some

		 * entities to the idle tree. It happens if, in some

		 * of the calls to bfq_bfqq_move() performed by

		 * bfq_reparent_active_queues(), the queue to move is

		 * empty and gets expired.

	/*

	 * @blkg is going offline and will be ignored by

	 * blkg_[rw]stat_recursive_sum().  Transfer stats to the parent so

	 * that they don't get lost.  If IOs complete after this point, the

	 * stats for them will be lost.  Oh well...

	/*

	 * Setting the prio_changed flag of the entity

	 * to 1 with new_weight == weight would re-set

	 * the value of the weight to its ioprio mapping.

	 * Set the flag only if necessary.

		/*

		 * Make sure that the above new value has been

		 * stored in bfqg->entity.new_weight before

		 * setting the prio_changed flag. In fact,

		 * this flag may be read asynchronously (in

		 * critical sections protected by a different

		 * lock than that held here), and finding this

		 * flag set may cause the execution of the code

		 * for updating parameters whose value may

		 * depend also on bfqg->entity.new_weight (in

		 * __bfq_entity_update_weight_prio).

		 * This barrier makes sure that the new value

		 * of bfqg->entity.new_weight is correctly

		 * seen in that code.

 require "default" on dfl */

 "WEIGHT" or "default WEIGHT" sets the default weight */

 print avg_queue_size */

 CONFIG_BFQ_CGROUP_DEBUG */

 statistics, covers only the tasks in the bfqg */

 CONFIG_BFQ_CGROUP_DEBUG */

 the same statistics which cover the bfqg and its descendants */

 CONFIG_BFQ_CGROUP_DEBUG */

 terminate */

 terminate */

 CONFIG_BFQ_GROUP_IOSCHED */

 CONFIG_BFQ_GROUP_IOSCHED */

 SPDX-License-Identifier: GPL-2.0

/*

 *  gendisk handling

 *

 * Portions Copyright (C) 2020 Christoph Hellwig

/*

 * Unique, monotonically increasing sequential number associated with block

 * devices instances (i.e. incremented each time a device is attached).

 * Associating uevents with block devices in userspace is difficult and racy:

 * the uevent netlink socket is lossy, and on slow and overloaded systems has

 * a very high latency.

 * Block devices do not have exclusive owners in userspace, any process can set

 * one up (e.g. loop devices). Moreover, device names can be reused (e.g. loop0

 * can be reused again and again).

 * A userspace process setting up a block device and watching for its events

 * cannot thus reliably tell whether an event relates to the device it just set

 * up or another earlier instance with the same name.

 * This sequential number allows userspace processes to solve this problem, and

 * uniquely associate an uevent to the lifetime to a device.

 for extended dynamic devt allocation, currently only one major is used */

/*

 * Set disk capacity and notify if the size is not currently zero and will not

 * be set to zero.  Returns true if a uevent was sent, otherwise false.

	/*

	 * Only print a message and send a uevent if the gendisk is user visible

	 * and alive.  This avoids spamming the log and udev when setting the

	 * initial capacity during probing.

	/*

	 * Historically we did not send a uevent for changes to/from an empty

	 * device.

/*

 * Format the device name of the indicated block device into the supplied buffer

 * and return a pointer to that same buffer for convenience.

 *

 * Note: do not use this in new code, use the %pg specifier to sprintf and

 * printk insted.

/*

 * Can be deleted altogether. Later.

 *

 index in the above - for now: assume no multimajor ranges */

 CONFIG_PROC_FS */

/**

 * __register_blkdev - register a new block device

 *

 * @major: the requested major device number [1..BLKDEV_MAJOR_MAX-1]. If

 *         @major = 0, try to allocate any unused major number.

 * @name: the name of the new block device as a zero terminated string

 * @probe: pre-devtmpfs / pre-udev callback used to create disks when their

 *	   pre-created device node is accessed. When a probe call uses

 *	   add_disk() and it fails the driver must cleanup resources. This

 *	   interface may soon be removed.

 *

 * The @name must be unique within the system.

 *

 * The return value depends on the @major input parameter:

 *

 *  - if a major device number was requested in range [1..BLKDEV_MAJOR_MAX-1]

 *    then the function returns zero on success, or a negative error code

 *  - if any unused major number was requested with @major = 0 parameter

 *    then the return value is the allocated major number in range

 *    [1..BLKDEV_MAJOR_MAX-1] or a negative error code otherwise

 *

 * See Documentation/admin-guide/devices.txt for the list of allocated

 * major numbers.

 *

 * Use register_blkdev instead for any new code.

 temporary */

/**

 * device_add_disk - add disk information to kernel list

 * @parent: parent device for the disk

 * @disk: per-device partitioning information

 * @groups: Additional per-device sysfs groups

 *

 * This function registers the partitioning information in @disk

 * with the kernel.

	/*

	 * The disk queue should now be all set with enough information about

	 * the device for the elevator code to pick an adequate default

	 * elevator if one is needed, that is, for devices requesting queue

	 * registration.

	/*

	 * If the driver provides an explicit major number it also must provide

	 * the number of minors numbers supported, and those will be used to

	 * setup the gendisk.

	 * Otherwise just allocate the device numbers for both the whole device

	 * and all partitions from the extended dev_t space.

 delay uevents, until we scanned partition table */

	/*

	 * avoid probable deadlock caused by allocating memory with

	 * GFP_KERNEL in runtime_resume callback of its all ancestor

	 * devices

		/*

		 * Don't let hidden disks show up in /proc/partitions,

		 * and don't bother scanning for partitions either.

		/*

		 * Announce the disk and partitions after all partitions are

		 * created. (for hidden disks uevents remain suppressed forever)

/**

 * del_gendisk - remove the gendisk

 * @disk: the struct gendisk to remove

 *

 * Removes the gendisk and all its associated resources. This deletes the

 * partitions associated with the gendisk, and unregisters the associated

 * request_queue.

 *

 * This is the counter to the respective __device_add_disk() call.

 *

 * The final removal of the struct gendisk happens when its refcount reaches 0

 * with put_disk(), which should be called after del_gendisk(), if

 * __device_add_disk() was used.

 *

 * Drivers exist which depend on the release of the gendisk to be synchronous,

 * it should not be deferred.

 *

 * Context: can sleep

	/*

	 * Fail any new I/O.

	/*

	 * Prevent new I/O from crossing bio_queue_enter().

		/*

		 * Unregister bdi before releasing device numbers (as they can

		 * get reused and we'd get clashes in sysfs).

	/*

	 * Allow using passthrough request again after the queue is torn down.

/**

 * invalidate_disk - invalidate the disk

 * @disk: the struct gendisk to invalidate

 *

 * A helper to invalidates the disk. It will clean the disk's associated

 * buffer/page caches and reset its internal states so that the disk

 * can be reused by the drivers.

 *

 * Context: can sleep

 sysfs access to bad-blocks list. */

 Make old-style 2.4 aliases work */

/*

 * print a full list of all partitions - intended for places where the root

 * filesystem can't be mounted and thus to give the victim some idea of what

 * went wrong

		/*

		 * Don't show empty devices or things that have been

		 * suppressed

		/*

		 * Note, unlike /proc/partitions, I am showing the numbers in

		 * hex - the same format as the root= option takes.

 iterator */

 stop is called even after start failed :-( */

 Don't show non-partitionable removeable devices or empty devices */

 create top-level block dir */

 CONFIG_FAIL_MAKE_REQUEST */

/**

 * disk_release - releases all allocated resources of the gendisk

 * @dev: the device representing this disk

 *

 * This function releases all allocated resources of the gendisk.

 *

 * Drivers which used __device_add_disk() have a gendisk with a request_queue

 * assigned. Since the request_queue sits on top of the gendisk for these

 * drivers we also call blk_put_queue() for them, and we expect the

 * request_queue refcount to reach 0 at this point, and so the request_queue

 * will also be freed prior to the disk.

 *

 * Context: can sleep

 frees the disk */

/*

 * aggregate disk stat collector.  Uses the same stats that the sysfs

 * entries do, above, but makes them available through one seq_file.

 *

 * The output looks suspiciously like /proc/partitions with a bunch of

 * extra fields.

	/*

	if (&disk_to_dev(gp)->kobj.entry == block_class.devices.next)

		seq_puts(seqf,	"major minor name"

				"     rio rmerge rsect ruse wio wmerge "

				"wsect wuse running use aveq"

				"\n\n");

 CONFIG_PROC_FS */

			/* We need to return the right devno, even

			 * if the partition doesn't exist yet.

 bdev_alloc() might need the queue, set before the first call */

/**

 * put_disk - decrements the gendisk refcount

 * @disk: the struct gendisk to decrement the refcount for

 *

 * This decrements the refcount for the struct gendisk. When this reaches 0

 * we'll have disk_release() called.

 *

 * Context: Any context, but the last reference must not be dropped from

 *          atomic context.

/**

 * blk_cleanup_disk - shutdown a gendisk allocated by blk_alloc_disk

 * @disk: gendisk to shutdown

 *

 * Mark the queue hanging off @disk DYING, drain all pending requests, then mark

 * the queue DEAD, destroy and put it and the gendisk structure.

 *

 * Context: can sleep

/**

 * set_disk_ro - set a gendisk read-only

 * @disk:	gendisk to operate on

 * @read_only:	%true to set the disk read-only, %false set the disk read/write

 *

 * This function is used to indicate whether a given disk device should have its

 * read-only flag set. set_disk_ro() is typically used by device drivers to

 * indicate whether the underlying physical device is write-protected.

 SPDX-License-Identifier: GPL-2.0

/*

 * Copyright (C) 2017 Facebook

	/*

	 * The "state" attribute is removed after blk_cleanup_queue() has called

	 * blk_mq_free_queue(). Return if QUEUE_FLAG_DEAD has been set to avoid

	 * triggering a use-after-free.

/*

 * Note: the state of a request may change while this function is in progress,

 * e.g. due to a concurrent blk_mq_finish_request() call. Returns true to

 * keep iterating requests.

	/*

	 * Attributes that only implement .seq_ops are read-only and 'attr' is

	 * the same with 'data' in this case.

	/*

	 * blk_mq_init_sched() attempted to do this already, but q->debugfs_dir

	 * didn't exist yet (because we don't know what to name the directory

	 * until the queue is registered to a gendisk).

 Similarly, blk_mq_init_hctx() couldn't do this previously. */

	/*

	 * If the parent directory has not been created yet, return, we will be

	 * called again later on and the directory/files will be created then.

	/*

	 * If the parent debugfs directory has not been created yet, return;

	 * We will be called again later on with appropriate parent debugfs

	 * directory from blk_register_queue()

 SPDX-License-Identifier: GPL-2.0

/*

 * Interface for controlling IO bandwidth on a request queue

 *

 * Copyright (C) 2010 Vivek Goyal <vgoyal@redhat.com>

 Max dispatch from a group in 1 round */

 Total max dispatch from all groups in one round */

 Throttling is performed over a slice and after that slice is renewed */

 5 s */

 4ms */

/*

 * For HD, very small latency comes from sequential IO. Such IO is helpless to

 * help determine if its IO is impacted by others, hence we ignore the IO

 1ms */

 A workqueue to queue throttle related work */

 on parent's pending tree */

 bio_lists[] became non-empty */

 We measure latency for request size from <= 4k to >= 1M */

 ns / 1024 */

 ns / 1024 */

 service tree for active throtl groups */

 Total Number of queued bios on READ and WRITE lists */

 Work for dispatching throttled bios */

/**

 * sq_to_tg - return the throl_grp the specified service queue belongs to

 * @sq: the throtl_service_queue of interest

 *

 * Return the throtl_grp @sq belongs to.  If @sq is the top-level one

 * embedded in throtl_data, %NULL is returned.

/**

 * sq_to_td - return throtl_data the specified service queue belongs to

 * @sq: the throtl_service_queue of interest

 *

 * A service_queue can be embedded in either a throtl_grp or throtl_data.

 * Determine the associated throtl_data accordingly and return it.

/*

 * cgroup's limit in LIMIT_MAX is scaled if low limit is set. This scale is to

 * make the IO dispatch more smooth.

 * Scale up: linearly scale up according to lapsed time since upgrade. For

 *           every throtl_slice, the limit scales up 1/2 .low limit till the

 *           limit hits .max limit

 * Scale down: exponentially scale down if a cgroup doesn't hit its .low limit

 arbitrary value to avoid too big scale */

 intermediate node or iops isn't 0 */

 intermediate node or bps isn't 0 */

/**

 * throtl_log - log debug message via blktrace

 * @sq: the service_queue being reported

 * @fmt: printf format string

 * @args: printf args

 *

 * The messages are prefixed with "throtl BLKG_NAME" if @sq belongs to a

 * throtl_grp; otherwise, just "throtl".

 assume it's one sector */

/**

 * throtl_qnode_add_bio - add a bio to a throtl_qnode and activate it

 * @bio: bio being added

 * @qn: qnode to add bio to

 * @queued: the service_queue->queued[] list @qn belongs to

 *

 * Add @bio to @qn and put @qn on @queued if it's not already on.

 * @qn->tg's reference count is bumped when @qn is activated.  See the

 * comment on top of throtl_qnode definition for details.

/**

 * throtl_peek_queued - peek the first bio on a qnode list

 * @queued: the qnode list to peek

/**

 * throtl_pop_queued - pop the first bio form a qnode list

 * @queued: the qnode list to pop a bio from

 * @tg_to_put: optional out argument for throtl_grp to put

 *

 * Pop the first bio from the qnode list @queued.  After popping, the first

 * qnode is removed from @queued if empty or moved to the end of @queued so

 * that the popping order is round-robin.

 *

 * When the first qnode is removed, its associated throtl_grp should be put

 * too.  If @tg_to_put is NULL, this function automatically puts it;

 * otherwise, *@tg_to_put is set to the throtl_grp to put and the caller is

 * responsible for putting it.

 init a service_queue, assumes the caller zeroed it */

 LIMIT_LOW will have default value 0 */

	/*

	 * If on the default hierarchy, we switch to properly hierarchical

	 * behavior where limits on a given throtl_grp are applied to the

	 * whole subtree rather than just the group itself.  e.g. If 16M

	 * read_bps limit is set on the root group, the whole system can't

	 * exceed 16M for the device.

	 *

	 * If not on the default hierarchy, the broken flat hierarchy

	 * behavior is retained where all throtl_grps are treated as if

	 * they're all separate root groups right below throtl_data.

	 * Limits of a group don't interact with limits of other groups

	 * regardless of the position of the group in the hierarchy.

/*

 * Set has_rules[] if @tg or any of its parents have limits configured.

 * This doesn't require walking up to the top of the hierarchy as the

 * parent's has_rules[] is guaranteed to be correct.

	/*

	 * We don't want new groups to escape the limits of its ancestors.

	 * Update has_rules[] after a new group is brought online.

 Call with queue lock held */

	/*

	 * Since we are adjusting the throttle limit dynamically, the sleep

	 * time calculated according to previous limit might be invalid. It's

	 * possible the cgroup sleep time is very long and no other cgroups

	 * have IO running so notify the limit changes. Make sure the cgroup

	 * doesn't sleep too long to avoid the missed notification.

/**

 * throtl_schedule_next_dispatch - schedule the next dispatch cycle

 * @sq: the service_queue to schedule dispatch for

 * @force: force scheduling

 *

 * Arm @sq->pending_timer so that the next dispatch cycle starts on the

 * dispatch time of the first pending child.  Returns %true if either timer

 * is armed or there's no pending child left.  %false if the current

 * dispatch window is still open and the caller should continue

 * dispatching.

 *

 * If @force is %true, the dispatch timer is always scheduled and this

 * function is guaranteed to return %true.  This is to be used when the

 * caller can't dispatch itself and needs to invoke pending_timer

 * unconditionally.  Note that forced scheduling is likely to induce short

 * delay before dispatch starts even if @sq->first_pending_disptime is not

 * in the future and thus shouldn't be used in hot paths.

 any pending children left? */

 is the next dispatch time in the future? */

 tell the caller to continue dispatching */

	/*

	 * Previous slice has expired. We must have trimmed it after last

	 * bio dispatch. That means since start of last slice, we never used

	 * that bandwidth. Do try to make use of that bandwidth while giving

	 * credit.

 Determine if previously allocated or extended slice is complete or not */

 Trim the used slices and adjust slice start accordingly */

	/*

	 * If bps are unlimited (-1), then time slice don't get

	 * renewed. Don't try to trim the slice if slice is used. A new

	 * slice will start when appropriate.

	/*

	 * A bio has been dispatched. Also adjust slice_end. It might happen

	 * that initially cgroup limit was very low resulting in high

	 * slice_end, but later limit was bumped up and bio was dispatched

	 * sooner, then we need to reduce slice_end. A high bogus slice_end

	 * is bad because it does not allow new slice to start.

 Round up to the next throttle slice, wait time must be nonzero */

	/*

	 * jiffy_elapsed_rnd should not be a big value as minimum iops can be

	 * 1 then at max jiffy elapsed should be equivalent of 1 second as we

	 * will allow dispatch after 1 second and after that slice should

	 * have been trimmed.

 Calc approx time to dispatch */

 Slice has just started. Consider one slice interval */

 Calc approx time to dispatch */

	/*

	 * This wait time is without taking into consideration the rounding

	 * up we did. Add that time also.

/*

 * Returns whether one can dispatch a bio or not. Also returns approx number

 * of jiffies to wait before this bio is with-in IO rate and can be dispatched

	/*

 	 * Currently whole state machine of group depends on first bio

	 * queued in the group bio list. So one should not be calling

	 * this function with a different bio if there are other bios

	 * queued.

 If tg->bps = -1, then BW is unlimited */

	/*

	 * If previous slice expired, start a new one otherwise renew/extend

	 * existing slice to make sure it is at least throtl_slice interval

	 * long since now. New slice is started only for empty throttle group.

	 * If there is queued bio, that means there should be an active

	 * slice and it should be extended instead.

 Charge the bio to the group */

	/*

	 * BIO_THROTTLED is used to prevent the same bio to be throttled

	 * more than once as a throttled bio will go through blk-throtl the

	 * second time when it eventually gets issued.  Set it when a bio

	 * is being charged to a tg.

/**

 * throtl_add_bio_tg - add a bio to the specified throtl_grp

 * @bio: bio to add

 * @qn: qnode to use

 * @tg: the target throtl_grp

 *

 * Add @bio to @tg's service_queue using @qn.  If @qn is not specified,

 * tg->qnode_on_self[] is used.

	/*

	 * If @tg doesn't currently have any bios queued in the same

	 * direction, queueing @bio can change when @tg should be

	 * dispatched.  Mark that @tg was empty.  This is automatically

	 * cleared on the next tg_update_disptime().

 Update dispatch time */

 see throtl_add_bio_tg() */

	/*

	 * @bio is being transferred from @tg to @parent_sq.  Popping a bio

	 * from @tg may put its reference and @parent_sq might end up

	 * getting released prematurely.  Remember the tg to put and put it

	 * after @bio is transferred to @parent_sq.

	/*

	 * If our parent is another tg, we just need to transfer @bio to

	 * the parent using throtl_add_bio_tg().  If our parent is

	 * @td->service_queue, @bio is ready to be issued.  Put it on its

	 * bio_lists[] and decrease total number queued.  The caller is

	 * responsible for issuing these bios.

 Try to dispatch 75% READS and 25% WRITES */

/**

 * throtl_pending_timer_fn - timer function for service_queue->pending_timer

 * @t: the pending_timer member of the throtl_service_queue being serviced

 *

 * This timer is armed when a child throtl_grp with active bio's become

 * pending and queued on the service_queue's pending_tree and expires when

 * the first child throtl_grp should be dispatched.  This function

 * dispatches bio's from the children throtl_grps to the parent

 * service_queue.

 *

 * If the parent's parent is another throtl_grp, dispatching is propagated

 * by either arming its pending_timer or repeating dispatch directly.  If

 * the top-level service_tree is reached, throtl_data->dispatch_work is

 * kicked so that the ready bio's are issued.

 this dispatch windows is still open, relax and repeat */

 @parent_sq is another throl_grp, propagate dispatch */

 window is already open, repeat dispatching */

 reached the top-level, queue issuing */

/**

 * blk_throtl_dispatch_work_fn - work function for throtl_data->dispatch_work

 * @work: work item being executed

 *

 * This function is queued for execution when bios reach the bio_lists[]

 * of throtl_data->service_queue.  Those bios are ready and issued by this

 * function.

	/*

	 * Update has_rules[] flags for the updated tg's subtree.  A tg is

	 * considered to have rules if either the tg itself or any of its

	 * ancestors has rules.  This identifies groups without any

	 * restrictions in the whole hierarchy and allows them to bypass

	 * blk-throttle.

 ignore root/second level */

		/*

		 * make sure all children has lower idle time threshold and

		 * higher latency target

	/*

	 * We're already holding queue_lock and know @tg is valid.  Let's

	 * apply the new config directly.

	 *

	 * Restart the slices for both READ and WRITES. It might happen

	 * that a group's limit are dropped suddenly and we don't want to

	 * account recently dispatched IO with new low rate.

 terminate */

 wiops=18446744073709551616 */

 force user to configure all settings for low limit  */

 terminate */

 tg should not be an intermediate node */

		/*

		 * The parent doesn't have low limit, it always reaches low

		 * limit. Its overflow time is useless for children

	/*

	 * cgroup is idle if:

	 * - single idle is too long, longer than a fixed value (in case user

	 *   configure a too big threshold) or 4 times of idletime threshold

	 * - average think time is more than threshold

	 * - IO latency is largely below threshold

	/*

	 * if cgroup reaches low limit (if low limit is 0, the cgroup always

	 * reaches), it's ok to upgrade to next limit

	/*

	 * If cgroup is below low limit, consider downgrade and throttle other

	 * cgroups

	/*

	 * If cgroup is below low limit, consider downgrade and throttle other

	 * cgroups

 this isn't race free, but ok in practice */

 throtl is FIFO - if bios are already queued, should queue */

 if above limits, break to queue */

 within limits, let's charge and dispatch directly */

		/*

		 * We need to trim slice even when bios are not being queued

		 * otherwise it might happen that a bio is not queued for

		 * a long time and slice keeps on extending and trim is not

		 * called for a long time. Now if limits are reduced suddenly

		 * we take into account all the IO dispatched so far at new

		 * low rate and * newly queued IO gets a really long dispatch

		 * time.

		 *

		 * So keep on trimming slice even if bio is not queued.

		/*

		 * @bio passed through this layer without being throttled.

		 * Climb up the ladder.  If we're already at the top, it

		 * can be executed directly.

 out-of-limit, queue to @tg */

	/*

	 * Update @tg's dispatch time and force schedule dispatch if @tg

	 * was empty before @bio.  The forced scheduling isn't likely to

	 * cause undue delay as @bio is likely to be dispatched directly if

	 * its @tg's disptime is not in the future.

 this is only for bio based driver */

		/*

		 * Not race free, could get wrong count, which means cgroups

		 * will be throttled

 activate policy */

 if no low limit, use previous default */

 SPDX-License-Identifier: GPL-2.0

/*

 * Tag allocation using scalable bitmaps. Uses active queue tracking to support

 * fairer distribution of tags between multiple submitters when a shared tag map

 * is used.

 *

 * Copyright (C) 2013-2014 Jens Axboe

/*

 * If a previously inactive queue goes active, bump the active user count.

 * We need to do this before try to allocate driver tag, then even if fail

 * to get tag when first time, the other shared-tag users could reserve

 * budget for it.

/*

 * Wakeup all potentially sleeping on tags

/*

 * If a previously busy queue goes inactive, potential waiters could now

 * be allowed to queue. Wake them up and check.

		/*

		 * We're out of tags on this hardware queue, kick any

		 * pending IO submits before going to sleep waiting for

		 * some to complete.

		/*

		 * Retry tag allocation after running the hardware queue,

		 * as running the queue may also have found completions.

		/*

		 * If destination hw queue is changed, fake wake up on

		 * previous queue for compensating the wake up miss, so

		 * other allocations on previous queue won't be starved.

	/*

	 * Give up this allocation if the hctx is inactive.  The caller will

	 * retry on an active hctx.

	/*

	 * We can hit rq == NULL here, because the tagging functions

	 * test and set the bit before assigning ->rqs[].

/**

 * bt_for_each - iterate over the requests associated with a hardware queue

 * @hctx:	Hardware queue to examine.

 * @bt:		sbitmap to examine. This is either the breserved_tags member

 *		or the bitmap_tags member of struct blk_mq_tags.

 * @fn:		Pointer to the function that will be called for each request

 *		associated with @hctx that has been assigned a driver tag.

 *		@fn will be called as follows: @fn(@hctx, rq, @data, @reserved)

 *		where rq is a pointer to a request. Return true to continue

 *		iterating tags, false to stop.

 * @data:	Will be passed as third argument to @fn.

 * @reserved:	Indicates whether @bt is the breserved_tags member or the

 *		bitmap_tags member of struct blk_mq_tags.

	/*

	 * We can hit rq == NULL here, because the tagging functions

	 * test and set the bit before assigning ->rqs[].

/**

 * bt_tags_for_each - iterate over the requests in a tag map

 * @tags:	Tag map to iterate over.

 * @bt:		sbitmap to examine. This is either the breserved_tags member

 *		or the bitmap_tags member of struct blk_mq_tags.

 * @fn:		Pointer to the function that will be called for each started

 *		request. @fn will be called as follows: @fn(rq, @data,

 *		@reserved) where rq is a pointer to a request. Return true

 *		to continue iterating tags, false to stop.

 * @data:	Will be passed as second argument to @fn.

 * @flags:	BT_TAG_ITER_*

/**

 * blk_mq_all_tag_iter - iterate over all requests in a tag map

 * @tags:	Tag map to iterate over.

 * @fn:		Pointer to the function that will be called for each

 *		request. @fn will be called as follows: @fn(rq, @priv,

 *		reserved) where rq is a pointer to a request. 'reserved'

 *		indicates whether or not @rq is a reserved request. Return

 *		true to continue iterating tags, false to stop.

 * @priv:	Will be passed as second argument to @fn.

 *

 * Caller has to pass the tag map from which requests are allocated.

/**

 * blk_mq_tagset_busy_iter - iterate over all started requests in a tag set

 * @tagset:	Tag set to iterate over.

 * @fn:		Pointer to the function that will be called for each started

 *		request. @fn will be called as follows: @fn(rq, @priv,

 *		reserved) where rq is a pointer to a request. 'reserved'

 *		indicates whether or not @rq is a reserved request. Return

 *		true to continue iterating tags, false to stop.

 * @priv:	Will be passed as second argument to @fn.

 *

 * We grab one request reference before calling @fn and release it after

 * @fn returns.

/**

 * blk_mq_tagset_wait_completed_request - Wait until all scheduled request

 * completions have finished.

 * @tagset:	Tag set to drain completed request

 *

 * Note: This function has to be run after all IO queues are shutdown

/**

 * blk_mq_queue_tag_busy_iter - iterate over all requests with a driver tag

 * @q:		Request queue to examine.

 * @fn:		Pointer to the function that will be called for each request

 *		on @q. @fn will be called as follows: @fn(hctx, rq, @priv,

 *		reserved) where rq is a pointer to a request and hctx points

 *		to the hardware queue associated with the request. 'reserved'

 *		indicates whether or not @rq is a reserved request.

 * @priv:	Will be passed as third argument to @fn.

 *

 * Note: if @q->tag_set is shared with other request queues then @fn will be

 * called for all requests on all queues that share that tag set and not only

 * for requests associated with @q.

	/*

	 * __blk_mq_update_nr_hw_queues() updates nr_hw_queues and queue_hw_ctx

	 * while the queue is frozen. So we can use q_usage_counter to avoid

	 * racing with it.

		/*

		 * If no software queues are currently mapped to this

		 * hardware queue, there's nothing to check

	/*

	 * If we are allowed to grow beyond the original size, allocate

	 * a new set of tags before freeing the old one.

		/*

		 * We need some sort of upper limit, set it high enough that

		 * no valid use cases should require more.

		/*

		 * Only the sbitmap needs resizing since we allocated the max

		 * initially.

		/*

		 * Don't need (or can't) update reserved tags here, they

		 * remain static and should never need resizing.

/**

 * blk_mq_unique_tag() - return a tag that is unique queue-wide

 * @rq: request for which to compute a unique tag

 *

 * The tag field in struct request is unique per hardware queue but not over

 * all hardware queues. Hence this function that returns a tag with the

 * hardware context index in the upper bits and the per hardware queue tag in

 * the lower bits.

 *

 * Note: When called for a request that is queued on a non-multiqueue request

 * queue, the hardware context index is set to zero.

