  linuxfsnlsnls_cp860.c
  Charset cp860 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_cp775.c
  Charset cp775 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_cp864.c
  Charset cp864 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsmac-croatian.c
  Charset maccroatian translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
  COPYRIGHT AND PERMISSION NOTICE
  Copyright 1991-2012 Unicode, Inc.  All rights reserved.  Distributed under
  the Terms of Use in http:www.unicode.orgcopyright.html.
  Permission is hereby granted, free of charge, to any person obtaining a
  copy of the Unicode data files and any associated documentation (the "Data
  Files") or Unicode software and any associated documentation (the
  "Software") to deal in the Data Files or Software without restriction,
  including without limitation the rights to use, copy, modify, merge,
  publish, distribute, andor sell copies of the Data Files or Software, and
  to permit persons to whom the Data Files or Software are furnished to do
  so, provided that (a) the above copyright notice(s) and this permission
  notice appear with all copies of the Data Files or Software, (b) both the
  above copyright notice(s) and this permission notice appear in associated
  documentation, and (c) there is clear notice in each modified Data File or
  in the Software as well as in the documentation associated with the Data
  File(s) or Software that the data or software has been modified.
  THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
  KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF
  THIRD PARTY RIGHTS.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS
  INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT
  OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
  USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THE DATA FILES OR SOFTWARE.
  Except as contained in this notice, the name of a copyright holder shall
  not be used in advertising or otherwise to promote the sale, use or other
  dealings in these Data Files or Software without prior written
  authorization of the copyright holder.
 0x00 
 0x10 
 0x20 
 0x30 
 0x40 
 0x50 
 0x60 
 0x70 
 0x80 
 0x90 
 0xa0 
 0xb0 
 0xc0 
 0xd0 
 0xe0 
 0xf0 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_euc-jp.c
  Added `OSFJVC Recommended Code Set Conversion Specification
  between Japanese EUC and Shift-JIS' support: <hirofumi@mail.parknet.co.jp>
  (http:www.opengroup.or.jpjvccdesjis-euc-e.html)
 JIS X 0208 (include NEC spesial characters) 
 Single Shift 2 
 Single Shift 3 
 G3 block 
 SJIS IBM extended characters to EUC map 
 EUC to SJIS IBM extended characters map (G3 JIS X 0212 block) 
 EUC to SJIS IBM extended characters map (G3 Upper block) 
 SJIS IBM extended characters to EUC 
 EUC to SJIS IBM extended characters (G3 JIS X 0212 block) 
 EUC to SJIS IBM extended characters (G3 Upper block) 
 EUC to SJIS IBM extended characters (G3 block) 
 NECIBM extended characters to IBM extended characters 
 translate SJIS into EUC-JP 
 JIS X 0201 KANA 
 NECIBM extended characters to IBM extended characters 
 User defined characters half low 
 User defined characters half high 
 IBM extended characters 
 JIS X 0208 (include NEC special characters) 
 Invalid characters 
 translate EUC-JP into SJIS 
 User defined characters half high 
 IBM extended characters 
 JIS X 0212 and Invalid characters
 'GETA' with SJIS coding 
 sjis_temp[0] = 0x81; 
 sjis_temp[1] = 0xAC; 
 JIS X 0201 KANA 
 User defined characters half low 
 JIS X 0208 (include NEC spesial characters) 
 Invalid characters 
 JIS X 0201 ROMAJI 
  linuxfsnlsnls_iso8859-4.c
  Charset iso8859-4 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_cp863.c
  Charset cp863 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_iso8859-9.c
  Charset iso8859-9 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_cp1255.c
  Charset cp1255 translation tables.
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_cp437.c
  Charset cp437 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_iso8859-1.c
  Charset iso8859-1 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_cp737.c
  Charset cp737 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_cp869.c
  Charset cp869 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  Module for handling utf8 just like any other charset.
  By Urban Widmark 2000
 ? 
 no conversion 
  linuxfsnlsnls_cp865.c
  Charset cp865 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_koi8-r.c
  Charset koi8-r translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsmac-gaelic.c
  Charset macgaelic translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
  COPYRIGHT AND PERMISSION NOTICE
  Copyright 1991-2012 Unicode, Inc.  All rights reserved.  Distributed under
  the Terms of Use in http:www.unicode.orgcopyright.html.
  Permission is hereby granted, free of charge, to any person obtaining a
  copy of the Unicode data files and any associated documentation (the "Data
  Files") or Unicode software and any associated documentation (the
  "Software") to deal in the Data Files or Software without restriction,
  including without limitation the rights to use, copy, modify, merge,
  publish, distribute, andor sell copies of the Data Files or Software, and
  to permit persons to whom the Data Files or Software are furnished to do
  so, provided that (a) the above copyright notice(s) and this permission
  notice appear with all copies of the Data Files or Software, (b) both the
  above copyright notice(s) and this permission notice appear in associated
  documentation, and (c) there is clear notice in each modified Data File or
  in the Software as well as in the documentation associated with the Data
  File(s) or Software that the data or software has been modified.
  THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
  KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF
  THIRD PARTY RIGHTS.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS
  INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT
  OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
  USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THE DATA FILES OR SOFTWARE.
  Except as contained in this notice, the name of a copyright holder shall
  not be used in advertising or otherwise to promote the sale, use or other
  dealings in these Data Files or Software without prior written
  authorization of the copyright holder.
 0x00 
 0x10 
 0x20 
 0x30 
 0x40 
 0x50 
 0x60 
 0x70 
 0x80 
 0x90 
 0xa0 
 0xb0 
 0xc0 
 0xd0 
 0xe0 
 0xf0 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsmac-turkish.c
  Charset macturkish translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
  COPYRIGHT AND PERMISSION NOTICE
  Copyright 1991-2012 Unicode, Inc.  All rights reserved.  Distributed under
  the Terms of Use in http:www.unicode.orgcopyright.html.
  Permission is hereby granted, free of charge, to any person obtaining a
  copy of the Unicode data files and any associated documentation (the "Data
  Files") or Unicode software and any associated documentation (the
  "Software") to deal in the Data Files or Software without restriction,
  including without limitation the rights to use, copy, modify, merge,
  publish, distribute, andor sell copies of the Data Files or Software, and
  to permit persons to whom the Data Files or Software are furnished to do
  so, provided that (a) the above copyright notice(s) and this permission
  notice appear with all copies of the Data Files or Software, (b) both the
  above copyright notice(s) and this permission notice appear in associated
  documentation, and (c) there is clear notice in each modified Data File or
  in the Software as well as in the documentation associated with the Data
  File(s) or Software that the data or software has been modified.
  THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
  KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF
  THIRD PARTY RIGHTS.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS
  INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT
  OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
  USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THE DATA FILES OR SOFTWARE.
  Except as contained in this notice, the name of a copyright holder shall
  not be used in advertising or otherwise to promote the sale, use or other
  dealings in these Data Files or Software without prior written
  authorization of the copyright holder.
 0x00 
 0x10 
 0x20 
 0x30 
 0x40 
 0x50 
 0x60 
 0x70 
 0x80 
 0x90 
 0xa0 
 0xb0 
 0xc0 
 0xd0 
 0xe0 
 0xf0 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_iso8859-3.c
  Charset iso8859-3 translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsnls_iso8859-14.c
  Charset iso8859-14 translation tables.
  Generated automatically from the Unicode and charset table
  provided by the Unicode Organisation at
  http:www.unicode.org
  The Unicode to charset table has only exact mappings.
  Rhys Jones, Swansea University Computer Society
  rhys@sucs.swan.ac.uk
 0x00
 0x10
 0x20
 0x30
 0x40
 0x50
 0x60
 0x70
 0x80
 0x90
 0xa0
 0xb0
 0xc0
 0xd0
 0xe0
 0xf0
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsmac-roman.c
  Charset macroman translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
  COPYRIGHT AND PERMISSION NOTICE
  Copyright 1991-2012 Unicode, Inc.  All rights reserved.  Distributed under
  the Terms of Use in http:www.unicode.orgcopyright.html.
  Permission is hereby granted, free of charge, to any person obtaining a
  copy of the Unicode data files and any associated documentation (the "Data
  Files") or Unicode software and any associated documentation (the
  "Software") to deal in the Data Files or Software without restriction,
  including without limitation the rights to use, copy, modify, merge,
  publish, distribute, andor sell copies of the Data Files or Software, and
  to permit persons to whom the Data Files or Software are furnished to do
  so, provided that (a) the above copyright notice(s) and this permission
  notice appear with all copies of the Data Files or Software, (b) both the
  above copyright notice(s) and this permission notice appear in associated
  documentation, and (c) there is clear notice in each modified Data File or
  in the Software as well as in the documentation associated with the Data
  File(s) or Software that the data or software has been modified.
  THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
  KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF
  THIRD PARTY RIGHTS.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS
  INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT
  OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
  USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THE DATA FILES OR SOFTWARE.
  Except as contained in this notice, the name of a copyright holder shall
  not be used in advertising or otherwise to promote the sale, use or other
  dealings in these Data Files or Software without prior written
  authorization of the copyright holder.
 0x00 
 0x10 
 0x20 
 0x30 
 0x40 
 0x50 
 0x60 
 0x70 
 0x80 
 0x90 
 0xa0 
 0xb0 
 0xc0 
 0xd0 
 0xe0 
 0xf0 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsmac-centeuro.c
  Charset maccenteuro translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
  COPYRIGHT AND PERMISSION NOTICE
  Copyright 1991-2012 Unicode, Inc.  All rights reserved.  Distributed under
  the Terms of Use in http:www.unicode.orgcopyright.html.
  Permission is hereby granted, free of charge, to any person obtaining a
  copy of the Unicode data files and any associated documentation (the "Data
  Files") or Unicode software and any associated documentation (the
  "Software") to deal in the Data Files or Software without restriction,
  including without limitation the rights to use, copy, modify, merge,
  publish, distribute, andor sell copies of the Data Files or Software, and
  to permit persons to whom the Data Files or Software are furnished to do
  so, provided that (a) the above copyright notice(s) and this permission
  notice appear with all copies of the Data Files or Software, (b) both the
  above copyright notice(s) and this permission notice appear in associated
  documentation, and (c) there is clear notice in each modified Data File or
  in the Software as well as in the documentation associated with the Data
  File(s) or Software that the data or software has been modified.
  THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
  KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF
  THIRD PARTY RIGHTS.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS
  INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT
  OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
  USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THE DATA FILES OR SOFTWARE.
  Except as contained in this notice, the name of a copyright holder shall
  not be used in advertising or otherwise to promote the sale, use or other
  dealings in these Data Files or Software without prior written
  authorization of the copyright holder.
 0x00 
 0x10 
 0x20 
 0x30 
 0x40 
 0x50 
 0x60 
 0x70 
 0x80 
 0x90 
 0xa0 
 0xb0 
 0xc0 
 0xd0 
 0xe0 
 0xf0 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsmac-celtic.c
  Charset macceltic translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
  COPYRIGHT AND PERMISSION NOTICE
  Copyright 1991-2012 Unicode, Inc.  All rights reserved.  Distributed under
  the Terms of Use in http:www.unicode.orgcopyright.html.
  Permission is hereby granted, free of charge, to any person obtaining a
  copy of the Unicode data files and any associated documentation (the "Data
  Files") or Unicode software and any associated documentation (the
  "Software") to deal in the Data Files or Software without restriction,
  including without limitation the rights to use, copy, modify, merge,
  publish, distribute, andor sell copies of the Data Files or Software, and
  to permit persons to whom the Data Files or Software are furnished to do
  so, provided that (a) the above copyright notice(s) and this permission
  notice appear with all copies of the Data Files or Software, (b) both the
  above copyright notice(s) and this permission notice appear in associated
  documentation, and (c) there is clear notice in each modified Data File or
  in the Software as well as in the documentation associated with the Data
  File(s) or Software that the data or software has been modified.
  THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
  KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF
  THIRD PARTY RIGHTS.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS
  INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT
  OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
  USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THE DATA FILES OR SOFTWARE.
  Except as contained in this notice, the name of a copyright holder shall
  not be used in advertising or otherwise to promote the sale, use or other
  dealings in these Data Files or Software without prior written
  authorization of the copyright holder.
 0x00 
 0x10 
 0x20 
 0x30 
 0x40 
 0x50 
 0x60 
 0x70 
 0x80 
 0x90 
 0xa0 
 0xb0 
 0xc0 
 0xd0 
 0xe0 
 0xf0 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
  linuxfsnlsmac-cyrillic.c
  Charset maccyrillic translation tables.
  Generated automatically from the Unicode and charset
  tables from the Unicode Organization (www.unicode.org).
  The Unicode to charset table has only exact mappings.
  COPYRIGHT AND PERMISSION NOTICE
  Copyright 1991-2012 Unicode, Inc.  All rights reserved.  Distributed under
  the Terms of Use in http:www.unicode.orgcopyright.html.
  Permission is hereby granted, free of charge, to any person obtaining a
  copy of the Unicode data files and any associated documentation (the "Data
  Files") or Unicode software and any associated documentation (the
  "Software") to deal in the Data Files or Software without restriction,
  including without limitation the rights to use, copy, modify, merge,
  publish, distribute, andor sell copies of the Data Files or Software, and
  to permit persons to whom the Data Files or Software are furnished to do
  so, provided that (a) the above copyright notice(s) and this permission
  notice appear with all copies of the Data Files or Software, (b) both the
  above copyright notice(s) and this permission notice appear in associated
  documentation, and (c) there is clear notice in each modified Data File or
  in the Software as well as in the documentation associated with the Data
  File(s) or Software that the data or software has been modified.
  THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY
  KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF
  THIRD PARTY RIGHTS.  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS
  INCLUDED IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT
  OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF
  USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
  OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  PERFORMANCE OF THE DATA FILES OR SOFTWARE.
  Except as contained in this notice, the name of a copyright holder shall
  not be used in advertising or otherwise to promote the sale, use or other
  dealings in these Data Files or Software without prior written
  authorization of the copyright holder.
 0x00 
 0x10 
 0x20 
 0x30 
 0x40 
 0x50 
 0x60 
 0x70 
 0x80 
 0x90 
 0xa0 
 0xb0 
 0xc0 
 0xd0 
 0xe0 
 0xf0 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 0x00-0x07 
 0x08-0x0f 
 0x10-0x17 
 0x18-0x1f 
 0x20-0x27 
 0x28-0x2f 
 0x30-0x37 
 0x38-0x3f 
 0x40-0x47 
 0x48-0x4f 
 0x50-0x57 
 0x58-0x5f 
 0x60-0x67 
 0x68-0x6f 
 0x70-0x77 
 0x78-0x7f 
 0x80-0x87 
 0x88-0x8f 
 0x90-0x97 
 0x98-0x9f 
 0xa0-0xa7 
 0xa8-0xaf 
 0xb0-0xb7 
 0xb8-0xbf 
 0xc0-0xc7 
 0xc8-0xcf 
 0xd0-0xd7 
 0xd8-0xdf 
 0xe0-0xe7 
 0xe8-0xef 
 0xf0-0xf7 
 0xf8-0xff 
 SPDX-License-Identifier: GPL-2.0-or-later
   Copyright (C) 2008 Red Hat, Inc., Eric Paris <eparis@redhat.com>
  fsnotify inode mark lockinglifetimeand refcnting
  REFCNT:
  The group->recnt and mark->refcnt tell how many "things" in the kernel
  currently are referencing the objects. Both kind of objects typically will
  live inside the kernel with a refcnt of 2, one for its creation and one for
  the reference a group and a mark hold to each other.
  If you are holding the appropriate locks, you can take a reference and the
  object itself is guaranteed to survive until the reference is dropped.
  LOCKING:
  There are 3 locks involved with fsnotify inode marks and they MUST be taken
  in order as follows:
  group->mark_mutex
  mark->lock
  mark->connector->lock
  group->mark_mutex protects the marks_list anchored inside a given group and
  each mark is hooked via the g_list.  It also protects the groups private
  data (i.e group limits).
  mark->lock protects the marks attributes like its masks and flags.
  Furthermore it protects the access to a reference of the group that the mark
  is assigned to as well as the access to a reference of the inodevfsmount
  that is being watched by the mark.
  mark->connector->lock protects the list of marks anchored inside an
  inode  vfsmount and each mark is hooked via the i_list.
  A list of notification marks relating to inode  mnt is contained in
  fsnotify_mark_connector. That structure is alive as long as there are any
  marks in the list and is also protected by fsnotify_mark_srcu. A mark gets
  detached from fsnotify_mark_connector when last reference to the mark is
  dropped.  Thus having mark reference is enough to protect mark->connector
  pointer and to make sure fsnotify_mark_connector cannot disappear. Also
  because we remove mark from g_list before dropping mark reference associated
  with that, any mark found through g_list is guaranteed to have
  mark->connector set until we drop group->mark_mutex.
  LIFETIME:
  Inode marks survive between when they are added to an inode and when their
  refcnt==0. Marks are also protected by fsnotify_mark_srcu.
  The inode mark can be cleared for a number of different reasons including:
  - The inode is unlinked for the last time.  (fsnotify_inode_remove)
  - The inode is being evicted from cache. (fsnotify_inode_delete)
  - The fs the inode is on is unmounted.  (fsnotify_inode_deletefsnotify_unmount_inodes)
  - Something explicitly requests that it be removed.  (fsnotify_destroy_mark)
  - The fsnotify_group associated with the mark is going away and all such marks
    need to be cleaned up. (fsnotify_clear_marks_by_group)
  This has the very interesting property of being able to run concurrently with
  any (or all) other directions.
 1 jiffy 
 We can get detached connector here when inode is getting unlinked. 
  Calculate mask of events for a list of marks. The caller must make sure
  connector and connector->obj cannot disappear under us.  Callers achieve
  this by holding a mark->lock or mark->group->mark_mutex for a mark on this
  list.
 Free all connectors queued for freeing once SRCU period ends 
 Drop object reference originally held by a connector 
 Currently only inode references are passed to be dropped 
 Catch marks that were actually never attached to object 
	
	  We have to be careful so that traversals of obj_list under lock can
	  safely grab mark reference.
	
	  Note that we didn't update flags telling whether inode cares about
	  what's happening with children. We update these flags from
	  __fsnotify_parent() lazily when next event happens on one of our
	  children.
  Get mark reference when we found the mark via lockless traversal of object
  list. Mark can be already removed from the list by now and on its way to be
  destroyed once SRCU period ends.
  Also pin the group so it doesn't disappear under us.
 mark is attached, group is still alive then 
  Puts marks and wakes up group destruction if necessary.
  Pairs with fsnotify_get_mark_safe()
		
		  We abuse notification_waitq on group shutdown for waiting for
		  all marks pinned when waiting for userspace.
 This can fail if mark is being removed 
	
	  Now that both marks are pinned by refcount in the inode  vfsmount
	  lists, we can drop SRCU lock, and safely resume the list iteration
	  once userspace returns.
  Mark mark as detached, remove it from group list. Mark still stays in object
  list until its last reference is dropped. Note that we rely on mark being
  removed from group list before corresponding reference to it is dropped. In
  particular we rely on mark->connector being valid while we hold
  group->mark_mutex if we found the mark through g_list.
  Must be called with group->mark_mutex held. The caller must either hold
  reference to the mark or be protected by fsnotify_mark_srcu.
 something else already called this function on this mark 
 Drop mark reference acquired in fsnotify_add_mark_locked() 
  Free fsnotify mark. The mark is actually only marked as being freed.  The
  freeing is actually happening only once last reference to the mark is
  dropped from a workqueue which first waits for srcu period end.
  Caller must have a reference to the mark or be protected by
  fsnotify_mark_srcu.
 something else already called this function on this mark 
	
	  Some groups like to know that marks are being freed.  This is a
	  callback to the group function to let it know that this mark
	  is being freed.
  Sorting function for lists of fsnotify marks.
  Fanotify supports different notification classes (reflected as priority of
  notification group). Events shall be passed to notification groups in
  decreasing priority order. To achieve this marks in notification lists for
  inodes and vfsmounts are sorted so that priorities of corresponding groups
  are descending.
  Furthermore correct handling of the ignore mask requires processing inode
  and vfsmount marks of each group together. Using the group address as
  further sort criterion provides a unique sorting order and thus we can
  merge inode and vfsmount lists of marks in linear time and find groups
  present in both lists.
  A return value of 1 signifies that b has priority over a.
  A return value of 0 signifies that the two marks have to be handled together.
  A return value of -1 signifies that a has priority over b.
 Cache fsid of filesystem containing the object 
	
	  cmpxchg() provides the barrier so that readers of connp can see
	  only initialized structure
 Someone else created list structure for us 
  Get mark connector, make sure it is alive and return with its lock held.
  This is for users that get connector pointer from inode or mount. Users that
  hold reference to a mark on the list may directly lock connector->lock as
  they are sure list cannot go away under them.
  Add mark into proper place in given list of marks. These marks may be used
  for the fsnotify backend to determine which event types should be delivered
  to which group and for which inodes. These marks are ordered according to
  priority, highest number first, and then by the group's location in memory.
 Backend is expected to check for zero fsid (e.g. tmpfs) 
 Pairs with smp_rmb() in fanotify_get_fsid() 
		
		  Backend is expected to check for non uniform fsid
		  (e.g. btrfs), but maybe we missed something?
		  Only allow setting conn->fsid once to non zero fsid.
		  inotify and non-fid fanotify groups do not set nor test
		  conn->fsid.
 is mark the first mark? 
 should mark be in the middle of the current list? 
 mark should be the last entry.  last is the current last entry 
	
	  Since connector is attached to object using cmpxchg() we are
	  guaranteed that connector initialization is fully visible by anyone
	  seeing mark->connector set.
  Attach an initialized mark to a given group and fs object.
  These marks may be used for the fsnotify backend to determine which
  event types should be delivered to which group.
	
	  LOCKING ORDER!!!!
	  group->mark_mutex
	  mark->lock
	  mark->connector->lock
 for g_list 
  Given a list of marks, find the mark associated with given group. If found
  take a reference to that mark and return it, else return NULL.
 Clear any marks in a group with given type mask 
 Skip selection step if we want to clear all marks. 
	
	  We have to be really careful here. Anytime we drop mark_mutex, e.g.
	  fsnotify_clear_marks_by_inode() can come and free marks. Even in our
	  to_free list so we have to use mark_mutex even when accessing that
	  list. And freeing mark requires us to drop mark_mutex. So we can
	  reliably free only the first mark in the list. That's why we first
	  move marks to free to to_free list in one go and then free marks in
	  to_free list one by one.
 Destroy all marks attached to an object via connector 
	
	  We have to be careful since we can race with e.g.
	  fsnotify_clear_marks_by_group() and once we drop the conn->lock, the
	  list can get modified. However we are holding mark reference and
	  thus our mark cannot be removed from obj_list so we can continue
	  iteration after regaining conn->lock.
	
	  Detach list from object now so that we don't pin inode until all
	  mark references get dropped. It would lead to strange results such
	  as delaying inode deletion or blocking unmount.
  Nothing fancy, just initialize lists and locks and counters.
  Destroy all marks in destroy_list, waits for SRCU period to finish before
  actually freeing marks.
 exchange the list head 
 Wait for all marks queued for destruction to be actually destroyed 
 SPDX-License-Identifier: GPL-2.0-or-later
   Copyright (C) 2008 Red Hat, Inc., Eric Paris <eparis@redhat.com>
  Clear all of the marks on an inode when it is being evicted from core
  fsnotify_unmount_inodes - an sb is unmounting.  handle any watched inodes.
  @sb: superblock being unmounted.
  Called during unmount with no locks held, so needs to be safe against
  concurrent modifiers. We temporarily drop sb->s_inode_list_lock and CAN block.
		
		  We cannot __iget() an inode in state I_FREEING,
		  I_WILL_FREE, or I_NEW which is fine because by that point
		  the inode cannot have any associated watches.
		
		  If i_count is zero, the inode cannot have any watches and
		  doing an __igetiput with SB_ACTIVE clear would actually
		  evict all inodes with zero i_count from icache which is
		  unnecessarily violent and may in fact be illegal to do.
		  However, we should have been called after evict_inodes
		  removed all zero refcount inodes, in any case.  Test to
		  be sure.
 for each watch, send FS_UNMOUNT and then remove it 
 Wait for outstanding object references from connectors 
  Given an inode, first check if we care what happens to our children.  Inotify
  and dnotify both tell their parents about events.  If we care about any event
  on a child we run all of our children and set a dentry flag saying that the
  parent cares.  Thus when an event happens on a child it can quickly tell if
  if there is a need to find a parent and send the event to the parent.
 determine if the children should tell inode about their events 
	 run all of the dentries associated with this inode.  Since this is a
		 run all of the children of the original inode and fix their
		  d_flags to indicate parental interest (their parent is the
 Are inodesbmount interested in parent and name info with this event? 
 We only send parentname to inodesbmount for events on non-dir 
	
	  All events that are possible on child can also may be reported with
	  parentname info to inodesbmount.  Otherwise, a watching parent
	  could result in events reported with unexpected name info to sbmount.
 Did either inodesbmount subscribe for events with parentname? 
 Did they subscribe for this event with parentname info? 
  Notify this dentry's parent about a child's events with child name info
  if parent is watching or if inodesbmount are interested in events with
  parent and name info.
  Notify only the child without name info if parent is not watching and
  inodesbmount are not interested in events with parent and name info.
	
	  Do inodesbmount care about parent and name info on non-dir?
	  Do they care about any event at all?
 Does parent inode care about events on children? 
	
	  Include parentname in notification either if some notification
	  groups require parent info or the parent is interested in this event.
 When notifying parent, child should be passed as data 
 Notify both parent and child with child name info 
 Check interest of this mark in case event was sent with two marks 
		
		  parent_mark indicates that the parent inode is watching
		  children and interested in this event, which is an event
		  possible on child. But is this mark watching children and
		  interested in this event?
		
		  Some events can be sent on both parent dir and child marks
		  (e.g. FS_ATTRIB).  If both parent dir and child are
		  watching, report the event once to parent dir with name (if
		  interested) and once to child without name (if interested).
		  The child watcher is expecting an event without a file name
		  and without the FS_EVENT_ON_CHILD flag.
 clear ignored on inode modification 
 does the object mark tell us to do something? 
  iter_info is a multi head priority queue of marks.
  Pick a subset of marks from queue heads, all with the
  same group and set the report_mask for selected subset.
  Returns the report_mask of the selected subset.
 Choose max prio group among groups of all queue heads 
 Set the report mask for marks from same group as max prio group 
  Pop from iter_info multi head queue, the marks that were iterated in the
  current iteration step.
  fsnotify - This is the main call to fsnotify.
  The VFS calls into hook specific functions in linuxfsnotify.h.
  Those functions then in turn call here.  Here will call out to all of the
  registered fsnotify_group.  Those groups can then use the notification event
  in whatever means they feel necessary.
  @mask:	event type and flags
  @data:	object that event happened on
  @data_type:	type of object for fanotify_data_XXX() accessors
  @dir:	optional directory associated with event -
 		if @file_name is not NULL, this is the directory that
 		@file_name is relative to
  @file_name:	optional file name associated with event
  @inode:	optional inode associated with event -
 		If @dir and @inode are both non-NULL, event may be
 		reported to both.
  @cookie:	inotify rename cookie
 Dirent event - report on TYPE_INODE to dir 
		
		  Event on child - report on TYPE_PARENT to dir if it is
		  watching children and on TYPE_INODE to child.
	
	  Optimization: srcu_read_lock() has a memory barrier which can
	  be expensive.  It protects walking the _fsnotify_marks lists.
	  However, if we do not walk the lists, we do not have to do
	  SRCU because we have no references to any objects and do not
	  need SRCU to keep them "alive".
	
	  if this is a modify event we may need to clear the ignored masks
	  otherwise return if none of the marks care about this type of event.
	
	  We need to merge inodevfsmountsb mark lists so that e.g. inode mark
	  ignore masks are properly reflected for mountsb mark notifications.
	  That's why this traversal is so complicated...
 SPDX-License-Identifier: GPL-2.0
		
		  IN_ALL_EVENTS represents all of the mask bits
		  that we expose to userspace.  There is at
		  least one bit (FS_EVENT_ON_CHILD) which is
		  used only internally to the kernel.
 CONFIG_INOTIFY_USER 
 CONFIG_FANOTIFY 
 CONFIG_INOTIFY_USER || CONFIG_FANOTIFY 
 CONFIG_PROC_FS 
 SPDX-License-Identifier: GPL-2.0-or-later
   Copyright (C) 2008 Red Hat, Inc., Eric Paris <eparis@redhat.com>
  Basic idea behind the notification queue: An fsnotify group (like inotify)
  sends the userspace notification about events asynchronously some time after
  the event happened.  When inotify gets an event it will need to add that
  event to the group notify queue.  Since a single event might need to be on
  multiple group's notification queues we can't add the event directly to each
  queue and instead add a small "event_holder" to each queue.  This event_holder
  has a pointer back to the original event.  Since the majority of events are
  going to end up on one, and only one, notification queue we embed one
  event_holder into each event.  This means we have a single allocation instead
  of always needing two.  If the embedded event_holder is already in use by
  another group a new event_holder (from fsnotify_event_holder_cachep) will be
  allocated and used.
  fsnotify_get_cookie - return a unique cookie for use in synchronizing events.
  Called from fsnotify_move, which is inlined into filesystem modules.
 Overflow events are per-group and we don't want to free them 
	
	  If the event is still queued, we have a problem... Do an unreliable
	  lockless check first to avoid locking in the common case. The
	  locking may be necessary for permission events which got removed
	  from the list by a different CPU than the one freeing the event.
  Try to add an event to the notification queue.
  The group can later pull this event off the queue to deal with.
  The group can use the @merge hook to merge the event with a queued event.
  The group can use the @insert hook to insert the event into hash table.
  The function returns:
  0 if the event was added to a queue
  1 if the event was merged with some other queued event
  2 if the event was not queued - either the queue of events has overflown
    or the group is shutting down.
 Queue overflow event only if it isn't already queued 
	
	  We need to init list head for the case of overflow event so that
	  check in fsnotify_add_event() works
  Return the first event on the notification list without removing it.
  Returns NULL if the list is empty.
  Remove and return the first event from the notification list.  It is the
  responsibility of the caller to destroy the obtained event
  Called when a group is being torn down to clean up any outstanding
  event notifications.
 SPDX-License-Identifier: GPL-2.0-or-later
   Copyright (C) 2008 Red Hat, Inc., Eric Paris <eparis@redhat.com>
  Final freeing of a group
  Stop queueing new events for this group. Once this function returns
  fsnotify_add_event() will not add any new events to the group's queue.
  Trying to get rid of a group. Remove all marks, flush all events and release
  the group reference.
  Note that another thread calling fsnotify_clear_marks_by_group() may still
  hold a ref to the group.
	
	  Stop queueing new events. The code below is careful enough to not
	  require this but fanotify needs to stop queuing events even before
	  fsnotify_destroy_group() is called and this makes the other callers
	  of fsnotify_destroy_group() to see the same behavior.
 Clear all marks for this group and queue them for destruction 
	
	  Some marks can still be pinned when waiting for response from
	  userspace. Wait for those now. fsnotify_prepare_user_wait() will
	  not succeed now so this wait is race-free.
	
	  Wait until all marks get really destroyed. We could actually destroy
	  them ourselves instead of waiting for worker to do it, however that
	  would be racy as worker can already be processing some marks before
	  we even entered fsnotify_destroy_group().
	
	  Since we have waited for fsnotify_mark_srcu in
	  fsnotify_mark_destroy_list() there can be no outstanding event
	  notification against this group. So clearing the notification queue
	  of all events is reliable now.
	
	  Destroy overflow event (we cannot use fsnotify_destroy_event() as
	  that deliberately ignores overflow events.
  Get reference to a group.
  Drop a reference to a group.  Free it if it's through.
 set to 0 when there a no external references to this group 
  Create a new fsnotify_group and hold a reference for the group returned.
  Create a new fsnotify_group and hold a reference for the group returned.
 SPDX-License-Identifier: GPL-2.0-or-later
  fsinotify_user.c - inotify support for userspace
  Authors:
 	John McCutchan	<ttb@tentacle.dhs.org>
 	Robert Love	<rml@novell.com>
  Copyright (C) 2005 John McCutchan
  Copyright 2006 Hewlett-Packard Development Company, L.P.
  Copyright (C) 2009 Eric Paris <Red Hat Inc>
  inotify was largely rewriten to make use of the fsnotify infrastructure
 d_unlinked 
 struct inode 
 struct path 
 kmem_ 
  Check if 2 events contain the same information.
	
	  Whoever is interested in the event, pays for the allocation. Do not
	  trigger OOM killer in the target monitoring memcg as it may have
	  security repercussion.
		
		  Treat lost event due to ENOMEM the same way as queue
		  overflow to let userspace know event was lost.
	
	  We now report FS_ISDIR flag with MOVE_SELF and DELETE_SELF events
	  for fanotify. inotify never reported IN_ISDIR with those events.
	  It looks like an oversight, but to avoid the risk of breaking
	  existing inotify programs, mask the flag out from those events.
 Our event wasn't used in the end. Free it. 
  This is NEVER supposed to be called.  Inotify marks should either have been
  removed from the idr when the watch was removed or in the
  fsnotify_destroy_mark_by_group() call when the inotify instance was being
  torn down.  This is only called if the idr is about to be freed but there
  are still marks in it.
	
	  I'm taking the liberty of assuming that the mark in question is a
	  valid address and I'm dereferencing it.  This might help to figure
	  out why we got here and the panic is no worse than the original
	  BUG() that was here.
 ideally the idr is empty and we won't hit the BUG in the callback 
 ding dong the mark is dead 
 SPDX-License-Identifier: GPL-2.0-or-later
  fsinotify_user.c - inotify support for userspace
  Authors:
 	John McCutchan	<ttb@tentacle.dhs.org>
 	Robert Love	<rml@novell.com>
  Copyright (C) 2005 John McCutchan
  Copyright 2006 Hewlett-Packard Development Company, L.P.
  Copyright (C) 2009 Eric Paris <Red Hat Inc>
  inotify was largely rewriten to make use of the fsnotify infrastructure
 struct inode 
 fs_initcall 
 roundup() 
 LOOKUP_FOLLOW 
 struct kmem_cache 
  An inotify watch requires allocating an inotify_inode_mark structure as
  well as pinning the watched inode. Doubling the size of a VFS inode
  should be more than enough to cover the additional filesystem inode
  size increase.
 configurable via procsysfsinotify 
 CONFIG_SYSCTL 
	
	  Everything should receive events when the inode is unmounted.
	  All directories care about children.
 mask off the flags used to open the fd 
 intofiy userspace file descriptor functions 
  Get an inotify_kernel_event if one exists and is small
  enough to fit in "count". Return an error pointer if
  not large enough.
  Called with the group->notification_lock held.
	 held the notification_lock the whole time, so this is the
  Copy an event to user space, returning how much we copied.
  We already checked that the event size is smaller than the
  buffer we had in "get_one_event()" above.
	
	  round up name length so it is a multiple of event_size
	  plus an extra byte for the terminating '\0'.
 send the main event 
	
	  fsnotify only stores the pathname, so here we have to send the pathname
	  and then pad that pathname out to a multiple of sizeof(inotify_event)
	  with zeros.
 copy the path name 
 fill userspace with 0's 
 free this group, matching get was inotify_init->fsnotify_obtain_group 
 CONFIG_CHECKPOINT_RESTORE 
  find_inode - resolve a user-given path to a specific inode
 you can only watch an inode if you have read permissions on it 
 we added the mark to the idr, take a reference 
 One ref for being in the idr, one ref we just took 
  Remove the mark from the idr (if present) and drop the reference
  on the mark because it was in the idr.
	
	  does this i_mark think it is in the idr?  we shouldn't get called
	  if it wasn't....
 Lets look in the idr to see if we find it 
	
	  We found an mark in the idr at the right wd, but it's
	  not the mark we were told to remove.  eparis seriously
	  fucked up somewhere.
	
	  One ref for being in the idr
	  one ref grabbed by inotify_idr_find
 we can't really recover with bad ref cnting.. 
 Removed from the idr, drop that ref. 
 match the ref taken by inotify_idr_find_locked() 
  Send IN_IGNORED for this wd, remove this wd from the idr.
 Queue ignore event for the watch 
 remove this mark from the idr 
 more bits in old than in new? 
 more bits in this fsn_mark than the inode's mask? 
 update the inode with this new fsn_mark 
 return the wd 
 match the get from fsnotify_find_mark() 
 increment the number of watches the user has 
 we are on the idr, now get on the inode 
 we failed to get on the inode, get off the idr 
 return the watch descriptor for this new mark 
 match the ref from fsnotify_init_mark() 
 try to update and existing watch with the new arg 
 no mark present, try to add a new one 
 inotify syscalls 
 Check the IN_ constants for consistency.  
 fsnotify_obtain_group took a reference to group, we put this when we kill the file in the end 
	
	  We share a lot of code with fsdnotify.  We also share
	  the bit layout between inotify's IN_ and the fsnotify
	  FS_.  This check ensures that only the inotify IN_
	  bits get passed in and set in watchesevents.
	
	  Require at least one valid bit set in the mask.
	  Without _something_ set, we would have no events to
	  watch for.
 IN_MASK_ADD and IN_MASK_CREATE don't make sense together 
 verify that this is indeed an inotify instance 
 inode held in place by reference to path; group by fget on fd 
 createupdate an inode mark 
 verify that this is indeed an inotify instance 
 match ref taken by inotify_idr_find 
  inotify_user_setup - Our initialization function.  Note that we cannot return
  error because we have compiled-in VFS hooks.  So an (unlikely) failure here
  must result in panic().
	
	  Allow up to 1% of addressable memory to be allocated for inotify
	  watches (per user) limited to the range [8192, 1048576].
 SPDX-License-Identifier: GPL-2.0
 UINT_MAX 
	
	  full_name_hash() works long by long, so it handles fh buf optimally.
 Do not merge fid events without object fh 
 Do not merge name events without dir fh 
 Error events against the same file system are always merged. 
	
	  We want to merge many dirent events in the same dir (i.e.
	  createsunlinksrenames), but we do not want to merge dirent
	  events referring to subdirs with dirent events referring to
	  non subdirs, otherwise, user won't be able to tell from a
	  mask FAN_CREATE|FAN_DELETE|FAN_ONDIR if it describes mkdir+
	  unlink pair or rmdir+create pair of events.
 Limit event merges to limit CPU overhead per event 
 and the list better be locked by something too! 
	
	  Don't merge a permission event with any other event so that we know
	  the event structure we have created in fanotify_handle_event() is the
	  one we should check for permission response.
  Wait for response to permission event. The function also takes care of
  freeing the permission event (or offloads that in case the wait is canceled
  by a signal). The function returns 0 in case access got allowed by userspace,
  -EPERM in case userspace disallowed the access, and -ERESTARTSYS in case
  the wait got interrupted by a signal.
 Signal pending? 
 Event reported to userspace and no answer yet? 
 Event will get freed once userspace answers to it 
 Event not yet reported? Just remove it. 
 Permission events are not supposed to be hashed 
		
		  Event may be also answered in case signal delivery raced
		  with wakeup. In that case we have nothing to do besides
		  freeing the event and reporting error.
 userspace responded, convert to something usable 
 Check if the response should be audited 
  This function returns a mask for an event that only contains the flags
  that have been specifically requested by the user. Flags that may have
  been included within the event mask, but have not been explicitly
  requested by the user, will not be present in the returned mask.
 Do we have path to open a file descriptor? 
 Path type events are only relevant for files and dirs 
 Do we have a directory inode to report? 
 Apply ignore mask regardless of ISDIR and ON_CHILD flags 
		
		  If the event is on dir and this mark doesn't care about
		  events on dir, don't send it!
		
		  If the event is on a child and this mark is on a parent not
		  watching children, don't send it!
	
	  For dirent modification events (createdeletemove) that do not carry
	  the child entry name information, we report FAN_ONDIR for mkdirrmdir
	  so user can differentiate them from creatunlink.
	 
	  For backward compatibility and consistency, do not report FAN_ONDIR
	  to user in legacy fanotify mode (reporting fd) and report FAN_ONDIR
	  to user in fid mode for all event types.
	 
	  We never report FAN_EVENT_ON_CHILD to user, but we do pass it in to
	  fanotify_alloc_event() when group is reporting fid as indication
	  that event happened on child.
 Do not report event flags without any event 
  Check size needed to encode fanotify_fh.
  Return size of encoded fh without fanotify_fh header.
  Return 0 on failure to encode.
	
	  struct fanotify_error_event might be preallocated and is
	  limited to MAX_HANDLE_SZ.  This should never happen, but
	  safeguard by forcing an invalid file handle.
  Encode fanotify_fh.
  Return total size of encoded fh including fanotify_fh header.
  Return 0 on failure to encode.
	
	  Invalid FHs are used by FAN_FS_ERROR for errors not
	  linked to any inode. The f_handle won't be reported
	  back to userspace.
	
	  !gpf means preallocated variable size fh, but fh_len could
	  be zero in that case if encoding fh len failed.
 No external buffer in a variable size allocated fh 
 Treat failure to allocate fh as failure to encode fh 
	
	  Mix fh into event merge key.  Hash might be NULL in case of
	  unhashed FID events (i.e. FAN_FS_ERROR).
 Report the event without a file identifier on encode error 
  The inode to use as identifier when reporting fid depends on the event.
  Report the modified directory inode on dirent modification events.
  Report the "victim" inode otherwise.
  For example:
  FS_ATTRIB reports the child inode even if reported on a watched parent.
  FS_CREATE reports the modified dir inode and not the created inode.
  The inode to use as identifier when reporting dir fid depends on the event.
  Report the modified directory inode on dirent modification events.
  Report the "victim" inode if "victim" is a directory.
  Report the parent inode if "victim" is not a directory and event is
  reported to parent.
  Otherwise, do not report dir fid.
 Bad fh_len. Fallback to using an invalid fh. Should never happen. 
		
		  With both flags FAN_REPORT_DIR_FID and FAN_REPORT_FID, we
		  report the child fid for events reported on a non-dir child
		  in addition to reporting the parent fid and maybe child name.
		
		  We record file name only in a group with FAN_REPORT_NAME
		  and when we have a directory inode to report.
		 
		  For directory entry modification event, we record the fid of
		  the directory and the name of the modified entry.
		 
		  For event on non-directory that is reported to parent, we
		  record the fid of the parent and the name of the child.
		 
		  Even if not reporting name, we need a variable length
		  fanotify_name_event if reporting both parent and child fids.
	
	  For queues with unlimited length lost events are not expected and
	  can possibly have security implications. Avoid losing events when
	  memory is short. For the limited size queues, avoid OOM killer in the
	  target monitoring memcg as it may have security repercussion.
 Whoever is interested in the event, pays for the allocation. 
 Mix event info, FAN_ONDIR flag and pid into event merge key 
  Get cached fsid of the filesystem containing the object from any connector.
  All connectors are supposed to have the same fsid, but we do not verify that
  here.
 Mark is just getting destroyed or created? 
 Pairs with smp_wmb() in fsnotify_add_mark_list() 
  Add an event to hash table for faster merge.
		
		  fsnotify_prepare_user_wait() fails if we race with mark
		  deletion.  Just let the operation pass in that case.
 Racing with mark destruction or creation? 
		
		  We don't queue overflow events for permission events as
		  there the access is denied and so no event is in fact lost.
 Permission events shouldn't be merged 
 Our event wasn't used in the end. Free it. 
 SPDX-License-Identifier: GPL-2.0
  Legacy fanotify marks limits (8192) is per group and we introduced a tunable
  limit of marks per user, similar to inotify.  Effectively, the legacy limit
  of fanotify marks per user is <max marks per group>  <max groups per user>.
  This default limit (1M) also happens to match the increased limit of inotify
  max_user_watches since v5.10.
  Most of the memory cost of adding an inode mark is pinning the marked inode.
  The size of the filesystem inode struct is not uniform across filesystems,
  so double the size of a VFS inode is used as a conservative approximation.
 configurable via procsysfsfanotify 
 CONFIG_SYSCTL 
  All flags that may be specified in parameter event_f_flags of fanotify_init.
  Internal and external open flags are stored together in field f_flags of
  struct file. Only external open flags shall be allowed in event_f_flags.
  Internal flags like FMODE_NONOTIFY, FMODE_EXEC, FMODE_NOCMTIME shall be
  excluded.
		
		  With group flag FAN_REPORT_NAME, if name was not recorded in
		  event on a directory, we will report the name ".".
  Remove an hashed event from merge hash table.
  Get an fanotify notification event if one exists and is small
  enough to fit in "count". Return an error pointer if the count
  is not large enough. When permission event is dequeued, its state is
  updated accordingly.
	
	  Held the notification_lock the whole time, so this is the
	  same event we peeked above.
	
	  we need a new file handle for the userspace program so it can read even if it was
	  originally opened O_WRONLY.
		
		  we still send an event even if we can't open the file.  this
		  can happen when say tasks are gone and we try to open their
		  proc files or we try to open a WRONLY file like in sysfs
		  we just send the errno to userspace since there isn't much
		  else we can do.
  Finish processing of permission event by setting it to ANSWERED state and
  drop group->notification_lock.
	
	  make sure the response is valid, if invalid we do nothing and either
	  userspace can send a valid response or we will clean it up after the
	  timeout
	
	  Copy event info fid header followed by variable sized file handle
	  and optionally followed by variable sized filename.
 Mangle handle_type for bad file_handle 
	
	  For an inline fh and inline file name, copy through stack to exclude
	  the copy from usercopy hardening protections.
 Copy the filename with terminating null 
 Pad with 0's 
	
	  Event info records order is as follows: dir fid + name, child fid.
			
			  With only group flag FAN_REPORT_FID only type FID is
			  reported. Second info record type is always FID.
			
			  With group flag FAN_REPORT_NAME, if name was not
			  recorded in an event on a directory, report the name
			  "." with info type DFID_NAME.
			
			  With group flag FAN_REPORT_DIR_FID, a single info
			  record has type DFID for directory entry modification
			  event and for event on a directory.
			
			  With group flags FAN_REPORT_DIR_FID|FAN_REPORT_FID,
			  a single info record has type FID for event on a
			  non-directory, when there is no directory to report.
			  For example, on FAN_DELETE_SELF event.
	
	  For an unprivileged listener, event->pid can be used to identify the
	  events generated by the listener process itself, without disclosing
	  the pids of other processes.
	
	  For now, fid mode is required for an unprivileged listener and
	  fid mode does not report fd in events.  Keep this check anyway
	  for safety in case fid mode requirement is relaxed in the future
	  to allow unprivileged listener to get events with no fd and no fid.
		
		  Complain if the FAN_REPORT_PIDFD and FAN_REPORT_TID mutual
		  exclusion is ever lifted. At the time of incoporating pidfd
		  support within fanotify, the pidfd API only supported the
		  creation of pidfds for thread-group leaders.
		
		  The PIDTYPE_TGID check for an event->pid is performed
		  preemptively in an attempt to catch out cases where the event
		  listener reads events after the event generating process has
		  already terminated. Report FAN_NOPIDFD to the event listener
		  in those cases, with all other pidfd creation errors being
		  reported as FAN_EPIDFD.
	
	  Sanity check copy size in case get_one_event() and
	  event_len sizes ever get out of sync.
 intofiy userspace file descriptor functions 
		
		  User can supply arbitrarily large buffer. Avoid softlockups
		  in case there are lots of available events.
			
			  We cannot report events with stale fd so drop it.
			  Setting ret to 0 will continue the event loop and
			  do the right thing if there are no more events to
			  read (i.e. return bytes read, -EAGAIN or wait).
		
		  Permission events get queued to wait for response.  Other
		  events can be destroyed now.
	
	  Stop new events from arriving in the notification queue. since
	  userspace cannot use fanotify fd anymore, no event can enter or
	  leave access_list by now either.
	
	  Process all permission events on access_list and notification queue
	  and simulate reply from userspace.
	
	  Destroy all non-permission events. For permission events just
	  dequeue them and set the response. They will be freed once the
	  response is consumed and fanotify_get_response() returns.
 Response for all permission events it set, wakeup waiters 
 matches the fanotify_init->fsnotify_alloc_group 
 you can only watch an inode if you have read permissions on it 
 umask bits cannot be removed by user 
	
	  We need to keep the mark around even if remaining mask cannot
	  result in any events (e.g. mask == FAN_ONDIR) to support incremenal
	  changes to the mask.
	  Destroy mark when only umask bits remain.
 matches the fsnotify_find_mark() 
	
	  Enforce per user marks limits per user in all containing user ns.
	  A group with FAN_UNLIMITED_MARKS does not contribute to mark count
	  in the limited groups account.
	
	  Error events are pre-allocated per group, only if strictly
	  needed (i.e. FAN_FS_ERROR was requested).
	
	  If some other task has this inode open for write we should not add
	  an ignored mark, unless that ignored mark is supposed to survive
	  modification changes anyway.
 fanotify syscalls 
		
		  An unprivileged user can setup an fanotify group with
		  limited functionality - an unprivileged group is limited to
		  notification events with file handles and it cannot use
		  unlimited queuemarks.
		
		  Setting the internal flag FANOTIFY_UNPRIV on the group
		  prevents setting mountfilesystem marks on this group and
		  prevents reporting pid and open fd in events.
	
	  A pidfd can only be returned for a thread-group leader; thus
	  FAN_REPORT_PIDFD and FAN_REPORT_TID need to remain mutually
	  exclusive.
	
	  Child name is reported with parent fid so requires dir fid.
	  We can report both child fid and dir fid with or without name.
 fsnotify_alloc_group takes a ref.  Dropped in fanotify_release 
 Enforce groups limits per user in all containing user ns 
	
	  Make sure dentry is not of a filesystem with zero fsid (e.g. fuse).
	
	  Make sure dentry is not of a filesystem subvolume (e.g. btrfs)
	  which uses a different fsid than sb root.
 Check if filesystem can encode a unique fid 
	
	  We need to make sure that the file system supports at least
	  encoding a file handle so user can use name_to_handle_at() to
	  compare fid returned with event to the file handle of watched
	  objects. However, name_to_handle_at() requires that the
	  filesystem also supports decoding file handles.
	
	  Some filesystems such as 'proc' acquire unusual locks when opening
	  files. For them fanotify permission events have high chances of
	  deadlocking the system - open done when reporting fanotify event
	  blocks on this "unusual" lock while another process holding the lock
	  waits for fanotify permission event to be answered. Just disallow
	  permission events for such filesystems.
 we only use the lower 32 bits as of right now. 
 Event flags (ONDIR, ON_CHILD) are meaningless in ignored mask 
 verify that this is indeed an fanotify instance 
	
	  An unprivileged user is not allowed to setup mount nor filesystem
	  marks.  This also includes setting up such marks by a group that
	  was initialized by an unprivileged user.
	
	  group->priority == FS_PRIO_0 == FAN_CLASS_NOTIF.  These are not
	  allowed to set permissions events.
	
	  Events that do not carry enough information to report
	  event->fd require a group that supports reporting fid.  Those
	  events are not supported on a mount mark, because they do not
	  carry enough information (i.e. path) to be filtered by mount
	  point.
 inode held in place by reference to path; group by fget on fd 
 Mask out FAN_EVENT_ON_CHILD flag for sbmountnon-dir marks 
		
		  If group needs to report parent fid, register for getting
		  events with parentname info for non-directory.
 createupdate an inode mark 
  fanotify_user_setup - Our initialization function.  Note that we cannot return
  error because we have compiled-in VFS hooks.  So an (unlikely) failure here
  must result in panic().
	
	  Allow up to 1% of addressable memory to be accounted for per user
	  marks limited to the range [8192, 1048576]. mount and sb marks are
	  a lot cheaper than inode marks, but there is no reason for a user
	  to have many of those, so calculate by the cost of inode marks.
 SPDX-License-Identifier: GPL-2.0-or-later
  Directory notifications for Linux.
  Copyright (C) 2000,2001,2002 Stephen Rothwell
  Copyright (C) 2009 Eric Paris <Red Hat Inc>
  dnotify was largly rewritten to use the new fsnotify infrastructure
  dnotify will attach one of these to each inode (i_fsnotify_marks) which
  is being watched by dnotify.  If multiple userspace applications are watching
  the same directory with dnotify their information is chained in dn
  When a process starts or stops watching an inode the set of events which
  dnotify cares about for that inode may change.  This function runs the
  list of everything receiving dnotify events about this directory and calculates
  the set of all those events.  After it updates what dnotify is interested in
  it calls the fsnotify function so it can update the set of all events relevant
  to this inode.
  Mains fsnotify call where events are delivered to dnotify.
  Find the dnotify mark on the relevant inode, run the list of dnotify structs
  on that mark and determine which of them has expressed interest in receiving
  events of this type.  When found send the correct process and signal and
  destroy the dnotify struct if it was not registered to receive multiple
  events.
 not a dir, dnotify doesn't care 
  Called every time a file is closed.  Looks first for a dnotify mark on the
  inode.  If one is found run all of the ->dn structures attached to that
  mark for one relevant to this process closing the file and remove that
  dnotify_struct.  If that was the last dnotify_struct also remove the
  fsnotify_mark.
	 nothing else could have found us thanks to the dnotify_groups
 this conversion is done only at watch creation 
  If multiple processes watch the same inode with dnotify there is only one
  dnotify mark in inode->i_fsnotify_marks but we chain a dnotify_struct
  onto that mark.  This function either attaches the new dnotify_struct onto
  that list, or it |= the mask onto an existing dnofiy_struct.
 adding more events to existing dnofiy_struct? 
  When a process calls fcntl to attach a dnotify watch to a directory it ends
  up here.  Allocate both a mark for fsnotify to add and a dnotify_struct to be
  attached to the fsnotify_mark.
 we use these to tell if we need to kfree 
 a 0 mask means we are explicitly removing the watch 
 dnotify only works on directories 
	
	  convert the userspace DN_ "arg" to the internal FS_
	  defined in fsnotify
 expect most fcntl to add new rather than augment old 
 new fsnotify mark, we expect most fcntl calls to add a new mark 
 set up the new_fsn_mark and new_dn_mark 
 this is needed to prevent the fcntlclose race described below 
 add the new_fsn_mark or find an old one. 
 we used new_fsn_mark, so don't free it 
	 if (f != filp) means that we lost a race and another taskthread
	  actually closed the fd we are still playing with before we grabbed
	  the dnotify_groups mark_mutex and fsn_mark->lock.  Since closing the
	  fd is the only time we clean up the marks we need to get our mark
		 if we added ourselves, shoot ourselves, it's possible that
		  the flush actually did shoot this fsn_mark.  That's fine too
		  since multiple calls to destroy_mark is perfectly safe, if
		  we found a dn_mark already attached to the inode, just sod
		  off silently as the flush at close time dealt with it.
 !error means that we attached the dn to the dn_mark, so don't free it 
	 -EEXIST means that we didn't add this new dn and used an old one.
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2008 Red Hat, Inc.  All rights reserved.
  __gfs2_ail_flush - remove all buffers for a given lock from the AIL
  @gl: the glock
  @fsync: set when called from fsync (not all buffers will be clean)
  @nr_revokes: Number of buffers to revoke
  None of the buffers should be dirty, locked, or pinned.
		
		  We have nothing on the ail, but there could be revokes on
		  the sdp revoke queue, in which case, we still want to flush
		  the log and wait for it to finish.
		 
		  If the sdp revoke list is empty too, we might still have an
		  io outstanding for writing revokes, so we should wait for
		  it before returning.
		 
		  If none of these conditions are true, our revokes are all
		  flushed and we can return.
  gfs2_rgrp_metasync - sync out the metadata of a resource group
  @gl: the glock protecting the resource group
  rgrp_go_sync - sync out the metadata for this glock
  @gl: the glock
  Called when demoting or unlocking an EX glock.  We must flush
  to disk all dirty bufferspages relating to this glock, and must not
  return to caller to demoteunlock the glock until IO is complete.
  rgrp_go_inval - invalidate the metadata for this glock
  @gl: the glock
  @flags:
  We never used LM_ST_DEFERRED with resource groups, so that we
  should always see the metadata flag set here.
  gfs2_inode_metasync - sync out the metadata of an inode
  @gl: the glock protecting the inode
  inode_go_sync - Sync the dirty metadata of an inode
  @gl: the glock protecting the inode
	
	  Writeback of the data mapping may cause the dirty flag to be set
	  so we have to clear it again here.
  inode_go_inval - prepare a inode glock to be released
  @gl: the glock
  @flags:
  Normally we invalidate everything, but if we are moving into
  LM_ST_DEFERRED from LM_ST_SHARED or LM_ST_EXCLUSIVE then we
  can keep hold of the metadata, since it won't have changed.
  inode_go_demote_ok - Check to see if it's ok to unlock an inode glock
  @gl: the glock
  Returns: 1 if it's ok
 i_diskflags and i_eattr must be set before gfs2_set_inode_flags() 
  gfs2_inode_refresh - Refresh the incore copy of the dinode
  @ip: The GFS2 inode
  Returns: errno
  inode_go_instantiate - read in an inode if necessary
  @gh: The glock holder
  Returns: errno
 no inode to populate - read it in later 
  inode_go_dump - print information about an inode
  @seq: The iterator
  @gl: The glock
  @fs_id_buf: file system id (may be empty)
  freeze_go_sync - promotedemote the freeze glock
  @gl: the glock
	
	  We need to check gl_state == LM_ST_SHARED here and not gl_req ==
	  LM_ST_EXCLUSIVE. That's because when any node does a freeze,
	  all the nodes should have the freeze glock in SH mode and they all
	  call do_xmote: One for EX and the others for UN. They ALL must
	  freeze locally, and they ALL must queue freeze work. The freeze_work
	  calls freeze_func, which tries to reacquire the freeze glock in SH,
	  effectively waiting for the thaw on the node who holds it in EX.
	  Once thawed, the work func acquires the freeze glock in
	  SH and everybody goes back to thawed.
 read-only mounts 
  freeze_go_xmote_bh - After promotingdemoting the freeze glock
  @gl: the glock
  freeze_go_demote_ok
  @gl: the glock
  Always returns 0
  iopen_go_callback - schedule the dcache entry for the inode to be deleted
  @gl: the glock
  @remote: true if this came from a different cluster node
  gl_lockref.lock lock is held while calling this
  inode_go_free - wake up anyone waiting for dlm's unlock ast to free it
  @gl: glock being freed
  For now, this is only used for the journal inode glock. In withdraw
  situations, we need to wait for the glock to be freed so that we know
  other nodes may proceed with recovery  journal replay.
	 Note that we cannot reference gl_object because it's already set
  nondisk_go_callback - used to signal when a node did a withdraw
  @gl: the nondisk glock
  @remote: true if this came from a different cluster node
	 Ignore the callback unless it's from another node, and it's the
	 First order of business is to cancel the demote request. We don't
	  really want to demote a nondisk glock. At best it's just to inform
 Ignore the unlock if we're withdrawn, unmounting, or in recovery. 
	 We only care when a node wants us to unlock, because that means
	
	  We can't call remote_withdraw directly here or gfs2_recover_journal
	  because this is called from the glock unlock function and the
	  remote_withdraw needs to enqueue and dequeue the same "live" glock
	  we were called from. So we queue it to the control work queue in
	  lock_dlm.
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  lock_module. Originally from lock_dlm
 Wait for our primary journal to be initialized 
	
	  If we're a spectator, we use journal0, but it's not really ours.
	  So we need to wait for its recovery too. If we skip it we'd never
	  queue work to the recovery workqueue, and so its completion would
	  never clear the DFL_BLOCK_LOCKS flag, so all our locks would
	  permanently stop working.
  get and set struct gfs2_tune fields
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  gfs2_pin - Pin a buffer in memory
  @sdp: The superblock
  @bh: The buffer to be pinned
  The log lock must be held when calling this function
	 If this buffer is in the AIL and it has already been written
	  to in-place disk block, remove it from the AIL.
  gfs2_unpin - Unpin a buffer
  @sdp: the filesystem the buffer belongs to
  @bh: The buffer to unpin
  @tr: The system transaction being flushed
  gfs2_end_log_write_bh - end log write of pagecache data with buffers
  @sdp: The superblock
  @bvec: The bio_vec
  @error: The io status
  This finds the relevant buffers and unlocks them and sets the
  error flag according to the status of the io request. This is
  used when the log is writing data which has an in-place version
  that is pinned in the pagecache.
  gfs2_end_log_write - end of io to the log
  @bio: The bio
  Each bio_vec contains either data from the pagecache or data
  relating to the log itself. Here we iterate over the bio_vec
  array, processing both kinds of data.
 prevent more writes to the journal 
  gfs2_log_submit_bio - Submit any pending log bio
  @biop: Address of the bio pointer
  @opf: REQ_OP | op_flags
  Submit any pending part-built or full bio to the block device. If
  there is no pending bio, then this is a no-op.
  gfs2_log_alloc_bio - Allocate a bio
  @sdp: The super block
  @blkno: The device block number we want to write to
  @end_io: The bi_end_io callback
  Allocate a new bio, initialize it with the given parameters and return it.
  Returns: The newly allocated bio
  gfs2_log_get_bio - Get cached log bio, or allocate a new one
  @sdp: The super block
  @blkno: The device block number we want to write to
  @biop: The bio to get or allocate
  @op: REQ_OP
  @end_io: The bi_end_io callback
  @flush: Always flush the current bio and allocate a new one?
  If there is a cached bio, then if the next block number is sequential
  with the previous one, return it, otherwise flush the bio to the
  device. If there is no cached bio, or we just flushed it, then
  allocate a new one.
  Returns: The bio to use for log writes
  gfs2_log_write - write to log
  @sdp: the filesystem
  @jd: The journal descriptor
  @page: the page to write
  @size: the size of the data to write
  @offset: the offset within the page 
  @blkno: block number of the log entry
  Try and add the page segment to the current bio. If that fails,
  submit the current bio to the device and create a new one, and
  then add the page segment to that.
  gfs2_log_write_bh - write a buffer's content to the log
  @sdp: The super block
  @bh: The buffer pointing to the in-place location
  This writes the content of the buffer to the next available location
  in the log. The buffer will be unlocked once the io to the log has
  completed.
  gfs2_log_write_page - write one block stored in a page, into the log
  @sdp: The superblock
  @page: The struct page
  This writes the first block-sized part of the page into the log. Note
  that the page must have been allocated from the gfs2_page_pool mempool
  and that after this has been called, ownership has been transferred and
  the page may be freed at any time.
  gfs2_end_log_read - end IO callback for reads from the log
  @bio: The bio
  Simply unlock the pages in the bio. The main thread will wait on them and
  process them in order as necessary.
  gfs2_jhead_pg_srch - Look for the journal head in a given page.
  @jd: The journal descriptor
  @head: The journal head to start from
  @page: The page to look in
  Returns: 1 if found, 0 otherwise.
  gfs2_jhead_process_page - Searchcleanup a page
  @jd: The journal descriptor
  @index: Index of the page to look into
  @head: The journal head to start from
  @done: If set, perform only cleanup, else search and set if found.
  Find the page with 'index' in the journal's mapping. Search the page for
  the journal head if requested (cleanup == false). Release refs on the
  page so the page cache can reclaim it (put_page() twice). We grabbed a
  reference on this page two times, first when we did a find_or_create_page()
  to obtain the page to add it to the bio and second when we do a
  find_get_page() here to get the page to wait on while IO on it is being
  completed.
  This function is also used to free up a page we might've grabbed but not
  used. Maybe we added it to a bio, but not submitted it for IO. Or we
  submitted the IO, but we already found the jhead so we only need to drop
  our references to the page.
 Once for find_get_page 
 Once more for find_or_create_page 
  gfs2_find_jhead - find the head of a log
  @jd: The journal descriptor
  @head: The log descriptor for the head of the log is returned here
  @keep_cache: If set inode pages will not be truncated
  Do a search of a journal by reading it in large chunks using bios and find
  the valid log entry with the highest sequence number.  (i.e. the log head)
  Returns: 0 on success, errno otherwise
 Keep at least one bio in flight 
 found 
 503 for 4k blocks 
  databuf_lo_before_commit - Scan the data buffers, writing as we go
  @sdp: The filesystem
  @tr: The system transaction being flushed
 Unescape 
 FIXME: sort out accounting for log blocks etc. 
 data sync? 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
		
		  The reserved blocks are either used for data or metadata.
		  We can have mixed data and metadata, each with its own log
		  descriptor block; see calc_reserved().
	
	  Try the reservations under sd_log_flush_lock to prevent log flushes
	  from creating inconsistencies between the number of allocated and
	  reserved revokes.  If that fails, do a full-block allocation outside
	  of the lock to avoid stalling log flushes.  Then, allot the
	  appropriate number of blocks to revokes, use as many revokes locally
	  as needed, and "release" the surplus into the revokes pool.
  gfs2_trans_add_data - Add a databuf to the transaction.
  @gl: The inode glock associated with the buffer
  @bh: The buffer to add
  This is used in journaled data mode.
  We need to journal the data block in the same way as metadata in
  the functions above. The difference is that here we have a tag
  which is two __be64's being the block number (as per meta data)
  and a flag which says whether the data block needs escaping or
  not. This means we need a new log entry for each 251 or so data
  blocks, which isn't an enormous overhead but twice as much as
  for normal metadata blocks.
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2008 Red Hat, Inc.  All rights reserved.
  gfs2_tune_init - Fill a gfs2_tune structure with default values
  @gt: tune
  gfs2_check_sb - Check superblock
  @sdp: the filesystem
  @silent: Don't print a message if the check fails
  Checks the version code of the FS is one that we understand how to
  read and that the sizes of the various on-disk structures have not
  changed.
  gfs2_read_super - Read the gfs2 super block from disk
  @sdp: The GFS2 super block
  @sector: The location of the super block
  @silent: Don't print a message if the check fails
  This uses the bio functions to read the super block from disk
  because we want to be 100% sure that we never read cached data.
  A super block is read twice only during each GFS2 mount and is
  never written to by the filesystem. The first time its read no
  locks are held, and the only details which are looked at are those
  relating to the locking protocol. Once locking is up and working,
  the sb is read again under the lock to establish the location of
  the master directory (contains pointers to journals etc) and the
  root directory.
  Returns: 0 on success or error
  gfs2_read_sb - Read super block
  @sdp: The GFS2 superblock
  @silent: Don't print message if mount fails
 not the rgrp bitmap, subsequent bitmaps only 
	
	  We always keep at least one block reserved for revokes in
	  transactions.  This greatly simplifies allocating additional
	  revoke blocks.
 Compute maximum reservation required to add a entry to a directory 
  Try to autodetect  
 ignore );
 Set up the buffer cache and SB for real 
 Get the root inode 
 Get the master inode 
  gfs2_jindex_hold - Grab a lock on the jindex
  @sdp: The GFS2 superblock
  @ji_gh: the holder for the jindex glock
  Returns: errno
  init_statfs - look up and initialize master and local (per node) statfs inodes
  @sdp: The GFS2 superblock
  This should be called after the jindex is initialized in init_journal() and
  before gfs2_journal_recovery() is called because we need to be able to write
  to these inodes during recovery.
  Returns: errno
	 For each jid, lookup the corresponding local statfs inode in the
 read in the local statfs buffer - other nodes don't change it. 
 Uninitialize and free up memory used by the list of statfs inodes 
 Load in the journal index special file 
 Map the extents for this journal's blocks 
 Lookup statfs inodes here so journal recovery can use them. 
 A withdraw may have done dquninit so now we need to check it 
 Read in the resource index inode 
 Read in the quota inode 
	
	  i_rwsem on quota files is special. Since this inode is hidden system
	  file, we are safe to define locking ourselves.
  gfs2_lm_mount - mount a locking protocol
  @sdp: the filesystem
  @silent: if 1, don't complain if the FS isn't a GFS2 fs
  Returns: errno
 Obsolete, but left for backward compat purposes 
  gfs2_fill_super - Read in superblock
  @sb: The VFS superblock
  @fc: Mount options and flags
  Returns: -errno
	 Set up the buffer cache and fill in some fake block size values
 Turn rgrplvb on by default if fs format is recent enough 
	
	  If user space has failed to join the cluster or some similar
	  failure has occurred, then the journal id will contain a
	  negative (error) number. This will then be returned to the
	  caller (of the mount syscall). We do this even for spectator
	  mounts (which just write a jid of 0 to indicate "ok" even though
	  the jid is unused in the spectator case)
  gfs2_get_tree - Get the GFS2 superblock and root directory
  @fc: The filesystem context
  Returns: 0 or -errno on error
 quota can be a flag or an enum so it gets special treatment 
 Parse a single mount parameter 
 Retained for backwards compat only 
 Retained for backwards compat only 
 Retained for backwards compat only 
 The uint_32 result maps directly to GFS2_DATA_ 
 Set up the filesystem mount context 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  gfs2_drevalidate - Check directory lookup consistency
  @dentry: the mapping to check
  @flags: lookup flags
  Check to make sure the lookup necessary to arrive at this inode from its
  parent is still good.
  Returns: 1 if the dentry is ok, 0 if it isn't
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2007 Red Hat, Inc.  All rights reserved.
  gfs2_jindex_free - Clear all the journal index information
  @sdp: The GFS2 superblock
  gfs2_make_fs_rw - Turn a Read-Only FS into a Read-Write one
  @sdp: the filesystem
  Returns: errno
  Initialize some head of the log stuff  
  gfs2_lock_fs_check_clean - Stop all writes to the FS and check that all
                             journals are clean
  @sdp: the file system
  Returns: errno
  gfs2_write_inode - Make sure the inode is stable on the disk
  @inode: The inode
  @wbc: The writeback control structure
  Returns: errno
  gfs2_dirty_inode - check for atime updates
  @inode: The inode in question
  @flags: The type of dirty
  Unfortunately it can be called under any combination of inode
  glock and transaction lock, so we have to check carefully.
  At the moment this deals only with atime - it should be possible
  to expand that role in future, once a review of the locking has
  been carried out.
  gfs2_make_fs_ro - Turn a Read-Write FS into a Read-Only one
  @sdp: the filesystem
  Returns: errno
  gfs2_put_super - Unmount the filesystem
  @sb: The VFS superblock
 No more recovery requests 
 Wait on outstanding recovery 
  At this point, we're through modifying the disk  
  Release stuff  
  Take apart glock structures and buffer lists  
  Unmount the locking protocol  
  At this point, we're through participating in the lockspace  
  gfs2_sync_fs - sync the filesystem
  @sb: the superblock
  @wait: true to wait for completion
  Flushes the log to disk.
  gfs2_freeze - prevent further writes to the filesystem
  @sb: the VFS structure for the filesystem
  gfs2_unfreeze - reallow writes to the filesystem
  @sb: the VFS structure for the filesystem
  statfs_slow_fill - fill in the sg for a given RG
  @rgd: the RG
  @sc: the sc structure
  Returns: 0 on success, -ESTALE if the LVB is invalid
  gfs2_statfs_slow - Stat a filesystem using asynchronous locking
  @sdp: the filesystem
  @sc: the sc info that will be returned
  Any error (other than a signal) will cause this routine to fall back
  to the synchronous version.
  FIXME: This really shouldn't busy wait like this.
  Returns: errno
  gfs2_statfs_i - Do a statfs
  @sdp: the filesystem
  @sc: the sc structure
  Returns: errno
  gfs2_statfs - Gather and return stats about the filesystem
  @dentry: The name of the link
  @buf: The buffer
  Returns: 0 on success or error code
  gfs2_drop_inode - Drop an inode (test for remote unlink)
  @inode: The inode to drop
  If we've received a callback on an iopen lock then it's because a
  remote node tried to deallocate the inode but failed due to this node
  still having the inode open. Here we mark the link count zero
  since we know that it must have reached zero if the GLF_DEMOTE flag
  is set on the iopen glock. If we didn't do a disk read since the
  remote node removed the final link then we might otherwise miss
  this event. This check ensures that this node will deallocate the
  inode's blocks, or alternatively pass the baton on to another
  node for later deallocation.
	
	  When under memory pressure when an inode's link count has dropped to
	  zero, defer deleting the inode to the delete workqueue.  This avoids
	  calling into DLM under memory pressure, which can deadlock.
  gfs2_show_options - Show mount options for procmounts
  @s: seq_file structure
  @root: root of this (sub)tree
  Returns: 0 on success or error code
  gfs2_glock_put_eventually
  @gl:	The glock to put
  When under memory pressure, trigger a deferred glock put to make sure we
  won't call into DLM and deadlock.  Otherwise, put the glock directly.
	
	  If there are no other lock holders, we'll get the lock immediately.
	  Otherwise, the other nodes holding the lock will be notified about
	  our locking request.  If they don't have the inode open, they'll
	  evict the cached inode and release the lock.  Otherwise, if they
	  poke the inode glock, we'll take this as an indication that they
	  still need the iopen glock and that they'll take care of deleting
	  the inode when they're done.  As a last resort, if another node
	  keeps holding the iopen glock without showing any activity on the
	  inode glock, we'll eventually time out.
	 
	  Note that we're passing the LM_FLAG_TRY_1CB flag to the first
	  locking request as an optimization to notify lock holders as soon as
	  possible.  Without that flag, they'd be notified implicitly by the
	  second locking request.
  evict_should_delete - determine whether the inode is eligible for deletion
  @inode: The inode to evict
  @gh: The glock holder structure
  This function determines whether the evicted inode is eligible to be deleted
  and locks the inode glock.
  Returns: the fate of the dinode
 Deletes should never happen under memory pressure anymore.  
 Must not read inode block until block type has been verified 
	
	  The inode may have been recreated in the meantime.
  evict_unlinked_inode - delete the pieces of an unlinked evicted inode
  @inode: The inode to evict
	 We're about to clear the bitmap for the dinode, but as soon as we
	   do, gfs2_create_inode can create another inode at the same block
	   location and try to set gl_object again. We clear gl_object here so
  evict_linked_inode - evict an inode whose dinode has not been unlinked
  @inode: The inode to evict
 Needs to be done before glock release & also in a transaction 
  gfs2_evict_inode - Remove an inode from cache
  @inode: The inode to evict
  There are three cases to consider:
  1. i_nlink == 0, we are final opener (and must deallocate)
  2. i_nlink == 0, we are not the final opener (and cannot deallocate)
  3. i_nlink > 0
  If the fs is read only, then we have to treat all cases as per #3
  since we are unable to do any deallocation. The inode will be
  deallocated by the next readwrite node to attempt an allocation
  in the same resource group
  We have to (at the moment) hold the inodes main lock to cover
  the gap between unlocking the shared lock on the iopen lock and
  taking the exclusive lock. I'd rather do a shared -> exclusive
  conversion on the iopen lock, but we can change that later. This
  is safe, just less efficient.
 Run through the statfs inodes list to iput and free memory 
 belongs to this node 
	 Return the local (per node) statfs inode in the
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2008 Red Hat, Inc.  All rights reserved.
		
		  If it's a fully non-blocking write attempt and we cannot
		  lock the buffer then redirty the page.  Note that this can
		  potentially cause a busy-wait loop from flusher thread and kswapd
		  activity, but those code paths have their own higher-level
		  throttling.
	
	  The page and its buffers are protected by PageWriteback(), so we can
	  drop the bh refcounts early.
  gfs2_getbuf - Get a buffer with a given address space
  @gl: the glock
  @blkno: the block number (filesystem scope)
  @create: 1 if the buffer should be created
  Returns: the buffer
 convert block to page 
 block buf index within page 
 Locate header for our buffer within our page 
 Do nothing ;
  gfs2_meta_new - Get a block
  @gl: The glock associated with this block
  @blkno: The block number
  Returns: The buffer
  Submit several consecutive buffer head IO requests as a single bio IO
  request.  (See submit_bh_wbc.)
  gfs2_meta_read - Read a block from disk
  @gl: The glock covering the block
  @blkno: The block number
  @flags: flags
  @rahead: Do read-ahead
  @bhp: the place where the buffer is returned (NULL on failure)
  Returns: errno
  gfs2_meta_wait - Reread a block from disk
  @sdp: the filesystem
  @bh: The block to wait for
  Returns: errno
  gfs2_ail1_wipe - remove deletedfreed buffers from the ail1 list
  @sdp: superblock
  @bstart: starting block address of buffers to remove
  @blen: length of buffers to be removed
  This function is called from gfs2_journal wipe, whose job is to remove
  buffers, corresponding to deleted blocks, from the journal. If we find any
  bufdata elements on the system ail1 list, they haven't been written to
  the journal yet. So we remove them.
 convert block to page 
 Locate header for our buffer within our page 
 Do nothing ;
  gfs2_journal_wipe - make inode's buffers so they aren't dirtypinned anymore
  @ip: the inode who owns the buffers
  @bstart: the first buffer in the run
  @blen: the number of buffers in the run
  gfs2_meta_buffer - Get a metadata buffer
  @ip: The GFS2 inode
  @mtype: The block type (GFS2_METATYPE_)
  @num: The block number (device relative) of the buffer
  @bhp: the buffer is returned here
  Returns: errno
  gfs2_meta_ra - start readahead on an extent of a file
  @gl: the glock the blocks belong to
  @dblock: the starting disk block
  @extlen: the number of blocks in the extent
  returns: the first buffer in the extent
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  ea_calc_size - returns the actual number of bytes the request will take up
                 (not counting any unstuffed data blocks)
  Returns: 1 if the EA should be stuffed
 Stuffed 
 Unstuffed 
 This can only happen with 512 byte blocks 
  ea_dealloc_unstuffed
  Take advantage of the fact that all unstuffed blocks are
  allocated from the same RG.  But watch, this may not always
  be true.
  Returns: errno
  gfs2_listxattr - List gfs2 extended attributes
  @dentry: The dentry whose inode we are interested in
  @buffer: The buffer to write the results
  @size: The size of the buffer
  Returns: actual size of data on success, -errno on error
  gfs2_iter_unstuffed - copies the unstuffed xattr data tofrom the
                        request buffer
  @ip: The GFS2 inode
  @ea: The extended attribute header structure
  @din: The data to be copied in
  @dout: The data to be copied out (one of din,dout will be NULL)
  Returns: errno
  __gfs2_xattr_get - Get a GFS2 extended attribute
  @inode: The inode
  @name: The name of the extended attribute
  @buffer: The buffer to write the result into
  @size: The size of the buffer
  @type: The type of extended attribute
  Returns: actual size of data on success, -errno on error
 During lookup, SELinux calls this function with the glock locked. 
  ea_alloc_blk - allocates a new block for extended attributes.
  @ip: A pointer to the inode that's getting extended attributes
  @bhp: Pointer to pointer to a struct buffer_head
  Returns: errno
  ea_write - writes the request info to an ea, creating new blocks if
             necessary
  @ip: inode that is being modified
  @ea: the location of the new ea in a block
  @er: the write request
  Note: does not update ea_rec_len or the GFS2_EAFLAG_LAST bin of ea_flags
  returns : errno
  ea_init - initializes a new eattr block
  Returns: errno
  gfs2_xattr_remove - Remove a GFS2 extended attribute
  @ip: The inode
  @type: The type of the extended attribute
  @name: The name of the extended attribute
  This is not called directly by the VFS since we use the (common)
  scheme of making a "set with NULL data" mean a remove request. Note
  that this is different from a set with zero length data.
  Returns: 0, or errno on failure
  __gfs2_xattr_set - Set (or remove) a GFS2 extended attribute
  @inode: The inode
  @name: The name of the extended attribute
  @value: The value of the extended attribute (NULL for remove)
  @size: The size of the @value argument
  @flags: Create or Replace
  @type: The type of the extended attribute
  See gfs2_xattr_remove() for details of the removal of xattrs.
  Returns: 0 or errno on failure
 May be called from gfs_setattr with the glock locked. 
  gfs2_ea_dealloc - deallocate the extended attribute fork
  @ip: the inode
  Returns: errno
 GFS2_FS_FORMAT_MAX 
 GFS2_FS_FORMAT_MIN 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright 2004-2011 Red Hat, Inc.
  gfs2_update_stats - Update time based stats
  @s: The stats to update (local or global)
  @index: The index inside @s
  @sample: New data to include
	
	  @delta is the difference between the current rtt sample and the
	  running average srtt. We add 18 of that to the srtt in order to
	  update the current srtt estimate. The variance estimate is a bit
	  more complicated. We subtract the current variance estimate from
	  the abs value of the @delta and add 14 of that to the running
	  total.  That's equivalent to 34 of the current variance
	  estimate plus 14 of the abs of @delta.
	 
	  Note that the index points at the array entry containing the
	  smoothed mean value, and the variance is always in the following
	  entry
	 
	  Reference: TCPIP Illustrated, vol 2, p. 831,832
	  All times are in units of integer nanoseconds. Unlike the TCPIP
	  case, they are not scaled fixed point.
  gfs2_update_reply_times - Update locking statistics
  @gl: The glock to update
  This assumes that gl->gl_dstamp has been set earlier.
  The rtt (lock round trip time) is an estimate of the time
  taken to perform a dlm lock request. We update it on each
  reply from the dlm.
  The blocking flag is set on the glock for all dlm requests
  which may potentially block due to lock requests from other nodes.
  DLM requests where the current lock state is exclusive, the
  requested state is null (or unlocked) or where the TRY or
  TRY_1CB flags are set are classified as non-blocking. All
  other DLM requests are counted as (potentially) blocking.
 Local 
 Global 
  gfs2_update_request_times - Update locking statistics
  @gl: The glock to update
  The irt (lock inter-request times) measures the average time
  between requests to the dlm. It is updated immediately before
  each dlm call.
 Local 
 Global 
 Unlocked, so glock can be freed 
 Cancel while getting lock 
 Try lock fails 
 Deadlock detected 
 Canceled due to timeout 
 Success 
 Something unexpected 
 convert gfs lock-state to dlm lock-mode 
	
	  Submit the actual lock request.
 don't want to call dlm if we've unmounted the lock protocol 
 don't want to skip dlm_unlock writing the lvb when lock has one 
  dlmgfs2 recovery coordination using dlm_recover callbacks
   0. gfs2 checks for another cluster node withdraw, needing journal replay
   1. dlm_controld sees lockspace members change
   2. dlm_controld blocks dlm-kernel locking activity
   3. dlm_controld within dlm-kernel notifies gfs2 (recover_prep)
   4. dlm_controld starts and finishes its own user level recovery
   5. dlm_controld starts dlm-kernel dlm_recoverd to do kernel recovery
   6. dlm_recoverd notifies gfs2 of failed nodes (recover_slot)
   7. dlm_recoverd does its own lock recovery
   8. dlm_recoverd unblocks dlm-kernel locking activity
   9. dlm_recoverd notifies gfs2 when done (recover_done with new generation)
  10. gfs2_control updates control_lock lvb with new generation and jid bits
  11. gfs2_control enqueues journals for gfs2_recover to recover (maybe none)
  12. gfs2_recover dequeues and recovers journals of failed nodes
  13. gfs2_recover provides recovery results to gfs2_control (recovery_result)
  14. gfs2_control updates control_lock lvb jid bits for recovered journals
  15. gfs2_control unblocks normal locking when all journals are recovered
  - failures during recovery
  recover_prep() may set BLOCK_LOCKS (step 3) again before gfs2_control
  clears BLOCK_LOCKS (step 15), e.g. another node fails while still
  recovering for a prior failure.  gfs2_control needs a way to detect
  this so it can leave BLOCK_LOCKS set in step 15.  This is managed using
  the recover_block and recover_start values.
  recover_done() provides a new lockspace generation number each time it
  is called (step 9).  This generation number is saved as recover_start.
  When recover_prep() is called, it sets BLOCK_LOCKS and sets
  recover_block = recover_start.  So, while recover_block is equal to
  recover_start, BLOCK_LOCKS should remain set.  (recover_spin must
  be held around the BLOCK_LOCKSrecover_blockrecover_start logic.)
  - more specific gfs2 steps in sequence above
   3. recover_prep sets BLOCK_LOCKS and sets recover_block = recover_start
   6. recover_slot records any failed jids (maybe none)
   9. recover_done sets recover_start = new generation number
  10. gfs2_control sets control_lock lvb = new gen + bits for failed jids
  12. gfs2_recover does journal recoveries for failed jids identified above
  14. gfs2_control clears control_lock lvb bits for recovered jids
  15. gfs2_control checks if recover_block == recover_start (step 3 occured
      again) then do nothing, otherwise if recover_start > recover_block
      then clear BLOCK_LOCKS.
  - parallel recovery steps across all nodes
  All nodes attempt to update the control_lock lvb with the new generation
  number and jid bits, but only the first to get the control_lock EX will
  do so; others will see that it's already done (lvb already contains new
  generation number.)
  . All nodes get the same recover_preprecover_slotrecover_done callbacks
  . All nodes attempt to set control_lock lvb gen + bits for the new gen
  . One node gets control_lock first and writes the lvb, others see it's done
  . All nodes attempt to recover jids for which they see control_lock bits set
  . One node succeeds for a jid, and that one clears the jid bit in the lvb
  . All nodes will eventually see all lvb bits clear and unblock locks
  - is there a problem with clearing an lvb bit that should be set
    and missing a journal recovery?
  1. jid fails
  2. lvb bit set for step 1
  3. jid recovered for step 1
  4. jid taken again (new mount)
  5. jid fails (for step 4)
  6. lvb bit set for step 5 (will already be set)
  7. lvb bit cleared for step 3
  This is not a problem because the failure in step 5 does not
  require recovery, because the mount in step 4 could not have
  progressed far enough to unblock locks and access the fs.  The
  control_mount() function waits for all recoveries to be complete
  for the latest lockspace generation before ever unblocking locks
  and returning.  The mount in step 4 waits until the recovery in
  step 1 is done.
  - special case of first mounter: first node to mount the fs
  The first node to mount a gfs2 fs needs to check all the journals
  and recover any that need recovery before other nodes are allowed
  to mount the fs.  (Others may begin mounting, but they must wait
  for the first mounter to be done before taking locks on the fs
  or accessing the fs.)  This has two parts:
  1. The mounted_lock tells a node it's the first to mount the fs.
  Each node holds the mounted_lock in PR while it's mounted.
  Each node tries to acquire the mounted_lock in EX when it mounts.
  If a node is granted the mounted_lock EX it means there are no
  other mounted nodes (no PR locks exist), and it is the first mounter.
  The mounted_lock is demoted to PR when first recovery is done, so
  others will fail to get an EX lock, but will get a PR lock.
  2. The control_lock blocks others in control_mount() while the first
  mounter is doing first mount recovery of all journals.
  A mounting node needs to acquire control_lock in EX mode before
  it can proceed.  The first mounter holds control_lock in EX while doing
  the first mount recovery, blocking mounts from other nodes, then demotes
  control_lock to NL when it's done (others_may_mountfirst_done),
  allowing other nodes to continue mounting.
  first mounter:
  control_lock EXNOQUEUE success
  mounted_lock EXNOQUEUE success (no other PR, so no other mounters)
  set first=1
  do first mounter recovery
  mounted_lock EX->PR
  control_lock EX->NL, write lvb generation
  other mounter:
  control_lock EXNOQUEUE success (if fail -EAGAIN, retry)
  mounted_lock EXNOQUEUE fail -EAGAIN (expected due to other mounters PR)
  mounted_lock PRNOQUEUE success
  read lvb generation
  control_lock EX->NL
  set first=0
  - mount during recovery
  If a node mounts while others are doing recovery (not first mounter),
  the mounting node will get its initial recover_done() callback without
  having seen any previous failurescallbacks.
  It must wait for all recoveries preceding its mount to be finished
  before it unblocks locks.  It does this by repeating the "other mounter"
  steps above until the lvb generation number is >= its mount generation
  number (from initial recover_done) and all lvb bits are clear.
  - control_lock lvb format
  4 bytes generation number: the latest dlm lockspace generation number
  from recover_done callback.  Indicates the jid bitmap has been updated
  to reflect all slot failures through that generation.
  4 bytes unused.
  GDLM_LVB_SIZE-8 bytes of jid bit map. If bit N is set, it indicates
  that jid N needs recovery.
 4 byte generation number + 4 byte unused 
  remote_withdraw - react to a node withdrawing from the file system
  @sdp: The superblock
 Now drop the additional reference we acquired 
 First check for other nodes that may have done a withdraw. 
	
	  No MOUNT_DONE means we're still mounting; control_mount()
	  will set this flag, after which this thread will take over
	  all further clearing of BLOCK_LOCKS.
	 
	  FIRST_MOUNT means this node is doing first mounter recovery,
	  for which recovery control is handled by
	  control_mount()control_first_done(), not this thread.
	
	  Equal block_gen and start_gen implies we are between
	  recover_prep and recover_done callbacks, which means
	  dlm recovery is in progress and dlm locking is blocked.
	  There's no point trying to do any work until recover_done.
	
	  Propagate recover_submit[] and recover_result[] to lvb:
	  dlm_recoverd adds to recover_submit[] jids needing recovery
	  gfs2_recover adds to recover_result[] journal recovery results
	 
	  set lvb bit for jids in recover_submit[] if the lvb has not
	  yet been updated for the generation of the failure
	 
	  clear lvb bit for jids in recover_result[] if the result of
	  the journal recovery is SUCCESS
		
		  Clear lvb bits for jids we've successfully recovered.
		  Because all nodes attempt to recover failed journals,
		  a journal can be recovered multiple times successfully
		  in succession.  Only the first will really do recovery,
		  the others find it clean, but still report a successful
		  recovery.  So, another node may have already recovered
		  the jid and cleared the lvb bit for it.
		
		  Failed slots before start_gen are already set in lvb.
		
		  Failed slots before start_gen are not yet set in lvb.
		 even if there are no bits to set, we need to write the
		
		  we should be getting a recover_done() for lvb_gen soon
	
	  Everyone will see jid bits set in the lvb, run gfs2_recover_set(),
	  and clear a jid bit in the lvb if the recovery is a success.
	  Eventually all journals will be recovered, all jid bits will
	  be cleared in the lvb, and everyone will clear BLOCK_LOCKS.
	
	  No more jid bits set in lvb, all recovery is done, unblock locks
	  (unless a new recover_prep callback has occured blocking locks
	  again while working above)
	
	  We always start with both locks in NL. control_lock is
	  demoted to NL below so we don't need to do it here.
	
	  Other nodes need to do some work in dlm recovery and gfs2_control
	  before the recover_done and control_lock will be ready for us below.
	  A delay here is not required but often avoids having to retry.
	
	  Acquire control_lock in EX and mounted_lock in either EX or PR.
	  control_lock lvb keeps track of any pending journal recoveries.
	  mounted_lock indicates if any other nodes have the fs mounted.
	
	  If we're a spectator, we don't want to take the lock in EX because
	  we cannot do the first-mount responsibility it implies: recovery.
 not even -EAGAIN should happen here 
	
	  If we got both locks above in EX, then we're the first mounter.
	  If not, then we need to wait for the control_lock lvb to be
	  updated by other mounted nodes to reflect our mount generation.
	 
	  In simple first mounter cases, first mounter will see zero lvb_gen,
	  but in cases where all existing nodes leavefail before mounting
	  nodes finish control_mount, then all nodes will be mounting and
	  lvb_gen will be non-zero.
 special value to force mount attempts to fail 
 first mounter, keep both EX while doing first recovery 
	
	  We are not first mounter, now we need to wait for the control_lock
	  lvb generation to be >= the generation from our first recover_done
	  and all lvb bits to be clear (no pending journal recoveries.)
 journals need recovery, wait until all are clear 
		 wait for mounted nodes to update control_lock lvb to our
		 wait for mounted nodes to update control_lock lvb to the
 dlm recovery in progress, wait for it to finish 
 sanity check, should not happen 
		
		  Wait for the end of a dlm recovery cycle to switch from
		  first mounter recovery.  We can ignore any recover_slot
		  callbacks between the recover_prep and next recover_done
		  because we are still the first mounter and any failed nodes
		  have not fully mounted, so they don't need recovery.
  Expand static jid arrays if necessary (by increments of RECOVER_SIZE_INC)
  to accomodate the largest slot number.  (NB dlm slot numbers start at 1,
  gfs2 jids start at 0, so jid = slot - 1)
 dlm calls before it does lock recovery 
 dlm calls after recover_prep has been completed on all lockspace members;
 dlm calls after recover_slot and after it completes lock recovery 
 ensure the ls jid arrays are large enough 
 gfs2_recover thread has a journal recovery result 
 don't care about the recovery of own journal during mount 
	 GAVEUP means another node is recovering the journal; delay our
	   next attempt to recover it, to give the other node a chance to
	
	  initialize everything
	
	  prepare dlm_new_lockspace args
	
	  createjoin lockspace
		
		  dlm does not support ops callbacks,
		  old dlm_controldgfs_controld are used, try without ops.
	
	  control_mount() uses control_lock to determine first mounter,
	  and for later mounts, waits for any recoveries to be cleared.
 wait for gfs2_control_wq to be done with this mount 
 mounted_lock and control_lock will be purged in dlm recovery 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2011 Red Hat, Inc.  All rights reserved.
  gfs2_set_iop - Sets inode operations
  @inode: The inode with correct i_mode filled in
  GFS2 lookup code fills in vfs inode contents based on info obtained
  from directory entry inside gfs2_inode_lookup().
  gfs2_inode_lookup - Lookup an inode
  @sb: The super block
  @type: The type of the inode
  @no_addr: The inode number
  @no_formal_ino: The inode generation number
  @blktype: Requested block type (GFS2_BLKST_DINODE or GFS2_BLKST_UNLINKED;
            GFS2_BLKST_FREE to indicate not to verify)
  If @type is DT_UNKNOWN, the inode type is fetched from disk.
  If @blktype is anything other than GFS2_BLKST_FREE (which is used as a
  placeholder because it doesn't otherwise make sense), the on-disk block type
  is verified to be @blktype.
  When @no_formal_ino is non-zero, this function will return ERR_PTR(-ESTALE)
  if it detects that @no_formal_ino doesn't match the actual inode generation
  number.  However, it doesn't always know unless @type is DT_UNKNOWN.
  Returns: A VFS inode, or an error
			
			  The GL_SKIP flag indicates to skip reading the inode
			  block.  We read the inode with gfs2_inode_refresh
			  after possibly checking the block type.
 Lowest possible timestamp; will be overwritten in gfs2_dinode_in. 
 Inode glock must be locked already 
  gfs2_lookup_by_inum - look up an inode by inode number
  @sdp: The super block
  @no_addr: The inode number
  @no_formal_ino: The inode generation number (0 for any)
  @blktype: Requested block type (see gfs2_inode_lookup)
	 gfs2_lookupi has inconsistent callers: vfs
	  related routines expect NULL for no entry found,
	  gfs2_lookup_simple callers expect ENOENT
	  and do not check for NULL.
  gfs2_lookupi - Look up a filename in a directory and return its inode
  @dir: The inode of the directory containing the inode to look-up
  @name: The name of the inode to look for
  @is_root: If 1, ignore the caller's permissions
  This can be called via the VFS filldir function when NFS is doing
  a readdirplus and the inode which its intending to stat isn't
  already in cache. In this case we must not take the directory glock
  again, since the readdir call will have already taken that lock.
  Returns: errno
  create_ok - OK to create a new on-disk inode here?
  @dip:  Directory in which dinode is to be created
  @name:  Name of new dinode
  @mode:
  Returns: errno
  Don't create entries in an unlinked directory  
 already GFS2 endian 
  gfs2_init_xattr - Initialise an xattr block for a new inode
  @ip: The inode in question
  This sets up an empty xattr block for a new inode, ready to
  take any ACLs, LSM xattrs, etc.
  init_dinode - Fill in a new dinode structure
  @dip: The directory this inode is being created in
  @ip: The inode
  @symname: The symlink destination (if a symlink)
  gfs2_trans_da_blks - Calculate number of blocks to link inode
  @dip: The directory we are linking into
  @da: The dir add information
  @nr_inodes: The number of inodes involved
  This calculate the number of blocks we need to reserve in a
  transaction to link @nr_inodes into a directory. In most cases
  @nr_inodes will be 2 (the directory plus the inode being linked in)
  but in case of rename, 4 may be required.
  Returns: Number of blocks
  gfs2_create_inode - Create a new inode
  @dir: The parent directory
  @dentry: The new dentry
  @file: If non-NULL, the file which is being opened
  @mode: The permissions on the new inode
  @dev: For device nodes, this is the device number
  @symname: For symlinks, this is the link destination
  @size: The initial size of the inode (ignored for directories)
  @excl: Force fail if inode exists
  Returns: 0 on success, or error code
 Temporarily zero until real addr is assigned 
 Force SYSTEM flag on all files and subdirs of a SYSTEM directory 
	free_vfs_inode = 0;  After this point, the inode is no longer
			       considered free. Any failures need to undo
	 After instantiate, errors should result in evict which will destroy
 else evict will do the put for us 
  gfs2_create - Create a file
  @mnt_userns: User namespace of the mount the inode was found from
  @dir: The directory in which to create the file
  @dentry: The dentry of the new file
  @mode: The mode of the new file
  @excl: Force fail if inode exists
  Returns: errno
  __gfs2_lookup - Look up a filename in a directory and return its inode
  @dir: The directory inode
  @dentry: The dentry of the new inode
  @file: File to be opened
  Returns: errno
  gfs2_link - Link to a file
  @old_dentry: The inode to link
  @dir: Add link to this directory
  @dentry: The name of the link
  Link the inode in "old_dentry" into the directory "dir" with the
  name in "dentry".
  Returns: errno
 parent 
 child 
  gfs2_unlink_ok - check to see that a inode is still in a directory
  @dip: the directory
  @name: the name of the file
  @ip: the inode
  Assumes that the lock on (at least) @dip is held.
  Returns: 0 if the parentchild relationship is correct, errno if it isn't
  gfs2_unlink_inode - Removes an inode from its parent dir and unlinks it
  @dip: The parent directory
  @dentry: The dentry to unlink
  Called with all the locks and in a transaction. This will only be
  called for a directory after it has been checked to ensure it is empty.
  Returns: 0 on success, or an error
  gfs2_unlink - Unlink an inode (this does rmdir as well)
  @dir: The inode of the directory containing the inode to unlink
  @dentry: The file itself
  This routine uses the type of the inode as a flag to figure out
  whether this is an unlink or an rmdir.
  Returns: errno
 parent 
 child 
 rgrp 
  gfs2_symlink - Create a symlink
  @mnt_userns: User namespace of the mount the inode was found from
  @dir: The directory to create the symlink in
  @dentry: The dentry to put the symlink in
  @symname: The thing which the link points to
  Returns: errno
  gfs2_mkdir - Make a directory
  @mnt_userns: User namespace of the mount the inode was found from
  @dir: The parent directory of the new one
  @dentry: The dentry of the new directory
  @mode: The mode of the new directory
  Returns: errno
  gfs2_mknod - Make a special file
  @mnt_userns: User namespace of the mount the inode was found from
  @dir: The directory in which the special file will reside
  @dentry: The dentry of the special file
  @mode: The mode of the special file
  @dev: The device specification of the special file
  gfs2_atomic_open - Atomically open a file
  @dir: The directory
  @dentry: The proposed new entry
  @file: The proposed new struct file
  @flags: open flags
  @mode: File mode
  Returns: error code or 0 for success
  gfs2_ok_to_move - check if it's ok to move a directory to another directory
  @this: move this
  @to: to here
  Follow @to back to the root and make sure we don't encounter @this
  Assumes we already hold the rename lock.
  Returns: errno
  update_moved_ino - Update an inode that's being moved
  @ip: The inode being moved
  @ndip: The parent directory of the new filename
  @dir_rename: True of ip is a directory
  Returns: errno
  gfs2_rename - Rename a file
  @odir: Parent directory of old file name
  @odentry: The old dentry of the file
  @ndir: Parent directory of new file name
  @ndentry: The new dentry of the file
  Returns: errno
 don't move a directory into its subdir 
		 Grab the resource group glock for unlink flag twiddling.
		  This is the case where the target dinode already exists
		  so we unlink before doing the rename.
 Check out the old directory 
 Check out the new directory 
 Check out the dir to be renamed 
 Remove the target file, if it exists 
  gfs2_exchange - exchange two files
  @odir: Parent directory of old file name
  @odentry: The old dentry of the file
  @ndir: Parent directory of new file name
  @ndentry: The new dentry of the file
  @flags: The rename flags
  Returns: errno
 don't move a directory into its subdir 
 don't move a directory into its subdir 
  gfs2_get_link - Follow a symbolic link
  @dentry: The dentry of the link
  @inode: The inode of the link
  @done: destructor for return value
  This can handle symlinks of any size.
  Returns: 0 on success or error code
  gfs2_permission
  @mnt_userns: User namespace of the mount the inode was found from
  @inode: The inode
  @mask: The mask to be tested
  This may be called from the VFS directly, or from within GFS2 with the
  inode locked, so we look to see if the glock is already locked and only
  lock the glock if its not already been done.
  Returns: errno
  gfs2_setattr - Change attributes on an inode
  @mnt_userns: User namespace of the mount the inode was found from
  @dentry: The dentry which is changing
  @attr: The structure describing the change
  The VFS layer wants to change one or more of an inodes attributes.  Write
  that change out to disk.
  Returns: errno
  gfs2_getattr - Read out an inode's attributes
  @mnt_userns:	user namespace of the mount the inode was found from
  @path: Object to query
  @stat: The inode's stats
  @request_mask: Mask of STATX_xxx flags indicating the caller's interests
  @flags: AT_STATX_xxx setting
  This may be called from the VFS directly, or from within GFS2 with the
  inode locked, so we look to see if the glock is already locked and only
  lock the glock if its not already been done. Note that its the NFS
  readdirplus operation which causes this to be called (from filldir)
  with the glock already held.
  Returns: errno
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2008 Red Hat, Inc.  All rights reserved.
 The offset is bitmap relative 
 Bitmap index 
  These routines are used by the resource group routines (rgrp.c)
  to keep track of block allocation.  Each block is represented by two
  bits.  So, each byte represents GFS2_NBBY (i.e. 4) blocks.
  0 = Free
  1 = Used (not metadata)
  2 = Unlinked (still in use) inode
  3 = Used (metadata)
 current 
 n  0, 1, 1, 1,
 e  1, 0, 0, 0,
 w  0, 0, 0, 1,
  gfs2_setbit - Set a bit in the bitmaps
  @rbm: The position of the bit to set
  @do_clone: Also set the clone bitmap, if it exists
  @new_state: the new state of the block
  gfs2_testbit - test a bit in the bitmaps
  @rbm: The bit to test
  @use_clone: If true, test the clone bitmap, not the official bitmap.
  Some callers like gfs2_unaligned_extlen need to test the clone bitmaps,
  not the "real" bitmaps, to avoid allocating recently freed blocks.
  Returns: The two bit block state of the requested bit
  gfs2_bit_search
  @ptr: Pointer to bitmap data
  @mask: Mask to use (normally 0x55555.... but adjusted for search start)
  @state: The state we are searching for
  We xor the bitmap data with a patter which is the bitwise opposite
  of what we are looking for, this gives rise to a pattern of ones
  wherever there is a match. Since we have two bits per entry, we
  take this pattern, shift it down by one place and then and it with
  the original. All the even bit positions (0,2,4, etc) then represent
  successful matches, so we mask with 0x55555..... to remove the unwanted
  odd bit positions.
  This allows searching of a whole u64 at once (32 blocks) with a
  single test (on 64 bit arches).
  rs_cmp - multi-block reservation range compare
  @start: start of the new reservation
  @len: number of blocks in the new reservation
  @rs: existing reservation to compare against
  returns: 1 if the block range is beyond the reach of the reservation
          -1 if the block range is before the start of the reservation
           0 if the block range overlaps with the reservation
  gfs2_bitfit - Search an rgrp's bitmap buffer to find a bit-pair representing
        a block in a given allocation state.
  @buf: the buffer that holds the bitmaps
  @len: the length (in bytes) of the buffer
  @goal: start search at this block's bit-pair (within @buffer)
  @state: GFS2_BLKST_XXX the state of the block we're looking for.
  Scope of @goal and returned block number is only within this bitmap buffer,
  not entire rgrp or filesystem.  @buffer will be offset from the actual
  beginning of a bitmap block buffer, skipping any header structures, but
  headers are always a multiple of 64 bits long so that the buffer is
  always aligned to a 64 bit boundary.
  The size of the buffer is in bytes, but is it assumed that it is
  always ok to read a complete multiple of 64 bits at the end
  of the block in case the end is no aligned to a natural boundary.
  Return: the block number (bitmap buffer scope) that was found
 Mask off bits we don't care about at the start of the search 
 Mask off any bits which are more than len bytes from the start 
 Didn't find anything, so return 
 two bits per entry in the bitmap 
  gfs2_rbm_from_block - Set the rbm based upon rgd and block number
  @rbm: The rbm with rgd already set correctly
  @block: The block number (filesystem relative)
  This sets the bi and offset members of an rbm based on a
  resource group and a filesystem relative block number. The
  resource group must be set in the rbm on entry, the bi and
  offset members will be set by this function.
  Returns: 0 on success, or an error code
 Check if the block is within the first block 
 Adjust for the size diff between gfs2_meta_header and gfs2_rgrp 
  gfs2_rbm_add - add a number of blocks to an rbm
  @rbm: The rbm with rgd already set correctly
  @blocks: The number of blocks to add to rpm
  This function takes an existing rbm structure and adds a number of blocks to
  it.
  Returns: True if the new rbm would point past the end of the rgrp.
  gfs2_unaligned_extlen - Look for free blocks which are not byte aligned
  @rbm: Position to search (valueresult)
  @n_unaligned: Number of unaligned blocks to check
  @len: Decremented for each block found (terminate on zero)
  Returns: true if a non-free block is encountered or the end of the resource
 	    group is reached.
  gfs2_free_extlen - Return extent length of free blocks
  @rrbm: Starting position
  @len: Max length to check
  Starting at the block specified by the rbm, see how many free blocks
  there are, not reading more than len blocks ahead. This can be done
  using memchr_inv when the blocks are byte aligned, but has to be done
  on a block by block basis in case of unaligned blocks. Also this
  function can cope with bitmap boundaries (although it must stop on
  a resource group boundary)
  Returns: Number of free blocks in the extent
 Start is now byte aligned 
 Deal with any bits left over at the end 
  gfs2_bitcount - count the number of bits in a certain state
  @rgd: the resource group descriptor
  @buffer: the buffer that holds the bitmaps
  @buflen: the length (in bytes) of the buffer
  @state: the state of the block we're looking for
  Returns: The number of bits
  gfs2_rgrp_verify - Verify that a resource group is consistent
  @rgd: the rgrp
 Count # blocks in each of 4 possible allocation states 
  gfs2_blk2rgrpd - Find resource group for a given datameta block number
  @sdp: The GFS2 superblock
  @blk: The data block number
  @exact: True if this needs to be an exact match
  The @exact argument should be set to true by most callers. The exception
  is when we need to match blocks which are not represented by the rgrp
  bitmap, but which are part of the rgrp (i.e. padding blocks) which are
  there for alignment purposes. Another way of looking at it is that @exact
  matches only valid datametadata blocks, but with @exact false, it will
  match any block within the extent of the rgrp.
  Returns: The resource group, or NULL if not found
  gfs2_rgrpd_get_first - get the first Resource Group in the filesystem
  @sdp: The GFS2 superblock
  Returns: The first rgrp in the filesystem
  gfs2_rgrpd_get_next - get the next RG
  @rgd: the resource group descriptor
  Returns: The next rgrp
  __rs_deltree - remove a multi-block reservation from the rgd tree
  @rs: The reservation to remove
 return requested blocks to the rgrp 
		 The rgrp extent failure point is likely not to increase;
		   it will only do so if the freed blocks are somehow
		   contiguous with a span of free blocks that follows. Still,
  gfs2_rs_deltree - remove a multi-block reservation from the rgd tree
  @rs: The reservation to remove
  gfs2_rs_delete - delete a multi-block reservation
  @ip: The inode for this reservation
  @wcount: The inode's write count, or NULL
  return_all_reservations - return all reserved blocks back to the rgrp.
  @rgd: the rgrp that needs its space back
  We previously reserved a bunch of blocks for allocation. Now we need to
  give them back. This leave the reservation structures in tact, but removes
  all of their corresponding "no-fly zones".
  compute_bitstructs - Compute the bitmap sizes
  @rgd: The resource group descriptor
  Calculates bitmap descriptors, one for each block that contains bitmap data
  Returns: errno
 # blocks in hdr & bitmap 
 small rgrp; bitmap stored completely in header block 
 header block 
 last block 
 other blocks 
  gfs2_ri_total - Total up the file system space, according to the rindex.
  @sdp: the filesystem
 Figure out where to put new node 
  read_rindex_entry - Pull in a new resource index entry from the disk
  @ip: Pointer to the rindex inode
  Returns: 0 on success, > 0 on EOF, error code otherwise
 someone else read in the rgrp; free it and ignore it 
  set_rgrp_preferences - Run all the rgrps, selecting some we prefer to use
  @sdp: the GFS2 superblock
  The purpose of this function is to select a subset of the resource groups
  and mark them as PREFERRED. We do it in such a way that each node prefers
  to use a unique set of rgrps to minimize glock contention.
	 Skip an initial number of rgrps, based on this node's journal ID.
  gfs2_ri_update - Pull in a new resource index from the disk
  @ip: pointer to the rindex inode
  Returns: 0 on successful update, error code otherwise
  gfs2_rindex_update - Update the rindex if required
  @sdp: The GFS2 superblock
  We grab a lock on the rindex inode to make sure that it doesn't
  change whilst we are performing an operation. We keep this lock
  for quite long periods of time compared to other locks. This
  doesn't matter, since it is shared and it is very, very rarely
  accessed in the exclusive mode (i.e. only when expanding the filesystem).
  This makes sure that we're using the latest copy of the resource index
  special file, which might have been updated if someone expanded the
  filesystem (via gfs2_grow utility), which adds new resource groups.
  Returns: 0 on succeess, error code otherwise
 Read new copy from disk if we don't have the latest 
 rd_data0, rd_data and rd_bitbytes already set from rindex 
  gfs2_rgrp_go_instantiate - Read in a RG's header and bitmaps
  @gh: the glock holder representing the rgrpd to read in
  Read in all of a Resource Group's header and bitmap blocks.
  Caller must eventually call gfs2_rgrp_brelse() to free the bitmaps.
  Returns: errno
 max out the rgrp allocation failure point 
 max out the rgrp allocation failure point 
  gfs2_rgrp_brelse - Release RG bitmaps read in with gfs2_rgrp_bh_get()
  @rgd: The resource group
  gfs2_fitrim - Generate discard requests for unused bits of the filesystem
  @filp: Any file on the filesystem
  @argp: Pointer to the arguments (also used to pass result)
  Returns: 0 on success, otherwise error code
 start is beyond the end of the fs 
 Trim each bitmap in the rgrp 
 Mark rgrp as having been trimmed 
  rs_insert - insert a new multi-block reservation into the rgrp's rb_tree
  @ip: the inode structure
 Do our rgrp accounting for the reservation 
 blocks requested 
  rgd_free - return the number of free blocks we can allocate
  @rgd: the resource group
  @rs: The reservation to free
  This function returns the number of free blocks for an rgrp.
  That's the clone-free blocks (blocks that are free, not including those
  still being used for unlinked files that haven't been deleted.)
  It also subtracts any blocks reserved by someone else, but does not
  include free blocks that are still part of our current reservation,
  because obviously we can (and will) allocate them.
  rg_mblk_search - find a group of multiple free blocks to form a reservation
  @rgd: the resource group descriptor
  @ip: pointer to the inode for which we're reserving blocks
  @ap: the allocation parameters
 Find bitmap block that contains bits for goal block 
  gfs2_next_unreserved_block - Return next block that is not reserved
  @rgd: The resource group
  @block: The starting block
  @length: The required length
  @ignore_rs: Reservation to ignore
  If the block does not appear in any reservation, then return the
  block number unchanged. If it does appear in the reservation, then
  keep looking through the tree of reservations in order to find the
  first block number which is not reserved.
  gfs2_reservation_check_and_update - Check for reservations during block alloc
  @rbm: The current position in the resource group
  @rs: Our own reservation
  @minext: The minimum extent length
  @maxext: A pointer to the maximum extent structure
  This checks the current position in the rgrp to see whether there is
  a reservation covering this block. If not then this function is a
  no-op. If there is, then the position is moved to the end of the
  contiguous reservation(s) so that we are pointing at the first
  non-reserved block.
  Returns: 0 if no reservation, 1 if @rbm has changed, otherwise an error
	
	  If we have a minimum extent length, then skip over any extent
	  which is less than the min extent length in size.
	
	  Check the extent which has been found against the reservations
	  and skip if parts of it are already reserved
  gfs2_rbm_find - Look for blocks of a particular state
  @rbm: Valueresult starting position and final position
  @state: The state which we want to find
  @minext: Pointer to the requested extent length
           This is updated to be the actual reservation size.
  @rs: Our own reservation (NULL to skip checking for reservations)
  @nowrap: Stop looking at the end of the rgrp, rather than wrapping
           around until we've reached the starting point.
  Side effects:
  - If looking for free blocks, we set GBF_FULL on each bitmap which
    has no free blocks in it.
  - If looking for free blocks, we set rd_extfail_pt on each rgrp which
    has come up short on a free block search.
  Returns: 0 on success, -ENOSPC if there is no block of the requested state
	
	  Determine the last bitmap to search.  If we're not starting at the
	  beginning of a bitmap, we need to search that bitmap twice to scan
	  the entire resource group.
 Find next bitmap in the rgrp 
 Have we scanned the entire resource group? 
	 If the extent was too small, and it's smaller than the smallest
	   to have failed before, remember for future reference that it's
	 If the maximum extent we found is big enough to fulfill the
  try_rgrp_unlink - Look for any unlinked, allocated, but unused inodes
  @rgd: The rgrp
  @last_unlinked: block address of the last dinode we unlinked
  @skip: block address we should explicitly not unlink
  Returns: 0 if no error
           The inode, if one has been found, in inode.
		 If the inode is already in cache, we can ignore it here
		  because the existing inode disposal code will deal with
		  it when all refs have gone away. Accessing gl_object like
		  this is not safe in general. Here it is ok because we do
		  not dereference the pointer, and we only need an approx
		  answer to whether it is NULL or not.
 Limit reclaim to sensible number of tasks 
  gfs2_rgrp_congested - Use stats to figure out whether an rgrp is congested
  @rgd: The rgrp in question
  @loops: An indication of how picky we can be (0=very, 1=less so)
  This function uses the recently added glock statistics in order to
  figure out whether a parciular resource group is suffering from
  contention from multiple nodes. This is done purely on the basis
  of timings, since this is the only data we have to work with and
  our aim here is to reject a resource group which is highly contended
  but (very important) not to do this too often in order to ensure that
  we do not land up introducing fragmentation by changing resource
  groups when not actually required.
  The calculation is fairly simple, we want to know whether the SRTTB
  (i.e. smoothed round trip time for blocking operations) to acquire
  the lock for this rgrp's glock is significantly greater than the
  time taken for resource groups on average. We introduce a margin in
  the form of the variable @var which is computed as the sum of the two
  respective variences, and multiplied by a factor depending on @loops
  and whether we have a lot of data to base the decision on. This is
  then tested against the square difference of the means in order to
  decide whether the result is statistically significant or not.
  Returns: A boolean verdict on the congestion status
  gfs2_rgrp_used_recently
  @rs: The block reservation with the rgrp to test
  @msecs: The time limit in milliseconds
  Returns: True if the rgrp glock has been used within the time limit
 If we didn't wrap 
  fast_to_acquire - determine if a resource group will be fast to acquire
  @rgd: The rgrp
  If this is one of our preferred rgrps, it should be quicker to acquire,
  because we tried to set ourselves up as dlm lock master.
  gfs2_inplace_reserve - Reserve space in the filesystem
  @ip: the inode to reserve space for
  @ap: the allocation parameters
  We try our best to find an rgrp that has at least ap->target blocks
  available. After a couple of passes (loops == 2), the prospects of finding
  such an rgrp diminish. At this stage, we return the first rgrp that has
  at least ap->min_target blocks available.
  Returns: 0 on success,
           -ENOMEM if a suitable rgrp can't be found
           errno otherwise
 Skip unusable resource groups 
 Get a reservation if we don't already have one 
 Skip rgrps when we can't get a reservation on first pass 
 If rgrp has enough free space, use it 
 Check for unlinked inodes which can be reclaimed 
 Drop reservation, if we couldn't use reserved rgrp 
 Unlock rgrp if required 
 Find the next rgrp, and continue looking 
		 If we've scanned all the rgrps, but found no free blocks
		  then this checks for some less likely conditions before
		  trying again.
 Check that fs hasn't grown if writing to rindex 
 Flushing the log may release space 
  gfs2_inplace_release - release an inplace reservation
  @ip: the inode the reservation was taken out on
  Release a reservation made by gfs2_inplace_reserve().
  gfs2_alloc_extent - allocate an extent from a given bitmap
  @rbm: the resource group information
  @dinode: TRUE if the first block we allocate is for a dinode
  @n: The extent length (valueresult)
  Add the bitmap buffer to the transaction.
  Set the found bits to @new_state to change block's allocation state.
  rgblk_free - Change alloc state of given block(s)
  @sdp: the filesystem
  @rgd: the resource group the blocks are in
  @bstart: the start of a run of blocks to free
  @blen: the length of the block run (all must lie within ONE RG!)
  @new_state: GFS2_BLKST_XXX the after-allocation block state
  gfs2_rgrp_dump - print out an rgrp
  @seq: The iterator
  @rgd: The rgrp in question
  @fs_id_buf: pointer to file system id (if requested)
  gfs2_adjust_reservation - Adjust (or remove) a reservation after allocation
  @ip: The inode we have just allocated blocks for
  @rbm: The start of the allocated blocks
  @len: The extent length
  Adjusts a reservation after an allocation has taken place. If the
  reservation does not match the allocation, or if it is now empty
  then it is removed.
			 We used up our block reservation, so we should
  gfs2_set_alloc_start - Set starting point for block allocation
  @rbm: The rbm which will be set to the required location
  @ip: The gfs2 inode
  @dinode: Flag to say if allocation includes a new inode
  This sets the starting point from the reservation if one is active
  otherwise it falls back to guessing a start point based on the
  inode's goal block or the last allocation point in the rgrp.
  gfs2_alloc_blocks - Allocate one or more blocks of data andor a dinode
  @ip: the inode to allocate the block for
  @bn: Used to return the starting block number
  @nblocks: requested number of blocksextent length (valueresult)
  @dinode: 1 if we're allocating a dinode block, else 0
  @generation: the generation number of the inode
  Returns: 0 or error
 block, within the file system scope 
 Since all blocks are reserved in advance, this shouldn't happen 
  __gfs2_free_blocks - free a contiguous run of block(s)
  @ip: the inode these blocks are being freed from
  @rgd: the resource group the blocks are in
  @bstart: first block of a run of contiguous blocks
  @blen: the length of the block run
  @meta: 1 if the blocks represent metadata
 Directories keep their data in the metadata address space 
  gfs2_free_meta - free a contiguous run of data block(s)
  @ip: the inode these blocks are being freed from
  @rgd: the resource group the blocks are in
  @bstart: first block of a run of contiguous blocks
  @blen: the length of the block run
  gfs2_check_blk_type - Check the type of a block
  @sdp: The superblock
  @no_addr: The block number to check
  @type: The block type we are looking for
  The inode glock of @no_addr must be held.  The @type to check for is either
  GFS2_BLKST_DINODE or GFS2_BLKST_UNLINKED; checking for type GFS2_BLKST_FREE
  or GFS2_BLKST_USED would make no sense.
  Returns: 0 if the block type matches the expected type
           -ESTALE if it doesn't match
           or -ve errno if something went wrong while checking
		
		  No need to take the local resource group lock here; the
		  inode glock of @no_addr provides the necessary
		  synchronization in case the block is an inode.  (In case
		  the block is not an inode, the block type will not match
		  the @type we are looking for.)
  gfs2_rlist_add - add a RG to a list of RGs
  @ip: the inode
  @rlist: the list of resource groups
  @block: the block
  Figure out what RG a block belongs to and add that RG to the list
  FIXME: Don't use NOFAIL
	
	  The resource group last accessed is kept in the last position.
  gfs2_rlist_alloc - all RGs have been added to the rlist, now allocate
       and initialize an array of glock holders for them
  @rlist: the list of resource groups
  FIXME: Don't use NOFAIL
  gfs2_rlist_free - free a resource group list
  @rlist: the list of resource groups
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  Implements Extendible Hashing as described in:
    "Extendible Hashing" by Fagin, et al in
      __ACM Trans. on Database Systems__, Sept 1979.
  Here's the layout of dirents which is essentially the same as that of ext2
  within a single block. The field de_name_len is the number of bytes
  actually required for the name (no null terminator). The field de_rec_len
  is the number of bytes allocated to the dirent. The offset of the next
  dirent in the block is (dirent + dirent->de_rec_len). When a dirent is
  deleted, the preceding dirent inherits its allocated space, ie
  prev->de_rec_len += deleted->de_rec_len. Since the next dirent is obtained
  by adding de_rec_len to the current dirent, this essentially causes the
  deleted dirent to get jumped over when iterating through all the dirents.
  When deleting the first dirent in a block, there is no previous dirent so
  the field de_ino is set to zero to designate it as deleted. When allocating
  a dirent, gfs2_dirent_alloc iterates through the dirents in a block. If the
  first dirent has (de_ino == 0) and de_rec_len is large enough, this first
  dirent is allocated. Otherwise it must go through all the 'used' dirents
  searching for one in which the amount of total space minus the amount of
  used space will provide enough space for the new dirent.
  There are two types of blocks in which dirents reside. In a stuffed dinode,
  the dirents begin at offset sizeof(struct gfs2_dinode) from the beginning of
  the block.  In leaves, they begin at offset sizeof(struct gfs2_leaf) from the
  beginning of the leaf block. The dirents reside in leaves when
  dip->i_diskflags & GFS2_DIF_EXHASH is true
  Otherwise, the dirents are "linear", within a single stuffed dinode block.
  When the dirents are in leaves, the actual contents of the directory file are
  used as an array of 64-bit block pointers pointing to the leaf blocks. The
  dirents are NOT in the directory file itself. There can be more than one
  block pointer in the array that points to the same leaf. In fact, when a
  directory is first converted from linear to exhash, all of the pointers
  point to the same leaf.
  When a leaf is completely full, the size of the hash table can be
  doubled unless it is already at the maximum size which is hard coded into
  GFS2_DIR_MAX_DEPTH. After that, leaves are chained together in a linked list,
  but never before the maximum hash table size has been reached.
 max read-ahead blocks 
  gfs2_dir_write_data - Write directory information to the inode
  @ip: The GFS2 inode
  @buf: The buffer containing information to be written
  @offset: The file offset to start writing at
  @size: The amount of data to write
  Returns: The number of bytes correctly written or error code
  gfs2_dir_read_data - Read a data from a directory inode
  @ip: The GFS2 Inode
  @buf: The buffer to place result into
  @size: Amount of data to transfer
  Returns: The amount of data actually copied or the error
  gfs2_dir_get_hash_table - Get pointer to the dir hash table
  @ip: The inode in question
  Returns: The hash table or an error
  gfs2_dir_hash_inval - Invalidate dir hash
  @ip: The directory inode
  Must be called with an exclusive glock, or during glock invalidation.
  name->name holds ptr to start of block.
  name->len holds size of block.
 Look for the dirent that contains the offset specified in data. Once we
  Other possible things to check:
  - Inode located within filesystem size (and on valid block)
  - Valid directory entry type
  Not sure how heavy-weight we want to make this... could also check
  hash is correct for example, but that would take a lot of extra time.
  For now the most important thing is to check that the various sizes
  are correct.
  dirent_next - Next dirent
  @dip: the directory
  @bh: The buffer
  @dent: Pointer to list of dirents
  Returns: 0 on success, error code otherwise
 Only the first dent could ever have de_inum.no_addr == 0 
  dirent_del - Delete a dirent
  @dip: The GFS2 inode
  @bh: The buffer
  @prev: The previous dirent
  @cur: The current dirent
	 If there is no prev entry, this is the first entry in the block.
	   The de_rec_len is already as big as it needs to be.  Just zero
  Combine this dentry with the previous one.  
  Takes a dent from which to grab space as an argument. Returns the
  newly created dent.
 pr_info("block num=%llu\n", leaf_no); 
  get_leaf_nr - Get a leaf number associated with the index
  @dip: The GFS2 inode
  @index: hash table index of the targeted leaf
  @leaf_out: Resulting leaf block number
  Returns: 0 on success, error code otherwise
  dir_make_exhash - Convert a stuffed directory into an ExHash directory
  @inode: The directory inode to be converted to exhash
  Returns: 0 on success, error code otherwise
  Turn over a new leaf  
  Copy dirents  
  Find last entry  
	  Adjust the last dirent's record length
	  We're done with the new leaf block, now setup the new
  dir_split_leaf - Split a leaf block into two
  @inode: The directory inode to be split
  @name: name of the dirent we're trying to insert
  Returns: 0 on success, error code on failure
  Get the old leaf block  
 can't split 
  Compute the start and len of leaf pointers in the hash table.  
	 Change the pointers.
	   Don't bother distinguishing stuffed from non-stuffed.
  Change the pointers  
  Compute the divider  
  Copy the entries  
 No endian worries 
 No endian worries 
  dir_double_exhash - Double size of ExHash table
  @dip: The GFS2 dinode
  Returns: 0 on success, error code on failure
 Replace original hash table & size 
  compare_dents - compare directory entries by hash value
  @a: first dent
  @b: second dent
  When comparing the hash entries of @a to @b:
    gt: returns 1
    lt: returns -1
    eq: returns 0
  do_filldir_main - read out directory entries
  @dip: The GFS2 inode
  @ctx: what to feed the entries to
  @darr: an array of struct gfs2_dirent pointers to read
  @entries: the number of entries in darr
  @sort_start: index of the directory array to start our sort
  @copied: pointer to int that's non-zero if a entry has been copied out
  Jump through some hoops to make sure that if there are hash collsions,
  they are read out at the beginning of a buffer.  We want to minimize
  the possibility that they will fall into different readdir buffers or
  that someone will want to seek to that location.
  Returns: errno, >0 if the actor tells you to stop
	 Increment the ctx->pos by one, so the next time we come into the
	   do_filldir fxn, we get the next entry instead of the last one in the
	
	  The extra 99 entries are not normally used, but are a buffer
	  zone in case the number of entries in the leaf is corrupt.
	  99 is the maximum number of entries that can fit in a single
	  leaf block.
  gfs2_dir_readahead - Issue read-ahead requests for leaf blocks.
  @inode: the directory inode
  @hsize: hash table size
  @index: index into the hash table
  @f_ra: read-ahead parameters
  Note: we can't calculate each index like dir_e_read can because we don't
  have the leaf, and therefore we don't have the depth, and therefore we
  don't have the length. So we have to just read enough ahead to make up
  for the loss of information.
 First check if we've already read-ahead for the whole range. 
 if exceeded the hash table 
  dir_e_read - Reads the entries from a directory into a filldir buffer
  @inode: the directory inode
  @ctx: actor to feed the entries to
  @f_ra: read-ahead parameters
  Returns: errno
 96 is max number of dirents which can be stuffed into an inode 
  gfs2_dir_search - Search a directory
  @dir: The GFS2 directory inode
  @name: The name we are looking up
  @fail_on_exist: Fail if the name exists rather than looking it up
  This routine searches a directory for a file or another directory.
  Assumes a glock is held on dip.
  Returns: errno
 ignore );
  dir_new_leaf - Add a new leaf onto hash chain
  @inode: The directory
  @name: The name we are adding
  This adds a new dir leaf onto an existing leaf when there is not
  enough space to add a new dir entry. This is a last resort after
  we've expanded the hash table to max size and also split existing
  leaf blocks, so it will only occur for very large directories.
  The dist parameter is set to 1 for leaf blocks directly attached
  to the hash table, 2 for one layer of indirection, 3 for two layers
  etc. We are thus able to tell the difference between an old leaf
  with dist set to zero (i.e. "don't know") and a new one where we
  set this information for debugfsck purposes.
  Returns: 0 on success, or -ve on error
  gfs2_dir_add - Add new filename into directory
  @inode: The directory inode
  @name: The new name
  @nip: The GFS2 inode to be linked in to the directory
  @da: The directory addition info
  If the call to gfs2_diradd_alloc_required resulted in there being
  no need to allocate any new directory blocks, then it will contain
  a pointer to the directory entry and the bh in which it resides. We
  can use that without having to repeat the search. If there was no
  free space, then we must now create more space.
  Returns: 0 on success, error code on failure
  gfs2_dir_del - Delete a directory entry
  @dip: The GFS2 inode
  @dentry: The directory entry we want to delete
  Returns: 0 on success, error code on failure
	 Returns _either_ the entry (if its first in block) or the
 If not first in block, adjust pointers accordingly 
  gfs2_dir_mvino - Change inode number of directory entry
  @dip: The GFS2 directory inode
  @filename: the filename to be moved
  @nip: the new GFS2 inode
  @new_type: the de_type of the new dirent
  This routine changes the inode number of a directory entry.  It's used
  by rename to change ".." when a directory is moved.
  Assumes a glock is held on dvp.
  Returns: errno
  leaf_dealloc - Deallocate a directory leaf
  @dip: the directory
  @index: the hash table offset in the directory
  @len: the number of pointers to this leaf
  @leaf_no: the leaf number
  @leaf_bh: buffer_head for the starting leaf
  @last_dealloc: 1 if this is the final dealloc for the leaf, else 0
  Returns: errno
  Count the number of leaves  
	 On the last dealloc, make this a regular file in case we crash.
  gfs2_dir_exhash_dealloc - free all the leaf blocks in a directory
  @dip: the directory
  Dealloc all on-disk directory leaves to FREEMETA state
  Change on-disk inode type to "regular file"
  Returns: errno
  gfs2_diradd_alloc_required - find if adding entry will require an allocation
  @inode: the directory inode being written to
  @name: the filename that's going to be added
  @da: The structure to return dir alloc info
  Returns: 0 if ok, -ve on error
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2008 Red Hat, Inc.  All rights reserved.
 incore superblock           
 rhashtable iterator         
 current glock struct        
 last position               
  wake_up_glock  -  Wake up waiters on a glock
  @gl: the glock
  glock_blocked_by_withdraw - determine if we can still use a glock
  @gl: the glock
  We need to allow some glocks to be enqueued, dequeued, promoted, and demoted
  when we're withdrawn. For example, to maintain metadata integrity, we should
  disallow the use of inode and rgrp glocks when withdrawn. Other glocks, like
  iopen or the transaction glocks may be safely used because none of their
  metadata goes through the journal. So in general, we should disallow all
  glocks that are journaled, and allow all the others. One exception is:
  we need to allow our active journal to be promoted and demoted so others
  may recover it and we can reacquire it when they're done.
  gfs2_glock_hold() - increment reference count on glock
  @gl: The glock to hold
  demote_ok - Check to see if it's ok to unlock a glock
  @gl: the glock
  Returns: 1 if it's ok
	
	  Note that demote_ok is used for the lru process of disposing of
	  glocks. For this purpose, we don't care if the glock's holders
	  have the HIF_MAY_DEMOTE flag set or not. If someone is using
	  them, don't demote.
  Enqueue the glock on the work queue.  Passes one glock reference on to the
  work queue.
		
		  We are holding the lockref spinlock, and the work was still
		  queued above.  The queued work (glock_work_func) takes that
		  spinlock before dropping its glock reference(s), so it
		  cannot have dropped them in the meantime.
  Cause the glock to be put in work queue context.
  gfs2_glock_put() - Decrement reference count on glock
  @gl: The glock to put
 last put could call sleepable dlm api 
  may_grant - check if it's ok to grant a new lock
  @gl: The glock
  @current_gh: One of the current holders of @gl
  @gh: The lock request which we wish to grant
  With our current compatibility rules, if a glock has one or more active
  holders (HIF_HOLDER flag set), any of those holders can be passed in as
  @current_gh; they are all the same as far as compatibility with the new @gh
  goes.
  Returns true if it's ok to grant the lock.
			
			  Here we make a special exception to grant holders
			  who agree to share the EX lock with other holders
			  who also have the bit set. If the original holder
			  has the LM_FLAG_NODE_SCOPE bit set, we grant more
			  holders with the bit set.
  do_error - Something unexpected has happened during a lock request
  @gl: The glock
  @ret: The status from the DLM
  demote_incompat_holders - demote incompatible demoteable holders
  @gl: the glock we want to promote
  @new_gh: the new holder to be promoted
	
	  Demote incompatible holders before we make ourselves eligible.
	  (This holder may or may not allow auto-demoting, but we don't want
	  to demote the new holder before it's even granted.)
		
		  Since holders are at the front of the list, we stop when we
		  find the first non-holder.
			
			  We should not recurse into do_promote because
			  __gfs2_glock_dq only calls handle_callback,
			  gfs2_glock_add_to_lru and __gfs2_glock_queue_work.
  find_first_holder - find the first "holder" gh
  @gl: the glock
  find_first_strong_holder - find the first non-demoteable holder
  @gl: the glock
  Find the first holder that doesn't have the HIF_MAY_DEMOTE flag set.
  gfs2_instantiate - Call the glops instantiate function
  @gl: The glock
  Returns: 0 if instantiate was successful, 2 if type specific operation is
  underway, or error.
	
	  Since we unlock the lockref lock, we set a flag to indicate
	  instantiate is in progress.
		
		  Here we just waited for a different instantiate to finish.
		  But that may not have been successful, as when a process
		  locks an inode glock _before_ it has an actual inode to
		  instantiate into. So we check again. This process might
		  have an inode to instantiate, so might be successful.
  do_promote - promote as many requests as possible on the current queue
  @gl: The glock
  Returns: 1 if there is a blocked holder at the head of the list, or 2
           if a type specific operation is underway.
			
			  If we get here, it means we may not grant this holder for
			  some reason. If this holder is the head of the list, it
			  means we have a blocked holder at the head, so return 1.
		
		  If we released the gl_lockref.lock the holders list may have
		  changed. For that reason, we start again at the start of
		  the holders queue.
  find_first_waiter - find the first gh that's waiting for the glock
  @gl: the glock
  state_change - record that the glock is now in a different state
  @gl: the glock
  @new_state: the new state
 shorten our minimum hold time 
  finish_xmote - The DLM has replied to one of our lock requests
  @gl: The glock
  @ret: The status from the DLM
 Demote to UN request arrived during demote to SH or DF 
 Check for state != intended state 
 move to back of queue and try next entry 
 Some error or failed "try lock" - report it 
 Unlocked due to conversion deadlock, try again 
 Conversion fails, unlock and try again 
 Everything else 
 Fast path - we got what we asked for 
  do_xmote - Calls the DLM to change the state of a lock
  @gl: The lock state
  @gh: The holder (only for promotes)
  @target: The target lock state
		
		  If another process is already doing the invalidate, let that
		  finish first.  The glock state machine will get back to this
		  holder again later.
 Fail queued try locks 
		 If we had a problem syncing (due to io errors or whatever,
		  we should not invalidate the metadata or tell dlm to
		  release the glock to other nodes.
		
		  The call to go_sync should have cleared out the ail list.
		  If there are still items, we have a problem. We ought to
		  withdraw, but we can't because the withdraw code also uses
		  glocks. Warn about the error, dump the glock, then fall
		  through and wait for logd to do the withdraw for us.
	
	  Check for an error encountered since we called go_sync and go_inval.
	  If so, we can't withdraw from the glock code because the withdraw
	  code itself uses glocks (see function signal_our_withdraw) to
	  change the mount to read-only. Most importantly, we must not call
	  dlm to unlock the glock until the journal is in a known good state
	  (after journal replay) otherwise other nodes may use the object
	  (rgrp or dinode) and then later, journal replay will corrupt the
	  file system. The best we can do here is wait for the logd daemon
	  to see sd_log_error and withdraw, and in the meantime, requeue the
	  work for later.
	 
	  We make a special exception for some system glocks, such as the
	  system statfs inode glock, which needs to be granted before the
	  gfs2_quotad daemon can exit, and that exit needs to finish before
	  we can unmount the withdrawn file system.
	 
	  However, if we're just unlocking the lock (say, for unmount, when
	  gfs2_gl_hash_clear calls clear_glock) and recovery is complete
	  then it's okay to tell dlm to unlock it.
 lock_dlm 
 lock_nolock 
  run_queue - do all outstanding tasks related to a glock
  @gl: The glock in question
  @nonblock: True if we must not block in run_queue
 Fail queued try locks 
	
	  If there is contention on the iopen glock and we have an inode, try
	  to grab and release the inode so that it can be evicted.  This will
	  allow the remote node to go ahead and delete the inode without us
	  having to do it, which will avoid rgrp glock thrashing.
	 
	  The remote node is likely still holding the corresponding inode
	  glock, so it will run before we get to verify that the delete has
	  happened below.
 If the inode was evicted, gl->gl_object will now be NULL. 
		
		  If we can evict the inode, give the remote node trying to
		  delete the inode some time before verifying that the delete
		  has happened.  Otherwise, if we cause contention on the inode glock
		  immediately, the remote node will think that we still have
		  the inode in use, and so it will give up waiting.
		 
		  If we can't evict the inode, signal to the remote node that
		  the inode is still in use.  We'll later try to delete the
		  inode locally in gfs2_evict_inode.
		 
		  FIXME: We only need to verify that the remote node has
		  deleted the inode because nodes before this remote delete
		  rework won't cooperate.  At a later time, when we no longer
		  care about compatibility with such nodes, we can skip this
		  step entirely.
 Keep one glock reference for the work we requeue. 
	
	  Drop the remaining glock references manually here. (Mind that
	  __gfs2_glock_queue_work depends on the lockref spinlock begin held
	  here as well.)
  gfs2_glock_get() - Get a glock, or create one if one doesn't exist
  @sdp: The GFS2 superblock
  @number: the lock number
  @glops: The glock_operations to use
  @create: If 0, don't create the glock if it doesn't exist
  @glp: the glock is returned here
  This does not lock a glock, just findscreates structures for one.
  Returns: errno
 We use the global stats to estimate the initial per-glock stats 
  gfs2_holder_init - initialize a struct gfs2_holder in the default way
  @gl: the glock
  @state: the state we're requesting
  @flags: the modifier flags
  @gh: the holder structure
  gfs2_holder_reinit - reinitialize a struct gfs2_holder so we can requeue it
  @state: the state we're requesting
  @flags: the modifier flags
  @gh: the holder structure
  Don't mess with the glock.
  gfs2_holder_uninit - uninitialize a holder structure (drop glock reference)
  @gh: the holder structure
 Have we waited longer that a second? 
 Lengthen the minimum hold time. 
  gfs2_glock_wait - wait on a glock acquisition
  @gh: the glock holder
  Returns: 0 on success
  gfs2_glock_async_wait - wait on multiple asynchronous glock acquisitions
  @num_gh: the number of holders in the array
  @ghs: the glock holder array
  Returns: 0 on success, meaning all glocks have been granted and are held.
           -ESTALE if the request timed out, meaning all glocks were released,
           and the caller should retry the operation.
	
	  Total up the (minimum hold time  2) of all glocks and use that to
	  determine the max amount of time we should wait.
 request timed out. 
	
	  If dlm granted all our requests, we need to adjust the glock
	  minimum hold time values according to how long we waited.
	 
	  If our request timed out, we need to repeatedly release any held
	  glocks we acquired thus far to allow dlm to acquire the remaining
	  glocks without deadlocking.  We cannot currently cancel outstanding
	  glock acquisitions.
	 
	  The HIF_WAIT bit tells us which requests still need a response from
	  dlm.
	 
	  If dlm sent us any errors, we return the first error we find.
 Skip holders we have already dequeued below. 
 Skip holders with a pending DLM response. 
	
	  At this point, we've either acquired all locks or released them all.
  handle_callback - process a demote request
  @gl: the glock
  @state: the state the caller wants us to change to
  @delay: zero to demote immediately; otherwise pending demote
  @remote: true if this came from a different cluster node
  There are only two requests that we are going to see in actual
  practise: LM_ST_SHARED and LM_ST_UNLOCKED
  add_to_queue - Add a holder to the wait queue (but look for recursion)
  @gh: the holder structure to add
  Eventually we should move the recursive locking trap to a
  debugging option or something like that. This is the fast
  path and needs to have the minimum number of distractions.
  gfs2_glock_nq - enqueue a struct gfs2_holder onto a glock (acquire a glock)
  @gh: the holder structure
  if (gh->gh_flags & GL_ASYNC), this never returns an error
  Returns: 0, GLR_TRYFAILED, or errno on failure
  gfs2_glock_poll - poll to see if an async request has been completed
  @gh: the holder
  Returns: 1 if the request is ready to be gfs2_glock_wait()ed on
	
	  This while loop is similar to function demote_incompat_holders:
	  If the glock is due to be demoted (which may be from another node
	  or even if this holder is GL_NOCACHE), the weak holders are
	  demoted as well, allowing the glock to be demoted.
		
		  If we're in the process of file system withdraw, we cannot
		  just dequeue any glocks until our journal is recovered, lest
		  we introduce file system corruption. We need two exceptions
		  to this rule: We need to allow unlocking of nondisk glocks
		  and the glock for our own journal that needs recovery.
		
		  This holder should not be cached, so mark it for demote.
		  Note: this should be done before the check for needs_demote
		  below.
		
		  If there hasn't been a demote request we are done.
		  (Let the remaining holders, if any, keep holding it.)
		
		  If we have another strong holder (we cannot auto-demote)
		  we are done. It keeps holding it until it is done.
		
		  If we have a weak holder at the head of the list, it
		  (and all others like it) must be auto-demoted. If there
		  are no more weak holders, we exit the while loop.
  gfs2_glock_dq - dequeue a struct gfs2_holder from a glock (release a glock)
  @gh: the glock holder
  gfs2_glock_dq_uninit - dequeue a holder from a glock and initialize it
  @gh: the holder structure
  gfs2_glock_nq_num - acquire a glock based on lock number
  @sdp: the filesystem
  @number: the lock number
  @glops: the glock operations for the type of glock
  @state: the state to acquire the glock in
  @flags: modifier flags for the acquisition
  @gh: the struct gfs2_holder
  Returns: errno
  glock_compare - Compare two struct gfs2_glock structures for sorting
  @arg_a: the first structure
  @arg_b: the second structure
  nq_m_sync - synchonously acquire more than one glock in deadlock free order
  @num_gh: the number of structures
  @ghs: an array of struct gfs2_holder structures
  @p: placeholder for the holder structure to pass back
  Returns: 0 on success (all glocks acquired),
           errno on failure (no glocks acquired)
  gfs2_glock_nq_m - acquire multiple glocks
  @num_gh: the number of structures
  @ghs: an array of struct gfs2_holder structures
  Returns: 0 on success (all glocks acquired),
           errno on failure (no glocks acquired)
  gfs2_glock_dq_m - release multiple glocks
  @num_gh: the number of structures
  @ghs: an array of struct gfs2_holder structures
	
	  Note 1: We cannot call demote_incompat_holders from handle_callback
	  or gfs2_set_demote due to recursion problems like: gfs2_glock_dq ->
	  handle_callback -> demote_incompat_holders -> gfs2_glock_dq
	  Plus, we only want to demote the holders if the request comes from
	  a remote cluster node because local holder conflicts are resolved
	  elsewhere.
	 
	  Note 2: if a remote node wants this glock in EX mode, lock_dlm will
	  request that we set our state to UNLOCKED. Here we mock up a holder
	  to make it look like someone wants the lock EX locally. Any SH
	  and DF requests should be able to share the lock without demoting.
	 
	  Note 3: We only want to demote the demoteable holders when there
	  are no more strong holders. The demoteable holders might as well
	  keep the glock until the last strong holder is done with it.
  gfs2_should_freeze - Figure out if glock should be frozen
  @gl: The glock in question
  Glocks are not frozen if (a) the result of the dlm operation is
  an error, (b) the locking operation was an unlock operation or
  (c) if there is a "noexp" flagged request anywhere in the queue
  Returns: 1 if freezing should occur, 0 otherwise
  gfs2_glock_complete - Callback used by locking
  @gl: Pointer to the glock
  @ret: The return value from the dlm
  The gl_reply field is under the gl_lockref.lock lock so that it is ok
  to use a bitfield shared with other glock state fields.
  gfs2_dispose_glock_lru - Demote a list of glocks
  @list: The list to dispose of
  Disposing of glocks may involve disk accesses, so that here we sort
  the glocks by number (i.e. disk location of the inodes) so that if
  there are any such accesses, they'll be sent in order (mostly).
  Must be called under the lru_lock, but may drop and retake this
  lock. While the lru_lock is dropped, entries may vanish from the
  list, but no new entries will appear on the list (since it is
  private)
  gfs2_scan_glock_lru - Scan the LRU looking for locks to demote
  @nr: The number of entries to scan
  This function selects the entries on the LRU which are able to
  be demoted, and then kicks off the process by calling
  gfs2_dispose_glock_lru() above.
 Test for being demotable 
  glock_hash_walk - Call a function for glock in a hash bucket
  @examiner: the function
  @sdp: the filesystem
  Note that the function can be called multiple times on the same
  object.  So the user must ensure that the function can cope with
  that.
  thaw_glock - thaw out a glock which has an unprocessed reply waiting
  @gl: The glock to thaw
  clear_glock - look at a glock and see if we can free it from glock cache
  @gl: the glock to look at
  gfs2_glock_thaw - Thaw any frozen glocks
  @sdp: The super block
  gfs2_gl_hash_clear - Empty out the glock hash table
  @sdp: the filesystem
  Called when unmounting the filesystem.
  dump_holder - print information about a glock holder
  @seq: the seq_file struct
  @gh: the glock holder
  @fs_id_buf: pointer to file system id (if requested)
  gfs2_dump_glock - print information about a glock
  @seq: The seq_file struct
  @gl: the glock
  @fsid: If true, also dump the file system id
  The file format is as follows:
  One line per object, capital letters are used to indicate objects
  G = glock, I = Inode, R = rgrp, H = holder. Glocks are not indented,
  other objects are indented by a single space and follow the glock to
  which they are related. Fields are indicated by lower case letters
  followed by a colon and the field value, except for strings which are in
  [] so that its possible to see if they are composed of spaces for
  example. The field's are n = number (id of the object), f = flags,
  t = type, s = state, r = refcount, e = error, p = pid.
 safety precaution 
 demote time in uSec 
	
	  We can either stay where we are, skip to the next hash table
	  entry, or start from the beginning.
		
		  Initially, we are "before" the first hash table entry; the
		  first call to rhashtable_walk_next gets us the first entry.
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  gfs2_llseek - seek to a location in a file
  @file: the file
  @offset: the offset
  @whence: Where to seek from (SEEK_SET, SEEK_CUR, or SEEK_END)
  SEEK_END requires the glock for the file because it references the
  file's size.
  Returns: The new offset, or errno
		
		  These don't reference inode->i_size and don't depend on the
		  block mapping, so we don't need the glock.
  gfs2_readdir - Iterator for a directory
  @file: The directory to read from
  @ctx: What to feed directory entries to
  Returns: errno
  struct fsflag_gfs2flag
  The FS_JOURNAL_DATA_FL flag maps to GFS2_DIF_INHERIT_JDATA for directories,
  and to GFS2_DIF_JDATA for non-directories.
 Flags that can be set by user space 
  do_gfs2_set_flags - set flags on an inode
  @inode: The inode
  @reqflags: The flags to set
  @mask: Indicates which flags are valid
 The GFS2_DIF_TOPDIR flag is only valid for directories. 
 Keep this list in sync with gfs2_ioctl 
  gfs2_size_hint - Give a hint to the size of a write request
  @filep: The struct file
  @offset: The file offset of the write
  @size: The length of the write
  When we are about to do a write, this function records the total
  write size in order to provide a suitable hint to the lower layers
  about how many blocks will be required.
  gfs2_allocate_page_backing - Allocate blocks for a write fault
  @page: The (locked) page to allocate backing for
  @length: Size of the allocation
  We try to allocate all the blocks required for the page in one go.  This
  might fail for various reasons, so we keep trying until all the blocks to
  back this page are allocated.  If some of the blocks are already allocated,
  that is ok too.
  gfs2_page_mkwrite - Make a shared, mmap()ed, page writable
  @vmf: The virtual memory fault containing the page to become writable
  When the page becomes writable, we need to ensure that we have
  blocks allocated on disk to back that page.
 Check page index against inode size 
 Update file times before taking page lock 
 page is wholly or partially inside EOF 
	
	  iomap_writepage  iomap_writepages currently don't support inline
	  files, so always unstuff here.
 Unstuff, if required, and allocate backing blocks for page 
	 If truncated, we must retry the operation, we may have raced
	  with the glock demotion code.
  gfs2_mmap
  @file: The file to map
  @vma: The VMA which described the mapping
  There is no need to get a lock here unless we should be updating
  atime. We ignore any locking errors since the only consequence is
  a missed atime update (which will just be deferred until later).
  Returns: 0
 grab lock to update inode 
  gfs2_open_common - This is common to open and atomic_open
  @inode: The inode being opened
  @file: The file being opened
  This maybe called under a glock or not depending upon how it has
  been called. We must always be called under a glock for regular
  files, however. For other file types, it does not matter whether
  we hold the glock or not.
  Returns: Error code or 0 for success
  gfs2_open - open a file
  @inode: the inode to open
  @file: the struct file for this opening
  After atomic_open, this function is only used for opening files
  which are already cached. We must still get the glock for regular
  files to ensure that we have the file size uptodate for the large
  file check which is in the common code. That is only an issue for
  regular files though.
  Returns: errno
  gfs2_release - called to close a struct file
  @inode: the inode the struct file belongs to
  @file: the struct file being closed
  Returns: errno
  gfs2_fsync - sync the dirty data for a file (across the cluster)
  @file: the file that points to the dentry
  @start: the start position in the file to sync
  @end: the end position in the file to sync
  @datasync: set if we can ignore timestamp changes
  We split the data flushing here so that we don't wait for the data
  until after we've also sent the metadata to disk. Note that for
  data=ordered, we will write & wait for the data at the log flush
  stage anyway, so this is unlikely to make much of a difference
  except in the data=writeback case.
  If the fdatawrite fails due to any reason except -EIO, we will
  continue the remainder of the fsync, although we'll still report
  the error at the end. This is to match filemap_write_and_wait_range()
  behaviour.
  Returns: errno
	
	  In this function, we disable page faults when we're holding the
	  inode glock while doing IO.  If a page fault occurs, we indicate
	  that the inode glock may be dropped, fault in the pages manually,
	  and retry.
	 
	  Unlike generic_file_read_iter, for reads, iomap_dio_rw can trigger
	  physical as well as manual page faults, and we need to disable both
	  kinds.
	 
	  For direct IO, gfs2 takes the inode glock in deferred mode.  This
	  locking mode is compatible with other deferred holders, so multiple
	  processes and nodes can do direct IO to a file at the same time.
	  There's no guarantee that reads or writes will be atomic.  Any
	  coordination among readers and writers needs to happen externally.
 skip atime 
	
	  In this function, we disable page faults when we're holding the
	  inode glock while doing IO.  If a page fault occurs, we indicate
	  that the inode glock may be dropped, fault in the pages manually,
	  and retry.
	 
	  For writes, iomap_dio_rw only triggers manual page faults, so we
	  don't need to disable physical ones.
	
	  Deferred lock, even if its a write, since we do no allocation on
	  this path. All we need to change is the atime, and this lock mode
	  ensures that other nodes have flushed their buffered read caches
	  (i.e. their page cache entries for this inode). We do not,
	  unfortunately, have the option of only flushing a range like the
	  VFS does.
 Silently fall back to buffered IO when writing beyond EOF 
	
	  In this function, we disable page faults when we're holding the
	  inode glock while doing IO.  If a page fault occurs, we indicate
	  that the inode glock may be dropped, fault in the pages manually,
	  and retry.
	
	  In this function, we disable page faults when we're holding the
	  inode glock while doing IO.  If a page fault occurs, we indicate
	  that the inode glock may be dropped, fault in the pages manually,
	  and retry.
  gfs2_file_write_iter - Perform a write to a file
  @iocb: The io context
  @from: The data to write
  We have to do a lockunlock here to refresh the inode size for
  O_APPEND writes, otherwise we can land up writing at the wrong
  offset. There is still a race, but provided the app is using its
  own file locking, this will make O_APPEND work as expected.
		
		  We need to ensure that the page cache pages are written to
		  disk and invalidated to preserve the expected O_DIRECT
		  semantics.  If the writeback or invalidate fails, only report
		  the direct IO range as we don't know if the buffered pages
		  made it to disk.
  calc_max_reserv() - Reverse of write_calc_reserv. Given a number of
                      blocks, determine how many bytes can be written.
  @ip:          The inode in question.
  @len:         Max cap of bytes. What we return in len must be <= this.
  @data_blocks: Compute and return the number of data blocks needed
  @ind_blocks:  Compute and return the number of indirect blocks needed
  @max_blocks:  The total blocks available to work with.
  Returns: void, but @len, @data_blocks and @ind_blocks are filled in.
		 We need to determine how many bytes we can actually
		  fallocate without exceeding quota or going over the
		  end of the fs. We start off optimistically by assuming
		 Since max_bytes is most likely a theoretical max, we
		  calculate a more realistic 'bytes' to serve as a good
		  starting point for the number of bytes we may be able
		 ap.allowed tells us how many blocks quota will allow
 check if the selected rgrp limits our max_blks further 
		 Almost done. Calculate bytes that can be written using
		  max_blks. We also recompute max_bytes, data_blocks and
 fallocate is needed by gfs2_grow to reserve space in the rindex 
  gfs2_lock - acquirerelease a posix lock on a file
  @file: the file pointer
  @cmd: either modify or retrieve lock state, possibly wait
  @fl: type and range of lock
  Returns: errno
 Hack: 
  gfs2_flock - acquirerelease a flock lock on a file
  @file: the file pointer
  @cmd: either modify or retrieve lock state, possibly wait
  @fl: type and range of lock
  Returns: errno
 CONFIG_GFS2_FS_LOCKING_DLM 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  check_journal_clean - Make sure a journal is clean for a spectator mount
  @sdp: The GFS2 superblock
  @jd: The journal descriptor
  @verbose: Show more prints in the log
  Returns: 0 if the journal is clean or locked, else an error
  gfs2_freeze_lock - hold the freeze glock
  @sdp: the superblock
  @freeze_gh: pointer to the requested holder
  @caller_flags: any additional flags needed by the caller
 frees all transactions 
 Prevent any glock dq until withdraw recovery is complete 
	
	  Don't tell dlm we're bailing until we have no more buffers in the
	  wind. If journal had an IO error, the log code should just purge
	  the outstanding buffers rather than submitting new IO. Making the
	  file system read-only will flush the journal, etc.
	 
	  During a normal unmount, gfs2_make_fs_ro calls gfs2_log_shutdown
	  which clears SDF_JOURNAL_LIVE. In a withdraw, we must not write
	  any UNMOUNT log header, so we can't call gfs2_log_shutdown, and
	  therefore we need to clear SDF_JOURNAL_LIVE manually.
 lock_nolock 
	
	  Drop the glock for our journal so another node can recover it.
 Make sure gfs2_unfreeze works if partially-frozen 
	
	  holder_uninit to force glock_put, to force dlm to let go
	
	  Note: We need to be careful here:
	  Our iput of jd_inode will evict it. The evict will dequeue its
	  glock, but the glock dq will wait for the withdraw unless we have
	  exception code in glock_dq.
	
	  Wait until the journal inode's glock is freed. This allows try locks
	  on other nodes to be successful, otherwise we remain the owner of
	  the glock as far as dlm is concerned.
	
	  Dequeue the "live" glock, but keep a reference so it's never freed.
	
	  We enqueue the "live" glock in EX so that all other nodes
	  get a demote request and act on it. We don't really want the
	  lock in EX, so we send a "try" lock with 1CB to produce a callback.
	
	  This will likely fail in a cluster, but succeed standalone:
	
	  If we actually got the "live" lock in EX mode, there are no other
	  nodes available to replay our journal. So we try to replay it
	  ourselves. We hold the "live" glock to prevent other mounters
	  during recovery, then just dequeue it and reacquire it in our
	  normal SH mode. Just in case the problem that caused us to
	  withdraw prevents us from recovering our journal (e.g. io errors
	  and such) we still check if the journal is clean before proceeding
	  but we may wait forever until another mounter does the recovery.
 drop extra reference we acquired 
	
	  At this point our journal is evicted, so we need to get a new inode
	  for it. Once done, we need to call gfs2_find_jhead which
	  calls gfs2_map_journal_extents to map it for us again.
	 
	  Note that we don't really want it to look up a FREE block. The
	  GFS2_BLKST_FREE simply overrides a block check in gfs2_inode_lookup
	  which would otherwise fail because it requires grabbing an rgrp
	  glock, which would fail with -EIO because we're withdrawing.
	
	  Now wait until recovery is complete.
  gfs2_assert_withdraw_i - Cause the machine to withdraw if @assertion is false
	
	  If errors=panic was specified on mount, it won't help to delay the
	  withdraw.
  gfs2_assert_warn_i - Print a message to the console if @assertion is false
  gfs2_consist_i - Flag a filesystem consistency error and withdraw
  gfs2_consist_inode_i - Flag an inode consistency error and withdraw
  gfs2_consist_rgrpd_i - Flag a RG consistency error and withdraw
  gfs2_meta_check_ii - Flag a magic number consistency error and withdraw
  Returns: -1 if this call withdrew the machine,
           -2 if it was already withdrawn
  gfs2_metatype_check_ii - Flag a metadata type consistency error and withdraw
  Returns: -1 if this call withdrew the machine,
           -2 if it was already withdrawn
  gfs2_io_error_i - Flag an IO error and withdraw
  Returns: -1 if this call withdrew the machine,
           0 if it was already withdrawn
  gfs2_io_error_bh_i - Flag a buffer IO error
  @withdraw: withdraw the filesystem
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2007 Red Hat, Inc.  All rights reserved.
  Quota change tags are associated with each transaction that allocates or
  deallocates space.  Those changes are accumulated locally to each node (in a
  per-node file) and then are periodically synced to the quota file.  This
  avoids the bottleneck of constantly touching the quota file, but introduces
  fuzziness in the current usage value of IDs that are being used on different
  nodes in the cluster simultaneously.  So, it is possible for a user on
  multiple nodes to overrun their quota, but that overrun is controlable.
  Since quota tags are part of transactions, there is no need for a quota check
  program to be run on node crashes or anything like that.
  There are couple of knobs that let the administrator manage the quota
  fuzziness.  "quota_quantum" sets the maximum time a quota change can be
  sitting on one node before being synced to the quota file.  (The default is
  60 seconds.)  Another knob, "quota_scale" controls how quickly the frequency
  of quota file syncs increases as the user moves closer to their limit.  The
  more frequent the syncs, the more accurate the quota enforcement, but that
  means that there is more contention between the nodes for the quota file.
  The default value is one.  This sets the maximum theoretical quota overrun
  (with infinite node with infinite bandwidth) to twice the user's limit.  (In
  practice, the maximum overrun you see should be much less.)  A "quota_scale"
  number greater than one makes quota syncs more frequent and reduces the
  maximum overrun.  Numbers less than one (but greater than zero) make quota
  syncs less frequent.
  GFS quotas also use per-ID Lock Value Blocks (LVBs) to cache the contents of
  the quota file, so it is not being constantly read.
 Lock order: qd_lock -> bucket lock -> qd->lockref.lock -> lru lock 
                     -> sd_bitmap_lock                              
 Free from the filesystem-specific list 
 Delete it from the common reclaim list 
  gfs2_qa_get - make sure we have a quota allocations data structure,
                if necessary
  @ip: the inode for this reservation
 Reset quiet flag if we freed some blocks 
 Find the beginning block within the page 
 If it's a newly allocated disk block, zero it 
 If we need to write to the next block as well 
 Write to the page, now that we have setup the buffer(s) 
 If the quota straddles a page boundary, split the write in two 
 If there's an overflow, write the remaining bytes to the next page 
  gfs2_adjust_quota - adjust record of current block usage
  @ip: The quota inode
  @loc: Offset of the entry in the quota file
  @change: The amount of usage change to record
  @qd: The quota data
  @fdq: The updated limits to record
  This function was mostly borrowed from gfs2_block_truncate_page which was
  in turn mostly borrowed from ext3
  Returns: 0 or -ve on error
 gfs2_internal_read would've advanced the loc ptr 
 Never go negative on quota usage 
	 
	  1 blk for unstuffing inode if stuffed. We add this extra
	  block to the reservation unconditionally. If the inode
	  doesn't need unstuffing, the block will be released to the 
	  rgrp since it won't be allocated during the transaction
	 +3 in the end for unstuffing block, inode size update block
	  and another block in case quota straddles page boundary and 
  gfs2_quota_check - check if allocating new blocks will exceed quota
  @ip:  The inode for which this check is being performed
  @uid: The uid to check against
  @gid: The gid to check against
  @ap:  The allocation parameters. ap->target contains the requested
        blocks. ap->min_target, if set, contains the minimum blks
        requested.
  Returns: 0 on success.
                   min_req = ap->min_target ? ap->min_target : ap->target;
                   quota must allow at least min_req blks for success and
                   ap->allowed is set to the number of blocks allowed
           -EDQUOT otherwise, quota violation. ap->allowed is set to number
                   of blocks available.
 Assume we are permitted a whole lot 
 If we can't meet the target 
			 If no min_target specified or we don't meet
 Also remove if this qd exists in the reclaim list 
  gfs2_quotad - Write cached quota changes into the quota file
  @data: Pointer to GFS2 superblock
 Update the master statfs file 
 Update quota file 
 Check for & recover partially truncated inodes 
 unsupported 
 Crazy XFS error code 
 GFS2 only supports a subset of the XFS fields 
 Crazy XFS error code 
 Check for existing entry, if none then alloc new blocks 
 If nothing has changed, this is a no-op 
	 Some quotas span block boundaries and can update two blocks,
 Apply changes 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
 assume lh_hash is zero 
  get_log_header - read the log header for a given segment
  @jd: the journal
  @blk: the block to look at
  @head: the log header to return
  Read the log header for a given segement in a given journal.  Do a few
  sanity checks on it.
  Returns: 0 on success,
           1 if the header was invalid or incomplete,
           errno on error
  foreach_descriptor - go through the active part of the log
  @jd: the journal
  @start: the first log header in the active region
  @end: the last log header (don't process the contents of this entry))
  @pass: iteration number (foreach_descriptor() is called in a for() loop)
  Call a given function once for every log descriptor in the active
  portion of the log.
  Returns: errno
  clean_journal - mark a dirty journal as being clean
  @jd: the journal
  @head: the head journal to start from
  Returns: errno
  update_statfs_inode - Update the master statfs inode or zero out the local
 			 statfs inode for a given journal.
  @jd: The journal
  @head: If NULL, @inode is the local statfs inode and we need to zero it out.
 	  Otherwise, it @head contains the statfs change info that needs to be
 	  synced to the master statfs inode (pointed to by @inode).
  @inode: statfs inode to update.
 Update the master statfs inode 
 Zero out the local statfs inode 
 If it's our own journal, reset any in-memory changes too 
  recover_local_statfs - Update the master and local statfs changes for this
 			  journal.
  Previously, statfs updates would be read in from the local statfs inode and
  synced to the master statfs inode during recovery.
  We now use the statfs updates in the journal head to update the master statfs
  inode instead of reading in from the local statfs inode. To preserve backward
  compatibility with kernels that can't do this, we still need to keep the
  local statfs inode up to date by writing changes to it. At some point in the
  future, we can do away with the local statfs inodes altogether and keep the
  statfs changes solely in the journal.
  @jd: the journal
  @head: the journal head
  Returns: errno
 No change 
	  First update the master statfs inode with the changes we
	 Zero out the local statfs inode so any changes in there
 Acquire the journal lock so we can do recovery 
 Acquire a shared hold on the freeze lock 
 check if device itself is read-only 
		 We take the sd_log_flush_lock here primarily to prevent log
		  flushes and simultaneous journal replays from stomping on
 we have JDF_RECOVERY, queue should always succeed 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
 This doesn't need to be that large as max 64 bit pointers in a 4k
  block is 512, so __u16 is fine for that. It saves stack space to
  keep it small.
 find_metapath height 
 actual height (lookup height) 
  gfs2_unstuffer_page - unstuff a stuffed inode into a block cached by a page
  @ip: the inode
  @dibh: the dinode buffer
  @block: the block number that was allocated
  @page: The (optional) page. This is looked up if @page is NULL
  Returns: errno
		 Get a free block, fill it with the stuffed data,
  Set up the pointer to the new block  
  gfs2_unstuff_dinode - Unstuff a dinode when the data has grown too big
  @ip: The GFS2 inode to unstuff
  This routine unstuffs a dinode and returns it to a "normal" state such
  that the height can be grown in the traditional way.
  Returns: errno
  find_metapath - Find path through the metadata tree
  @sdp: The superblock
  @block: The disk block to look up
  @mp: The metapath to return the result in
  @height: The pre-calculated height of the metadata tree
    This routine returns a struct metapath structure that defines a path
    through the metadata of inode "ip" to get to block "block".
    Example:
    Given:  "ip" is a height 3 file, "offset" is 101342453, and this is a
    filesystem with a blocksize of 4096.
    find_metapath() would return a struct metapath structure set to:
    mp_fheight = 3, mp_list[0] = 0, mp_list[1] = 48, and mp_list[2] = 165.
    That means that in order to get to the block containing the byte at
    offset 101342453, we would load the indirect block pointed to by pointer
    0 in the dinode.  We would then load the indirect block pointed to by
    pointer 48 in that indirect block.  We would then load the data block
    pointed to by pointer 165 in that indirect block.
              ----------------------------------------
              | Dinode |                             |
              |        |                            4|
              |        |0 1 2 3 4 5                 9|
              |        |                            6|
              ----------------------------------------
                        |
                        |
                        V
              ----------------------------------------
              | Indirect Block                       |
              |                                     5|
              |            4 4 4 4 4 5 5            1|
              |0           5 6 7 8 9 0 1            2|
              ----------------------------------------
                                 |
                                 |
                                 V
              ----------------------------------------
              | Indirect Block                       |
              |                         1 1 1 1 1   5|
              |                         6 6 6 6 6   1|
              |0                        3 4 5 6 7   2|
              ----------------------------------------
                                            |
                                            |
                                            V
              ----------------------------------------
              | Data block containing offset         |
              |            101342453                 |
              |                                      |
              |                                      |
              ----------------------------------------
  metaptr1 - Return the first possible metadata pointer in a metapath buffer
  @height: The metadata height (0 = dinode)
  @mp: The metapath
  metapointer - Return pointer to start of metadata in a buffer
  @height: The metadata height (0 = dinode)
  @mp: The metapath
  Return a pointer to the block number of the next height of the metadata
  tree given a buffer containing the pointer to the current height of the
  metadata tree.
  lookup_metapath - Walk the metadata tree to a specific point
  @ip: The inode
  @mp: The metapath
  Assumes that the inode's buffer has already been looked up and
  hooked onto mp->mp_bh[0] and that the metapath has been initialised
  by find_metapath().
  If this function encounters part of the tree which has not been
  allocated, it returns the current height of the tree at the point
  at which it found the unallocated block. Blocks which are found are
  added to the mp->mp_bh[] list.
  Returns: error
  fillup_metapath - fill up buffers for the metadata path to a specific height
  @ip: The inode
  @mp: The metapath
  @h: The height to which it should be mapped
  Similar to lookup_metapath, but does lookups for a range of heights
  Returns: error or the number of buffers filled
 find the first buffer we need to look up. 
  gfs2_extent_length - Returns length of an extent of blocks
  @bh: The metadata block
  @ptr: Current position in @bh
  @limit: Max extent length to return
  @eob: Set to 1 if we hit "end of block"
  Returns: The length of the extent (minimum of one block)
  gfs2_metadata_walker - walk an indirect block
  @mp: Metapath to indirect block
  @ptrs: Number of pointers to look at
  When returning WALK_FOLLOW, the walker must update @mp to point at the right
  indirect block to follow.
  gfs2_walk_metadata - walk a tree of indirect blocks
  @inode: The inode
  @mp: Starting point of walk
  @max_len: Maximum number of blocks to walk
  @walker: Called during the walk
  Returns 1 if the walk was stopped by @walker, 0 if we went past @max_len or
  past the end of metadata, and a negative error code otherwise.
	
	  The walk starts in the lowest allocated indirect block, which may be
	  before the position indicated by @mp.  Adjust @max_len accordingly
	  to avoid a short walk.
 Walk indirect block. 
 Decrease height of metapath. 
 Advance in metadata tree. 
 Increase height of metapath. 
  gfs2_hole_size - figure out the size of a hole
  @inode: The inode
  @lblock: The logical starting block number
  @len: How far to look (in blocks)
  @mp: The metapath at lblock
  @iomap: The iomap to store the hole size in
  This function modifies @mp.
  Returns: errno on error
 ALLOC_UNSTUFF = 3,   TBD and rather complicated 
  __gfs2_iomap_alloc - Build a metadata tree of the requested height
  @inode: The GFS2 inode
  @iomap: The iomap structure
  @mp: The metapath, with proper height information calculated
  In this routine we may have to alloc:
    i) Indirect blocks to grow the metadata tree height
   ii) Indirect blocks to fill in lower part of the metadata tree
  iii) Data blocks
  This function is called after __gfs2_iomap_get, which works out the
  total number of blocks which we need via gfs2_alloc_size.
  We then do the actual allocation asking for an extent at a time (if
  enough contiguous free blocks are available, there will only be one
  allocation request per call) and uses the state machine to initialise
  the blocks in order.
  Right now, this function will allocate at most one indirect block
  worth of data -- with a default block size of 4K, that's slightly
  less than 2M.  If this limitation is ever removed to allow huge
  allocations, we would probably still want to limit the iomap size we
  return to avoid stalling other tasks during huge writes; the next
  iomap iteration would then find the blocks already allocated.
  Returns: errno on error
 Bottom indirect block exists 
 Need to allocate indirect blocks 
 Writing into existing tree, extend tree down 
 Building up tree height 
 start of the second part of the function (state machine) 
 Growing height of tree 
 To branching from existing tree 
 To tree complete, adding data blocks 
  gfs2_alloc_size - Compute the maximum allocation size
  @inode: The inode
  @mp: The metapath
  @size: Requested size in blocks
  Compute the maximum size of the next allocation at @mp.
  Returns: size in blocks
	
	  For writes to stuffed files, this function is called twice via
	  __gfs2_iomap_get, before and after unstuffing. The size we return the
	  first time needs to be large enough to get the reservation and
	  allocation sizes right.  The size we return the second time must
	  be exact or else __gfs2_iomap_alloc won't do the right thing.
  __gfs2_iomap_get - Map blocks from an inode to disk blocks
  @inode: The inode
  @pos: Starting position in bytes
  @length: Length to map, in bytes
  @flags: iomap flags
  @iomap: The iomap structure
  @mp: The metapath
  Returns: errno
 (see gfs2_file_direct_write) 
			
			  Silently fall back to buffered IO for stuffed files
			  or if we've got a hole (see gfs2_file_direct_write).
 Deallocate blocks that were just allocated. 
  gfs2_block_map - Map one or more blocks of an inode to a disk block
  @inode: The inode
  @lblock: The logical block number
  @bh_map: The bh to be mapped
  @create: True if its ok to alloc blocks to satify the request
  The size of the requested mapping is defined in bh_map->b_size.
  Clears buffer_mapped(bh_map) and leaves bh_map->b_size unchanged
  when @lblock is not mapped.  Sets buffer_mapped(bh_map) and
  bh_map->b_size to indicate the size of the mapping when @lblock and
  successive blocks are mapped, up to the requested size.
  Sets buffer_boundary() if a read of metadata will be required
  before the next block can be mapped. Sets buffer_new() if new
  blocks were allocated.
  Returns: errno
  NOTE: Never call gfs2_block_zero_range with an open transaction because it
  uses iomap write to perform its actions, which begin their own transactions
  (iomap_begin, page_prepare, etc.)
  gfs2_journaled_truncate - Wrapper for truncate_pagecache for jdata files
  @inode: The inode being truncated
  @oldsize: The original (larger) size
  @newsize: The new smaller size
  With jdata files, we have to journal a revoke for each block which is
  truncated. As a result, we need to split this into separate transactions
  if the number of pages being truncated gets too large.
  sweep_bh_for_rgrps - find an rgrp in a meta buffer and free blocks therein
  @ip: inode
  @rd_gh: holder of resource group glock
  @bh: buffer head to sweep
  @start: starting point in bh
  @end: end point in bh
  @meta: true if bh points to metadata (rather than data)
  @btotal: place to keep count of total blocks freed
  We sweep a metadata buffer (provided by the metapath) for blocks we need to
  free, and free them all. However, we do it one rgrp at a time. If this
  block has references to multiple rgrps, we break it into individual
  transactions. This allows other processes to use the rgrps while we're
  focused on a single one, for better concurrency  performance.
  At every transaction boundary, we rewrite the inode into the journal.
  That way the bitmaps are kept consistent with the inode and we can recover
  if we're interrupted by power-outages.
  Returns: 0, or return code if an error occurred.
           btotal has the total number of blocks freed
 needs to be s64 or gfs2_add_inode_blocks breaks 
 buffer was added to transaction 
 Must be done with the rgrp glock held: 
		 The size of our transactions will be unknown until we
		   actually process all the metadata blocks that relate to
		   the rgrp. So we estimate. We know it can't be more than
		   the dinode's i_blocks and we don't want to exceed the
 check if we will exceed the transaction blocks requested 
			 We set blks_outside_rgrp to ensure the loop will
			   be repeated for the same rgrp, but with a new
			 This next part is tricky. If the buffer was added
			   to the transaction, we've already set some block
			   pointers to 0, so we better follow through and free
			   them, or we will introduce corruption (so break).
			   This may be impossible, or at least rare, but I
			   decided to cover the case regardless.
			   If the buffer was not added to the transaction
			   (this call), doing so would exceed our transaction
			   size, so we need to end the transaction and start a
	if (!ret && blks_outside_rgrp) {  If buffer still has non-zero blocks
					    outside the rgrp we just processed,
			 Every transaction boundary, we rewrite the dinode
  find_nonnull_ptr - find a non-null pointer given a metapath and height
  @sdp: The superblock
  @mp: starting metapath
  @h: desired height to search
  @end_list: See punch_hole().
  @end_aligned: See punch_hole().
  Assumes the metapath is valid (with buffers) out to height h.
  Returns: true if a non-null pointer was found in the metapath buffer
           false if all remaining pointers are NULL in the buffer
 if we have a non-null pointer 
 Strip a metapath with all buffers read in 
 lower the metapath strip height 
 Fill in the metapath to the given height. 
 process complete 
  punch_hole - deallocate blocks in a file
  @ip: inode to truncate
  @offset: the start of the hole
  @length: the size of the hole (or 0 for truncate)
  Punch a hole into a file or truncate a file at a given position.  This
  function operates in whole blocks (@offset and @length are rounded
  accordingly); partially filled blocks must be cleared otherwise.
  This function works from the bottom up, and from the right to the left. In
  other words, it strips off the highest layer (data) before stripping any of
  the metadata. Doing it this way is best in case the operation is interrupted
  by power failure, etc.  The dinode is rewritten in every transaction to
  guarantee integrity.
 metapath buffers are read in to this height 
		
		  The starting point lies beyond the allocated meta-data;
		  there are no blocks do deallocate.
	
	  The start position of the hole is defined by lblock, start_list, and
	  start_aligned.  The end position of the hole is defined by lend,
	  end_list, and end_aligned.
	 
	  start_aligned and end_aligned define down to which height the start
	  and end positions are aligned to the metadata tree (i.e., the
	  position is a multiple of the metadata granularity at the height
	  above).  This determines at which heights additional meta pointers
	  needs to be preserved for the remaining data.
		
		  Clip the end at the maximum file size for the given height:
		  that's how far the metadata goes; files bigger than that
		  will have additional layers of indirection.
 issue read-ahead on metadata 
 We have a complete metapath 
 deal with partial metapath 
		 Truncate a full metapath at the given strip height.
			
			  Below, passing end_aligned as 0 gives us the
			  metapointer range excluding the end point: the end
			  point is the first metapath we must not deallocate!
 end_aligned ,
			 If we hit an error or just swept dinode buffer,
 lower the metapath strip height 
			 We're done with the current buffer, so release it,
			   unless it's the dinode buffer. Then back up to the
			 If we can't get any lower in height, we've stripped
			   off all we can. Next step is to back up and start
 search one metadata height down 
			 Here we've found a part of the metapath that is not
			  allocated. We need to search at that height for the
			 No more non-null pointers at this height. Back up
 loop around in the same state 
 Fill the metapath with buffers to the given height. 
 Fill the buffers out to the current height. 
 On the first pass, issue read-ahead on metadata. 
 No read-ahead for data blocks. 
 If buffers found for the entire strip height 
 We have a partial height 
			 If we find a non-null block pointer, crawl a bit
			   higher up in the metapath and try again, otherwise
  do_shrink - make a file smaller
  @inode: the inode
  @newsize: the size to make the file
  Called with an exclusive lock on @inode. The @size must
  be equal to or smaller than the current inode size.
  Returns: errno
  do_grow - Touch and update inode size
  @inode: The inode
  @size: The new size
  This function updates the timestamps on the inode and
  may also increase the size of the inode. This function
  must not be called with @size any smaller than the current
  inode size.
  Although it is not strictly required to unstuff files here,
  earlier versions of GFS2 have a bug in the stuffed file reading
  code which will result in a buffer overrun if the size is larger
  than the max stuffed file size. In order to prevent this from
  occurring, such files are unstuffed, but in other cases we can
  just update the inode size directly.
  Returns: 0 on success, or -ve on error
  gfs2_setattr_size - make a file a given size
  @inode: the inode
  @newsize: the size to make the file
  The file size can grow, shrink, or stay the same size. This
  is called holding i_rwsem and an exclusive glock on the inode
  in question.
  Returns: errno
  gfs2_free_journal_extents - Free cached journal bmap info
  @jd: The journal
  gfs2_add_jextent - Add or merge a new extent to extent cache
  @jd: The journal descriptor
  @lblock: The logical block at start of new extent
  @dblock: The physical block at start of new extent
  @blocks: Size of extent in fs blocks
  Returns: 0 on success or -ENOMEM
  gfs2_map_journal_extents - Cache journal bmap info
  @sdp: The super block
  @jd: The journal to map
  Create a reusable "extent" mapping from all logical
  blocks to all physical blocks for the given journal.  This will save
  us time when writing journal blocks.  Most journals will have only one
  extent that maps all their logical blocks.  That's because gfs2.mkfs
  arranges the journal blocks sequentially to maximize performance.
  So the extent would map the first block for the entire file length.
  However, gfs2_jadd can happen while file activity is happening, so
  those journals may not be sequential.  Less likely is the case where
  the users created their own journals by mounting the metafs and
  laying it out.  But it's still possible.  These journals might have
  several extents.
  Returns: 0 on success, or error on failure
  gfs2_write_alloc_required - figure out if a write will require an allocation
  @ip: the file being written to
  @offset: the offset to write to
  @len: the number of bytes being written
  Returns: 1 if an alloc is required, 0 otherwise
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2008 Red Hat, Inc.  All rights reserved.
  gfs2_get_block_noalloc - Fills in a buffer head with details about a block
  @inode: The inode
  @lblock: The block number to look up
  @bh_result: The buffer head to return the result in
  @create: Non-zero if we may add block to the file
  Returns: errno
  gfs2_writepage - Write page for writeback mappings
  @page: The page
  @wbc: The writeback control
  gfs2_write_jdata_page - gfs2 jdata-specific version of block_write_full_page
  @page: The page to write
  @wbc: The writeback control
  This is the same as calling block_write_full_page, but it also
  writes pages outside of i_size
	
	  The page straddles i_size.  It must be zeroed out on each and every
	  writepage invocation because it may be mmapped.  "A file is mapped
	  in multiples of the page size.  For a file that is not a multiple of
	  the  page size, the remaining memory is zeroed when mapped, and
	  writes to that region are not written out to the file."
  __gfs2_jdata_writepage - The core of jdata writepage
  @page: The page to write
  @wbc: The writeback control
  This is shared between writepage and writepages and implements the
  core of the writepage operation. If a transaction is required then
  PageChecked will have been set and the transaction will have
  already been started before this is called.
  gfs2_jdata_writepage - Write complete page
  @page: Page to write
  @wbc: The writeback control
  Returns: errno
  gfs2_writepages - Write a bunch of dirty pages back to disk
  @mapping: The mapping to write
  @wbc: Write-back control
  Used for both ordered and writeback modes.
	
	  Even if we didn't write any pages here, we might still be holding
	  dirty pages in the ail. We forcibly flush the ail because we don't
	  want balance_dirty_pages() to loop indefinitely trying to write out
	  pages held in the ail that it can't find.
  gfs2_write_jdata_pagevec - Write back a pagevec's worth of pages
  @mapping: The mapping
  @wbc: The writeback control
  @pvec: The vector of pages
  @nr_pages: The number of pages to write
  @done_index: Page index
  Returns: non-zero if loop should terminate, zero otherwise
 someone wrote it for us 
				
				  done_index is set past this page,
				  so media errors will not choke
				  background writeout for the entire
				  file. This has consequences for
				  range_cyclic semantics (ie. it may
				  not be suitable for data integrity
				  writeout).
		
		  We stop writing back only if we are not doing
		  integrity sync. In case of integrity sync we have to
		  keep going until we have written all the pages
		  we tagged for writeback prior to entering this loop.
  gfs2_write_cache_jdata - Like write_cache_pages but different
  @mapping: The mapping to write
  @wbc: The writeback control
  The reason that we use our own function here is that we need to
  start transactions before we grab page locks. This allows us
  to get the ordering right.
 prev offset 
 ignore range_cyclic tests 
		
		  range_cyclic:
		  We hit the last page and there is more work to be done: wrap
		  back to the start of the file
  gfs2_jdata_writepages - Write a bunch of dirty pages back to disk
  @mapping: The mapping to write
  @wbc: The writeback control
  stuffed_readpage - Fill in a Linux page with stuffed file data
  @ip: the inode
  @page: the page
  Returns: errno
	
	  Due to the order of unstuffing files and ->fault(), we can be
	  asked for a zero page in the case of a stuffed file being extended,
	  so we need to supply one here. It doesn't happen often.
  gfs2_readpage - read a page of a file
  @file: The file to read
  @page: The page of the file
  gfs2_internal_read - read an internal file
  @ip: The gfs2 inode
  @buf: The buffer to fill
  @pos: The file position
  @size: The amount to read
  gfs2_readahead - Read a bunch of pages at once
  @rac: Read-ahead control structure
  Some notes:
  1. This is only for readahead, so we can simply ignore any things
     which are slightly inconvenient (such as locking conflicts between
     the page lock and the glock) and return having done no IO. Its
     obviously not something we'd want to do on too regular a basis.
     Any IO we ignore at this time will be done via readpage later.
  2. We don't handle stuffed files here we let readpage do the honours.
  3. mpage_readahead() does most of the heavy lifting in the common case.
  4. gfs2_block_map() is relied upon to set BH_Boundary in the right places.
  adjust_fs_space - Adjusts the free space available due to gfs2_grow
  @inode: the rindex inode
 Total up the file system space, according to the latest rindex. 
  jdata_set_page_dirty - Page dirtying function
  @page: The page to dirty
  Returns: 1 if it dirtyed the page, or 0 otherwise
  gfs2_bmap - Block map function
  @mapping: Address space info
  @lblock: The block to map
  Returns: The disk address for the block or 0 on hole or error
  gfs2_releasepage - free the metadata associated with a page
  @page: the page that's being released
  @gfp_mask: passed from Linux VFS, ignored by us
  Calls try_to_free_buffers() to free the buffers and put the page if the
  buffers can be released.
  Returns: 1 if the page was put or else 0
	
	  From xfs_vm_releasepage: mm accommodates an old ext3 case where
	  clean pages might not have had the dirty bit cleared.  Thus, it can
	  send actual dirty pages to ->releasepage() via shrink_active_list().
	 
	  As a workaround, we skip pages that contain dirty buffers below.
	  Once ->releasepage isn't called on dirty pages anymore, we can warn
	  on dirty buffers like we used to here again.
			
			  The bd may still be queued as a revoke, in which
			  case we must not dequeue nor free it.
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2007 Red Hat, Inc.  All rights reserved.
  gfs2_struct2blk - compute stuff
  @sdp: the filesystem
  @nstruct: the number of structures
  Compute the number of log descriptor blocks needed to hold a certain number
  of structures of a certain size.
  Returns: the number of blocks needed (minimum is always 1)
 The initial struct gfs2_log_descriptor block 
 Subsequent struct gfs2_meta_header blocks 
  gfs2_remove_from_ail - Remove an entry from the ail lists, updating counters
  @bd: The gfs2_bufdata to remove
  The ail lock _must_ be held when calling this function
  gfs2_ail1_start_one - Start IO on a transaction
  @sdp: The superblock
  @wbc: The writeback control structure
  @tr: The transaction to start IO on
  @plug: The block plug currently active
 if a jdata write into a new hole 
 ignore it 
  gfs2_ail1_flush - start writeback of some ail1 entries 
  @sdp: The super block
  @wbc: The writeback control structure
  Writes back some ail1 entries, according to the limits in the
  writeback control structure
  gfs2_ail1_start - start writeback of all ail1 entries
  @sdp: The superblock
  gfs2_ail_empty_tr - empty one of the ail lists of a transaction
  gfs2_ail1_empty_one - Check whether or not a trans in the AIL has been synced
  @sdp: the filesystem
  @tr: the transaction
  @max_revokes: If nonzero, issue revokes for the bd items for written buffers
  returns: the transaction's count of remaining active items
		
		  If another process flagged an io error, e.g. writing to the
		  journal, error all other bhs and move them off the ail1 to
		  prevent a tight loop when unmount tries to flush ail1,
		  regardless of whether they're still busy. If no outside
		  errors were found and the buffer is busy, move to the next.
		  If the ail buffer is not busy and caught an error, flag it
		  for others.
		
		  If we have space for revokes and the bd is no longer on any
		  buf list, we can just add a revoke for it immediately and
		  avoid having to put it on the ail2 list, where it would need
		  to be revoked later.
  gfs2_ail1_empty - Try to empty the ail1 lists
  @sdp: The superblock
  @max_revokes: If non-zero, add revokes where appropriate
  Tries to empty the ail1 lists, starting with the oldest first
  gfs2_log_is_empty - Check if the log is empty
  @sdp: The GFS2 superblock
  gfs2_log_release_revokes - Release a given number of revokes
  @sdp: The GFS2 superblock
  @revokes: The number of revokes to release
  sdp->sd_log_flush_lock must be held.
  gfs2_log_release - Release a given number of log blocks
  @sdp: The GFS2 superblock
  @blks: The number of blocks
  __gfs2_log_try_reserve - Try to make a log reservation
  @sdp: The GFS2 superblock
  @blks: The number of blocks to reserve
  @taboo_blks: The number of blocks to leave free
  Try to do the same as __gfs2_log_reserve(), but fail if no more log
  space is immediately available.
  __gfs2_log_reserve - Make a log reservation
  @sdp: The GFS2 superblock
  @blks: The number of blocks to reserve
  @taboo_blks: The number of blocks to leave free
  @taboo_blks is set to 0 for logd, and to GFS2_LOG_FLUSH_MIN_BLOCKS
  for all other processes.  This ensures that when the log is almost full,
  logd will still be able to call gfs2_log_flush one more time  without
  blocking, which will advance the tail and make some more log space
  available.
  We no longer flush the log here, instead we wake up logd to do that
  for us. To avoid the thundering herd and to ensure that we deal fairly
  with queued waiters, we use an exclusive wait. This means that when we
  get woken with enough journal space to get our reservation, we need to
  wake the next waiter on the list.
  gfs2_log_try_reserve - Try to make a log reservation
  @sdp: The GFS2 superblock
  @tr: The transaction
  @extra_revokes: The number of additional revokes reserved (output)
  This is similar to gfs2_log_reserve, but sdp->sd_log_flush_lock must be
  held for correct revoke accounting.
  gfs2_log_reserve - Make a log reservation
  @sdp: The GFS2 superblock
  @tr: The transaction
  @extra_revokes: The number of additional revokes reserved (output)
  sdp->sd_log_flush_lock must not be held.
  log_distance - Compute distance between two journal blocks
  @sdp: The GFS2 superblock
  @newer: The most recent journal block of the pair
  @older: The older journal block of the pair
    Compute the distance (in the journal direction) between two
    blocks in the journal
  Returns: the distance in blocks
  calc_reserved - Calculate the number of blocks to keep reserved
  @sdp: The GFS2 superblock
  This is complex.  We need to reserve room for all our currently used
  metadata blocks (e.g. normal file IO rewriting file time stamps) and
  all our journaled data blocks for journaled files (e.g. files in the
  meta_fs like rindex, or files for which chattr +j was done.)
  If we don't reserve enough space, corruption will follow.
  We can have metadata blocks and jdata blocks in the same journal.  Each
  type gets its own log descriptor, for which we need to reserve a block.
  In fact, each type has the potential for needing more than one log descriptor
  in cases where we have more blocks than will fit in a log descriptor.
  Metadata journal entries take up half the space of journaled buffer entries.
  Also, we need to reserve blocks for revoke journal entries and one for an
  overall header for the lot.
  Returns: the number of blocks reserved
 drops ref on bh 
  gfs2_flush_revokes - Add as many revokes to the system transaction as we can
  @sdp: The GFS2 superblock
  Our usual strategy is to defer writing revokes as much as we can in the hope
  that we'll eventually overwrite the journal, which will make those revokes
  go away.  This changes when we flush the log: at that point, there will
  likely be some left-over space in the last revoke block of that transaction.
  We can fill that space with additional revokes for blocks that have already
  been written back.  This will basically come at no cost now, and will save
  us from having to keep track of those blocks on the AIL2 list later.
 number of revokes we still have room for 
  gfs2_write_log_header - Write a journal log header buffer at lblock
  @sdp: The GFS2 superblock
  @jd: journal descriptor of the journal to which we are writing
  @seq: sequence number
  @tail: tail of the log
  @lblock: value for lh_blkno (block number relative to start of journal)
  @flags: log header flags GFS2_LOG_HEAD_
  @op_flags: flags to pass to the bio
  Returns: the initialized log buffer descriptor
	 We may only write local statfs, quota, etc., when writing to our
	   own journal. The values are left 0 when recovering a journal
  log_write_header - Get and initialize a journal header buffer
  @sdp: The GFS2 superblock
  @flags: The log header flags, including log header origin
  Returns: the initialized log buffer descriptor
  gfs2_ail_drain - drain the ail lists after a withdraw
  @sdp: Pointer to GFS2 superblock
	
	  For transactions on the sd_ail1_list we need to drain both the
	  ail1 and ail2 lists. That's because function gfs2_ail1_start_one
	  (temporarily) moves items from its tr_ail1 list to tr_ail2 list
	  before revokes are sent for that block. Items on the sd_ail2_list
	  should have already gotten beyond that point, so no need.
  empty_ail1_list - try to start IO and empty the ail1 list
  @sdp: Pointer to GFS2 superblock
  trans_drain - drain the buf and databuf queue for a failed transaction
  @tr: the transaction to drain
  When this is called, we're taking an error exit for a log write that failed
  but since we bypassed the after_commit functions, we need to remove the
  items from the buf and databuf queue.
  gfs2_log_flush - flush incore transaction(s)
  @sdp: The filesystem
  @gl: The glock structure to flush.  If NULL, flush the whole incore log
  @flags: The log header flags: GFS2_LOG_HEAD_FLUSH_ and debug flags
	
	  Do this check while holding the log_flush_lock to prevent new
	  buffers from being added to the ail via gfs2_pin()
 Log might have been flushed while we waited for the flush lock 
	
	  If the tr_list is empty, we're withdrawing during a log
	  flush that targets a transaction, but the transaction was
	  never queued onto any of the ail lists. Here we add it to
	  ail1 just so that ail_drain() will find and free it.
  gfs2_merge_trans - Merge a new transaction into a cached transaction
  @sdp: the filesystem
  @new: New transaction to be merged
  gfs2_log_commit - Commit a transaction to the log
  @sdp: the filesystem
  @tr: the transaction
  We wake up gfs2_logd if the number of pinned blocks exceed thresh1
  or the total number of used blocks (pinned blocks plus AIL blocks)
  is greater than thresh2.
  At mount time thresh1 is 25ths of journal size, thresh2 is 45ths of
  journal size.
  Returns: errno
  gfs2_log_shutdown - write a shutdown header into a journal
  @sdp: the filesystem
  gfs2_logd - Update log tail as Active Items get flushed to in-place blocks
  @data: Pointer to GFS2 superblock
  Also, periodically check to make sure that we're using the most recent
  journal index.
 Check for errors writing to the journal 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) Sistina Software, Inc.  1997-2003 All rights reserved.
  Copyright (C) 2004-2006 Red Hat, Inc.  All rights reserved.
  init_gfs2_fs - Register GFS2 as a filesystem
  Returns: 0 on success, error code on failure
  exit_gfs2_fs - Unregister the file system
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  fill_name_de - Format NTFS_DE in @buf.
 Convert input string to unicode. 
  ntfs_lookup - inode_operations::lookup
  ntfs_create - inode_operations::create
  ntfs_mknod
  inode_operations::mknod
  ntfs_link - inode_operations::link
  ntfs_unlink - inode_operations::unlink
  ntfs_symlink - inode_operations::symlink
  ntfs_mkdir- inode_operations::mkdir
  ntfs_rmdir - inode_operations::rm_dir
  ntfs_rename - inode_operations::rename
	
	  de		- memory of PATH_MAX bytes:
	  [0-1024)	- original name (dentry->d_name)
	  [1024-2048)	- paired to original name, usually DOS variant of dentry->d_name
	  [2048-3072)	- new name (new_dentry->d_name)
 Nothing to do. 
 Should we print an error? 
 Target name exists. Unlink it. 
 Allocate PATH_MAX bytes. 
 Translate dentry->d_name into unicode form. 
 Reuse 'de'. 
 Translate new_dentry->d_name into unicode form. 
 Restore after failed rename failed too. 
 clang-format off
 clang-format on
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  cmp_fnames - Compare two names in index.
  if l1 != 0
    Both names are little endian on-disk ATTR_FILE_NAME structs.
  else
    key1 - cpu_str, key2 - ATTR_FILE_NAME
&& !sbi->options.nocase;
		
		  If names are equal (case insensitive)
		  try to compare it case sensitive.
  cmp_uint - $SII of $Secure and $Q of Quota
  cmp_sdh - $SDH of $Secure
 First value is a hash value itself. 
 Second value is security Id. 
  cmp_uints - $O of ObjId and "$R" for Reparse.
		
		  ni_delete_all -> ntfs_remove_reparse ->
		  delete all with this reference.
		  k1, k2 - pointers to REPARSE_KEY
 Skip REPARSE_KEY.ReparseTag
 Skip REPARSE_KEY.ReparseTag
 Looks like filesystem error. 
  indx_mark_used - Mark the bit @bit as used.
  indx_mark_free - Mark the bit @bit as free.
  scan_nres_bitmap
  If ntfs_readdir calls this function (indx_used_bit -> scan_nres_bitmap),
  inode is shared locked and no ni_lock.
  Use rw_semaphore for readwrite access to bitmap_run.
  indx_find_free - Look for free bit.
  Return: -1 if no free bits.
  indx_used_bit - Look for used bit.
  Return: MINUS_ONE_T if no used bits.
  hdr_find_split
  Find a point at which the index allocation buffer would like to be split.
  NOTE: This function should never return 'END' entry NULL returns on error.
 We must not return END entry. 
  hdr_insert_head - Insert some entries at the beginning of the buffer.
  It is used to insert entries into a newly-created buffer.
 Now we just make room for the inserted entries and jam it in. 
  hdr_find_e - Locate an entry the index buffer.
  If no matching entry is found, it returns the first entry which is greater
  than the desired entry If the search key is greater than all the entries the
  buffer, it returns the 'end' entry. This function does a binary search of the
  current index buffer, for the first entry that is <= to the search value.
  Return: NULL if error.
  hdr_insert_de - Insert an index entry into the buffer.
  'before' should be a pointer previously returned from hdr_find_e.
 First, check to see if there's enough room. 
 We know there's enough space, so we know we'll succeed. 
 Check that before is inside Index. 
 No insert point is applied. Get it manually. 
 Now we just make room for the entry and jam it in. 
  hdr_delete_de - Remove an entry from the index buffer.
 Check root fields. 
 Check index record size. 
 Index record is smaller than a cluster, use 512 blocks. 
 Check alignment to a cluster. 
 Index record must be a multiple of cluster size. 
 Create header. 
 0x28
 9
  indx_read
  If ntfs_readdir calls this function
  inode is shared locked and no ni_lock.
  Use rw_semaphore for readwrite access to alloc_run.
  indx_find - Scan NTFS directory for given entry.
 Check cache. 
 Soft finder reset. 
 Lookup entry that is <= to the search value. 
 Read next level. 
 Lookup entry that is <= to the search value. 
 Start find. 
 Just to avoid tree cycle. 
 Read next level. 
 Try next level. 
 Pop one level. 
 Use non sorted algorithm. 
 This is the first call. 
 The first call with setup of initial element. 
 Jump inside cycle 'for'. 
 Start enumeration from root. 
 Check if current entry can be used. 
 Continue to enumerate root. 
 Start to enumerate indexes from 0. 
 Continue to enumerate indexes. 
 Continue with next index. 
 Release current index. 
 Skip all free indexes. 
 No used indexes. 
 Read buffer into memory. 
 Return offset to restore enumerator if necessary. 
 'e' points in root, 
 'e' points in index, 
  indx_create_allocate - Create "Allocation + Bitmap" attributes.
  indx_add_allocate - Add clusters to index.
 Increase bitmap. 
 Increase allocation. 
 Ops. No space? 
  indx_insert_into_root - Attempt to insert an entry into the index root.
  @undo - True if we undoing previous remove.
  If necessary, it will twiddle the index b-tree.
 Get the record this root placed in. 
	
	  Try easy case:
	  hdr_insert_de will succeed if there's
	  room the root for the new entry.
 If 'undo' is set then reduce requirements. 
 Make a copy of root attribute to restore if error. 
	
	  Copy all the non-end entries from
	  the index root to the new buffer.
 Calculate the size to copy. 
 Make root external. 
 Fill first entry (vcn will be set later). 
 Create alloc and bitmap attributes (if not). 
 Layout of record may be changed, so rescan root. 
 Bug? 
 Restore root. 
 Bug? 
 Now we can createformat the new buffer and copy the entries into. 
 Copy root entries into new buffer. 
 Update bitmap attribute. 
 Check if we can insert new entry new index buffer. 
		
		  This occurs if MFT record is the same or bigger than index
		  buffer. Move all root new index and have no space to add
		  new entry classic case when MFT record is 1K and index
		  buffer 4K the problem should not occurs.
	
	  Now root is a parent for new index buffer.
	  Insert NewEntry a new buffer.
 Just write updates index into disk. 
  indx_insert_into_buffer
  Attempt to insert an entry into an Index Allocation Buffer.
  If necessary, it will split the buffer.
 Try the most easy case. 
 Just write updated index into disk. 
	
	  No space to insert into buffer. Split it.
	  To split we:
	   - Save split point ('cause index buffers will be changed)
	  - Allocate NewBuffer and copy all entries <= sp into new buffer
	  - Remove all entries (sp including) from TargetBuffer
	  - Insert NewEntry into left or right buffer (depending on sp <=>
	      NewEntry)
	  - Insert sp into parent buffer (or root)
	  - Make sp a parent for new buffer
 Allocate on disk a new index allocation buffer. 
 Allocate and format memory a new index buffer. 
 Make sp a parent for new buffer. 
 Copy all the entries <= sp into the new buffer. 
 Remove all entries (sp including) from hdr1. 
	
	  Insert new entry into left or right buffer
	  (depending on sp <=> new_de).
	
	  We've finished splitting everybody, so we are ready to
	  insert the promoted entry into the parent.
 Insert in root. 
		
		  The target buffer's parent is another index buffer.
		  TODO: Remove recursion.
  indx_insert_entry - Insert new entry into index.
  @undo - True if we undoing previous remove.
		
		  Find the spot the tree where we want to
		  insert the new entry.
		
		  The root is also a leaf, so we'll insert the
		  new entry into it.
		
		  Found a leaf buffer, so we'll insert the new entry into it.
  indx_find_buffer - Locate a buffer from the tree.
 Step 1: Scan one level. 
 Step2: Do recursion. 
  indx_shrink - Deallocate unused tail indexes.
 First, recurse into the children, if any. 
	
	  We've gotten rid of the children; add this buffer to the free list.
	
	  If there are no used indexes after current free index
	  then we can truncate allocation and bitmap.
	  Use bitmap to estimate the case.
  indx_get_entry_to_replace
  Find a replacement entry for a deleted entry.
  Always returns a node entry:
  NTFS_IE_HAS_SUBNODES is set the flags and the size includes the sub_vcn.
 Find first leaf entry down from de_next. 
			
			  This buffer is non-empty, so its first entry
			  could be used as the replacement entry.
 This buffer is a node. Continue to go down. 
 Copy the candidate entry into the replacement entry buffer. 
		
		  The replacement entry we found doesn't have a sub_vcn.
		  increase its size to hold one.
		
		  The replacement entry we found was a node entry, which
		  means that all its child buffers are empty. Return them
		  to the free pool.
	
	  Expunge the replacement entry from its former location,
	  and then write that buffer.
 Check to see if this action created an empty leaf. 
  indx_delete_entry - Delete an entry from the index.
 Locate the entry to remove. 
 The entry to delete is a leaf, so we can just rip it out. 
 Shrink resident root attribute. 
		
		  Check to see if removing that entry made
		  the leaf empty.
		
		  The entry we wish to delete is a node buffer, so we
		  have to find a replacement for it.
			
			  There is no replacement for the current entry.
			  This means that the subtree rooted at its node
			  is empty, and can be deleted, which turn means
			  that the node can just inherit the deleted
			  entry sub_vcn.
 Shrink resident root attribute. 
 Delete a branch of tree. 
 Reinit root 'cause it can be changed. 
 Scan current level. 
 Do slow search from root. 
 Merge fnd2 -> fnd. 
			
			  Didn't find the parent entry, although this buffer
			  is the parent trail. Something is corrupt.
			
			  Since we can't remove the end entry, we'll remove
			  its predecessor instead. This means we have to
			  transfer the predecessor's sub_vcn to the end entry.
			  Note: This index block is not empty, so the
			  predecessor must exist.
		
		  Copy the current entry into a temporary buffer (stripping
		  off its down-pointer, if any) and delete it from the current
		  buffer or root, as appropriate.
 Shrink resident root attribute. 
 Mark unused buffers as free. 
fnd->root_de = NULL;
		
		  Re-insert the entry into the tree.
		  Find the spot the tree where we want to insert the new entry.
		
		  This tree needs to be collapsed down to an empty root.
		  Recreate the index root as an empty leaf and free all
		  the bits the index allocation bitmap.
 Fill first entry. 
 0x02
  Update duplicated information in directory entry
  'dup' - info from MFT record
 Find entry in directory. 
		
		  Nothing to update in index! Try to avoid this call.
 Directory entry in index. 
 Directory entry in directory MFT record. 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  fill_mask[i] - first i bits are '1' , i = 0,1,2,3,4,5,6,7,8
  fill_mask[i] = 0xFF >> (8-i)
  zero_mask[i] - first i bits are '0' , i = 0,1,2,3,4,5,6,7,8
  zero_mask[i] = 0xFF << i
  are_bits_clear
  Return: True if all bits [bit, bit+nbits) are zeros "0".
  are_bits_set
  Return: True if all bits [bit, bit+nbits) are ones "1".
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
 clang-format off
 Src buffer is zero. 
 clang-format on
 Compare two matches and select the best one. 
  compress_chunk
  Return:
   0	- Ok, @cmpr contains @cmpr_chunk_size bytes of compressed data.
   1	- Input buffer is full zero.
   -2 - The compressed buffer is too small to hold the compressed data.
 Control byte of 8-bit values: ( 0 - means byte as is, 1 - short pair ). 
 Find match. 
	
	  Copy non cmpr data.
	  0x3FFF == ((LZNT_CHUNK_SIZE + 2 - 3) | 0x3000)
 Do decompression until pointers are inside range. 
 Correct index 
 Check the current flag for zero. 
 Just copy byte. 
 Check for boundary. 
 Read a short from little endian stream. 
 Translate packed information into offset and length. 
 Check offset for boundary. 
 Truncate the length if necessary. 
 Now we copy bytes. This is the heart of LZ algorithm. 
 Advance flag bit value. 
 Return the size of uncompressed data. 
  get_lznt_ctx
  @level: 0 - Standard compression.
 	   !0 - Best compression, requires a lot of cpu.
  compress_lznt - Compresses @unc into @cmpr
  Return:
   +x - Ok, @cmpr contains 'final_compressed_size' bytes of compressed data.
   0 - Input buffer is full zero.
 Compression cycle. 
  decompress_lznt - Decompress @cmpr into @unc.
 Read chunk header. 
 Loop through decompressing chunks. 
 Check that the chunk actually fits the supplied buffer. 
 First make sure the chunk contains compressed data. 
 Decompress a chunk and return if we get an error. 
 This chunk does not contain compressed data. 
 Advance pointers. 
 Check for the end of unc buffer. 
 Proceed the next chunk. 
 Read chunk header. 
 Check the size of unc buffer. 
 'Zero' memory. 
 Check compression boundary. 
	
	  The unc size is just a difference between current
	  pointer and original one.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  ni_find_mi - Find mft_inode by record number.
  ni_add_mi - Add new mft_inode into ntfs_inode.
  ni_remove_mi - Remove mft_inode from ntfs_inode.
  ni_std - Return: Pointer into std_info from primary record.
  ni_std5
  Return: Pointer into std_info from primary record.
  ni_clear - Clear resources allocated by ntfs_inode.
 Bad inode always has mode == S_IFREG. 
 On-demand allocated page for offsets. 
  ni_load_mi_ex - Find mft_inode by record number.
  ni_load_mi - Load mft_inode corresponded list_entry.
  ni_find_attr
  Return: Attribute and record this attribute belongs to.
 Look for required attribute in primary record. 
 First look for list entry of required type. 
 Load record that contains this attribute. 
 Look for required attribute. 
  ni_enum_attr_ex - Enumerates attributes in ntfs_inode.
 Do we have an attribute list? 
 Enum attributes in primary record. 
 Get next list entry. 
 Load record that contains the required attribute. 
 Find attribute in loaded record. 
  ni_load_attr - Load attribute that contains given VCN.
	
	  Unfortunately ATTR_LIST_ENTRY contains only start VCN.
	  So to find the ATTRIB segment that contains 'vcn' we should
	  enumerate some entries.
  ni_load_all_mi - Load all subrecords.
  ni_add_subrecord - Allocate + format + attach a new subrecord.
  ni_remove_attr - Remove all attributes for the given typenameid.
  ni_ins_new_attr - Insert the attribute into record.
  Return: Not full constructed attribute or NULL if not possible to create.
 No memory or no space. 
		
		  al_add_le -> attr_set_size (list) -> ni_expand_list
		  which moves some attributes out of primary record
		  this means that name may point into moved memory
		  reinit 'name' from le.
 Attr list is not in list entry array. 
 Update ATTRIB Id and record reference. 
  ni_repack
  Random write access to sparsed or compressed file may result to
  not optimized packed runs.
  Here is the place to optimize it.
 Do not try if not enogh free space. 
 Do not try if last attribute segment. 
		
		  Run contains data from two records: mi_p and mi
		  Try to pack in one.
 We can remove this attribute segment. 
 Pack loaded but not packed runs. 
  ni_try_remove_attr_list
  Can we remove attribute list?
  Check the case when primary record contains enough space for all attributes.
 Free space in primary record without attribute list. 
 It seems that attribute list can be removed from primary record. 
	
	  Repeat the cycle above and move all attributes to primary record.
	  It should be success!
 Should never happened, 'cause already checked. 
 Should never happened, 'cause already checked. 
 Insert into primary record. 
			
			  Internal error.
			  Either no space in primary record (already checked).
			  Either tried to insert another
			  non indexed attribute (logic error).
 Copy all except id. 
 Remove from original record. 
  ni_create_attr_list - Generates an attribute list for this primary record.
	
	  Skip estimating exact memory requirement.
	  Looks like one record_size is always enough.
 Allocate child MFT. 
 Call mi_remove_attr() in reverse order to keep pointers 'arr_move' valid. 
 Copy all except id. 
 Remove from primary record. 
  ni_ins_attr_ext - Add an external attribute to the ntfs_inode.
	
	  Standard information and attr_list cannot be made external.
	  The Log File cannot have any external attributes.
 Create attribute list if it is not already existed. 
 Load all subrecords into memory. 
 Check each of loaded subrecord. 
 We can't accept this record 'cause MFT's bootstrapping. 
			
			  This child record already has a ATTR_DATA.
			  So it can't accept any other records.
 Only indexed attributes can share same record. 
		
		  Do not try to insert this attribute
		  if there is no room in record.
 Try to insert attribute into this subrecord. 
 We have to allocate a new child subrecord. 
  ni_insert_attr - Insert an attribute into the file.
  If the primary record has room, it will just insert the attribute.
  If not, it may make the attribute external.
  For $MFT::Data it may make room for the attribute by
  making other attributes external.
  NOTE:
  The ATTR_LIST and ATTR_STD cannot be made external.
  This function does not fill new attribute full.
  It only fills 'size''type''id''name_len' fields.
 Reserve space for the ATTRIB list. 
 This ATTRIB will be external. 
	
	  Here we have: "is_mft && type == ATTR_DATA && !svcn"
	 
	  The first chunk of the $MFT::Data ATTRIB must be the base record.
	  Evict as many other attributes as possible.
 Estimate the result of moving all possible attributes away. 
 Impossible to insert this attribute into primary record. 
 Start real attribute moving. 
 We should never be here 'cause we have already check this case. 
 Skip attributes that MUST be primary record. 
 Really this is a serious bug. 
 Remove from primary record. 
 attr now points to next attribute. 
 ni_expand_mft_list - Split ATTR_DATA of $MFT. 
 Find the nearest MFT. 
 Really this is not critical. 
	
	  Split primary attribute [0 evcn] in two parts [0 svcn) + [svcn evcn].
	 
	  Update first part of ATTR_DATA in 'primary MFT.
 'done' - How many bytes of primary MFT becomes free. 
 Estimate the size of second part: run_buf=NULL. 
	
	  This function may implicitly call expand attr_list.
	  Insert second part of ATTR_DATA in 'mi_min'.
  ni_expand_list - Move all possible attributes out of primary record.
 Find attribute in primary record. 
 Always insert into new record to avoid collisions (deep recursive). 
 Remove from primary record. 
 Attr list is too big(?) 
 Split MFT data as much as possible. 
  ni_insert_nonresident - Insert new nonresident attribute.
  ni_insert_resident - Inserts new resident attribute.
 is_attr_indexed(attr)) == true 
  ni_remove_attr_le - Remove attribute from record.
  ni_delete_all - Remove all attributes and frees allocates space.
  ntfs_evict_inode->ntfs_clear_inode->ni_delete_all (if no links).
 run==1 means unpack and deallocate. 
 Free all subrecords. 
 Free base record. 
 ni_fname_name
  Return: File name attribute by its value.
 Enumerate all names. 
  ni_fname_type
  Return: File name attribute with given type.
 Enumerate all names. 
  ni_new_attr_flags
  Process compressedsparsed in special way.
  NOTE: You need to set ni->std_fa = new_fa
  after this function to keep internal structures in consistency.
 Resize nonresident empty attribute in-place only. 
 Windows uses 16 clusters per frame but supports one cluster per frame too. 
 The only allowed: 16 clusters per frame. 
 Normal files. 
  ni_parse_reparse
  buffer - memory for reparse buffer header
 Try to estimate reparse point. 
 Symbolic link. 
 Mount points and junctions. 
		
		  WOF - Windows Overlay Filter - Used to compress files with
		  LZXXpress.
		 
		  Unlike native NTFS file compression, the Windows
		  Overlay Filter supports only read operations. This means
		  that it doesn't need to sector-align each compressed chunk,
		  so the compressed data can be packed more tightly together.
		  If you open the file for writing, the WOF just decompresses
		  the entire file, turning it back into a plain file.
		 
		  Ntfs3 driver decompresses the entire file only on write or
		  change size requests.
 4k
 8k
 16k
 32k
 64k
 Looks like normal symlink. 
  ni_fiemap - Helper for file_fiemap().
  Assumed ni_lock.
  TODO: Less aggressive locks.
 Unfortunately cp -r incorrectly treats compressed clusters. 
 ?
 vbo < valid && valid < vbo + bytes 
  ni_readpage_cmpr
  When decompressing, we typically obtain more than one page per reference.
  We inject the additional pages into the page cache.
 Array of at most 16 pages. stack? 
 Xpress or LZX. 
 LZNT compression. 
 At this point, err contains 0 or -EIO depending on the "critical" page. 
  ni_decompress_file - Decompress LZXXpress compressed file.
  Remove ATTR_DATA::WofCompressedData.
  Remove ATTR_REPARSE.
 Clusters for decompressed data. 
 Check in advance. 
	
	  Step 1: Decompress data and copy to new allocated clusters.
	
	  Step 2: Deallocate attributes ATTR_DATA::WofCompressedData
	  and ATTR_REPARSE.
run==1  Means unpack and deallocate. 
	
	  Step 3: Remove attribute ATTR_DATA::WofCompressedData.
	
	  Step 4: Remove ATTR_REPARSE.
	
	  Step 5: Remove sparse flag from data attribute.
 Sparsed attribute header is 8 bytes bigger than normal. 
 Clear cached flag. 
  decompress_lzx_xpress - External compression LZXXpress.
 Frame not compressed. 
 LZX: Frame compressed. 
 Lazy initialize LZX decompress context. 
 Treat all errors as "invalid argument". 
 XPRESS: Frame compressed. 
 Lazy initialize Xpress decompress context. 
 Treat all errors as "invalid argument". 
  ni_read_frame
  Pages - Array of locked pages.
	
	  To simplify decompress algorithm do vmap for source
	  and target pages.
 Unknown compression. 
 Load all runs to read [vbo_disk-vbo_to). 
 LZNT compression. 
 Frame is not compressed. 
 Read 'ondisk_size' bytes from disk. 
	
	  To simplify decompress algorithm do vmap for source and target pages.
 Decompress: Frame_ondisk -> frame_mem. 
 LZX or XPRESS 
 LZNT - Native NTFS compression. 
  ni_write_frame
  Pages - Array of locked pages.
 To simplify compress algorithm do vmap for source and target pages. 
 Map in-memory frame for read-only. 
		
		  LZNT implements two levels of compression:
		  0 - Standard compression
		  1 - Best compression, requires a lot of cpu
		  use mount option?
 Compress: frame_mem -> frame_ondisk 
 Frame is not compressed. 
 Frame is compressed. 
 Frame is sparsed. 
  ni_remove_name - Removes name 'de' from MFT and from directory.
  'de2' and 'undo_step' are used to restore MFTdir, if error occurs.
 Find name in record. 
 Mark ntfs as dirty. It will be cleared at umount. 
 Step 1: Remove name from directory. 
 Step 2: Remove name from MFT. 
 Get paired name. 
 Step 3: Remove paired name from directory. 
 Step 4: Remove paired name from MFT. 
  ni_remove_name_undo - Paired function for ni_remove_name.
  Return: True if ok
  ni_add_name - Add new name in MFT and in directory.
 Insert new name in MFT. 
 Insert new name in directory. 
  ni_rename - Remove one name and insert new name.
	
	  There are two possible ways to rename:
	  1) Add new name and remove old name.
	  2) Remove old name and add new name.
	 
	  In most cases (not all!) adding new name in MFT and in directory can
	  allocate additional cluster(s).
	  Second way may result to bad inode if we can't add new name
	  and then can't restore (add) old name.
	
	  Way 1 - Add new + remove old.
	
	  Way 2 - Remove old + add new.
	
	 	err = ni_remove_name(dir_ni, ni, de, &de2, &undo);
	 	if (!err) {
	 		err = ni_add_name(new_dir_ni, ni, new_de);
	 		if (err && !ni_remove_name_undo(dir_ni, ni, de, de2, undo))
	 			is_bad = true;
	 	}
  ni_is_dirty - Return: True if 'ni' requires ni_write_inode.
  ni_update_parent
  Update duplicate info of ATTR_FILE_NAME in MFT and in parent directories.
 TODO: Fill reparse info. 
 If ATTR_EA_INFO exists 'info' can't be NULL. 
 ntfs_iget5 may sleep. 
  ni_write_inode - Write MFT base record and all subrecords to disk.
 'ni' is under modification, skip for now. 
 Update times in standard attribute. 
 Update the access times if they have changed. 
 Avoid __wait_on_freeing_inode(inode). 
 Not critical if this function fail. 
 Update attribute list. 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
                  terminology
  cluster - allocation unit     - 512,1K,2K,4K,...,2M
  vcn - virtual cluster number  - Offset inside the file in clusters.
  vbo - virtual byte offset     - Offset inside the file in bytes.
  lcn - logical cluster number  - 0 based cluster in clusters heap.
  lbo - logical byte offset     - Absolute position inside volume.
  run - maps VCN to LCN         - Stored in attributes in packed form.
  attr - attribute segment      - stdnamedata etc records inside MFT.
  mi  - MFT inode               - One MFT record(usually 1024 bytes or 4K), consists of attributes.
  ni  - NTFS inode              - Extends linux inode. consists of one or more mft inodes.
  index - unit inside directory - 2K, 4K, <=page size, does not depend on cluster size.
  WSL - Windows Subsystem for Linux
  https:docs.microsoft.comen-uswindowswslfile-permissions
  It stores uidgidmodedev in xattr
  ntfs_printk - Trace warningsnoticeserrors.
  Thanks Joe Perches <joe@perches.com> for implementation
 Should we use different ratelimits for warningsnoticeserrors? 
 1 means 'free s_name_buf'.
  ntfs_inode_printk
  Print warningsnoticeserrors about inode using name or inode number.
 Use static allocated buffer, if possible. 
 To be sure. 
 Cocci warns if placed in branch "if (de)" 
  Shared memory struct.
  On-disk ntfs's upcase table is created by ntfs formatter.
  'upcase' table is 128K bytes of memory.
  We should read it into memory when mounting.
  Several ntfs volumes likely use the same 'upcase' table.
  It is good idea to share in-memory 'upcase' table between different volumes.
  Unfortunately winxpvistawin7 use different upcase tables.
  ntfs_set_shared
  Return:
   @ptr - If pointer was saved in shared memory.
   NULL - If pointer was not shared.
  ntfs_put_shared
  Return:
   @ptr - If pointer is not shared anymore.
   NULL - If pointer is still shared.
  Load nls table or if @nls is utf8 then return NULL.
 Should not be here unless we forget add case. 
  put_ntfs - Noinline to reduce binary size.
 Mark rw ntfs as clear, if possible. 
  ntfs_sync_fs - super_operations::sync_fs
 TODO: == ntfs_sync_inode 
  format_size_gb - Return Gb,Mb to print with "%u.%02u Gb".
 Do simple right 30 bit shift of 64 bit value. 
  ntfs_init_from_boot - Init internal info from on-disk boot sector.
 0x55AA is not mandaroty. Thanks Maxim Suhanov
	if (0x55 != boot->boot_magic[0] || 0xAA != boot->boot_magic[1])
	 	goto out;
 cluster size: 512, 1K, 2K, 4K, ... 2M 
 Check MFT record size. 
 Check index record size. 
	
	  - Volume formatted and mounted with the same sector size.
	  - Volume formatted 4K and mounted as 512.
	  - Volume formatted 512 and mounted as 4K.
 Compare boot's cluster and sector. 
 Compare boot's cluster and media sector. 
 No way to use ntfs_get_block in this case. 
 ~320 bytes
 Warning if RAW volume. 
 32 bits per cluster. 
 Maximum size for normal files. 
 Maximum size for sparse file. 
  ntfs_fill_super - Try to mount.
 "ntfs"
 100 nsec
 Parse boot. 
	
	  Load $Volume. This should be done before $LogFile
	  'cause 'sbi->volume.ni' is used 'ntfs_set_state'.
 Load and save label (not necessary). 
 It is ok if no ATTR_LABEL 
 $AttrDef allows labels to be up to 128 symbols. 
 Should we break mounting here? 
err = -EINVAL;
goto put_inode_out;
 Load $MFTMirr to estimate recs_mirr. 
 Load LogFile to replay. 
 Load $MFT. 
 Load $BadClus. 
 Load $Bitmap. 
 Check bitmap boundary. 
 Not necessary. 
 Compute the MFT zone. 
 Load $AttrDef. 
 default formatter value 
 Load $UpCase. 
 Load $Secure. 
 Load $Extend. 
 Load $Extend\$Reparse. 
 Load $Extend\$ObjId. 
 Load root. 
	
	  Free resources here.
	  ntfs_fs_free will be called with fc->s_fs_info = NULL
  ntfs_discard - Issue a discard request (trim for SSD).
 Align up 'start' on discard_granularity. 
 Align down 'end' on discard_granularity. 
  ntfs_fs_free - Free fs_context.
  Note that this will be called after fill_super and reconfigure
  even when they pass. So they have to take pointers if they pass.
  ntfs_init_fs_context - Initialize spi and opts
  This will called when mountremount. We will first initiliaze
  options so that if remount we can use just that.
 Default options. 
 clang-format off
 clang-format on
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  TODO: try to use extents tree (instead of array)
 runs_tree is a continues memory. Try to avoid big size. 
 Virtual cluster number. 
 Length in clusters. 
 Logical cluster number. 
  run_lookup - Lookup the index of a MCB entry that is first <= vcn.
  Case of success it will return non-zero value and set
  @index parameter to index of entry been found.
  Case of entry missing from list 'index' will be set to
  point to insertion position for the entry question.
 Check boundary cases specially, 'cause they cover the often requests. 
  run_consolidate - Consolidate runs starting from a given one.
		
		  I should merge current run with next
		  if start of the next run lies inside one being tested.
 Stop if runs are not aligned one to another. 
		
		  If range at index overlaps with next one
		  then I will either adjust it's start position
		  or (if completely matches) dust remove one from the list.
		
		  Stop if sparse mode does not match
		  both current and next runs.
		
		  Check if volume block
		  of a next run lcn does not match
		  last volume block of the current run.
		
		  Next and current are siblings.
		  Eatjoin.
  run_is_mapped_full
  Return: True if range [svcn - evcn] is mapped.
 Fail immediately if nrun was not touched yet. 
  run_truncate_head - Decommit the range before vcn.
  run_truncate - Decommit the range after vcn.
	
	  If I hit the range then
	  I have to truncate one.
	  If range to be truncated is becoming empty
	  then it will entirely be removed.
	
	  At this point 'index' is set to position that
	  should be thrown away (including index itself)
	  Simple one - just set the limit.
 Do not reallocate array 'runs'. Only free if possible. 
  run_truncate_around - Trim head and tail if necessary.
  run_add_entry
  Sets location to known state.
  Run to be added may overlap with existing location.
  Return: false if of memory.
	
	  Lookup the insertion point.
	 
	  Execute bsearch for the entry containing
	  start position question.
	
	  Shortcut here would be case of
	  range not been found but one been added
	  continues previous run.
	  This case I can directly make use of
	  existing range as my start point.
	
	  At this point 'index' either points to the range
	  containing start position or to the insertion position
	  for a new range.
	  So first let's check if range I'm probing is here already.
		
		  Range was not found.
		  Insert at position 'index'
		
		  Check allocated space.
		  If one is not enough to get one more entry
		  then it will be reallocated.
 Use power of 2 for 'bytes'. 
 memmove appears to be a bottle neck here... 
		
		  If one of ranges was not allocated then we
		  have to split location we just matched and
		  insert current one.
		  A common case this requires tail to be reinserted
		  a recursive call.
 lcn should match one were going to add. 
		
		  If existing range fits then were done.
		  Otherwise extend found one and fall back to range jocode.
	
	  And normalize it starting from insertion point.
	  It's possible that no insertion needed case if
	  start point lies within the range of an entry
	  that 'index' points to.
	
	  A special case.
	  We have to add extra range a tail.
 run_collapse_range
  Helper for attr_collapse_range(),
  which is helper for fallocate(collapse_range).
 Should never be here. 
 Collapse tail of run .
 Collapse a middle part of sparsed run. 
 Collapse a middle part of normal run, split. 
 Eat this run. 
  run_get_entry - Return index-th mapped region.
  run_packed_size - Calculate the size of packed int64.
 Full trusted function. It does not check 'size' for errors. 
 Full trusted function. It does not check 'size' for errors. 
 Full trusted function. It does not check 'size' for errors. 
 memcpy( run_buf, &v, size); Is it faster? 
 full trusted function. It does not check 'size' for errors 
 memcpy( &v, run_buf, size); Is it faster? 
  run_pack - Pack runs into buffer.
  packed_vcns - How much runs we have packed.
  packed_size - How much bytes we have used run_buf.
 How much bytes required to pack len. 
 offset_size - How much bytes is packed dlcn. 
 NOTE: lcn can be less than prev_lcn! 
 Can we store this entire run. 
 Pack run header. 
 Pack the length of run. 
 Pack the offset from previous LCN. 
 Store last zero. 
  run_unpack - Unpack packed runs from @run_buf.
  Return: Error if negative, or real used bytes.
 Check for empty. 
 Read all runs the chain. 
 size_size - How much bytes is packed len. 
 size_size - How much bytes is packed len. 
 offset_size - How much bytes is packed dlcn. 
		
		  Unpack runs.
		  NOTE: Runs are stored little endian order
		  "len" is unsigned value, "dlcn" is signed.
		  Large positive number requires to store 5 bytes
		  e.g.: 05 FF 7E FF FF 00 00 00
 Skip size_size. 
 Initial value of dlcn is -1 or 0. 
 Skip offset_size. 
 Check boundary. 
 LCN range is out of volume. 
 Called from check_attr(fslog.c) to check run. 
			
			  Called from ni_delete_all to free clusters
			  without storing in run.
 Not expected length of unpacked runs. 
  run_unpack_ex - Unpack packed runs from "run_buf".
  Checks unpacked runs to be used in bitmap.
  Return: Error if negative, or real used bytes.
 Check for free blocks. 
 Looks like volume is corrupted. 
 Mark all zero bits as used in range [lcn, lcn+len). 
  run_get_highest_vcn
  Return the highest vcn from a mapping pairs array
  it used while replaying log file.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  ntfs_cmp_names
  Thanks Kari Argillander <kari.argillander@gmail.com> for idea and implementation 'bothcase'
  Straight way to compare names:
  - Case insensitive
  - If name equals and 'bothcases' then
  - Case sensitive
  'Straight way' code scans input names twice in worst case.
  Optimized code scans input names only once.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
 clang-format off
 clang-format on
  find_ea
  Assume there is at least one xattr in the list.
  ntfs_read_ea - Read all extended attributes.
  @ea:		New allocated memory.
  @info:	Pointer into resident data.
 Check Ea limit. 
 Allocate memory for packed Ea. 
  ntfs_list_ea
  Copy a list of xattrs names into the buffer
  provided, or compute the buffer size required.
  Return:
   Number of bytes used  required on
   -ERRNO - on failure
 Enumerate all xattrs. 
 Enumerate all xattrs. 
		
		  Check simple case when we try to insert xattr with the same value
		  e.g. ntfs_save_wsl_perm
 xattr already contains the required value. 
 Remove current xattr. 
 Remove xattr. 
 Append new xattr. 
 New size of ATTR_EA. 
	
	  1. Check ea_info.size_pack for overflow.
	  2. New attibute size must fit value from $AttrDef
 -EINVAL?
 Create xattr. 
 Delete xattr, ATTR_EA_INFO 
 Delete xattr, ATTR_EA 
 Check if we delete the last xattr. 
 Allocate PATH_MAX bytes. 
 Possible values of 'type' was already checked above. 
 Translate extended attribute to acl. 
  ntfs_get_acl - inode_operations::get_acl
 TODO: init_user_ns? 
 Remove xattr if it can be presented via mode. 
 Removing non existed xattr. 
  ntfs_set_acl - inode_operations::set_acl
  ntfs_init_acl - Initialize the ACLs of a new inode.
  Called from ntfs_create_inode().
  ntfs_acl_chmod - Helper for ntfs3_setattr().
  ntfs_permission - inode_operations::permission
 "No access rules" mode - Allow all changes. 
  ntfs_listxattr - inode_operations::listxattr
 no xattr in file 
 Dispatch request. 
 system.dos_attrib 
 system.ntfs_attrib 
 system.ntfs_security
 We should get nt4 security. 
 Deal with NTFS extended attribute. 
  ntfs_setxattr - inode_operations::setxattr
 Dispatch request. 
 Process compressedsparsed in special way. 
		
		  Thanks Mark Harmstone:
		  Keep directory bit consistency.
 Std attribute always in primary record. 
 system.ntfs_security
			
			  We should replace ATTR_SECURE.
			  Skip this way cause it is nt4 feature.
 Std attribute always in primary record. 
 Deal with NTFS extended attribute. 
  ntfs_save_wsl_perm
  save uidgidmode in xattr
 TODO: refactor this, so we don't lock 4 times in ntfs_set_ea 
 In case of error should we delete all WSL xattr? 
  ntfs_get_wsl_perm
  get uidgidmode from xattr
  it is called from ntfs_iget5->ntfs_read_mft
 clang-format off
 clang-format on
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  TODO: Merge attr_set_sizeattr_data_get_blockattr_allocate_frame?
  You can set external NTFS_MIN_LOG2_OF_CLUMPNTFS_MAX_LOG2_OF_CLUMP to manage
  preallocate algorithm.
 16M
 16G
  attr_must_be_resident
  Return: True if attribute must be resident.
  attr_load_runs - Load all runs stored in @attr.
  run_deallocate_ex - Deallocate clusters.
 Save memory - don't load entire run. 
  attr_allocate_clusters - Find free space, mark it as used and store in @run.
 Add new fragment into run storage. 
 Undo last 'ntfs_look_for_free_space' 
 Undo 'ntfs_look_for_free_space' 
  attr_make_nonresident
  If page is not NULL - it is already contains resident data
  and locked (called from ni_write_frame()).
 Make a copy of original attribute. 
 Empty resident -> Empty nonresident. 
 Empty resident -> Non empty nonresident. 
 Remove original attribute. 
 Resident attribute becomes non resident. 
 Undo: do not trim new allocated clusters. 
  attr_set_size_res - Helper for attr_set_size().
  attr_set_size - Change the size of attribute.
  Extend:
    - Sparsecompressed: No allocated clusters.
    - Normal: Append allocated and preallocated new clusters.
  Shrink:
    - No deallocate if @keep_prealloc is set.
 Layout of records may be changed, so do a full search. 
 MFT allocates clusters from MFT zone. 
 No preallocate for sparsecompress. 
 Get the last LCN to allocate from. 
 ~3 bytes per fragment. 
 Normal way. Update attribute and exit. 
 At least two MFT to avoid recursive loop. 
 Layout of records is changed. 
 Layout of records is changed. 
 This is MFT data, repeat. 
 Insert new attribute segment. 
		
		  Layout of records maybe changed.
		  Find base attribute to update.
			
			  NOTE: List entries for one attribute are always
			  the same size. We deal with last entry (vcn==0)
			  and it is not first in entries array
			  (list entry for std attribute always first).
			  So it is safe to step back.
 Update inode_set_bytes. 
 Normal way. 
 Normal way. 
 Get the last LCN to allocate from. 
 Stored [vcn : next_svcn) from [vcn : end). 
 Normal way. Update attribute and exit. 
 Add new segment [next_svcn : evcn1 - next_svcn). 
 Layout of records is changed. 
 Estimate next attribute. 
 Remove segment [svcn : evcn). 
 Last attribute segment. 
 Return special error code to check this case. 
  attr_load_runs_vcn - Load runs with VCN.
 Is record corrupted? 
 Is record corrupted? 
  attr_load_runs_range - Load runs for given range [from to).
 Next run_lookup_entry(vcn) must be success. 
  attr_wof_frame_info
  Read header of XpressLZX file to get info about frame.
 File starts with array of 32 bit offsets. 
 File starts with array of 64 bit offsets. 
	
	  Read 48 bytes at [vbo - 4(8)] == offset where compressed frame starts.
	  Read 48 bytes at [vbo] == offset where compressed frame ends.
 Two values in one page. 
  attr_is_frame_compressed - Used to detect compressed frame.
 Sparsed frame. 
		
		  The frame is not compressed 'cause
		  it does not contain any sparse clusters.
	
	  The frame is compressed if clst_data + slen >= clst_frame.
	  Check next fragments.
				
				  Data_clusters + sparse_clusters =
				  not enough for frame.
				
				  There is no sparsed clusters in this frame
				  so it is not compressed.
 Frame is compressed. 
  attr_allocate_frame - Allocatefree clusters for @frame.
  Assumed: down_write(&ni->file.run_lock);
 Run contains updated range [vcn + len : end). 
 Get the last LCN to allocate from. 
 Run contains updated range [vcn + clst_data : end). 
 Stored [vcn : next_svcn) from [vcn : end). 
 Normal way. Update attribute and exit. 
 Add new segment [next_svcn : evcn1 - next_svcn). 
 Layout of records is changed. 
 Estimate next attribute. 
 Remove segment [svcn : evcn). 
 Last attribute segment. 
  attr_collapse_range - Collapse range in file.
 Attribute is resident. Nothing to do? 
 Allow to collapse only cluster aligned ranges. 
 Simple truncate file at 'vbo'. 
	
	  Enumerate all attribute segments and collapse.
 Shift VCN- 
 Collapse a part of this attribute segment. 
 Shift VCN 
 Layout of records maybe changed. 
 Free all allocated memory. 
 Delete this attribute segment. 
 Load next record that contains this attribute. 
 Look for required attribute. 
 Update inode size. 
  attr_punch_hole
  Not for normal files.
 NOTE: It is allowed. 
 We have to zero a range(s). 
 Caller insists range is aligned. 
	
	  Enumerate all attribute segments and punch hole where necessary.
 Looks like the required range is already sparsed. 
 Free all allocated memory. 
 Update inode size. 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  ntfs_read_mft - Read record and parses MFT.
 0x18 bytes
 Setup 'uid' and 'gid' 
 Bad inode? 
 Record should contain $I30 root. 
 Enumerate all struct Attributes MFT. 
	
	  To reduce tab pressure use goto instead of
	  while( (attr = ni_enum_attr_ex(ni, attr, &le, NULL) ))
 This is non primary attribute segment. Ignore if not MFT. 
 Ignore data attribute in dir record. 
 File contains stream attribute. Ignore it. 
 0x20000000 = 2^32  8 
			
			  Normal symlink.
			  Assume one unicode symbol == one utf8.
 Clear directory bit. 
 Double break.
			
			  ntfs_get_wsl_perm updates inode->i_uid, inode->i_gid, inode->i_mode
 Reuse rec as buffer for ascii name. 
 Correct minor error on the fly. Do not mark inode as dirty. 
		
		  Dot and dot-dot should be included in count but was not
		  included in enumeration.
		  Usually a hard links to directories are disabled.
 Records in $Extend are not a files or general directories. 
 If no xattr then no security (stored in xattr). 
  ntfs_test_inode
  Return: 1 if match.
 If this is a freshly allocated inode, need to read it now. 
 Inode overlaps? 
 Clear previous state. 
 Direct write uses 'create=0'. 
 Out of valid. 
 Out of size. 
 ntfs_direct_IO will update ni->i_valid. 
 Normal write. 
 Read out of valid data. 
 Should never be here 'cause already checked. 
 Normal read. 
 Normal short read. 
		
		  Read across valid size: vbo < valid && valid < vbo + block_size
 Normal + sparse files. 
 No readahead for resident. 
 No readahead for compressed. 
 Range cross 'valid'. Read it page by page. 
 Switch to buffered write. 
 Fix page. 
 Check for maximum file size. 
 Redirect call to 'ntfs_writepage' for resident files. 
  ntfs_write_end - Address_space_operations::write_end.
 Clear any buffers in page. 
 ni->i_valid is changed in ntfs_get_block_vbo. 
  writeback_inode - Helper function for ntfs_flush_inodes().
  This writes both the inode and the file data blocks, waiting
  for in flight data blocks before the start of the call.  It
  does not wait for any io started during the call.
  ntfs_flush_inodes
  Write data and metadata corresponding to i1 and i2.  The io is
  started but we do not wait for any of it to finish.
  filemap_flush() is used for the block device, so if there is a dirty
  page for a block already in flight, we will not wait and start the
  io over again.
 Write non resident data. 
  ntfs_reparse_bytes
  Number of bytes for REPARSE_DATA_BUFFER(IO_REPARSE_TAG_SYMLINK)
  for unicode string of @uni_len length.
 Header + unicode string + decorated unicode string. 
 Convert link name to UTF-16. 
 err = the length of unicode name of symlink. 
 Translate Linux '' into Windows '\'. 
 PrintName + SubstituteName. 
	
	  TODO: Use relative path if possible to allow Windows to
	  parse this path.
	  0-absolute path 1- relative path (SYMLINK_FLAG_RELATIVE).
 Decorate SubstituteName. 
 Use parent's directory attributes. 
		
		  By default child directory inherits parent attributes.
		  Root directory is hidden + system.
		  Make an exception for children in root.
 It is good idea that link should be the same type (filedir) as target 
		
		  Linux: there are dirfilesymlink and so on.
		  NTFS: symlinks are "dir + reparse" or "file + reparse"
		  It is good idea to create:
		  dir + reparse if 'symname' points to directory
		  or
		  file + reparse if 'symname' points to file
		  Unfortunately kern_path hangs if symname contains 'dir'.
		
		 	struct path path;
		 
		 	if (!kern_path(symname, LOOKUP_FOLLOW, &path)){
		 		struct inode target = d_inode(path.dentry);
		 
		 		if (S_ISDIR(target->i_mode))
		 			fa |= FILE_ATTRIBUTE_DIRECTORY;
		 		 if ( target->i_sb == sb ){
		 			use relative path?
		 		 }
		 		path_put(&path);
		 	}
 Sparsed regular file, cause option 'sparse'. 
 Compressed regular file, if parent is compressed. 
 Regular file, default attributes. 
 Allocate PATH_MAX bytes. 
 Mark rw ntfs as dirty. it will be cleared at umount. 
 Step 1: allocate and fill new mft record. 
 Get default security id. 
 Insert standard info. 
 Insert file name. 
 Insert security attribute. 
		
		  Regular directory or symlink to directory.
		  Create root attribute.
 0x10
		
		  Symlink to file.
		  Create empty resident data attribute.
 Insert empty ATTR_DATA 
		
		  Regular file. Create empty non resident data attribute.
		
		  Node. Create empty resident data attribute.
		
		  Insert ATTR_REPARSE.
 Resident or non resident? 
		
		  Below function 'ntfs_save_wsl_perm' requires 0x78 bytes.
		  It is good idea to keep extened attributes resident.
 Bytes per runs. 
 Size of symlink equals the length of input string. 
 Step 2: Add new name in index. 
 Unlock parent directory before ntfs_init_acl. 
 Write non resident data. 
	
	  Call 'd_instantiate' after inode->i_op is set
	  but before finish_open.
 Normal exit. 
 Undo 'indx_insert_entry'. 
 ni_unlock(dir_ni); will be called later. 
 Allocate PATH_MAX bytes. 
 Mark rw ntfs as dirty. It will be cleared at umount. 
 Construct 'de'. 
 Fill duplicate info. 
  ntfs_unlink_inode
  inode_operations::unlink
  inode_operations::rmdir
 Allocate PATH_MAX bytes. 
 Reparse data present. Try to parse it. 
 Read into temporal buffer. 
 Microsoft Tag. 
 Mount points and junctions. 
 Can we use 'Rp->MountPointReparseBuffer.PrintNameLength'? 
 FolderSymbolicLink 
 Can we use 'Rp->SymbolicLinkReparseBuffer.PrintNameLength'? 
 Unknown Microsoft Tag. 
 Users tag. 
 Convert nlen from bytes to UNICODE chars. 
 Check that name is available. 
 If name is already zero terminated then truncate it now. 
 Translate Windows '\' into Linux ''. 
 Always set last zero. 
 clang-format off
 clang-format on
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
   Directory handling functions for NTFS-based filesystems.
 Convert little endian UTF-16 to NLS string. 
 UTF-16 -> UTF-8 
 clang-format off
 clang-format on
  put_utf16 - Modified version of put_utf16 from fsnlsnls_base.c
  Function is sparse warnings free.
  _utf8s_to_utf16s
  Modified version of 'utf8s_to_utf16s' allows to
  detect -ENAMETOOLONG without writing out of expected maximum.
  ntfs_nls_to_utf16 - Convert input string to UTF-16.
  @name:	Input name.
  @name_len:	Input name length.
  @uni:	Destination memory.
  @max_ulen:	Destination memory.
  @endian:	Endian of target UTF-16 string.
  This function is called:
  - to create NTFS name
  - to create symlink
  Return: UTF-16 string length or error (if negative).
 utf8 -> utf16 
  dir_search_u - Helper function.
 Skip meta files. Unless option to show metafiles is set. 
  ntfs_read_hdr - Helper function for ntfs_readdir().
 Skip already enumerated. 
 Submit the name to the filldir callback. 
  ntfs_readdir - file_operations::iterate_shared
  Use non sorted enumeration.
  We have an example of broken volume where sorted enumeration
  counts each name twice.
 Name is a buffer of PATH_MAX length. 
 Allocate PATH_MAX bytes. 
		
		  Directory inode is locked for read.
		  Load all subrecords to avoid 'write' access to 'ni' during
		  directory reading.
 clang-format off
 clang-format on
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
 First, compare the type codes. 
 They have the same type code, so we have to compare the names. 
  mi_new_attt_id
  Return: Unused attribute id that is less than mrec->next_attr_id.
 One record can store up to 102424 ~= 42 attributes. 
  mi_read - Read MFT data.
 Check field 'total' only here. 
 Skip non-resident records. 
 Check if input attr inside record. 
 Impossible 'cause we should not return such attribute. 
 Can we use the first field (attr->type). 
 End of enumeration. 
 0x100 is last known attribute for now. 
 Check boundary. 
 Check size of attribute. 
 Check some nonresident fields. 
  mi_find_attr - Find the attribute by type and name and id.
 Record is reused. Update its sequence number. 
  mi_mark_free - Mark record as unused and marks it as free in bitmap.
  mi_insert_attr - Reserve space for new attribute.
  Return: Not full constructed attribute or NULL if not possible to create.
 Can we insert mi attribute? 
	
	  Scan through the list of attributes to find the point
	  at which we should insert it.
 Not used, just to suppress warning. 
  mi_remove_attr - Remove the attribute from record.
  NOTE: The source attr will point to next attribute.
 bytes = "new attribute size" - "old attribute size" 
 Move tail 
 Make a maximum gap in current record. 
 Pack as much as possible. 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
 clang-format off
 clang-format on
  ntfs_fix_pre_write - Insert fixups into @rhdr before writing to disk.
 Get fixup pointer. 
  ntfs_fix_post_read - Remove fixups after reading from disk.
  Return: < 0 if error, 0 if ok, 1 if need to update fixups.
 Check errors. 
 Native chkntfs returns ok! 
 Get fixup pointer. 
 Test current word. 
 Fixup does not match! Is it serious error? 
 Replace fixup. 
  ntfs_extend_init - Load $Extend file.
 If ntfs_iget5() reads from disk it never returns bad inode. 
 Try to find $ObjId 
 Try to find $Quota 
 Try to find $Reparse 
 Try to find $UsnJrnl 
 Check for 4GB. 
 Try to use MFT copy. 
 LogFile should not contains attribute list. 
 Fill LogFile by '-1' if it is initialized. 
  ntfs_query_def
  Return: Current ATTR_DEF_ENTRY for given attribute type.
  ntfs_look_for_free_space - Look for a free space in bitmap.
	
	  'Cause cluster 0 is always used this value means that we should use
	  cached value of 'next_free_lcn' to improve performance.
 Try to use clusters from MftZone. 
 Check too big request 
 How many clusters to cat from zone. 
 Allocate continues clusters. 
 Set hint for next requests. 
  ntfs_extend_mft - Allocate additional MFT records.
  sbi->mft.bitmap is locked for write.
  NOTE: recursive:
 	ntfs_look_free_mft ->
 	ntfs_extend_mft ->
 	attr_set_size ->
 	ni_insert_nonresident ->
 	ni_insert_attr ->
 	ni_ins_attr_ext ->
 	ntfs_look_free_mft ->
 	ntfs_extend_mft
  To avoid recursive always allocate space for two new MFT records
  see attrib.c: "at least two MFT to avoid recursive loop".
 Step 1: Resize $MFT::DATA. 
 Step 2: Resize $MFT::BITMAP. 
 Refresh MFT Zone if necessary. 
  ntfs_look_free_mft - Look for a free MFT record.
 Always reserve space for MFT. 
 No MFT zone. Find the nearest to '0' free MFT. 
 Resize MFT 
		
		  Look for free record reserved area [11-16) ==
		  [MFT_REC_RESERVED, MFT_REC_FREE ) MFT bitmap always
		  marks it as used.
 Once per session create internal bitmap for 5 bits. 
 Scan 5 bits for zero. Bit 0 == MFT_REC_RESERVED 
 [zbit, zbit + zlen) will be used for MFT itself. 
 The request to get record for general purpose. 
 We have found a record that are not reserved for next MFT. 
  ntfs_mark_rec_free - Mark record as free.
  ntfs_clear_mft_tail - Format empty records [from, to).
  sbi->mft.bitmap is locked for write.
  ntfs_refresh_zone - Refresh MFT zone.
  sbi->used.bitmap is locked for rw.
  sbi->mft.bitmap is locked for write.
  sbi->mft.ni->file.run_lock for write.
 Do not change anything unless we have non empty MFT zone. 
	
	  Compute the MFT zone at two steps.
	  It would be nice if we are able to allocate 18 of
	  total clusters for MFT but not more then 512 MB.
 We should always find Last Lcn for MFT. 
 Try to allocate clusters after last MFT run. 
 Truncate too large zone. 
  ntfs_update_mftmirr - Update $MFTMirr data.
  ntfs_set_state
  Mount: ntfs_set_state(NTFS_DIRTY_DIRTY)
  Umount: ntfs_set_state(NTFS_DIRTY_CLEAR)
  NTFS error: ntfs_set_state(NTFS_DIRTY_ERROR)
	
	  Do not change state if fs was real_dirty.
	  Do not change state if fs already dirty(clear).
	  Do not change any thing if mounted read only.
 Check cached value. 
 Cache current volume flags. 
 verify(!ntfs_update_mftmirr()); 
	
	  If we used wait=1, sync_inode_metadata waits for the io for the
	  inode to finish. It hangs when media is removed.
	  So wait=0 is sent down to sync_inode_metadata
	  and filemap_fdatawrite is used for the data blocks.
  security_hash - Calculates a hash of security descriptor.
 First reading of $Volume + $MFTMirr + $LogFile goes here. 
 Use absolute boot's 'MFTCluster' to read record. 
  ntfs_read_bh
  Return: < 0 if error, 0 if ok, -E_NTFS_FIXUP if need to update fixups.
  ntfs_bio_pages - Readwrite pages fromto disk.
 Align vbo and bytes to be 512 bytes aligned. 
  ntfs_bio_fill_1 - Helper for ntfs_loadlog_and_replay().
  Fill on-disk logfile range by (-1)
  this means empty logfile.
	
	  TODO: Try blkdev_issue_write_same.
  O:BAG:BAD:(A;OICI;FA;;;WD)
  Owner S-1-5-32-544 (Administrators)
  Group S-1-5-32-544 (Administrators)
  ACE: allow S-1-1-0 (Everyone) with FILE_ALL_ACCESS
  is_acl_valid
  Thanks Mark Harmstone for idea.
		
		  This value should be ACL_REVISION, unless the ACL contains an
		  object-specific ACE, in which case this value must be ACL_REVISION_DS.
		  All ACEs in an ACL must be at the same revision level.
  ntfs_security_init - Load and parse $Secure.
 Find the last valid Id. 
 Always write new security at the end of bucket. 
  ntfs_get_security_by_id - Read security descriptor by id.
 Try to find this SECURITY descriptor in SII indexes. 
 Looks like too big security. 0x10000 - is arbitrary big number. 
  ntfs_insert_security - Insert security descriptor into $Secure::SDS.
  SECURITY Descriptor Stream data is organized into chunks of 256K bytes
  and it contains a mirror copy of each security descriptor.  When writing
  to a security descriptor at location X, another copy will be written at
  location (X+256K).
  When writing a security descriptor that will cross the 256K boundary,
  the pointer will be advanced by 256K to skip
  over the mirror portion.
 Allocate a temporal buffer. 
	
	  Check if such security already exists.
	  Use "SDH" and hash -> to get the offset in "SDS".
 Such security already exists. 
 Zero unused space. 
 Zero gap until SecurityDescriptorsBlockSize. 
 Zero "left" bytes from sbi->security.next_off. 
 Zero tail of previous security. 
used = ni->vfs_inode.i_size & (SecurityDescriptorsBlockSize - 1);
	
	  Example:
	  0x40438 == ni->vfs_inode.i_size
	  0x00440 == sbi->security.next_off
	  need to zero [0x438-0x440)
	  if (next > used) {
	   u32 tozero = next - used;
	   zero "tozero" bytes from sbi->security.next_off - tozero
 Format new security descriptor. 
 Write main SDS bucket. 
 Write copy SDS bucket. 
 Fill SII entry. 
 Fill SDH entry. 
 Update Id and offset for next descriptor. 
  ntfs_reparse_init - Load and parse $Extend$Reparse.
  ntfs_objid_init - Load and parse $Extend$ObjId.
 1 - forces to ignore rkey.ReparseTag when comparing keys. 
 Impossible. Looks like volume corrupt? 
  run_deallocate - Deallocate clusters.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  al_is_valid_le
  Return: True if @le is valid.
  ntfs_load_attr_list
  This method makes sure that the ATTRIB list, if present,
  has been properly set up.
  al_enumerate
  Return:
   The next list le.
   If @le is NULL then return the first le.
 Impossible 'cause we should not return such le. 
 Check boundary. 
 The regular end of list. 
 Check le for errors. 
  al_find_le
  Find the first le in the list which matches type, name and VCN.
  Return: NULL if not found.
  al_find_ex
  Find the first le in the list which matches type, name and VCN.
  Return: NULL if not found.
 List entries are sorted by type, name and VCN. 
			
			  Compare entry names only for entry with vcn == 0.
  al_find_le_to_insert
  Find the first list entry which matches type, name and VCN.
 List entries are sorted by type, name and VCN. 
			
			  Compare entry names only for entry with vcn == 0.
  al_add_le
  Add an "attribute list entry" to the list.
	
	  Compute the size of the new 'le'
 Scan forward to the point at which the new 'le' should be inserted. 
 Undo memmove above. 
  al_remove_le - Remove @le from attribute list.
 Save on stack the size of 'le' 
  al_delete_le - Delete first le from the list which matches its parameters.
 Scan forward to the first le that matches the input. 
	
	  The caller specified a segment reference, so we have to
	  scan through the matching entries until we find that segment
	  reference or we run of matching entries.
 Save on stack the size of 'le'. 
 Delete the le. 
	
	  Attribute list increased on demand in al_add_le.
	  Attribute list decreased here.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
   Regular file handling primitives for NTFS-based filesystems.
 Inappropriate ioctl for device. 
  ntfs_getattr - inode_operations::getattr
 512, 1K, ..., 2M 
 This function in any case puts page. 
  ntfs_zero_range - Helper function for punch_hole.
  It zeroes a range [vbo, vbo_to).
 Unmapped? It's a hole - nothing to do. 
 Ok, it's mapped. Make sure it's up-to-date. 
  ntfs_sparse_cluster - Helper function to zero a new allocated clusters.
  NOTE: 512 <= cluster size <= 2M
  ntfs_file_mmap - file_operations::mmap
 Allocate clusters for rw map. 
 Mark rw ntfs as dirty. It will be cleared at umount. 
ntfs_flush_inodes(inode->i_sb, inode, NULL);
  ntfs_fallocate
  Preallocate space for a file. This implements ntfs's fallocate file
  operation, which gets called from sys_fallocate system call. User
  space requests 'len' bytes at 'vbo'. If FALLOC_FL_KEEP_SIZE is set
  we just allocate clusters without zeroing them out. Otherwise we
  allocate and zero out clusters via an expanding truncate.
 No support for dir. 
 Return error if mode is not supported. 
 Should never be here, see ntfs_file_open. 
			
			  Normal file, can't make hole.
			  TODO: Try to find way to save info about hole.
 Process not aligned punch. 
 Aligned punch_hole 
		
		  Write tail of the last page before removed range since
		  it will get removed from the page cache below.
		
		  Write data that will be shifted to preserve them
		  when discarding page cache below.
 Wait for existing dio to complete. 
		
		  Normal file: Allocate clusters, do not change 'valid' size.
			
			  Allocate but do not zero new clusters. (see below comments)
			  This breaks security: One can read unused on-disk areas.
			  Zeroing these clusters may be too long.
			  Maybe we should check here for root rights?
				
				  Unwritten area.
				  NTFS is not able to store several unwritten areas.
				  Activate 'ntfs_sparse_cluster' to zero new allocated clusters.
				 
				  Dangerous in case:
				  1G of sparsed clusters + 1 cluster of data =>
				  valid_size == 1G + 1 cluster
				  fallocate(1G) will zero 1G and this can be very long
				  xfstest 016086 will fail without 'ntfs_sparse_cluster'.
 True - Keep preallocated. 
  ntfs3_setattr - inode_operations::setattr
 "No access rules" - Force any changes of time etc. 
 and disable for editing some attributes. 
 Should never be here, see ntfs_file_open(). 
 Linux 'w' -> Windows 'ro'. 
  ntfs_get_frame_pages
  Return: Array of locked pages.
  ntfs_compress_write - Helper for ntfs_file_write_iter() (compressed files).
		
		  frame_size == 8K if cluster 512
		  frame_size == 64K if cluster 4096
 Zero range [valid : pos). 
 Load full frame. 
 Copy user data [pos : pos + count). 
 Load full frame. 
 Copy user data to pages. 
		
		  We can loop for a long time in here. Be nice and allow
		  us to schedule out to avoid softlocking if preempt
		  is disabled.
  ntfs_file_write_iter - file_operations::write_iter
 Should never be here, see ntfs_file_open(). 
  ntfs_file_open - file_operations::open
 Decompress "external compressed" file if opened for rw. 
  ntfs_file_release - file_operations::release
 If we are last writer on the inode, drop the block reservation. 
  ntfs_fiemap - file_operations::fiemap
 clang-format off
 clang-format on
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  This code builds two trees of free clusters extents.
  Trees are sorted by start of extent and by length of extent.
  NTFS_MAX_WND_EXTENTS defines the maximum number of elements in trees.
  In extreme case code reads on-disk bitmap to find free clusters.
  Maximum number of extents in tree.
 Tree sorted by start. 
 Tree sorted by len. 
  wnd_scan
  b_pos + b_len - biggest fragment.
  Scan range [wpos wbits) window @buf.
  Return: -1 if not found.
		
		  Now we have a fragment [wpos, wend) staring with 0.
  wnd_close - Frees all resources.
  rb_insert_count - Helper function to insert special kind of 'count' tree.
  rb_insert_start - Helper function to insert special kind of 'count' tree.
  wnd_add_free_ext - Adds a new extent of free space.
  @build:	1 when building tree.
 Use extent_min to filter too short extents. 
 Try to find extent before 'bit'. 
 Remove left. 
 Remove right. 
 Check bits before 'bit'. 
 Check bits after 'end_in'. 
 Insert new fragment. 
 Compare with smallest fragment. 
 Do not insert small fragments. 
 Smallest fragment will be 'e2->count.key'. 
 Replace smallest fragment by new one. 
  wnd_remove_free_ext - Remove a run from the cached free space.
 Try to find extent before 'bit'. 
 Range [bit,end_in) must be inside 'e' or outside 'e' and 'n'. 
 Range [bit,end_in) inside 'e'. 
 Get minimal extent. 
 Replace minimum. 
  wnd_rescan - Scan all bitmap. Used while initialization.
 All ones. 
 All zeroes. 
 No free blocks. 
 Keep last free block. 
 Skip free block and first '1'. 
 Reset previous tail. 
 Add last block. 
	
	  Before init cycle wnd->uptodated was 0.
	  If any errors or limits occurs while initialization then
	  wnd->uptodated will be -1.
	  If 'uptodated' is still 0 then Tree is really updated.
  wnd_map - Call sb_bread for requested window.
  wnd_set_free - Mark the bits range from bit to bit + bits as free.
  wnd_set_used - Mark the bits range from bit to bit + bits as used.
  wnd_is_free_hlp
  Return: True if all clusters [bit, bit+bits) are free (bitmap only).
  wnd_is_free
  Return: True if all clusters [bit, bit+bits) are free.
  wnd_is_used
  Return: True if all clusters [bit, bit+bits) are used.
  wnd_find - Look for free space.
  - flags - BITMAP_FIND_XXX flags
  Return: 0 if not found.
 Fast checking for available free space. 
 Extents tree is updated -> No free space. 
 Use hint: Enumerate extents by start >= hint. 
 We have found extension with 'hint' inside. 
 Allocate from biggest free extent. 
 Biggest free block is less then requested. 
 Check if we can use more bits. 
 Prepare to return. 
 Extents tree is updated -> no free space. 
 At most two ranges [hint, max_alloc) + [0, hint). 
 TODO: Optimize request for case nbits > wbits. 
 Enumerate all windows. 
 Skip full used window. 
 Here we have a window [wbit, ebit) and zone [zbit, zend). 
 Zone does not overlap window. 
 Zone overlaps window. 
 Scan two ranges window: [wbit, zbit) and [zend, ebit). 
 TODO: Error 
 Scan range [wbit, zbit). 
 Scan range [wpos, zbit). 
 Scan range [zend, ebit). 
 Current window does not overlap zone. 
 Window is empty. 
 Increase 'prev_tail' and process next window. 
 Read window. 
 TODO: Error.
 Scan range [wpos, eBits). 
 The last fragment. 
		
		  We have scanned range [hint max_alloc).
		  Prepare to scan range [0 hint + to_alloc).
 TODO: Optimize remove extent (pass 'e'?). 
  wnd_extend - Extend bitmap ($MFT bitmap).
 Align to 8 byte boundary. 
 Zero bits [old_bits,new_bits). 
 err = sync_dirty_buffer(bh); 
 Process the last fragment. 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2019-2021 Paragon Software GmbH, All rights reserved.
  LOG FILE structs
 clang-format off
 'RSTR'
 0x10: Page size of the system which initialized the log.
 0x14: Log page size used for this log file.
 0x18:
 0x1A:
 0x1C:
 0x08:
 0x10:
 0x12:
 0x14:
 0x16:
 0x1C: In bytes.
 0x20: Name of client.
 Two copies of these will exist at the beginning of the log file 
 0x00: Current logical end of log file.
 0x08: Maximum number of clients.
 0x0A: Freeuse index into the client record arrays.
 0x0E: See RESTART_SINGLE_PAGE_IO.
 0x10: The number of bits in sequence number.
 0x14:
 0x16:
 0x18: Usable log file size.
 0x20:
 0x24: Log page data offset.
 0x26: Log page data length.
 0x28:
 0x2C:
 0x40:
 0x00:  NTFS_LOG_OPERATION
 0x02:  NTFS_LOG_OPERATION
 0x04:  Offset to Redo record.
 0x06:  Redo length.
 0x08:  Offset to Undo record.
 0x0A:  Undo length.
 0x0C:
 0x0E:
 0x10:
 0x12:
 0x14:
 0x16:
 0x18:
 0x20:
 0x00: In bytes
 0x02: Entries
 0x04: Entries
 0x06:
 0x0C:
 0x10:
 0x14:
 Offset in the Open attribute Table.
 0x00: RESTART_ENTRY_ALLOCATED if allocated
 0x04:
 0x08:
 0x0C:
 0x0B: Faked field to manage 'ptr'
 0x0C: Faked field to manage 'ptr'
 0x10: File Reference of file containing attribute
 0x18:
 0x20:
 32 bit version of 'struct OPEN_ATTR_ENRTY' 
 0x00: RESTART_ENTRY_ALLOCATED if allocated
 0x04:
 0x08:
 0x10:
 0x18:
 0x19:
 0x1C:
 0x20: In wchar
 0x24:
 0x28:
 static_assert( 0x2C == sizeof(struct OPEN_ATTR_ENRTY_32) );
  One entry exists in the Dirty Pages Table for each page which is dirty at
  the time the Restart Area is written.
 0x00: RESTART_ENTRY_ALLOCATED if allocated
 0x04: Index into the Open attribute Table
 0x08:
 0x0C:
 0x10: Vcn of dirty page
 0x18:
 0x20:
 32 bit version of 'struct DIR_PAGE_ENTRY' 
 0x00: RESTART_ENTRY_ALLOCATED if allocated
 0x04: Index into the Open attribute Table
 0x08:
 0x0C:
 0x10:
 0x14: Vcn of dirty page
 0x18: Vcn of dirty page
 0x1C:
 0x1C:
 0x24:
 0x24:
 0x00: RESTART_ENTRY_ALLOCATED if allocated
 0x04:
 0x05:
 0x08:
 0x10:
 0x18:
 0x20: Number of undo log records pending abort
 0x24: Total undo size
 0x00:
 0x04:
 0x08:
 0x10:
 0x18:
 0x20:
 0x28:
 0x30: In bytes
 0x34: In bytes
 0x38: In bytes
 0x3C: In bytes
 The following type defines the different log record types. 
 This is used to uniquely identify a client for a particular log file. 
 This is the header that begins every Log Record in the log file. 
 0x00:
 0x08:
 0x10:
 0x18:
 0x1C: Owner of this log record.
 0x20: LfsClientRecord or LfsClientRestart.
 0x24:
 0x28: LOG_RECORD_MULTI_PAGE
 0x2A:
 0x00: Offset of the free space in the page,
 0x02:
 0x08: lsn for the last log record which ends on the page,
 'RCRD'
 0x10: See LOG_PAGE_LOG_RECORD_END
 0x14:
 0x16:
 0x18:
 0x28:
 0x3c: Used when major version >= 2
 clang-format on
 Page contains the end of a log record.
  END of NTFS LOG structures
 Define some tuning parameters to keep the restart tables a reasonable size. 
 NtOfsRestartUpdateRelativeDataInIndex
  Array for log records which require a target attribute.
  A true indicates that the corresponding restart operation
  requires a target attribute.
 Bytes per restart table. 
 Log record length. 
 Log record header of the current lsn.
 lcb_ctx_undo_nextlcb_ctx_prevlcb_ctx_next
 If true the we should deallocate 'log_rec'.
 Find the oldest lsn from active clients. 
 Ignore this block if it's oldest lsn is 0. 
 Check that if the file offset isn't 0, it is the system page size. 
 Check support version 1.1+. 
	
	  Check the restart length field and whether the entire
	  restart area is contained that length.
	
	  As a final check make sure that the use list and the free list
	  are either empty or point to a valid client.
 Make sure the sequence number bits match the log file size. 
 The log page data offset and record header length must be quad-aligned. 
 Find the start of the client array. 
	
	  Start with the free list.
	  Check that all the clients are valid and that there isn't a cycle.
	  Do the in-use list on the second pass.
  remove_client
  Remove a client record from a client record list an restart area.
  add_client - Add a client record to the start of a list.
 Loop until we hit the first one allocated, or the end of the list. 
  find_dp - Search for a @vcn in Dirty Page Table.
 Round the file size down to a system page boundary. 
 File should contain at least 2 restart pages and MinLogRecordPages pages. 
	
	  Verify each entry is either allocated or points
	  to a valid offset the table.
	
	  Walk through the list headed by the first entry to make
	  sure none of the entries are currently being used.
  free_rsttbl_idx - Free a previously allocated index a Restart Table.
  alloc_rsttbl_idx
  Allocate an index from within a previously initialized Restart Table.
 Dequeue this entry and zero it. 
 If list is going empty, then we fix the last_free as well. 
  alloc_rsttbl_from_idx
  Allocate a specific index from within a previously initialized Restart Table.
 If the entry is not the table, we will have to extend the table. 
		
		  Extend the size by computing the number of entries between
		  the existing size and the desired index and adding 1 to that.
		
		  There should always be an integral number of entries
		  being added. Now extend the table.
 See if the entry is already allocated, and just return if it is. 
	
	  Walk through the table, looking for the entry we're
	  interested and the previous entry.
 this is a match 
	
	  Need to walk through the list looking for the predecessor
	  of our entry.
 Remember the entry just found 
 Should never run of entries. 
 Lookup up the next entry the list. 
 If this is our match we are done. 
			
			  If this was the last entry, we update that
			  table as well.
 If the list is now empty, we fix the last_free as well. 
 Zero this entry. 
 Helper struct to work with NTFS $LogFile. 
 page_size - 1
 (1 << file_data_bits) - 1 
 In-memory image of the next restart area. 
 The usable size of the restart area. 
	
	  If true, then the in-memory restart area is to be written
	  to the first position on the disk.
 True if we need to set dirty flag. 
 See NTFSLOG_XXX 
 On-disk value for open_log_count. 
 Compute the offset in the log file of the next log page. 
 Check that the update sequence array for this page is valid 
 If we don't allow errors, raise an error status 
  log_read_rst
  It walks through 512 blocks of the file looking for a valid
  restart page header. It will stop the first time we find a
  valid page header.
 Determine which restart area we are looking for. 
 Loop continuously until we succeed. 
 Read a page header at the current offset. 
 Ignore any errors. 
 Exit if the signature is a log record page. 
				
				  Remember if the signature does not
				  indicate uninitialized file.
 Let's check the restart area if this is a valid page. 
		
		  We have a valid restart page header and restart area.
		  If chkdsk was run or we have no clients then we have
		  no more checking to do.
 Read the entire restart area. 
 Ignore any errors. 
		
		  If chkdsk was run then update the caller's
		  values and return.
		
		  If we have a valid page then copy the values
		  we need from it.
  Ilog_init_pg_hdr - Init @log from restart page header.
  log_create - Init @log in cases when we don't have a restart area to use.
 All file offsets must be quadword aligned. 
 Set the correct flags for the IO and indicate if we have wrapped. 
 Compute the log page values. 
 Remember the different page sizes for reservation. 
 Compute the restart page values. 
	
	  The total available log file space is the number of
	  log file pages times the space available on each page.
	
	  We assume that we can't use the end of the page less than
	  the file record size.
	  Then we won't need to reserve more than the caller asks for.
  log_create_ra - Fill a restart area from the values stored in @log.
 Add the length of the header. 
	
	  If this lsn is contained this log page we are done.
	  Otherwise we need to walk through several log pages.
			
			  We are done if the remaining bytes
			  fit on this page.
	
	  We add the remaining bytes to our starting position on this page
	  and then add that value to the file offset of this log page.
 Remember if we wrapped. 
 Log page header for this page. 
	
	  If the lsn we were given was not the last lsn on this page,
	  then the starting offset for the next lsn is on a quad word
	  boundary following the last file offset for the current lsn.
	  Otherwise the file offset is the start of the data on the next page.
 If we wrapped, we need to increment the sequence number. 
 Compute the lsn based on the file offset and the sequence count. 
	
	  If this lsn is within the legal range for the file, we return true.
	  Otherwise false indicates that there are no more lsn's.
  current_log_avail - Calculate the number of bytes available for log records.
 The entire file is available. 
	
	  If there is a last lsn the restart area then we know that we will
	  have to compute the free range.
	  If there is no oldest lsn then start at the first page of the file.
	
	  We will use the next log page offset to compute the next free page.
	  If we are going to reuse this page go to the next page.
	  If we are at the first page then use the end of the file.
 If the two offsets are the same then there is no available space. 
	
	  If the free offset follows the oldest offset then subtract
	  this range from the total available pages.
	
	  If the last lsn on the page occurs was written after the page
	  that caused the original error then we have a fatal error.
	
	  If the sequence number for the lsn the page is equal or greater
	  than lsn we expect, then this is a subsequent write.
  last_log_lsn
  Walks through the log pages for a file, searching for the
  last log page written to the file.
 0x10 == 0x12 - 0x2
 Read second tail page (at pos 30x12000). 
 Read first tail page (at pos 20x2000). 
 Read the next log page. 
 Compute the next log page offset the file. 
	
	  If we are at the expected first page of a transfer check to see
	  if either tail copy is at this offset.
	  If this page is the last page of a transfer, check if we wrote
	  a subsequent tail copy.
		
		  Check if the offset matches either the first or second
		  tail copy. It is possible it will match both.
		
		  If we already matched on the first page then
		  check the ending lsn's.
 We have a candidate for a tail copy. 
			
			  If the sequence number is not expected,
			  then don't use the tail copy.
			
			  If the last lsn is greater than the one on
			  this page then forget this tail.
	
	 If we have an error on the current page,
	  we will break of this loop.
	
	  Done if the last lsn on this page doesn't match the previous known
	  last lsn or the sequence number is not expected.
	
	  Check that the page position and page count values are correct.
	  If this is the first page of a transfer the position must be 1
	  and the count will be unknown.
			
			  If the current page is the first page we are
			  looking at and we are reusing this page then
			  it can be either the first or last page of a
			  transfer. Otherwise it can only be the first.
		
		  The page position better be 1 more than the last page
		  position and the page count better match.
	
	  We have a valid page the file and may have a valid page
	  the tail copy area.
	  If the tail page was written after the page the file then
	  break of the loop.
 Remember if we will replace the page. 
		
		  Since we have read this page we know the sequence number
		  is the same as our expected value.
		
		  If there is room on this page for another header then
		  remember we want to reuse the page.
 Remember if we wrapped the log file. 
	
	  Remember the last page count and position.
	  Also remember the last known lsn.
 Remember that the partial IO will start at the next page. 
	
	  If the next page is the first page of the file then update
	  the sequence number for log records which begon the next page.
	
	  If we have a tail copy or are performing single page IO we can
	  immediately look at the next page.
	
	  If the next page causes us to wrap to the beginning of the log
	  file then we know which page to check next.
 Walk through the file, reading log pages. 
	
	  If we get a USA error then assume that we correctly found
	  the end of the original transfer.
	
	  If we were able to read the page, we examine it to see if it
	  is the same or different Io block.
 Skip over the remaining pages this transfer. 
 Call our routine to check this log page. 
 We have a valid file. 
			
			  Correct page and copy the data from this page
			  into it and flush it to disk.
 Fill last flushed lsn value flush the page. 
  read_log_rec_buf - Copy a log record from the file to a buffer.
  The log record may span several log pages and may even wrap the file.
	
	  While there are more bytes to transfer,
	  we continue to attempt to perform the read.
		
		  The last lsn on this page better be greater or equal
		  to the lsn we are copying.
 If there are no more bytes to transfer, we exit the loop. 
		
		  Adjust our pointer the user's buffer to transfer
		  the next block to.
 If the client doesn't have a restart area, go ahead and exit now. 
 If the lsn values don't match, then the disk is corrupt. 
 Copy the data into the 'rst' buffer. 
 Read the record header for this lsn. 
	
	  If the lsn the log record doesn't match the desired
	  lsn then the disk is corrupt.
	
	  Check that the length field isn't greater than the total
	  available space the log file.
	
	  If the entire log record is on this log page,
	  put a pointer to the log record the context block.
 Copy the data into the buffer returned. 
 If beyond the end of the current page -> an error. 
  read_log_rec_lcb - Init the query operation.
 Check that the given lsn is the legal range for this client. 
 Find the log record indicated by the given lsn. 
  find_client_next_lsn
  Attempt to find the next lsn to return to a client based on the context mode.
 Loop as long as another lsn can be found. 
err = -EINVAL; 
 Check the fixed part of the attribute record header. 
 Check the attribute fields. 
 Check the file record header for consistency. 
 Loop to check all of the attributes. 
 CLST rno;
  cmp_type_and_name
  Return: 0 if 'attr' has the same type and name.
  do_action - Common routine for the Redo and Undo Passes.
  @rlsn: If it is NULL then undo.
 Big switch to prepare. 
	 ============================================================
	  Process MFT records, as described by the current log record.
	  ============================================================
 Read from disk. 
	
	  Process attributes, as described by the current log record.
 align
 Big switch to do operation. 
 run_close(oa2->run1);
 To skip below memmove().
 run_close(&oa2->run0);
  log_replay - Replays log and empties it.
  This function is called during mount operation.
  It replays log and empties it.
  Initialized is set false if logfile contains '-1'.
 Get the size of page. NOTE: To replay we can use default page. 
 Look for a restart area on the disk. 
 remember 'initialized' 
 No restart area but the file is not initialized. 
	
	  If the restart offset above wasn't zero then we won't
	  look for a second restart.
 Determine which restart area to use. 
	
	  If the restart area is at offset 0, we want
	  to write the second restart area first.
 If we have a valid page then grab a pointer to the restart area. 
 Do some checks based on whether we have a valid log page. 
		
		  If the restart page size isn't changing then we want to
		  check how much work we need to do.
		 Put the restart areas and initialize
		  the log file as required.
	
	  If the log page or the system page sizes have changed, we can't
	  use the log file. We must use the system page size instead of the
	  default size if there is not a clean shutdown.
 If the file size has shrunk then we won't mount it. 
 This is a pseudo lsn. 
 Find the end of this log record. 
 If we wrapped the file then increment the sequence number. 
 Now compute the next log page to use. 
	
	 If we can fit another log record on the page,
	  move back a page the log file.
	
	  Find the oldest client lsn. Use the last
	  flushed lsn as a starting point.
 Now we need to walk through looking for the last lsn. 
 Remember which restart area to write first. 
 1.0, 1.1, 2.0 log->major_verminor_ver - short values. 
 One client "NTFS" per logfile. 
 Insert "NTFS" client LogFile. 
 Update the client handle with the client block information. 
 Allocate and Read the Transaction Table. 
 Now check that this is a valid restart table. 
 The next record back should be the Dirty Pages Table. 
 Now check that this is a valid restart table. 
 Convert Ra version '0' into version '1'. 
 NOTE: Danger. Check for of boundary.
	
	  Go through the table and remove the duplicates,
	  remembering the oldest lsn values.
 The next record should be the Attribute Names. 
 The next record should be the attribute Table. 
 Clear all of the Attr pointers. 
 Really 'oe' points to OPEN_ATTR_ENRTY_32. 
 TODO: Clear table on exit! 
	
	  If the checkpt_lsn is zero, then this is a freshly
	  formatted disk and we have no work to do.
 Start the analysis pass from the Checkpoint lsn. 
 Read the first lsn. 
 Loop to read all subsequent records to the end of the log file. 
	
	  The first lsn after the previous lsn remembered
	  the checkpoint is the first candidate for the rlsn.
	
	  Now update the Transaction Table for this transaction. If there
	  is no entry present or it is unallocated we allocate the entry.
	
	  If this is a compensation log record, then change
	  the undo_next_lsn to be the undo_next_lsn of this record.
 Dispatch to handle log record depending on type. 
		
		  Calculate the number of clusters per page the system
		  which wrote the checkpoint, possibly creating the table.
		
		  Copy the Lcns from the log record into the Dirty Page Entry.
		  TODO: For different page size support, must somehow make
		  whole routine a loop, case Lcns do not fit below.
 Loop through all of the Lcn ranges this log record. 
			
			  Compute how big the table needs to be.
			  Add 10 extra entries for some cushion.
 Point to the entry being opened. 
 Initialize this entry from the log record. 
 Convert version '0' into version '1'. 
oe0.name_len;
 The following cases require no action the Analysis Pass. 
		
		  All codes will be explicitly handled.
		  If we see a code we do not expect, then we are trouble.
	
	  Scan the Dirty Page Table and Transaction Table for
	  the lowest lsn, and return it as the Redo lsn.
	
	  Only proceed if the Dirty Page Table or Transaction
	  table are not empty.
 Reopen all of the attributes with dirty pages. 
	
	  Now loop through the dirty page table to extract all of the VcnLcn.
	  Mapping that we have, and insert it into the appropriate run.
	
	  Perform the Redo Pass, to restore all of the dirty pages to the same
	  contents that they had immediately before the crash. If the dirty
	  page table is empty, then we can skip the entire Redo Pass.
	
	  Read the record at the Redo lsn, before falling
	  into common code to handle each record.
	
	  Now loop to read all of our log records forwards, until
	  we hit the end of the file, cleaning up at the end.
 Ignore log records that do not update pages. 
 Point to the Redo data and get its length. 
 Shorten length by any Lcns which were deleted. 
 If the Vcn question is allocated, we can just get out. 
		
		  Calculate the allocated space left relative to the
		  log record Vcn, after removing this unallocated Vcn.
		
		  If the update described this log record goes beyond
		  the allocated space, then we will have to reduce the length.
	
	  If the resulting dlen from above is now zero,
	  we can skip this log record.
 Apply the Redo operation a common routine. 
 Keep reading and looping back until end of file. 
 Scan Transaction Table. 
	
	  We only have to do anything if the transaction has
	  something its undo_next_lsn field.
 Read the first record to be undone by this transaction. 
	
	  Now loop to read all of our log records forwards,
	  until we hit the end of the file, cleaning up at the end.
	
	  If the mapping isn't already the table or the  mapping
	  corresponds to a hole the mapping, we need to make sure
	  there is no partial page already memory.
 Point to the Redo data and get its length. 
 It is time to apply the undo action. 
	
	  Keep reading and looping back until we have read the
	  last record for this transaction.
 0x1A:
 0x1C:
	
	  Scan the Open Attribute Table to close all of
	  the open attributes.
 SPDX-License-Identifier: GPL-2.0-or-later
  lzx_decompress.c - A decompressor for the LZX compression format, which can
  be used in "System Compressed" files.  This is based on the code from wimlib.
  This code only supports a window size (dictionary size) of 32768 bytes, since
  this is the only size used in System Compression.
  Copyright (C) 2015 Eric Biggers
 Number of literal byte values  
 The smallest and largest allowed match lengths  
 Number of distinct match lengths that can be represented  
 Number of match lengths for which no length symbol is required  
 Valid values of the 3-bit block type field  
 Number of offset slots for a window size of 32768  
 Number of symbols in the main code for a window size of 32768  
 Number of symbols in the length code  
 Number of symbols in the precode  
 Number of bits in which each precode codeword length is represented  
 Number of low-order bits of each match offset that are entropy-encoded in
  aligned offset blocks
 Number of symbols in the aligned offset code  
 Mask for the match offset bits that are entropy-encoded in aligned offset
  blocks
 Number of bits in which each aligned offset codeword length is represented  
 Maximum lengths (in bits) of the codewords in each Huffman code  
 The default "filesize" value used in prepost-processing.  In the LZX format
  used in cabinet files this value must be given to the decompressor, whereas
  in the LZX format used in WIM files and system-compressed files this value is
  fixed at 12000000.
 Assumed block size when the encoded block size begins with a 0 bit.  
 Number of offsets in the recent (or "repeat") offsets queue.  
 These values are chosen for fast decompression.  
 Mapping: offset slot => first match offset that uses that offset slot.
 0  --- 4  
 5  --- 9  
 10 --- 14 
 15 --- 19 
 20 --- 24 
 25 --- 29 
 extra     
 Mapping: offset slot => how many extra bits must be read and added to the
  corresponding offset slot base to decode the match offset.
 Reusable heap-allocated memory for LZX decompression  
	 Huffman decoding tables, and arrays that map symbols to codeword
	  lengths
 Temporary space for make_huffman_decode_table()  
 "good translation" 
 "compensating translation" 
  Undo the 'E8' preprocessing used in LZX.  Before compression, the
  uncompressed data was preprocessed by changing the targets of suspected x86
  CALL instructions from relative offsets to absolute offsets.  After
  matchliteral decoding, the decompressor must undo the translation.
	
	  A worthwhile optimization is to push the end-of-buffer check into the
	  relatively rare E8 case.  This is possible if we replace the last six
	  bytes of data with E8 bytes; then we are guaranteed to hit an E8 byte
	  before reaching end-of-buffer.  In addition, this scheme guarantees
	  that no translation can begin following an E8 byte in the last 10
	  bytes because a 4-byte offset containing E8 as its high byte is a
	  large negative number that is not valid for translation.  That is
	  exactly what we need.
 Read a Huffman-encoded symbol using the precode.  
 Read a Huffman-encoded symbol using the main code.  
 Read a Huffman-encoded symbol using the length code.  
 Read a Huffman-encoded symbol using the aligned offset code.  
  Read the precode from the compressed input bitstream, then use it to decode
  @num_lens codeword length values.
  @is:		The input bitstream.
  @lens:	An array that contains the length values from the previous time
 		the codeword lengths for this Huffman code were read, or all 0's
 		if this is the first time.  This array must have at least
 		(@num_lens + LZX_READ_LENS_MAX_OVERRUN) entries.
  @num_lens:	Number of length values to decode.
  Returns 0 on success, or -1 if the data was invalid.
	 Read the lengths of the precode codewords.  These are given
	  explicitly.
 Make the decoding table for the precode.  
 Decode the codeword lengths.  
 Read the next precode symbol.  
 Difference from old length  
 Special RLE values  
 Run of 0's  
 Longer run of 0's  
 Run of identical lengths  
			 Worst case overrun is when presym == 18,
			  run_len == 20 + 31, and only 1 length was remaining.
			  So LZX_READ_LENS_MAX_OVERRUN == 50.
			 
			  Overrun while reading the first half of maincode_lens
			  can corrupt the previous values in the second half.
			  This doesn't really matter because the resulting
			  lengths will still be in range, and data that
			  generates overruns is invalid anyway.
  Read the header of an LZX block and save the block type and (uncompressed)
  size in block_type_ret and block_size_ret, respectively.
  If the block is compressed, also update the Huffman decode @tables with the
  new Huffman codes.  If the block is uncompressed, also update the match
  offset @queue with the new match offsets.
  Return 0 on success, or -1 if the data was invalid.
	 The first three bits tell us what kind of block it is, and should be
	  one of the LZX_BLOCKTYPE_ values.
 Read the block size.  
		 Read the aligned offset code and prepare its decode table.
		 Fall though, since the rest of the header for aligned offset
		  blocks is the same as that for verbatim blocks.
		 Read the main code and prepare its decode table.
		 
		  Note that the codeword lengths in the main code are encoded
		  in two parts: one part for literal symbols, and one part for
		  match symbols.
 Read the length code and prepare its decode table.  
		 Before reading the three recent offsets from the uncompressed
		  block header, the stream must be aligned on a 16-bit
		  boundary.  But if the stream is already aligned, then the
		  next 16 bits must be discarded.
 Offsets of 0 are invalid.  
 Unrecognized block type.  
 Decompress a block of LZX-compressed data.  
 Literal  
 Match  
 Decode the length header and offset slot.  
 If needed, read a length symbol to decode the full length. 
 Repeat offset  
			 Note: This isn't a real LRU queue, since using the R2
			  offset doesn't bump the R1 offset down to R2.  This
			  quirk allows all 3 recent offsets to be handled by
			  the same code.  (For R0, the swap is a no-op.)
 Explicit offset  
			 Look up the number of extra bits that need to be read
			  to decode offsets with this offset slot.
 Start with the offset slot base value.  
			 In aligned offset blocks, the low-order 3 bits of
			  each offset are encoded using the aligned offset
			  code.  Otherwise, all the extra bits are literal.
 Adjust the offset.  
 Update the recent offsets.  
 Validate the match, then copy it to the current position.  
  lzx_allocate_decompressor - Allocate an LZX decompressor
  Return the pointer to the decompressor on success, or return NULL and set
  errno on failure.
  lzx_decompress - Decompress a buffer of LZX-compressed data
  @decompressor:      A decompressor allocated with lzx_allocate_decompressor()
  @compressed_data:	The buffer of data to decompress
  @compressed_size:	Number of bytes of compressed data
  @uncompressed_data:	The buffer in which to store the decompressed data
  @uncompressed_size:	The number of bytes the data decompresses into
  Return 0 on success, or return -1 and set errno on failure.
 Codeword lengths begin as all 0's for delta encoding purposes.  
 Decompress blocks until we have all the uncompressed data.  
 Compressed block  
 Uncompressed block  
 Postprocess the data unless it cannot possibly contain 0xe8 bytes. 
  lzx_free_decompressor - Free an LZX decompressor
  @decompressor:       A decompressor that was allocated with
 			lzx_allocate_decompressor(), or NULL.
 SPDX-License-Identifier: GPL-2.0-or-later
  xpress_decompress.c - A decompressor for the XPRESS compression format
  (Huffman variant), which can be used in "System Compressed" files.  This is
  based on the code from wimlib.
  Copyright (C) 2015 Eric Biggers
 This value is chosen for fast decompression.  
 Reusable heap-allocated memory for XPRESS decompression  
 The Huffman decoding table  
 An array that maps symbols to codeword lengths  
 Temporary space for make_huffman_decode_table()  
  xpress_allocate_decompressor - Allocate an XPRESS decompressor
  Return the pointer to the decompressor on success, or return NULL and set
  errno on failure.
  xpress_decompress - Decompress a buffer of XPRESS-compressed data
  @decompressor:       A decompressor that was allocated with
 			xpress_allocate_decompressor()
  @compressed_data:	The buffer of data to decompress
  @compressed_size:	Number of bytes of compressed data
  @uncompressed_data:	The buffer in which to store the decompressed data
  @uncompressed_size:	The number of bytes the data decompresses into
  Return 0 on success, or return -1 and set errno on failure.
 Read the Huffman codeword lengths.  
 Build a decoding table for the Huffman code.  
 Decode the matches and literals.  
 Literal  
 Match  
  xpress_free_decompressor - Free an XPRESS decompressor
  @decompressor:       A decompressor that was allocated with
 			xpress_allocate_decompressor(), or NULL.
 SPDX-License-Identifier: GPL-2.0-or-later
  decompress_common.c - Code shared by the XPRESS and LZX decompressors
  Copyright (C) 2015 Eric Biggers
  make_huffman_decode_table() -
  Build a decoding table for a canonical prefix code, or "Huffman code".
  This is an internal function, not part of the library API!
  This takes as input the length of the codeword for each symbol in the
  alphabet and produces as output a table that can be used for fast
  decoding of prefix-encoded symbols using read_huffsym().
  Strictly speaking, a canonical prefix code might not be a Huffman
  code.  But this algorithm will work either way; and in fact, since
  Huffman codes are defined in terms of symbol frequencies, there is no
  way for the decompressor to know whether the code is a true Huffman
  code or not until all symbols have been decoded.
  Because the prefix code is assumed to be "canonical", it can be
  reconstructed directly from the codeword lengths.  A prefix code is
  canonical if and only if a longer codeword never lexicographically
  precedes a shorter codeword, and the lexicographic ordering of
  codewords of the same length is the same as the lexicographic ordering
  of the corresponding symbols.  Consequently, we can sort the symbols
  primarily by codeword length and secondarily by symbol value, then
  reconstruct the prefix code by generating codewords lexicographically
  in that order.
  This function does not, however, generate the prefix code explicitly.
  Instead, it directly builds a table for decoding symbols using the
  code.  The basic idea is this: given the next 'max_codeword_len' bits
  in the input, we can look up the decoded symbol by indexing a table
  containing 2max_codeword_len entries.  A codeword with length
  'max_codeword_len' will have exactly one entry in this table, whereas
  a codeword shorter than 'max_codeword_len' will have multiple entries
  in this table.  Precisely, a codeword of length n will be represented
  by 2(max_codeword_len - n) entries in this table.  The 0-based index
  of each such entry will contain the corresponding codeword as a prefix
  when zero-padded on the left to 'max_codeword_len' binary digits.
  That's the basic idea, but we implement two optimizations regarding
  the format of the decode table itself:
  - For many compression formats, the maximum codeword length is too
    long for it to be efficient to build the full decoding table
    whenever a new prefix code is used.  Instead, we can build the table
    using only 2table_bits entries, where 'table_bits' is some number
    less than or equal to 'max_codeword_len'.  Then, only codewords of
    length 'table_bits' and shorter can be directly looked up.  For
    longer codewords, the direct lookup instead produces the root of a
    binary tree.  Using this tree, the decoder can do traditional
    bit-by-bit decoding of the remainder of the codeword.  Child nodes
    are allocated in extra entries at the end of the table; leaf nodes
    contain symbols.  Note that the long-codeword case is, in general,
    not performance critical, since in Huffman codes the most frequently
    used symbols are assigned the shortest codeword lengths.
  - When we decode a symbol using a direct lookup of the table, we still
    need to know its length so that the bitstream can be advanced by the
    appropriate number of bits.  The simple solution is to simply retain
    the 'lens' array and use the decoded symbol as an index into it.
    However, this requires two separate array accesses in the fast path.
    The optimization is to store the length directly in the decode
    table.  We use the bottom 11 bits for the symbol and the top 5 bits
    for the length.  In addition, to combine this optimization with the
    previous one, we introduce a special case where the top 2 bits of
    the length are both set if the entry is actually the root of a
    binary tree.
  @decode_table:
 	The array in which to create the decoding table.  This must have
 	a length of at least ((2table_bits) + 2  num_syms) entries.
  @num_syms:
 	The number of symbols in the alphabet; also, the length of the
 	'lens' array.  Must be less than or equal to 2048.
  @table_bits:
 	The order of the decode table size, as explained above.  Must be
 	less than or equal to 13.
  @lens:
 	An array of length @num_syms, indexable by symbol, that gives the
 	length of the codeword, in bits, for that symbol.  The length can
 	be 0, which means that the symbol does not have a codeword
 	assigned.
  @max_codeword_len:
 	The longest codeword length allowed in the compression format.
 	All entries in 'lens' must be less than or equal to this value.
 	This must be less than or equal to 23.
  @working_space
 	A temporary array of length '2  (max_codeword_len + 1) +
 	num_syms'.
  Returns 0 on success, or -1 if the lengths do not form a valid prefix
  code.
	 Count how many symbols have each possible codeword length.
	  Note that a length of 0 indicates the corresponding symbol is not
	  used in the code and therefore does not have a codeword.
	 We can assume all lengths are <= max_codeword_len, but we
	  cannot assume they form a valid prefix code.  A codeword of
	  length n should require a proportion of the codespace equaling
	  (12)^n.  The code is valid if and only if the codespace is
	  exactly filled by the lengths, by this measure.
			 The lengths overflow the codespace; that is, the code
			  is over-subscribed.
		 The lengths do not fill the codespace; that is, they form an
		  incomplete set.
			 The code is completely empty.  This is arguably
			  invalid, but in fact it is valid in LZX and XPRESS,
			  so we must allow it.  By definition, no symbols can
			  be decoded with an empty code.  Consequently, we
			  technically don't even need to fill in the decode
			  table.  However, to avoid accessing uninitialized
			  memory if the algorithm nevertheless attempts to
			  decode symbols using such a code, we zero out the
			  decode table.
	 Sort the symbols primarily by length and secondarily by symbol order.
	 Initialize 'offsets' so that offsets[len] for 1 <= len <=
	  max_codeword_len is the number of codewords shorter than 'len' bits.
	 Use the 'offsets' array to sort the symbols.  Note that we do not
	  include symbols that are not used in the code.  Consequently, fewer
	  than 'num_syms' entries in 'sorted_syms' may be filled.
	 Fill entries for codewords with length <= table_bits
	  --- that is, those short enough for a direct mapping.
	 
	  The table will start with entries for the shortest codeword(s), which
	  have the most entries.  From there, the number of entries per
	  codeword will decrease.
	 If we've filled in the entire table, we are done.  Otherwise,
	  there are codewords longer than table_bits for which we must
	  generate binary trees.
		 First, zero out the remaining entries.  This is
		  necessary so that these entries appear as
		  "unallocated" in the next part.  Each of these entries
		  will eventually be filled with the representation of
		  the root node of a binary tree.
		 We allocate child nodes starting at the end of the
		  direct lookup table.  Note that there should be
		  2num_syms extra entries for this purpose, although
		  fewer than this may actually be needed.
		 Iterate through each codeword with length greater than
		  'table_bits', primarily in order of codeword length
		  and secondarily in order of symbol.
				 'sorted_sym' is the symbol represented by the
				  codeword.
				 Go through each bit of the current codeword
				  beyond the prefix of length @table_bits and
				  walk the appropriate binary tree, allocating
				  any slots that have not yet been allocated.
				 
				  Note that the 'pointer' entry to the binary
				  tree, which is stored in the direct lookup
				  portion of the table, is represented
				  identically to other internal (non-leaf)
				  nodes of the binary tree; it can be thought
				  of as simply the root of the tree.  The
				  representation of these internal nodes is
				  simply the index of the left child combined
				  with the special bits 0xC000 to distinguish
				  the entry from direct mapping and leaf node
				  entries.
					 At least one bit remains in the
					  codeword, but the current node is an
					  unallocated leaf.  Change it to an
					  internal node.
					 Go to the left child if the next bit
					  in the codeword is 0; otherwise go to
					  the right child.
				 We've traversed the tree using the entire
				  codeword, and we're now at the entry where
				  the actual symbol will be stored.  This is
				  distinguished from internal nodes by not
				  having its high two bits set.
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  See COPYING in top-level directory.
	
	  Rather than incurring a network call just to determine the exact
	  length of the attribute, I just allocate a max length to save on
	  the network call. Conceivably, we could pass NULL to
	  orangefs_inode_getxattr() to probe the length of the value, but
	  I don't do that for now.
 if the key exists, convert it to an in-memory rep 
 kfree(NULL) is safe, so don't worry if value ever got used 
	
	  Go ahead and set the extended attribute now. NOTE: Suppose acl
	  was NULL, then value will be NULL and size will be 0 and that
	  will xlate to a removexattr. However, we don't want removexattr
	  complain if attributes does not exist.
		
		  posix_acl_update_mode checks to see if the permissions
		  described by the ACL can be encoded into the
		  object's mode. If so, it sets "acl" to NULL
		  and "mode" to the new desired value. It is up to
		  us to propagate the new mode back to the server...
 If mode of the inode was changed, then do a forcible ->setattr 
 SPDX-License-Identifier: GPL-2.0
  What:		syskerneldebugorangefsdebug-help
  Date:		June 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			List of client and kernel debug keywords.
  What:		syskerneldebugorangefsclient-debug
  Date:		June 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			Debug setting for "the client", the userspace
  			helper for the kernel module.
  What:		syskerneldebugorangefskernel-debug
  Date:		June 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			Debug setting for the orangefs kernel module.
  			Any of the keywords, or comma-separated lists
  			of keywords, from debug-help can be catted to
  			client-debug or kernel-debug.
  			"none", "all" and "verbose" are special keywords
  			for client-debug. Setting client-debug to "all"
  			is kind of like trying to drink water from a
  			fire hose, "verbose" triggers most of the same
  			output except for the constant flow of output
  			from the main wait loop.
  			"none" and "all" are similar settings for kernel-debug
  			no need for a "verbose".
  An array of client_debug_mask will be built to hold debug keywordmask
  values fetched from userspace.
  Used to protect data in ORANGEFS_KMOD_DEBUG_FILE and
  ORANGEFS_KMOD_DEBUG_FILE.
 Used to protect data in ORANGEFS_KMOD_DEBUG_HELP_FILE 
  initialize kmod debug operations, create orangefs debugfs dir and
  ORANGEFS_KMOD_DEBUG_HELP_FILE.
 convert input debug mask to a 64-bit unsigned integer 
	
	  set the kernel's gossip debug string; invalid mask values will
	  be ignored.
 remove any invalid values from the mask 
	
	  if the mask has a non-zero value, then indicate that the mask
	  was set when the kernel module was loaded.  The orangefs dev ioctl
	  command will look at this boolean to determine if the kernel's
	  debug mask should be overwritten when the client-core is started.
  initialize the kernel-debug file.
 open ORANGEFS_KMOD_DEBUG_HELP_FILE 
  I think start always gets called again after stop. Start
  needs to return NULL when it is done. The whole "payload"
  in this case is a single (long) string, so by the second
  time we get to start (pos = 1), we're done.
  initialize the client-debug file.
 open ORANGEFS_KMOD_DEBUG_FILE or ORANGEFS_CLIENT_DEBUG_FILE.
	
	  Thwart users who try to jamb a ridiculous number
	  of bytes into the debug file...
	
	  Map the keyword string from userspace into a valid debug mask.
	  The mapping process involves mapping the human-inputted string
	  into a valid mask, and then rebuilding the string from the
	  verified valid mask.
	 
	  A service operation is required to set a new client-side
	  debug mask.
 Can't reset client debug mask if client is not running. 
 service_operation returns 0 on success... 
  After obtaining a string representation of the client's debug
  keywords and their associated masks, this function is called to build an
  array of these values.
	
	  figure out how many elements the cdm_array needs.
  syskerneldebugorangefsdebug-help can be catted to
  see all the available kernel and client debug keywords.
  When orangefs.ko initializes, we have no idea what keywords the
  client supports, nor their associated masks.
  We pass through this function once at module-load and stamp a
  boilerplate "we don't know" message for the client in the
  debug-help file. We pass through here again when the client
  starts and then we can fill out the debug-help file fully.
  The client might be restarted any number of times between
  module reloads, we only build the debug-help file the first time.
 build a new debug_help_string. 
	
	  strlcat(dst, src, size) will append at most
	  "size - strlen(dst) - 1" bytes of src onto dst,
	  null terminating the result, and return the total
	  length of the string it tried to create.
	 
	  We'll just plow through here building our new debug
	  help string and let strlcat take care of assuring that
	  dst doesn't overflow.
		  fill the client keywordmask array and remember
		  how many elements there were.
 See if we tried to put too many bytes into "new"... 
  kernel = type 0
  client = type 1
	
	  Some keywords, like "all" or "verbose", are amalgams of
	  numerous other keywords. Make a special check for those
	  before grinding through the whole mask only to find out
	  later...
 Build the debug string. 
  kernel = type 0
  client = type 1
  return 1 if we found an amalgam.
  kernel = type 0
  client = type 1
	
	  The real client-core makes an effort to ensure
	  that actual strings that aren't too long to fit in
	  this buffer is what we get here. We're going to use
	  string functions on the stuff we got, so we'll make
	  this extra effort to try and keep from
	  flowing out of this buffer when we use the string
	  functions, even if somehow the stuff we end up
	  with here is garbage.
 Build a proper debug help string. 
			
			  the kernel debug mask was set when the
			  kernel module was loaded; don't override
			  it if the client-core was started without
			  a value for ORANGEFS_KMODMASK.
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  See COPYING in top-level directory.
   Linux VFS namei operations.
  Get a newly allocated inode to go with a negative dentry.
  Attempt to resolve an object name (dentry->d_name), parent handle, and
  fsid into a handle for the object.
	
	  in theory we could skip a lookup here (if the intent is to
	  create) in order to avoid a potentially failed lookup, but
	  leaving it in can skip a valid lookup and try to create a file
	  that already exists (e.g. the vfs already handles checking for
	  -EEXIST on O_EXCL opens, which is broken if we skip this lookup
	  in the create path)
 must be a non-recoverable error 
 return 0 on success; non-zero otherwise 
	
	  This is necessary because orangefs_inode_getattr will not
	  re-read symlink size as it is impossible for it to change.
	  Invalidating the cache does not help.  orangefs_new_inode
	  does not set the correct size (it does not know symname).
	
	  NOTE: we have no good way to keep nlink consistent for directories
	  across clients; keep constant at 1.
 ORANGEFS implementation of VFS inode operations for directories 
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  See COPYING in top-level directory.
 a cache for orangefs-inode objects (i.e. orangefs inode private data) 
 list for storing orangefs specific superblocks in use 
	
	  Force any potential flags that might be set from the mount
	  to zero, ie, initialize to unset.
	
	  We want to clear everything except for rw_semaphore and the
	  vfs_inode.
  NOTE: information filled in here is typically reflected in the
  output of the system command 'df'
  Remount as initiated by VFS layer.  We just need to reparse the mount
  options, no need to signal pvfs2-client-core about it.
  Remount as initiated by pvfs2-client-core on restart.  This is used to
  repopulate mount information left from previous pvfs2-client-core.
  the idea here is that given a valid superblock, we're
  re-initializing the user space client with the initial mount
  information specified when the super block was first initialized.
  this is very different than the first initializationcreation of a
  superblock.  we use the special service_priority_operation to make
  sure that the mount gets ahead of any other pending operation that
  is waiting for servicing.  this means that the pvfs2-client won't
  fail to start several times for all other pending operations before
  the client regains all of the mount information from us.
  NOTE: this function assumes that the request_mutex is already acquired!
	
	  we assume that the calling function has already acquired the
	  request_mutex to prevent other operations from bypassing
	  this one
		
		  store the id assigned to this sb -- it's just a
		  short-lived mapping that the system interface uses
		  to map this superblock to a particular mount entry
 Not much to do about an error here. 
 Hang the xattr handlers off the superblock 
 allocates and places root dentry in dcache 
 alloc and init our private orangefs sb info 
	
	  on successful mount, store the devname and data
	  used
 mount_pending must be cleared 
	
	  finally, add this sb to our list of known orangefs
	  sb's
 Must be removed from the list now. 
 Will call orangefs_kill_sb with sb not in list. 
 ORANGEFS_VFS_OP_FS_UMOUNT is done by orangefs_kill_sb. 
 provided sb cleanup 
	
	  issue the unmount to userspace to tell it to remove the
	  dynamic mount info it has for this superblock
 remove the sb from our list of orangefs specific sb's 
 not list_del_init 
	
	  make sure that ORANGEFS_DEV_REMOUNT_ALL loop that might've seen us
	  gets completed before we free the dang thing.
 free the orangefs superblock private data 
 SPDX-License-Identifier: GPL-2.0
  DocumentationABIstablesysfs-fs-orangefs:
  What:		sysfsorangefsperf_counter_reset
  Date:		June 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			echo a 0 or a 1 into perf_counter_reset to
  			reset all the counters in
  			sysfsorangefsperf_counters
  			except ones with PINT_PERF_PRESERVE set.
  What:		sysfsorangefsperf_counters...
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			Counters and settings for various caches.
  			Read only.
  What:		sysfsorangefsperf_time_interval_secs
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
 			Length of perf counter intervals in
 			seconds.
  What:		sysfsorangefsperf_history_size
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			The perf_counters cache statistics have N, or
  			perf_history_size, samples. The default is
  			one.
 			Every perf_time_interval_secs the (first)
 			samples are reset.
 			If N is greater than one, the "current" set
 			of samples is reset, and the samples from the
 			other N-1 intervals remain available.
  What:		sysfsorangefsop_timeout_secs
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
 			Service operation timeout in seconds.
  What:		sysfsorangefsslot_timeout_secs
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
 			"Slot" timeout in seconds. A "slot"
 			is an indexed buffer in the shared
 			memory segment used for communication
 			between the kernel module and userspace.
 			Slots are requested and waited for,
 			the wait times out after slot_timeout_secs.
  What:		sysfsorangefscache_timeout_msecs
  Date:		Mar 2018
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
 			Time in milliseconds between which
 			orangefs_revalidate_mapping will invalidate the page
 			cache.
  What:		sysfsorangefsdcache_timeout_msecs
  Date:		Jul 2016
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
 			Time lookup is valid in milliseconds.
  What:		sysfsorangefsgetattr_timeout_msecs
  Date:		Jul 2016
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
 			Time getattr is valid in milliseconds.
  What:		sysfsorangefsreadahead_count
  Date:		Aug 2016
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
 			Readahead cache buffer count.
  What:		sysfsorangefsreadahead_size
  Date:		Aug 2016
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
 			Readahead cache buffer size.
  What:		sysfsorangefsreadahead_count_size
  Date:		Aug 2016
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
 			Readahead cache buffer count and size.
  What:		sysfsorangefsreadahead_readcnt
  Date:		Jan 2017
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
 			Number of buffers (in multiples of readahead_size)
 			which can be read ahead for a single file at once.
  What:		sysfsorangefsacache...
  Date:		Jun 2015
  Contact:		Martin Brandenburg <martin@omnibond.com>
  Description:
  			Attribute cache configurable settings.
  What:		sysfsorangefsncache...
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			Name cache configurable settings.
  What:		sysfsorangefscapcache...
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			Capability cache configurable settings.
  What:		sysfsorangefsccache...
  Date:		Jun 2015
  Contact:		Mike Marshall <hubcap@omnibond.com>
  Description:
  			Credential cache configurable settings.
  Every item calls orangefs_attr_show and orangefs_attr_store through
  orangefs_sysfs_ops. They look at the orangefs_attributes further below to
  call one of sysfs_int_show, sysfs_int_store, sysfs_service_op_show, or
  sysfs_service_op_store.
  obtain attribute values from userspace with a service operation.
 Can't do a service_operation if the client is not running... 
 Drop unsupported requests first. 
	
	  The service_operation will return an errno return code on
	  error, and zero on success.
  pass attribute values back to userspace with a service operation.
  We have to do a memory allocation, an sscanf and a service operation.
  And we have to evaluate what the user entered, to make sure the
  value is within the range supported by the attribute. So, there's
  a lot of return code checking and mapping going on here.
  We want to return 1 if we think everything went OK, and
  EINVAL if not.
 sic 
 Can't do a service_operation if the client is not running... 
	
	  The value we want to send back to userspace is in buf, unless this
	  there are two parameters, which is specially handled below.
 Drop unsupported requests first. 
	
	  The service_operation will return a errno return code on
	  error, and zero on success.
 create sysfsorangefs. 
 create sysfsorangefsacache. 
 create sysfsorangefscapcache. 
 create sysfsorangefsccache. 
 create sysfsorangefsncache. 
 create sysfsorangefsperf_counters. 
 create sysfsorangefsstats. 
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  Copyright 2018 Omnibond Systems, L.L.C.
  See COPYING in top-level directory.
   Linux VFS extended attribute operations.
  this function returns
    0 if the key corresponding to name is not meant to be printed as part
      of a listxattr.
    1 if the key corresponding to name is meant to be returned as part of
      a listxattr.
  The ones that start SYSTEM_ORANGEFS_KEY are the ones to avoid printing.
 Attribute must exist! 
 Attribute must not exist 
		if (!time_before(jiffies, cx->timeout)) {
			hlist_del(&cx->node);
			kfree(cx);
			continue;
  Tries to get a specified key's attributes of a given
  file into a user-specified buffer. Note that the getxattr
  interface allows for the users to probe the size of an
  extended attribute by passing in a value of 0 to size.
  Thus our return value is always the size of the attribute
  unless the key does not exist for the file andor if
  there were errors in fetching the attribute value.
	
	  NOTE: Although keys are meant to be NULL terminated textual
	  strings, I am going to explicitly pass the length just in case
	  we change this later on...
	
	  Length returned includes null terminator.
	
	  Just return the length of the queried attribute.
	
	  Check to see if key length is > provided buffer size.
	
	  NOTE: Although keys are meant to be NULL terminated
	  textual strings, I am going to explicitly pass the
	  length just in case we change this later on...
		
		  Request to replace a non-existent attribute is an error.
  Tries to set an attribute for a given key on a file.
  Returns a -ve number on error and 0 on success.  Key is text, but value
  can be binary!
 This is equivalent to a removexattr 
	
	  NOTE: Although keys are meant to be NULL terminated textual
	  strings, I am going to explicitly pass the length just in
	  case we change this later on...
 when request is serviced properly, free req op struct 
  Tries to get a specified object's keys into a user-specified buffer of a
  given size.  Note that like the previous instances of xattr routines, this
  also allows you to pass in a NULL pointer and 0 size to probe the size for
  subsequent memory allocations. Thus our return value is always the size of
  all the keys unless there were errors in fetching the keys!
		
		  This is a bit of a big upper limit, but I did not want to
		  spend too much time getting this correct, since users end
		  up allocating memory rather than us...
	
	  Check to see how much can be fit in the buffer. Fit only whole keys.
		
		  Since many dumb programs try to setxattr() on our reserved
		  xattrs this is a feeble attempt at defeating those by not
		  listing them in the output of listxattr.. sigh
	
	  Since the buffer was large enough, we might have to continue
	  fetching more keys!
 match any name => handlers called with full name 
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  Copyright 2018 Omnibond Systems, L.L.C.
  See COPYING in top-level directory.
   Linux VFS inode operations.
 Should've been handled in orangefs_invalidatepage. 
 It's not private so there's nothing to write, right? 
 read in the pages. 
 clean up. 
 offset into this page 
 this will only zero remaining unread portions of the page data 
 takes care of potential aliasing 
 unlock the page after the ->readpage() routine completes 
		
		  Should be impossible.  If it happens, launder the page
		  since we don't know what's dirty.  This will WARN in
		  orangefs_writepage_locked.
	
	  No need to use i_size_read() here, the i_size
	  cannot change under us because we hold the i_mutex.
 zero the stale part of the page if we did a short copy 
 Set fully written pages uptodate. 
 write range entirely within invalidate range (or equal) 
 XXX is this right? only caller in fs 
 invalidate range chops off end of write range 
 invalidate range chops off beginning of write range 
 invalidate range entirely within write range (punch hole) 
 XXX what do we do here... should not WARN_ON 
 punch hole 
		
		  should we just ignore this and write it out anyway?
		  it hardly makes sense
 non-overlapping ranges 
 WARN if they do overlap 
	
	  Above there are returns where wr is freed or where we WARN.
	  Thus the following runs if wr was modified above.
	
	  Comment from original do_readv_writev:
	  Common entry point for readwritereadvwritev
	  This function will dispatch it to either the direct IO
	  or buffered IO path depending on the mount options andor
	  augmentedextended metadata attached to the file.
	  Note: File extended attributes override any mount options.
 how much to transfer in this loop iteration 
		
		  if we got a short IO operations,
		  fall out and return what we got so far
end while 
 ORANGEFS2 implementation of address space operations 
		
		  Should be impossible.  If it happens, launder the page
		  since we don't know what's dirty.  This will WARN in
		  orangefs_writepage_locked.
	
	  We mark the page dirty already here so that when freeze is in
	  progress, we are guaranteed that writeback during freezing will
	  see the dirty page and writeprotect it again.
 Ensure that we have a up to date size, so we know if it changed. 
 This is truncate_setsize in a different order. 
	
	  the truncate has no downcall members to retrieve, but
	  the status value tells us if it went through ok or not
				
				  allow sticky bit to be set on root (since
				  it shows up that way by default anyhow),
				  but don't show it to the server
 change mod on a file that has ACLs 
  Change attributes of an object referenced by dentry.
  Obtain attributes of an object given a dentry
 override block size reported to stat 
 Make sure the permission (and other common attrs) are up to date. 
	
	  ORANGEFS_MIRROR_FL is set internally when the mirroring mode is
	  turned on for a file. The user is not allowed to turn on this bit,
	  but the bit is present if the user first gets the flags and then
	  updates the flags with some new settings. So, we ignore it in the
	  following edit. bligon.
 ORANGEFS2 implementation of VFS inode operations for files 
  Given an ORANGEFS object identifier (fsid, handle), convert it into
  a ino_t type that will be used as a hash-index from where the handle will
  be searched for in the VFS hash table of inodes.
  Called to set up an inode from iget5_locked.
  Called to determine if handles match.
 test handles and fs_ids... 
  Front-end to lookup the inode-cache maintained by the VFS using the ORANGEFS
  file handle.
  @sb: the file system super block instance.
  @ref: The ORANGEFS object for which we are trying to locate an inode.
 needed for stat etc 
  Allocate an inode for a newly created file and insert it into the inode hash.
 needed for stat etc 
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  Copyright 2018 Omnibond Systems, L.L.C.
  See COPYING in top-level directory.
  NOTE: in kernel land, we never use the sys_attr->link_target for
  anything, so don't bother copying it into the sys_attr object here.
	
	  ORANGEFS cannot set size with a setattr operation. Probably not
	  likely to be requested through the VFS, but just in case, don't
	  worry about ATTR_SIZE
		
		  if this occurs, the pvfs2-client-core was killed but we
		  can't afford to lose the inode operations and such
		  associated with the root handle in any case.
	
	  If the inode type or symlink target have changed then this
	  inode is stale.
 Must have all the attributes in the mask and be within cache time. 
	
	  Size is the hardest attribute to get.  The incremental cost of any
	  other attribute is essentially zero.
 Must have all the attributes in the mask and be within cache time. 
 i.e. -1 
 XXX: ESTALE?  This is what is done if it is not new. 
 special case: mark the root inode as sticky 
  issues a orangefs setattr request to make sure the new attribute values
  take effect if successful.  returns 0 on success; -errno otherwise
  The following is a very dirty hack that is now a permanent part of the
  ORANGEFS protocol. See protocol.h for more error definitions.
 The order matches includeorangefs-types.h in the OrangeFS source. 
 Success 
	
	  This shouldn't ever happen. If it does it should be fixed on the
	  server.
	
	  XXX: This is very bad since error codes from ORANGEFS may not be
	  suitable for return into userspace.
	
	  Convert ORANGEFS error values into errno values suitable for return
	  from the kernel.
			
			  cancellation error codes generally correspond to
			  a timeout from the client's perspective
 assume a default error code 
 Convert ORANGEFS encoded errno values into regular errno values. 
	
	  Only ORANGEFS protocol error codes should ever come here. Otherwise
	  there is a bug somewhere.
 SPDX-License-Identifier: GPL-2.0
  Copyright 2017 Omnibond Systems, L.L.C.
  There can be up to 512 directory entries.  Each entry is encoded as
  follows:
  4 bytes: string size (n)
  n bytes: string
  1 byte: trailing zero
  padding to 8 bytes
  16 bytes: khandle
  padding to 8 bytes
  The trailer_buf starts with a struct orangefs_readdir_response_s
  which must be skipped to get to the directory data.
  The data which is received from the userspace daemon is termed a
  part and is stored in a linked list in case more than one part is
  needed for a large directory.
  The position pointer (ctx->pos) encodes the part and offset on which
  to begin reading at.  Bits above PART_SHIFT encode the part and bits
  below PART_SHIFT encode the offset.  Parts are stored in a linked
  list which grows as data is received from the server.  The overhead
  associated with managing the list is presumed to be small compared to
  the overhead of communicating with the server.
  As data is received from the server, it is placed at the end of the
  part list.  Data is parsed from the current position as it is needed.
  When data is determined to be corrupt, it is either because the
  userspace component has sent back corrupt data or because the file
  pointer has been moved to an invalid location.  Since the two cannot
  be differentiated, return EIO.
  Part zero is synthesized to contains `.' and `..'.  Part one is the
  first part of the part list.
	
	  Despite the badly named field, readdir does not use shared
	  memory.  However, there are a limited number of readdir
	  slots, which must be allocated here.  This flag simply tells
	  the op scheduler to return the op here for retry.
	
	  The maximum size is size per entry times the 512 entries plus
	  the header.  This is well under the limit.
 The file offset from userspace is too large. 
	
	  If the seek pointer is positioned just before an entry it
	  should find the next entry.
		
		  len is the size of the string itself.  padlen is the
		  total size of the encoded string.
 This means the userspace file offset is invalid. 
 Userspace buffer is full. 
			
			  The part ran out of data.  Move to the next
	
	  Delete the stored data so userspace sees new directory
	  entries.
	
	  The seek position is in the first synthesized part but is not
	  valid.
	
	  Must read more if the user has sought past what has been read
	  so far.  Stop a user who has sought past the end.
 Then try to fill if there's any left in the buffer. 
 Finally get some more and try to fill. 
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  See COPYING in top-level directory.
   Implementation of dentry (directory cache) functions.
 Returns 1 if dentry can still be trusted, else 0. 
 Positive dentry: reject if error or not the same inode. 
 Negative dentry: reject if success or error other than ENOENT. 
  Verify that dentry is valid.
  Should return 1 if dentry can still be trusted, else 0.
 skip root handle lookups. 
	
	  If this passes, the positive dentry still exists or the negative
	  dentry still does not exist.
 We do not need to continue with negative dentries. 
 Now we must perform a getattr to validate the inode contents. 
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  See COPYING in top-level directory.
 finished dying 
 we are waiting for map to be installed 
 it would better be there soon, or we go away 
 used to describe mapped buffers 
 user space address pointer 
 array of mapped pages 
 size of above arrays 
 array to track usage of buffer descriptors 
 array to track usage of buffer descriptors for readdir 
  XXX: Can the size and shift change while the caller gives up the
  XXX: lock between calling this and doing something useful?
 allocate storage to track our page mappings 
 map the pages 
	
	  ideally we want to get kernel space pointers for each page, but
	  we can't kmap that many pages at once if highmem is being used.
	  so instead, we just kmapkunmap the page address each time the
	  kaddr is needed.
 build a list of available descriptors 
  orangefs_bufmap_initialize()
  initializes the mapped buffer interface
  returns 0 on success, -errno on failure
	
	  sanity check alignment and size of buffer that caller wants to
	  work with
  orangefs_bufmap_finalize()
  shuts down the mapped buffer interface and releases any resources
  associated with it
  no return value
  orangefs_bufmap_get()
  gets a free mapped buffer descriptor, will sleep until one becomes
  available if necessary
  returns slot on success, -errno on failure
  orangefs_bufmap_put()
  returns a mapped buffer descriptor to the collection
  no return value
  orangefs_readdir_index_get()
  gets a free descriptor, will sleep until one becomes
  available if necessary.
  Although the readdir buffers are not mapped into kernel space
  we could do that at a later point of time. Regardless, these
  indices are used by the client-core.
  returns slot on success, -errno on failure
  we've been handed an iovec, we need to copy it to
  the shared memory descriptor at "buffer_index".
  we've been handed an iovec, we need to fill it from
  the shared memory descriptor at "buffer_index".
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  Copyright 2018 Omnibond Systems, L.L.C.
  See COPYING in top-level directory.
   Linux VFS file operations.
  Post and wait for the IO upcall to finish
 synchronous IO 
 get a shared buffer index 
	
	  Orangefs has no open, and orangefs checks file permissions
	  on each file access. Posix requires that file permissions
	  be checked on open and nowhere else. Orangefs-through-the-kernel
	  needs to seem posix compliant.
	 
	  The VFS opens files, even if the filesystem provides no
	  method. We can see if a file was successfully opened for
	  read and or for write by looking at file->f_mode.
	 
	  When writes are flowing from the page cache, file is no
	  longer available. We can trust the VFS to have checked
	  file->f_mode before writing to the page cache.
	 
	  The mode of a file might change between when it is opened
	  and IO commences, or it might be created with an arbitrary mode.
	 
	  We'll make sure we don't hit EACCES during the IO stage by
	  using UID 0. Some of the time we have access without changing
	  to UID 0 - how to check?
 not relevant? 
	
	  Stage 1: copy the buffers into client-core's address space
 Stage 2: Service the IO operation 
	
	  If service_operation() returns -EAGAIN #and# the operation was
	  purged from orangefs_request_list or htable_ops_in_progress, then
	  we know that the client was restarted, causing the shared memory
	  area to be wiped clean.  To restart a  write operation in this
	  case, we must re-copy the data from the user's iovec to a NEW
	  shared memory location. To restart a read operation, we must get
	  a new shared memory location.
			
			  We can't return EINTR if any data was written,
			  it's not POSIX. It is minimally acceptable
			  to give a partial write, the way NFS does.
			 
			  It would be optimal to return all or nothing,
			  but if a userspace write is bigger than
			  an IO buffer, and the interrupt occurs
			  between buffer writes, that would not be
			  possible.
			
			  If the op was waiting when the interrupt
			  occurred, then the client-core did not
			  trigger the write.
			
			  If the op was in progress when the interrupt
			  occurred, then the client-core was able to
			  trigger the write.
	
	  Stage 3: Post copy buffers from client-core's address space
		
		  NOTE: the iovector can either contain addresses which
		        can futher be kernel-space or user-space addresses.
		        or it can pointers to struct page's
  Memory map a region of a file.
 set the sequential readahead hint 
  Called to notify the module that there are no more references to
  this file (i.e. no processes have it open).
  \note Not called when each file is closed.
	
	  remove all associated inode pages from the page cache and
	  readahead cache (if any); this forces an expensive refresh of
	  data for the next caller of mmap (or 'get_block' accesses)
  Push all data for a specific file onto permanent storage.
  Change the file pointer position for an instance of an open file.
  \note If .llseek is overriden, we must acquire lock as described in
        Documentationfilesystemslocking.rst.
  Future upgrade could support SEEK_DATA and SEEK_HOLE but would
  require much changes to the FS
		
		  revalidate the inode's file size.
		  NOTE: We are only interested in file size here,
		  so we set mask accordingly.
  Support local locks (locks that only this kernel knows about)
  if Orangefs was mounted -o local_lock.
	
	  This is vfs_fsync_range(file, 0, LLONG_MAX, 0) without the
	  service_operation in orangefs_fsync.
	 
	  Do not send fsync to OrangeFS server on a close.  Do send fsync
	  on an explicit fsync call.  This duplicates historical OrangeFS
	  behavior.
 ORANGEFS implementation of VFS file operations 
 SPDX-License-Identifier: GPL-2.0-only
  (C) 2001 Clemson University and The University of Chicago
  Changes by Acxiom Corporation to add proc file handler for pvfs2 client
  parameters, Copyright Acxiom Corporation, 2005.
  See COPYING in top-level directory.
 ORANGEFS_VERSION is a .configure define 
  global variables declared here
 the size of the hash tables for ops in progress 
  Blocks non-priority requests from being queued for servicing.  This
  could be used for protecting the request list data structure, but
  for now it's only being used to stall the op addition to the request
  list
 hash table for storing operations waiting for matching downcall 
 list for queueing upcall operations 
 used to protect the above orangefs_request_list 
 used for incoming request notification 
 initialize global book keeping data structures 
 initialize a doubly linked at each hash table index 
	
	  Build the contents of syskerneldebugorangefsdebug-help
	  from the keywords in the kernel keywordmask array.
	 
	  The keywords in the client keywordmask array are
	  unknown at boot time.
	 
	  orangefs_prepare_debugfs_help_string will be used again
	  later to rebuild the debug-help-string after the client starts
	  and passes along the needed info. The argument signifies
	  which time orangefs_prepare_debugfs_help_string is being
	  called.
 Initialize the orangefsdev subsystem. 
  What we do in this function is to walk the list of operations
  that are in progress in the hash table and mark them as purged as well.
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  See COPYING in top-level directory.
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  Changes by Acxiom Corporation to add protocol version to kernel
  communication, Copyright Acxiom Corporation, 2005.
  See COPYING in top-level directory.
 this file implements the devpvfs2-req device node 
  find the op with this tag and remove it from the in progress
  hash table.
 Returns whether any FS are still pending remounted 
 All of these file system require a remount 
  Determine if a given file system needs to be remounted or not
   Returns -1 on error
            0 if already mounted
            1 if needs remount
 in order to ensure that the filesystem driver sees correct UIDs 
 Function for read() callers into the device 
 We do not support blocking IO. 
	
	  The client will do an ioctl to find MAX_DEV_REQ_UPSIZE, then
	  always read with that size buffer.
 Check for an empty list before locking. 
 Get next op (if any) from top of list. 
 This lock is held past the end of the loop when we break. 
 Skip ops whose filesystem needs to be mounted. 
			
			  Skip ops whose filesystem we don't know about unless
			  it is being mounted or unmounted.  It is possible for
			  a filesystem we don't know about to be unmounted if
			  it fails to mount in the kernel after userspace has
			  been sent the mount request.
 XXX: is there a better way to detect this? 
		
		  Either this op does not pertain to a filesystem, is mounting
		  a filesystem, or pertains to a mounted filesystem. Let it
		  through.
	
	  At this point we either have a valid op and can continue or have not
	  found an op and must ask the client to try again later.
	
	  Such an op should never be on the list in the first place. If so, we
	  will abort.
 Push the upcall out. 
	
	  Set the operation to be in progress and move it between lists since
	  it has been sent to the client.
 The client only asks to read one size buffer. 
	
	  We were unable to copy the op data to the client. Put the op back in
	  list. If client has crashed, the op will be purged later when the
	  device is released.
  Function for writev() callers into the device.
  Userspace should have written:
   - __u32 version
   - __u32 magic
   - __u64 tag
   - struct orangefs_downcall_s
   - trailer buffer (in the case of READDIR operations)
 remove the op from the in progress hash table 
	
	  We've successfully peeled off the head and the downcall.
	  Something has gone awry if total doesn't equal the
	  sum of head_size, downcall_size and trailer_size.
 Only READDIR operations should have trailers. 
 READDIR operations should always have trailers. 
	
	  Return to vfs waitqueue, and back to service_operation
	  through wait_for_matching_downcall.
  NOTE: gets called when the last reference to this device is dropped.
  Using the open_access_count variable, we enforce a reference count
  on this file so that it can be opened by only one process at a time.
  the devreq_mutex is used to make sure all io has completed
  before we call orangefs_bufmap_finalize, and similar such tricky
  situations
	
	  What this function does is checks if client-core is alive
	  based on the access count we maintain on the device.
 Check for valid ioctl codes 
 and valid ioctl commands 
 mtmoore: add locking here 
 WTF -EIO and not -EFAULT? 
		
		  remount all mounted orangefs volumes to regain the lost
		  dynamic mount tables (if any) -- NOTE: this is done
		  without keeping the superblock list locked due to the
		  upcalldowncall waiting.  also, the request mutex is
		  used to ensure that no operations will be serviced until
		  all of the remounts are serviced (to avoid ops between
		  mounts to fail)
			
			  We have to drop the spinlock, so entries can be
			  removed.  They can't be freed, though, so we just
			  keep the forward pointers and zero the back ones -
			  that way we can get to the rest of the list.
 Check for properly constructed commands 
 CONFIG_COMPAT is in .config 
  Compat structure for the ORANGEFS_DEV_MAP ioctl 
  32 bit user-space apps' ioctl handlers when kernel modules
  is compiled as a 64 bit one
 Check for properly constructed commands 
 no other ioctl requires translation 
 CONFIG_COMPAT is in .config 
 the assigned character device major number 
 CONFIG_COMPAT is in .config 
  Initialize orangefs device specific state:
  Must be called at module load time only
 register orangefs-req device  
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  See COPYING in top-level directory.
 tags assigned to kernel upcall operations 
 the orangefs memory caches 
 a cache for orangefs upcalldowncall operations 
 initialize our atomic tag counter 
 initialize the op specific tag and upcall credentials 
 SPDX-License-Identifier: GPL-2.0
  (C) 2001 Clemson University and The University of Chicago
  (C) 2011 Omnibond Systems
  Changes by Acxiom Corporation to implement generic service_operation()
  function, Copyright Acxiom Corporation, 2005.
  See COPYING in top-level directory.
   In-kernel waitqueue operations.
  What we do in this function is to walk the list of operations that are
  present in the request queue and mark them as purged.
  NOTE: This is called from the device close after client-core has
  guaranteed that no new operations could appear on the list since the
  client-core is anyway going to exit.
  submits a ORANGEFS operation and waits for it to complete
  Note op->downcall.status will contain the status of the operation (in
  errno format), whether provided by pvfs2-client or a result of failure to
  service the operation.  If the caller wishes to distinguish, then
  op->state can be checked to see if it was serviced or not.
  Returns contents of op->downcall.status for convenience
	
	  If ORANGEFS_OP_NO_MUTEX was set in flags, we need to avoid
	  acquiring the request_mutex because we're servicing a
	  high priority remount operation and the request_mutex is
	  already taken.
		
		  check to see if we were interrupted while waiting for
		  mutex
 queue up the operation 
 add high priority remount op to the front of the line. 
		
		  Don't wait for the userspace component to return if
		  the filesystem is being umounted anyway.
 got matching downcall; make sure status is in errno format 
 failed to get matching downcall 
	
	  remove a waiting op from the request list or
	  remove an in-progress op from the in-progress list.
 retry if operation has not been serviced and if requested 
		
		  io ops (ops that use the shared memory buffer) have
		  to be returned to their caller for a retry. Other ops
		  can just be recycled here.
 This can get called on an IO op if it had a bad service_operation. 
 orangefs_request_list_lock is enough of a barrier here 
  Change an op to the "given up" state and remove it from its list.
	
	  handle interrupted cases depending on what state we were in when
	  the interruption is detected.
	 
	  Called with op->lock held.
	
	  List manipulation code elsewhere will ignore ops that
	  have been given up upon.
 caught copying tofrom daemon 
		
		  upcall hasn't been read; remove op from upcall request
		  list.
 op must be removed from the in progress htable 
  Sleeps on waitqueue waiting for matching downcall.
  If client-core finishes servicing, then we are good to go.
  else if client-core exits, we get woken up here, and retry with a timeout
  When this call returns to the caller, the specified op will no
  longer be in either the in_progress hash table or on the request list.
  Returns 0 on success and -errno on failure
  Errors are:
  EAGAIN in case we want the caller to requeue and try again..
  EINTREIOETIMEDOUT indicating we are done trying to service this
  operation since client-core seems to be exiting too often
  or if we were interrupted.
  Returns with op->lock taken.
	
	  There's a "schedule_timeout" inside of these wait
	  primitives, during which the op is out of the hands of the
	  user process that needs something done and is being
	  manipulated by the client-core process.
 !writeback && !interruptible but compiler complains 
 must have timed out, then... 
 SPDX-License-Identifier: GPL-2.0
  Cryptographic API.
  MD4 Message Digest Algorithm (RFC1320).
  Implementation derived from Andrew Tridgell and Steve French's
  CIFS MD4 implementation, and the cryptoapi implementation
  originally based on the public domain implementation written
  by Colin Plumb in 1993.
  Copyright (c) Andrew Tridgell 1997-1998.
  Modified by Steve French (sfrench@us.ibm.com) 2002
  Copyright (c) Cryptoapi developers.
  Copyright (c) 2002 David S. Miller (davem@redhat.com)
  Copyright (c) 2002 James Morris <jmorris@intercode.com.au>
 SPDX-License-Identifier: GPL-2.0-or-later
  Cryptographic API
  ARC4 Cipher Algorithm
  Jon Oberheide <jon@oberheide.org>
 SPDX-License-Identifier: GPL-2.0-only
  linuxfslockdsvc.c
  This is the central lockd service.
  FIXME: Separate the lockd NFS server functionality from the lockd NFS
  	  client functionality. Oh why didn't Sun create two separate
 	  services in the first place?
  Authors:	Olaf Kirch (okir@monad.swb.de)
  Copyright (C) 1995, 1996 Olaf Kirch <okir@monad.swb.de>
  These can be set at insmod time (useful for NFS as root filesystem),
  and also changed through the sysctl interface.  -- Jamie Lokier, Aug 2003
 RLIM_NOFILE defaults to 1024. That seems like a reasonable default here. 
  Constants needed for the sysctl interface.
 Note: nlm_timeout should always be nonzero 
  This is the lockd kernel thread
 try_to_freeze() is called from svc_recv() 
 Allow SIGKILL to tell lockd to drop all of its locks 
	
	  The main request loop. We don't terminate until the last
	  NFS mount or NFS daemon has gone away.
 update sv_maxconn if it has changed 
		
		  Find a socket with data available and call its
		  recvfrom routine.
  Ensure there are active UDP and TCP listeners for lockd.
  Even if we have only TCP NFS mounts andor TCP NFSDs, some
  local services (such as rpc.statd) still require UDP, and
  some NFS servers do not yet support NLM over TCP.
  Returns zero if all listeners are available; otherwise a
  negative errno value is returned.
	
	  Create the kernel thread and wait for it to start.
	
	  Check whether we're already up and running.
		
		  Note: increase service usage, because later in case of error
		  svc_destroy() will be called.
	
	  Sanity check: if there's no pid,
	  we should be the first user ...
  Bring up the lockd process if it's not already up.
	
	  Note: svc_serv structures have an initial use count of 1,
	  so we exit through here on both success and failure.
  Decrement the user count and bring down lockd if we're the last.
  Sysctl parameters (same as module parameters, different interface).
 CONFIG_SYSCTL 
  Module (and sysfs) parameters.
				 Leave it to individual procedures to
				  call nlmsvc_lookup_host(rqstp)
  Initialising and terminating the module.
 FIXME: delete all NLM clients 
  nlmsvc_dispatch - Process an NLM Request
  @rqstp: incoming request
  @statp: pointer to location of accept_stat field in RPC Reply buffer
  Return values:
   %0: Processing complete; do not send a Reply
   %1: Processing complete; send Reply in rqstp->rq_res
  Define NLM program and procedures
 program number 
 number of entries in nlmsvc_version 
 version table 
 service name 
 share authentication with nfsd 
 stats table 
 export authentication 
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdxdr4.c
  XDR support for lockd and the lock client.
  Copyright (C) 1995, 1996 Olaf Kirch <okir@monad.swb.de>
  Copyright (C) 1999, Trond Myklebust <trond.myklebust@fys.uio.no>
  NLM file handles are defined by specification to be a variable-length
  XDR opaque no longer than 1024 bytes. However, this implementation
  limits their length to the size of an NFSv3 file handle.
 exclusive 
  Decode Call arguments
 monitor client by default 
 XXX: Range checks are missing in the original code 
  Encode Reply results
 sequence 
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdsvcproc.c
  Lockd server procedures. We don't implement the NLM__RES 
  procedures because we don't use the async procedures.
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
 Note: status is assumed to be in network byte order !!! 
  Obtain client and file from arguments
 nfsd callbacks must have been installed for this procedure 
 Obtain host handle 
 Obtain file pointer. Not used by FREE_ALL call. 
 Set up the missing parts of the file_lock structure 
 lockowner allocation has failed 
  NULL: Test for presence of service
  TEST: Check for conflicting lock
 Obtain client and file 
 Now check for conflicting locks 
 Obtain client and file 
	 If supplied state doesn't match current state, we assume it's
	  an old request that time-warped somehow. Any error return would
	  do in this case because it's irrelevant anyway.
	 
	  NB: We don't retrieve the remote host's state yet.
 Now try to lock the file 
 Don't accept requests during grace period 
 Obtain client and file 
 Try to cancel request. 
  UNLOCK: release a lock
 Don't accept new lock requests during grace period 
 Obtain client and file 
 Now try to remove the lock 
  GRANTED: A server calls us to tell that a process' lock request
  was granted
  This is the generic lockd callback for async RPC calls
  `Async' versions of the above service routines. They aren't really,
  because we send the callback before the reply proper. I hope this
  doesn't break any clients.
  SHARE: create a DOS share or alter existing share.
 Don't accept new lock requests during grace period 
 Obtain client and file 
 Now try to create the share 
  UNSHARE: Release a DOS share.
 Don't accept requests during grace period 
 Obtain client and file 
 Now try to unshare the file 
  NM_LOCK: Create an unmonitored lock
 just clean the monitor flag 
  FREE_ALL: Release all locks and shares held by client
 Obtain client 
  SM_NOTIFY: private callback from statd (not part of official NLM proto)
  client sent a GRANTED_RES, let's remove the associated block
  NLM Server procedures.
 cookie 
 status 
 Net Obj 
 range - offset + size 
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdclntxdr.c
  XDR functions to encodedecode NLM version 3 RPC arguments and results.
  NLM version 3 is backwards compatible with NLM versions 1 and 2.
  NLM client-side only.
  Copyright (C) 2010, Oracle.  All rights reserved.
  Declare the space requirements for NLM arguments and replies as
  number of 32bit-words
  Encodedecode NLMv3 basic data types
  Basic NLMv3 data types are not defined in an IETF standards
  document.  XOpen has a description of these data types that
  is useful.  See Chapter 10 of "Protocols for Interworking:
  XNFS, Version 3W".
  Not all basic data types have their own encoding and decoding
  functions.  For run-time efficiency, some data types are encoded
  or decoded inline.
 	typedef opaque netobj<MAXNETOBJ_SZ>
 	netobj cookie;
 apparently HPUX can return empty cookies 
 	netobj fh;
 	enum nlm_stats {
 		LCK_GRANTED = 0,
 		LCK_DENIED = 1,
 		LCK_DENIED_NOLOCKS = 2,
 		LCK_BLOCKED = 3,
 		LCK_DENIED_GRACE_PERIOD = 4
 	};
 	struct nlm_stat {
 		nlm_stats stat;
 	};
  NB: we don't swap bytes for the NLM status values.  The upper
  layers deal directly with the status value in network byte
  order.
 	struct nlm_holder {
 		bool exclusive;
 		int uppid;
 		netobj oh;
 		unsigned l_offset;
 		unsigned l_len;
 	};
 	string caller_name<LM_MAXSTRLEN>;
 NB: client-side does not set lock->len 
 	struct nlm_lock {
 		string caller_name<LM_MAXSTRLEN>;
 		netobj fh;
 		netobj oh;
 		int uppid;
 		unsigned l_offset;
 		unsigned l_len;
 	};
  NLMv3 XDR encode functions
  NLMv3 argument types are defined in Chapter 10 of The Open Group's
  "Protocols for Interworking: XNFS, Version 3W".
 	struct nlm_testargs {
 		netobj cookie;
 		bool exclusive;
 		struct nlm_lock alock;
 	};
 	struct nlm_lockargs {
 		netobj cookie;
 		bool block;
 		bool exclusive;
 		struct nlm_lock alock;
 		bool reclaim;
 		int state;
 	};
 	struct nlm_cancargs {
 		netobj cookie;
 		bool block;
 		bool exclusive;
 		struct nlm_lock alock;
 	};
 	struct nlm_unlockargs {
 		netobj cookie;
 		struct nlm_lock alock;
 	};
 	struct nlm_res {
 		netobj cookie;
 		nlm_stat stat;
 	};
 	union nlm_testrply switch (nlm_stats stat) {
 	case LCK_DENIED:
 		struct nlm_holder holder;
 	default:
 		void;
 	};
 	struct nlm_testres {
 		netobj cookie;
 		nlm_testrply test_stat;
 	};
  NLMv3 XDR decode functions
  NLMv3 result types are defined in Chapter 10 of The Open Group's
  "Protocols for Interworking: XNFS, Version 3W".
 	union nlm_testrply switch (nlm_stats stat) {
 	case LCK_DENIED:
 		struct nlm_holder holder;
 	default:
 		void;
 	};
 	struct nlm_testres {
 		netobj cookie;
 		nlm_testrply test_stat;
 	};
 	struct nlm_res {
 		netobj cookie;
 		nlm_stat stat;
 	};
  For NLM, a void procedure really returns nothing
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdmon.c
  The kernel statd client.
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
 RPC callback info 
  Local NSM state
  nsm_monitor - Notify a peer in case we reboot
  @host: pointer to nlm_host of peer to notify
  If this peer is not already monitored, this function sends an
  upcall to the local rpc.statd to record the nameaddress of
  the peer to notify in case we reboot.
  Returns zero if the peer is monitored by the local rpc.statd;
  otherwise a negative errno value is returned.
	
	  Choose whether to record the caller_name or IP address of
	  this peer in the local rpc.statd's database.
  nsm_unmonitor - Unregister peer notification
  @host: pointer to nlm_host of peer to stop monitoring
  If this peer is monitored, this function sends an upcall to
  tell the local rpc.statd not to send this peer a notification
  when we reboot.
  Construct a unique cookie to match this nsm_handle to this monitored
  host.  It is passed to the local rpc.statd via NSMPROC_MON, and
  returned via NLMPROC_SM_NOTIFY, in the "priv" field of these
  requests.
  The NSM protocol requires that these cookies be unique while the
  system is running.  We prefer a stronger requirement of making them
  unique across reboots.  If user space bugs cause a stale cookie to
  be sent to the kernel, it could cause the wrong host to lose its
  lock state if cookies were not unique across reboots.
  The cookies are exposed only to local user space via loopback.  They
  do not appear on the physical network.  If we want greater security
  for some reason, nsm_init_private() could perform a one-way hash to
  obscure the contents of the cookie.
  nsm_get_handle - Find or create a cached nsm_handle
  @net: network namespace
  @sap: pointer to socket address of handle to find
  @salen: length of socket address
  @hostname: pointer to C string containing hostname to find
  @hostname_len: length of C string
  Behavior is modulated by the global nsm_use_hostnames variable.
  Returns a cached nsm_handle after bumping its ref count, or
  returns a fresh nsm_handle if a handle that matches @sap andor
  @hostname cannot be found in the handle cache.  Returns NULL if
  an error occurs.
  nsm_reboot_lookup - match NLMPROC_SM_NOTIFY arguments to an nsm_handle
  @net:  network namespace
  @info: pointer to NLMPROC_SM_NOTIFY arguments
  Returns a matching nsm_handle if found in the nsm cache. The returned
  nsm_handle's reference count is bumped. Otherwise returns NULL if some
  error occurred.
  nsm_release - Release an NSM handle
  @nsm: pointer to handle to be released
  XDR functions for NSM.
  See https:www.opengroup.org for details on the Network
  Status Monitor wire protocol.
  "mon_name" specifies the host to be monitored.
  The "my_id" argument specifies the hostname and RPC procedure
  to be called when the status manager receives notification
  (via the NLMPROC_SM_NOTIFY call) that the state of host "mon_name"
  has changed.
  The "mon_id" argument specifies the non-private arguments
  of an NSMPROC_MON or NSMPROC_UNMON call.
  The "priv" argument may contain private information required
  by the NSMPROC_MON call. This information will be supplied in the
  NLMPROC_SM_NOTIFY call.
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdclnt4xdr.c
  XDR functions to encodedecode NLM version 4 RPC arguments and results.
  NLM client-side only.
  Copyright (C) 2010, Oracle.  All rights reserved.
  Declare the space requirements for NLM arguments and replies as
  number of 32bit-words
  Encodedecode NLMv4 basic data types
  Basic NLMv4 data types are defined in Appendix II, section 6.1.4
  of RFC 1813: "NFS Version 3 Protocol Specification" and in Chapter
  10 of XOpen's "Protocols for Interworking: XNFS, Version 3W".
  Not all basic data types have their own encoding and decoding
  functions.  For run-time efficiency, some data types are encoded
  or decoded inline.
 	typedef opaque netobj<MAXNETOBJ_SZ>
 	netobj cookie;
 apparently HPUX can return empty cookies 
 	netobj fh;
 	enum nlm4_stats {
 		NLM4_GRANTED = 0,
 		NLM4_DENIED = 1,
 		NLM4_DENIED_NOLOCKS = 2,
 		NLM4_BLOCKED = 3,
 		NLM4_DENIED_GRACE_PERIOD = 4,
 		NLM4_DEADLCK = 5,
 		NLM4_ROFS = 6,
 		NLM4_STALE_FH = 7,
 		NLM4_FBIG = 8,
 		NLM4_FAILED = 9
 	};
 	struct nlm4_stat {
 		nlm4_stats stat;
 	};
  NB: we don't swap bytes for the NLM status values.  The upper
  layers deal directly with the status value in network byte
  order.
 	struct nlm4_holder {
 		bool	exclusive;
 		int32	svid;
 		netobj	oh;
 		uint64	l_offset;
 		uint64	l_len;
 	};
 	string caller_name<LM_MAXSTRLEN>;
 NB: client-side does not set lock->len 
 	struct nlm4_lock {
 		string	caller_name<LM_MAXSTRLEN>;
 		netobj	fh;
 		netobj	oh;
 		int32	svid;
 		uint64	l_offset;
 		uint64	l_len;
 	};
  NLMv4 XDR encode functions
  NLMv4 argument types are defined in Appendix II of RFC 1813:
  "NFS Version 3 Protocol Specification" and Chapter 10 of XOpen's
  "Protocols for Interworking: XNFS, Version 3W".
 	struct nlm4_testargs {
 		netobj cookie;
 		bool exclusive;
 		struct nlm4_lock alock;
 	};
 	struct nlm4_lockargs {
 		netobj cookie;
 		bool block;
 		bool exclusive;
 		struct nlm4_lock alock;
 		bool reclaim;
 		int state;
 	};
 	struct nlm4_cancargs {
 		netobj cookie;
 		bool block;
 		bool exclusive;
 		struct nlm4_lock alock;
 	};
 	struct nlm4_unlockargs {
 		netobj cookie;
 		struct nlm4_lock alock;
 	};
 	struct nlm4_res {
 		netobj cookie;
 		nlm4_stat stat;
 	};
 	union nlm4_testrply switch (nlm4_stats stat) {
 	case NLM4_DENIED:
 		struct nlm4_holder holder;
 	default:
 		void;
 	};
 	struct nlm4_testres {
 		netobj cookie;
 		nlm4_testrply test_stat;
 	};
  NLMv4 XDR decode functions
  NLMv4 argument types are defined in Appendix II of RFC 1813:
  "NFS Version 3 Protocol Specification" and Chapter 10 of XOpen's
  "Protocols for Interworking: XNFS, Version 3W".
 	union nlm4_testrply switch (nlm4_stats stat) {
 	case NLM4_DENIED:
 		struct nlm4_holder holder;
 	default:
 		void;
 	};
 	struct nlm4_testres {
 		netobj cookie;
 		nlm4_testrply test_stat;
 	};
 	struct nlm4_res {
 		netobj cookie;
 		nlm4_stat stat;
 	};
  For NLM, a void procedure really returns nothing
 SPDX-License-Identifier: GPL-2.0-only
  linuxfslockdclntproc.c
  RPC procedures for the client side NLM implementation
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
  Cookie counter for NLM requests
  Initialize arguments for TESTLOCKUNLOCKCANCEL calls
  nlmclnt_proc - Perform a single client-side lock request
  @host: address of a valid nlm_host context representing the NLM server
  @cmd: fcntl-style file lock operation to perform
  @fl: address of arguments for the lock operation
  @data: address of data to be sent to callback operations
 lockowner allocation has failed 
 Set up the argument struct 
  Allocate an NLM RPC call struct
  Generic NLM call
 If we have no RPC client yet, create one. 
 Perform the RPC call. If an error occurs, try again 
 We appear to be out of the grace period 
 Okay, call complete 
		
		  The server has rebooted and appears to be in the grace
		  period during which locks are only allowed to be
		  reclaimed.
		  We can only back off and try again later.
  Generic NLM call, async version.
 If we have no RPC client yet, create one. 
 bootstrap and kick off the async RPC call 
  NLM asynchronous call.
  NLM client asynchronous call.
  Note that although the calls are asynchronous, and are therefore
       guaranteed to complete, we still always attempt to wait for
       completion in order to be able to correctly track the lock
       state.
  TEST for the presence of a conflicting lock
			
			  Report the conflicting lock back to the application.
  LOCK: Try to create a lock
 			Programmer Harassment Alert
  When given a blocking lock request in a sync RPC call, the HPUX lockd
  will faithfully return LCK_BLOCKED but never cares to notify us when
  the lock could be granted. This way, our local process could hang
  around forever waiting for the callback.
   Solution A:	Implement busy-waiting
   Solution B: Use the async version of the call (NLM_LOCK_{MSG,RES})
  For now I am implementing solution A, because I hate the idea of
  re-implementing lockd for a third time in two months. The async
  calls shouldn't be too hard to do, however.
  This is one of the lovely things about standards in the NFS area:
  they're so soft and squishy you can't really blame HP for doing this.
	
	  Initialise resp->status to a valid non-zero value,
	  since 0 == nlm_lck_granted
 Reboot protection 
 Did a reclaimer thread notify us of a server reboot? 
 Wait on an NLM blocking lock 
	 if we were interrupted while blocking, then cancel the lock request
	  and exit
 Check whether or not the server has rebooted 
 Ensure the resulting lock will get added to granted list 
	
	  EAGAIN doesn't make sense for sleeping locks, and in some
	  cases NLM_LCK_DENIED is returned for a permanent error.  So
	  turn it into an ENOLCK.
 Fatal error: ensure that we remove the lock altogether 
  RECLAIM: Try to reclaim a lock
 Set up the argument struct 
	
	  FIXME: This is a serious failure. We can
	 
	   a.	Ignore the problem
	   b.	Send the owning process some signal (Linux doesn't have
	 	SIGLOST, though...)
	   c.	Retry the operation
	 
	  Until someone comes up with a simple implementation
	  for b or c, I'll choose option a.
  UNLOCK: remove an existing lock
	
	  Note: the server is supposed to either grant us the unlock
	  request, or to deny it with NLM_LCK_DENIED_GRACE_PERIOD. In either
	  case, we want to unlock.
 What to do now? I'm out of my depth... 
  Cancel a blocked lock request.
  We always use an async RPC call for this in order not to hang a
  process that has been Ctrl-C'ed.
 Everything's good 
 Don't ever retry more than 3 times 
  Convert an NLM status code to a generic kernel errno
 SPDX-License-Identifier: GPL-2.0-only
  linuxfslockdclntlock.c
  Lock handling for the client side NLM implementation
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
  Local function prototypes
  The following functions handle blocking and granting from the
  client perspective.
  This is the representation of a blocked client lock.
 linked list 
 where to wait on 
 local file lock 
 got to reclaim lock 
 grant callback status 
  nlmclnt_init - Set up per-NFS mount point lockd data structures
  @nlm_init: pointer to arguments structure
  Returns pointer to an appropriate nlm_host struct,
  or an ERR_PTR value.
  nlmclnt_done - Release resources allocated by nlmclnt_init()
  @host: nlm_host structure reserved by nlmclnt_init()
  Queue up a lock for blocking so that the GRANTED request can see it
  Block on a lock
	 A borken server might ask us to block even if we didn't
	  request it. Just say no!
	 Go to sleep waiting for GRANT callback. Some servers seem
	  to lose callbacks, however, so we're going to poll from
	  time to time just to make sure.
	 
	  For now, the retry frequency is pretty high; normally 
	  a 1 minute timeout would do. See the comment before
	  nlmclnt_lock for an explanation.
 Reset the lock status after a server reboot so we resend 
  The server lockd has called us back to tell us the lock was granted
	
	  Look up blocked request based on arguments. 
	  Warning: must not use cookie to match it!
		
		  Careful! The NLM server will return the 32-bit "pid" that
		  we put on the wire: in this case the lockowner "pid".
		 Alright, we found a lock. Set the return status
		  and wake up the caller
  The following procedures deal with the recovery of locks after a
  server crash.
  Reclaim all locks on server host. We do this by spawning a separate
  reclaimer thread.
 note: this cannot fail as lockd is already running 
	 Force a portmap getport - the peer's lockd will
	  most likely end up on a different port.
 First, reclaim all locks that have been granted. 
		
		  sending this thread a SIGKILL will result in any unreclaimed
		  locks being removed from the h_granted list. This means that
		  the kernel will not attempt to reclaim them again if a new
		  reclaimer thread is spawned for this host.
 Argh! The server rebooted again! 
 Now, wake up all processes that sleep on a blocked lock 
 Release host handle after use 
 SPDX-License-Identifier: GPL-2.0-only
  linuxfslockdsvcsubs.c
  Various support routines for the NLM server.
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
  Global file hash table
 print the first 32 bytes of the fh 
  Open the file. Note that if we're reexporting, for example,
  this could block the lockd thread for a while.
  We have to make sure we have the right credential to open
  the file.
  Lookup file info. If it doesn't exist, create a file info struct
  and open a (VFS) file for the given inode.
 Lock file table 
  Delete a file after having released all locks, blocks and shares
  Loop over all locks on the given file and perform the specified
  action.
 update current lock count 
  Inspect a single file
  Quick check whether there are still any locks, blocks or
  shares on a given file.
  Loop over all files in the file table.
			 Traverse locks, blocks and shares of this file
 No more references to this file. Let go of it. 
  Release file. If there are no more remote locks on this file,
  close it and free the handle.
  Note that we can't do proper reference counting without major
  contortions because the code in fslocks.c creates, deletes and
  splits locks without notification. Our only way is to walk the
  entire lock list each time we remove a lock.
 Lock file table 
 If there are no more locks etc, delete the file 
  Helpers function for resource traversal
  nlmsvc_mark_host:
 	used by the garbage collector; simply sets h_inuse only for those
 	hosts, which passed network check.
 	Always returns 0.
  nlmsvc_same_host:
 	returns 1 iff the two hosts match. Used to release
 	all resources bound to a specific host.
  nlmsvc_is_client:
 	returns 1 iff the host is a client.
 	Used by nlmsvc_invalidate_all
		 we are destroying locks even though the client
		  hasn't asked us too, so don't unmonitor the
		  client
  Mark all hosts that still hold resources
  Release all resources held by the given client
  nlmsvc_invalidate_all - remove all locks held for clients
  Release all locks held by NFS clients.
	
	  Previously, the code would call
	  nlmsvc_free_host_resources for each client in
	  turn, which is about as inefficient as it gets.
	  Now we just do it once in nlm_traverse_files.
  nlmsvc_unlock_all_by_sb - release locks held on this file system
  @sb: super block
  Release all locks held by clients accessing this file system.
  nlmsvc_unlock_all_by_ip - release local locks by IP address
  @server_addr: server's IP address as seen by clients
  Release all locks held by clients accessing this host
  via the passed in IP address.
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdsvcshare.c
  Management of DOS shares.
  Copyright (C) 1996 Olaf Kirch <okir@monad.swb.de>
 Copy owner handle 
  Delete a share.
	 XOpen spec says return success even if there was no
  Traverse all shares for a given file, and delete
  those owned by the given (type of) host
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdxdr.c
  XDR support for lockd and the lock client.
  Copyright (C) 1995, 1996 Olaf Kirch <okir@monad.swb.de>
  NLM file handles are defined by specification to be a variable-length
  XDR opaque no longer than 1024 bytes. However, this implementation
  constrains their length to exactly the length of an NFSv2 file
  handle.
 exclusive 
  Decode Call arguments
 monitor client by default 
 XXX: Range checks are missing in the original code 
  Encode Reply results
 sequence 
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdsvc4proc.c
  Lockd server procedures. We don't implement the NLM__RES 
  procedures because we don't use the async procedures.
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
  Obtain client and file from arguments
 nfsd callbacks must have been installed for this procedure 
 Obtain host handle 
 Obtain file pointer. Not used by FREE_ALL call. 
 Set up the missing parts of the file_lock structure 
 lockowner allocation has failed 
  NULL: Test for presence of service
  TEST: Check for conflicting lock
 Obtain client and file 
 Now check for conflicting locks 
 Obtain client and file 
	 If supplied state doesn't match current state, we assume it's
	  an old request that time-warped somehow. Any error return would
	  do in this case because it's irrelevant anyway.
	 
	  NB: We don't retrieve the remote host's state yet.
 Now try to lock the file 
 Don't accept requests during grace period 
 Obtain client and file 
 Try to cancel request. 
  UNLOCK: release a lock
 Don't accept new lock requests during grace period 
 Obtain client and file 
 Now try to remove the lock 
  GRANTED: A server calls us to tell that a process' lock request
  was granted
  This is the generic lockd callback for async RPC calls
  `Async' versions of the above service routines. They aren't really,
  because we send the callback before the reply proper. I hope this
  doesn't break any clients.
  SHARE: create a DOS share or alter existing share.
 Don't accept new lock requests during grace period 
 Obtain client and file 
 Now try to create the share 
  UNSHARE: Release a DOS share.
 Don't accept requests during grace period 
 Obtain client and file 
 Now try to lock the file 
  NM_LOCK: Create an unmonitored lock
 just clean the monitor flag 
  FREE_ALL: Release all locks and shares held by client
 Obtain client 
  SM_NOTIFY: private callback from statd (not part of official NLM proto)
  client sent a GRANTED_RES, let's remove the associated block
  NLM Server procedures.
 cookie 
 netobj 
 status 
 range (offset + length) 
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdsvclock.c
  Handling of server-side locks, mostly of the blocked variety.
  This is the ugliest part of lockd because we tread on very thin ice.
  GRANT and CANCEL calls may get stuck, meet in mid-flight, etc.
  IMNSHO introducing the grant callback into the NLM protocol was one
  of the worst ideas Sun ever had. Except maybe for the idea of doing
  NFS file locking at all.
  I'm trying hard to avoid race conditions by protecting most accesses
  to a file's list of blocked locks through a semaphore. The global
  list of blocked locks is not protected in this fashion however.
  Therefore, some functions (such as the RPC callback for the async grant
  call) move blocked locks towards the head of the list while some other
  process might be traversing it. This should not be a problem in
  practice, because this will only cause functions traversing the list
  to visit some blocks twice.
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
  The list of blocked locks to retry
	
	  We can get away with a static buffer because this is only called
	  from lockd, which is single-threaded.
 allow for trailing \0 
  Insert a blocked lock into the global list
		 On normal exit from the loop, pos == &nlm_blocked,
		  so we will be adding to the end of the list - good
  Remove a block from the global list
  Find a block for a given lock
  Find a block with a given NLM cookie.
  Create a block and initialize it.
  Note: we explicitly set the cookie of the grant reply to that of
  the blocked lock request. The spec explicitly mentions that the client
  should _not_ rely on the callback containing the same cookie as the
  request, but (as I found out later) that's because some implementations
  do just this. Never mind the standards comittees, they support our
  logging industries.
  10 years later: I hope we can safely ignore these old and broken
  clients by now. Let's fix this so we can uniquely identify an incoming
  GRANTED_RES message by cookie, without having to rely on the client's IP
  address. --okir
 Allocate memory for block, and initialize arguments 
 Set notifier function for VFS, and init args 
 Create and initialize the block 
 Add to file's list of blocks 
 Set up RPC arguments for callback 
  Delete a block.
  It is the caller's responsibility to check whether the file
  can be closed hereafter.
 Remove block from list 
 Remove block from file's list of blocks 
  Loop over all blocks and delete blocks held by
  a matching host.
		 Do not destroy blocks that are not on
 fslocks.c will manage the refcount through lock_ops 
  Initialize arguments for GRANTED call. The nlm_rqst structure
  has been cleared already.
 set default data area 
  Deferred lock request handling for non-blocking lock
  Attempt to establish a lock, and if it can't be granted, block it
  if required.
 Lock file against concurrent access 
	 Get existing block (in case client is busy-waiting)
	  or create new block
			
			  If this is a blocking request for an
			  already pending lock request then we need
			  to put it back on lockd's block list
			 Filesystem lock operation is in progress
 includes ENOLCK 
 Append to list of blocked 
  Test for presence of a conflicting lock.
 If there's a conflicting lock, remember to clean up the test lock 
 We can't currently deal with deferred test requests 
 FIXME 
 don't return OH info 
 Clean up the test lock 
  Remove a lock.
  This implies a CANCEL call: We send a GRANT_MSG, the client replies
  with a GRANT_RES call which gets lost, and calls UNLOCK immediately
  afterwards. In this case the block will still be there, and hence
  must be removed.
 First, cancel any lock that might be there 
  Cancel a previously blocked request.
  A cancel request always overrides any grant that may currently
  be in progress.
  The calling procedure must check whether the file can be closed.
  This is a callback from the filesystem for VFS file lock requests.
  It will be used if lm_grant is defined and the filesystem can not
  respond to the request immediately.
  For SETLK or SETLKW request it will get the local posix lock.
  In all cases it will move the block to the head of nlm_blocked q where
  nlmsvc_retry_blocked() can send back a reply for SETLKW or revisit the
  deferred rpc for GETLK and SETLK.
  Unblock a blocked lock request. This is a callback invoked from the
  VFS layer when a lock on which we blocked is removed.
  This function doesn't grant the blocked lock instantly, but rather moves
  the block to the head of nlm_blocked where it can be picked up by lockd.
  Try to claim a lock that was previously blocked.
  Note that we use both the RPC_GRANTED_MSG call _and_ an async
  RPC thread when notifying the client. This seems like overkill...
  Here's why:
   -	we don't want to use a synchronous RPC thread, otherwise
 	we might find ourselves hanging on a dead portmapper.
   -	Some lockd implementations (e.g. HP) don't react to
 	RPC_GRANTED calls; they seem to insist on RPC_GRANTED_MSG calls.
 Unlink block request from list 
	 If b_granted is true this means we've been here before.
	  Just retry the grant callback, possibly refreshing the RPC
 Try the lock operation again 
	 vfs_lock_file() can mangle fl_start and fl_end, but we need
	  them unchanged for the GRANT_MSG
 Lock was granted by VFS. 
	 keep block on the list, but don't reattempt until the RPC
	  completes or the submission fails
	 Call the client -- use a soft RPC task since nlmsvc_retry_blocked
	  will queue up a new one if this one times out
 RPC submission failed, wait a bit and retry 
  This is the callback from the RPC layer when the NLM_GRANTED_MSG
  RPC call has succeeded or timed out.
  Like all RPC callbacks, it is invoked by the rpciod process, so it
  better not sleep. Therefore, we put the blocked lock on the nlm_blocked
  chain once more in order to have it removed by lockd itself (which can
  then sleep on the file semaphore without disrupting e.g. the nfs client).
	 if the block is not on a list at this point then it has
	  been invalidated. Don't try to requeue it.
	 
	  FIXME: it's possible that the block is removed from the list
	  after this check but before the nlmsvc_insert_block. In that
	  case it will be added back. Perhaps we need better locking
	  for nlm_blocked?
	 Technically, we should down the file semaphore here. Since we
	  move the block towards the head of the queue only, no harm
 RPC error: Re-insert for retransmission 
 Call was successful, now wait for client callback 
  FIXME: nlmsvc_release_block() grabs a mutex.  This is not allowed for an
  .rpc_release rpc_call_op
  We received a GRANT_RES callback. Try to find the corresponding
  block.
 Try again in a couple of seconds 
		
		  Lock is now held by client, or has been rejected.
		  In both cases, the block should be removed.
 Helper function to handle retry of a deferred block.
  If it is a blocking lock, call grant_blocked.
  For a non-blocking lock or test lock, revisit the request.
  Retry all blocked locks that have been notified. This is where lockd
  picks up locks that can be granted, or grant notifications that must
  be retransmitted.
 SPDX-License-Identifier: GPL-2.0
  linuxfslockdhost.c
  Management for NLM peer hosts. The nlm_host struct is shared
  between client and server implementation. The only reason to
  do so is to reduce code bloat.
  Copyright (C) 1996, Olaf Kirch <okir@monad.swb.de>
 search for server|client 
 address to search for 
 it's length 
 transport to search for
 NLM version to search for 
 remote's hostname 
 it's length 
 use non-priv port 
 network namespace to bind 
  Hash function must work well on big- and little-endian platforms
  Allocate and initialize an nlm_host.  Common to both client and server.
  Destroy an nlm_host and free associated resources
  Caller must hold nlm_host_mutex.
  nlmclnt_lookup_host - Find an NLM host handle matching a remote server
  @sap: network address of server
  @salen: length of server address
  @protocol: transport protocol to use
  @version: NLM protocol version
  @hostname: '\0'-terminated hostname of server
  @noresvport: 1 if non-privileged port should be used
  @net: pointer to net namespace
  @cred: pointer to cred
  Returns an nlm_host structure that matches the passed-in
  [server address, transport protocol, NLM version, server hostname].
  If one doesn't already exist in the host cache, a new handle is
  created and returned.
 Same address. Share an NSM handle if we already have one 
  nlmclnt_release_host - release client nlm_host
  @host: nlm_host to release
  nlmsvc_lookup_host - Find an NLM host handle matching a remote client
  @rqstp: incoming NLM request
  @hostname: name of client host
  @hostname_len: length of client hostname
  Returns an nlm_host structure that matches the [client address,
  transport protocol, NLM version, client hostname] of the passed-in
  NLM request.  If one doesn't already exist in the host cache, a
  new handle is created and returned.
  Before possibly creating a new nlm_host, construct a sockaddr
  for a specific source address in case the local system has
  multiple network addresses.  The family of the address in
  rq_daddr is guaranteed to be the same as the family of the
  address in rq_addr, so it's safe to use the same family for
  the source address.
 Same address. Share an NSM handle if we already have one 
 Move to head of hash chain. 
  nlmsvc_release_host - release server nlm_host
  @host: nlm_host to release
  Host is destroyed later in nlm_gc_host().
  Create the NLM RPC client for an NLM peer
 Lock host handle 
	 If we've already created an RPC client, check whether
	  RPC rebind is required
		
		  lockd retries server side blocks automatically so we want
		  those to be soft RPC calls. Client side calls need to be
		  hard RPC tasks.
  nlm_rebind_host - If needed, force a portmap lookup of the peer's lockd port
  @host: NLM host handle for peer
  This is not needed when using a connection-oriented protocol, such as TCP.
  The existing autobind mechanism is sufficient to force a rebind when
  required, e.g. on connection state transitions.
  Increment NLM host count
  nlm_host_rebooted - Release all resources held by rebooted host
  @net:  network namespace
  @info: pointer to decoded results of NLM_SM_NOTIFY call
  We were notified that the specified host has rebooted.  Release
  all resources held by that peer.
	 Mark all hosts tied to this NSM state as having rebooted.
	  We run the loop repeatedly, because we drop the host table
	  lock for this.
	  To avoid processing a host several times, we match the nsmstate.
 First, make all hosts eligible for gc 
 Then, perform a garbage collection pass 
  Shut down the hosts module.
  Note that this routine is called only at server shutdown time.
  Garbage collect any unused NLM hosts.
  This GC combines reference counting for async operations with
  mark & sweep for resources held by remote clients.
 Mark all hosts that hold locks, blocks or shares 
 SPDX-License-Identifier: GPL-2.0
  Procfs support for lockd
  Copyright (c) 2014 Jeff Layton <jlayton@primarydata.com>
  We only allow strings that start with 'Y', 'y', or '1'.
 SPDX-License-Identifier: GPL-2.0
  QNX6 file system, Linux implementation.
  Version : 1.0.0
  History :
  01-02-2012 by Kai Bankett (chaosman@ontika.net) : first release.
  16-02-2012 pagemap extension by Al Viro
 SPDX-License-Identifier: GPL-2.0
  QNX6 file system, Linux implementation.
  Version : 1.0.0
  History :
  01-02-2012 by Kai Bankett (chaosman@ontika.net) : first release.
 the rest of the superblock is the same 
	 Check the superblock signatures
 checksum check - start at byte 8 and end at byte 512 
 calculate second superblock blocknumber 
 set new blocksize 
 blocksize invalidates bh - pull it back in 
 read second superblock 
 checksum check - start at byte 8 and end at byte 512 
 superblock #1 active 
 superblock #2 active 
 offset for mmi_fs is just SUPERBLOCK_AREA bytes 
 success 
 SPDX-License-Identifier: GPL-2.0-only
  QNX6 file system, Linux implementation.
  Version : 1.0.0
  History :
  01-02-2012 by Kai Bankett (chaosman@ontika.net) : first release.
  16-02-2012 pagemap extension by Al Viro
 logical block is before EOF 
  returns the block number for the no-th element in the tree
  inodebits requred as there are multiple inodes in one inode block
  Check the root directory of the filesystem to make sure
  it really _is_ a qnx6 filesystem, and to check the size
  of the directory entry.
 maximum 3 bytes - due to match_root limitation 
	 Check the superblock signatures
 we got a big endian fs 
 Superblock always is 512 Byte long 
 parse the mount-options 
	 Check the superblock signatures
 try again without bootblock offset 
 seems that no bootblock at partition start 
 checksum check - start at byte 8 and end at byte 512 
 set new blocksize 
 blocksize invalidates bh - pull it back in 
 calculate second superblock blocknumber 
 set bootblock offset 
 next the second superblock 
 checksum check - start at byte 8 and end at byte 512 
 superblock #1 active 
 superblock #2 active 
 sanity check - limit maximum indirect pointer levels 
 Yup, read-only yet 
 ease the later tree level calculations 
 prefetch root inode 
 probably wrong 
 calc blocks based on 512 byte blocksize 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 SPDX-License-Identifier: GPL-2.0
  QNX6 file system, Linux implementation.
  Version : 1.0.0
  History :
  01-02-2012 by Kai Bankett (chaosman@ontika.net) : first release.
  16-02-2012 pagemap extension by Al Viro
 in block units 
 in pages 
 within page 
		 error - long filename entries always have size 0xff
	 calc & validate longfilename checksum
 success 
				 long filename detected
				   get the filename from long filename
  check if the long filename is correct.
  check if the filename is correct.
 short filename 
 deal with long filename 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsfatinode.c
   Written 1992,1993 by Werner Almesberger
   VFAT extensions by Gordon Chaffee, merged with msdos fs by Henrik Storner
   Rewritten for the constant inumbers support by Al Viro
   Fixes:
 	Max Cohan: Fixed invalid FSINFO offset when info_sector is 0
 if user don't select VFAT, this is undefined. 
 DOS dates from 198011 through 21071231 
  A deserialized copy of the on-disk structure laid out in struct
  fat_boot_sector.
	 FIXME: this cluster should be added after data of this
	
	  allocate a cluster according to the following.
	  1) no more available blocks
	  2) not part of fallocate region
 TODO: multiple cluster allocation would be desirable. 
 available blocks on this cluster 
		
		  FIXME: blockdev_direct_IO() doesn't use ->write_begin(),
		  so we need to update the ->mmu_private to block boundary.
		 
		  But we must fill the remaining area or hole by nul for
		  updating ->mmu_private.
		 
		  Return 0, and fallback to normal buffered write.
	
	  FAT need to use the DIO_LOCKING for avoiding the race
	  condition of fat_get_block() and ->truncate().
 fat_get_cluster() assumes the requested blocknr isn't truncated. 
  fat_block_truncate_page() zeroes out a mapping from file offset `from'
  up to the end of the block which corresponds to `from'.
  This is required during truncate to physically zeroout the tail end
  of that block so it doesn't yield old data if the file is later grown.
  Also, avoid causing failure from fsx for cases of "data past EOF"
  New FAT inode stuff. We do the following:
 	a) i_ino is constant and has nothing with on-disk location.
 	b) FAT manages its own cache of directory entries.
 	c) This cache is indexed by on-disk location.
 	d) inode has an associated directory entry, all right, but
 		it may be unhashed.
 	e) currently entries are stored within struct inode. That should
 		change.
 	f) we deal with races in the following way:
 		1. readdir() and lookup() do FAT-dir-cache lookup.
 		2. rename() unhashes the F-d-c entry and rehashes it in
 			a new place.
 		3. unlink() and rmdir() unhash F-d-c entry.
 		4. fat_write_inode() checks whether the thing is unhashed.
 			If it is we silently return. If it isn't we do bread(),
 			check if the location is still valid and retry if it
 			isn't. Otherwise we do changes.
 		5. Spinlock is used to protect hashunhashlocation checklookup
 		6. fat_evict_inode() unhashes the F-d-c entry.
 		7. lookup() and readdir() do igrab() if they find a F-d-c entry
 			and consider negative result as cache miss.
	 If NFS support is enabled, cache the mapping of start cluster
	  to directory inode. This is used during reconnection of
	  dentries to the filesystem root.
 Directory should have "."".." entries at least. 
 Directory should point valid cluster. 
 doesn't deal with root inode 
 not a directory 
 Release unwritten fallocated blocks on inode eviction. 
		 Fallocate results in updating the i_startiogstart
		  for the zero byte file. So, make it return to
		  original state during evict and commit it to avoid
		  any corruption on the next access to the cluster
		  chain for the file.
 do not change any thing if mounted read only 
 do not change state if fs was dirty 
 warn only on set (mount). 
 fat 16 and 12  {
 Note: opts->iocharset can be NULL here 
 Zeroing to allow iput() even if partial initialized inode. 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 make sure we update state on remount. 
 If the count of free cluster is still unknown, counts it here. 
 strip "cp" prefix from displayed option 
 0 or no or false 
 empty or 1 or yes or true 
 0 or no or false 
 empty or 1 or yes or true 
 0 or no or false 
 empty or 1 or yes or true 
 for backward compatibility 
			
			  GMT+-12 zones may have DST corrections so at least
			  13 hours difference is needed. Make the limit 24
			  just in case someone invents something unusual.
 msdos specific 
 vfat specific 
 0 or no or false 
 empty or 1 or yes or true 
 0 or no or false 
 empty or 1 or yes or true 
 0 or no or false 
 negated option 
 empty or 1 or yes or true 
 negated option 
 obsolete mount options 
 unknown option 
 UTF-8 doesn't provide FAT semantics 
 If user doesn't specify allow_utime, it's initialized from dmask. 
 Divide first to avoid overflow 
 Read in BPB ... 
 Validate this looks like a FAT filesystem BPB 
	
	  Earlier we checked here that b->secs_track and b->head are nonzero,
	  but it turns out valid FAT filesystems can have zero there.
 16-bit DOS 1.x reliably wrote bootstrap short-jmp code 
	
	  If any value in this region is non-zero, it isn't archaic
	  DOS.
  Read the super block of an MS-DOS FS.
	
	  GFP_KERNEL is ok here, because while we do hold the
	  superblock lock, memory pressure can't call back into
	  the filesystem, since we're only just about to mount
	  it and have no inodes etc active!
	
	  fat timestamps are complex and truncated by fat itself, so
	  we set 1 here to be fast
 flavour-specific stuff that needs options 
 Verify that the larger boot sector is fully readable 
 Don't know yet 
 Don't know yet 
 Must be FAT32 
 MC - if info_sector is 0, don't multiply by 0 
 interpret volume ID as a little endian 32 bit integer 
 fat 16 or 12 
 some OSes set FAT_STATE_DIRTY and clean it on unmount. 
 fat 16 or 12 
 check that FAT table does not overflow 
 check the free_clusters, it's not necessarily correct 
 check the prev_free, it's not necessarily correct 
 set up enough so that it can read an inode 
	
	  The low byte of the first FAT entry must have the same value as
	  the media field of the boot sector. But in real world, too many
	  devices are writing wrong values. So, removed that validity check.
	 
	  The removed check compared the first FAT entry to a value dependent
	  on the media field like this:
	  == (0x0F00 | media), for FAT12
	  == (0XFF00 | media), for FAT16
	  == (0x0FFFFF | media), for FAT32
 FIXME: utf8 is using iocharset for upperlower conversion 
  helper function for fat_flush_inodes.  This writes both the inode
  and the file data blocks, waiting for in flight data blocks before
  the start of the call.  It does not wait for any io started
  during the call
	 if we used wait=1, sync_inode_metadata waits for the io for the
	 inode to finish.  So wait=0 is sent down to sync_inode_metadata
	 and filemap_fdatawrite is used for the data blocks
  write data and metadata corresponding to i1 and i2.  The io is
  started but we do not wait for any of it to finish.
  filemap_flush is used for the block device, so if there is a dirty
  page for a block already in flight, we will not wait and start the
  io over again
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsfatdir.c
   directory handling functions for fat-based filesystems
   Written 1992,1993 by Werner Almesberger
   Hidden files 1995 by Albert Cahalan <albert@ccs.neu.edu> <adc@coe.neu.edu>
   VFAT extensions by Gordon Chaffee <chaffee@plateau.cs.berkeley.edu>
   Merged with msdos fs by Henrik Storner <storner@osiris.ping.dk>
   Rewritten for constant inumbers. Plugged buffer overrun in readdir(). AV
   Short name translation 1999, 2001 by Wolfram Pienkoss <wp@bszh.de>
  Maximum buffer size of short name.
  [(MSDOS_NAME + '.')  max one char + nul]
  For msdos style, ['.' (hidden) + MSDOS_NAME + '.' + nul]
  Maximum buffer size of unicode chars from slots.
  [(max longname slots  13 (size in a slot) + nul)  sizeof(wchar_t)]
 This is not a first sector of cluster, or sec_per_clus == 1 
 root dir of FAT12FAT16 
 Returns the inode number of the directory entry at offset pos. If bh is
   non-NULL, it is brelse'd before. Pos is incremented. The buffer header is
   returned in bh.
   AV. Most often we do it item-by-item. Makes sense to optimize.
   AV. OK, there we go: if both bh and de are non-NULL we assume that we just
   AV. want the next entry (took one explicit de=NULL in vfatnamei.c).
   AV. It's done in fat_get_entry() (inlined), here the slow case lives.
   AV. Additionally, when we return -1 (i.e. reached the end of directory)
   AV. we make bh NULL.
 beyond EOF or error 
 skip this block 
 Fast stuff first 
  Convert Unicode 16 to UTF-8, translated Unicode, or ASCII.
  If uni_xlate is enabled and we can't get a 1:1 conversion, use a
  colon as an escape character since it is normally invalid on the vfat
  filesystem. The following four characters are the hexadecimal digits
  of Unicode value. This lets us do a full dump and restore of Unicode
  filenames. We could get into some trouble with long Unicode names,
  but ignore that right now.
  Ahem... Stack smashing in ring 0 isn't fun. Fixed.
 a question mark 
 a question mark 
 a question mark 
  fat_parse_long - Parse extended directory entry.
  This function returns zero on success, negative value on error, or one of
  the following:
  %PARSE_INVALID - Directory entry is invalid.
  %PARSE_NOT_LONGNAME - Directory entry does not contain longname.
  %PARSE_EOF - Directory has no more entries.
 ceil(256  2  26) 
  fat_parse_short - Parse MS-DOS (short) directory entry.
  @sb:		superblock
  @de:		directory entry to parse
  @name:	FAT_MAX_SHORT_SIZE array in which to place extracted name
  @dot_hidden:	Nonzero == prepend '.' to names with ATTR_HIDDEN
  Returns the number of characters extracted into 'name'.
	 For an explanation of the special treatment of 0x05 in
	  filenames, see msdos_format_name in namei_msdos.c
 Filename 
 Extension 
  Return values: negative -> errornot found, 0 -> found.
		 Never prepend '.' to hidden files here.
		  That is done only for msdos mounts (and only when
		  'dotsOK=yes'); if we are executing here, it is in the
		  context of a vfat mount.
 Compare shortname 
 Compare longname 
 include the de 
 for dir ioctl 
 Fake . and .. for the root directory. 
	
	  Check for long filename entry, but if short_only, we don't
	  need to parse long filename.
 !both && !short_only, so we don't need shortname. 
 hack for fat_ioctl_filldir() 
 dirent has only short name 			   \
 dirent has short and long name 			   \
	
	  Yes, we don't need this put_user() absolutely. However old
	  code didn't return the right value. So, app use this value,
	  in order to check whether it is EOF.
	
	  Yes, we don't need this put_user() absolutely. However old
	  code didn't return the right value. So, app use this value,
	  in order to check whether it is EOF.
 CONFIG_COMPAT 
 free entry or long name entry or volume label 
  The ".." entry can not provide the "struct fat_slot_info" information
  for inode, nor a usable i_pos. So, this function provides some information
  only.
  Since this function walks through the on-disk inodes within a directory,
  callers are responsible for taking any locks necessary to prevent the
  directory from changing.
 See if directory is empty 
  fat_subdirs counts the number of sub-directories of dir. It can be run
  on directories being created.
  Scans a directory for a given file (name points to its formatted name).
  Returns an error code or zero.
  Scans a directory for a given logstart.
  Returns an error code or zero.
 pos is next de's position, so this does `- sizeof(de)' 
	
	  First stage: Remove the shortname. By this, the directory
	  entry is removed.
		
		  Second stage: remove the remaining longname slots.
		  (This directory entry is already removed, and so return
		  the success)
 Zeroing the unused blocks on this cluster 
 Avoid race with userspace read via bdev 
 Avoid race with userspace read via bdev 
 filling the new directory slots ("." and ".." entries) 
 extra timestamps 
	
	  The minimum cluster size is 512bytes, and maximum entry
	  size is 32slots (672bytes).  So, iff the cluster size is
	  512bytes, we may need two clusters.
	
	  First stage: Fill the directory entry.  NOTE: This cluster
	  is not referenced from any inode yet, so updates order is
	  not important.
 fill the directory entry 
 Avoid race with userspace read via bdev 
 Second stage: clear the rest of cluster, and write outs 
 32slots (672bytes) 
 First stage: search free directory entries 
 check the maximum size of directory 
		
		  Second stage: filling the free entries with new entries.
		  NOTE: If this slots has shortname, first, we write
		  the long name slots, then write the short name.
 Fill the long name slots. 
 Fill the short name slot. 
		
		  Third stage: allocate the cluster for new entries.
		  And initialize the cluster with new entries, then
		  add the cluster to dir.
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsfatmisc.c
   Written 1992,1993 by Werner Almesberger
   22112000 - Fixed fat_date_unix2dos for dates earlier than 01011980
 		 and date_dos2unix for date==0 by Igor Zhbanov(bsg@uniyar.ac.ru)
  fat_fs_error reports a file system problem that might indicate fa data
  corruptioninconsistency. Depending on 'errors' mount option the
  panic() is called, or error message is printed FAT and nothing is done,
  or filesystem is remounted read-only (default behavior).
  In case the file system is remounted read-only, it can be made writable
  again by remounting it.
  fat_msg() - print preformated FAT specific messages. Every thing what is
  not fat_fs_error() should be fat_msg().
 Flushes the number of free clusters on FAT32 
 XXX: Need to write one per FSINFO block.  Currently only writes 1 
 Sanity check 
  fat_chain_add() adds a new cluster to the chain of clusters represented
  by inode.
	
	  We must locate the last cluster of the file to add this new
	  one (new_dclus) to the end of the link list (the FAT).
 add new one to the last of the cluster chain 
		
		  FIXME:Although we can add this cache, fat_cache_add() is
		  assuming to be called after linear search with fat_cache_id.
		fat_cache_add(inode, new_fclus, new_dclus);
		
		  Since generic_write_sync() synchronizes regular files later,
		  we sync here only directories.
  The epoch of FAT timestamp is 1980.
      :  bits :     value
  date:  0 -  4: day	(1 -  31)
  date:  5 -  8: month	(1 -  12)
  date:  9 - 15: year	(0 - 127) from 1980
  time:  0 -  4: sec	(0 -  29) 2sec counts
  time:  5 - 10: min	(0 -  59)
  time: 11 - 15: hour	(0 -  23)
 days between 1.1.70 and 1.1.80 (2 leap days) 
 120 (2100 - 1980) isn't leap year 
 Linear day numbers of the respective 1sts in non-leap years. 
 Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec 
 Convert a FAT timedate pair to a UNIX date (seconds since 1 1 70). 
 2100 isn't leap year 
 Export fat_time_fat2unix() for the fat_test KUnit tests. 
 Convert linear UNIX date to a FAT timedate pair. 
  FAT can only support year between 1980 to 2107 
 from 1900 -> from 1980 
 0~11 -> 1~12 
 0~59 -> 0~29(2sec counts) 
  truncate the various times with appropriate granularity:
    root inode:
      all times always 0
    all other inodes:
      mtime - 2 seconds
      ctime
        msdos - 2 seconds
        vfat  - 10 milliseconds
      atime - 24 hours (00:00:00 in local timezone)
 to localtime 
 to day boundary, and back to unix time 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsfatfile.c
   Written 1992,1993 by Werner Almesberger
   regular file handling primitives for fat-based filesystems
	
	  ATTR_VOLUME and ATTR_DIR cannot be changed; this also
	  prevents the user from turning us into a VFAT
	  longname entry.  Also, we obviously can't set
	  any of the NTFS attributes in the high 24 bits.
 Merge in ATTR_VOLUME and ATTR_DIR 
 Equivalent to a chmod() 
 The root directory has no attributes 
	
	  The security check is questionable...  We single
	  out the RO attribute for checking by the security
	  module, just because it maps to a file mode.
 This MUST be done before doing anything irreversible... 
 Inappropriate ioctl for device 
		
		  Opencode syncing since we don't have a file open to use
		  standard fsync path.
  Preallocate space for a file. This implements fat's fallocate file
  operation, which gets called from sys_fallocate system call. User
  space requests len bytes at offset. If FALLOC_FL_KEEP_SIZE is set
  we just allocate clusters without zeroing them out. Otherwise we
  allocate and zero out clusters via an expanding truncate.
 Number of clusters to be allocated 
 Number of bytes to be allocated for file 
 block aligned on-disk size in bytes
 No support for hole punch or other fallocate flags. 
 No support for dir 
 First compute the number of clusters to be allocated 
 Start the allocation.We are not zeroing out the clusters 
 This is just an expanding truncate 
 Free all clusters after the skip'th cluster. 
 First, we write the new file size. 
 Write a new EOF, and get the remaining cluster chain for freeing. 
 Freeing the remained cluster chain 
	
	  This protects against truncating a file bigger than it was then
	  trying to write into the hole.
 Use i_pos for ino. This is used as fileid of nfs. 
	
	  Note, the basic check is already done by a caller of
	  (attr->ia_mode & ~FAT_VALID_MODE)
	
	  Of the r and x bits, all (subject to umask) must be present. Of the
	  w bits, either all (subject to umask) or none must be present.
	 
	  If fat_mode_can_hold_ro(inode) is false, can't change w bits.
 use a default check 
 valid file mode bits 
 Check for setting the inode time. 
	
	  Expand the file. Since inode_setattr() updates ->i_size
	  before calling the ->truncate(), but FAT needs to fill the
	  hole before it. XXX: this is no longer true with new truncate
	  sequence.
	
	  We don't return -EPERM here. Yes, strange, but this is too
	  old behavior.
	
	  setattr_copy can't truncate these appropriately, so we'll
	  copy them ourselves
 SPDX-License-Identifier: GPL-2.0-only
 fsfatnfs.c
  Look up a directory inode given its starting cluster.
		 If a file is deleted on server and client is not updated
		  yet, we must not build the inode upon a lookup call.
  Map a NFS file handle to a corresponding dentry.
  The dentry may or may not be connected to the filesystem root.
  Find the parent for a file specified by NFS handle.
  This requires that the handle contain the i_ino of the parent.
  Rebuild the parent for a directory that is not connected
   to the filesystem root
  Find the parent for a directory that is not currently connected to
  the filesystem root.
  On entry, the caller holds d_inode(child_dir)->i_mutex.
 SPDX-License-Identifier: GPL-2.0
   linuxfsfatcache.c
   Written 1992,1993 by Werner Almesberger
   Mar 1999. AV. Changed cache, so that it uses the starting cluster instead
 	of inode number.
   May 1999. AV. Fixed the bogosity with FAT32 (read "FAT28"). Fscking lusers.
 this must be > 0. 
 number of contiguous clusters 
 cluster number in the file. 
 cluster number on disk. 
 Find the cache of "fclus" or nearest cache. 
 Find the same part as "new" in cluster-chain. 
 dummy cache 
 this cache was invalidated 
  Cache invalidation occurs rarely, thus the LRU chain is not updated. It
  fixes itself after a while.
 Update. The copy of caches before this id is discarded. 
		
		  dummy, always not contiguous
		  This is reinitialized by cache_init(), later.
 prevent the infinite loop of cluster chain 
		
		  ->mmu_private can access on only allocation path.
		  (caller must hold ->i_mutex)
 SPDX-License-Identifier: GPL-2.0
  KUnit tests for FAT filesystems.
  Copyright (C) 2020 Google LLC.
  Author: David Gow <davidgow@google.com>
 With no extension. 
 With 3-letter extension. 
 With short (1-letter) extension. 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsvfatnamei.c
   Written 1992,1993 by Werner Almesberger
   Windows95Windows NT compatible extended MSDOS filesystem
     by Gordon Chaffee Copyright (C) 1995.  Send bug reports for the
     VFAT filesystem to <chaffee@cs.berkeley.edu>.  Specify
     what file operation caused you trouble and if you can duplicate
     the problem, send a script that demonstrates it.
   Short name translation 1999, 2001 by Wolfram Pienkoss <wp@bszh.de>
   Support Multibyte characters and cleanup by
 				OGAWA Hirofumi <hirofumi@mail.parknet.co.jp>
  If new entry was created in the parent, it could create the 8.3
  alias (the shortname of logname).  So, the parent may have the
  negative-dentry which matches the created 8.3 alias.
  If it happened, the negative dentry isn't actually negative
  anymore.  So, drop it.
 This is not negative dentry. Always valid. 
	
	  This is not negative dentry. Always valid.
	 
	  Note, rename() to existing directory entry will have ->d_inode,
	  and will use existing name which isn't specified name by user.
	 
	  We may be able to drop this positive dentry here. But dropping
	  positive dentry isn't good idea. So it's unsupported like
	  rename("filename", "FILENAME") for now.
	
	  This may be nfsd (or something), anyway, we can't see the
	  intent of this. So, since this can be for creation, drop it.
	
	  Drop the negative dentry, in order to make sure to use the
	  case sensitive name which is specified by user if this is
	  for creation.
 returns the length of a struct qstr, ignoring trailing dots 
  Compute the hash for the vfat name corresponding to the dentry.
  Note: if the name is invalid, we leave the hash code unchanged so
  that the existing dentry can be used. The vfat fs routines will
  return ENOENT or EINVAL as appropriate.
  Compute the hash for the vfat name corresponding to the dentry.
  Note: if the name is invalid, we leave the hash code unchanged so
  that the existing dentry can be used. The vfat fs routines will
  return ENOENT or EINVAL as appropriate.
  Case insensitive compare of two vfat names.
 A filename cannot end in '.' or we treat it like it has none 
  Case sensitive compare of two vfat names.
 A filename cannot end in '.' or we treat it like it has none 
 Characters that are undesirable in an MS-DOS file name 
 last character cannot be space 
  1) Valid characters for the 8.3 format alias are any combination of
  letters, uppercase alphabets, digits, any of the
  following special characters:
      $ % ' ` - @ { } ~ ! # ( ) & _ ^
  In this case Longfilename is not stored in disk.
  WinNT's Extension:
  File name and extension name is contain uppercaselowercase
  only. And it is expressed by CASE_LOWER_BASE and CASE_LOWER_EXT.
  2) File name is 8.3 format, but it contain the uppercase and
  lowercase char, muliti bytes char, etc. In this case numtail is not
  added, but Longfilename is stored.
  3) When the one except for the above, or the following special
  character are contained:
         .   [ ] ; , + =
  numtail is added, and Longfilename must be stored in disk .
  Given a valid longname, create a unique shortname.  Make sure the
  shortname does not exist
  Returns negative number on error, 0 for a normal
  return, and 1 for valid shortname
 Now, we need to create a shortname from the long name 
 is `.' 
		
		  Names which start with a dot could be just
		  an extension eg. "...test".  In this case Win95
		  uses the extension as the name and sets no extension.
 Yes, it can happen. ".\xe5" would do it. 
	 OK, at this point we know that base is not longer than 8 symbols,
	  ext is not longer than 3, base is nonempty, both don't contain
	  any bad symbols (lowercase transformed to uppercase).
	
	  Try to find a unique extension.  This used to
	  iterate through all possibilities sequentially,
	  but that gave extremely bad performance.  Windows
	  only tries a few cases before using random
	  values for part of the base.
 Translate a string, including coded sequences into Unicode 
 build the entry of long file name 
 build the entry of 8.3 alias name 
 update timestamp 
	
	  Checking "alias->d_parent == dentry->d_parent" to make sure
	  FS is not corrupted (especially double linked dir).
		
		  This inode has non anonymous-DCACHE_DISCONNECTED
		  dentry. This means, the user did ->lookup() by an
		  another name (longname vs 8.3 alias of it) in past.
		 
		  Switch to new one for reason of locality if possible.
 timestamp is already written, so mark_inode_dirty() is unneeded. 
 and releases bh 
 and releases bh 
 the directory was completed, just return a error 
 timestamp is already written, so mark_inode_dirty() is unneeded. 
 and releases bh 
 data cluster is shared, serious corruption 
		
		  If new entry was not sharing the data cluster, it
		  shouldn't be serious corruption.
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsmsdosnamei.c
   Written 1992,1993 by Werner Almesberger
   Hidden files 1995 by Albert Cahalan <albert@ccs.neu.edu> <adc@coe.neu.edu>
   Rewritten for constant inumbers 1999 by Al Viro
 Characters that are undesirable in an MS-DOS file name 
 Formats an MS-DOS file name. Rejects invalid names. 
	
	  name is the proposed name, len is its length, res is
	  the resulting name, opts->name_check is either (r)elaxed,
	  (n)ormal or (s)trict, opts->dotsOK allows dots at the
	  beginning of name (for hidden files)
 dotfile because . and .. already done 
 Get rid of dot - test for it elsewhere 
	
	  disallow names that _really_ start with a dot
	
	  0xE5 is legal as a first character, but we must substitute
	  0x05 because 0xE5 marks deleted files.  Yes, DOS really
	  does this.
	  It seems that Microsoft hacked DOS to support non-US
	  characters after the 0xE5 character was already in use to
	  mark deleted files.
 Locates a directory entry.  Uses unformatted name. 
  Compute the hash for the msdos name corresponding to the dentry.
  Note: if the name is invalid, we leave the hash code unchanged so
  that the existing dentry can be used. The msdos fs routines will
  return ENOENT or EINVAL as appropriate.
  Compare two msdos names. If either of the names are invalid,
  we fall back to doing the standard name comparison.
  AV. Wrappers for FAT sb operations. Is it wise?
 Get inode using directory and name 
 Creates a directory entry (name is already formatted). 
 Create a file 
 Have to do it due to foo vs. .foo conflicts 
 timestamp is already written, so mark_inode_dirty() is unneeded. 
 Remove a directory 
 and releases bh 
 Make a directory 
 foo vs .foo situation 
 the directory was completed, just return a error 
 timestamp is already written, so mark_inode_dirty() is unneeded. 
 Unlink a file 
 and releases bh 
 "foo" -> ".foo" case. just change the ATTR_HIDDEN 
 and releases bh 
 data cluster is shared, serious corruption 
		
		  If new entry was not sharing the data cluster, it
		  shouldn't be serious corruption.
 Rename, a wrapper for rename_same_dir & rename_diff_dir 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) 2004, OGAWA Hirofumi
 This entry is block boundary, it needs the next block 
 Is this fatent's blocks including this entry? 
 This entry is on bhs[0]. 
 This entry needs the next block. 
 FIXME: We can write the blocks as more big chunk. 
 Avoid race with userspace read via bdev 
 fixed limit 
 Find the free entries in a block 
 make the cluster chain 
				
				  fat_collect_bhs() gets ref-count of bhs,
				  so we can still use the prev_ent.
 Couldn't allocate the free entries 
			
			  Issue discard for the sectors we no longer
			  care about, batching contiguous clusters
			  into one request
	
	  This is the sequential read, so ra_pages  2 (but try to
	  align the optimal hardware IO size).
	  [BTW, 128kb covers the whole sectors for FAT12 and FAT16]
 Initialize the range for sequential read 
 Advancing the window at half size 
 Assuming to be called before reading a new block (increments ->cur). 
		
		  FIXME: we would want to directly use the bio with
		  pages to reduce the number of segments.
 Advance the readahead window 
 readahead of fat blocks 
	
	  FAT data is organized as clusters, trim at the granulary of cluster.
	 
	  fstrim_range is in byte, convert values to cluster index.
	  Treat sectors before data region as all used, not to trim them.
 readahead of fat blocks 
 handle scenario when tail entries are all free 
 SPDX-License-Identifier: GPL-2.0
   linuxfsisofsnamei.c
   (C) 1992  Eric Youngdale Modified for ISO 9660 filesystem.
   (C) 1991  Linus Torvalds - minix filesystem
  ok, we cannot use strncmp, as the name is not in our data space.
  Thus we'll have to use isofs_match. No big problem. Match also makes
  some sanity tests.
 	isofs_find_entry()
  finds an entry in the specified directory with the wanted name. It
  returns the inode number of the found entry, or 0 on error.
 Make sure we have a full directory entry 
 Basic sanity check, whether name doesn't exceed dir entry 
 possibly -1 
		
		  Skip hidden or associated files unless hide or showassoc,
		  respectively, is set
 SPDX-License-Identifier: GPL-2.0
   linuxfsisofsjoliet.c
   (C) 1996 Gordon Chaffee
   Joliet: Microsoft's Unicode extensions to iso9660
  Convert Unicode 16 to UTF-8 or ASCII.
	
	  Windows doesn't like periods at the end of a name,
	  so neither do we
 SPDX-License-Identifier: GPL-2.0-or-later
 -- linux-c -- ------------------------------------------------------- 
    Copyright 2001 H. Peter Anvin - All Rights Reserved
  linuxfsisofscompress.c
  Transparent decompression of files on an iso9660 filesystem
 This should probably be global. 
  This contains the zlib memory allocation and the mutex for the
  allocation; this avoids failures at block-decompression time.
  Read data of @inode from @block_start to @block_end and uncompress
  to one zisofs block. Store the data in the @pages array with @pcount
  entries. Start storing at offset @poffset of the first page.
 Empty block? 
 Because zlib is not thread-safe, do all the IO at the top. 
	
	  First block is special since it may be fractional.  We also wait for
	  it before grabbing the zlib mutex; odds are that the subsequent
	  blocks are going to come in in short order so we don't hold the zlib
	  mutex longer than necessary.
 EOF, error, or trying to read beyond end of input 
 This page completed 
  Uncompress data so that pages[full_page] is fully uptodate and possibly
  fills in other pages if we have data for them.
	
	  We want to read at least 'full_page' page. Because we have to
	  uncompress the whole compression block anyway, fill the surrounding
	  pages with the data we have anyway...
 Find the pointer to this specific chunk 
 Note: we're not using isonum_731() here because the data is known aligned 
 Note: header_size is in 32-bit words (4 bytes) 
 Load end of the compressed block in the file 
 Traversed to next block? 
			
			  Did we finish reading the page we really wanted
			  to read?
  When decompressing, we typically obtain more than one page
  per reference.  We inject the additional pages into the page
  cache as a form of readahead.
	
	  If this page is wholly outside i_size we just return zero;
	  do_generic_file_read() will handle this for us
		 We have already been given one page, this is the one
 Release any residual pages, do not SetPageUptodate 
 At this point, err contains 0 or -EIO depending on the "critical" page 
 No bmap operation supported 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsisofsinode.c
   (C) 1991  Linus Torvalds - minix filesystem
       1992, 1993, 1994  Eric Youngdale Modified for ISO 9660 filesystem.
       1994  Eberhard Mnkeberg - multi session handling.
       1995  Mark Dobie - allow mounting of some weird VideoCDs and PhotoCDs.
 	1997  Gordon Chaffee - Joliet CDs
 	1998  Eric Lammerts - ISO 9660 Level 3
 	2004  Paul Serice - Inode Support pushed out from 4GB to 128GB
 	2004  Paul Serice - NFS Export Operations
 max tz offset is 13 hours 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 LVE 
  Compute the hash for the isofs name corresponding to the dentry.
  Compare of two isofs names.
 A filename cannot end in '.' or we treat it like it has none 
  Compute the hash for the isofs name corresponding to the dentry.
 unset 
			
			  Track numbers are supposed to be in range 1-99, the
			  mount option starts indexing at 0.
  Display the mount options in procmounts.
  look if the driver can tell the multi session redirection value
  don't change this if you don't know what you do, please!
  Multisession is legal only with XA disks.
  A non-XA disk with more than one volume descriptor may do it right, but
  usually is written in a nowhere standardized "multi-partition" manner.
  Multisession uses absolute addressing (solely the first frame of the whole
  track is #0), multi-partition uses relative addressing (each first frame of
  each track is #0), and a track is not a session.
  A broken CDwriter software or drive firmware does not set new standards,
  at least not if conflicting with the existing ones.
  emoenke@gwdg.de
 necessary for a valid ms_info.addr 
  Check if root directory is empty (has less than 3 files).
  Used to detect broken CDs where ISO root directory is empty but Joliet root
  directory is OK. If such CD has Rock Ridge extensions, they will be disabled
  (and Joliet used instead) or else no files would be visible.
  Initialize the superblock and read the root inode.
	
	  First of all, get the hardware blocksize for this device.
	  If we don't know what it is, or the hardware blocksize is
	  larger than the blocksize the user specified, then use
	  that value.
	
	  What if bugger tells us to go beyond page size?
 default is iso9660 
		
		  Due to the overlapping physical location of the descriptors,
		  ISO CDs can match hdp->id==HS_STANDARD_ID as well. To ensure
		  proper identification in this case, we first check for ISO.
 Save the buffer in case we need it ... 
 Unknown supplementary volume descriptor 
 Just skip any volume descriptors we don't recognize 
	
	  If we fall through, either no volume descriptor was found,
	  or else we passed a primary descriptor looking for others.
 We don't support read-write mounts 
		 This is the case of Joliet with the norock mount flag.
		  A disc with both Joliet and Rock Ridge is handled later
 No way to figure this out easily 
	
	  If the zone size is smaller than the hardware sector size,
	  this is a fatal error.  This would occur if the disc drive
	  had sectors that were 2048 bytes, but the filesystem had
	  blocks that were 512 bytes (which should only very rarely
	  happen.)
 RDE: convert log zone size to bit shift 
	
	  With multi-extent files, file size is only limited by the maximum
	  size of a file system, which is 8 TB.
 ECMA-119 timestamp from 190011 with tz offset 
	 Set this for reference. Its not currently used except on write
	
	  If the Joliet level is set, we _may_ decide to use the
	  secondary descriptor, but can't be sure until after we
	  read the root inode. But before reading the root inode
	  we may need to change the device blocksize, and would
	  rather release the old buffer first. So, we cache the
	  first_data_zone value from the secondary descriptor.
	
	  We're all done using the volume descriptor, and may need
	  to change the device blocksize, so release the buffer now.
	
	  Force the blocksize to 512 for 512 byte sectors.  The file
	  read primitives really get it wrong in a bad way if we don't
	  do this.
	 
	  Note - we should never be setting the blocksize to something
	  less than the hardware sector size for the device.  If we
	  do, we would end up having to read larger buffers and split
	  out portions to satisfy requests.
	 
	  Note2- the idea here is that we want to deal with the optimal
	  zonesize in the filesystem.  If we have it set to something less,
	  then we have horrible problems with trying to piece together
	  bits of adjacent blocks in order to properly read directory
	  entries.  By forcing the blocksize in this way, we ensure
	  that we will never be required to do this.
 initial offset, will guess until SP is found
	
	  It would be incredibly stupid to allow people to mark every file
	  on the disk as suid, so we merely allow them to set the default
	  permissions.
	
	  Read the root inode, which _may_ result in changing
	  the s_rock flag. Once we have the final s_rock value,
	  we then decide whether to use the Joliet descriptor.
	
	  Fix for broken CDs with Rock Ridge and empty ISO root directory but
	  correct Joliet root directory.
	
	  If this disk has both Rock Ridge and Joliet on it, then we
	  want to use Rock Ridge by default.  This can be overridden
	  by using the norock mount option.  There is still one other
	  possibility that is not taken into account: a Rock Ridge
	  CD with Unicode names.  Until someone sees such a beast, it
	  will not be supported.
 Only Joliet is case insensitive by default 
 Make sure the root inode is a directory 
 get the root dentry 
	
	  Display error messages and free resources.
  Get a set of blocks; filling in buffer_heads if already allocated
  or getblk() if they are not.  Returns the number of blocks inserted
  (-ve == error.)
		 If we are way beyond the end of the file, print a message.
		  Access beyond the end of the file up to the next page boundary
		  is normal, however because of the way the page cache works.
		  In this case, we just return 0 so that we can properly fill
		  the page with useless information without generating any
		  IO errors.
		 On the last section, nextblk == 0, section size is likely to
		  exceed sect_size by a partial block, and access beyond the
		  end of the file will reach beyond the section size, too.
 Next buffer head 
 Next buffer offset 
  Used by the standard interfaces.
	 The first 16 blocks are reserved as the System Area.  Thus,
	  no inodes can appear in block 0.  We use this to flag that
 Make sure we have a full directory entry 
 Assume it is a normal-format file unless told otherwise 
		set_nlink(inode, 1);	
					  Set to 1.  We know there are 2, but
					  the find utility tries to optimize
					  if it is 2, and it screws up.  It is
					  easier to give 1 which tells find to
					  do it the hard way.
			
			  Set default permissions: r-x for all.  The disc
			  could be shared with DOS machines so virtually
			  anything could be a valid executable.
	
	  Some dipshit decided to store some other bit of information
	  in the high byte of the file length.  Truncate size in case
	  this CDROM was mounted with the cruft option.
	 I have no idea what file_unit_size is used for, so
	 I have no idea what other flag bits are used for, so
 Set the number of blocks for stat() - should be done before RR 
	
	  Now test for possible Rock Ridge extensions which will override
	  some of these numbers in the inode structure.
 if we want uidgid set, override the rock ridge setting 
 Now set final access rights if overriding rock ridge setting 
 Install the inode operations vector 
 XXX - parse_rock_ridge_inode() had already set i_rdev. 
 Store, in the inode's containing structure, the block and block
  offset that point to the underlying meta-data for the inode.  The
  code below is otherwise similar to the iget() code in
 SPDX-License-Identifier: GPL-2.0
   linuxfsisofsdir.c
   (C) 1992, 1993, 1994  Eric Youngdale Modified for ISO 9660 filesystem.
   (C) 1991  Linus Torvalds - minix filesystem
   Steve Beynon		       : Missing last directory entries fixed
   (stephen@askone.demon.co.uk)      : 21st June 1996
   isofs directory handling functions
 lower case 
 Drop trailing '.;1' (ISO 9660:1988 7.5.1 requires period) 
 Drop trailing ';1' 
 Convert remaining ';' to '.' 
 Also '' to '.' (broken Acorn-generated ISO9660 images) 
 Acorn extensions written by Matthew Wilcox <willy@infradead.org> 1998 
  This should _really_ be cleaned up some day..
 Quiet GCC 
 Quiet GCC 
		
		  If the length byte is zero, we should move on to the next
		  CDROM sector.  If we are at the end of the directory, we
		  kick out of the while loop.
 Make sure we have a full directory entry 
 Basic sanity check, whether name doesn't exceed dir entry 
 Handle the case of the '.' directory 
 Handle the case of the '..' directory 
		 Handle everything else.  Do name translation if there
		
		  Do not report hidden files if so instructed, or associated
		  files unless instructed to do so
 may be -1 
  Handle allocation of temporary space for name translation and
  handling split directory entries.. The real work is done by
  "do_isofs_readdir()".
  directories can handle most operations...
 SPDX-License-Identifier: GPL-2.0
   linuxfsisofsrock.c
   (C) 1992, 1993  Eric Youngdale
   Rock Ridge Extensions to iso9660
  These functions are designed to read the system areas of a directory record
  and extract relevant information.  There are different functions provided
  depending upon what information we need at the time.  One function fills
  out an inode structure, a second one extracts a filename, a third one
  returns a symbolic link name, and a fourth one returns the extent number
  for the file.
 isonum_721() 
  This is a way of ensuring that we have something in the system
  use fields that is compatible with Rock Ridge.  Return zero on success.
 Maximum number of Rock Ridge continuation entries 
  Returns 0 if the caller should continue scanning, 1 if the scan must end
  and -ve on error.
  We think there's a record of type `sig' at rs->chr.  Parse the signature
  and make sure that there's really room for a record of that type.
  return length of name field; 0: not found, -1: to be ignored
 There may be one byte for padding somewhere 
		
		  Ignore rock ridge info if rr->len is out of range, but
		  don't return -EIO because that would make the file
		  invisible.
 Something got screwed up here 
		
		  As above, just ignore the rock ridge info if rr->len
		  is bogus.
 Something got screwed up here 
			
			  If the flags are 2 or 4, this indicates '.' or '..'.
			  We don't want to do anything with this, because it
			  screws up the code that calls us.  We don't really
			  care anyways, since we can just use the non-RR
			  name.
 If 0, this file did not have a NM field 
 There may be one byte for padding somewhere 
		
		  Ignore rock ridge info if rr->len is out of range, but
		  don't return -EIO because that would make the file
		  invisible.
 Something got screwed up here 
		
		  As above, just ignore the rock ridge info if rr->len
		  is bogus.
 Something got screwed up here 
 No flag for SF or ZF 
 Invalid length of ER tag id? 
				
				  The Rock Ridge standard specifies that if
				  sizeof(dev_t) <= 4, then the high field is
				  unused, and the device number is completely
				  stored in the low field.  Some writers may
				  ignore this subtlety,
				  and as a result we test to see if the entire
				  device number is
				  stored in the low field, and use that.
			
			  Some RRIP writers incorrectly place ctime in the
			  TF_CREATE field. Try to handle this correctly for
			  either case.
 Rock ridge never appears on a High Sierra disk 
					
					  If this component record isn't
					  continued, then append a ''.
					
					  Note: we don't change
					  i_blocks here
					
					  Parameters to compression
					  algorithm (header size,
					  block size)
			
			  If there is another SL record, and this component
			  record isn't continued, then add a slash.
		
		  If this component record isn't continued, then append a ''.
	
	  if rockridge flag was reset and we didn't look for attributes
	  behind eventual XA attributes, have a look there
  readpage() for symlinks: reads symlink contents into the page and either
  makes it uptodate and returns 0 or returns error (-EIO)
	
	  If we go past the end of the buffer, there is some sort of error.
	
	  Now test for possible Rock Ridge extensions which will override
	  some of these numbers in the inode structure.
 There may be one byte for padding somewhere 
 Something got screwed up here 
 corrupted isofs 
 This tells is if there is a continuation record 
 error exit from macro 
 SPDX-License-Identifier: GPL-2.0
   linuxfsisofsutil.c
  We have to convert from a MMDDYY format to the Unix ctime format.
  We have to take into account leap years and all of that good stuff.
  Unfortunately, the kernel does not have the information on hand to
  take into account daylight savings time, but it shouldn't matter.
  The time stored should be localtime (with or without DST in effect),
  and the timezone offset should hold the offset required to get back
  to GMT.  Thus  we should always be correct.
 High sierra has no time zone 
 sign extend 
		 
		  The timezone offset is unreliable on some disks,
		  so we make a sanity check.  In no case is it ever
		  more than 13 hours from GMT, which is 5215min.
		  The time is always stored in localtime with the
		  timezone offset being what get added to GMT to
		  get to localtime.  Thus we need to subtract the offset
		  to get to true GMT, which is what we store the time
		  as internally.  On the local system, the user may set
		  their timezone any way they wish, of course, so GMT
		  gets converted back to localtime on the receiving
		  system.
		 
		  NOTE: mkisofs in versions prior to mkisofs-1.10 had
		  the sign wrong on the timezone offset.  This has now
		  been corrected there too, but if you are getting screwy
		  results this may be the explanation.  If enough people
		  complain, a user configuration option could be added
		  to add the timezone offset in with the wrong sign
		  for 'compatibility' with older discs, but I cannot see how
		  it will matter that much.
		 
		  Thanks to kuhlmav@elec.canterbury.ac.nz (Volker Kuhlmann)
		  for pointing out the sign error.
 SPDX-License-Identifier: GPL-2.0
  fsisofsexport.c
   (C) 2004  Paul Serice - The new inode scheme requires switching
                           from iget() to iget5_locked() which means
                           the NFS export operations have to be hand
                           coded because the default routines rely on
                           iget().
  The following files are helpful:
      Documentationfilesystemsnfsexporting.rst
      fsexportfsexpfs.c.
 This function is surprisingly simple.  The trick is understanding
  that "child" is always a directory. So, to find its parent, you
  simply need to find its ".." entry, normalize its block and offset,
  and return the underlying inode.  See the comments for
 "child" must always be a directory. 
	 It is an invariant that the directory offset is zero.  If
	  it is not zero, it means the directory failed to be
	 The child inode has been normalized such that its
	  i_iget5_block value points to the "." entry.  Fortunately,
 Get the block in question. 
 This is the "." entry. 
 The ".." entry is always the second entry. 
 Verify it is in fact the ".." entry. 
 Normalize 
	
	  WARNING: max_len is 5 for NFSv2.  Because of this
	  limitation, we use the lower 16 bits of fh32[1] to hold the
	  offset of the inode and the upper 16 bits of fh32[1] to
	  hold the offset of the parent.
 fh16 [sic] 
 avoid leaking uninitialized data 
 fh16 [sic] 
 SPDX-License-Identifier: GPL-2.0-only
  fsnfs_commonnfsacl.c
   Copyright (C) 2002-2003 Andreas Gruenbacher <agruen@suse.de>
  The Solaris nfsacl protocol represents some ACLs slightly differently
  than POSIX 1003.1e draft 17 does (and we do):
   - Minimal ACLs always have an ACL_MASK entry, so they have
     four instead of three entries.
   - The ACL_MASK entry in such minimal ACLs always has the same
     permissions as the ACL_GROUP_OBJ entry. (In extended ACLs
     the ACL_MASK and ACL_GROUP_OBJ entries may differ.)
   - The identifier fields of the ACL_USER_OBJ and ACL_GROUP_OBJ
     entries contain the identifiers of the owner and owning group.
     (In POSIX ACLs we always set them to ACL_UNDEFINED_ID).
   - ACL entries in the kernel are kept sorted in ascending order
     of (e_tag, e_id). Solaris ACLs are unsorted.
 Solaris depends on that! 
  nfsacl_encode - Encode an NFSv3 ACL
  @buf: destination xdr_buf to contain XDR encoded ACL
  @base: byte offset in xdr_buf where XDR'd ACL begins
  @inode: inode of file whose ACL this is
  @acl: posix_acl to encode
  @encode_entries: whether to encode ACEs as well
  @typeflag: ACL type: NFS_ACL_DEFAULT or zero
  Returns size of encoded ACL in bytes or a negative errno value.
		 Avoid the use of posix_acl_alloc().  nfsacl_encode() is
		  invoked in contexts where a memory allocation failure is
		  fatal.  Fortunately this fake ACL is small enough to
		 Insert entries in canonical order: other orders seem
 ACL_USER_OBJ 
 ACL_GROUP_OBJ 
 ACL_MASK 
 ACL_OTHER 
  nfs_stream_encode_acl - Encode an NFSv3 ACL
  @xdr: an xdr_stream positioned to receive an encoded ACL
  @inode: inode of file whose ACL this is
  @acl: posix_acl to encode
  @encode_entries: whether to encode ACEs as well
  @typeflag: ACL type: NFS_ACL_DEFAULT or zero
  Return values:
    %false: The ACL could not be encoded
    %true: @xdr is advanced to the next available position
		 Avoid the use of posix_acl_alloc().  nfsacl_encode() is
		  invoked in contexts where a memory allocation failure is
		  fatal.  Fortunately this fake ACL is small enough to
		 Insert entries in canonical order: other orders seem
 ACL_USER_OBJ 
 ACL_GROUP_OBJ 
 ACL_MASK 
 ACL_OTHER 
 Solaris sometimes sets additional bits in the mask 
  Convert from a Solaris ACL to a POSIX 1003.1e draft 17 ACL.
 Find the ACL_GROUP_OBJ and ACL_MASK entries. 
 remove bogus ACL_MASK entry 
  nfsacl_decode - Decode an NFSv3 ACL
  @buf: xdr_buf containing XDR'd ACL data to decode
  @base: byte offset in xdr_buf where XDR'd ACL begins
  @aclcnt: count of ACEs in decoded posix_acl
  @pacl: buffer in which to place decoded posix_acl
  Returns the length of the decoded ACL in bytes, or a negative errno value.
  nfs_stream_decode_acl - Decode an NFSv3 ACL
  @xdr: an xdr_stream positioned at an encoded ACL
  @aclcnt: OUT: count of ACEs in decoded posix_acl
  @pacl: OUT: a dynamically-allocated buffer containing the decoded posix_acl
  Return values:
    %false: The encoded ACL is not valid
    %true: @pacl contains a decoded ACL, and @xdr is advanced
  On a successful return, caller must release pacl using posix_acl_release().
 SPDX-License-Identifier: GPL-2.0-only
  Helper for knfsd's SSC to access ops in NFS client modules
  Author: Dai Ngo <dai.ngo@oracle.com>
  Copyright (c) 2020, Oracle andor its affiliates.
  nfs42_ssc_register - install the NFS_V4 client ops in the nfs_ssc_client_tbl
  @ops: NFS_V4 ops to be installed
  Return values:
    None
  nfs42_ssc_unregister - uninstall the NFS_V4 client ops from
 				the nfs_ssc_client_tbl
  @ops: ops to be uninstalled
  Return values:
    None
 CONFIG_NFS_V4_2 
  nfs_ssc_register - install the NFS_FS client ops in the nfs_ssc_client_tbl
  @ops: NFS_FS ops to be installed
  Return values:
    None
  nfs_ssc_unregister - uninstall the NFS_FS client ops from
 				the nfs_ssc_client_tbl
  @ops: ops to be uninstalled
  Return values:
    None
 CONFIG_NFS_V4_2 
 SPDX-License-Identifier: GPL-2.0-only
  Common code for control of lockd and nfsv4 grace periods.
  Transplanted from lockd code
  locks_start_grace
  @net: net namespace that this lock manager belongs to
  @lm: who this grace period is for
  A grace period is a period during which locks should not be given
  out.  Currently grace periods are only enforced by the two lock
  managers (lockd and nfsd), using the locks_in_grace() function to
  check when they are in a grace period.
  This function is called to start a grace period.
  locks_end_grace
  @lm: who this grace period is for
  Call this function to state that the given lock manager is ready to
  resume regular locking.  The grace period will not end until all lock
  managers that called locks_start_grace() also call locks_end_grace().
  Note that callers count on it being safe to call this more than once,
  and the second call should be a no-op.
  locks_in_grace
  @net: network namespace
  Lock managers call this function to determine when it is OK for them
  to answer ordinary lock requests, and when they should accept only
  lock reclaims.
   linuxfshfstrans.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  This file may be distributed under the terms of the GNU General Public License.
  This file contains routines for converting between the Macintosh
  character set and various other encodings.  This includes dealing
  with ':' vs. '' as the path-element separator.
================ Global functions ================
  hfs_mac2asc()
  Given a 'Pascal String' (a string preceded by a length byte) in
  the Macintosh character set produce the corresponding filename using
  the 'trivial' name-mangling scheme, returning the length of the
  mangled filename.  Note that the output string is not NULL
  terminated.
  The name-mangling works as follows:
  The character '', which is illegal in Linux filenames is replaced
  by ':' which never appears in HFS filenames.	 All other characters
  are passed unchanged from input to output.
  hfs_asc2mac()
  Given an ASCII string (not null-terminated) and its length,
  generate the corresponding filename in the Macintosh character set
  using the 'trivial' name-mangling scheme, returning the length of
  the mangled filename.  Note that the output string is not NULL
  terminated.
  This routine is a inverse to hfs_mac2triv().
  A ':' is replaced by a ''.
   linuxfshfsmdb.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains functions for readingwriting the MDB.
================ File-local data types ================
  The HFS Master Directory Block (MDB).
  Also known as the Volume Information Block (VIB), this structure is
  the HFS equivalent of a superblock.
  Reference: _Inside Macintosh: Files_ pages 2-59 through 2-62
  modified for HFS Extended
 default values 
  hfs_mdb_get()
  Build the in-core MDB for a filesystem, including
  the B-trees and the volume bitmap.
 set the device driver to 512-byte blocks 
 See if this is an HFS filesystem 
		 check for a partition block
		  (should do this only for cdromloop though)
 size must be a multiple of 512 
 align block size to first sector 
 align block size to weird alloc size 
 These parameters are read from the MDB, and never written 
 These parameters are read from and written to the MDB 
 TRY to get the alternate (backup) MDB. 
 read in the bitmap 
 Mark the volume uncleanly unmounted in case we crash 
  hfs_mdb_commit()
  Description:
    This updates the MDB on disk.
    It does not check, if the superblock has been modified, or
    if the filesystem has been mounted read-only. It is mainly
    called by hfs_sync_fs() and flush_mdb().
  Input Variable(s):
    struct hfs_mdb mdb: Pointer to the hfs MDB
    int backup;
  Output Variable(s):
    NONE
  Returns:
    void
  Preconditions:
    'mdb' points to a "valid" (struct hfs_mdb).
  Postconditions:
    The HFS MDB and on disk will be updated, by copying the possibly
    modified fields from the in memory MDB (in native byte order) to
    the disk block buffer.
    If 'backup' is non-zero then the alternate MDB is also written
    and the function doesn't return until it is actually on disk.
 These parameters may have been modified, so write them back 
 write MDB to disk 
	 write the backup MDB, not returning until it is written.
	  we only do this when either the catalog or extents overflow
 update volume attributes 
  hfs_mdb_put()
 free the B-trees 
 free the buffers holding the primary and alternate MDBs 
   linuxfshfssuper.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains hfs_read_super(), some of the super_ops and
  init_hfs_fs() and exit_hfs_fs().  The remaining super_ops are in
  inode.c since they deal with inodes.
  Based on the minix file system code, (C) 1991, 1992 by Linus Torvalds
  hfs_put_super()
  This is the put_super() entry in the super_operations structure for
  HFS filesystems.  The purpose is to release the resources
  associated with the superblock sb.
 release the MDB's resources 
  hfs_statfs()
  This is the statfs() entry in the super_operations structure for
  HFS filesystems.  The purpose is to return various data about the
  filesystem.
  changed f_filesf_ffree to reflect the fs_ablockfree_ablocks.
  parse_options()
  adapted from linuxfsmsdosinode.c written 1992,93 by Werner Almesberger
  This function is called by hfs_read_super() to parse the mount options.
 initialize the sb with defaults 
 == '????' 
  hfs_read_super()
  This is the function that is responsible for mounting an HFS
  filesystem.	It performs all the tasks necessary to get enough data
  from the disk to read the root inode.  This includes parsing the
  mount options, dealing with Macintosh partitions, reading the
  superblock and the allocation bitmap blocks, calling
  hfs_btree_init() to get the necessary data about the extents and
  catalog B-trees and, finally, reading the root inode into memory.
 try to get the root inode 
 everything's okay 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
   linuxfshfsinode.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains inode-related functions which do not depend on
  which scheme is being used to represent forks.
  Based on the minix file system code, (C) 1991, 1992 by Linus Torvalds
================ Variable-like macros ================
	
	  In case of error extending write may have instantiated a few
	  blocks outside i_size. Trim these off again.
  hfs_new_inode
  hfs_read_inode
 Initialize the inode 
  __hfs_iget()
  Given the MDB for a HFS filesystem, a 'key' and an 'entry' in
  the catalog B-tree and the 'type' of the desired file return the
  inode for that filedirectory or NULL.  Note that 'type' indicates
  whether we want the actual file or directory, or the corresponding
  metadata (AppleDouble header file or CAP metadata file).
 panic? 
 panic? 
struct super_block sb = inode->i_sb;
if (inode->i_flags & S_DEAD) {
	hfs_delete_cat(inode->i_ino, HFSPLUS_SB(sb).hidden_dir, NULL);
	hfs_delete_inode(inode);
}
  hfs_notify_change()
  Based very closely on fsmsdosinode.c by Werner Almesberger
  This is the notify_change() field in the super_operations structure
  for HFS file systems.  The purpose is to take that changes made to
  an inode and apply then in a filesystem-dependent manner.  In this
  case the process has a few of tasks to do:
   1) prevent changes to the i_uid and i_gid fields.
   2) map file permissions to the closest allowable permissions
   3) Since multiple Linux files can share the same on-disk inode under
      HFS (for instance the data and resource forks of a file) a change
      to permissions must be applied to all other in-core inodes which
      correspond to the same HFS file.
 basic permission checks 
 no uiggid changes and limit which mode bits can be set 
 Only the 'w' bits can ever change and only all together. 
 sync the inode to buffers 
 sync the superblock to buffers 
 .. finally sync the buffers to disk 
   linuxfshfsdir.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains directory-related functions independent of which
  scheme is being used to represent forks.
  Based on the minix file system code, (C) 1991, 1992 by Linus Torvalds
  hfs_lookup()
  hfs_readdir
 This is completely artificial... 
if (fd.entrylength < HFS_MIN_THREAD_SZ) {
	pr_err("truncated catalog thread\n");
	err = -EIO;
	goto out;
}
	
	  Can be done after the list insertion; exclusion with
	  hfs_delete_cat() is provided by directory lock.
  hfs_create()
  This is the create() entry in the inode_operations structure for
  regular HFS directories.  The purpose is to create a new file in
  a directory and return a corresponding inode, given the inode for
  the directory and the name (and its length) of the new file.
  hfs_mkdir()
  This is the mkdir() entry in the inode_operations structure for
  regular HFS directories.  The purpose is to create a new directory
  in a directory, given the inode for the parent directory and the
  name (and its length) of the new directory.
  hfs_remove()
  This serves as both unlink() and rmdir() in the inode_operations
  structure for regular HFS directories.  The purpose is to delete
  an existing child, given the inode for the parent directory and
  the name (and its length) of the existing directory.
  HFS does not have hardlinks, so both rmdir and unlink set the
  link count to 0.  The only difference is the emptiness check.
  hfs_rename()
  This is the rename() entry in the inode_operations structure for
  regular HFS directories.  The purpose is to rename an existing
  file or directory, given the inode for the current directory and
  the name (and its length) of the existing filedirectory and the
  inode for the new directory and the name (and its length) of the
  new filedirectory.
  XXX: how do you handle must_be dir?
 Unlink destination if it already exists 
   linuxfshfssysdep.c
  Copyright (C) 1996  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains the code to do various system dependent things.
 dentry case-handling: just lowercase everything 
 fix up inode on a timezone change 
 SPDX-License-Identifier: GPL-2.0
   linuxfshfsattr.c
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  Export hfs data via xattr
   linuxfshfscatalog.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains the functions related to the catalog B-tree.
  Cache code shamelessly stolen from
      linuxfsinode.c Copyright (C) 1991, 1992  Linus Torvalds
      re-shamelessly stolen Copyright (C) 1997 Linus Torvalds
  hfs_cat_build_key()
  Given the ID of the parent and the name build a search key.
 init some fields for the file record 
  create_entry()
  Add a new file or directory to the catalog B-tree and
  return a (struct hfs_cat_entry) for it in 'result'.
	
	  Fail early and avoid ENOSPC during the btree operations. We may
	  have to split the root node at most once.
 panic? 
  hfs_cat_compare()
  Description:
    This is the comparison function used for the catalog B-tree.  In
    comparing catalog B-tree entries, the parent id is the most
    significant field (compared as unsigned ints).  The name field is
    the least significant (compared in "Macintosh lexical order",
    see hfs_strcmp() in string.c)
  Input Variable(s):
    struct hfs_cat_key key1: pointer to the first key to compare
    struct hfs_cat_key key2: pointer to the second key to compare
  Output Variable(s):
    NONE
  Returns:
    int: negative if key1<key2, positive if key1>key2, and 0 if key1==key2
  Preconditions:
    key1 and key2 point to "valid" (struct hfs_cat_key)s.
  Postconditions:
    This function has no side-effects
 Try to get a catalog entry for given catalog id 
 move to read_super???
  hfs_cat_delete()
  Delete the indicated file or directory.
  The associated thread is also removed unless ('with_thread'==0).
 we only need to take spinlock for exclusion with ->release() 
  hfs_cat_move()
  Rename a file or directory, possibly to a new directory.
  If the destination exists it is removed and a
  (struct hfs_cat_entry) for it is returned in 'result'.
	
	  Fail early and avoid ENOSPC during the btree operations. We may
	  have to split the root node at most once.
 find the old dir entry and read the data 
 create new dir entry with the data from the old entry 
 finally remove the old entry 
 remove old thread entry 
 create new thread entry 
 SPDX-License-Identifier: GPL-2.0
   linuxfshfsbnode.c
  Copyright (C) 2001
  Brad Boyer (flar@allandria.com)
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  Handle basic btree node operations
 compute page offset for the first page 
 page offset only applies to the first page 
 optimize later...
 optimize later...
 optimize later...
 optimize later...
 move down?
 Load a particular node out of a tree 
|| key_size & 1)
 Dispose of resources used by a node 
   linuxfshfsextent.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains the functions related to the extents B-tree.
================ File-local functions ================
  build_key
  hfs_ext_compare()
  Description:
    This is the comparison function used for the extents B-tree.  In
    comparing extent B-tree entries, the file id is the most
    significant field (compared as unsigned ints); the fork type is
    the second most significant field (compared as unsigned chars);
    and the allocation block number field is the least significant
    (compared as unsigned ints).
  Input Variable(s):
    struct hfs_ext_key key1: pointer to the first key to compare
    struct hfs_ext_key key2: pointer to the second key to compare
  Output Variable(s):
    NONE
  Returns:
    int: negative if key1<key2, positive if key1>key2, and 0 if key1==key2
  Preconditions:
    key1 and key2 point to "valid" (struct hfs_ext_key)s.
  Postconditions:
  hfs_ext_find_block
  Find a block within an extent record
 panic? 
 Fail early and avoid ENOSPC during the btree operation 
 panic? 
 panic? 
  hfs_get_block
 Convert inode block to disk allocation block 
 no extents yet 
 try to append to extents in inode 
 XXX: Can use generic_cont_expand? 
 XXX: We lack error handling of hfs_file_truncate() 
   linuxfshfsstring.c
  Copyright (C) 1995-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  This file contains the string comparison function for the
  Macintosh character set.
  The code in this file is derived from code which is copyright
  1986, 1989, 1990 by Abacus Research and Development, Inc. (ARDI)
  It is used here by the permission of ARDI's president Cliff Matthews.
================ File-local variables ================
  unsigned char caseorder[]
  Defines the lexical ordering of characters on the Macintosh
  Composition of the 'casefold' and 'order' tables from ARDI's code
  with the entry for 0x20 changed to match that for 0xCA to remove
  special case for those two characters.
================ Global functions ================
  Hash a string to an integer in a case-independent way
  Compare two strings in the HFS filename character ordering
  Returns positive, negative, or zero, not just 0 or (+-)1
  Equivalent to ARDI's call:
 	ROMlib_RelString(s1+1, s2+1, true, false, (s1[0]<<16) | s2[0])
  Test for equality of two strings in the HFS filename character ordering.
  return 1 on failure and 0 on success
   linuxfshfspart_tbl.c
  Copyright (C) 1996-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  Original code to handle the new style Mac partition table based on
  a patch contributed by Holger Schemel (aeglos@valinor.owl.de).
  The new style Mac partition map
  For each partition on the media there is a physical block (512-byte
  block) containing one of these structures.  These blocks are
  contiguous starting at block 1.
 signature 
 padding 
 partition blocks count 
 physical block start of partition 
 physical block count of partition 
	u8	pmPartName[32];	 (null terminated?) string
				   giving the name of this
	u8	pmPartType[32];	 (null terminated?) string
				   giving the type of this
 a bunch more stuff we don't need 
  The old style Mac partition map
  The partition map consists for a 2-byte signature followed by an
  array of these structures.  The map is terminated with an all-zero
  one of these.
 Signature bytes 
  hfs_part_find()
  Parse the partition map looking for the
  start and length of the 'part'th HFS partition.
"TFS1" &&
   linuxfshfsbitmap.c
  Copyright (C) 1996-1997  Paul H. Hargrove
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  This file may be distributed under the terms of the GNU General Public License.
  Based on GPLed code Copyright (C) 1995  Michael Dreher
  This file contains the code to modify the volume bitmap:
  searchsetclear bits.
  hfs_find_zero_bit()
  Description:
   Given a block of memory, its length in bits, and a starting bit number,
   determine the number of the first zero bits (in left-to-right ordering)
   in that range.
   Returns >= 'size' if no zero bits are found in the range.
   Accesses memory in 32-bit aligned chunks of 32-bits and thus
   may read beyond the 'size'th bit.
 scan the first partial u32 for zero bits 
 scan complete u32s for the first zero bit 
 do any partial u32 at the start 
 do full u32s 
 do any partial u32 at end 
  hfs_vbm_search_free()
  Description:
    Search for 'num_bits' consecutive cleared bits in the bitmap blocks of
    the hfs MDB. 'mdb' had better be locked or the returned range
    may be no longer free, when this functions returns!
    XXX Currently the search starts from bit 0, but it should start with
    the bit number stored in 's_alloc_ptr' of the MDB.
  Input Variable(s):
    struct hfs_mdb mdb: Pointer to the hfs MDB
    u16 num_bits: Pointer to the number of cleared bits
      to search for
  Output Variable(s):
    u16 num_bits: The number of consecutive clear bits of the
      returned range. If the bitmap is fragmented, this will be less than
      requested and it will be zero, when the disk is full.
  Returns:
    The number of the first bit of the range of cleared bits which has been
    found. When 'num_bits' is zero, this is invalid!
  Preconditions:
    'mdb' points to a "valid" (struct hfs_mdb).
    'num_bits' points to a variable of type (u16), which contains
 	the number of cleared bits to find.
  Postconditions:
    'num_bits' is set to the length of the found sequence.
 make sure we have actual work to perform 
  hfs_clear_vbm_bits()
  Description:
    Clear the requested bits in the volume bitmap of the hfs filesystem
  Input Variable(s):
    struct hfs_mdb mdb: Pointer to the hfs MDB
    u16 start: The offset of the first bit
    u16 count: The number of bits
  Output Variable(s):
    None
  Returns:
     0: no error
    -1: One of the bits was already clear.  This is a strange
 	 error and when it happens, the filesystem must be repaired!
    -2: One or more of the bits are out of range of the bitmap.
  Preconditions:
    'mdb' points to a "valid" (struct hfs_mdb).
  Postconditions:
    Starting with bit number 'start', 'count' bits in the volume bitmap
    are cleared. The affected bitmap blocks are marked "dirty", the free
    block count of the MDB is updated and the MDB is marked dirty.
 is there any actual work to be done? 
 are all of the bits in range? 
 bitmap is always on a 32-bit boundary 
 do any partial u32 at the start 
 do full u32s 
 do any partial u32 at end 
 SPDX-License-Identifier: GPL-2.0
   linuxfshfsbrec.c
  Copyright (C) 2001
  Brad Boyer (flar@allandria.com)
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  Handle individual btree records
 Get the length and offset of the given record in the given node 
 Get the length of the key from a keyed record 
 new record idx and complete record size 
 get last offset 
 write new last offset 
 move all following entries 
 move data away 
	
	  update parent key if we inserted a key
	  at the start of the node and it is not the new node
 create index data entry 
 get index key 
 fill hole 
 panic? 
		 new record is in the lower half,
		  so leave some more space there
 update new bnode header 
 update previous bnode header 
 update next bnode header 
 if there is no next node, this might be the new tail 
 size difference between old and new key 
 move previous cnid too 
 create index key and entry 
 restore search_key 
 insert old root idx into new root 
 SPDX-License-Identifier: GPL-2.0
   linuxfshfsbfind.c
  Copyright (C) 2001
  Brad Boyer (flar@allandria.com)
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  Search routines for btrees
 Find the record in bnode that best matches key (not greater than...)
 Traverse a BTree from the root to a leaf finding best fit to key 
 Return allocated copy of node found, set recnum to best record 
 SPDX-License-Identifier: GPL-2.0
   linuxfshfsbtree.c
  Copyright (C) 2001
  Brad Boyer (flar@allandria.com)
  (C) 2003 Ardis Technologies <roman@ardistech.com>
  Handle openingclosing btree
 Get a reference to a BTree and do some initial checks 
 Set the correct compare function 
 Load the header 
 Release resources used by a btree 
 panic? 
 Load the header 
 Make sure @tree has enough space for the @rsvd_nodes 
 panic ;
 panic ;
 SPDX-License-Identifier: GPL-2.0-or-later
  inode.c - basic inode and dentry operations.
  Based on sysfs:
  	sysfs is Copyright (C) 2001, 2002, 2003 Patrick Mochel
  configfs Copyright (C) 2005 Oracle.  All rights reserved.
  Please see Documentationfilesystemsconfigfs.rst for more
  information.
 setting attributes for the first time, allocate now 
 assign default attributes 
 attributes were changed atleast once in past 
			 sysfs_dirent has non-default attributes
			  get them for the new inode from persistent copy
			  in sysfs_dirent
			
			  In practice the maximum level of locking depth is
			  already reached. Just inform about possible reasons.
 CONFIG_LOCKDEP 
 CONFIG_LOCKDEP 
  Get the name for corresponding element represented by the given configfs_dirent
 These always have a dentry, so use that 
  Unhashes the dentry corresponding to given configfs_dirent
  Called with parent inode's i_mutex held.
 no inode means this hasn't been made visible yet 
 SPDX-License-Identifier: GPL-2.0-or-later
  item.c - library routines for handling generic config items
  Based on kobject:
 	kobject is Copyright (c) 2002-2003 Patrick Mochel
  configfs Copyright (C) 2005 Oracle.  All rights reserved.
  Please see the file Documentationfilesystemsconfigfs.rst for
  critical information about using the config_item interface.
 Evil kernel 
 	config_item_init - initialize item.
 	@item:	item in question.
 	config_item_set_name - Set the name of an item
 	@item:	item.
 	@fmt:  The vsnprintf()'s format string.
 	If strlen(name) >= CONFIGFS_ITEM_NAME_LEN, then use a
 	dynamically allocated string that @item->ci_name points to.
 	Otherwise, use the static @item->ci_namebuf array.
	
	  First, try the static array
 Free the old name, if necessary. 
 Now, set the new name 
 	config_item_put - decrement refcount for item.
 	@item:	item.
 	Decrement the refcount, and if 0, call config_item_cleanup().
 	config_group_init - initialize a group for use
 	@group:	config_group
 	config_group_find_item - search for item in group.
 	@group:	group we're looking in.
 	@name:	item's name.
 	Iterate over @group->cg_list, looking for a matching config_item.
 	If matching item is found take a reference and return the item.
 	Caller must have locked group via @group->cg_subsys->su_mtx.
 SPDX-License-Identifier: GPL-2.0-or-later
  dir.c - Operations for configfs directories.
  Based on sysfs:
  	sysfs is Copyright (C) 2001, 2002, 2003 Patrick Mochel
  configfs Copyright (C) 2005 Oracle.  All rights reserved.
  Protects mutations of configfs_dirent linkage together with proper i_mutex
  Also protects mutations of symlinks linkage to target configfs_dirent
  Mutators of configfs_dirent linkage must both have the proper inode locked
  and configfs_dirent_lock locked, in that order.
  This allows one to safely traverse configfs_dirent trees and symlinks without
  having to lock inodes.
  Protects setting of CONFIGFS_USET_DROPPING: checking the flag
  unlocked is not reliable unless in detach_groups() called from
  rmdir()unregister() and from configfs_attach_group()
 Coordinate with configfs_readdir 
		
		  Set sd->s_dentry to null only when this dentry is the one
		  that is going to be killed.  Otherwise configfs_d_iput may
		  run just after configfs_lookup and set sd->s_dentry to
		  NULL even it's still in use.
  Helpers to make lockdep happy with our recursive locking of default groups'
  inodes (see configfs_attach_group() and configfs_detach_group()).
  We put default groups i_mutexes in separate classes according to their depth
  from the youngest non-default group ancestor.
  For a non-default group A having default groups AB, AC, and ACD, default
  groups AB and AC will have their inode's mutex in class
  default_group_class[0], and default group ACD will be in
  default_group_class[1].
  The lock classes are declared and assigned in inode.c, according to the
  s_depth value.
  The s_depth value is initialized to -1, adjusted to >= 0 when attaching
  default groups, and reset to -1 when all default groups are attached. During
  attachment, if configfs_create() sees s_depth > 0, the lock class of the new
  inode's mutex is set to default_group_class[s_depth - 1].
	
	  item's i_mutex class is already setup, so s_depth is now only
	  used to set new sub-directories s_depth, which is always done
	  with item's i_mutex locked.
	
	   sd->s_depth == -1 iff we are a non default group.
	   else (we are a default group) sd->s_depth > 0 (see
	   create_dir()).
		
		  We are a non default group and we are going to create
		  default groups.
 We will not create default groups anymore. 
 CONFIG_LOCKDEP 
 CONFIG_LOCKDEP 
  Allocates a new configfs_dirent and links it to the parent configfs_dirent
  Return -EEXIST if there is already a configfs element with the same
  name for the same parent.
  called with parent inode's i_mutex held
 	configfs_create_dir - create a directory for an config_item.
 	@item:		config_itemwe're creating directory for.
 	@dentry:	config_item's dentry.
 	@frag:		config_item's fragment.
 	Note: user-created entries won't be allowed under this new directory
 	until it is validated by configfs_dir_set_ready()
 directory inodes start off with i_nlink == 2 (for "." entry) 
 already hashed 
 pin directory dentries in core 
  Allow userspace to create new entries under a new directory created with
  configfs_create_dir(), and under all of its chidlren directories recursively.
  @sd		configfs_dirent of the new directory to validate
  Caller must hold configfs_dirent_lock.
  Check that a directory does not belong to a directory hierarchy being
  attached and not validated yet.
  @sd		configfs_dirent of the directory to check
  @return	non-zero iff the directory was validated
  Note: takes configfs_dirent_lock, so the result may change from false to true
  in two consecutive calls, but never from true to false.
 pin link dentries in core 
  configfs_remove_dir - remove an config_item's directory.
  @item:	config_item we're removing.
  The only thing special about this is that we remove any files in
  the directory before we remove the directory, and we've inlined
  what used to be configfs_rmdir() below, instead of calling separately.
  Caller holds the mutex of the item's inode
	
	  Drop reference from dget() on entrance.
	
	  Fake invisibility if dir belongs to a groupdefault groups hierarchy
	  being attached
	 
	  This forbids userspace to readwrite attributes of items which may
	  not complete their initialization, since the dentries of the
	  attributes won't be instantiated.
  Only subdirectories count here.  Files (CONFIGFS_NOT_PINNED) are
  attributes and are removed by rmdir().  We recurse, setting
  CONFIGFS_USET_DROPPING on all children that are candidates for
  default detach.
  If there is an error, the caller will reset the flags via
  configfs_detach_rollback().
 Mark that we're trying to drop the group 
 Abort if racing with mkdir() 
			
			  Yup, recursive.  If there's a problem, blame
			  deep nesting of default_groups
  Walk the tree, resetting CONFIGFS_USET_DROPPING wherever it was
  set.
	
	  Drop reference from dget() on entrance.
	
	  Drop reference from dget() on entrance.
  This fakes mkdir(2) on a default_groups[] entry.  It
  creates a dentry, attachs it, and then does fixup
  on the sd->s_type.
  We could, perhaps, tweak our parent's ->mkdir for a minute and
  try using vfs_mkdir.  Just a thought.
 We trust the caller holds a reference to parent 
  All of link_objunlink_objlink_groupunlink_group require that
  subsys->su_mutex is held.
 Drop the reference for ci_entry 
 Drop the reference for ci_parent 
	
	  Parent seems redundant with group, but it makes certain
	  traversals much nicer.
	
	  We hold a reference on the parent for the child's ci_parent
	  link.
	
	  We hold a reference on the child for ci_entry on the parent's
	  cg_children
 gcc is a turd 
  The goal is that configfs_attach_item() (and
  configfs_attach_group()) can be called from either the VFS or this
  module.  That is, they assume that the items have been created,
  the dentry allocated, and the dcache is all ready to go.
  If they fail, they must clean up after themselves as if they
  had never been called.  The caller (VFS or local function) will
  handle cleaning up the dcache bits.
  configfs_detach_group() and configfs_detach_item() behave similarly on
  the way out.  They assume that the proper semaphores are held, they
  clean up the configfs items, and they expect their callers will
  handle the dcache bits.
			
			  We are going to remove an inode and its dentry but
			  the VFS may already have hit and used them. Thus,
			  we must lock them as rmdir() would.
 Caller holds the mutex of the item's inode 
		
		  FYI, we're faking mkdir in populate_groups()
		  We must lock the group's inode to avoid races with the VFS
		  which can already hit the inode and try to addremove entries
		  under it.
		 
		  We must also lock the inode to remove it safely in case of
		  error, as rmdir() would.
 Caller holds the mutex of the group's inode 
  After the item has been detached from the filesystem view, we are
  ready to tear it out of the hierarchy.  Notify the client before
  we do that so they can perform any cleanup that requires
  navigating the hierarchy.  A client does not need to provide this
  callback.  The subsystem semaphore MUST be held by the caller, and
  references must be valid for both items.  It also assumes the
  caller has validated ci_type.
  Drop the initial reference from make_item()make_group()
  This function assumes that reference is held on item
  and that item holds a valid reference to the parent.  Also, it
  assumes the caller has validated ci_type.
	
	  If ->drop_item() exists, it is responsible for the
	  config_item_put().
  configfs_depend_item() and configfs_undepend_item()
  WARNING: Do not call these from a configfs callback!
  This describes these functions and their helpers.
  Allow another kernel system to depend on a config_item.  If this
  happens, the item cannot go away until the dependent can live without
  it.  The idea is to give client modules as simple an interface as
  possible.  When a system asks them to depend on an item, they just
  call configfs_depend_item().  If the item is live and the client
  driver is in good shape, we'll happily do the work for them.
  Why is the locking complex?  Because configfs uses the VFS to handle
  all locking, but this function is called outside the normal
  VFS->configfs path.  So it must take VFS locks to prevent the
  VFS->configfs stuff (configfs_mkdir(), configfs_rmdir(), etc).  This is
  why you can't call these functions underneath configfs callbacks.
  Note, btw, that this can be called at any time, even when a configfs
  subsystem isn't registered, or when configfs is loading or unloading.
  Just like configfs_register_subsystem().  So we take the same
  precautions.  We pin the filesystem.  We lock configfs_dirent_lock.
  If we can find the target item in the
  configfs tree, it must be part of the subsystem tree as well, so we
  do not need the subsystem semaphore.  Holding configfs_dirent_lock helps
  locking out mkdir() and rmdir(), who might be racing us.
  configfs_depend_prep()
  Only subdirectories count here.  Files (CONFIGFS_NOT_PINNED) are
  attributes.  This is similar but not the same to configfs_detach_prep().
  Note that configfs_detach_prep() expects the parent to be locked when it
  is called, but we lock the parent inside configfs_depend_prep().  We
  do that so we can unlock it if we find nothing.
  Here we do a depth-first search of the dentry hierarchy looking for
  our object.
  We deliberately ignore items tagged as dropping since they are virtually
  dead, as well as items in the middle of attachment since they virtually
  do not exist yet. This completes the locking out of racing mkdir() and
  rmdir().
  Note: subdirectories in the middle of attachment start with s_type =
  CONFIGFS_DIR|CONFIGFS_USET_CREATING set by create_dir().  When
  CONFIGFS_USET_CREATING is set, we ignore the item.  The actual set of
  s_type is in configfs_new_dirent(), which has configfs_dirent_lock.
  If the target is not found, -ENOENT is bubbled up.
  This adds a requirement that all config_items be unique!
  This is recursive.  There isn't
  much on the stack, though, so folks that need this function - be careful
  about your stack!  Patches will be accepted to make it iterative.
 Boo-yah 
 Child path boo-yah 
 We looped all our children and didn't find target 
 Scan the tree, return 0 if found 
	
	  We are sure that the item is not about to be removed by rmdir(), and
	  not in the middle of attachment by mkdir().
	
	  Pin the configfs filesystem.  This means we can safely access
	  the root of the configfs filesystem.
	
	  Next, lock the root directory.  We're going to check that the
	  subsystem is really registered, and so we need to lock out
	  configfs_[un]register_subsystem().
 Ok, now we can trust subsyss_item 
	
	  If we succeeded, the fs is pinned via other methods.  If not,
	  we're done with it anyway.  So release_fs() is always right.
  Release the dependent linkage.  This is much simpler than
  configfs_depend_item() because we know that the client driver is
  pinned, thus the subsystem is pinned, and therefore configfs is pinned.
	
	  Since we can trust everything is pinned, we just need
	  configfs_dirent_lock.
	
	  After this unlock, we cannot trust the item to stay alive!
	  DO NOT REFERENCE item after this unlock.
  caller_subsys is a caller's subsystem not target's. This is used to
  determine if we should lock root and check subsys or not. When we are
  in the same subsystem as our target there is no need to do locking as
  we know that subsys is valid and is not unregistered during this function
  as we are called from callback of one of his children and VFS holds a lock
  on some inode. Otherwise we have to lock our root to  ensure that target's
  subsystem it is not unregistered during this function.
 Disallow this function for configfs root 
	
	  This may happen when someone is trying to depend root
	  directory of some subsystem
 Find a cofnigfs root as we may need it for locking 
		
		  We are in other configfs subsystem, so we have to do
		  additional locking to prevent other subsystem from being
		  unregistered
		
		  As we are trying to depend item from other subsystem
		  we have to check if this subsystem is still registered
 Now we can execute core of depend item 
		
		  We were called from subsystem other than our target so we
		  took some locks so now it's time to release them
	
	  Fake invisibility if dir belongs to a groupdefault groups hierarchy
	  being attached
 Get a working ref for the duration of this function 
 Lack-of-mkdir returns -EPERM 
	
	  The subsystem may belong to a different module than the item
	  being created.  We don't want to safely pin the new item but
	  fail to pin the subsystem it sits under.
		
		  If ret != 0, then link_obj() was never called.
		  There are no extra references to clean up.
	
	  link_obj() has been called (via link_group() for groups).
	  From here on out, errors must clean that up.
	
	  I hate doing it this way, but if there is
	  an error,  module_put() probably should
	  happen after any cleanup.
	
	  Make racing rmdir() fail if it did not tag parent with
	  CONFIGFS_USET_DROPPING
	  Note: if CONFIGFS_USET_DROPPING is already set, attach_group() will
	  fail and let rmdir() terminate correctly
 This will make configfs_detach_prep() fail 
 Tear down everything we built up 
	
	  link_obj()link_group() took a reference from child->parent,
	  so the parent is safely pinned.  We can drop our working
	  reference.
 Get a working ref until we have the child 
 configfs_mkdir() shouldn't have allowed this 
	
	  Ensure that no racing symlink() will make detach_prep() fail while
	  the new link is temporarily attached
		
		  Here's where we check for dependents.  We're protected by
		  configfs_dirent_lock.
		  If no dependent, atomically tag the item as dropping.
 Wait until the racing operation terminates 
 Get a working ref for the duration of this function 
 Drop reference from above, item already holds one. 
 Drop our reference from above 
	
	  Fake invisibility if dir belongs to a groupdefault groups hierarchy
	  being attached
 Relationship between s_mode and the DT_xxx types 
		
		  We'll have a dentry and an inode for
		  PINNED items and for open attribute
		  files.  We lock here to prevent a race
		  with configfs_d_iput() clearing
		  s_dentry before calling iput().
		 
		  Why do we go to the trouble?  If
		  someone has an attribute file open,
		  the inode number should match until
		  they close it.  Beyond that, we don't
		  care.
  configfs_register_group - creates a parent-child relation between two groups
  @parent_group:	parent group
  @group:		child group
  link groups, creates dentry for the child and attaches it to the
  parent dentry.
  Return: 0 on success, negative errno code on error
  configfs_unregister_group() - unregisters a child group from its parent
  @group: parent group to be unregistered
  Undoes configfs_register_group()
  configfs_register_default_group() - allocates and registers a child group
  @parent_group:	parent group
  @name:		child group name
  @item_type:		child item type description
  boilerplate to allocate and register a child group with its parent. We need
  kzalloc'ed memory because child's default_group is initially empty.
  Return: allocated config group or ERR_PTR() on error
  configfs_unregister_default_group() - unregisters and frees a child group
  @group:	the group to act on
 SPDX-License-Identifier: GPL-2.0-or-later
  file.c - operations for regular (text) files.
  Based on sysfs:
  	sysfs is Copyright (C) 2001, 2002, 2003 Patrick Mochel
  configfs Copyright (C) 2005 Oracle.  All rights reserved.
  A simple attribute can only be 4096 characters.  Why 4k?  Because the
  original code limited it to PAGE_SIZE.  That's a bad idea, though,
  because an attribute of 16k on ia64 won't work on x86.  So we limit to
  4k, our minimum common page size.
 we don't support switching readwrite modes 
 perform first read with buf == NULL to get extent 
 do not exceed the maximum value 
 perform second read to fill buffer 
 Fill @buffer with data coming from @from. 
	 if buf is assumed to contain a string, terminate it by \0,
  There is no easy way for us to know if userspace is only doing a partial
  write, so we don't support them. We expect the entire buffer to come on the
  first write.
  Hint: if you're writing a value, first read the file, modify only the value
  you're changing, then write entire buffer back.
 we don't support switching readwrite modes 
 buffer grows? 
 copy old contents 
 clear the new area 
 Grab the module reference for this attribute if we have one 
	 File needs write support.
	  The inode's perms must say it's ok,
	  and we must have a store method.
	 File needs read support.
	  The inode's perms must say it's ok, and we there
	  must be a show method for it.
 result of ->release() is ignored 
 bin file is not seekable 
 	configfs_create_file - create an attribute file for an item.
 	@item:	item we're creating for.
 	@attr:	atrribute descriptor.
 	configfs_create_bin_file - create a binary attribute file for an item.
 	@item:	item we're creating for.
 	@bin_attr: atrribute descriptor.
 SPDX-License-Identifier: GPL-2.0-or-later
  symlink.c - operations for configfs symlinks.
  Based on sysfs:
  	sysfs is Copyright (C) 2001, 2002, 2003 Patrick Mochel
  configfs Copyright (C) 2005 Oracle.  All rights reserved.
 Protects attachments of new symlinks 
 back up enough to print this bus id with '' 
	
	  Fake invisibility if dir belongs to a groupdefault groups hierarchy
	  being attached
	
	  This is really sick.  What they wanted was a hybrid of
	  link(2) and symlink(2) - they wanted the target resolved
	  at syscall time (as link(2) would've done), be a directory
	  (which link(2) would've refused to do) AND be a deep
	  fucking magic, making the target busy from rmdir POV.
	  symlink(2) is nothing of that sort, and the locking it
	  gets matches the normal symlink(2) semantics.  Without
	  attempts to resolve the target (which might very well
	  not even exist yet) done prior to locking the parent
	  directory.  This perversion, OTOH, needs to resolve
	  the target, which would lead to obvious deadlocks if
	  attempted with any directories locked.
	 
	  Unfortunately, that garbage is userland ABI and we should've
	  said "no" back in 2005.  Too late now, so we get to
	  play very ugly games with locking.
	 
	  Try ANYTHING of that sort in new code, and you will
	  really regret it.  Just ask yourself - what could a BOFH
	  do to me and do I want to find it out first-hand?
	 
	   AV, a thoroughly annoyed bastard.
 What lack-of-symlink returns 
	
	  drop_link() must be called before
	  decrementing target's ->s_links, so that the order of
	  drop_link(this, target) and drop_item(target) is preserved.
 SPDX-License-Identifier: GPL-2.0-or-later
  mount.c - operations for initializing and mounting configfs.
  Based on sysfs:
  	sysfs is Copyright (C) 2001, 2002, 2003 Patrick Mochel
  configfs Copyright (C) 2005 Oracle.  All rights reserved.
 Random magic number 
 directory inodes start off with i_nlink == 2 (for "." entry) 
 the rest get that 
 SPDX-License-Identifier: LGPL-2.1
    vfs operations that deal with io control
    Copyright (C) International Business Machines  Corp., 2005,2013
    Author(s): Steve French (sfrench@us.ibm.com)
 the destination must be opened for writing 
 check if target volume is readonly and take reference 
	trace_cifs_shutdown(sb, flags);
	
	  see:
	    https:man7.orglinuxman-pagesman2ioctl_xfs_goingdown.2.html
	  for more information and description of original intent of the flags
	
	  We could add support later for default flag which requires:
	      "Flush all dirty data and metadata to disk"
	  would need to call syncfs or equivalent to flush page cache for
	  the mount and then issue fsync to server (if nostrictsync not set)
	
	  FLAGS_LOGFLUSH is easy since it asks to write out metadata (not
	  data) but metadata writes are not cached on the client, so can treat
	  it similarly to NOLOGFLUSH
 copy user input into our output buffer 
 if ses id is 0, use current user session 
 otherwise if a session id is given, look for it in all our sessions 
					
					  since we are using the session outside the crit
					  section, we need to make sure it won't be released
					  so increment its refcount
 check if user buffer is big enough to store all the keys 
 overwrite user input with our output 
 append all the keys at the end of the user buffer 
 strange error - but the precedent 
 CONFIG_CIFS_POSIX 
 add in the compressed bit 
 caps = le64_to_cpu(tcon->fsUnixInfo.Capability); 
			
			  if (CIFS_UNIX_EXTATTR_CAP & caps)
			 	rc = CIFSSetExtAttr(xid, tcon,
			 		       pSMBFile->fid.netfid,
			 		       extAttrBits,
			 		       &ExtAttrMask);
			  if (rc != EOPNOTSUPP)
			 	break;
 Currently only flag we can set is compressed flag 
 Try to set compress flag 
			
			  Dump encryption keys. This is an old ioctl that only
			  handles AES-128-{CCM,GCM}.
 SMB2_NTLMV2_SESSKEY_SIZE );
			
			  Dump encryption keys (handles any key sizes)
 Notify can only be done on directories 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2011
    Author(s): Steve French (sfrench@us.ibm.com)
 FIXME: should these be tunable? 
 Drop the connection to not overload the server 
  Resolve hostname and set ip addr in tcp ses. Useful for hostnames that may
  get their ip addresses changed at some point.
  This should be called with server->srv_mutex held.
 rc == 1 means success here 
			
			  To make sure we don't use the cached entry, retry 1s
			  after expiry.
	
	  Resolve the hostname again to make sure that IP address is up-to-date.
  Mark all sessions and tcons for reconnect.
  @server needs to be previously set to CifsNeedReconnect.
	
	  before reconnecting the tcp session, mark the smb session (uid) and the tid bad so they
	  are not used until reconnected.
 If server is a channel, select the primary channel 
 do not want to be sending data on a socket we are freeing 
 mark submitted MIDs for retry and issue callback 
 the demux thread will exit normally next time through the loop 
  cifs tcp session reconnection
  mark tcp session as reconnecting so temporarily locked
  mark all smb sessions as reconnecting for tcp session
  reconnect tcp session
  wake up waiters on reconnection? - (not needed currently)
 resolve the hostname again to make sure that IP address is up-to-date 
 resolve the hostname again to make sure that IP address is up-to-date. 
 Reconnect the socket 
 If dfs target list is empty, then reconnect to last server 
 Otherwise, try every dfs target in @tl 
	
	  Determine the number of dfs targets the referral path in @cifs_sb resolves to.
	 
	  smb2_reconnect() needs to know how long it should wait based upon the number of dfs
	  targets (server->nr_targets).  It's also possible that the cached referral was cleared
	  through procfscifsdfscache or the target list is empty due to server settings after
	  refreshing the referral, so, in this case, default it to 1.
 Failed to reconnect socket 
		
		  Socket was created.  Update tcp session status to CifsNeedNegotiate so that a
		  process waiting for reconnect will know it needs to re-establish session and tcon
		  through the reconnected target server.
 Need to set up echo worker again once connection has been established 
 If tcp session is not an dfs connection, then reconnect to last target server 
	
	  We cannot send an echo if it is disabled.
	  Also, no need to ping if we got a response recently.
 Check witness registrations 
 retry will check if exiting 
 we are reusing a dirty large buf, clear its start 
 retry will check if exiting 
 beginning of smb buffer is cleared in our buf_get 
 if existing small buf clear beginning 
	
	  We need to wait 3 echo intervals to make sure we handle such
	  situations right:
	  1s  client sends a normal SMB request
	  2s  client gets a response
	  30s echo workqueue job pops, and decides we got a response recently
	      and don't need to send another
	  ...
	  65s kernel_recvmsg times out, and we see that we haven't gotten
	      a response in >60s.
 reconnect if no credits and no requests in flight 
			
			  Minimum sleep to prevent looping, allowing socket
			  to clear and app threads to set tcpStatus
			  CifsNeedReconnect if server hung.
	
	   iov_iter_discard already sets smb_msg.type and count and iov_offset
	   and cifs_readv_from_socket sets msg_control and msg_controllen
	   so little to initialize in struct msghdr
	
	  The first byte big endian of the length field,
	  is actually not part of the length but the type
	  with the most common, zero, as regular data.
 Regular SMB response 
		
		  We get this from Windows 98 instead of an error on
		  SMB negprot response.
 give server a second to clean up 
		
		  Always try 445 first on reconnect since we get NACK
		  on some if we ever connected to port 139 (the NACK
		  is since we do not begin with RFC1001 session
		  initialize frame).
	
	  Trying to handledequeue a mid after the send_recv()
	  function has finished processing it is a bug.
	
	  SMB1 does not use credits.
 Was previous buf put in mpx struct for multi-rsp? 
 smb buffer will be freed by user thread 
 take it off the list, if it's not already 
 check if we have blocked requests that need to free 
	
	  Although there should not be any requests blocked on this queue it
	  can not hurt to be paranoid and try to wake up requests that may
	  haven been blocked when more than 50 at time were on the wire to the
	  same server - they now will see the session is in exit state and get
	  out of SendReceive.
 give those requests time to exit 
 now walk dispose list and issue callbacks 
 18th of sec is more than enough time for them to exit 
		
		  mpx threads have not exited yet give them at least the smb
		  send timeout time for long ops.
		 
		  Due to delays on oplock break requests, we need to wait at
		  least 45 seconds before giving up on a request getting a
		  response and going ahead and killing cifsd.
		
		  If threads still have not exited they are probably never
		  coming home not much else we can do but free the memory.
 make sure this will fit in a large buffer 
 switch to large buffer if too big for a small one 
 now read the rest 
	
	  We know that we received enough to get to the MID as we
	  checked the pdu_length earlier. Now check to see
	  if the rest of the header is OK. We borrow the length
	  var for the rest of the loop to avoid a new stack var.
	 
	  48 bytes is enough to display the header and a little bit
	  into the payload for debugging purposes.
	
	  SMB1 does not use credits.
 enough to get RFC1001 header 
		
		  The right amount was read from socket - 4 bytes,
		  so we can now interpret the length field.
 make sure we have enough to get to the MID 
 read down to the MID 
 CIFS_DEBUG2 
 end while !EXITING 
 buffer usually freed in free_mid - need to free it here on exit 
 no sense logging a debug message if NULL 
 if server->tsk was NULL then wait for a signal before exiting 
  Returns true if srcaddr isn't specified and rhs isn't specified, or
  if srcaddr is specified and matches the IP address of the rhs argument
 don't expect to be here 
  If no port is specified in addr structure, we try to match with 445 port
  and if it fails - with 139 ports. It should be called only if address
  families of server and addr are equal.
 SMBDirect manages its own ports, don't match it here 
 don't expect to be here 
	
	  The select_sectype function should either return the ctx->sectype
	  that was specified, or "Unspecified" if that sectype was not
	  compatible with the given NEGOTIATE request.
	
	  Now check if signing mode is acceptable. No need to check
	  global_secflags at this point since if MUST_SIGN is set then
	  the server->sign had better be too.
 this server does not share socket 
 If multidialect negotiation see if existing sessions match one 
		
		  DFS failover implementation in cifs_reconnect() requires unique tcp sessions for
		  DFS connections to do failover properly, so avoid sharing them with regular
		  shares or even links that may connect to same server but having completely
		  different failover targets.
		
		  Skip ses channels since they're only handled in lower layers
		  (e.g. cifs_send_recv).
 srv_count can never go negative 
 For secondary channels, we pick up ref-count on the primary server 
		
		  Avoid deadlock here: reconnect work calls
		  cifs_put_tcp_session() at its end. Need to be sure
		  that reconnect work does nothing with server pointer after
		  that step.
 fscache server cookies are based on primary channel only 
 see if we already have a matching tcp_ses 
	
	  at this point we are the only ones with the pointer
	  to the struct since the kernel thread not created yet
	  no need to spinlock this init of tcpStatus or srv_count
	
	  since we're in a cifs function already, we know that
	  this will succeed. No need for try_module_get().
	
	  at this point we are the only ones with the pointer
	  to the struct since the kernel thread not created yet
	  no need to spinlock this update of tcpStatus
 thread spawned, put it on the list 
 fscache server cookies are based on primary channel only 
 queue echo request delayed work 
 queue dns resolution delayed work 
	
	  If an existing session is limited to less channels than
	  requested, it should not be reused
 NULL username means anonymous session 
 anything else takes usernamepassword 
  cifs_setup_ipc - helper to setup the IPC tcon for the session
  @ses: smb session to issue the request on
  @ctx: the superblock configuration context to use for building the
        new tree connection for the IPC (interprocess communication RPC)
  A new IPC connection is made and stored in the session
  tcon_ipc. The IPC tcon has the same lifetime as the session.
xIPC$")] = {0};
	
	  If the mount request that resulted in the creation of the
	  session requires encryption, force IPC to be encrypted too.
  cifs_free_ipc - helper to release the session IPC tcon
  @ses: smb session to unmount the IPC from
  Needs to be called everytime a session is destroyed.
  On session close, the IPC is closed and the server must release all tcons of the session.
  No need to send a tree disconnect here.
  Besides, it will make the server to not close durable and resilient files on session close, as
  specified in MS-SMB2 3.3.5.6 Receiving an SMB2 LOGOFF Request.
 ses_count can never go negative 
 close any extra channels 
			
			  note: for now, we're okay accessing ses->chans
			  without chan_lock. But when chans can go away, we'll
			  need to introduce ref counting to make sure that chan
			  is not freed from under us.
 strlen("cifs:a:") + CIFS_MAX_DOMAINNAME_LEN + 1 
 Populate username and pw fields from keyring if possible 
 try to find an address key first 
 didn't work, try to find a domain key 
 find first : in payload 
	
	  If we have a domain key then we must set the domainName in the
	  for the request.
 ! CONFIG_KEYS 
 CONFIG_KEYS 
  cifs_get_smb_ses - get a session matching @ctx data from @server
  @server: server to setup the session to
  @ctx: superblock configuration context to use to setup the session
  This function assumes it is being called from cifs_mount() where we
  already got a server reference (server refcount +1). See
  cifs_get_tcon() for refcount explanations.
 problem -- put our ses reference 
 problem -- put our reference 
 existing SMB ses has a server reference already 
 new SMB session uses our server ref 
 ctx->password freed at unmount 
 add server as first channel 
 each channel uses a different signing key 
 success, put it on the list and add it as first channel 
	
	  IPC tcon share the lifetime of their session and are
	  destroyed in the session put function
 tc_count can never go negative 
  cifs_get_tcon - get a tcon matching @ctx data from @ses
  @ses: smb session to issue the request on
  @ctx: the superblock configuration context to use for building the
  - tcon refcount is the number of mount points using the tcon.
  - ses refcount is the number of tcon using the session.
  1. This function assumes it is being called from cifs_mount() where
     we already got a session reference (ses refcount +1).
  2. Since we're in the context of adding a mount point, the end
     result should be either:
  a) a new tcon already allocated with refcount=1 (1 mount point) and
     its session refcount incremented (1 new tcon). This +1 was
     already done in (1).
  b) an existing tcon with refcount+1 (add a mount point to it) and
     identical ses refcount (no new tcon). Because of (1) we need to
     decrement the ses refcount.
		
		  tcon has refcount already incremented but we need to
		  decrement extra ses reference gotten by caller (case b)
	
	  BB Do we need to wrap session_mutex around this TCon call and Unix
	  SetFS as we do on SessSetup and reconnect?
 check if SMB2 or later, CIFS does not support persistent handles 
 persistent handles requested but not supported  {
				
				  Set witness in use flag in first place
				  to retry registration in the echo task
 And try to register immediately 
 TODO: try to extend for non-cluster uses (eg multichannel) 
 If the user really knows what they are doing they can override 
	
	  We can have only one retry value for a connection to a share so for
	  resources mounted more than once to the same server share the last
	  value passed in for the retry flag is used.
	
	  We want to share sb only if we don't specify an rwsize or
	  specified rwsize is greater than or equal to existing one.
 can not match superblock if tlink were ever null 
 See RFC1001 section 14 on representation of Netbios names 
 mask a nibble at a time and encode 
 Bind to the specified local IP address 
	
	  some servers require RFC1001 sessinit before sending
	  negprot - BB check reconnection in case where second
	  sessinit is sent but no second negprot
		
		  calling name ends in null (byte 16) from old smb
		  convention.
 sizeof RFC1002_SESSION_REQUEST with no scope 
		
		  RFC1001 layer in at least one server
		  requires very short break before negprot
		  presumably because not expecting negprot
		  to follow so fast.  This is a simple
		  solution that works without
		  complicating the code and causes no
		  significant slowing down on mount
		  for everyone else
	
	  else the negprot may still work without this
	  even though malloc failed
 BB other socket options to set KEEPALIVE, NODELAY? 
	
	  Eventually check for other socket options to change from
	  the default. sock_setsockopt not used because it expects
	  user space buffer
 make the bufsizes depend on wsizersize and max requests 
	
	  When mounting SMB root file systems, we do not want to block in
	  connect. Otherwise bail out and then let cifs_reconnect() perform
	  reconnect failover - if possible.
 try with 445 port at first 
 if it failed, try with 139 port 
	
	  If we are reconnecting then should we check to see if
	  any requested capabilities changed locally e.g. via
	  remount but we can not do much about it here
	  if they have (even if we could detect it by the following)
	  Perhaps we could add a backpointer to array of sb from tcon
	  or if we change to make all sb to same share the same
	  sb as NFS - then we only have one backpointer to sb.
	  What if we wanted to mount the server share twice once with
	  and once without posixacls or posix paths?
 Unix Extensions disabled 
 Unix Extensions supported 
		
		  check for reconnect case in which we do not
		  want to change the mount behavior if we can avoid it
			
			  turn off POSIX ACL and PATHNAMES if not set
			  originally at mount time
 CIFS_DEBUG2 
 this is needed for ASCII cp to Unicode converts 
 load_nls_default cannot return null 
 Release all succeed connections 
 Get connections for tcp, ses and tcon 
 get a reference to a tcp session 
 get a reference to a SMB session 
 search for existing tcon to this server share 
 if new SMB3.11 POSIX extensions are supported do not remap  and \ 
 tell server which Unix caps we support 
		
		  reset of caps checks mount to see if unix extensions disabled
		  for just this mount.
 server does not support them 
 do not care if a following call succeed - informational 
 no need to log a RW mount of a typical RW share 
		
		  The cookie is initialized from volume info returned above.
		  Inside cifs_fscache_get_super_cookie it checks
		  that we do not get super cookie twice.
	
	  Clamp the rsizewsize mount arguments if they are too big for the server
	  and set the rsizewsize to the negotiated values if not passed in by
	  the user on mount
 hang the tcon off of the superblock 
 Get unique dfs connections 
  cifs_build_path_to_root returns full path to root when we do not have an
  existing connection (tcon)
 add trailing null 
  expand_dfs_referral - Update cifs_sb from dfs referral path
  cifs_sb->ctx->mount_options will be (re-)allocated to a string containing updated options for the
  submount.  Otherwise it will be left untouched.
		
		  We can not clear out the whole structure since we no longer have an explicit
		  function to parse a mount-string. Instead we need to clear out the individual
		  fields that are no longer valid.
 TODO: all callers to this are broken. We are not parsing mount_options here
  we should pass a clone of the original context?
 BB fixme parse for domain name here 
	 In userspace mount helper we can get user name from alternate
 skip separators 
 next separator 
		
		  if the treename is added, we then have to skip the first
		  part within the separators
		
		  temporarily null-terminate the path at the end of
		  the current component
  Check if path is remote (e.g. a DFS share). Return -EREMOTE if it is,
  otherwise 0.
	
	  cifs_build_path_to_root works only when we have a valid tcon
	
	  If called with 'nodfs' mount option, then skip DFS resolving.  Otherwise unconditionally
	  try to get an DFS referral (even cached) to determine whether it is an DFS mount.
	 
	  Skip prefix path to provide support for DFS referrals from w2k8 servers which don't seem
	  to respond with PATH_NOT_COVERED to requests that include the prefix.
 Check if it is fully accessible and then mount it 
 Connect to new target only if we were redirected (e.g. mount options changed) 
	 Put initial connections as they might be shared with other mounts.  We need unique dfs
	  connections per mount to properly failover, so mount_get_dfs_conns() must be used from
	  now on.
 Try all dfs root targets 
 Get referral from dfs link 
 Try all dfs link targets 
 Set up DFS referral paths for failover 
	
	  After reconnecting to a different server, unique ids won't match anymore, so we disable
	  serverino. This prevents dentry revalidation to think the dentry are stale (ESTALE).
	
	  Force the use of prefix path to support failover on DFS paths that resolve to targets
	  that have different prefix paths.
  Issue a TREE_CONNECT request.
no tid  , 4 
 minimum 
 password is null byte 
 skip password 
 already aligned so no need to do it below 
 max utf8 char length in bytes  
 server len + 256 
 convert num 16 bit words to bytes 
 skip trailing null 
 ASCII 
 above now done in SendReceive 
 skip service field (NB: this field is always ASCII) 
 the most common case 
 mostly informational -- no need to fail on error here 
 field is in same location 
 only send once per connect 
 krb5 is special, since we don't need username or pw 
 get a reference for the same TCP session 
 find and return a tlink with given uid 
 insert a tcon_link into the tree 
  Find or construct an appropriate tcon given a cifs_sb and the fsuid of the
  current task.
  If the superblock doesn't refer to a multiuser mount, then just return
  the master tcon for the mount.
  First, search the rbtree for an existing tcon for this fsuid. If one
  exists, then check to see if it's pending construction. If it is then wait
  for construction to complete. Once it's no longer pending, check to see if
  it failed and either return an error or retry construction, depending on
  the timeout.
  If one doesn't exist then insert a new tcon_link struct into the tree and
  try to construct a new one.
 was one inserted after previous search? 
 if it's good, return it 
 return error if we tried this already recently 
  periodic workqueue job that scans tcon_tree for a superblock and closes
  out tcons.
	
	  Because we drop the spinlock in the loop in order to put the tlink
	  it's not guarded against removal of links from the tree. The only
	  places that remove entries from the tree are this function and
	  umounts. Because this function is non-reentrant and is canceled
	  before umount can proceed, this is safe.
 Update dfs referral path of superblock 
 Check if hostnames or addresses match 
 Try to tree connect to all dfs targets 
 Check if share matches with tcp ses 
		
		  If no dfs referrals were returned from link target, then just do a TREE_CONNECT
		  to it.  Otherwise, cache the dfs referral and then mark current tcp ses for
		  reconnect so either the demultiplex thread or the echo worker will reconnect to
		  newly resolved target.
 Target is another dfs share 
	
	  If we couldn't tree connect to any targets from last referral path, then retry from
	  original referral path.
 If it is not dfs or there was no cached dfs referral, then reconnect to same share 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2008
    Author(s): Steve French (sfrench@us.ibm.com)
    Common Internet FileSystem (CIFS) client
 Note that BB means BUGBUG (ie something to fix eventually) 
  DOS dates from 198011 through 21071231
  Protocol specifications indicate the range should be to 119, which
  limits maximum year to 2099. But this range has not been checked.
 false by default 
 false by default 
 false by default 
 unsigned int ntlmv2_support = 0; 
 STATS2 
  Bumps refcount for cifs super block.
  Note that it should be only called if a referece to VFS super block is
  already held, e.g. in open-type syscalls context. Otherwise it can race with
  atomic_dec_and_test in deactivate_locked_super.
	
	  Some very old servers like DOS and OS2 used 2 second granularity
	  (while all current servers use 100ns granularity - see MS-DTYP)
	  but 1 second is the maximum allowed granularity for the VFS
	  so for old servers set time granularity to 1 second while for
	  everything else (current servers) set it to 100ns.
 1 second is max allowed gran 
		
		  Almost every server, including all SMB2+, uses DCE TIME
		  ie 100 nanosecond units, since 1601.  See MS-DTYP and MS-FSCC
 tune readahead according to rsize if readahead size not set on mount 
 default 214 = CIFS_MAX_MSGSIZE 
 CONFIG_CIFS_NFSD_EXPORT 
	
	  We ned to release all dentries for the cached directories
	  before we kill the sb.
 are using part of create time for more randomness, see man statfs 
 undefined 
 unlimited 
	} else  file mode might have been restricted at mount time
		on the client (above and beyond ACL on servers) for
		servers which do not support setting and viewing mode bits,
 default 
	
	  Until the file is open and we have gotten oplock info back from the
	  server, can not assume caching of file data or metadata.
 214 = CIFS_MAX_MSGSIZE 
	
	  Can not set i_flags here - they get immediately overwritten to zero
	  by the VFS.
 cifs_inode->vfs_inode.i_flags = S_NOATIME | S_NOCMTIME; 
 shouldn't ever happen 
 assume only one client access 
 read only caching assumed 
  cifs_show_devname() is used so we show the mount device name with correct
  format (e.g. forward slashes vs. back slashes) in procmounts
 escape all spaces in share names 
  cifs_show_options() is for displaying mount options in procmounts.
  Not all settable options are displayed but most of the important
  ones are.
 Only display max_credits if it was overridden on mount 
	
	  Display file and directory attribute timeout in seconds.
	  If file and directory attribute timeout the same then actimeo
	  was likely specified on mount
		 we have other mounts to same share or we have
		   already tried to force umount this and woken up
 cancel_brl_requests(tcon);  
 cancel_notify_requests(tcon); 
 yield 
 we have to kick the requests once more 
 BB FIXME 
 no serverino => unconditional eviction 
	.show_path	= cifs_show_path,  
	.delete_inode	= cifs_delete_inode,     Do not need above
	function unless later we add lazy close of inodes or unless the
	kernel forgets to call us with the same number of releases (closes)
  Get root dentry from superblock according to prefix path mount option.
  Return dentry with refcount + 1 on success and NULL otherwise.
 skip separators 
 next separator 
	
	  Prints in Kernel  CIFS log the attempted mount operation
	 	If CIFS_DEBUG && cifs_FYI
 BB should we make this contingent on mount parm? 
	
	  whence == SEEK_END || SEEK_DATA || SEEK_HOLE => we must revalidate
	  the cached file length
		
		  We need to be sure that all dirty pages are written and the
		  server has the newest file length.
		
		  Some applications poll for the file length in this strange
		  way so we must seek to end on non-oplocked files by
		  setting the revalidate time to zero.
	
	  Note that this is called by vfs setlease with i_lock held to
	  protect lease from going away.
 Check if file is oplocked if this is request for new lease 
		
		  If the server claims to support oplock on this file, then we
		  still need to check oplock even if the local_lease mount
		  option is set, but there are servers which do not support
		  oplock for which this mount option may be useful if the user
		  knows that the file won't be changed on the server by anyone
		  else.
	
	  Note: cifs case is easier than btrfs since server responsible for
	  checks for proper open modes and file type and if it wants
	  server could even support copy of range where source = target
 should we flush first and last page first 
	 force revalidate of size and timestamps of target file now
	 although unlocking in the reverse order from locking is not
	
	  Note: cifs case is easier than btrfs since server responsible for
	  checks for proper open modes and file type and if it wants
	  server could even support copy of range where source = target
 should we flush first and last page first 
	 force revalidate of size and timestamps of target file now
	  that target is updated on the server
	 although unlocking in the reverse order from locking is not
	  strictly necessary here it is a little cleaner to be consistent
  Directory operations under CIFSSMB2SMB3 are synchronous, so fsync()
  is a dummy operation.
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
	
	  SMB2 maximum header size is bigger than CIFS one - no problems to
	  allocate some more bytes for CIFS.
	 Buffer size can not be smaller than 2  PATH_MAX since maximum
 Round size to even 512 byte mult
	cifs_dbg(VFS, "CIFSMaxBufSize %d 0x%x\n",
		 CIFSMaxBufSize, CIFSMaxBufSize);
	 MAX_CIFS_SMALL_BUFFER_SIZE bytes is enough for most SMB responses and
	almost all handle based requests (but not write response, nor is it
	sufficient for path based requests).  A smaller size would have
	been more efficient (compacting multiple slab items on one 4k page)
	for the case in which debug was on, but this larger size allows
	more SMBs to use small buffer alloc and is still much more
	efficient to alloc 1 per page off the slab compared to 17K (5page)
 3 is a reasonable minimum number of simultaneous operations 
   Initialize Global counters
 CONFIG_CIFS_STATS2 
	
	  Consider in future setting limit!=0 maybe to min(num_of_cores - 1, 3)
	  so that we don't launch too many worker threads but
	  Documentationcore-apiworkqueue.rst recommends setting it to 0
 WQ_UNBOUND allows decrypt tasks to run on any CPU 
 CONFIG_CIFS_DFS_UPCALL 
 CONFIG_CIFS_UPCALL 
 CONFIG_CIFS_SWN_UPCALL 
 combination of LGPL + GPL source behaves as GPL 
 SPDX-License-Identifier: GPL-2.0-or-later
    Copyright (C) 2020, Microsoft Corporation.
    Author(s): Steve French <stfrench@microsoft.com>
               Suresh Jayaraman <sjayaraman@suse.de>
               Jeff Layton <jlayton@kernel.org>
 extract the host portion of the UNC string 
 skip double chars at beginning of string 
 BB: check validity of these bytes? 
 delimiter between hostname and sharename is always '\\' now 
 skip double chars at the beginning 
 share name is always preceded by '\\' now 
 caller has to free the memory 
 SPDX-License-Identifier: LGPL-2.1
    Functions which do error mapping of SMB2 status codes to POSIX errors
    Copyright (C) International Business Machines  Corp., 2009
    Author(s): Steve French (sfrench@us.ibm.com)
 Note that ENOATTTR and ENODATA are the same errno 
 Print an error message from the status code
 mask facility 
 on error mapping not found  - return EIO 
 SPDX-License-Identifier: GPL-2.0-or-later
    Copyright (C) 2020, Microsoft Corporation.
    Author(s): Steve French <stfrench@microsoft.com>
               David Howells <dhowells@redhat.com>
#include <linuxmodule.h>
#include <linuxnsproxy.h>
#include <linuxslab.h>
#include <linuxmagic.h>
#include <linuxsecurity.h>
#include <netnet_namespace.h>
#ifdef CONFIG_CIFS_DFS_UPCALL
#include "dfs_cache.h"
#endif
 Mount options that take no arguments 
 Mount options which take numeric value 
 Mount options which take string value 
 Arguments that should be ignored 
	
	  UNC and prefixpath is now extracted from Opt_source
	  in the new mount API so we can just ignore them going forward.
	
	  With mount options, the last one should win. Reset any existing
	  settings back to default.
	
	  Make sure to stay in sync with smb3_cleanup_fs_context_contents()
 CIFS_ALLOW_INSECURE_LEGACY 
 currently identical with 3.0 
 currently identical with 3.0 
  Parse a devname into substrings and populate the ctx->UNC and ctx->prepath
  fields with the result. Returns 0 on success and an error otherwise
  (e.g. ENOMEM or EINVAL)
 make sure we have a valid UNC double delimiter prefix 
 find delimiter between host and sharename 
 record the server hostname 
 skip past delimiter 
 now go until next delimiter or end of string 
 move "pos" up to delimiter or NULL 
 skip any delimiter 
 If pos is NULL then no prepath 
  Parse a monolithic block of data from sys_mount().
  smb3_fs_context_parse_monolithic - Parse key[=val][,key[=val]] mount data
  @ctx: The superblock configuration to fill in.
  @data: The data to parse
  Parse a blob of data that's in key[=val][,key[=val]] form.  This can be
  called from the ->monolithic_mount_data() fs_context operation.
  Returns 0 on success or the error returned by the ->parse_option() fs_context
  operation on failure.
 BB Need to add support for sep= here TBD 
		 Check if following character is the deliminator If yes,
		  we have encountered a double deliminator reset the NULL
		  character to the deliminator
  Validate the preparsed information in the config.
 Muliuser mounts require CONFIG_KEYS support 
 make sure UNC has a share name 
 No ip= option specified? Try to get it from UNC 
 Use the address part of the UNC. 
 set the port that we got earlier 
  Create an SMB3 superblock from the parameters passed.
  Compare the old and new proposed context during reconfigure
  and check if the changes are compatible.
	
	  We can not change UNCusernamepassworddomainname
	  workstation_namenodenameiocharset
	  during reconnect so ignore what we have in the new context and
	  just use what we already have in cifs_sb->ctx.
 if rsize or wsize not passed in on remount, use previous values 
	
	  fs_parse can not handle string options with an empty value so
	  we will need special handling of them.
 disable SFU mapping 
 if number of channels not specified, default to 2 
		
		  inode blocksize realistically should never need to be
		  less than 16K or greater than 16M and default is 1MB.
		  Note that small inode block sizes (e.g. 64K) can lead
		  to very poor performance of common tools like cp and scp
		
		  readahead size realistically should never need to be
		  less than 1M (CIFS_DEFAULT_IOSIZE) or greater than 32M
		  (perhaps an exception should be considered in the
		  for the case of a large number of channels
		  when multichannel is negotiated) since that would lead
		  to plenty of parallel IO in flight to the server.
		  Note that smaller read ahead sizes would
		  hurt performance of common tools like cp and scp
		  which often trigger sequential io with read ahead
 If more than one channel requested ... they want multichan 
 null user, ie. anonymous authentication 
		 if iocharset not set then load_nls_default
		  is used by caller
		
		  FIXME: are there cases in which a comma can
		  be valid in workstation netbios name (and
		  need special handling)?
 don't ucase netbiosname for user 
		 The string has 16th byte zero still from
		  set at top of the function
 last byte, type, is 0x20 for servr type 
		
		  BB are there cases in which a comma can be valid in this
		  workstation netbios name (and need special handling)?
 user or mount helper must uppercase the netbios name 
 The string has 16th byte zero still from set at top of function 
 version of mount userspace tools, not dialect 
 If interface changes in mount.cifs bump to new ver 
 This is the default 
 For all other value, error 
 protocol version (dialect) 
			
			  turn off mandatory locking in mode
			  if remote locking is turned off since the
			  local vfs will do advisory
		 we do not do the following in secFlags because seal
		  is a per tree connection (mount) not a per socket
		  or per-smb connection option in the protocol
		  vol->secFlg |= CIFSSEC_MUST_SEAL;
 already the default 
 tcp nodelay should not usually be needed since we CORKUNCORK the socket 
 case Opt_ignore: - is ignored as expected ... 
	
	  does not have to be perfect mapping since field is
	  informational, only used for servers that do not support
	  port 445 and it can be overridden at mount time
	
	  null target name indicates to use SMBSERVR default called name
	   if we end up sending RFC1001 session initialize
 By default 4MB read ahead size, 1MB block size 
 can improve cp performance significantly 
 0 = use default (ie negotiated rsize) for read ahead pages 
	
	  default to SFM style remapping of seven reserved characters
	  unless user overrides it or we negotiate CIFS POSIX where
	  it is unnecessary.  Can not simultaneously use more than one mapping
	  since then readdir could list files that open could not open
 default to only allowing write access to owner of the mount 
 ctx->retry default is 0 (i.e. "soft" limited retry not hard retry) 
 default is always to request posix paths. 
 default to using server inode numbers where available 
 default is to use strict cifs caching semantics 
 Most clients set timeout to 0, allows server to use its default 
 See MS-SMB2 spec section 2.2.14.2.12 
 offer SMB2.1 and later (SMB3 etc). Secure and widely accepted 
 default to no multichannel (single server connection) 
 no backup intent for a user 
 no backup intent for a group 
 	short int override_uid = -1;
 	short int override_gid = -1;
 	char nodename = strdup(utsname()->nodename);
 	struct sockaddr dstaddr = (struct sockaddr )&vol->dstaddr;
	
	  Make sure this stays in sync with smb3_fs_context_dup()
			
			  Our SFU ("Services for Unix" emulation does not allow
			  creating symlinks but does allow reading existing SFU
			  symlinks (it does allow both creating and reading SFU
			  style mknod and FIFOs though). When "mfsymlinks" and
			  "sfu" are both enabled at the same time, it allows
			  reading both types of symlinks, but will only create
			  them with mfsymlinks format. This allows better
			  Apple compatibility (probably better for Samba too)
			  while still recognizing old Windows style symlinks.
 SPDX-License-Identifier: GPL-2.0
  Witness Service client for CIFS
  Copyright (c) 2020 Samuel Cabrero <scabrero@suse.de>
  Sends a register message to the userspace daemon based on the registration.
  The authentication information to connect to the witness service is bundled
  into the message.
	
	  If there is an address stored use it instead of the server address, because we are
	  in the process of reconnecting to it after a share has been moved or we have been
	  told to switch to it (client move message). In these cases we unregister from the
	  server address and register to the new address when we receive the notification.
  Sends an uregister message to the userspace daemon based on the registration
  Try to find a matching registration for the tcon's server name and share name.
  Calls to this function must be protected by cifs_swnreg_idr_mutex.
  TODO Try to avoid memory allocations
  Get a registration for the tcon's server and share name, allocating a new one if it does not
  exists
 Check if we are already registered for this network and share names 
 Store the reconnect address 
	
	  Unregister to stop receiving notifications for the old IP address.
	
	  And register to receive notifications for the new IP address now that we have
	  stored the new address.
 Do not put the swnreg or return error, the echo task will retry 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (c) International Business Machines  Corp., 2003, 2007
    Author(s): Steve French (sfrench@us.ibm.com)
 DACL only 
 owner plus DACL 
 ownerDACLSACL 
 full name: user.cifs.dosattrib 
 user.cifs.creationtime 
  Although these three are just aliases for the above, need to move away from
  confusing users and using the 20+ year old term 'cifs' when it is no longer
  secure, replaced by SMB2 (then even more highly secure SMB3) many years ago
 DACL only 
 owner plus DACL 
 ownerDACLSACL 
 full name: user.smb3.dosattrib 
 user.smb3.creationtime 
 BB need to add server (Samba e.g) support for security and trusted prefix 
 return dos attributes as pseudo xattr 
 return alt name if available as pseudo attr 
	 if procfscifsstreamstoxattr is set then
		search server for EAs or streams to
 force revalidate of the inode 
 force revalidate of the inode 
 force revalidate of the inode 
 CONFIG_CIFS_POSIX 
 CONFIG_CIFS_POSIX 
 return dos attributes as pseudo xattr 
 return dos attributes as pseudo xattr 
 return alt name if available as pseudo attr 
		
		  fetch owner, DACL, and SACL if asked for full descriptor,
		  fetch owner and DACL otherwise
 rc already EOPNOTSUPP 
 CONFIG_CIFS_POSIX 
 CONFIG_CIFS_POSIX 
	 We could add an additional check for streams ie
	    if procfscifsstreamstoxattr is set then
		search server for EAs or streams to
 return dos attributes as pseudo xattr 
 return alt name if available as pseudo attr 
	 if procfscifsstreamstoxattr is set then
		search server for EAs or streams to
 os2. attributes are treated like user. attributes 
  Although this is just an alias for the above, need to move away from
  confusing users and using the 20 year old term 'cifs' when it is no
  longer secure and was replaced by SMB2SMB3 a long time ago, and
  SMB3 and later are highly secure.
  Although this is just an alias for the above, need to move away from
  confusing users and using the 20 year old term 'cifs' when it is no
  longer secure and was replaced by SMB2SMB3 a long time ago, and
  SMB3 and later are highly secure.
  Although this is just an alias for the above, need to move away from
  confusing users and using the 20 year old term 'cifs' when it is no
  longer secure and was replaced by SMB2SMB3 a long time ago, and
  SMB3 and later are highly secure.
 alias for above since avoiding "cifs" 
 alias for above since avoiding "cifs" 
 alias for above since avoiding "cifs" 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2010
    Author(s): Steve French (sfrench@us.ibm.com)
 not direct, send byte range locks 
 check if server can support readpages 
 NO DFS support, treat as a directory 
 check inode attributes against fattr. If they don't match, tag the
  inode for cache invalidation
 don't bother with revalidation if we have an oplock 
 revalidate if mtime or size have changed 
  copy nlink to the inode, unless it wasn't provided.  Provide
  sane values if we don't have an existing one and none was provided
	
	  if we're in a situation where we can't trust what we
	  got from the server (readdir, some non-unix cases)
	  fake reasonable values
 only provide fake values on a new inode 
 we trust the server, so update it 
 populate an inode with info from a cifs_fattr struct 
 force reval 
 we do not want atime to be less than mtime, it broke some apps 
 if dynperm is set, don't clobber existing mode 
	
	  Can't safely change the file size here if the client is writing to
	  it due to potential races.
		
		  i_blocks is not related to (i_size  i_blksize),
		  but instead 512 byte (29) size is required for
		  calculating num blocks.
 Fill a cifs_fattr struct with info from FILE_UNIX_BASIC_INFO. 
 old POSIX extensions don't get create time 
	
	  Since we set the inode type below we need to mask off
	  to avoid strange results if bits set above.
 safest to call it a file if we do not know 
  Fill a cifs_fattr struct with fake inode info.
  Needed to setup cifs_fattr data for the directory which is the
  junction to the new submount (ie to setup the fake directory
  which represents a DFS referral).
 could have done a find first instead but this returns more info 
 check for Minshall+French symlinks 
 get new inode 
 we already have inode, update it 
 if uniqueid is different, return error 
 force reval 
 if filetype is different, return error 
 EOPNOTSUPP? 
 Read header 
 we have enough to decode dev num 
 major 
 minor 
 we have enough to decode dev num 
 major 
 minor 
 file? 
 then it is a file 
 or some unknown SFU type 
 SETFILEBITS valid bits 
  Fetch mode bits as provided by SFU.
  FIXME: Doesn't this clobber the type bit we got from cifs_sfu_type ?
 size of buf ,
 Fill a cifs_fattr struct with info from POSIX info struct 
 no fattr->flags to set 
 The srv fs device id is overridden on network mount so setting rdev isn't needed here 
 fattr->cf_rdev = le32_to_cpu(info->DeviceId); 
 file 
 else if reparse point ... TODO: add support for FIFO and blk dev; special file types 
 TODO: map uid and gid from SID 
 Fill a cifs_fattr struct with info from FILE_ALL_INFO 
 TODO add more reparse tag checks 
		
		  Server can return wrong NumberOfLinks value for directories
		  when Unix extensions are disabled - fake it.
 clear write bits if ATTR_READONLY is set 
		
		  Don't accept zero nlink from non-unix servers unless
		  delete is pending.  Instead mark it as unknown.
 TODO: add support to query reparse tag 
 no reparse tag );
		
		  FIXME: legacy server -- fall back to path-based call?
		  for now, just skip revalidating and mark inode for
		  immediate reval.
	
	  don't bother with SFU junk here -- just mark inode as needing
	  revalidation.
 if filetype is different, return error 
 Simple function to return a 64 bit hash of string.  Rarely called 
 a big enough prime 
  cifs_backup_query_path_info - SMB1 fallback code to get ino
  Fallback code to get file metadata when we don't have access to
  full_path (EACCES) and have backup creds.
  @xid:	transaction id used to identify original request in logs
  @tcon:	information about the server share we have mounted
  @sb:	the superblock stores info such as disk space available
  @full_path:	name of the file we are getting the metadata for
  @resp_buf:	will be set to cifs resp buf and needs to be freed with
  		cifs_buf_release() when done with @data
  @data:	will be set to search info result buffer
 no srvino useful for fallback to some netapp 
	
	  If we have an inode pass a NULL tcon to ensure we don't
	  make a round trip to the server. This only works for SMB2+.
		
		  If that fails reuse existing ino or generate one
		  and disable server ones
 If no errors, check for zero root inode (invalid) 
 reuse 
 make an ino by hashing the UNC 
	
	  1. Fetch file metadata if not provided (data)
	
	  2. Convert it to internal cifs metadata (fattr)
		
		  If the file is a reparse point, it is more complicated
		  since we have to check if its reparse tag matches a known
		  special file type e.g. symlink or fifo or char etc.
 DFS link, no metadata available on this server 
		
		  perm errors, try again with backup flags if possible
		 
		  For SMB2 and later the backup intent flag
		  is already sent if needed on open and there
		  is no path based FindFirst operation to use
		  to retry with
 for easier reading 
 uniqueid set, skip get inum step 
 nothing we can do, bail out 
	
	  3. Get or update inode number (fattr.cf_uniqueid)
	
	  4. Tweak fattr based on mount options
 query for SFU type info if supported and needed 
 fill in 0777 bits from ACL 
 fill in remaining high mode bits e.g. SUID, VTX 
 check for Minshall+French symlinks 
	
	  5. Update inode with final fattr data
 we already have inode, update it 
 if uniqueid is different, return error 
 force reval 
 if filetype is different, return error 
	
	  1. Fetch file metadata
	
	  2. Convert it to internal cifs metadata (fattr)
 DFS link, no metadata available on this server 
		
		  For SMB2 and later the backup intent flag
		  is already sent if needed on open and there
		  is no path based FindFirst operation to use
		  to retry with so nothing we can do, bail out
	
	  3. Tweak fattr based on mount options
 check for Minshall+French symlinks 
	
	  4. Update inode with final fattr data
 we already have inode, update it 
 if uniqueid is different, return error 
 force reval 
 if filetype is different, return error 
 don't match inode with different uniqueid 
 use createtime like an i_generation field 
 don't match inode of different type 
 if it's not a directory or has no dentries, then flag it 
  walk dentry list for an inode and report whether it has aliases that
  are hashed. We use this to determine if a directory inode can actually
  be used.
 Given fattrs, get a corresponding inode 
 hash down to 32-bits on 32-bit arch 
 was there a potentially problematic inode collision? 
 can't fail - see cifs_find_inode() 
 initialize per-inode cache cookie pointer 
 gets root inode 
 leading sep + null , GFP_KERNEL);
 some servers mistakenly claim POSIX support 
 populate tcon->resource_id 
	
	  Samba throws this field away, but windows may actually use it.
	  Do not set ctime unless other time stamps are changed explicitly
	  (i.e. by utimes()) since we would then have a mix of client and
	  server times.
 don't change 
  Open the given file (if it isn't already), set the DELETE_ON_CLOSE bit
  and rename it to a random name that hopefully won't conflict with
  anything else.
	
	  We cannot rename the file if the server doesn't support
	  CAP_INFOLEVEL_PASSTHRU
 set ATTR_HIDDEN and clear ATTR_READONLY, but only if needed 
		 although we would like to mark the file hidden
 since not able to change them 
 rename the file 
 try to set DELETE_ON_CLOSE 
		
		  some samba versions return -ENOENT when we try to set the
		  file disposition here. Likely a samba bug, but work around
		  it for now. This means that some cifsXXX files may hang
		  around after they shouldn't.
		 
		  BB: remove this hack after more servers have the fix
	
	  reset everything back to the original state. Don't bother
	  dealing with errors here since we can't do anything about
	  them anyway.
 copied from fsnfsdir.c with small changes 
  If d_inode(dentry) is null (usually meaning the cached dentry
  is a negative dentry) then we would attempt a standard SMB delete, but
  if that fails we can not attempt the fall back mechanisms on EACCES
  but will return the EACCES to the caller. Note that the VFS does not call
  unlink on negative dentries currently.
	 Unlink can be called from rename so we can not take the
 try to reset dos attributes 
 undo the setattr if we errored out and it's needed 
		cifs_inode->time = 0;	 will force revalidate to get info
 force revalidate of dir as well 
		
		  mkdir succeeded, but another client has managed to remove the
		  sucker and replace it with non-directory.  Return success,
		  but don't leave the child in dcache.
	
	  setting nlink not necessary except in cases where we failed to get it
	  from the server or was set bogus. Also, since this is a brand new
	  inode, no need to grab the i_lock before setting the i_nlink.
 must turn on setgid bit if parent dir has it 
 no change 
 no change 
 netfid , info, &oplock, full_path,
 no return info, go query for it 
	
	  BB check (cifs_sb->mnt_cifs_flags & CIFS_MOUNT_SET_UID ) to see if
	  need to set uidgid.
 for time being always refresh inode info 
 BB add setting the equivalent of mode via CreateX wACLs 
 TODO: skip this for smb2smb3 
	
	  Force revalidate to get parent dir info when needed since cached
	  attributes are invalid now.
 force revalidate to go get info when needed 
	
	  Force revalidate to get parent dir info when needed since cached
	  attributes are invalid now.
 try path-based rename first 
	
	  Don't bother with rename by filehandle unless file is busy and
	  source. Note that cross directory moves do not work with
	  rename by filehandle to various Windows servers.
 Don't fall back to using SMB on SMB 2+ mount 
 open-file renames don't work across directories 
 open the file to be renamed -- we need DELETE perms 
	
	  No-replace is the natural behavior for CIFS, so skip unlink hacks.
		
		  Are src and dst hardlinks of same inode? We can only tell
		  with unix extensions enabled.
 same file, POSIX says that this is a noop 
	
	  else ... BB we could add the same check for Windows by
	  checking the UniqueId via FILE_INTERNAL_INFO
 Try unlinking the target dentry if it's not negative 
 force revalidate to go get info when needed 
	
	  depending on inode type, check if attribute caching disabled for
	  files or directories
 file 
 hardlinked files w noserverino get "special" treatment 
  Zap the cache. Called when invalid_mapping flag is set.
  cifs_wait_bit_killable - helper for functions that are sleeping on bit locks
  @key:	currently unused
  @mode:	the task state to sleep in
 swapfiles are not supposed to be shared 
 for cache=singleclient, do not invalidate 
 revalidate a dentry's inode attributes 
	
	  We need to be sure that all dirty pages are written and the server
	  has actual ctime, mtime and file length.
 force revalidate 
	
	  If the caller doesn't require syncing, only sync if
	  necessary (e.g. due to earlier truncate or setattr
	  invalidating the cached metadata)
 old CIFS Unix Extensions doesn't return create time 
	
	  If on a multiuser mount without unix extensions or cifsacl being
	  enabled, and the admin hasn't overridden them, set the ownership
	  to the fsuidfsgid of the current process.
	
	  We need to be sure that all dirty pages are written as they
	  might fill holes on the server.
 Cached inode must be refreshed on truncate 
	
	  To avoid spurious oplock breaks from server, in the case of
	  inodes that we already have open, avoid doing path based
	  setting of file size if we can do it by handle.
	  This keeps our caching token (oplock) and avoids timeouts
	  when the local oplock break takes longer to flush
	  writebehind data than the SMB timeout for the SetPathInfo
	  request would allow
	
	  Set file size by pathname rather than by handle either because no
	  valid, writeable file handle for it was found or because there was
	  an error setting it by handle.
		
		  i_blocks is not related to (i_size  i_blksize), but instead
		  512 byte (29) size is required for calculating num blocks.
		  Until we can query the server for actual allocation size,
		  this is best estimate we have for blocks allocated for a file
		  Number of blocks must be rounded up so size 1 is not 0 blocks
		
		  The man page of truncate says if the size changed,
		  then the st_ctime and st_mtime fields for the file
		  are updated.
	
	  Attempt to flush data before changing attributes. We need to do
	  this for ATTR_SIZE and ATTR_MTIME for sure, and if we change the
	  ownership or mode then we may also need to do this. Here, we take
	  the safe way out and just do the flush on all setattr requests. If
	  the flush returns error, store it to report later and continue.
	 
	  BB: This should be smarter. Why bother flushing pages that
	  will be truncated anyway? Also, should we error out here if
	  the flush returns error?
 skip mode change if it's just for clearing setuidsetgid 
 set up the struct 
 no change 
 no change 
	 force revalidate when any of these times are set since some
	   of the fs types (eg ext3, fat) do not have fine enough
	   time granularity to match protocol, and we do not have a
	   a way (yet) to query the server fs's time granularity (and
	   whether it rounds times down).
	
	  Attempt to flush data before changing attributes. We need to do
	  this for ATTR_SIZE and ATTR_MTIME.  If the flush of the data
	  returns error, store it to report later and continue.
	 
	  BB: This should be smarter. Why bother flushing pages that
	  will be truncated anyway? Also, should we error out here if
	  the flush returns error? Do we need to check for ATTR_MTIME_SET flag?
 skip mode change if it's just for clearing setuidsetgid 
			
			  In case of CIFS_MOUNT_CIFS_ACL, we cannot support all modes.
			  Pick up the actual mode bits that were set.
 fix up mode if we're not using dynperm 
 Attributes of 0 are ignored 
 reset local inode permissions to normal 
 ignore mode change - ATTR_READONLY hasn't changed 
 BB: check for rc = -EOPNOTSUPP and switch to legacy mode 
		 Even if error on time set, no sense failing the call if
		the server would set the time to a reasonable value anyway,
		and this check ensures that we are not being called from
		sys_utimes in which case we ought to fail the call back to
	 do not need local check to inode_check_ok since the server does
 BB: add cifs_setattr_legacy for really old servers 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002, 2011
                  Etersoft, 2012
    Author(s): Pavel Shilovsky (pshilovsky@samba.org),
               Steve French (sfrench@us.ibm.com)
  note: If cfile is passed, the reference to it is dropped here.
  So make sure that you do not reuse cfile after return from this func.
 We already have a handle so we can skip the open 
 Open 
 Operation 
 TBD: fix following to allow for longer SIDs 
		
		  Directories are created through parameters in the
		  SMB2_open() call.
 sizeof __u8 See MS-FSCC section 2.4.11 
 sizeof __le64 
 null ;
 null ;
 We already have a handle so we can skip the close 
 Close 
 add SIDs , ptr);
 we don't use it 
 If it is a root and its handle is cached then use it 
 Failed on a symbolic link - query a reparse point info 
 BB TODO: Make struct larger when add support for parsing owner SIDs 
	
	  BB TODO: Add support for using the cached root handle.
	  Create SMB2_query_posix_info worker function to do non-compounded query
	  when we already have an open file handle for this. For now this is fast enough
	  (always using the compounded version).
 BB TODO: When support for special files added to Samba re-verify this path 
 Failed on a symbolic link - query a reparse point info 
 TODO: will need to allow for the 2 SIDs when add support for getting owner UIDGID 
 would be a no op, no sense sending this 
 SPDX-License-Identifier: GPL-2.0-or-later
   Unix SMBNetbios implementation.
   Version 1.9.
   RPC Pipe client  server routines
   Copyright (C) Luke Kenneth Casson Leighton 1997-2001.
 NT error codes - see nterr.h 
 SPDX-License-Identifier: GPL-2.0-or-later
    Copyright (C) International Business Machines  Corp., 2000,2005
    Modified by Steve French (sfrench@us.ibm.com)
 CONFIG_CIFS_DEBUG2 
 STATS2 
 CONFIG_CIFS_DEBUG2 
 CIFS_DEBUG2 
 CIFS_DEBUG2 
 channel info will be printed as a part of sessions below 
 dump session id helpful for use with network trace 
 BB add code to dump additional info such as TCP session info now 
 CONFIG_CIFS_STATS2 
 CONFIG_CIFS_STATS2 
 STATS2 
 CONFIG_CIFS_STATS2 
 STATS2 
 see cifs_debug.h for meanings 
  Ensure that if someone sets a MUST flag, that we disable all other MAY
  flags except for the ones corresponding to the given MUST flag. If there are
  multiple MUST flags, then try to prefer more secure ones.
 single char or single char followed by null 
 else we have a number 
 flags look ok - update the global security flags for cifs module 
 requiring signing implies signing is allowed 
 BB should we turn on MAY flags for other MUST options? 
 To make it easier to debug, can help to show mount params 
 cannot use switch with pointers... 
 No need for write for now 
 .proc_write	= cifs_mount_params_proc_write, 
 PROC_FS 
 SPDX-License-Identifier: LGPL-2.1
    vfs operations that deal with dentries
    Copyright (C) International Business Machines  Corp., 2002,2009
    Author(s): Steve French (sfrench@us.ibm.com)
	 BB check if there is a way to get the kernel to do this or if we
 if no prefix path, simply set path to the root of share to "" 
 Note: caller must free return buffer 
 for root we want "", not ""
 BB test paths to Windows with '' in the midst of prepath 
  Don't allow path components longer than the server max.
  Don't allow the separator character in a path component.
  The VFS will not allow "", but "\" is allowed by posix.
 Inode operations in similar order to how they appear in Linux file fs.h 
 query inode info 
				
				  The server may allow us to open things like
				  FIFOs, but the client isn't set up to deal
				  with that. If it's not a regular file, just
				  close it and proceed as if it were a normal
				  lookup.
 success, no need to query 
			
			  EIO could indicate that (posix open) operation is not
			  supported, despite what server claimed in capability
			  negotiation.
			 
			  POSIX open in samba versions 3.3.1 and earlier could
			  incorrectly fail with invalid parameter.
			
			  EREMOTE indicates DFS junction, which is not handled
			  in posix open.  If either that or op not supported
			  returned, follow the normal lookup.
		
		  fallthrough to retry, using older open call, this is case
		  where server does not support this SMB level, and falsely
		  claims capability (also get here for DFS case which should be
		  rare for path not covered on files)
 is this too little? 
	
	  BB add processing to set equivalent of mode - e.g. via CreateX with
	  ACLs
	
	  if we're not using unix extensions, see if we need to set
	  ATTR_READONLY on the create call
	
	  If Open reported that we actually created a file then we now have to
	  set the mode if possible.
 no change 
 no change 
		
		  BB implement mode setting via Windows security
		  descriptors e.g.
 CIFSSMBWinSetPerms(xid,tcon,path,mode,-1,-1,nls);
 Could set ro dos attribute if mode & 0222 == 0 
 server might mask mode so we have to query for it 
 TODO: Add support for calling POSIX query info here, but passing in fid 
	
	  Posix open is only called (at lookup time) for file create now. For
	  opens (rather than creates), because we do not know if it is a file
	  or directory yet, and current Samba no longer allows us to do posix
	  open on dirs, we could end up wasting an open call on what turns out
	  to be a dir. For file opens, we wait to call posix open till
	  cifs_open.  It could be added to atomic_open in the future but the
	  performance tradeoff of the extra network request when EISDIR or
	  EACCES is returned would have to be weighed against the 50% reduction
	  in network traffic in the other paths.
		
		  Check for hashed negative dentry. We have already revalidated
		  the dentry and it is fine. No need to perform another lookup.
	
	  BB below access is probably too much for mknod to request
	     but we have to do query and setpathinfo so requesting
	     less could fail (unless we want to request getatr and setatr
	     permissions (only).  At least for POSIX we do not have to
	     request so much.
 to get around spurious gcc warning, set to zero here 
 check whether path exists 
	 can not grab the rename sem here since it would
	deadlock in the cases (beginning of sys_rename itself)
		 since paths are not looked up by component - the parent
			 We special case check for Access Denied - since that
 force reval 
				
				  Those errors mean the dentry is invalid
				  (file was deleted or recreated)
				
				  Otherwise some unexpected error happened
				  report it as-is to VFS layer
			
			  If the inode wasn't known to be a dfs entry when
			  the dentry was instantiated, such as when created
			  via ->readdir(), it needs to be set now since the
			  attributes will have been updated by
			  cifs_revalidate_dentry().
	
	  This may be nfsd (or something), anyway, we can't see the
	  intent of this. So, since this can be for creation, drop it.
	
	  Drop the negative dentry, in order to make sure to use the
	  case sensitive name which is specified by user if this is
	  for creation.
 static int cifs_d_delete(struct dentry direntry)
{
	int rc = 0;
	cifs_dbg(FYI, "In cifs d_delete, name = %pd\n", direntry);
	return rc;
 d_delete:       cifs_d_delete,       
 error out if we can't convert the character 
	
	  We make the assumption here that uppercase characters in the local
	  codepage are always the same length as their lowercase counterparts.
	 
	  If that's ever not the case, then this will fail to match it.
 Convert characters in both strings to UTF-16. 
		
		  If we can't convert either character, just declare it to
		  be 1 byte long and compare the original byte.
		
		  Here, we again ass|u|me that upperlowercase versions of
		  a character are the same length in the local NLS.
 Now compare uppercase versions of these characters 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2011
                  Etersoft, 2012
    Author(s): Steve French (sfrench@us.ibm.com)
               Pavel Shilovsky (pshilovsky@samba.org) 2012
	
	  Make sure that this really is an SMB, that it is a response,
	  and that the message ids match.
 only one valid case where server sends us request 
 bad signature or mid 
   The following table defines the expected "StructureSize" of SMB2 responses
   in order by SMB2 command.  This is similar to "wct" in SMBCIFS responses.
   Note that commands are defined in smb2pdu.h in le16 but the array below is
   indexed by command in host byte order
 SMB2_NEGOTIATE  cpu_to_le16(65),
 SMB2_SESSION_SETUP  cpu_to_le16(9),
 SMB2_LOGOFF  cpu_to_le16(4),
 SMB2_TREE_CONNECT  cpu_to_le16(16),
 SMB2_TREE_DISCONNECT  cpu_to_le16(4),
 SMB2_CREATE  cpu_to_le16(89),
 SMB2_CLOSE  cpu_to_le16(60),
 SMB2_FLUSH  cpu_to_le16(4),
 SMB2_READ  cpu_to_le16(17),
 SMB2_WRITE  cpu_to_le16(17),
 SMB2_LOCK  cpu_to_le16(4),
 SMB2_IOCTL  cpu_to_le16(49),
 BB CHECK this ... not listed in documentation 
 SMB2_CANCEL  cpu_to_le16(0),
 SMB2_ECHO  cpu_to_le16(4),
 SMB2_QUERY_DIRECTORY  cpu_to_le16(9),
 SMB2_CHANGE_NOTIFY  cpu_to_le16(9),
 SMB2_QUERY_INFO  cpu_to_le16(9),
 SMB2_SET_INFO  cpu_to_le16(2),
 BB FIXME can also be 44 for lease break 
 SMB2_OPLOCK_BREAK  cpu_to_le16(24)
 Negotiate contexts are only valid for latest dialect SMB3.11 
	
	  if SPNEGO blob present (ie the RFC2478 GSS info which indicates
	  which security mechanisms the server supports) make sure that
	  the negotiate contexts start after it
	
	  non_ctxlen is at least shdr->StructureSize + pdu->StructureSize2
	  and the latter is 1 byte bigger than the fix-sized area of the
	  NEGOTIATE response
 has padding, but no SPNEGO blob 
 Verify that at least minimal negotiate contexts fit within frame 
 length of negcontexts including pad from end of sec blob to them 
 calculated length 
	
	  Add function to do table lookup of StructureSize by command
	  ie Validate the wct via smb2_struct_sizes table above
 decrypt frame now that it is completely read in 
			
			  As with SMBCIFS, on some error cases servers may
			  not return wct properly
 error packets have 9 byte structure size 
 special case for SMB2.1 lease break message 
 create failed on symlink 
 Windows 7 server returns 24 bytes more 
 server can return one byte more due to implied bcc[0] 
		
		  Some windows servers (win2016) will pad also the final
		  PDU in a compound to 8 bytes.
		
		  MacOS server pads after SMB2.1 write response with 3 bytes
		  of junk. Other servers match RFC1001 len to actual
		  SMB2SMB3 frame length (header + smb2 response specific data)
		  Some windows servers also pad up to 8 bytes when compounding.
  The size of the variable area depends on the offset and length fields
  located in different fields for various SMB2 responses. SMB2 responses
  with no variable length info, show an offset of zero for the offset field.
 SMB2_NEGOTIATE  true,
 SMB2_SESSION_SETUP  true,
 SMB2_LOGOFF  false,
 SMB2_TREE_CONNECT 	false,
 SMB2_TREE_DISCONNECT  false,
 SMB2_CREATE  true,
 SMB2_CLOSE  false,
 SMB2_FLUSH  false,
 SMB2_READ 	true,
 SMB2_WRITE  false,
 SMB2_LOCK 	false,
 SMB2_IOCTL  true,
 SMB2_CANCEL  false, 
 SMB2_ECHO  false,
 SMB2_QUERY_DIRECTORY  true,
 SMB2_CHANGE_NOTIFY  true,
 SMB2_QUERY_INFO  true,
 SMB2_SET_INFO  false,
 SMB2_OPLOCK_BREAK  false
  Returns the pointer to the beginning of the data area. Length of the data
  area and the offset to it (from the beginning of the smb are also returned.
 error responses do not have data area 
	
	  Following commands have data areas so we have to get the location
	  of the data buffer offset and data buffer length for the particular
	  command.
 TODO: is this a bug ? 
	
	  Invalid length or offset probably means data area is invalid, but
	  we have little choice but to ignore the data area in this case.
 return pointer to beginning of data area, ie offset from SMB start 
  Calculate the size of the SMB message based on the fixed header
  portion, the number of word parameters and the data portion of the message.
 the offset from the beginning of SMB to data area 
 the length of the variable length data area 
 Structure Size has already been checked to make sure it is 64 
	
	  StructureSize2, ie length of fixed parameter area has already
	  been checked to make sure it is the correct length.
		
		  Check to make sure that data area begins after fixed area,
		  Note that last byte of the fixed area is part of data area
		  for some commands, typically those with odd StructureSize,
		  so we must add one to the calculation.
 Note: caller must free return buffer 
 Windows doesn't allow paths beginning with \ 
 SMB311 POSIX extensions paths do not include leading slash 
 look up tcon based on tid & uid 
 look up tcon based on tid & uid 
  Caller should already has an extra reference to @tcon
  This function is used to queue work to close a handle to prevent leaks
  on the server.
  We handle two cases. If an open was interrupted after we sent the
  SMB2_CREATE to the server but before we processed the reply, and second
  if a close was interrupted before we sent the SMB2_CLOSE to the server.
  smb311_update_preauth_hash - update @ses hash with the packet data in @iov
  Assumes @iov does not contain the rfc1002 length and iov[0] has the
  SMB2 header.
  @ses:	server session structure
  @iov:	array containing the SMB request we will send to the server
  @nvec:	number of array entries for the iov
 neg prot are always taken 
	
	  If we process a command which wasn't a negprot it means the
	  neg prot was already done, so the server dialect was set
	  and we can test it. Preauth requires 3.1.1 for now.
 skip last sess setup response 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2010
    Author(s): Steve French (sfrench@us.ibm.com)
    Contains the routines for constructing the SMB PDUs themselves
 SMBCIFS PDU handling routines here - except for leftovers in connect.c   
 These are mostly routines that operate on a pathname, or on a tree id     
 (mounted volume), but there are eight handle based routines which must be 
 treated slightly differently for reconnection purposes since we never     
 want to reuse a stale file handle and only the caller knows the file info 
 define the number of elements in the cifs dialect array 
 not posix 
 CIFS_POSIX 
  Mark as invalid, all open files on tree connections since they
  were closed when session to server was lost.
 list all files open on tree connection and mark them invalid 
 cached handle is not valid, so SMB2_CLOSE won't be sent below 
	
	  BB Add call to invalidate_inodes(sb) for all superblocks mounted
	  to this tcon.
 reconnect the socket, tcon, and smb session if needed 
	
	  SMBs NegProt, SessSetup, uLogoff do not have tcon yet so check for
	  tcp and smb session status done differently for those three - in the
	  calling routine
	
	  only tree disconnect, open, and write, (and ulogoff which does not
	  have tcon) are allowed as we start force umount
	
	  Give demultiplex thread up to 10 seconds to each target available for
	  reconnect -- should be greater than cifs socket timeout which is 7
	  seconds.
 are we still trying to reconnect? 
		
		  on "soft" mounts we wait once. Hard mounts keep
		  retrying until process is killed or server comes
		  back on-line
	
	  need to prevent multiple threads trying to simultaneously
	  reconnect the same SMB session
	
	  Recheck after acquire mutex. If another thread is negotiating
	  and the server never sends an answer the socket will be closed
	  and tcpStatus set to reconnect.
 do we need to reconnect tcon? 
 tell server Unix caps we support 
	
	  Removed call to reopen open files here. It is safer (and faster) to
	  reopen files one at a time as needed in read and write.
	 
	  FIXME: what about file locks? don't we need to reclaim them ASAP?
	
	  Check if handle based operation so we know whether we can continue
	  or not without returning to caller to reset file handle
 Allocate and return pointer to an SMB request buffer, and set basic
   SMB information in the SMB header.  If the return code is zero, this
 BB should we add a retry in here if not a writepage? 
 uid, tid can stay at zero as set in header assemble 
	 BB add support for turning on the signing when
 If the return code is zero, this function must fill in request_buf pointer 
 BB should we add a retry in here if not a writepage? 
 Although the original thought was we needed the response buf for  
 potential retries of smb operations it turns out we can determine 
 from the mid flags when the request buffer can be resent without  
 having to use a second distinct buffer for the response 
 If the return code is zero, this function must fill in request_buf pointer 
 check for plausible wct 
 check for parm and data offset going beyond end of smb 
	 check that bcc is at least as big as parms + data, and that it is
	  less than negotiated smb buffer
	
	  Is signing required by mnt options? If not then check
	  global_secflags to see if it is there.
	
	  If signing is required then it's automatically enabled too,
	  otherwise, check to see if the secflags allow it.
 If server requires signing, does client allow it? 
 If client requires signing, does server allow it? 
 no tcon yet  ,
	
	  We know that all the name entries in the protocols array
	  are short (< 16 bytes anyway) and are NUL terminated.
 Check wct = 1 error case 
		 core returns wct = 1, but we do not ask for core - otherwise
		small wct just comes when dialect index is -1 indicating we
 unknown wct 
 else wct == 17, NTLM or better 
	 one byte, so no need to convert this or EncryptionKeyLen from
 probably no need to store and check maxvcs 
 set up max_read for readpages check 
 no crypt key only if plain text pwd 
 BB: do we need to check this? These should never be NULL. 
	
	  No need to return error on this operation if tid invalidated and
	  closed on server already e.g. due to tcp session crashing. Also,
	  the tcon is no longer on the list, so no need to take lock before
	  checking this.
	 No need to return error on this operation if tid invalidated and
  This is a no-op for now. We're not really interested in the reply, but
  rather in the fact that the server sent one and that server->lstrp
  gets updated.
  FIXME: maybe we should consider checking that the reply matches request?
 set up echo request 
	
	  BB: do we need to check validity of ses and server? They should
	  always be valid since we have an active reference. If not, that
	  should probably be a BUG()
		goto session_already_dead;  no need to send SMBlogoff if uid
	 if session dead then we do not need to do ulogoff,
		since server closed smb session, no sense reporting
 trailing null 
 BB double check this with jra 
	 Setup pointer to Request Data (inode type).
	  Note that SMB offsets are from the beginning of SMB which is 4 bytes
	  in, after RFC1001 field
 pad   + params + sizeof(struct unlink_psx_rq);
 trailing null 
 trailing null 
 trailing null 
 trailing null 
 large enough 
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 pad   + params + count;
 bad smb 
 copy return information to pRetData 
 cifs fid stays in le 
 Let caller know file was created so we can set the mode. 
 Do we care about the CreateAction in any other cases? 
 check to make sure response data is there 
 unknown 
 regular open 
 just go for readwrite 
 none 
 account for one byte pad to word boundary 
 trailing null 
 no pad 
 deny none 
	 set file as system file if special file such
	   as fifo and server expecting SFU style and
 BB FIXME BB 
ATTR_NORMAL);
 BB FIXME BB 
	pSMB->CreateOptions = cpu_to_le32(create_options &
 BB FIXME END BB 
 BB verify if wct == 15 
		pOplock = pSMBr->OplockLevel;  
 cifs fid stays in le 
 Let caller know file was created so we can set the mode. 
 Do we care about the CreateAction in any other cases? 
 BB FIXME BB 
		if (cpu_to_le32(FILE_CREATE) == pSMBr->CreateAction)
 BB FIXME END 
 BB convert CreateTime
 BB fixme 
 BB fixme 
 BB fixme 
 the file_info buf is endian converted by caller 
 no commands go after this 
 account for one byte pad to word boundary 
 trailing null 
 BB improve check for buffer overruns BB 
 no pad 
	
	  Set file as system file if special file such as fifo and server
	  expecting SFU style and no Unix extensions.
	
	  XP does not handle ATTR_POSIX_SEMANTICS but it helps speed up case
	  sensitive checks for other servers such as Samba.
 BB Expirement with various impersonation levels and verify 
 1 byte no need to le_to_cpu 
 cifs fid stays in le 
 Let caller know file was created so we can set the mode. 
 Do we care about the CreateAction in any other cases? 
 copy from CreationTime to Attributes 
 the file_info buf is endian converted by caller 
  Discard any remaining data in the current SMB. To do this, we borrow the
  current bigbuf.
	
	  read the rest of READ_RSP header (sans Data array), or whatever we
	  can if there's not enough data. At this point, we've read down to
	  the Mid.
 set up first two iov for signature check and to get credits 
 Was the SMB read successful? 
 normal error on read response 
 Is there enough to get to the rest of the READ_RSP header? 
		
		  win2k8 sometimes sends an offset of 0 when the read
		  is beyond the EOF. Treat it as if the data starts just after
		  the header.
 data_offset is beyond the end of smallbuf 
 read any junk before data into the rest of smallbuf 
 how much data is in the response? 
 data_len is corrupt -- discard frame 
 discard anything left over 
 result already set, check signature 
 FIXME: should this be counted toward the initiating task? 
 reset bytes number since we can not check a sign 
 FIXME: should this be counted toward the initiating task? 
 cifs_async_readv - send an async write, and set up mid to handle result 
 old style read 
 can not handle this big offset for old 
 none 
 old style read 
 4 for RFC1001 length + 1 for BCC 
 old style read 
 can not handle this big offset for old 
 tcon and ses pointer are checked in smb_init 
 none 
 no need to do le conversion since 0 
 old style read 
check that DataLength would not go beyond end of SMB 
			if (rc = copy_to_user(buf, pReadData, data_length)) {
				cifs_dbg(VFS, "Faulting on read rc = %d\n",rc);
				rc = -EFAULT;
 can not use copy_to_user when using page cache
 return buffer to caller to free 
 else no valid buffer on return - leave as null 
	 Note: On -EAGAIN error only caller can retry on handle based calls
 cifs_dbg(FYI, "write at %lld %d bytes\n", offset, count);
 can not handle big offset for old srv 
 tcon and ses pointer are checked in smb_init 
 none 
	 Can increase buffer size if buffer is big enough in some cases ie we
	can send more if LARGE_WRITE_X capability returned by the server and if
	our buffer is big enough or if we convert to iovecs on socket writes
 No buffer 
 else setting file size with write of zero bytes 
 pad 
 wct == 12 
 bigger pad, smaller smb hdr 
	else {  old style write has byte count 4 bytes earlier
		
		  Mask off high 16 bits when bytes written as returned by the
		  server is greater than bytes requested by the client. Some
		  OS2 servers are known to set incorrect CountHigh values.
	 Note: On -EAGAIN error only caller can retry on handle based calls
  Write failed with a retryable error. Resend the write request. It's also
  possible that the page was redirtied so re-clean the page.
 cleanup remaining pages from the original wdata 
  Check the mid_state and signature on received buffer (if any), and queue the
  workqueue completion task.
		
		  Mask off high 16 bits when bytes written as returned
		  by the server is greater than bytes requested by the
		  client. OS2 servers are known to set incorrect
		  CountHigh values.
 cifs_async_writev - send an async write, and set up mid to handle result 
 can not handle big offset for old srv 
 none 
 4 for RFC1001 length + 1 for BCC 
 wct == 12 
 pad bigger by four bytes 
 can not handle big offset for old srv 
 tcon and ses pointer are checked in smb_init 
 none 
 header + 1 byte pad 
 wct == 12 
 smb data starts later 
 wct == 12  
 wct == 12 pad bigger by four bytes 
 presumably this can not happen, but best to be safe 
		
		  Mask off high 16 bits when bytes written as returned by the
		  server is greater than bytes requested by the client. OS2
		  servers are known to set incorrect CountHigh values.
	 Note: On -EAGAIN error only caller can retry on handle based calls
 none 
 netfid stays le 
	LOCK_RSP pSMBr = NULL;  
 no response expected 
 blocking operation, no timeout 
 blocking - do not time out 
 none 
 netfid stays le 
 BB where to store pid high? 
 oplock break 
	 Note: On -EAGAIN error only caller can retry on handle based calls
 BB find max SMB from sess 
 pad   + params + count;
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 blocking operation, no timeout 
 normalize negative numbers 
 num iovecs ,
 lock structure can be returned on get 
 bad smb 
	 Note: On -EAGAIN error only caller can retry on handle based calls
 do not retry on dead session on close 
 EINTR is expected when user ctl-c to kill app 
 Since session is dead, file will be closed on server already 
 trailing null 
 pad 
 protocol requires ASCII signature byte on Unicode string 
 trailing null   + 1 
 convert to bytes 
 2nd buffer format 
 signature byte 
 1st signature byte   + name_len + name_len2;
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 BB find max SMB from sess 
 pad   + params;
 construct random name ".cifs_tmp<inodenum><mid>" 
 unicode only call 
 sizeof(struct set_file_rename)  + (2  len_of_str);
	 Note: On -EAGAIN error only caller can retry on handle based calls
 trailing null 
 pad 
 protocol requires ASCII signature byte on Unicode string 
 trailing null   + 1 
 convert to bytes 
 2nd buffer format 
 signature byte 
 1st signature byte   + name_len + name_len2;
 find define for this maxpathcomponent 
 trailing null 
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 find define for this maxpathcomponent 
 trailing null 
 BB find exact max on data count below from sess 
 pad   + params + name_len_target;
 trailing null 
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 trailing null 
 BB find exact max on data count below from sess
 pad   + params + name_len_target;
 trailing null 
 protocol specifies ASCII buffer format (0x04) for unicode 
 pad 
 trailing null   + 1 
 convert to bytes 
 2nd buffer format 
 signature byte 
 string type byte   + name_len + name_len2;
 SMB_QUERY_FILE_UNIX_LINK 
 trailing null 
 level   + 4  incl null  ;
 pad  ;
 decode response 
 BB also check enough total bytes returned 
 BB FIXME investigate remapping reserved chars here 
 	Recent Windows versions now create symlinks more frequently
 	and they use the "reparse point" mechanism below.  We can of course
 	do symlinks nicely to Samba and other servers which support the
 	CIFS Unix Extensions and we can also do SFU symlinks and "client only"
 	"MF" symlinks optionally, but for recent Windows we really need to
 	reenable the code below and fix the cifs_symlink callers to handle this.
 	In the interim this code has been moved to its own config option so
 	it is not compiled in by default until callers fixed up and more tested.
 BB find exact data count max from sess structure BB 
 FSCTL 
 file handle always le 
 BB also check enough total bytes returned 
 bad smb 
 Reparse tag is NTFS symlink 
 BB FIXME investigate remapping reserved chars here 
	
	  Note: On -EAGAIN error only caller can retry on handle based calls
	  since file handle passed in no longer valid.
 84 
 FSCTL 
 file handle always le 
 3 byte pad, followed by 2 byte compress state 
	
	  Note: On -EAGAIN error only caller can retry on handle based calls
	  since file handle passed in no longer valid.
Convert an Access Control Entry from wire format to local POSIX xattr format
 u8 cifs fields do not need le conversion 
	cifs_dbg(FYI, "perm %d tag %d id %d\n",
		 ace->e_perm, ace->e_tag, ace->e_id);
 Convert ACL from CIFS POSIX wire format to local Linux POSIX ACL xattr 
 check if we would go beyond end of SMB 
 skip past access ACEs to get to default ACEs 
 check if we would go beyond end of SMB 
 illegal type 
 used to query ACL EA size 
 buffer big enough  {
 BB is there a better way to handle the large uid? 
 Probably no need to le convert -1 on any arch but can not hurt 
	cifs_dbg(FYI, "perm %d tag %d id %d\n",
		 ace->e_perm, ace->e_tag, ace->e_id);
 Convert ACL from local Linux POSIX xattr to CIFS POSIX ACL wire format 
 BB add check to make sure ACL does not overflow SMB 
 SMB_QUERY_POSIX_ACL 
 trailing null 
 level   + 4  incl null  ;
 BB find exact max data count below from sess structure BB 
 pad  ;
 decode response 
 BB also check enough total bytes returned 
 bad smb 
 trailing null 
 BB find max SMB size from sess 
 convert to on the wire format for POSIX ACL 
 pad   + params + data_count;
 BB fix tabs in this function FIXME BB 
 level  + 2 
 BB find exact max data count below from sess structure BB 
 pad  ;
 decode response 
 BB also check enough total bytes returned 
			 If rc should we check for EOPNOSUPP and
 bad smb 
 BB Do we need a cast or hash here ? 
 CONFIG_POSIX 
  Initialize NT TRANSACT SMB into small smb request buffer.  This assumes that
  all NT TRANSACTS that we init here have total parm and data under about 400
  bytes (to fit in small cifs buffer size), which is the case so far, it
  easily fits. NB: Setup words themselves and ByteCount MaxSetupCount (size of
  returned setup area) and MaxParameterCount (returned parms size) must be set
  by caller
 for rfc1001 length itself ;
 no need to le convert byte fields 
 sizeof byte count  + bcc +
 should we also check that parm and data areas do not overlap? 
 Get Security Descriptor (by handle) from remote server for a file or dir 
 parm len , tcon, (void ) &pSMB);
 BB TEST with big acls that might need to be e.g. larger than 16K 
 file handle always le 
 3 bytes pad + 8 bytes parm 
 num iovec , &buf_type,
 decode response 
 validate_nttransact 
 bad smb 
 BB check that data area is minimum length and as big as acl_len 
		 check if buffer is big enough for the acl
 pad   + param_count;
 file handle always le 
 Legacy Query Path Information call for lookup to old servers such
 trailing null 
 account for buffer type byte 
 decode response 
 BB FIXME - add time zone adjustment BB 
 decode time fields 
 bad buffer passed in 
 level  + 2 
 BB find exact max data count below from sess structure BB 
 pad  ;
 decode response 
 BB add auto retry on EOPNOTSUPP? 
 bad smb 
 old style infolevel ,
 level 263 SMB_QUERY_FILE_ALL_INFO 
 cifs_dbg(FYI, "In QPathInfo path %s\n", search_name); 
 trailing null 
 level  + 4  includes NUL ;
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 decode response 
 BB add auto retry on EOPNOTSUPP? 
 bad smb 
			rc = -EIO;   24 or 26 expected but we do not read
			
			  On legacy responses we do not read the last field,
			  EAsize, fortunately since it varies by subdialect and
			  also note it differs on Set vs Get, ie two bytes or 4
			  bytes depending but we don't care here.
 level  + 2 
 BB find exact max data count below from sess structure BB 
 pad  ;
 decode response 
 bad smb 
 SMB_QUERY_FILE_UNIX_BASIC 
 trailing null 
 level  + 4  includes NUL ;
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 decode response 
 bad smb 
 xid, tcon, searchName and codepage are input parms, rest are returned 
 level 257 SMB_ 
		 We can not add the asterik earlier in case
		it got remapped to 0xF03A as if it were part of the
 now the trailing null 
 null terminate just in case 
 overwrite nul byte 
 includes null  ;
 no EAs 
 pad  ;
 one byte, no need to make endian neutral 
 BB what should we set StorageType to? Does it matter? BB 
	if (rc) { BB add logic to retry regular search if Unix search
 BB Add code to handle unsupported level rc 
 BB eventually could optimize out free and realloc of buf 
    for this case 
 decode response 
 BB remember to free buffer if error BB 
 skip . and ..  +
 includes 2 bytes of null string, converted to LE below
 no EAs 
 always kept as le 
 14 byte parm len above enough for 2 byte null terminator 
 pad  ;
 search probably was closed at end of search
 decode response 
 BB fixme add lock for file (srch_info) struct here 
  cifs_dbg(FYI, "fnxt2 entries in buf %d index_of_last %d\n",
 BB fixme add unlock here 
	 BB On error, should we leave previous search buf (and count and
	 Note: On -EAGAIN error only caller can retry on handle based calls
	 no sense returning error if session restarted
 Since session is dead, search handle closed on server already 
 trailing null 
 level   + 4  incl null  ;
 BB find exact max data count below from sess structure BB 
 pad  ;
 decode response 
 BB also check enough total bytes returned 
			 If rc should we check for EOPNOSUPP and
 bad smb 
 BB Do we need a cast or hash here ? 
 TRANS2_GET_DFS_REFERRAL 
	 server pointer checked in called function,
 trailing null 
 BB improve the check for buffer overruns BB 
 level   + name_len 
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 BB Also check if enough total bytes returned? 
 bad smb 
 parse returned result into more usable form 
 Query File System Info such as free space to old servers such as Win 9x 
 level 0x01 SMB_QUERY_FILE_SYSTEM_INFO 
 level 
 pad  ;
 decode response 
 bad smb 
			
			  much prefer larger but if server doesn't report
			  a valid size than 4K is a reasonable minimum
 level 0x103 SMB_QUERY_FILE_SYSTEM_INFO 
 level 
 pad  ;
 decode response 
 bad smb 
			
			  much prefer larger but if server doesn't report
			  a valid size than 4K is a reasonable minimum
 level 0x105  SMB_QUERY_FILE_SYSTEM_INFO 
 level 
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 decode response 
 BB also check if enough bytes returned 
 bad smb 
 level 0x104 SMB_QUERY_FILE_SYSTEM_INFO 
 level 
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 decode response 
 bad smb 
 level 0x200  SMB_QUERY_CIFS_UNIX_INFO 
 level 
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 decode response 
 bad smb 
 level 0x200  SMB_SET_CIFS_UNIX_INFO 
 BB switch to small buf init to save memory 
 2 bytes zero followed by info level. 
 BB find exact max SMB PDU from sess structure BB 
 pad  + params + 12;
 Params. 
 Data. 
 decode response 
 bad smb 
 level 0x201  SMB_QUERY_CIFS_POSIX_INFO 
 level 
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 decode response 
 bad smb 
			
			  much prefer larger but if server doesn't report
			  a valid size than 4K is a reasonable minimum
  We can not use write of zero bytes trick to set file size due to need for
  large file support. Also note that this SetPathInfo is preferred to
  SetFileInfo based method in next routine which is only needed to work around
  a sharing violation bugin Samba which this routine can run into.
 trailing null 
 Set File Size   {
 pad   + params + data_count;
 BB find exact max SMB PDU from sess structure BB 
 pad   + params + count;
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 Set File Size   {
	 Note: On -EAGAIN error only caller can retry on handle based calls
 Some legacy servers such as NT4 require that the file times be set on
   an open handle, rather than by pathname - this is awkward due to
   potential access conflicts on the open, but it is unavoidable for these
   old servers since the only other choice is to go from 100 nanosecond DCE
   time and resort to the original setpathinfo level which takes the ancient
 BB find max SMB PDU from sess 
 pad   + params + count;
	 Note: On -EAGAIN error only caller can retry on handle based calls
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 BB find max SMB PDU from sess 
 pad   + params + count;
 trailing null 
 BB find max SMB PDU from sess structure BB 
 pad   + params + count;
	
	  Samba server ignores set of file size to zero due to bugs in some
	  older clients, but we should be precise - we use SetFileSize to
	  set file size and do not want to truncate file size to zero
	  accidentally as happened on one Samba server beta by putting
	  zero instead of -1 here
 better to leave device as zero when it is  
 BB find max SMB PDU from sess 
 pad   + params + count;
	 Note: On -EAGAIN error only caller can retry on handle based calls
 trailing null 
 BB find max SMB PDU from sess structure BB 
 SMB offsets are from the beginning of SMB which is 4 bytes in, after RFC1001 field 
 pad   + params + count;
  Do a path-based QUERY_ALL_EAS call and parse the result. This is a common
  function used by listxattr and getxattr type calls. When ea_name is set,
  it looks for that attribute name and stuffs that value into the EAData
  buffer. When ea_name is NULL, it stuffs a list of attribute names into the
  buffer. In both cases, the return value is either the length of the
  resulting data or a negative error code. If EAData is a NULL pointer then
  the data isn't copied to it, but the length is returned.
 BB assumes one setup word 
 trailing null 
 level  + 4  includes NUL ;
 BB find exact max SMB PDU from sess structure BB 
 pad  ;
 BB also check enough total bytes returned 
	 BB we need to improve the validity checking
 bad smb 
 check that length of list is not more than bcc 
	 check that each entry does not go beyond length
	 check that each element of each entry does not
 validate_trans2_offsets() 
 BB check if start of smb + data_offset > &bcc+ bcc 
 didn't find the named attribute 
 make sure list_len doesn't go past end of SMB 
 account for ea list len 
 make sure we can read name_len and value_len 
 account for prefix user. and trailing null 
 null terminate name 
 skip copy - calc size only 
 stop before overrun buffer 
 didn't find the named attribute 
 trailing null 
	 done calculating parms using name_len of file name,
	now use name_len to calculate length of ea name
 BB find max SMB PDU from sess 
 pad   + params + count;
 we checked above that name len is less than 255 
 EA names are always ASCII 
	 caller ensures that ea_value_len is less than 64K but
	BB add length check to see if it would fit in
 if (ea_value_len > buffer_size - 512 (enough for header)) 
 SPDX-License-Identifier: GPL-2.0
  DFS referral cache routines
  Copyright (c) 2018-2019 Paulo Alcantara <palcantara@suse.de>
 2 minutes 
 RESP_GET_DFS_REFERRAL.ReferralHeaderFlags 
 DFS_REREFERRAL_V3.TimeToLive 
 DFS_REREFERRAL_V3.ServerType 
 DFS_REREFERRAL_V3.ReferralEntryFlags 
 RESP_GET_DFS_REFERRAL.PathConsumed 
 List of referral server sessions per dfs mount 
  Number of entries in the cache
xIPC$")] = {0};
  dfs_cache_canonical_path - get a canonical DFS path
  @path: DFS path
  @cp: codepage
  @remap: mapping type
  Return canonical path if success, otherwise error.
  dfs cache proc file
  dfs_cache_init - Initialize DFS referral cache.
  Return zero if initialized successfully, otherwise non-zero.
 Return target hint of a DFS cache entry 
 Return expire time out of a new entry's TTL 
 Allocate a new DFS target 
  Copy DFS referral information to a cache entry and conditionally update
  target hint.
 Allocate a new cache entry 
 Add a new DFS cache entry 
 Check if two DFS paths are equal.  @s1 and @s2 are expected to be in @cache_cp's charset 
  Find a DFS cache entry in hash table and optionally check prefix path against normalized @path.
  Use whole path components in the match.  Must be called with htable_rw_lock held.
  Return ERR_PTR(-EEXIST) if the entry is not found.
	
	  Handle paths that have more than two path components and are a complete prefix of the DFS
	  referral request path (@path).
	 
	  See MS-DFSC 3.2.5.5 "Receiving a Root Referral Request or Link Referral Request".
 skip separators 
 backward until separator 
  dfs_cache_destroy - destroy DFS referral cache
 Update a cache entry with the new referral in @refs 
  Find, create or update a DFS cache entry.
  If the entry wasn't found, it will create a new one. Or if it was found but
  expired, then it will update the entry accordingly.
  For interlinks, cifs_mount() and expand_dfs_referral() are supposed to
  handle them properly.
	
	  Either the entry was not found, or it is expired.
	  Request a new DFS referral in order to create or update a cache entry.
  Set up a DFS referral from a given cache entry.
  Must be called with htable_rw_lock held.
 Return target list of a DFS cache entry 
  dfs_cache_find - find a DFS cache entry
  If it doesn't find the cache entry, then it will get a DFS referral
  for @path and create a new entry.
  In case the cache entry exists but expired, it will get a DFS referral
  for @path and then update the respective cache entry.
  These parameters are passed down to the get_dfs_refer() call if it
  needs to be issued:
  @xid: syscall xid
  @ses: smb session to issue the request on
  @cp: codepage
  @remap: path character remapping type
  @path: path to lookup in DFS referral cache.
  @ref: when non-NULL, store single DFS referral result in it.
  @tgt_list: when non-NULL, store complete DFS target list in it.
  Return zero if the target was found, otherwise non-zero.
  dfs_cache_noreq_find - find a DFS cache entry without sending any requests to
  the currently connected server.
  NOTE: This function will neither update a cache entry in case it was
  expired, nor create a new cache entry if @path hasn't been found. It heavily
  relies on an existing cache entry.
  @path: canonical DFS path to lookup in the DFS referral cache.
  @ref: when non-NULL, store single DFS referral result in it.
  @tgt_list: when non-NULL, store complete DFS target list in it.
  Return 0 if successful.
  Return -ENOENT if the entry was not found.
  Return non-zero for other errors.
  dfs_cache_update_tgthint - update target hint of a DFS cache entry
  If it doesn't find the cache entry, then it will get a DFS referral for @path
  and create a new entry.
  In case the cache entry exists but expired, it will get a DFS referral
  for @path and then update the respective cache entry.
  @xid: syscall id
  @ses: smb session
  @cp: codepage
  @remap: type of character remapping for paths
  @path: path to lookup in DFS referral cache
  @it: DFS target iterator
  Return zero if the target hint was updated successfully, otherwise non-zero.
  dfs_cache_noreq_update_tgthint - update target hint of a DFS cache entry
  without sending any requests to the currently connected server.
  NOTE: This function will neither update a cache entry in case it was
  expired, nor create a new cache entry if @path hasn't been found. It heavily
  relies on an existing cache entry.
  @path: canonical DFS path to lookup in DFS referral cache.
  @it: target iterator which contains the target hint to update the cache
  entry with.
  Return zero if the target hint was updated successfully, otherwise non-zero.
  dfs_cache_get_tgt_referral - returns a DFS referral (@ref) from a given
  target iterator (@it).
  @path: canonical DFS path to lookup in DFS referral cache.
  @it: DFS target iterator.
  @ref: DFS referral pointer to set up the gathered information.
  Return zero if the DFS referral was set up correctly, otherwise non-zero.
  dfs_cache_add_refsrv_session - add SMB session of referral server
  @mount_id: mount group uuid to lookup.
  @ses: reference counted SMB session of referral server.
  dfs_cache_put_refsrv_sessions - put all referral server sessions
  Put all SMB sessions from the given mount group id.
  @mount_id: mount group uuid to lookup.
  dfs_cache_get_tgt_share - parse a DFS target
  @path: DFS full path
  @it: DFS target iterator.
  @share: tree name.
  @prefix: prefix path.
  Return zero if target was parsed correctly, otherwise non-zero.
 point to prefix in target node 
 extract target share 
 skip separator 
 point to prefix in DFS path 
 merge prefix paths from DFS path and target node 
	
	  Resolve share's hostname and check if server address matches.  Otherwise just ignore it
	  as we could not have upcall to resolve hostname or failed to convert ip address.
  Mark dfs tcon for reconnecting when the currently connected tcon does not match any of the new
  target shares in @refs.
 Refresh dfs referral of tcon and mark it for reconnect if needed 
 Create or update a cache entry with the new referral 
  dfs_cache_remount_fs - remount a DFS share
  Reconfigure dfs mount by forcing a new DFS referral and if the currently cached targets do not
  match any of the new targets, mark it for reconnect.
  @cifs_sb: cifs superblock.
  Return zero if remounted, otherwise non-zero.
	
	  After reconnecting to a different server, unique ids won't match anymore, so we disable
	  serverino. This prevents dentry revalidation to think the dentry are stale (ESTALE).
	
	  Force the use of prefix path to support failover on DFS paths that resolve to targets
	  that have different prefix paths.
  Refresh all active dfs mounts regardless of whether they are in cache or not.
  (cache can be cleared)
	
	  Refresh all cached entries.  Get all new referrals outside critical section to avoid
	  starvation while performing SMB2 IOCTL on broken or slow connections.
	  The cache entries may cover more paths than the active mounts
	  (e.g. domain-based DFS referrals or multi tier DFS setups).
			
			  We need to re-check it because other tasks might have it deleted or
			  updated.
  Worker that will refresh DFS cache and active mounts based on lowest TTL value from a DFS
  referral.
 Get refereces of mount groups 
 Fill in local array with an NULL-terminated list of all referral server sessions 
 Refresh all active mounts and cached entries 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2008
    Author(s): Steve French (sfrench@us.ibm.com)
 The xid serves as a useful identifier for each incoming vfs request,
   in a similar way to the mid which is useful to track each sent smb,
   and CurrentXid can also provide a running counter (although it
   will eventually wrap past zero) of the total vfs operations handled
 keep high water mark for number of simultaneous ops in filesystem 
	 if (GlobalTotalActiveXid == 0)
	
	  SMB2 header is bigger than CIFS one - no problems to clean some
	  more bytes for CIFS.
	
	  We could use negotiated size instead of max_msgsize -
	  but it may be more efficient to always alloc same size
	  albeit slightly larger than necessary and maxbuffersize
	  defaults to this and can not be bigger.
 clear the first few header bytes 
 for most paths, more is cleared in header_assemble 
 CONFIG_CIFS_STATS2 
 cifs_dbg(FYI, "Null buffer passed to cifs_buf_release\n");
 We could use negotiated size instead of max_msgsize -
   but it may be more efficient to always alloc same size
   albeit slightly larger than necessary and maxbuffersize
 No need to clear memory here, cleared in header assemble 
	memset(ret_buf, 0, sizeof(struct smb_hdr) + 27);
 CONFIG_CIFS_STATS2 
 NB: MID can not be set if treeCon not passed in, in that
 command  ,
 length of fixed section (word count) in two byte units  )
 bigger than MAX_CIFS_HDR_SIZE 
  RFC 1001 length field does not count   +
 for bcc field itself ) ;
 case sensitive 
 Uid is not converted 
  endian conversion of flags is now done just before sending 
 does it have the right SMB "signature" ? 
 if it's a response then accept 
 only one valid case where server sends us request 
 calculated length 
 is this frame too small to even get to a BCC? 
 it's an error return 
 some error cases do not return wct and bcc 
 Need to work around a bug in two servers here 
 First, check if the part of bcc they sent was zero 
				 some servers return only half of bcc
				  on simple responses (wct, bcc both zero)
				  in particular have seen this on
				  ulogoffX and FindClose. This leaves
				  one byte of bcc potentially unitialized
 zero rest of bcc 
 otherwise, there is enough to get to the BCC 
 check if bcc wrapped around for large read responses 
 check if lengths match mod 64K 
 bcc wrapped 
			
			  Some servers (Windows XP in particular) send more
			  data than the lengths in the SMB packet would
			  indicate on certain calls (byte range locks and
			  trans2 find first calls in particular). While the
			  client can handle such a frame by ignoring the
			  trailing data, we choose limit the amount of extra
			  data to 512 bytes.
			   cifs_dump_mem("Rcvd notify Data: ",buf,
		 no sense logging error on invalid handle on oplock
		   break - harmless race between close request and oplock
		   break response is expected from time to time writing out
 on valid oplock brk we get "request" 
 look up tcon based on tid & uid 
  We wait for oplock breaks to be processed before we attempt to perform
  writes.
 Check to see if we have started servicing an oplock break 
  cifs_queue_oplock_break - queue the oplock break handler for cfile
  @cfile: The file to break the oplock on
  This function is called from the demultiplex thread when it
  receives an oplock break for @cfile.
  Assumes the tcon->open_file_lock is held.
  Assumes cfile->file_info_lock is NOT held.
	
	  Bump the handle refcount now while we hold the
	  open_file_lock to enforce the validity of it for the oplock
	  break handler. The matching put is done at the end of the
	  handler.
  Critical section which runs after acquiring deferred_lock.
  As there is no reference count on cifs_deferred_close, pdclose
  should not be used outside deferred_lock.
  Critical section which runs after acquiring deferred_lock.
  Critical section which runs after acquiring deferred_lock.
 parses DFS refferal V3 structure
  caller is responsible for freeing target_nodes
  returns:
  - on success - 0
  - on failure - errno
 get the upper boundary of the resp buffer 
 collect necessary data from referrals 
 copy DfsPath 
 copy link target UNC 
	
	  Must use kzalloc to initialize ctx->bv to NULL and ctx->direct_io
	  to false so that we know when we have to unreference pages within
	  cifs_aio_ctx_release()
	
	  ctx->bv is only set if setup_aio_ctx_iter() was call successfuly
	  which means that iov_iter_get_pages() was a success and thus that
	  we have taken reference on pages.
  cifs_alloc_hash - allocate hash and hash context together
  @name: The name of the crypto hash algo
  @shash: Where to put the pointer to the hash algo
  @sdesc: Where to put the pointer to the hash descriptor
  The caller has to make sure @sdesc is initialized to either NULL or
  a valid context. Both can be freed via cifs_free_hash().
  cifs_free_hash - free hash and hash context together
  @shash: Where to find the pointer to the hash algo
  @sdesc: Where to find the pointer to the hash descriptor
  Freeing a NULL hash or context is safe.
  rqst_page_get_length - obtain the length and offset for a page in smb_rqst
  @rqst: The request descriptor
  @page: The index of the page to query
  @len: Where to store the length for this page:
  @offset: Where to store the offset for this page
 skip initial slashes 
  copy_path_name - copy src path to dst, possibly truncating
  @dst: The destination buffer
  @src: The source name
  returns number of bytes written (including trailing nul)
	
	  PATH_MAX includes nul, so if strlen(src) >= PATH_MAX it
	  will truncate and strlen(dst) will be PATH_MAX-1
 we count the trailing nul 
	
	  Grab an active reference in order to prevent automounts (DFS links)
	  of expiring and then freeing up our cifs superblock pointer while
	  we're doing failover.
 SPDX-License-Identifier: GPL-2.0-or-later
    Copyright (c) International Business Machines  Corp., 2000,2009
    Modified by Steve French (sfrench@us.ibm.com)
 Convert character using the SFU - "Services for Unix" remapping range 
	
	  BB: Cannot handle remapping UNI_SLASH until all the calls to
	      build_path_from_dentry are modified, as they use slash as
	      separator.
 Convert character using the SFM - "Services for Mac" remapping range 
  cifs_mapchar - convert a host-endian char to proper char in codepage
  @target - where converted character should be copied
  @src_char - 2 byte host-endian source character
  @cp - codepage to which character should be converted
  @map_type - How should the 7 NTFSSMB reserved characters be mapped to UCS2?
  This function handles the conversion of a single character. It is the
  responsibility of the caller to ensure that the target buffer is large
  enough to hold the result of the conversion (at least NLS_MAX_CHARSET_SIZE).
 if character not one of seven in special remap set 
 convert SURROGATE_PAIR and IVS 
  cifs_from_utf16 - convert utf16le string to local charset
  @to - destination buffer
  @from - source buffer
  @tolen - destination buffer size (in bytes)
  @fromlen - source buffer size (in bytes)
  @codepage - codepage to which characters should be converted
  @mapchar - should characters be remapped according to the mapchars option?
  Convert a little-endian utf16le string (as sent by the server) to a string
  in the provided codepage. The tolen and fromlen parameters are to ensure
  that the code doesn't walk off of the end of the buffer (which is always
  a danger if the alignment of the source buffer is off). The destination
  string is always properly null terminated and fits in the destination
  buffer. Returns the length of the destination string in bytes (including
  null terminator).
  Note that some windows versions actually send multiword UTF-16 characters
  instead of straight UTF16-2. The linux nls routines however aren't able to
  deal with those characters properly. In the event that we get some of
  those characters, they won't be translated properly.
 ftmp[3] = 3array x 2bytes = 6bytes UTF-16 
	
	  because the chars can be of varying widths, we need to take care
	  not to overflow the destination buffer when we get close to the
	  end of it. Until we get to this offset, we don't need to check
	  for overflow however.
		
		  check to see if converting this character might make the
		  conversion bleed into the null terminator
 put converted char into 'to' buffer 
		 charlen (=bytes of UTF-8 for 1 character)
		  4bytes UTF-8(surrogate pair) is charlen=4
		    (4bytes UTF-16 code)
		  7-8bytes UTF-8(IVS) is charlen=3+4 or 4+4
 5-6bytes UTF-8 
 properly null-terminate string 
  NAME:	cifs_strtoUTF16()
  FUNCTION:	Convert character string to unicode string
 needed to quiet sparse 
 special case for utf8 to handle no plane0 chars 
		
		  convert utf8 -> utf16, we assume we have enough space
		  as caller should have assumed conversion does not overflow
		  in destination len is length in wchar_t units (16bits)
 if success terminate and exit 
		
		  if fails fall back to UCS encoding as this
		  function should not return negative values
		  currently can fail only if source contains
		  invalid encoded characters
 A question mark 
  cifs_utf16_bytes - how long will a string be after conversion?
  @utf16 - pointer to input string
  @maxbytes - don't go past this many bytes of input string
  @codepage - destination codepage
  Walk a utf16le string and return the number of bytes that the string will
  be after being converted to the given charset, not including any null
  termination required. Don't walk past maxbytes in the source buffer.
  cifs_strndup_from_utf16 - copy a string from wire format to the local
  codepage
  @src - source string
  @maxlen - don't walk past this many bytes in the source string
  @is_unicode - is this a unicode string?
  @codepage - destination codepage
  Take a string given by the server, convert it to the local codepage and
  put it in a new buffer. Returns a pointer to the new string or NULL on
  error.
  Convert 16 bit Unicode pathname to wire format from string in current code
  page. Conversion may involve remapping up the six characters that are
  only legal in POSIX-like OS (if they are present in the string). Path
  names are little endian 16 bit Unicode on the wire
 UTF-16 
 check if end of string 
 see if we must remap this char 
			
			  Remap spaces and periods found at the end of every
			  component of the path. The special cases of '.' and
			  '..' do not need to be dealt with explicitly because
			  they are addressed in namei.c:link_path_walk().
		
		  FIXME: We can not handle remapping backslash (UNI_SLASH)
		  until all the calls to build_path_from_dentry are modified,
		  as they use backslash as separator.
			
			  if no match, use question mark, which at least in
			  some cases serves as wild card
 convert SURROGATE_PAIR 
 1-3bytes UTF-8 to 2bytes UTF-16 
				 4bytes UTF-8(surrogate pair) to 4bytes UTF-16
				  7-8bytes UTF-8(IVS) divided to 2 UTF-16
 5-6bytes UTF-8 to 6bytes UTF-16 
		
		  character may take more than one byte in the source string,
		  but will take exactly two bytes in the target string
 Null terminate target unicode string 
  cifs_local_to_utf16_bytes - how long will a string be after conversion?
  @from - pointer to input string
  @maxbytes - don't go past this many bytes of input string
  @codepage - source codepage
  Walk a string and return the number of bytes that the string will
  be after being converted to the given charset, not including any null
  termination required. Don't walk past maxbytes in the source buffer.
 Failed conversion defaults to a question mark 
 UTF16 characters are two bytes 
  cifs_strndup_to_utf16 - copy a string to wire format from the local codepage
  @src - source string
  @maxlen - don't walk past this many bytes in the source string
  @utf16_len - the length of the allocated string in bytes (including null)
  @cp - source codepage
  @remap - map special chars
  Take a string convert it from the local codepage to UTF16 and
  put it in a new buffer. Returns a pointer to the new string or NULL on
  error.
 NULL 
 SPDX-License-Identifier: LGPL-2.1
    CIFS filesystem cache interface
    Copyright (c) 2010 Novell, Inc.
    Author(s): Suresh Jayaraman <sjayaraman@suse.de>
  Key layout of CIFS server cache index object
 address family 
 IP port 
  Get a cookie for a server object keyed by {IPaddress,port,family} tuple
	
	  Should not be a problem as sin_familysin6_family overlays
	  sa_family field
	
	  Check if cookie was already initialized so don't reinitialize it.
	  In the future, as we integrate with newer fscache features,
	  we may want to instead add a check if cookie has changed
 fscache_relinquish_cookie does not seem to update auxdata 
 retire the current fscache cache and get a new one 
  Retrieve a page from FS-Cache
 page found in fscache, read submitted 
 page won't be cached 
 page not in cache 
  Retrieve a set of pages from FS-Cache
 read submitted to the cache for all pages 
 some pages are not cached and can't be 
 some pages are not cached 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (c) 2007 Igor Mammedov
    Author(s): Igor Mammedov (niallain@gmail.com)
               Steve French (sfrench@us.ibm.com)
               Wang Lei (wang840925@gmail.com)
 		David Howells (dhowells@redhat.com)
    Contains the CIFS DFS upcall routines used for hostname to
    IP address translation.
  dns_resolve_server_name_to_ip - Resolve UNC server name to ip address.
  @unc: UNC path specifying the server (with '' as delimiter)
  @ip_addr: Where to return the IP address.
  @expiry: Where to return the expiry time for the dns record.
  The IP address will be returned in string form, and the caller is
  responsible for freeing it.
  Returns length of result on success, -ve on error.
 Discount leading slashes for cifs 
 Search for server name delimiter 
 Try to interpret hostname as an IPv4 or IPv6 address 
 Perform the upcall 
 SPDX-License-Identifier: LGPL-2.1
    vfs operations that deal with files
    Copyright (C) International Business Machines  Corp., 2002,2010
    Author(s): Steve French (sfrench@us.ibm.com)
               Jeremy Allison (jra@samba.org)
		 GENERIC_ALL is too much permission to request
 return GENERIC_ALL; 
 be safe and imply O_SYNC for O_DSYNC 
 open ok, caller does qpathinfo 
 caller does not need info 
 get new inode and set it up 
   open flag mapping table:
 	POSIX Flag            CIFS Disposition
 	----------            ----------------
 	O_CREAT               FILE_OPEN_IF
 	O_CREAT | O_EXCL      FILE_CREATE
 	O_CREAT | O_TRUNC     FILE_OVERWRITE_IF
 	O_TRUNC               FILE_OVERWRITE
 	none of the above     FILE_OPEN
 	Note that there is not a direct match between disposition
 	FILE_SUPERSEDE (ie create whether or not file exists although
 	O_CREAT | O_TRUNC is similar but truncates the existing
 	file rather than creating a new file as FILE_SUPERSEDE does
 	(which uses the attributes  metadata passed in on open call)
 ?
 ?  O_SYNC is a reasonable match to CIFS writethrough flag
 ?  and the read write flags match reasonably.  O_LARGEFILE
 ?  is irrelevant because largefile support is always used
 ?  by this client. Flags O_APPEND, O_DIRECT, O_DIRECTORY,
 	 O_FASYNC, O_NOFOLLOW, O_NONBLOCK need further investigation
 BB pass O_SYNC flag through on file attributes .. BB 
 O_SYNC also has bit for O_DSYNC so following check picks up either 
 TODO: Add support for calling posix query info but with passing in fid 
	
	  If the server returned a read oplock and we have mandatory brlocks,
	  set oplock level to None.
 if readable file instance put first in list
	
	  Delete any outstanding lock records. We'll lose them when the file
	  is closed anyway.
  cifsFileInfo_put - release a reference of file priv data
  Always potentially wait for oplock handler. See _cifsFileInfo_put().
  @cifs_file:	cifssmb3 specific info (eg refcounts) for an open file
  _cifsFileInfo_put - release a reference of file priv data
  This may involve closing the filehandle @cifs_file out on the
  server. Must be called without holding tcon->open_file_lock,
  cinode->open_file_lock and cifs_file->file_info_lock.
  If @wait_for_oplock_handler is true and we are releasing the last
  reference, wait for any running oplock break handler of the file
  and cancel any pending one.
  @cifs_file:	cifssmb3 specific info (eg refcounts) for an open file
  @wait_oplock_handler: must be false if called from oplock_break_handler
  @offload:	not offloaded on close and oplock breaks
 store open in pending opens to make sure we don't miss lease break 
 remove it from the lists 
		
		  In strict cache mode we need invalidate mapping on the last
		  close  because it may cause a error when we open this file
		  again and get at least level II oplock.
 Get the cached handle as SMB2 close is deferred 
 can not refresh inode info since size could be stale 
 ignored ,
 path not found or net err 
		
		  Else fallthrough to retry open the old way on network io
		  or DFS errors.
		
		  Time to set mode which we can not set earlier due to
		  problems creating new read-only files.
 no change 
 no change 
  Try to reacquire byte range locks that were released when session
  to server was lost.
 can cache locks - no need to relock 
	
	  Can not grab rename sem here because various ops, including those
	  that already have the rename sem can end up causing writepage to get
	  called and if the server was down that means we end up here, and we
	  can never tell if the caller already has the rename_sem.
		
		  O_CREAT, O_EXCL and O_TRUNC already had their effect on the
		  original open. Must mask them off for a reopen.
 ignored ,
		
		  fallthrough to retry open the old way on errors, especially
		  in the reconnect path it is important to retry hard
 O_SYNC also has bit for O_DSYNC so following check picks up either 
	
	  Can not refresh inode by passing in file_info buf to be returned by
	  ops->open and then calling get_inode_info with returned buf since
	  file might have write behind data that needs to be flushed and server
	  version of file size can be stale. If we knew for sure that inode was
	  not dirty locally we could do this.
 durable handle timeout is expired - open the file again 
 indicate that we need to relock the file 
	
	  Else we are writing out data to server already and could deadlock if
	  we tried to flush data, and since we do not know if we have data that
	  would invalidate the current end of file on the server we can not go
	  to the server to get the new inode info.
	
	  If the server returned a read oplock and we have mandatory brlocks,
	  set oplock level to None.
				
				  If there is no pending work, mod_delayed_work queues new work.
				  So, Increase the ref count to avoid use-after-free.
 Deferred close for files 
 return code from the ->release op is always ignored 
 list all files open on tree connection, reopen resilient handles  
 do not flush ))
 not much we can do if it fails anyway, ignore rc 
 BB can we lock the filestruct while this is going on? 
 @rw_check : 0 - no op, 1 - read, 2 - write 
 shared lock prevents write op through the same fid 
  Check if there is another lock that prevents us to set the lock (mandatory
  style). If such a lock exists, update the flock structure with its
  properties. Otherwise, set the flock type to F_UNLCK if we can cache brlocks
  or leave it the same if we can't. Returns 0 if we don't need to request to
  the server or 1 otherwise.
  Set the byte-range lock (mandatory style). Returns:
  1) 0, if we set the lock and don't need to request to the server;
  2) 1, if no locks prevent us but we need to request to the server;
  3) -EACCES, if there is a lock that prevents us and wait is false.
  Check if there is another lock that prevents us to set the lock (posix
  style). If such a lock exists, update the flock structure with its
  properties. Otherwise, set the flock type to F_UNLCK if we can cache brlocks
  or leave it the same if we can't. Returns 0 if we don't need to request to
  the server or 1 otherwise.
  Set the byte-range lock (posix style). Returns:
  1) <0, if the error occurs while setting the lock;
  2) 0, if we set the lock and don't need to request to the server;
  3) FILE_LOCK_DEFERRED, if we will wait for some other file_lock;
  4) FILE_LOCK_DEFERRED + 1, if we need to request to the server.
	
	  Accessing maxBuf is racy with cifs_reconnect - need to store value
	  and check it before using.
	
	  Allocating count locks is enough because no FL_POSIX locks can be
	  added to the list while we are holding cinode->lock_sem that
	  protects locking operations of this inode.
			
			  The list ended. We don't have enough allocated
			  structures - something is really wrong.
 we are going to update can_cache_brlcks here - need a write access 
 Check if unlock includes more than one lock range 
 BB we could chain these into one lock request BB 
	
	  Accessing maxBuf is racy with cifs_reconnect - need to store value
	  and check it before using.
				
				  We can cache brlock requests - simply remove
				  a lock from the file's list.
			
			  We need to save a lock here to let us add it again to
			  the file's list if the unlock range request fails on
			  the server.
					
					  We failed on the unlock range
					  request - add all locks from the tmp
					  list to the head of the file's list.
					
					  The unlock range request succeed -
					  free the tmp list.
		
		  Windows 7 server can delay breaking lease from read to None
		  if we set a byte-range lock on a file - break it explicitly
		  before sending the lock to the server to be sure the next
		  read won't conflict with non-overlapted locks due to
		  pagereading.
		
		  If this is a request to remove all locks because we
		  are closing the file, it doesn't matter if the
		  unlocking failed as both cifs.ko and the SMB server
		  remove the lock on file close
		
		  if no lock or unlock then nothing to do since we do not
		  know what it is
	
	  BB add code here to normalize offset and length to account for
	  negative length which we can not accept over the wire.
		
		  if no lock or unlock then nothing to do since we do not
		  know what it is
  update the file size (if needed) after a write. Should be called with
  the inode->i_lock held
				 we could deadlock if we called
				   filemap_fdatawait from here so tell
				   reopen_file not to flush data to
 iov[0] is reserved for smb header 
 only filter by fsuid on multiuser mounts 
	 we could simply get the first_list_entry since write-only entries
	   are always at the end of the list but since the first entry might
 found a good file 
 lock it so it will not be closed on us 
			}  else might as well continue, and look for
			     another, or simply have the caller reopen it
 write only file 
 write only files are last so must be done 
 Return -EBADF if no handle is found and general rc otherwise 
	
	  Having a null inode here (because mapping->host was set to zero by
	  the VFS or MM) should not happen but we had reports of on oops (due
	  to it being zero) during stress testcases so we need to check for it
 only filter by fsuid on multiuser mounts 
 found a good writable file 
 couldn't find useable FH with same pid, try any available 
 racing with truncate? 
 don't care 
 check to make sure that we are not extending the file 
 Does mm or vfs already set times? 
		
		  At this point we hold neither the i_pages lock nor the
		  page lock: the page may be truncated or invalidated
		  (changing page->mapping to NULL), or even swizzled
		  back from swapper_space to tmpfs file mapping
 Not next consecutive page 
		
		  This actually clears the dirty bit in the radix tree.
		  See cifs_writepage() for more commentary.
 reset index to refind any pages skipped 
 put any pages we aren't going to use 
	
	  If wsize is smaller than the page cache size, default to writing
	  one page at a time via cifs_writepage
 Start from prev offset 
 in case of an error store it to return later 
 nothing to write? 
 send failure -- clean up the mess 
 Return immediately if we received a signal during writing 
		
		  We hit the last page and there is more work to be done: wrap
		  back to the start of the file
 Indication to update ctime and mtime as close is deferred 
 BB add check for wbc flags 
	
	  Set the "writeback" flag, and clear "dirty" in the radix tree.
	 
	  A writepage() implementation always needs to do either this,
	  or re-dirty the page with "redirty_page_for_writepage()" in
	  the case of a failure.
	 
	  Just unlocking the page will cause the radix tree tag-bits
	  to fail to update with the state of the page correctly.
		 this is probably better than directly calling
		   partialpage_write since in this function the file handle is
		 BB check if anything else missing out of ppw
 if (rc < 0) should we set writebehind rc? 
 Indication to update ctime and mtime as close is deferred 
 don't care about it in fsync 
  As file closes, flush all cached write data for this inode checking
  for write behind errors.
			
			  save number of pages we have already allocated and
			  return with ENOMEM error
 the below call can possibly free the last ref to aio ctx 
		
		  If we didn't copy as much as we expected, then that
		  may mean we trod into an unmapped area. Stop copying
		  at that point. On the next pass through the big
		  loop, we'll likely end up getting a zero-length
		  write and bailing out of it.
	
	  If we have no data to send, then that probably means that
	  the copy above failed altogether. That's most likely because
	  the address in the iovec was bogus. Return -EFAULT and let
	  the caller free anything we allocated and bail out.
	
	  i + 1 now represents the number of pages we actually used in
	  the copy phase above.
		
		  Wait for credits to resend this wdata.
		  Note: we are attempting to resend the whole wdata not in
		  segments
 If the write was successfully sent, we are done 
 Roll back credits and retry if needed 
			
			  Bring nr_pages down to the number of pages we
			  actually used, and free any pages that we didn't use.
	
	  Wait for and collect replies for any successful sends in order of
	  increasing offset. Once an error is hit, then return without waiting
	  for any more replies.
 resend call if it's a retryable error 
	
	  iov_iter_get_pages_alloc doesn't work with ITER_KVEC.
	  In this case, fall back to non-direct write function.
	  this could be improved by getting pages directly in ITER_KVEC
 grab a lock here due to read response handlers can access ctx 
	
	  If at least one write was successfully sent, then discard any rc
	  value from the later writes. If the other write succeeds, then
	  we'll end up returning whatever was written. If it fails, then
	  we'll get a new rc value from that.
	
	  We need to hold the sem to be sure nobody modifies lock list
	  with a brlock that prevents writing.
	
	  For non-oplocked files in strict cache mode we need to write the data
	  to the server exactly from the pos to pos+len-1 rather than flush all
	  affected pages because it may cause a error with mandatory locks on
	  these pages but not on the region from pos to ppos+len-1.
		
		  We have read level caching and we have just sent a write
		  request to the server thus making data in the cache stale.
		  Zap the cache and set oplocklease level to NONE to avoid
		  reading stale data from the cache. All subsequent read
		  operations will read new data from the server.
  cifs_readdata_to_iov - copy data from pages in response to an iovec
  @rdata:	the readdata response with list of pages holding data
  @iter:	destination for our data
  This function copies data from a list of pages in a readdata response into
  an array of iovecs. It will first calculate where the data should go
  based on the info in the readdata and then copy the data into that spot.
 the below call can possibly free the last ref to aio ctx 
 no need to hold page hostage 
 enough data to fill the page 
 XXX: should we pick a new channel here? 
		
		  Wait for credits to resend this rdata.
		  Note: we are attempting to resend the whole rdata not in
		  segments
 If the read was successfully sent, we are done 
 Add to aio pending list 
 Roll back credits and retry if needed 
 allocate a readdata struct 
 the loop below should proceed in the order of increasing offsets 
 resend call if it's a retryable error 
				
				  Got a part of data and then reconnect has
				  happened -- fill the buffer and continue
				  reading.
					
					  Re-use rdata as this is a
					  direct IO
 if there was a short read -- discard anything left 
 mask nodata case 
	
	  iov_iter_get_pages_alloc() doesn't work with ITER_KVEC,
	  fall back to data copy read path
	  this could be improved by getting pages directly in ITER_KVEC
 grab a lock here due to read response handlers can access ctx 
 if at least one read request send succeeded, then reset rc 
	
	  In strict cache mode we need to read from the server all the time
	  if we don't have level II oplock because the server can delay mtime
	  change - so we can't make a decision about inode invalidating.
	  And we can also fail with pagereading if there are mandatory locks
	  on pages affected by this read but not on the region from pos to
	  pos+len-1.
	
	  We need to hold the sem to be sure nobody modifies lock list
	  with a brlock that prevents reading.
 FIXME: set up handlers for larger reads andor convert to async 
			
			  For windows me and 9x we do not want to request more
			  than it negotiated since it will refuse the read
			  then.
  If the page is mmap'ed into a process' page tables, then we need to make
  sure that it doesn't change while being written back.
 determine the eof that the server (probably) has 
 enough for partial page, fill and zero the rest 
			
			  The VFS will not try to do readahead past the
			  i_size, but it's possible that we have outstanding
			  writes with gaps in the middle and the i_size hasn't
			  caught up yet. Populate those with zeroed out pages
			  to prevent the VFS from repeatedly attempting to
			  fill them until the writes are flushed.
 no need to hold page hostage 
	
	  Lock the page and put it in the cache. Since no one else
	  should have access to this page, we're safe to simply set
	  PG_locked without checking it first.
 give up if we can't stick it in the cache 
 move first page to the tmplist 
 now try and add more pages onto the request 
 discontinuity ? 
 would this page push the read over the rsize? 
	
	  Reads as many pages as possible from fscache. Returns -ENOBUFS
	  immediately if the cookie is negative
	 
	  After this point, every page in the list might have PG_fscache set,
	  so we will need to clean that up off of every page we don't use.
	
	  Start with the page at end of list and move it to private
	  list. Do the same with any following pages until we hit
	  the rsize limit, hit an index discontinuity, or run out of
	  pages. Issue the async read and then start the loop again
	  until the list is empty.
	 
	  Note that list order is important. The page_list is in
	  the order of declining indexes. When we put the pages in
	  the rdata->pages, then we want them in increasing order.
		
		  Give up immediately if rsize is too small to read an entire
		  page. The VFS will fall back to readpage. We should never
		  reach this point however since we set ra_pages to 0 when the
		  rsize is smaller than a cache page.
 best to give up if we're out of mem 
 Fallback to the readpage in errorreconnect cases 
	 Any pages that have been shown to fscache but didn't get added to
	  the pagecache must be uncached before they get returned to the
	  allocator.
  cifs_readpage_worker must be called with the page pinned
 Is the page cached? 
 for reads over a certain size could initiate async read ahead 
 we do not want atime to be less than mtime, it broke some apps 
 send this page to the cache 
 We do not want to update the file size from server for inodes
   open for write - to avoid races with writepage extending
   the file - in the future we could consider allowing
   refreshing the inode only on increases in the file size
   but this is tricky to do without racing with writebehind
 This inode is open for write at least once 
			 since no page cache to corrupt on directio
	
	  If we write a full page it will be up to date, no need to read from
	  the server. If the write is short, we'll end up doing a sync write
	  instead.
	
	  optimize away the read when we have an oplock, and we're not
	  expecting to use any of the data we'd be reading in. That
	  is, when the page lies beyond the EOF, or straddles the EOF
	  and the write will cover all of the existing data.
			
			  PageChecked means that the parts of the page
			  to which we're not writing are considered up
			  to date. Once the data is copied to the
			  page, it can be set uptodate.
		
		  might as well read a page, it is fast enough. If we get
		  an error, we don't need to return it. cifs_write_end will
		  do a sync write instead since PG_uptodate isn't set.
		 we could try using another file handle if there is one -
		   but how would we lock it to prevent close of that handle
		   racing with this read? In any case
	
	  When oplock break is received and there are no active
	  file handles but cached, then schedule deferred close immediately.
	  So, new open will not use cached handle.
	
	  releasing stale oplock after recent reconnect of smb session using
	  a now incorrect file handle is not a data integrity issue but do
	  not bother sending an oplock release if session to server still is
	  disconnected since oplock already released by the server
 do not wait for ourself , false);
  The presence of cifs_direct_io() in the address space ops vector
  allowes open() O_DIRECT flags which would have failed otherwise.
  In the non-cached mode (mount with cache=none), we shunt off direct read and write requests
  so this method should never be called.
  Direct IO is not yet supported in the cached mode. 
          FIXME
          Eventually need to support direct IO for non forcedirectio mounts
	
	  TODO: consider adding ACL (or documenting how) to prevent other
	  users (on this or other systems) from reading it
 TODO: add sk_set_memalloc(inet) or similar 
	
	  TODO: Since file already open, we can't open with DENY_ALL here
	  but we could add call to grab a byte range lock to prevent others
	  from reading or writing the file
 TODO: undo sk_set_memalloc(inet) will eventually be needed 
 do we need to unpin (or unlock) the file 
	
	  TODO: investigate and if useful we could add an cifs_migratePage
	  helper (under an CONFIG_MIGRATION) in the future, and also
	  investigate and add an is_dirty_writeback helper if needed
  cifs_readpages requires the server to support a buffer large enough to
  contain the header plus one complete page of data.  Otherwise, we need
  to leave cifs_readpages out of the address space operations.
 SPDX-License-Identifier: GPL-2.0
   SMB2 version specific operations
   Copyright (c) 2012, Jeff Layton <jlayton@redhat.com>
 Change credits for different ops and return the total number of credits 
 eg found case where write overlapping reconnect messed up credits 
 Don't get near 64K credits, avoid srv bugs 
	
	  Sometimes server returns 0 credits on oplock break ack - we need to
	  rebalance credits in this case.
 change_conf hasn't been executed 
 change_conf rebalanced credits for different types 
 don't log while holding the lock 
 can deadlock with reopen 
 leave some credits for reopen and other ops 
 for SMB2 we need the current value 
 BB we probably don't need to retry with modern servers 
 start with specified wsize, or default 
 start with specified wsize, or default 
			
			  Account for SMB2 data transfer packet header and
			  possible encryption header
 start with specified rsize, or default 
 start with specified rsize, or default 
			
			  Account for SMB2 data transfer packet header and
			  possible encryption header
	
	  Fist pass: count and sanity check
 Azure rounds the buffer size up 8, to a 16 byte boundary 
	
	  Second pass: extract info to internal structure
		
		  The kernel and wire socket structures have the same
		  layout and use network byte order but make the
		  conversion explicit in case either one changes.
 [MS-SMB2] 2.2.32.5.1.1 Clients MUST ignore these 
 [MS-SMB2] 2.2.32.5.1.2 Clients MUST ignore these 
 is_fsctl ,
 no data input , 0 
 sort interfaces from fastest to slowest 
	
	  We only check validity above to send SMB2_close,
	  but we still need to invalidate these entries
	  when this function is called
  Open the and cache a directory handle.
  Only supported for the root handle.
 Null - since an open of top of share 
	
	  We do not hold the lock for the open because in case
	  SMB2_open needs to reconnect, it will end up calling
	  cifs_mark_open_files_invalid() which takes the lock again
	  thus causing a deadlock
 Open 
	
	  Now we need to check again as the cached root might have
	  been successfully re-opened from a concurrent process
 work was already done 
 stash fids for close() later 
		
		  caller expects this func to set the fid in crfid to valid
		  cached root, so increment the refcount.
 close extra handle outside of crit sec 
 Cached root is still invalid, continue normaly 
 CIFS_DEBUG2 
 BB TBD check to see if oplock level check can be removed below 
		
		  See commit 2f94a3125b87. Increment the refcount when we
		  get a lease for root, release it if lease break occurs
 Null - open root of share 
 SMB3 specific 
 Null - open root of share 
 'user.' plus a terminating null 
 skip copy - calc size only 
 stop before overrun buffer 
 stop before overrun buffer 
 didn't find the named attribute 
		
		  If ea_name is NULL (listxattr) and there are no EAs,
		  return 0 as it's not an error. Otherwise, the specified
		  ea_name was not found.
			 If we are adding a attribute we should first check
			  if there will be enough space available to store
			  the new EA. If not we should not add it since we
			  would not be able to even read the EAs back.
			 Use a fudge factor of 256 bytes in case we collide
			  with a different set_EAs command.
 Open 
 Set Info 
 Close 
 no need to bump num_remote_opens because handle immediately closed 
	
	   Can't display SMB2_NEGOTIATE, SESSION_SETUP, LOGOFF, CANCEL and ECHO
	   totals (requests sent) since those SMBs are per-session not per tcon
 CIFS_DEBUG2 
 Creation time should not need to be updated on close 
	
	  i_blocks is not related to (i_size  i_blksize),
	  but instead 512 byte (29) size is required for
	  calculating num blocks.
 End of file and Attributes should not have to be updated on close 
 is_fsctl ,
 no input , CIFSMaxBufSize,
 Open 
 Query 
 Can eventually relax perm check since server enforces too 
 Can eventually relax perm check since server enforces too 
 unknown flags 
 Close 
 No need to bump num_remote_opens since handle immediately closed 
 Request a key from the server to identify the source of the copy 
 Note: request_res_key sets res_key null only if rc !=0 
 For now array only one chunk long, will make more flexible later 
 Request server copy to target from src identified by key 
 is_fsctl , (char )pcchunk,
			
			  Check if server claimed to write more than we asked
			
			  Check if this is the first request using these sizes,
			  (ie check if copy succeed once with original sizes
			  and check if the server gave us different sizes after
			  we already updated max sizes on previous request).
			  if not then why is the server returning an error now
 Check that server is not asking us to grow size 
 server gave us bogus size 
 No need to change MaxChunks since already set to 1 
 Set or clear the SPARSE_FILE attribute based on value passed in setsparse 
 if file already sparse don't bother setting sparse again 
 already sparse 
 already not sparse 
	
	  Can't check for sparse support on share the usual way via the
	  FS attribute info (FILE_SUPPORTS_SPARSE_FILES) on the share
	  since Samba server doesn't set the flag on the share, yet
	  supports the set sparse FSCTL and returns sparse correctly
	  in the file attributes. If we fail setting sparse though we
	  mark that server does not support sparse files for this share
	  to avoid repeatedly sending the unsupported fsctl to server
	  if the file is repeatedly extended.
 is_fctl ,
	
	  If extending file more than one page make sparse. Many Linux fs
	  make files sparse by default when extending via ftruncate
 whether set sparse succeeds or not, extend the file 
 server fileays advertise duplicate extent support with this flag 
		
		  Although also could set plausible allocation size (i_blocks)
		  here in addition to setting the file size, in reflink
		  it is likely that the target file is sparse. Its allocation
		  size will be queried on next revalidate, but it is important
		  to make sure that file's cached size is updated immediately
 is_fsctl ,
 is_fsctl ,
 GMT Token is @GMT-YYYY.MM.DD-HH.MM.SS Unicode which is 48 bytes + null 
 See MS-SMB2 section 3.3.5.15.1 
  Input buffer contains (empty) struct smb_snapshot array with size filled in
  For output see struct SRV_SNAPSHOT_ARRAY in MS-SMB2 section 2.2.32.2
	
	  On the first query to enumerate the list of snapshots available
	  for this volume the buffer begins with 0 (number of snapshots
	  which can be returned is zero since at that point we do not know
	  how big the buffer needs to be). On the second query,
	  it (ret_data_len) is set to number of snapshots so we can
	  know to set the maximum response size larger (see below).
	
	  Note that for snapshot queries that servers like Azure expect that
	  the first query be minimal size (and just used to get the numbersize
	  of previous versions) so response size must be specified as EXACTLY
	  sizeof(struct snapshot_array) which is 16 when rounded up to multiple
	  of eight bytes.
 is_fsctl ,
 no input data , max_response_size,
 Fixup buffer 
		
		  Check for min size, ie not large enough to fit even one GMT
		  token (snapshot).  On the first ioctl some users may pass in
		  smaller size (or zero) to simply get the size of the array
		  so the user space caller can allocate sufficient memory
		  and retry the ioctl again with larger array size sufficient
		  to hold all of the snapshot GMT tokens on the second try.
		
		  We return struct SRV_SNAPSHOT_ARRAY, followed by
		  the snapshot array (of 50 byte GMT tokens) each
		  representing an available previous version of the data
 Open 
 Query directory 
 If the open failed there is nothing to do 
 Anything else than ENODATA means a genuine error 
  If we negotiate SMB2 protocol and get STATUS_PENDING - update
  the number of credits and return true. Otherwise - return false.
 SMB headers in a compound are 8 byte aligned. 
 No padding needed 
		
		  If we do not have encryption then we can just add an extra
		  iov for the padding.
		
		  We can not add a small padding iov for the encryption case
		  because the encryption framework can not handle the padding
		  iovs.
		  We have to flatten this into a single buffer and add
		  the padding to it.
  Passes the query info response back to the caller on success.
  Caller need to free this with free_rsp_buf().
 Null - open root of share 
 Null - open root of share 
	
	  Try to use the IPC tcon, otherwise just use any
 Highest DFS referral version understood 
 Path to resolve in an UTF-16 null-terminated string 
 is_fsctl ,
 is_unicode );
 ipc tcons are not refcounted 
 tc_count can never go negative 
 See MS-FSCC 2.1.2.6 for the 'NFS' style reparse tags 
 We handle Symbolic Link reparse tag here. See: MS-FSCC 2.1.2.4 
 See MS-FSCC 2.1.2 
 Open 
 IOCTL 
 is_fctl , NULL, 0,
 Close 
	
	  Open was successful and we got an ioctl response.
 See MS-FSCC 2.3.23 
 open must fail on symlink - reset rc 
	
	  setup smb2open - TODO add optimization to call cifs_get_readable_path
	  to see if there is a handle already open that we can use
 IOCTL 
 is_fctl , NULL, 0,
 Close 
	
	  Open was successful and we got an ioctl response.
 See MS-FSCC 2.3.23 
	
	  When querying an ACL, even if the file is a symlink we want to open
	  the source not the target, and so the protocol requires that the
	  client specify this flag when opening a reparse point
 Retrieve an ACL from the server 
	
	  We zero the range through ioctl, so we need remove the page caches
	  first, otherwise the data may be inconsistent with the server.
 if file not oplocked can't be sure whether asking to extend size 
	
	  do we also need to change the size of the file?
 Need to make file sparse, if not already, before freeing range. 
 Consider adding equivalent for compressed since it could also work 
	
	  We implement the punch hole through ioctl, so we need remove the page
	  caches first, otherwise the data may be inconsistent with the server.
 is_fctl , (char )&fsctl_buf,
 iov[0] is reserved for smb header 
		
		  The rest of the region is unmapped so write it all.
			
			  We are at a hole. Write until the end of the region
			  or until the next allocated data,
			  whichever comes next.
		
		  We are at a section of allocated data, just skip forward
		  until the end of the data or the end of the region
		  we are supposed to fallocate, whichever comes first.
 if file not oplocked can't be sure whether asking to extend size 
	
	  Extending the file
	
	  Files are non-sparse by default so falloc may be a no-op
	  Must check if file sparse. If not sparse, and since we are not
	  extending then no need to do anything since file already allocated
		
		  We can not preallocate pages beyond the end of the file
		  in SMB2
		
		  For fallocates that are partially beyond the end of file,
		  clamp len so we only fallocate up to the end of file.
		
		  At this point, we are trying to fallocate an internal
		  regions of a sparse file. Since smb2 does not have a
		  fallocate command we have two otions on how to emulate this.
		  We can either turn the entire file to become non-sparse
		  which we only do if the fallocate is for virtually
		  the whole file,  or we can overwrite the region with zeroes
		  using SMB2_write, which could be prohibitevly expensive
		  if len is large.
		
		  We are only trying to fallocate a small region so
		  just write it with zero.
		
		  Check if falloc starts within first few pages of file
		  and ends within a few pages of the end of file to
		  ensure that most of file is being forced to be
		  fallocated now. If so then setting whole file sparse
		  ie potentially making a few extra pages at the beginning
		  or end of the file non-sparse via set_sparse is harmless.
	
	  We need to be sure that all dirty pages are written as they
	  might fill holes on the server.
	  Note that we also MUST flush any written pages since at least
	  some servers (Windows2016) will not reflect recent writes in
	  QUERY_ALLOCATED_RANGES until SMB2_flush is called.
 KEEP_SIZE already checked for by do_fallocate 
 Check if the server granted an oplock rather than a lease 
 SMB2_CREATE_REQUEST_LEASE is "RqLs" 
 SMB2_CREATE_REQUEST_LEASE is "RqLs" 
 not used 
 We can not use the normal sg_set_buf() as we will sometimes pass a
  stack object as buf.
	
	  VMAP_STACK (at least) puts stack into the vmalloc address space
 Assumes the first rqst has a transform header as the first iov.
  I.e.
  rqst[0].rq_iov[0]  is transform header
  rqst[0].rq_iov[1+] data to be encrypteddecrypted
  rqst[1+].rq_iov[0+] data to be encrypteddecrypted
			
			  The first rqst has a transform header where the
			  first 20 bytes are not part of the encrypted blob
  Encrypt or decrypt @rqst message. @rqst[0] has the following format:
  iov[0]   - transform header (associate data),
  iov[1-N] - SMB2 header and pages - data to encrypt.
  On success return encrypted data in iov[1-N] and pages, leave iov[0]
  untouched.
  This function will initialize new_rq and encrypt the content.
  The first entry, new_rq[0], only contains a single iov which contains
  a smb2_transform_hdr and is pre-allocated by the caller.
  This function then populates new_rq[1+] with the content from olq_rq[0+].
  The end result is an array of smb_rqst structures where the first structure
  only contains a single iov for the transform header which we then can pass
  to crypt_message().
  new_rq[0].rq_iov[0] :  smb2_transform_hdr pre-allocated by the caller
  new_rq[1+].rq_iov[] == old_rq[0+].rq_iov[] : SMB23 requests
 copy pages form the old 
 fill the 1st iov with a transform header 
 enough data to fill the page 
 set up first two iov to get credits 
 normal error on read response 
		
		  win2k8 sometimes sends an offset of 0 when the read
		  is beyond the EOF. Treat it as if the data starts just after
		  the header.
 data_offset is beyond the end of smallbuf 
 read response payload is in pages 
 data offset is beyond the 1st page of response 
 data_len is corrupt -- discard frame 
 read response payload is in buf 
 read response payload cannot be in both buf and pages 
 read read data into pages 
	
	  For large reads, offload to different thread for better performance,
	  use more cores decrypting which can be expensive
 worker thread takes care of finding mid 
 switch to large buffer if too big for a small one 
 now read the rest 
		
		  ret != 0 here means that we didn't get to handle_mid() thus
		  server->smallbuf and server->bigbuf are still valid. We need
		  to free next_buffer because it is not going to be used
		  anywhere.
 TODO: add support for compounds containing READ. 
	
	  Check if mounted with mount parm 'sfu' mount parm.
	  SFU emulation should work with all servers, but only
	  supports block and char device (no socket & fifo),
	  and was used by default in earlier versions of Windows
	
	  TODO: Add ability to create instead via reparse point. Windows (e.g.
	  their current NFS server) uses this approach to expose special files
	  over SMB2SMB3 and Samba will do this with SMB3.1.1 POSIX Extensions
	
	  BB Do not bother to decode buf since no local inode yet to put
	  timestamps in, but we can reuse it safely.
 FIXME: add code here to set EAs 
 CIFS_XATTR 
 CIFS_XATTR 
 WSL tags introduced long after smb2.1, enable for SMB3, 3.11 only 
 CIFS_XATTR 
	.validate_negotiate = smb3_validate_negotiate,  
 CIFS_XATTR 
 MBZ 
 MBZ on negotiate req until SMB3 dialect 
 doesn't matter, send protocol array 
 doesn't matter, send protocol array 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002, 2011
                  Etersoft, 2012
    Author(s): Steve French (sfrench@us.ibm.com)
               Jeremy Allison (jra@samba.org) 2006
               Pavel Shilovsky (pshilovsky@samba.org) 2012
		
		  If we are in the process of binding a new channel
		  to an existing session, use the master connection
		  session key
	
	  Otherwise, use the channel key.
  Obtain tcon corresponding to the tid in the given
  cifs_ses
 tcon already has a ref to ses, so we don't need ses anymore 
	
	  For SMB2+, __cifs_calc_signature() expects to sign only the actual
	  data, that is, iov[0] should not contain a rfc1002 length.
	 
	  Sign the rfc1002 length prior to passing the data (iov[1-N]) down to
	  __cifs_calc_signature().
	
	  All channels use the same encryptiondecryption keys but
	  they have their own signing key.
	 
	  When we generate the keys, check if it is for a new channel
	  (binding) in which case we only need to generate a signing
	  key and store it in the channel as to not overwrite the
	  master connection signing key stored in the session
	
	  The session id is opaque in terms of endianness, so we can't
	  print it as a long long. we dump it as we got it on the wire
	
	  we already allocate sdesccmacaes when we init smb3 signing key,
	  so unlike smb2 case we do not have to check here if secmech are
	  initialized
	
	  For SMB2+, __cifs_calc_signature() expects to sign only the actual
	  data, that is, iov[0] should not contain a rfc1002 length.
	 
	  Sign the rfc1002 length prior to passing the data (iov[1-N]) down to
	  __cifs_calc_signature().
 must be called with server->srv_mutex held 
	
	  BB what if signatures are supposed to be on for session but
	  server does not send one? BB
 Do not need to verify session setups with signature "BSRSPYL " 
	
	  Save off the origiginal signature so we can modify the smb and check
	  our calculated signature against what the server sent.
  Set message id for the request. Should be called after wait_for_free_request
  and when srv_mutex is held.
 skip message numbers according to CreditCharge field 
 Always LE 
	
	  The default is for the mid to be synchronous, so the
	  default callback just wakes up the current task.
 else ok - we are setting up session 
 else ok - we are shutting down the session 
 convert the length into a more usable form 
 SPDX-License-Identifier: LGPL-2.1
    CIFS filesystem cache index structure definitions
    Copyright (c) 2010 Novell, Inc.
    Authors(s): Suresh Jayaraman (sjayaraman@suse.de>
  CIFS filesystem definition for FS-Cache
  Register CIFS for caching with FS-Cache
  Unregister CIFS for caching
  Server object for FS-Cache
  Superblock object for FS-Cache
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2008
    Author(s): Steve French (sfrench@us.ibm.com)
    Jeremy Allison (jra@samba.org) 2006.
 Max number of iovectors we can use off the stack when sending requests. 
	do_gettimeofday(&temp->when_sent); 
 when mid allocated can be before when sent 
	
	  The default is for the mid to be synchronous, so the
	  default callback just wakes up the current task.
	
	  commands taking longer than one second (default) can be indications
	  that something is wrong, unless it is quite a slow link or a very
	  busy server. Note that this calc is unlikely or impossible to wrap
	  as long as slow_rsp_threshold is not set way above recommended max
	  value (32767 ie 9 hours) and is generally harmless even if wrong
	  since only affects debug counters - so leaving the calc as simple
	  comparison rather than doing multiple conversions and overflow
	  checks
		
		  smb2slowcmd[NUMBER_OF_SMB2_COMMANDS] counts by command
		  NB: le16_to_cpu returns unsigned so can not be negative below
  smb_send_kvec - send an array of kvecs to the server
  @server:	Server to send the data to
  @smb_msg:	Message to send
  @sent:	amount of data sent on socket is stored here
  Our basic "send data to server" function. Should be called with srv_mutex
  held. The caller is responsible for handling the results.
		
		  If blocking send, we try 3 times, since each can block
		  for 5 seconds. For nonblocking  we have to try more
		  but wait increasing amounts of time allowing time for
		  socket to clear.  The overall time we wait in either
		  case to send on the socket is about 15 seconds.
		  Similarly we wait for 15 seconds for a response from
		  the server in SendReceive[2] for the server to send
		  a response back for most types of requests (except
		  SMB Write past end of file which can be slow, and
		  blocking lock operations). NFS waits slightly longer
		  than CIFS, but this can make it take longer for
		  nonresponsive servers to be detected and 15 seconds
		  is more than enough time for modern networks to
		  send a packet.  In most cases if we fail to send
		  after the retries we will kill the socket and
		  reconnect which may clear the network problem.
			 should never happen, letting socket clear before
 send was at least partially successful 
 in case we get ENOSPC on the next send 
 total up iov array first 
	
	  Add in the page array if there is one. The caller needs to make
	  sure rq_offset and rq_tailsz are set correctly. If a buffer of
	  multiple pages ends at page boundary, rq_tailsz needs to be set to
	  PAGE_SIZE.
			
			  If there is more than one page, calculate the
			  buffer length based on rq_offset and rq_tailsz
 return -EAGAIN when connecting or reconnecting 
 cork the socket 
	
	  We should not allow signals to interrupt the network send because
	  any partial send will cause session reconnects thus increasing
	  latency of system calls and overload a server with unnecessary
	  requests.
 Generate a rfc1002 marker for SMB2+ 
 now walk the page array and send each page in it 
	
	  If signal is pending but we have already sent the whole packet to
	  the server we need to return success status to allow a corresponding
	  mid entry to be kept in the pending requests queue thus allowing
	  to handle responses from the server by the client.
	 
	  If only part of the packet has been sent there is no need to hide
	  interrupt because the session will be reconnected anyway, so there
	  won't be any response from the server to handle.
 uncork it 
		
		  If we have only sent part of an SMB then the next SMB could
		  be taken as the remainder of this one. We need to kill the
		  socket so the server throws away the partial SMB
 Since an echo is already inflight, no need to wait to send another 
 oplock breaks must not be held up 
			
			  For normal commands, reserve the last MAX_COMPOUND
			  credits to compound requests.
			  Otherwise these compounds could be permanently
			  starved for credits by single-credit requests.
			 
			  To prevent spinning CPU, block this thread until
			  there are >MAX_COMPOUND credits available.
			  But only do this is we already have a lot of
			  credits in flight to avoid triggering this check
			  for servers that are slow to hand out credits on
			  new sessions.
			
			  Can not count locking commands against total
			  as they are allowed to block on server.
 update # of requests on the wire to server 
		
		  If the server is tight on resources or just gives us less
		  credits for other reasons (e.g. requests are coming out of
		  order and the server delays granting more credits until it
		  processes a missing mid) and we exhausted most available
		  credits there may be situations when we try to send
		  a compound request but we don't have enough credits. At this
		  point the client needs to decide if it should wait for
		  additional credits or fail the request. If at least one
		  request is in flight there is a high probability that the
		  server will return enough credits to satisfy this compound
		  request.
		 
		  Return immediately if no requests in flight since we will be
		  stuck on waiting for credits.
 else ok - we are setting up session 
 check if SMB session is bad because we are setting it up 
 else ok - we are shutting down session 
 enable signing if server requires it 
  Send a SMB request and set the callback function in the mid to handle
  the result. Caller is responsible for dealing with timeouts.
	
	  We can't use credits obtained from the previous session to send this
	  request. Check if there were reconnects after we obtained credits and
	  return -EAGAIN in such cases to let callers handle it.
 put it on the pending_mid_q 
	
	  Need to store the time in mid before calling IO. For call_async,
	  IO response may come back and free the mid entry on another thread.
  Send an SMB Request.  No response info (other than return code)
  needs to be parsed.
  flags indicate the type of request buffer and how long to wait
  and whether to log NT STATUS code (error) before mapping it to POSIX error
 convert the length into a more usable form 
 FIXME: add code to kill session 
 BB special case reconnect tid and uid here? 
  Return a channel (master if none) of @ses that can be used to send
  regular requests.
  If we are currently binding a new channel (negprotsess.setup),
  return the new incomplete channel.
 round robin 
 no response buf yet 
	
	  Wait for all the requests to become available.
	  This approach still leaves the possibility to be stuck waiting for
	  credits if the server doesn't grant credits to the outstanding
	  requests and if the client is completely idle, not generating any
	  other requests.
	  This can be handled by the eventual session reconnect.
	
	  Make sure that we sign in the same order that we send on this socket
	  and avoid races inside tcp sendmsg code that could cause corruption
	  of smb data.
	
	  All the parts of the compound chain belong obtained credits from the
	  same session. We can not use credits obtained from the previous
	  session to send this request. Check if there were reconnects after
	  we obtained credits and return -EAGAIN in such cases to let callers
	  handle it.
 Update # of requests on wire to server 
		
		  Invoke callback for every part of the compound chain
		  to calculate credits properly. Wake up this thread only when
		  the last element is received.
	
	  If sending failed for some reason or it is an oplock break that we
	  will not receive a response to - return credits back
	
	  At this point the request is passed to the network stack - we assume
	  that any credits taken from the server structure on the client have
	  been spent and we can't return them back. Once we receive responses
	  we will collect credits granted by the server in the mid callbacks
	  and add those credits to the server structure.
	
	  Compounding is never used during session establish.
 mark this mid as cancelled to not free it below 
 mark it so buf will not be freed by cifs_delete_mid 
	
	  Compounding is never used during session establish.
	
	  This will dequeue all mids. After this it is important that the
	  demultiplex_thread will not process any of these mids any futher.
	  This is prevented above by using a noop callback that will not
	  wake this thread except for the very last PDU.
 ret ,
 otherwise cifs_send_recv below sets resp_buf_type 
 1st iov is a RFC1001 length followed by the rest of the packet 
	 Ensure that we do not send more than 50 overlapping requests
	   to the same server. We may make this configurable later or
	 make sure that we sign in the same order that we send on this socket
	   and avoid races inside tcp sendmsg code that could cause corruption
 Update # of requests on wire to server 
 no longer considered to be "in-flight" 
 We send a LOCKINGX_CANCEL_LOCK to cause the Windows
	 We just modify the current in_buf to change
	   the type of lock from LOCKING_ANDX_SHARED_LOCK
	   or LOCKING_ANDX_EXCLUSIVE_LOCK to
	 Ensure that we do not send more than 50 overlapping requests
	   to the same server. We may make this configurable later or
	 make sure that we sign in the same order that we send on this socket
	   and avoid races inside tcp sendmsg code that could cause corruption
 Wait for a reply - allow signals to interrupt. 
 Were we interrupted by a signal ? 
			 POSIX lock. We send a NT_CANCEL SMB to cause the
			 Windows lock. We send a LOCKINGX_CANCEL_LOCK
			 If we get -ENOLCK back the lock may have
 no longer considered to be "in-flight" 
 We got the response - restart system call. 
 rcvd frame is ok 
 SPDX-License-Identifier: LGPL-2.1
    Encryption and hashing operations relating to NTLM, NTLMv2.  See MS-NLMP
    for more detailed information
    Copyright (C) International Business Machines  Corp., 2005,2013
    Author(s): Steve French (sfrench@us.ibm.com)
 iov[0] is actual data and not the rfc1002 length for SMB2+ 
 skip rfc1002 length 
 now hash over the rq_pages array 
  Calculate and return the CIFS signature based on the mac key and SMB PDU.
  The 16 byte signature must be allocated by the caller. Note we only use the
  1st eight bytes and that the smb header signature field on input contains
  the sequence number before this function is called. Also, this function
  should be called with the server->srv_mutex held.
 must be called with server->srv_mutex held 
 must be called with server->srv_mutex held 
	 BB what if signatures are supposed to be on for session but
 Do not need to verify session setups with signature "BSRSPYL "  
	 save off the origiginal signature so we can modify the smb and check
	cifs_dump_mem("what we think it should be: ",
 Build a proper attribute valuetarget info pairs blob.
  Fill in netbios and dns domain name and workstation name
  and client time (total five av pairs and + one end of fields indicator.
  Allocate domain name which gets freed when session struct is deallocated.
	
	  The length of this blob is two times the size of a
	  structure (av pair) which holds namesize
	  ( for NTLMSSP_AV_NB_DOMAIN_NAME followed by NTLMSSP_AV_EOL ) +
	  unicode length of a netbios domain name
	
	  As defined in MS-NTLM 3.3.2, just this av pair field
	  is sufficient as part of the temp
 Server has provided av pairstarget info in the type 2 challenge
  packet and we have plucked it and stored within smb session.
  We parse that blob here to find netbios domain name to be used
  as part of ntlmv2 authentication (in Target String), if not already
  specified on the command line.
  If this function returns without any error but without fetching
  domain name, authentication may fail against some server but
  may not fail against other (those who are not very particular
  about target string i.e. for some, just user name might suffice.
 advance attr type 
 advance attr size 
 advance attr  value 
 Server has provided av pairstarget info in the type 2 challenge
  packet and we have plucked it and stored within smb session.
  We parse that blob here to find the server given timestamp
  as part of ntlmv2 authentication (or local current time as
  default in case of failure)
 advance attr type 
 advance attr size 
 advance attr value 
 calculate md4 hash of password 
 convert ses->user_name to unicode 
 convert ses->domainName to unicode and uppercase 
 We use ses->ip_addr if no domain name available 
 The MD5 hash starts at challenge_key.key 
 Note that the MD5 digest over writes anon.challenge_key.key 
 target info blob 
	 Must be within 5 minutes of the server (or in range +-2h
	  in case of Mac OS X), so simply carry over server timestamp
	  (as Windows 7 does)
 calculate ntlmv2_hash 
 calculate first part of the client response (CR1) 
 now calculate the session key for NTLMv2 
 a nonce 
 make secondary_keynonce as session key 
 and make len as that of session key only 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2007
    Author(s): Steve French (sfrench@us.ibm.com)
    Common Internet FileSystem (CIFS) client
    Operations related to support for exporting files via NFSD
   See Documentationfilesystemsnfsexporting.rst
   and examples in fsexportfs
   Since cifs is a network file system, an "fsid" must be included for
   any nfs exports file entries which refer to cifs paths.  In addition
   the cifs mount must be mounted with the "serverino" option (ie use stable
   server inode numbers instead of locally generated temporary ones).
   Although cifs inodes do not use generation numbers (have generation number
   of zero) - the inode number alone should be good enough for simple cases
   in which users want to export cifs shares with NFS. The decode and encode
   could be improved by using a new routine which expects 64 bit inode numbers
   instead of the default 32 bit routines in fsexportfs
 BB need to add code here eventually to enable export via NFSD 
	Following five export operations are unneeded so far and can default:
	.get_dentry =
	.get_name =
	.find_exported_dentry =
	.decode_fh =
 CONFIG_CIFS_NFSD_EXPORT 
 SPDX-License-Identifier: GPL-2.0-or-later
  Copyright (c) Jeffrey Layton <jlayton@redhat.com>, 2013
  The const tables in this file were converted from the following info
  provided by Microsoft:
  3.1.5.3 Mapping UTF-16 Strings to Upper Case:
  https:msdn.microsoft.comen-uslibraryhh877830.aspx
  http:www.microsoft.comen-usdownloaddetails.aspx?displaylang=en&id=10921
  In particular, the table in "Windows 8 Upper Case Mapping Table.txt" was
  post-processed using the winucase_convert.pl script.
 quiet sparse 
  cifs_toupper - convert a wchar_t from lower to uppercase
  @in: character to convert from lower to uppercase
  This function consults the static tables above to convert a wchar_t from
  lower to uppercase. In the event that there is no mapping, the original
  "in" character is returned.
 grab upper byte 
 find pointer to 2nd layer table 
 grab lower byte 
 look up character in table 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2007,2008
    Author(s): Steve French (sfrench@us.ibm.com)
    Contains the routines for mapping CIFSNTFS ACLs
 security id for everyoneworld system group 
 security id for Authenticated Users system group 
 S-1-22-1 Unmapped Unix users 
 S-1-22-2 Unmapped Unix groups 
  See https:technet.microsoft.comen-uslibraryhh509017(v=ws.10).aspx
 S-1-5-88 MS NFS and Apple style UIDGIDmode 
 S-1-5-88-1 Unix uid 
 S-1-5-88-2 Unix gid 
 S-1-5-88-3 Unix mode 
	
	  If the payload is less than or equal to the size of a pointer, then
	  an allocation here is wasteful. Just copy the data directly to the
	  payload.value union member instead.
	 
	  With this however, you must check the datalen before trying to
	  dereference payload.data!
 3 bytes for prefix 
 The authority field is a single 48-bit number 
	
	  MS-DTYP states that if the authority is >= 2^32, then it should be
	  expressed as a hex value.
  if the two SIDs (roughly equivalent to a UUID for a user or group) are
  the same returns zero, if they do not match returns non-zero.
 compare the revision 
 compare all of the six auth values 
 compare all of the subauth values if any 
 sids comparematch 
 check if Mac (or Windows NFS) vs. Samba format for Unix owner SID 
 compare the revision 
 compare all of the six auth values 
 3 subauths, ie WindowsMac style  {
 well known sid found, uid returned 
 3 byte prefix + 10 bytes for value + NULL 
	
	  A sid is usually too large to be embedded in payload.value, but if
	  there are no subauthorities and the host has 8-byte pointers, then
	  it could be.
	
	  If we have too many subauthorities, then something is really wrong.
	  Just return an error.
 If unable to find uidgid easily from SID try via upcall 
	
	  FIXME: Here we assume that uid_t and gid_t are same size. It's
	  probably a safe assumption but might be better to check based on
	  sidtype.
	
	  Note that we return 0 here unconditionally. If the mapping
	  fails then we just fall back to using the ctx->linux_uidlinux_gid.
	 create an override credential set with a special thread keyring in
	  which requests are cached
	 
	  this is used to prevent malicious redirections from being installed
	  with add_key().
	 instruct request_key() to use this special keyring as a cache for
 copy ntsd, owner sid, and group sid from a security descriptor to another 
 copy security descriptor control portion 
 copy owner sid 
 copy group sid 
   change posix mode to reflect permissions
   pmode is the existing mode (we only want to overwrite part of this
   bits to set can be: S_IRWXU, S_IRWXG or S_IRWXO ie 00700 or 00070 or 00007
	
	  Do not assume "preferred" or "canonical" order.
	  The first DENY or ALLOW ACE which matches perfectly is
	  the permission to be used. Once allowed or denied, same
	  permission in later ACEs do not matter.
 If not already allowed, deny these bits 
 else ACCESS_ALLOWED type 
 If DELETE_CHILD is set only on an owner ACE, set sticky bit 
   Generate access flags to reflect permissions mode is the existing mode.
   This function is called for every ACE in the DACL whose SID matches
   with either owner or group or everyone.
 reset access mask 
 bits to use are either S_IRWXU or S_IRWXG or S_IRWXO 
	 check for RWX UGO since we do not know whose flags
	   is this but we have cleared all the bits sans RWX for
 Check if there's a replacement sid specified 
 validate that we do not go past end of acl 
		 BB add length check to make sure that we do not have huge
 BB need to add parm so we can store the SID BB 
		 no DACL in the security descriptor, set
 validate that we do not go past end of acl 
	 reset rwx permissions for usergroupother.
	   Also, if num_aces is 0 i.e. DACL has no ACEs,
				
				  Full permissions are:
				  07777 = S_ISUID | S_ISGID | S_ISVTX |
				          S_IRWXU | S_IRWXG | S_IRWXO
			memcpy((void )(&(cifscred->aces[i])),
				(void )ppace[i],
 size = 1 + 1 + 2 + 4 + 1 + 1 + 6 + (psid->num_subauth4) 
  Fill in the special SID based on the mode. See
  https:technet.microsoft.comen-uslibraryhh509017(v=ws.10).aspx
 size = 1 + 1 + 2 + 4 + 1 + 1 + 6 + (psid->num_subauth4) 
 size = 1 + 1 + 2 + 4 + 1 + 1 + 6 + (psid->num_subauth4) 
	
	  We'll try to keep the mode as requested by the user.
	  But in cases where we cannot meaningfully convert that
	  into ACL, return back the updated mode, so that it is
	  updated in the inode.
		
		  Case when owner and group SIDs are the same.
		  Set the more restrictive of the two modes.
 We need DENY ACE when the perm is more restrictive than the next sets. 
 This tells if we should allow delete child for group and everyone. 
 Group DENY ACE does not conflict with owner ALLOW ACE. Keep in preferred order
 Group DENY ACE conflicts with owner ALLOW ACE. So keep it after. 
 Go through all the ACEs 
 Assuming that pndacl and pnmode are never NULL 
 If pdacl is NULL, we don't have a src. Simply populate new ACL. 
 Retain old ACEs which we can retain 
 Place the new ACEs in between existing explicit and inherited 
 If it's any one of the ACE we're replacing, skip! 
 update the pointer to the next ACE to populate
 If inherited ACEs are not present, place the new ones at the tail 
 BB need to add parm so we can store the SID BB 
	 validate that we do not go past end of ACL - sid must be at least 8
		 BB add length check to make sure that we do not have huge
 Convert CIFS ACL to POSIX form 
 no need for SACL ptr 
	cifs_dump_mem("owner_sid: ", owner_sid_ptr, 64); 
 BB grant all or default perms? 
 Convert permission bits from mode to equivalent CIFS ACL 
 no need for SACL ptr 
 no need for SACL ptr 
 chmod 
 copy the non-dacl portion of secdesc 
 chown 
 Populate the user ownership fields S-1-5-88-1 
 lookup sid with upcall 
 chgrp 
 Populate the group ownership fields S-1-5-88-2 
 lookup sid with upcall 
 Replace ACEs for old owner with new one 
 copy the non-dacl portion of secdesc 
 errors could jump here. So make sure we return soon after this 
 Retrieve an ACL from the server 
 Set an ACL on the server 
 Translate the CIFS ACL (similar to NTFS ACL) for a file into mode bits 
 if we can retrieve the ACL, now parse Access Control Entries, ACEs 
 get approximated mode from ACL 
 Convert mode bits to an ACL so we can update the ACL on the server 
 default flag to set 
 acl obtained from server 
 modified acl to be sent to server 
 Get the security descriptor 
 Potentially, five new ACEs can be added to the ACL for U,G,O mapping 
 chmod 
 cifsacl 
 chown 
 When ownership changes, changes new owner sid length could be different 
 cifsacl 
	
	  Add three ACEs for owner, group, everyone getting rid of other ACEs
	  as chmod disables ACEs and set the security descriptor. Allocate
	  memory for the smb header, set security descriptor request security
	  descriptor parameters, and security descriptor itself
 Set the security descriptor 
 SPDX-License-Identifier: GPL-2.0
  SMB root file system support
  Copyright (c) 2019 Paulo Alcantara <palcantara@suse.de>
 TODO: ipv6 support 
<server-ip><share>[,options] 
 make s point to ',' or '\0' at end of line 
 len is strlen(unc) + '\0' 
 SPDX-License-Identifier: LGPL-2.1
    SMBCIFS session setup handling routines
    Copyright (c) International Business Machines  Corp., 2006, 2009
    Author(s): Steve French (sfrench@us.ibm.com)
 unknown family.. 
 returns number of channels added 
	
	  Make a copy of the iface list at the time and use that
	  instead so as to not hold the iface spinlock for opening
	  channels
	
	  Keep connecting to same, fastest, iface for all channels as
	  long as its RSS. Try next fastest one if not RSS or channel
	  creation fails.
  If server is a channel of ses, return the corresponding enclosing
  cifs_chan otherwise return NULL.
	
	  Setup a ctx with mostly the same info as the existing
	  session and overwrite it with the requested iface data.
	 
	  We need to setup at least the fields used for negprot and
	  sesssetup.
	 
	  We only need the ctx here, so we can reuse memory from
	  the session and server without caring about memory
	  management.
 Always make new connection for now (TODO?) 
 Auth 
 UNC and paths 
 XXX: Use ses->server->hostname? 
 Reuse same version as master connection 
	
	  This will be used for encodingdecoding userdomainpw
	  during sess setup auth.
 Use RDMA if possible 
 reuse master con client guid 
	
	  We need to allocate the server crypto now as we will need
	  to sign packets before we generate the channel signing key
	  (we sign with the session key)
	 success, put it on the list
	  XXX: sharing ses between 2 tcp servers is not possible, the
	  way "internal" linked lists works in linux makes element
	  only able to belong to one list
	 
	  the binding session is already established so the rest of
	  the code should be able to look it up, no need to add the
	  ses to the new server.
 Mark all session channels for reconnect 
 init fields common to all four types of SessSetup 
 Note that offsets for first seven fields in req struct are same  
	in CIFS Specs so does not matter which of 3 forms of struct 
	that we use in next few lines                               
 Note that header is initialized to zero in header_assemble 
 Now no need to set SMBFLG_CASELESS or obsolete CANONICAL PATH 
	 BB verify whether signing required on neg or just on auth frame
 Copy OS version 
 trailing null 
 trailing null 
 copy domain 
		 Sending null domain better than using a bogus domain name (as
 account for null terminator 
	 BB FIXME add check that strings total less
 unicode strings, must be word aligned before the call 
	if ((long) bcc_ptr % 2)	{
		bcc_ptr = 0;
		bcc_ptr++;
 copy user 
 null user mount 
 account for null termination 
 copy user 
 BB what about null user mounts - check that we do this BB 
 copy user 
 else null user mount 
 account for null termination 
 copy domain 
	}  else we will send a null domain name
 BB check for overflow here 
	 No domain field in LANMAN case. Domain is
	 BB For newer servers which do not support Unicode,
	   but thus do return domain here we could add parsing
 challenge message target info area 
 challenge message target info area length  
 BB we could decode pblob->NegotiateFlags; some may be useful 
 In particular we can examine sign flags 
	 BB spec says that if AvId field of MsvAvTimestamp is populated then
 BB Move to ntlmssp.c eventually 
 BB is NTLMV2 session security format easier to use here? 
 these fields should be null in negotiate phase MS-NLMP 3.1.5.1.1 
		
		  don't send an NT Response for anonymous access
	 we will send the SMB in three pieces:
	  a fixed length beginning part, an optional
	  SPNEGO blob (which can be zero length), and a
	  last part which will include the strings
	  and rest of bcc area. This allows us to avoid
	  a large buffer 17K allocation
	
	  This variable will be used to clear the buffer
	  allocated above in case of any error in the calling function.
 2000 big enough to fit max user, domain, NOS name etc. 
 num_iovecs ,
 old style NTLM sessionsetup 
 wct = 13 
 LM2 password would be here if we supported it 
 calculate nlmv2 response and session key 
		 set case sensitive password length after tilen may get
		  assigned, tilen is 0 otherwise.
 BB mark SesInfo struct? 
 UID left in wire format (le) 
 BB check if Unicode and decode strings 
 no string area to decode, do nothing 
 unicode string area must be word-aligned 
 extended security 
 wct = 12 
	
	  check version field to make sure that cifs.upcall is
	  sending us a response in an expected form
 unicode strings must be word aligned 
 BB: is this right? 
 BB mark SesInfo struct? 
 UID left in wire format (le) 
 BB check if Unicode and decode strings 
 no string area to decode, do nothing 
 unicode string area must be word-aligned 
 ! CONFIG_CIFS_UPCALL 
  The required kvec buffers have to be allocated before calling this
  function.
 unicode strings must be word aligned 
	
	  if memory allocation is successful, caller of this function
	  frees it.
 wct = 12 
 Build security blob before we assemble the request 
 If true, rc here is expected and not an error 
 UID left in wire format (le) 
 Else error. Cleanup 
 wct = 12 
 Build security blob before we assemble the request 
	
	  Make sure that we tell the server that we are using
	  the uid that it just gave us back on the response
	  (challenge)
 BB mark SesInfo struct? 
 BB check if Unicode and decode strings 
 no string area to decode, do nothing 
 unicode string area must be word-aligned 
 Cleanup 
 CONFIG_CIFS_UPCALL 
 Store result before we free sess_data 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2009, 2013
                  Etersoft, 2012
    Author(s): Steve French (sfrench@us.ibm.com)
               Pavel Shilovsky (pshilovsky@samba.org) 2012
    Contains the routines for constructing the SMB2 PDUs themselves
 SMB2 PDU handling routines here - except for leftovers (eg session setup) 
 Note that there are handle based routines which must be		      
 treated slightly differently for reconnection purposes since we never     
 want to reuse a stale file handle and only the caller knows the file info 
   The following table defines the expected "StructureSize" of SMB2 requests
   in order by SMB2 command.  This is similar to "wct" in SMBCIFS requests.
   Note that commands are defined in smb2pdu.h in le16 but the array below is
   indexed by command in host byte order.
 SMB2_NEGOTIATE  36,
 SMB2_SESSION_SETUP  25,
 SMB2_LOGOFF  4,
 SMB2_TREE_CONNECT 	9,
 SMB2_TREE_DISCONNECT  4,
 SMB2_CREATE  57,
 SMB2_CLOSE  24,
 SMB2_FLUSH  24,
 SMB2_READ 	49,
 SMB2_WRITE  49,
 SMB2_LOCK 	48,
 SMB2_IOCTL  57,
 SMB2_CANCEL  4,
 SMB2_ECHO  4,
 SMB2_QUERY_DIRECTORY  33,
 SMB2_CHANGE_NOTIFY  32,
 SMB2_QUERY_INFO  41,
 SMB2_SET_INFO  33,
 SMB2_OPLOCK_BREAK  24 
 Request up to 10 credits but don't go over the limit. 
 GLOBAL_CAP_LARGE_MTU will only be set if dialect > SMB2.02 
 See sections 2.2.4 and 3.2.4.1.5 of MS-SMB2 
 else CreditCharge MBZ 
 Uid is not converted 
	
	  If we would set SMB2_FLAGS_DFS_OPERATIONS on open we also would have
	  to pass the path on the Open SMB prefixed by \\server\share.
	  Not sure when we would need to do the augmented path (if ever) and
	  setting this flag breaks the SMB2 open operation since it is
	  illegal to send an empty path name (without \\server\share prefix)
	  when the DFS flag is set in the SMB open header. We could
	  consider setting the flag on all operations other than open
	  but it is safer to net set it for now.
	if (tcon->share_flags & SHI1005_FLAGS_DFS)
	
	  SMB2s NegProt, SessSetup, Logoff do not have tcon yet so
	  check for tcp and smb session status done differently
	  for those three - in the calling routine.
	
	  Need to also skip SMB2_IOCTL because it is used for checking nested dfs links in
	  cifs_tree_connect().
		
		  only tree disconnect, open, and write,
		  (and ulogoff which does not have tcon)
		  are allowed as we start force umount.
	
	  Give demultiplex thread up to 10 seconds to each target available for
	  reconnect -- should be greater than cifs socket timeout which is 7
	  seconds.
		
		  Return to caller for TREE_DISCONNECT and LOGOFF and CLOSE
		  here since they are implicitly done when session drops.
		
		  BB Should we keep oplock break and add flush to exceptions?
 are we still trying to reconnect? 
		
		  on "soft" mounts we wait once. Hard mounts keep
		  retrying until process is killed or server comes
		  back on-line
	
	  need to prevent multiple threads trying to simultaneously reconnect
	  the same SMB session
	
	  Recheck after acquire mutex. If another thread is negotiating
	  and the server never sends an answer the socket will be closed
	  and tcpStatus set to reconnect.
	
	  If we are reconnecting an extra channel, bind
	
	  End of channel binding
 If sess reconnected but tcon didn't, something strange ... 
	
	  Check if handle based operation so we know whether we can continue
	  or not without returning to caller to reset file handle.
	
	  BB Is flush done by server on drop of tcp session? Should we special
	  case it and skip above?
 lookup word count ie StructureSize from table 
	
	  smaller than SMALL_BUFFER_SIZE but bigger than fixed area of
	  largest operations (Create)
  Allocate and return pointer to an SMB request hdr, and set basic
  SMB information in the SMB header. If the return code is zero, this
  function must have filled in request_buf pointer.
 BB eventually switch this to SMB2 specific small buf size 
 BB should we add a retry in here if not a writepage? 
 Skip reconnect only for FSCTL_VALIDATE_NEGOTIATE_INFO IOCTLs 
 For explanation of negotiate contexts see MS-SMB2 section 2.2.3.1 
 number of signing algorithms sent 
	
	  Context Data length must be rounded to multiple of 8 for some servers
 sizeof u16 ), 8)  8);
 sizeof le16   num_algs;
 TBD add SIGNING_ALG_AES_GMAC andor SIGNING_ALG_HMAC_SHA256 
 Cipher Count + 1 cipher 
 Cipher Count + 3 ciphers 
 Cipher Count + 2 ciphers 
 copy up to max of first 100 bytes of server name to NetName field 
 context size is DataLength + minimal smb2_neg_context 
 SMB2_CREATE_TAG_POSIX is "0x93AD25509CB411E7B42383DE968BCD7C" 
 In case length corrupted don't want to overrun smb buffer 
	
	  round up total_len of fixed part of SMB3 negotiate request to 8
	  byte boundary before adding negotiate contexts
 check for and add transport_capabilities and signing capabilities 
 If invalid preauth context warn but use what we requested, SHA-512 
 sizeof compress context is a one element compression capbility struct 
		
		  e.g. if server only supported AES256_CCM (very unlikely)
		  or server supported no encryption types or had all disabled.
		  Since GLOBAL_CAP_ENCRYPTION will be not set, in the case
		  in which mount requested encryption ("seal") checks later
		  on during tree connection will return proper rc, but if
		  seal not requested by client, since server is allowed to
		  return 0 to indicate no supported cipher, we can't fail here
 server returned a cipher we didn't ask for 
 check that offset is not beyond end of SMB 
 offsets must be 8 byte aligned 
 SMB2_CREATE_TAG_POSIX is "0x93AD25509CB411E7B42383DE968BCD7C" 
 	SMB2 Worker functions follow:
 	The general structure of the worker functions is:
 	1) Call smb2_init (assembles SMB2 header)
 	2) Initialize SMB2 command specific fields in fixed length area of SMB
 	3) Call smb_sendrcv2 (sends request on socket and waits for response)
 	4) Decode SMB2 command specific fields in the fixed length area
 	5) Decode variable length data area (if any for this SMB2 command type)
 	6) Call free smb buffer
 	7) return
 otherwise send specific dialect 
 only one of SMB2 signing flags may be set in SMB2 request 
 ClientGUID must be zero for SMB2.02 dialect 
	
	  No tcon so can't do
	  cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);
 ops set to 3.0 by default for default so update 
 ops set to 3.0 by default for default so update 
 if requested single dialect ensure returned dialect matched 
	
	  Keep a copy of the hash after negprot. This hash will be
	  the starting hash value for all sessions made from this
	  server.
 SMB2 only has an extended negflavor 
 set it to the maximum buffer size value we can send with 1 credit 
 Internal types 
	
	  SMB3.0 supports only 1 cipher and doesn't have a encryption neg context
	  Set the cipher type manually.
	
	  See MS-SMB2 section 2.2.4: if no blob, client picks default which
	  for us will be
	 	ses->sectype = RawNTLMSSP;
	  but for time being this is our only auth choice so doesn't matter.
	  We just found a server which sets blob length to zero expecting raw.
 max of 4 dialects 
 In SMB3.11 preauth integrity supersedes validate negotiate 
	
	  validation ioctl must be signed, so no point sending this if we
	  can not sign it (ie are not known user).  Even if signing is not
	  required (enabled but not negotiated), in those cases we selectively
	  sign just this, the first and only signed request on a connection.
	  Having validation of negotiate info  helps reduce attack vectors.
 validation requires signing 
 validation requires signing 
 SMB 2.1 not included so subtract one dialect from len 
 structure is big enough for 4 dialects 
 otherwise specific dialect was requested 
 structure is big enough for 3 dialects, sending only 1 
 is_fsctl ,
		
		  Old Windows versions or Netapp SMB server can return
		  not supported error. Client should accept it.
 relax check since Mac returns max bufsize allowed on ioctl 
 check validate negotiate info response matches what we got earlier 
 do not validate server guid because not saved at negprot time yet 
 validate negotiate successful 
	 we will send the SMB in three pieces:
	  a fixed length beginning part, an optional
	  SPNEGO blob (which can be zero length), and a
	  last part which will include the strings
	  and rest of bcc area. This allows us to avoid
	  a large buffer 17K allocation
 First session, not a reauthenticate 
		
		  if reconnect, we need to send previous sess id
		  otherwise it is 0
 MBZ 
 enough to enable echos and oplocks and one max size write 
 only one of SMB2 signing flags may be set in SMB2 request 
 one flag unlike MUST_ 
 DFS_UPCALL 
 MBZ 
 1 for pad 
	
	  This variable will be used to clear the buffer
	  allocated above in case of any error in the calling function.
 Testing shows that buffer offset must be at location of Buffer[0] 
 pad );
 BB add code to build os and lm fields 
 keep existing ses state if binding 
	
	  check version field to make sure that cifs.upcall is
	  sending us a response in an expected form
 keep session key if binding 
 keep session id and flags if binding 
 else use raw ntlmssp 
	
	  If memory allocation is successful, caller of this function
	  frees it.
 BB eventually need to add this 
 If true, rc here is expected and not an error 
 keep existing ses id and flags if binding 
 else use raw ntlmssp 
 BB eventually need to add this 
 keep existing ses id and flags if binding 
		
		  The session id is opaque in terms of endianness, so we can't
		  print it as a long long. we dump it as we got it on the wire
	
	  Initialize the session hash with the server one.
 response is also trivial struct 
 no need to send SMB logoff if uid already closed due to reconnect 
 since no tcon, smb2_init can not do this, so do here 
	
	  No tcon so can't do
	  cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);
 server  + 80  NULL )
 These are similar values to what Windows uses 
 always use master channel 
 SMB2 TREE_CONNECT request must be called with TreeId == 0 
 1 for pad 
 Testing shows that buffer offset must be at location of Buffer[0] 
 pad );
	
	  3.11 tcon req must be signed if not encrypted. See MS-SMB2 3.2.4.1.1
	  unless it is guest or anonymous user. See MS-SMB2 3.2.5.3.1
	  (Samba servers don't always set the flag so also check if null user)
 Need 64 for max size write so ask for more in case not there yet 
 we keep caps little endian 
 response is trivial 
 SMB2_CREATE_DURABLE_HANDLE_REQUEST is "DHnQ" 
 SMB2_CREATE_DURABLE_HANDLE_RECONNECT is "DHnC" 
 Initialize inode number to 0 in case no valid data in qfid context 
		 else {
			cifs_dbg(FYI, "Context not matched with len %d\n",
				le16_to_cpu(cc->NameLength));
			cifs_dump_mem("Cctxt name: ", name, 4);
	
	  NB: Handle timeout defaults to 0, which allows server to choose
	  (most servers default to 120 seconds) and most clients default to 0.
	  This can be overridden at mount ("handletimeout=") if the user wants
	  a different persistent (or resilient) handle timeout for all opens
	  opens on a particular SMB3 mount.
 SMB2_CREATE_DURABLE_HANDLE_REQUEST is "DH2Q" 
 SMB2_CREATE_DURABLE_HANDLE_RECONNECT_V2 is "DH2C" 
 indicate that we don't need to relock the file 
 indicate that we don't need to relock the file 
 See MS-SMB2 2.2.13.2.7 
 SMB2_CREATE_TIMEWARP_TOKEN is "TWrp" 
 See MS-SMB2 2.2.13.2.7 
technet.microsoft.comen-uslibraryhh509017(v=ws.10).aspx 
 Populate the user ownership fields S-1-5-88-1 
 Populate the group ownership fields S-1-5-88-2 
 See MS-SMB2 2.2.13.2.2 and MS-DTYP 2.4.6 
 sizeof(struct owner_group_sids) is already multiple of 8 so no need to round 
 offset fields are from beginning of security descriptor not of create context 
 SMB2_CREATE_SD_BUFFER_TOKEN is "SecD" 
 Must be one see MS-DTYP 2.4.6 
	
	  ACL is "self relative" ie ACL is stored in contiguous block of memory
	  and "DP" ie the DACL is present
 offset owner, group and Sbz1 and SACL are all zero 
 Ship the ACL for now. we will copy it into buf later. 
 create one ACE to hold the mode embedded in reserved special SID 
 we do not need to reallocate buffer to add the two more ACEs. plenty of space 
 and one more ACE to allow access for authenticated users 
 See 2.4.4.1 of MS-DTYP 
 SMB2_CREATE_QUERY_ON_DISK_ID is "QFid" 
 See MS-SMB2 2.2.13.2.9 
	
	  skip leading "\\"
	
	  make room for one path separator between the treename and
	  path
	
	  final path needs to be null-terminated UTF16 with a
	  size aligned to 8
 make sure at least one for each open context 
 resource #1: path allocation 
 resource #2: request 
 File attributes ignored on open (used in create though) 
 -1 since last byte is buf[0] which is sent below (path) 
	 [MS-SMB2] 2.2.13 NameOffset:
	  If SMB2_FLAGS_DFS_OPERATIONS is set in the Flags field of
	  the SMB2 header, the file name includes a prefix that will
	  be processed during DFS name normalization as specified in
	  section 3.3.5.9. Otherwise, the file name is relative to
	  the share that is identified by the TreeId in the SMB2
	  header.
 free before overwriting resource 
 MUST set path len (NameLength) to 0 opening root of share 
 free before overwriting resource 
 resource #3: posix buf 
 no need to inc num_remote_opens because we close it just below 
 resource #4: response buffer 
	
	  Although unlikely to be possible for rsp to be null and rc not set,
	  adding check below is slightly safer long term (and quiets Coverity
	  warning)
 Eventually save off posix specific response info and timestaps 
 -1 since last byte is buf[0] which is sent below (path) 
 File attributes ignored on open (used in create though) 
	 [MS-SMB2] 2.2.13 NameOffset:
	  If SMB2_FLAGS_DFS_OPERATIONS is set in the Flags field of
	  the SMB2 header, the file name includes a prefix that will
	  be processed during DFS name normalization as specified in
	  section 3.3.5.9. Otherwise, the file name is relative to
	  the share that is identified by the TreeId in the SMB2
	  header.
 MUST set path len (NameLength) to 0 opening root of share 
 no srv lease support 
 need to set Next field of lease context if we request it 
 rq_iov[0] is the request and is released by cifs_small_buf_release().
  All other vectors are freed by kfree().
 unlikely to happen, but safer to check 
 CIFS_DEBUG2 
		
		  indatalen is usually small at a couple of bytes max, so
		  just allocate through generic pool
	
	  If no input data, the size of ioctl struct in
	  protocol spec still includes a 1 byte data buffer,
	  but if input data passed to ioctl, we do not
	  want to double count this, so we do not send
	  the dummy one byte of data in iovec[0] if sending
	  input data (in iovec[1]).
 do not set InputOffset if no input data 
 MBZ 
	
	  In most cases max_response_size is set to 16K (CIFSMaxBufSize)
	  We Could increase default MaxOutputResponse, but that could require
	  more credits. Windows typically sets this smaller, but for some
	  ioctls it may be useful to allow server to send more. No point
	  limiting what the server can send as long as fits in one credit
	  We can not handle more than CIFS_MAX_BUF_SIZE yet but may want
	  to increase this limit up in the future.
	  Note that for snapshot queries that servers like Azure expect that
	  the first query be minimal size (and just used to get the numbersize
	  of previous versions) so response size must be specified as EXACTLY
	  sizeof(struct snapshot_array) which is 16 when rounded up to multiple
	  of eight bytes.  Currently that is the only case where we set max
	  response size smaller.
 validate negotiate request must be signed - see MS-SMB2 3.2.5.5 
 request 
 	SMB2 IOCTL is used for both IOCTLs and FSCTLs
 returned data len )
 zero out returned data len, in case of error 
 check if caller wants to look at return data or just return rc 
	
	  Although unlikely to be possible for rsp to be null and rc not set,
	  adding check below is slightly safer long term (and quiets Coverity
	  warning)
 We check for obvious errors in the output buffer length and offset 
 server returned no data 
    Individual callers to ioctl worker function follow
 is_fsctl ,
 data input ,
 in data len , CIFSMaxBufSize 
 out data , NULL);
 request 
 check if need to ask server to return timestamps in close response 
		
		  Note that have to subtract 4 since struct network_open_info
		  has a final 4 byte pad that close response does not have
 retry close in a worker thread if this one is interrupted 
 check if beyond RFC1001 maximum length 
  If SMB buffer fields are valid, copy into temporary buffer to hold result.
  Caller must free buffer.
 total_len for smb query request never close to le16 max 
 1 for Buffer 
 request 
 currently unused, as now we are doing compounding instead (see smb311_posix_query_path_info) 
 Note caller must free "data" (passed in above). It may be allocated in query_info call 
  CHANGE_NOTIFY Request is sent to get notifications on changes to a directory
  See MS-SMB2 2.2.35 and 2.2.36
 See note 354 of MS-SMB2, 64K max 
 request 
  This is a no-op for now. We're not really interested in the reply, but
  rather in the fact that the server sent one and that server->lstrp
  gets updated.
  FIXME: maybe we should consider checking that the reply matches request?
 Prevent simultaneous reconnects that can corrupt tcon->rlist list 
		
		  IPC has the same lifetime as its session and uses its
		  refcount.
	
	  Get the reference to server struct to be sure that the last call of
	  cifs_put_tcon() in the loop below won't release the server pointer.
 now we can safely release srv struct 
 No need to send echo on newly established connections 
 request 
  To form a chain of read requests, any read requests after the first should
  have the end_of_chain boolean set to true.
 reserved 
 reserved 
 reserved 
 xid ,
	
	  If we want to do a RDMA write, fill in and append
	  smbd_buffer_descriptor_v1 to the end of read request
 next 8-byte aligned request 
 END_OF_CHAIN 
			
			  Related requests use info from previous read request
			  in chain.
 result already set, check signature 
 FIXME: should this be counted toward the initiating task? 
 reset bytes number since we can not check a sign 
 FIXME: should this be counted toward the initiating task? 
	
	  If this rdata has a memmory registered, the MR can be freed
	  MR needs to be freed as soon as IO finishes to prevent deadlock
	  because they have limited number and are used for future IOs
 xid ,
 xid ,
 smb2_async_readv - send an async read, and set up mid to handle result 
 xid , io_parms.persistent_fid,
  Check the mid_state and signature on received buffer (if any), and queue the
  workqueue completion task.
		
		  Mask off high 16 bits when bytes written as returned
		  by the server is greater than bytes requested by the
		  client. OS2 servers are known to set incorrect
		  CountHigh values.
	
	  If this wdata has a memory registered, the MR can be freed
	  The number of MRs available is limited, it's important to recover
	  used MR as soon as IO is finished. Hold MR longer in the later
	  IO process can possibly result in IO deadlock due to lack of MR
	  to send request on IO retry
 no xid ,
 no xid ,
 smb2_async_writev - send an async write, and set up mid to handle result 
 xid , wdata->cfile->fid.persistent_fid,
	
	  If we want to do a server RDMA read, fill in and append
	  smbd_buffer_descriptor_v1 to the end of write request
 For RDMA read, IO size is in RemainingBytes not in Length 
 no xid ,
  SMB2_write function gets iov pointer to kvec array with n_vec as a length.
  The length field from io_parms must be at least 1 and indicates a number of
  elements with data to write that begins with position 1 in iov array. All
  data length is specified by count.
 1 for Buffer 
 if no end bound given, assume payload to be correct 
 last element will have a 0 offset, pick a sensible bound 
 check base buf 
 check owner sid 
 check group sid 
 check name len 
 check name 
  ReaddirFindFirst
	
	  BB could be 30 bytes or so longer if we used SMB2 specific
	  buffer lengths, but this is safe and close enough.
 1 for Buffer 
 request 
 note that posix payload are variable size 
 1 for Buffer 
 request 
 1 for pad 
 SPDX-License-Identifier: GPL-2.0
  Netlink routines for CIFS
  Copyright (c) 2020 Samuel Cabrero <scabrero@suse.de>
  cifs_genl_init - Register generic netlink family
  Return zero if initialized successfully, otherwise non-zero.
  cifs_genl_exit - Unregister generic netlink family
 SPDX-License-Identifier: GPL-2.0-or-later
 SPDX-License-Identifier: LGPL-2.1
    SPNEGO upcall management for CIFS
    Copyright (c) 2007 Red Hat, Inc.
    Author(s): Jeff Layton (jlayton@redhat.com)
 create a new cifs key 
 attach the data 
  keytype for CIFS spnego keys
 length of longest version string e.g.  strlen("ver=0xFF") 
 length of longest security mechanism name, eg in future could have
 strlen of "host=" 
 strlen of ";ip4=" or ";ip6=" 
 strlen of ";uid=0x" 
 strlen of ";creduid=0x" 
 strlen of ";user=" 
 strlen of ";pid=0x" 
 get a key struct with a SPNEGO security blob, suitable for session setup 
	 length of fields (with semicolons): ver=0xyz ip4=ipaddress
 start with version and hostname portion of UNC string 
 add the server address 
 for now, only sec=krb5 and sec=mskrb5 are valid 
 CONFIG_CIFS_DEBUG2 
	
	  Create an override credential set with special thread keyring for
	  spnego upcalls.
	
	  instruct request_key() to use this special keyring as a cache for
	  the results it looks up
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002, 2011
    Author(s): Steve French (sfrench@us.ibm.com),
               Pavel Shilovsky ((pshilovsky@samba.org) 2012
 default timeout is 0, servers pick default (120 seconds) 
 is_fsctl ,
 no return info );
 if open response does not have IndexNumber field - get it 
				
				  let get_inode_info disable server inode
				  numbers
	
	  Accessing maxBuf is racy with cifs_reconnect - need to store value
	  and check it before using.
			
			  flock and OFD lock are associated with an open
			  file description, not the process.
			
			  We can cache brlock requests - simply remove a lock
			  from the file's list.
		
		  We need to save a lock here to let us add it again to the
		  file's list if the unlock range request fails on the server.
				
				  We failed on the unlock range request - add
				  all locks from the tmp list to the head of
				  the file's list.
				
				  The unlock range request succeed - free the
				  tmp list.
	
	  Accessing maxBuf is racy with cifs_reconnect - need to store value
	  and check it for zero before using.
 SPDX-License-Identifier: GPL-2.0-or-later
    Copyright (c) International Business Machines  Corp., 2002,2008
    Author(s): Steve French (sfrench@us.ibm.com)
    Error mapping routines from Samba libsmberrormap.c
    Copyright (C) Andrew Tridgell 2001
 was EPERM 
	{ERRaccountexpired, -EACCES},
	{ERRbadclient, -EACCES},
	{ERRbadLogonTime, -EACCES},
  Convert a string containing text IPv4 or IPv6 address to binary form.
  Returns 0 on failure.
 calculate length by finding first slash or NULL 
  Try to convert a string to an IPv4 address and then attempt to convert
  it to an IPv6 address if that fails. Set the family field if either
  succeeds. If it's an IPv6 address and it has a '%' sign in it, try to
  treat the part following it as a numeric sin6_scope_id.
  Returns 0 on failure.
 IPv4 address 
 attempt to exclude the scope ID from the address part 
 grab the scope ID 
convert a NT status code to a dos classcode
 NT status -> dos error map 
	{ This NT error code was 'sqashed'
	 from NT_STATUS_MORE_PROCESSING_REQUIRED to NT_STATUS_OK
	{ This NT error code was 'sqashed'
	 from NT_STATUS_ACCESS_DENIED to NT_STATUS_TRUSTED_RELATIONSHIP_FAILURE
 mapping changed since shell does lookup on  expects FileNotFound 
	{ This NT error code was 'sqashed'
	 from NT_STATUS_NO_SUCH_USER to NT_STATUS_LOGON_FAILURE
 could map to 2238 
	{ This NT error code was 'sqashed'
	 from NT_STATUS_WRONG_PASSWORD to NT_STATUS_LOGON_FAILURE
	{ This NT error code was 'sqashed'
	 from NT_STATUS_INSUFFICIENT_RESOURCES to
	{ This NT error code was 'sqashed'
	 from NT_STATUS_NO_TRUST_SAM_ACCOUNT to
	{ This NT error code was 'sqashed'
	 from NT_STATUS_DOMAIN_TRUST_INCONSISTENT to NT_STATUS_LOGON_FAILURE
 Print an error message from the status code
 if transport error smb error may not be set 
 BB if NT Status codes - map NT BB 
 old style smb error codes 
		 translate the newer STATUS codes to old style SMB errors
 old style errors 
 DOS class smb error codes - map DOS 
 1 byte field no need to byte reverse 
 else try next error mapping one to see if match 
 server class of error codes 
 else try next error mapping to see if match 
 else ERRHRD class errors or junk  - return EIO 
	 generic corrective action e.g. reconnect SMB session on
 possible ERRBaduid 
 switch can be used to handle different errors 
  calculate the size of the SMB message based on the fixed header
  portion, the number of word parameters and the data portion of the message
 size of the bcc field  + get_bcc(ptr));
 The following are taken from fsntfsutil.c 
  Convert the NT UTC (based 1601-01-01, in hundred nanosecond units)
  into Unix UTC (based 1970-01-01, in seconds).
 BB what about the timezone? BB 
 Subtract the NTFS time offset, then convert to 1s intervals. 
	
	  Unfortunately can not use normal 64 bit division on 32 bit arch, but
	  the alternative, do_div, does not work with negative numbers so have
	  to special case them
 Convert the Unix UTC into NT UTC. 
 Convert to 100ns intervals and then add the NTFS time offset. 
 account for difference in days between 1980 and 1970 
 leap year 
	 generalized leap year calculation is more complex, ie no leap year
	for years100 except for years400, but since the maximum number for DOS
	 year is 27, the last year is 1980+127, which means we need only
	 consider 2 special case years, ie the years 2000 and 2100, and only
	 adjust for the lack of leap year for the year 2100, as 2000 was a
 the year 2100 
 do not count leap year for the year 2100 
 adjust for leap year where we are still before leap day 
 cifs_dbg(FYI, "sec after cnvrt dos to unix time %d\n",sec); 
 SPDX-License-Identifier: GPL-2.0-or-later
    Contains the CIFS DFS referral mounting routines used for handling
    traversal via DFS junction point
    Copyright (c) 2007 Igor Mammedov
    Copyright (C) International Business Machines  Corp., 2008
    Author(s): Igor Mammedov (niallain@gmail.com)
 		Steve French (sfrench@us.ibm.com)
  cifs_build_devname - build a devicename from a UNC and optional prepath
  @nodename:	pointer to UNC string
  @prepath:	pointer to prefixpath (or NULL if there isn't one)
  Build a new cifs devicename after chasing a DFS referral. Allocate a buffer
  big enough to hold the final thing. Copy the UNC from the nodename, and
  concatenate the prepath onto the end of it if there is one.
  Returns pointer to the built string, or a ERR_PTR. Caller is responsible
  for freeing the returned string.
 skip over any preceding delimiters 
 get length of UNC and set pos to last char 
 trim off any trailing delimiters 
	 allocate a buffer:
	  +2 for preceding ""
	  +1 for delimiter between UNC and prepath
	  +1 for trailing NULL
" 
 copy in the UNC portion from referral 
 copy the prefixpath remainder (if there is one) 
 NULL terminator 
  cifs_compose_mount_options	-	creates mount options for referral
  @sb_mountdata:	parentroot DFS mount options (template)
  @fullpath:		full path in UNC format
  @ref:		optional server's referral
  @devname:		return the built cifs device name if passed pointer not NULL
  creates mount options for submount based on template options sb_mountdata
  and replacing unc,ip,prefixpath options with ones we've got form ref_unc.
  Returns: pointer to new mount options or ERR_PTR.
  Caller is responsible for freeing returned value if it is not error.
 skip initial delimiter 
	
	  In most cases, we'll be building a shorter string than the original,
	  but we do have to assume that the address in the ip= option may be
	  much longer than the original. Add the max length of an address
	  string to the length of the original string to allow for worst case.
 copy all options except of unc,ip,prefixpath 
 copy new IP and ref share name 
cifs_dbg(FYI, "%s: parent mountdata: %s\n", __func__, sb_mountdata);
cifs_dbg(FYI, "%s: submount mountdata: %s\n", __func__, mountdata );
  cifs_dfs_do_mount - mounts specified path using DFS full path
  Always pass down @fullpath to smb3_do_mount() so we can use the root server
  to perform failover in case we failed to connect to the first target in the
  referral.
  @mntpt:		directory entry for the path we are trying to automount
  @cifs_sb:		parentroot superblock
  @fullpath:		full path in UNC format
 TODO: change to call fs_context_for_mount(), fill in context directly, call fc_mount 
 See afs_mntpt_do_automount in fsafsmntpt.c for an example 
 strip first '\' from fullpath 
  Create a vfsmount that we can automount
	
	  The MSDFS spec states that paths in DFS referral requests and
	  responses must be prefixed by a single '\' character instead of
	  the double backslashes usually used in the UNC. This function
	  gives us the latter, so we must adjust the result.
 always use tree name prefix 
  Attempt to automount the referral
 prevent immediate expiration 
 SPDX-License-Identifier: LGPL-2.1
    Directory search handling
    Copyright (C) International Business Machines  Corp., 2004, 2008
    Copyright (C) Red Hat, Inc., 2011
    Author(s): Steve French (sfrench@us.ibm.com)
  To be safe - for UCS to UTF-8 with strings loaded with the rare long
  characters alloc more to account for such multibyte target UTF-8
  characters.
 DEBUG2 
  Attempt to preload the dcache with the results from the FIND_FIRSTNEXT
  Find the dentry that matches "name". If there isn't one, create one. If it's
  a negative dentry or the uniqueid or filetype(mode) changed,
  then drop it and recreate it.
		
		  If we know that the inode will need to be revalidated
		  immediately, then don't create a new dentry for it.
		  We'll end up doing an on the wire call either way and
		  this spares us an invalidation.
			
			  If we're generating inode numbers, then we don't
			  want to clobber the existing one with the one that
			  the readdir code created.
			 update inode in place
	
	  The DFS tags should be only intepreted by server side as per
	  MS-FSCC 2.1.2.1, but let's include them anyway.
	 
	  Besides, if cf_cifstag is unset (0), then we still need it to be
	  revalidated to know exactly what reparse point it is.
	
	  The IO_REPARSE_TAG_LX_ tags originally were used by WSL but they
	  are preferred by the Linux client in some cases since, unlike
	  the NFS reparse tag (or EAs), they don't require an extra query
	  to determine which type of special file they represent.
	  TODO: go through all documented  reparse tags to see if we can
	  reasonably map some of them to directories vs. files vs. symlinks
 TODO: should we mark some other reparse points (like DFSR) as directories? 
	
	  We need to revalidate it further to make a decision about whether it
	  is a symbolic link, DFS referral or a reparse point with a direct
	  access like junctions, deduplicated files, NFS symlinks.
 non-unix readdir doesn't provide nlink 
	
	  We of course don't get ACL info in FIND_FIRSTNEXT results, so
	  mark it for revalidation so that "ls -l" will look right. It might
	  be super-slow, but if we don't do this then the ownership of files
	  may look wrong since the inodes may not have timed out by the time
	  "ls" does a stat() call on them.
			
			  trying to get the type and mode via SFU can be slow,
			  so just call those regular files for now, and mark
			  for reval
 Fill a cifs_fattr struct with info from SMB_FIND_FILE_POSIX_INFO. 
	
	  Since we set the inode type below we need to mask off
	  to avoid strange results if bits set above.
	  XXX: why not make server&client use the type bits?
		
		  mark anything that is not a dir as regular
		  file. special files should have the REPARSE
		  attribute and will be marked as needing revaluation
 See MS-FSCC 2.4.19 FileIdFullDirectoryInformation 
 BB eventually need to add the following helper function to
      resolve NT_STATUS_STOPPED_ON_SYMLINK return code when
int get_symlink_reparse_path(char full_path, struct cifs_sb_info cifs_sb,
			     unsigned int xid)
{
	__u16 fid;
	int len;
	int oplock = 0;
	int rc;
	struct cifs_tcon ptcon = cifs_sb_tcon(cifs_sb);
	char tmpbuffer;
	rc = CIFSSMBOpen(xid, ptcon, full_path, FILE_OPEN, GENERIC_READ,
			OPEN_REPARSE_POINT, &fid, &oplock, NULL,
			cifs_sb->local_nls,
			cifs_remap(cifs_sb);
	if (!rc) {
		tmpbuffer = kmalloc(maxpath);
		rc = CIFSSMBQueryReparseLinkInfo(xid, ptcon, full_path,
				tmpbuffer,
				maxpath -1,
				fid,
				cifs_sb->local_nls);
		if (CIFSSMBClose(xid, ptcon, fid)) {
			cifs_dbg(FYI, "Error closing temporary reparsepoint open\n");
		}
	}
}
 test for Unix extensions 
 but now check for them on the sharemount not on the SMB session 
 if (cap_unix(tcon->ses) { 
 not srvinos - BB fixme add check for backlevel?  {
	 BB add following call to handle readdir on new NTFS symlink errors
	else if STATUS_STOPPED_ON_SYMLINK
		
		  If we don't have enough credits to start reading the
		  directory just try again after short wait.
 return length of unicode string in bytes 
 validate that new_entry is not past end of SMB 
 payload should have already been checked at this point 
 one byte length, no endianess conversion 
 return 0 if no match and 1 for . (current directory) and 2 for .. (parent) 
 check for . 
 check for .. 
 ASCII  {
 Check if directory that we are searching has changed so we can decide
 directory was changed, perhaps due to unlink 
  Find the corresponding entry in the search. Note that the SMB server returns
  search entries for . and .. which complicates logic here if we choose to
  parse for them and we do not assume that they are located in the findfirst
  return buffer. We start counting in the buffer with entry 2 and increment for
  every entry (do not increment for . or .. entry).
 check if index in the buffer 
	
	  If first entry in buf is zero then is first buffer
	  in search response data which means it is likely . and ..
	  will be in this buffer, although some servers do not return
	  . and .. for the root of a drive and for those we need
	  to start two entries earlier.
 close and restart search 
 FindFirstNext set last_entry to NULL on malformed reply 
 FindFirstNext set last_entry to NULL on malformed reply 
 we found the buffer that contains the entry 
 scan and find it 
 go entry by entry figuring out which is first 
 BB fixme - check if we should flag this error 
 skip . and .. since we added them first 
		
		  trying to get the type and mode can be slow,
		  so just call those regular files for now, and mark
		  for reval
	
	  Ensure FindFirst doesn't fail before doing filldir() for '.' and
	  '..'. Otherwise we won't be able to notify VFS in case of failure.
	 1) If search is active,
		is in current search buffer?
		if it before then restart search
	}  else {
		cifsFile->invalidHandle = true;
		tcon->ses->server->close(xid, tcon, &cifsFile->fid);
 evaluate whether this case is an error 
		
		  if buggy server returns . and .. late do we want to
		  check for that here?
 SPDX-License-Identifier: GPL-2.0-only
   SMB1 (CIFS) version specific operations
   Copyright (c) 2012, Jeff Layton <jlayton@redhat.com>
  An NT cancel request header looks just like the original request except:
  The Command is SMB_COM_NT_CANCEL
  The WordCount is zeroed out
  The ByteCount is zeroed out
  This function mangles an existing request buffer into a
  SMB_COM_NT_CANCEL request and then sends it.
 -4 for RFC1001 length and +2 for BCC field 
	
	  The response to this call was already factored into the sequence
	  number when the call went out, so we must adjust it back downward
	  after signing here.
 It's a bug reading remaining data for SMB1 packets 
  Find a free multiplex id (SMB mid). Otherwise there could be
  mid collisions which might cause problems, demultiplexing the
  wrong response to this request. Multiplex ids could collide if
  one of a series requests takes much longer than the others, or
  if a very large number of long lived requests (byte range
  locks or FindNotify requests) are pending. No more than
  64K-1 requests can be outstanding at one time. If no
  mids are available, return zero. A future optimization
  could make the combination of mids and uid the key we use
  to demultiplex on (rather than mid alone).
  In addition to the above check, the cifs demultiplex
  code already used the command code as a secondary
  check of the frame and if signing is negotiated the
  response would be discarded if the mid were the same
  but the signature was wrong. Since the mid is not put in the
  pending queue until later (when it is about to be dispatched)
  we do have to limit the number of outstanding requests
  to somewhat less than 64K-1 although it is hard to imagine
  so many threads being in the vfs at one time.
 mid is 16 bit only for CIFSSMB 
 we do not want to loop forever 
 avoid 0xFFFF MID 
	
	  This nested loop looks more expensive than it is.
	  In practice the list of pending requests is short,
	  fewer than 50, and the mids are likely to be unique
	  on the first pass through the loop unless some request
	  takes longer than the 64 thousand requests before it
	  (and it would also have to have been a request that
	  did not time out).
 This mid is in use, try a different one 
		
		  if we have more than 32k mids in the list, then something
		  is very wrong. Possibly a local user is trying to DoS the
		  box by issuing long-running calls and SIGKILL'ing them. If
		  we get to 2^16 mids then we're in big trouble as this
		  function could loop forever.
		 
		  Go ahead and assign out the mid in this situation, but force
		  an eventual reconnect to clean out the pending_mid_q.
	return codes:
		0	not a transact2, or all data present
		>0	transact2 with that much data missing
		-EINVAL	invalid transact2
 check for plausible wct, bcc and t2 data and parm sizes 
 check for parm and data offset going beyond end of smb 
 coalesce_t2 depends on this 
 nothing to do, ignore 
 find end of first SMB data area 
 validate target area 
 is the result too big for the field? 
 fix up the BCC 
 is the result too big for the field? 
 don't allow buffer to overflow 
 copy second buffer into end of first buffer 
 more responses to go 
 we are done 
 merge response - fix up 1st
 All parts received or packet is malformed. 
FIXME: switch to already allocated largebuf?
 Have first buffer 
 retry only once on 1st time connection 
 start with specified wsize, or default 
 can server support 24-bit write sizes? (via UNIX extensions) 
	
	  no CAP_LARGE_WRITE_X or is signing enabled without CAP_UNIX set?
	  Limit it to max buffer offered by the server, minus the size of the
	  WRITEX header, not including the 4 byte RFC1001 length.
 hard limit of CIFS_MAX_WSIZE 
	
	  Set default value...
	 
	  HACK alert! Ancient servers have very small buffers. Even though
	  MS-CIFS indicates that servers are only limited by the client's
	  bufsize for reads, testing against win98se shows that it throws
	  INVALID_PARAMETER errors if you try to request too large a read.
	  OS2 just sends back short reads.
	 
	  If the server doesn't advertise CAP_LARGE_READ_X, then assume that
	  it can't handle a read request larger than its MaxBufferSize either.
	
	  no CAP_LARGE_READ_X? Then MS-CIFS states that we must limit this to
	  the client's MaxBufferSize.
 hard limit of CIFS_MAX_RSIZE 
 not legacy , cifs_sb->local_nls,
 could do find first instead but this returns more info 
 not legacy ,
	
	  BB optimize code so we do not make the above call when server claims
	  no NT SMB support and the above call failed at least once - set flag
	  in tcon or mount.
 Need to check if this is a symbolic link or not 
	
	  We can not use the IndexNumber field by default from Windows or
	  Samba (in ALL_INFO buf) but we can request it explicitly. The SNIA
	  CIFS spec claims that this value is unique within the scope of a
	  share, and the windows docs hint that it's actually unique
	  per-machine.
	 
	  There may be higher info levels that work but are there Windows
	  server or network appliances for which IndexNumber field is not
	  guaranteed unique?
 if the file is already open for write, just use that fileid 
	
	  We could add a second check for a QFS Unix capability bit
	
	  Only need to call the old QFSInfo if failed on newer one,
	  e.g. by OS2.
	
	  Some old Windows servers also do not support level 103, retry with
	  older level one if old server failed the previous call or we
	  bypassed it because we detected that this was an older LANMAN sess
 No DFS support 
 Check for unix extensions 
		
		  SMB1 Unix Extensions: requires server support but
		  works with all special files
 no change 
 no change 
	
	  SMB1 SFU emulation: should work with all servers, but only
	  support block and char device (no socket & fifo)
	
	  BB Do not bother to decode buf since no local inode yet to put
	  timestamps in, but we can reuse it safely.
 FIXME: add code here to set EAs 
 CIFS_XATTR 
 SPDX-License-Identifier: LGPL-2.1
    Copyright (C) International Business Machines  Corp., 2002,2008
    Author(s): Steve French (sfrench@us.ibm.com)
  M-F Symlink Functions - Begin
 it's not a symlink 
 it's not a symlink 
 not a symlink 
 it's not a symlink 
 not a symlink 
 it's not a symlink 
 it is a symlink 
  SMB 1.0 Protocol specific functions
 it's not a symlink 
  SMB 2.1SMB3 Protocol specific functions
 it's not a symlink 
 Is there a better rc to return? 
 iov[0] is reserved for smb header 
 Make sure we wrote all of the symlink data 
  M-F Symlink Functions - End
 force new lookup from server of target 
	
	  if source file is cached (oplocked) revalidate will not go to server
	  until the file is closed or oplock broken so update nlinks locally
			
			  parent dir timestamps will update from srv within a
			  second, would it really be worth it to set the parent
			  dir cifs inode time to zero to force revalidate
			  (faster) for it too?
		
		  if not oplocked will force revalidate to get info on source
		  file from srv.  Note Samba server prior to 4.2 has bug -
		  not updating src file ctime on hardlinks but Windows servers
		  handle it properly
		
		  Will update parent dir timestamps from srv within a second.
		  Would it really be worth it to set the parent dir (cifs
		  inode) time field to zero to force revalidate on parent
		  directory faster ie
		 
		  CIFS_I(inode)->time = 0;
	
	  First try Minshall+French Symlinks, if configured
	  and fallback to UNIX Extensions Symlinks.
 BB what if DFS and this volume is on different share? BB 
	 else
	   rc = CIFSCreateReparseSymLink(xid, pTcon, fromName, toName,
 SPDX-License-Identifier: GPL-2.0-or-later
    Copyright (C) 2017, Microsoft Corporation.
    Author(s): Long Li <longli@microsoft.com>
 SMBD version number 
 Port numbers for SMBD transport 
 Address lookup and resolve timeout in ms 
 SMBD negotiation timeout in seconds 
 SMBD minimum receive size and fragmented sized defined in [MS-SMBD] 
  Default maximum number of RDMA readwrite outstanding on this connection
  This value is possibly decreased during QP creation on hardware limit
 Maximum number of retries on data transfer operations 
 No need to retry on Receiver Not Ready since SMBD manages credits 
  User configurable initial values per SMBD transport connection
  as defined in [MS-SMBD] 3.1.1.1
  Those may change after a SMBD negotiation
 The local peer's maximum number of credits to grant to the peer 
 The remote peer's credit request of local peer 
 The maximum single message size can be sent to remote peer 
  The maximum fragmented upper-layer payload receive size supported 
  The maximum single-message size which can be received 
 The timeout to initiate send of a keepalive message on idle 
  User configurable initial values for RDMA transport
  The actual values used may be lower and are limited to hardware capabilities
 Default maximum number of SGEs in a RDMA writeread 
 If payload is less than this byte, use RDMA sendrecv not readwrite 
 Transport logging functions
  Logging are defined as classes. They can be OR'ed to define the actual
  logging level via module parameter smbd_logging_class
  e.g. cifs.smbd_logging_class=0xa0 will log all log_rdma_recv() and
  log_rdma_event()
 Upcall from RDMA CM 
 This happenes when we fail the negotiation 
 Upcall from RDMA QP 
 Called when a RDMA send is done 
  Process a negotiation response message, according to [MS-SMBD]3.1.5.7
  response, packet_length: the negotiation response message
  return value: true if negotiation is a success, false if failed
 now switch to emtpy packet queue 
 Promptly send an immediate packet as defined in [MS-SMBD] 3.1.1.1 
 Called from softirq, when recv is done 
 SMBD negotiation response 
 SMBD data transfer packet 
		
		  If this is a packet with data playload place the data in
		  reassembly queue and wake up the reading thread
			
			  We have new send credits granted from remote peer
			  If any sender is waiting for credits, unblock it
 Send a KEEP_ALIVE response right away if requested 
 e.g. if interrupted returns -ERESTARTSYS 
 e.g. if interrupted returns -ERESTARTSYS 
  Test if FRWR (Fast Registration Work Requests) is supported on the device
  This implementation requries FRWR on RDMA readwrite
  return value: true if it is supported
  Send a negotiation request message to the peer
  The negotiation procedure is in [MS-SMBD] 3.1.5.2 and 3.1.5.3
  After negotiation, the transport is connected and ready for
  carrying upper layer SMB payload
 if we reach here, post send failed 
  Extend the credits to remote peer
  This implements [MS-SMBD] 3.1.5.9
  The idea is that we should extend credits to remote peer as quickly as
  it's allowed, to maintain data flow. We allocate as much receive
  buffer as possible, and extend the receive credits to remote peer
  return value: the new credtis being granted.
  Check if we need to send a KEEP_ALIVE message
  The idle connection timer triggers a KEEP_ALIVE message when expires
  SMB_DIRECT_RESPONSE_REQUESTED is set in the message flag to have peer send
  back a response.
  return value:
  1 if SMB_DIRECT_RESPONSE_REQUESTED needs to be set
  0: otherwise
 Post the send request 
 Reset timer for idle connection after packet is sent 
 Wait for send credits. A SMBD packet needs one credit 
 Fill in the packet header 
 Map the packet to DMA 
 If this is a packet without payload, don't send padding 
 Fill in the packet data payload 
 roll back receive credits and credits to be offered 
 roll back send credits and pending 
  Send a page
  page: the page to send
  offset: offset in the page to send
  size: length in the page to send
  remaining_data_length: remaining data to send in this payload
  Send an empty message
  Empty message is used to extend credits to peer to for keep live
  while there is no upper layer payload to send at the time
  Send a data buffer
  iov: the iov array describing the data buffers
  n_vec: number of iov array
  remaining_data_length: remaining data to send following this packet
  in segmented SMBD packet
  Post a receive request to the transport
  The remote peer can only send data when a receive request is posted
  The interaction is controlled by sendreceive credit system
 Perform SMBD negotiate according to [MS-SMBD] 3.1.5.2 
  Implement Connection.FragmentReassemblyBuffer defined in [MS-SMBD] 3.1.1.1
  This is a queue for reassembling upper layer payload and present to upper
  layer. All the inncoming payload go to the reassembly queue, regardless of
  if reassembly is required. The uuper layer code reads from the queue for all
  incoming payloads.
  Put a received packet to the reassembly queue
  response: the packet received
  data_length: the size of payload in this packet
	
	  Make sure reassembly_data_length is updated after list and
	  reassembly_queue_length are updated. On the dequeue side
	  reassembly_data_length is checked without a lock to determine
	  if reassembly_queue_length and list is up to date
  Get the first entry at the front of reassembly queue
  Caller is responsible for locking
  return value: the first entry if any, NULL if queue is empty
  Get a receive buffer
  For each remote send, we need to post a receive. The receive buffers are
  pre-allocated in advance.
  return value: the receive buffer, NULL if none is available
  Return a receive buffer
  Upon returning of a receive buffer, we can post new receive and extend
  more receive credits to remote peer. This is done immediately after a
  receive buffer is returned.
 Preallocate all receive buffer on transport establishment 
 Implement idle connection timer [MS-SMBD] 3.1.6.2 
 Setup the next idle timeout work 
  Destroy the transport and related RDMA and memory resources
  Need to go through all the pending counters and make sure on one is using
  the transport while it is destroyed
 It's not posssible for upper layer to get to reassembly 
	
	  For performance reasons, memory registration and deregistration
	  are not locked by srv_mutex. It is possible some processes are
	  blocked on transport srv_mutex while holding memory registration.
	  Release the transport srv_mutex to allow them to hit the failure
	  path when sending data, and then release memory registartions.
 free mempools 
  Reconnect this SMBD connection, called from upper layer
  return value: 0 on success, or actual error code
	
	  This is possible if transport is disconnected and we haven't received
	  notification from RDMA, but upper layer has detected timeout
 Create a SMBD connection, called by upper layer 
 Need to send IRDORD in private data for iWARP 
 At this point, need to a full transport shutdown 
 Try SMB_PORT if SMBD_PORT doesn't work 
  Receive data from receive reassembly queue
  All the incoming data packets are placed in reassembly queue
  buf: the buffer to read data into
  size: the length of data to read
  return value: actual data read
  Note: this implementation copies the data from reassebmly queue to receive
  buffers used by upper layer. This is not the optimal code path. A better way
  to do it is to not have upper layer allocate its receive buffers but rather
  borrow the buffer from reassembly queue, and return it after data is
  consumed. But this will require more changes to upper layer code, and also
  need to consider packet boundaries while they still being reassembled.
	
	  No need to hold the reassembly queue lock all the time as we are
	  the only one reading from the front of the queue. The transport
	  may add more entries to the back of the queue at the same time
		
		  Need to make sure reassembly_data_length is read before
		  reading reassembly_queue_length and calling
		  _get_first_reassembly. This call is lock free
		  as we never read at the end of the queue which are being
		  updated in SOFTIRQ as more data is received
			
			  The upper layer expects RFC1002 length at the
			  beginning of the payload. Return it to indicate
			  the total length of the packet. This minimize the
			  change to upper layer packet processing logic. This
			  will be eventually remove when an intermediate
			  transport layer is added
 move on to the next buffer? 
				
				  No need to lock if we are not at the
				  end of the queue
 Don't return any data if interrupted 
  Receive a page from receive reassembly queue
  page: the page to read data into
  to_read: the length of data to read
  return value: actual data read
 make sure we have the page ready for read 
 now we can read from reassembly queue and not sleep 
  Receive data from transport
  msg: a msghdr point to the buffer, can be ITER_KVEC or ITER_BVEC
  return: total bytes read, or 0. SMB Direct will not do partial read.
 It's a bug in upper layer to get there 
 It's a bug in upper layer to get there 
 SMBDirect will read it all or nothing 
  Send data to transport
  Each rqst is transported as a SMBDirect payload
  rqst: the data to write
  return value: 0 if successfully write, otherwise error code
	
	  Add in the page array if there is one. The caller needs to set
	  rq_tailsz to PAGE_SIZE when the buffer has multiple pages and
	  ends at page boundary
 iov[start] is too big, break it 
 send out all remaining vecs 
 now sending pages if there are any 
	
	  As an optimization, we don't wait for individual IO to finish
	  before sending the next one.
	  Send them all and wait for pending send count to get to 0
	  that means all the IOs have been out and we are good to return
  The work queue function that recovers MRs
  We need to call ib_dereg_mr() and ib_alloc_mr() before this MR can be used
  again. Both calls are slow, so finish them in a workqueue. This will not
  block IO path.
  There is one workqueue that recovers MRs, there is no need to lock as the
  IO requests calling smbd_register_mr will never update the links in the
  mr_list.
 recover this MR entry 
 This MR is being used, don't recover it 
		 smbdirect_mr->state is updated by this function
		  and is read and updated by IO issuing CPUs trying
		  to get a MR, the call to atomic_inc_return
		  implicates a memory barrier and guarantees this
		  value is updated before waking up any calls to
		  get_mr() from the IO issuing CPUs
  Allocate MRs used for RDMA readwrite
  The number of MRs will not exceed hardware capability in responder_resources
  All MRs are kept in mr_list. The MR can be recovered after it's used
  Recovery is done in smbd_mr_recovery_work. The content of list entry changes
  as MRs are used and recovered for IO, but the list links will not change
 Allocate more MRs (2x) than hardware responder_resources 
  Get a MR from mr_list. This function waits until there is at least one
  MR available in the list. It may access the list while the
  smbd_mr_recovery_work is recovering the MR list. This doesn't need a lock
  as they never modify the same places. However, there may be several CPUs
  issueing IO trying to get MR at the same time, mr_list_lock is used to
  protect this situation.
	
	  It is possible that we could fail to get MR because other processes may
	  try to acquire a MR at the same time. If this is the case, retry it.
  Register memory for RDMA readwrite
  pages[]: the list of pages to register memory with
  num_pages: the number of pages to register
  tailsz: if non-zero, the bytes to register in the last page
  writing: true if this is a RDMA write (SMB read), false for RDMA read
  need_invalidate: true if this MR needs to be locally invalidated after IO
  return value: the MR registered, NULL if failed.
 We have at least two pages to register 
	
	  There is no need for waiting for complemtion on ib_post_send
	  on IB_WR_REG_MR. Hardware enforces a barrier and order of execution
	  on the next ib_post_send when we actaully send IO to remote peer
 If all failed, attempt to recover this MR by setting it MR_ERROR
  Deregister a MR after IO is done
  This function may wait if remote invalidation is not used
  and we have to locally invalidate the buffer to prevent data is being
  modified by remote peer after upper layer consumes it
 Need to finish local invalidation before returning 
		
		  For remote invalidation, just set it to MR_INVALIDATED
		  and defer to mr_recovery_work to recover the MR for next use
		
		  Schedule the work to do MR recovery for future IOs MR
		  recovery is slow and don't want it to block current IO
 SPDX-License-Identifier: GPL-2.0
    Copyright (C) 2018, Microsoft Corporation.
    Author(s): Steve French <stfrench@microsoft.com>
 SPDX-License-Identifier: GPL-2.0-or-later
   Unix SMBNetbios implementation.
   Version 1.9.
   SMB parameters and setup
   Copyright (C) Andrew Tridgell 1992-2000
   Copyright (C) Luke Kenneth Casson Leighton 1996-2000
   Modified by Jeremy Allison 1995.
   Copyright (C) Andrew Bartlett <abartlet@samba.org> 2002-2003
   Modified by Steve French (sfrench@us.ibm.com) 2002-2003
 following came from the other byteorder.h to avoid include conflicts 
 produce a md4 message digest from data of length n bytes 
  Creates the MD4 Hash of the users password in NT UNICODE.
 Password cannot be longer than 128 characters 
 Password must be converted to NT unicode 
 Ensure string is null terminated 
 SPDX-License-Identifier: GPL-2.0
   linuxfsaffsnamei.c
   (c) 1996  Hans-Joachim Widmaier - Rewritten
   (C) 1993  Ray Burr - Modified for Amiga FFS filesystem.
   (C) 1991  Linus Torvalds - minix filesystem
 Simple toupper() for DOS\1 
 International toupper() for DOS\3 ("international") 
  Note: the dentry argument is the parent dentry.
	
	  'str' is the name of an already existing dentry, so the name
	  must be valid. 'name' must be validated first.
	
	  If the names are longer than the allowed 30 chars,
	  the excess is ignored, so their length may differ.
  NOTE! unlike strncmp, affs_match returns 1 for success, 0 for failure.
 store the real header ino in d_fsdata for faster lookups 
link to dirs disabled
case ST_LINKDIR:
 Cannot overflow 
 Unlink destination if it already exists 
 Remove header from its parent directory. 
 And insert it into the new directory with the new name. 
 TODO: move it back to old_dir, if error? 
 Remove old header from its parent directory. 
 Remove new header from its parent directory. 
 Insert old into the new directory with the new name. 
 Insert new into the old directory with the old name. 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsaffsinode.c
   (c) 1996  Hans-Joachim Widmaier - Rewritten
   (C) 1993  Ray Burr - Modified for Amiga FFS filesystem.
   (C) 1992  Eric Youngdale Modified for ISO 9660 filesystem.
   (C) 1991  Linus Torvalds - minix filesystem
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 Fill in defaults 
 Silently ignore the quota options 
 This function definitely needs to be split up. Some fine day I'll
  hopefully have the guts to do so. Until then: sorry for the mess.
 fix remount prototype... 
 N.B. after this point s_prefix must be released 
	 Get the size of the device in 512-byte blocks.
	  If we later see that the partition uses bigger
	  blocks, we will have to change it.
 Try to find root block. Its location depends on the block size. 
		 The root block location that was calculated above is not
		  correct if the partition size is an odd number of 512-
		  byte blocks, which will be rounded down to a number of
		  1024-byte blocks, and if there were an even number of
		  reserved blocks. Ideally, all partition checkers should
		  report the real number of blocks of the real blocksize,
		  but since this just cannot be done, we have to try to
		  find the root block anyways. In the above case, it is one
		  block behind the calculated one. So we check this one, too.
 N.B. after this point bh must be released 
 Keep super block in cache 
 Find out which kind of FS we have 
	 Dircache filesystems are compatible with non-dircache ones
	  when reading. As long as they aren't supported, writing is
	  not recommended.
 set up enough so that it can read an inode 
 protect against readers 
 SPDX-License-Identifier: GPL-2.0
   linuxfsaffsinode.c
   (c) 1996  Hans-Joachim Widmaier - Rewritten
   (C) 1993  Ray Burr - Modified for Amiga FFS filesystem.
   (C) 1992  Eric Youngdale Modified for ISO9660 filesystem.
   (C) 1991  Linus Torvalds - minix filesystem
 Maybe it should be controlled by mount parameter? 
inode->i_mode |= S_ISVTX;
 ... and leave ->i_op and ->i_fop pointing to empty 
 possibly free block
  Add an entry to a directory. Create the header block
  and insert it into the hash table.
 SPDX-License-Identifier: GPL-2.0
   linuxfsaffsdir.c
   (c) 1996  Hans-Joachim Widmaier - Rewritten
   (C) 1993  Ray Burr - Modified for Amiga FFS filesystem.
   (C) 1992  Eric Youngdale Modified for ISO 9660 filesystem.
   (C) 1991  Linus Torvalds - minix filesystem
   affs directory handling functions
  directories can handle most operations...
	 If the directory hasn't changed since the last call to readdir(),
	  we can jump directly to where we left off.
 SPDX-License-Identifier: GPL-2.0
   linuxfsaffsamigaffs.c
   (c) 1996  Hans-Joachim Widmaier - Rewritten
   (C) 1993  Ray Burr - Amiga FFS filesystem.
   Please send bug reports to: hjw@zvw.de
  Functions for accessing Amiga-FFS structures.
 Insert a header block bh into the directory dir
  caller must hold AFFS_DIR->i_hash_lock!
 Remove a header block from its directory.
  caller must hold AFFS_DIR->i_hash_lock!
 Remove header from link chain 
		 we can't remove the head of the link, as its blocknr is still used as ino,
		  so we remove the block of the first link instead.
		
		  if there's a dentry for that block, make it
		  refer to inode itself.
 Fix the link count, if bh is a normal header block without links 
 Remove a filesystem object. If the object to be removed has
  links to it, one of the links must be changed to inherit
  the file or directory. As above, any inode will do.
  The buffer will not be freed. If the header is a link, the
  block will be marked as free.
  This function returns a negative error number in case of
  an error, else 0 if the inode is to be deleted or 1 if not.
		 if we ever want to support links to dirs
		  i_hash_lock of the inode must only be
		  taken after some checks
 Checksum a block, do various consistency checks and optionally return
   the blocks type number.  DATA points to the block.  If their pointers
   are non-null, PTYPE and STYPE are set to the primary and secondary
   block types respectively, HASHSIZE is set to the size of the hashtable
   (which lets us calculate the block size).
  Calculate the checksum of a disk block and store it
  at the indicated position.
	
	  First, clear all RWED bits for owner, group, other.
	  Then, recalculate them afresh.
	 
	  We'll always clear the delete-inhibit bit for the owner, as that is
	  the classic single-user mode AmigaOS protection bit and we need to
	  stay compatible with all scenarios.
	 
	  Since multi-user AmigaOS is an extension, we'll only set the
	  delete-allow bit if any of the other bits in the same user class
	  (groupother) are used.
 Classic single-user AmigaOS flags. These are inverted. 
 Multi-user extended flags. Not inverted. 
 Check if the name is valid for a affs object. 
 This function copies name to bstr, with at most 30
  characters length. The bstr will be prepended by
  a length byte.
  NOTE: The name will must be already checked by
        affs_check_name()!
 SPDX-License-Identifier: GPL-2.0
   linuxfsaffsfile.c
   (c) 1996  Hans-Joachim Widmaier - Rewritten
   (C) 1993  Ray Burr - Modified for Amiga FFS filesystem.
   (C) 1992  Eric Youngdale Modified for ISO 9660 filesystem.
   (C) 1991  Linus Torvalds - minix filesystem
   affs regular file handling primitives
 need to recalculate linear cache, start from old size 
 fix idx and old size to new shift 
 first shrink old cache to make more space 
 fill cache to the needed index 
 unlock cache
 lock cache
 lock cache
 inline the simplest case: same extended block as last time 
 we have to do more (not inlined) 
 read the next extended block from the current one 
 we seek back to the file header block 
 allocate a new extended block 
 get previous extended block 
 check if there is an extended cache and whether it's large enough 
 every n'th key we find in the linear cache 
 maybe it's still in the associative cache 
 try to find one of the previous extended blocks 
 fall back to the linear cache 
 read all extended blocks until we find the one we need 
unlock cache
lock cache
 store it in the associative cache 
 recalculate ac_idx?
 finally read the right extended block 
unlock cache
lock cache
 release old cached extended block and store the new one 
lock cache
 store new block 
 insert first block into header block 
unlock cache
 unlock cache
 unlock cache
 Clear Archived bit on file writes, as AmigaOS would do 
		 XXX: this probably leaves a too-big i_size in case of
		  failure. Should really be updating i_size at write_end time
 XXX: inefficient but safe in the face of short writes 
	
	  XXX: not sure if this can handle short copies (len < copied), but
	  we don't have to, because the page should always be uptodate here,
	  due to write_begin.
 Clear Archived bit on file writes, as AmigaOS would do 
.writepage = affs_writepage_ofs,
 Free any preallocated blocks. 
 Truncate (or enlarge) a file to the requested size. 
 lock cache
 clear linear cache 
 clear associative cache 
 unlock cache
 SPDX-License-Identifier: GPL-2.0
   linuxfsaffssymlink.c
   1995  Hans-Joachim Widmaier - Modified for affs.
   Copyright (C) 1991, 1992  Linus Torvalds
   affs symlink handling code
 Handle assign or volume name 
 parent dir 
 SPDX-License-Identifier: GPL-2.0
   linuxfsaffsbitmap.c
   (c) 1996 Hans-Joachim Widmaier
   bitmap.c contains the code that handles all bitmap related stuff -
   block allocation, deallocation, calculation of free space.
 mark block free 
 fix checksum 
  Allocate a block in the given allocation zone.
  Since we have to byte-swap the bitmap on little-endian
  machines, this is rather expensive. Therefore we will
  preallocate up to 16 blocks from the same word, if
  possible. We are not doing preallocations in the
  header zone, though.
if (!AFFS_I(inode)->i_last_block)
	affs_warning(sb, "affs_balloc", "no last alloc block");
 search for the next bmap buffer with free bits 
 restart search at zero 
 find an unused block in this bitmap block 
 scan the rest of the buffer 
			 didn't find something, can only happen
			  if scan didn't start at 0, try next bmap
 finally look for a free bit in the word 
 prealloc as much as possible within this word 
 fix checksum 
		 Don't try read the extension if this is the last block,
		  but we also need the right bm pointer below
 Mark unused bits in the last word as allocated 
if (old != new) {
 fix checksum 
new -= old;
old = be32_to_cpu((__be32 )bh->b_data);
			(__be32 )bh->b_data = cpu_to_be32(old - new);
			mark_buffer_dirty(bh);
		}
		 correct offset for the bitmap count below 
		offset++;
	}
	while (++offset < sb->s_blocksize  4)
		((__be32 )bh->b_data)[offset] = 0;
	((__be32 )bh->b_data)[0] = 0;
	((__be32 )bh->b_data)[0] = cpu_to_be32(-affs_checksum_block(sb, bh));
	mark_buffer_dirty(bh);
	 recalculate bitmap count for last block 
	bm--;
	bm->bm_free = memweight(bh->b_data + 4, sb->s_blocksize - 4);
out:
	affs_brelse(bh);
	affs_brelse(bmap_bh);
	return res;
}
void affs_free_bitmap(struct super_block sb)
{
	struct affs_sb_info sbi = AFFS_SB(sb);
	if (!sbi->s_bitmap)
		return;
	affs_brelse(sbi->s_bmap_bh);
	sbi->s_bmap_bh = NULL;
	sbi->s_last_bmap = ~0;
	kfree(sbi->s_bitmap);
	sbi->s_bitmap = NULL;
}
 SPDX-License-Identifier: GPL-2.0-or-later
 Network filesystem high-level read support.
  Copyright (C) 2021 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  Allocate and partially initialise an IO request structure.
  Clear the unread part of an IO request.
  Issue a read against the cache.
  - Eats the caller's ref on subreq.
  Fill a subrequest region with zeroes.
  Ask the netfs to issue a read request to the server for us.
  The netfs is expected to read from subreq->pos + subreq->transferred to
  subreq->pos + subreq->len - 1.  It may not backtrack and write data into the
  buffer prior to the transferred point as it might clobber dirty data
  obtained from the cache.
  Alternatively, the netfs is allowed to indicate one of two things:
  - NETFS_SREQ_SHORT_READ: A short read - it will get called again to try and
    make progress.
  - NETFS_SREQ_CLEAR_TAIL: A short read - the rest of the buffer will be
    cleared.
  Release those waiting.
  Deal with the completion of writing the data to the cache.  We have to clear
  the PG_fscache bits on the folios involved and release the caller's ref.
  May be called in softirq mode and we inherit a ref from the caller.
			 We might have multiple writes from the same huge
			  folio, but we mustn't unlock a folio more than once.
 If we decrement nr_wr_ops to 0, the ref belongs to us. 
  Perform any outstanding writes to the cache.  We inherit a ref from the
  caller.
	 We don't want terminating writes trying to wake us up whilst we're
	  still going through the list.
 Amalgamate adjacent writes 
 If we decrement nr_wr_ops to 0, the usage ref belongs to us. 
  Unlock the folios in a read operation.  We need to set PG_fscache on any
  folios we're going to write back before we unlock them.
	 Walk through the pagecache and the IO request lists simultaneously.
	  We may have a mixture of cached and uncached sections and we only
	  really want to write out the uncached sections.  This is slightly
	  complicated by the possibility that we might have huge pages with a
	  mixture inside.
  Handle a short read.
  Resubmit any short or failed operations.  Returns true if we got the rreq
  ref back.
	 We don't want terminating submissions trying to wake us up whilst
	  we're still going through the list.
 If we decrement nr_rd_ops to 0, the usage ref belongs to us. 
  Check to see if the data read is still valid.
  Assess the state of a read request and decide what to do next.
  Note that we could be in an ordinary kernel thread, on a workqueue or in
  softirq context at this point.  We inherit a ref from the caller.
  Handle the completion of all outstanding IO operations on a read request.
  We inherit a ref from the caller.
  netfs_subreq_terminated - Note the termination of an IO operation.
  @subreq: The IO request that has terminated.
  @transferred_or_error: The amount of data transferred or an error code.
  @was_async: The termination was asynchronous
  This tells the read helper that a contributory IO operation has terminated,
  one way or another, and that it should integrate the results.
  The caller indicates in @transferred_or_error the outcome of the operation,
  supplying a positive value to indicate the number of bytes transferred, 0 to
  indicate a failure to transfer anything that should be retried or a negative
  error code.  The helper will look after reissuing IO operations as
  appropriate and writing downloaded data to the cache.
  If @was_async is true, the caller might be running in softirq or interrupt
  context and we can't sleep.
 If we decrement nr_rd_ops to 0, the ref belongs to us. 
  Work out what sort of subrequest the next one will be.
		 Call out to the netfs to let it shrink the request to fit
		  its own IO sizes and boundaries.  If it shinks it here, it
		  will be called again to make simultaneous calls; if it wants
		  to make serial calls, it can indicate a short read and then
		  we will call it again.
  Slice off a piece of a read request and submit an IO request for it.
	 Call out to the cache to find out what it can do with the remaining
	  subset.  It tells us in subreq->flags what it decided should be done
	  and adjusts subreq->len down if the subset crosses a cache boundary.
	 
	  Then when we hand the subset, it can choose to take a subset of that
	  (the starts must coincide), in which case, we go around the loop
	  again and ask it to download the next piece.
	 Give the cache a chance to change the request parameters.  The
	  resultant request must contain the original region.
	 Give the netfs a chance to change the request parameters.  The
	  resultant request must contain the original region.
	 Expand the request if the cache wants it to start earlier.  Note
	  that the expansion may get further extended if the VM wishes to
	  insert THPs and the preferred start andor end wind up in the middle
	  of THPs.
	 
	  If this is the case, however, the THP size should be an integer
	  multiple of the cache granule size, so we get a whole number of
	  granules to deal with.
  netfs_readahead - Helper to manage a read request
  @ractl: The description of the readahead request
  @ops: The network filesystem's operations for the helper to use
  @netfs_priv: Private netfs data to be retained in the request
  Fulfil a readahead request by drawing data from the cache if possible, or
  the netfs if not.  Space beyond the EOF is zero-filled.  Multiple IO
  requests from different sources will get munged together.  If necessary, the
  readahead window can be expanded in either direction to a more convenient
  alighment for RPC efficiency or to make storage in the cache feasible.
  The calling netfs must provide a table of operations, only one of which,
  issue_op, is mandatory.  It may also be passed a private token, which will
  be retained in rreq->netfs_priv and will be cleaned up by ops->cleanup().
  This is usable whether or not caching is enabled.
	 Drop the refs on the folios here rather than in the cache or
	  filesystem.  The locks will be dropped in netfs_rreq_unlock().
 If we decrement nr_rd_ops to 0, the ref belongs to us. 
  netfs_readpage - Helper to manage a readpage request
  @file: The file to read from
  @folio: The folio to read
  @ops: The network filesystem's operations for the helper to use
  @netfs_priv: Private netfs data to be retained in the request
  Fulfil a readpage request by drawing data from the cache if possible, or the
  netfs if not.  Space beyond the EOF is zero-filled.  Multiple IO requests
  from different sources will get munged together.
  The calling netfs must provide a table of operations, only one of which,
  issue_op, is mandatory.  It may also be passed a private token, which will
  be retained in rreq->netfs_priv and will be cleaned up by ops->cleanup().
  This is usable whether or not caching is enabled.
	 Keep nr_rd_ops incremented so that the ref always belongs to us, and
	  the service code isn't punted off to a random thread pool to
	  process.
  netfs_skip_folio_read - prep a folio for writing without reading first
  @folio: The folio being prepared
  @pos: starting position for the write
  @len: length of write
  In some cases, write_begin doesn't need to read at all:
  - full folio write
  - write that lies in a folio that is completely beyond EOF
  - write that covers the folio from start to EOF or beyond it
  If any of these criteria are met, then zero out the unwritten parts
  of the folio and return true. Otherwise, return false.
 Full folio write 
 pos beyond last folio in the file 
 Write that covers from the start of the folio to EOF or beyond 
  netfs_write_begin - Helper to prepare for writing
  @file: The file to read from
  @mapping: The mapping to read from
  @pos: File position at which the write will begin
  @len: The length of the write (may extend beyond the end of the folio chosen)
  @aop_flags: AOP_ flags
  @_folio: Where to put the resultant folio
  @_fsdata: Place for the netfs to store a cookie
  @ops: The network filesystem's operations for the helper to use
  @netfs_priv: Private netfs data to be retained in the request
  Pre-read data for a write-begin request by drawing data from the cache if
  possible, or the netfs if not.  Space beyond the EOF is zero-filled.
  Multiple IO requests from different sources will get munged together.  If
  necessary, the readahead window can be expanded in either direction to a
  more convenient alighment for RPC efficiency or to make storage in the cache
  feasible.
  The calling netfs must provide a table of operations, only one of which,
  issue_op, is mandatory.
  The check_write_begin() operation can be provided to check for and flush
  conflicting writes once the folio is grabbed and locked.  It is passed a
  pointer to the fsdata cookie that gets returned to the VM to be passed to
  write_end.  It is permitted to sleep.  It should return 0 if the request
  should go ahead; unlock the folio and return -EAGAIN to cause the folio to
  be regot; or return an error.
  This is usable whether or not caching is enabled.
 Allow the netfs (eg. ceph) to flush conflicts. 
	 If the page is beyond the EOF, we want to clear it - unless it's
	  within the cache granule containing the EOF, in which case we need
	  to preload the granule.
	 Expand the request to meet caching requirements and download
	  preferences.
 We hold the folio locks, so we can drop the references 
	 Keep nr_rd_ops incremented so that the ref always belongs to us, and
	  the service code isn't punted off to a random thread pool to
	  process.
 SPDX-License-Identifier: GPL-2.0-or-later
 Netfs support statistics
  Copyright (C) 2021 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2013 Trond Myklebust <Trond.Myklebust@netapp.com>
 SPDX-License-Identifier: GPL-2.0-or-later
 getroot.c: get the root dentry for an NFS mount
  Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  Set the superblock root dentry.
  Note that this function frees the inode in case of error.
 The mntroot acts as the dummy root dentry for this superblock 
		
		  Ensure that this dentry is invisible to d_find_alias().
		  Otherwise, it may be spliced into the tree by
		  d_splice_alias if a parent directory from the same
		  filesystem gets mounted at a later time.
		  This again causes shrink_dcache_for_umount_subtree() to
		  Oops, since the test for IS_ROOT() will fail.
  get an NFS2NFS3 root dentry from the root filehandle
 get the actual root for this mount 
	 root dentries normally start off anonymous and get spliced in later
	  if the dentry tree reaches them; however if the dentry already
	  exists, we'll pick it up at this point and use it as the root
 clone lsm security options from the parent to the new sb 
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2016 Trond Myklebust
  IO and data path helper functionality.
 Call with exclusively locked inode->i_rwsem 
  nfs_start_io_read - declare the file is being used for buffered reads
  @inode: file inode
  Declare that a buffered read operation is about to start, and ensure
  that we block all direct IO.
  On exit, the function ensures that the NFS_INO_ODIRECT flag is unset,
  and holds a shared lock on inode->i_rwsem to ensure that the flag
  cannot be changed.
  In practice, this means that buffered read operations are allowed to
  execute in parallel, thanks to the shared lock, whereas direct IO
  operations need to wait to grab an exclusive lock in order to set
  NFS_INO_ODIRECT.
  Note that buffered writes and truncates both take a write lock on
  inode->i_rwsem, meaning that those are serialised w.r.t. the reads.
 Be an optimist! 
 Slow path.... 
  nfs_end_io_read - declare that the buffered read operation is done
  @inode: file inode
  Declare that a buffered read operation is done, and release the shared
  lock on inode->i_rwsem.
  nfs_start_io_write - declare the file is being used for buffered writes
  @inode: file inode
  Declare that a buffered read operation is about to start, and ensure
  that we block all direct IO.
  nfs_end_io_write - declare that the buffered write operation is done
  @inode: file inode
  Declare that a buffered write operation is done, and release the
  lock on inode->i_rwsem.
 Call with exclusively locked inode->i_rwsem 
  nfs_start_io_direct - declare the file is being used for direct io
  @inode: file inode
  Declare that a direct IO operation is about to start, and ensure
  that we block all buffered IO.
  On exit, the function ensures that the NFS_INO_ODIRECT flag is set,
  and holds a shared lock on inode->i_rwsem to ensure that the flag
  cannot be changed.
  In practice, this means that direct IO operations are allowed to
  execute in parallel, thanks to the shared lock, whereas buffered IO
  operations need to wait to grab an exclusive lock in order to clear
  NFS_INO_ODIRECT.
  Note that buffered writes and truncates both take a write lock on
  inode->i_rwsem, meaning that those are serialised w.r.t. O_DIRECT.
 Be an optimist! 
 Slow path.... 
  nfs_end_io_direct - declare that the direct io operation is done
  @inode: file inode
  Declare that a direct IO operation is done, and release the shared
  lock on inode->i_rwsem.
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsnfssuper.c
   Copyright (C) 1992  Rick Sladkey
   nfs superblock handling functions
   Modularised by Alan Cox <alan@lxorguk.ukuu.org.uk>, while hacking some
   experimental NFS changes. Modularisation taken straight from SYS5 fs.
   Change to nfs_read_super() to permit NFS mounts to multi-homed hosts.
   J.S.Peatfield@damtp.cam.ac.uk
   Split from inode.c by David Howells <dhowells@redhat.com>
  - superblocks are indexed on server only - all inodes, dentries, etc. associated with a
    particular server are held in the same superblock
  - NFS superblocks can have several effective roots to the dentry tree
  - directory type roots are spliced into the tree when a path from one root reaches the root
    of another (see nfs_lookup())
 CONFIG_NFS_V4_2 
  Register the NFS filesystems
  Unregister the NFS filesystems
  Deliver file system statistics to userspace
	
	  Current versions of glibc do not correctly handle the
	  case where f_frsize != f_bsize.  Eventually we want to
	  report the value of wtmult in this field.
	
	  On most nix systems, f_blocks, f_bfree, and f_bavail
	  are reported in units of f_frsize.  Linux hasn't had
	  an f_frsize field in its statfs struct until recently,
	  thus historically Linux's sys_statfs reports these
	  fields in units of f_bsize.
  Map the security flavour number to a name
 update NFS_AUTH_INFO_MAX_FLAVORS when this list changes! 
  Describe the mount options in force on this server representation
  Describe the mount options on this VFS mountpoint
  Present statistical information for this VFS mountpoint
	
	  Display all mount option settings
	
	  Display security flavor in effect for this mount
	
	  Display superblock IO counters
  Begin unmount by attempting to remove all automounted mountpoints we added
  in response to xdev traversals and referrals
 -EIO all pending IO 
  Return true if 'match' is in auth_info or auth_info is empty.
  Return false otherwise.
  Ensure that a specified authtype in ctx->auth_info is supported by
  the server. Returns 0 and sets ctx->selected_flavor if it's ok, and
  -EACCES if not.
	
	  If the sec= mount option is used, the specified flavor or AUTH_NULL
	  must be in the list returned by the server.
	 
	  AUTH_NULL has a special meaning when it's in the server list - it
	  means that the server will ignore the rpc creds, so any flavor
	  can be used but still use the sec= that was specified.
	 
	  Note also that the MNT procedure in MNTv1 does not return a list
	  of supported security flavors. In this case, nfs_mount() fabricates
	  a security flavor list containing just AUTH_NULL.
  Use the remote server's MOUNT service to request the NFS file handle
  corresponding to the provided path.
	
	  Construct the mount server's address.
	
	  Now ask the mount server to map our export path
	  to a file handle.
	
	  Was a sec= authflavor specified in the options? First, verify
	  whether the server supports it, and then just try to use it if so.
	
	  No sec= option was provided. RFC 2623, section 2.7 suggests we
	  SHOULD prefer the flavor listed first. However, some servers list
	  AUTH_NULL first. Avoid ever choosing AUTH_NULL.
	
	  Nothing we tried so far worked. At this point, give up if we've
	  already tried AUTH_UNIX or if the server's list doesn't contain
	  AUTH_NULL
 Last chance! Try AUTH_UNIX 
	
	  Userspace mount programs that send binary options generally send
	  them populated with default values. We have no way to know which
	  ones were explicitly specified. Fall back to legacy behavior and
	  just return success.
	
	  noac is a special case. It implies -o sync, but that's not
	  necessarily reflected in the mtab options. reconfigure_super
	  will clear SB_SYNCHRONOUS if -o sync wasn't specified in the
	  remount options, so we have to explicitly reset it.
 compare new mount options with old ones 
  Finish setting up an NFS superblock
		 The VFS shouldn't apply the umask to mode bits. We will do
		  so ourselves when necessary.
 We probably want something more informative here 
 Note: NFS_MOUNT_UNSHARED == NFS4_MOUNT_UNSHARED 
 -o noac implies -o sync 
 Get a superblock - note that we may end up sharing one that already exists 
 initial superblockroot creation 
  Destroy an NFS23 superblock
  NFS v4 module parameters need to stay in the
  NFS client for backwards compatibility
 Default cache timeout is 10 minutes 
 Turn off NFSv4 uidgid mapping when using AUTH_SYS 
 CONFIG_NFS_V4 
 SPDX-License-Identifier: GPL-2.0-only
  linuxfsnfswrite.c
  Write file data over NFS.
  Copyright (C) 1996, 1997, Olaf Kirch <okir@monad.swb.de>
  Local function declarations
		 It is OK to do some reclaim, not no safe to wait
		  for anything to be returned to the pool.
		  mempool_alloc() cannot handle that particular combination,
		  so we need two separate attempts.
  nfs_page_find_head_request_locked - find head request associated with @page
  must be called while holding the inode lock.
  returns matching head request with reference held, or NULL if not found.
  nfs_page_find_head_request - find head request associated with @page
  returns matching head request with reference held, or NULL if not found.
 Ensure that nobody removed the request before we locked it 
 Adjust the file length if we're writing beyond the end 
 A writeback failed: mark the page as bad, and invalidate the page cache 
 Force file size revalidation 
  nfs_page_group_search_locked
  @head - head request of page group
  @page_offset - offset into page
  Search page group with head @head to find a request that contains the
  page offset @page_offset.
  Returns a pointer to the first matching nfs request, or NULL if no
  match is found.
  Must be called with the page group lock held
  nfs_page_group_covers_page
  @head - head request of page group
  Return true if the page group with head @head covers the whole page,
  returns false otherwise
 We can set the PG_uptodate flag if we see that a write request
  covers the full page.
  NFS congestion control
  nfs_destroy_unlinked_subrequests - destroy recently unlinked subrequests
  @destroy_list - request list (using wb_this_page) terminated by @old_head
  @old_head - the old head of the list
  All subrequests must be locked and removed from all lists, so at this point
  they are only "active" in this function, and possibly in nfs_wait_on_request
  with a reference held by some other context.
 Note: lock subreq in order to change subreq->wb_head 
 make sure old group is not used 
 Note: races with nfs_page_group_destroy() 
 Check if we raced with nfs_page_group_destroy() 
		 subreq is now totally disconnected from page group or any
  nfs_join_page_group - destroy subrequests of the head req
  @head: the page used to lookup the "page group" of nfs_page structures
  @inode: Inode to which the request belongs.
  This function joins all sub requests to the head request by first
  locking all requests in the group, cancelling any pending operations
  and finally updating the head request to cover the whole range covered by
  the (former) group.  All subrequests are removed from any write or commit
  lists, unlinked from the group and destroyed.
 Subrequests should always form a contiguous range 
 Set the head request's range to cover the former page group 
	 Now that all requests are locked, make sure they aren't on any list.
 unlink subrequests from head, destroy them later 
 destroy list will be terminated by head 
  nfs_lock_and_join_requests - join all subreqs to the head req
  @page: the page used to lookup the "page group" of nfs_page structures
  This function joins all sub requests to the head request by first
  locking all requests in the group, cancelling any pending operations
  and finally updating the head request to cover the whole range covered by
  the (former) group.  All subrequests are removed from any write or commit
  lists, unlinked from the group and destroyed.
  Returns a locked, referenced pointer to the head request - which after
  this call is guaranteed to be the only request associated with the page.
  Returns NULL if no requests are found for @page, or a ERR_PTR if an
  error was encountered.
	
	  A reference is taken only on the head request which acts as a
	  reference to the whole page group - the group will not be destroyed
	  until the head reference is released.
 lock each request in the page group 
  Find an associated nfs write request, and prepare to flush it out
  May return an error if the user signalled nfs_wait_on_request().
 If there is a fatal error that covers this write, just exit 
		
		  Remove the problematic req upon fatal errors on the server
  Write an mmapped page to the server.
  Insert a write request into an inode
 Lock the request! 
	
	  Swap-space should not get truncated. Hence no need to plug the race
	  with invalidatetruncate.
	 this a head request for a page group - mark it as having an
	  extra reference so sub groups can follow suit.
	  This flag also informs pgio layer when to bump nrequests when
  Remove a write request from an inode
  nfs_page_search_commits_for_head_request_locked
  Search through commit lists on @inode for the head request for @page.
  Must be called while holding the inode (which is cinfo) lock.
  Returns the head request if found, or NULL if not found.
 search through pnfs commit lists 
 Linearly search the commit list for the correct request 
  nfs_request_add_commit_list_locked - add request to a commit list
  @req: pointer to a struct nfs_page
  @dst: commit list head
  @cinfo: holds list lock and accounting info
  This sets the PG_CLEAN bit, updates the cinfo count of
  number of outstanding requests requiring a commit as well as
  the MM page stats.
  The caller must hold NFS_I(cinfo->inode)->commit_mutex, and the
  nfs_page lock.
  nfs_request_add_commit_list - add request to a commit list
  @req: pointer to a struct nfs_page
  @cinfo: holds list lock and accounting info
  This sets the PG_CLEAN bit, updates the cinfo count of
  number of outstanding requests requiring a commit as well as
  the MM page stats.
  The caller must _not_ hold the cinfo->lock, but must be
  holding the nfs_page lock.
  nfs_request_remove_commit_list - Remove request from a commit list
  @req: pointer to a nfs_page
  @cinfo: holds list lock and accounting info
  This clears the PG_CLEAN bit, and updates the cinfo's count of
  number of outstanding requests requiring a commit
  It does not update the MM page stats.
  The caller _must_ hold the cinfo->lock and the nfs_page lock.
  Add a request to the inode's commit list.
 Called holding the request lock on @req 
 Reset wb_nio, since the write was successful. 
 NFS_I(cinfo->inode)->commit_mutex held by caller 
  nfs_scan_commit - Scan an inode for commit requests
  @inode: NFS inode to scan
  @dst: mds destination list
  @cinfo: mds and ds lists of reqs ready to commit
  Moves requests from the inode's 'commit' request list.
  The requests are not checked to ensure that they form a contiguous set.
  Search for an existing write request, and attempt to update
  it to reflect a new dirty region on a given page.
  If the attempt fails, then the existing request is flushed out
  to disk.
	
	  Tell the caller to flush out the request if
	  the offsets are non-contiguous.
	  Note: nfs_flush_incompatible() will already
	  have flushed out requests having wrong owners.
 Okay, the request matches. Update the region 
	
	  Note: we mark the request dirty here because
	  nfs_lock_and_join_requests() cannot preserve
	  commit flags, so we have to replay the write.
  Try to update an existing write request, or create one if there is none.
  Note: Should always be called with the Page Lock held to prevent races
  if we have to add a new request. Also assumes that the caller has
  already called nfs_flush_incompatible() if necessary.
 Update file length 
	
	  Look for a request corresponding to this page. If there
	  is one, and it belongs to another file, we flush it out
	  before we try to copy anything into the page. Do this
	  due to the lack of an ACCESS-type call in NFSv2.
	  Also do the same if we find a request from an existing
	  dropped page.
  Avoid buffered writes when a open context credential's key would
  expire soon.
  Returns -EACCES if the key will expire within RPC_KEY_EXPIRE_FAIL.
  Return 0 and set a credential flag which triggers the inode to flush
  and performs  NFS_FILE_SYNC writes if the key will expired within
  RPC_KEY_EXPIRE_TIMEO.
 Already expired! 
  Test if the open context credential key is marked to expire soon.
  If the page cache is marked as unsafe or invalid, then we can't rely on
  the PageUptodate() flag. In this case, we will need to turn off
  write optimisations that depend on the page contents being correct.
 If we know the page is up to date, and we're not using byte range locks (or
  if we have the whole file locked for writing), it may be more efficient to
  extend the write to cover the entire page in order to avoid fragmentation
  inefficiencies.
  If the file is opened for synchronous writes then we can just skip the rest
  of the checks.
 Check to see if there are whole file write locks 
  Update and possibly write a cached page of an NFS file.
  XXX: Keep an eye on generic_file_read to make sure it doesn't do bad
  things with a page scheduled for an RPC call (e.g. invalidate it).
 If a nfs_flush_ function fails, it should remove reqs from @head and
  call this on each, which will prepare them to be retried on next
  writeback using standard nfs.
 Bump the transmission count 
  Special version of should_remove_suid() that ignores capabilities.
 suid always must be killed 
	
	  sgid without any exec bits is just a mandatory locking mark; leave
	  it alone.  If some exec bits are set, it's a real sgid; kill it.
 Set attribute barrier 
 ...and update size 
  This function is called when the WRITE call is complete.
	
	  ->write_done will attempt to use post-op attributes to detect
	  conflicting writes by other clients.  A strict interpretation
	  of close-to-open would allow us to continue caching even if
	  another writer had changed the file, but some applications
	  depend on tighter cache coherency when writing.
		 We tried a write call, but the server did not
		  commit data to stable storage even though we
		  requested it.
		  Note: There is a known bug in Tru64 < 5.0 in which
		 	 the server reports NFS_DATA_SYNC, but performs
		 	 NFS_FILE_SYNC. We therefore implement this checking
		 	 as a dprintk() in order to avoid filling syslog.
 Note this will print the MDS for a DS write 
 Deal with the suidsgid bit corner case 
  This function is called when the WRITE call is complete.
 This a short write! 
 Has the server at least made some progress? 
 For non rpc-based layout drivers, retry-through-MDS 
 Was this an NFSv2 write or an NFSv3 stable write? 
 Resend from where the server left off 
			 Resend as a stable write in order to avoid
			  headaches in the case of a server crash.
 Set up the initial task struct.  
  Set up the argumentresult storage required for the RPC call.
	 Set up the RPC argument and reply structs
 reference transferred 
 only set lwb for pnfs commit 
 Note: we always request a commit of the entire inode 
  Commit dirty pages
 another commit raced with us 
 Set up the argument struct 
  COMMIT call returned
 Call the NFS version-specific code 
		 Okay, COMMIT succeeded, apparently. Check the verifier
 We have a match 
 We have a mismatch. Write the page again 
 Latency breaker 
 no commits means nothing needs to be done 
		 Don't commit yet if this is a non-blocking flush and there
		  are a lot of outstanding writes for this mapping.
 don't wait for the COMMIT response 
  Wrapper for filemap_write_and_wait_range()
  Needed for pNFS in order to ensure data becomes visible to the
  client.
  flush the inode to disk.
	 blocking call to cancel all requests and join to a single (head)
		 all requests from this page have been cancelled by
		  nfs_lock_and_join_requests, so just remove the head
		  request from the inode  page_private pointer and
  Write back all requests on one page - we do this before reading it.
	
	  If PagePrivate is set, then the page is currently associated with
	  an in-progress read or write request. Don't try to migrate it.
	 
	  FIXME: we could do this in principle, but we'll need a way to ensure
	         that we can safely release the inode reference while holding
	         the page lock.
	
	  NFS congestion size, scale with available memory.
	 
	   64MB:    8192k
	  128MB:   11585k
	  256MB:   16384k
	  512MB:   23170k
	    1GB:   32768k
	    2GB:   46340k
	    4GB:   65536k
	    8GB:   92681k
	   16GB:  131072k
	 
	  This allows larger machines to have largermore transfers.
	  Limit the default to 256M
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2013 Trond Myklebust <Trond.Myklebust@netapp.com>
 SPDX-License-Identifier: GPL-2.0-only
  linuxfsnfsfs_context.c
  Copyright (C) 1992 Rick Sladkey
  Conversion to new mount api Copyright (C) David Howells
  NFS mount handling.
  Split from fsnfssuper.c by David Howells <dhowells@redhat.com>
  Sanity-check a server address provided by the mount command.
  Address family must be initialized, and address must not be
  the ANY address for that family.
  Sanity check the NFS transport protocol.
  For text based NFSv2v3 mounts, the mount protocol transport default
  settings should depend upon the specified NFS transport.
  Add 'flavor' to 'auth_info' if not already present.
  Returns true if 'flavor' ends up in the list, false otherwise
 make sure this flavor isn't already in the list 
  Parse the value of the 'sec=' option.
		 Backward compatibility option. In future,
		  the mount program should always supply
		  a NFSv4 minor version number.
  Parse a single mount parameter.
		
		  boolean options:  foonofoo
 for side protocols 
		
		  options that take numeric values
		
		  options that take text values
 vector side protocols to TCP 
 not used for side protocols 
		
		  Special options
  Split fc->source into "hostname:export_path".
  The leftmost colon demarks the split between the server's hostname
  and the export path.  If the hostname starts with a left square
  bracket, then it may contain colons.
  Note: caller frees hostname and export path, even on error.
 Is the host name protected with square brakcets? 
 kill possible hostname list: not supported 
 N.B. caller will free nfs_server.hostname in all cases 
  Parse monolithic NFS2NFS3 mount data
  - fills in the mount root filehandle
  For option strings, user space handles the following behaviors:
  + DNS: mapping server host name to IP address ("addr=" option)
  + failure mode: how to behave if a mount request can't be handled
    immediately ("fgbg" option)
  + retry: how often to retry a mount request ("retry=" option)
  + breaking back: trying proto=udp after proto=tcp, v2 after v3,
    mountproto=tcp after mountproto=udp, and so on
 Turn off security negotiation 
		
		  for proto == XPRT_TRANSPORT_UDP, which is what uses
		  to_exponential, implying shift: limit the shift value
		  to BITS_PER_LONG (majortimeo is unsigned long)
 this will be UDP 
 shift value is too large 
		
		  Translate to nfs_fs_context, which nfs_fill_super
		  can deal with.
 N.B. caller will free nfs_server.hostname in all cases 
		
		  The legacy version 6 binary mount data from userspace has a
		  field used only to transport selinux information into the
		  kernel.  To continue to support that functionality we
		  have a touch of selinux knowledge here in the NFS code. The
		  userspace code converted context=blah to just blah so we are
		  converting back to the full string selinux understands.
 copy the fields backwards 
  Validate NFSv4 mount options
	
	  Translate to nfs_fs_context, which nfs_fill_super
	  can deal with.
  Parse a monolithic block of data from sys_mount().
  Validate the preparsed information in the config.
 Check for sanity first. 
	 Verify that any proto=mountproto= options match the address
	  families in the addr=mountaddr= options.
 Load the NFS protocol module if we haven't done so yet 
 Ensure the filesystem context has the correct fs_type 
  Create an NFS superblock by the appropriate method.
  Handle duplication of a configuration.  The caller copied src into sc, but
  it can't deal with resource pointers in the filesystem context, so we have
  to do that.  We need to clear pointers, copy data or get extra refs as
  appropriate.
  Prepare superblock configuration.  We use the namespaces attached to the
  context.  This may be the current process's namespaces, or it may be a
  container's namespaces.
 reconfigure, start with the current config 
 defaults 
 CONFIG_NFS_V4 
 SPDX-License-Identifier: GPL-2.0-or-later
 NFS FS-Cache index structure definition
  Copyright (C) 2008 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  Define the NFS filesystem for FS-Cache.  Upon registration FS-Cache sticks
  the cookie for the top-level index object for NFS into here.  The top-level
  index can than have other cache objects inserted into it.
  Register NFS for caching
  Unregister NFS for caching
  Define the server object for FS-Cache.  This is used to describe a server
  object to fscache_acquire_cookie().  It is keyed by the NFS protocol and
  server address parameters.
  Define the superblock object for FS-Cache.  This is used to describe a
  superblock object to fscache_acquire_cookie().  It is keyed by all the NFS
  parameters that might cause a separate superblock.
  Consult the netfs about the state of an object
  - This function can be absent if the index carries no state data
  - The netfs data from the cookie being used as the target is
    presented, as is the auxiliary data
  Get an extra reference on a read context.
  - This function can be absent if the completion function doesn't require a
    context.
  - The read context is passed back to NFS in the event that a data read on the
    cache fails with EIO - in which case the server must be contacted to
    retrieve the data, which requires the read context for security.
  Release an extra reference on a read context.
  - This function can be absent if the completion function doesn't require a
    context.
  Define the inode object for FS-Cache.  This is used to describe an inode
  object to fscache_acquire_cookie().  It is keyed by the NFS file handle for
  an inode.
  Coherency is managed by comparing the copies of i_size, i_mtime and i_ctime
  held in the cache auxiliary data for the data storage object with those in
  the inode struct in memory.
   pNFS functions to call and manage layout drivers.
   Copyright (c) 2002 [year of first publication]
   The Regents of the University of Michigan
   All Rights Reserved
   Dean Hildebrand <dhildebz@umich.edu>
   Permission is granted to use, copy, create derivative works, and
   redistribute this software and such derivative works for any purpose,
   so long as the name of the University of Michigan is not used in
   any advertising or publicity pertaining to the use or distribution
   of this software without specific, written prior authorization. If
   the above copyright notice or any other identification of the
   University of Michigan is included in any copy of any portion of
   this software, then the disclaimer below must also be included.
   This software is provided as is, without representation or warranty
   of any kind either express or implied, including without limitation
   the implied warranties of merchantability, fitness for a particular
   purpose, or noninfringement.  The Regents of the University of
   Michigan shall not be liable for any damages, including special,
   indirect, incidental, or consequential damages, with respect to any
   claim arising out of or in connection with the use of the software,
   even if it has been or is hereafter advised of the possibility of
   such damages.
 Locking:
  pnfs_spinlock:
       protects pnfs_modules_tbl.
  pnfs_modules_tbl holds all pnfs modules
 Return the registered pnfs layout driver module matching given id 
 Decrement the MDS count. Purge the deviceid cache if zero 
  When the server sends a list of layout types, we choose one in the order
  given in the list below.
  FIXME: should this list be configurable in some fashion? module param?
  	  mount option? something else?
  Try to set the server's pnfs module to the pnfs layout type specified by id.
  Currently only one pNFS layout driver per filesystem is supported.
  @ids array of layout types supported by MDS.
 Bump the MDS count 
  pNFS client layout cache
 Need to hold i_lock if caller does not already hold reference 
 Reset MDS Threshold IO counters 
 Notify pnfs_destroy_layout_final() that we're done 
  Compare 2 layout stateid sequence ids, to see which is newer,
  taking into account wraparound issues.
	
	  We must set lo->plh_return_seq to avoid livelocks with
	  pnfs_layout_need_return()
  Update the seqid of a layout stateid after receiving
  NFS4ERR_OLD_STATEID
 Is our call using the most recent seqid? If so, bump it 
 Try to update the seqid to the most recent 
  Mark a pnfs_layout_hdr and all associated layout segments as invalid
  In order to continue using the pnfs_layout_hdr, a full recovery
  is required.
  Note that caller must hold inode->i_lock.
 It is time to retry the failed layoutgets 
 Matched by pnfs_get_layout_hdr in pnfs_layout_insert_lseg 
  is l2 fully contained in l1?
    start1                             end1
    [----------------------------------)
            start2           end2
            [----------------)
 Returns 1 if lseg is removed from list, 0 otherwise 
		 Remove the reference keeping the lseg in the
		  list.  It will now be removed when all
		  outstanding io is finished.
  pnfs_mark_matching_lsegs_invalid - tear down lsegs or mark them for later
  @lo: layout header containing the lsegs
  @tmp_list: list head where doomed lsegs should go
  @recall_range: optional recall range argument to match (may be NULL)
  @seq: only invalidate lsegs obtained prior to this sequence (may be 0)
  Walk the list of lsegs in the layout header, and tear down any that should
  be destroyed. If "recall_range" is specified then the segment must match
  that range. If "seq" is non-zero, then only match segments that were handed
  out at or before that sequence.
  Returns number of matching invalid lsegs remaining in list after scanning
  it and purging them.
 note free_me must contain lsegs from a single layout_hdr 
 Caller must hold rcu_read_lock and clp->cl_lock 
 If the sb is being destroyed, just bail 
 Free all lsegs that are attached to commit buckets 
  Called by the state manager to remove all layouts established under an
  expired lease.
 update lo->plh_stateid with new if is more recent 
	
	  Because of wraparound, we want to keep the barrier
	  "close" to the current seqids. We really only want to
	  get here from a layoutget call.
 lget is set to 1 if called from inside send_layoutget call chain 
 Don't confuse uninitialised result and success 
 Serialise LAYOUTGETLAYOUTRETURN 
 Return true if layoutreturn is needed 
 Send an async layoutreturn so we dont deadlock 
  Initiates a LAYOUTRETURN(FILE), and removes the pnfs_layout_hdr
  when the layout segment list is empty.
  Note that a pnfs_layout_hdr can exist with an empty layout segment
  list when LAYOUTGET has failed, or when LAYOUTGET succeeded, but the
  deviceid is marked invalid.
 Reference matched in nfs4_layoutreturn_release 
 Is there an outstanding layoutreturn ? 
 Don't send a LAYOUTRETURN if list was initially empty 
 Block new layoutgets and readwrite to ds 
 no roc if we hold a delegation 
 Don't return layout if there is open file state 
 If we are sending layoutreturn, invalidate all valid lsegs 
		
		  Note: mark lseg for return so pnfs_layout_remove_lseg
		  doesn't invalidate the layout for us.
	 ROC in two conditions:
	  1. there are ROC lsegs
	  2. we don't send layoutreturn
 lo ref dropped in pnfs_roc_release() 
 If the creds don't match, we can't compound the layoutreturn 
 Handle Layoutreturn errors 
 Was there an RPC level error? If not, retry 
 If the call was not sent, let caller handle it 
		
		  Otherwise, assume the call succeeded and
		  that we need to release the layout
 Let the caller handle the retry 
	 we might not have grabbed lo reference. so need to check under
  Compare two layout segments for sorting into layout cache.
  We want to preferentially return RW over RO layouts, so ensure those
  are seen first.
 high offset > low offset 
 short length > long length 
 read > readwrite 
 Won the race? 
  iomode matching rules:
  iomode	lseg	strict match
                       iomode
  -----	-----	------ -----
  ANY		READ	NA    true
  ANY		RW	NA    true
  RW		READ	NA    false
  RW		RW	NA    true
  READ		READ	NA    true
  READ		RW	true   false
  READ		RW	false  true
 range1 covers only the first byte in the range 
  lookup range in layout
  Use mdsthreshold hints set at each OPEN to determine if IO should go
  to the MDS or over pNFS
  The nfs_inode read_io and write_io fields are cumulative counters reset
  when there are no layout segments. Note that in pnfs_update_layout iomode
  is set to IOMODE_READ for a READ request, and set to IOMODE_RW for a
  WRITE request.
  A return of true means use MDS IO.
  From rfc 5661:
  If a file's size is smaller than the file size threshold, data accesses
  SHOULD be sent to the metadata server.  If an IO request has a length that
  is below the IO size threshold, the IO SHOULD be sent to the metadata
  server.  If both file size and IO size are provided, the client SHOULD
  reach or exceed  both thresholds before sending its read or write
  requests to the data server.
	
	  send layoutcommit as it can hold up layoutreturn due to lseg
	  reference
		 The lo must be on the clp list if there is any
		  chance of a CB_LAYOUTRECALL(FILE) coming in.
  Layout segment is retreived from the server if not cached.
  The appropriate layout segment is referenced and returned to the caller.
 Do we even need to bother with this? 
 if LAYOUTGET already failed once we don't try again 
	
	  If the layout segment list is empty, but there are outstanding
	  layoutget calls, then they might be subject to a layoutrecall.
	
	  Because we free lsegs when sending LAYOUTRETURN, we need to wait
	  for LAYOUTRETURN.
	
	  Choose a stateid for the LAYOUTGET. If we don't have a layout
	  stateid, or it has been invalidated, then we must use the open
	  stateid.
		
		  The first layoutget for the file. Need to serialize per
		  RFC 5661 Errata 3208.
 Heuristic: don't send layoutget if we have cached data 
 Could check on max_ops, but currently hardcoded high enough 
		
		  Halt lgopen attempts if the server doesn't recognise
		  the "current stateid" value, the layout type, or the
		  layoutget operation as being valid.
		  Also if it complains about too many ops in the compound
		  or of the requestreply being too big.
 Inject layout blob into IO device driver 
 existing state ID, make sure the sequence number matches. 
		
		  We got an entirely new state ID.  Mark all segments for the
		  inode invalid, and retry the layoutget
 We have a completely new layout 
  pnfs_mark_matching_lsegs_return - Free or return matching layout segments
  @lo: pointer to layout header
  @tmp_list: list header to be used with pnfs_free_lseg_list()
  @return_range: describe layout segment ranges to be returned
  @seq: stateid seqid to match
  This function is mainly intended for use by layoutrecall. It attempts
  to free the layout segment immediately, or else to mark it for return
  as soon as its reference count drops to zero.
  Returns
  - 0: a layoutreturn needs to be scheduled.
  - EBUSY: there are layout segment that are still in use.
  - ENOENT: there are no layout segments that need to be returned.
	
	  mark all matching lsegs so that we are sure to have no live
	  segments at hand when sending layoutreturn. See pnfs_put_lseg()
	  for how it works.
 Find open file states whose mode matches that of the range 
  Check for any intersection between the request and the pgio->pg_lseg,
  and if none, put this pgio->pg_lseg away.
 If no lseg, fall back to read through mds 
 If no lseg, fall back to write through mds 
  Return 0 if @req cannot be coalesced into @pgio, otherwise return the number
  of bytes (maximum @req->wb_bytes) that can be coalesced.
	
	  'size' contains the number of bytes left in the current page (up
	  to the original size asked for in @req->wb_bytes).
	 
	  Calculate how many bytes are left in the layout segment
	  and if there are less bytes than 'size', return that instead.
	 
	  Please also note that 'end_offset' is actually the offset of the
	  first byte that lies outside the pnfs_layout_range. FIXME?
	 
 start of request is past the last byte of this segment 
		 adjust 'size' iff there are fewer bytes left in the
 Resend all requests through the MDS 
  Called by non rpc-based layout drivers
 cleanup hdr and prepare to redo pnfs 
 Resend all requests through the MDS 
  Called by non rpc-based layout drivers
  Call the appropriate parallel IO subsystem read function.
 Resend all requests through pnfs. 
 Prevent deadlocks with layoutreturn! 
 cleanup hdr and prepare to redo pnfs 
  There can be multiple RW segments.
 Matched by references in pnfs_set_layoutcommit 
 references matched in nfs4_layoutcommit_release 
	 if pnfs_layoutcommit_inode() runs between inode locks, the next one
  For the LAYOUT4_NFSV4_1_FILES layout type, NFS_DATA_SYNC WRITEs and
  NFS_UNSTABLE WRITEs with a COMMIT to data servers must store enough
  data to disk to allow the server to recover the data if it crashes.
  LAYOUTCOMMIT is only needed when the NFL4_UFLG_COMMIT_THRU_MDS flag
  is off, and a COMMIT is sent to a data server, or
  if WRITEs to a data server return NFS_DATA_SYNC.
 Note kzalloc ensures data->res.seq_res.sr_slot == NULL 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsnfsinode.c
   Copyright (C) 1992  Rick Sladkey
   nfs inode and superblock handling functions
   Modularised by Alan Cox <alan@lxorguk.ukuu.org.uk>, while hacking some
   experimental NFS changes. Modularisation taken straight from SYS5 fs.
   Change to nfs_read_super() to permit NFS mounts to multi-homed hosts.
   J.S.Peatfield@damtp.cam.ac.uk
 Default is to see 64-bit inode numbers 
  nfs_compat_user_ino64 - returns the user-visible inode number
  @fileid: 64-bit fileid
  This function returns a 32-bit inode number if the boot parameter
  nfs.enable_ino64 is zero.
	
	  The following should never happen...
  nfs_sync_mapping - helper to flush all mmapped dirty data to disk
  @mapping: pointer to struct address_space
  Invalidate the local caches
  Invalidate, but do not unhash, the inode.
  NB: must be called with inode->i_lock held!
  In NFSv3 we can have 64bit inode numbers. In order to support
  this, and re-exported directories (also seen in NFSv2)
  we are forced to allow 2 different inodes to have the same
  i_ino.
 Search for inode identified by fh, fileid and i_mode in inode cache. 
  This is our front-end to iget that looks up inodes by file handle
  instead of inode number.
		 We set i_ino for the few things that still rely on it,
 We can't support update_atime(), since the server will reset it 
		 Why so? Because we want revalidate for devicesFIFOs, and
		  that's precisely what we have in nfs_file_inode_operations.
 Deal with crossing mountpoints 
			
			  report the blocks in 512byte units
 skip mode change if it's just for clearing setuidsetgid 
 Optimization: if the end result is no change, don't RPC 
 Write all dirty data 
  nfs_vmtruncate - unmap mappings "freed" by truncate() syscall
  @inode: inode of the file used
  @offset: file offset to start truncating
  This is a copy of the common vmtruncate, but with the locking
  corrected to take into account the fact that NFS requires
  inode->i_size to be updated under the inode->i_lock.
  Note: must be called with inode->i_lock held!
 Optimisation 
  nfs_setattr_update_inode - Update inode metadata after a setattr call.
  @inode: pointer to struct inode
  @attr: pointer to struct iattr
  @fattr: pointer to struct nfs_fattr
  Note: we do this in the proc.c in order to ensure that
        it works for things like exclusive creates too.
 Barrier: bump the attribute generation count. 
 Flush out writes to the server in order to update cmtime.  
	
	  We may force a getattr if the user cares about atime.
	 
	  Note that we only have to check the vfsmount flags here:
	   - NFS always sets S_NOATIME by so checking it would give a
	     bogus result
	   - NFS never sets SB_NOATIME or SB_NODIRATIME so there is
	     no point in checking those.
 Is the user requesting attributes that might need revalidation? 
 Check whether the cached attributes are stale 
 Update the attribute cache 
 Only return attributes that were revalidated. 
  nfs_close_context - Common close_context() routine NFSv2v3
  @ctx: pointer to context
  @is_sync: is this a synchronous close
  Ensure that the attributes are up to date if we're mounted
  with close-to-open semantics and we have cached data that will
  need to be revalidated on open.
  Ensure that mmap has a recent RPC credential for use when writing out
  shared pages
  Given an inode, search for an open context with the desired characteristics
		
		  We fatal error on write before. Try to writeback
		  every page again.
  These allocate and release file readwrite context information.
  This function is called whenever some part of NFS notices that
  the cached attributes have to be refreshed.
 pNFS: Attributes aren't updated until we layoutcommit 
 A soft timeout occurred. Use cached information? 
  nfs_revalidate_inode - Revalidate the inode attributes
  @inode: pointer to inode struct
  @flags: cache flags to check
  Updates inode attribute information by retrieving the data from the server.
  nfs_clear_invalid_mapping - Conditionally clear a mapping
  @mapping: pointer to mapping
  If the NFS_INO_INVALID_DATA inode flag is set, clear the mapping.
	
	  We must clear NFS_INO_INVALID_DATA first to ensure that
	  invalidations that come in while we're shooting down the mappings
	  are respected. But, that leaves a race window where one revalidator
	  can clear the flag, and then another checks it before the mapping
	  gets invalidated. Fix that by serializing access to this part of
	  the function.
	 
	  At the same time, we need to allow other tasks to see whether we
	  might be in the middle of invalidating the pages, so we only set
	  the bit lock here if it looks like we're going to be doing that.
  nfs_revalidate_mapping - Revalidate the pagecache
  @inode: pointer to host inode
  @mapping: pointer to mapping
 swapfiles are not supposed to be shared. 
 If we have atomic WCC data, we may update some attributes 
  nfs_check_inode_attributes - verify consistency of the inode attribute cache
  @inode: pointer to inode
  @fattr: updated attributes
  Verifies the attribute cache. If we have just changed the attributes,
  so that fattr carries weak cache consistency data, then it may
  also update the ctimemtimechange_attribute.
 Only a mounted-on-fileid? Just exit 
 Has the inode gone and changed behind our back? 
 Is this perhaps the mounted-on fileid? 
 Verify a few of the more important attributes 
 Have any file permissions changed? 
 Has the link count changed? 
  nfs_fattr_set_barrier
  @fattr: attributes
  Used to set a barrier after an attribute was updated. This
  barrier ensures that older attributes from RPC calls that may
  have raced with our update cannot clobber these new values.
  Note that you are still responsible for ensuring that other
  operations which change the attribute on the server do not
  collide.
  _nfs_display_fhandle_hash - calculate the crc32 hash for the filehandle
                              in the same way that wireshark does
  @fh: file handle
  For debugging only.
	 wireshark uses 32-bit AUTODIN crc and does a bitwise
  _nfs_display_fhandle - display an NFS file handle on the console
  @fh: file handle to display
  @caption: display caption
  For debugging only.
  nfs_inode_attrs_cmp_generic - compare attributes
  @fattr: attributes
  @inode: pointer to inode
  Attempt to divine whether or not an RPC call reply carrying stale
  attributes got scheduled after another call carrying updated ones.
  Note also the check for wraparound of 'attr_gencount'
  The function returns '1' if it thinks the attributes in @fattr are
  more recent than the ones cached in @inode. Otherwise it returns
  the value '0'.
  nfs_inode_attrs_cmp_monotonic - compare attributes
  @fattr: attributes
  @inode: pointer to inode
  Attempt to divine whether or not an RPC call reply carrying stale
  attributes got scheduled after another call carrying updated ones.
  We assume that the server observes monotonic semantics for
  the change attribute, so a larger value means that the attributes in
  @fattr are more recent, in which case the function returns the
  value '1'.
  A return value of '0' indicates no measurable change
  A return value of '-1' means that the attributes in @inode are
  more recent.
  nfs_inode_attrs_cmp_strict_monotonic - compare attributes
  @fattr: attributes
  @inode: pointer to inode
  Attempt to divine whether or not an RPC call reply carrying stale
  attributes got scheduled after another call carrying updated ones.
  We assume that the server observes strictly monotonic semantics for
  the change attribute, so a larger value means that the attributes in
  @fattr are more recent, in which case the function returns the
  value '1'.
  A return value of '-1' means that the attributes in @inode are
  more recent or unchanged.
  nfs_inode_attrs_cmp - compare attributes
  @fattr: attributes
  @inode: pointer to inode
  This function returns '1' if it thinks the attributes in @fattr are
  more recent than the ones cached in @inode. It returns '-1' if
  the attributes in @inode are more recent than the ones in @fattr,
  and it returns 0 if not sure.
  nfs_inode_finish_partial_attr_update - complete a previous inode update
  @fattr: attributes
  @inode: pointer to inode
  Returns '1' if the last attribute update left the inode cached
  attributes in a partially unrevalidated state, and @fattr
  matches the change attribute of that partial update.
  Otherwise returns '0'.
  nfs_refresh_inode - try to update the inode attribute cache
  @inode: pointer to inode
  @fattr: updated attributes
  Check that an RPC call that returned attributes has not overlapped with
  other recent updates of the inode metadata, then decide whether it is
  safe to do a full update of the inode attributes, or whether just to
  call nfs_check_inode_attributes.
  nfs_post_op_update_inode - try to update the inode attribute cache
  @inode: pointer to inode
  @fattr: updated attributes
  After an operation that has changed the inode metadata, mark the
  attribute cache as being invalid, then try to update it.
  NB: if the server didn't return any post op attributes, this
  function will force the retrieval of attributes before the next
  NFS request.  Thus it should be used only for operations that
  are expected to change one or more attributes, to avoid
  unnecessary NFS requests and trips through nfs_update_inode().
  nfs_post_op_update_inode_force_wcc_locked - update the inode attribute cache
  @inode: pointer to inode
  @fattr: updated attributes
  After an operation that has changed the inode metadata, mark the
  attribute cache as being invalid, then try to update it. Fake up
  weak cache consistency data, if none exist.
  This function is mainly designed to be used by the ->write_done() functions.
 Don't do a WCC update if these attributes are already stale 
  nfs_post_op_update_inode_force_wcc - try to update the inode attribute cache
  @inode: pointer to inode
  @fattr: updated attributes
  After an operation that has changed the inode metadata, mark the
  attribute cache as being invalid, then try to update it. Fake up
  weak cache consistency data, if none exist.
  This function is mainly designed to be used by the ->write_done() functions.
  Many nfs protocol calls return the new file attributes after
  an operation.  Here we update the inode to reflect the state
  of the server's inode.
  This is a bit tricky because we have to make sure all dirty pages
  have been sent off to the server before calling invalidate_inode_pages.
  To make sure no other process adds more write requests while we try
  our best to flush them, we make them sleep during the attribute refresh.
  A very similar scenario holds for the dir cache.
 Only a mounted-on-fileid? Just exit 
 Has the inode gone and changed behind our back? 
 Is this perhaps the mounted-on fileid? 
	
	  Make sure the inode's type hasn't changed.
		
		 Big trouble! The inode has become a different object.
 Update the fsid? 
 Save the delegation state before clearing cache_validity 
	
	  Update the read time so we don't revalidate too often.
 Do atomic weak cache consistency updates 
 More cache consistency checks 
 Could it be a race with writeback? 
 Force revalidate of all attributes 
 Check if our cached file size is stale 
			 Do we perhaps have any outstanding writes, or has
		
		  report the blocks in 512byte units
 Update attrtimeo value if we're out of the unstable period 
 Set barrier to be more recent than all outstanding updates 
 Set the barrier to be more recent than this fattr 
 Don't invalidate the data if we were to blame 
	
	  No need to worry about unhashing the dentry, as the
	  lookup validation will know that the inode is bad.
	  (But we fall through to invalidate the caches.)
 CONFIG_NFS_V4 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
  start up the nfsiod workqueue
  Destroy the nfsiod workqueue
  Initialize NFS
 Not quite true; I just maintain it 
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfscallback.c
  Copyright (C) 2004 Trond Myklebust
  NFSv4 callback handling
  This is the NFSv4 callback kernel thread.
		
		  Listen for a request on the socket
  The callback service for NFSv4.1 callbacks
		
		  Save the svc_serv in the transport so that it can
		  be referenced when the session backchannel is initialized
 CONFIG_NFS_V4_1 
	
	  Check whether we're already up and running.
		
		  Note: increase service usage, because later in case of error
		  svc_destroy() will be called.
	
	  Sanity check: if there's no task,
	  we should be the first user ...
	 As there is only one thread we need to over-ride the
	  default maximum of 80 connections
  Bring up the callback thread if it is not already up.
	
	  svc_create creates the svc_serv with sv_nrthreads == 1, and then
	  svc_prepare_thread increments that. So we need to call svc_destroy
	  on both success and failure so that the refcount is 1 when the
	  thread exits.
  Kill the callback thread if it's no longer being used.
 Boolean check of RPC_AUTH_GSS principal 
 No RPC_AUTH_GSS on NFSv4.1 back channel yet 
	
	  It might just be a normal user principal, in which case
	  userspace won't bother to tell us the name at all.
	
	  Did we get the acceptor from userland during the SETCLIENID
	  negotiation?
	
	  Otherwise try to verify it using the cl_hostname. Note that this
	  doesn't work if a non-canonical hostname was used in the devname.
 Expect a GSS_C_NT_HOSTBASED_NAME like "nfs@serverhostname" 
  pg_authenticate method for nfsv4 callback threads.
  The authflavor has been negotiated, so an incorrect flavor is a server
  bug. Deny packets with incorrect authflavor.
  All other checking done after NFS decoding where the nfs_client can be
  found in nfs4_callback_compound
 No RPC_AUTH_GSS support yet in NFSv4.1 
  Define NFS4 callback program
 RPC service number 
 Number of entries 
 version table 
 service name 
 authentication class 
 SPDX-License-Identifier: GPL-2.0
  In-kernel MOUNT protocol client
  Copyright (C) 1997, Olaf Kirch <okir@monad.swb.de>
  Defined by RFC 1094, section A.3; and RFC 1813, section 5.1.4
  XDR data type sizes
  XDR argument and result sizes
  Defined by RFC 1094, section A.5
  Defined by RFC 1813, section 5.2
  Defined by OpenGroup XNFS Version 3W, chapter 8
  Defined by RFC 1813, section 5.1.5
 no error 
 Not owner 
 No such file or directory 
 IO error 
 Permission denied 
 Not a directory 
 Invalid argument 
 Filename too long 
 Operation not supported 
 A failure on the server 
  nfs_mount - Obtain an NFS file handle for the given host and path
  @info: pointer to mount request arguments
  @timeo: deciseconds the mount waits for a response before it retries
  @retrans: number of times the mount retries a request
  Uses timeout parameters specified by caller. On successful return, the
  auth_flavs list and auth_flav_len will be populated with the list from the
  server or a faked-up list if the server didn't provide one.
	
	  If the server didn't provide a flavor list, allow the
	  client to try any flavor.
  nfs_umount - Notify a server that we have unmounted this export
  @info: pointer to umount request arguments
  MOUNTPROC_UMNT is advisory, so we set a short timeout, and always
  use UDP.
  XDR encodedecode functions for MOUNT
  RFC 1094: "A non-zero status indicates some sort of error.  In this
  case, the status is a UNIX error number."  This can be problematic
  if the server and client use different errno values for the same
  error.
  However, the OpenGroup XNFS spec provides a simple mapping that is
  independent of local errno values on the server and the client.
 SPDX-License-Identifier: GPL-2.0
   linuxfsnfsunlink.c
  nfs sillydelete handling
  nfs_free_unlinkdata - release data from a sillydelete operation.
  @data: pointer to unlink structure.
  nfs_async_unlink_done - Sillydelete post-processing
  @task: rpc_task of the sillydelete
  @calldata: pointer to nfs_unlinkdata
  Do the directory attribute update.
  nfs_async_unlink_release - Release the sillydelete data.
  @calldata: struct nfs_unlinkdata to release
  We need to call nfs_put_unlinkdata as a 'tk_release' task since the
  rpc_task would be freed too.
		
		  Hey, we raced with lookup... See if we need to transfer
		  the sillyrename information to the aliased dentry.
		
		  If we'd displaced old cached devname, free it.  At that
		  point dentry is definitely not a root, so we won't need
		  that anymore.
  nfs_async_unlink - asynchronous unlinking of a file
  @dentry: parent directory of dentry
  @name: name of dentry to unlink
	
	  If we'd displaced old cached devname, free it.  At that
	  point dentry is definitely not a root, so we won't need
	  that anymore.
  nfs_complete_unlink - Initialize completion of the sillydelete
  @dentry: dentry to delete
  @inode: inode
  Since we're most likely to be called by dentry_iput(), we
  only use the dentry to find the sillydelete. We then copy the name
  into the qstr.
 Cancel a queued async unlink. Called when a sillyrename run fails. 
  nfs_async_rename_done - Sillyrename post-processing
  @task: rpc_task of the sillyrename
  @calldata: nfs_renamedata for the sillyrename
  Do the directory attribute updates and the d_move
  nfs_async_rename_release - Release the sillyrename data.
  @calldata: the struct nfs_renamedata to be released
	 The result of the rename is unknown. Play it safe by
  nfs_async_rename - perform an asynchronous rename operation
  @old_dir: directory that currently holds the dentry to be renamed
  @new_dir: target directory for the rename
  @old_dentry: original dentry to be renamed
  @new_dentry: dentry to which the old_dentry should be renamed
  @complete: Function to run on successful completion
  It's expected that valid references to the dentries and inodes are held
 set up nfs_renamedata 
 set up nfs_renameargs 
 set up nfs_renameres 
  Perform tasks needed when a sillyrename is done such as cancelling the
  queued async unlink if it failed.
  nfs_sillyrename - Perform a silly-rename of a dentry
  @dir: inode of directory that contains dentry
  @dentry: dentry to be sillyrenamed
  NFSv23 is stateless and the server doesn't know when the client is
  holding a file open. To prevent application problems when a file is
  unlinked while it's still open, the client performs a "silly-rename".
  That is, it renames the file to a hidden file in the same directory,
  and only performs the unlink once the last reference to it is put.
  The final cleanup is done during dentry_iput.
  (Note: NFSv4 is stateful, and has opens, so in theory an NFSv4 server
  could take responsibility for keeping open files referenced.  The server
  would also need to ensure that opened-but-deleted files were kept over
  reboots.  However, we may not assume a server does so.  (RFC 5661
  does provide an OPEN4_RESULT_PRESERVE_UNLINKED flag that a server can
  use to advertise that it does this; some day we may take advantage of
  it.))
	
	  We don't allow a dentry to be silly-renamed twice.
		
		  N.B. Better to return EBUSY here ... it could be
		  dangerous to delete the file while it's in use.
 need negative lookup 
	 queue unlink first. Can't do this from rpc_release as it
	  has to allocate memory
 run the rename task, undo unlink if it fails 
 wait for the RPC task to complete, unless a SIGKILL intervenes 
 The rename succeeded 
		 The result of the rename is unknown. Play it safe by
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (c) 2012 Netapp, Inc. All rights reserved.
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsnfsdir.c
   Copyright (C) 1992  Rick Sladkey
   nfs directory handling functions
  10 Apr 1996	Added silly rename for unlink	--okir
  28 Sep 1996	Improved directory cache --okir
  23 Aug 1997  Claus Heine claus@momo.math.rwth-aachen.de 
               Re-implemented silly rename for unlink, newly implemented
               silly rename for nfs_rename() following the suggestions
               of Olaf Kirch (okir) found in this file.
               Following Linus comments on my original hack, this version
               depends only on the dcache stuff and doesn't touch the inode
               layer (iput() and friends).
   6 Jun 1999	Cache readdir lookups in the page cache. -DaveM
 #define NFS_DEBUG_VERBOSE 1 
  Open file
  we are freeing strings created by nfs_add_to_readdir_array()
  the caller is responsible for freeing qstr.name
  when called by nfs_readdir_add_to_array, the strings will be freed in
  nfs_clear_readdir_array()
	
	  Avoid a kmemleak false positive. The pointer to the name is stored
	  in a page cache page which kmemleak does not scan.
  Check that the next array entry lies entirely within the page bounds
 Optimisation for monotonically increasing cookies 
 Fill a page with xdr information before transferring to the cache page 
 We requested READDIRPLUS, but the server doesn't grok it 
 Match file and dirent using either filehandle or fileid
  Note: caller is responsible for checking the fsid
  This function is called by the lookup and getattr code to request the
  use of readdirplus to accelerate any future lookups in the same
  directory.
  This function is mainly for use by nfs_getattr().
  If this is an 'ls -l', we want to force use of readdirplus.
  Do this by checking if there is an active file descriptor
  and calling nfs_advise_use_readdirplus, then forcing a
  cache flush.
 Validate that the name doesn't contain any illegal '\0' 
 ...or '' 
 Is there a mountpoint here? If so, just exit 
 Perform conversion from xdr to cache array 
  nfs_readdir_alloc_pages() will allocate pages that must be freed with a call
  to nfs_readdir_free_pages()
  Returns 0 if desc->dir_cookie was found on page desc->page_index
  and locks the page to prevent removal from the page cache.
		
		  Set the cookie verifier if the page cache was empty
	
	  Default to uncached readdir if the page cache is empty, and
	  we're looking for a non-zero cookie in a large directory.
 Search for desc->dir_cookie from the beginning of the page cache 
  Once we've found the start of the dirent within a page: fill 'er up...
  If we cannot find a cookie in our cache, we suspect that this is
  because it points to a deleted file, so we ask the server to return
  whatever it thinks is the next entry. We then feed this to filldir.
  If all goes well, we should then be able to find our way round the
  cache on the next call to readdir_search_pagecache();
  NOTE: we cannot add the anonymous page to the pagecache because
 	 the data it contains might not be page aligned. Besides,
 	 we should already have a complete representation of the
 	 directory in the page cache by the time we get here.
 The file offset position represents the dirent entry number.  A
   last cookie cache takes care of the common case of reading the
   whole directory.
	
	  ctx->pos points to the dirent entry number.
	  desc->dir_cookie has the cookie for the next entry. We have
	  to either find the entry with the appropriate number or
	  revalidate the cookie.
 This means either end of directory 
 Or that the server has 'lost' a cookie 
  All directory operations under NFS are synchronous, so fsync()
  is a dummy operation.
  nfs_force_lookup_revalidate - Mark the directory as having changed
  @dir: pointer to directory inode
  This forces the revalidation code in nfs_lookup_revalidate() to do a
  full lookup on all child dentries of 'dir' whenever a change occurs
  on the server that might have invalidated our dcache.
  Note that we reserve bit '0' as a tag to let us know when a dentry
  was revalidated while holding a delegation on its inode.
  The caller should be holding dir->i_lock
  nfs_verify_change_attribute - Detects NFS remote directory changes
  @dir: pointer to parent directory inode
  @verf: previously saved change attribute
  Return "false" if the verifiers doesn't match the change attribute.
  This would usually indicate that the directory contents have changed on
  the server, and that any dentries need revalidating.
 IS_ENABLED(CONFIG_NFS_V4) 
  nfs_set_verifier - save a parent directory verifier in the dentry
  @dentry: pointer to dentry
  @verf: verifier to save
  Saves the parent directory verifier in @dentry. If the inode has
  a delegation, we also tag the dentry as having been revalidated
  while holding a delegation so that we know we don't have to
  look it up again after a directory change.
  nfs_clear_verifier_delegated - clear the dir verifier delegation tag
  @inode: pointer to inode
  Iterates through the dentries in the inode alias list and clears
  the tag used to indicate that the dentry has been revalidated
  while holding a delegation.
  This function is intended for use when the delegation is being
  returned or revoked.
 IS_ENABLED(CONFIG_NFS_V4) 
  A check for whether or not the parent directory has changed.
  In the case it has, we assume that the dentries are untrustworthy
  and may need to be looked up again.
  If rcu_walk prevents us from performing a full check, return 0.
 Revalidate nfsi->cache_change_attribute before we declare a match 
  Use intent information to check whether or not we're going to do
  an O_EXCL create using this path component.
  Inode and filehandle revalidation for lookups.
  We force revalidation in the cases where the VFS sets LOOKUP_REVAL,
  or if the intent information indicates that we're about to open this
  particular file and the "nocto" mount flag is not set.
 A NFSv4 OPEN will revalidate later 
 NFS close-to-open cache consistency validation 
 VFS wants an on-the-wire revalidation 
  We judge how long we want to trust negative
  dentries by looking at the parent inode mtime.
  If parent mtime has changed, we revalidate, else we wait for a
  period corresponding to the parent's attribute cache timeout value.
  If LOOKUP_RCU prevents us from performing a full check, return 1
  suggesting a reval is needed.
  Note that when creating a new file, or looking up a rename target,
  then it shouldn't be necessary to revalidate a negative dentry.
		
		  We can't d_drop the root of a disconnected tree:
		  its d_hash is on the s_anon list and d_drop() would hide
		  it from shrink_dcache_for_unmount(), leading to busy
		  inodes on unmount and further oopses.
 set a readdirplus hint that we had a cache miss 
	
	  If the lookup failed despite the dentry change attribute being
	  a match, then we should revalidate the directory cache.
  This is called every time the dcache has a lookup hit,
  and we should check whether we can really trust that
  lookup.
  NOTE! The hit can be a negative hit too, don't assume
  we have an inode!
  If the parent directory is seen to have changed, we throw out the
  cached dentry and do a new lookup.
 Force a full look up iff the parent directory has changed 
  A weaker form of d_revalidate for revalidating just the d_inode(dentry)
  when we don't really care about the dentry name. This is called when a
  pathwalk ends on a dentry that was not found via a normal lookup in the
  parent dir (e.g.: ".", "..", procfs symlinks or mountpoint traversals).
  In this situation, we just want to verify that the inode itself is OK
  since the dentry might have changed on the server.
	
	  I believe we can only get a negative dentry here in the case of a
	  procfs-style symlink. Just assume it's correct for now, but we may
	  eventually need to do something more here.
  This is called from dput() when d_count is going to 0.
 Unhash any dentry with a stale inode 
 Unhash it, so that ->d_iput() would be called 
		 Unhash it, so that ancestors of killed async unlink
 Ensure that we revalidate inode->i_nlink 
 drop the inode if we're reasonably sure this is the last link 
  Called when the dentry loses inode.
  We use it to clean up silly-renamed files.
 free cached devname value, if it survived that far 
	
	  If we're doing an exclusive create, optimize away the lookup
	  but don't hash the dentry.
 Notify readdir to use READDIRPLUS 
 Expect a negative dentry 
 NFS only supports OPEN on regular files 
			
			  Hashed negative dentry with O_DIRECTORY: dentry was
			  revalidated and is fine, no need to perform lookup
			  again
 case -EINVAL: 
	 We can't create new files in nfs_open_revalidate(), so we
	  optimize away revalidation of negative dentries.
 NFS only supports OPEN on regular files 
 We cannot do exclusive creation on a positive dentry 
 Check if the directory changed 
 Let f_op->open() actually open (and revalidate) the file 
 CONFIG_NFSV4 
  Code common to create, mkdir, and mknod.
 Callers don't care 
  Following a failed create operation, we drop the dentry rather
  than retain a negative dentry. This avoids a problem in the event
  that the operation succeeded on the server, but an error in the
  reply path made it appear to have failed.
  See comments for nfs_proc_create regarding failed operations.
  See comments for nfs_proc_create regarding failed operations.
 Ensure the VFS deletes this inode 
  Remove a file after making sure there are no pending writes,
  and after checking that the file has only one user. 
  We invalidate the attribute cache and free the inode prior to the operation
  to avoid possible races if the server reuses the inode.
 If the dentry was sillyrenamed, we simply call d_delete() 
  We do silly rename. In case sillyrename() returns -EBUSY, the inode
   belongs to an active ".nfs..." file and we return -EBUSY.
   If sillyrename() returns 0, we do nothing, otherwise we unlink.
 Start asynchronous writeout of the inode 
  To create a symbolic link, most file systems instantiate a new inode,
  add a page to it containing the path, then write it out to the disk
  using prepare_writecommit_write.
  Unfortunately the NFS client can't create the in-core inode first
  because it needs a file handle to create an in-core inode (see
  fsnfsinode.c:nfs_fhget).  We only have a file handle after the
  symlink request has completed on the server.
  So instead we allocate a raw page, copy the symname into it, then do
  the SYMLINK request with the page as the buffer.  If it succeeds, we
  now have a new file handle and can instantiate an in-core NFS inode
  and move the raw page into its mapping.
	
	  No big deal if we can't add this page to the page cache here.
	  READLINK will get the missing page from the server if needed.
		
		  add_to_page_cache_lru() grabs an extra page refcount.
		  Drop it here to avoid leaking this page later.
  RENAME
  FIXME: Some nfsds, like the Linux user space nfsd, may generate a
  different file handle for the same inode after a rename (e.g. when
  moving to a different directory). A fail-safe method to do so would
  be to look up old_dirold_name, create a link to new_dirnew_name and
  rename the old file using the sillyrename stuff. This way, the original
  file in old_dir will go away when the last process iput()s the inode.
  FIXED.
  It actually works quite well. One needs to have the possibility for
  at least one ".nfs..." file in each directory the file ever gets
  moved or linked to which happens automagically with the new
  implementation that only depends on the dcache stuff instead of
  using the inode layer
  Unfortunately, things are a little more complicated than indicated
  above. For a cross-directory move, we want to make sure we can get
  rid of the old inode after the operation.  This means there must be
  no pending writes (if it's a file), and the use count must be 1.
  If these conditions are met, we can drop the dentries before doing
  the rename.
	
	  For non-directories, check whether the target is busy and if so,
	  make a copy of the dentry and then do a silly-rename. If the
	  silly-rename succeeds, the copied dentry is hashed and becomes
	  the new target.
		
		  To prevent any new references to the target during the
		  rename, we unhash the dentry in advance.
 copy the target dentry's name 
 silly-rename the existing target ... 
 Paired with the atomic_dec_and_test() barrier in rpc_do_put_task() 
 Ensure the inode attributes are revalidated 
		
		  The d_move() should be here instead of in an async RPC completion
		  handler because we need the proper locks to move the dentry.  If
		  we're interrupted by a signal, the async RPC completion handler
		  should mark the directories for revalidation.
 new dentry created? 
 Unhook entries from the cache 
 Remove from global LRU init 
 Found an entry, is our attribute cache valid? 
	 Only check the most recently returned cache entry,
	  but do it without locking.
	 The above field assignments must be visible
	  before this item appears on the lru.  We cannot easily
	  use rcu_assign_pointer, so just force the memory barrier.
 Update accounting 
 Add inode to global LRU list 
	
	  Determine which access bits we want to ask for...
 ONLY check exec rights 
 Is this sys_access() ? 
			
			  Optimize away all write operations, since the server
			  will check permissions when we perform the op.
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2014 Anna Schumaker <Anna.Schumaker@Netapp.com>
 offset  + \
 length )
 wr_callback_id size  +\
 wr_count  + \
 wr_committed  + \
 One cnr_source_server \
 nl4_type  \
 cr_consecutive  + \
 cr_synchronous )
 nl4_type  \
 cnr_lease_time \
 Support 1 cnr_source_server \
 nl4_type  \
 data_content4  + \
 data_info4.di_offset  + \
 data_info4.di_length )
 rpr_eof  + \
 rpr_contents count  + \
 offset  + \
 whence )
 eof  + \
 whence  + \
 offset  + \
 length )
 offset  + \
 length  + \
 opaque devaddr4 length  + \
 status  + 1 
 offset  + \
 length  + \
 Array size  + \
 src offset  + \
 dst offset  + \
 count )
 Not limited by NFS itself, limited by the generic xattr code 
  These values specify the maximum amount of data that is not
  associated with the extended attribute name or extended
  attribute list in the SETXATTR, GETXATTR and LISTXATTR
  respectively.
 consecutive = true 
 intra-ssc 
 no src server list 
 supporting 1 server 
 Encode layoutupdate4 
	
	  Only check against the page length here. The actual
	  requested length may be smaller, but that is only
	  checked against after possibly caching a valid reply.
	
	  RFC 8276 says to specify the full max length of the LISTXATTRS
	  XDR reply. Count is set to the XDR length of the names array
	  plus the EOF marker. So, add the cookie and the names count.
		
		  Special case: for LISTXATTRS, NFS4ERR_TOOSMALL
		  should be translated to ERANGE.
	
	  We have asked for enough room to encode the maximum number
	  of possible attribute names, so everything should fit.
	 
	  But, don't rely on that assumption. Just decode entries
	  until they don't fit anymore, just in case the server did
	  something odd.
  Encode ALLOCATE request
  Encode COPY request
  Encode OFFLOAD_CANEL request
  Encode COPY_NOTIFY request
  Encode DEALLOCATE request
  Encode READ_PLUS request
  Encode SEEK request
  Encode LAYOUTSTATS request
  Encode CLONE request
  Encode LAYOUTERROR request
 nl_type 
 netid string 
 uaddr string 
 cnr_lease_time 
 number of source addresses 
 Server returned an out-of-sequence extent 
  Decode ALLOCATE request
  Decode COPY response
  Decode OFFLOAD_CANCEL response
  Decode COPY_NOTIFY response
  Decode DEALLOCATE request
  Decode READ_PLUS request
  Decode SEEK request
  Decode LAYOUTSTATS request
  Decode CLONE request
  Decode LAYOUTERROR request
 __LINUX_FS_NFS_NFS4_2XDR_H 
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2014 Anna Schumaker <Anna.Schumaker@Netapp.com>
  nfs42_copy_dest_done - perform inode cache updates after clonecopy offload
  @inode: pointer to destination inode
  @pos: destination offset
  @len: copy length
  Punch a hole in the inode page cache, so that the NFS client will
  know to retrieve new data.
  Update the file size if necessary, and then mark the inode as having
  invalid cached values for change attribute, ctime, mtime and space used.
			
			  Mark the bad layout state as invalid, then retry
			  with the current stateid.
 Do we need to delay before resending? 
			
			  Mark the bad layout state as invalid, then retry
			  with the current stateid.
 Do we need to delay before resending? 
	
	  Normally, the caching is done one layer up, but for successful
	  RPCS, always cache the result here, even if the caller was
	  just querying the length, or if the reply was too big for
	  the caller. This avoids a second RPC in the case of the
	  common query-alloc-retrieve cycle for xattrs.
	 
	  Note that xattr_len is always capped to XATTR_SIZE_MAX.
	
	  The GETXATTR op has no length field in the call, and the
	  xattr data is at the end of the reply.
	 
	  There is no downside in using the page-aligned length. It will
	  allow receiving and caching xattrs that are too large for the
	  caller but still fit in the page-rounded value.
 SPDX-License-Identifier: GPL-2.0-only
  linuxfsnfsnamespace.c
  Copyright (C) 2005 Trond Myklebust <Trond.Myklebust@netapp.com>
  - Modified by David Howells <dhowells@redhat.com>
  NFS namespace
  nfs_path - reconstruct the path given an arbitrary dentry
  @base - used to return pointer to the end of devname part of path
  @dentry_in - pointer to dentry
  @buffer - result buffer
  @buflen_in - length of buffer
  @flags - options (see below)
  Helper function for constructing the server pathname
  by arbitrary hashed dentry.
  This is mainly for use in figuring out the path on the
  server side when automounting on top of an existing partition
  and in generating procmounts and friends.
  Supported flags:
  NFS_PATH_CANONICAL: ensure there is exactly one slash after
 		       the original device (export) name
 		       (if unset, the original name is returned verbatim)
 Strip off excess slashes in base string 
  nfs_d_automount - Handle crossing a mountpoint on the server
  @path - The mountpoint
  When we encounter a mountpoint on the server, we want to set up
  a mountpoint on the client too, to prevent inode numbers from
  colliding, and to allow "df" to work properly.
  On NFSv4, we also want to allow for the fact that different
  filesystems may be migrated to different servers in a failover
  situation, and that different filesystems may want to use
  different security flavours.
	 Open a new filesystem context, transferring parameters from the
	  parent superblock, including the network namespace.
 for submounts we want the same server; referrals will reassign 
 prevent immediate expiration 
  nfs_do_submount - set up mountpoint when crossing a filesystem boundary
  @fc: pointer to struct nfs_fs_context
 create a new volume representation 
 Look it up again to get its attributes 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  Get a unique NFSv4.0 callback identifier which will be used
  by the V4.0 callback service to lookup the nfs_client struct
  Per auth flavor data server rpc clients
 ds_clp->cl_ds_clients 
  nfs4_find_ds_client - Common lookup case for DS IO
  @ds_clp: pointer to the DS's nfs_client
  @flavor: rpc auth flavour to match
 need some lock to protect list 
  nfs4_find_or_create_ds_client - Find or create a DS rpc client
  @ds_clp: pointer to the DS's nfs_client
  @inode: pointer to the inode
  Find or create a DS rpc client with th MDS server rpc client auth flavor
  in the nfs_client cl_ds_clients list.
 CONFIG_NFS_V4_1 
	
	  Set up the connection to the server before we add add to the
	  global list.
 If no clientaddr= option was specified, find a usable cb address 
  Destroy the NFS4 callback service
  Initialize the NFS4 callback service
  nfs40_init_client - nfs_client initialization tasks for NFSv4.0
  @clp: nfs_client to initialize
  Returns zero on success, or a negative errno if some error occurred.
  nfs41_init_client - nfs_client initialization tasks for NFSv4.1+
  @clp: nfs_client to initialize
  Returns zero on success, or a negative errno if some error occurred.
	
	  Create the session and mark it expired.
	  When a SEQUENCE operation encounters the expired session
	  it will do session recovery to initialize it.
	
	  The create session reply races with the server back
	  channel probe. Mark the client NFS_CS_SESSION_INITING
	  so that the client back channel can find the
	  nfs_client struct
 CONFIG_NFS_V4_1 
  Initialize the minor version specific parts of an NFS4 client record
  nfs4_init_client - Initialise an NFS4 client record
  @clp: nfs_client to initialise
  @cl_init: pointer to nfs_client_initdata
  Returns pointer to an NFS client, or an ERR_PTR value.
 the client is initialised already 
		
		  Mark the client as having failed initialization so other
		  processes walking the nfs_client_list in nfs_match_client()
		  won't try to use it.
  SETCLIENTID just did a callback update with the callback ident in
  "drop," but server trunking discovery claims "drop" and "keep" are
  actually the same server.  Swap the callback IDs so that "keep"
  will continue to use the callback ident the server now knows about,
  and so that "keep"'s original callback ident is destroyed when
  "drop" is freed.
	 If "pos" isn't marked ready, we can't trust the
	  remaining fields in "pos", especially the client
	  ID and serverowner fields.  Wait for CREATE_SESSION
	 NFSv4.1 always uses the uniform string, however someone
	  might switch the uniquifier string on us.
  nfs40_walk_client_list - Find server that recognizes a client ID
  @new: nfs_client with client ID to test
  @result: OUT: found nfs_client, or new
  @cred: credential to use for trunking test
  Returns zero, a negative errno, or a negative NFS4ERR status.
  If zero is returned, an nfs_client pointer is planted in "result."
  NB: nfs40_walk_client_list() relies on the new nfs_client being
      the last nfs_client on the list.
		
		  We just sent a new SETCLIENTID, which should have
		  caused the server to return a new cl_confirm.  So if
		  cl_confirm is the same, then this is a different
		  server that just returned the same cl_confirm by
		  coincidence:
		
		  But if the cl_confirm's are different, then the only
		  way that a SETCLIENTID_CONFIRM to pos can succeed is
		  if new and pos point to the same server:
			 The callback path may have been inadvertently
			  changed. Schedule recovery!
 No match found. The server lost our clientid 
  Returns true if the server major ids match
  Returns true if the server scopes match
  nfs4_detect_session_trunking - Checks for session trunking.
  @clp:    original mount nfs_client
  @res:    result structure from an exchange_id using the original mount
           nfs_client with a new multi_addr transport
  @xprt:   pointer to the transport to add.
  Called after a successful EXCHANGE_ID on a multi-addr connection.
  Upon success, add the transport.
  Returns zero on success, otherwise -EINVAL
  Note: since the exchange_id for the new multi_addr transport uses the
  same nfs_client from the original mount, the cl_owner_id is reused,
  so eir_clientowner is the same.
 Check eir_clientid 
 Check eir_server_owner so_major_id 
 Check eir_server_owner so_minor_id 
 Check eir_server_scope 
  nfs41_walk_client_list - Find nfs_client that matches a clientserver owner
  @new: nfs_client with client ID to test
  @result: OUT: found nfs_client, or new
  @cred: credential to use for trunking test
  Returns zero, a negative errno, or a negative NFS4ERR status.
  If zero is returned, an nfs_client pointer is planted in "result."
  NB: nfs41_walk_client_list() relies on the new nfs_client being
      the last nfs_client on the list.
		
		  Note that session trunking is just a special subcase of
		  client id trunking. In either case, we want to fall back
		  to using the existing nfs_client.
 CONFIG_NFS_V4_1 
  NFSv4.0 callback thread helper
  Find a client by callback identifier
 Common match routine for v4.0 and v4.1 callback services 
 Don't match clients that failed to initialise 
 Match the version and minorversion 
 Match only the IP address, not the port number 
  NFSv4.1 callback thread helper
  For CB_COMPOUND calls, find a client by IP address, protocol version,
  minorversion, and sessionID
  Returns NULL if no such client
 Match sessionid
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
  Set up an NFS4 client
 Allocate or find a client reference we can use 
	
	  Query for the lease time on clientid setup or renewal
	 
	  Note that this will be set on nfs_clients that were created
	  only for the DS role and did not set this bit, but now will
	  serve a dual role.
  Set up a pNFS Data Server client.
  Return any existing nfs_client that matches server address,port,version
  and minorversion.
  For a new nfs_client, use a soft mount (default), a low retrans and a
  low timeout interval so that if a connection is lost, we retry through
  the MDS.
	
	  Set an authflavor equual to the MDS value. Use the MDS nfs_client
	  cl_ipaddr so as to use the same EXCHANGE_ID co_ownerid as the MDS
	  (section 13.1 RFC 5661).
  Session has been established, and the client marked ready.
  Limit the mount rsize, wsize and dtsize using negotiated fore
  channel attributes.
 CONFIG_NFS_V4_1 
  Limit xattr sizes using the channel attributes.
 Set the basic capabilities 
	
	  Don't use NFS uidgid mapping if we're using AUTH_SYS or lower
	  authentication.
 data servers support only a subset of NFSv4.1 
 We must ensure the session is initialised first 
 Probe the root fh to retrieve its FSID and filehandle 
  Create a version 4 volume record
 Initialise the client representation from the mount data 
	 Use the first specified auth flavor. If this flavor isn't
	  allowed by the server, use the SECINFO path to try the
 Get a client record 
  Create a version 4 volume record
  - keyed on server and FSID
 set up the general RPC client 
  Create an NFS4 referral server record
 Initialise the client representation from the parent server 
 Get a client representation 
 IS_ENABLED(CONFIG_SUNRPC_XPRT_RDMA) 
  nfs4_update_server - Move an nfs_server to a different nfs_client
  @server: represents FSID to be moved
  @hostname: new end-point's hostname
  @sap: new end-point's socket address
  @salen: size of "sap"
  @net: net namespace
  The nfs_server must be quiescent before this function is invoked.
  Either its session is drained (NFSv4.1+), or its transport is
  plugged and drained (NFSv4.0).
  Returns zero on success, or a negative errno value.
 SPDX-License-Identifier: GPL-2.0
  Copyright 2019, 2020 Amazon.com, Inc. or its affiliates. All rights reserved.
  User extended attribute client side cache functions.
  Author: Frank van der Linden <fllinden@amazon.com>
  User extended attributes client side caching is implemented by having
  a cache structure attached to NFS inodes. This structure is allocated
  when needed, and freed when the cache is zapped.
  The cache structure contains as hash table of entries, and a pointer
  to a special-cased entry for the listxattr cache.
  Accessing and allocating  freeing the caches is done via reference
  counting. The cache entries use a similar refcounting scheme.
  This makes freeing a cache, both from the shrinker and from the
  zap cache path, easy. It also means that, in current use cases,
  the large majority of inodes will not waste any memory, as they
  will never have any user extended attributes assigned to them.
  Attribute entries are hashed in to a simple hash table. They are
  also part of an LRU.
  There are three shrinkers.
  Two shrinkers deal with the cache entries themselves: one for
  large entries (> PAGE_SIZE), and one for smaller entries. The
  shrinker for the larger entries works more aggressively than
  those for the smaller entries.
  The other shrinker frees the cache structures themselves.
  64 buckets is a good default. There is likely no reasonable
  workload that uses more than even 64 user extended attributes.
  You can certainly add a lot more - but you get what you ask for
  in those circumstances.
  LRU list of NFS inodes that have xattr caches.
  Hashing helper functions.
  Locking order:
  1. inode i_lock or bucket lock
  2. list_lru lock (taken by list_lru_ functions)
  Wrapper functions to add a cache entry to the right LRU.
  This function allocates cache entries. They are the normal
  extended attribute namevalue pairs, but may also be a listxattr
  cache. Those allocations use the same entry so that they can be
  treated as one by the memory shrinker.
  xattr cache entries are allocated together with names. If the
  value fits in to one page with the entry structure and the name,
  it will also be part of the same allocation (kmalloc). This is
  expected to be the vast majority of cases. Larger allocations
  have a value pointer that is allocated separately by kvmalloc.
  Parameters:
  @name:  Name of the extended attribute. NULL for listxattr cache
          entry.
  @value: Value of attribute, or listxattr cache. NULL if the
          value is to be copied from pages instead.
  @pages: Pages to copy the value from, if not NULL. Passed in to
 	   make it easier to copy the value after an RPC, even if
 	   the value will not be passed up to application (e.g.
 	   for a 'query' getxattr with NULL buffer).
  @len:   Length of the value. Can be 0 for zero-length attributes.
          @value and @pages will be NULL if @len is 0.
  Set the listxattr cache, which is a special-cased cache entry.
  The special value ERR_PTR(-ESTALE) is used to indicate that
  the cache is being drained - this prevents a new listxattr
  cache from being added to what is now a stale cache.
  Unlink a cache from its parent inode, clearing out an invalid
  cache. Must be called with i_lock held.
  Discard a cache. Called by get_cache() if there was an old,
  invalid cache. Can also be called from a shrinker callback.
  The cache is dead, it has already been unlinked from its inode,
  and no longer appears on the cache LRU list.
  Mark all buckets as draining, so that no new entries are added. This
  could still happen in the unlikely, but possible case that another
  thread had grabbed a reference before it was unlinked from the inode,
  and is still holding it for an add operation.
  Remove all entries from the LRU lists, so that there is no longer
  any way to 'find' this cache. Then, remove the entries from the hash
  table.
  At that point, the cache will remain empty and can be freed when the final
  reference drops, which is very likely the kref_put at the end of
  this function, or the one called immediately afterwards in the
  shrinker callback.
  Get a referenced copy of the cache structure. Avoid doing allocs
  while holding i_lock. Which means that we do some optimistic allocation,
  and might have to free the result in rare cases.
  This function only checks the NFS_INO_INVALID_XATTR cache validity bit
  and acts accordingly, replacing the cache when needed. For the read case
  (!add), this means that the caller must make sure that the cache
  is valid before caling this function. getxattr and listxattr call
  revalidate_inode to do this. The attribute cache timeout (for the
  non-delegated case) is expected to be dealt with in the revalidate
  call.
			
			  The cache was invalidated again. Give up,
			  since what we want to enter is now likely
			  outdated anyway.
		
		  Check if someone beat us to it.
		
		  If there was a race, throw away the cache we just
		  allocated, and use the new one allocated by someone
		  else.
	
	  Discard the now orphaned old cache.
  Entry point to retrieve an entry from the cache.
 Length probe only 
  Retrieve a cached list of xattrs from the cache.
 Length probe only 
  Add an xattr to the cache.
  This also invalidates the xattr list cache.
  Remove an xattr from the cache.
  This also invalidates the xattr list cache.
  Cache listxattr output, replacing any possible old one.
	
	  This is just there to be able to get to bucket->cache,
	  which is obviously the same for all buckets, so just
	  use bucket 0.
  Zap the entire cache. Called when an inode is evicted.
  The entry LRU is shrunk more aggressively than the cache LRU,
  by settings @seeks to 1.
  Cache structures are freed only when they've become empty, after
  pruning all but one entry.
	
	  If a cache structure is on the LRU list, we know that
	  its inode is valid. Try to lock it to break the link.
	  Since we're inverting the lock order here, only try.
	
	  Unhook the entry from its parent (either a cache bucket
	  or a cache structure if it's a listxattr buf), so that
	  it's no longer found. Then add it to the isolate list,
	  to be freed later.
	 
	  In both cases, we're reverting lock order, so use
	  trylock and skip the entry if we can't get the lock.
 Regular cache entry 
 Listxattr cache entry 
		
		  Drop two references: the one that we just grabbed
		  in entry_lru_isolate, and the one that was set
		  when the entry was first allocated.
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfsnfs3xdr.c
  XDR functions to encodedecode NFSv3 RPC arguments and results.
  Copyright (C) 1996, 1997 Olaf Kirch
 Mapping from NFS error code to "errno" error code. 
  Declare the space requirements for NFS arguments and replies as
  number of 32bit-words
 Page padding 
 shorthand 
  Map file type to S_IFMT bits
  Encodedecode NFSv3 basic data types
  Basic NFSv3 data types are defined in section 2.5 of RFC 1813:
  "NFS Version 3 Protocol Specification".
  Not all basic data types have their own encoding and decoding
  functions.  For run-time efficiency, some data types are encoded
  or decoded inline.
  fileid3
 	typedef uint64 fileid3;
  filename3
 	typedef string filename3<>;
  nfspath3
 	typedef string nfspath3<>;
  cookie3
 	typedef uint64 cookie3
  cookieverf3
 	typedef opaque cookieverf3[NFS3_COOKIEVERFSIZE];
  createverf3
 	typedef opaque createverf3[NFS3_CREATEVERFSIZE];
  size3
 	typedef uint64 size3;
  nfsstat3
 	enum nfsstat3 {
 		NFS3_OK = 0,
 		...
 	}
  ftype3
 	enum ftype3 {
 		NF3REG	= 1,
 		NF3DIR	= 2,
 		NF3BLK	= 3,
 		NF3CHR	= 4,
 		NF3LNK	= 5,
 		NF3SOCK	= 6,
 		NF3FIFO	= 7
 	};
  specdata3
      struct specdata3 {
              uint32  specdata1;
              uint32  specdata2;
      };
  nfs_fh3
 	struct nfs_fh3 {
 		opaque       data<NFS3_FHSIZE>;
 	};
  nfstime3
 	struct nfstime3 {
 		uint32	seconds;
 		uint32	nseconds;
 	};
  sattr3
 	enum time_how {
 		DONT_CHANGE		= 0,
 		SET_TO_SERVER_TIME	= 1,
 		SET_TO_CLIENT_TIME	= 2
 	};
 	union set_mode3 switch (bool set_it) {
 	case TRUE:
 		mode3	mode;
 	default:
 		void;
 	};
 	union set_uid3 switch (bool set_it) {
 	case TRUE:
 		uid3	uid;
 	default:
 		void;
 	};
 	union set_gid3 switch (bool set_it) {
 	case TRUE:
 		gid3	gid;
 	default:
 		void;
 	};
 	union set_size3 switch (bool set_it) {
 	case TRUE:
 		size3	size;
 	default:
 		void;
 	};
 	union set_atime switch (time_how set_it) {
 	case SET_TO_CLIENT_TIME:
 		nfstime3	atime;
 	default:
 		void;
 	};
 	union set_mtime switch (time_how set_it) {
 	case SET_TO_CLIENT_TIME:
 		nfstime3  mtime;
 	default:
 		void;
 	};
 	struct sattr3 {
 		set_mode3	mode;
 		set_uid3	uid;
 		set_gid3	gid;
 		set_size3	size;
 		set_atime	atime;
 		set_mtime	mtime;
 	};
	
	  In order to make only a single xdr_reserve_space() call,
	  pre-compute the total number of bytes to be reserved.
	  Six boolean values, one for each set_foo field, are always
	  present in the encoded result, so start there.
  fattr3
 	struct fattr3 {
 		ftype3		type;
 		mode3		mode;
 		uint32		nlink;
 		uid3		uid;
 		gid3		gid;
 		size3		size;
 		size3		used;
 		specdata3	rdev;
 		uint64		fsid;
 		fileid3		fileid;
 		nfstime3	atime;
 		nfstime3	mtime;
 		nfstime3	ctime;
 	};
  post_op_attr
 	union post_op_attr switch (bool attributes_follow) {
 	case TRUE:
 		fattr3	attributes;
 	case FALSE:
 		void;
 	};
  wcc_attr
 	struct wcc_attr {
 		size3		size;
 		nfstime3	mtime;
 		nfstime3	ctime;
 	};
  pre_op_attr
 	union pre_op_attr switch (bool attributes_follow) {
 	case TRUE:
 		wcc_attr	attributes;
 	case FALSE:
 		void;
 	};
  wcc_data
 	struct wcc_data {
 		pre_op_attr	before;
 		post_op_attr	after;
 	};
  post_op_fh3
 	union post_op_fh3 switch (bool handle_follows) {
 	case TRUE:
 		nfs_fh3  handle;
 	case FALSE:
 		void;
 	};
  diropargs3
 	struct diropargs3 {
 		nfs_fh3		dir;
 		filename3	name;
 	};
  NFSv3 XDR encode functions
  NFSv3 argument types are defined in section 3.3 of RFC 1813:
  "NFS Version 3 Protocol Specification".
  3.3.1  GETATTR3args
 	struct GETATTR3args {
 		nfs_fh3  object;
 	};
  3.3.2  SETATTR3args
 	union sattrguard3 switch (bool check) {
 	case TRUE:
 		nfstime3  obj_ctime;
 	case FALSE:
 		void;
 	};
 	struct SETATTR3args {
 		nfs_fh3		object;
 		sattr3		new_attributes;
 		sattrguard3	guard;
 	};
  3.3.3  LOOKUP3args
 	struct LOOKUP3args {
 		diropargs3  what;
 	};
  3.3.4  ACCESS3args
 	struct ACCESS3args {
 		nfs_fh3		object;
 		uint32		access;
 	};
  3.3.5  READLINK3args
 	struct READLINK3args {
 		nfs_fh3	symlink;
 	};
  3.3.6  READ3args
 	struct READ3args {
 		nfs_fh3		file;
 		offset3		offset;
 		count3		count;
 	};
  3.3.7  WRITE3args
 	enum stable_how {
 		UNSTABLE  = 0,
 		DATA_SYNC = 1,
 		FILE_SYNC = 2
 	};
 	struct WRITE3args {
 		nfs_fh3		file;
 		offset3		offset;
 		count3		count;
 		stable_how	stable;
 		opaque		data<>;
 	};
  3.3.8  CREATE3args
 	enum createmode3 {
 		UNCHECKED = 0,
 		GUARDED   = 1,
 		EXCLUSIVE = 2
 	};
 	union createhow3 switch (createmode3 mode) {
 	case UNCHECKED:
 	case GUARDED:
 		sattr3       obj_attributes;
 	case EXCLUSIVE:
 		createverf3  verf;
 	};
 	struct CREATE3args {
 		diropargs3	where;
 		createhow3	how;
 	};
  3.3.9  MKDIR3args
 	struct MKDIR3args {
 		diropargs3	where;
 		sattr3		attributes;
 	};
  3.3.10  SYMLINK3args
 	struct symlinkdata3 {
 		sattr3		symlink_attributes;
 		nfspath3	symlink_data;
 	};
 	struct SYMLINK3args {
 		diropargs3	where;
 		symlinkdata3	symlink;
 	};
  3.3.11  MKNOD3args
 	struct devicedata3 {
 		sattr3		dev_attributes;
 		specdata3	spec;
 	};
 	union mknoddata3 switch (ftype3 type) {
 	case NF3CHR:
 	case NF3BLK:
 		devicedata3	device;
 	case NF3SOCK:
 	case NF3FIFO:
 		sattr3		pipe_attributes;
 	default:
 		void;
 	};
 	struct MKNOD3args {
 		diropargs3	where;
 		mknoddata3	what;
 	};
  3.3.12  REMOVE3args
 	struct REMOVE3args {
 		diropargs3  object;
 	};
  3.3.14  RENAME3args
 	struct RENAME3args {
 		diropargs3	from;
 		diropargs3	to;
 	};
  3.3.15  LINK3args
 	struct LINK3args {
 		nfs_fh3		file;
 		diropargs3	link;
 	};
  3.3.16  READDIR3args
 	struct READDIR3args {
 		nfs_fh3		dir;
 		cookie3		cookie;
 		cookieverf3	cookieverf;
 		count3		count;
 	};
  3.3.17  READDIRPLUS3args
 	struct READDIRPLUS3args {
 		nfs_fh3		dir;
 		cookie3		cookie;
 		cookieverf3	cookieverf;
 		count3		dircount;
 		count3		maxcount;
 	};
	
	  readdirplus: need dircount + buffer size.
	  We just make sure we make dircount big enough
  3.3.21  COMMIT3args
 	struct COMMIT3args {
 		nfs_fh3		file;
 		offset3		offset;
 		count3		count;
 	};
 FIXME: this is just broken 
 CONFIG_NFS_V3_ACL 
  NFSv3 XDR decode functions
  NFSv3 result types are defined in section 3.3 of RFC 1813:
  "NFS Version 3 Protocol Specification".
  3.3.1  GETATTR3res
 	struct GETATTR3resok {
 		fattr3		obj_attributes;
 	};
 	union GETATTR3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		GETATTR3resok  resok;
 	default:
 		void;
 	};
  3.3.2  SETATTR3res
 	struct SETATTR3resok {
 		wcc_data  obj_wcc;
 	};
 	struct SETATTR3resfail {
 		wcc_data  obj_wcc;
 	};
 	union SETATTR3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		SETATTR3resok   resok;
 	default:
 		SETATTR3resfail resfail;
 	};
  3.3.3  LOOKUP3res
 	struct LOOKUP3resok {
 		nfs_fh3		object;
 		post_op_attr	obj_attributes;
 		post_op_attr	dir_attributes;
 	};
 	struct LOOKUP3resfail {
 		post_op_attr	dir_attributes;
 	};
 	union LOOKUP3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		LOOKUP3resok	resok;
 	default:
 		LOOKUP3resfail	resfail;
 	};
  3.3.4  ACCESS3res
 	struct ACCESS3resok {
 		post_op_attr	obj_attributes;
 		uint32		access;
 	};
 	struct ACCESS3resfail {
 		post_op_attr	obj_attributes;
 	};
 	union ACCESS3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		ACCESS3resok	resok;
 	default:
 		ACCESS3resfail	resfail;
 	};
  3.3.5  READLINK3res
 	struct READLINK3resok {
 		post_op_attr	symlink_attributes;
 		nfspath3	data;
 	};
 	struct READLINK3resfail {
 		post_op_attr	symlink_attributes;
 	};
 	union READLINK3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		READLINK3resok	resok;
 	default:
 		READLINK3resfail resfail;
 	};
  3.3.6  READ3res
 	struct READ3resok {
 		post_op_attr	file_attributes;
 		count3		count;
 		bool		eof;
 		opaque		data<>;
 	};
 	struct READ3resfail {
 		post_op_attr	file_attributes;
 	};
 	union READ3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		READ3resok	resok;
 	default:
 		READ3resfail	resfail;
 	};
  3.3.7  WRITE3res
 	enum stable_how {
 		UNSTABLE  = 0,
 		DATA_SYNC = 1,
 		FILE_SYNC = 2
 	};
 	struct WRITE3resok {
 		wcc_data	file_wcc;
 		count3		count;
 		stable_how	committed;
 		writeverf3	verf;
 	};
 	struct WRITE3resfail {
 		wcc_data	file_wcc;
 	};
 	union WRITE3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		WRITE3resok	resok;
 	default:
 		WRITE3resfail	resfail;
 	};
  3.3.8  CREATE3res
 	struct CREATE3resok {
 		post_op_fh3	obj;
 		post_op_attr	obj_attributes;
 		wcc_data	dir_wcc;
 	};
 	struct CREATE3resfail {
 		wcc_data	dir_wcc;
 	};
 	union CREATE3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		CREATE3resok	resok;
 	default:
 		CREATE3resfail	resfail;
 	};
	 The server isn't required to return a file handle.
	  If it didn't, force the client to perform a LOOKUP
	  to determine the correct file handle and attribute
  3.3.12  REMOVE3res
 	struct REMOVE3resok {
 		wcc_data    dir_wcc;
 	};
 	struct REMOVE3resfail {
 		wcc_data    dir_wcc;
 	};
 	union REMOVE3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		REMOVE3resok   resok;
 	default:
 		REMOVE3resfail resfail;
 	};
  3.3.14  RENAME3res
 	struct RENAME3resok {
 		wcc_data	fromdir_wcc;
 		wcc_data	todir_wcc;
 	};
 	struct RENAME3resfail {
 		wcc_data	fromdir_wcc;
 		wcc_data	todir_wcc;
 	};
 	union RENAME3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		RENAME3resok   resok;
 	default:
 		RENAME3resfail resfail;
 	};
  3.3.15  LINK3res
 	struct LINK3resok {
 		post_op_attr	file_attributes;
 		wcc_data	linkdir_wcc;
 	};
 	struct LINK3resfail {
 		post_op_attr	file_attributes;
 		wcc_data	linkdir_wcc;
 	};
 	union LINK3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		LINK3resok	resok;
 	default:
 		LINK3resfail	resfail;
 	};
  nfs3_decode_dirent - Decode a single NFSv3 directory entry stored in
 			the local page cache
  @xdr: XDR stream where entry resides
  @entry: buffer to fill in with entry data
  @plus: boolean indicating whether this should be a readdirplus entry
  Returns zero if successful, otherwise a negative errno value is
  returned.
  This function is not invoked during READDIR reply decoding, but
  rather whenever an application invokes the getdents(2) system call
  on a directory already in our cache.
  3.3.16  entry3
 	struct entry3 {
 		fileid3		fileid;
 		filename3	name;
 		cookie3		cookie;
 		fhandle3	filehandle;
 		post_op_attr3	attributes;
 		entry3		nextentry;
 	};
  3.3.17  entryplus3
 	struct entryplus3 {
 		fileid3		fileid;
 		filename3	name;
 		cookie3		cookie;
 		post_op_attr	name_attributes;
 		post_op_fh3	name_handle;
 		entryplus3	nextentry;
 	};
 In fact, a post_op_fh3: 
  3.3.16  READDIR3res
 	struct dirlist3 {
 		entry3		entries;
 		bool		eof;
 	};
 	struct READDIR3resok {
 		post_op_attr	dir_attributes;
 		cookieverf3	cookieverf;
 		dirlist3	reply;
 	};
 	struct READDIR3resfail {
 		post_op_attr	dir_attributes;
 	};
 	union READDIR3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		READDIR3resok	resok;
 	default:
 		READDIR3resfail	resfail;
 	};
  Read the directory contents into the page cache, but otherwise
  don't touch them.  The actual decoding is done by nfs3_decode_entry()
  during subsequent nfs_readdir() calls.
 XXX: do we need to check if result->verf != NULL ? 
  3.3.18  FSSTAT3res
 	struct FSSTAT3resok {
 		post_op_attr	obj_attributes;
 		size3		tbytes;
 		size3		fbytes;
 		size3		abytes;
 		size3		tfiles;
 		size3		ffiles;
 		size3		afiles;
 		uint32		invarsec;
 	};
 	struct FSSTAT3resfail {
 		post_op_attr	obj_attributes;
 	};
 	union FSSTAT3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		FSSTAT3resok	resok;
 	default:
 		FSSTAT3resfail	resfail;
 	};
 ignore invarsec 
  3.3.19  FSINFO3res
 	struct FSINFO3resok {
 		post_op_attr	obj_attributes;
 		uint32		rtmax;
 		uint32		rtpref;
 		uint32		rtmult;
 		uint32		wtmax;
 		uint32		wtpref;
 		uint32		wtmult;
 		uint32		dtpref;
 		size3		maxfilesize;
 		nfstime3	time_delta;
 		uint32		properties;
 	};
 	struct FSINFO3resfail {
 		post_op_attr	obj_attributes;
 	};
 	union FSINFO3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		FSINFO3resok	resok;
 	default:
 		FSINFO3resfail	resfail;
 	};
 ignore properties 
  3.3.20  PATHCONF3res
 	struct PATHCONF3resok {
 		post_op_attr	obj_attributes;
 		uint32		linkmax;
 		uint32		name_max;
 		bool		no_trunc;
 		bool		chown_restricted;
 		bool		case_insensitive;
 		bool		case_preserving;
 	};
 	struct PATHCONF3resfail {
 		post_op_attr	obj_attributes;
 	};
 	union PATHCONF3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		PATHCONF3resok	resok;
 	default:
 		PATHCONF3resfail resfail;
 	};
 ignore remaining fields 
  3.3.21  COMMIT3res
 	struct COMMIT3resok {
 		wcc_data	file_wcc;
 		writeverf3	verf;
 	};
 	struct COMMIT3resfail {
 		wcc_data	file_wcc;
 	};
 	union COMMIT3res switch (nfsstat3 status) {
 	case NFS3_OK:
 		COMMIT3resok	resok;
 	default:
 		COMMIT3resfail	resfail;
 	};
 CONFIG_NFS_V3_ACL 
  We need to translate between nfs status return values and
  the local errno values which may not be the same.
	{ NFSERR_EAGAIN,	-EAGAIN		}, 
  nfs3_stat_to_errno - convert an NFS status code to a local errno
  @status: NFS status code to convert
  Returns a local errno value, or -EIO if the NFS status code is
  not recognized.  This function is used jointly by NFSv2 and NFSv3.
 CONFIG_NFS_V3_ACL 
 SPDX-License-Identifier: GPL-2.0-only
  linuxfsnfsread.c
  Block IO for NFS
  Partial copy of Linus' read cache modifications to fsnfsfile.c
  modified for async RPC by okir@monad.swb.de
 It doesn't make sense to do mirrored reads! 
 read path should never have more than one mirror 
			 note: regions of the page not covered by a
				 nothing in this request was good, so zero
				 part of this request has good bytes, but
  This is the callback from RPC telling us whether a reply was
  received or some error occurred (timeout or socket shutdown).
 This is a short read! 
 Has the server at least made some progress? 
 For non rpc-based layout drivers, retry-through-MDS 
 Yes, so retry the read at the end of the hdr 
  Read a page over NFS.
  We read the page synchronously in the following case:
   -	The error flag is set for this page. This happens only when a
 	previous async read operation failed.
	
	  Try to flush any pending writes to the file..
	 
	  NOTE! Because we own the page lock, there cannot
	  be any new pending writes generated at this point
	  for this page (other pages can be written to).
	 attempt to read as many of the pages as possible from the cache
	  - this returns -ENOBUFS immediately if the cookie is negative
 all pages were read 
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfssysctl.c
  Sysctl interface to NFS parameters
 SPDX-License-Identifier: GPL-2.0-or-later
 client.c: NFS client sharing and management code
  Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  RPC cruft for NFS
  Allocate a shared client record
  Since these are allocateddeallocated very rarely, we don't
  bother putting them in a slab cache...
 nfs_client_lock held 
 CONFIG_NFS_V4 
  Destroy a shared client record
 -EIO all pending IO 
  Release a reference to a shared client record
  Find an nfs_client on the list that matches the initialisation data
  that is supplied.
 Don't match clients that failed to initialise properly 
 If a client is still initializing then we need to wait 
 Different NFS versions cannot share the same nfs_client 
 Match nfsv4 minorversion 
 Match request for a dedicated DS 
 Match the full socket address 
 Match all xprt_switch full socket addresses 
  Return true if @clp is done initializing, false if still working on it.
  Use nfs_client_init_status to check if it was successful.
  Return 0 if @clp was successfully initialized, -errno otherwise.
  This must be called after nfs_client_init_is_complete() returns true,
  otherwise it will pop WARN_ON_ONCE and return -EINVAL
 called without checking nfs_client_init_is_complete 
  Found an existing client.  Make sure it's ready before returning.
  Look up a client by IP address and protocol version
  - creates a new record if one doesn't yet exist
 see if the client already exists 
  Mark a server as ready or failed
  Initialise the timeout values for a connection
  Create an RPC client handle
  Version 2 or 3 client destruction
  Version 2 or 3 lockd setup
  Create a general RPC client
  nfs_init_client - Initialise an NFS2 or NFS3 client
  @clp: nfs_client to initialise
  @cl_init: Initialisation parameters
  Returns pointer to an NFS client, or an ERR_PTR value.
 the client is already initialised 
	
	  Create a client RPC handle for doing FSSTAT with UNIX auth only
	  - RFC 2623, sec 2.3.2
  Create a version 2 or 3 client
 Allocate or find a client reference we can use 
 Initialise the client representation from the mount data 
 Start lockd here, before we might error out 
 Preserve the values of mount_server-related mount options 
  Load up the server record from information gained in an fsinfo record
 Work out a lot of parameters 
 We're airborne Set socket buffersize 
	
	  Defaults until limited by the session parameters.
  Probe filesystem information, including the FSID on v2v3
 Get some general file system info 
  Grab the destination's particulars, including lease expiry time.
  Returns zero if probe succeeded and retrieved FSID matches the FSID
  we have cached.
	 Sanity: the probe won't work if the destination server
  Copy useful information when duplicating a server record
  Allocate and initialise a server record
 Zero out the NFS state stuff 
  Free up a server record
  Create a version 2 or 3 volume record
  - keyed on server and FSID
 Get a client representation 
 Probe the root fh to retrieve its FSID 
  Clone an NFS2, NFS3 or NFS4 server record
 Copy data from the source 
 probe the filesystem info for this server filesystem 
  set up the iterator to start reading from the server list and return the first item
 lock the list against modification 
  move to next server
  clean up after reading from the transports list
  display a header line followed by a load of call lines
 display header on line 1 
 display one transport per line on subsequent lines 
 Check if the client is initialized 
  set up the iterator to start reading from the volume list and return the first item
 lock the list against modification 
  move to next volume
  clean up after reading from the transports list
  display a header line followed by a load of call lines
 8 for 2^24, 1 for ':', 3 for 2^8, 1 for '\0'
 2  16 for %llx, 1 for ':', 1 for '\0'
 display header on line 1 
 display one transport per line on subsequent lines 
 a file of servers with which we're dealing 
 a file of volumes that we have mounted 
  initialise the procfsnfsfs directory
 a file of servers with which we're dealing 
 a file of volumes that we have mounted 
  clean up the procfsnfsfs directory
 CONFIG_PROC_FS 
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (c) 2012 Netapp, Inc. All rights reserved.
 SPDX-License-Identifier: GPL-2.0
   linuxfsnfsnfs3proc.c
   Client-side NFSv3 procedures stubs.
   Copyright (C) 1997, Olaf Kirch
 A wrapper to handle the EJUKEBOX error messages 
  Bare-bones access to getattr: this is for nfs_get_rootnfs_get_sb
  One function for each procedure in the NFS protocol.
 Is this is an attribute revalidation, subject to softreval? 
 Is this is an attribute revalidation, subject to softreval? 
  Create a regular file.
		 If the server doesn't support the exclusive creation
	 When we created the file with exclusive semantics, make
		 Note: we could use a guarded setattr here, but I'm
		  not sure this buys us anything (and I'd have
  The READDIR implementation is somewhat hackish - we pass the user buffer
  to the encode function, which installs it in the receive iovec.
  The decode function itself doesn't perform any decoding, it just makes
  sure the reply is syntactically correct.
  Also note that this implementation handles both plain readdir and
  readdirplus.
  Bare-bones access to fsinfo: this is for nfs_get_rootnfs_get_sb via
  nfs_create_server
 protocol version 
 SPDX-License-Identifier: GPL-2.0-or-later
 NFS filesystem cache interface
  Copyright (C) 2008 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  Layout of the key for an NFS server cache object.
 NFS protocol version 
 NFSv4 minor version 
 address family 
 IP port 
 IPv4 address 
 IPv6 address 
  Get the per-client index cookie for an NFS client if the appropriate mount
  flag was set
  - We always try and get an index cookie for the client, but get filehandle
    cookies on a per-superblock basis, depending on the mount flags
 create a cache index for looking up filehandles 
  Dispose of a per-client cookie
  Get the cache cookie for an NFS superblock.  We have to handle
  uniquification here because the cache doesn't do it for us.
  The default uniquifier is just an empty string, but it may be overridden
  either by the 'fsc=xxx' option to mount, or by inheriting it from the parent
  superblock across an automount point of some nature.
 create a cache index for looking up filehandles 
  release a per-superblock cookie
  Initialise the per-inode cache cookie pointer for an NFS inode.
  Release a per-inode cookie.
  Enable or disable caching for a file that is being opened as appropriate.
  The cookie is allocated when the inode is initialised, but is not enabled at
  that time.  Enablement is deferred to file-open time to avoid stat() and
  access() thrashing the cache.
  For now, with NFS, only regular files that are open read-only will be able
  to use the cache.
  We enable the cache for an inode if we open it read-only and it isn't
  currently open for writing.  We disable the cache if the inode is open
  write-only.
  The caller uses the file struct to pin i_writecount on the inode before
  calling us when a file is opened for writing, so we can make use of that.
  Note that this may be invoked multiple times in parallel by parallel
  nfs_open() functions.
  Release the caching state associated with a page, if the page isn't busy
  interacting with the cache.
  - Returns true (can release page) or false (page busy).
  Release the caching state associated with a page if undergoing complete page
  invalidation.
  Handle completion of a page being read from the cache.
  - Called in process (keventd) context.
	
	  If the read completes with an error, mark the page with PG_checked,
	  unlock the page, and let the VM reissue the readpage.
  Retrieve a page from fscache
 read BIO submitted (page in fscache) 
 inode not in cache 
 page not in cache 
  Retrieve a set of pages from fscache
 read submitted to the cache for all pages 
 some pages aren't cached and can't be 
 some pages aren't cached 
  Store a newly fetched page in fscache
  - PG_fscache must be set on the page
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfsnfs2xdr.c
  XDR functions to encodedecode NFS RPC arguments and results.
  Copyright (C) 1992, 1993, 1994  Rick Sladkey
  Copyright (C) 1996 Olaf Kirch
  04 Aug 1998  Ion Badulescu <ionut@cs.columbia.edu>
  		FIFO's need special handling in NFSv2
 Mapping from NFS error code to "errno" error code. 
  Declare the space requirements for NFS arguments and replies as
  number of 32bit-words
 Page padding 
  Encodedecode NFSv2 basic data types
  Basic NFSv2 data types are defined in section 2.3 of RFC 1094:
  "NFS: Network File System Protocol Specification".
  Not all basic data types have their own encoding and decoding
  functions.  For run-time efficiency, some data types are encoded
  or decoded inline.
 	typedef opaque	nfsdata<>;
 NFSv2 does not pass EOF flag on the wire. 
 	enum stat {
 		NFS_OK = 0,
 		NFSERR_PERM = 1,
 		NFSERR_NOENT = 2,
 		NFSERR_IO = 5,
 		NFSERR_NXIO = 6,
 		NFSERR_ACCES = 13,
 		NFSERR_EXIST = 17,
 		NFSERR_NODEV = 19,
 		NFSERR_NOTDIR = 20,
 		NFSERR_ISDIR = 21,
 		NFSERR_FBIG = 27,
 		NFSERR_NOSPC = 28,
 		NFSERR_ROFS = 30,
 		NFSERR_NAMETOOLONG = 63,
 		NFSERR_NOTEMPTY = 66,
 		NFSERR_DQUOT = 69,
 		NFSERR_STALE = 70,
 		NFSERR_WFLUSH = 99
 	};
  2.3.2.  ftype
 	enum ftype {
 		NFNON = 0,
 		NFREG = 1,
 		NFDIR = 2,
 		NFBLK = 3,
 		NFCHR = 4,
 		NFLNK = 5
 	};
  2.3.3.  fhandle
 	typedef opaque fhandle[FHSIZE];
  2.3.4.  timeval
 	struct timeval {
 		unsigned int seconds;
 		unsigned int useconds;
 	};
  Passing the invalid value useconds=1000000 is a Sun convention for
  "set to current server time".  It's needed to make permissions checks
  for the "touch" program across v2 mounts to Solaris and Irix servers
  work correctly.  See description of sattr in section 6.1 of "NFS
  Illustrated" by Brent Callaghan, Addison-Wesley, ISBN 0-201-32750-5.
  2.3.5.  fattr
 	struct fattr {
 		ftype		type;
 		unsigned int	mode;
 		unsigned int	nlink;
 		unsigned int	uid;
 		unsigned int	gid;
 		unsigned int	size;
 		unsigned int	blocksize;
 		unsigned int	rdev;
 		unsigned int	blocks;
 		unsigned int	fsid;
 		unsigned int	fileid;
 		timeval		atime;
 		timeval		mtime;
 		timeval		ctime;
 	};
  2.3.6.  sattr
 	struct sattr {
 		unsigned int	mode;
 		unsigned int	uid;
 		unsigned int	gid;
 		unsigned int	size;
 		timeval		atime;
 		timeval		mtime;
 	};
  2.3.7.  filename
 	typedef string filename<MAXNAMLEN>;
  2.3.8.  path
 	typedef string path<MAXPATHLEN>;
  2.3.9.  attrstat
 	union attrstat switch (stat status) {
 	case NFS_OK:
 		fattr attributes;
 	default:
 		void;
 	};
  2.3.10.  diropargs
 	struct diropargs {
 		fhandle  dir;
 		filename name;
 	};
  2.3.11.  diropres
 	union diropres switch (stat status) {
 	case NFS_OK:
 		struct {
 			fhandle file;
 			fattr   attributes;
 		} diropok;
 	default:
 		void;
 	};
  NFSv2 XDR encode functions
  NFSv2 argument types are defined in section 2.2 of RFC 1094:
  "NFS: Network File System Protocol Specification".
  2.2.3.  sattrargs
 	struct sattrargs {
 		fhandle file;
 		sattr attributes;
 	};
  2.2.7.  readargs
 	struct readargs {
 		fhandle file;
 		unsigned offset;
 		unsigned count;
 		unsigned totalcount;
 	};
  2.2.9.  writeargs
 	struct writeargs {
 		fhandle file;
 		unsigned beginoffset;
 		unsigned offset;
 		unsigned totalcount;
 		nfsdata data;
 	};
 nfsdata 
  2.2.10.  createargs
 	struct createargs {
 		diropargs where;
 		sattr attributes;
 	};
  2.2.12.  renameargs
 	struct renameargs {
 		diropargs from;
 		diropargs to;
 	};
  2.2.13.  linkargs
 	struct linkargs {
 		fhandle from;
 		diropargs to;
 	};
  2.2.14.  symlinkargs
 	struct symlinkargs {
 		diropargs from;
 		path to;
 		sattr attributes;
 	};
  2.2.17.  readdirargs
 	struct readdirargs {
 		fhandle dir;
 		nfscookie cookie;
 		unsigned count;
 	};
  NFSv2 XDR decode functions
  NFSv2 result types are defined in section 2.2 of RFC 1094:
  "NFS: Network File System Protocol Specification".
  2.2.6.  readlinkres
 	union readlinkres switch (stat status) {
 	case NFS_OK:
 		path data;
 	default:
 		void;
 	};
  2.2.7.  readres
 	union readres switch (stat status) {
 	case NFS_OK:
 		fattr attributes;
 		nfsdata data;
 	default:
 		void;
 	};
 All NFSv2 writes are "file sync" writes 
  nfs2_decode_dirent - Decode a single NFSv2 directory entry stored in
                       the local page cache.
  @xdr: XDR stream where entry resides
  @entry: buffer to fill in with entry data
  @plus: boolean indicating whether this should be a readdirplus entry
  Returns zero if successful, otherwise a negative errno value is
  returned.
  This function is not invoked during READDIR reply decoding, but
  rather whenever an application invokes the getdents(2) system call
  on a directory already in our cache.
  2.2.17.  entry
 	struct entry {
 		unsigned	fileid;
 		filename	name;
 		nfscookie	cookie;
 		entry		nextentry;
 	};
	
	  The type (size and byte order) of nfscookie isn't defined in
	  RFC 1094.  This implementation assumes that it's an XDR uint32.
  2.2.17.  readdirres
 	union readdirres switch (stat status) {
 	case NFS_OK:
 		struct {
 			entry entries;
 			bool eof;
 		} readdirok;
 	default:
 		void;
 	};
  Read the directory contents into the page cache, but don't
  touch them.  The actual decoding is done by nfs2_decode_dirent()
  during subsequent nfs_readdir() calls.
  2.2.18.  statfsres
 	union statfsres (stat status) {
 	case NFS_OK:
 		struct {
 			unsigned tsize;
 			unsigned bsize;
 			unsigned blocks;
 			unsigned bfree;
 			unsigned bavail;
 		} info;
 	default:
 		void;
 	};
  We need to translate between nfs status return values and
  the local errno values which may not be the same.
	{ NFSERR_EAGAIN,	-EAGAIN		}, 
  nfs_stat_to_errno - convert an NFS status code to a local errno
  @status: NFS status code to convert
  Returns a local errno value, or -EIO if the NFS status code is
  not recognized.  This function is used jointly by NFSv2 and NFSv3.
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfsdns_resolve.c
  Copyright (c) 2009 Trond Myklebust <Trond.Myklebust@netapp.com>
  Resolves DNS hostnames into valid ip addresses
 SPDX-License-Identifier: GPL-2.0-only
  fsnfsnfs4session.c
  Copyright (c) 2012 Trond Myklebust <Trond.Myklebust@netapp.com>
  nfs4_shrink_slot_table - free retired slots from the slot table
  nfs4_slot_tbl_drain_complete - wake waiters when drain is complete
  @tbl: controlling slot table
  nfs4_free_slot - free a slot and efficiently update slot table.
  freeing a slot is trivially done by clearing its respective bit
  in the bitmap.
  If the freed slotid equals highest_used_slotid we want to update it
  so that the server would be able to size down the slot table if needed,
  otherwise we know that the highest_used_slotid is still in use.
  When updating highest_used_slotid there may be "holes" in the bitmap
  so we need to scan down from highest_used_slotid to 0 looking for the now
  highest slotid in use.
  If none found, highest_used_slotid is set to NFS4_NO_SLOT.
  Must be called while holding tbl->slot_tbl_lock
 clear used bit in bitmap 
 update highest_used_slotid when it is freed 
  nfs4_try_to_lock_slot - Given a slot try to allocate it
  Note: must be called with the slot_tbl_lock held.
  nfs4_lookup_slot - Find a slot but don't allocate it
  Note: must be called with the slot_tbl_lock held.
  nfs4_slot_seqid_in_use - test if a slot sequence id is still in use
  Given a slot table, slot id and sequence number, determine if the
  RPC call in question is still in flight. This function is mainly
  intended for use by the callback channel.
  nfs4_slot_wait_on_seqid - wait until a slot sequence id is complete
  Given a slot table, slot id and sequence number, wait until the
  corresponding RPC call completes. This function is mainly
  intended for use by the callback channel.
  nfs4_alloc_slot - efficiently look for a free slot
  nfs4_alloc_slot looks for an unset bit in the used_slots bitmap.
  If found, we mark the slot as used, update the highest_used_slotid,
  and respectively set up the sequence operation args.
  Note: must be called with under the slot_tbl_lock.
  (re)Initialise a slot table
  nfs4_release_slot_table - release all slot table entries
  nfs4_shutdown_slot_table - release resources attached to a slot table
  @tbl: slot table to shut down
  nfs4_setup_slot_table - prepare a stand-alone slot table for use
  @tbl: slot table to set up
  @max_reqs: maximum number of requests allowed
  @queue: name to give RPC wait queue
  Returns zero on success, or a negative errno.
 Update the client's idea of target_highest_slotid 
 Deallocate slots 
 Try to eliminate outliers by checking for sharp changes in the
  derivatives and second derivatives
 Is first derivative same sign? 
 Is second derivative same sign? 
  Initialize or reset the forechannel and backchannel tables
 Fore channel 
 -ENOMEM 
 Back channel 
		 Fore and back channel share a connection so get
  With sessions, the client is not marked ready until after a
  successful EXCHANGE_ID and CREATE_SESSION.
  Map errors cl_cons_state errors to EPROTONOSUPPORT to indicate
  other versions of NFS can be tried.
		
		  Do not set NFS_CS_CHECK_LEASE_TIME instead set the
		  DS lease to be equal to the MDS lease.
 Test for the DS role 
 defined(CONFIG_NFS_V4_1) 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsnfsfile.c
   Copyright (C) 1992  Rick Sladkey
   Changes Copyright (C) 1994 by Florian La Roche
    - Do not copy data too often around in the kernel.
    - In nfs_file_read the return value of kmalloc wasn't checked.
    - Put in a better version of read look-ahead buffering. Original idea
      and implementation by Wai S Kok elekokws@ee.nus.sg.
   Expire cache on write to a file by Wai S Kok (Oct 1994).
   Total rewrite of read side for new NFS buffer cache.. Linus.
   nfs regular file handling functions
 Hack for future NFS swap support 
  Open file
  nfs_revalidate_file_size - Revalidate the file size
  @inode: pointer to inode struct
  @filp: pointer to struct file
  Revalidates the file length. This is basically a wrapper around
  nfs_revalidate_inode() that takes into account the fact that we may
  have cached writes (in which case we don't care about the server's
  idea of what the file length is), or O_DIRECT (in which case we
  shouldn't trust the cache).
	
	  whence == SEEK_END || SEEK_DATA || SEEK_HOLE => we must revalidate
	  the cached file length
  Flush all dirty pages, and check for write errors.
 Flush writes to the server and return any errors 
	 Note: generic_file_mmap() returns ENOSYS on nommu systems
	        so we call that before revalidating the mapping
  Flush any dirty pages for this process, and check for write errors.
  The return status from this call provides a reliable indication of
  whether any write errors occurred for this process.
		
		  If nfs_file_fsync_commit detected a server reboot, then
		  resend all dirty pages that might have been covered by
		  the NFS_CONTEXT_RESEND_WRITES flag
  Decide whether a readmodifywrite cycle may be more efficient
  then a modifywriteread cycle when writing to a page in the
  page cache.
  Some pNFS layout drivers can only readwrite at a certain block
  granularity like all block devices and therefore we must perform
  readmodifywrite whenever a page hasn't read yet and the data
  to be written there is not aligned to a block boundary andor
  smaller than the block size.
  The modifywriteread cycle may occur if a page is read before
  being completely filled by the writer.  In this situation, the
  page must be completely written to stable storage on the server
  before it can be refilled by reading in the page from the server.
  This can lead to expensive, small, FILE_SYNC mode writes being
  done.
  It may be more efficient to read the page first if the file is
  open for reading in addition to writing, the page is not marked
  as Uptodate, it is not dirty or waiting to be committed,
  indicating that it was previously allocated and then modified,
  that there were valid bytes of data in that range of the file,
  and that the new data won't completely replace the old data in
  that range of the file.
	
	  Up-to-date pages, those with ongoing or full-page write
	  don't need readmodifywrite
 Open for reading too? 
  This does the "real" work of the write. We must allocate and lock the
  page to be sent back to the generic routine, which then copies the
  data from user space.
  If the writer ends up delaying the write, the writer needs to
  increment the page use counts until he is done with the page.
	
	  Zero any uninitialised parts of the page, and then mark the page
	  as up to date if it turns out that we're extending the file.
  Partially or wholly invalidate a page
  - Release the private state associated with a page if undergoing complete
    page invalidation
  - Called if either PG_private or PG_fscache is set on the page
  - Caller holds page lock
 Cancel any unstarted writes on this page 
  Attempt to release the private state associated with a page
  - Called if either PG_private or PG_fscache is set on the page
  - Caller holds page lock
  - Return true (may release page) or false (may not)
 If PagePrivate() is set, then the page is not freeable 
	
	  Check if an unstable page is currently being committed and
	  if so, have the VM treat it as if the page is under writeback
	  so it will not block due to pages that will shortly be freeable.
	
	  If PagePrivate() is set, then the page is not freeable and as the
	  inode is not being committed, it's not going to be cleaned in the
	  near future so treat it as dirty
  Attempt to clear the private state associated with a page when an error
  occurs that requires the cached contents of an inode to be written back or
  destroyed
  - Called if either PG_private or fscache is set on the page
  - Caller holds page lock
  - Return 0 if successful, -error otherwise
  Notification that a PTE pointing to an NFS page is about to be made
  writable, implying that someone is about to modify the page through a
  shared-writable mapping
 make sure the cache has finished storing the page 
	
	  O_APPEND implies that we must revalidate the file length.
 Return error values 
 Try local locking first 
 found a conflict 
	
	  Flush all pending writes before doing anything
	  with locks..
		  NOTE: special case
		  	If we're signalled while cleaning up locks on process exit, we
		  	still need to complete the unlock.
	
	  Use local locking if mounted with "-onolock" or with appropriate
	  "-olocal_lock="
	
	  Flush all pending writes before doing anything
	  with locks..
	
	  Use local locking if mounted with "-onolock" or with appropriate
	  "-olocal_lock="
	
	  Invalidate cache to prevent missing any changes.  If
	  the file is mapped, clear the page cache as well so
	  those mappings will be loaded.
	 
	  This makes locking act as a cache coherency point.
  Lock a (portion of) a file
  Lock a (portion of) a file
 We're simulating flock() locks using posix locks on the server 
 SPDX-License-Identifier: GPL-2.0-only
  Initialise an NFSv3 ACL client connection
 No errors! Assume that Sun nfsacls are supported 
 Create a client RPC handle for the NFS v3 ACL management interface 
  Set up a pNFS Data Server client over NFSv3.
  Return any existing nfs_client that matches server address,port,version
  and minorversion.
  For a new nfs_client, use a soft mount (default), a low retrans and a
  low timeout interval so that if a connection is lost, we retry through
  the MDS.
 fake a hostname because lockd wants it 
 Use the MDS nfs_client cl_ipaddr. 
   Device operations for the pnfs client.
   Copyright (c) 2002
   The Regents of the University of Michigan
   All Rights Reserved
   Dean Hildebrand <dhildebz@umich.edu>
   Garth Goodson   <Garth.Goodson@netapp.com>
   Permission is granted to use, copy, create derivative works, and
   redistribute this software and such derivative works for any purpose,
   so long as the name of the University of Michigan is not used in
   any advertising or publicity pertaining to the use or distribution
   of this software without specific, written prior authorization. If
   the above copyright notice or any other identification of the
   University of Michigan is included in any copy of any portion of
   this software, then the disclaimer below must also be included.
   This software is provided as is, without representation or warranty
   of any kind either express or implied, including without limitation
   the implied warranties of merchantability, fitness for a particular
   purpose, or noninfringement.  The Regents of the University of
   Michigan shall not be liable for any damages, including special,
   indirect, incidental, or consequential damages, with respect to any
   claim arising out of or in connection with the use of the software,
   even if it has been or is hereafter advised of the possibility of
   such damages.
  Device ID RCU cache. A device ID is unique per server and layout type.
	
	  Use the session max response size as the basis for setting
	  GETDEVICEINFO's maxcount
	
	  Found new device, need to decode it and then add it to the
	  list of known devices for this mountpoint.
  Lookup a deviceid in cache and get a reference count on it if found
  @clp nfs_client associated with deviceid
  @id deviceid to look up
  Remove a deviceid from cache
  @clp nfs_client associated with deviceid
  @id the deviceid to unhash
  @ret the unhashed node, if found and dereferenced to zero, NULL otherwise.
 balance the initial ref set in pnfs_insert_deviceid 
  Dereference a deviceid node and delete it when its reference count drops
  to zero.
  @d deviceid node to put
  return true iff the node was deleted
  Note that since the test for d->ref == 0 is sufficient to establish
  that the node is no longer hashed in the global device id cache.
  Stop use of all deviceids associated with an nfs_client
 SPDX-License-Identifier: GPL-2.0-only
  linuxfsnfspagelist.c
  A set of helper functions for managing NFS read and write requests.
  The main purpose of these routines is to provide support for the
  coalescing of several requests into a single RPC call.
  Copyright 2000, 2001 (c) Trond Myklebust <trond.myklebust@fys.uio.no>
  nfs_iocounter_wait - wait for io to complete
  @l_ctx: nfs_lock_context with io_counter to use
  returns -ERESTARTSYS if interrupted by a fatal signal.
  Otherwise returns 0 once the io_count hits 0.
  nfs_async_iocounter_wait - wait on a rpc_waitqueue for IO
  to complete
  @task: the rpc_task that should wait
  @l_ctx: nfs_lock_context with io_counter to check
  Returns true if there is outstanding IO to wait on and the
  task has been put to sleep.
  nfs_page_lock_head_request - page lock the head of the page group
  @req: any member of the page group
  nfs_unroll_locks -  unlock all newly locked reqs and wait on @req
  @head: head request of page group, must be holding head lock
  @req: request that couldn't lock and needs to wait on the req bit lock
  This is a helper function for nfs_lock_and_join_requests
  returns 0 on success, < 0 on error.
 relinquish all the locks successfully grabbed this run 
  nfs_page_group_lock_subreq -  try to lock a subrequest
  @head: head request of page group
  @subreq: request to lock
  This is a helper function for nfs_lock_and_join_requests which
  must be called with the head request and page group both locked.
  On error, it returns with the page group unlocked.
  nfs_page_group_lock_subrequests -  try to lock the subrequests
  @head: head request of page group
  This is a helper function for nfs_lock_and_join_requests which
  must be called with the head request locked.
 lock each request in the page group 
  nfs_page_set_headlock - set the request PG_HEADLOCK
  @req: request that is to be locked
  this lock must be held when modifying req->wb_head
  return 0 on success, < 0 on error
  nfs_page_clear_headlock - clear the request PG_HEADLOCK
  @req: request that is to be locked
  nfs_page_group_lock - lock the head of the page group
  @req: request in group that is to be locked
  this lock must be held when traversing or modifying the page
  group list
  return 0 on success, < 0 on error
  nfs_page_group_unlock - unlock the head of the page group
  @req: request in group that is to be unlocked
  nfs_page_group_sync_on_bit_locked
  must be called with page group lock held
 true! reset all bits 
  nfs_page_group_sync_on_bit - set bit on current request, but only
    return true if the bit is set for all requests in page group
  @req - request in page group
  @bit - PG_ bit that is used to sync page group
  nfs_page_group_init - Initialize the page group linkage for @req
  @req - a new nfs request
  @prev - the previous request in page group, or NULL if @req is the first
          or only request in the group (the head).
 a head request 
 a subrequest 
		 All subrequests take a ref on the head request until
		 grab extra ref and bump the request count if head request
		  has extra ref from the writecommit path to handle handoff
  nfs_page_group_destroy - sync the destruction of page groups
  @req - request that no longer needs the page group
  releases the page group reference from each member once all
  members have called this function.
 unlink and free 
 subrequests must release the ref on the head request 
 try to allocate the request struct 
	 Initialize the request struct. Initially, we assume a
	  long write-back delay. This will be adjusted in
  nfs_create_request - Create an NFS readwrite request.
  @ctx: open context to use
  @page: page to write
  @offset: starting offset within the page for the write
  @count: number of bytes to readwrite
  The page must be locked by the caller. This makes sure we never
  create two different requests for the same page.
  User should ensure it is safe to sleep in this function.
 find the last request 
  nfs_unlock_request - Unlock request and wake up sleepers.
  @req: pointer to request
  nfs_unlock_and_release_request - Unlock request and release the nfs_page
  @req: pointer to request
  nfs_clear_request - Free up all resources allocated to the request
  @req:
  Release page and open context resources associated with a readwrite
  request after it has completed.
  nfs_free_request - Release the count on an NFS readwrite request
  @req: request to release
  Note: Should never be called with the spinlock held!
 extra debug: make sure no sync bits are still set 
 Release struct file and open context 
  nfs_wait_on_request - Wait for a request to complete.
  @req: request to wait upon.
  Interruptible by fatal signals only.
  The user is responsible for holding a count on the request.
  nfs_generic_pg_test - determine if requests can be coalesced
  @desc: pointer to descriptor
  @prev: previous request in desc, or NULL
  @req: this request
  Returns zero if @req cannot be coalesced into @desc, otherwise it returns
  the size of the request.
 should never happen 
	
	  Limit the request size so that we can still allocate a page array
	  for it without upsetting the slab allocator.
  nfs_pgio_data_destroy - make @hdr suitable for reuse
  Frees memory and releases refs from nfs_generic_pgio, so that it may
  be called again.
  @hdr: A header that has had nfs_generic_pgio called
  nfs_pgio_header_free - Free a read or write header
  @hdr: The header to free
  nfs_pgio_rpcsetup - Set up arguments for a pageio call
  @hdr: The pageio hdr
  @count: Number of bytes to read
  @how: How to commit data (writes only)
  @cinfo: Commit information for the call (writes only)
	 Set up the RPC argument and reply structs
 pnfs_set_layoutcommit needs this 
  nfs_pgio_prepare - Prepare pageio hdr to go over the wire
  @task: The current task
  @calldata: pageio header to prepare
  nfs_pgio_error - Clean up from a pageio error
  @hdr: pageio header
  nfs_pgio_release - Release pageio data
  @calldata: The pageio header to release
  nfs_pageio_init - initialise a page io descriptor
  @desc: pointer to descriptor
  @inode: pointer to inode
  @pg_ops: pointer to pageio operations
  @compl_ops: pointer to pageio completion operations
  @rw_ops: pointer to nfs readwrite operations
  @bsize: io block size
  @io_flags: extra parameters for the io function
  nfs_pgio_result - Basic pageio error handling
  @task: The task that ran
  @calldata: Pageio header to check
  Create an RPC task for the given read or write request and kick it.
  The page must have been locked by the caller.
  It may happen that the page we're passed is not marked dirty.
  This is the case if nfs_updatepage detects a conflicting request
  that has been written but not committed.
 Set up the argument struct 
  nfs_pageio_setup_mirroring - determine if mirroring is to be used
 				by calling the pg_get_mirror_count op
  nfs_coalesce_size - test two requests for compatibility
  @prev: pointer to nfs_page
  @req: pointer to nfs_page
  @pgio: pointer to nfs_pagio_descriptor
  The nfs_page structures 'prev' and 'req' are compared to ensure that the
  page data area they describe is contiguous, and that their RPC
  credentials, NFSv4 open state, and lockowners are the same.
  Returns size of the request that can be coalesced
  nfs_pageio_do_add_request - Attempt to coalesce a request into a page list.
  @desc: destination io descriptor
  @req: request
  If the request 'req' was successfully coalesced into the existing list
  of pages 'desc', it returns the size of req.
  Helper for nfs_pageio_add_request and nfs_pageio_complete
  __nfs_pageio_add_request - Attempt to coalesce a request into a page list.
  @desc: destination io descriptor
  @req: request
  This may split a request into subrequests which are all part of the
  same page group. If so, it will submit @req as the last one, to ensure
  the pointer to @req is still valid in case of failure.
  Returns true if the request 'req' was successfully coalesced into the
  existing list of pages 'desc'.
 We successfully submitted a request 
 Can't coalesce any more, so do IO 
 retry add_request for this subreq 
 Create the mirror instances first, and fire them off 
  nfs_pageio_complete_mirror - Complete IO on the current mirror of an
 				nfs_pageio_descriptor
  @desc: pointer to io descriptor
  @mirror_idx: pointer to mirror index
  nfs_pageio_resend - Transfer requests to new descriptor and resend
  @hdr - the pgio header to move request from
  @desc - the pageio descriptor to add requests to
  Try to move each request (nfs_page) from @hdr to @desc then attempt
  to send them.
  Returns 0 on success and < 0 on error.
  nfs_pageio_complete - Complete IO then cleanup an nfs_pageio_descriptor
  @desc: pointer to io descriptor
  nfs_pageio_cond_complete - Conditional IO completion
  @desc: pointer to io descriptor
  @index: page index
  It is important to ensure that processes don't try to take locks
  on non-contiguous ranges of pages as that might deadlock. This
  function should be called before attempting to wait on a locked
  nfs_page. It will complete the IO if the page index 'index'
  is not contiguous with the existing list of pages in 'desc'.
  nfs_pageio_stop_mirroring - stop using mirroring (set mirror count to 1)
 SPDX-License-Identifier: GPL-2.0
   Copyright (C) 1995, 1996  Gero Kuhlmann <gero@gkminix.han.de>
   Allow an NFS filesystem to be mounted as root. The way this works is:
      (1) Use the IP autoconfig mechanism to set local IP addresses and routes.
      (2) Construct the device string and the options string using DHCP
          option 17 andor kernel command line options.
      (3) When mount_root() sets up the root file system, pass these strings
          to the NFS client's regular mount interface via sys_mount().
 	Changes:
 	Alan Cox	:	Removed get_address name clash with FPU.
 	Alan Cox	:	Reformatted a bit.
 	Gero Kuhlmann	:	Code cleanup
 	Michael Rausch  :	Fixed recognition of an incoming RARP answer.
 	Martin Mares	: (2.0)	Auto-configuration via BOOTP supported.
 	Martin Mares	:	Manual selection of interface & BOOTPRARP.
 	Martin Mares	:	Using network routes instead of host routes,
 				allowing the default configuration to be used
 				for normal operation of the host.
 	Martin Mares	:	Randomized timer with exponential backoff
 				installed to minimize network congestion.
 	Martin Mares	:	Code cleanup.
 	Martin Mares	: (2.1)	BOOTP and RARP made configuration options.
 	Martin Mares	:	Server hostname generation fixed.
 	Gerd Knorr	:	Fixed wired inode handling
 	Martin Mares	: (2.2)	"0.0.0.0" addresses from command line ignored.
 	Martin Mares	:	RARP replies not tested for server address.
 	Gero Kuhlmann	: (2.3) Some bug fixes and code cleanup again (please
 				send me your new patches _before_ bothering
 				Linus so that I don' always have to cleanup
 				_afterwards_ - thanks)
 	Gero Kuhlmann	:	Last changes of Martin Mares undone.
 	Gero Kuhlmann	: 	RARP replies are tested for specified server
 				again. However, it's now possible to have
 				different RARP and NFS servers.
 	Gero Kuhlmann	:	"0.0.0.0" addresses from command line are
 				now mapped to INADDR_NONE.
 	Gero Kuhlmann	:	Fixed a bug which prevented BOOTP path name
 				from being used (thanks to Leo Spiekman)
 	Andy Walker	:	Allow to specify the NFS server in nfs_root
 				without giving a path name
 	Swen Thmmler	:	Allow to specify the NFS options in nfs_root
 				without giving a path name. Fix BOOTP request
 				for domainname (domainname is NIS domain, not
 				DNS domain!). Skip dummy devices for BOOTP.
 	Jacek Zapala	:	Fixed a bug which prevented server-ip address
 				from nfsroot parameter from being used.
 	Olaf Kirch	:	Adapted to new NFS code.
 	Jakub Jelinek	:	Free used code segment.
 	Marko Kohtala	:	Fixed some bugs.
 	Martin Mares	:	Debug message cleanup
 	Martin Mares	:	Changed to use the new generic IP layer autoconfig
 				code. BOOTP and RARP moved there.
 	Martin Mares	:	Default path now contains host name instead of
 				host IP address (but host name defaults to IP
 				address anyway).
 	Martin Mares	:	Use root_server_addr appropriately during setup.
 	Martin Mares	:	Rewrote parameter parsing, now hopefully giving
 				correct overriding.
 	Trond Myklebust :	Add in preliminary support for NFSv3 and TCP.
 				Fix bug in root_nfs_addr(). nfs_data.namlen
 				is NOT for the length of the hostname.
 	Hua Qin		:	Support for mounting root file system via
 				NFS over TCP.
 	Fabian Frederick:	Option parser rebuilt (using parser lib)
 	Chuck Lever	:	Use super.c's text-based mount option parsing
 	Chuck Lever	:	Add "nfsrootdebug".
 Default path we try to mount. "%s" gets replaced by our IP address 
 Default NFSROOT mount options. 
 Parameters passed from the kernel command line 
 Text-based mount options passed to super.c 
 Address of NFS server 
 Name of directory to mount 
 server:export path string passed to super.c 
  When the "nfsrootdebug" kernel command line option is specified,
  enable debugging messages for NFSROOT.
   Parse NFS server and directory information passed on the kernel
   command line.
   nfsroot=[<server-ip>:]<root-dir>[,<nfs-options>]
   If there is a "%s" token in the <root-dir> string, it is replaced
   by the ASCII-representation of the client's IP address.
	
	  Extract the IP address of the NFS server containing our
	  root file system, if one was specified.
	 
	  Note: root_nfs_parse_addr() removes the server-ip from
	 	 nfs_root_parms, if it exists.
  Parse out root export path and mount options from
  passed-in string @incoming.
  Copy the export path into @exppath.
	
	  Set the NFS remote path
	
	  @incoming now points to the rest of the string; if it
	  contains something, append it to our root options buffer
   Decode the export directory path name and NFS options from
   the kernel command line.  This has to be done late in order to
   use a dynamically acquired client IP address for the remote
   root directory path.
   Returns zero if successful; otherwise -1 is returned.
	
	  Append mandatory options for nfsroot so they override
	  what has come before
	
	  Set up nfs_root_device.  For NFS mounts, this looks like
	 
	 	server:path
	 
	  At this point, utsname()->nodename contains our local
	  IP address or hostname, set by ipconfig.  If "%s" exists
	  in tmp, substitute the nodename, then shovel the whole
	  mess into nfs_root_device.
  nfs_root_data - Return prepared 'data' for NFSROOT mount
  @root_device: OUT: address of string containing NFSROOT device
  @root_data: OUT: address of string containing NFSROOT mount options
  Returns zero and sets @root_device and @root_data if successful,
  otherwise -1 is returned.
 SPDX-License-Identifier: GPL-2.0
   linuxfsnfssymlink.c
   Copyright (C) 1992  Rick Sladkey
   Optimization changes Copyright (C) 1994 Florian La Roche
   Jun 7 1999, cache symlink lookups in the page cache.  -DaveM
   nfs symlink handling code
 Symlink caching in the page cache is even more simplistic
  and straight-forward than readdir caching.
  symlinks can't do much...
   fsnfsnfs4renewd.c
   Copyright (c) 2002 The Regents of the University of Michigan.
   All rights reserved.
   Kendrick Smith <kmsmith@umich.edu>
   Redistribution and use in source and binary forms, with or without
   modification, are permitted provided that the following conditions
   are met:
   1. Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
   2. Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation andor other materials provided with the distribution.
   3. Neither the name of the University nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.
   THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
   WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
   MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
   DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
   FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
   CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
   SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
   BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
   LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  Implementation of the NFSv4 "renew daemon", which wakes up periodically to
  send a RENEW, to keep state alive on the server.  The daemon is implemented
  as an rpc_task, not a real kernel thread, so it always runs in rpciod's
  context.  There is one renewd per nfs_server.
 Are we close to a lease timeout? 
 Queue an asynchronous RENEW. 
  nfs4_set_lease_period - Sets the lease period on a nfs_client
  @clp: pointer to nfs_client
  @lease: new value for lease period
 Cap maximum reconnect timeout at 12 lease period 
 SPDX-License-Identifier: GPL-2.0
  nfs3_prepare_get_acl, nfs3_complete_get_acl, nfs3_abort_get_acl: Helpers for
  caching get_acl results in a race-free way.  See fsposix_acl.c:get_acl()
  for explanations.
 Not the first reader or sentinel already in place. 
 Only cache the ACL if our sentinel is still in place. 
 Remove our sentinel upon failure. 
 The xdr layer may allocate pages here. 
	
	  Only get the access acl when explicitly requested: We don't
	  need it for access decisions, and only some applications use
	  it. Applications which request the access acl first are not
	  penalized from this optimization.
 pages may have been allocated at the xdr layer. 
	 We are doing this here because XDR marshalling does not
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfsnfs4sysctl.c
  Sysctl interface to NFS v4 parameters
  Copyright (c) 2006 Trond Myklebust <Trond.Myklebust@netapp.com>
 SPDX-License-Identifier: GPL-2.0
   linuxfsnfsfile.c
   Copyright (C) 1992  Rick Sladkey
	
	  If no cached dentry exists or if it's negative, NFSv4 handled the
	  opens in ->lookup() or ->create().
	 
	  We only get this far for a cached positive dentry.  We skipped
	  revalidation, so handle it here by dropping the dentry and returning
	  -EOPENSTALE.  The VFS will retry the lookupcreateopen.
 We can't create new files here 
  Flush all dirty pages, and check for write errors.
	
	  If we're holding a write delegation, then check if we're required
	  to flush the io on close. If not, then just start the io now.
 Flush writes to the server and return any errors 
 Only offload copy if superblock is the same 
	 if the copy size if smaller than 2 RPC payloads, make it
	  synchronous
		
		  for inter copy, if copy size is too small
		  then fallback to generic copy.
 NFS does not support deduplication. 
 check alignment w.r.t. clone_blksize 
 XXX: do we lock at all? what if server needs CB_RECALL_LAYOUT? 
	 flush all pending writes on both src and dst so that server
	 truncate inode page cache of the dst range so that future reads can fetch
  nfs42_ssc_register_ops - Wrapper to register NFS_V4 ops in nfs_common
  Return values:
    None
  nfs42_ssc_unregister_ops - wrapper to un-register NFS_V4 ops in nfs_common
  Return values:
    None.
 CONFIG_NFS_V4_2 
 SPDX-License-Identifier: GPL-2.0-only
  linuxfsnfsdelegation.c
  Copyright (C) 2004 Trond Myklebust
  NFS file delegation management
  nfs_mark_delegation_referenced - set delegation's REFERENCED flag
  @delegation: delegation to process
  nfs4_have_delegation - check if inode has a delegation, mark it
  NFS_DELEGATION_REFERENCED if there is one.
  @inode: inode to check
  @flags: delegation types to check for
  Returns one if inode has the indicated delegation, otherwise zero.
  nfs4_check_delegation - check if inode has a delegation, do not mark
  NFS_DELEGATION_REFERENCED if it has one.
 Block nfs4_proc_unlck 
  nfs_inode_reclaim_delegation - process a delegation reclaim request
  @inode: inode to process
  @cred: credential to use for request
  @type: delegation type
  @stateid: delegation stateid
  @pagemod_limit: write delegation "space_limit"
 We appear to have raced with a delegation return. 
 Refcount matched in nfs_end_delegation_return() 
 smp_mb__before_atomic() is implicit due to xchg() 
  nfs_inode_set_delegation - set up a delegation on an inode
  @inode: inode to which delegation applies
  @cred: cred to use for subsequent delegation processing
  @type: delegation type
  @stateid: delegation stateid
  @pagemod_limit: write delegation "space_limit"
  Returns zero on success, or a negative errno value.
 Is this an update of the existing delegation? 
		
		  Deal with broken servers that hand out two
		  delegations for the same file.
		  Allow for upgrades to a WRITE delegation, but
		  nothing else.
	
	  If we didn't revalidate the change attribute before setting
	  the delegation, then pre-emptively ask for a full attribute
	  cache revalidation.
  Basic procedure for returning a delegation to the server
 Recall of any remaining application leases 
		
		  Guard against state recovery
 Refcount matched in nfs_start_delegation_return_locked() 
	
	  To avoid quadratic looping we hold a reference
	  to an inode place_holder.  Each time we restart, we
	  list delegation in the server from the delegations
	  of that inode.
	  prev is an RCU-protected pointer to a delegation which
	  wasn't marked for return and might be a good choice for
	  the next place_holder.
  nfs_client_return_marked_delegations - return previously marked delegations
  @clp: nfs_client to process
  Note that this function is designed to be called by the state
  manager thread. For this reason, it cannot flush the dirty data,
  since that could deadlock in case of a state recovery error.
  Returns zero on success, or a negative errno value.
 If a return was delayed, sleep to prevent hard looping 
  nfs_inode_evict_delegation - return delegation, don't reclaim opens
  @inode: inode to process
  Does not protect against delegation reclaims, therefore really only safe
  to be called from nfs4_clear_inode(). Guaranteed to always free
  the delegation structure.
  nfs4_inode_return_delegation - synchronously return a delegation
  @inode: inode to process
  This routine will always flush any dirty data to disk on the
  assumption that if we need to return the delegation, then
  we should stop caching.
  Returns zero on success, or a negative errno value.
 Synchronous recall of any application leases 
  nfs4_inode_return_delegation_on_close - asynchronously return a delegation
  @inode: inode to process
  This routine is called on file close in order to determine if the
  inode delegation needs to be returned immediately.
 Refcount matched in nfs_end_delegation_return() 
  nfs4_inode_make_writeable
  @inode: pointer to inode
  Make the inode writeable by returning the delegation if necessary
  Returns zero on success, or a negative errno value.
  nfs_expire_all_delegations
  @clp: client to process
  nfs_server_return_all_delegations - return delegations for one superblock
  @server: pointer to nfs_server to process
 If delegation->stateid is newer, dont mark as returned 
  nfs_expire_unused_delegation_types
  @clp: client to process
  @flags: delegation types to expire
  nfs_expire_unreferenced_delegations - Eliminate unused delegations
  @clp: nfs_client to process
  nfs_async_inode_return_delegation - asynchronously return a delegation
  @inode: inode to process
  @stateid: state ID information
  Returns zero on success, or a negative errno value.
 If there are any application leases or delegations, recall them 
  nfs_delegation_find_inode - retrieve the inode associated with a delegation
  @clp: client state handle
  @fhandle: filehandle from a delegation recall
  Returns pointer to inode matching "fhandle," or NULL if a matching inode
  cannot be found.
		
		  If the delegation may have been admin revoked, then we
		  cannot reclaim it.
  nfs_delegation_mark_reclaim - mark all delegations as needing to be reclaimed
  @clp: nfs_client to process
 Match nfs_start_delegation_return_locked 
  nfs_delegation_reap_unclaimed - reap unclaimed delegations after reboot recovery is done
  @clp: nfs_client to process
  nfs_mark_test_expired_all_delegations - mark all delegations for testing
  @clp: nfs_client to process
  Iterates through all the delegations associated with this server and
  marks them as needing to be checked for validity.
  nfs_test_expired_all_delegations - test all delegations for a client
  @clp: nfs_client to process
  Helper for handling "recallable state revoked" status from server.
  nfs_reap_expired_delegations - reap expired delegations
  @clp: nfs_client to process
  Iterates through all the delegations associated with this server and
  checks if they have may have been revoked. This function is usually
  expected to be called in cases where the server may have lost its
  lease.
  nfs_delegations_present - check for existence of delegations
  @clp: client state handle
  Returns one if there are any nfs_delegation structures attached
  to this nfs_client.
  nfs4_refresh_delegation_stateid - Update delegation stateid seqid
  @dst: stateid to refresh
  @inode: inode to check
  Returns "true" and updates "dst->seqid"  if inode had a delegation
  that matches our delegation stateid. Otherwise "false" is returned.
  nfs4_copy_delegation_stateid - Copy inode's state ID information
  @inode: inode to check
  @flags: delegation type requirement
  @dst: stateid data structure to fill in
  @cred: optional argument to retrieve credential
  Returns "true" and fills in "dst->data"  if inode had a delegation,
  otherwise "false" is returned.
  nfs4_delegation_flush_on_close - Check if we must flush file on close
  @inode: inode to check
  This function checks the number of outstanding writes to the file
  against the delegation 'space_limit' field to see if
  the spec requires us to flush the file on close.
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfscache_lib.c
  Helper routines for the NFS client caches
  Copyright (c) 2009 Trond Myklebust <Trond.Myklebust@netapp.com>
	
	  Disable the upcall mechanism if we're getting an ENOENT or
	  EACCES error. The admin can re-enable it on the fly by using
	  sysfs to set the 'cache_getent' parameter once the problem
	  has been fixed.
  Deferred request handling
 SPDX-License-Identifier: GPL-2.0
 Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.
 Written by David Howells (dhowells@redhat.com)
 Start by getting the root filehandle from the server 
   fsnfsnfs4proc.c
   Client-side procedure declarations for NFSv4.
   Copyright (c) 2002 The Regents of the University of Michigan.
   All rights reserved.
   Kendrick Smith <kmsmith@umich.edu>
   Andy Adamson   <andros@umich.edu>
   Redistribution and use in source and binary forms, with or without
   modification, are permitted provided that the following conditions
   are met:
   1. Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
   2. Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation andor other materials provided with the distribution.
   3. Neither the name of the University nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.
   THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
   WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
   MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
   DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
   FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
   CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
   SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
   BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
   LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 file attributes which can be mapped to nfs attributes 
 Prevent leaks of NFSv4 errors into userland 
  This is our standard bitmap for GETATTR requests.
 Remove the attributes over which we have full control 
	
	  NFSv4 servers do not return entries for '.' and '..'
	  Therefore, we fake these entries here.  We let '.'
	  have cookie 0 and '..' have cookie 1.  Note that
	  when talking to the server, we always send cookie 0
	  instead of 1 or 2.
 next 
 cookie, first word 
 cookie, second word 
 entry len 
 entry 
 bitmap length 
 bitmap 
 attribute buffer length 
 next 
 cookie, first word 
 cookie, second word 
 entry len 
 entry 
 bitmap length 
 bitmap 
 attribute buffer length 
 This is the error handling routine for processes that are allowed
  to sleep.
 Handled in nfs41_sequence_process() 
 defined(CONFIG_NFS_V4_1) 
				 We have retried a decent amount, time to
				  fail
 The following works around a Linux server bug! 
 We failed to handle the error 
 This is the error handling routine for processes that are allowed
  to sleep.
		
		  For NFS4ERR_MOVED, the client transport will need to
		  be recomputed after migration recovery has completed.
  Return 'true' if 'clp' is using an rpc_client that is integrity protected
  or 'false' otherwise.
 Bump the slot sequence number 
	 Be nice to the server: try to ensure that the last transmitted
	  value for highest_user_slotid <= target_highest_slotid
 don't increment the sequence number if the task wasn't sent 
 Check the SEQUENCE operation status 
 Mark this sequence number as having been acked 
 Update the slot's sequence and clientid lease timer 
 Check sequence flags 
		
		  sr_status remains 1 if an RPC level error occurred.
		  The server may or may not have processed the sequence
		  operation..
		 The server detected a resend of the RPC call and
		  returned NFS4ERR_DELAY as per Section 2.10.6.2
		  of RFC5661.
		
		  The server thinks we tried to replay a request.
		  Retry the call after bumping the sequence ID.
		
		  The slot id we used was probably retired. Try again
		  using a different slot id.
		
		  Were one or more calls using this slot interrupted?
		  If the server never received the request, then our
		  transmitted slot sequence number may be too high. However,
		  if the server did receive the request then it might
		  accidentally give us a reply with a mismatched operation.
		  We can sort this out by sending a lone sequence operation
		  to the server on the same slot.
		
		  RFC5661:
		  A retry might be sent while the original request is
		  still in progress on the replier. The replier SHOULD
		  deal with the issue by returning NFS4ERR_DELAY as the
		  reply to SEQUENCE or CB_SEQUENCE operation, but
		  implementations MAY return NFS4ERR_SEQ_MISORDERED.
		 
		  Restart the search after a delay.
 Just update the slot sequence no. 
 The session may be reset by one of the error handlers. 
 !CONFIG_NFS_V4_1 
 !CONFIG_NFS_V4_1 
 slot already allocated? 
 The state manager will wait until the slot table is empty 
 Try again in 14 second 
 Want no delegation if we're using O_DIRECT 
	 ask server to check for all possible rights as results
 CONFIG_NFS_V4_1 
  Check for whether or not the caller may update the open stateid
  to the value passed in by stateid.
  Note: This function relies heavily on the server implementing
  RFC7530 Section 9.1.4.2, and RFC5661 Section 8.2.2
  correctly.
  i.e. The stateid seqids have to be initialised to 1, and
  are then incremented on every state transition.
 The common case - we're updating to a new sequence number 
 The server returned a new stateid 
 This is the first OPEN in this generation 
 Handle OPEN+OPEN_DOWNGRADE races 
 Ignore, if the CLOSE argment doesn't match the current stateid 
 Rely on seqids for serialisation with NFSv4.0 
		
		  Ensure we process the state changes in the same order
		  in which the server processed them by delaying the
		  update of the stateid until we are in sequence.
	
	  Protect the call to nfs4_state_set_mode_locked and
	  serialise the stateid update
	
	  Protect the call to nfs4_state_set_mode_locked and
	  serialise the stateid update
 Save the delegation 
 Try to update the stateid using the delegation 
  Check the inode attributes against the CLAIM_PREVIOUS returned attributes
  and update the nfs4_state.
 cached opens have already been processed 
 memory barrier prior to reading state->n_ 
	
	  We may have performed cached opens for all three recoveries.
	  Check if we need to update the current stateid.
  OPEN_RECLAIM:
  	reclaim state on the server after a reboot.
 Don't recall a delegation if it was lost 
 If this request hasn't been cancelled, do nothing 
 In case of error, no cleanup! 
  Note: On error, nfs4_proc_open_confirm will free the struct nfs4_opendata
	
	  Check if we still need to send an OPEN call, or if we can use
	  a delegation instead.
 Update client id. 
 Set the create mode (note dependency on the session type) 
			 don't put an ACCESS op in OPEN compound if O_EXCL,
			  because ACCESS will return permission denied for
 If this request hasn't been cancelled, do nothing 
 In case of error, no cleanup! 
 In case we need an open_confirm, no cleanup! 
  Additional permission checks in order to distinguish between an
  open for read, and an open for execute. This works around the
  fact that NFSv4 OPEN treats read and execute permissions as being
  the same.
  Note that in the non-execute case, we want to turn off permission
  checking if we just created a new file (POSIX open() semantics).
	 access call failed or for some reason the server doesn't
	
	  Use openflags to check for exec, because fmode won't
	  always have FMODE_EXEC set when file open for exec.
 ONLY check for exec rights 
  Note: On error, nfs4_proc_open will free the struct nfs4_opendata
  OPEN_EXPIRED:
  	reclaim state on the server after a network partition.
  	Assumes caller holds the appropriate lock
 NFSv4.0 doesn't allow for delegation recovery on open expire 
 Ack the revoked state to the server 
 Get the delegation credential for use by testfree_stateid 
  nfs41_check_expired_locks - possibly free a lock stateid
  @state: NFSv4 state for an inode
  Returns NFS_OK if recovery for this stateid is now finished.
  Otherwise a negative NFS4ERR value is returned.
  nfs41_check_open_stateid - possibly free an open stateid
  @state: NFSv4 state for an inode
  Returns NFS_OK if recovery for this stateid is now finished.
  Otherwise a negative NFS4ERR value is returned.
  on an EXCLUSIVE create, the server should send back a bitmask with FATTR4-
  fields corresponding to attributes that were used to store the verifier.
  Make sure we clobber those fields in the later setattr call
 d_splice_alias() can't fail here - it's a non-directory 
 Parse layoutget results before we check for access 
  Returns a referenced nfs4_state
 Protect against reboot recovery conflicts 
		
		  send create attributes which was not set by open
		  with an extra setattr.
		 NOTE: BAD_SEQID means the server and client disagree about the
		  book-keeping w.r.t. state-changing operations
		  (OPENCLOSELOCKLOCKU...)
		  It is actually a sign of a bug on the client or on the server.
		 
		  If we receive a BAD_SEQID error in the particular case of
		  doing an OPEN, we assume that nfs_increment_open_seqid() will
		  have unhashed the old state_owner for us, and that we can
		  therefore safely retry using a new one. We should still warn
		  the user though...
		
		  BAD_STATEID on OPEN means that the server cancelled our
		  state before it received the OPEN_CONFIRM.
		  Recover by retrying the request as per the discussion
		  on Page 181 of RFC3530.
 We must have found a delegation 
 Servers should only apply open mode checks for file size changes 
 Use that stateid 
  Update the seqid of an open stateid
  Update the seqid of an open stateid after receiving
  NFS4ERR_OLD_STATEID
 Did another OPEN bump the state's seqid?  try again: 
 server says we're behind but we haven't seen the update yet 
 we slept the whole 5 seconds, we must have lost a seqid 
 Handle Layoutreturn errors 
	 hmm. we are done with the inode, and in the process of freeing
	  the state_owner. we keep this around to process errors
 Did we race with OPEN? 
 Calculate the change in open mode 
 Note: exit _without_ calling nfs4_close_done 
 Close-to-open cache consistency revalidation 
  It is possible for data to be readwritten from a mem-mapped file 
  after the sys_close call (which hits the vfs layer as a flush).
  This means that we can't safely call nfsv4 close on a file until 
  the inode is cleared. This in turn means that we are not good
  NFSv4 citizens - we do not indicate to the server to update the file's 
  share state even when we are done with one of the three share 
  stateid's in the inode.
  NOTE: Caller must be holding the sp->so_owner semaphore!
 Serialization for the sequence id 
 Protect against concurrent sillydeletes 
 Sanity check the server answers 
 Avoid a regression due to buggy server 
	
	  Process the label in the upcoming getfattr
  Retry pseudoroot lookup with various security flavors.  We do this when:
    NFSv4.0: the PUTROOTFH operation returns NFS4ERR_WRONGSEC
    NFSv4.1: the server does not support the SECINFO_NO_NAME operation
  Returns zero on success, or a negative NFS4ERR value, or a
  negative errno value.
 Per 3530bis 15.33.5 
 courtesy 
 try each flavor specified by user 
 no flavors specified by user, try default list 
	
	  -EACCES could mean that the user doesn't have correct permissions
	  to access the mount.  It could also mean that we tried to mount
	  with a gss auth flavor, but rpc.gssd isn't running.  Either way,
	  existing mount programs don't handle -EACCES very well so it should
	  be mapped to -EPERM instead.
  nfs4_proc_get_rootfh - get file handle for server's pseudoroot
  @server: initialized nfs_server handle
  @fhandle: we fill in the pseudo-fs root file handle
  @info: we fill in an FSINFO struct
  @auth_probe: probe the auth flavours
  Returns zero on success, or a negative errno.
  Get locations and (maybe) other attributes of a referral.
  Note that we'll actually follow the referral later when
  we detect fsid mismatch in inode revalidation
	
	  If the fsid didn't change, this is a migration event, not a
	  referral.  Cause us to drop into the exception handler, which
	  will kick off migration recovery.
 Fixup attributes for the nfs_lookup() call to nfs_fhget() 
 replace the lookup nfs_fattr with the locations nfs_fattr 
 Is this is an attribute revalidation, subject to softreval? 
  The file is not closed if it is opened due to the a request to change
  the size of the file. The open call will not be needed once the
  VFS layer lookup-intents are implemented.
  Close is called when the inode is destroyed.
  If we haven't opened the file for O_WRONLY, we
  need to in the size_change case to obtain a stateid.
  Got race?
  Because OPEN is always done by name in nfsv4, it is
  possible that we opened a different file by the same
  name.  We can recognize this race condition, but we
  can't do anything about it besides returning an error.
  This will be fixed with VFS changes (lookup-intent).
 Deal with open(O_TRUNC) 
 Optimization: if the end result is no change, don't RPC 
 Search for an existing open(O_WRITE) file 
 Return any delegations if we're going to change ACLs 
 Is this is an attribute revalidation, subject to softreval? 
  TODO: For the time being, we don't try to get any attributes
  along with any of the zero-copy operations READ, READDIR,
  READLINK, WRITE.
  In the case of the first three, we want to put the GETATTR
  after the read-type operation -- this is because it is hard
  to predict the length of a GETATTR response in v4, and thus
  align the READ data correctly.  This means that the GETATTR
  may end up partially falling into the page cache, and we should
  shift it into the 'tail' of the xdr_buf before processing.
  To do this efficiently, we need to know the total length
  of data received, which doesn't seem to be available outside
  of the RPC layer.
  In the case of WRITE, we also want to put the GETATTR after
  the operation -- in this case because we want to make sure
  we get the post-operation mtime and size.
  Both of these changes to the XDR layer would in fact be quite
  minor, but I decided to leave them for a subsequent patch.
  This is just for mknod.  open(O_CREAT) will always do ->open_context().
 Removing a directory decrements nlink in the parent 
 Note: If we moved a directory, nlink will change 
 Creating a directory bumps nlink in the parent 
 block layout checks this! 
 None of the pathconf attributes are mandatory to implement 
 If the current stateid represents a lost lock, then exit 
 Note: We don't use READ_PLUS with pNFS yet 
 CONFIG_NFS_V4_2 
 Don't request attributes for pNFS or O_DIRECT writes 
	 Otherwise, request attributes if and only if we don't hold
	  a delegation
  nfs4_proc_async_renew(): This is not one of the nfs_rpc_ops; it is a special
  standalone procedure for queueing an asynchronous RENEW.
 Unless we're shutting down, schedule state recovery! 
 Assuming that XATTR_SIZE_MAX is a multiple of PAGE_SIZE, and that
  it's OK to put sizeof(void)  (XATTR_SIZE_MAXPAGE_SIZE) bytes on
  the stack.
 user is just asking for length 
 see getxattr(2) man page 
  The getxattr API returns the required buffer length when called with a
  NULL buf. The NFSv4 acl tool then calls getxattr again after allocating
  the required buf.  On a NULL buf, we send a page of data to the server
  guessing that the ACL request can be serviced by a page. If so, we cache
  up to the page of ACL data, and the 2nd call to getxattr is serviced by
  the cache. If not so, we throw away the page, and cache the required
  length. The next getxattr call will then produce another round trip to
  the server, this time with the input buf of the required size.
 for decoding across pages 
 Handle the case where the passed-in buffer is too short 
 Did the user only issue a request for the acl length? 
		 -ENOENT is returned if there is no ACL or if there is an ACL
 You can't remove system.nfs4_acl: 
	
	  Free each page after tx, so the only ref left is
	  held by the network stack
	
	  Acl update can result in inode attribute update.
	  so mark the attribute cache invalid.
			
			  no need to retry since the kernel
			  isn't involved in encoding the ACEs.
 CONFIG_NFS_V4_SECURITY_LABEL 
		 An impossible timestamp guarantees this value
	
	  Since this string is allocated at mount time, and held until the
	  nfs_client is destroyed, we can use GFP_KERNEL here wo worrying
	  about a memory-reclaim deadlock.
	
	  Since this string is allocated at mount time, and held until the
	  nfs_client is destroyed, we can use GFP_KERNEL here wo worrying
	  about a memory-reclaim deadlock.
  nfs4_callback_up_net() starts only "tcp" and "tcp6" callback
  services.  Advertise one based on the address family of the
  clientaddr.
  nfs4_proc_setclientid - Negotiate client ID
  @clp: state data structure
  @program: RPC program for NFSv4 callback service
  @port: IP port number for NFS4 callback service
  @cred: credential to use for this call
  @res: where to place the result
  Returns zero, a negative errno, or a negative NFS4ERR status code.
 nfs_client_id4 
 cb_client4 
  nfs4_proc_setclientid_confirm - Confirm client ID
  @clp: state data structure
  @arg: result of a previous SETCLIENTID
  @cred: credential to use for this call
  Returns zero, a negative errno, or a negative NFS4ERR status code.
 Handle Layoutreturn errors 
  Update the seqid of a lock stateid after receiving
  NFS4ERR_OLD_STATEID
 Ensure we don't close file until we're done freeing locks! 
 Note: exit _without_ running nfs4_locku_done 
	 Ensure this is an unlock - when canceling a lock, the
	  canceled lock is passed in, and it won't be an unlock.
 Unlock _before_ we do the RPC call 
 Exclude nfs_delegation_claim_locks() 
 Exclude nfs4_reclaim_open_stateid() - note nesting! 
 Is this a delegated lock? 
 Do we need to do an open_to_lock_owner? 
 Cache the lock if possible... 
 Yes: cache locks! 
 ...but avoid races with delegation recall... 
 NULL key means to wake up everyone 
 Only wake if the callback was for the same owner. 
 Make sure it's for the right inode 
 Don't bother with waitqueue if we don't expect a callback 
 !CONFIG_NFS_V4_1 
 verify open state 
	
	  Don't rely on the VFS having checked the file open mode,
	  since it won't do this for flock() locks.
 No delegation, no lease 
 We raced with a delegation return 
	
	  There is no mapping from the MAY_ flags to the NFS_ACCESS_XA
	  flags right now. Handling of xattr operations use the normal
	  file readwrite permissions.
	 
	  Just in case the server has other ideas (which RFC 8276 allows),
	  do a cached access check for the XA flags to possibly avoid
	  doing an RPC and getting EACCES back.
 CONFIG_NFS_V4_2 
  nfs_fhget will use either the mounted_on_fileid or the fileid
	 Ask for the fileid of the absent filesystem if mounted_on_fileid
  This operation also signals the server that this client is
  performing migration recovery.  The server can stop returning
  NFS4ERR_LEASE_MOVED to this client.  A RENEW operation is
  appended to this compound to identify the client ID which is
  performing recovery.
 skip LOOKUP 
 append RENEW 
  This operation also signals the server that this client is
  performing migration recovery.  The server can stop asserting
  SEQ4_STATUS_LEASE_MOVED for this client.  The client ID
  performing this operation is identified in the SEQUENCE
  operation in this compound.
  When the client supports GETATTR(fs_locations_info), it can
  be plumbed in here.
 skip LOOKUP 
 CONFIG_NFS_V4_1 
  nfs4_proc_get_locations - discover locations for a migrated FSID
  @inode: inode on FSID that is migrating
  @locations: result of query
  @page: buffer
  @cred: credential to use for this operation
  Returns NFS4_OK on success, a negative NFS4ERR status code if the
  operation failed, or a negative errno if a local error occurred.
  On success, "locations" is filled in, but if the server has
  no locations information, NFS_ATTR_FATTR_V4_LOCATIONS is not
  asserted.
  -NFS4ERR_LEASE_MOVED is returned if the server still has leases
  from this client that require migration recovery.
  This operation also signals the server that this client is
  performing "lease moved" recovery.  The server can stop
  returning NFS4ERR_LEASE_MOVED to this client.  A RENEW operation
  is appended to this compound to identify the client ID which is
  performing recovery.
 append RENEW 
  This operation also signals the server that this client is
  performing "lease moved" recovery.  The server can stop asserting
  SEQ4_STATUS_LEASE_MOVED for this client.  The client ID performing
  this operation is identified in the SEQUENCE operation in this
  compound.
 CONFIG_NFS_V4_1 
  nfs4_proc_fsid_present - Is this FSID present or absent on server?
  @inode: inode on FSID to check
  @cred: credential to use for this operation
  Server indicates whether the FSID is present, moved, or not
  recognized.  This operation is necessary to clear a LEASE_MOVED
  condition for this client ID.
  Returns NFS4_OK if the FSID is present on this server,
  -NFS4ERR_MOVED if the FSID is no longer present, a negative
   NFS4ERR code if some error occurred on the server, or a
   negative errno if a local failure occurred.
  If 'use_integrity' is true and the state managment nfs_client
  cl_rpcclient is using krb5ip, use the integrity protected cl_rpcclient
  and the machine credential as per RFC3530bis and RFC5661 Security
  Considerations sections. Otherwise, just use the user cred with the
  filesystem's rpc_client.
 try to use integrity protection with machine cred 
		
		  if unable to use integrity protection, or SECINFO with
		  integrity protection returns NFS4ERR_WRONGSEC (which is
		  disallowed by spec, but exists in deployed servers) use
		  the current filesystem's rpc_client and the user cred.
  Check the exchange flags returned by the server for invalid flags, having
  both PNFS and NON_PNFS flags set, and not having one of NON_PNFS, PNFS, or
  DS flags set.
  nfs4_proc_bind_one_conn_to_session()
  The 4.1 client currently uses the same TCP connection for the
  fore and backchannel.
 Do not set the backchannel flag unless this is clnt->cl_xprt 
  Minimum set of SP4_MACH_CRED operations from RFC 5661 in the enforce map
  and operations we'd like to see to enable certain features in the allow map
  Select the state protection mode for client `clp' given the server results
  from exchange_id in `sp'.
  Returns 0 on success, negative errno otherwise.
 Print state protect result 
 make sure nothing is on enforce list that isn't supported 
		
		  Minimal mode - state operations are allowed to use machine
		  credential.  Note this already happens by default, so the
		  client doesn't have to do anything more than the negotiation.
		 
		  NOTE: we don't care if EXCHANGE_ID is in the list -
		        we're already using the machine cred for exchange_id
		        and will never use a different cred.
  _nfs4_proc_exchange_id()
  Wrapper for EXCHANGE_ID operation.
 unsupported! 
  _nfs4_proc_exchange_id()
  Wrapper for EXCHANGE_ID operation.
 Client ID is not confirmed 
 Save the EXCHANGE_ID verifier session trunk tests 
  nfs4_proc_exchange_id()
  Returns zero, a negative errno, or a negative NFS4ERR status code.
  Since the clientid has expired, all compounds using sessions
  associated with the stale clientid will be returning
  NFS4ERR_BADSESSION in the sequence operation, and will therefore
  be in some phase of session reset.
  Will attempt to negotiate SP4_MACH_CRED if krb5i  krb5p auth is used.
 try SP4_MACH_CRED if krb5ip	
 try SP4_NONE 
  nfs4_test_session_trunk
  This is an add_xprt_test() test function called from
  rpc_clnt_setup_test_and_add_xprt.
  The rpc_xprt_switch is referrenced by rpc_clnt_setup_test_and_add_xprt
  and is dereferrenced in nfs4_exchange_id_release
  Upon success, add the new transport to the rpc_clnt
  @clnt: struct rpc_clnt to get new transport
  @xprt: the rpc_xprt to test
  @data: call data for _nfs4_proc_exchange_id.
 Test connection for session trunking. Async exchange_id call 
 CONFIG_NFS_V4_1 
	 just setup sequence, do not trigger session recovery
  Called from nfs4_state_manager thread for session setup, so don't recover
  from sequence operation or clientid errors.
  Initialize the values to be used by the client in CREATE_SESSION
  If nfs4_init_session set the fore channel request and response sizes,
  use them.
  Set the back channel max_resp_sz_cached to zero to force the client to
  always set csa_cachethis to FALSE because the current implementation
  of the back channel DRC only supports caching the CB_SEQUENCE operation.
 Fore channel attributes 
 Back channel attributes 
	
	  Our requested max_ops is the minimum we need; we're not
	  prepared to break up compounds into smaller pieces than that.
	  So, no point even trying to continue if the server won't
	  cooperate:
 Mark client id and session as being confirmed 
 Verify the session's negotiated channel_attrs values 
 Increment the clientid slot sequence id 
  Issues a CREATE_SESSION operation to the server.
  It is the responsibility of the caller to verify the session is
  expired before calling this routine.
 Init or reset the session slot tables 
  Issue the over-the-wire RPC DESTROY_SESSION.
  The caller must serialize access to this routine.
 session is still being setup 
  Renew the cl_session lease.
 What to do here? 
  Issue a global reclaim complete.
	
	  NFS4ERR_LAYOUTUNAVAILABLE means we are not supposed to use pnfs
	  on the file. set tk_status to -ENODATA to tell upper layer to
	  retry go inband.
	
	  NFS4ERR_BADLAYOUT means the MDS cannot return a layout of
	  length lgp->args.minlength != 0 (see RFC5661 section 18.43.3).
	
	  NFS4ERR_LAYOUTTRYLATER is a conflict with another client
	  (or clients) writing to the same RAID stripe except when
	  the minlength argument is 0 (see RFC5661 section 18.43.3).
	 
	  Treat it like we would RECALLCONFLICT -- we retry for a little
	  while, and then eventually give up.
 If the open stateid was bad, then recover it. 
		
		  Mark the bad layout state as invalid, then retry
	
	  Was there an RPC level error? Assume the call succeeded,
	  and that we need to release the layout
 Just ignore these failures 
 layout was recalled 
 no IOMODE_RW layout for range 
 no layout 
 loca_recalim always false 
  Use the state managment nfs_client cl_rpcclient, which uses krb5i (if
  possible) as per RFC3530bis and RFC5661 Security Considerations sections
 first try using integrity protection 
 try to use integrity protection with machine cred 
		
		  if unable to use integrity protection, or SECINFO with
		  integrity protection returns NFS4ERR_WRONGSEC (which is
		  disallowed by spec, but exists in deployed servers) use
		  the current filesystem's rpc_client and the user cred.
	
	  Fall back on "guess and check" method if
	  the server doesn't support SECINFO_NO_NAME
  nfs41_test_stateid - perform a TEST_STATEID operation
  @server: server  transport on which to perform the operation
  @stateid: state ID to test
  @cred: credential
  Returns NFS_OK if the server recognizes that "stateid" is valid.
  Otherwise a negative NFS4ERR value is returned if the operation
  failed or the state ID is not currently valid.
  nfs41_free_stateid - perform a FREE_STATEID operation
  @server: server  transport on which to perform the operation
  @stateid: state ID to release
  @cred: credential
  @privileged: set to true if this call needs to be privileged
  Note: this function is always asynchronous.
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
 protocol version 
  fsnfsidmap.c
   UID and GID to name mapping for clients.
   Copyright (c) 2002 The Regents of the University of Michigan.
   All rights reserved.
   Marius Aamodt Eriksen <marius@umich.edu>
   Redistribution and use in source and binary forms, with or without
   modification, are permitted provided that the following conditions
   are met:
   1. Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
   2. Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation andor other materials provided with the distribution.
   3. Neither the name of the University nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.
   THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
   WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
   MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
   DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
   FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
   CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
   SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
   BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
   LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  nfs_fattr_init_names - initialise the nfs_fattr owner_namegroup_name fields
  @fattr: fully initialised struct nfs_fattr
  @owner_name: owner name string cache
  @group_name: group name string cache
  nfs_fattr_free_names - free up the NFSv4 owner and group strings
  @fattr: a fully initialised nfs_fattr structure
  nfs_fattr_map_and_free_names - map ownergroup strings into uidgid and free
  @server: pointer to the filesystem nfs_server structure
  @fattr: a fully initialised nfs_fattr structure
  This helper maps the cached NFSv4 ownergroup strings in fattr into
  their numeric uidgid equivalents, and then frees the cached strings.
  Assemble the description to pass to request_key()
  This function will allocate a new string and update dest to point
  at it.  The caller is responsible for freeing dest.
  On error 0 is returned.  Otherwise, the length of dest is returned.
 ID -> Name 
 Name -> ID 
 idmap classic begins here 
 msg and im are freed in idmap_pipe_destroy_msg 
 ret = -ENOKEY 
 Note: here we store the NUL terminator too 
	 If instantiation is successful, anyone waiting for key construction
	  will have been woken up and someone else may now have used
	  idmap_key_cons - so after this point we may no longer touch it.
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2019 Hammerspace Inc
 Strip trailing '\n' 
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2015, Primary Data, Inc. All rights reserved.
  Tao Peng <bergwolf@primarydata.com>
 inode fileid high 
 inode fileid low 
 inode type 
 embeded server fh 
  Let's break subtree checking for now... otherwise we'll have to embed parent fh
  but there might not be enough space.
 Padding 
 NULL translates to ESTALE 
 SPDX-License-Identifier: GPL-2.0-only
  linuxfsnfsdirect.c
  Copyright (C) 2003 by Chuck Lever <cel@netapp.com>
  High-performance uncached IO for the Linux NFS client
  There are important applications whose performance or correctness
  depends on uncached access to file data.  Database clusters
  (multiple copies of the same instance running on separate hosts)
  implement their own cache coherency protocol that subsumes file
  system cache protocols.  Applications that process datasets
  considerably larger than the client's memory do not always benefit
  from a local cache.  A streaming video server, for instance, has no
  need to cache the contents of a file.
  When an application requests uncached IO, all read and write requests
  are made directly to the server; data stored or fetched via these
  requests is not cached in the Linux page cache.  The client does not
  correct unaligned requests from applications.  All requested bytes are
  held on permanent storage before a direct write system call returns to
  an application.
  Solaris implements an uncached IO facility called directio() that
  is used for backups and sequential IO to very large files.  Solaris
  also supports uncaching whole NFS partitions with "-o forcedirectio,"
  an undocumented mount option.
  Designed by Jeff Kimmel, Chuck Lever, and Trond Myklebust, with
  help from Andrew Morton.
  18 Dec 2001	Initial implementation for 2.4  --cel
  08 Jul 2002	Version for 2.4.19, with bug fixes --trondmy
  08 Jun 2003	Port to 2.5 APIs  --cel
  31 Mar 2004	Handle direct IO without VFS support  --cel
  15 Sep 2004	Parallel async reads  --cel
  04 May 2005	support O_DIRECT with aio  --cel
 release manager 
 IO parameters 
 file open context info 
 Lock context info 
 controlling io request 
 target file of io 
 completion state 
 ios we're waiting for 
 protect completion state 
 Start offset for IO 
 bytes actually processed 
 max expected count 
 bytes left to be sent 
 any reported error 
 wait for io completion 
 commit state 
 Storage for cinfo 
 Storage for cinfo 
 for write 
 an unstable reply was received 
 write verification failed 
 for read 
 dirty user-space page after read 
 write verification failed 
 Clear outstanding error if this is EOF 
  nfs_direct_IO - NFS address space operation for direct IO
  @iocb: target IO control block
  @iter: IO buffer
  The presence of this routine in the address space ops vector means
  the NFS client supports direct IO. However, for most direct IO, we
  shunt off direct read and write requests before the VFS gets them,
  so this method is only ever called for swap.
 we only support swap file calling nfs_direct_IO 
  Collects and returns the final error valuebyte-count.
 Async requests don't wait here 
  Synchronous IO uses a stack-allocated iocb.  Thus we can't trust
  the iocb is still valid here if this is a synchronous request.
  For each rsize'd chunk of the user's buffer, dispatch an NFS READ
  operation.  If nfs_readdata_alloc() or get_user_pages() fails,
  bail and stop sending more reads.  Read length accounting is
  handled automatically by nfs_direct_read_result().  Otherwise, if
  no requests have been sent, just return an error.
 XXX do we need to do the eof zeroing found in async_filler? 
	
	  If no bytes were started, return the error, and let the
	  generic layer handle the completion.
  nfs_file_direct_read - file direct read operation for NFS files
  @iocb: target IO control block
  @iter: vector of user buffers into which to read data
  We use this function for direct reads instead of calling
  generic_file_aio_read() in order to avoid gfar's check to see if
  the request starts before the end of the file.  For that check
  to work, we must generate a GETATTR before each direct read, and
  even then there is a window between the GETATTR and the subsequent
  READ where the file size could change.  Our preference is simply
  to do all reads the application wants, and the server will take
  care of managing the end of file boundary.
  This function also eliminates unnecessarily updating the file's
  atime locally, as the NFS server sets the file's atime, and this
  client must read the updated atime from the server back into its
  cache.
 Bump the transmission count 
 Errors in commit are fatal 
			
			  Despite the reboot, the write was successful,
			  so reset wb_nio.
 Error or match 
 res == -ENOMEM 
 Calls nfs_direct_write_schedule_work 
 fake unstable write to let common nfs resend pages 
  NB: Return the value of the first error return code.  Subsequent
      errors after the first one are ignored.
  For each wsize'd chunk of the user's buffer, dispatch an NFS WRITE
  operation.  If nfs_writedata_alloc() or get_user_pages() fails,
  bail and stop sending more writes.  Write length accounting is
  handled automatically by nfs_direct_write_result().  Otherwise, if
  no requests have been sent, just return an error.
	
	  If no bytes were started, return the error, and let the
	  generic layer handle the completion.
  nfs_file_direct_write - file direct write operation for NFS files
  @iocb: target IO control block
  @iter: vector of user buffers from which to write data
  We use this function for direct writes instead of calling
  generic_file_aio_write() in order to avoid taking the inode
  semaphore and updating the i_size.  The NFS server will set
  the new i_size and this client must read the updated size
  back into its cache.  We let the server do generic write
  parameter checking and report problems.
  We eliminate local atime updates, see direct read above.
  We avoid unnecessary page cache invalidations for normal cached
  readers of this file.
  Note that O_APPEND is not supported for NFS direct writes, as there
  is no atomic O_APPEND write facility in the NFS protocol.
 XXX: should check the generic_write_sync retval 
  nfs_init_directcache - create a slab cache for nfs_direct_req structures
  nfs_destroy_directcache - destroy the slab cache for nfs_direct_req structures
 SPDX-License-Identifier: GPL-2.0-only
  Common NFS IO  operations for the pnfs file based
  layout drivers.
  Copyright (c) 2014, Primary Data, Inc. All rights reserved.
  Tom Haynes <loghyr@primarydata.com>
 Fake up some data that will cause nfs_commit_release to retry the writes. 
 Note this may cause RPC to be resent 
 The generic layer is about to remove the req from the commit list.
  If this will make the bucket empty, it will need to put the lseg reference.
  Note this must be called holding nfsi->commit_mutex
  Locks the nfs_page requests for commit and moves them to
  @bucket->committing.
 Move reqs from written to committing lists, returning count
  of number moved.
 Pull everything off the committing lists and dump into @dst.  
	 Linearly search the commit lists for each bucket until a matching
 pnfs_generic_search_commit_reqs - Search lists in @cinfo for the head reqest
 				   for @page
  @cinfo - commit info for current inode
  @page - page to search for matching head request
  Returns a the head request if one is found, otherwise returns NULL.
 Clean up on error 
 This follows nfs_commit_list pretty closely 
  Data server cache
  Data servers can be mapped to different device ids.
  nfs4_pnfs_ds reference counting
    - set to 1 on allocation
    - incremented when a device id maps a data server already in the cache.
    - decremented when deviceid is removed from the cache.
 Debug routines 
 LINKLOCAL addresses must have matching scope_id 
  Checks if 'dsaddrs1' contains a subset of 'dsaddrs2'. If it does,
  declare a match.
  Lookup DS by addresses.  nfs4_ds_cache_lock is held
  Create a string with a human readable address and port to avoid
  complicated setup around many dprinks.
 '{', '}' and eol 
 string plus comma 
  Given a list of multipath struct nfs4_pnfs_ds_addr, add it to ds cache if
  uncached and return cached struct nfs4_pnfs_ds.
 this is only used for debugging, so it's ok if its NULL 
 Add this address as an alias 
			
			 Test this address for session trunking and
			 add as an alias
  Create an rpc connection to the nfs4_pnfs_ds data server.
  Currently only supports IPv4 and IPv6 addresses.
  If connection fails, make devid unavailable and return a -errno.
	
	  At this point the ds->ds_clp should be ready, but it might have
	  hit an error.
  Currently only supports ipv4, ipv6 and one multi-path address.
 r_netid 
 r_addr: ipip6addr with port in dec octets - see RFC 5665 
 port is ".ABC.DEF", 8 chars max 
 replace port '.' with '-' 
 find '.' between address and port 
 save human readable address 
 NULL is ok, only used for dprintk 
	 Non-empty buckets hold a reference on the lseg.  That ref
	  is normally transferred to the COMMIT call and released
	  there.  It could also be released if the last req is pulled
	  off due to a rewrite, in which case it will be done in
	  pnfs_common_clear_request_commit
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (c) 2012 Bryan Schumaker <bjschuma@netapp.com>
  Clean out any remaining NFSv4 state that might be left over due
  to open() calls that passed nfs_atomic_lookup, but failed to call
  nfs_open().
 If we are holding a delegation, return and free it 
 Note that above delegreturn would trigger pnfs return-on-close 
 First call standard NFS clear_inode() code 
 We leave export_path unset as it's not used to find the root. 
 Does hostname needs to be enclosed in brackets? 
	 We create a mount for the server's root, walk to the requested
	  location and then create another mount for that.
  Create an NFS4 server record on referral traversal
 create a new volume representation 
 Not called in the _init(), conditionally loaded 
 SPDX-License-Identifier: GPL-2.0
   linuxfsnfsproc.c
   Copyright (C) 1992, 1993, 1994  Rick Sladkey
   OS-independent nfs remote procedure call functions
   Tuned by Alan Cox <A.Cox@swansea.ac.uk> for >3K buffers
   so at last we can have decent(ish) throughput off a 
   Sun server.
   Coding optimized and cleaned up by Florian La Roche.
   Note: Error returns are optimized for NFS_OK, which isn't translated via
   nfs_stat_to_errno(), but happens to be already the right return code.
   Also, the code currently doesn't check the size of the packet, when
   it decodes the packet.
   Feel free to fix it and mail me the diffs if it worries you.
   Completely rewritten to support the new RPC call interface;
   rewrote and moved the entire XDR stuff to xdr.c
   --Olaf Kirch June 1996
   The code below initializes all auto variables explicitly, otherwise
   it will fail to work as a module (gcc generates a memset call for an
   incomplete struct).
  Bare-bones access to getattr: this is for nfs_read_super.
 Retry with default authentication if different 
 Retry with default authentication if different 
  One function for each procedure in the NFS protocol.
 Is this is an attribute revalidation, subject to softreval? 
 Mask out the non-modebit related stuff from attr->ia_mode 
 Is this is an attribute revalidation, subject to softreval? 
  In NFSv2, mknod is grafted onto the create call.
 get out your barf bag 
	
	  V2 SYMLINK requests don't return any attributes.  Setting the
	  filehandle size to zero indicates to nfs_instantiate that it
	  should fill in the data with a LOOKUP call on the wire.
  The READDIR implementation is somewhat hackish - we pass a temporary
  buffer to the encode function, which installs it in the receive
  the receive iovec. The decode function just parses the reply to make
  sure it is syntactically correct; the entries itself are decoded
  from nfs_readdir by calling the decode_entry function directly.
		 Emulate the eof flag, which isn't normally needed in NFSv2
		  as it is guaranteed to always return the file attributes
 Note: NFSv2 ignores @stable and always uses NFS_FILE_SYNC 
 Helper functions for NFS lock bounds checking 
 protocol version 
 access 
   fsnfsnfs4state.c
   Client-side XDR for NFSv4.
   Copyright (c) 2002 The Regents of the University of Michigan.
   All rights reserved.
   Kendrick Smith <kmsmith@umich.edu>
   Redistribution and use in source and binary forms, with or without
   modification, are permitted provided that the following conditions
   are met:
   1. Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
   2. Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation andor other materials provided with the distribution.
   3. Neither the name of the University nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.
   THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
   WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
   MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
   DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
   FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
   CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
   SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
   BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
   LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  Implementation of the NFSv4 state model.  For the time being,
  this is minimal, but will be made much more complex in a
  subsequent patch.
 Funky initialiser keeps older gcc versions happy 
 Funky initialiser keeps older gcc versions happy 
  nfs40_discover_server_trunking - Detect server IP address trunking (mv0)
  @clp: nfs_client under test
  @result: OUT: found nfs_client, or clp
  @cred: credential to use for trunking test
  Returns zero, a negative errno, or a negative NFS4ERR status.
  If zero is returned, an nfs_client pointer is planted in
  "result".
  Note: The returned client may not yet be marked ready.
		 Sustain the lease, even if it's empty.  If the clientid4
 If the client state need to recover, do it. 
 Force root creds instead of machine 
  nfs4_get_renew_cred - Acquire credential for a renew operation
  @clp: client state handle
  Returns an rpc_cred with reference count bumped, or NULL.
  Caller must hold clp->cl_lock.
 Use machine credentials if available 
 back channel 
 fore channel 
 create_session negotiated new slot table 
  nfs41_discover_server_trunking - Detect server IP address trunking (mv1)
  @clp: nfs_client under test
  @result: OUT: found nfs_client, or clp
  @cred: credential to use for trunking test
  Returns NFS4_OK, a negative errno, or a negative NFS4ERR status.
  If NFS4_OK is returned, an nfs_client pointer is planted in
  "result".
  Note: The returned client may not yet be marked ready.
	
	  Purge state if the client id was established in a prior
	  instance and the client id could not have arrived on the
	  server via Transparent State Migration.
 CONFIG_NFS_V4_1 
  nfs4_get_clid_cred - Acquire credential for a setclientid operation
  @clp: client state handle
  Returns a cred with reference count bumped, or NULL.
  nfs4_alloc_state_owner(): this is called on the OPEN or CREATE path to
  create a new state_owner.
	 This state_owner is no longer usable, but must
	  remain in place so that state recovery can find it
	  and the opens associated with it.
	  It may also be used for new 'open' request to
	  return a delegation to the server.
	  So update the 'create_time' so that it looks like
	  a new state_owner.  This will cause the server to
	  request an OPEN_CONFIRM to start a new sequence.
 NB: LRU is sorted so that oldest is at the head 
  nfs4_get_state_owner - Look up a state owner given a credential
  @server: nfs_server to search
  @cred: RPC credential to match
  @gfp_flags: allocation mode
  Returns a pointer to an instantiated nfs4_state_owner struct, or NULL.
  nfs4_put_state_owner - Release a nfs4_state_owner
  @sp: state owner data to release
  Note that we keep released state owners on an LRU
  list.
  This caches valid state owners so that they can be
  reused, to avoid the OPEN_CONFIRM on minor version 0.
  It also pins the uniquifier of dropped state owners for
  a while, to ensure that those state owner names are
  never reused.
  nfs4_purge_state_owners - Release all cached state owners
  @server: nfs_server with cached state owners to release
  @head: resulting list of state owners
  Called at umount time.  Remaining state owners will be on
  the LRU with ref count of zero.
  Note that the state owners are not freed, but are added
  to the list @head, which can later be used as an argument
  to nfs4_free_state_owners.
  nfs4_free_state_owners - Release all cached state owners
  @head: resulting list of state owners
  Frees a list of state owners that was generated by
  nfs4_purge_state_owners
 NB! List reordering - see the reclaim code for why.  
		 Note: The reclaim code dictates that we add stateless
  Close the current file.
 Protect against nfs4_find_state() 
  Search the state->lock_states for an existing lock_owner
  that is compatible with either of the given owners.
  If the second is non-zero, then the first refers to a Posix-lock
  owner (current->files) and the second refers to a flockOFD
  owner (struct file).  In that case, prefer a match for the first
  owner.
  If both sorts of locks are held on the one file we cannot know
  which stateid was intended to be used, so a "correct" choice cannot
  be made.  Failing that, a "consistent" choice is preferable.  The
  consistent choice we make is to prefer the first owner, that of a
  Posix lock.
  Return a compatible lock_state. If no initialized lock_state structure
  exists, return an uninitialized one.
  Return a compatible lock_state. If no initialized lock_state structure
  exists, return an uninitialized one.
  Release reference to lock_state, and free it if we see that
  it is no longer in use
  Byte-range lock aware utility to initialize the stateid of readwrite
  requests.
 A lost lock - don't even consider delegations 
 returns true if delegation stateid found and copied 
		 nfs4_copy_delegation_stateid() didn't over-write
		  dst, so it still has the lock stateid which we now
		  choose to use.
  Increment the seqid if the OPENOPEN_DOWNGRADECLOSE succeeded, or
  failed with a seqid incrementing error -
  see comments nfs4.h:seqid_mutating_error()
 Non-seqid mutating errors 
	
	  Note: no locking needed as we are guaranteed to be first
	  on the sequence list
  Increment the seqid if the LOCKLOCKU succeeded, or
  failed with a seqid incrementing error -
  see comments nfs4.h:seqid_mutating_error()
  Schedule the nfs_client asynchronous state management routine
	 The rcu_read_lock() is not strictly necessary, as the state
	  manager is the only thread that ever changes the rpc_xprt
  Schedule a lease recovery attempt
  nfs4_schedule_migration_recovery - trigger migration recovery
  @server: FSID that is migrating
  Returns zero if recovery has started, otherwise a negative NFS4ERR
  value is returned.
  nfs4_schedule_lease_moved_recovery - start lease-moved recovery
  @clp: server to check for moved leases
  nfs40_handle_cb_pathdown - return all delegations after NFS4ERR_CB_PATH_DOWN
  @clp: client to process
  Set the NFS4CLNT_LEASE_EXPIRED state in order to force a
  resend of the SETCLIENTID and hence re-establish the
  callback channel. Then return all existing delegations.
 Don't recover state that expired before the reboot 
 Guard against delegation returns and new lockunlock calls 
 !CONFIG_NFS_V4_2 
 CONFIG_NFS_V4_2 
 CONFIG_NFS_V4_2 
	 Note: we rely on the sp->so_states list being ordered 
	  so that we always reclaim open(O_RDWR) andor open(O_WRITE)
	  states first.
	  This is needed to ensure that the server won't give us any
	  read delegations that we have to return if, say, we are
	  recovering after a network partition or a reboot from a
	  server that doesn't support a grace period.
 CONFIG_NFS_V4_2 
 Open state on this file cannot be recovered 
 CONFIG_NFS_V4_2 
 Mark all delegations for reclaim 
 Notify the server we're done reclaiming our state 
 Zero session reset errors 
 Is the client already known to have an expired lease? 
 Set NFS4CLNT_LEASE_EXPIRED and reclaim reboot state for all v4.0 errors
  and for recoverable errors on EXCHANGE_ID for v4.1
 Lease confirmation error: retry after purging the lease 
	case -NFS4ERR_NOT_SAME:  FixMe: implement recovery
  Returns zero or a negative errno.  NFS4ERR values are converted
  to local errno values.
  Try remote migration of one FSID from a source server to a
  destination server.  The source server provides a list of
  potential destinations.
  Returns zero or a negative NFS4ERR status code.
  Returns zero or a negative NFS4ERR status code.
  Test each nfs_server on the clp's cl_superblocks list to see
  if it's moved to another server.  Stop when the server no longer
  returns NFS4ERR_LEASE_MOVED.
 wasn't this one 
 there are more 
  nfs4_discover_server_trunking - Detect server IP address trunking
  @clp: nfs_client under test
  @result: OUT: found nfs_client, or clp
  Returns zero or a negative errno.  If zero is returned,
  an nfs_client pointer is planted in "result".
  Note: since we are invoked in process context, and
  not from inside the state manager, we cannot use
  nfs4_handle_reclaim_lease_error().
 No point in retrying if we already used RPC_AUTH_UNIX 
		 Note: this is safe because we haven't yet marked the
		  client as ready, so we are the only user of
		  clp->cl_rpcclient
	case -NFS4ERR_NOT_SAME:  FixMe: implement recovery
 Use CHECK_LEASE to ping the server with a SEQUENCE 
 FIXME: For now, we destroy all layouts. 
	
	  If we're called from the state manager thread, then assume we're
	  already handling the RECLAIM_NEEDED andor STATE_REVOKED.
	  Those flags are expected to remain set until we're done
	  recovering (see RFC5661, section 18.46.3).
 Note: IOMODE_READ + IOMODE_RW == IOMODE_ANY 
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
 Ensure exclusive access to NFSv4 state 
 We're going to have to re-establish a clientid 
 Initialize or reset the session 
 Send BIND_CONN_TO_SESSION 
 First recover reboot state... 
 Detect expired delegations... 
 Now recover expired state... 
 Did we race with an attempt to give us more work? 
   fsnfsnfs4xdr.c
   Client-side XDR for NFSv4.
   Copyright (c) 2002 The Regents of the University of Michigan.
   All rights reserved.
   Kendrick Smith <kmsmith@umich.edu>
   Andy Adamson   <andros@umich.edu>
   Redistribution and use in source and binary forms, with or without
   modification, are permitted provided that the following conditions
   are met:
   1. Redistributions of source code must retain the above copyright
      notice, this list of conditions and the following disclaimer.
   2. Redistributions in binary form must reproduce the above copyright
      notice, this list of conditions and the following disclaimer in the
      documentation andor other materials provided with the distribution.
   3. Neither the name of the University nor the names of its
      contributors may be used to endorse or promote products derived
      from this software without specific prior written permission.
   THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
   WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
   MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
   DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
   FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
   CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
   SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
   BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
   LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
   NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 Mapping from NFS error code to "errno" error code. 
 NFSv4 COMPOUND tags are only wanted for debugging purposes 
 lock,open owner id:
  we currently use size 2 (u64) out of (NFS4_OPAQUE_LIMIT  >> 2)
 PI(4 bytes) + LFS(4 bytes) + 1(for null terminator?) + MAXLABELLEN 
 We support only one layout type per file system 
 This is based on getfattr, which uses the most attributes: 
 The 5 accounts for the PNFS attributes, and assumes that at most three
  layout types will be returned.
 lease time  + \
 max filesize  + \
 max read  + \
 max write  + \
 time delta  + \
 fs layout types  + \
 layout blksize  + \
 clone blksize  + \
 change attr type  + \
 xattr support )
 client name  \
 sc_prog  + \
 sc_cb_ident 
 clientid  + \
 co_ownerid.len  + \
 eia_clientowner  \
 flags  + \
 spa_how  + \
 max is SP4_MACH_CRED (for now)  + \
 implementation id array of size 1  + \
 nii_domain  + \
 nii_name  + \
 nii_date )
 eir_clientid  + \
 eir_sequenceid  + \
 eir_flags  + \
 spr_how  + \
 max is SP4_MACH_CRED (for now)  + \
 eir_server_owner.so_minor_id  + \
 eir_server_owner.so_major_id<>  \
 eir_server_scope<>  \
 eir_server_impl_id array length  + \
 nii_domain  + \
 nii_name  + \
 nii_date )
 ca_rdma_ird.len (0) )
 ca_rdma_ird.len  + \
 ca_rdma_ird )
 csa_clientid  + \
 csa_sequence  + \
 csa_flags  + \
 csa_cb_program  + \
 csa_sec_parms.len (1)  + \
 cb_secflavor (AUTH_SYS)  + \
 stamp  + \
 machinename.len  + \
 uid  + \
 gid  + \
 gids.len (0) )
 csr_sequence  + \
 csr_flags  + \
 bctsa_sessid  \
 bctsa_dir  + \
 bctsa_use_conn_in_rdma_mode )
 bctsr_sessid  \
 bctsr_dir  + \
 bctsr_use_conn_in_rdma_mode )
 layout type  + \
 maxcount  + \
 bitmap size  + \
 notification bitmap length  + \
 notification bitmap, word 0 )
 layout type  + \
 opaque devaddr4 length  + \
 devaddr4 payload is read into page  \
 notification bitmap length  + \
 notification bitmap, word 0  + \
 possible XDR padding )
 offset  + \
 length  + \
 reclaim  + \
 new offset (true)  + \
 last byte written  + \
 nt_timechanged (false)  + \
 layoutupdate4 layout type  + \
 layoutupdate4 opaqueue len )
				   the actual content of layoutupdate4 should
				     be allocated by drivers and spliced in
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
 XXX: large enough? 
 XXX: large enough? 
 CONFIG_NFS_V4_1 
 expected reply words 
 Trim empty words 
	 initialize running count of expected bytes in reply.
	  NOTE: the replied tag SHOULD be the same is the one sent,
	
	  We reserve enough space to write the entire attribute buffer at once.
 XXX 
 goto out; 
 goto out; 
 out: 
  opcode,type,reclaim,offset,length,new_lock_owner = 32
  open_seqid,open_stateid,lock_seqid,lock_owner.clientid, lock_owner.id = 40
 for linux, share_deny = 0 always 
  opcode 4, seqid 4, share_access 4, share_deny 4, clientid 8, ownerlen 4,
  owner 4 = 32
 Use mounted_on_fileid only if the server supports it 
 NFSv4.1 operations 
 implementation id array length=1 
 just send zeros for nii_date - the date is in nii_name 
 implementation id array length=0 
	
	  Assumes OPEN is the biggest non-idempotent compound.
	  2 is the verifier.
Sequence id 
flags 
 Fore Channel 
 header padding size 
 max req size 
 max resp size 
 Max resp sz cached 
 max operations 
 max requests 
 rdmachannel_attrs 
 Back Channel 
 header padding size 
 max req size 
 max resp size 
 Max resp sz cached 
 max operations 
 max requests 
 rdmachannel_attrs 
 cb_program 
 auth_sys 
 authsys_parms rfc1831 
 stamp 
 UID 
 GID 
 No more gids 
 CONFIG_NFS_V4_1 
	
	  Sessionid + seqid + slotid + max slotid + cache_this
 CONFIG_NFS_V4_1 
 gdia_maxcount 
 bitmap length 
 Signal layout available 
 Only whole file layouts 
 offset 
 length 
 reclaim 
 newoffset = TRUE 
 newoffset = FALSE 
 Never send time_modify_changed 
 type 
 reclaim. always 0 for now 
 CONFIG_NFS_V4_1 
  END OF "GENERIC" ENCODE ROUTINES.
 CONFIG_NFS_V4_1 
  Encode an ACCESS request
  Encode LOOKUP request
  Encode LOOKUPP request
  Encode LOOKUP_ROOT request
  Encode REMOVE request
  Encode RENAME request
  Encode LINK request
  Encode CREATE request
  Encode SYMLINK request
  Encode GETATTR request
  Encode a CLOSE request
  Encode an OPEN request
  Encode an OPEN_CONFIRM request
  Encode an OPEN request with no attributes.
  Encode an OPEN_DOWNGRADE request
  Encode a LOCK request
  Encode a LOCKT request
  Encode a LOCKU request
  Encode a READLINK request
  Encode a READDIR request
  Encode a READ request
  Encode an SETATTR request
  Encode a GETACL request
  Encode a WRITE request
   a COMMIT request
  FSINFO request
  a PATHCONF request
  a STATFS request
  GETATTR_BITMAP request
  a RENEW request
  a SETCLIENTID request
  a SETCLIENTID_CONFIRM request
  DELEGRETURN request
  Encode FS_LOCATIONS request
  Encode SECINFO request
  Encode FSID_PRESENT request
  BIND_CONN_TO_SESSION request
  EXCHANGE_ID request
  a CREATE_SESSION request
  a DESTROY_SESSION request
  a DESTROY_CLIENTID request
  a SEQUENCE request
  a GET_LEASE_TIME request
  a RECLAIM_COMPLETE request
  Encode GETDEVICEINFO request
	 set up reply kvec. device_addr4 opaque data is read into the
   Encode LAYOUTGET request
   Encode LAYOUTCOMMIT request
  Encode LAYOUTRETURN request
  Encode SECINFO_NO_NAME request
   Encode TEST_STATEID request
   Encode FREE_STATEID request
 CONFIG_NFS_V4_1 
 Dummy routine 
 a root pathname is sent as a zero component4 
 Ignore borken servers that return unrequested attrs 
 layout type 
 thi_hintset bitmap 
 thi_hintlist length 
 thi_hintlist 
  Thresholds on pNFS direct IO vrs MDS IO
 Did the server return an unrequested attribute? 
  Decode potentially multiple layout types.
 pNFS is not supported by the underlying file system 
 Decode and set first layout type, move xdr->p past unused types 
 If we get too many, then just cap it at the max 
  The type of file system exported.
  Note we must ensure that layouttype is set in any non-error case.
  The prefered block size for layout directed io
  The granularity of a CLONE operation.
 ??? 
 Zero handle first to allow comparisons 
  We create the owner, so we know a proper owner.id length is 4.
 read 32 bytes 
 read 2 8-byte long words 
 4 byte read 
 manipulate file lock 
 read 8 bytes 
 read 4 bytes   
 variable size field 
 This is too sick! 
 Ignore for now 
 Convert length of symlink 
	
	  The XDR encode routine has set things up so that
	  the link text will be copied directly into the
	  buffer.  We just have to do overflow-checking,
	  and null-terminate the text (the VFS expects
	  null-termination).
		 The bitmap (xdr len + bitmaps) and the attr xdr len words
		  are stored with the acl data to handle the problem of
 Check for receive buffer overflow 
 skip netid string 
 skip uaddr string 
 server_owner4.so_minor_id 
 server_owner4.so_major_id 
 server_scope4 
 Implementation Id 
 nii_domain 
 nii_name 
 nii_date 
 if there's more than one entry, ignore the rest 
 headerpadsz 
 no support for header padding yet 
 skip rdma_attrs 
 dir flags, rdma mode bool 
 seqid, flags 
 Channel attributes 
 CONFIG_NFS_V4_1 
	
	  If the server returns different values for sessionID, slotID or
	  sequence number, the server is looney tunes.
 seqid 
 slot id 
 highest slot id 
 target highest slot id 
 result flags 
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
	
	  Get the length of the opaque device_addr4. xdr_read_pages places
	  the opaque device_addr4 in the xdr_buf->pages (pnfs_device->pages)
	  and places the remaining xdr data in xdr_buf->tail
 Parse notification bitmap, verifying that it is zero. 
		 We only handle a length one array at the moment.  Any
		  further entries are just ignored.  Note that this means
		  the client may see a response that is less than the
		  minimum it requested.
 throw away new size 
 CONFIG_NFS_V4_1 
  END OF "GENERIC" DECODE ROUTINES.
  Decode OPEN_DOWNGRADE response
  Decode ACCESS response
  Decode LOOKUP response
  Decode LOOKUPP response
  Decode LOOKUP_ROOT response
  Decode REMOVE response
  Decode RENAME response
  Decode LINK response
	
	  Note order: OP_LINK leaves the directory as the current
	              filehandle.
  Decode CREATE response
  Decode SYMLINK response
  Decode GETATTR response
  Encode an SETACL request
  Decode SETACL response
  Decode GETACL response
  Decode CLOSE response
  Decode OPEN response
  Decode OPEN_CONFIRM response
  Decode OPEN response
  Decode SETATTR response
  Decode LOCK response
  Decode LOCKT response
  Decode LOCKU response
  Decode READLINK response
  Decode READDIR response
  Decode Read response
  Decode WRITE response
  Decode COMMIT response
  Decode FSINFO response
  Decode PATHCONF response
  Decode STATFS response
  Decode GETATTR_BITMAP response
  Decode RENEW response
  Decode SETCLIENTID response
  Decode SETCLIENTID_CONFIRM response
  Decode DELEGRETURN response
  Decode FS_LOCATIONS response
  Decode SECINFO response
  Decode FSID_PRESENT response
  Decode BIND_CONN_TO_SESSION response
  Decode EXCHANGE_ID response
  Decode CREATE_SESSION response
  Decode DESTROY_SESSION response
  Decode DESTROY_CLIENTID response
  Decode SEQUENCE response
  Decode GET_LEASE_TIME response
  Decode RECLAIM_COMPLETE response
  Decode GETDEVINFO response
  Decode LAYOUTGET response
  Decode LAYOUTRETURN response
  Decode LAYOUTCOMMIT response
  Decode SECINFO_NO_NAME response
  Decode TEST_STATEID response
  Decode FREE_STATEID response
 CONFIG_NFS_V4_1 
  nfs4_decode_dirent - Decode a single NFSv4 directory entry stored in
                       the local page cache.
  @xdr: XDR stream where entry resides
  @entry: buffer to fill in with entry data
  @plus: boolean indicating whether this should be a readdirplus entry
  Returns zero if successful, otherwise a negative errno value is
  returned.
  This function is not invoked during READDIR reply decoding, but
  rather whenever an application invokes the getdents(2) system call
  on a directory already in our cache.
	
	  In case the server doesn't return an inode number,
	  we fake one here.  (We don't use inode number 0,
	  since glibc seems to choke on it...)
  We need to translate between nfs status return values and
  the local errno values which may not be the same.
  Convert an NFS error code to a local one.
  This one is used jointly by NFSv2 and NFSv3.
 The server is looney tunes. 
	 If we cannot translate the error, the recovery routines should
	  handle it.
	  Note: remaining NFSv4 error codes have values > 10000, so should
	  not conflict with native Linux error codes.
 CONFIG_NFS_V4_2 
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfsnfs4namespace.c
  Copyright (C) 2005 Trond Myklebust <Trond.Myklebust@netapp.com>
  - Modified by David Howells <dhowells@redhat.com>
  NFSv4 namespace
  Work out the length that an NFSv4 path would render to as a standard posix
  path, with a leading slash but no terminating slash.
 Adding "foo" 
  Convert the NFSv4 pathname components into a standard posix path.
  return the path component of "<server>:<path>"
   nfspath - the "<server>:<path>" string
   end - one past the last char that could contain "<server>:"
  returns NULL on failure
 parse [] escaped IPv6 addrs 
 otherwise split on first colon 
  Determine the mount path as a string
  Check that fs_locations::fs_root [RFC3530 6.3] is a prefix for what we
  believe to be the server path to this dentry
  nfs_find_best_sec - Find a security mechanism supported locally
  @clnt: pointer to rpc_clnt
  @server: NFS server struct
  @flavors: List of security tuples returned by SECINFO procedure
  Return an rpc client that uses the first security mechanism in
  "flavors" that is locally supported.  The "flavors" array
  is searched in the order returned from the server, per RFC 3530
  recommendation and each flavor is checked for membership in the
  sec= mount option list if it exists.
  Return -EPERM if no matching flavor is found in the array.
  Please call rpc_shutdown_client() when you are done with this rpc client.
 does the pseudoflavor match a sec= mount opt? 
 Cloning creates an rpc_auth for the flavor 
				
				 Check that the user actually can use the
				 flavor. This is mostly for RPC_AUTH_GSS
				 where cr_init obtains a gss context
  nfs4_negotiate_security - in response to an NFS4ERR_WRONGSEC on lookup,
  return an rpc_clnt that uses the best available security flavor with
  respect to the secinfo flavor list and the sec= mount options.
  @clnt: RPC client to clone
  @inode: directory inode
  @name: lookup name
  Please call rpc_shutdown_client() when you are done with this rpc client.
	 Allocate a buffer big enough to hold any of the hostnames plus a
	  terminating char and also a buffer big enough to hold the hostname
	  plus a colon plus the path.
  nfs_follow_referral - set up mountpoint when hitting a referral on moved error
  @fc: pointer to struct nfs_fs_context
  @locations: array of NFSv4 server location information
 Ensure fs path is a prefix of current dentry path 
  nfs_do_refmount - handle crossing a referral on server
  @dentry - dentry of referral
 BUG_ON(IS_ROOT(dentry)); 
 Get locations 
 Look it up again to get its attributes and sec flavor 
  Try one location from the fs_locations array.
  Returns zero on success, or a negative errno value.
  nfs4_replace_transport - set up transport to destination server
  @server: export being migrated
  @locations: fs_locations array
  Returns zero on success, or a negative errno value.
  The client tries all the entries in the "locations" array, in the
  order returned by the server, until one works or the end of the
  array is reached.
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfscallback_proc.c
  Copyright (C) 2004 Trond Myklebust
  NFSv4 callback procedures
 Always set for v4.0. Set in cb_sequence for v4.1 
 Always set for v4.0. Set in cb_sequence for v4.1 
 Set up a helper thread to actually return the delegation 
  Lookup a layout inode by stateid
  Note: returns a refcount on the inode and superblock
  Lookup a layout inode by filehandle.
  Note: returns a refcount on the inode and superblock
  Enforce RFC5661 section 12.5.5.2.1. (Layout Recall and Return Sequencing)
 Is the stateid not initialised? 
 Mismatched stateid? 
 Are we already in a layout recall situation? 
 Check that the stateid matches what we think it should be. 
 Crazy server! 
	
	  Enforce RFC5661 Section 12.5.5.2.1.5 (Bulk Recall and Return)
 There are layout segments that need to be returned 
 Embrace your forgetfulness! 
 Free all lsegs that are attached to commit buckets 
 Pretend we got a CB_LAYOUTRECALL(ALL) 
 FIXME we ignore errors, what should we do? 
  Validate the sequenceID sent by the server.
  Return success if the sequenceID is one more than what we last saw on
  this slot, accounting for wraparound.  Increments the slot's sequence.
  We don't yet implement a duplicate request cache, instead we set the
  back channel ca_maxresponsesize_cached to zero. This is OK for now
  since we only currently implement idempotent callbacks anyway.
  We have a single slot backchannel at this time, so we don't bother
  checking the used_slots bit array on the table.  The lower layer guarantees
  a single outstanding callback request at a time.
 Replay 
 Signal process_op to set this error on next op 
 Liar! We never allowed you to set csa_cachethis != 0 
 Note: wraparound relies on seq_nr being of type u32 
 Misordered request 
  For each referring call triple, check the session's slot table for
  a match.  If the slot is in use and the sequence numbers match, the
  client is still waiting for a response to the original request.
	
	  XXX When client trunking is implemented, this becomes
	  a session lookup from within the loop
 Set up res before grabbing the spinlock 
 state manager is resetting the session 
		 Return NFS4ERR_BADSESSION if we're draining the session
		  in order to reset it.
 The ca_maxresponsesize_cached is 0 with no DRC 
	
	  Check for pending referring calls.  If a match is found, a
	  related callback was received before the response to the original
	  call.
	
	  RFC5661 20.9.3
	  If CB_SEQUENCE returns an error, then the state of the slot
	  (sequence ID, cached reply) MUST NOT change.
 put in nfs4_callback_compound 
 set in cb_sequence 
 Reduce the fore channel's max_slots to the target value 
 set in cb_sequence 
 set in cb_sequence 
 Don't wake anybody if the string looked bogus 
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_2 
 SPDX-License-Identifier: GPL-2.0
  linuxfsnfscallback_xdr.c
  Copyright (C) 2004 Trond Myklebust
  NFSv4 callback encodedecode procedures
 opcode, status
 bitmap length, 3 bitmaps
 change, size, ctime, mtime \
 seqid, 3 slotids
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_2 
 Internal error code 
  svc_process_common() looks for an XDR encoder to know when
  not to drop a Reply.
 Check for minor version support 
 ignored by v4.1 and v4.2 
	 Depite the spec's xdr, iomode really belongs in the FILE switch,
	  as it is unusable and ignored with the other types.
 Num of device notifications 
 Decode each dev notification 
 bitmap size 
 opaque size 
 Only try to decode if the length is right 
 skip "lock id:" 
 CONFIG_NFS_V4_1 
 skip the always zero field 
 decode count, stable_how, verifier 
 decode fh 
 decode stateid 
 decode status 
 CONFIG_NFS_V4_2 
	
	  Let the state manager know callback processing done.
	  A single slot, so highest used slotid is either 0 or -1
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_2 
 CONFIG_NFS_V4_2 
  Decode, process and encode a COMPOUND
	 Buffer overflow in decode_ops_hdr or encode_ops_hdr. Return
  Define NFS4 callback COMPOUND ops.
 CONFIG_NFS_V4_1 
 CONFIG_NFS_V4_2 
  Define NFS4 callback procedures
 SPDX-License-Identifier: GPL-2.0-only
  Module for pnfs flexfile layout driver.
  Copyright (c) 2014, Primary Data, Inc. All rights reserved.
  Tao Peng <bergwolf@primarydata.com>
 fh.data 
  Currently only stringified uids and gids are accepted.
  I.e., kerberos is not supported to the DSes, so no pricipals.
  That means that one common function will suffice, but when
  principals are added, this should be split to accomodate
  calls to both nfs_map_name_to_uid() and nfs_map_group_to_gid().
 opaque_length(4)
 opaque body 
 Mergeable: copy info from 'old' to 'new' 
 stripe unit and mirror_array_cnt 
 FIXME: allow for striping? 
 deviceid 
 efficiency 
 stateid 
 fh 
 user 
 group 
 swap cred ptrs so free_mirror will clean up old 
 first IO request? 
 mirrors are initially sorted by efficiency 
 Use full layout for now 
 Sleep for 1 second before retrying 
 If no lseg, fall back to write through mds 
 Use a direct mapping of ds_idx to pgio mirror_idx 
 Sleep for 1 second before retrying 
 no lseg means that pnfs is not in use, so no mirroring here 
 Invalidate Layout errors 
 mapped NFS4ERR_STALE 
 mapped NFS4ERR_BADHANDLE 
 mapped NFS4ERR_ISDIR 
		
		  Destroy layout so new io will get a new layout.
		  Layout will not be destroyed until all current lseg
		  references are put. Mark layout as invalid to resend failed
		  io and all io waiting on the slot table to the MDS until
		  layout is destroyed and a new valid layout is obtained.
 RPC connection errors 
 Retry all errors through either pNFS or MDS except for -EJUKEBOX 
 File access problems. Don't mark the device as unavailable 
 FIXME: Need to prevent infinite looping here. 
 Handle the case of an invalid layout segment 
 should never happen 
		
		  Don't return the layout if this is a read and we still
		  have layouts to try
 NFS_PROTO call done callback routines 
  We reference the rpc_cred of the first WRITE that triggers the need for
  a LAYOUTCOMMIT, and use it to send the layoutcommit compound.
  rfc5661 is not clear about which credential should be used.
  Flexlayout client should treat DS replied FILE_SYNC as DATA_SYNC, so
  to follow http:www.rfc-editor.orgerrata_search.php?rfc=5661&eid=2751
  we always send layoutcommit after DS writes.
  Call ops for the async readwrite cases
  In the case of dense layouts, the offset needs to be reset to its
  original value.
 Note this may cause RPC to be resent 
 Note: if the write is unstable, don't set end_offs until commit 
 zero out fattr since we don't care DS attr at all 
 Note this may cause RPC to be resent 
	
	  Note that if we ever decide to split across DSes,
	  then we may need to handle dense-like offsets.
 Perform an asynchronous read to ds 
 Perform async writes. 
	
	  Note that if we ever decide to split across DSes,
	  then we may need to handle dense-like offsets.
 Perform an asynchronous write 
	 FIXME: Assume that there is only one NFS version available
	  for the DS.
 This assume we always return _ALL_ layouts 
 report nothing for now 
	
	  RFC 4291, Section 2.2.2
	 
	  Shorthanded ANY address
	
	  RFC 4291, Section 2.2.2
	 
	  Shorthanded loopback address
	
	  RFC 4291, Section 2.2.3
	 
	  Special presentation address format for mapped v4
	  addresses.
	
	  RFC 4291, Section 2.2.1
 Derived from rpc_sockaddr2uaddr 
 netaddr4 
 nfs_fh4 
 ff_io_latency4 read 
 ff_io_latency4 write 
 nfstime4 
 bool 
 layoutupdate length 
 mirror refcount put in cleanup_layoutstats 
 For now, send at most PNFS_LAYOUTSTATS_MAXDEV statistics 
 1 page or so... 
 SPDX-License-Identifier: GPL-2.0
  Device operations for the pnfs nfs4 file layout driver.
  Copyright (c) 2014, Primary Data, Inc. All rights reserved.
  Tao Peng <bergwolf@primarydata.com>
 Decode opaque device data and construct new_ds using it 
 set up xdr stream 
 multipath count 
 multipath ds 
 version count 
		 20 = version(4) + minor_version(4) + rsize(4) + wsize(4) +
		
		  check for valid majorminor combination.
		  currently we support dataserver which talk:
		    v3, v4.0, v4.1, v4.2
 If DS was already in cache, free ds addrs 
 If ranges overlap or are contiguous, they are the same 
 Do insertion sort w merges 
 Add entry "dserr" _before_ entry "err" 
 Entries match, so merge "err" into "dserr" 
 FIXME: For now assume there is only 1 version available for the DS 
 check for race with another call to this function 
  nfs4_ff_layout_prepare_ds - prepare a DS connection for an RPC call
  @lseg: the layout segment we're operating on
  @mirror: layout mirror describing the DS to use
  @fail_return: return layout on connect failure?
  Try to prepare a DS connection to accept an RPC call. This involves
  selecting a mirror to use and connecting the client to it if it's not
  already connected.
  Since we only need a single functioning mirror to satisfy a read, we don't
  want to return the layout if there is one. For writes though, any down
  mirror should result in a LAYOUTRETURN. @fail_return is how we distinguish
  between the two cases.
  Returns a pointer to a connected DS object on success or NULL on failure.
 matching smp_wmb() in _nfs4_pnfs_v34_ds_connect 
	 FIXME: For now we assume the server sent only one version of NFS
	  to use for the DS.
 connect success, check rsizewsize limit 
  nfs4_ff_find_or_create_ds_client - Find or create a DS rpc client
  @mirror: pointer to the mirror
  @ds_clp: nfs_client for the DS
  @inode: pointer to inode
  Find or create a DS rpc client with th MDS server rpc client auth flavor
  in the nfs_client cl_ds_clients list.
 For NFSv3 DS, flavor is set when creating DS connections 
 called with inode i_lock held 
		 offset(8) + length(8) + stateid(NFS4_STATEID_SIZE)
		  + array length + deviceid(NFS4_DEVICEID4_SIZE)
		  + status(4) + opnum(4)
 Encode 1 error 
 If we're over the max, discard all remaining entries 
 Note: RW layout needs all mirrors available 
   Module for the pnfs nfs4 file layout driver.
   Defines all IO and Policy interface operations, plus code
   to register itself with the pNFS client.
   Copyright (c) 2002
   The Regents of the University of Michigan
   All Rights Reserved
   Dean Hildebrand <dhildebz@umich.edu>
   Permission is granted to use, copy, create derivative works, and
   redistribute this software and such derivative works for any purpose,
   so long as the name of the University of Michigan is not used in
   any advertising or publicity pertaining to the use or distribution
   of this software without specific, written prior authorization. If
   the above copyright notice or any other identification of the
   University of Michigan is included in any copy of any portion of
   this software, then the disclaimer below must also be included.
   This software is provided as is, without representation or warranty
   of any kind either express or implied, including without limitation
   the implied warranties of merchantability, fitness for a particular
   purpose, or noninfringement.  The Regents of the University of
   Michigan shall not be liable for any damages, including special,
   indirect, incidental, or consequential damages, with respect to any
   claim arising out of or in connection with the use of the software,
   even if it has been or is hereafter advised of the possibility of
   such damages.
 This function is used by the layout driver to calculate the
  offset of the file on the dserver based on whether the
  layout type is STRIPE_DENSE or STRIPE_SPARSE
 DS session errors 
 Invalidate Layout errors 
 mapped NFS4ERR_STALE 
 mapped NFS4ERR_BADHANDLE 
 mapped NFS4ERR_ISDIR 
		
		  Destroy layout so new io will get a new layout.
		  Layout will not be destroyed until all current lseg
		  references are put. Mark layout as invalid to resend failed
		  io and all io waiting on the slot table to the MDS until
		  layout is destroyed and a new valid layout is obtained.
 RPC connection errors 
 NFS_PROTO call done callback routines 
  We reference the rpc_cred of the first WRITE that triggers the need for
  a LAYOUTCOMMIT, and use it to send the layoutcommit compound.
  rfc5661 is not clear about which credential should be used.
 Note: if the write is unstable, don't set end_offs until commit 
  Call ops for the async readwrite cases
  In the case of dense layouts, the offset needs to be reset to its
  original value.
 lost lock, terminate IO 
 Note this may cause RPC to be resent 
 zero out the fattr 
 lost lock, terminate IO 
 Note this may cause RPC to be resent 
 Retrieve the correct rpc_client for the byte range 
 No multipath support. Use first DS 
 Perform an asynchronous read to ds 
 Perform async writes. 
 Retrieve the correct rpc_client for the byte range 
 Perform an asynchronous write 
 Is the deviceid already set? If so, we're good. 
 find and reference the deviceid 
 Found deviceid is unavailable 
	
	  Atomic compare and xchange to ensure we don't scribble
	  over a non-NULL pointer.
  filelayout_check_layout()
  Make sure layout segment parameters are sane WRT the device.
  At this point no generic layer initialization of the lseg has occurred,
  and nothing has been added to the layout_hdr cache.
 FIXME: remove this check when layout segment support is added 
	 20 = ufl_util (4), first_stripe_index (4), pattern_offset (8),
	 Note that a zero value for num_fh is legal for STRIPE_SPARSE.
 Do we want to use a mempool here? 
 This assumes a single RW lseg 
  filelayout_pg_test(). Called by nfs_can_coalesce_requests()
  Return 0 if @req cannot be coalesced into @pgio, otherwise return the number
  of bytes (maximum @req->wb_bytes) that can be coalesced.
 calls nfs_generic_pg_test 
 see if req and prev are in the same stripe 
 calculate remaining bytes in the current stripe 
 If no lseg, fall back to read through mds 
 If no lseg, fall back to write through mds 
		 Note that we are calling nfs4_fl_calc_j_index on each page
		  that ends up being committed to a data server.  An attractive
		  alternative is to add a field to nfs_write_data and nfs_page
		  to store the value calculated in filelayout_write_pagelist
		  and just use that here.
 Use the MDS OPEN fh set in nfs_read_rpcsetup 
 1 page or so... 
   Device operations for the pnfs nfs4 file layout driver.
   Copyright (c) 2002
   The Regents of the University of Michigan
   All Rights Reserved
   Dean Hildebrand <dhildebz@umich.edu>
   Garth Goodson   <Garth.Goodson@netapp.com>
   Permission is granted to use, copy, create derivative works, and
   redistribute this software and such derivative works for any purpose,
   so long as the name of the University of Michigan is not used in
   any advertising or publicity pertaining to the use or distribution
   of this software without specific, written prior authorization. If
   the above copyright notice or any other identification of the
   University of Michigan is included in any copy of any portion of
   this software, then the disclaimer below must also be included.
   This software is provided as is, without representation or warranty
   of any kind either express or implied, including without limitation
   the implied warranties of merchantability, fitness for a particular
   purpose, or noninfringement.  The Regents of the University of
   Michigan shall not be liable for any damages, including special,
   indirect, incidental, or consequential damages, with respect to any
   claim arising out of or in connection with the use of the software,
   even if it has been or is hereafter advised of the possibility of
   such damages.
 Decode opaque device data and return the result 
 set up xdr stream 
 Get the stripe count (number of stripe index) 
 read stripe indices 
 Check the multipath list count 
 validate stripe indices are all < num 
 multipath count 
 If DS was already in cache, free ds addrs 
 stripe_indicies was part of dsaddr 
  Want res = (offset - layout->pattern_offset) layout->stripe_unit
  Then: ((res + fsi) % dsaddr->stripe_count)
 Use the MDS OPEN fh set in nfs_read_rpcsetup 
 Upon return, either ds is connected, or ds is NULL 
   Copyright (c) 2006,2007 The Regents of the University of Michigan.
   All rights reserved.
   Andy Adamson <andros@citi.umich.edu>
   Fred Isaman <iisaman@umich.edu>
  permission is granted to use, copy, create derivative works and
  redistribute this software and such derivative works for any purpose,
  so long as the name of the university of michigan is not used in
  any advertising or publicity pertaining to the use or distribution
  of this software without specific, written prior authorization.  if
  the above copyright notice or any other identification of the
  university of michigan is included in any copy of any portion of
  this software, then the disclaimer below must also be included.
  this software is provided as is, without representation from the
  university of michigan as to its fitness for any purpose, and without
  warranty by the university of michigan of any kind, either express
  or implied, including without limitation the implied warranties of
  merchantability and fitness for a particular purpose.  the regents
  of the university of michigan shall not be liable for any damages,
  including special, indirect, incidental, or consequential damages,
  with respect to any claim arising out or in connection with the use
  of the software, even if it has been or is hereafter advised of the
  possibility of such damages.
 single volume 
   linuxfsnfsblocklayoutblocklayout.c
   Module for the NFSv4.1 pNFS block layout driver.
   Copyright (c) 2006 The Regents of the University of Michigan.
   All rights reserved.
   Andy Adamson <andros@citi.umich.edu>
   Fred Isaman <iisaman@umich.edu>
  permission is granted to use, copy, create derivative works and
  redistribute this software and such derivative works for any purpose,
  so long as the name of the university of michigan is not used in
  any advertising or publicity pertaining to the use or distribution
  of this software without specific, written prior authorization.  if
  the above copyright notice or any other identification of the
  university of michigan is included in any copy of any portion of
  this software, then the disclaimer below must also be included.
  this software is provided as is, without representation from the
  university of michigan as to its fitness for any purpose, and without
  warranty by the university of michigan of any kind, either express
  or implied, including without limitation the implied warranties of
  merchantability and fitness for a particular purpose.  the regents
  of the university of michigan shall not be liable for any damages,
  including special, indirect, incidental, or consequential damages,
  with respect to any claim arising out or in connection with the use
  of the software, even if it has been or is hereafter advised of the
  possibility of such damages.
 struct bio 
 The data we are handed might be spread across several bios.  We need
  to track when the last one is finished.
 translate to device offset 
 translate to physical disk offset 
 limit length to what the device mapping allows 
 Code assumes extents are page-aligned 
 We've used up the previous extent 
 Get the next one 
 Fill hole w zeroes wo accessing device 
 invalidate map 
 Function scheduled for call during bl_end_par_io_write,
  it marks sectors as written and extends the commitlist.
 Called when last of bios associated with a bl_write_pagelist call finishes 
	 At this point, header->page_aray is a (sequential) list of nfs_pages.
	  We want to write each, and if there is an error set pnfs_error
	  to have it redone using nfs.
 we always write out the whole page 
 We've used up the previous extent 
 Get the next one 
 Tracks info needed to ensure extents in layout obey constraints of spec 
 R or RW 
 Expected start of next non-COW extent 
 Start of INVAL coverage 
 End of COW read coverage 
 Verify the extent meets the layout requirements of the pnfs-block draft,
  section 2.3.1.
 lv->mode == IOMODE_RW 
		 It looks like you might want to min this with lv->start,
		  but you really don't.
	
	  The next three values are read in as bytes, but stored in the
	  extent structure in 512-byte granularity.
	
	  Decode individual extents, putting them in temporary staging area
	  until whole layout is decoded to make error recovery easier.
 Our extent block devices are unavailable 
	
	  Always accept buffered writes, higher layers take care of the
	  right alignment.
		
		  If the write goes up to the inode size, just write
		  the full page.  Data past the inode size is
		  guaranteed to be zeroed by the higher level client
		  code, and this behaviour is mandated by RFC 5663
		  section 2.3.2.
  Return 0 if @req cannot be coalesced into @pgio, otherwise return the number
  of bytes (maximum @req->wb_bytes) that can be coalesced.
  Return the number of contiguous bytes for a given inode
  starting at page frame idx.
 Optimize common case that writes from 0 to end of file 
  Return 0 if @req cannot be coalesced into @pgio, otherwise return the number
  of bytes (maximum @req->wb_bytes) that can be coalesced.
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2014-2016 Christoph Hellwig.
 error, should not happen 
 truncate offset to the beginning of the stripe 
 disk offset of the stripe 
  Try to open the udev path for the WWN.  At least on Debian the udev
  by-id path will always point to the dm-multipath device if one exists.
  Try to open the RHFedora specific dm-mpath udev path for this WWN, as the
  wwn- links will only point to the first discovered SCSI device there.
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2014-2016 Christoph Hellwig.
	
	  First remove all COW extents or holes from written to range.
	
	  Then mark all invalid extents in the range as written to.
 keep counting.. 
			
			  Mark as written and try again.
			 
			  XXX: some real error handling here wouldn't hurt..
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0
   linuxfsprockmsg.c
   Copyright (C) 1992  by Linus Torvalds
 SPDX-License-Identifier: GPL-2.0-only
  Copyright (c) 2010 Werner Fink, Jiri Slaby
  This is handler for procconsoles
 SPDX-License-Identifier: GPL-2.0
  Logic: we've got two memory sums for each process, "shared", and
  "non-shared". Shared memory may get counted more than once, for
  each process that owns it. Non-shared memory is counted
  accurately.
 includes kernel stack 
	
	  We make no effort to guess what a given thread considers to be
	  its "stack".  It's not even well-defined for programs written
	  languages like Go.
  display a single VMA to a sequenced file
  display mapping lines for a particular process's procpidmaps
 pin the task and mm whilst we play with them 
 start from the Nth VMA 
 SPDX-License-Identifier: GPL-2.0
 Nothing to do 
 SPDX-License-Identifier: GPL-2.0
	
	  Note: to minimize their overhead, mm maintains hiwater_vm and
	  hiwater_rss only when about to lower total_vm or rss.  Any
	  collector of these hiwater stats must therefore get total_vm
	  and rss too, which will usually be the higher.  Barriers? not
	  worth the effort, such snapshots can always be inconsistent.
 split executable areas between text and lib 
  Save get_task_policy() for show_numa_map().
 See m_next(). Zero at the start or after lseek. 
  Indicate if the VMA is a stack for the given task; for
  procPIDmaps that is the stack of the main task.
	
	  We make no effort to guess what a given thread considers to be
	  its "stack".  It's not even well-defined for programs written
	  languages like Go.
	
	  Print the dentry name for named mappings, and a
	  special [heap] marker for the heap:
  Proportional Set Size(PSS): my share of RSS.
  PSS of a process is the count of pages it has in memory, where each
  page is divided by the number of processes sharing it.  So if a
  process has 1000 pages all to itself, and 1000 shared with one other
  process, its PSS will be 1500.
  To keep (accumulated) division errors low, we adopt a 64bit
  fixed-point pss counter to minimize division errors. So (pss >>
  PSS_SHIFT) would be the real byte count.
  A shift of 12 before division means (assuming 4K page size):
  	- 1M 3-user-pages add up to 8KB errors;
  	- supports mapcount up to 2^24, or 16M;
  	- supports PSS up to 2^52 bytes, or 4PB.
	
	  First accumulate quantities that depend only on |size| and the type
	  of the compound page.
 Accumulate the size in pages that have been accessed. 
	
	  Then accumulate quantities that may depend on sharing, or that may
	  differ page-by-page.
	 
	  page_count(page) == 1 guarantees the page is mapped exactly once.
	  If any subpage of the compound page mapped with PTE it would elevate
	  page_count().
 CONFIG_SHMEM 
 depth is not used 
 FOLL_DUMP will return -EFAULT on huge zero page 
 pass ;
	
	  The mmap_lock held all the way back in m_start() is what
	  keeps khugepaged out of here and from collapsing things
	  in here.
	
	  Don't forget to update Documentation on changes.
		
		  In case if we meet a flag we don't know about.
 These come out via ProtectionKey: 
 CONFIG_ARCH_HAS_PKEYS 
 CONFIG_HAVE_ARCH_USERFAULTFD_MINOR 
 HUGETLB_PAGE 
  Gather mem stats from @vma with the indicated beginning
  address @start, and keep them in @mss.
  Use vm_start of @vma as the beginning address if @start is 0.
 Invalid start 
		
		  For shared or readonly shmem mappings we know that all
		  swapped out pages belong to the shmem object, and we can
		  obtain the swap value much more efficiently. For private
		  writable mappings, we might have COW pages that are
		  not affected by the parent swapped out pages of the shmem
		  object, so we have to distinguish them during the page walk.
		  Unless we know that the shmem object (or the part mapped by
		  our VMA) has no swapped out pages at all.
 mmap_lock is held in m_start 
 Show the contents common for smaps and smaps_rollup 
		
		  These are meaningful only for smaps_rollup, otherwise two of
		  them are zero, and the other one is the same as Pss.
		
		  Release mmap_lock temporarily if someone wants to
		  access it for write request.
			
			  After dropping the lock, there are four cases to
			  consider. See the following example for explanation.
			 
			    +------+------+-----------+
			    | VMA1 | VMA2 | VMA3      |
			    +------+------+-----------+
			    |      |      |           |
			   4k     8k     16k         400k
			 
			  Suppose we drop the lock after reading VMA2 due to
			  contention, then we get:
			 
			 	last_vma_end = 16k
			 
			  1) VMA2 is freed, but VMA3 exists:
			 
			     find_vma(mm, 16k - 1) will return VMA3.
			     In this case, just continue from VMA3.
			 
			  2) VMA2 still exists:
			 
			     find_vma(mm, 16k - 1) will return VMA2.
			     Iterate the loop like the original one.
			 
			  3) No more VMAs can be found:
			 
			     find_vma(mm, 16k - 1) will return NULL.
			     No more things to do, just break.
			 
			  4) (last_vma_end - 1) is the middle of a vma (VMA'):
			 
			     find_vma(mm, 16k - 1) will return VMA' whose range
			     contains last_vma_end.
			     Iterate VMA' from last_vma_end.
 Case 3 above 
 Case 1 above 
 Case 4 above 
 Case 2 above 
	
	  The soft-dirty tracker uses #PF-s to catch writes
	  to pages, so write-protect the pte as well. See the
	  Documentationadmin-guidemmsoft-dirty.rst for full description
	  of how soft-dirty works.
 See comment in change_huge_pmd() 
 Clear accessed and referenced bits. 
 Clear accessed and referenced bits. 
	
	  Writing 1 to procpidclear_refs affects all pages.
	  Writing 2 to procpidclear_refs only affects anonymous pages.
	  Writing 3 to procpidclear_refs only affects file mapped pages.
	  Writing 4 to procpidclear_refs affects all pages.
			
			  Writing 5 to procpidclear_refs resets the peak
			  resident set size to this mm's current rss value.
 units: PM_ENTRY_BYTES, not bytes 
 End of address space hole, which we mark as non-present. 
 Addresses in the VMA. 
 CONFIG_TRANSPARENT_HUGEPAGE 
	
	  We can assume that @vma always points to a valid one and @end never
	  goes beyond vma->vm_end.
 This function walks within one hugetlb entry in the single call 
 HUGETLB_PAGE 
  procpidpagemap - an array mapping virtual pages to pfns
  For each page in the address space, this file contains one 64-bit entry
  consisting of the following:
  Bits 0-54  page frame number (PFN) if present
  Bits 0-4   swap type if swapped
  Bits 5-54  swap offset if swapped
  Bit  55    pte is soft-dirty (see Documentationadmin-guidemmsoft-dirty.rst)
  Bit  56    page exclusively mapped
  Bits 57-60 zero
  Bit  61    page is file-page or shared-anon
  Bit  62    page swapped
  Bit  63    page present
  If the page is not present but in swap, then the PFN contains an
  encoding of the swap file number and the page's offset into the
  swap. Unmapped pages return a null PFN. This allows determining
  precisely which pages are mapped (or in swap) and comparing mapped
  pages between processes.
  Efficient users of this interface will use procpidmaps to
  determine which areas of memory are actually mapped and llseek to
  skip over unmapped regions.
 file position must be aligned 
 do not disclose physical addresses: attack vector 
 watch out for wraparound 
 Ensure the address is inside the task 
	
	  The odds are that this will stop walking way
	  before end_vaddr, because the length of the
	  user buffer is tracked in "pm", and the walk
	  will stop when we hit the end of the buffer.
 overflow ? 
 borrow this 
 CONFIG_PROC_PAGE_MONITOR 
  Display pages allocated per node and memory policy via proc.
 Ensure we start with an empty set of numa_maps statistics. 
 mmap_lock is held by m_start 
 CONFIG_NUMA 
 SPDX-License-Identifier: GPL-2.0-or-later
 nommu.c: mmu-less memory info files
  Copyright (C) 2004 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  display a single region to a sequenced file
  display a list of all the REGIONs the kernel knows about
  - nommu kernels have a single flat list
 SPDX-License-Identifier: GPL-2.0
   linuxfsprocinode.c
   Copyright (C) 1991, 1992  Linus Torvalds
 Stop tracking associated processes 
 Let go of any associated proc directory entry 
 pde is locked on entry, unlocked on exit 
	
	  close() (proc_reg_release()) can't delete an entry and proceed:
	  ->release hook needs to be available at the right moment.
	 
	  rmmod (remove_proc_entry() et al) can't delete an entry and proceed:
	  "struct file" needs to be available at the right moment.
	 
	  Therefore, first process to enter this function does ->release() and
	  signals its completion to the other process which does nothing.
 somebody else is doing that, just wait 
 After ->release. 
 Wait until all existing callers into module are done. 
 ->pde_openers list can't grow from now on. 
	
	  Ensure that
	  1) PDE's ->release hook will be called no matter what
	     either normally by close()->release, or forcefully by
	     rmmodremove_proc_entry.
	 
	  2) rmmod isn't blocked by opening file in proc and sitting on
	     the descriptor (including "rmmod foo <procfoo" scenario).
	 
	  Save every "struct file" with custom ->release hook.
 To know what to release. 
 SPDX-License-Identifier: GPL-2.0
 show_fd_locks() never deferences files so a stale value is safe 
  procpidfd needs a special permission handler so that a process can still
  access procselffd after it has executed a setuid().
 SPDX-License-Identifier: GPL-2.0
  procbootconfig - Extra boot configuration
 Rest size of buffer 
 Return the needed total length if @size is 0 
 SPDX-License-Identifier: GPL-2.0
  procself:
 max length of unsigned int in decimal + NULL term 
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0
   linuxfsprocbase.c
   Copyright (C) 1991, 1992 Linus Torvalds
   proc base directory handling functions
   1999, Al Viro. Rewritten. Now it covers the whole per-process part.
   Instead of using magical inumbers to determine the kind of object
   we allocate and fill in-core inodes upon lookup. They don't even
   go into icache. We cache the reference to task_struct upon lookup too.
   Eventually it should become a filesystem in its own. We don't use the
   rest of procfs anymore.
   Changelog:
   17-Jan-2005
   Allan Bezerra
   Bruna Moreira <bruna.moreira@indt.org.br>
   Edjard Mota <edjard.mota@indt.org.br>
   Ilias Biris <ilias.biris@indt.org.br>
   Mauricio Lin <mauricio.lin@indt.org.br>
   Embedded Linux Lab - 10LE Instituto Nokia de Tecnologia - INdT
   A new process specific entry (smaps) included in proc. It shows the
   size of rss for each memory area. The maps entry lacks information
   about physical memory size (rss) for each mapped file, i.e.,
   rss information for executables and library files.
   This additional information is useful for any tools that need to know
   about physical memory consumption for a process specific library.
   Changelog:
   21-Feb-2005
   Embedded Linux Lab - 10LE Instituto Nokia de Tecnologia - INdT
   Pud inclusion in the page table walking.
   ChangeLog:
   10-Mar-2005
   10LE Instituto Nokia de Tecnologia - INdT:
   A better way to walks through the page table as suggested by Hugh Dickins.
   Simo Piiroinen <simo.piiroinen@nokia.com>:
   Smaps information related to shared, private, clean and dirty pages.
   Paul Mundt <paul.mundt@nokia.com>:
   Overall revision about smaps.
 NOTE:
 	Implementing inode permission operations in proc is almost
 	certainly an error.  Permission checks need to happen during
 	each system call not at open time.  The reason is that most of
 	what we wish to check for permissions in proc varies at runtime.
 	The classic example of a problem is opening file descriptors
 	in proc for a task before it execs a suid executable.
  Count the number of hardlinks for the pid_entry table, excluding the .
  and .. links.
  If the user used setproctitle(), we just get the string from
  user space at arg_start, and limit it to a maximum of one page.
 Include the NUL character if it was found 
 Check if process spawned far enough to have cmdline. 
	
	  We allow setproctitle() to overwrite the argument
	  strings, and overflow past the original end. But
	  only when it overflows into the environment area.
 We're not going to care if "ppos" has high bits set 
	
	  Magical special case: if the argv[] end byte is not
	  zero, the user has overwritten it with setproctitle(3).
	 
	  Possible future enhancement: do this only once when
	  pos is 0, and set a flag in the 'struct file'.
	
	  For the non-setproctitle() case we limit things strictly
	  to the [arg_start, arg_end[ range.
  Provides a wchan file via kallsyms in a proper one-value-per-file format.
  Returns the resolved symbol.  If that fails, simply return the address.
 CONFIG_KALLSYMS 
	
	  The ability to racily run the kernel stack unwinder on a running task
	  and then observe the unwinder output is scary; while it is useful for
	  debugging kernel issues, it can also allow an attacker to leak kernel
	  stack contents.
	  Doing this in a manner that is at least safe from races would require
	  some work to ensure that the remote task can not be scheduled; and
	  even then, this would still expose the unwinder as local attack
	  surface.
	  Therefore, this interface is restricted to root.
  Provides procPIDschedstat
	
	  Special case OOM_SCORE_ADJ_MIN for all others scale the
	  badness value into [0, 2000] range which we have been
	  exporting for a long time so userspace might depend on it.
 Display limits for a process 
	
	  print the file header
 CONFIG_HAVE_ARCH_TRACEHOOK 
                       Here the fs part begins                        
 permission checks 
	 Allow access to a task's file descriptors if it is us or we
	  may use ptrace attach to the process and find out that
	  information.
  May current process learn task's schedcmdline info (for hide_pid_min=1)
  or euidegid (for hide_pid_min=2)?
	
	  If 'hidpid' mount option is set force a ptrace check,
	  we indicate that we are using a filesystem syscall
	  by passing PTRACE_MODE_READ_FSCREDS
			
			  Let's make getdents(), stat(), and open()
			  consistent with each other.  If a process
			  may not stat() a file, it shouldn't be seen
			  in procfs at all.
 ensure this mm_struct can't be freed 
 but do not pin its memory 
 OK to pass negative loff_t, we can catch out-of-range 
 Ensure the process spawned far enough to have an environment. 
 AT_NULL 
		
		  procpidoom_adj is provided for legacy purposes, ask users to use
		  procpidoom_score_adj instead.
	
	  Make sure we will check other processes sharing the mm if this is
	  not vfrok which wants its own oom_score_adj.
	  pin the mm so it doesn't go away and get reused after task_unlock
 do not touch kernel threads or the global init 
  procpidoom_adj exists solely for backwards compatibility with previous
  kernels.  The effective policy is defined by oom_score_adj, which has a
  different scale: oom_adj grew exponentially and oom_score_adj grows linearly.
  Values written to oom_adj are simply mapped linearly to oom_score_adj.
  Processes that become oom disabled via oom_adj will still be oom disabled
  with this implementation.
  oom_adj cannot be removed since existing userspace binaries use it.
	
	  Scale procpidoom_score_adj appropriately ensuring that a maximum
	  value is always attainable.
 Don't let kthreads write their own loginuid 
 No partial writes. 
 is userspace tring to explicitly UNSET the loginuid? 
  Print out various scheduling related per-task fields:
  Print out autogroup related information:
 CONFIG_SCHED_AUTOGROUP 
 Only allow < page size writes at the beginning of the file 
 Slurp in the user data 
 Parse the user data 
 Find the end of line and ensure we don't look past it 
 CONFIG_TIME_NS 
 Are we allowed to snoop on the tasks file descriptors? 
 Are we allowed to snoop on the tasks file descriptors? 
 building an inode 
	 Depending on the state of dumpable compute who should own a
	  proc file for a task.
 Default to the tasks effective ownership 
	
	  Before the procpidstatus file was created the only way to read
	  the effective uid of a process was to stat procpid.  Reading
	  procpidstatus is slow enough that procps and other packages
	  kept stating procpid.  To keep the rules in proc simple I have
	  made this apply to all per process world readable and executable
	  directories.
 Make non-dumpable tasks owned by some root 
 We need a new inode 
 Common stuff 
	
	  grab the reference to task.
 Let the pid remember us for quick removal 
			
			  This doesn't prevent learning whether PID exists,
			  it only makes getattr() consistent with readdir().
 dentry stuff 
  Set <pid>... inode ownership (can change due to setuid(), etc.)
  Rewrite the inode's ownerships here because the owning task may have
  performed a setuid(), etc.
	 Is the task we represent dead?
	  If so, then don't put the dentry on the lru list,
	  kill it immediately.
 Lookups 
  Fill a directory entry.
  If possible create the dcache entry and derive our inode number and
  file type from dcache entry.
  Since all of the proc inode numbers are dynamically generated, the inode
  numbers do not exist until the inode is cache.  This means creating
  the dcache entry in readdir is necessary to keep the inode numbers
  reported by readdir in sync with the inode numbers reported
  by stat.
  dname_to_vma_addr - maps a dentry name into two unsigned longs
  which represent vma start and end addresses.
  Only allow CAP_SYS_ADMIN and CAP_CHECKPOINT_RESTORE to follow the links, due
  to concerns about how the symlinks may be used to bypass permissions on
  ancestor directories in the path to the file in question.
  Identical to proc_pid_link_inode_operations except for get_link()
	
	  We need two passes here:
	 
	   1) Collect vmas of mapped files with mmap_lock taken
	   2) Release mmap_lock and instantiate entries
	 
	  otherwise we get lockdep complained, since filldir()
	  routine might require mmap_lock taken in might_fault().
 max: %lx-%lx\0 
 Use getattr to fix if necessary 
	
	  Yes, it does not scale. And it should not. Don't add
	  new entries into proc<tgid> without very good reasons.
 A task may only write when it was the opener. 
 A task may only write its own attributes. 
 Prevent changes to overridden credentials. 
 No partial writes. 
 Guard against adverse ptrace interaction 
 CONFIG_TASK_IO_ACCOUNTING 
 CONFIG_USER_NS 
 CONFIG_LIVEPATCH 
 CONFIG_STACKLEAK_METRICS 
  Thread groups
  proc_flush_pid -  Remove dcache entries for @pid from the proc dcache.
  @pid: pid that should be flushed.
  This function walks a list of inodes (that belong to any proc
  filesystem) that are attached to the pid and flushes them from
  the dentry cache.
  It is safe and reasonable to cache proc entries for a task until
  that task exits.  After that they just clog up the dcache with
  useless entries, possibly causing useful dcache entries to be
  flushed instead.  This routine is provided to flush those useless
  dcache entries when a process is reaped.
  NOTE: This routine is just an optimization so it does not guarantee
        that no dcache entries will exist after a process is reaped
        it just makes it very unlikely that any will persist.
 Limit procfs to only ptraceable tasks 
  Find the first task with tgid >= tgid
 for the proc directory itself, after non-process stuff has been done 
  proc_tid_comm_permission is a special permission function exclusively
  used for the node proc<pid>task<tid>comm.
  It bypasses generic permission checks in the case where a task of the same
  task group attempts to access the node.
  The rationale behind this is that glibc and bionic access this node for
  cross thread naming (pthread_setgetname_np(!self)). However, if
  PR_SET_DUMPABLE gets set to 0 this node among others becomes uid=0 gid=0,
  which locks out the cross thread naming implementation.
  This function makes sure that the node is always accessible for members of
  same thread group.
		 This file (proc<pid>task<tid>comm) can always be
		  read or written by the members of the corresponding
		  thread group.
  Tasks
  Find the first tid of a thread group to return to user space.
  Usually this is just the thread group leader, but if the users
  buffer was too small or there was a seek into the middle of the
  directory we have more work todo.
  In the case of a short read we start with find_task_by_pid.
  In the case of a seek we start with the leader and walk nr
  threads past it.
 32bit overflow? 
 Attempt to start with the tid of a thread 
 If nr exceeds the number of threads there is nothing todo 
	 If we haven't found our starting place yet start
	  with the leader and walk nr threads forward.
  Find the next thread in the thread list.
  Return NULL if there is an error or no next thread.
  The reference to the input task_struct is released.
 for the procTGIDtask directories 
	 f_version caches the tgid value that the last readdir call couldn't
	  return. lseek aka telldir automagically resets f_version to 0.
 The task has just exited. 
			 returning this tgid failed, save it as the first
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0-only
 	fsprocvmcore.c Interface for accessing the crash
  				 dump from the system's previous life.
  	Heavily borrowed from fsprockcore.c
 	Created by: Hariprasad Nellitheertha (hari@in.ibm.com)
 	Copyright (C) IBM Corporation, 2004. All rights reserved
 List representing chunks of contiguous memory areas and their offsets in
  vmcore file.
 Stores the pointer to the buffer containing kernel elf core headers. 
 Size of all notes minus the device dump notes 
 Total size of vmcore file. 
 Device Dump list and mutex to synchronize access to list 
 CONFIG_PROC_VMCORE_DEVICE_DUMP 
 Device Dump Size 
 List of registered vmcore callbacks. 
 Whether we had a surprise unregistration of a callback. 
 Whether the vmcore has been opened once. 
	
	  Registering a vmcore callback after the vmcore was opened is
	  very unusual (e.g., manual driver loading).
	
	  Unregistering a vmcore callback after the vmcore was opened is
	  very unusual (e.g., forced driver removal), but we cannot stop
	  unregistering.
 Reads a page from the oldmem device from given offset. 
 If pfn is not ram, return zeros for sparse dump files 
  Architectures may override this function to allocate ELF header in 2nd kernel
  Architectures may override this function to free header
  Architectures may override this function to read from ELF header
  Architectures may override this function to read from notes sections
  Architectures may override this function to map oldmem
  Architectures which support memory encryption override this.
  Copy to either kernel or user space
 Leave now if buffer filled already 
 Leave now if buffer filled already 
 CONFIG_MMU 
 CONFIG_PROC_VMCORE_DEVICE_DUMP 
 Read from the ELF header and then the crash dump. On error, negative value is
  returned otherwise number of bytes read are returned.
 trim buflen to not go beyond EOF 
 Read ELF core header 
 leave now if filled buffer already 
 Read Elf note segment 
		 We add device dumps before other elf notes because the
		  other elf notes may not fill the elf notes buffer
		  completely and we will end up with zero-filled data
		  between the elf notes and the device dumps. Tools will
		  then try to decode this zero-filled data as valid notes
		  and we don't want that. Hence, adding device dumps before
		  the other elf notes ensure that zero-filled data can be
		  avoided.
 Read device dumps 
 leave now if filled buffer already 
 CONFIG_PROC_VMCORE_DEVICE_DUMP 
 Read remaining elf notes 
 leave now if filled buffer already 
 leave now if filled buffer already 
  The vmcore fault handler uses the page cache and fills data using the
  standard __vmcore_read() function.
  On s390 the fault handler is used for memory regions that can't be mapped
  directly with remap_pfn_range().
  vmcore_alloc_buf - allocate buffer in vmalloc memory
  @sizez: size of buffer
  If CONFIG_MMU is defined, use vmalloc_user() to allow users to mmap
  the buffer to user-space by means of remap_vmalloc_range().
  If CONFIG_MMU is not defined, use vzalloc() since mmap_vmcore() is
  disabled and there's no need to allow users to mmap the buffer.
  Disable mmap_vmcore() if CONFIG_MMU is not defined. MMU is
  essential for mmap_vmcore() in order to map physically
  non-contiguous objects (ELF header, ELF note segment and memory
  regions in the 1st kernel pointed to by PT_LOAD entries) into
  virtually contiguous user-space in ELF layout.
  remap_oldmem_pfn_checked - do remap_oldmem_pfn_range replacing all pages
  reported as not being ram with the zero page.
  @vma: vm_area_struct describing requested mapping
  @from: start remapping from
  @pfn: page frame number to start remapping to
  @size: remapping size
  @prot: protection bits
  Returns zero on success, -EAGAIN on failure.
			
			  We hit a page which is not ram. Remap the continuous
			  region between pos_start and pos-1 and replace
			  the non-ram page at pos with the zero page.
 Remap continuous region 
 Remap the zero page 
 Remap the rest 
	
	  Check if oldmem_pfn_is_ram was registered to avoid
	  looping over all pages without a reason.
		 We add device dumps before other elf notes because the
		  other elf notes may not fill the elf notes buffer
		  completely and we will end up with zero-filled data
		  between the elf notes and the device dumps. Tools will
		  then try to decode this zero-filled data as valid notes
		  and we don't want that. Hence, adding device dumps before
		  the other elf notes ensure that zero-filled data can be
		  avoided. This also ensures that the device dumps and
		  other elf notes can be properly mmaped at page aligned
		  address.
 Read device dumps 
 leave now if filled buffer already 
 CONFIG_PROC_VMCORE_DEVICE_DUMP 
 Read remaining elf notes 
  update_note_header_size_elf64 - update p_memsz member of each PT_NOTE entry
  @ehdr_ptr: ELF header
  This function updates p_memsz member of each PT_NOTE entry in the
  program header table pointed to by @ehdr_ptr to real size of ELF
  note segment.
  get_note_number_and_size_elf64 - get the number of PT_NOTE program
  headers and sum of real size of their ELF note segment headers and
  data.
  @ehdr_ptr: ELF header
  @nr_ptnote: buffer for the number of PT_NOTE program headers
  @sz_ptnote: buffer for size of unique PT_NOTE program header
  This function is used to merge multiple PT_NOTE program headers
  into a unique single one. The resulting unique entry will have
  @sz_ptnote in its phdr->p_mem.
  It is assumed that program headers with PT_NOTE type pointed to by
  @ehdr_ptr has already been updated by update_note_header_size_elf64
  and each of PT_NOTE program headers has actual ELF note segment
  size in its p_memsz member.
  copy_notes_elf64 - copy ELF note segments in a given buffer
  @ehdr_ptr: ELF header
  @notes_buf: buffer into which ELF note segments are copied
  This function is used to copy ELF note segment in the 1st kernel
  into the buffer @notes_buf in the 2nd kernel. It is assumed that
  size of the buffer @notes_buf is equal to or larger than sum of the
  real ELF note segment headers and data.
  It is assumed that program headers with PT_NOTE type pointed to by
  @ehdr_ptr has already been updated by update_note_header_size_elf64
  and each of PT_NOTE program headers has actual ELF note segment
  size in its p_memsz member.
 Merges all the PT_NOTE headers into one. 
 Prepare merged PT_NOTE program header. 
 Add merged PT_NOTE program header
 Remove unwanted PT_NOTE program headers. 
 Modify e_phnum to reflect merged headers. 
	 Store the size of all notes.  We need this to update the note
	  header when the device dumps will be added.
  update_note_header_size_elf32 - update p_memsz member of each PT_NOTE entry
  @ehdr_ptr: ELF header
  This function updates p_memsz member of each PT_NOTE entry in the
  program header table pointed to by @ehdr_ptr to real size of ELF
  note segment.
  get_note_number_and_size_elf32 - get the number of PT_NOTE program
  headers and sum of real size of their ELF note segment headers and
  data.
  @ehdr_ptr: ELF header
  @nr_ptnote: buffer for the number of PT_NOTE program headers
  @sz_ptnote: buffer for size of unique PT_NOTE program header
  This function is used to merge multiple PT_NOTE program headers
  into a unique single one. The resulting unique entry will have
  @sz_ptnote in its phdr->p_mem.
  It is assumed that program headers with PT_NOTE type pointed to by
  @ehdr_ptr has already been updated by update_note_header_size_elf32
  and each of PT_NOTE program headers has actual ELF note segment
  size in its p_memsz member.
  copy_notes_elf32 - copy ELF note segments in a given buffer
  @ehdr_ptr: ELF header
  @notes_buf: buffer into which ELF note segments are copied
  This function is used to copy ELF note segment in the 1st kernel
  into the buffer @notes_buf in the 2nd kernel. It is assumed that
  size of the buffer @notes_buf is equal to or larger than sum of the
  real ELF note segment headers and data.
  It is assumed that program headers with PT_NOTE type pointed to by
  @ehdr_ptr has already been updated by update_note_header_size_elf32
  and each of PT_NOTE program headers has actual ELF note segment
  size in its p_memsz member.
 Merges all the PT_NOTE headers into one. 
 Prepare merged PT_NOTE program header. 
 Add merged PT_NOTE program header
 Remove unwanted PT_NOTE program headers. 
 Modify e_phnum to reflect merged headers. 
	 Store the size of all notes.  We need this to update the note
	  header when the device dumps will be added.
 Add memory chunks represented by program headers to vmcore list. Also update
 PT_NOTE hdr 
 Skip Elf header, program headers and Elf note segment. 
 Add this contiguous chunk of memory to vmcore list.
 Update the program header offset. 
 PT_NOTE hdr 
 Skip Elf header, program headers and Elf note segment. 
 Add this contiguous chunk of memory to vmcore list.
 Update the program header offset 
 Sets offset fields of vmcore elements. 
 Skip Elf header, program headers and Elf note segment. 
 Read Elf header 
 Do some basic Verification. 
 Read in all elf headers. 
 Merge all PT_NOTE headers into one. 
 Read Elf header 
 Do some basic Verification. 
 Read in all elf headers. 
 Merge all PT_NOTE headers into one. 
 Determine vmcore size. 
  vmcoredd_write_header - Write vmcore device dump header at the
  beginning of the dump's buffer.
  @buf: Output buffer where the note is written
  @data: Dump info
  @size: Size of the dump
  Fills beginning of the dump's buffer with vmcore device dump header.
  vmcoredd_update_program_headers - Update all Elf program headers
  @elfptr: Pointer to elf header
  @elfnotesz: Size of elf notes aligned to page size
  @vmcoreddsz: Size of device dumps to be added to elf note header
  Determine type of Elf header (Elf64 or Elf32) and update the elf note size.
  Also update the offsets of all the program headers after the elf note header.
 Update all program headers 
 Update note size 
 Update all program headers 
 Update note size 
  vmcoredd_update_size - Update the total size of the device dumps and update
  Elf header
  @dump_size: Size of the current device dump to be added to total size
  Update the total size of all the device dumps and update the Elf program
  headers. Calculate the new offsets for the vmcore list and update the
  total vmcore size.
 Update vmcore list offsets 
  vmcore_add_device_dump - Add a buffer containing device dump to vmcore
  @data: dump info.
  Allocate a buffer and invoke the calling driver's dump collect routine.
  Write Elf note at the beginning of the buffer to indicate vmcore device
  dump and add the dump to global list.
 Keep size of the buffer page aligned so that it can be mmaped 
 Allocate buffer for driver's to write their dumps 
 Invoke the driver's dump collection routing 
 Add the dump to driver sysfs list 
 CONFIG_PROC_VMCORE_DEVICE_DUMP 
 Free all dumps in vmcore device dump list 
 CONFIG_PROC_VMCORE_DEVICE_DUMP 
 Init function for vmcore module. 
 Allow architectures to allocate ELF header in 2nd kernel 
	
	  If elfcorehdr= has been passed in cmdline or created in 2nd kernel,
	  then capture the dump.
 Cleanup function for vmcore module. 
 clear the vmcore list. 
 clear vmcore device dump list 
 SPDX-License-Identifier: GPL-2.0
	
	  The memmap of early sections is completely populated and marked
	  online even if max_pfn does not fall on a section boundary -
	  pfn_to_online_page() will succeed on all pages. Allow inspecting
	  these memmaps.
 prockpagecount - an array exposing page counts
  Each entry is a u64 representing the corresponding
  physical page count.
		
		  TODO: ZONE_DEVICE support requires to identify
		  memmaps that were actually initialized.
 prockpageflags - an array exposing page flags
  Each entry is a u64 representing the corresponding
  physical page flags.
	
	  pseudo flag: KPF_NOPAGE
	  it differentiates a memory hole from a page with no flags
	
	  pseudo flags for the well known (anonymous) memory mapped pages
	 
	  Note that page->_mapcount is overloaded in SLOBSLUBSLQB, so the
	  simple test in page_mapped() is not enough.
	
	  compound pages: export both headtail info
	  they together define a compound page's startend pos and order
	
	  PageTransCompound can be true for non-huge compound pages (slab
	  pages or pages allocated by drivers with __GFP_COMP) because it
	  just checks PG_headPG_tail, so we need to check PageLRUPageAnon
	  to make sure a given page is a thp, not a non-huge compound page.
	
	  Caveats on high order pages: page->_refcount will only be set
	  -1 on the head page; SLUBSLQB do the same for PG_slab;
	  SLOB won't set PG_slab at all on compound pages.
		
		  TODO: ZONE_DEVICE support requires to identify
		  memmaps that were actually initialized.
		
		  TODO: ZONE_DEVICE support requires to identify
		  memmaps that were actually initialized.
 CONFIG_MEMCG 
 SPDX-License-Identifier: GPL-2.0-only
  procfsgeneric.c --- generic routines for the proc-fs
  This file contains generic proc-fs routines for handling
  directories and files.
  Copyright (C) 1991, 1992 Linus Torvalds.
  Copyright (C) 1997 Theodore Ts'o
 Figure out where to put new node 
 Add new node and rebalance tree. 
  This function parses a name such as "ttydriverserial", and
  returns the struct proc_dir_entry for "procttydriver", and
  returns "serial" in residual.
  Return an inode number between PROC_DYNAMIC_FIRST and
  0xffffffff, or zero on failure.
 revalidate 
  Don't create negative dentries here, return -ENOENT by hand
  instead.
  This returns non-zero if at EOF, so that the proc
  root directory can use this and check if it should
  continue with the <pid> entries..
  Note that the VFS-layer doesn't care about the return
  value of the readdir() call, as long as it's non-negative
  for success..
  These are the generic proc directory operations. They
  use the in-memory "struct proc_dir_entry" tree to parse
  the proc directory.
  proc directories can do almost nothing..
 returns the registered entry, or frees dp and returns NULL on failure 
 not permanent -- can call into arbitrary seq_operations 
 not permanent -- can call into arbitrary ->single_show 
  Remove a proc entry and free it if it's not currently in use.
  Pull a user buffer into memory and pass it to the file's write handler if
  one is supplied.  The ->write() method is permitted to modify the
  kernel-side buffer.
 SPDX-License-Identifier: GPL-2.0
  proc_tty.c -- handles proctty
  Copyright 1997, Theodore Ts'o
  The proctty directory inodes...
  This is the handler for procttydrivers
 pseudo-drivers first 
 iterator 
  This function is called by tty_register_driver() to handle
  registering the driver's proc handler into procttydriver<foo>
  This function is called by tty_unregister_driver()
  Called by proc_root_init() to initialize the proctty subtree
 Preserved: it's userspace visible 
	
	  procttydriverserial reveals the exact character counts for
	  serial links which is just too easy to abuse for inferring
	  password lengths and inter-keystroke timings during password
	  entry.
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0
  procthread_self:
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsprocnet.c
   Copyright (C) 2007
   Author: Eric Biederman <ebiederm@xmission.com>
   proc net directory handling functions
  proc_create_net_data_write - Create a writable net_ns-specific proc file
  @name: The name of the file.
  @mode: The file's access mode.
  @parent: The parent directory in which to create.
  @ops: The seq_file ops with which to read the file.
  @write: The write method with which to 'modify' the file.
  @data: Data for retrieval by PDE_DATA().
  Create a network namespaced proc file in the @parent directory with the
  specified @name and @mode that allows reading of a file that displays a
  series of elements and also provides for the file accepting writes that have
  some arbitrary effect.
  The functions in the @ops table are used to iterate over items to be
  presented and extract the readable content using the seq_file interface.
  The @write function is called with the data copied into a kernel space
  scratch buffer and has a NUL appended for convenience.  The buffer may be
  modified by the @write function.  @write should return 0 on success.
  The @data value is accessible from the @show and @write functions by calling
  PDE_DATA() on the file inode.  The network namespace must be accessed by
  calling seq_file_net() on the seq_file struct.
  proc_create_net_single_write - Create a writable net_ns-specific proc file
  @name: The name of the file.
  @mode: The file's access mode.
  @parent: The parent directory in which to create.
  @show: The seqfile show method with which to read the file.
  @write: The write method with which to 'modify' the file.
  @data: Data for retrieval by PDE_DATA().
  Create a network-namespaced proc file in the @parent directory with the
  specified @name and @mode that allows reading of a file that displays a
  single element rather than a series and also provides for the file accepting
  writes that have some arbitrary effect.
  The @show function is called to extract the readable content via the
  seq_file interface.
  The @write function is called with the data copied into a kernel space
  scratch buffer and has a NUL appended for convenience.  The buffer may be
  modified by the @write function.  @write should return 0 on success.
  The @data value is accessible from the @show and @write functions by calling
  PDE_DATA() on the file inode.  The network namespace must be accessed by
  calling seq_file_single_net() on the seq_file struct.
 SPDX-License-Identifier: GPL-2.0
  procinterrupts
 Nothing to do 
 SPDX-License-Identifier: GPL-2.0
 !NO_HZ or cpu offline so we can rely on cpustat.idle 
 !NO_HZ or cpu offline so we can rely on cpustat.iowait 
 shift boot timestamp according to the timens offset 
 Copy values here to work around gcc-2.95.3, gcc-2.96 
 minimum size to display an interrupt count : 2 bytes 
 SPDX-License-Identifier: GPL-2.0
  procsys support
 shared constants to be used in various sysctls 
 Support for permanently empty directories 
 Called under sysctl_lock 
 Is this a permanently empty directory? 
 Am I creating a permanently empty directory? 
 called under sysctl_lock 
 called under sysctl_lock 
 called under sysctl_lock, will reacquire if has to wait 
	
	  if p->used is 0, nobody will ever touch that entry again;
	  we'll eliminate all paths to it before dropping sysctl_lock
 anything non-NULL; we'll never dereference it 
	
	  Invalidate dentries for unregistered sysctls: namespaced sysctls
	  can have duplicate names and contaminate dcache very badly.
	
	  do not remove from the list until nobody holds it; walking the
	  list in do_sysctl() relies on that.
  sysctl_perm does NOT grant the superuser all rights automatically, because
  some sysctl variables are readonly even to root.
	
	  At this point we know that the sysctl was not unregistered
	  and won't be until we finish.
 if that can happen at all, it should be -EINVAL, not -EISDIR 
 don't even try if the size is too large 
 careful: calling conventions are nasty here 
 sysctl was unregistered 
 sysctl was unregistered 
 It is not an error if we can not follow the link ignore it 
	
	  sysctl entries that are not writeable,
	  are _NOT_ writeable, capabilities or not.
 Executable files are not allowed under procsys 
 global root - r-xr-xr-x 
 Use the permissions on the sysctl table entry 
	 Although proc doesn't have negative dentries, rcu-walk means
 AV: can it, indeed? 
  get_subdir - find or create a subdir with the specified name.
  @dir:  Directory to create the subdirectory in
  @name: The name of the subdirectory to find or create
  @namelen: The length of name
  Takes a directory with an elevated reference count so we know that
  if we drop the lock the directory will not go away.  Upon success
  the reference is moved from @dir to the returned subdirectory.
  Upon error an error code is returned and the reference on @dir is
  simply dropped.
 Was the subdir added while we dropped the lock? 
 Nope.  Use the our freshly made directory entry. 
 Are there links available for every entry in table? 
 The checks passed.  Increase the registration count on the links 
  __register_sysctl_table - register a leaf sysctl table
  @set: Sysctl tree to register on
  @path: The path to the directory the sysctl table is in.
  @table: the top-level table structure
  Register a sysctl table hierarchy. @table should be a filled in ctl_table
  array. A completely 0 filled entry terminates the table.
  The members of the &struct ctl_table structure are used as follows:
  procname - the name of the sysctl file under procsys. Set to %NULL to not
             enter a sysctl file
  data - a pointer to data for use by proc_handler
  maxlen - the maximum size in bytes of the data
  mode - the file permissions for the procsys file
  child - must be %NULL.
  proc_handler - the text handler routine (described below)
  extra1, extra2 - extra pointers usable by the proc handler routines
  Leaf nodes in the sysctl tree will be represented by a single file
  under proc; non-leaf nodes will be represented by directories.
  There must be a proc_handler routine for any terminal nodes.
  Several default handlers are available to cover common cases -
  proc_dostring(), proc_dointvec(), proc_dointvec_jiffies(),
  proc_dointvec_userhz_jiffies(), proc_dointvec_minmax(),
  proc_doulongvec_ms_jiffies_minmax(), proc_doulongvec_minmax()
  It is the handler's job to read the input buffer from user memory
  and process it. The handler should return 0 on success.
  This routine returns %NULL on a failure to register, and a pointer
  to the table header on success.
 Reference moved down the diretory tree get_subdir 
 Find the directory for the ctl_table 
  register_sysctl - register a sysctl table
  @path: The path to the directory the sysctl table is in.
  @table: the table structure
  Register a sysctl table. @table should be a filled in ctl_table
  array. A completely 0 filled entry terminates the table.
  See __register_sysctl_table for more details.
 special case: no directory and empty directory 
 If there are mixed files and directories we need a new table 
 Register everything except a directory full of subdirectories 
 Remember if we need to free the file table 
 Recurse into the subdirectories. 
 On failure our caller will unregister all registered subheaders 
  __register_sysctl_paths - register a sysctl table hierarchy
  @set: Sysctl tree to register on
  @path: The path to the directory the sysctl table is in.
  @table: the top-level table structure
  Register a sysctl table hierarchy. @table should be a filled in ctl_table
  array. A completely 0 filled entry terminates the table.
  See __register_sysctl_table for more details.
  register_sysctl_paths - register a sysctl table hierarchy
  @path: The path to the directory the sysctl table is in.
  @table: the top-level table structure
  Register a sysctl table hierarchy. @table should be a filled in ctl_table
  array. A completely 0 filled entry terminates the table.
  See __register_sysctl_paths for more details.
  register_sysctl_table - register a sysctl table hierarchy
  @table: the top-level table structure
  Register a sysctl table hierarchy. @table should be a filled in ctl_table
  array. A completely 0 filled entry terminates the table.
  See register_sysctl_paths for more details.
  unregister_sysctl_table - unregister a sysctl table hierarchy
  @header: the header returned from register_sysctl_table
  Unregisters the sysctl table and all children. proc entries may not
  actually be removed until they are no longer used by anyone.
  Historically some settings had both sysctl and a command line parameter.
  With the generic sysctl. parameter support, we can handle them at a single
  place and only keep the historical name for compatibility. This is not meant
  to add brand new aliases. When adding existing aliases, consider whether
  the possibly different moment of changing the value (e.g. from early_param
  to the moment do_sysctl_args() is called) is an issue for the specific
  parameter.
 Set sysctl value passed on kernel command line. 
	
	  To set sysctl options, we use a temporary mount of proc, look up the
	  respective sys file and write to it. To avoid mounting it when no
	  options were given, we mount it only when the first sysctl option is
	  found. Why not a persistent mount? There are problems with a
	  persistent mount of proc in that it forces userspace not to use any
	  proc mount options.
 SPDX-License-Identifier: GPL-2.0
 	fsprockcore.c kernel ELF core dumper
 	Modelled on fsexec.c:aout_core_dump()
 	Jeremy Fitzhardinge <jeremy@sw.oz.au>
 	ELF version written by David Howells <David.Howells@nexor.co.uk>
 	Modified and incorporated into 2.3.x by Tigran Aivazian <tigran@veritas.com>
 	Support to dump vmalloc'd areas (ELF only), Tigran Aivazian <tigran@veritas.com>
 	Safe accesses to vmallocdirect-mapped discontiguous areas, Kanoj Sarcar <kanoj@sgi.com>
  Returns > 0 for RAM pages, 0 for non-RAM pages, < 0 on error
  Same as oldmem_pfn_is_ram in vmcore
 This doesn't grab kclist_lock, so it should only be used at init time. 
 PT_NOTE 
  If no highmem, we can assume [0...max_low_pfn) continuous range of memory
  because memory hole is not as big as !HIGHMEM case.
  (HIGHMEM is special because part of memory is _invisible_ from the kernel.)
 !CONFIG_HIGHMEM 
 calculate vmemmap's address from given system ram pfn and register it 
 overlap check (because we have to align page 
 cut not-mapped area. ....from ppc-32 code. 
	
	  We've already checked virt_addr_valid so we know this address
	  is a valid pointer, therefore we can check against it to determine
	  if we need to trim
 Not inialized....update now 
 find out "max pfn" 
 scan 0 to max_pfn 
 CONFIG_HIGHMEM 
 Couldn't get the RAM list, try again next time. 
	
	  Don't race against drivers that set PageOffline() and expect no
	  further page access.
 ELF file header. 
 ELF program headers. 
 ELF note segment. 
		
		  vmcoreinfo_size is mostly constant after init time, but it
		  can be changed by crash_save_vmcoreinfo(). Racing here with a
		  panic on another CPU before the machine goes down is insanely
		  unlikely, but it's better to not leave potential buffer
		  overflows lying around, regardless.
	
	  Check to see if our file offset matches with any of
	  the addresses in the elf_phdr on our list.
		
		  If this is the first iteration or the address is not within
		  the previous entry, search for a matching entry.
 skip the list anchor 
 we have to zero-fill user buffer even if no read 
 User page is handled prior to normal kernel page: 
			
			  Don't read offline sections, logically offline pages
			  (e.g., inflated in a balloon), hwpoisoned pages,
			  and explicitly excluded physical ranges.
				
				  Using bounce buffer to bypass the
				  hardened user copy kernel text checks.
 just remember that we have to update kcore 
  If defined, special segment is used for mapping kernel text instead of
  direct-map area. We need to create special TEXT section.
  MODULES_VADDR has no intersection with VMALLOC_ADDR.
 Always returns 0. 
 Store text area if it's special 
 Store vmalloc area 
 Store direct-map area from physical memory map 
 SPDX-License-Identifier: GPL-2.0
   linuxfsprocarray.c
   Copyright (C) 1992  by Linus Torvalds
   based on ideas by Darren Senn
  Fixes:
  Michael. K. Johnson: stat,statm extensions.
                       <johnsonm@stolaf.edu>
  Pauline Middelink :  Made cmdline,envline only break at '\0's, to
                       make sure SET_PROCTITLE works. Also removed
                       bad '!' which forced address recalculation for
                       EVERY character on the current page.
                       <middelin@polyware.iaf.nl>
  Danny ter Haar    :	added cpuinfo
 			<dth@cistron.nl>
  Alessandro Rubini :  profile extension.
                       <rubini@ipvvis.unipv.it>
  Jeff Tranter      :  added BogoMips field to cpuinfo
                       <Jeff_Tranter@Mitel.COM>
  Bruno Haible      :  remove 4K limit for the maps file
 			<haible@ma2s2.mathematik.uni-karlsruhe.de>
  Yves Arrouye      :  remove removal of trailing spaces in get_array.
 			<Yves.Arrouye@marin.fdn.fr>
  Jerome Forissier  :  added per-CPU time information to procstat
                       and proc<pid>cpu extension
                       <forissier@isia.cma.fr>
 			- Incorporation and non-SMP safe operation
 			of forissier patch in 2.1.78 by
 			Hans Marcus <crowbar@concepts.nl>
  aeb@cwi.nl        :  procpartitions
  Alan Cox	     :  security fixes.
 			<alan@lxorguk.ukuu.org.uk>
  Al Viro           :  safe handling of mm_struct
  Gerhard Wichert   :  added BIGMEM support
  Siemens AG           <Gerhard.Wichert@pdb.siemens.de>
  Al Viro & Jeff Garzik :  moved most of the thing into base.c and
 			 :  proc_misc.c. The rest may eventually go into
 			 :  base.c too.
  The task state array is a strange "bitmap" of
  reasons to sleep. Thus "running" is zero, and
  you can test for combinations of others with
  simple bit tests.
 states in TASK_REPORT: 
 0x00 
 0x01 
 0x02 
 0x04 
 0x08 
 0x10 
 0x20 
 0x40 
 states beyond TASK_REPORT: 
 0x80 
 Trailing space shouldn't have been added in the first place. 
 FIXME: is this correct? 
 render them all 
		
		  esp and eip are intentionally zeroed out.  There is no
		  non-racy way to read them without freezing the task.
		  Programs that need reliable values can use ptrace(2).
		 
		  The only exception is if the task is core dumping because
		  a program is not able to use ptrace(2) in that case. It is
		  safe because the task has stopped executing permanently.
 add up live thread stats at the group level 
 scale priority and nice values from timeslices to -20..20 
 to make it look like a "normal" Unix prioritynice value  
 apply timens offset for boottime and convert nsec -> ticks 
	 The signal information here is obsolete.
	  It must be decimal for Linux 2.0 compatibility.
	  Use proc#status for real-time signals.
	
	  We used to output the absolute kernel address, but that's an
	  information leak - so instead we show a 01 flag here, to signal
	  to user-space whether there's a wchan field in procPIDwchan.
	 
	  This works with older implementations of procps as well.
		
		  For quick read, open code by putting numbers directly
		  expected format is
		  seq_printf(m, "%lu %lu %lu %lu 0 %lu 0\n",
		                size, resident, shared, text, data);
	
	  Lets try to continue searching first, this gives
	  us significant speedup on children-rich processes.
	
	  Slow search case.
	 
	  We might miss some children here if children
	  are exited while we were not holding the lock,
	  but it was never promised to be accurate that
	  much.
	 
	  "Just suppose that the parent sleeps, but N children
	   exit after we printed their tids. Now the slow paths
	   skips N extra children, we miss N tasks." (c)
	 
	  So one need to stop or freeze the leader and all
	  its children to get a precise result.
 CONFIG_PROC_CHILDREN 
 SPDX-License-Identifier: GPL-2.0
   linuxfsprocroot.c
   Copyright (C) 1991, 1992 Linus Torvalds
   proc root directory handling functions
 User space would break if executables or devices appear on proc 
	
	  procfs isn't actually a stacking filesystem; however, there is
	  too much magic going on inside it to permit stacking things on
	  top of it
 procfs dentries and inodes don't require IO to create 
 somewhere for the nfsd filesystem to be mounted 
 just give it a mountpoint 
  The root proc directory is special, as it has the
  <pid> directories. Thus we don't use the generic
  directory handling functions for that..
  proc root can do almost nothing..
  This is the root "inode" in the proc tree..
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0
  procsoftirqs  ... display the number of softirqs
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsadfssuper.c
   Copyright (C) 1997-1999 Russell King
 sector size must be 256, 512 or 1024 bytes 
 idlen must be at least log2secsize + 3 
	 we cannot have such a large disc that we
	  are unable to represent sector offsets in
	  32 bits.  This works out at 2.0 TB.
	
	  Maximum idlen is limited to 16 bits for new directories by
	  the three-byte storage of an indirect disc address.  For
	  big directories, idlen must be no greater than 19 v2 [1.0]
 reserved bytes should be zero 
 always drop inodes if we are read-only 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 try to set the requested block size 
 read the buffer 
 validate it 
 does the block size match the filesystem block size? 
 Do some sanity checks on the ADFS disc record 
 Do some sanity checks on the ADFS disc record 
 set default options 
 Try to probe the filesystem boot block 
 set up enough so that we can read an inode 
 Set root object date as 01 Jan 1987 00:00:00 
	
	  If this is a F+ disk with variable length directories,
	  get the root_size from the disc record.
	
	  ,xyz hex filetype suffix may be added by driver
	  to files that have valid RISC OS filetype
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsadfsinode.c
   Copyright (C) 1997-1999 Russell King
  LookupCreate a block at offset 'block' into 'inode'.  We currently do
  not support creation of new blocks, so we return -EIO for this case.
 don't support allocation of blocks yet 
  Convert ADFS attributes and filetype to Linux permission.
 LinkFS 
 UnixExec 
  Convert Linux permission to ADFS attribute.  We try to do the reverse
  of atts2mode, but there is not a 1:1 translation.
 FIXME: should we be able to alter a link? 
 Directories do not have readwrite permissions on the media 
  Convert an ADFS time to Unix time.  ADFS has a 40-bit centi-second time
  referenced to 1 Jan 1900 (til 2248) so we need to discard 2208988800 seconds
  of time to convert from RISC OS epoch to Unix epoch.
	 01 Jan 1970 00:00:00 (Unix epoch) as nanoseconds since
	  01 Jan 1900 00:00:00 (RISC OS epoch)
 top 8 bits of timestamp 
 bottom 32 bits of timestamp 
	 convert 40-bit centi-seconds to 32-bit seconds
	  going via nanoseconds to retain precision
 cs to ns 
 Files dated pre  01 Jan 1970 00:00:00. 
 convert from RISC OS to Unix epoch 
 Convert an Unix time to ADFS time for an entry that is already stamped. 
 convert from Unix to RISC OS epoch 
 convert from nanoseconds to centiseconds 
  Fill in the inode information from the object information.
  Note that this is an inode-less filesystem, so we can't use the inode
  number to reference the metadata on the media.  Instead, we use the
  inode number to hold the object ID, which in turn will tell us where
  the data is held.  We also save the parent object ID, and with these
  two, we can locate the metadata.
  This does mean that we rely on an objects parent remaining the same at
  all times - we cannot cope with a cross-directory rename (yet).
	
	  we need to save the parent directory ID so that
	  write_inode can update the directory information
	  for this file.  This will need special handling
	  for cross-directory renames.
  Validate and convert a changed access modetime to their ADFS equivalents.
  adfs_write_inode will actually write the information back to the directory
  later.
	
	  we can't change the UID or GID of any file -
	  we have a global UIDGID in the superblock
 XXX: this is missing some actual on-disk truncation.. 
	
	  FIXME: should we make these == to i_mtime since we don't
	  have the ability to represent them in our filesystem?
	
	  FIXME: should we be marking this inode dirty even if
	  we don't have any metadata to write back?
  write an existing inode back to the directory, and therefore the disk.
  The adfs-specific inode data has already been updated by
  adfs_notify_change()
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsadfsdir.c
   Copyright (C) 1999-2000 Russell King
   Common directory handling for ADFS
  For future.  This should probably be per-directory.
 We only allow one extension 
 Mark the buffers dirty 
	
	  RISC OS allows the use of '' in directory entry names, so we need
	  to fix these up.  '' is typically used for FAT compatibility to
	  represent '.', so do the same conversion here.  In any case, '.'
	  will never be in a RISC OS name since it is used as the pathname
	  separator.  Handle the case where we may generate a '.' or '..'
	  name, replacing the first character with '^' (the RISC OS "parent
	  directory" character.)
	
	  If the object is a file, and the user requested the ,xyz hex
	  filetype suffix to the name, check the filetype and append.
	
	  If the updated failed because the entry wasn't found, we can
	  just release the buffers. If it was any other error, forget
	  the dirtied buffers so they aren't written back to the media.
  Compare two names, taking note of the name length
  requirements of the underlying filesystem.
		
		  This only returns NULL if get_empty_inode
		  fails.
  directories can handle most operations...
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsadfsdir_fplus.c
   Copyright (C) 1997-1999 Russell King
 Return the byte offset to directory entry pos 
 Check that bigdirnamelen fits within the directory 
 Check that bigdirnamesize fits within the directory 
	
	  Avoid division, we know that absolute maximum number of entries
	  can not be so large to cause overflow of the multiplication below.
 Accumulate the contents of the header, entries and names 
 Accumulate the contents of the tail except for the check byte 
 Read first buffer 
 Read remaining buffers 
 Increment directory sequence number 
 Update directory check byte 
 Make sure the directory still validates correctly 
 SPDX-License-Identifier: GPL-2.0
   linuxfsadfsfile.c
  Copyright (C) 1997-1999 Russell King
  from:
   linuxfsext2file.c
  Copyright (C) 1992, 1993, 1994, 1995
  Remy Card (card@masi.ibp.fr)
  Laboratoire MASI - Institut Blaise Pascal
  Universite Pierre et Marie Curie (Paris VI)
   from
   linuxfsminixfile.c
   Copyright (C) 1991, 1992  Linus Torvalds
   adfs regular file handling primitives           
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsadfsdir_f.c
  Copyright (C) 1997-1999 Russell King
   E and F format directory handling
  Read an (unaligned) value of length 1..4 bytes
  There are some algorithms that are nice in
  assembler, but a bitch in C...  This is one
  of them.
	
	  Accumulate each word up to the last whole
	  word of the last directory entry.  This
	  can spread across several buffer heads.
	
	  Accumulate the last few bytes.  These
	  bytes will be within the same bh.
	
	  The directory tail is in the final bh
	  Note that contary to the RISC OS PRMs,
	  the first few bytes are NOT included
	  in the check.  All bytes are in the
	  same bh.
 Read and check that a directory is valid 
  convert a disk-based directory entry to a Linux ADFS directory entry
  convert a Linux ADFS directory entry to a disk-based directory entry
  get a directory entry.  Note that the caller is responsible
  for holding the relevant locks.
 Update the directory entry with the new object state 
 Write the directory entry back to the directory 
 Increment directory sequence number 
 Update directory check byte 
 Make sure the directory still validates correctly 
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsadfsmap.c
   Copyright (C) 1997-2002 Russell King
  The ADFS map is basically a set of sectors.  Each sector is called a
  zone which contains a bitstream made up of variable sized fragments.
  Each bit refers to a set of bytes in the filesystem, defined by
  log2bpmb.  This may be larger or smaller than the sector size, but
  the overall size it describes will always be a round number of
  sectors.  A fragment id is always idlen bits long.
   < idlen > <       n        > <1>
  +---------+----------------+---+
  | frag id |  0000....000000  | 1 |
  +---------+----------------+---+
  The physical disk space used by a fragment is taken from the start of
  the fragment id up to and including the '1' bit - ie, idlen + n + 1
  bits.
  A fragment id can be repeated multiple times in the whole map for
  large or fragmented files.  The first map zone a fragment starts in
  is given by fragment id  ids_per_zone - this allows objects to start
  from any zone on the disk.
  Free space is described by a linked list of fragments.  Each free
  fragment describes free space in the same way as the other fragments,
  however, the frag id specifies an offset (in map bits) from the end
  of this fragment to the start of the next free fragment.
  Objects stored on the disk are allocated object ids (we use these as
  our inode numbers.)  Object ids contain a fragment id and an optional
  offset.  This allows a directory fragment to contain small files
  associated with that directory.
  For the future...
  This is fun.  We need to load up to 19 bits from the map at an
  arbitrary bit alignment.  (We're limited to 19 bits by F+ version 2).
  return the map bit offset of the fragment frag_id in the zone dm.
  Note that the loop is optimised for best asm code - look at the
  output of:
   gcc -D__KERNEL__ -O2 -I....include -o - -S map.c
  Scan the free space map, for this zone, calculating the total
  number of map bits in each free space fragment.
  Note: idmask is limited to 15 bits [3.2]
	
	  get fragment id
	
	  If the freelink is null, then no free fragments
	  exist in this zone.
  calculate the amount of free blocks in the map.
               n=1
   total_free = E(free_in_zone_n)
               nzones
	
	  map & root fragment is special - it starts in the center of the
	  disk.  The other fragments start at zone (frag  ids_per_zone)
 Convert sector offset to map offset 
 Calculate sector offset into map block 
  Layout the map - the first zone contains a copy of the disc record,
  and the last zone must be limited to the size of the filesystem.
 SPDX-License-Identifier: GPL-2.0-only
  fskernfsinode.c - kernfs inode implementation
  Copyright (c) 2001-3 Patrick Mochel
  Copyright (c) 2007 SUSE Linux Products GmbH
  Copyright (c) 2007, 2013 Tejun Heo <tj@kernel.org>
 assign default attributes 
  kernfs_setattr - set iattr on a node
  @kn: target node
  @iattr: iattr to set
  Returns 0 on success, -errno on failure.
 this ignores size changes 
		
		  kernfs_node has non-default attributes get them from
		  persistent copy in kernfs_node.
 initialize inode according to type 
 	kernfs_get_inode - get inode for kernfs_node
 	@sb: super block
 	@kn: kernfs_node to allocate inode for
 	Get inode for @kn.  If such inode doesn't exist, a new inode is
 	allocated and basics are initialized.  New inode is returned
 	locked.
 	LOCKING:
 	Kernel thread context (may sleep).
 	RETURNS:
 	Pointer to allocated inode on success, NULL on failure.
  The kernfs_node serves as both an inode and a directory entry for
  kernfs.  To prevent the kernfs inode numbers from being freed
  prematurely we take a reference to kernfs_node from the kernfs inode.  A
  super_operations.evict_inode() implementation is needed to drop that
  reference upon inode destruction.
 SPDX-License-Identifier: GPL-2.0-only
  fskernfsdir.c - kernfs directory implementation
  Copyright (c) 2001-3 Patrick Mochel
  Copyright (c) 2007 SUSE Linux Products GmbH
  Copyright (c) 2007, 2013 Tejun Heo <tj@kernel.org>
 kn->parent and ->name 
 protected by rename_lock 
 root->ino_idr 
 kernfs_node_depth - compute depth from @from to @to 
 worst case b and a will be the same at root 
  kernfs_path_from_node_locked - find a pseudo-absolute path to @kn_to,
  where kn_from is treated as root of the path.
  @kn_from: kernfs node which should be treated as root for the path
  @kn_to: kernfs node to which path is needed
  @buf: buffer to copy the path into
  @buflen: size of @buf
  We need to handle couple of scenarios here:
  [1] when @kn_from is an ancestor of @kn_to at some level
  kn_from: n1n2n3
  kn_to:   n1n2n3n4n5
  result:  n4n5
  [2] when @kn_from is on a different hierarchy and we need to find common
  ancestor between @kn_from and @kn_to.
  kn_from: n1n2n3n4
  kn_to:   n1n2n5
  result:  ....n5
  OR
  kn_from: n1n2n3n4n5   [depth=5]
  kn_to:   n1n2n3         [depth=3]
  result:  ....
  [3] when @kn_to is NULL result will be "(null)"
  Returns the length of the full path.  If the full length is equal to or
  greater than @buflen, @buf contains the truncated path with the trailing
  '\0'.  On error, -errno is returned.
 Calculate how many bytes we need for the rest 
  kernfs_name - obtain the name of a given node
  @kn: kernfs_node of interest
  @buf: buffer to copy @kn's name into
  @buflen: size of @buf
  Copies the name of @kn into @buf of @buflen bytes.  The behavior is
  similar to strlcpy().  It returns the length of @kn's name and if @buf
  isn't long enough, it's filled upto @buflen-1 and nul terminated.
  Fills buffer with "(null)" if @kn is NULL.
  This function can be called from any context.
  kernfs_path_from_node - build path of node @to relative to @from.
  @from: parent kernfs_node relative to which we need to build the path
  @to: kernfs_node of interest
  @buf: buffer to copy @to's path into
  @buflen: size of @buf
  Builds @to's path relative to @from in @buf. @from and @to must
  be on the same kernfs-root. If @from is not parent of @to, then a relative
  path (which includes '..'s) as needed to reach from @from to @to is
  returned.
  Returns the length of the full path.  If the full length is equal to or
  greater than @buflen, @buf contains the truncated path with the trailing
  '\0'.  On error, -errno is returned.
  pr_cont_kernfs_name - pr_cont name of a kernfs_node
  @kn: kernfs_node of interest
  This function can be called from any context.
  pr_cont_kernfs_path - pr_cont path of a kernfs_node
  @kn: kernfs_node of interest
  This function can be called from any context.
  kernfs_get_parent - determine the parent node and pin it
  @kn: kernfs_node of interest
  Determines @kn's parent, pins and returns it.  This function can be
  called from any context.
 	kernfs_name_hash
 	@name: Null terminated string to hash
 	@ns:   Namespace tag to hash
 	Returns 31 bit hash of ns + name (so it fits in an off_t )
 Reserve hash numbers 0, 1 and INT_MAX for magic directory entries 
 	kernfs_link_sibling - link kernfs_node into sibling rbtree
 	@kn: kernfs_node of interest
 	Link @kn into its sibling rbtree which starts from
 	@kn->parent->dir.children.
 	Locking:
 	kernfs_rwsem held exclusive
 	RETURNS:
 	0 on susccess -EEXIST on failure.
 add new node and rebalance the tree 
 successfully added, account subdir number 
 	kernfs_unlink_sibling - unlink kernfs_node from sibling rbtree
 	@kn: kernfs_node of interest
 	Try to unlink @kn from its sibling rbtree which starts from
 	kn->parent->dir.children.  Returns %true if @kn was actually
 	removed, %false if @kn wasn't on the rbtree.
 	Locking:
 	kernfs_rwsem held exclusive
 	kernfs_get_active - get an active reference to kernfs_node
 	@kn: kernfs_node to get an active reference to
 	Get an active reference of @kn.  This function is noop if @kn
 	is NULL.
 	RETURNS:
 	Pointer to @kn on success, NULL on failure.
 	kernfs_put_active - put an active reference to kernfs_node
 	@kn: kernfs_node to put an active reference to
 	Put an active reference to @kn.  This function is noop if @kn
 	is NULL.
  kernfs_drain - drain kernfs_node
  @kn: kernfs_node to drain
  Drain existing usages and nuke all existing mmaps of @kn.  Mutiple
  removers may invoke this function concurrently on @kn and all will
  return after draining is complete.
 but everyone should wait for draining 
  kernfs_get - get a reference count on a kernfs_node
  @kn: the target kernfs_node
  kernfs_put - put a reference count on a kernfs_node
  @kn: the target kernfs_node
  Put a reference count of @kn and destroy it if it reached zero.
	
	  Movingrenaming is always done while holding reference.
	  kn->parent won't change beneath us.
 just released the root kn, free @root too 
  kernfs_node_from_dentry - determine kernfs_node associated with a dentry
  @dentry: the dentry in question
  Return the kernfs_node associated with @dentry.  If @dentry is not a
  kernfs one, %NULL is returned.
  While the returned kernfs_node will stay accessible as long as @dentry
  is accessible, the returned node can be in any state and the caller is
  fully responsible for determining what's accessible.
  kernfs_find_and_get_node_by_id - get kernfs_node from node id
  @root: the kernfs root
  @id: the target node id
  @id's lower 32bits encode ino and upper gen.  If the gen portion is
  zero, all generations are matched.
  RETURNS:
  NULL on failure. Return a kernfs node with reference counter incremented
 we looked up with the low 32bits, compare the whole 
 0 matches all generations 
	
	  ACTIVATED is protected with kernfs_mutex but it was clear when
	  @kn was added to idr and we just wanna see it set.  No need to
	  grab kernfs_mutex.
 	kernfs_add_one - add kernfs_node to parent without warning
 	@kn: kernfs_node to be added
 	The caller must already have initialized @kn->parent.  This
 	function increments nlink of the parent's inode if @kn is a
 	directory and link into the children list of the parent.
 	RETURNS:
 	0 on success, -EEXIST if entry with the given name already
 	exists.
 Update timestamps on the parent 
	
	  Activate the new node unless CREATE_DEACTIVATED is requested.
	  If not activated here, the kernfs user is responsible for
	  activating the node with kernfs_activate().  A node which hasn't
	  been activated is not visible to userland and its removal won't
	  trigger deactivation.
  kernfs_find_ns - find kernfs_node with the given name
  @parent: kernfs_node to search under
  @name: name to look for
  @ns: the namespace tag to use
  Look for kernfs_node with name @name under @parent.  Returns pointer to
  the found kernfs_node on success, %NULL on failure.
 grab kernfs_rename_lock to piggy back on kernfs_pr_cont_buf 
  kernfs_find_and_get_ns - find and get kernfs_node with the given name
  @parent: kernfs_node to search under
  @name: name to look for
  @ns: the namespace tag to use
  Look for kernfs_node with name @name under @parent and get a reference
  if found.  This function may sleep and returns pointer to the found
  kernfs_node on success, %NULL on failure.
  kernfs_walk_and_get_ns - find and get kernfs_node with the given path
  @parent: kernfs_node to search under
  @path: path to look for
  @ns: the namespace tag to use
  Look for kernfs_node with path @path under @parent and get a reference
  if found.  This function may sleep and returns pointer to the found
  kernfs_node on success, %NULL on failure.
  kernfs_create_root - create a new kernfs hierarchy
  @scops: optional syscall operations for the hierarchy
  @flags: KERNFS_ROOT_ flags
  @priv: opaque data associated with the new directory
  Returns the root of the new hierarchy on success, ERR_PTR() value on
  failure.
	
	  On 64bit ino setups, id is ino.  On 32bit, low 32bits are ino.
	  High bits generation.  The starting value for both ino and
	  genenration is 1.  Initialize upper 32bit allocation
	  accordingly.
  kernfs_destroy_root - destroy a kernfs hierarchy
  @root: root of the hierarchy to destroy
  Destroy the hierarchy anchored at @root by removing all existing
  directories and destroying @root.
 will also free @root 
  kernfs_create_dir_ns - create a directory
  @parent: parent in which to create a new directory
  @name: name of the new directory
  @mode: mode of the new directory
  @uid: uid of the new directory
  @gid: gid of the new directory
  @priv: opaque data associated with the new directory
  @ns: optional namespace tag of the directory
  Returns the created node on success, ERR_PTR() value on failure.
 allocate 
 link in 
  kernfs_create_empty_dir - create an always empty directory
  @parent: parent in which to create a new directory
  @name: name of the new directory
  Returns the created node on success, ERR_PTR() value on failure.
 allocate 
 link in 
 Negative hashed dentry? 
		 If the kernfs parent node has changed discard and
		  proceed to ->lookup.
		 The kernfs parent node hasn't changed, leave the
		  dentry negative and return success.
 The kernfs node has been deactivated 
 The kernfs node has been moved? 
 The kernfs node has been renamed 
 The kernfs node has been moved to a different namespace 
 attach dentry and inode 
		 Inactive nodes are invisible to the VFS so don't
		  create a negative.
	
	  Needed for negative dentry validation.
	  The negative dentry can be created in kernfs_iop_lookup()
	  or transforms from positive dentry in dentry_unlink_inode()
	  called from vfs_rmdir().
 instantiate and hash (possibly negative) dentry 
  kernfs_next_descendant_post - find the next descendant for post-order walk
  @pos: the current position (%NULL to initiate traversal)
  @root: kernfs_node whose descendants to walk
  Find the next descendant to visit for post-order traversal of @root's
  descendants.  @root is included in the iteration and the last node to be
  visited.
 if first iteration, visit leftmost descendant which may be root 
 if we visited @root, we're done 
 if there's an unvisited sibling, visit its leftmost descendant 
 no sibling left, visit parent 
  kernfs_activate - activate a node which started deactivated
  @kn: kernfs_node whose subtree is to be activated
  If the root has KERNFS_ROOT_CREATE_DEACTIVATED set, a newly created node
  needs to be explicitly activated.  A node which hasn't been activated
  isn't visible to userland and deactivation is skipped during its
  removal.  This is useful to construct atomic init sequences where
  creation of multiple nodes should either succeed or fail atomically.
  The caller is responsible for ensuring that this function is not called
  after kernfs_remove() is invoked on @kn.
	
	  Short-circuit if non-root @kn has already finished removal.
	  This is for kernfs_remove_self() which plays with active ref
	  after removal.
 prevent any new usage under @kn by deactivating all nodes 
 deactivate and unlink the subtree node-by-node 
		
		  kernfs_drain() drops kernfs_rwsem temporarily and @pos's
		  base ref could have been put by someone else by the time
		  the function returns.  Make sure it doesn't go away
		  underneath us.
		
		  Drain iff @kn was activated.  This avoids draining and
		  its lockdep annotations for nodes which have never been
		  activated and allows embedding kernfs_remove() in create
		  error paths without worrying about draining.
		
		  kernfs_unlink_sibling() succeeds once per node.  Use it
		  to decide who's responsible for cleanups.
 update timestamps on the parent 
  kernfs_remove - remove a kernfs_node recursively
  @kn: the kernfs_node to remove
  Remove @kn along with all its subdirectories and files.
  kernfs_break_active_protection - break out of active protection
  @kn: the self kernfs_node
  The caller must be running off of a kernfs operation which is invoked
  with an active reference - e.g. one of kernfs_ops.  Each invocation of
  this function must also be matched with an invocation of
  kernfs_unbreak_active_protection().
  This function releases the active reference of @kn the caller is
  holding.  Once this function is called, @kn may be removed at any point
  and the caller is solely responsible for ensuring that the objects it
  dereferences are accessible.
	
	  Take out ourself out of the active ref dependency chain.  If
	  we're called without an active ref, lockdep will complain.
  kernfs_unbreak_active_protection - undo kernfs_break_active_protection()
  @kn: the self kernfs_node
  If kernfs_break_active_protection() was called, this function must be
  invoked before finishing the kernfs operation.  Note that while this
  function restores the active reference, it doesn't and can't actually
  restore the active protection - @kn may already or be in the process of
  being removed.  Once kernfs_break_active_protection() is invoked, that
  protection is irreversibly gone for the kernfs operation instance.
  While this function may be called at any point after
  kernfs_break_active_protection() is invoked, its most useful location
  would be right before the enclosing kernfs operation returns.
	
	  @kn->active could be in any state; however, the increment we do
	  here will be undone as soon as the enclosing kernfs operation
	  finishes and this temporary bump can't break anything.  If @kn
	  is alive, nothing changes.  If @kn is being deactivated, the
	  soon-to-follow put will either finish deactivation or restore
	  deactivated state.  If @kn is already removed, the temporary
	  bump is guaranteed to be gone before @kn is released.
  kernfs_remove_self - remove a kernfs_node from its own method
  @kn: the self kernfs_node to remove
  The caller must be running off of a kernfs operation which is invoked
  with an active reference - e.g. one of kernfs_ops.  This can be used to
  implement a file operation which deletes itself.
  For example, the "delete" file for a sysfs device directory can be
  implemented by invoking kernfs_remove_self() on the "delete" file
  itself.  This function breaks the circular dependency of trying to
  deactivate self while holding an active ref itself.  It isn't necessary
  to modify the usual removal path to use kernfs_remove_self().  The
  "delete" implementation can simply invoke kernfs_remove_self() on self
  before proceeding with the usual removal path.  kernfs will ignore later
  kernfs_remove() on self.
  kernfs_remove_self() can be called multiple times concurrently on the
  same kernfs_node.  Only the first one actually performs removal and
  returns %true.  All others will wait until the kernfs operation which
  won self-removal finishes and return %false.  Note that the losers wait
  for the completion of not only the winning kernfs_remove_self() but also
  the whole kernfs_ops which won the arbitration.  This can be used to
  guarantee, for example, all concurrent writes to a "delete" file to
  finish only after the whole operation is complete.
	
	  SUICIDAL is used to arbitrate among competing invocations.  Only
	  the first one will actually perform removal.  When the removal
	  is complete, SUICIDED is set and the active ref is restored
	  while kernfs_rwsem for held exclusive.  The ones which lost
	  arbitration waits for SUICIDED && drained which can happen only
	  after the enclosing kernfs operation which executed the winning
	  instance of kernfs_remove_self() finished.
	
	  This must be done while kernfs_rwsem held exclusive; otherwise,
	  waiting for SUICIDED && deactivated could finish prematurely.
  kernfs_remove_by_name_ns - find a kernfs_node by name and remove it
  @parent: parent of the target
  @name: name of the kernfs_node to remove
  @ns: namespace tag of the kernfs_node to remove
  Look for the kernfs_node with @name and @ns under @parent and remove it.
  Returns 0 on success, -ENOENT if such entry doesn't exist.
  kernfs_rename_ns - move and rename a kernfs_node
  @kn: target node
  @new_parent: new parent to put @sd under
  @new_name: new name
  @new_ns: new namespace tag
 can't move or rename root 
 nothing to rename 
 rename kernfs_node 
	
	  Move to the appropriate place in the appropriate directories rbtree.
 rename_lock protects ->parent and ->name accessors 
 Relationship between mode and the DT_xxx types 
 Skip over entries which are dyingdead or in the wrong namespace 
 SPDX-License-Identifier: GPL-2.0-only
  fskernfsfile.c - kernfs file implementation
  Copyright (c) 2001-3 Patrick Mochel
  Copyright (c) 2007 SUSE Linux Products GmbH
  Copyright (c) 2007, 2013 Tejun Heo <tj@kernel.org>
  There's one kernfs_open_file for each open file and one kernfs_open_node
  for each kernfs_node with one or more open files.
  kernfs_node->attr.open points to kernfs_open_node.  attr.open is
  protected by kernfs_open_node_lock.
  filp->private_data points to seq_file whose ->private points to
  kernfs_open_file.  kernfs_open_files are chained at
  kernfs_open_node->files, which is protected by kernfs_open_file_mutex.
 goes through kernfs_open_file.list 
  kernfs_notify() may be called from any context and bounces notifications
  through a work item.  To minimize space overhead in kernfs_node, the
  pending queue is implemented as a singly linked list of kernfs_nodes.
  The list is terminated with the self pointer so that whether a
  kernfs_node is on the list or not can be determined by testing the next
  pointer for NULL.
  Determine the kernfs_ops for the given kernfs_node.  This function must
  be called while holding an active reference.
  As kernfs_seq_stop() is also called after kernfs_seq_start() or
  kernfs_seq_next() failure, it needs to distinguish whether it's stopping
  a seq_file iteration which is fully initialized with an active reference
  or an aborted kernfs_seq_start() due to get_active failure.  The
  position pointer is the only context for each seq_file iteration and
  thus the stop condition should be encoded in it.  As the return value is
  directly visible to userland, ERR_PTR(-ENODEV) is the only acceptable
  choice to indicate get_active failure.
  Unfortunately, this is complicated due to the optional custom seq_file
  operations which may return ERR_PTR(-ENODEV) too.  kernfs_seq_stop()
  can't distinguish whether ERR_PTR(-ENODEV) is from get_active failure or
  custom seq_file operations and thus can't decide whether put_active
  should be performed or not only on ERR_PTR(-ENODEV).
  This is worked around by factoring out the custom seq_stop() and
  put_active part into kernfs_seq_stop_active(), skipping it from
  kernfs_seq_stop() if ERR_PTR(-ENODEV) while invoking it directly after
  custom seq_file operations fail with ERR_PTR(-ENODEV) - this ensures
  that kernfs_seq_stop_active() is skipped only after get_active failure.
	
	  @of->mutex nests outside active ref and is primarily to ensure that
	  the ops aren't called concurrently for the same open file.
 see the comment above kernfs_seq_stop_active() 
		
		  The same behavior and code as single_open().  Returns
		  !NULL if pos is at the beginning; otherwise, NULL.
 see the comment above kernfs_seq_stop_active() 
		
		  The same behavior and code as single_open(), always
		  terminate after the initial read.
  As reading a bin file can have side-effects, the exact offset and bytes
  specified in read(2) call should be passed to the read callback making
  it difficult to use seq_file.  Implement simplistic custom buffering for
  bin files.
	
	  @of->mutex nests outside active ref and is used both to ensure that
	  the ops aren't called concurrently for the same open file.
  Copy data in from userland and pass it to the matching kernfs write
  operation.
  There is no easy way for us to know if userspace is only doing a partial
  write, so we don't support them. We expect the entire buffer to come on
  the first write.  Hint: if you're writing a value, first read the file,
  modify only the the value you're changing, then write entire buffer
  back.
 guarantee string termination 
	
	  @of->mutex nests outside active ref and is used both to ensure that
	  the ops aren't called concurrently for the same open file.
	
	  mmap path and of->mutex are prone to triggering spurious lockdep
	  warnings and we don't want to add spurious locking dependency
	  between the two.  Check whether mmap is actually implemented
	  without grabbing @of->mutex by testing HAS_MMAP flag.  See the
	  comment in kernfs_file_open() for more details.
	
	  PowerPC's pci_mmap of legacy_mem uses shmem_zero_setup()
	  to satisfy versions of X which crash if the mmap fails: that
	  substitutes a new vm_file, and we don't then want bin_vm_ops.
	
	  It is not possible to successfully wrap close.
	  So error if someone is trying to use close.
 	kernfs_get_open_node - get or create kernfs_open_node
 	@kn: target kernfs_node
 	@of: kernfs_open_file for this instance of open
 	If @kn->attr.open exists, increment its reference count; otherwise,
 	create one.  @of is chained to the files list.
 	LOCKING:
 	Kernel thread context (may sleep).
 	RETURNS:
 	0 on success, -errno on failure.
 not there, initialize a new one and retry 
 	kernfs_put_open_node - put kernfs_open_node
 	@kn: target kernfs_nodet
 	@of: associated kernfs_open_file
 	Put @kn->attr.open and unlink @of from the files list.  If
 	reference count reaches zero, disassociate and free it.
 	LOCKING:
 	None.
 see the flag definition for details 
 allocate a kernfs_open_file for the file 
	
	  The following is done to give a different lockdep key to
	  @of->mutex for files which implement mmap.  This is a rather
	  crude way to avoid false positive lockdep warning around
	  mm->mmap_lock - mmap nests @of->mutex under mm->mmap_lock and
	  reading sysblocksdatraceact_mask grabs sr_mutex, under
	  which mm->mmap_lock nests, while holding @of->mutex.  As each
	  open file has a separate mutex, it's okay as long as those don't
	  happen on the same file.  At this point, we can't easily give
	  each file a separate locking class.  Let's differentiate on
	  whether the file has mmap or not for now.
	 
	  Both paths of the branch look the same.  They're supposed to
	  look that way and give @of->mutex different static lockdep keys.
	
	  Write path needs to atomic_write_len outside active reference.
	  Cache it in open_file.  See kernfs_fop_write_iter() for details.
	
	  ->seq_show is incompatible with ->prealloc,
	  as seq_read does its own allocation.
	  ->read must be used instead.
	
	  Always instantiate seq_file even if read access doesn't use
	  seq_file or is not requested.  This unifies private data access
	  and readable regular files are the vast majority anyway.
 seq_file clears PWRITE unconditionally, restore it if WRITE 
 make sure we have open node struct 
 nobody has access to @of yet, skip @of->mutex 
 open succeeded, put active references 
 used from releasedrain to ensure that ->release() is called exactly once 
	
	  @of is guaranteed to have no other file operations in flight and
	  we just want to synchronize release and drain paths.
	  @kernfs_open_file_mutex is enough.  @of->mutex can't be used
	  here because drain path may be called from places which can
	  cause circular dependency.
		
		  A file is never detached without being released and we
		  need to be able to release files which are deactivated
		  and being drained.  Don't use kernfs_ops().
  Kernfs attribute files are pollable.  The idea is that you read
  the content and then you use 'poll' or 'select' to wait for
  the content to change.  When the content changes (assuming the
  manager for the kobject supports notification), poll will
  return EPOLLERR|EPOLLPRI, and select will return the fd whether
  it is waiting for read, write, or exceptions.
  Once pollselect indicates that the value has changed, you
  need to close and re-open the file, or seek to 0 and read again.
  Reminder: this only works for attributes which actively support
  it, and it is not possible to test an attribute from userspace
  to see if it supports poll (Neither 'poll' nor 'select' return
  an appropriate error code).  When in doubt, set a suitable timeout value.
 pop one off the notify_list 
 kick fsnotify 
		
		  We want fsnotify_modify() on @kn but as the
		  modifications aren't originating from userland don't
		  have the matching @file available.  Look up the inodes
		  and generate the events manually.
  kernfs_notify - notify a kernfs file
  @kn: file to notify
  Notify @kn such that poll(2) on @kn wakes up.  Maybe be called from any
  context.
 kick poll immediately 
 schedule work to kick fsnotify 
  __kernfs_create_file - kernfs internal function to create a file
  @parent: directory to create the file in
  @name: name of the file
  @mode: mode of the file
  @uid: uid of the file
  @gid: gid of the file
  @size: size of the file
  @ops: kernfs operations for the file
  @priv: private data for the file
  @ns: optional namespace tag of the file
  @key: lockdep key for the file's active_ref, %NULL to disable lockdep
  Returns the created node on success, ERR_PTR() value on error.
	
	  kn->attr.ops is accesible only while holding active ref.  We
	  need to know whether some ops are implemented outside active
	  ref.  Cache their existence in flags.
 SPDX-License-Identifier: GPL-2.0-only
  fskernfssymlink.c - kernfs symlink implementation
  Copyright (c) 2001-3 Patrick Mochel
  Copyright (c) 2007 SUSE Linux Products GmbH
  Copyright (c) 2007, 2013 Tejun Heo <tj@kernel.org>
  kernfs_create_link - create a symlink
  @parent: directory to create the symlink in
  @name: name of the symlink
  @target: target node for the symlink to point to
  Returns the created node on success, ERR_PTR() value on error.
  Ownership of the link matches ownership of the target.
 ref owned by symlink 
 go up to the root, stop at the base 
 determine end of target string for reverse fillup 
 check limits 
 reverse fillup of target string from target to base 
 SPDX-License-Identifier: GPL-2.0-only
  fskernfsmount.c - kernfs mount implementation
  Copyright (c) 2001-3 Patrick Mochel
  Copyright (c) 2007 SUSE Linux Products GmbH
  Copyright (c) 2007, 2013 Tejun Heo <tj@kernel.org>
		
		  blk_log_action() exposes "LOW32,HIGH32" pair without
		  type and userland can call us with generic fid
		  constructed from them.  Combine it back to ID.  See
		  blk_log_action().
  kernfs_root_from_sb - determine kernfs_root associated with a super_block
  @sb: the super_block in question
  Return the kernfs_root associated with @sb.  If @sb is not a kernfs one,
  %NULL is returned.
  find the next ancestor in the path down to @child, where @parent was the
  ancestor whose descendant we want to find.
  Say the path is abcd.  @child is d, @parent is NULL.  We return the root
  node.  If @parent is b, then we return the node for c.
  Passing in d as @parent is not ok.
  kernfs_node_dentry - get a dentry for the given kernfs_node
  @kn: kernfs_node for which a dentry is needed
  @sb: the kernfs super_block
 Check if this is the root kernfs_node 
 Userspace would break if executables or devices appear on sysfs 
 sysfs dentries and inodes don't require IO to create 
 get root inode, initialize and unlock it 
 instantiate and link root dentry 
  kernfs_super_ns - determine the namespace tag of a kernfs super_block
  @sb: super_block of interest
  Return the namespace tag associated with kernfs super_block @sb.
  kernfs_get_tree - kernfs filesystem accessretrieval helper
  @fc: The filesystem context.
  This is to be called from each kernfs user's fs_context->ops->get_tree()
  implementation, which should set the specified ->@fs_type and ->@flags, and
  specify the hierarchy and namespace tag to mount via ->@root and ->@ns,
  respectively.
 Note that we don't deal with kfc->ns_tag here. 
  kernfs_kill_sb - kill_sb for kernfs
  @sb: super_block being killed
  This can be used directly for file_system_type->kill_sb().  If a kernfs
  user needs extra cleanup, it can implement its own kill_sb() and call
  this function at the end.
	
	  Remove the superblock from fs_superss_instances
	  so we can't find it, before freeing kernfs_super_info.
 Creates slab cache for kernfs inode attributes 
 SPDX-License-Identifier: GPL-2.0-only
  Optimized MPEG FS - inode and super operations.
  Copyright (C) 2006 Bob Copeland <me@bobcopeland.com>
  Update the header checksums for a dirty inode based on its contents.
  Caller is expected to hold the buffer head underlying oi and mark it
  dirty.
 get current inode since we may have written sibling ptrs etc. 
 if mirroring writes, copy to next fsblock 
  called when an entry is deleted, need to clear the bits in the
  bitmaps.
 check self 
  Display the mount options in procmounts.
  For Rio Karma, there is an on-disk free bitmap whose location is
  stored in the root block.  For ReplayTV, there is no such free bitmap
  so we have to walk the tree.  Both inodes and file data are allocated
  from the same map.  This array can be big (300k) so we allocate
  in units of the blocksize.
	
	  Use sys_blocksize as the fs block since it is smaller than a
	  page while the fs blocksize can be larger.
	
	  ...and the difference goes into a shift.  sys_blocksize is always
	  a power of two factor of blocksize.
 SPDX-License-Identifier: GPL-2.0-only
  OMFS (as used by RIO Karma) directory operations.
  Copyright (C) 2005 Bob Copeland <me@bobcopeland.com>
  Finds the bucket for a given name and reads the containing block;
  ofs is set to the offset of the first list entry.
 just prepend to head of queue in proper bucket 
 now set the sibling and parent pointers on the new inode 
 mark affected inodes dirty to rebuild checksums 
 delete the proper node in the bucket's linked list 
 found in middle of list, get list ptr 
 sanity check block's self pointer 
 follow chain in this bucket 
 skip visited nodes 
 overwriting existing filedir 
	 since omfs locates files by name, we need to unlink _before_
 high 12 bits store bucket + 1 and low 20 bits store hash index 
 SPDX-License-Identifier: GPL-2.0-only
  OMFS (as used by RIO Karma) file operations.
  Copyright (C) 2005 Bob Copeland <me@bobcopeland.com>
	 traverse extent table, freeing each entry that is greater
	  than inode->i_size;
 only support truncate -> 0 for now 
 ignore last entry as it is the terminator 
  Add new blocks to the current extent, or create new entriescontinuations
  as necessary.
	 reached the end of the extent table with no blocks mapped.
	  there are three possibilities for adding: grow last extent,
	  add a new extent to the current extent table, and add a
	  continuation inode.  in last two cases need an allocator for
	  sbi->s_cluster_size
 TODO: handle holes 
 should always have a terminator 
 trivially grow current extent, if next block is not taken 
 TODO: add a continuation block here 
 try to allocate a new cluster 
 copy terminator down an entry 
 write in new entry 
  Scans across the directory table for a given file block number.
  If block not found, return 0.
 count > 1 because of terminator 
			
			  found it at cluster + (block - searched)
			  numblocks - (block - searched) is remainder
 SPDX-License-Identifier: GPL-2.0
   Counts the run of zero bits starting at bit up to max.
   It handles the case where a run might spill over a buffer.
   Called with bitmap lock.
  Sets or clears the run of count bits starting with bit.
  Called with bitmap lock.
  Tries to allocate exactly one block.  Returns true if successful.
   Tries to allocate a set of blocks.	The request size depends on the
   type: for inodes, we must allocate sbi->s_mirrors blocks, and for file
   blocks, we try to allocate sbi->s_clustersize, but can always get away
   with just one block.
  Clears count bits starting at a given block.
 SPDX-License-Identifier: GPL-2.0-only
  acl.c
  Copyright (C) 2004, 2008 Oracle.  All rights reserved.
  CREDITS:
  Lots of code in this file is copy from linuxfsext3acl.c.
  Copyright (C) 2001-2003 Andreas Gruenbacher, <agruen@suse.de>
  Convert from xattr value to acl struct.
  Convert acl struct to xattr value.
  Helper function to set i_mode in memory and disk. Some call paths
  will not have di_bh or a journal handle to pass, in which case it
  will create it's own.
  Set the access or default ACL of an inode.
  Initialize the ACLs of a new inode. If parent directory has default ACL,
  then clone to new inode. Called from ocfs2_mknod.
 SPDX-License-Identifier: GPL-2.0-or-later
  uptodate.c
  Tracking the up-to-date-ness of a local buffer_head with respect to
  the cluster.
  Copyright (C) 2002, 2004, 2005 Oracle.  All rights reserved.
  Standard buffer head caching flags (uptodate, etc) are insufficient
  in a clustered environment - a buffer may be marked up to date on
  our local node but could have been modified by another cluster
  member. As a result an additional (and performant) caching scheme
  is required. A further requirement is that we consume as little
  memory as possible - we never pin buffer_head structures in order
  to cache them.
  We track the existence of up to date buffers on the inodes which
  are associated with them. Because we don't want to pin
  buffer_heads, this is only a (strong) hint and several other checks
  are made in the IO path to ensure that we don't use a stale or
  invalid buffer without going to disk:
 	- buffer_jbd is used liberally - if a bh is in the journal on
 	  this node then it must be up to date.
 	- the standard buffer_uptodate() macro is used to detect buffers
 	  which may be invalid (even if we have an up to date tracking
  	  item for them)
  For a full understanding of how this code works together, one
  should read the callers in dlmglue.c, the IO functions in
  buffer_head_io.c and ocfs2_journal_access in journal.c
 No lock taken here as 'root' is not expected to be visible to other
 Called from locking and called from ocfs2_clear_inode. Dump the
  cache for a given inode.
  This function is a few more lines longer than necessary due to some
  accounting done here, but I think it's worth tracking down those
	 If we're a tree, save off the root so that we can safely
	  initialize the cache. We do the work to free tree members
	 If possible, track the number wiped so that we can more
	  easily detect counting errors. Unfortunately, this is only
 Returns the index in the cache array, -1 if not found.
 Returns the cache item if found, otherwise NULL.
 Warning: even if it returns true, this does not guarantee that
  the block is stored in our inode metadata cache.
  This can be called under lock_buffer()
	 Doesn't matter if the bh is in our cache or not -- if it's
	  not marked uptodate then we know it can't have correct
	 OCFS2 does not allow multiple nodes to be changing the same
	 Ok, locally the buffer is marked as up to date, now search
  Determine whether a buffer is currently out on a read-ahead request.
  ci_io_sem should be held to serialize submitters with the logic here.
 Requires ip_lock 
 By now the caller should have checked that the item does not
  exist in the tree.
 This should never happen! 
 co_cache_lock() must be held 
 tree should be exactly OCFS2_CACHE_INFO_MAX_ARRAY wide. NULL the
  pointers in tree after we use them - this allows caller to detect
  when to free in case of error.
	 Be careful to initialize the tree members first because
 this will be set again by __ocfs2_insert_cache_tree 
 Slow path function - memory allocation is necessary. See the
		 Do not allocate an array here - the removal code
 These are initialized in ocfs2_expand_cache! 
		 Ok, items were removed from the cache in between
	 If these were used, then ocfs2_expand_cache re-set them to
 Item insertion is guarded by co_io_lock(), so the insertion path takes
  advantage of this by not rechecking for a duplicate insert during
  the slow case. Additionally, if the cache needs to be bumped up to
  a tree, the code will not recheck after acquiring the lock --
  multiple paths cannot be expanding to a tree at the same time.
  The slow path takes into account that items can be removed
  (including the whole tree wiped and reset) when this process it out
  allocating memory. In those cases, it reverts back to the fast
  path.
  Note that this function may actually fail to insert the block if
  memory cannot be allocated. This is not fatal however (but may
  result in a performance penalty)
  Readahead buffers can be passed in here before the IO request is
  completed.
	 The block may very well exist in our cache already, so avoid
	 No need to recheck under spinlock - insertion is guarded by
		 Fast case - it's an array and there's a free
 We need to bump things up to a tree. 
 Called against a newly allocated buffer. Most likely nobody should
  be able to read this sort of metadata while it's still being
 This should definitely not exist in our cache 
 Requires ip_lock. 
	 don't need to copy if the array is now empty, or if we
 Requires ip_lock. 
  Called when we remove a chunk of metadata from an inode. We don't
  bother reverting things to an inlined array in the case of a remove
  which moves us back under the limit.
 Called when we remove xattr clusters from an inode. 
 SPDX-License-Identifier: GPL-2.0
  linuxfsocfs2ioctl.c
  Copyright (C) 2006 Herbert Poetzl
  adapted from Remy Card's ext2ioctl.c
  This is just a best-effort to tell userspace that this request
  caused the error.
 Check already done by VFS, but repeat with ocfs lock 
			
			  last chunk may be not an entire one.
				
				  - chunk_free counts free clusters in #N chunk.
				  - last_chunksize records the size(in) clusters
				    for the last real free chunk being counted.
		
		  need to update the info for last free chunk.
	
	  Chunksize(in) clusters from userspace should be
	  less than clusters in a group.
	
	  chunksize from userspace should be power of 2.
  Validate and distinguish OCFS2_IOC_INFO requests.
  - validate the magic number.
  - distinguish different requests.
  - validate size of different requests.
		
		  pointer bp stores the base address of a pointers array,
		  which collects all addresses of separate request.
  OCFS2_IOC_INFO handles an array of requests passed from userspace.
  ocfs2_info_handle() recevies a large info aggregation, grab and
  validate the request count from header, then break it into small
  pieces, later specific handlers can handle them one by one.
  Idea here is to make each separate request small enough to ensure
  a better backward&forward compatibility, since a small piece of
  request will be less likely to be broken if disk layout get changed.
 SPDX-License-Identifier: GPL-2.0-or-later
  namei.c
  Create and rename file, directory, symlinks
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
   Portions of this code from linuxfsext3dir.c
   Copyright (C) 1992, 1993, 1994, 1995
   Remy Card (card@masi.ibp.fr)
   Laboratoire MASI - Institut Blaise pascal
   Universite Pierre et Marie Curie (Paris VI)
    from
    linuxfsminixdir.c
    Copyright (C) 1991, 1992 Linux Torvalds
 An orphan dir name is an 8 byte value, printed as a hex string 
	 Clear any orphaned state... If we were able to look up the
	  inode from a directory, it certainly can't be orphaned. We
	  might have the bad state from a node which intended to
	  orphan this inode but crashed before it could commit the
		
		  If d_splice_alias() finds a DCACHE_DISCONNECTED
		  dentry, it will d_move() it on top of ourse. The
		  return value will indicate this however, so in
		  those cases, we switch them around for the locking
		  code.
		 
		  NOTE: This dentry already has ->d_op set from
		  ocfs2_get_parent() and ocfs2_get_dentry()
	 Don't drop the cluster lock until after the d_add --
	  unlink on another node will message us to remove that
	  dentry under this lock so otherwise we can race this with
	 populate as many fields early on as possible - many of
	  these are used by the support functions here and in
 get our super block 
 can't make a file in a deleted directory. 
 get a spot inside the dir. 
 reserve an inode spot 
 get security xattr 
 calculate meta dataclusters for setting security and acl xattr 
 Reserve a cluster if creating an extent based directory. 
 Dir indexing requires extra space as well 
 Starting to change things, restart is no longer possible. 
 do the real work now. 
	
	  Do this before adding the entry to the directory. We add
	  also set d_op after success so that ->d_iput() will cleanup
	  the dentry lock even if ocfs2_add_entry() fails below.
	
	  We should call iput after the i_mutex of the bitmap been
	  unlocked in ocfs2_free_alloc_context, or the
	  ocfs2_delete_inode will mutex_lock again.
	 populate as many fields early on as possible - many of
	  these are used by the support functions here and in
	
	  If supported, directories start with inline data. If inline
	  isn't supported, but indexing is, we start them as indexed.
	 make sure both dirs have bhs
	
	  Check whether another node removed the source inode while we
	  were in the vfs.
 Starting to change things, restart is no longer possible. 
  Takes and drops an exclusive lock on the given dentry. This will
  force other nodes to drop it.
		 This remote delete should succeed under all normal
 delete the name from the parent dir 
 This was locked for us in ocfs2_prepare_orphan_dir() 
  The only place this should be used is rename and link!
  if they have the same id, then the 1st one is the only one locked.
	 we always want to lock the one with the lower lockid first.
 switch id1 and id2 around 
 lock id2 
 lock id1 
		
		  An error return must mean that no cluster locks
		  were held on function exit.
	 At some point it might be nice to break this function up a
	 Assume a directory hierarchy thusly:
	  abc
	  ad
	  a,b,c, and d are all directories.
	 
	  from cwd of 'a' on both nodes:
	  node1: mv bc d
	  node2: mv d   bc
	 
	  And that's why, just like the VFS, we need a file system
		 here we cannot guarantee the inodes haven't just been
 if old and new are the same, this'll just do one lock. 
	 make sure both dirs have bhs
	
	  Aside from allowing a meta data update, the locking here
	  also ensures that the downconvert thread on other nodes
	  won't have to concurrently downconvert the inode and the
	  dentry locks.
	
	   Check for inode number is _not_ due to possible IO errors.
	   We might rmdir the source, keep it as pwd of some process
	   and merrily kill the link to whatever was created under the
	   same name. Goodbye sticky bit ;-<
	 check if the target already exists (in which case we need
	 The only error we allow here is -ENOENT because the new
 If we cannot find the file specified we should just 
 return the error... 
		
		  Target was unlinked by another node while we were
		  waiting to get to ocfs2_rename(). There isn't
		  anything we can do here to help the situation, so
		  bubble up the appropriate error.
	 In case we need to overwrite an existing file, we blow it
		 VFS didn't think there existed an inode here, but
		  someone else in the cluster must have raced our
		  rename to create one. Today we error cleanly, in
		  the future we should consider calling iget to build
 change the dirent to point to the correct inode 
 if the name was not found in new_dir, add it now 
	
	  Now that the name has been added to new_dir, remove the old name.
	 
	  We don't keep any directory entry context around until now
	  because the insert might have changed the type of directory
	  we're dealing with.
 Keep the same times on both directories.
		
		  This will also pick up the i_nlink change from the
		  block above.
 This was locked for us in ocfs2_prepare_orphan_dir() 
  we expect i_size = strlen(symname). Copy symname into the file
  data, including the null terminator.
	 we can't trust i_blocks because we're actually going to
 Sanity check -- make sure we're going to fit. 
	 links can never be larger than one cluster so we know this
	  is all going to be contiguous, but do a sanity check
 lock the parent directory 
 can't make a file in a deleted directory. 
 get security xattr 
 calculate meta dataclusters for setting security xattr 
 don't reserve bitmap space for fast symlinks. 
 Starting to change things, restart is no longer possible. 
	
	  Do this before adding the entry to the directory. We add
	  also set d_op after success so that ->d_iput() will cleanup
	  the dentry lock even if ocfs2_add_entry() fails below.
  ocfs2_prepare_orphan_dir() - Prepare an orphan directory for
  insertion of an orphan.
  @osb: ocfs2 file system
  @ret_orphan_dir: Orphan dir inode - returned locked!
  @blkno: Actual block number of the inode to be inserted into orphan dir.
  @lookup: dir lookup result, to be passed back into functions like
           ocfs2_orphan_add
  Returns zero on success and the ret_orphan_dir, name and lookup
  fields will be populated.
  Returns non-zero on failure. 
	
	  We're going to journal the change of i_flags and i_orphaned_slot.
	  It's safe anyway, though some callers may duplicate the journaling.
	  Journaling within the func just make the logic look more
	  straightforward.
	 we're a cluster, and nlink can change on disk from
		 Update flag OCFS2_DIO_ORPHANED_FL and record the orphan
		  slot.
		 Record which orphan dir our inode now resides
		  in. delete_inode will use this to determine which orphan
 unlike orphan_add, we expect the orphan dir to already be locked here. 
 find it's spot in the orphan directory 
 remove it from the orphan directory 
 do the i_nlink dance! :) 
  ocfs2_prep_new_orphaned_file() - Prepare the orphan dir to receive a newly
  allocated file. This is different from the typical 'add to orphan dir'
  operation in that the inode does not yet exist. This is a problem because
  the orphan dir stringifies the inode block number to come up with it's
  dirent. Obviously if the inode does not yet exist we have a chicken and egg
  problem. This function works around it by calling deeper into the orphan
  and suballoc code than other callers. Use this only by necessity.
  @dir: The directory which this inode will ultimately wind up under - not the
  orphan dir!
  @dir_bh: buffer_head the @dir inode block
  @orphan_name: string of length (CFS2_ORPHAN_NAMELEN + 1). Will be filled
  with the string to be used for orphan dirent. Pass back to the orphan dir
  code.
  @ret_orphan_dir: orphan dir inode returned to be passed back into orphan
  dir code.
  @ret_di_blkno: block number where the new inode will be allocated.
  @orphan_insert: Dir insert context to be passed back into orphan dir code.
  @ret_inode_ac: Inode alloc context to be passed back to the allocator.
  Returns zero on success and the ret_orphan_dir, name and lookup
  fields will be populated.
  Returns non-zero on failure. 
 reserve an inode spot 
		
		  orphan_name and orphan_insert are already up to
		  date via prepare_orphan_dir
 Unroll reserve_new_inode 
 Unroll orphan dir locking 
 do the real work now. 
 get open lock so that only nodes can't remove it from orphan dir. 
 This was locked for us in ocfs2_prepare_orphan_dir() 
	
	  Another append dio crashed?
	  If so, manually recover it first.
 can't make a file in a deleted directory. 
 get a spot inside the dir. 
 SPDX-License-Identifier: GPL-2.0-or-later
  super.c
  loadunload driver, mountdismount volumes
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
 this should be the only file to include a version 1 header 
 CONFIG_DEBUG_FS 
 the array now has one ref, so drop this one
 the array now has one ref, so drop this one 
 We're allocating fs objects, use GFP_NOFS 
	
	  i_size and all block offsets in ocfs2 are always 64 bits
	  wide. i_clusters is 32 bits, in cluster-sized units. So on
	  64 bit platforms, cluster size will be the limiting factor.
	
	  We might be limited by page cache size.
		
		  Shift by 31 here so that we don't get larger than
		  MAX_LFS_FILESIZE
	
	  Trim by a whole cluster when we can actually approach the
	  on-disk limits. Otherwise we can overflow i_clusters when
	  an extent start is at the max offset.
	 Probably don't want this on remount; it might
 We're going tofrom readonly mode. 
 Disable quota accounting before remounting RO 
		 Lock here so the check of HARD_RO and the potential
 Enable quota accounting after remounting RW 
 Return back changes... 
		 Only save off the new mount options in case of a successful
 may be > 512 
 Can this really happen? 
 check block zero for old format 
	
	  Now check at magic offset for 512, 1024, 2048, 4096
	  blocksizes.  4096 is the maximum blocksize because it is
	  the minimum clustersize.
  If we're using a userspace stack, mount should have passed
  a name that matches the disk.  If not, mount should not
  have passed a stack.
 Cancel periodic syncing before suspending 
	 We mostly ignore errors in this function because there's not much
		 Turn off quotas. This will remove all dquot structures from
		  memory and so they will be automatically synced to global
 probe for superblock 
	 Hard readonly mode only if: bdev_read_only, SB_RDONLY,
		 You should not be able to start a local heartbeat
	 Create filecheck sysfs related directoriesfiles at
	 Now we can initialize quotas because we can afford to wait
	  for cluster locks recovery now. That also means that truncation
			 We have to err-out specially here because
 Now we wake up again for processes waiting for quotas 
 Start this when the mount is almost sure of being successful 
 No ACL setting specified? Use XATTR feature... 
			
			  Changing this during remount could race
			  flock() requests, or "unbalance" existing
			  ones (e.g., a lock is taken in one mode but
			  dropped in the other). If users care enough
			  to flip locking modes during remount, we
			  could add a "local" flag to individual
			  flock structures for proper tracking of
			  state.
			 Check both that the option we were passed
			  is of the right length and that it is a proper
			  string of the right length.
			
			  Open code the memcmp here as we don't have
			  an osb to pass to
			  ocfs2_userspace_stack().
 Ensure only one heartbeat mode 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 This will load up the node map and add ourselves to it. 
 load all node-local system inodes 
	 Remove file check sysfs related directoresfiles,
 Orphan scan should be stopped as early as possible 
 All dquots should be freed by now 
 Wait for worker to be done with the work structure in osb 
 This will disable recovery and flush any recovery work. 
	 No cluster connection means we've failed during mount, so skip
	
	  If we're dismounting due to mount error, mount.ocfs2 will clean
	  up heartbeat.  If we're a local mount, there is no heartbeat.
	  If we failed before we got a uuid_str yet, we can't stop
	  heartbeat.  Otherwise, do it.
 print with null 
 drop super cleans up 
 then only advance past the last char 
 Make sure entire volume is addressable by our journal.  Requires
   osb_clusters_at_boot to be valid and for the journal to have been
 32-bit block number is always OK. 
	 Volume is "huge", so see if our journal is new enough to
 this is needed to support O_LARGEFILE 
 Copy the blockcheck stats from the superblock probe 
		
		  ci_stack and ci_cluster in ocfs2_cluster_info may not be null
		  terminated, so make sure no overflow happens here by using
		  memcpy. Destination strings will always be null terminated
		  because osb is allocated using kzalloc.
		 The empty string is identical with classic tools that
 get some pseudo constants for clustersize bits 
 load root, system_dir, and all global system inodes 
	
	  global bitmap
  will return: -EAGAIN if it is ok to keep searching for superblocks
               -EINVAL if there is a bad superblock
               0 on success
 We have to do a raw check of the feature here 
 found it! 
	struct ocfs2_dinode local_alloc = NULL;  only used if we
						   recover
 Init our journal object. 
	 Now that journal has been initialized, check to make sure
	 If the journal was unmounted cleanly then we don't want to
	  recover anything. Otherwise, journal_load will do that
 will play back anything left in the journal. 
 recover my local alloc if we didn't unmount cleanly. 
		 we complete the recovery process after we've marked
		 Recovery will be completed after we've mounted the
	 go through each journal, trylock it and if you get the
	  lock, and it's marked as dirty, set the bit in the recover
  The routine gets called from dismount or close whenever a dismount on
  volume is requested and the osb open count becomes 1.
  It will remove the osb from the global list and also free up all the
  initialized resources and fileobject.
 This function assumes that the caller has the main osb resource 
 ocfs2_initializer_super have already created this workqueue 
 Depending on the mount option passed, perform one of the following:
  Put OCFS2 into a readonly state (default)
  Return EIO so that only the process errs
  Fix the error as if fsck.ocfs2 -y
  panic
 default option 
	 Not using mlog here because we want to show the actual
 Handle critical errors. This is intentionally more drastic than
  ocfs2_handle_error, so we only use for things like journal errors,
	 We don't have the cluster support yet to go straight to
	  hard readonly in here. Until then, we want to keep
	  ocfs2_abort() so that we can at least mark critical
	  errors.
	 
	  TODO: This should abort the journal and alert other nodes
	 Force a panic(). This stinks, but it's better than letting
	  things continue without having a proper hard readonly
  Void signal blockers, because in-kernel sigprocmask() only fails
  when SIG_ is wrong.
 SPDX-License-Identifier: GPL-2.0
   Implementation of operations over global quota file
  Locking of quotas with OCFS2 is rather complex. Here are rules that
  should be obeyed by all the functions:
  - any write of quota structure (either to local or global file) is protected
    by dqio_sem or dquot->dq_lock.
  - any modification of global quota file holds inode cluster lock, i_mutex,
    and ip_alloc_sem of the global quota file (achieved by
    ocfs2_lock_global_qf). It also has to hold qinfo_lock.
  - an allocation of new blocks for local quota file is protected by
    its ip_alloc_sem
  A rough sketch of locking dependencies (lf = local file, gf = global file):
  Normal filesystem operation:
    start_trans -> dqio_sem -> write to lf
  Syncing of local and global file:
    ocfs2_lock_global_qf -> start_trans -> dqio_sem -> qinfo_lock ->
      write to gf
 						       -> write to lf
  Acquire dquot for the first time:
    dq_lock -> ocfs2_lock_global_qf -> qinfo_lock -> read from gf
 				     -> alloc space for gf
 				     -> start_trans -> qinfo_lock -> write to gf
 	     -> ip_alloc_sem of lf -> alloc space for lf
 	     -> write to lf
  Release last reference to dquot:
    dq_lock -> ocfs2_lock_global_qf -> start_trans -> qinfo_lock -> write to gf
 	     -> write to lf
  Note that all the above operations also hold the inode cluster lock of lf.
  Recovery:
    inode cluster lock of recovered lf
      -> read bitmaps -> ip_alloc_sem of lf
      -> ocfs2_lock_global_qf -> start_trans -> dqio_sem -> qinfo_lock ->
         write to gf
 Update from disk only entries not set by the admin 
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
 Read data from global quotafile - avoid pagecache and such because we cannot
  afford acquiring the locks... We use quota cluster lock to serialize
 Write to quotafile (we know the transaction is already started and has
 Space is already allocated in ocfs2_acquire_dquot() 
 Not rewriting whole block? 
 Read information header from global quota file 
 Read global header 
 Write information to global quota file. Expects exlusive lock on quota
	
	  We may need to allocate tree blocks and a leaf block but not the
	  root block
	 We modify all the allocated blocks, tree root, info block and
 Sync local information about quota modifications with global quota file.
  Caller must have started the transaction and obtained exclusive lock for
	 Update space and inode usage. Get also other information from
	  global quota file so that we don't overwrite any changes there.
 Set properly space grace time... 
 Set properly inode grace time... 
 All information is properly updated, clear the flags 
   Functions for periodic syncing of dquots with global file
 We have to write local structure as well... 
	
	  We have to be careful here not to deadlock on s_umount as umount
	  disabling quotas may be in progress and it waits for this work to
	  complete. If trylock fails, we'll do the sync next time...
   Wrappers for generic quota functions
	
	  We modify tree, leaf block, global info, local chunk header,
	  global and local inode; OCFS2_QINFO_WRITE_CREDITS already
	  accounts for inode update
 Drop the reference we acquired in ocfs2_dquot_release() 
  Called when the last reference to dquot is dropped. If we are called from
  downconvert thread, we cannot do all the handling here because grabbing
  quota lock could deadlock (the node holding the quota lock could need some
  other cluster lock to proceed but with blocked downconvert thread we cannot
  release any lock).
 Check whether we are not racing with some other dqget() 
 Running from downconvert thread? Postpone quota processing to wq 
		
		  Grab our own reference to dquot and queue it for delayed
		  dropping.  Quota code rechecks after calling
		  ->release_dquot() and won't free dquot structure.
 First entry on list -> queue work 
	
	  If we fail here, we cannot do much as global structure is
	  already released. So just complain...
	
	  Clear dq_off so that we search for the structure in quota file next
	  time we acquire it. The structure might be deleted and reallocated
	  elsewhere by another node while our dquot structure is on freelist.
  Read global dquot structure from disk or create it if it does
  not exist. Also update use count of the global structure and
  create structure in node-local quota file.
	
	  We need an exclusive lock, because we're going to update use count
	  and instantiate possibly new dquot structure
	
	  We always want to read dquot structure from disk because we don't
	  know what happened with it while it was on freelist.
 No real quota entry? 
		
		  Add blocks to quota file before we start a transaction since
		  locking allocators ranks above a transaction start
	
	  Avoid logging ENOENT since it just means there isn't next ID and
	  ESRCH which means quota isn't enabled for the filesystem.
	 In case user set some limits, sync dquot immediately to global
	 This is a slight hack but we can't afford getting global quota
 Now write updated local dquot structure 
 This should happen only after set_dqinfo(). 
 We never make dquot dirty so .write_dquot is never called 
 SPDX-License-Identifier: GPL-2.0-only
  xattr.c
  Copyright (C) 2004, 2008 Oracle.  All rights reserved.
  CREDITS:
  Lots of code in this file is copy from linuxfsext3xattr.c.
  Copyright (C) 2001-2003 Andreas Gruenbacher, <agruen@suse.de>
 The inode these xattrs are associated with 
 The actual buffers that make up the bucket 
 How many blocks make up one bucket for this filesystem 
	
	  xattr_bh point to the block buffer head which has extended attribute
	  when extended attribute in inode, xattr_bh is equal to inode_bh.
 Operations on struct ocfs2_xa_entry 
	
	  Journal functions
	
	  Return a pointer to the appropriate buffer in loc->xl_storage
	  at the given offset from loc->xl_header.
 Can we reuse the existing entry for the new value? 
 How much space is needed for the new value? 
	
	  Return the offset of the first name+value pair.  This is
	  the start of our downward-filling free space.
	
	  Remove the name+value at this location.  Do whatever is
	  appropriate with the remaining name+value pairs.
 Fill xl_entry with a new entry 
 Add name+value storage to an entry 
	
	  Initialize the value buf's access and bh fields for this entry.
	  ocfs2_xa_fill_value_buf() will handle the xv pointer.
  Describes an xattr entry location.  This is a memory structure
  tracking the on-disk structure.
 This xattr belongs to this inode 
 The ocfs2_xattr_header inside the on-disk storage. Not NULL. 
 Bytes from xl_header to the end of the storage 
	
	  The ocfs2_xattr_entry this location describes.  If this is
	  NULL, this location describes the on-disk structure where it
	  would have been.
	
	  Internal housekeeping
 Buffer(s) containing this entry 
 Operations on the storage backing this location 
  Convenience functions to calculate how much space is needed for a
  given name+value pair
  A bucket that has never been written to disk doesn't need to be
  read.  We just need the buffer_heads.  Don't call this for
  buckets that are already on disk.  ocfs2_read_xattr_bucket() initializes
  them fully.
 Read the xattr bucket at xb_blkno 
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
	
	  Errors after here are fatal
 If ocfs2_read_block() got us a new bh, pass it up. 
 Get hash value of uuid from super block 
 hash extended attribute name 
	
	  The max space of security xattr taken inline is
	  256(name) + 80(value) + 16(entry) = 352 bytes,
	  So reserve one metadata block for it is ok.
 reserve clusters for xattr value which will be set in B tree
	
	  The max space of security xattr taken inline is
	  256(name) + 80(value) + 16(entry) = 352 bytes,
	  The max space of acl xattr taken inline is
	  80(value) + 16(entry)  2(if directory) = 192 bytes,
	  when blocksize = 512, may reserve one more cluser for
	  xattr bucket, otherwise reserve one metadata block
	  for them is ok.
	  If this is a new directory with inline data,
	  we choose to reserve the entire inline area for
	  directory contents and force an external xattr block.
	
	  reserve credits and clusters for xattrs which has large value
	  and have to be set outside
 for directory, it has DEFAULT and ACCESS two types of acls 
			
			  We can only fail in case the alloc file doesn't give
			  up enough clusters.
 we are just looking for how big our buffer needs to be 
 Copy ocfs2_xattr_value 
 ocfs2_xattr_get()
  Copy an extended attribute into the buffer provided.
  Buffer is NULL to compute the size of buffer required.
			
			  XXX: do we need to empty all the following
			  blocks in this cluster?
 Give a pointer into the storage for the given offset 
  Wipe the name+value pair and allow the storage to reclaim it.  This
  must be followed by either removal of the entry or a call to
  ocfs2_xa_add_namevalue().
  Find lowest offset to a name+value pair.  This is the start of our
  downward-growing free space.
 Can we reuse loc->xl_entry for xi? 
 How much free space is needed to set the new value 
	
	  We can't leave the new entry's xe_name_offset at zero or
	  add_namevalue() will go nuts.  We set it to the size of our
	  storage so that it can never be less than any other entry.
 Value bufs are for value trees 
	
	  Block storage is strict.  If the sizes aren't exact, we will
	  remove the old one and reinsert the new.
	
	  Block storage will reclaim the original entry before inserting
	  the new value, so we only need the difference.  If the new
	  entry is smaller than the old one, we don't need anything.
 Don't need space if we're reusing! 
  Block storage for xattrs keeps the name+value pairs compacted.  When
  we remove one, we have to shift any that preceded it towards the end.
 Shift the name+value pairs 
 Now tell xh->xh_entries about it 
	
	  Note that we don't update xh_free_start or xh_name_value_len
	  because they're not used in block-stored xattrs.
  Operations for xattrs stored in blocks.  This includes inline inode
  storage and unindexed ocfs2_xattr_blocks.
 The header is at the front of the bucket 
	
	  We need to make sure that the name+value pair fits within
	  one block.
	
	  Bucket storage does not reclaim name+value pairs it cannot
	  reuse.  They live as holes until the bucket fills, and then
	  the bucket is defragmented.  However, the bucket can reclaim
	  the ocfs2_xattr_entry.
 Don't need space if we're reusing! 
		
		  First we check if it would fit in the first place.
		  Below, we align the free start to a block.  This may
		  slide us below the minimum gap.  By checking unaligned
		  first, we avoid that error.
	
	  We keep buckets sorted by name_hash, so we need to find
	  our insert place.
 Values are not allowed to straddle block boundaries 
 We expect the bucket to be filled in 
 Operations for xattrs stored in buckets. 
	
	  The caller of ocfs2_xa_value_truncate() has already called
	  ocfs2_xa_journal_access on the loc.  However, The truncate code
	  calls ocfs2_extend_trans().  This may commit the previous
	  transaction and open a new one.  If this is a bucket, truncate
	  could leave only vb->vb_bh set up for journaling.  Meanwhile,
	  the caller is expecting to dirty the entire bucket.  So we must
	  reset the journal work.  We do this even if truncate has failed,
	  as it could have failed after committing the extend.
 Errors in truncate take precedence 
	
	  Only zero out the entry if there are more remaining.  This is
	  important for an empty bucket, as it keeps track of the
	  bucket's hash value.  It doesn't hurt empty block storage.
  If we have a problem adjusting the size of an external value during
  ocfs2_xa_prepare_entry() or ocfs2_xa_remove(), we may have an xattr
  in an intermediate state.  For example, the value may be partially
  truncated.
  If the value tree hasn't changed, the extendtruncate went nowhere.
  We have nothing to do.  The caller can treat it as a straight error.
  If the value tree got partially truncated, we now have a corrupted
  extended attribute.  We're going to wipe its entry and leak the
  clusters.  Better to leak some storage than leave a corrupt entry.
  If the value tree grew, it obviously didn't grow enough for the
  new entry.  We're not going to try and reclaim those clusters either.
  If there was already an external value there (orig_clusters != 0),
  the new clusters are attached safely and we can just leave the old
  value in place.  If there was no external value there, we remove
  the entry.
  This way, the xattr block we store in the journal will be consistent.
  If the size change broke because of the journal, no changes will hit
  disk anyway.
			
			  Since this is remove, we can return 0 if
			  ocfs2_xa_cleanup_value_truncate() is going to
			  wipe the entry anyway.  So we check the
			  cluster count as well.
  Take an existing entry and make it ready for the new value.  This
  won't allocate space, but it may free space.  It should be ready for
  ocfs2_xa_prepare_entry() to finish the work.
  Prepares loc->xl_entry to receive the new xattr.  This includes
  properly setting up the name+value pair region.  If loc->xl_entry
  already exists, it will take care of modifying it appropriately.
  Note that this modifies the data.  You did journal_access already,
  right?
	
	  If we get here, we have a blank entry.  Fill it.  We grow our
	  name+value pair back from the end.
			
			  If we were growing an existing value,
			  ocfs2_xa_cleanup_value_truncate() won't remove
			  the entry. We need to restore the original value
			  size.
  Store the value portion of the name+value pair.  This will skip
  values that are stored externally.  Their tree roots were set up
  by ocfs2_xa_prepare_entry().
	
	  From here on out, everything is going to modify the buffer a
	  little.  Errors are going to leave the xattr header in a
	  sane state.  Thus, even with errors we dirty the sucker.
 Don't worry, we are never called with !xi_value and !xl_entry 
  In xattr remove, if it is stored outside and refcounted, we may have
  the chance to split the refcount tree. So need the allocators.
  ocfs2_xattr_remove()
  Free extended attribute resources associated with this inode.
  ocfs2_xattr_ibody_find()
  Find extended attribute in inode block and
  fill search info into struct ocfs2_xattr_search.
 Find the named attribute. 
	
	  Adjust extent record count or inline data size
	  to reserve space for extended attribute.
  ocfs2_xattr_ibody_set()
  Set, replace or remove an extended attribute into inode block.
  ocfs2_xattr_block_find()
  Find extended attribute in external block and
  fill search info into struct ocfs2_xattr_search.
 Initialize ocfs2_xattr_block 
 Add it to the inode 
  ocfs2_xattr_block_set()
  Set, replace or remove an extended attribute into external block.
 Check whether the new xattr can be inserted into the inode. 
	
	  Calculate the clusters we need to write.
	  No matter whether we replace an old one or add a new one,
	  we need this for writing.
	
	  delete a xattr doesn't need metadata and cluster allocation.
	  so just calculate the credits and return.
	 
	  The credits for removing the value tree will be extended
	  by ocfs2_remove_extent itself.
 do cluster allocation guess first. 
		
		  In xattr set, we always try to set the xe in inode first,
		  so if it can be inserted into inode successfully, the old
		  one will be removed from the xattr block, and this xattr
		  will be inserted into inode as a new xattr in inode.
 the new values will be stored outside. 
		
		  Now the new value will be stored inside. So if the new
		  value is smaller than the size of value root or the old
		  value, we don't need any allocation, otherwise we have
		  to guess metadata allocation.
 calculate metadata allocation. 
		
		  If there is already an xattr tree, good, we can calculate
		  like other b-trees. Otherwise we may have the chance of
		  create a tree, the credit calculation is borrowed from
		  ocfs2_calc_extend_credits with root_el = NULL. And the
		  new tree will be cluster based, so no meta is needed.
		
		  This cluster will be used either for new bucket or for
		  new xattr block.
		  If the cluster size is the same as the bucket size, one
		  more is needed since we may need to extend the bucket
		  also.
		
		  We cannot have an error and a non null ctxt->data_ac.
 Remove existing extended attribute 
 We always try to set extended attribute into inode first
			
			  If succeed and that extended attribute existing in
			  external block, then we will remove it.
			
			  If no space in inode, we will set extended attribute
			  into external block.
				
				  If succeed and that extended attribute
				  existing in inode, we will remove it.
 Update inode ctime. 
  This function only called duing creating inode
  for init securityacl xattrs of the new inode.
  All transanction credits have been reserved in mknod.
	
	  In extreme situation, may need xattr bucket when
	  block size is too small. And we have already reserved
	  the credits for bucket in mknod.
  ocfs2_xattr_set()
  Set, replace or remove an extended attribute for this inode.
  value is NULL to remove an existing extended attribute, else either
  create or replace an extended attribute.
	
	  Only xbs will be used on indexed trees.  xis doesn't need a
	  bucket.
	
	  Scan inode and external block to find the same name
	  extended attribute and collect search information.
 Check whether the value is refcounted and do some preparation. 
 we need to update inode's ctime field, so add credit for it. 
  Find the xattr extent rec which may contains name_hash.
  e_cpos will be the first name hash of the xattr rec.
  el must be the ocfs2_xattr_header.xb_attrs.xb_root.xt_list.
	
	  We don't use binary search in the bucket because there
	  may be multiple entries with the same name hash.
  Find the specified xattr entry in a series of buckets.
  This series start from p_blkno and last for num_clusters.
  The ocfs2_xattr_header.xh_num_buckets of the first bucket contains
  the num of the valid buckets.
  Return the buffer_head this xattr should reside in. And if the xattr's
  hash is in the gap of 2 buckets, return the lower bucket.
		
		  Check whether the hash of the last entry in our
		  bucket is larger than the search one. for an empty
		  bucket, the last one is also the first one.
 record lower_blkno which may be the insert place. 
 the searched xattr should reside in this bucket if exists. 
	
	  Record the bucket we have found.
	  When the xattr's hash value is in the gap of 2 buckets, we will
	  always set it to the previous bucket.
 This should be in cache - we just read it during the search 
		
		  The real bucket num in this series of blocks is stored
		  in the 1st bucket.
 Fall through to bucket_relse() 
  When the ocfs2_xattr_block is filled up, new bucket will be created
  and all the xattr entries will be moved to the new bucket.
  The header goes at the start of the bucket, and the names+values are
  filled from the end.  This is why target starts as the last buffer.
  Note: we need to sort the entries since they are not saved in order
  in the ocfs2_xattr_block.
	
	  Since the xe_name_offset is based on ocfs2_xattr_header,
	  there is a offset change corresponding to the change of
	  ocfs2_xattr_header's position.
 copy all the names and values. 
 Init new header now. 
 copy all the entries. 
 Change the xe offset for all the xe because of the move. 
  After we move xattr from block to index btree, we have to
  update ocfs2_xattr_search to the new xe and base.
  When the entry is in xattr block, xattr_bh indicates the storage place.
  While if the entry is in index b-tree, "bucket" indicates the
  real place of the xattr.
	
	  XXX:
	  We can use this lock for now, and maybe move to a dedicated mutex
	  if performance becomes a problem later.
	
	  The bucket may spread in many blocks, and
	  we will only touch the 1st block and the last block
	  in the whole bucket(one for entry and one for data).
 Change from ocfs2_xattr_header to ocfs2_xattr_tree_root 
  defrag a xattr bucket if we find that the bucket has some
  holes beteen namevalue pairs.
  We will move all the namevalue pairs to the end of the bucket
  so that we can spare some space for insertion.
	
	  In order to make the operation more efficient and generic,
	  we copy all the blocks into a contiguous memory and do the
	  defragment there, so if anything is error, we will not touch
	  the real block.
	
	  sort all the entries by their offset.
	  the largest will be the first, so that we can
	  move them to the end one by one.
 Move all namevalues to the end of the bucket. 
		
		  We must make sure that the namevalue pair
		  exist in the same block. So adjust end to
		  the previous block end if needed.
 sort the entries by their name_hash. 
  prev_blkno points to the start of an existing extent.  new_blkno
  points to a newly allocated extent.  Because we know each of our
  clusters contains more than bucket, we can easily split one cluster
  at a bucket boundary.  So we take the last cluster of the existing
  extent and split it down the middle.  We move the last half of the
  buckets in the last cluster of the existing extent over to the new
  extent.
  first_bh is the buffer at prev_blkno so we can update the existing
  extent's bucket count.  header_bh is the bucket were we were hoping
  to insert our xattr.  If the bucket move places the target in the new
  extent, we'll update first_bh and header_bh after modifying the old
  extent.
  first_hash will be set as the 1st xe's name_hash in the new extent.
 This is the first bucket that got moved 
	
	  If the target bucket was part of the moved buckets, we need to
	  update first and target.
 Find the block for the new target bucket 
		
		  These shouldn't fail - the buffers are in the
		  journal from ocfs2_cp_xattr_bucket().
  Find the suitable pos when we divide a bucket into 2.
  We have to make sure the xattrs with the same hash value exist
  in the same bucket.
  If this ocfs2_xattr_header covers more than one hash value, find a
  place where the hash value changes.  Try to find the most even split.
  The most common case is that all entries have different hash values,
  and the first check we make will find a place to split.
	
	  We start at the middle.  Each step gets farther away in both
	  directions.  We therefore hit the change in hash value
	  nearest to the middle.  Note that this loop does not execute for
	  count < 2.
 Let's check delta earlier than middle 
 For even counts, don't walk off the end 
 Now try delta past middle 
 Every entry had the same hash 
  Move some xattrs in old bucket(blk) to new bucket(new_blk).
  first_hash will record the 1st hash of the new bucket.
  Normally half of the xattrs will be moved.  But we have to make
  sure that the xattrs with the same hash value are stored in the
  same bucket. If all the xattrs in this bucket have the same hash
  value, the new bucket will be initialized as an empty one and the
  first_hash will be initialized as (hash_value+1).
	
	  Even if !new_bucket_head, we're overwriting t_bucket.  Thus,
	  there's no need to read it.
	
	  Hey, if we're overwriting t_bucket, what difference does
	  ACCESS_CREATE vs ACCESS_WRITE make?  See the comment in the
	  same part of ocfs2_cp_xattr_bucket().
		
		  initialized a new empty bucket here.
		  The hash value is set as one larger than
		  that of the last entry in the previous bucket.
 copy the whole bucket to the new first. 
 update the new bucket. 
	
	  Calculate the total namevalue len and xh_free_start for
	  the old bucket first.
	
	  Now begin the modification to the new bucket.
	 
	  In the new bucket, We just move the xattr entry to the beginning
	  and don't touch the namevalue. So there will be some holes in the
	  bucket, and they will be removed when ocfs2_defrag_xattr_bucket is
	  called.
 Calculate xh_free_start for the new bucket. 
 set xh->xh_num_buckets for the new xh. 
 store the first_hash of the new bucket. 
	
	  Now only update the 1st block of the old bucket.  If we
	  just added a new empty bucket, there is no need to modify
	  it.
  Copy xattr from one bucket to another bucket.
  The caller must make sure that the journal transaction
  has enough space for journaling.
	
	  Even if !t_is_new, we're overwriting t_bucket.  Thus,
	  there's no need to read it.
	
	  Hey, if we're overwriting t_bucket, what difference does
	  ACCESS_CREATE vs ACCESS_WRITE make?  Well, if we allocated a new
	  cluster to fill, we came here from
	  ocfs2_mv_xattr_buckets(), and it is really new -
	  ACCESS_CREATE is required.  But we also might have moved data
	  out of t_bucket before extending back into it.
	  ocfs2_add_new_xattr_bucket() can do this - its call to
	  ocfs2_add_new_xattr_cluster() may have created a new extent
	  and copied out the end of the old extent.  Then it re-extends
	  the old extent back to create space for new xattrs.  That's
	  how we get here, and the bucket isn't really new.
  src_blk points to the start of an existing extent.  last_blk points to
  last cluster in that extent.  to_blk points to a newly allocated
  extent.  We copy the buckets from the cluster at last_blk to the new
  extent.  If start_bucket is non-zero, we skip that many buckets before
  we start copying.  The new extent's xh_num_buckets gets set to the
  number of buckets we copied.  The old extent's xh_num_buckets shrinks
  by the same amount.
 The first bucket of the original extent 
 The first bucket of the new extent 
	
	  We need to update the first bucket of the old extent and all
	  the buckets going to the new extent.
	
	  Get the new bucket ready before we dirty anything
	  (This actually shouldn't fail, because we already dirtied
	  it once in ocfs2_cp_xattr_bucket()).
 Now update the headers 
  Move some xattrs in this cluster to the new cluster.
  This function should only be called when bucket size == cluster size.
  Otherwise ocfs2_mv_xattr_bucket_cross_cluster should be used instead.
 Move half of the xattr in start_blk to the next bucket. 
  Move some xattrs from the old cluster to the new one since they are not
  contiguous in ocfs2 xattr tree.
  new_blk starts a new separate cluster, and we will move some xattrs from
  prev_blk to it. v_start will be set as the first name hash value in this
  new cluster so that it can be used as e_cpos during tree insertion and
  don't collide with our original b-tree operations. first_bh and header_bh
  will also be updated since they will be used in ocfs2_extend_xattr_bucket
  to extend the insert bucket.
  The problem is how much xattr should we move to the new one and when should
  we update first_bh and header_bh?
  1. If cluster size > bucket size, that means the previous cluster has more
     than 1 bucket, so just move half nums of bucket into the new cluster and
     update the first_bh and header_bh if the insert bucket has been moved
     to the new cluster.
  2. If cluster_size == bucket_size:
     a) If the previous extent rec has more than one cluster and the insert
        place isn't in the last cluster, copy the entire last cluster to the
        new one. This time, we don't need to upate the first_bh and header_bh
        since they will not be moved into the new cluster.
     b) Otherwise, move the bottom half of the xattrs in the last cluster into
        the new one. And we set the extend flag to zero if the insert place is
        moved into the new allocated cluster since no extend is needed.
 The start of the last cluster in the first extent 
  Add a new cluster for xattr storage.
  If the new cluster is contiguous with the previous one, it will be
  appended to the same extent record, and num_clusters will be updated.
  If not, we will insert a new extent for it and move some xattrs in
  the last cluster into the new allocated one.
  We also need to limit the maximum size of a btree leaf, otherwise we'll
  lose the benefits of hashing because we'll have to search large leaves.
  So now the maximum size is OCFS2_MAX_XATTR_TREE_LEAF_SIZE(or clustersize,
  if it's bigger).
  first_bh is the first block of the previous extent rec and header_bh
  indicates the bucket we will insert the new xattrs. They will be updated
  when the header_bh is moved into the new cluster.
		
		  If this cluster is contiguous with the old one and
		  adding this new cluster, we don't surpass the limit of
		  OCFS2_MAX_XATTR_TREE_LEAF_SIZE, cool. We will let it be
		  initialized and used like other buckets in the previous
		  cluster.
		  So add it as a contiguous one. The caller will handle
		  its init process.
  We are given an extent.  'first' is the bucket at the very front of
  the extent.  The extent has space for an additional bucket past
  bucket_xh(first)->xh_num_buckets.  'target_blkno' is the block number
  of the target bucket.  We wish to shift every bucket past the target
  down one, filling in that additional space.  When we get back to the
  target, we split the target between itself and the now-empty bucket
  at target+1 (aka, target_blkno + blks_per_bucket).
 The extent must have room for an additional bucket 
 end_blk points to the last existing bucket 
	
	  end_blk is the start of the last existing bucket.
	  Thus, (end_blk - target_blk) covers the target bucket and
	  every bucket after it up to, but not including, the last
	  existing bucket.  Then we add the last existing bucket, the
	  new bucket, and the first bucket (3  blk_per_bucket).
 Move half of the xattr in target_blkno to the next bucket. 
  Add new xattr bucket in an extent record and adjust the buckets
  accordingly.  xb_bh is the ocfs2_xattr_block, and target is the
  bucket we want to insert into.
  In the easy case, we will move all the buckets after target down by
  one. Half of target's xattrs will be moved to the next bucket.
  If current cluster is full, we'll allocate a new one.  This may not
  be contiguous.  The underlying calls will make sure that there is
  space for the insert, shifting buckets around if necessary.
  'target' may be moved by those calls.
 The bucket at the front of the extent 
 The first bucket of the original extent 
		
		  This can move first+target if the target bucket moves
		  to the new extent.
  Truncate the specified xe_off entry in xattr bucket.
  bucket is indicated by header_bh and len is the new length.
  Both the ocfs2_xattr_value_root and the entry will be updated here.
  Copy the new updated xe and xe_value_root to new_xe and new_xv if needed.
 We don't allow ocfs2_xattr_value to be stored in different block. 
	
	  From here on out we have to dirty the bucket.  The generic
	  value calls only modify one of the bucket's bhs, but we need
	  to send the bucket at once.  So if they error, they could have
	  modified something.  We have to assume they did, and dirty
	  the whole bucket.  This leaves us in a consistent state.
  check whether the xattr bucket is filled up with the same hash value.
  If we want to insert the xattr with the same hash, return -ENOSPC.
  If we want to insert a xattr with different hash value, go ahead
  and ocfs2_divide_xattr_bucket will handle this.
  Try to set the entry in the current bucket.  If we fail, the caller
  will handle getting us another bucket.
 Ok, we need space.  Let's try defragmenting the bucket. 
 Ack, need more space.  Let's try to get another bucket! 
	
	  We do not allow for overlapping ranges between buckets. And
	  the maximum number of collisions we will allow for then is
	  one bucket's worth, so check it here whether we need to
	  add a new bucket for the insert.
	
	  ocfs2_add_new_xattr_bucket() will have updated
	  xs->bucket if it moved, but it will not have updated
	  any of the other search fields.  Thus, we drop it and
	  re-search.  Everything should be cached, so it'll be
	  quick.
 Ok, we have a new bucket, let's try again 
  Whenever we modify a xattr value root in the bucket(e.g, CoW
  or change the extent record flag), we need to recalculate
  the metaecc for the whole bucket. So it is done here.
  Note:
  We have to give the extra credits for the caller.
  Special action we need if the xattr value is refcounted.
  1. If the xattr is refcounted, lock the tree.
  2. CoW the xattr if we are setting the new value and the value
     will be stored outside.
  3. In other case, decrease_refcount will work for us, so just
     lock the refcount tree, calculate the meta and credits is OK.
  We have to do CoW before ocfs2_init_xattr_set_ctxt since
  currently CoW is a completed transaction, while this function
  will also lock the allocators and let us deadlock. So we will
  CoW the whole xattr value.
create parameters for ocfs2_post_refcount. 
	
	  We just need to check the 1st extent record, since we always
	  CoW the whole xattr. So there shouldn't be a xattr with
	  some REFCOUNT extent recs after the 1st one.
	
	  If we are deleting the xattr or the new size will be stored inside,
	  cool, leave it there, the xattr truncate process will remove them
	  for us(it still needs the refcount tree lock and the meta, credits).
	  And the worse case is that every cluster truncate will split the
	  refcount tree, and make the original extent become 3. So we will need
	  2  cluster more extent recs at most.
  Add the REFCOUNTED flags for all the extent rec in ocfs2_xattr_value_root.
  The physical clusters will be added to refcount tree.
  Given a normal ocfs2_xattr_header, refcount all the entries which
  have value stored outside.
  Used for xattrs stored in inode and ocfs2_xattr_block.
  For a given xattr bucket, refcount all the entries which
  have value stored outside.
 We only need post_refcount if we support metaecc. 
  Store the information we need in xattr reflink.
  old_bh and new_bh are inode bh for the old and new inode.
  Given a xattr header and xe offset,
  return the proper xv and the corresponding bh.
  xattr in inode, block and xattr tree have different implementaions.
  Calculate all the xattr value root metadata stored in this xattr header and
  credits we need if we create them from the scratch.
  We use get_xattr_value_root so that all types of xattr container can use it.
		
		  If the value is a tree with depth > 1, We don't go deep
		  to the extent block, so just calculate a maximum record num.
 Used by xattr inode and block to return the right xv and buffer_head. 
  Lock the meta_ac and caculate how much credits we need for reflink xattrs.
  It is only used for inline xattr and xattr block.
	
	  We need to addmodify num_recs in refcount tree, so just calculate
	  an approximate number we need for refcount tree change.
	  Sometimes we need to split the tree, and after split,  half recs
	  will be moved to the new block, and a new block can only provide
	  half number of recs. So we multiple new blocks by 2.
  Given a xattr header, reflink all the xattrs in this container.
  It can be used for inode, block and bucket.
  NOTE:
  Before we call this function, the caller has memcpy the xattr in
  old_xh to the new_xh.
  If args.xattr_reflinked is set, call it to decide whether the xe should
  be reflinked or not. If not, remove it from the new xattr header.
			
			  We don't want j to increase in the next round since
			  it is already moved ahead.
		
		  For the xattr which has l_tree_depth = 0, all the extent
		  recs have already be copied to the new xh with the
		  propriate OCFS2_EXT_REFCOUNTED flag we just need to
		  increase the refount count int the refcount tree.
		 
		  For the xattr which has l_tree_depth > 0, we need
		  to initialize it to the empty default value root,
		  and then insert the extents one by one.
	
	  Adjust extent record count to reserve space for extended attribute.
	  Inline data count had been adjusted in ocfs2_duplicate_inline_data().
 One more credits in case we need to add xattr flags in new inode. 
  NOTE:
  We have to handle the case that both old bucket and new bucket
  will call this function to get the right ret_bh.
  So The caller must give us the right bh.
 Add the credits for this bucket first. 
  Given a xattr extent rec starting from blkno and having len clusters,
  iterate all the buckets calculate how much metadata we need for reflinking
  all the ocfs2_xattr_value_root and lock the allocators accordingly.
	
	  Calculate we need for refcount tree change.
	 
	  We need to addmodify num_recs in refcount tree, so just calculate
	  an approximate number we need for refcount tree change.
	  Sometimes we need to split the tree, and after split,  half recs
	  will be moved to the new block, and a new block can only provide
	  half number of recs. So we multiple new blocks by 2.
	  In the end, we have to add credits for modifying the already
	  existed refcount block.
 count in the xattr tree change. 
		
		  Record the start cpos so that we can use it to initialize
		  our xattr tree we also set the xh_num_bucket for the new
		  bucket.
		
		  Re-access and dirty the bucket to calculate metaecc.
		  Because we may extend the transaction in reflink_xattr_header
		  which will let the already accessed block gone.
		
		  For the 1st allocated cluster, we make it use the same cpos
		  so that the xattr tree looks the same as the original one
		  in the most case.
  Create the same xattr extent record in the new inode's xattr tree.
  Create reflinked xattr buckets.
  We will add bucket one by one, and refcount all the xattrs in the bucket
  if they are stored outside.
  Initialize security and acl for a already created inode.
  Used for reflink a non-preserve-security file.
  It uses common api like ocfs2_xattr_set, so the caller
  must not hold any lock expect i_mutex.
  'security' attributes support
 check whether ocfs2 support feature xattr 
  'trusted' attributes support
  'user' attributes support
 SPDX-License-Identifier: GPL-2.0-or-later
  journal.c
  Defines functions of journalling api
  Copyright (C) 2003, 2004 Oracle.  All rights reserved.
  This replay_map is to track onlineoffline slots, so we could recover
  offline slots during recovery and mount
 Replay is not needed, so ignore this map 
 Replay slots marked in rm_replay_slots 
 Replay was already queued 
 If we've already queued the replay, we don't have any more to do 
 If replay map is already set, we don't do it again 
 set rm_replay_slots for offline slot(s) 
 we can't grab the goofy sem lock from inside wait_event, so we use
  memory barriers to make sure that we'll see the null task before
	 disable any new recovery threads and wait for any currently
	 At this point, we know that no more recovery threads can be
	  launched, so wait for any recovery completion work to
	
	  Now that recovery is shut down, and the osb is about to be
	  freed,  the osb_lock is not taken here.
 XXX: Should we bug if there are dirty entries? 
 Behaves like test-and-set.  Returns the previous value 
 XXX: Can this be exploited? Not from o2dlm... 
 XXX: be careful with the pointer math 
 Flush all pending commits and checkpoint the journal. 
 Nested transaction? Just return the handle... 
  'nblocks' is what you want to add to the current transaction.
  This might call jbd2_journal_restart() which will commit dirty buffers
  and then restart the transaction. Before calling
  ocfs2_extend_trans(), any changed blocks should have been
  dirtied. After calling it, all blocks which need to be changed must
  go through another set of journal_accessjournal_dirty calls.
  WARNING: This will not release any semaphores or disk locks taken
  during the transaction, so make sure they were taken before
  start_trans or we'll have ordering deadlocks.
  WARNING2: Note that we do not drop j_trans_barrier here. This is
  good because transaction ids haven't yet been recorded on the
  cluster locks associated with this handle.
  If we have fewer than thresh credits, extend by OCFS2_MAX_TRANS_DATA.
  If that fails, restart the transaction & regain write access for the
  buffer head which is used for metadata modifications.
  Taken from Ext4: extend_or_restart_transaction()
	
	  We aren't guaranteed to have the superblock here, so we
	  must unconditionally compute the ecc data.
	  __ocfs2_journal_access() will only set the triggers if
	  metaecc is enabled.
  Quota blocks have their own trigger because the struct ocfs2_block_check
  offset depends on the blocksize.
	
	  We aren't guaranteed to have the superblock here, so we
	  must unconditionally compute the ecc data.
	  __ocfs2_journal_access() will only set the triggers if
	  metaecc is enabled.
  Directory blocks also have their own trigger because the
  struct ocfs2_block_check offset depends on the blocksize.
	
	  We aren't guaranteed to have the superblock here, so we
	  must unconditionally compute the ecc data.
	  __ocfs2_journal_access() will only set the triggers if
	  metaecc is enabled.
 we can safely remove this assertion after testing. 
		
		  A previous transaction with a couple of buffer heads fail
		  to checkpoint, so all the bhs are marked as BH_Write_EIO.
		  For current transaction, the bh is just among those error
		  bhs which previous transaction handle. We can't just clear
		  its BH_Write_EIO and reuse directly, since other bhs are
		  not written to disk yet and that will cause metadata
		  inconsistency. So we should set fs read-only to avoid
		  further damage.
	 Set the current transaction information on the ci so
	  that the locking code knows whether it can drop it's locks
	  on this ci or not. We're protected from the commit
	  thread updating the current transaction id until
	  ocfs2_commit_trans() because ocfs2_start_trans() took
 the journal inode 
 initialize our journal structure 
 already have the inode for our journal 
	 Skip recovery waits here - journal inode metadata never
	  changes in a live cluster so it can be considered an
 call the kernels journal init function now 
	 The journal bh on the osb always comes from ocfs2_journal_init()
	  and was validated there inside ocfs2_inode_lock_full().  It's a
  If the journal has been kmalloc'd it needs to be freed after this
  call.
 need to inc inode use count - jbd2_journal_destroy will iput. 
	 Do a commit_cache here. It will flush our journal, and
	  release any locks that are still held.
	  set the SHUTDOWN flag and release the trans lock.
	 The OCFS2_JOURNAL_IN_SHUTDOWN will signal to commit_cache to not
	  drop the trans_lock (which we want to hold until we
 Wait for the commit thread 
 Shutdown the kernel journal system 
		
		  Do not toggle if flush was unsuccessful otherwise
		  will leave dirty metadata in a "clean" journal
 unlock our journal 
 Launch the commit thread 
 'full' flag tells us whether we clear out all blocks or if we just
  JBD Might read a cached version of another nodes journal file. We
  don't want this as this file changes often and we get no
  notification on those changes. The only way to be sure that we've
  got the most up to date version of those blocks then is to force
  read them off disk. Just searching through the buffer cache won't
  work as there may be pages backing this file which are still marked
  up to date. We know things can't change on this file underneath us
  as we have the lock by now :)
 block not cached. 
			 We are reading journal data which should not
			  be put in the uptodate cache.
 Does the second half of the recovery process. By this point, the
  node is marked clean and can actually be considered recovered,
  hence it's no longer in the recovery map, but there's still some
  cleanup we can do which shouldn't happen within the recovery thread
  as locking in that context becomes very difficult if we are to take
  recovering nodes into account.
  NOTE: This function can and will sleep on recovery of other nodes
  during cluster locking, just like any other ocfs2 process.
 Recovery info is already freed now 
 NOTE: This function always eats your references to la_dinode and
  tl_dinode, either manually on error, or by passing them to
		 Though we wish to avoid it, we are in fact safe in
		  skipping local alloc cleanup as fsck.ocfs2 is more
 Called by the mount code to queue recovery the last part of
	 No need to queue up our truncate_log as regular cleanup will catch
 queue to recover orphan slots for all offline slots 
 Whether the quota supported. 
 queue recovery for our own slot 
		 It's always safe to remove entry zero, as we won't
		 It is a bit subtle with quota recovery. We cannot do it
		  immediately because we have to obtain cluster locks from
		  quota files and we also don't want to just skip it because
		  then quota usage would be out of sync until some node takes
		  the slot. So we remember which nodes need quota recovery
 Refresh all journal recovery generations from disk 
	 Now it is right time to recover quotas... We have to do this under
	  superblock lock so that no one can start using the slot (and crash)
 queue recovery for offline slots 
 sync with ocfs2_recovery_thread_running 
 Does the actual journal replay and marks the journal inode as
	
	  As the fs recovery is asynchronous, there is a small chance that
	  another node mounted (and recovered) the slot before the recovery
	  thread could get the lock. To handle that, we dirty read the journal
	  inode for that slot to get the recovery generation. If it is
	  different than what we expected, the slot has been recovered.
	  If not, it needs recovery.
 Continue with recovery as the journal has not yet been recovered 
 Refresh recovery generation for the slot 
 we need to run complete recovery for offline orphan slots 
 wipe the journal 
 This will mark the node clean 
 Increment recovery generation to indicate successful recovery 
 drop the lock on this nodes journal 
  Do the most important parts of node recovery:
   - Replay it's journal
   - Stamp a clean local allocator file
   - Stamp a clean truncate log
   - Mark the node clean
  If this function completes without error, a node in OCFS2 can be
  said to have been safely recovered. As a result, failure during the
  second part of a nodes recovery process (local alloc recovery) is
  far less concerning.
	 Should not ever be called to recover ourselves -- in that
 Stamp a clean local alloc file AFTER recovering the journal... 
	 An error from begin_truncate_log_recovery is not
	  serious enough to warrant halting the rest of
	 Likewise, this would be a strange but ultimately not so
 This will kfree the memory pointed to by la_copy and tl_copy 
 Test node liveness by trylocking his journal. If we get the lock,
  we drop it here. Return 0 if we got the lock, -EAGAIN if node is
 Call this underneath ocfs2_super_lock. It also assumes that the
	 This is called with the super block cluster lock, so we
 Read journal inode to get the recovery generation 
		 Ok, we have a slot occupied by another node which
		  is not in the recovery map. We trylock his journal
			 Since we're called from mount, we know that
			  the recovery thread can't race us on
  Scan timer should get fired every ORPHAN_SCAN_SCHEDULE_TIMEOUT. Add some
  randomness to the timeout to minimize multple nodes firing the timer at the
  same time.
  ocfs2_queue_orphan_scan calls ocfs2_queue_recovery_completion for
  every slot, queuing a recovery of the slot on the ocfs2_wq thread. This
  is done to catch any orphans that are left over in orphan directories.
  It scans all slots, even ones that are in use. It does so to handle the
  case described below:
    Node 1 has an inode it was using. The dentry went away due to memory
    pressure.  Node 1 closes the inode, but it's on the free list. The node
    has the open lock.
    Node 2 unlinks the inode. It grabs the dentry lock to notify others,
    but node 1 has no dentry and doesn't get the message. It trylocks the
    open lock, sees that another node has a PR, and does nothing.
    Later node 2 runs its orphan dir. It igets the inode, trylocks the
    open lock, sees the PR still, and does nothing.
    Basically, we have to trigger an orphan iput on node 1. The only way
    for this to happen is if node 1 runs node 2's orphan dir.
  ocfs2_queue_orphan_scan gets called every ORPHAN_SCAN_SCHEDULE_TIMEOUT
  seconds.  It gets an EX lock on os_lockres and checks sequence number
  stored in LVB. If the sequence number has changed, it means some other
  node has done the scan.  This node skips the scan and tracks the
  sequence number.  If the sequence number didn't change, it means a scan
  hasn't happened.  The node queues a scan and increments the
  sequence number in the LVB.
 Do no queue the tasks if the volume is being umounted 
	
	  We queued a recovery on orphan slots, increment the sequence
	  number and update LVB so other node will skip the scan for a while
 Worker task that gets fired every ORPHAN_SCAN_SCHEDULE_TIMEOUT millsec 
 do not include dio entry in case of orphan scan 
 Skip bad inodes so that recovery can continue 
	 Skip inodes which are already added to recover list, since dio may
	 No locking is required for the next_orphan queue as there
	 Mark ourselves such that new processes in delete_inode()
		 If any processes are already in the middle of an
		  orphan wipe on this dir, then we need to wait for
  Orphan recovery. Each mounted node has it's own orphan dir which we
  must run during recovery. Our strategy here is to build a list of
  the inodes in the orphan dir and igetiput them. The VFS does
  (most) of the rest of the work.
  Orphan recovery can happen at any time, not just mount so we have a
  couple of extra considerations.
  - We grab as many inodes as we can under the orphan dir lock -
    doing iget() outside the orphan dir risks getting a reference on
    an invalid inode.
  - We must be sure not to deadlock with other processes on the
    system wanting to run delete_inode(). This can happen when they go
    to lock the orphan dir and the orphan recovery process attempts to
    iget() inside the orphan dir lock. This can be avoided by
    advertising our state to ocfs2_delete_inode().
	 Error here should be noted, but we want to continue with as
			
			  We need to take and drop the inode lock to
			  force read inode from disk.
 clear dio flag in ocfs2_inode_info 
			 Set the proper information to get us going into
	 This check is good because ocfs2 will wait on our recovery
	  thread before changing it to something other than MOUNTED
	 If there's an error on mount, then we may never get to the
	  MOUNTED flag, but this is set right before
	 we can trust j_num_trans here because _should_stop() is only set in
	  shutdown and nobody other than ourselves should be able to start
	  transactions.  committing on shutdown might take a few iterations
 Warn about this once per minute 
			
			  After ocfs2_commit_cache() fails, j_num_trans has a
			  non-zero value.  Sleep here to avoid a busy-wait
			  loop.
 Reads all the journal inodes without taking any cluster locks. Used
  for hard readonly access to determine whether any journal requires
  recovery. Also used to refresh the recovery generation numbers after
  a journal has been recovered by another node.
 SPDX-License-Identifier: GPL-2.0-or-later
  inode.c
  vfs' aops, fops, dops and iops
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
 Propagate flags from i_flags to OCFS2_I(inode)->ip_attr 
	 Ok. By now we've either got the offsets passed to us by the
	  caller, or we just pulled them off the bh. Lets do some
	 inode was not in the inode cache. 2.6.x requires
	  us to do our own read_inode call and unlock it
	
	  Set transaction id's of transactions that have to be committed
	  to finish f[data]sync. We set them to currently running transaction
	  as we cannot be sure that the inode or some of its metadata isn't
	  part of the transaction - the inode could have been reclaimed and
	  now it is reread from disk.
  here's how inodes get read from disk:
  iget5_locked -> find_actor -> OCFS2_FIND_ACTOR
  found? : return the in-memory inode
  not found? : get_new_inode -> OCFS2_INIT_LOCKED_INODE
  initialize the new inode, but don't do anything that would cause
  us to sleep.
  return 0 on success, 1 on failure
	
	  These have all been checked by ocfs2_read_inode_block() or set
	  by ocfs2_mknod_locked(), so a failure is a code bug.
	BUG_ON(!OCFS2_IS_VALID_DINODE(fe));   This means that read_inode
						cannot create a superblock
						inode today.  change if
 Fast symlinks will have i_size but no allocated clusters. 
		 we can't actually hit this as read_inode can't
		
		  If we ever want to create system files from kernel,
		  the generation argument to
		  ocfs2_inode_lock_res_init() will have to change.
	
	  To improve performance of cold-cache inode stats, we take
	  the cluster lock here if possible.
	 
	  Generally, OCFS2 never trusts the contents of an inode
	  unless it's holding a cluster lock, so taking it here isn't
	  a correctness issue as much as it is a performance
	  improvement.
	 
	  There are three times when taking the lock is not a good idea:
	 
	  1) During startup, before we have initialized the DLM.
	 
	  2) If we are reading certain system files which never get
	     cluster locks (local alloc, truncate log).
	 
	  3) If the process doing the iget() is responsible for
	     orphan dir recovery. We're holding the orphan dir lock and
	     can get into a deadlock with another process on another
	     node in ->delete_inode().
	 
	  #1 and #2 can be simply solved by never taking the lock
	  here for system files (which are the only type we read
	  during mount). It's a heavier approach, but our main
	  concern is user-accessible files anyway.
	 
	  #3 works itself out because we'll eventually take the
	  cluster lock before trusting anything anyway.
	
	  To maintain backwards compatibility with older versions of
	  ocfs2-tools, we still store the generation value for system
	  files. The only ones that actually matter to userspace are
	  the journals, but it's easier and inexpensive to just flag
	  all system files similarly.
		
		  If buffer is in jbd, then its checksum may not have been
		  computed as yet.
	
	  This is a code bug. Right now the caller needs to
	  understand whether it is asking for a system file inode or
	  not so the proper lock names can be built.
	
	  This check will also skip truncate of inodes with inline
	  data and fast symlinks.
 set the inodes dtime 
  Serialize with orphan dir recovery. If the process doing
  recovery on this orphan dir does an iget() with the dir
  i_mutex held, we'll deadlock here. Instead we detect this
  and exit early - recovery will wipe this inode for us.
	 This signals to the orphan recovery process that it should
		 Lock the orphan dir. The lock will be held for the entire
		  delete_inode operation. We do this now to avoid races with
	 we do this while holding the orphan dir lock because we
	  don't want recovery being run from another node to try an
	  inode delete underneath us -- this will result in two nodes
 Remove any dir index tree 
Free extended attribute resources associated with this inode.
 There is a series of simple checks that should be done before a
	 We shouldn't be getting here for the root directory
	
	  If we're coming from downconvert_thread we can't go into our own
	  voting [hello, deadlock city!] so we cannot delete the inode. But
	  since we dropped last inode ref when downconverting dentry lock,
	  we cannot have the file open and thus the node doing unlink will
	  take care of deleting the inode.
	 OCFS2 never deletes system files. This should technically
	  never get here as system file inodes should always have a
 Query the cluster to determine whether we should wipe an inode from
  disk or not.
	 While we were waiting for the cluster lock in
	  ocfs2_delete_inode, another node might have asked to delete
	 Now that we have an up to date inode, we can double check
 Do some basic inode verification... 
		
		  Inodes in the orphan dir must have ORPHANED_FL.  The only
		  inodes that come back out of the orphan dir are reflink
		  targets. A reflink target may be moved out of the orphan
		  dir between the time we scan the directory and the time we
		  process it. This would lead to HAS_REFCOUNT_FL being set but
		  ORPHANED_FL not.
 for lack of a better error? 
 has someone already deleted us?! baaad... 
	
	  This is how ocfs2 determines whether an inode is still live
	  within the cluster. Every node takes a shared read lock on
	  the inode open lock in ocfs2_read_locked_inode(). When we
	  get to ->delete_inode(), each node tries to convert it's
	  lock to an exclusive. Trylocks are serialized by the inode
	  meta data lock. If the upconvert succeeds, we know the inode
	  is no longer live and can be deleted.
	 
	  Though we call this with the meta data lock held, the
	  trylock keeps us from ABBA deadlock.
 Support function for ocfs2_delete_inode. Will help us keep the
  inode data in a consistent state for clear_inode. Always truncates
	 When we fail in read_inode() we mark inode as bad. The second test
	  catches the case when inode allocation fails before allocating
		 It's probably not necessary to truncate_inode_pages
		  here but we do it for safety anyway (it will most
	 We want to block signals in delete_inode as the lock and
	  messaging paths may return us -ERESTARTSYS. Which would
	  cause us to exit early, resulting in inodes being orphaned
	
	  Synchronize us against ocfs2_get_dentry. We take this in
	  shared mode so that all nodes can still concurrently
	  process deletes.
	 Lock down the inode. This gives us an up to date view of
	  it's metadata (for verification), and allows us to
	  serialize delete_inode on multiple nodes.
	 
	  Even though we might be doing a truncate, we don't take the
	  allocation lock here as it won't be needed - nobody will
	  have the file open.
	 Skip inode deletion and wait for dio orphan entry recovered
	 Query the cluster. This will be the final decision made
		 Error and remote inode busy both mean we won't be
		  removing the inode, so they take almost the same
		 Someone in the cluster has disallowed a wipe of
		  this inode, or it was never completely
	
	  Mark the inode as successfully deleted.
	 
	  This is important for ocfs2_clear_inode() as it will check
	  this flag and skip any checkpointing work
	 
	  ocfs2_stuff_meta_lvb() also uses this flag to invalidate
	  the LVB for other nodes.
	 To preven remote deletes we hold open lock before, now it
	 Do these before all the other work so that we don't bounce
	 We very well may get a clear_inode before all an inodes
	  metadata has hit disk. Of course, we can't drop any cluster
	  locks until the journal has finished with it. The only
	  exception here are successfully wiped inodes - their
	  metadata can now be considered to be part of the system
	
	  down_trylock() returns 0, down_write_trylock() returns 1
	  kernel 1, world 0
 Clear all other flags. 
	
	  ip_jinode is used to track txns against this inode. We ensure that
	  the journal is flushed before journal shutdown. Thus it is safe to
	  have inodes get cleaned up after journal shutdown.
 Called under inode_lock, with no more references on the
  struct inode, so it's safe here to check the flags field
  This is called from our getattr.
	 Let ocfs2_inode_lock do the work of updating our struct
  Updates a disk inode from a
  struct inode.
  Only takes ip_lock.
  Updates a struct inode from a disk inode.
  does no io, only takes ip_lock.
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
	
	  Errors after here are fatal.
	
	  Call ocfs2_validate_meta_ecc() first since it has ecc repair
	  function, but we should not return error immediately when ecc
	  validation fails, because the reason is quite likely the invalid
	  inode number inputed.
 Cannot fix invalid inode block 
		 Cannot just add VALID_FL flag back as a fix,
		  need more things to check here.
 Check inode block 
 Repair inode block 
 If ocfs2_read_blocks() got us a new bh, pass it up. 
 If ocfs2_read_blocks() got us a new bh, pass it up. 
 SPDX-License-Identifier: GPL-2.0-or-later
  slot_map.c
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
 This version is for the extended slot map 
  Post the slot information on disk into our slot_info struct.
  Must be protected by osb_lock.
	
	  The slot data will have been refreshed when ocfs2_super_lock
	  was taken.
	
	  We pass -1 as blocknr because we expect all of si->si_bh to
	  be !NULL.  Thus, ocfs2_read_blocks() will ignore blocknr.  If
	  this is not true, the read of -1 (UINT64_MAX) will fail.
 post the our slot info stuff into it's destination bh and write it
  Calculate how many bytes are needed by the slot map.  Returns
  an error if the slot map file is too small.
 try to find global node in the slot info. Returns -ENOENT
 The size checks above should ensure this 
 Acquire a fresh bh 
 use slot 0 directly in local mode 
		 search for ourselves first and take the slot if it already
		  exists. Perhaps we need to mark this in a variable for our
		  own journal recovery? Possibly not, though we certainly
			 if no slot yet, then just take 1st available
		
		  if write block failed, invalidate slot to avoid overwrite
		  slot during dismount in case another node rightly has mounted
 SPDX-License-Identifier: GPL-2.0-only
  stack_o2cb.c
  Code which interfaces ocfs2 with the o2cb stack.
  Copyright (C) 2007 Oracle.  All rights reserved.
 Needed for AOP_TRUNCATED_PAGE in mlog_errno() 
 These should be identical 
  Map an o2dlm status to standard errno values.
  o2dlm only uses a handful of these, and returns even fewer to the
  caller. Still, we try to assign sane values to each error.
  The following value pairs have special meanings to dlmglue, thus
  the right hand side needs to stay unique - never duplicate the
  mapping elsewhere in the table!
  DLM_NORMAL:		0
  DLM_NOTQUEUED:	-EAGAIN
  DLM_CANCELGRANT:	-EBUSY
  DLM_CANCEL:		-DLM_ECANCEL
 Keep in sync with dlmapi.h 
 Success 
 It is what it is 
 Cancel after grant 
 Trylock failed 
 Successful cancel 
	
	  In o2dlm, you can get both the lock_ast() for the lock being
	  granted and the unlock_ast() for the CANCEL failing.  A
	  successful cancel sends DLM_NORMAL here.  If the
	  lock grant happened before the cancel arrived, you get
	  DLM_CANCELGRANT.
	 
	  There's no need for the double-ast.  If we see DLM_CANCELGRANT,
	  we just ignore it.  We expect the lock_ast() to handle the
	  granted lock.
  o2dlm aways has a "valid" LVB. If the dlm loses track of the LVB
  contents, it will zero out the LVB.  Thus the caller can always trust
  the contents.
  Check if this node is heartbeating and is connected to all other
  heartbeating nodes.
	
	  o2dlm expects o2net sockets to be created. If not, then
	  dlm_join_domain() fails with a stack of errors which are both cryptic
	  and incomplete. The idea here is to detect upfront whether we have
	  managed to connect to all nodes or not. If not, then list the nodes
	  to allow the user to check the configuration (incorrect IP, firewall,
	  etc.) Yes, this is racy. But its not the end of the world.
 Force set the current node to allow easy compare 
  Called from the dlm when it's about to evict a node. This is how the
  classic stack signals node death.
 Ensure cluster stack is up and all nodes are connected 
 This just fills the structure in.  It is safe to pass conn. 
	 used by the dlm code to make message headers unique, each
 SPDX-License-Identifier: GPL-2.0
   Implementation of operations over local quota file
 Number of local quota structures per block 
 Number of blocks with entries in one chunk 
 Number of entries in a chunk bitmap 
 Offset of the chunk in quota file 
 1 block for local quota file info, 1 block per chunk for chunk info 
 Offset of the dquot structure in the quota file 
 Compute offset in the chunk of a structure with the given offset 
 Write bufferhead into the fs 
  Read quota block from a given logical offset.
  This function acquires ip_alloc_sem and thus it must not be called with a
  transaction started.
 If ocfs2_read_virt_blocks() got us a new bh, pass it up. 
 Check whether we understand format of quota files 
 First check whether we understand local quota file 
 Next check whether we understand global quota file 
 Since the header is read only, we don't care about locking 
 Release given list of quota file chunks 
 Load quota bitmaps into memory 
 Load entries in our quota file we have to recover
 Load information we need for quota recovery into memory 
 First init... 
		 At this point, journal of the slot is already replayed so
 Now read local header 
 Sync changes in local quota file into global quota file and
  reinitialize local quota file.
  The function expects local quota file to be already locked and
			 Add usage from quota entry into quota changes
			  of our node. Auxiliary variables are important
			 We want to drop reference held by the crashed
			  node. Since we have our own reference we know
 Release local quota file entry 
 Recover local quota files for given node different from us 
		 Someone else is holding the lock? Then he must be
 Now read local header 
 Is recovery still needed? 
		 We don't want to mark file as clean when it is actually
		 Mark quota file as clean if we are recovering quota file of
 Read information header from quota file 
 Now read local header 
 We crashed when using local quota file? 
 Now mark quota file as used 
 Write local info to quota file 
 Release info from memory 
 Not all entries free? Bug! 
	
	  s_umount held in exclusive mode protects us against racing with
	  recovery thread...
 Mark local file as clean 
 Write dquot to local quota file 
 Find free entry in local quota file 
 We failed? 
 Add new chunk to the local quota file 
 We are protected by dqio_sem so no locking needed 
 Local quota info and two new blocks we initialize 
 Initialize chunk header 
 Initialize new block with structures 
 Update local quotafile info 
 Find free entry in local quota file 
 Is the last chunk full? 
 We are protected by dqio_sem so no locking needed 
 Get buffer from the just added block 
 Local quota info, chunk header and the new block we initialize 
 Zero created block 
 Update chunk header 
 Update file header 
 Create dquot in the local file for given id 
 Initialize dquot structure on disk 
 Mark structure as allocated 
  Release dquot structure from local quota file. ocfs2_release_dquot() has
  already started a transaction and written all changes to global quota file
 Mark structure as freed 
 SPDX-License-Identifier: GPL-2.0-or-later
  dir.c
  Creates, reads, walks and deletes directory-nodes
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
   Portions of this code from linuxfsext3dir.c
   Copyright (C) 1992, 1993, 1994, 1995
   Remy Card (card@masi.ibp.fr)
   Laboratoire MASI - Institut Blaise pascal
   Universite Pierre et Marie Curie (Paris VI)
    from
    linuxfsminixdir.c
    Copyright (C) 1991, 1992 Linus Torvalds
  These are distinct checks because future versions of the file system will
  want to have a trailing dirent structure independent of indexing.
  "new' here refers to the point at which we're creating a new
  directory via "mkdir()", but also when we're expanding an inline
  directory. In either case, we don't yet have the indexing bit set
  on the directory, so the standard checks will fail in when metaecc
  is turned off. Only directory-initialization type functions should
  use this then. Everything else wants ocfs2_supports_dir_trailer()
 XXX ocfs2_block_dqtrailer() is similar but not quite - can we make
  XXX: This is executed once on every dirent. We should consider optimizing
  it.
  Link an unindexed block with a dir trailer structure into the index free
  list. This function will modify dirdata_bh, but assumes you've already
  passed it to the journal.
  Hashing code adapted from ext3
	
	  XXX: Is this really necessary, if the index is never looked
	  at by readdir? Is a hash value of '0' a bad idea?
	
	  This makes it very easy to debug indexing problems. We
	  should never allow this to be selected without hand editing
	  this file though.
  bh passed here can be an inode block or a dir data block, depending
  on the inode inline data flag.
  Returns 0 if not found, -1 on failure, and 1 on success
 this code is executed quadratically often 
 do minimal checking `by hand' 
 found a match - just to be sure, do a full check 
 prevent looping on a bad block 
	
	  We don't validate dirents here, that's handled
	  in-place when the code walks them.
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
	 
	  Note that we are safe to call this even if the directory
	  doesn't have a trailer.  Filesystems without metaecc will do
	  nothing, and filesystems with it will have one.
  Validate a directory trailer.
  We check the trailer here rather than in ocfs2_validate_dir_block()
  because that function doesn't have the inode to test.
  This function forces all errors to -EIO for consistency with its
  predecessor, ocfs2_bread().  We haven't audited what returning the
  real error codes would do to callers.  We log the real codes with
  mlog_errno() before we squash them.
 If ocfs2_read_virt_blocks() got us a new bh, pass it up. 
  Read the block at 'phys' which belongs to this directory
  inode. This function does no virtual->physical block translation -
  what's passed in is assumed to be a valid directory block.
 If ocfs2_read_block() got us a new bh, pass it up. 
 If ocfs2_read_block() got us a new bh, pass it up. 
  Read a series of dx_leaf blocks. This expects all buffer_head
  pointers to be NULL on function entry.
	int ra_max = 0;		 Number of bh's in the readahead
	int ra_ptr = 0;		 Current index into readahead
		
		  We deal with the read-ahead logic here.
 Refill the readahead buffer 
				
				  Terminate if we reach the end of the
				  directory and must wrap, or if our
				  search has finished at this block.
			 read error, skip block & hope for the best.
	
	  If the directory has grown while we were searching, then
	  search the last part of the directory before giving up.
 Clean up the read-ahead blocks 
  Returns the block index, from the start of the cluster which this
  hash belongs too.
 We want the last cluster 
	
	  We now have the cluster which should hold our entry. To
	  find the exact block from the start of the cluster to
	  search, we take the lower bits of the hash.
	
	  Empty leaf is legal, so no need to check for that.
		
		  Search unindexed leaf block now. We're not
		  guaranteed to find anything.
		
		  XXX: We should check the unindexed block here,
		  before using it.
 This means we found a bad directory entry. 
  Try to find an entry of the provided name within 'dir'.
  If nothing was found, -ENOENT is returned. Otherwise, zero is
  returned and the struct 'res' will contain information useful to
  other directory manipulation functions.
  Caller can NOT assume anything about the contents of the
  buffer_heads - they are passed back only so that it can be passed
  into any one of the manipulation functions (add entry, delete
  entry, etc). As an example, bh in the extent directory case is a
  data block, in the inline-data case it actually points to an inode,
  in the indexed directory case, multiple buffers are involved.
	
	  The unindexed dir code only uses part of the lookup
	  structure, so there's no reason to push it down further
	  than this.
  Update inode number and type of a previously found directory entry.
	
	  The same code works fine for both inline-data and extent
	  based directories, so no need to split this up.  The only
	  difference is the journal_access function.
  __ocfs2_delete_entry deletes a directory entry by merging it with the
  previous entry
	
	  This function gets a bit messy because we might have to
	  modify the root block, regardless of whether the indexed
	  entries are stored inline.
	
	  Only set 'entry_list' here, based on where we're looking
	  for the indexed entries. Later, we might still want to
	  journal both blocks, based on free list state.
	 Neither of these are a disk corruption - that should have
	
	  We know that removal of this dirent will leave enough room
	  for a new one, so add this block to the free list if it
	  isn't already there.
	
	  Add the block holding our index into the journal before
	  removing the unindexed entry. If we get an error return
	  from __ocfs2_delete_entry(), then it hasn't removed the
	  entry yet. Likewise, successful return means we must
	  remove the indexed entry.
	 
	  We're also careful to journal the root tree block here as
	  the entry count needs to be updated. Also, we might be
	  adding to the start of the free list.
 leaf_bh was journal_accessed for us in __ocfs2_delete_entry 
  Delete a directory entry. Hide the details of directory
  implementation from the caller.
  Check whether 'de' has enough room to hold an entry of
  'new_rec_len' bytes.
 Check whether this is an empty record with enough space 
	
	  Record might have free space at the end which we can
	  use.
  This expects that a journal write has been reserved on
  lookup->dl_prev_leaf_bh or lookup->dl_dx_root_bh
 Walk dl_leaf_bh to figure out what the new free rec_len is. 
		
		  There's still room in this block, so no need to remove it
		  from the free list. In this case, we just want to update
		  the rec len accounting.
 we don't always have a dentry for what we want to add, so people
  like orphan dir can call this instead.
  The lookup context must have been filled from
  ocfs2_prepare_dir_for_insert.
		
		  An indexed dir may require that we update the free space
		  list. Reserve a write to the previous node in the list so
		  that we don't fail later.
		 
		  XXX: This can be either a dx_root_block, or an unindexed
		  directory tree leaf block.
		 These checks should've already been passed by the
		  prepare function, but I guess we can leave them
		 We're guaranteed that we should have space, so we
 By now the buffer is marked for journaling 
	 when you think about it, the assert above should prevent us
		 If the dir block has changed since the last call to
		  readdir(2), then we might be pointing to an invalid
		  dirent right now.  Scan from the start of the block
				 It's too expensive to do a full
				  dirent test each time round this
				  loop, but we do have to test at
				  least that it is non-zero.  A
				  failure will be detected in the
 On error, skip the f_pos to the end. 
  NOTE: This function can be called against unindexed directories,
  and indexed ones.
 Skip the corrupt dirblock and keep trying 
		 The idea here is to begin with 8k read-ahead and to stay
		  4k ahead of our current position.
		 
		  TODO: Use the pagecache for this. We just need to
		 If the dir block has changed since the last call to
		  readdir(2), then we might be pointing to an invalid
		  dirent right now.  Scan from the start of the block
				 It's too expensive to do a full
				  dirent test each time round this
				  loop, but we do have to test at
				  least that it is non-zero.  A
				  failure will be detected in the
				 On error, skip the f_pos to the
  This is intended to be called from inside other kernel functions,
  so we fake some arguments.
  ocfs2_readdir()
		 We release EX lock which used to update atime
		  and get PR lock again to reduce contention
 we haven't got any yet, so propagate the error. 
  NOTE: this should always be called with parent dir i_mutex taken.
  Convenience function for callers which just want the block number
  mapped to a name and don't require the full dirent info, etc.
 Check for a name within a directory.
  Return 0 if the name does not exist
  Return -EEXIST if the directory contains the name
  Callers should have i_mutex + a cluster lock on dir
	
	  Check the positions of "." and ".." records to be sure
	  they're in the correct place.
	 
	  Indexed directories don't need to proceed past the first
	  two entries, so we end the scan after seeing '..'. Despite
	  that, we allow the scan to proceed In the event that we
	  have a corrupted indexed directory (no dot or dot dot
	  entries). This allows us to double check for existing
	  entries which might not have been found in the index.
  routine to check that the specified directory is empty (for rmdir)
  Returns 1 if dir is empty, zero otherwise.
  XXX: This is a performance problem for unindexed directories.
		
		  We still run ocfs2_dir_foreach to get the checks
		  for "." and "..".
		
		  XXX: Is it really safe to allow an unlink to continue?
  Fills "." and ".." dirents in a new directory block. Returns dirent for
  "..", which might be used during creation of a directory with a trailing
  header. It is otherwise safe to ignore the return code.
  This works together with code in ocfs2_mknod_locked() which sets
  the inline-data flag and initializes the inline-data section.
		
		  Figure out the size of the hole left over after
		  insertion of '.' and '..'. The trailer wants this
		  information.
  Allocates and formats a new cluster for use in an indexed dir
  leaf. This version will not do the extent insert, so that it can be
  used by operations which need careful ordering.
	
	  XXX: For create, this should claim cluster for the index
	  before the unindexed insert so that we have a better
	  chance of contiguousness as the directory grows in number
	  of entries.
	
	  Format the new cluster first. That way, we're inserting
	  valid data.
	
	  Our strategy is to create the directory as though it were
	  unindexed, then add the index block. This works with very
	  little complication since the state of a new directory is a
	  very well known quantity.
	 
	  Essentially, we have two dirents ("." and ".."), in the 1st
	  block which need indexing. These are easily inserted into
	  the index block.
 Buffer has been journaled for us by ocfs2_dx_dir_attach_index 
  XXX: This expects dx_root_bh to already be part of the transaction.
  Count the number of inline directory entries in di_bh and compare
  them against the number of entries we can hold in an inline dx root
  block.
 We are careful to leave room for one extra record. 
  Expand rec_len of the rightmost dirent in a directory block so that it
  contains the end of our valid space for dirents. We do this during
  expansion from an inline directory to one with extents. The first dir block
  in that case is taken from the inline data portion of the inode block.
  This will also return the largest amount of contiguous space for a dirent
  in the block. That value is not necessarily the last dirent, even after
  expansion. The directory indexing code wants this value for free space
  accounting. We do this here since we're already walking the entire dir
  block.
  We add the dir trailer if this filesystem wants it.
	 We need to double check this after modification of the final
  We allocate enough clusters to fulfill "blocks_wanted", but set
  i_size to exactly one block. Ocfs2_extend_dir() will handle the
  rest automatically for us.
  first_block_bh is a pointer to the 1st data block allocated to the
   directory.
 Add one more cluster for an index leaf 
 This gets us the dx_root 
	
	  We should never need more than 2 clusters for the unindexed
	  tree - maximum dirent size is far less than one block. In
	  fact, the only time we'd need more than one cluster is if
	  blocksize == clustersize and the dirent won't fit in the
	  extra space that the expansion to a single block gives. As
	  of today, that only happens on 4k4k file systems.
	
	  Prepare for worst case allocation scenario of two separate
	  extents in the unindexed tree.
		
		  Allocate our index cluster first, to maximize the
		  possibility that unindexed leaves grow
		  contiguously.
	
	  Try to claim as many clusters as the bitmap can give though
	  if we only get one now, that's enough to continue. The rest
	  will be claimed after the conversion to extents.
	
	  Operations are carefully ordered so that we set up the new
	  data block first. The conversion from inline data to
	  extents follows.
		
		  Prepare the dir trailer up front. It will otherwise look
		  like a valid dirent. Even if inserting the index fails
		  (unlikely), then all we'll have done is given first dir
		  block a small amount of fragmentation.
		
		  Dx dirs with an external cluster need to do this up
		  front. Inline dx root's get handled later, after
		  we've allocated our root block. We get passed back
		  a total number of items so that dr_num_entries can
		  be correctly set once the dx_root has been
		  allocated.
	
	  Set extent, i_size, etc on the directory. After this, the
	  inode should contain the same exact dirents as before and
	  be fully accessible from system calls.
	 
	  We let the later dirent insert modify cmtime - to the user
	  the data hasn't changed.
	
	  This should never fail as our extent list is empty and all
	  related blocks have been journaled already.
	
	  Set i_blocks after the extent insert for the most up to
	  date ip_clusters value.
	
	  We asked for two clusters, but only got one in the 1st
	  pass. Claim the 2nd cluster as a separate extent.
			
			  We need to return the correct block within the
			  cluster which should hold our entry.
 returns a bh of the 1st new block in the allocation. 
  Assumes you already have a cluster lock on the directory.
  'blocks_wanted' is only used if we have an inline directory which
  is to be turned into an extent based one. The size of the dirent to
  insert might be larger than the space gained by growing to just one
  block, so we may have to grow the inode by two blocks in that case.
  If the directory is already indexed, dx_root_bh must be provided.
		
		  This would be a code error as an inline directory should
		  never have an index root.
		 Expansion from inline to an indexed directory will
			
			  If the new dirent will fit inside the space
			  created by pushing out to one block, then
			  we can complete the operation
			  here. Otherwise we have to expand i_size
			  and format the 2nd block below.
		
		  Get rid of 'new_bh' - we want to format the 2nd
		  data block and return that instead.
 dir->i_size is always block aligned. 
		credits++;  For attaching the new dirent block to the
	
	  This calculates how many free bytes we'd have in block zero, should
	  this function force expansion to an extent tree.
		
		  No need to check for a trailing dirent record here as
		  they're not used for inline dirs.
			 Ok, we found a spot. Return this bh and let
	
	  We're going to require expansion of the directory - figure
	  out how many blocks we'll need so that a place for the
	  dirent can be found.
				
				  Caller will have to expand this
				  directory.
 move to next block 
			 Ok, we found a spot. Return this bh and let
	
	  It is not strictly necessary to sort by minor
  Find the optimal value to split this leaf on. This expects the leaf
  entries to be in sorted order.
  leaf_cpos is the cpos of the leaf we're splitting. insert_hash is
  the hash we want to insert.
  This function is only concerned with the major hash - that which
  determines which cluster an item belongs to.
	
	  There's a couple rare, but nasty corner cases we have to
	  check for here. All of them involve a leaf where all value
	  have the same hash, which is what we look for first.
	 
	  Most of the time, all of the above is false, and we simply
	  pick the median value for a split.
			
			  No matter where we would choose to split,
			  the new entry would want to occupy the same
			  block as these. Since there's no space left
			  in their existing block, we know there
			  won't be space after the split.
			
			  Because val is the same as leaf_cpos (which
			  is the smallest value this leaf can have),
			  yet is not equal to insert_hash, then we
			  know that insert_hash must be larger than
			  val (and leaf_cpos). At least cpos+1 in value.
			 
			  We also know then, that there cannot be an
			  adjacent extent (otherwise we'd be looking
			  at it). Choosing this value gives us a
			  chance to get some contiguousness.
			
			  val can not be the same as insert hash, and
			  also must be larger than leaf_cpos. Also,
			  we know that there can't be a leaf between
			  cpos and val, otherwise the entries with
			  hash 'val' would be there.
	
	  Since the records are sorted and the checks above
	  guaranteed that not all records in this block are the same,
	  we simple travel forward, from the median, and pick the 1st
	  record whose value is larger than leaf_cpos.
 Should be impossible 
  Transfer all entries in orig_dx_leaves whose major hash is equal to or
  larger than split_hash into new_dx_leaves. We use a temporary
  buffer (tmp_dx_leaf) to make the changes to the original leaf blocks.
  Since the block offset inside a leaf (cluster) is a constant mask
  of minor_hash, we can optimize - an item at block offset X within
  the original cluster, will be at offset X within the new cluster.
  Find the median value in dx_leaf_bh and allocate a new leaf to move
  half our entries into.
	
	  XXX: This is a rather large limit. We should use a more
	  realistic value.
	
	  This block is changing anyway, so we can sort it in place.
	
	  We have to carefully order operations here. There are items
	  which want to be in the new cluster before insert, but in
	  order to put those items in the new cluster, we alter the
	  old cluster. A failure to insert gets nasty.
	 
	  So, start by reserving writes to the old
	  cluster. ocfs2_dx_dir_new_cluster will reserve writes on
	  the new cluster for us, before inserting it. The insert
	  won't happen if there's an error before that. Once the
	  insert is done then, we can transfer from one leaf into the
	  other without fear of hitting any error.
	
	  The leaf transfer wants some scratch space so that we don't
	  wind up doing a bunch of expensive memmove().
			
			  Rebalancing should have provided us with
			  space in an appropriate leaf.
			 
			  XXX: Is this an abnormal condition then?
			  Should we print a message here?
		
		  Restart the lookup. The rebalance might have
		  changed which block our item fits into. Mark our
		  progress, so we only execute this once.
	
	  We do this up front, before the allocation, so that a
	  failure to add the dx_root_bh to the journal won't result
	  us losing clusters.
	
	  Transfer the entries from our dx_root into the appropriate
	  block
		 Each leaf has been passed to the journal already
	 This should never fail considering we start with an empty
		
		  We ran out of room in the root block. Expand it to
		  an extent, then allow ocfs2_find_dir_space_dx to do
		  the rest.
	
	  Insert preparation for an indexed directory is split into two
	  steps. The call to find_dir_space_dx reserves room in the index for
	  an additional item. If we run out of space there, it's a real error
	  we can't continue on.
	
	  Next, we need to find space in the unindexed tree. This call
	  searches using the free space linked list. If the unindexed tree
	  lacks sufficient space, we'll expand it below. The expansion code
	  is smart enough to add any new blocks to the free space list.
 Do this up here - ocfs2_extend_dir might need the dx_root 
		
		  We make the assumption here that new leaf blocks are added
		  to the front of our free list.
  Get a directory ready for insert. Any directory allocation required
  happens here. Success returns zero, and enough context in the dir
  lookup result that ocfs2_add_entry() will be able complete the task
  with minimal performance impact.
	
	  Do this up front to reduce confusion.
	 
	  The directory might start inline, then be turned into an
	  indexed one, in which case we'd need to hash deep inside
	  ocfs2_find_dir_space_id(). Since
	  ocfs2_prepare_dx_dir_for_insert() also needs this hash
	  done, there seems no point in spreading out the calls. We
	  can optimize away the case where the file system doesn't
	  support indexing.
		
		  We have to expand the directory to add this name.
 XXX: What if dr_clusters is too large? 
 SPDX-License-Identifier: GPL-2.0-or-later
  dcache.c
  dentry cache handling code
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
 if all else fails, just return false 
	 For a negative dentry -
	  check the generation number of the parent and compare with the
	  one stored in the inode.
 did we or someone else delete this inode? 
	
	  We don't need a cluster lock to test this because once an
	  inode nlink hits zero, it never goes back.
	
	  If the last lookup failed to create dentry lock, let us
	  redo it.
	
	  ocfs2_lookup() does a d_splice_alias() _before_ attaching
	  to the lock data, so we skip those here, otherwise
	  ocfs2_dentry_attach_lock() will get its original dentry
	  back.
 Negative parent dentry? 
 Name is in a different directory. 
  Walk the inode alias list, and find a dentry which has a given
  parent. ocfs2_dentry_attach_lock() wants to find _any_ alias as it
  is looking for a dentry_lock reference. The downconvert thread is
  looking to unhash aliases, so we allow it to skip any that already
  have that property.
  Attach this dentry to a cluster lock.
  Dentry locks cover all links in a given directory to a particular
  inode. We do this so that ocfs2 can build a lock name which all
  nodes in the cluster can agree on at all times. Shoving full names
  in the cluster lock won't work due to size restrictions. Covering
  links inside of a directory is a good compromise because it still
  allows us to use the parent directory lock to synchronize
  operations.
  Call this function with the parent dir semaphore and the parent dir
  cluster lock held.
  The dir semaphore will protect us from having to worry about
  concurrent processes on our node trying to attach a lock at the
  same time.
  The dir cluster lock (held at either PR or EX mode) protects us
  from unlink and rename on other nodes.
  A dput() can happen asynchronously due to pruning, so we cover
  attaching and detaching the dentry lock with a
  dentry_attach_lock.
  A node which has done lookup on a name retains a protected read
  lock until final dput. If the user requests and unlink or rename,
  the protected read is upgraded to an exclusive lock. Other nodes
  who have seen the dentry will then be informed that they need to
  downgrade their lock, which will involve d_delete on the
  dentry. This happens in ocfs2_dentry_convert_worker().
	
	  Negative dentry. We ignore these for now.
	 
	  XXX: Could we can improve ocfs2_dentry_revalidate() by
	  tracking these?
		 Converting a negative dentry to positive
		
		  Great, an alias exists, which means we must have a
		  dentry lock already. We can just grab the lock off
		  the alias and add it to the list.
		 
		  We're depending here on the fact that this dentry
		  was found and exists in the dcache and so must have
		  a reference to the dentry_lock because we can't
		  race creates. Final dput() cannot happen on it
		  since we have it pinned, so our reference is safe.
	
	  There are no other aliases
	
	  Does this have to happen below, for all attaches, in case
	  the struct inode gets blown away by the downconvert thread?
		 d_fsdata is set by a racing thread which is doing
		  the same thing as this thread is doing. Leave the racing
		  thread going ahead and we return here.
	
	  This actually gets us our PRMODE level lock. From now on,
	  we'll have a notification if one of these names is
	  destroyed on another node.
	
	  In case of error, manually free the allocation and do the iput().
	  We need to do this because error here means no d_instantiate(),
	  which means iput() will not be called during dput(dentry).
  ocfs2_dentry_iput() and friends.
  At this point, our particular dentry is detached from the inodes
  alias list, so there's no way that the locking code can find it.
  The interesting stuff happens when we determine that our lock needs
  to go away because this is the last subdir alias in the
  system. This function needs to handle a couple things:
  1) Synchronizing lock shutdown with the downconvert threads. This
     is already handled for us via the lockres release drop function
     called in ocfs2_release_dentry_lock()
  2) A race may occur when we're doing our lock shutdown and
     another process wants to create a new dentry lock. Right now we
     let them race, which means that for a very short while, this
     node might have two locks on a lock resource. This should be a
     problem though because one of them is in the process of being
     thrown out.
		
		  No dentry lock is ok if we're disconnected or
		  unhashed.
  d_move(), but keep the locks in sync.
  When we are done, "dentry" will have the parent dir and name of
  "target", which will be thrown away.
  We manually update the lock of "dentry" if need be.
  "target" doesn't have it's dentry lock touched - we allow the later
  dput() to handle this for us.
  This is called during ocfs2_rename(), while holding parent
  directory locks. The dentries have already been deleted on other
  nodes via ocfs2_remote_dentry_delete().
  Normally, the VFS handles the d_move() for the file system, after
  the ->rename() callback. OCFS2 wants to handle this internally, so
  the new lock can be created atomically with respect to the cluster.
	
	  Move within the same directory, so the actual lock info won't
	  change.
	 
	  XXX: Is there any advantage to dropping the lock here?
 SPDX-License-Identifier: GPL-2.0-or-later
  mmap.c
  Code to deal with the mess that is clustered mmap.
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
	
	  There are cases that lead to the page no longer belonging to the
	  mapping.
	  1) pagecache truncates locally due to memory pressure.
	  2) pagecache truncates when another is taking EX lock against 
	  inode lock. see ocfs2_data_convert_worker.
	  
	  The i_size check doesn't catch the case where nodes truncated and
	  then re-extended the file. We'll re-check the page mapping after
	  taking the page lock inside of ocfs2_write_begin_nolock().
	 
	  Let VM retry with these cases.
	
	  Call ocfs2_write_begin() and ocfs2_write_end() to take
	  advantage of the allocation code there. We pass a write
	  length of the whole page (chopped to i_size) to make sure
	  the whole thing is allocated.
	 
	  Since we know the page is up to date, we don't have to
	  worry about ocfs2_write_begin() skipping some buffer reads
	  because the "write" would invalidate their data.
	
	  The cluster locks taken will block a truncate from another
	  node. Taking the data lock will also ensure that we don't
	  attempt page truncation as part of a downconvert.
	
	  The alloc sem should be enough to serialize with
	  ocfs2_truncate_file() changing i_size as well as any thread
	  modifying the inode btree.
 SPDX-License-Identifier: GPL-2.0-only
  extent_map.c
  BlockCluster mapping functions
  Copyright (C) 2004 Oracle.  All rights reserved.
  The extent caching implementation is intentionally trivial.
  We only cache a small number of extents stored directly on the
  inode, so linear order operations are acceptable. If we ever want
  to increase the size of the extent map, then these algorithms must
  get smarter.
  Forget about all clusters equal to or greater than cpos.
 Full truncate of this record. 
 Partial truncate 
  Is any part of emi2 contained within emi1
	
	  Check if logical start of emi2 is inside emi1
	
	  Check if logical end of emi2 is inside emi1
  Try to merge emi with ins. Returns 1 if merge succeeds, zero
  otherwise.
	
	  Handle contiguousness
	
	  Overlapping extents - this shouldn't happen unless we've
	  split an extent to change it's flags. That is exceedingly
	  rare, so there's no sense in trying to optimize it yet.
 No merge was possible. 
  In order to reduce complexity on the caller, this insert function
  is intentionally liberal in what it will accept.
  The only rule is that the truncate call must be used whenever
  records have been deleted. This avoids inserting overlapping
  records with different physical mappings.
	
	  No item could be merged.
	 
	  Either allocate and add a new item, or overwrite the last recently
	  inserted.
  Return the 1st index within el which contains an extent start
  larger than v_cluster.
  Figure out the size of a hole which starts at v_cluster within the given
  extent list.
  If there is no more allocation past v_cluster, we return the maximum
  cluster size minus v_cluster.
  If we have in-inode extents, then el points to the dinode list and
  eb_bh is NULL. Otherwise, eb_bh should point to the extent block
  containing el.
		
		  Check the next leaf for any extents.
		
		  We're at the end of our existing allocation. Just
		  return the maximum number of clusters we could
		  possibly allocate.
		
		  Holes can be larger than the maximum size of an
		  extent, so we return their lengths in a separate
		  field.
	
	  Checking for last extent is potentially expensive - we
	  might have to look at the next leaf over to see if it's
	  empty.
	 
	  The first two checks are to see whether the caller even
	  cares for this information, and if the extent is at least
	  the last in it's list.
	 
	  If those hold true, then the extent is last if any of the
	  additional conditions hold true:
	   - Extent list is in-inode
	   - Extent list is right-most
	   - Extent list is 2nd to rightmost, with empty right-most
		
		  A hole was found. Return some canned values that
		  callers can key on. If asked for, num_clusters will
		  be populated with the size of the hole.
  This expects alloc_sem to be held. The allocation cannot change at
  all while the map is in the process of being updated.
	
	  p_cluster == 0 indicates a hole.
  The ocfs2_fiemap_inline() may be a little bit misleading, since
  it not only handles the fiemap for inlined files, but also deals
  with the fast symlink, cause they have no difference for extent
  mapping per se.
	
	  Handle inline-data and fast symlink separately.
 Is IO overwriting allocated blocks? 
		
		  If the caller passed us bhs, they should have come
		  from a previous readahead call to this function.  Thus,
		  they should have the right b_blocknr.
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmglue.c
  Code which implements an OCFS2 specific interface to our DLM.
  Copyright (C) 2003, 2004 Oracle.  All rights reserved.
  Return value from ->downconvert_worker functions.
  These control the precise actions of ocfs2_unblock_lock()
  and ocfs2_process_blocked_lock()
 Continue downconvert 
	UNBLOCK_CONTINUE_POST	= 1,  Continue downconvert, fire
	UNBLOCK_STOP_POST	= 2,  Do not downconvert, fire
 Lockdep class keys 
 This aids in debugging situations where a bad LVB might be involved. 
  OCFS2 Lock Resource Operations
  These fine tune the behavior of the generic dlmglue locking infrastructure.
  The most basic of lock types can point ->l_priv to their respective
  struct ocfs2_super and allow the default actions to manage things.
  Right now, each lock type also needs to implement an init function,
  and trivial lockunlock wrappers. ocfs2_simple_drop_lockres()
  should be called when the lock is no longer needed (i.e., object
  destruction time).
	
	  Translate an ocfs2_lock_res  into an ocfs2_super . Define
	  this callback if ->l_priv is not an ocfs2_super pointer
	
	  Optionally called in the downconvert thread after a
	  successful downconvert. The lockres will not be referenced
	  after this callback is called, so it is safe to free
	  memory, etc.
	 
	  The exact semantics of when this is called are controlled
	  by ->downconvert_worker()
	
	  Allow a lock type to add checks to determine whether it is
	  safe to downconvert a lock. Return 0 to re-queue the
	  downconvert at a later time, nonzero to continue.
	 
	  For most locks, the default checks that there are no
	  incompatible holders are sufficient.
	 
	  Called with the lockres spinlock held.
	
	  Allows a lock type to populate the lock value block. This
	  is called on downconvert, and when we drop a lock.
	 
	  Locks that want to use this should set LOCK_TYPE_USES_LVB
	  in the flags field.
	 
	  Called with the lockres spinlock held.
	
	  Called from the downconvert thread when it is determined
	  that a lock will be downconverted. This is called without
	  any locks held so the function can do work that might
	  schedule (syncing out data, etc).
	 
	  This should return any one of the ocfs2_unblock_action
	  values, depending on what it wants the thread to do.
	
	  LOCK_TYPE_ flags which describe the specific requirements
	  of a lock type. Descriptions of each individual flag follow.
  Some locks want to "refresh" potentially stale data when a
  meaningful (PRMODE or EXMODE) lock level is first obtained. If this
  flag is set, the OCFS2_LOCK_NEEDS_REFRESH flag will be set on the
  individual lockres l_flags member from the ast function. It is
  expected that the locking wrapper will clear the
  OCFS2_LOCK_NEEDS_REFRESH flag when done.
  Indicate that a lock type makes use of the lock value block. The
  ->set_lvb lock type callback must be defined.
 overflow 
 This also clears out the lock status block 
 thanks, gcc 
	
	  Unfortunately, the standard lock naming scheme won't work
	  here because we have two 16 byte values to use. Instead,
	  we'll stuff the inode number as a binary value. We still
	  want error prints to show something without garbling the
	  display, so drop a null byte in there before the inode
	  number. A future version of OCFS2 will likely use all
	  binary lock names. The stringified names have been a
	  tremendous aid in debugging, but now that the debugfs
	  interface exists, we can mangle things there if need be.
	 
	  NOTE: We also drop the standard "pad" value (the total lock
	  name size stays the same though - the last part is all
	  zeros due to the memset in ocfs2_lock_res_init_once()
	 Superblock lockres doesn't come from a slab so we call init
	 Rename lockres doesn't come from a slab so we call init
	 nfs_sync lockres doesn't come from a slab so we call init
 Only one trimfs thread are allowed to work at the same time. 
 Need to clear out the lock status block for the dlm 
  Keep a list of processes who have interest in a lockres.
  Note: this is now only uesed for check recursive cluster locking.
 WARNING: This function lives in a world where the only three lock
  levels are EX, PR, and NL. It will have to be adjusted when more
	 Convert from RO to EX doesn't really need anything as our
	  information is already up to data. Convert from NL to
	  anything however should mark ourselves as needing an
	
	  We set the OCFS2_LOCK_UPCONVERT_FINISHING flag before clearing
	  the OCFS2_LOCK_BUSY flag to prevent the dc thread from
	  downconverting the lock before the upconvert has fully completed.
	  Do not prevent the dc thread from downconverting if NONBLOCK lock
	  had already returned.
		 only schedule a downconvert if we haven't already scheduled
		  one that goes low enough to satisfy the level we're
		  blocking.  this also catches the case where we get
  OCFS2_LOCK_PENDING and l_pending_gen.
  Why does OCFS2_LOCK_PENDING exist?  To close a race between setting
  OCFS2_LOCK_BUSY and calling ocfs2_dlm_lock().  See ocfs2_unblock_lock()
  for more details on the race.
  OCFS2_LOCK_PENDING closes the race quite nicely.  However, it introduces
  a race on itself.  In o2dlm, we can get the ast before ocfs2_dlm_lock()
  returns.  The ast clears OCFS2_LOCK_BUSY, and must therefore clear
  OCFS2_LOCK_PENDING at the same time.  When ocfs2_dlm_lock() returns,
  the caller is going to try to clear PENDING again.  If nothing else is
  happening, __lockres_clear_pending() sees PENDING is unset and does
  nothing.
  But what if another path (eg downconvert thread) has just started a
  new locking action?  The other path has re-set PENDING.  Our path
  cannot clear PENDING, because that will re-open the original race
  window.
  [Example]
  ocfs2_meta_lock()
   ocfs2_cluster_lock()
    set BUSY
    set PENDING
    drop l_lock
    ocfs2_dlm_lock()
     ocfs2_locking_ast()		ocfs2_downconvert_thread()
      clear PENDING			 ocfs2_unblock_lock()
 					  take_l_lock
 					  !BUSY
 					  ocfs2_prepare_downconvert()
 					   set BUSY
 					   set PENDING
 					  drop l_lock
    take l_lock
    clear PENDING
    drop l_lock
 			<window>
 					  ocfs2_dlm_lock()
  So as you can see, we now have a window where l_lock is not held,
  PENDING is not set, and ocfs2_dlm_lock() has not been called.
  The core problem is that ocfs2_cluster_lock() has cleared the PENDING
  set by ocfs2_prepare_downconvert().  That wasn't nice.
  To solve this we introduce l_pending_gen.  A call to
  lockres_clear_pending() will only do so when it is passed a generation
  number that matches the lockres.  lockres_set_pending() will return the
  current generation number.  When ocfs2_cluster_lock() goes to clear
  PENDING, it passes the generation it got from set_pending().  In our
  example above, the generation numbers will not match.  Thus,
  ocfs2_cluster_lock() will not clear the PENDING set by
  ocfs2_prepare_downconvert().
 Unlocked version for ocfs2_locking_ast() 
	
	  The ast and locking functions can race us here.  The winner
	  will clear pending, the loser will not.
	
	  The downconvert thread may have skipped us because we
	  were PENDING.  Wake it up.
 Locked version for callers of ocfs2_dlm_lock() 
	
	  We can skip the bast for locks which don't enable caching -
	  they'll be dropped at the earliest possible time anyway.
	 set it to something invalid so if we get called again we
 Did we try to cancel this lock?  Clear that state 
	
	  We may have beaten the locking functions here.  We certainly
	  know that dlm_lock() has been called :-)
	  Because we can't have two lock calls in flight at once, we
	  can use lockres->l_pending_gen.
		 Downconvert thread may have requeued this lock, we
  This is the filesystem locking protocol.  It provides the lock handling
  hooks for the underlying DLM.  It has a maximum version number.
  The version number allows interoperability with systems running at
  the same major number and an equal or smaller minor number.
  Whenever the filesystem does new things with locks (adds or removes a
  lock, orders them differently, does different things underneath a lock),
  the version must be changed.  The protocol is negotiated when joining
  the dlm domain.  A node may join the domain if its major version is
  identical to all other nodes and its minor version is greater than
  or equal to all other nodes.  When its minor version is greater than
  the other nodes, it will run at the minor version specified by the
  other nodes.
  If a locking change is made that will not be compatible with older
  versions, the major number must be increased and the minor version set
  to zero.  If a change merely adds a behavior that can be disabled when
  speaking to older versions, the minor version must be increased.  If a
  change adds a fully backwards compatible change (eg, LVB changes that
  are just ignored by older versions), the version does not need to be
  updated.
 Note: If we detect another process working on the lock (i.e.,
  OCFS2_LOCK_BUSY), we'll bail out returning 0. It's up to the caller
  to do the right thing in that case.
 predict what lock level we'll be dropping down to on behalf
  of another node, and return true if the currently wanted
 Re-arm the completion in case we want to wait on it again 
 returns 0 if the mw that was removed was already satisfied, -EBUSY
 Re-arm the completion in case we want to wait on it again 
 gcc doesn't realize wait = 1 guarantees ret is set 
	 We only compare against the currently granted level
	  here. If the lock is blocked waiting on a downconvert,
		 is someone sitting in dlm_lock? If so, wait on
		
		  We've upconverted. If the lock now has a level we can
		  work with, we take it. If, however, the lock is not at the
		  required level, we go thru the full cycle. One way this could
		  happen is if a process requesting an upconvert to PR is
		  closely followed by another requesting upconvert to an EX.
		  If the process requesting EX lands here, we want it to
		  continue attempting to upconvert and let the process
		  requesting PR take the lock.
		  If multiple processes request upconvert to PR, the first one
		  here will take the lock. The others will have to go thru the
		  OCFS2_LOCK_BLOCKED check to ensure that there is no pending
		  downconvert request.
		 is the lock is currently blocked on behalf of
 call dlm_lock to upgrade lock now 
		 At this point we've gone inside the dlm and need to
 wait for busy to clear and carry on 
 Ok, if we get here then we're good to go. 
 ocfs2_unblock_lock reques on seeing OCFS2_LOCK_UPCONVERT_FINISHING 
	
	  This is helping work around a lock inversion between the page lock
	  and dlm locks.  One path holds the page lock while calling aops
	  which block acquiring dlm locks.  The voting thread holds dlm
	  locks while acquiring page locks while down converting data locks.
	  This block is helping an aop path notice the inversion and back
	  off to unlock its page lock before trying the dlm lock again.
 Grants us an EX lock on the data and metadata resources, skipping
  the normal cluster directory lookup. Use this ONLY on newly created
  inodes which other nodes can't possibly see, and which haven't been
  hashed in the inode hash yet. This can give us a good performance
  increase as it'll skip the network broadcast normally associated
	 NOTE: That we don't increment any of the holder counts, nor
	  do we add anything to a journal handle. Since this is
	  supposed to be a new inode which the cluster doesn't know
	  about yet, there is no need to.  As far as the LVB handling
	  is concerned, this is basically like acquiring an EX lock
	  on a resource which has an invalid one -- we'll set it
	
	  We don't want to use DLM_LKF_LOCAL on a meta data lock as they
	  don't use a generation in their lock names.
  ocfs2_open_lock always get PR mode lock.
	
	  The file system may already holding a PRMODEEXMODE open lock.
	  Since we pass DLM_LKF_NOQUEUE, the request won't block waiting on
	  other nodes and the -EAGAIN will indicate to the caller that
	  this inode is still in use.
  ocfs2_open_unlock unlock PR and EX mode open locks.
	
	  We may still have gotten the lock, in which case there's no
	  point to restarting the syscall.
  ocfs2_file_lock() and ocfs2_file_unlock() map to a single pair of
  flock() calls. The locking approach this requires is sufficiently
  different from all other cluster lock types that we implement a
  separate path to the "low-level" dlm calls. In particular:
  - No optimization of lock levels is done - we take at exactly
    what's been requested.
  - No lock caching is employed. We immediately downconvert to
    no-lock at unlock time. This also means flock locks never go on
    the blocking list).
  - Since userspace can trivially deadlock itself with flock, we make
    sure to allow cancellation of a misbehaving applications flock()
    request.
  - Access to any flock lockres doesn't require concurrency, so we
    can simplify the code by requiring the caller to guarantee
    serialization of dlmglue flock calls.
		
		  Get the lock at NLMODE to start - that way we
		  can cancel the upconvert request if need be.
		
		  Userspace can cause deadlock itself with
		  flock(). Current behavior locally is to allow the
		  deadlock, but abort the system call if a signal is
		  received. We follow this example, otherwise a
		  poorly written program could sit in kernel until
		  reboot.
		 
		  Handling this is a bit more complicated for Ocfs2
		  though. We can't exit this function with an
		  outstanding lock request, so a cancel convert is
		  required. We intentionally overwrite 'ret' - if the
		  cancel fails and the lock was granted, it's easier
		  to just bubble success back up to the user.
 Trylock failed asynchronously 
	
	  Fake a blocking ast for the downconvert code.
	 If we know that another node is waiting on our lock, kick
	  the downconvert thread  pre-emptively when we reach a release
 LVB only has room for 64 bits of time here so we pack it for
 Call this with the lockres locked. I am reasonably sure we don't
  need ip_lock in this function as anyone who would be changing those
	
	  Invalidate the LVB of a deleted inode - this way other
	  nodes are forced to go to disk and discover the new inode
	  status.
 We're safe here without the lockres lock... 
 fast-symlinks are a special case 
 Determine whether a lock resource needs to be refreshed, and
  arbitrate who gets to refresh it.
    0 means no refresh needed.
    > 0 means you need to refresh this and you MUST call
 Ok, I'll be the one to refresh this lock. 
 If status is non zero, I'll mark it as not being in refresh
 may or may not return a bh if it went to disk. 
	 This will discard any caching information we might have had
 Boo, we have to go to disk. 
 read bh, cast, ocfs2_refresh_inode 
		 This is a good chance to make sure we're not
		  locking an invalid object.  ocfs2_read_inode_block()
		  already checked that the inode block is sane.
		 
		  We bug on a stale inode here because we checked
		  above whether it was wiped from disk. The wiping
		  node provides a guarantee that we receive that
		  message and can mark the inode before dropping any
		 Ok, the update went to disk for us, use the
  returns < 0 error if the callback will never be called, otherwise
  the result of the lock will be communicated via the callback.
	 We'll allow faking a readonly metadata lock for
 Notify the error cleanup path to drop the cluster lock. 
	 We wait twice because a node may have died while we were in
	  the lower dlm layers. The second time though, we've
	  committed to owning this lock so we don't allow signals to
	
	  We only see this flag if we're being called from
	  ocfs2_read_locked_inode(). It means we're locking an inode
	  which hasn't been populated yet, so clear the refresh flag
	  and let the caller handle it.
	 This is fun. The caller may want a bh back, or it may
	  not. ocfs2_inode_lock_update definitely wants one in, but
	  may or may not read one, depending on what's in the
	  LVB. The result of all of this is that we've only gone to
  This is working around a lock inversion between tasks acquiring DLM
  locks while holding a page lock and the downconvert thread which
  blocks dlm lock acquiry while acquiring page locks.
   These _with_page variantes are only intended to be called from aop
  methods that hold page locks and return a very specific positive error
  code that aop methods pass up to the VFS -- test for errors with != 0. 
  The DLM is called such that it returns -EAGAIN if it would have
  blocked waiting for the downconvert thread.  In that case we unlock
  our page so the downconvert thread can make progress.  Once we've
  done this we have to return AOP_TRUNCATED_PAGE so the aop method
  that called us can bubble that back up into the VFS who will then
  immediately retry the aop call.
		
		  If we can't get inode lock immediately, we should not return
		  directly here, since this will lead to a softlockup problem.
		  The method is to get a blocking lock and immediately unlock
		  before returning, this can avoid CPU resource waste due to
		  lots of retries, and benefits fairness in getting lock.
	
	  If we should update atime, we will get EX lock,
	  otherwise we just get PR lock.
  This _tracker variantes are introduced to deal with the recursive cluster
  locking issue. The idea is to keep track of a lock holder on the stack of
  the current process. If there's a lock holder on the stack, we know the
  task context is already protected by cluster locking. Currently, they're
  used in some VFS entry routines.
  return < 0 on error, return == 0 if there's no lock holder on the stack
  before this call, return == 1 if this call would be a recursive locking.
  return == -1 if this lock attempt will cause an upgrade which is forbidden.
  When taking lock levels into account,we face some different situations.
  1. no lock is held
     In this case, just lock the inode as requested and return 0
  2. We are holding a lock
     For this situation, things diverges into several cases
     wanted     holding	     what to do
     ex		ex	    see 2.1 below
     ex		pr	    see 2.2 below
     pr		ex	    see 2.1 below
     pr		pr	    see 2.1 below
     2.1 lock level that is been held is compatible
     with the wanted level, so no lock action will be tacken.
     2.2 Otherwise, an upgrade is needed, but it is forbidden.
  Reason why upgrade within a process is forbidden is that
  lock upgrade may cause dead lock. The following illustrates
  how it happens.
          thread on node1                             thread on node2
  ocfs2_inode_lock_tracker(ex=0)
                                 <======   ocfs2_inode_lock_tracker(ex=1)
  ocfs2_inode_lock_tracker(ex=1)
		
		  This corresponds to the case 1.
		  We haven't got any lock before.
		
		  case 2.2 upgrade may cause dead lock, forbid it.
	
	   case 2.1 OCFS2_META_LOCK_GETBH flag make ocfs2_inode_lock_full.
	   ignore the lock level and just update it.
	 had_lock means that the currect process already takes the cluster
	  lock previously.
	  If had_lock is 1, we have nothing to do here.
	  If had_lock is 0, we will release the lock.
	 The super block lock path is really in the best position to
	  know when resources covered by the lock need to be
	  refreshed, so we do it here. Of course, making sense of
 Reference counting of the dlm debug structure. We want this because
  open references on the debug inodes can live on after a mount, so
 Access to this is arbitrated for us via seq_file->sem. 
 discover the head of the list 
		 We track our "dummy" iteration lockres' by a NULL
		 Since lockres' have the lifetime of their container
		  (which can be inodes, ocfs2_supers, etc) we want to
		  copy this out to a temporary lockres while still
		  under the spinlock. Obviously after this we can't
		  trust any pointers on the copy returned, but that's
		  ok as the information we want isn't typically held
  Version is used by debugfs.ocfs2 to determine the format being used
  New in version 2
 	- Lock stats printed
  New in version 3
 	- Max time in lock stats is in usecs (instead of nsecs)
  New in version 4
 	- Add last prex unlock times and first lock wait time in usecs
		
		  Use d_filter_secs field to filter lock resources dump,
		  the default d_filter_secs(0) value filters nothing,
		  otherwise, only dump the last N seconds active lock
		  resources.
 Dump the raw LVB 
 The following seq_print was added in version 2 of this output 
 End the line 
 launch downconvert thread 
 for now, uuid == domain 
	
	  Now that we have dropped all locks and ocfs2_dismount_volume()
	  has disabled recovery, the DLM won't be talking to us.  It's
	  safe to tear things down before disconnecting the cluster.
 We didn't get anywhere near actually using this lockres. 
		 XXX: Today we just wait on any busy
		  locks... Perhaps we need to cancel converts in the
	 make sure we never get here while waiting for an ast to
 is this necessary? 
 Mark the lockres as being dropped. It will no longer be
  queued if blocking, but we still may have to wait on it
  being dequeued from the downconvert thread before we can consider
  it safe to drop.
		
		  We know the downconvert is queued but not in progress
		  because we are the downconvert thread and processing
		  different lock. So we can just remove the lock from the
		  queue. This is not only an optimization but also a way
		  to avoid the following deadlock:
		    ocfs2_dentry_post_unlock()
		      ocfs2_dentry_lock_put()
		        ocfs2_drop_dentry_lock()
		          iput()
		            ocfs2_evict_inode()
		              ocfs2_clear_inode()
		                ocfs2_mark_lockres_freeing()
		                  ... blocks waiting for OCFS2_LOCK_QUEUED
		                  since we are the downconvert thread which
		                  should clear the flag.
		
		  Warn if we recurse into another post_unlock call.  Strictly
		  speaking it isn't a problem but we need to be careful if
		  that happens (stack overflow, deadlocks, ...) so warn if
		  ocfs2 grows a path for which this can happen.
 Since the lock is freeing we don't do much in the fn below 
	 No need to call ocfs2_mark_lockres_freeing here -
	
	  On DLM_LKF_VALBLK, fsdlm behaves differently with o2cb. It always
	  expects DLM_LKF_VALBLK being set if the LKB has LVB, so that
	  we can recover correctly from node failure. Otherwise, we may get
	  invalid LVB in LKB, but without DLM_SBF_VALNOTVALID being set.
 returns 1 when the caller should unlock and call ocfs2_dlm_unlock 
		 If we're already trying to cancel a lock conversion
		  then just drop the spinlock and allow the caller to
 were we in a convert when we got the bast fire? 
	 set things up for the unlockast to know to just
	
	  Is it still blocking? If not, we have no more work to do.
		 XXX
		  This is a big race.  The OCFS2_LOCK_PENDING flag
		  exists entirely for one reason - another thread has set
		  OCFS2_LOCK_BUSY, but has NOT yet called dlm_lock().
		 
		  If we do ocfs2_cancel_convert() before the other thread
		  calls dlm_lock(), our cancel will do nothing.  We will
		  get no ast, and we will have no way of knowing the
		  cancel failed.  Meanwhile, the other thread will call
		  into dlm_lock() and wait...forever.
		 
		  Why forever?  Because another node has asked for the
		  lock first; that's why we're here in unblock_lock().
		 
		  The solution is OCFS2_LOCK_PENDING.  When PENDING is
		  set, we just requeue the unblock.  Only when the other
		  thread has called dlm_lock() and cleared PENDING will
		  we then cancel their request.
		 
		  All callers of dlm_lock() must set OCFS2_DLM_PENDING
		  at the same time they set OCFS2_DLM_BUSY.  They must
		  clear OCFS2_DLM_PENDING after dlm_lock() returns.
	
	  This prevents livelocks. OCFS2_LOCK_UPCONVERT_FINISHING flag is
	  set when the ast is received for an upconvert just before the
	  OCFS2_LOCK_BUSY flag is cleared. Now if the fs received a bast
	  on the heels of the ast, we want to delay the downconvert just
	  enough to allow the up requestor to do its task. Because this
	  lock is in the blocked queue, the lock will be downconverted
	  as soon as the requestor is done with the lock.
	
	  How can we block and yet be at NL?  We were trying to upconvert
	  from NL and got canceled.  The code comes back here, and now
	  we notice and clear BLOCKING.
	 if we're blocking an exclusive and we have any holders,
	 If it's a PR we're blocking, then only
	
	  Can we get a lock in this state if the holder counts are
	  zero? The meta data unblock code used to check this.
	 If we get here, then we know that there are no more
	  incompatible holders (and anyone asking for an incompatible
	 Some lockres types want to do a bit of work before
	  downconverting a lock. Allow that here. The worker function
	  may sleep, so we save off a copy of what we're blocking as
		 If this changed underneath us, then we can't drop
		
		  We only set the lvb if the lock has been fully
		  refreshed - otherwise we risk setting stale
		  data. Otherwise, there's no need to actually clear
		  out the lvb here as it's value is still valid.
	 The dlm lock convert is being cancelled in background,
	  ocfs2_cancel_convert() is asynchronous in fsdlm,
	  requeue it, try again later.
	
	  We need this before the filemap_fdatawrite() so that it can
	  transfer the dirty bit from the PTE to the
	  page. Unfortunately this means that even for EX->PR
	  downconverts, we'll lose our mappings and have to build
	  them up again.
		 We only need to wait on the IO if we're not also
		  truncating pages because truncate_inode_pages waits
		  for us above. We don't truncate pages if we're
		  blocking anything < EXMODE because we want to keep
  Does the final reference drop on our dentry lock. Right now this
  happens in the downconvert thread, but we could choose to simplify the
  dlmglue API and push these off to the ocfs2_wq in the future.
  d_delete() matching dentries before the lock downconvert.
  At this point, any process waiting to destroy the
  dentry_lock due to last ref count is stopped by the
  OCFS2_LOCK_QUEUED flag.
  We have two potential problems
  1) If we do the last reference drop on our dentry_lock (via dput)
     we'll wind up in ocfs2_release_dentry_lock(), waiting on
     the downconvert to finish. Instead we take an elevated
     reference and push the drop until after we've completed our
     unblock processing.
  2) There might be another process with a final reference,
     waiting on us to finish processing. If this is the case, we
     detect it and exit out - there's no more dentries anyway.
	
	  This node is blocking another node from getting a read
	  lock. This happens when we've renamed within a
	  directory. We've forced the other nodes to d_delete(), but
	  we never actually dropped our lock because it's still
	  valid. The downconvert code will retain a PR for this node,
	  so there's no further work to do.
	
	  Mark this inode as potentially orphaned. The code in
	  ocfs2_delete_inode() will figure out whether it actually
	  needs to be freed or not.
	
	  Yuck. We need to make sure however that the check of
	  OCFS2_LOCK_FREEING and the extra reference are atomic with
	  respect to a reference decrement or the setting of that
	  flag.
	
	  We have a process waiting on us in ocfs2_dentry_iput(),
	  which means we can't have any more outstanding
	  aliases. There's no need to do any more work.
		
		  The following dcache calls may do an
		  iput(). Normally we don't want that from the
		  downconverting thread, but in this case it's ok
		  because the requesting node already has an
		  exclusive lock on the inode, so it can't be queued
		  for a downconvert.
	
	  If we are the last holder of this dentry lock, there is no
	  reason to downconvert so skip straight to the unlock.
 Lock quota info, this function expects at least shared lock on the quota file
 On RO devices, locking really isn't needed... 
 OK, we have the lock but we need to refresh the quota info 
	 Our reference to the lockres in this function can be
	  considered valid until we remove the OCFS2_LOCK_QUEUED
	 Detect whether a lock has been marked as going away while
	  the downconvert thread was processing other things. A lock can
	  still be marked with OCFS2_LOCK_FREEING after this check,
	  but short circuiting here will still save us some
		 Do not schedule a lock for downconvert when it's on
		  the way to destruction - any nodes wanting access
	 grab this early so we know to try again if a state change and
	
	  blocked lock processing in this loop might call iput which can
	  remove items off osb->blocked_lock_list. Downconvert up to
	  'processed' number of locks, but stop short if we had some
	  removed in ocfs2_mark_lockres_freeing when downconverting.
	 only quit once we've been asked to stop and there is no more
	 make sure the voting thread gets a swipe at whatever changes
 SPDX-License-Identifier: GPL-2.0-only
  refcounttree.c
  Copyright (C) 2009 Oracle.  All rights reserved.
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
 If ocfs2_read_block() got us a new bh, pass it up. 
 osb_lock is already locked. 
 This should never happen! 
	
	  We need the generation to create the refcount tree lock and since
	  it isn't changed during the tree modification, we are safe here to
	  read without protection.
	  We also have to purge the cache after we create the lock since the
	  refcount block may have the stale data. It can only be trusted when
	  we hold the refcount lock.
  Lock the refcount tree pointed by ref_blkno and return the tree.
  In most case, we lock the tree and read the refcount block.
  So read it here if the caller really needs it.
  If the tree has been re-created by other node, it will free the
  old one and re-create it.
	
	  If the refcount block has been freed and re-created, we may need
	  to recreate the refcount tree also.
	 
	  Here we just remove the tree from the rb-tree, and the last
	  kref holder will unlock and delete this refcount_tree.
	  Then we goto "again" and ocfs2_get_refcount_tree will create
	  the new refcount tree for us.
		
		  We get an extra reference when we create the refcount
		  tree, so another put will destroy it.
  Create a refcount tree for an inode.
  We take for granted that the inode is already locked.
 Initialize ocfs2_refcount_block. 
	
	  We have to init the tree lock here since it will use
	  the generation number to create it.
	
	  We've just created a new refcount tree in this block.  If
	  we found a refcount tree on the ocfs2_super, it must be
	  one we just deleted.  We free the old tree before
	  inserting the new tree.
	
	  If we are the last user, we need to free the block.
	  So lock the allocator ahead.
 ok, cpos fail in this rec. Just return. 
 We meet with a hole here, so fake the rec. 
  Try to remove refcount tree. The mechanism is:
  1) Check whether i_clusters == 0, if no, exit.
  2) check whether we have i_xattr_loc in dinode. if yes, exit.
  3) Check whether we have inline xattr stored outside, if yes, exit.
  4) Remove the tree.
  Find the end range for a leaf refcount block indicated by
  el->l_recs[index].e_blkno.
		
		  We have a extent rec after index, so just use the e_cpos
		  of the next extent rec.
		
		  We are the last extent rec, so any high cpos should
		  be stored in this leaf refcount block.
	
	  If the extent block isn't the last one, we have to find
	  the subtree root between this extent block and the next
	  leaf extent block and get the corresponding e_cpos from
	  the subroot. Otherwise we may corrupt the b-tree.
  Given a cpos and len, try to find the refcount record which contains cpos.
  1. If cpos can be found in one refcount record, return the record.
  2. If cpos can't be found, return a fake record which start from cpos
     and end at a small value between cpos+len and start of the next record.
     This fake record has r_refcount = 0.
  Merge the refcount rec if we are contiguous with the adjacent recs.
  Change the refcount indexed by "index" in ref_bh.
  If refcount reaches 0, remove it.
	
	  Initialize ocfs2_refcount_block.
	  It should contain the same information as the old root.
	  so just memcpy it and change the corresponding field.
 Now change the root. 
  The refcount cpos are ordered by their 64bit cpos,
  But we will use the low 32 bit to be the e_cpos in the b-tree.
  So we need to make sure that this pos isn't intersected with others.
  Note: The refcount block is already sorted by their low 32 bit cpos,
        So just try the middle pos first, and we will exit when we find
        the good position.
 Let's check delta earlier than middle 
 For even counts, don't walk off the end 
 Now try delta past middle 
	
	  XXX: Improvement later.
	  If we know all the high 32 bit cpos is the same, no need to sort.
	 
	  In order to make the whole process safe, we do:
	  1. sort the entries by their low 32 bit cpos first so that we can
	     find the split cpos easily.
	  2. call ocfs2_insert_extent to insert the new refcount block.
	  3. move the refcount rec to the new block.
	  4. sort the entries by their 64 bit cpos.
	  5. dirty the new_rb and rb.
 move refcount records starting from split_index to the new block. 
ok, remove the entries we just moved over to the other block. 
 change old and new rl_used accordingly. 
 Initialize ocfs2_refcount_block. 
 Insert the new leaf block with the specific offset cpos. 
		
		  the old root bh hasn't been expanded to a b-tree,
		  so expand it first.
 Now add a new refcount block into the tree.
  Adjust the extent rec in b-tree representing ref_leaf_bh.
  Only called when we have inserted a new refcount rec at index 0
  which means ocfs2_extent_rec.e_cpos may need some change.
	
	  2 more credits, one for the leaf refcount block, one for
	  the extent block contains the extent rec.
 change the leaf extent block first. 
 change the r_cpos in the leaf block. 
  Split the refcount_rec indexed by "index" in ref_leaf_bh.
  This is much simple than our b-tree code.
  split_rec is the new refcount rec we want to insert.
  If split_rec->r_refcount > 0, we are changing the refcount(in case we
  increase refcount or decrease a refcount to non-zero).
  If split_rec->r_refcount == 0, we are punching a hole in current refcount
  rec( in case we decrease a refcount to zero).
	
	  If we just need to split the header or tail clusters,
	  no more recs are needed, just split is OK.
	  Otherwise we at least need one new recs.
	
	  We need one more rec if we split in the middle and the new rec have
	  some refcount in it.
 If the leaf block don't have enough record, expand it. 
		
		  We have to re-get it since now cpos may be moved to
		  another leaf block.
	
	  We have calculated out how many new records we need and store
	  in recs_need, so spare enough space first by moving the records
	  after "index" to the end.
	
	  If we have "len", the we will split in the tail and move it
	  to the end of the space we have just spared.
	
	  If the split pos isn't the same as the original one, we need to
	  split in the head.
	 
	  Note: We have the chance that split_rec.r_refcount = 0,
	  recs_need = 0 and len > 0, which means we just cut the head from
	  the orig_rec and in that case we have done some modification in
	  orig_rec above, so the check for r_cpos is faked.
		
		  Here we may meet with 3 situations:
		 
		  1. If we find an already existing record, and the length
		     is the same, cool, we just need to increase the r_refcount
		     and it is OK.
		  2. If we find a hole, just insert it with r_refcount = 1.
		  3. If we are in the middle of one extent record, split
		     it.
	
	  add the freed block to the dealloc so that it will be freed
	  when we run dealloc.
	
	  check whether we need to restore the root refcount block if
	  there is no leaf extent block at atll.
 Remove the leaf refcount block if it contains no refcount record. 
 Caller must hold refcount tree lock. 
  Mark the already-existing extent at cpos as refcounted for len clusters.
  This adds the refcount extent flag.
  If the existing extent is larger than the request, initiate a
  split. An attempt will be made at merging with adjacent extents.
  The caller is responsible for passing down meta_ac if we'll need it.
  Given some contiguous physical clusters, calculate what we need
  for modifying their refcount.
			
			  Now we encounter a new leaf block, so calculate
			  whether we need to extend the old leaf.
		
		  We record all the records which will be inserted to the
		  same refcount block, so that we can tell exactly whether
		  we need a new refcount block or not.
		 
		  If we will insert a new one, this is easy and only happens
		  during adding refcounted flag to the extent, so we don't
		  have a chance of spliting. We just need one record.
		 
		  If the refcount rec already exists, that would be a little
		  complicated. we may have to:
		  1) split at the beginning if the start pos isn't aligned.
		     we need 1 more record in this case.
		  2) split int the end if the end pos isn't aligned.
		     we need 1 more record in this case.
		  3) split in the middle because of file system fragmentation.
		     we need 2 more records in this case(we can't detect this
		     beforehand, so always think of the worst case).
 Check whether we need a split at the beginning. 
 Check whether we need a split in the end. 
	
	  So we may need ref_blocks to insert into the tree.
	  That also means we need to change the b-tree and add that number
	  of records since we never merge them.
	  We need one more block for expansion since the new created leaf
	  block is also full and needs split.
  For refcount tree, we will decrease some contiguous clusters
  refcount count, so just go through it to see how many blocks
  we gonna touch and whether we need to create new blocks.
  Normally the refcount blocks store these refcount should be
  contiguous also, so that we can get the number easily.
  We will at most add split 2 refcount records and 2 more
  refcount blocks, so just check it in a rough way.
  Caller must hold refcount tree lock.
  Given an extent that starts at 'start' and an IO that starts at 'cpos',
  find an offset (start + (n  contig_clusters)) that is closest to cpos
  while still being less than or equal to it.
  The goal is to break the extent at a multiple of contig_clusters.
  Given a cluster count of len, pad it out so that it is a multiple
  of contig_clusters.
 Did we wrap? 
  Calculate out the start and number of virtual clusters we need to to CoW.
  cpos is vitual start cluster position we want to do CoW in a
  file and write_len is the cluster length.
  max_cpos is the place where we want to stop CoW intentionally.
  Normal we will start CoW from the beginning of extent record cotaining cpos.
  We try to break up extents on boundaries of MAX_CONTIG_BYTES so that we
  get good IO from the resulting extent tree.
			
			  We should find a refcounted record in the
			  first pass.
		
		  If we encounter a hole, a non-refcounted record or
		  pass the max_cpos, stop the search.
		
		  How many clusters do we actually need from
		  this extent?  First we see how many we actually
		  need to complete the write.  If that's smaller
		  than contig_clusters, we try for contig_clusters.
		
		  If the write does not cover the whole extent, we
		  need to calculate how we're going to split the extent.
		  We try to do it on contig_clusters boundaries.
		 
		  Any extent smaller than contig_clusters will be
		  CoWed in its entirety.
			
			  This extent needs to be CoW'd from its
			  beginning, so all we have to do is compute
			  how many clusters to grab.  We align
			  want_clusters to the edge of contig_clusters
			  to get better IO.
			
			  Breaking off contig_clusters at the front
			  of the extent will cover our write.  That's
			  easy.
			
			  Breaking off contig_clusters at the tail of
			  this extent will cover cpos.
			
			  While we can't fit the entire write in this
			  extent, we know that the write goes from cpos
			  to the end of the extent.  Break that off.
			  We try to break it at some multiple of
			  contig_clusters from the front of the extent.
			  Failing that (ie, cpos is within
			  contig_clusters of the front), we'll CoW the
			  entire extent.
			
			  Ok, the entire write lives in the middle of
			  this extent.  Let's try to slice the extent up
			  nicely.  Optimally, our CoW region starts at
			  mcontig_clusters from the beginning of the
			  extent and goes for ncontig_clusters,
			  covering the entire write.
 Have we covered our entire write yet? 
		
		  If we reach the end of the extent block and don't get enough
		  clusters, continue with the next extent block if possible.
  Prepare meta_ac, data_ac and calculate credits when we want to add some
  num_clusters in data_tree "et" and change the refcount for the old
  clusters(starting form p_cluster) in the refcount tree.
  Note:
  1. since we may split the old tree, so we at most will need num_clusters + 2
     more new leaf records.
  2. In some case, we may not need to reserve new clusters(e.g, reflink), so
     just give data_ac = NULL.
	
	  We only duplicate pages until we reach the page contains i_size - 1.
	  So trim 'end' to i_size.
 from, to is the offset within the page. 
		
		  In case PAGE_SIZE <= CLUSTER_SIZE, we do not expect a dirty
		  page, so write it back.
				
				  write_on_page will unlock the page on return
If the old clusters is unwritten, no need to duplicate. 
		
		  There are many different situation here.
		  1. If refcount == 1, remove the flag and don't COW.
		  2. If refcount > 1, allocate clusters.
		     Here we may not allocate r_len once at a time, so continue
		     until we reach num_clusters.
 handle any post_cow action. 
	
	  Here we should write the new page out first if we are
	  in write-back mode.
  Starting at cpos, try to CoW write_len clusters.  Don't CoW
  past max_cpos.  This will stop when it runs into a hole or an
  unrefcounted extent.
	
	  truncate the extent map here since no matter whether we meet with
	  any error during the action, we shouldn't trust cached extent map
	  any more.
  CoW any and all clusters between cpos and cpos+write_len.
  Don't CoW past max_cpos.  If this returns successfully, all
  clusters between cpos and cpos+write_len are safe to modify.
  Given a xattr value root, calculate the most metacredits we need for
  refcount tree change if we truncate it to 0.
			
			  We really don't know whether the other clusters is in
			  this refcount block or not, so just take the worst
			  case that all the clusters are in this block and each
			  one will split a refcount rec, so totally we need
			  clusters  2 new refcount rec.
  Do CoW for xattr.
 We need the extra credits for duplicate_clusters by jbd. 
  Insert a new extent into refcount tree and mark a extent rec
  as refcounted in the dinode tree.
 We need to be able to handle at least an extent tree split. 
	
	  Empty the extent map so that we may get the right extent
	  record from the disk.
  change the new file's attributes to the src.
  reflink creates a snapshot of a file, that means the attributes
  must be identical except for three exceptions - nlink, ino, and ctime.
		
		  update time.
		  we want mtime to appear identical to the source and
		  update ctime.
 If the security isn't preserved, we need to re-initialize them. 
		
		  We need to open_unlock the inode no matter whether we
		  succeed or not, so that other nodes can delete it later.
  Below here are the bits used by OCFS2_IOC_REFLINK() to fake
  sys_reflink().  This will go away when vfs_reflink() exists in
  fsnamei.c.
 copied from may_create in VFS. 
  ocfs2_vfs_reflink - Create a reference-counted link
  @old_dentry:        source dentry + inode
  @dir:       directory to create the target
  @new_dentry:        target dentry
  @preserve:  if true, preserve all file attributes
	
	  A reflink to an append-only or immutable file cannot be created.
 Only regular files can be reflinked. 
	
	  If the caller wants to preserve ownership, they require the
	  rights to do so.
	
	  If the caller is modifying any aspect of the attributes, they
	  are not creating a snapshot.  They need read permission on the
	  file.
  Most codes are copied from sys_linkat.
 Update destination inode size, if necessary. 
 Extend i_size if needed. 
 Remap the range pos_in:len in s_inode to pos_out:len in t_inode. 
 Look up the extent. 
 Punch out the dest range. 
 Lock the refcount btree... 
 Mark s_inode's extent as refcounted. 
 Map in the new extent. 
 Set up refcount tree and remap s_inode to t_inode. 
	
	  If we're reflinking the entire file and the source is inline
	  data, just copy the contents.
	
	  If both inodes belong to two different refcount groups then
	  forget it because we don't know how (or want) to go merging
	  refcount trees.
 Neither inode has a refcount tree.  Add one to s_inode. 
 Ensure that both inodes end up with the same refcount tree. 
 Turn off inline data in the dest file. 
 Actually remap extents now. 
 Lock an inode and grab a bh pointing to the inode. 
 First grab the VFS and rw locks. 
 Now go for the cluster locks 
 We always want to lock the one with the lower lockid first. 
 lock id1 
 lock id2 
	
	  If we swapped inode order above, we have to swap the buffer heads
	  before passing them back to the caller.
 Unlock both inodes and release buffers. 
 SPDX-License-Identifier: GPL-2.0-or-later
  suballoc.c
  metadata alloc and free
  Inspired by ext3 block groups.
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
	u64		sr_bg_blkno;	 The bg we allocated from.  Set
					   to 0 when a block group is
	u64		sr_bg_stable_blkno; 
					      Doesn't change, always
					      set to target block
					      group descriptor
					      block.
 The first allocated block 
 The bit in the bg 
 How many bits we claimed 
 In resize, we may meet the case bg_chain == cl_next_free_rec. 
  This version only prints errors.  It does not fail the filesystem, and
  exists only for resize.
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
	
	  Errors after here are fatal.
 If ocfs2_read_block() got us a new bh, pass it up. 
 set the 1st bit in the bitmap to account for the descriptor block 
	 There is no need to zero out or otherwise initialize the
	  other blocks in a group - All valid FS metadata in a block
	  group stores the superblock fs_generation value at
 setup the group 
		
		  We have used up all the extent rec but can't fill up
		  the cpg. So bail out.
 Try all the clusters to free 
	
	  We're going to be grabbing from multiple cluster groups.
	  We don't have enough credits to relink them all, and the
	  cluster groups will be staying in cache for the duration of
	  this operation.
 Claim the first region 
 setup the group 
  We expect the block group allocator to already be locked.
 save the new last alloc group so that the caller can cache it. 
	 The bh was validated by the inode read inside
 cluster bitmap never grows 
 You should never ask for this much metadata 
 Start to steal resource from the first slot after ours. 
	
	  stat(2) can't handle i_ino > 32bits, so we tell the
	  lower levels not to allocate us a block group past that
	  limit.  The 'inode64' mount option avoids this behavior.
	
	  slot is set when we successfully steal inode from other nodes.
	  It is reset in 3 places:
	  1. when we flush the truncate log
	  2. when we complete local alloc recovery.
	  3. when we successfully allocate from our own slot.
	  After it is set, we will go on stealing inodes until we find the
	  need to check our slots to see whether there is some space for us.
		
		  Some inodes must be freed by us, so try to allocate
		  from our own next time.
 local alloc code has to do the same thing, so rather than do this
 Callers don't need to care which bitmap (local alloc or main) to
  use so we figure it out for them, but unfortunately this clutters
 Retry if there is sufficient space cached in truncate log 
  More or less lifted from ext3. I'll leave their description below:
  "For ext3 allocations, we must not reuse any blocks which are
  allocated in the bitmap buffer's "last committed data" copy.  This
  prevents deletes from freeing up the page for reuse until we have
  committed the delete transaction.
  If we didn't do this, then deleting something and reallocating it as
  data would allow the old block to be overwritten before the
  transaction committed (because we force data to disk before commit).
  This would lead to corruption if we crashed between overwriting the
  data and committing the delete.
  @@@ We may want to make this allocation behaviour conditional on
  data-writes at some point, and disable it for metadata allocations or
  sync-data inodes."
  Note: OCFS2 already does this differently for metadata vs data
  allocations, as those bitmaps are separate and undo access is never
  called on a metadata group descriptor.
	 Callers got this descriptor from
			 We found a zero, but we can't use it as it
 we found a zero 
 move start to the next bit to test 
 got a zero after some ones 
 we got everything we needed 
 mlog(0, "Found it all!\n"); 
		 No error log here -- see the comment above
	 All callers get the descriptor via
 find the one with the most empty bits 
	 there is a really tiny chance the journal calls could fail,
	 The caller got these descriptors from
 return 0 on success, -ENOSPC to keep searching and any other < 0
		 Tail groups in cluster bitmaps which aren't cpg
		  aligned are prone to partial extension by a failed
		  fs resize. If the file system resize never got to
		  update the dinode cluster count, then we don't want
		  to trust any clusters past it, regardless of what
		 ocfs2_block_group_find_clear_bits() might
		  return success, but we still want to return
		  -ENOSPC unless it found the minimum number
 success 
			
			  Don't show bits which we'll be returning
			  for allocation to the local alloc bitmap.
 Save off 
 Clear it for contig block groups 
 Restore 
	
	  sr_bg_blkno might have been changed by
	  ocfs2_bg_discontig_fix_result
	 for now, the chain search is a bit simplistic. We just use
	
	  sr_bg_blkno might have been changed by
	  ocfs2_bg_discontig_fix_result
	
	  Keep track of previous block descriptor read. When
	  we find a target, if we have read more than X
	  number of descriptors, and the target is reasonably
	  empty, relink him to top of his chain.
	 
	  We've read 0 extra blocks and only send one more to
	  the transaction, yet the next guy to search has a
	  much easier time.
	 
	  Do this after figuring out how many bits we're taking out
	  of our target group.
 will give out up to bits_wanted contiguous bits. 
	 The bh was validated by the inode read during
		 Attempt to short-circuit the usual search mechanism
		  by jumping straight to the most recently used
		  allocation group. This helps us maintain some
	 If we didn't pick a good victim, then just default to
	  searching each chain in order. Don't allow chain relinking
	  because we only calculate enough journal credits for one
		 If the next search of this group is not likely to
		  yield a suitable extent, then we reset the last
	
	  Try to allocate inodes from some specific group.
	 
	  If the parent dir has recorded the last group used in allocation,
	  cool, use it. Otherwise if we try to allocate new inode from the
	  same slot the parent dir belongs to, use the same chunk.
	 
	  We are very careful here to avoid the mistake of setting
	  ac_last_group to a group descriptor from a different (unlocked) slot.
	
	  The handle started here is for chain relink. Alternatively,
	  we could just disable relink for these calls.
	
	  This will instruct ocfs2_claim_suballoc_bits and
	  ocfs2_search_one_group to search but save actual allocation
	  for later.
	
	  Since di_blkno is being passed back in, we check for any
	  inconsistencies which may have happened between
	  calls. These are code bugs as di_blkno is not expected to
	  change once returned from ocfs2_find_new_inode_loc()
 translate a group desc. blkno and it's bitmap offset into
 given a cluster offset, calculate which block group it belongs to
 given the block number of a cluster start, calculate which cluster
  min_bits - minimum contiguous chunk from this total allocation we
  can handle. set to what we asked for originally for a full
  contig. allocation, set to '1' to indicate we can deal with extents
  of any size.
			 The only paths asking for contiguousness
 clamp the current request down to a realistic size. 
 cluster alloc can't set 
	 The caller got this descriptor from
  expects the suballoc inode to already be locked.
	 The alloc_bh comes from ocfs2_free_dinode() or
	  ocfs2_free_clusters().  The callers have all locked the
	  allocator and gotten alloc_bh from the lock call.  This
	  validates the dinode buffer.  Any corruption that has happened
	 You can't ever have a contiguous set of clusters
	  bigger than a block group bitmap so we never have to worry
	  about looping on them.
	  This is expensive. We can safely remove once this stuff has
  Give never-used clusters back to the global bitmap.  We don't need
  to protect these bits in the undo buffer.
  For a given allocation, determine which allocators will need to be
  accessed, and lock them, reserving the appropriate number of bits.
  Sparse file systems call this from ocfs2_write_begin_nolock()
  and ocfs2_allocate_unwritten_extents().
  File systems which don't support holes call this from
  ocfs2_extend_allocation().
	
	  Sparse allocation file systems need to be more conservative
	  with reserving room for expansion - the actual allocation
	  happens while we've got a journal handle open so re-taking
	  a cluster lock (because we ran out of room for another
	  extent) will violate ordering rules.
	 
	  Most of the time we'll only be seeing this 1 cluster at a time
	  anyway.
	 
	  Always lock for any unwritten extents - we might want to
	  add blocks during a split.
		
		  We cannot have an error and a non null data_ac.
  Read the inode specified by blkno to get suballoc_slot and
  suballoc_bit.
 dirty read disk 
  test whether bit is SET in allocator bitmap or not.  on success, 0
  is returned and res is 1 for SET; 0 otherwise.  when fails, errno
  is returned and res is meaningless.  Call this after you have
  cluster locked against suballoc, or you may get a result based on
  non-up2date contents
  Test if the bit representing this inode (blkno) is set in the
  suballocator.
  On success, 0 is returned and res is 1 for SET; 0 otherwise.
  In the event of failure, a negative value is returned and res is
  meaningless.
  Callers must make sure to hold nfs_sync_lock to prevent
  ocfs2_delete_inode() on another node from accessing the same
  suballocator concurrently.
		 the error code could be inaccurate, but we are not able to
 SPDX-License-Identifier: GPL-2.0-or-later
  resize.c
  volume resize.
  Inspired by ext3resize.c.
  Copyright (C) 2007 Oracle.  All rights reserved.
  Check whether there are new backup superblocks exist
  in the last group. If there are some, mark them or clear
  them in the bitmap.
  Return how many backups we find in the last group.
 check if already done backup super 
 update the group first. 
	
	  check whether there are some new backup superblocks exist in
	  this group and update the group bitmap accordingly.
 update the inode accordingly. 
 calculate the real backups we need to update. 
	
	  update the superblock last.
	  It doesn't matter if the write failed.
  Extend the filesystem to the new number of clusters specified.  This entry
  point is only used to extend the current filesystem to the end of the last
  existing group.
	 main_bm_bh is validated by inode read inside ocfs2_inode_lock(),
 update the last group descriptor and inode. 
 Add a new group descriptor to global_bitmap. 
 SPDX-License-Identifier: GPL-2.0-or-later
  localalloc.c
  Node local data allocation
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
  ocfs2_la_default_mb() - determine a default size, in megabytes of
  the local alloc.
  Generally, we'd like to pick as large a local alloc as
  possible. Performance on large workloads tends to scale
  proportionally to la size. In addition to that, the reservations
  code functions more efficiently as it can reserve more windows for
  write.
  Some things work against us when trying to choose a large local alloc:
  - We need to ensure our sizing is picked to leave enough space in
    group descriptors for other allocations (such as block groups,
    etc). Picking default sizes which are a multiple of 4 could help
    - block groups are allocated in 2mb and 4mb chunks.
  - Likewise, we don't want to starve other nodes of bits on small
    file systems. This can easily be taken care of by limiting our
    default to a reasonable size (256M) on larger cluster sizes.
  - Some file systems can't support very large sizes - 4k and 8k in
    particular are limited to less than 128 and 256 megabytes respectively.
  The following reference table shows group descriptor and local
  alloc maximums at various cluster sizes (4k blocksize)
  csize: 4K	group: 126M	la: 121M
  csize: 8K	group: 252M	la: 243M
  csize: 16K	group: 504M	la: 486M
  csize: 32K	group: 1008M	la: 972M
  csize: 64K	group: 2016M	la: 1944M
  csize: 128K	group: 4032M	la: 3888M
  csize: 256K	group: 8064M	la: 7776M
  csize: 512K	group: 16128M	la: 15552M
  csize: 1024K	group: 32256M	la: 31104M
	
	  This takes care of files systems with very small group
	  descriptors - 512 byte blocksize at cluster sizes lower
	  than 16K and also 1k blocksize with 4k cluster size.
	
	  Leave enough room for some block groups and make the final
	  value we work from a multiple of 4.
	
	  Keep window sizes down to a reasonable default
		
		  Some clustersize  blocksize combinations will have
		  given us a larger than OCFS2_LA_MAX_DEFAULT_MB
		  default size, but get poor distribution when
		  limited to exactly 256 megabytes.
		 
		  As an example, 16K clustersize at 4K blocksize
		  gives us a cluster group size of 504M. Paring the
		  local alloc size down to 256 however, would give us
		  only one window and around 200MB left in the
		  cluster group. Instead, find the first size below
		  256 which would give us an even distribution.
		 
		  Larger cluster group sizes actually work out pretty
		  well when pared to 256, so we don't have to do this
		  for any group that fits more than two
		  OCFS2_LA_MAX_DEFAULT_MB windows.
 Too many nodes, too few disk clusters. 
 We can't store more bits than we can in a block. 
 No user request - use defaults 
 Request is too big, we give the maximum available 
  Tell us whether a given allocation should use the local alloc
  file. Otherwise, it has to go to the main bitmap.
  This function does semi-dirty reads of local alloc size and state!
  This is ok however, as the values are re-checked once under mutex.
	 la_bits should be at least twice the size (in clusters) of
	  a new block group. We want to be sure block group
	  allocations go through the local alloc, so allow an
 read the alloc off disk 
 do a little verification. 
	 hopefully the local alloc has always been recovered before
  return any unused bits to the bitmap and write out a clean
  local_alloc.
  local_alloc_bh is optional. If not passed, we will simply use the
  one off osb. If you do pass it however, be warned that it will be
 WINDOW_MOVE_CREDITS is a bit heavy... 
  We want to free the bitmap bits outside of any recovery context as
  we'll need a cluster lock to do so, but we must clear the local
  alloc before giving up the recovered nodes journal. To solve this,
  we kmalloc a copy of the local alloc before it's change for the
  caller to process with ocfs2_complete_local_alloc_recovery
  Step 2: By now, we've completed the journal recovery, we've stamped
  a clean local alloc on disk and dropped the node out of the
  recovery map. Dlm locks will no longer stall, so lets clear out the
  main bitmap.
 we want the bitmap change to be recorded on disk asap 
  make sure we've got at least bits_wanted contiguous bits in the
  local alloc. You lose them when you drop i_mutex.
  We will add ourselves to the transaction passed in, but may start
  our own in order to shift windows.
	
	  We must double check state and allocator bits because
	  another process may have changed them while holding i_mutex.
 uhoh, window change time. 
		
		  Under certain conditions, the window slide code
		  might have reduced the number of bits available or
		  disabled the local alloc entirely. Re-check
		  here and return -ENOSPC if necessary.
 We should never use localalloc from another slot 
 TODO: Shouldn't we just BUG here? 
	
	  Code error. While reservations are enabled, local
	  allocation should _always_ go through them.
	
	  Reservations are disabled. Handle this the old way.
 mlog(0, "bitoff (%d) == left", bitoff); 
		 mlog(0, "Found a zero: bitoff = %d, startoff = %d, "
		 Ok, we found a zero bit... is it contig. or do we
 we found a zero 
 got a zero after some ones 
 we got everything we needed 
 mlog(0, "Found it all!\n"); 
 turn this on and uncomment below to aid debugging window shifts. 
  sync the local alloc to main bitmap.
  assumes you've already locked the main bitmap -- the bitmap inode
  passed is used for caching.
 Normal window slide. 
	OCFS2_LA_EVENT_FRAGMENTED,	 The global bitmap has
					  enough bits theoretically
					  free, but a contiguous
					  allocation could not be
	OCFS2_LA_EVENT_ENOSPC,		 Global bitmap doesn't have
					  enough bits free to satisfy
  Given an event, calculate the size of our next local alloc window.
  This should always be called under i_mutex of the local alloc inode
  so that local alloc disabling doesn't race with processes trying to
  use the allocator.
  Returns the state which the local alloc was left in. This value can
  be ignored by some paths.
	
	  ENOSPC and fragmentation are treated similarly for now.
		
		  We ran out of contiguous space in the primary
		  bitmap. Drastically reduce the number of bits used
		  by local alloc until we have to disable it.
			
			  By setting state to THROTTLED, we'll keep
			  the number of local alloc bits used down
			  until an event occurs which would give us
			  reason to assume the bitmap situation might
			  have changed.
	
	  Don't increase the size of the local alloc window until we
	  know we might be able to fulfill the request. Otherwise, we
	  risk bouncing around the global bitmap during periods of
	  low space.
  pass it the bitmap lock in lock_bh if you have it.
	 Instruct the allocation code to try the most recently used
	  cluster group. We'll re-record the group used this pass
	 we used the generic suballoc reserve function, but we set
	  everything up nicely, so there's no reason why we can't use
		
		  Note: We could also try syncing the journal here to
		  allow use of any free bits which the current
		  transaction can't give us access to. --Mark
		
		  We only shrunk the minimum number of in our
		  request - it's entirely possible that the allocator
		  might give us more than we asked for.
	 just in case... In the future when we find space ourselves,
	  we don't have to get all contiguous -- but we'll have to
	  set all previously used bits in bitmap and update
 Note that we do NOT lock the local alloc inode here as
 This will lock the main bitmap for us. 
	 We want to clear the local alloc before doing anything
	  else, so that if we error later during this operation,
	  local alloc shutdown won't try to double free main bitmap
	  bits. Make a copy so the sync function knows which bits to
 SPDX-License-Identifier: GPL-2.0-only
  move_extents.c
  Copyright (C) 2011 Oracle.  All rights reserved.
	
	  after movingdefraging to new location, the extent is not going
	  to be refcounted anymore.
	
	  need I to append truncate log for old clusters?
  lock allocator, and reserve appropriate number of bits for
  meta blocks.
  Using one journal handle to guarantee the data consistency in case
  crash happens anywhere.
   XXX: defrag can end up with finishing partial extent as requested,
  due to not enough contiguous clusters can be found in allocator.
	
	  should be using allocation reservation strategy there?
	 
	  if (context->data_ac)
	 	context->data_ac->ac_resv = &OCFS2_I(inode)->ip_la_data_resv;
	
	  Make sure ocfs2_reserve_cluster is called after
	  __ocfs2_flush_truncate_log, otherwise, dead lock may happen.
	 
	  If ocfs2_reserve_cluster is called
	  before __ocfs2_flush_truncate_log, dead lock on global bitmap
	  may happen.
	 
	
	  allowing partial extent moving is kind of 'pros and cons', it makes
	  whole defragmentation less likely to fail, on the contrary, the bad
	  thing is it may make the fs even more fragmented after moving, let
	  userspace make a good decision here.
	
	  Here we should write the new page out first if we are
	  in write-back mode.
  find the victim alloc group, where #blkno fits.
	
	  'vict_blkno' was out of the valid range.
	
	  caller has to release the gd_bh properly.
  XXX: helper to validate and adjust moving goal.
	
	  make goal become cluster aligned.
	
	  validate goal sits within global_bitmap, and return the victim
	  group desc
	
	  moving goal is not allowd to start with a group desc blok(#0 blk)
	  let's compromise to the latter cluster.
	
	  movement is not gonna cross two groups.
	
	  more exact validationsadjustments will be performed later during
	  moving operation for each extent range.
			
			  we even tried searching the free chunk by jumping
			  a 'max_hop' distance, but still failed.
	
	  need to count 2 extra credits for global_bitmap inode and
	  group descriptor.
	
	  ocfs2_move_extent() didn't reserve any clusters in lock_allocators()
	  logic, while we still need to lock the global_bitmap.
	
	  probe the victim cluster group to find a proper
	  region to fit wanted movement, it even will perfrom
	  a best-effort attempt by compromising to a threshold
	  around the goal.
	
	  Here we should write the new page out first if we are
	  in write-back mode.
  Helper to calculate the defraging length in one run according to threshold.
		
		  proceed defragmentation until we meet the thresh
		
		  XXX: skip a large extent.
		
		  split this extent to coalesce with former pieces as
		  to reach the threshold.
		 
		  we're done here with one cycle of defragmentation
		  in a size of 'thresh', resetting 'len_defraged'
		  forces a new defragmentation.
	
	  TO-DO XXX:
	 
	  - xattr extents.
	
	  extents moving happens in unit of clusters, for the sake
	  of simplicity, we may ignore two clusters where 'byte_start'
	  and 'byte_start + len' were within.
		
		  XXX: how to deal with a hole:
		 
		  - skip the hole of course
		  - force a new defragmentation
			
			  skip large extents
	
	  This prevents concurrent writes from other nodes
	
	  rememer ip_xattr_sem also needs to be held if necessary
	
	  We update ctime for these changes
		
		  ok, the default theshold for the defragmentation
		  is 1M, since our maximum clustersize was 1M also.
		  any thought?
		
		  first best-effort attempt to validate and adjust the goal
		  (physical address in block), while it can't guarantee later
		  operation can succeed all the time since global_bitmap may
		  change a bit over time.
	
	  movementdefragmentation may end up being partially completed,
	  that's the reason why we need to return userspace the finished
	  length and new_offset even if failure happens somewhere.
 SPDX-License-Identifier: GPL-2.0-or-later
  file.c
  File open, close, extend, truncate
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
	 Check that the inode hasn't been wiped from disk by another
	  node. If it hasn't then we're safe as long as we hold the
		
		  We want to set open count back if we're failing the
		  open.
	
	  We can be called with no vfsmnt structure - NFSD will
	  sometimes do this.
	 
	  Note that our action here is different than touch_atime() -
	  if we can't tell whether this is a noatime mount, then we
	  don't know whether to trust the value of s_atime_quantum.
	
	  Don't use ocfs2_mark_inode_dirty() here as we don't always
	  have i_mutex to guard against concurrent changes to other
	  inode fields.
	
	  If the new offset is aligned to the range of the cluster, there is
	  no space for ocfs2_zero_range_for_truncate to fill, so no need to
	  CoW either.
	
	  We need to CoW the cluster contains the offset if it is reflinked
	  since we will call ocfs2_zero_range_for_truncate later which will
	  write "0" from offset to the end of the cluster.
	 TODO: This needs to actually orphan the inode in this
	
	  Do this before setting i_size.
	 We trust di_bh because it comes from ocfs2_inode_lock(), which
	
	  The inode lock forced other nodes to sync and drop their
	  pages, which (correctly) happens even if we have a truncate
	  without allocation change - ocfs2 cluster sizes can be much
	  greater than page size, so we have to truncate them
	  anyway.
	 alright, we're going to need to do a full blown alloc size
	  change. Orphan the inode so that recovery can complete the
	  truncate if necessary. This does the task of marking
 TODO: orphan dir cleanup here. 
  extend file allocation only here.
  we'll update all the disk stuff, and oip->alloc_size
  expect stuff to be locked, a transaction started and enough data 
  metadata reservations in the contexts.
  Will return -EAGAIN, and a reason if a restart is needed.
  If passed in, reason will always be set, even in error.
	
	  Unwritten extent only exists for file systems which
	  support holes.
	 reserve a write to the file entry early on - that we if we
	  run out of credits in the allocation path, we can still
 Release unused quota reservation 
				 handle still has to be committed at
  While a write will already be ordering the data, a truncate will not.
  Thus, we need to explicitly order the zeroed pages.
 Some parts of this taken from generic_cont_expand, which turned out
  to be too fragile to do exactly what we need without us having to
 Get the offsets within the page that we want to zero 
 We know that zero_from is block aligned 
		
		  block_start is block-aligned.  Bump it by one to force
		  __block_write_begin and block_commit_write to zero the
		  whole block.
 must not update i_size! 
	
	  fs-writeback will release the dirty pages without page lock
	  whose offset are over inode size, the release happens at
	  block_write_full_page().
  Find the next range to zero.  We do this in terms of bytes because
  that's what ocfs2_zero_extend() wants, and it is dealing with the
  pagecache.  We may return multiple extents.
  zero_start and zero_end are ocfs2_zero_extend()s current idea of what
  needs to be zeroed.  range_start and range_end return the next zeroing
  range.  A subsequent call should pass the previous range_end as its
  zero_start.  If range_end is 0, there's nothing to do.
  Unwritten extents are skipped over.  Refcounted extents are CoWd.
  Zero one range returned from ocfs2_zero_extend_get_range().  The caller
  has made sure that the entire range needs zeroing.
		
		  Very large extends have the potential to lock up
		  the cpu for extended periods of time.
 Trim the ends 
	
	  Only quota files call this without a bh, and they can't be
	  refcounted.
	
	  Call this even if we don't add any clusters to the tree. We
	  still need to zero the area between the old i_size and the
	  new i_size.
 setattr sometimes calls us like this. 
	
	  The alloc sem blocks people in readwrite from reading our
	  allocation until we're done changing it. We depend on
	  i_mutex to block other extendtruncate calls while we're
	  here.  We even have to hold it for sparse files because there
	  might be some tail zeroing.
		
		  We can optimize small extends by keeping the inodes
		  inline data.
 ensuring we don't even attempt to truncate a symlink 
		
		  Here we should wait dio to finish before inode lock
		  to avoid a deadlock between ocfs2_setattr() and
		  ocfs2_dio_end_io_write()
		
		  As far as we know, ocfs2_setattr() could only be the first
		  VFS entry point in the call chain of recursive cluster
		  locking issue.
		 
		  For instance:
		  chmod_common()
		   notify_change()
		    ocfs2_setattr()
		     posix_acl_chmod()
		      ocfs2_iop_get_acl()
		 
		  But, we're not 100% sure if it's always true, because the
		  ordering of the VFS entry points in the call chain is out
		  of our control. So, we'd better dump the stack here to
		  catch the other cases of recursive locking.
		
		  Gather pointers to quota structures so that allocation 
		  freeing of quota structures happens here and not inside
		  dquot_transfer() where we have problems with lock ordering
 Release quota pointers in case we acquired them 
	
	  If there is inline data in the inode, the inode will normally not
	  have data blocks allocated (it may have an external xattr block).
	  Report at least one sector for such files, so tools like tar, rsync,
	  others don't incorrectly think the file is completely sparse.
 We set the blksize from the cluster size for performance 
		 See comments in ocfs2_setattr() for details.
		  The call chain of this case could be:
		  do_sys_open()
		   may_open()
		    inode_permission()
		     ocfs2_permission()
		      ocfs2_iop_get_acl()
  Allocate enough extents to cover the region starting at byte offset
  start for len bytes. Existing extents are skipped, any extents
  added are marked as "unwritten".
		
		  Nothing to do if the requested reservation range
		  fits within the inode.
	
	  We consider both start and len to be inclusive.
		
		  Hole or existing extent len can be arbitrary, so
		  cap it to our own allocation request.
			
			  We already have an allocation at this
			  region so we can safely skip it.
  Truncate a byte range, avoiding pages within partial clusters. This
  preserves those pages for the zeroing code to write to.
  zero out partial blocks of one cluster.
  start: file offset where zero starts, will be made upper block aligned.
  len: it will be trimmed to the end of current cluster if "start + len"
       is bigger than it.
	
	  The "start" and "end" values are NOT necessarily part of
	  the range whose allocation is being deleted. Rather, this
	  is what the user passed in with the request. We must zero
	  partial clusters here. There's no need to worry about
	  physical allocation - the zeroing code knows to skip holes.
	
	  If both edges are on a cluster boundary then there's no
	  zeroing required as the region is part of the allocation to
	  be truncated.
 No page cache for EOF blocks, issue zero out to disk. 
		
		  zeroout eof blocks in last cluster starting from
		  "isize" even "start" > "isize" because it is
		  complicated to zeroout just at "start" as "start"
		  may be not aligned with block size, buffer write
		  would be required to do that, but out of eof buffer
		  write is not supported.
	
	  If start is on a cluster boundary and end is somewhere in another
	  cluster, we have not COWed the cluster starting at start, unless
	  end is also within the same cluster. So, in this case, we skip this
	  first call to ocfs2_zero_range_for_truncate() truncate and move on
	  to the next one.
		
		  We want to get the byte offset of the end of the 1st
		  cluster.
		
		  This may make start and end equal, but the zeroing
		  code will skip any work in that case so there's no
		  need to catch it up here.
  Helper to calculate the punching pos and length in one run, we handle the
  following three cases in order:
  - remove the entire record
  - remove a partial record
  - no record needs to be removed (hole-punching completed)
		
		  remove an entire extent record.
		
		  Skip holes if any.
		
		  remove a partial extent record, which means we're
		  removing the last extent record.
		
		  skip hole if any.
		
		  It may have two following possibilities:
		 
		  - last record has been removed
		  - trunc_start was within a hole
		 
		  both two cases mean the completion of hole punching.
		
		  There's no need to get fancy with the page cache
		  truncate of an inline-data inode. We're talking
		  about less than a page here, which will be cached
		  in the dinode buffer anyway.
	
	  For reflinks, we may need to CoW 2 clusters which might be
	  partially zero'd later, if hole's start and end offset were
	  within one cluster(means is not exactly aligned to clustersize).
		
		  Need to go to previous extent block.
			
			  We've reached the leftmost extent block,
			  it's safe to leave.
			
			  The 'pos' searched for previous extent block is
			  always one cluster less than actual trunc_end.
  Parts of this function taken from xfs_change_file_space()
	
	  This prevents concurrent writes on other nodes
SEEK_SET
SEEK_CUR
SEEK_END
		
		  This takes unsigned offsets, but the signed ones we
		  pass have been checked against overflow above.
 zeroout eof blocks in the cluster. 
	
	  We update cmtime for these changes
	
	  We start with a read level meta lock and only jump to an ex
	  if we need to make modifications here.
		
		  Check if IO will overwrite allocated blocks in case
		  IOCB_NOWAIT flag is set.
		 Clear suid  sgid if necessary. We do this here
		  instead of later in the write path because
		  remove_suid() calls ->setattr without any hint that
		  we may have already done our cluster locking. Since
		  ocfs2_setattr() must take cluster locks to
		  proceed, this will lead us to recursively lock the
		  inode. There's also the dinode i_size state which
		  can be lost via setattr during extending writes (we
 GRRRRR 
	
	  Concurrent O_DIRECT writes are allowed with
	  mount_option "coherency=buffered".
	  For append write, we must take rw EX.
	
	  O_DIRECT writes with "coherency=full" need to take EX cluster
	  inode_lock to guarantee coherency.
		
		  We need to take and drop the inode lock to force
		  other nodes to drop their caches.  Buffered IO
		  already does this in write_begin().
		
		  Make it a sync io if it's an unaligned aio.
 communicate with ocfs2_dio_end_io 
 buffered aio wouldn't have proper lock coverage today 
	
	  deep in g_f_a_w_n()->ocfs2_direct_IO we pass in a ocfs2_dio_end_io
	  function pointer which is called when o_direct io completes so that
	  it can unlock our rw lock.
	  Unfortunately there are error cases which call end_io and others
	  that don't.  so we don't have to unlock the rw_lock if either an
	  async dio is going to do it in the future or an end_io after an
	  error has already done it.
 GRRRRR 
	
	  buffered reads protect themselves in ->readpage().  O_DIRECT reads
	  need locks to protect pending reads from racing with truncate.
 communicate with ocfs2_dio_end_io 
	
	  We're fine letting folks race truncates and extending
	  writes with read across the cluster, just like they can
	  locally. Hence no rw_lock during read.
	 
	  Take and drop the meta data lock to update inode fields
	  like i_size. This allows the checks down below
	  generic_file_read_iter() a chance of actually working.
 buffered aio wouldn't have proper lock coverage today 
 see ocfs2_file_write_iter 
 Refer generic_file_llseek_unlocked() 
		 SEEK_END requires the OCFS2 inode lock for the file
		  because it references the file's size.
 Lock both files against IO 
 Check file eligibility and prepare for block sharing. 
 Lock out changes to the allocation maps and remap. 
 Zap any page cache for the destination file's range. 
	
	  Empty the extent map so that we may get the right extent
	  record from the disk.
  Other than ->lock, keep ocfs2_fops and ocfs2_dops in sync with
  ocfs2_fops_no_plocks and ocfs2_dops_no_plocks!
  POSIX-lockless variants of our file_operations.
  These will be used if the underlying cluster stack does not support
  posix file locking, if the user passes the "localflocks" mount
  option, or if we have a local-only fs.
  ocfs2_flock is in here because all stacks handle UNIX file locks,
  so we still want it in the case of no stack support for
  plocks. Internally, it will do the right thing when asked to ignore
  the cluster.
 SPDX-License-Identifier: GPL-2.0-only
  blockcheck.c
  Checksum and ECC codes for the OCFS2 userspace library.
  Copyright (C) 2006, 2008 Oracle.  All rights reserved.
  We use the following conventions:
  d = # data bits
  p = # parity bits
  c = # total code bits (d + p)
  Calculate the bit offset in the hamming code buffer based on the bit's
  offset in the data buffer.  Since the hamming code reserves all
  power-of-two bits for parity, the data bit number and the code bit
  number are offset by all the parity bits beforehand.
  Recall that bit numbers in hamming code are 1-based.  This function
  takes the 0-based data bit from the caller.
  An example.  Take bit 1 of the data buffer.  1 is a power of two (2^0),
  so it's a parity bit.  2 is a power of two (2^1), so it's a parity bit.
  3 is not a power of two.  So bit 1 of the data buffer ends up as bit 3
  in the code buffer.
  The caller can pass in p if it wants to keep track of the most recent
  number of parity bits added.  This allows the function to start the
  calculation at the last place.
	
	  Data bits are 0-based, but we're talking code bits, which
	  are 1-based.
 Use the cache if it is there 
	
	  For every power of two below our bit number, bump our bit.
	 
	  We compare with (b + 1) because we have to compare with what b
	  would be _if_ it were bumped up by the parity bit.  Capice?
	 
	  p is set above.
  This is the low level encoder function.  It can be called across
  multiple hunks just like the crc32 code.  'd' is the number of bits
  _in_this_hunk_.  nr is the bit offset of this hunk.  So, if you had
  two 512B buffers, you would do it like so:
  parity = ocfs2_hamming_encode(0, buf1, 512  8, 0);
  parity = ocfs2_hamming_encode(parity, buf2, 512  8, 512  8);
  If you just have one buffer, use ocfs2_hamming_encode_block().
	
	  b is the hamming code bit number.  Hamming code specifies a
	  1-based array, but C uses 0-based.  So 'i' is for C, and 'b' is
	  for the algorithm.
	 
	  The i++ in the for loop is so that the start offset passed
	  to ocfs2_find_next_bit_set() is one greater than the previously
	  found bit.
		
		  i is the offset in this hunk, nr + i is the total bit
		  offset.
		
		  Data bits in the resultant code are checked by
		  parity bits that are part of the bit number
		  representation.  Huh?
		 
		  <wikipedia href="https:en.wikipedia.orgwikiHamming_code">
		  In other words, the parity bit at position 2^k
		  checks bits in positions having bit k set in
		  their binary representation.  Conversely, for
		  instance, bit 13, i.e. 1101(2), is checked by
		  bits 1000(2) = 8, 0100(2)=4 and 0001(2) = 1.
		  <wikipedia>
		 
		  Note that 'k' is the _code_ bit number.  'b' in
		  our loop.
	 While the data buffer was treated as little endian, the
  Like ocfs2_hamming_encode(), this can handle hunks.  nr is the bit
  offset of the current hunk.  If bit to be fixed is not part of the
  current hunk, this does nothing.
  If you only have one hunk, use ocfs2_hamming_fix_block().
	
	  If the bit to fix has an hweight of 1, it's a parity bit.  One
	  busted parity bit is its own error.  Nothing to do here.
	
	  nr + d is the bit right past the data hunk we're looking at.
	  If fix after that, nothing to do
	
	  nr is the offset in the data hunk we're starting at.  Let's
	  start b at the offset in the code buffer.  See hamming_encode()
	  for a more detailed description of 'b'.
 If the fix is before this hunk, nothing to do 
 Skip past parity bits 
		
		  i is the offset in this data hunk.
		  nr + i is the offset in the total data buffer.
		  b is the offset in the total code buffer.
		 
		  Thus, when b == fix, bit i in the current hunk needs
		  fixing.
  Debugfs handling.
 CONFIG_DEBUG_FS 
 Always-called wrappers for starting and stopping the debugfs files 
  These are the low-level APIs for using the ocfs2_block_check structure.
  This function generates check information for a block.
  data is the block to be checked.  bc is a pointer to the
  ocfs2_block_check structure describing the crc32 and the ecc.
  bc should be a pointer inside data, as the function will
  take care of zeroing it before calculating the check information.  If
  bc does not point inside data, the caller must make sure any inline
  ocfs2_block_check structures are zeroed.
  The data buffer must be in on-disk endian (little endian for ocfs2).
  bc will be filled with little-endian values and will be ready to go to
  disk.
	
	  No ecc'd ocfs2 structure is larger than 4K, so ecc will be no
	  larger than 16 bits.
  This function validates existing check information.  Like _compute,
  the function will take care of zeroing bc before calculating check codes.
  If bc is not a pointer inside data, the caller must have zeroed any
  inline ocfs2_block_check structures.
  Again, the data passed in should be the on-disk endian.
 Fast path - if the crc32 validates, we're good to go 
 Ok, try ECC fixups 
 And check the crc32 again 
  This function generates check information for a list of buffer_heads.
  bhs is the blocks to be checked.  bc is a pointer to the
  ocfs2_block_check structure describing the crc32 and the ecc.
  bc should be a pointer inside data, as the function will
  take care of zeroing it before calculating the check information.  If
  bc does not point inside data, the caller must make sure any inline
  ocfs2_block_check structures are zeroed.
  The data buffer must be in on-disk endian (little endian for ocfs2).
  bc will be filled with little-endian values and will be ready to go to
  disk.
		
		  The number of bits in a buffer is obviously b_size8.
		  The offset of this buffer is b_sizei, so the bit offset
		  of this buffer is b_size8i.
	
	  No ecc'd ocfs2 structure is larger than 4K, so ecc will be no
	  larger than 16 bits.
  This function validates existing check information on a list of
  buffer_heads.  Like _compute_bhs, the function will take care of
  zeroing bc before calculating check codes.  If bc is not a pointer
  inside data, the caller must have zeroed any inline
  ocfs2_block_check structures.
  Again, the data passed in should be the on-disk endian.
 Fast path - if the crc32 validates, we're good to go 
 Ok, try ECC fixups 
		
		  The number of bits in a buffer is obviously b_size8.
		  The offset of this buffer is b_sizei, so the bit offset
		  of this buffer is b_size8i.
		
		  Try the fix against each buffer.  It will only affect
		  one of them.
 And check the crc32 again 
  These are the main API.  They check the superblock flag before
  calling the underlying operations.
  They expect the buffer(s) to be in disk format.
 SPDX-License-Identifier: GPL-2.0-only
  stackglue.c
  Code which implements an OCFS2 specific interface to underlying
  cluster stacks.
  Copyright (C) 2007, 2009 Oracle.  All rights reserved.
  The stack currently in use.  If not null, active_stack->sp_count > 0,
  the module is pinned, and the locking protocol cannot be changed.
	
	  If the stack passed by the filesystem isn't the selected one,
	  we can't continue.
		
		  If the active stack isn't the one we want, it cannot
		  be selected right now.
 If we found it, pin it 
  This function looks up the appropriate stack and makes it active.  If
  there is no stack, it tries to load it.  It will fail if the stack still
  cannot be found.  It will also fail if a different stack is in use.
	
	  Classic stack does not pass in a stack name.  This is
	  compatible with older tools as well.
 Anything that isn't the classic stack is a user stack 
  The ocfs2_dlm_lock() and ocfs2_dlm_unlock() functions take no argument
  for the ast and bast functions.  They will pass the lksb to the ast
  and bast.  The caller can wrap the lksb with their own structure to
  get more information.
  ocfs2_plock() can only be safely called if
  ocfs2_stack_supports_plocks() returned true
 Start the new connection at our maximum compatibility level 
 This will pin the stack driver if successful 
 The caller will ensure all nodes have the same cluster stack 
 If hangup_pending is 0, the stack driver will be dropped 
 XXX Should we free it anyway? 
  Leave the group for this filesystem.  This is executed by a userspace
  program (stored in ocfs2_hb_ctl_path).
 minimal command environment taken from cpu_run_sbin_hotplug 
  Hangup is a required post-umount.  ocfs2-tools software expects the
  filesystem to call "ocfs2_hb_ctl" during unmount.  This happens
  regardless of whether the DLM got started, so we can't do it
  in ocfs2_cluster_disconnect().  The ocfs2_leave_group() function does
  the actual work.
 cluster_disconnect() was called with hangup_pending==1 
  Sysfs bits
 snprintf() didn't fit 
  Sysctl bits
  The sysctl lives at procsysfsocfs2nmhb_ctl_path.  The 'nm' doesn't
  make as much sense in a multiple cluster stack world, but it's safer
  and easier to preserve the name.
  Initialization
 or something. 
   linuxclusterssicfssymlink.c
 	This program is free software; you can redistribute it andor
 	modify it under the terms of the GNU General Public License as
 	published by the Free Software Foundation; either version 2 of
 	the License, or (at your option) any later version.
 	This program is distributed in the hope that it will be useful,
 	but WITHOUT ANY WARRANTY; without even the implied warranty of
 	MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE
 	or NON INFRINGEMENT.  See the GNU General Public License for more
 	details.
  	You should have received a copy of the GNU General Public License
  	along with this program; if not, write to the Free Software
  	Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 	QuestionsCommentsBugfixes to ssic-linux-devel@lists.sourceforge.net
   Copyright (C) 1992  Rick Sladkey
   Optimization changes Copyright (C) 1994 Florian La Roche
   Jun 7 1999, cache symlink lookups in the page cache.  -DaveM
   Portions Copyright (C) 2001 Compaq Computer Corporation
   ocfs2 symlink handling code.
   Copyright (C) 2004, 2005 Oracle.
 will be less than a page size 
 SPDX-License-Identifier: GPL-2.0-or-later
  sysfile.c
  Initialize, read, write, etc. system files.
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
			
			  return NULL here so that ocfs2_get_sytem_file_inodes
			  will try to create an inode and use it. We will try
			  to initialize local_system_inodes next time.
 Someone has initialized it for us. 
 avoid the lookup if cached in local system file array 
 get a ref in addition to the array ref 
 this gets one ref thru iget 
 add one more if putting into array for first time 
		 Ignore inode lock on these inodes as the lock does not
		  really belong to any process and lockdep cannot handle
 SPDX-License-Identifier: GPL-2.0-or-later
  io.c
  Buffer cache handling
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
  Bits on bh->b_state used by ocfs2.
  These MUST be after the JBD2 bits.  Hence, we use BH_JBDPrivateStart.
 Expand the magic b_state functions 
	 No need to check for a soft readonly file system here. non
	  journalled writes are only ever done on system files which
 remove from dirty list before IO. 
 for end_buffer_write_sync() 
		 We don't need to remove the clustered uptodate
		  information for this bh as it's not marked locally
 Caller must provide a bhs[] with all NULL or non-NULL entries, so it
  will be easier to handle read failure.
	 Don't put buffer head and re-assign it to NULL if it is allocated
	  outside since the caller can't be aware of this alternation!
			 This should probably be a BUG, or
 for end_buffer_read_sync() 
				 If middle bh fails, let previous bh
				  finish its read and then put it to
				  aovoid bh leak
 No need to wait on the buffer if it's managed by JBD. 
			 Status won't be cleared from here on out,
			  so we can safely record this and loop back
 Caller must provide a bhs[] with all NULL or non-NULL entries, so it
  will be easier to handle read failure.
	 Don't put buffer head and re-assign it to NULL if it is allocated
	  outside since the caller can't be aware of this alternation!
 Don't forget to put previous bh! 
		 There are three read-ahead cases here which we need to
		  be concerned with. All three assume a buffer has
		  previously been submitted with OCFS2_BH_READAHEAD
		  and it hasn't yet completed IO.
		 
		  1) The current request is sync to disk. This rarely
		     happens these days, and never when performance
		     matters - the code can just wait on the buffer
		     lock and re-submit.
		 
		  2) The current request is cached, but not
		     readahead. ocfs2_buffer_uptodate() will return
		     false anyway, so we'll wind up waiting on the
		     buffer lock to do IO. We re-check the request
		     with after getting the lock to avoid a re-submit.
		 
		  3) The current request is readahead (and so must
		     also be a caching one). We short circuit if the
		     buffer is locked (under IO) and if it's in the
		     uptodate cache. The re-check from #2 catches the
		     case that the previous read-ahead completes just
		     before our is-it-in-flight check.
			 We're using ignore_cache here to say
				 This should probably be a BUG, or
			 A read-ahead request was made - if the
			  buffer is already under read-ahead from a
			  previously submitted request than we are
			 Re-check ocfs2_buffer_uptodate() as a
			  previously read-ahead buffer may have
			  completed IO while we were waiting for the
 for end_buffer_read_sync() 
				 Clear the buffers on error including those
				  ever succeeded in reading
					 If middle bh fails, let previous bh
					  finish its read and then put it to
					  aovoid bh leak
			 We know this can't have changed as we hold the
			  owner sem. Avoid doing any work on the bh if the
				 Status won't be cleared from here on out,
				  so we can safely record this and loop back
				  to cleanup the other buffers. Don't need to
				  remove the clustered uptodate information
				  for this bh as it's not marked locally
				 We never set NeedsValidate if the
				  buffer was held by the journal, so
		 Always set the buffer in the cache, even if it was
		  a forced read, or read-ahead which hasn't yet
 Check whether the blkno is the super block or one of the backups. 
  Write super block and backups doesn't need to collaborate with journal,
  so we don't need to lock ip_io_mutex and ci doesn't need to bea passed
  into this function.
 remove from dirty list before IO. 
 for end_buffer_write_sync() 
 SPDX-License-Identifier: GPL-2.0-or-later
  locks.c
  Userspace file locking support
  Copyright (C) 2007 Oracle.  All rights reserved.
		
		  Converting an existing lock is not guaranteed to be
		  atomic, so we can get away with simply unlocking
		  here and allowing the lock code to try at the new
		  level.
  Overall flow of ocfs2_flock() was influenced by gfs2_flock().
 SPDX-License-Identifier: GPL-2.0-or-later
  export.c
  Functions to facilitate NFS exporting
  Copyright (C) 2002, 2005 Oracle.  All rights reserved.
	
	  If the inode exists in memory, we only need to check it's
	  generation number
	
	  This will synchronize us against ocfs2_delete_inode() on
	  all nodes
			
			  The blkno NFS gave us doesn't even show up
			  as an inode, we return -ESTALE to be
			  nice
 If the inode allocator bit is clear, this inode must be stale 
 SPDX-License-Identifier: GPL-2.0-only
  stack_user.c
  Code which interfaces ocfs2 with fsdlm and a userspace stack.
  Copyright (C) 2007 Oracle.  All rights reserved.
  The control protocol starts with a handshake.  Until the handshake
  is complete, the control device will fail all write(2)s.
  The handshake is simple.  First, the client reads until EOF.  Each line
  of output is a supported protocol tag.  All protocol tags are a single
  character followed by a two hex digit version number.  Currently the
  only things supported is T01, for "Text-base version 0x01".  Next, the
  client writes the version they would like to use, including the newline.
  Thus, the protocol tag is 'T01\n'.  If the version tag written is
  unknown, -EINVAL is returned.  Once the negotiation is complete, the
  client can start sending messages.
  The T01 protocol has three messages.  First is the "SETN" message.
  It has the following syntax:
   SETN<space><8-char-hex-nodenum><newline>
  This is 14 characters.
  The "SETN" message must be the first message following the protocol.
  It tells ocfs2_control the local node number.
  Next comes the "SETV" message.  It has the following syntax:
   SETV<space><2-char-hex-major><space><2-char-hex-minor><newline>
  This is 11 characters.
  The "SETV" message sets the filesystem locking protocol version as
  negotiated by the client.  The client negotiates based on the maximum
  version advertised in sysfsocfs2max_locking_protocol.  The major
  number from the "SETV" message must match
  ocfs2_user_plugin.sp_max_proto.pv_major, and the minor number
  must be less than or equal to ...sp_max_version.pv_minor.
  Once this information has been set, mounts will be allowed.  From this
  point on, the "DOWN" message can be sent for node down notification.
  It has the following syntax:
   DOWN<space><32-char-cap-hex-uuid><space><8-char-hex-nodenum><newline>
  eg:
   DOWN 632A924FDD844190BDA93C0DF6B94899 00000001\n
  This is 47 characters.
  Whether or not the client has done the handshake.
  For now, we have just one protocol version.
 Handshake states 
 Messages 
  ocfs2_live_connection is refcounted because the filesystem and
  miscdevice sides can detach in different order.  Let's just be safe.
 SETN<space><8-char-hex-nodenum><newline> 
 SETV<space><2-char-hex-major><space><2-char-hex-minor><newline> 
 DOWN<space><32-char-cap-hex-uuid><space><8-char-hex-nodenum><newline> 
  ocfs2_live_connection structures are created underneath the ocfs2
  mount path.  Since the VFS prevents multiple calls to
  fill_super(), we can't get dupes here.
  This function disconnects the cluster connection from ocfs2_control.
  Afterwards, userspace can't affect the cluster connection.
 The T01 expects write(2) calls to have exactly one command 
  Called whenever configuration elements are sent to devocfs2_control.
  If all configuration elements are present, try to set the global
  values.  If there is a problem, return an error.  Skip any missing
  elements, and only bump ocfs2_control_opened when we have all elements
  and are successful.
 We set the global values successfully 
	
	  The major must be between 1 and 255, inclusive.  The minor
	  must be between 0 and 255, inclusive.  The version passed in
	  must be within the maximum version supported by the filesystem.
 Try to catch padding issues 
  This is a naive version.  If we ever have a new protocol, we'll expand
  it.  Probably using seq_file.
 Have we read the whole protocol list? 
 XXX: Do bad things! 
		
		  Last valid close clears the node number and resets
		  the locking protocol version
	
	  For now we're punting on the issue of other non-standard errors
	  where we can't tell if the unlock_ast or lock_ast should be called.
	  The main "other error" that's possible is EINVAL which means the
	  function was called with invalid args, which shouldn't be possible
	  since the caller here is under our control.  Other non-standard
	  errors probably fall into the same category, or otherwise are fatal
	  which means we can't carry on anyway.
	
	  This more or less just demuxes the plock request into any
	  one of three dlm calls.
	 
	  Internally, fsdlm will pass these to a misc device, which
	  a userspace daemon will read and write to.
	 
	  For now, cancel requests (which happen internally only),
	  are turned into unlocks. Most of this function taken from
	  gfs2_lock.
  Compare a requested locking protocol version against the current one.
  If the major numbers are different, they are incompatible.
  If the current minor is greater than the request, they are incompatible.
  If the current minor is less than or equal to the request, they are
  compatible, and the requester should run at the current minor version.
	
	  ocfs2_protocol_version has two u8 variables, so we don't
	  need any endian conversion.
	
	  ocfs2_protocol_version has two u8 variables, so we don't
	  need any endian conversion.
 get_protocol_version()
  To exchange ocfs2 versioning, we use the LVB of the version dlm lock.
  The algorithm is:
  1. Attempt to take the lock in EX mode (non-blocking).
  2. If successful (which means it is the first mount), write the
     version number and downconvert to PR lock.
  3. If unsuccessful (returns -EAGAIN), read the version from the LVB after
     taking the PR lock.
	
	  running_proto must have been set before we allowed any mounts
	  to proceed.
 SPDX-License-Identifier: GPL-2.0-or-later
  heartbeat.c
  Register ourselves with the heartbaet service, keep our node maps
  up to date, and fire off recovery when needed.
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
 special case -1 for now
		
		  No cluster connection means we're not even ready to
		  participate yet.  We check the slots after the cluster
		  comes up, so we will notice the node death then.  We
		  can safely ignore it here.
 SPDX-License-Identifier: GPL-2.0-only
  filecheck.c
  Code which implements online file check.
  Copyright (C) 2016 SuSE.  All rights reserved.
 File check error strings,
  must correspond with error number in header file.
 To free a undone file check entry 
 too shortlong args length 
 snprintf() didn't fit 
			 Delete the oldest entry which was done,
			  make sure the entry size in list does
			  not exceed maximum value
 SPDX-License-Identifier: GPL-2.0-or-later
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
	 We don't use the page cache to create symlink data, so if
		 we haven't locked out transactions, so a commit
		  could've happened. Since we've got a reference on
		  the bh, even if it commits while we're doing the
 this always does IO for some reason. 
	
	  ocfs2 never allocates in this function - the only time we
	  need to use BH_New is when we're extending i_size on a file
	  system which doesn't support holes, in which case BH_New
	  allows __block_write_begin() to zero.
	 
	  If we see this on a sparse file system, then a truncate has
	  raced us and removed the cluster. In this case, we clear
	  the buffers dirty and uptodate bits and let the buffer code
	  ignore it as a hole.
 Treat the unwritten extent as a hole for zeroing purposes. 
 Clear the remaining part of the page 
		
		  Unlock the page and cycle ip_alloc_sem so that we don't
		  busyloop waiting for ip_alloc_sem to unlock
	
	  i_size might have just been updated as we grabed the meta lock.  We
	  might now be discovering a truncate that hit on another node.
	  block_read_full_page->get_block freaks out if it is asked to read
	  beyond the end of a file, so we check here.  Callers
	  (generic_file_read, vm_ops->fault) are clever enough to check i_size
	  and notice that the page they just read isn't needed.
	 
	  XXX sys_readahead() seems to get that wrong?
  This is used only for read-ahead. Failures or difficult to handle
  situations are safe to ignore.
  Right now, we don't bother with BH_Boundary - in-inode extent lists
  are quite large (243 extents on 4k blocks), so most inodes don't
  grow out to a tree. If need be, detecting boundary extents could
  trivially be added in a future version of ocfs2_get_block().
	
	  Use the nonblocking flag for the dlm code to avoid page
	  lock inversion, but don't bother with retrying.
	
	  Don't bother with inline-data. There isn't anything
	  to read-ahead in that case anyway...
	
	  Check whether a remote node truncated this file - we just
	  drop out in that case as it's not worth handling here.
 Note: Because we don't support holes, our allocation has
  already happened (allocation writes zeros to the file data)
  so we don't have to worry about ordered writes in
  ocfs2_writepage.
  ->writepage is called during the process of invalidating the page cache
  during blocked lock processing.  It can't block on any cluster locks
  to during block mapping.  It's relying on the fact that the block
  mapping can't have disappeared under the dirty pages that it is
  being asked to write back.
 Taken from ext3. We don't necessarily need the full blown
  functionality yet, but IMHO it's better to cut and paste the whole
  thing so we can avoid introducing our own bugs (and easily pick up
	
	  The swap code (ab-)uses ->bmap to get a block mapping and then
	  bypasse the file system for actual IO.  We really can't allow
	  that on refcounted inodes, so we have to skip out here.  And yes,
	  0 is the magic code for a bmap error..
	 We don't need to lock journal system files, since they aren't
	  accessed concurrently from multiple nodes.
  'from' and 'to' are the region in the page to avoid zeroing.
  If pagesize > clustersize, this function will avoid zeroing outside
  of the cluster boundary.
  from == to == 0 is code for "zero the entire cluster region"
  Nonsparse file systems fully allocate before we get to the write
  code. This prevents ocfs2_write() from tagging the write as an
  allocating one, which means ocfs2_map_page_blocks() might try to
  read-in the blocks at the tail of our file. Avoid reading them by
  testing i_size against each block offset.
  Some of this taken from __block_write_begin(). We already have our
  mapping by now though, and the entire write will be allocating or
  it won't, so not much need to use BH_New.
  This will also skip zeroing, which is handled externally.
		
		  Ignore blocks outside of our io range -
		  they may belong to unallocated clusters.
		
		  For an allocating write with cluster size >= page
		  size, we always write the entire page.
	
	  If we issued read requests - let them complete.
	
	  If we get -EIO above, zero out any newly allocated blocks
	  to avoid exposing stale data.
  Describe the state of a single cluster to be written to.
	
	  Give this a unique field because c_phys eventually gets
	  filled.
 Logical cluster position  len of write 
 First cluster allocated in a nonsparse extend 
 Type of caller. Must be one of buffer, mmap, direct.  
	
	  This is true if page_size > cluster_size.
	 
	  It triggers a set of special cases during write which might
	  have to deal with allocating writes to partial pages.
	
	  Pages involved in this write.
	 
	  w_target_page is the page being written to by the user.
	 
	  w_pages is an array of pages which always contains
	  w_target_page, and in the case of an allocating write with
	  page_size < cluster size, it will contain zero'd and mapped
	  pages adjacent to w_target_page which need to be written
	  out in so that future reads from that region will get
	  zero's.
	
	  w_target_locked is used for page_mkwrite path indicating no unlocking
	  against w_target_page in ocfs2_write_end_nolock.
	
	  ocfs2_write_end() uses this to know what the real range to
	  write in the target should be.
	
	  We could use journal_current_handle() but this is cleaner,
	  IMHO -Mark
	
	  w_target_locked is only set to true in the page_mkwrite() case.
	  The intent is to allow us to lock the target page from write_begin()
	  to write_end(). The caller must hold a ref on w_target_page.
  If a page has any new buffers, zero them out here, and mark them uptodate
  and dirty so they'll be written out (in order to prevent uninitialised
  block data from leaking). And clear the new bit.
  Only called when we have a failure during allocating write to write
  zero's to the newly allocated region.
	 treat the write as new if the a holelseek spanned across
	  the page boundary.
		
		  If we haven't allocated the new page yet, we
		  shouldn't be writing it out without copying user
		  data. This is likely a math error from the caller.
	
	  Parts of newly allocated pages need to be zero'd.
	 
	  Above, we have also rewritten 'to' and 'from' - as far as
	  the rest of the function is concerned, the entire cluster
	  range inside of a page needs to be written.
	 
	  We can skip this if the page is up to date - it's already
	  been zero'd from being read in as a hole.
  This function will only grab one clusters worth of pages.
	
	  Figure out how many pages we'll be manipulating here. For
	  non allocating write, we just change the one
	  page. Otherwise, we'll need a whole clusters worth.  If we're
	  writing past i_size, we only need enough pages to cover the
	  last page of the write.
		
		  We need the index past the last page we could possibly
		  touch.  This is the page past the end of the write or
		  i_size, whichever is greater.
			
			  ocfs2_pagemkwrite() is a little different
			  and wants us to directly use the page
			  passed in.
 Exit and let the caller retry 
 Direct write has no mapping page. 
  Prepare a single cluster for write one cluster into the file.
		
		  This is safe to call with the page locks - it won't take
		  any additional semaphores or cluster locks.
		
		  This shouldn't happen because we must have already
		  calculated the correct meta data allocation required. The
		  internal tree allocation code should know how to increase
		  transaction credits itself.
		 
		  If need be, we could handle -EAGAIN for a
		  RESTART_TRANS here.
	
	  The only reason this should fail is due to an inability to
	  find the extent added.
 This is the direct io target page. 
	
	  We only have cleanup to do in case of allocating write.
		
		  We have to make sure that the total write passed in
		  doesn't extend past a single cluster.
  ocfs2_write_end() wants to know which parts of the target page it
  should complete the write on. It's easiest to compute them ahead of
  time when a more complete view of the write is available.
	
	  Allocating write - we may have different boundaries based
	  on page size and cluster size.
	 
	  NOTE: We can no longer compute one value from the other as
	  the actual write length and user provided length may be
	  different.
		
		  We only care about the 1st and last cluster within
		  our range and whether they should be zero'd or not. Either
		  value may be extended out to the startend of a
		  newly allocated cluster.
  Check if this extent is marked UNWRITTEN by direct io. If so, we need not to
  do the zero work. And should not to clear UNWRITTEN since it will be cleared
  by the direct io procedure.
  If this is a new extent that allocated by direct io, we should mark it in
  the ip_unwritten_list.
	 Needs not to zero no metter buffer or direct. The one who is zero
	  the cluster is doing zero. And he will clear unwritten after all
 This direct write will doing zero. 
  Populate each single-cluster write descriptor in the write context
  with information about the io to be done.
  Returns the number of clusters that will have to be allocated, as
  well as a worst case estimate of the number of extent records that
  would have to be created during a write to an unwritten region.
			
			  Need to look up the next extent record.
 We should already CoW the refcountd extent. 
			
			  Assume worst case - that we're writing in
			  the middle of the extent.
			 
			  We can assume that the write proceeds from
			  left to right, in which case the extent
			  insert code is smart enough to coalesce the
			  next splits into the previous records created.
			
			  Only increment phys if it doesn't describe
			  a hole.
		
		  If w_first_new_cpos is < UINT_MAX, we have a non-sparse
		  file that got extended.  w_first_new_cpos tells us
		  where the newly allocated clusters are so we can
		  zero them.
	
	  If we don't set w_num_pages then this page won't get unlocked
	  and freed on cleanup of the write context.
	
	  Handle inodes which already have inline data 1st.
		
		  The write won't fit - we have to give this inode an
		  inline extent list now.
	
	  Check whether the inode can accept inline data.
	
	  Check whether the write can fit.
	
	  This signals to the caller that the data can be written
	  inline.
  This function only does anything for file systems which can't
  handle sparse files.
  What we want to do here is fill in any hole between the current end
  of allocation and the end of our write. That way the rest of the
  write path can treat it as an non-allocating write, which has no
  special case code for sparsenonsparse files.
 There is no wc if this is call from direct. 
 Direct io change i_size late, should not zero tail here. 
	
	  We set w_target_from, w_target_to here so that
	  ocfs2_write_end() knows which range in the target page to
	  write out. An allocation requires that we write the entire
	  cluster range.
		
		  XXX: We are stretching the limits of
		  ocfs2_lock_allocators(). It greatly over-estimates
		  the work to be done.
 direct write needs not to start trans if no extents alloc. 
	
	  We have to zero sparse allocated clusters, unwritten extent clusters,
	  and non-sparse clusters we just extended.  For non-sparse writes,
	  we know zeros will only be needed in the first andor last cluster.
	
	  Fill our page array first. That way we've grabbed enough so
	  that we can zero and flush if we error after adding the
	  extent.
	
	  ocfs2_grab_pages_for_write() returns -EAGAIN if it could not lock
	  the target page. In this case, we exit with no error and no target
	  page. This will trigger the caller, page_mkwrite(), to re-try
	  the operation.
	
	  The mmapped page won't be unlocked in ocfs2_free_write_ctxt(),
	  even in case of error here like ENOSPC and ENOMEM. So, we need
	  to unlock the target page manually to prevent deadlocks when
	  retrying again on ENOSPC, or when returning non-VM_FAULT_LOCKED
	  to VM code.
		
		  Try to free some truncate log so that we can have enough
		  clusters to allocate.
	
	  Take alloc sem here to prevent concurrent lookups. That way
	  the mapping, zeroing and tree manipulation within
	  ocfs2_write() will be safe against ->readpage(). This
	  should also serve to lock out allocation from a shared
	  writeable region.
 This is the direct io target page. 
			
			  Pages adjacent to the target (if any) imply
			  a hole-filling write in which case we want
			  to flush their entire range.
 Direct io do not update i_size here. 
	 unlock pages before dealloc since it needs acquiring j_trans_barrier
	  lock, or it will cause a deadlock since journal commit threads holds
	  this lock and will ask for the page lock when flushing the data.
	  put it here to preserve the unlock order.
  TODO: Make this into a generic get_blocks function.
  From do_direct_io in direct-io.c:
   "So what we do is to permit the ->get_blocks function to populate
    bh.b_size with the size of IO which is permitted at this offset and
    this i_blkbits."
  This function is called directly from get_more_blocks in direct-io.c.
  called like this: dio->get_blocks(dio->inode, fs_startblk,
  					fs_count, map_bh, dio->rw == WRITE);
	
	  bh_result->b_size is count in get_more_blocks according to write
	  "pos" and "end", we need map twice to return different buffer state:
	  1. area in file size, not set NEW;
	  2. area out file size, set  NEW.
	 
	 		   iblock    endblk
	  |--------|---------|---------|---------
	  |<-------area in file------->|
	
	  Because we need to change file size in ocfs2_dio_end_io_write(), or
	  we may need to add it to orphan dir. So can not fall to fast path
	  while file size will be changed.
 This is the fast path for re-write. 
 Clear state set by ocfs2_get_block. 
		
		  when we are going to alloc extents beyond file size, add the
		  inode to orphan dir, so we can recall those spaces when
		  system crashed during write.
	 May sleep in end_io. It should not happen in a irq context. So defer
 The physical address may be 0, fill it. 
	 We do clear unwritten, delete orphan, change i_size here. If neither
 Delete orphan before acquire i_mutex. 
	 Attach dealloc with extent tree in case that we may reuse extents
	  which are already unlinked from current extent tree due to extent
	  rotation and merging.
  ocfs2_dio_end_io is called by the dio core when a dio is finished.  We're
  particularly interested in the aiodio case.  We use the rw_lock DLM lock
  to protect io on one node from truncation on another.
 this io's submitter should not have unlocked this before we could 
	
	  Fallback to buffered IO if we see an inode without
	  extents.
 Fallback to buffered IO if we do not support append dio. 
 SPDX-License-Identifier: GPL-2.0-only
  reservations.c
  Allocation reservations implementation
  Some code borrowed from fsext3balloc.c and is:
  Copyright (C) 1992, 1993, 1994, 1995
  Remy Card (card@masi.ibp.fr)
  Laboratoire MASI - Institut Blaise Pascal
  Universite Pierre et Marie Curie (Paris VI)
  The rest is copyright (C) 2010 Novell.  All rights reserved.
 8, 16, 32, 64, 128, 256, 512, 1024 
 m_bitmap_len is initialized to zero by the above memset. 
	
	  last_len and last_start no longer make sense if
	  we're changing the range of our allocations.
 does nothing if 'resv' is null 
 Does nothing for now. Keep this around for API symmetry 
			
			  This is a good place to check for
			  overlapping reservations.
 This should never happen! 
  ocfs2_find_resv_lhs() - find the window which contains goal
  @resmap: reservation map to search
  @goal: which bit to search for
  If a window containing that goal is not found, we return the window
  which comes before goal. Returns NULL on empty rbtree or no window
  before goal.
 Check if we overshot the reservation just before goal? 
  We are given a range within the bitmap, which corresponds to a gap
  inside the reservations tree (search_start, search_len). The range
  can be anything from the whole bitmap, to a gap between
  reservations.
  The start value of rstart is insignificant.
  This function searches the bitmap range starting at search_start
  with length search_len for a set of contiguous free bits. We try
  to find up to 'wanted' bits, but can sometimes return less.
  Returns the length of allocation, 0 if no free bits are found.
  cstart and clen will also be populated with the result.
 Search reached end of the region 
 we found a zero 
 move start to the next bit to test 
 got a zero after some ones 
	
	  Nasty cases to consider:
	 
	  - rbtree is empty
	  - our window should be first in all reservations
	  - our window should be last in all reservations
	  - need to make sure we don't go past end of bitmap
		
		  Easiest case - empty tree. We can just take
		  whatever window of free bits we want.
		
		  This should never happen - the local alloc window
		  will always have free bits when we're called.
		
		  A NULL here means that the search code couldn't
		  find a window that starts before goal.
		 
		  However, we can take the first window after goal,
		  which is also by definition, the leftmost window in
		  the entire tree. If we can find free bits in the
		  gap between goal and the LHS window, then the
		  reservation can safely be placed there.
		 
		  Otherwise we fall back to a linear search, checking
		  the gaps in between windows for a place to
		  allocate.
		
		  The search should never return such a window. (see
		  comment above
 Now we do a linear search for a window, starting at 'prev_rsv' 
			
			  We're at the rightmost edge of the
			  tree. See if a reservation between this
			  window and the end of the bitmap will work.
		
		  No need to check this gap if we have already found
		  a larger region of free bits.
		min_bits = wanted;  We at know the temp window will use all
	
	  Take the first reservation off the LRU as our 'target'. We
	  don't try to be smart about it. There might be a case for
	  searching based on size but I don't have enough data to be
	  sure. --Mark (3162010)
	
	  Cannibalize (some or all) of the target reservation and
	  feed it to the current window.
		
		  Discard completely if size is less than or equal to a
		  reasonable threshold - 50% of window bits for non temporary
		  windows.
	
	  Begin by trying to get a window as close to the previous
	  one as possible. Using the most recent allocation as a
	  start goal makes sense.
 Search from last alloc didn't work, try once more from beginning. 
		
		  Still empty? Pull oldest one off the LRU, remove it from
		  tree, put this one in it's place.
		
		  We don't want to over-allocate for temporary
		  windows. Otherwise, we run the risk of fragmenting the
		  allocation space.
		
		  Try to get a window here. If it works, we must fall
		  through and test the bitmap . This avoids some
		  ping-ponging of windows due to non-reserved space
		  being allocation before we initialize a window for
		  that inode.
	
	  Completely used? We can remove it then.
	
	  This should have been trapped above.
	
	  May have been discarded above from
	  ocfs2_adjust_resv_from_alloc().
 SPDX-License-Identifier: GPL-2.0-or-later
  alloc.c
  Extent allocs and frees
  Copyright (C) 2002, 2004 Oracle.  All rights reserved.
  Operations for a specific extent tree type.
  To implement an on-disk btree (extent tree) type in ocfs2, add
  an ocfs2_extent_tree_operations structure and the matching
  ocfs2_init_<thingy>_extent_tree() function.  That's pretty much it
  for the allocation portion of the extent tree.
	
	  last_eb_blk is the block number of the right most leaf extent
	  block.  Most on-disk structures containing an extent tree store
	  this value for fast access.  The ->eo_set_last_eb_blk() and
	  ->eo_get_last_eb_blk() operations access this value.  They are
	   both required.
	
	  The on-disk structure usually keeps track of how many total
	  clusters are stored in this extent tree.  This function updates
	  that value.  new_clusters is the delta, and must be
	  added to the total.  Required.
	
	  If this extent tree is supported by an extent map, insert
	  a record into the map.
	
	  If this extent tree is supported by an extent map, truncate the
	  map to clusters,
	
	  If ->eo_insert_check() exists, it is called before rec is
	  inserted into the extent tree.  It is optional.
	
	  --------------------------------------------------------------
	  The remaining are internal to ocfs2_extent_tree and don't have
	  accessor functions
	
	  ->eo_fill_root_el() takes et->et_object and sets et->et_root_el.
	  It is required.
	
	  ->eo_fill_max_leaf_clusters sets et->et_max_leaf_clusters if
	  it exists.  If it does not, et->et_max_leaf_clusters is set
	  to 0 (unlimited).  Optional.
	
	  ->eo_extent_contig test whether the 2 ocfs2_extent_rec
	  are contiguous or not. Optional. Don't need to set it if use
	  ocfs2_extent_rec as the tree leaf.
  Pre-declare ocfs2_dinode_et_ops so we can use it as a sanity check
  in the methods.
  Reset the actual path elements so that we can re-use the structure
  to build another path. Generally, this involves freeing the buffer
  heads.
	
	  Tree depth may change during truncate, or insert. If we're
	  keeping the root extent list, then make sure that our path
	  structure reflects the proper depth.
  All the elements of src into dest. After this call, src could be freed
  without affecting dest.
  Both paths should have the same root. Any non-root elements of dest
  will be freed.
  Make the dest path the same as src and re-initialize src path to
  have a root only.
  Insert an extent block at given index.
  This will not take an additional reference on eb_bh.
	
	  Right now, no root bh is an extent block, so this helps
	  catch code errors with dinode trees. The assertion can be
	  safely removed if we ever need to insert extent block
	  structures at the root.
  Journal the buffer at depth idx.  All idx>0 are extent_blocks,
  otherwise it's the root_access function.
  I don't like the way this function's name looks next to
  ocfs2_journal_access_path(), but I don't have a better one.
  Convenience function to journal all components in a path.
  Return the index of the extent record which contains cluster #v_cluster.
  -1 is returned if it was not found.
  Should work fine on interior and exterior nodes.
  NOTE: ocfs2_block_extent_contig(), ocfs2_extents_adjacent() and
  ocfs2_extent_rec_contig only work properly against leaf nodes!
	
	  Refuse to coalesce extent records with different flag
	  fields - we don't want to mix unwritten extents with user
	  data.
  NOTE: We can have pretty much any combination of contiguousness and
  appending.
  The usefulness of APPEND_TAIL is more in that it lets us know that
  we'll have to update the path to that leaf.
	
	  If the ecc fails, we return the error but otherwise
	  leave the filesystem running.  We know any error is
	  local to this block.
	
	  Errors after here are fatal.
 If ocfs2_read_block() got us a new bh, pass it up. 
  How many free extents have we got before we need more meta data?
 expects array to already be allocated
  sets h_signature, h_blkno, h_suballoc_bit, h_suballoc_slot, and
  l_count for you
 Ok, setup the minimal stuff here. 
			 We'll also be dirtied by the caller, so
  Helper function for ocfs2_add_branch() and ocfs2_shift_tree_depth().
  Returns the sum of the rightmost extent rec logical offset and
  cluster count.
  ocfs2_add_branch() uses this to determine what logical cluster
  value should be populated into the leftmost new branch records.
  ocfs2_shift_tree_depth() uses this to determine the # clusters
  value for the new topmost tree record.
  Change range of the branches in the right most path according to the leaf
  extent block's rightmost record.
  Add an entire tree branch to our inode. eb_bh is the extent block
  to start at, if we don't want to start the branch at the root
  structure.
  last_eb_bh is required as we have to update it's next_leaf pointer
  for the new last extent block.
  the new branch will be 'empty' in the sense that every block will
  contain a single record with cluster count == 0.
 we never add a branch to a leaf. 
	
	  If there is a gap before the root end and the real end
	  of the righmost leaf block, we need to remove the gap
	  between new_cpos and root_end first so that the tree
	  is consistent after we add a new branch(it will start
	  from new_cpos).
 allocate the number of new eb blocks we need 
	 Firstyly, try to reuse dealloc since we have already estimated how
	  many extent blocks we may use.
	 Note: new_eb_bhs[new_blocks - 1] is the guy which will be
	  linked with the rest of the tree.
	  conversly, new_eb_bhs[0] is the new bottommost leaf.
	 
	  when we leave the loop, new_last_eb_blk will point to the
	  newest leaf, and next_blkno will point to the topmost extent
 ocfs2_create_new_meta_bhs() should create it right! 
		
		  This actually counts as an empty extent as
		  c_clusters == 0
		
		  eb_el isn't always an interior node, but even leaf
		  nodes want a zero'd flags and reserved field so
		  this gets the whole 32 bits regardless of use.
	 This is a bit hairy. We want to update up to three blocks
	  here without leaving any of them in an inconsistent state
	  in case of error. We don't have to worry about
	  journal_dirty erroring as it won't unless we've aborted the
	  handle (in which case we would never be here) so reserving
	 Link the new branch into the rest of the tree (el will
	 fe needs a new last extent block pointer, as does the
	
	  Some callers want to track the rightmost leaf so pass it
	  back here.
  adds another level to the allocation tree.
  returns back the new extent block so you can add a branch to it
  after this call.
 ocfs2_create_new_meta_bhs() should create it right! 
 copy the root extent list data into the new extent block 
 update root_bh now 
	 If this is our 1st tree depth shift, then last_eb_blk
  Should only be called when there is no space left in any of the
  leaf nodes. What we want to do is find the lowest tree depth
  non-leaf extent block with room for new records. There are three
  valid results of this search:
  1) a lowest extent block is found, then we pass it back in
     lowest_eb_bh and return '0'
  2) the search fails to find anything, but the root_el has room. We
     pass NULL back in lowest_eb_bh, but still return '0'
  3) the search fails to find anything AND the root_el is full, in
     which case we return > 0
  return status < 0 indicates an error.
	 If we didn't find one and the fe doesn't have any room,
  Grow a b-tree so that it has more records.
  We might shift the tree depth in which case existing paths should
  be considered invalid.
  Tree depth after the grow is returned via final_depth.
  last_eb_bh will be updated by ocfs2_add_branch().
	 We traveled all the way to the bottom of the allocation tree
	  and didn't find room for any more extents - we need to add
		 ocfs2_shift_tree_depth will return us a buffer with
		  the new extent block (so we can pass that to
			
			  Special case: we have room now if we shifted from
			  tree_depth 0, so no more work needs to be done.
			 
			  We won't be calling add_branch, so pass
			  back last_eb_bh as the new leaf. At depth
			  zero, it should always be null so there's
			  no reason to brelse.
	 call ocfs2_add_branch to add the final part of the tree with
  This function will discard the rightmost extent record.
 This will cause us to go off the end of our extent list. 
 The tree code before us didn't allow enough room in the leaf. 
	
	  The easiest way to approach this is to just remove the
	  empty extent and temporarily decrement next_free.
		
		  If next_free was 1 (only an empty extent), this
		  loop won't execute, which is fine. We still want
		  the decrement above to happen.
	
	  Figure out what the new record index should be.
	
	  No need to memmove if we're just adding to the tail.
	
	  Either we had an empty extent, and need to re-increment or
	  there was no empty extent on a non full rightmost leaf node,
	  in which case we still need to increment.
	
	  Make sure none of the math above just messed up our tree.
  Create an empty extent record .
  l_next_free_rec may be updated.
  If an empty extent already exists do nothing.
  For a rotation which involves two leaf nodes, the "root node" is
  the lowest level tree node which contains a path to both leafs. This
  resulting set of information can be used to form a complete "subtree"
  This function is passed two full paths from the dinode down to a
  pair of adjacent leaves. It's task is to figure out which path
  index contains the subtree root - this can be the root index itself
  in a worst-case rotation.
  The array index of the subtree root is passed back.
	
	  Check that the caller passed in two paths from the same tree.
		
		  The caller didn't pass two adjacent paths.
  Traverse a btree path in search of cpos, starting at root_el.
  This code can be called with a cpos larger than the tree, in which
  case it will return the rightmost path.
			
			  In the case that cpos is off the allocation
			  tree, this should just wind up returning the
			  rightmost record.
	
	  Catch any trailing bh that the loop didn't handle.
  Given an initialized path (that is, it has a valid root extent
  list), this function will traverse the btree in search of the path
  which would contain cpos.
  The path traveled is recorded in the path structure.
  Note that this will not do any comparisons on leaf node extent
  records, so it will work fine in the case that we just added a tree
  branch.
 We want to retain only the leaf block. 
  Find the leaf block in the tree which would contain cpos. No
  checking of the actual leaf is done.
  Some paths want to call this instead of allocating a path structure
  and calling ocfs2_find_path().
  This function doesn't handle non btree extent lists.
  Adjust the adjacent records (left_rec, right_rec) involved in a rotation.
  Basically, we've moved stuff around at the bottom of the tree and
  we need to fix up the extent records above the changes to reflect
  the new changes.
  left_rec: the record on the left.
  right_rec: the record to the right of left_rec
  right_child_el: is the child list pointed to by right_rec
  By definition, this only works on interior nodes.
	
	  Interior nodes never have holes. Their cpos is the cpos of
	  the leftmost record in their child list. Their cluster
	  count covers the full theoretical range of their child list
	  - the range between their cpos and the cpos of the record
	  immediately to their right.
	
	  Calculate the rightmost cluster count boundary before
	  moving cpos - we will need to adjust clusters after
	  updating e_cpos to keep the same highest cluster count.
  Adjust the adjacent root node records involved in a
  rotation. left_el_blkno is passed in as a key so that we can easily
  find it's index in the root list.
	
	  The path walking code should have never returned a root and
	  two paths which are not adjacent.
  We've changed a leaf block (in right_path) and need to reflect that
  change back up the subtree.
  This happens in multiple places:
    - When we've moved an extent record from the left path leaf to the right
      path leaf to make room for an empty extent in the left path leaf.
    - When our insert into the right path leaf is at the leftmost edge
      and requires an update of the path immediately to it's left. This
      can occur at the end of some types of rotation and appending inserts.
    - When we've adjusted the last extent record in the left path leaf and the
      1st extent record in the right path leaf during cross extent block merge.
	
	  Update the counts and position values within all the
	  interior nodes to reflect the leaf rotation we just did.
	 
	  The root node is handled below the loop.
	 
	  We begin the loop with right_el and left_el pointing to the
	  leaf lists and work our way up.
	 
	  NOTE: within this loop, left_el and right_el always refer
	  to the child lists.
		
		  One nice property of knowing that all of these
		  nodes are below the root is that we only deal with
		  the leftmost right node record and the rightmost
		  left node record.
		
		  Setup our list pointers now so that the current
		  parents become children in the next iteration.
	
	  At the root node, adjust the two adjacent records which
	  begin our path to the leaves.
	
	  This extent block may already have an empty record, so we
	  return early if so.
 This is a code error, not a disk corruption. 
 Do the copy now. 
	
	  Clear out the record we just copied and shift everything
	  over, leaving an empty extent in the left leaf.
	 
	  We temporarily subtract from next_free_rec so that the
	  shift will lose the tail record (which is now defunct).
  Given a full path, determine what cpos value would return us a path
  containing the leaf immediately to the left of the current one.
  Will return zero if the path passed in is already the leftmost path.
 Start at the tree node just above the leaf and work our way up. 
		
		  Find the extent record just before the one in our
		  path.
						
						  We've determined that the
						  path specified is already
						  the leftmost one - return a
						  cpos of zero.
					
					  The leftmost record points to our
					  leaf - we need to travel up the
					  tree one level.
		
		  If we got here, we never found a valid node where
		  the tree indicated one should be.
  Extend the transaction by enough credits to complete the rotation,
  and still leave at least the original number of credits allocated
  to this transaction.
  Trap the case where we're inserting into the theoretical range past
  the _actual_ left leaf range. Otherwise, we'll rotate a record
  whose cpos is less than ours into the right leaf.
  It's only necessary to look at the rightmost record of the left
  leaf because the logic that calls us should ensure that the
  theoretical ranges in the path components above the leaves are
  correct.
 Empty list. 
  Rotate all the records in a btree right one record, starting at insert_cpos.
  The path to the rightmost leaf should be passed in.
  The array is assumed to be large enough to hold an entire path (tree depth).
  Upon successful return from this function:
  - The 'right_path' array will contain a path to the leaf block
    whose range contains e_cpos.
  - That leaf block will have a single empty extent in list index 0.
  - In the case that the rotation requires a post-insert update,
    ret_left_path will contain a valid path which can be passed to
    ocfs2_insert_path().
	
	  What we want to do here is:
	 
	  1) Start with the rightmost path.
	 
	  2) Determine a path to the leaf block directly to the left
	     of that leaf.
	 
	  3) Determine the 'subtree root' - the lowest level tree node
	     which contains a path to both leaves.
	 
	  4) Rotate the subtree.
	 
	  5) Find the next subtree by considering the left path to be
	     the new right path.
	 
	  The check at the top of this while loop also accepts
	  insert_cpos == cpos because cpos is only a _theoretical_
	  value to get us the left path - insert_cpos might very well
	  be filling that hole.
	 
	  Stop at a cpos of '0' because we either started at the
	  leftmost branch (i.e., a tree with one branch and a
	  rotation inside of it), or we've gone as far as we can in
	  rotating subtrees.
			
			  We've rotated the tree as much as we
			  should. The rest is up to
			  ocfs2_insert_path() to complete, after the
			  record insertion. We indicate this
			  situation by returning the left path.
			 
			  The reason we don't adjust the records here
			  before the record insert is that an error
			  later might break the rule where a parent
			  record e_cpos will reflect the actual
			  e_cpos of the 1st nonempty record of the
			  child list.
			
			  A rotate moves the rightmost left leaf
			  record over to the leftmost right leaf
			  slot. If we're doing an extent split
			  instead of a real insert, then we have to
			  check that the extent to be split wasn't
			  just moved over. If it was, then we can
			  exit here, passing left_path back -
			  ocfs2_split_extent() is smart enough to
			  search both leaves.
		
		  There is no need to re-read the next right path
		  as we know that it'll be our current left
		  path. Optimize by copying values instead.
 Path should always be rightmost. 
		
		  Not all nodes might have had their final count
		  decremented by the caller - handle this here.
		
		  It's legal for us to proceed if the right leaf is
		  the rightmost one and it has an empty extent. There
		  are two cases to handle - whether the leaf will be
		  empty after removal or not. If the leaf isn't empty
		  then just remove the empty extent up front. The
		  next block will handle empty leaves by flagging
		  them for unlink.
		 
		  Non rightmost leaves will throw -EAGAIN and the
		  caller can manually move the subtree and retry.
		
		  We have to update i_last_eb_blk during the meta
		  data delete.
	
	  Getting here with an empty extent in the right path implies
	  that it's the rightmost path and will be deleted.
		
		  Only do this if we're moving a real
		  record. Otherwise, the action is delayed until
		  after removal of the right path in which case we
		  can do a simple shift to remove the empty extent.
		
		  Move recs over to get rid of empty extent, decrease
		  next_free. This is allowed to remove the last
		  extent in our leaf (setting l_next_free_rec to
		  zero) - the delete code below won't care.
		
		  Removal of the extent in the left leaf was skipped
		  above so we could delete the right path
		  1st.
  Given a full path, determine what cpos value would return us a path
  containing the leaf immediately to the right of the current one.
  Will return zero if the path passed in is already the rightmost path.
  This looks similar, but is subtly different to
  ocfs2_find_cpos_for_left_leaf().
 Start at the tree node just above the leaf and work our way up. 
		
		  Find the extent record just after the one in our
		  path.
						
						  We've determined that the
						  path specified is already
						  the rightmost one - return a
						  cpos of zero.
					
					  The rightmost record points to our
					  leaf - we need to travel up the
					  tree one level.
		
		  If we got here, we never found a valid node where
		  the tree indicated one should be.
		
		  Caller might still want to make changes to the
		  tree root, so re-add it to the journal here.
			
			  The rotation has to temporarily stop due to
			  the right subtree having an empty
			  extent. Pass it back to the caller for a
			  fixup.
		
		  The subtree rotate might have removed records on
		  the rightmost edge. If so, then rotation is
		  complete.
		
		  We have a path to the left of this one - it needs
		  an update too.
		
		  'path' is also the leftmost path which
		  means it must be the only one. This gets
		  handled differently because we want to
		  revert the root back to having extents
		  in-line.
  Left rotation of btree records.
  In many ways, this is (unsurprisingly) the opposite of right
  rotation. We start at some non-rightmost path containing an empty
  extent in the leaf block. The code works its way to the rightmost
  path by rotating records to the left in every subtree.
  This is used by any code which reduces the number of extent records
  in a leaf. After removal, an empty record should be placed in the
  leftmost list position.
  This won't handle a length update of the rightmost path records if
  the rightmost tree leaf record is removed so the caller is
  responsible for detecting and correcting that.
		
		  Inline extents. This is trivially handled, so do
		  it up front.
	
	  Handle rightmost branch now. There's several cases:
	   1) simple rotation leaving records in there. That's trivial.
	   2) rotation requiring a branch delete - there's no more
	      records left. Two cases of this:
	      a) There are branches to the left.
	      b) This is also the leftmost (the only) branch.
	 
	   1) is handled via ocfs2_rotate_rightmost_leaf_left()
	   2a) we need the left branch so that we can update it with the unlink
	   2b) we need to bring the root back to inline extents.
		
		  This gets a bit tricky if we're going to delete the
		  rightmost path. Get the other cases out of the way
		  1st.
		
		  XXX: The caller can not trust "path" any more after
		  this as it will have been deleted. What do we do?
		 
		  In theory the rotate-for-merge code will never get
		  here because it'll always ask for a rotate in a
		  nonempty list.
	
	  Now we can loop, remembering the path we get from -EAGAIN
	  and restarting from there.
		
		  We consumed all of the merged-from record. An empty
		  extent cannot exist anywhere but the 1st array
		  position, so move things over if the merged-from
		  record doesn't occupy that position.
		 
		  This creates a new empty extent so the caller
		  should be smart enough to have removed any existing
		  ones.
		
		  Always memset - the caller doesn't check whether it
		  created an empty extent, so there could be junk in
		  the other fields.
 This function shouldn't be called for non-trees. 
 This function shouldn't be called for the rightmost leaf. 
  Remove split_rec clusters from the record at index and merge them
  onto the beginning of the record "next" to it.
  For index < l_count - 1, the next means the extent rec at index + 1.
  For index == l_count - 1, the "next" means the 1st extent rec of the
  next extent block.
 we meet with a cross extent block merge. 
 This function shouldn't be called for non-trees. 
 This function shouldn't be called for the leftmost leaf. 
  Remove split_rec clusters from the record at index and merge them
  onto the tail of the record "before" it.
  For index > 0, the "before" means the extent rec at index - 1.
  For index == 0, the "before" means the last record of the previous
  extent block. And there is also a situation that we may need to
  remove the rightmost leaf extent block in the right_path and change
  the right path to indicate the new rightmost path.
 we meet with a cross extent block merge. 
		
		  The easy case - we can just plop the record right in.
		
		  In the situation that the right_rec is empty and the extent
		  block is empty also,  ocfs2_complete_edge_insert can't handle
		  it and we need to delete the right extent block.
 extend credit for ocfs2_remove_rightmost_path 
			 Now the rightmost extent block has been deleted.
			  So we use the new rightmost path.
 extend credit for ocfs2_remove_rightmost_path 
		
		  The merge code will need to create an empty
		  extent to take the place of the newly
		  emptied slot. Remove any pre-existing empty
		  extents - having more than one in a leaf is
		  illegal.
		
		  Left-right contig implies this.
		
		  Since the leftright insert always covers the entire
		  extent, this call will delete the insert record
		  entirely, resulting in an empty extent record added to
		  the extent block.
		 
		  Since the adding of an empty extent shifts
		  everything back to the right, there's no need to
		  update split_index here.
		 
		  When the split_index is zero, we need to merge it to the
		  prevoius extent block. It is more efficient and easier
		  if we do merge_right first and merge_left later.
		
		  We can only get this from logic error above.
 extend credit for ocfs2_remove_rightmost_path 
 The merge left us with an empty extent, remove it. 
		
		  Note that we don't pass split_rec here on purpose -
		  we've merged it into the rec already.
 extend credit for ocfs2_remove_rightmost_path 
		
		  Error from this last rotate is not critical, so
		  print but don't bubble it up.
		
		  Merge a record to the left or right.
		 
		  'contig_type' is relative to the existing record,
		  so for example, if we're "right contig", it's to
		  the record on the left (hence the left merge).
 extend credit for ocfs2_remove_rightmost_path 
			
			  The merge may have left an empty extent in
			  our leaf. Try to rotate it away.
		
		  Region is on the left edge of the existing
		  record.
		
		  Region is on the right edge of the existing
		  record.
  Do the final bits of extent record insertion at the target leaf
  list. If this leaf is part of an allocation tree, it is assumed
  that the tree above has been prepared.
	
	  Contiguous insert - either left or right.
	
	  Handle insert into an empty leaf.
	
	  Appending insert.
	
	  Ok, we have to rotate.
	 
	  At this point, it is safe to assume that inserting into an
	  empty leaf and appending to a leaf have both been handled
	  above.
	 
	  This leaf needs to have space, either by the empty 1st
	  extent record, or by virtue of an l_next_free_rec < l_count.
	
	  Update everything except the leaf block.
	
	  This shouldn't happen for non-trees. The extent rec cluster
	  count manipulation below only works for interior nodes.
	
	  If our appending insert is at the leftmost edge of a leaf,
	  then we might need to update the rightmost records of the
	  neighboring path.
		
		  No need to worry if the append is already in the
		  leftmost leaf.
			
			  ocfs2_insert_path() will pass the left_path to the
			  journal for us.
			
			  This typically means that the record
			  started in the left path but moved to the
			  right as a result of rotation. We either
			  move the existing record to the left, or we
			  do the later insert there.
			 
			  In this case, the left path should always
			  exist as the rotate code will have passed
			  it back for a post-insert update.
				
				  It's a left split. Since we know
				  that the rotate code gave us an
				  empty extent in the left path, we
				  can just do the insert there.
				
				  Right split - we have to move the
				  existing record over to the left
				  leaf. The insert will be into the
				  newly created empty extent in the
				  right leaf.
		
		  Left path is easy - we can just allow the insert to
		  happen.
  This function only does inserts on an allocation b-tree. For tree
  depth = 0, ocfs2_insert_at_leaf() is called directly.
  right_path is the path we want to do the actual insert
  in. left_path should only be passed in if we need to update that
  portion of the tree after an edge insert.
		
		  There's a chance that left_path got passed back to
		  us without being accounted for in the
		  journal. Extend our transaction here to be sure we
		  can change those blocks.
	
	  Pass both paths to the journal. The majority of inserts
	  will be touching all components anyway.
		
		  We could call ocfs2_insert_at_leaf() for some types
		  of splits, but it's easier to just let one separate
		  function sort it all out.
		
		  Split might have modified either leaf and we don't
		  have a guarantee that the later edge insert will
		  dirty this for us.
		
		  The rotate code has indicated that we need to fix
		  up portions of the tree after the insert.
		 
		  XXX: Should we extend the transaction here?
	
	  Determine the path to start with. Rotations need the
	  rightmost path, everything else can go directly to the
	  target leaf.
	
	  Rotations and appends need special treatment - they modify
	  parts of the tree's above them.
	 
	  Both might pass back a path immediate to the left of the
	  one being inserted to. This will be cause
	  ocfs2_insert_path() to modify the rightmost records of
	  left_path to account for an edge insert.
	 
	  XXX: When modifying this code, keep in mind that an insert
	  can wind up skipping both of these two special cases...
		
		  ocfs2_rotate_tree_right() might have extended the
		  transaction without re-journaling our tree root.
	
	  We're careful to check for an empty extent record here -
	  the merge code will know what to do if it sees one.
		
		  Caller might want us to limit the size of extents, don't
		  calculate contiguousness if we might exceed that limit.
  This should only be called against the righmost leaf extent list.
  ocfs2_figure_appending_type() will figure out whether we'll have to
  insert at the tail of the rightmost leaf.
  This should also work against the root extent list for tree's with 0
  depth. If we consider the root extent list to be the rightmost leaf node
  then the logic here makes sense.
 Were all records empty? 
  Helper function called at the beginning of an insert.
  This computes a few things that are commonly used in the process of
  inserting into the btree:
    - Whether the new extent is contiguous with an existing one.
    - The current tree depth.
    - Whether the insert is an appending one.
    - The total # of free records in the tree.
  All of the information is stored on the ocfs2_insert_type
  structure.
		
		  If we have tree depth, we read in the
		  rightmost extent block ahead of time as
		  ocfs2_figure_insert_type() and ocfs2_add_branch()
		  may want it later.
	
	  Unless we have a contiguous insert, we'll need to know if
	  there is room left in our allocation tree for another
	  extent record.
	 
	  XXX: This test is simplistic, we can search for empty
	  extent records too.
	
	  In the case that we're inserting past what the tree
	  currently accounts for, ocfs2_find_path() will return for
	  us the rightmost tree path. This is accounted for below in
	  the appending code.
	
	  Now that we have the path, there's two things we want to determine:
	  1) Contiguousness (also set contig_index if this is so)
	 
	  2) Are we doing an append? We can trivially break this up
              into two types of appends: simple record append, or a
              rotate inside the tail leaf.
	
	  The insert code isn't quite ready to deal with all cases of
	  left contiguousness. Specifically, if it's an insert into
	  the 1st record in a leaf, it will require the adjustment of
	  cluster count on the last record of the path directly to it's
	  left. For now, just catch that case and fool the layers
	  above us. This works just fine for tree_depth == 0, which
	  is why we allow that above.
	
	  Ok, so we can simply compare against last_eb to figure out
	  whether the path doesn't exist. This will only happen in
	  the case that we're doing a tail append, so maybe we can
	  take advantage of that information somehow.
		
		  Ok, ocfs2_find_path() returned us the rightmost
		  tree path. This might be an appending insert. There are
		  two cases:
		     1) We're doing a true append at the tail:
		 	-This might even be off the end of the leaf
		     2) We're "appending" by rotating in the tail
  Insert an extent into a btree.
  The caller needs to update the owning btree's cluster count.
 Finally, we can add clusters. This might rotate the tree for us. 
  Allcate and add clusters into the extent b-tree.
  The new clusters(clusters_to_add) will be inserted at logical_offset.
  The extent b-tree's root is specified by et, and
  it is not limited to the file storage. Any extent tree can use this
  function if it implements the proper ocfs2_extent_tree.
	 there are two cases which could cause us to EAGAIN in the
	  we-need-more-metadata case:
	  1) we haven't reserved any
	  2) we are so fragmented, we've needed to add metadata too
 reserve our write early -- insert_extent may update the tree root 
	
	  Store a copy of the record on the stack - it might move
	  around as the tree is manipulated below.
		
		  Leftright split. We fake this as a right split
		  first and then make a second pass as a left split.
  Split part or all of the extent record at split_index in the leaf
  pointed to by path. Merge with the contiguous extent record if needed.
  Care is taken to handle contiguousness so as to not grow the tree.
  meta_ac is not strictly necessary - we only truly need it if growth
  of the tree is required. All other cases will degrade into a less
  optimal tree layout.
  last_eb_bh should be the rightmost leaf block for any extent
  btree. Since a split may grow the tree or a merge might shrink it,
  the caller cannot trust the contents of that buffer after this call.
  This code is optimized for readability - several passes might be
  made over certain portions of the tree. All of those blocks will
  have been brought into cache (and pinned via the journal), so the
  extra overhead is not expressed in terms of disk reads.
	
	  The core merge  split code wants to know how much room is
	  left in this allocation tree, so we pass the
	  rightmost extent list.
  Change the flags of the already-existing extent at cpos for len clusters.
  new_flags: the flags we want to set.
  clear_flags: the flags we want to clear.
  phys: the new physical offset we want this new extent starts from.
  If the existing extent is larger than the request, initiate a
  split. An attempt will be made at merging with adjacent extents.
  The caller is responsible for passing down meta_ac if we'll need it.
  Mark the already-existing extent at cpos as written for len clusters.
  This removes the unwritten extent flag.
  If the existing extent is larger than the request, initiate a
  split. An attempt will be made at merging with adjacent extents.
  The caller is responsible for passing down meta_ac if we'll need it.
	
	  XXX: This should be fixed up so that we just re-insert the
	  next extent records.
	
	  Setup the record to split before we grow the tree.
 extend credit for ocfs2_remove_rightmost_path 
		
		  Check whether this is the rightmost tree record. If
		  we remove all of this record or part of its right
		  edge then an update of the record lengths above it
		  will be required.
		
		  Changing the leftmost offset (via partial or whole
		  record truncate) of an interior (or rightmost) path
		  means we have to update the subtree that is formed
		  by this leaf and the one to it's left.
		 
		  There are two cases we can skip:
		    1) Path is the leftmost one in our btree.
		    2) The leaf is rightmost and will be empty after
		       we remove the extent record - the rotate code
		       knows how to update the newly formed edge.
			
			  We skip the edge update if this path will
			  be deleted by the rotate code.
 Remove leftmost portion of the record. 
 Remove rightmost portion of the record 
 Caller should have trapped this. 
	
	  XXX: Why are we truncating to 0 instead of wherever this
	  affects us?
	
	  We have 3 cases of extent removal:
	    1) Range covers the entire extent rec
	    2) Range begins or ends on one edge of the extent rec
	    3) Range is in the middle of the extent rec (no shared edges)
	 
	  For case 1 we remove the extent rec and left rotate to
	  fill the hole.
	 
	  For case 2 we just shrink the existing extent rec, with a
	  tree update if the shrinking edge is also the edge of an
	  extent block.
	 
	  For case 3 we do a right split to turn the extent rec into
	  something case 2 can handle.
		
		  The split could have manipulated the tree enough to
		  move the record location, so we have to look for it again.
		
		  Double check our values here. If anything is fishy,
		  it's easier to catch it at the top level.
  ocfs2_reserve_blocks_for_rec_trunc() would look basically the
  same as ocfs2_lock_alloctors(), except for it accepts a blocks
  number to reserve some extra blocks, and it only handles meta
  data allocations.
  Currently, only ocfs2_remove_btree_range() uses it for truncating
  and punching holes.
 No records, nothing to coalesce 
	 tl_bh is loaded from ocfs2_truncate_log_init().  It's validated
	  by the underlying call to ocfs2_read_inode_block(), so any
 Caller should have known to flush before calling us. 
		
		  Move index back to the record we are coalescing with.
		  ocfs2_truncate_log_can_coalesce() guarantees nonzero
		 Caller has given us at least enough credits to
		 if start_blk is not set, we ignore the record as
 Expects you to already be holding tl_inode->i_mutex 
	 tl_bh is loaded from ocfs2_truncate_log_init().  It's validated
	  by the underlying call to ocfs2_read_inode_block(), so any
	 Appending truncate log(TA) and flushing truncate log(TF) are
	  two separated transactions. They can be both committed but not
	  checkpointed. If crash occurs then, both two transaction will be
	  replayed with several already released to global bitmap clusters.
	  Then truncate log will be replayed resulting in cluster double free.
		 We want to push off log flushes while truncates are
  Try to flush truncate logs if we can free enough clusters from it.
  As for return value, "< 0" means error, "0" no space and "1" means
  we have freed enough spaces and let the caller try to allocate again.
	
	  Check whether we can succeed in allocating if we free
	  the truncate log.
 called during the 1st stage of node recovery. we stamp a clean
  truncate log and pass back a copy for processing later. if the
  truncate log does not require processing, a tl_copy is set to
	 tl_bh is loaded from ocfs2_get_truncate_log_info().  It's
	  validated by the underlying call to ocfs2_read_inode_block(),
		
		  Assuming the write-out below goes well, this copy will be
		  passed back to recovery for processing.
		 All we need to do to clear the truncate log is set
	 ocfs2_truncate_log_shutdown keys on the existence of
	  osb->osb_tl_inode so we don't set any of the osb variables
  Delayed de-allocation of suballocator blocks.
  Some sets of block de-allocations might involve multiple suballocator inodes.
  The locking for this can get extremely complicated, especially when
  the suballocator inodes to delete from aren't known until deep
  within an unrelated codepath.
  ocfs2_extent_block structures are a good example of this - an inode
  btree could have been grown by any number of nodes each allocating
  out of their own suballoc inode.
  These structures allow the delay of block de-allocation until a
  later time, when locking of multiple cluster inodes won't cause
  deadlock.
  Describe a single bit freed from a suballocator.  For the block
  suballocators, it represents one block.  For the global cluster
  allocator, it represents some clusters and free_bit indicates
  clusters number.
 Premature exit may have left some dangling items. 
 Premature exit may have left some dangling items. 
	 If we can't find any free list matching preferred slot, just use
	  the first one.
 Return Value 1 indicates empty 
 If extent was deleted from tree due to extent rotation and merging, and
  no metadata is reserved ahead of time. Try to reuse some extents
  just deleted. This is only used to reuse extent blocks.
  It is supposed to find enough extent blocks in dealloc if our estimation
  on metadata is accurate.
	 If extent tree doesn't have a dealloc, this is not faulty. Just
	  tell upper caller dealloc can't provide any block and it should
	  ask for alloc to claim more space.
 Prefer to use local slot 
		 If no more block can be reused, we should claim more
		  from alloc. Just return here normally.
		 We can't guarantee that buffer head is still cached, so
		  polutlate the extent block again.
		 We'll also be dirtied by the caller, so
		  this isn't absolutely necessary.
	
	  Need to set the buffers we zero'd into uptodate
	  here if they aren't - ocfs2_map_page_blocks()
	  might've skipped some
  Zero partial cluster for a hole punch or truncate. This avoids exposing
  nonzero data on subsequent file extends.
  We need to call this before i_size is updated on the inode because
  otherwise block_write_full_page() will skip writeout of pages past
  i_size.
	
	  File systems which don't support sparse files zero on every
	  extend.
	
	  Avoid zeroing pages fully beyond current i_size. It is pointless as
	  underlying blocks of those pages should be already zeroed out and
	  page writeback will skip them anyway.
	
	  Tail is a hole, or is marked unwritten. In either case, we
	  can count on read and write to returnpush zero's.
	
	  Initiate writeout of the pages we zero'd here. We don't
	  wait on them - the truncate_inode_pages() call later will
	  do that for us.
	
	  We clear the entire i_data structure here so that all
	  fields can be properly initialized.
		
		  Save two copies, one for insert, and one that can
		  be changed by ocfs2_map_and_dirty_page() below.
		
		  This should populate the 1st page for us and mark
		  it up to date.
		
		  An error at this point should be extremely rare. If
		  this proves to be false, we could always re-build
		  the in-inode data from our pages.
  It is expected, that by the time you call this function,
  inode->i_size and fe->i_size have been adjusted.
  WARNING: This will kfree the truncate context
	
	  Check that we still have allocation to delete.
	
	  Truncate always works against the rightmost tree branch.
	
	  By now, el will point to the extent list on the bottom most
	  portion of this tree. Only the tail record is considered in
	  each pass.
	 
	  We handle the following cases, in order:
	  - empty extent: delete the remaining branch
	  - remove the entire record
	  - remove a partial record
	  - no record needs to be removed (truncate has completed)
		
		  Lower levels depend on this never happening, but it's best
		  to check it up here before changing the tree.
		
		  Truncate entire record.
		
		  Partial truncate. it also should be
		  the last truncate we're doing.
		
		  Truncate completed, leave happily.
	
	  The check above will catch the case where we've truncated
	  away all allocation.
  'start' is inclusive, 'end' is not.
 No need to punch hole beyond i_size. 
	
	  No need to worry about the data page here - it's been
	  truncated already and inline data doesn't need it for
	  pushing zero's to disk, so we'll let readpage pick it up
	  later.
	
	  For the first cluster group, the gd->bg_blkno is not at the start
	  of the group, but at an offset from the start. If we add it while
	  calculating discard for first group, we will wrongly start fstrim a
	  few blocks after the desried start block and the range can cross
	  over into the next cluster group. So, add it only if this is not
	  the first cluster group.
	
	  Do some check before trim the first group.
		
		  Determine first and last group to examine based on
		  start and len
	
	  If all the groups trim are not done or failed, but we should release
	  main_bm related locks for avoiding the current IO starve, then go to
	  trim the next group
 Avoid sending duplicated trim to a shared device 
 SPDX-License-Identifier: GPL-2.0-or-later
  userdlm.c
  Code which implements the kernel side of a minimal userspace
  interface to our DLM.
  Many of the functions here are pared down versions of dlmglue.c
  functions.
  Copyright (C) 2003, 2004 Oracle.  All rights reserved.
 I heart container_of... 
 WARNING: This function lives in a world where the only three lock
  levels are EX, PR, and NL. It will have to be adjusted when more
 we're downconverting. 
	 The teardown flag gets set early during the unlock process,
	  so test the cancel flag to make sure that this ast isn't
		 We tried to cancel a convert request, but it was
		  already granted. Don't clear the busy flag - the
 Cancel succeeded, we want to re-queue 
		lockres->l_requested = DLM_LOCK_IV;  cancel an
						     upconvert
		 we want the unblock thread to look at it again
  This is the userdlmfs locking protocol version.
  See fsocfs2dlmglue.c for more details on locking versions.
	 notice that we don't clear USER_LOCK_BLOCKED here. If it's
	 It's valid to get here and no longer be blocked - if we get
	  several basts in a row, we might be queued by the first
	  one, the unblock thread might run and clear the queued
	  flag, and finally we might get another bast which re-queues
	 If there are still incompat holders, we can exit safely
	  without worrying about re-queueing this lock as that will
 yay, we can downconvert now. 
 need lock downconvert request now... 
 predict what lock level we'll be dropping down to on behalf
  of another node, and return true if the currently wanted
	 We only compare against the currently granted level
	  here. If the lock is blocked waiting on a downconvert,
		 is someone sitting in dlm_lock? If so, wait on
		 is the lock is currently blocked on behalf of
 call dlm_lock to upgrade lock now 
 should have been checked before getting here. 
 We ignore recovery events 
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmfs.c
  Code which implements the kernel side of a minimal userspace
  interface to our DLM. This file handles the virtual file system
  used for communication with userspace. Credit should go to ramfs,
  which was a template for the fs side of this module.
  Copyright (C) 2003, 2004 Oracle.  All rights reserved.
 Simple VFS hooks based on: 
  Resizable simple ram filesystem for Linux.
  Copyright (C) 2000 Linus Torvalds.
                2000 Transmeta Corp.
  These are the ABI capabilities of dlmfs.
  Over time, dlmfs has added some features that were not part of the
  initial ABI.  Unfortunately, some of these features are not detectable
  via standard usage.  For example, Linux's default poll always returns
  EPOLLIN, so there is no way for a caller of poll(2) to know when dlmfs
  added poll support.  Instead, we provide this list of new capabilities.
  Capabilities is a read-only attribute.  We do it as a module parameter
  so we can discover it whether dlmfs is built in, loaded, or even not
  loaded.
  The ABI features are local to this machine's dlmfs mount.  This is
  distinct from the locking protocol, which is concerned with inter-node
  interaction.
  Capabilities:
  - bast	: EPOLLIN against the file descriptor of a held lock
 		  signifies a bast fired on the lock.
  decodes a set of open flags into a valid lock level and a set of flags.
  returns < 0 if we have invalid flags
  flags which mean something to us:
  O_RDONLY -> PRMODE level
  O_WRONLY -> EXMODE level
  O_NONBLOCK -> NOQUEUE
	 We don't want to honor O_APPEND at readwrite time as it
		 this is a strange error to return here but I want
		  to be able userspace to be able to distinguish a
		  valid lock request from one that simply couldn't be
  We do ->setattr() just to override size changes.  Our size is the size
  of the LVB and nothing else.
 don't write past the lvb 
	 we must be a directory. If required, lets unregister the
		 for now we don't support anything other than
		 released at clear_inode time, this insures that we
		  get to drop the dlm reference on each lock before
		  we call the unregister code for releasing parent
		 directory inodes start off with i_nlink ==
  File creation. Allocate an inode, and we're done..
 SMP-safe 
 verify that we have a proper domain 
 Extra count - pin the dentry in core 
	 verify name is valid and doesn't contain any dlm reserved
 Extra count - pin the dentry in core 
	 if there are no current holders, or none that are waiting
 this way we can restrict mkdir to only the toplevel of the fs. 
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 SPDX-License-Identifier: GPL-2.0-or-later
  Copyright (C) 2005 Oracle.  All rights reserved.
 This quorum hack is only here until we transition to some more rational
  approach that is driven from userspace.  Honest.  No foolin'.
  Imagine two nodes lose network connectivity to each other but they're still
  up and operating in every other way.  Presumably a network timeout indicates
  that a node is broken and should be recovered.  They can't both recover each
  other and both carry on without serialising their access to the file system.
  They need to decide who is authoritative.  Now extend that problem to
  arbitrary groups of nodes losing connectivity between each other.
  So we declare that a node which has given up on connecting to a majority
  of nodes who are still heartbeating will fence itself.
  There are huge opportunities for races here.  After we give up on a node's
  connection we need to wait long enough to give heartbeat an opportunity
  to declare the node as truly dead.  We also need to be careful with the
  race between when we see a node start heartbeating and when we connect
  to it.
  So nodes that are in this transtion put a hold on the quorum decision
  with a counter.  As they fall out of this transition they drop the count
  and if they're the last, they fire off the decision.
 this is horribly heavy-handed.  It should instead flip the file
	 panic spins with interrupts enabled.  with preempt
 Indicate that a timeout occurred on a heartbeat region write. The
  other nodes in the cluster may consider us dead at that time so we
  want to "fence" ourselves so that we don't scribble on the disk
  after they think they've recovered us. This can't solve all
  problems related to writeout after recovery but this hack can at
  least close some of those gaps. When we have real fencing, this can
  go away as our node would be fenced externally before other nodes
		 the odd numbered cluster case is straight forward --
		 the even numbered cluster adds the possibility of each half
		  of the cluster being able to talk amongst themselves.. in
		  that case we're hosed if we can't talk to the group that has
 as a node comes up we delay the quorum decision until we know the fate of
  the connection.  the hold will be droped in conn_up or hb_down.  it might be
  perpetuated by con_err until hb_down.  if we already have a conn, we might
 hb going down releases any holds we might have had due to this node from
 this tells us that we've decided that the node is still heartbeating
  even though we've lost it's conn.  it must only be called after conn_err
  and indicates that we must now make a quorum decision in the future,
  though we might be doing so after waiting for holds to drain.  Here
 This is analogous to hb_up.  as a node's connection comes up we delay the
  quorum decision until we see it heartbeating.  the hold will be droped in
  hb_up or hb_down.  it might be perpetuated by con_err until hb_down.  if
  it's already heartbeating we might be dropping a hold that conn_up got.
 we've decided that we won't ever be connecting to the node again.  if it's
  still heartbeating we grab a hold that will delay decisions until either the
  node stops heartbeating from hb_down or the caller decides that the node is
 SPDX-License-Identifier: GPL-2.0-only
  sys.c
  OCFS2 cluster sysfs interface
  Copyright (C) 2005 Oracle.  All rights reserved.
 SPDX-License-Identifier: GPL-2.0-or-later
  Copyright (C) 2004, 2005 Oracle.  All rights reserved.
 SPDX-License-Identifier: GPL-2.0-or-later
  Copyright (C) 2004 Oracle.  All rights reserved.
  ----
  Callers for this were originally written against a very simple synchronus
  API.  This implementation reflects those simple callers.  Some day I'm sure
  we'll need to move to a more robust postingcallback mechanism.
  Transmit calls pass in kernel virtual addresses and block copying this into
  the socket's tx buffers via a usual blocking sendmsg.  They'll block waiting
  for a failed socket to timeout.  TX callers can also pass in a poniter to an
  'int' which gets filled with an errno off the wire in response to the
  message they send.
  Handlers for unsolicited messages are registered.  Each socket has a page
  that incoming data is copied into.  First the header, then the data.
  Handlers are called from only one thread with a reference to this per-socket
  page.  This page is destroyed after the handler call, so it can't be
  referenced beyond the call.  Handlers may block but are discouraged from
  doing so.
  Any framing errors (bad magic, large payload lengths) close a connection.
  Our sock_container holds the state we associate with a socket.  It's current
  framing state is held there as well as the refcounting we do around when it
  is safe to tear down the socket.  The socket is only finally torn down from
  the container when the container loses all of its references -- so as long
  as you hold a ref on the container you can trust that the socket is valid
  for use with kernel socket APIs.
  Connections are initiated between a pair of nodes when the node with the
  higher node number gets a heartbeat callback which indicates that the lower
  numbered node has started heartbeating.  The lower numbered node is passive
  and only accepts the connection if the higher numbered node is heartbeating.
  In the following two log macros, the whitespace after the ',' just
  before ##args is intentional. Otherwise, gcc 2.95 will eat the
  previous token if args expands to nothing.
 XXX someday we'll need better accounting 
  listen work is only queued by the listening socket callbacks on the
  o2net_wq.  teardown detaches the callbacks before destroying the workqueue.
  quorum work is queued as sock containers are shutdown.. stop_listening
  tears down all the node's sock containers, preventing future shutdowns
  and queued quroum work, before canceling delayed quorum work and
  destroying the work queue.
 can't quite avoid all internal declarations : 
 CONFIG_DEBUG_FS 
 CONFIG_DEBUG_FS 
 CONFIG_OCFS2_FS_STATS 
 Just in case we mess up the translation table above 
 ------------------------------------------------------------ 
 ------------------------------------------------------------ 
 pin the node item of the remote node 
 ------------------------------------------------------------ 
	 the node num comparison and single connectaccept path should stop
 mirrors o2net_tx_can_proceed() 
	 trigger the connecting worker func as long as we're not valid,
	  it will back off if it shouldn't connect.  This can be called
	  from node config teardown and so needs to be careful about
		 delay if we're within a RECONNECT_DELAY of the
		
		  Delay the expired work after idle timeout.
		 
		  We might have lots of failed connection attempts that run
		  through here but we only cancel the connect_expired work when
		  a connection attempt succeeds.  So only the first enqueue of
		  the connect_expired work will do anything.  The rest will see
		  that it's already queued and do nothing.
 keep track of the nn's sc ref for the caller 
 see o2net_register_callbacks() 
 see o2net_register_callbacks() 
 ignore connecting sockets as they make progress 
  we register callbacks so we can queue work on events before calling
  the original callbacks.  our callbacks our careful to test user_data
  to discover when they've reaced with o2net_unregister_callbacks().
 accepted sockets inherit the old listen socket data ready 
  this is a little helper that is called by callers who have seen a problem
  with an sc and want to detach it from the nn if someone already hasn't beat
  them to it.  if an error is given then the shutdown will be persistent
  and pending transmits will be canceled.
  This work queue function performs the blocking parts of socket shutdown.  A
  few paths lead here.  set_nn_state will trigger this callback if it sees an
  sc detached from the nn.  state_change will also trigger this callback
  directly when it sees errors.  In that case we need to call set_nn_state
  ourselves as state_change couldn't get the nn_lock and call set_nn_state
  itself.
 drop the callbacks ref and call shutdown only once 
		 we shouldn't flush as we're in the thread, the
	 not fatal so failed connects before the other guy has our
 ------------------------------------------------------------ 
 max_len is protection for the handler func.  incoming messages won't
	 the tree and list get this ref.. they're both removed in
 we've had some trouble with handlers seemingly vanishing. 
 ------------------------------------------------------------ 
 should be smarter, I bet 
 Get a map of all nodes to which this node is currently connected to 
	 finally, convert the message header to network byte-order
 wait on other node's handler 
	 Note that we avoid overwriting the callers status return
	  variable if a system error was reported on the other
 must be before dropping sc and node 
	 leave other fields intact from the incoming message, msg_num
 twiddle the magic
 hdr has been in host byteorder this whole time 
 this returns -errno if the header was unknown or too large, etc.
 special type for returning message status 
 find a handler for it 
 this destroys the hdr, so don't use it after this 
 don't bother reconnecting if its the wrong version. 
	
	  Ensure timeouts are consistent with other nodes, otherwise
	  we can end up with one node thinking that the other must be down,
	  but isn't. This can ultimately cause corruption.
	 set valid and queue the idle timers only if it hasn't been
 shift everything up as though it wasn't there 
 this demuxes the queued rx bytes into header or payload bits and calls
  handlers as each full message is read off the socket.  it returns -error,
 do we need more header? 
			 only swab incoming here.. we can
			  only get here once as we cross from
 oof, still don't have a header 
 this was swabbed above when we first read it 
 do we need more payload? 
 need more payload 
		 we can only get here once, the first time we read
		  the payload.. so set ret to progress if the handler
 this work func is triggerd by data ready.  it reads until it can read no
  more.  it interprets 0, eof, as fatal.  if data_ready hits while we're doing
 not permanent so read failed handshake can retry 
 ------------------------------------------------------------ 
 called when a connect completes and after a sock is accepted.  the
 this is called as a work_struct func. 
 socket shutdown does a del_timer_sync against this as it tears down.
  we can't start this timer until we've got to the point in sc buildup
	 idle timerout happen, don't shutdown the connection, but
	  make fence decision. Maybe the connection can recover before
	  the decision is made.
 clear fence decision since the connection recover from timeout
 Only push out an existing timer 
 this work func is kicked whenever a path sets the nn state which doesn't
  have valid set.  This includes seeing hb come up, losing a connection,
  having a connect attempt fail, etc. This centralizes the logic which decides
  if a connect attempt should be made or if we should give up and all future
	
	  sock_create allocates the sock with GFP_KERNEL. We must
	  prevent the filesystem from being reentered by memory reclaim.
 if we're greater we initiate tx, otherwise we accept 
 watch for racing with tearing a node down 
	
	  see if we already have one pending or have given up.
	  For nn_timeout, it is set when we close the connection
	  because of the idle time out. So it means that we have
	  at least connected to that node successfully once,
	  now try to connect to it again.
 freed by sc_kref_release 
 any port 
 handshake completion will set nn->nn_sc_valid 
		 0 err so that another will be queued and attempted
 ------------------------------------------------------------ 
 don't reconnect until it's heartbeating again 
 ensure an immediate connect attempt 
		 believe it or not, accept and node heartbeating testing
		  can succeed for this node before we got here.. so
		  only use set_nn_state to clear the persistent error
 ------------------------------------------------------------ 
	
	  sock_create_lite allocates the sock with GFP_KERNEL. We must
	  prevent the filesystem from being reentered by memory reclaim.
	 this happens all the time when the other node sees our heartbeat
  This function is invoked in response to one or more
  pending accepts at softIRQ level. We must drain the
  entire que before returning.
	
	  It is critical to note that due to interrupt moderation
	  at the network driver level, we can't assume to get a
	  softIRQ for every single conn since tcp SYN packets
	  can arrive back-to-back, and therefore many pending
	  accepts may result in just 1 softIRQ. If we terminate
	  the o2net_accept_one() loop upon seeing an err, what happens
	  to the rest of the conns in the queue? If no new SYN
	  arrives for hours, no softIRQ  will be delivered,
	  and the connections will just sit in the queue.
 check for teardown race 
	 This callback may called twice when a new connection
	  is  being established as a child socket inherits everything
	  from a parent LISTEN socket, including the data_ready cb of
	  the parent. This leads to a hazard. In o2net_accept_one()
	  we are still initializing the child socket but have not
	  changed the inherited data_ready callback yet when
	  data starts arriving.
	  We avoid this hazard by checking the state.
	  For the listening socket,  the state will be TCP_LISTEN; for the new
	  socket, will be  TCP_ESTABLISHED. Also, in this case,
	  sk->sk_user_data is not a valid function pointer.
  called from node manager when we should bring up our network listening
  socket.  node manager handles all the serialization to only call this
  once and to match it with o2net_stop_listening().  note,
  o2nm_this_node() doesn't work yet as we're being called while it
  is being set up.
 ? 
 again, o2nm_this_node() doesn't work here as we're involved in
 stop the listening socket from generating work 
 finish all work and tear down the work queue 
 ------------------------------------------------------------ 
 until we see hb from a node we'll return einval 
 SPDX-License-Identifier: GPL-2.0-or-later
  Copyright (C) 2004, 2005 Oracle.  All rights reserved.
 for now we operate under the assertion that there can be only one
  cluster active at a time.  Changing this will require trickling
 O2NM_FENCE_RESET 
 O2NM_FENCE_PANIC 
 node configfs bits 
	 through the first node_set .parent
	 once we're in the cl_nodes tree networking can look us up by
	  node number and try to use our address and port attributes
	  to connect to this node.. make sure that they've been set
 XXX 
 boolean of whether this node wants to be local 
	 setting local turns on networking rx for now so we require having
 XXX 
	 the only failure case is trying to set a new local node
 bring up the rx thread if we're setting the new local node. 
 node set 
 some stuff? 
 use item.ci_namebuf instead? 
 XXX call into net to stop this node from trading messages 
 XXX sloppy 
 nd_num might be 0 if the node number hasn't been set.. 
 cluster 
 cluster set 
 some stuff? 
	 this runs under the parent dir's i_mutex; there can be only
 XXX sync with hb callbacks and shut down hb? 
 SPDX-License-Identifier: GPL-2.0-or-later
  Copyright (C) 2004, 2005 Oracle.  All rights reserved.
  The first heartbeat pass had one global thread that would serialize all hb
  callback calls.  This global serializing sem should only be removed once
  we've made sure that all callees can deal with being called concurrently
  from multiple hb region threads.
  multiple hb threads are watching multiple regions.  A node is live
  whenever any of the threads sees activity from the node in its region.
  In global heartbeat, we maintain a series of region bitmaps.
  	- o2hb_region_bitmap allows us to limit the region number to max region.
  	- o2hb_live_region_bitmap tracks live regions (seen steady iterations).
  	- o2hb_quorum_region_bitmap tracks live regions that have seen all nodes
  		heartbeat on it.
  	- o2hb_failed_region_bitmap tracks the regions that have seen io timeouts.
 O2HB_HEARTBEAT_LOCAL 
 O2HB_HEARTBEAT_GLOBAL 
  o2hb_dependent_users tracks the number of registered callbacks that depend
  on heartbeat. o2net and o2dlm are two entities that register this callback.
  However only o2dlm depends on the heartbeat. It does not want the heartbeat
  to stop while a dlm domain is still active.
  In global heartbeat mode, all regions are pinned if there are one or more
  dependent users and the quorum region count is <= O2HB_PIN_CUT_OFF. All
  regions are unpinned if the region count exceeds the cut off or the number
  of dependent users falls to zero.
  In local heartbeat mode, we assume the dlm domain name to be the same as
  region uuid. This is true for domains created for the file system but not
  necessarily true for userdlm domains. This is a known limitation.
  In global heartbeat mode, we pinunpin all o2hb regions. This solution
  works for both file system and userdlm domains.
 Only sets a new threshold if there are no active regions.
  No locking or otherwise interesting code is required for reading
  o2hb_dead_threshold as it can't change once regions are active and
 each thread owns a region.. when we're asked to tear down the region
 protected by the hr_callback_sem 
 live node map of this region 
	 let the person setting up hb wait for it to return until it
	  has reached a 'steady' state.  This will be fixed when we have
	 terminate o2hb thread if it does not reach steady state
	 randomized as the region goes up and down so that a node
 negotiate timer, used to negotiate extending hb timeout. 
	 Used during o2hb_check_slot to hold a copy of the block
	  being checked because we temporarily have to zero out the
 Message key for negotiate timeout message. 
 last hb status, 0 for success, other value for error. 
		
		  Fence if the number of failed regions >= half the number
		  of  quorum regions
 Arm writeout only after thread reaches steady state 
 negotiate timeout must be less than write timeout. 
	 don't negotiate timeout if last hb failed since it is very
	  possible io failed. Should let write timeout fence self.
 lowest node as master node to make negotiate decision. 
			 check negotiate bitmap every second to do timeout
			  approve decision.
 approve negotiate timeout request. 
 negotiate timeout with master node. 
 Used in error paths too 
	 sadly atomic_sub_and_test() isn't available on all platforms.  The
 Setup a Bio to cover IO against num_slots slots starting at
	 Testing has shown this allocation to take long enough under
	  GFP_KERNEL that the local node can get fenced. It would be
	  nicest if we could pre-allocate these bios and avoid this
 Must put everything in 512 byte sectors for the bio... 
	 We want to compute the block crc with a 0 value in the
	  hb_cksum field. Save it off here and replace after the
  Compare the slot data with what we wrote in the last iteration.
  If the match fails, print an appropriate error message. This is to
  detect errors like... another node hearting on the same slot,
  flaky device that is losing writes, etc.
  Returns 1 if check succeeds, 0 otherwise.
 Don't check on our 1st timestamp 
 TODO: time stuff 
 This step must always happen last! 
 Will run the list in order until we process the passed event 
	 Holding callback sem assures we don't alter the callback
	  lists when doing this, and serializes ourselves with other
		 We should never have gotten on to the list with a
		  bad type... This isn't something that we should try
 Prevent race with o2hb_heartbeat_group_drop_item() 
 Tag region as quorum only after thread reaches steady state 
	
	  A region can be added to the quorum only when it sees all
	  live nodes heartbeat on it. In other words, the region has been
	  added to all nodes.
	
	  If global heartbeat active, unpin all regions if the
	  region count > CUT_OFF
	
	  If a node is no longer configured but is still in the livemap, we
	  may need to clear that bit from the livemap.
		 all paths from here will drop o2hb_live_lock for
		 Don't print an error on the console in this case -
		  a freshly formatted heartbeat area will not have a
		 The node is live but pushed out a bad crc. We
		  consider it a transient miss but don't populate any
	 we don't care if these wrap.. the state transitions below
	 The node changed heartbeat generations. We assume this to
	  mean it dropped off but came back before we timed out. We
	  want to consider it down for the time being but don't want
	  to lose any changed_samples state we might build up to
	 dead nodes only come to life after some number of
 first on the list generates a callback 
		 We want to be sure that all nodes agree on the
		  number of milliseconds before a node will be
		  considered dead. The self-fencing timeout is
		  computed from this value, and a discrepancy might
		  result in heartbeat calling a node dead when it
 TODO: Perhaps we can fail the region here. 
 if the list is dead, we're done.. 
	 live nodes only go dead after enough consequtive missed
	  samples..  reset the missed counter whenever we see
 last off the live_slot generates a callback 
 node can be null 
		 We don't clear this because the node is still
	
	  If a node is not configured but is in the livemap, we still need
	  to read the slot so as to be able to remove it from the livemap.
	 No sense in reading the slots of nodes that don't exist
	  yet. Of course, if the node definitions have holes in them
	  then we're reading an empty slot anyway... Consider this
	 With an up to date view of the slots, we can check that no
	  other node has been improperly configured to heartbeat in
 fill in the proper info for our next heartbeat 
	
	  We have to be sure we've advertised ourselves on disk
	  before we can go to steady state.  This ensures that
	  people we find in our steady state have seen us.
		 Do not re-arm the write timeout on IO error - we
		  can't be sure that the new block ever made it to
 Skip disarming the timeout if own slot has stalebad data 
 let the person who launched us know when things are steady 
  we ride the region ref that the region dir holds.  before the region
  dir is removed and drops it ref it will wait to tear down this
  thread.
 Pin node 
		 We track the time spent inside
		  o2hb_do_disk_heartbeat so that we avoid more than
		  hr_timeout_ms between disk writes. On busy systems
		  this should result in a heartbeat which is less
			 the kthread api has blocked signals for us so no
 unclean stop is only used in very bad situation 
	 Explicit down notification - avoid forcing the other nodes
	  to timeout on this region when we could just as easily
	  write a clear generation - thus indicating to them that
	  this node has left this region.
 Unpin node 
 max_nodes should be the largest bitmap we pass here 
 If 0, it has never been set before 
 CONFIG_DEBUG_FS 
 if we're already in a callback then we're already serialized by the sem 
  get a map of all nodes that are heartbeating in any regions
	 callers want to serialize this map and callbacks so that they
  heartbeat configfs bits.  The heartbeat set is a default set under
  the cluster set in nodemanager.c.
 drop_item only drops its ref after killing the thread, nothing should
  be using the region anymore.  this has to clean up any state that
 Heartbeat and fs min  max block sizes are the same. 
 Read in all the slots available and populate the tracking
  structures so that we can start with a baseline idea of what's
	 We only want to get an idea of the values initially in each
	  slot, so we do no verification - o2hb_check_slot will
	  actually determine if each configured slot is valid and
		 Only fill the values that o2hb_check_slot uses to
 this is acting as commit; we set up all of hr_bdev and hr_task or nothing 
	 We can't heartbeat without having had our node number
 Generation of zero is invalid 
	
	  A node is considered live after it has beat LIVE_THRESHOLD
	  times.  We're not steady until we've given them a chance
	  _after_ our first read.
	  The default threshold is bare minimum so as to limit the delay
	  during mounts. For global heartbeat, the threshold doubled for the
	  first region.
 unsteady_iterations is triple the steady_iterations 
 Ok, we were woken.  Make sure it wasn't by drop_item() 
 heartbeat set 
 some stuff? 
	 this is the same way to generate msg key as dlm, for local heartbeat,
	  name is also the same, so make initial crc value different to avoid
	  message key conflict.
 stop the thread when the user removes the region dir 
	
	  If we're racing a dev_write(), we need to wake them.  They will
	  check reg->hr_task
	
	  If global heartbeat active and there are dependent users,
	  pin all regions if quorum region count <= CUT_OFF
 this will validate ranges for us. 
 this is just here to avoid touching group in heartbeat.h which the
 hb callback registration and issuing 
  In local heartbeat mode, region_uuid passed matches the dlm domain name.
  In global heartbeat mode, region_uuid passed is NULL.
  In local, we only pin the matching region. In global we pin all the active
  regions.
 local heartbeat 
 Ignore ENOENT only for local hb (userdlm domain) 
  In local heartbeat mode, region_uuid passed matches the dlm domain name.
  In global heartbeat mode, region_uuid passed is NULL.
  In local, we only unpin the matching region. In global we unpin all the
  active regions.
 local heartbeat 
	
	  if global heartbeat active and this is the first dependent user,
	  pin all regions if quorum region count <= CUT_OFF
 local heartbeat 
	
	  if global heartbeat active and there are no dependent users,
	  unpin all quorum regions
 XXX Can this happen _with_ a region reference? 
  this is just a hack until we get the plumbing which flips file systems
  read only and drops the hb ref instead of killing the node dead.
 SPDX-License-Identifier: GPL-2.0-or-later
  netdebug.c
  debug functionality for o2net
  Copyright (C) 2005, 2008 Oracle.  All rights reserved.
 discover the head of the list 
 use st_task to detect real nsts in the list 
 unused, just needs to be null when done 
 get_task_comm isn't exported.  oh well. 
 discover the head of the list miscast as a sc 
 use sc_page to detect real scs in the list 
 unused, just needs to be null when done 
 So that debugfs.ocfs2 can determine which format is being used 
 the stack's structs aren't sparse endian clean 
	 XXX sigh, inet-> doesn't have sparse annotation so any
 CONFIG_DEBUG_FS 
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmrecovery.c
  recovery stuff
  Copyright (C) 2004 Oracle.  All rights reserved.
 Worker function used during recovery. 
		 already have ref on dlm to avoid having
		 this is allowed to sleep and
  RECOVERY THREAD
	 wake the recovery thread
	  this will wake the reco thread in one of three places
	  1) sleeping with no recovery happening
	  2) sleeping with recovery mastered elsewhere
 Launch the recovery thread 
  this is lame, but here's how recovery works...
  1) all recovery threads cluster wide will work on recovering
     ONE node at a time
  2) negotiate who will take over all the locks for the dead node.
     thats right... ALL the locks.
  3) once a new master is chosen, everyone scans all locks
     and moves aside those mastered by the dead guy
  4) each of these locks should be locked until recovery is done
  5) the new master collects up all of secondary lock queue info
     one lock at a time, forcing each node to communicate back
     before continuing
  6) each secondary lock queue responds with the full known lock info
  7) once the new master has run all its locks, it sends a ALLDONE!
     message to everyone
  8) upon receiving this message, the secondary queue node unlocks
     and responds to the ALLDONE
  9) once the new master gets responses from everyone, he unlocks
     everything and recovery for this dead node is done
 10) go back to 2) while there are still dead nodes
 do not sleep, recheck immediately. 
 returns true when the recovery master has contacted us 
 returns true if node is no longer in the domain
 returns true if node is no longer in the domain
 callers of the top-level api calls (dlmlockdlmunlock) should
  block on the dlm->reco.event when recovery is in progress.
  the dlm recovery thread will set this state when it begins
  recovering a dead node (as the new master or not) and clear
  the state and wake as soon as all affected lock resources have
 check to see if the new master has died 
 unset the new_master, leave dead_node 
 select a target to recover 
 BUG? 
 mlog(0, "nothing to recover!  sleeping now!\n");
 return to main thread loop and sleep. 
 take write barrier 
 (stops the list reshuffling thread, proxy ast handling) 
		 choose a new master, returns 0 if this node
		  is the master, -EEXIST if it's another node.
		  this does not return until a new master is chosen
 already notified everyone.  go. 
	 it is safe to start everything back up here
	  because all of the dead node's lock resources
 sleep out in main dlm_recovery_thread loop. 
 we should never hit this anymore 
		 yield a bit to allow any final network messages
 success!  see if any other nodes need recovery 
 continue and look for another dead node 
		 we have become recovery master.  there is no escaping
	 safe to access the node data list without a lock, since this
 node died, ignore it for recovery 
					 wait for the domain map to catch up
 -ENOMEM on the other node 
				 fine.  don't need this node's info.
	 nodes should be sending reco data now
		 check all the nodes now to see if we are
			 Set this flag on recovery master to avoid
			  a new recovery for another dead node start
			  before the recovery is not done. That may
			 all nodes are now in DLM_RECO_NODE_DATA_DONE state
	 		  just send a finalize message to everyone and
 rescan everything marked dirty along the way 
		 wait to be signalled, with periodic timeout
	 nodes can only be removed (by dying) after dropping
 send message
 negative status is handled by caller 
 return from here, then
 sleep until all received or error
 this is a hack 
 this will get freed by dlm_request_all_locks_worker 
 queue up work for dlm_request_all_locks_worker 
 get an extra ref for the work item 
		 worker could have been created before the recovery master
	 lock resources should have already been moved to the
 	  dlm->reco.resources list.  now move items from that list
 	  to a temp list if the dead owner matches.  note that the
	  whole cluster recovers only one node at a time, so we
	  can safely move UNKNOWN lock resources for each recovery
 now we can begin blasting lockreses without the dlm lock 
	 any errors returned will be due to the new_master dying,
 move the resources back to the list 
 should have moved beyond INIT but not to FINALIZE yet 
			 these states are possible at this point, anywhere along
 wake the recovery thread, some node is done 
		 always prune any $RECOVERY entries for dead nodes,
					 Can't schedule DLM_UNLOCK_FREE_LOCK
 add an all-done flag if we reached the last lock 
 send it 
		 XXX: negative status is not handled.
 might get an -ENOMEM back here 
 zero and reinit the message buffer 
 mres here is one full page 
 Ignore lvb in all locks in the blocked list 
 Only consider lvbs in locks with granted EX or PR lock levels 
 Ensure the lvb copied for migration matches in other valid locks 
 returns 1 if this lock fills the network structure,
 we reached the max, send this network message 
 rare, but possible 
 add another lock. 
			 this filled the lock message,
 send a dummy lock to indicate a mastery reference only 
 flush any remaining locks 
  this message will contain no more than one page worth of
  recovery data, and it will work on only one lockres.
  there may be many locks in this page, and we may need to wait
  for additional packets to complete all the locks (rare, but
  possible).
  NOTE: the allocation error cases here are scary
  we really cannot afford to fail an alloc in recovery
  do we spin?  returning an error only delays the problem really
 cannot migrate a lockres with no master 
	 lookup the lock to see if we have a secondary queue for this
	  already...  just add the locks in and this will have its owner
 this will get a ref on res 
 mark it as recoveringmigrating and hash it 
				 this is at least the second
 caller should BUG 
		 need to allocate, just like if it was
		 to match the ref that we would have gotten if
 mark it as recoveringmigrating and hash it 
		 Add an extra ref for this lock-less lockres lest the
		  dlm_thread purges it before we get the chance to add
		 There are three refs that need to be put.
		  1. Taken above.
		  2. kref_init in dlm_new_lockres()->dlm_init_lockres().
		  3. dlm_lookup_lockres()
		  The first one is handled at the end of this function. The
		  other two are handled in the worker thread after locks have
		  been attached. Yes, we don't wait for purge time to match
		  kref_init. The lockres will still have atleast one ref
		 now that the new lockres is inserted,
	 at this point we have allocated everything we need,
	  and we have a hashed lockres with an extra ref and
	 drop this either when master requery finds a different master
 migration cannot have an unknown master 
		 take a reference now to pin the lockres, drop it
 queue up work for dlm_mig_lockres_worker 
 get an extra ref for the work item 
 copy the whole message 
 already have a ref 
 One extra ref taken needs to be put here 
		 this case is super-rare. only occurs if
 cannot touch this lockres 
 See comment in dlm_mig_lockres_handler() 
	 we only reach here if one of the two nodes in a
	  migration died while the migration was in progress.
	  at this point we need to requery the master.  we
	  know that the new_master got as far as creating
	  an mle on at least one node, but we do not know
	  if any nodes had actually cleared the mle and set
	  the master to the new_master.  the old master
	  is supposed to set the owner to UNKNOWN in the
	  event of a new_master death, so the only possible
	  responses that we can get from nodes here are
	  that the master is new_master, or that the master
	  is UNKNOWN.
	  if all nodes come back with UNKNOWN then we know
	  the lock needs remastering here.
	  if any node comes back with a valid master, check
	  to see if that master is the one that we are
	  recovering.  if so, then the new_master died and
	  we need to remaster this lock.  if not, then the
	  new_master survived and that node will respond to
	  other nodes about the owner.
	  if there is an owner, this node needs to dump this
	  lockres and alert the sender that this lockres
 do not send to self 
			 host is down, so answer for that node would be
 this function cannot error, so unless the sending
  or receiving of the message failed, the owner can
		 since the domain has gone away on this
 sender will take care of this and retry 
 put.. incase we are not the master 
 TODO: do ast flush business
  TODO: do MIGRATING and RECOVERING spinning
 NOTE about in-flight requests during migration:
 Before attempting the migrate, the master has marked the lockres as
 MIGRATING and then flushed all of its pending ASTS.  So any in-flight
 requests either got queued before the MIGRATING flag got set, in which
 case the lock data will reflect the change and a return message is on
 the way, or the request failed to get in before MIGRATING got set.  In
 this case, the caller will be told to spin and wait for the MIGRATING
 flag to be dropped, then recheck the master.
 This holds true for the convert, cancel and unlock cases, and since lvb
 updates are tied to these same messages, it applies to lvb updates as
 well.  For the lock case, there is no way a lock can be on the master
 queue and not be on the secondary queue since the lock is always added
 locally first.  This means that the new target node will never be sent
 a lock that he doesn't already have on the list.
 In total, this means that the local lock is correct and should not be
 updated to match the one sent by the master.  Any messages sent back
 from the master before the MIGRATING flag will bring the lock properly
 up-to-date, and the change will be ordered properly for the waiter.
 We will not attempt to modify the lock underneath the waiter.
 placeholder, just need to set the refmap bit 
		 if the lock is for the local node it needs to
		  be moved to the proper location within the queue.
 MIGRATION ONLY! 
			 lock is always created locally first, and
			 see NOTE above about why we do not update
 move the lock to its proper place 
 do not alter lock refcount.  switching lists. 
 lock is for another node. 
		
		  If the lock is in the blocked list it can't have a valid lvb,
		  so skip it
				 other node was trying to update
				  lvb when node died.  recreate the
				 the lock resource lvb update must happen
				  NOW, before the spinlock is dropped.
				  we no longer wait for the AST to update
				 otherwise, the node is sending its
		 NOTE:
		  wrt lock queue ordering and recovery:
		     1. order of locks on granted queue is
		        meaningless.
		     2. order of locks on converting queue is
		        LOST with the node death.  sorry charlie.
		     3. order of locks on the blocked queue is
		        also LOST.
		  order of locks does not affect integrity, it
		  just means that a lock request may get pushed
		  back in line as a result of the node death.
		  also note that for a given node the lock order
		  for its secondary queue locks is preserved
		  relative to each other, but clearly not
		  preserved relative to locks from other nodes.
				 newlock is doing downconvert, add it to the
 balance the ref taken when the work was queued 
 We need to hold a reference while on the recovery list 
 find any pending locks and put them back on proper list 
 move converting lock back to granted 
 remove pending lock requests completely 
				 lock will be floating until ref in
				  dlmlock_remote is freed after the network
				  call returns.  ok for it to not be on any
				  list since no ast can be called
				 if an unlock was in progress, treat as
				  if this had completed successfully
				  before sending this lock state to the
				  new master.  note that the dlm_unlock
				  call is still responsible for calling
				  the unlockast.  that will happen after
				  the network call times out.  for now,
				  just move lists to prepare the new
				 if a cancel was in progress, treat as
				  if this had completed successfully
				  before sending this lock state to the
 removes all recovered locks from the recovery list.
  sets the res->owner to the new master.
			 new_master has our reference from
	 this will become unnecessary eventually, but
	  for now we need to run the whole hash, clear
	  the RECOVERING state and set the owner
			 new_master has our reference from
		 if this node owned the lockres, and if the dead node
		 if this is a secondary lockres, and we had no EX or PR
 check local state for valid lvb 
 zero the lksb lvb and lockres lvb 
	 this node is the lockres master:
	  1) remove any stale locks for the dead node
	  2) if the dead node had an EX when he died, blank out the lvb
	 We do two dlm_lock_put(). One for removing from list and the other is
 TODO: check pending_asts, pending_basts here 
 Can't schedule DLM_UNLOCK_FREE_LOCK - do manually 
 Can't schedule DLM_UNLOCK_FREE_LOCK - do manually 
 Can't schedule DLM_UNLOCK_FREE_LOCK - do manually 
 do not kick thread yet 
 purge any stale mles 
	
	  now clean up all lock resources.  there are two rules:
	 
	  1) if the dead node was the master, move the lockres
	     to the recovering list.  set the RECOVERING flag.
	     this lockres needs to be cleaned up before it can
	     be used further.
	 
	  2) if this node was the master, remove all locks from
	     each of the lockres queues that were owned by the
	     dead node.  once recovery finishes, the dlm thread
	     can be kicked again to see if any ASTs or BASTs
	     need to be fired as a result.
 			 always prune any $RECOVERY entries for dead nodes,
						 Can't schedule
						  DLM_UNLOCK_FREE_LOCK
 zero the lvb if necessary 
			 finalize1 was reached, so it is safe to clear
			  the new_master and dead_node.  that recovery
 Clean up join state on node death. 
 check to see if the node is already considered dead 
 check to see if we do not care about this node 
		 This also catches the case that we get a node down
 make sure local cleanup occurs before the heartbeat events 
 notify anything attached to the heartbeat events 
	 wake up migration waiters if a node goes down.
	
	  This will notify any dlm users that a node in our domain
	  went away without notifying us first.
	 do NOT notify mle attached to the heartbeat events.
  dlm_pick_recovery_master will continually attempt to use
  dlmlock() on the special "$RECOVERY" lockres with the
  LKM_NOQUEUE flag to get an EX.  every thread that enters
  this function on each node racing to become the recovery
  master will not stop attempting this until either:
  a) this node gets the EX (and becomes the recovery master),
  or b) dlm->reco.new_master gets set to some nodenum
  != O2NM_INVALID_NODE_NUM (another node will do the reco).
  so each time a recovery master is needed, the entire cluster
  will sync at this point.  if the new master dies, that will
		 got the EX lock.  check to see if another node
 see if recovery was already finished elsewhere 
		 if this node has actually become the recovery master,
 this always succeeds 
 set the new_master to this node 
		 recovery lock is a special case.  ast will not get fired,
			 this would really suck. this could only happen
			  if there was a network error during the unlock
			  because of node death.  this means the unlock
			  is actually "done" and the lock structure is
			  even freed.  we can continue, but only
		 another node is master. wait on
		  reco.new_master != O2NM_INVALID_NODE_NUM
 another node has informed this one that it is reco master 
 dlmlock returned something other than NOTQUEUED or NORMAL 
 negative status is handled ok by caller here 
			 node is down.  not involved in recovery
		
		  Prior to commit aad1b15310b9bcd59fa81ab8f2b1513b59553ea8,
		  dlm_begin_reco_handler() returned EAGAIN and not -EAGAIN.
		  We are handling both for compatibility reasons.
			 this is now a serious problem, possibly ENOMEM
			 sleep for a bit in hopes that we can avoid
 ok to return 0, domain has gone away 
 may not have seen the new master as dead yet 
		 force the recovery cleanup in __dlm_hb_node_down
				 this has no effect on this recovery
				  session, so set the status to zero to
 reset the node_iter back to the top and send finalize2 
 ok to return 0, domain has gone away 
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmdebug.c
  debug functionality for the dlm
  Copyright (C) 2004, 2008 Oracle.  All rights reserved.
 NOTE: This function converts a lockname into a string. It uses knowledge
  of the format of the lockname that should be outside the purview of the dlm.
  We are adding only to make dlm debugging slightly easier.
  For more on lockname formats, please refer to dlmglue.c and ocfs2_lockid.h.
 begin - utils funcs 
 end - util funcs 
 begin - purge list funcs 
 end - purge list funcs 
 begin - debug mle funcs 
 end - debug mle funcs 
 begin - debug lockres funcs 
 refmap 
 lvb 
 granted 
 converting 
 blocked 
 passed to seq_show 
 end - debug lockres funcs 
 begin - debug state funcs 
 Domain: xxxxxxxxxx  Key: 0xdfbac769 
 Thread Pid: xxx  Node: xxx  State: xxxxx 
 Number of Joins: xxx  Joining Node: xxx 
 Domain Map: xx xx xx 
 Exit Domain Map: xx xx xx 
 Live Map: xx xx xx 
 Lock Resources: xxx (xxx) 
 MLEs: xxx (xxx) 
  Blocking: xxx (xxx) 
  Mastery: xxx (xxx) 
  Migration: xxx (xxx) 
 Lists: Dirty=Empty  Purge=InUse  PendingASTs=Empty  ... 
 Purge Count: xxx  Refs: xxx 
 Dead Node: xxx 
 What about DLM_RECO_STATE_FINALIZE? 
 Recovery Pid: xxxx  Master: xxx  State: xxxx 
 Recovery Map: xx xx 
 Recovery Node State: 
 end  - debug state funcs 
 files in subroot 
 for dumping dlm_ctxt 
 for dumping lockres 
 for dumping mles 
 for dumping lockres on the purge list 
 subroot - domain dir 
 debugfs root 
 CONFIG_DEBUG_FS 
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmlock.c
  underlying calls for lock creation
  Copyright (C) 2004 Oracle.  All rights reserved.
 Tell us whether we can grant a new lock request.
  locking:
    caller needs:  res->spinlock
    taken:         none
    held on exit:  none
  returns: 1 if the lock can be granted, 0 otherwise.
 performs lock creation at the lockres master site
  locking:
    caller needs:  none
    taken:         takes and drops res->spinlock
    held on exit:  none
  returns: DLM_NORMAL, DLM_NOTQUEUED
	 if called from dlm_create_lock_handler, need to
 erf.  state changed after lock was dropped. 
 got it right away 
		 for the recovery lock, we can't allow the ast
		  to be queued since the dlmthread is already
		  frozen.  but the recovery lock is always locked
		  with LKM_NOQUEUE so we do not need the ast in
		 for NOQUEUE request, unless we get the
 either queue the ast or release it 
 remove from local queue if it failed 
  locking:
    caller needs:  none
    taken:         takes and drops res->spinlock
    held on exit:  none
  returns: DLM_DENIED, DLM_RECOVERING, or net status
	
	  Wait if resource is getting recovered, remastered, etc.
	  If the resource was remastered and new owner is self, then exit.
 add lock to local (secondary) queue 
	 spec seems to say that you will get DLM_NORMAL when the lock
			 recovery lock was mastered by dead node.
			  we need to have calc_usage shoot down this
			
			  DO NOT call calc_usage, as this would unhash
			  the remote lockres before we ever get to use
			  it.  treat as if we never made any change to
			  the lockres.
		 special case for the $RECOVERY lock.
		  there will never be an AST delivered to put
		  this lock on the proper secondary queue
 for remote lock creation.
  locking:
    caller needs:  none, but need res->state & DLM_LOCK_RES_IN_PROGRESS
    taken:         none
    held on exit:  none
  returns: DLM_NOLOCKMGR, or net status
 associate a lock with it's lockres, getting a ref on the lockres 
 drop ref on lockres, if there is still one associated with lock 
 zero memory only if kernel-allocated 
 handler for lock creation net message
  locking:
    caller needs:  none
    taken:         takes and drops res->spinlock
    held on exit:  none
  returns: DLM_NORMAL, DLM_SYSERR, DLM_IVLOCKID, DLM_NOTQUEUED
 fetch next node-local (u8 nodenum + u56 cookie) into u64 
 shift single byte of node num into top 8 bits 
	 yes this function is a mess.
	  TODO: clean this up.  lots of common code in the
 CONVERT request 
 if converting, must pass in a valid dlm_lock 
		 XXX: for ocfs2 purposes, the astbastastdatalksb are
	 	  static after the original lock call.  convert requests will
		  ensure that everything is the same, or return DLM_BADARGS.
	 	  this means that DLM_DENIED_NOASTS will never be returned.
			 for now, see how this works without sleeping
			  and just retry right away.  I suspect the reco
			  or migration will complete fast enough that
 LOCK request 
 find or create the lock resource 
			 LVB requests for non PR, PW or EX locks are
				 wait to see the node go down, then
				  drop down and allow the lockres to
 Inflight taken in dlm_get_lock_resource() is dropped here 
 this is kind of unnecessary
	 put lockres ref from the convert path
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmunlock.c
  underlying calls for unlocking locks
  Copyright (C) 2004 Oracle.  All rights reserved.
  according to the spec:
  http:opendlm.sourceforge.netcvsmirroropendlmdocsdlmbook_final.pdf
   flags & LKM_CANCEL != 0: must be converting or blocked
   flags & LKM_CANCEL == 0: must be granted
  So to unlock a converting lock, you must first cancel the
  convert (passing LKM_CANCEL in flags), then call the unlock
  again (with no LKM_CANCEL in flags).
  locking:
    caller needs:  none
    taken:         res->spinlock and lock->spinlock taken and dropped
    held on exit:  none
  returns: DLM_NORMAL, DLM_NOLOCKMGR, status from network
  all callers should have taken an extra ref on lock coming in
	 We want to be sure that we're not freeing a lock
 ok for this to sleep if not in a network handler 
	 see above for what the spec says about
 By now this has been masked out of cancel requests. 
 make the final update to the lvb 
			flags |= LKM_PUT_LVB;  let the send function
 drop locks and send message 
		 if the master told us the lock was already granted,
			 must clear the actions because this unlock
			  is about to be retried.  cannot free or do
	 get an extra ref on lock.  if we are just switching
 remove the extra ref on lock 
		 Unlock request will directly succeed after owner dies,
		  and the lock is already removed from grant list. We have to
		  wait for RECOVERING done or we miss the chance to purge it
		  since the removement is much faster than RECOVERING proc.
 let the caller's final dlm_lock_put handle the actual kfree 
 this should always be coupled with list removal 
 if cancel or unlock succeeded, lvb work is done 
	 leave DLM_LKSB_PUT_LVB on the lksb so any final
  locking:
    caller needs:  none
    taken:         none
    held on exit:  none
  returns: DLM_NORMAL, DLM_NOLOCKMGR, status from network
		 ended up trying to contact ourself.  this means
		  that the lockres had been remote but became local
 extra data to send if we are updating lvb 
 successfully sent and received
			 NOTE: this seems strange, but it is what we want.
			  when the master goes down during a cancel or
			  unlock, the recovery code completes the operation
			  as if the master had not died, then passes the
			  updated state to the recovery master.  this thread
			  just needs to finish out the operation and call
 something bad.  this will BUG in ocfs2 
  locking:
    caller needs:  none
    taken:         takes and drops res->spinlock
    held on exit:  none
  returns: DLM_NORMAL, DLM_BADARGS, DLM_IVLOCKID,
           return value from dlmunlock_master
		 We assume here that a no lock resource simply means
		  it was migrated away and destroyed before the other
 scan granted -> converting -> blocked queues 
 lock was found on queue 
 unlockast only called on originating node 
	 if this is in-progress, propagate the DLM_FORWARD
 cancel this outright 
 cancel the request, put back on granted 
 too late, already granted. 
 unlock request 
 unlock granted lock 
 there seems to be no point in doing this async
  since (even for the remote case) there is really
  no work to queue up... so just do it and fire the
 need to retry up here because owner may have changed 
		 We want to go away for a tiny bit to allow recovery
		   migration to complete on this resource. I don't
		  know of any wait queue we could sleep on as this
		  may be happening on another node. Perhaps the
		  proper solution is to queue up requests on the
 do we want to yield(); ?? 
			 it is possible that there is one last bast
			  pending.  make sure it is flushed, then
			  call the unlockast.
			  not an issue if this is a mastered remotely,
			  since this lock has been removed from the
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmmod.c
  standalone DLM module
  Copyright (C) 2004 Oracle.  All rights reserved.
		case -EINVAL:    if returned from our tcp code,
  MASTER LIST FUNCTIONS
  regarding master list entries and heartbeat callbacks:
  in order to avoid sleeping and allocation that occurs in
  heartbeat, master list entries are simply attached to the
  dlm's established heartbeat callbacks.  the mle is attached
  when it is created, and since the dlm->spinlock is held at
  that time, any heartbeat event will be properly discovered
  by the mle.  the mle needs to be detached from the
  dlm->mle_hb_events list as soon as heartbeat events are no
  longer useful to the mle, and before the mle is freed.
  as a general rule, heartbeat events are no longer needed by
  the mle once an "answer" regarding the lock master has been
  received.
 remove from list and free 
		 this may or may not crash, but who cares.
 must not have any spinlocks coming in 
 copy off the node_map and register hb callbacks on our copy 
 attach the mle to the domain node updown events 
 returns 1 if found, 0 if not 
 remove from list if not already 
 detach the mle from the domain node updown events 
	 NOTE: kfree under spinlock here.
  LOCK RESOURCE FUNCTIONS
	 This should not happen -- all lockres' have a name
	 By the time we're ready to blow this guy away, we shouldn't
	 If we memset here, we lose our reference to the kmalloc'd
	  res->lockname.name, so be sure to init every field
 just for consistency 
  lookup a lock resource by name.
  may already exist in the hashtable.
  lockid is null terminated
  if not, allocate enough for the lockres and for
  the temporary structure used in doing the mastering.
  also, do a lookup in the dlm->master_list to see
  if another node has begun mastering the same lock.
  if so, there should be a block entry in there
  for this name, and we should not attempt to master
  the lock here.   need to wait around for that node
  to assert_master (or die).
		
		  Right after dlm spinlock was released, dlm_thread could have
		  purged the lockres. Check if lockres got unhashed. If so
		  start over.
 Wait on the thread that is mastering the resource 
 Wait on the resource purge to complete before continuing 
 Grab inflight ref to pin the resource 
 nothing found and we need to allocate one. 
		 caller knows it's safe to assume it's not mastered elsewhere
 lockres still marked IN_PROGRESS 
 check master list to see if another node has started mastering it 
 if we found a block, wait for lock to be mastered by another node 
		 if there is a migration in progress, let the migration
		  finish before continuing.  we can wait for the absence
		  of the MIGRATION mle: either the migrate finished or
		  one of the nodes died and the mle was cleaned up.
		  if there is a BLOCK here, but it already has a master
		  set, we are too late.  the master does not have a ref
		  for us in the refmap.  detach the mle and drop it.
			 we arrived too late.  the master does not
 master is known, detach 
			 this is lame, but we can't wait on either
 go ahead and try to master lock on this node 
 make sure this does not get freed below 
		 still holding the dlm spinlock, check the recovery map
		  to see if there are any nodes that still need to be
		  considered.  these will not appear in the mle nodemap
	 at this point there is either a DLM_MLE_BLOCK or a
	  DLM_MLE_MASTER on the master list, so it's safe to add the
	  lockres to the hashtable.  anyone who finds the lock will
 finally add the lockres to its hash bucket 
 since this lockres is new it doesn't not require the spinlock 
	 get an extra ref on the mle in case this is a BLOCK
	  if so, the creator of the BLOCK may try to put the last
	  ref at this time in the assert master handler, so we
		 any cluster changes that occurred after dropping the
		  dlm spinlock would be detectable be a change on the mle,
 must wait for lock to be mastered elsewhere 
 found a master ! 
			 if our master request has not reached the master
			  yet, keep going until it does.  this is how the
			  master will know that asserts are needed back to
 keep going until the response map includes all nodes 
 make sure we never continue without this 
 master is known, detach if not already detached 
 put the extra ref 
 need to free the unused mle 
 check if another node has already become the owner 
		 this will cause the master to re-assert across
 give recovery a chance to run 
 restart if we hit any errors 
		 another node has done an assert!
 have all nodes responded? 
				 my node number is lowest.
			 	  now tell other nodes that I am
				 ref was grabbed in get_lock_resource
			 if voting is done, but we have not received
 sleep if we haven't finished voting yet 
 done 
			 This is a failure in the network path,
			  not in the response to the assert_master
			  (any nonzero response is a BUG on this node).
			  Most likely a socket just got disconnected
		 no longer need to restart lock mastery.
 set the lockres owner 
	 mastery reference obtained either during
 if it was there in the original then this node died 
			 a node came up.  clear any old vote from
			  the response map and set it in the vote map
 redo the master request, but only for the new node 
 act like it was never there 
						 mle is an MLE_BLOCK, but
						  there is now nothing left to
						  block on.  we need to return
						  all the way back out and try
						  again with an MLE_MASTER.
						  dlm_do_local_recovery_cleanup
						  has already run, so the mle
			 now blank out everything, as if we had never
 reset the vote_map to the current node_map 
 put myself into the maybe map 
  DLM_MASTER_REQUEST_MSG
  returns: 0 on success,
           -errno on a network error
  on error, the caller should assume the target node is "dead"
 should never happen 
 this is totally crude 
 not a network error. bad. 
		 all other errors should be network errors,
 this is also totally crude 
  locks that can be taken here:
  dlm->spinlock
  res->spinlock
  mle->spinlock
  dlm->master_list
  if possible, TRIM THIS DOWN!!!
 take care of the easy cases up front 
		
		  Right after dlm spinlock was released, dlm_thread could have
		  purged the lockres. Check if lockres got unhashed. If so
		  start over.
			 this node is the owner.
			  there is some extra work that needs to
			  happen now.  the requesting node has
			  caused all nodes up to this one to
			  create mles.  this node now needs to
 mlog(0, "node %u is the master\n", res->owner);
		 ok, there is no owner.  either this node is
		  being blocked, or it is actively trying to
 mlog(0, "lockres is in progress...\n");
 mlog(0, "this node is waiting for "
 "lockres to be mastered\n");
 the real master can respond on its own 
				 this node will be the owner.
				  go back and clean the mles on any
 mlog(0, "this node is attempting to "
 "master lockres\n");
 keep the mle attached to heartbeat events 
	
	  lockres doesn't exist on this node
	  if there is an MLE_BLOCK, return NO
	  if there is an MLE_MASTER, return MAYBE
	  otherwise, add an MLE_BLOCK, return NO
 this lockid has never been seen on this node yet 
 mlog(0, "no mle found\n");
 mlog(0, "this is second time thru, already allocated, "
 "add the block.\n");
 real master can respond on its own 
 keep the mle attached to heartbeat events 
	
	  __dlm_lookup_lockres() grabbed a reference to this lockres.
	  The reference is released by dlm_assert_master_worker() under
	  the call to dlm_dispatch_assert_master().  If
	  dlm_assert_master_worker() isn't called, we drop it here.
  DLM_ASSERT_MASTER_MSG
  NOTE: this can be used for debugging
  can periodically run all locks owned by this node
  and re-assert across the cluster...
 note that if this nodemap is empty, it returns 0 
 a node died.  finish out the rest of the nodes. 
 any nonzero status return will do 
 ok, something horribly messed.  kill thyself. 
  locks that can be taken here:
  dlm->spinlock
  res->spinlock
  mle->spinlock
  dlm->master_list
  if possible, TRIM THIS DOWN!!!
 find the MLE 
 not an error, could be master just re-asserting 
			 not necessarily an error, though less likely.
				 with the fix for bug 569, a higher node
				  number winning the mastery will respond
				  YES to mastery requests, but this node
	 ok everything checks out with the MLE
 owner is just re-asserting 
 mle->type == DLM_MLE_MIGRATION  {
 should only be getting an assert from new master 
 mlog(0, "woo!  got an assert_master from node %u!\n",
 	     assert->node_idx);
			 MASTER mle: if any bits set in the response map
			  then the calling node needs to re-assert to clear
		 master is known, detach if not already detached.
		  ensures that only one assert_master call will happen
			 the assert master message now balances the extra
		 	  ref given by the master  migration request message.
		 	  if this is the last put, it will be removed
 positive. negative would shoot down the node. 
 let the master know we have a reference to the lockres 
 kill the caller! 
 queue up work for dlm_assert_master_worker 
 already have a ref 
 can optionally ignore node numbers higher than this node 
		 if is this just to clear up mles for nodes below
		  this node, do not send the message to the original
	
	  If we're migrating this lock to someone else, we are no
	  longer allowed to assert out own mastery.  OTOH, we need to
	  prevent migration from starting while we're still asserting
	  our dominance.  The reserved ast delays migration.
	 this call now finishes out the nodemap
 no need to restart, we are done 
 Ok, we've asserted ourselves.  Let's let migration start. 
 SPECIAL CASE for the $RECOVERY lock used by the recovery thread.
  We cannot wait for node recovery to complete to begin mastering this
  lockres because this lockres is used to kick off recovery! ;-)
  So, do a pre-check on all living nodes to see if any of those nodes
  think that $RECOVERY is currently mastered by a dead node.  If so,
  we wait a short time to allow that node to get notified by its own
  heartbeat stack, then check again.  All $RECOVERY lock resources
  mastered by dead nodes are purged when the heartbeat callback is
  fired, so we can know for sure that it is safe to continue once
 do not send to self 
			 host is down, so answer for that node would be
 check to see if this master is in the recovery map 
  DLM_DEREF_LOCKRES_MSG
 BAD.  other node says I did not have a ref. 
 ignore the error 
  A migratable resource is one that is :
  1. locally mastered, and,
  2. zero local locks, and,
  3. one or more non-local locks, or, one or more references
  Returns 1 if yes, 0 if not.
 delay migration when the lockres is in MIGRATING state 
 delay migration when the lockres is in RECOCERING state 
  DLM_MIGRATE_LOCKRES
 preallocate up front. if this fails, abort 
	
	  clear any existing master requests and
	  add the migration mle to the list
	 get an extra reference on the mle.
	  otherwise the assert_master from the new
	  master will destroy this.
	
	  set the MIGRATING flag and flush asts
	  if we fail after this we need to re-dirty the lockres
 master is known, detach if not already detached 
	
	  at this point, we have a migration target, an mle
	  in the master list, and the MIGRATING flag set on
	  the lockres
	 now that remote nodes are spinning on the MIGRATING flag,
 notify new node and send all lock state 
	 call send_one_lockres with migration flag.
	  this serves as notice to the target node that a
 migration failed, detach and clean up mle 
	 at this point, the target sends a message to all nodes,
	  (using dlm_do_migrate_request).  this node is skipped since
	  we had to put an mle in the list to begin the process.  this
	  node now waits for target to do an assert master.  this node
	  will be the last one notified, ensuring that the migration
	  is complete everywhere.  if the target dies while this is
	  going on, some nodes could potentially see the target as the
	  master, so it is important that my recovery finds the migration
 wait for new node to assert master 
			 avoid hang during shutdown when migrating lockres
 migration failed, detach and clean up mle 
 all done, set the owner, clear the flag 
 master is known, detach if not already detached 
 re-dirty the lockres if we failed 
	 wake up waiters if the MIGRATING flag got set
  Should be called only after beginning the domain leave process.
  There should not be any remaining locks on nonlocal lock resources,
  and there should be no local locks left on locally mastered resources.
  Called with the dlm spinlock held, may drop it to do migration, but
  will re-acquire before exit.
  Returns: 1 if dlm->spinlock was droppedretaken, 0 if never dropped
 Wheee! Migrate lockres here! Will sleep so drop spinlock. 
	 target has died, so make the caller break out of the
	 need to set MIGRATING flag on lockres.  this is done by
	 strategy is to reserve an extra ast then release
 now flush all the pending asts 
	 before waiting on DIRTY, block processes which may
 now wait on any pending asts and the DIRTY state 
	 if the extra ref we just put was the final one, this
	  will pass thru immediately.  otherwise, we need to wait
 did the target go down or die? 
	
	  if target is down, we need to clear DLM_LOCK_RES_BLOCK_DIRTY for
	  another try; otherwise, we are sure the MIGRATING state is there,
	  drop the unneeded state which blocked threads trying to DIRTY
	
	  at this point:
	 
	    o the DLM_LOCK_RES_MIGRATING flag is set if target not down
	    o there are no pending asts on this lockres
	    o all processes trying to reserve an ast on this
	      lockres must wait for the MIGRATING flag to clear
 last step in the migration process.
  original master calls this to free all of the dlm_lock
 be extra careful 
				 In a normal unlock, we would have added a
		 do not clear the local node reference, if there is a
  Pick a node to migrate the lock resource to. This function selects a
  potential target based first on the locks and then on refmap. It skips
  nodes that are in the process of exiting the domain.
 Go through all the locks 
 Go thru the refmap 
 this is called by the new master once all lockres
 send message to all nodes, except the master and myself 
 We could race exit domain. If exited, skip. 
			 during the migration request we short-circuited
			  the mastery of the lockres.  make sure we have
 if there is an existing mle for this lockres, we now know who the master is.
  (the one who sent us this message) we can clear it up right away.
  since the process that put the mle on the list still has a reference to it,
  we can unhash it now, set the master and wake the process.  as a result,
  we will have no mle in the list to start with.  now we can add an mle for
  the migration and this should be the only one found for those scanning the
 preallocate.. if this fails, abort 
 check for pre-existing lock 
			 if all is working ok, this can only mean that we got
		 	 a migrate request from a node that we now see as
 need a better solution 
 ignore status.  only nonzero status would BUG. 
 master is known, detach if not already detached 
 must be holding dlm->spinlock and dlm->master_lock
  when adding a migration mle, we can clear any other mles
  in the master list because we know with certainty that
  the master is "master".  so we remove any old mle from
  the list after setting it's master field, and then add
  the new migration mle.  this way we can hold with the rule
 caller is responsible for any ref taken here on oldmle 
 ah another process raced me to it 
 bad.  2 NODES are trying to migrate! 
 request: "
 "
 this is essentially what assert_master does 
 remove it so that only one mle will be found 
 now add a migration mle to the tail of the list 
	 the new master will be sending an assert master for this.
 do this for consistency with other mle types 
  Sets the owner of the lockres, associated to the mle, to UNKNOWN
 Find the lockres associated to the mle and set its owner to UNK 
 move lockres onto recovery list 
 about to get rid of mle, detach from heartbeat 
 dump the mle 
		 Must drop the refcount by one since the assert_master will
		  never arrive. This may result in the mle being unlinked and
		  freed, but there may still be a process waiting in the
 Do not need events any longer, so detach from heartbeat 
 clean the master list 
			 MASTER mles are initiated locally. The waiting
			  process will notice the node map change shortly.
			 BLOCK mles are initiated by other nodes. Need to
			  clean up if the dead node would have been the
 Everything else is a MIGRATION mle 
			 The rule for MIGRATION mles is that the master
			  becomes UNKNOWN if either the original or the new
			  master dies. All UNKNOWN lockres' are sent to
			  whichever node becomes the recovery master. The new
			  master is responsible for determining if there is
			  still a master for this lockres, or if he needs to
			  take over mastery. Either way, this node should
			 If we have reached this point, this mle needs to be
			 If we find a lockres associated with the mle, we've
			  hit this rare case that messes up our lock ordering.
			  If so, we need to drop the master lock so that we can
			  take the lockres lock, meaning that we will have to
 restart 
 This may be the last reference 
	 ownership of the lockres is changing.  account for the
	  mastery reference here since old_master will briefly have
	 this call now finishes out the nodemap
 no longer need to retry.  all living nodes contacted. 
		 the only nonzero status here would be because of
 all done, set the owner, clear the flag 
 re-dirty it on the new master 
  LOCKRES AST REFCOUNT
  this is integral to migration
 for future intent to call an ast, reserve one ahead of time.
  this should be called only after waiting on the lockres
  with dlm_wait_on_lockres, and while still holding the
  used to drop the reserved ast, either because it went unused,
  or because the astbast was actually called.
  also, if there is a pending migration on this lockres,
  and this was the last pending ast on the lockres,
  atomically set the MIGRATING flag before we drop the lock.
  this is how we ensure that migration can proceed with no
  asts in progress.  note that it is ok if the state of the
  queues is such that a lock should be granted in the future
  or that a bast should be fired, because the new master will
  shuffle the lists on this lockres as soon as it is migrated.
	
	  We notified all other nodes that we are exiting the domain and
	  marked the dlm state to DLM_CTXT_LEAVING. If any mles are still
	  around we force free them and wake any processes that are waiting
	  on the mles
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmast.c
  AST and BAST functionality for local and remote nodes
  Copyright (C) 2004 Oracle.  All rights reserved.
 Should be called as an ast gets queued to see if the new
  lock level will obsolete a pending bast.
  For example, if dlm_thread queued a bast for an EX lock that
  was blocking another EX, but before sending the bast the
  lock owner downconverted to NL, the bast is now obsolete.
  Only the ast should be sent.
  This is needed because the lock and convert paths can queue
  asts out-of-band (not waiting for dlm_thread) in order to
 old bast already sent, ok 
 EX blocks anything left, any bast still valid 
 NL blocks nothing, no reason to send any bast, cancel it 
 PR only blocks EX 
 putting lock on list, add a ref 
 check to see if this ast obsoletes the bast 
		 removing lock from list, remove a ref.  guaranteed
		  this won't be the last ref because of the get above,
		 free up the reserved bast that we are cancelling.
		  guaranteed that this will not be the last reserved
		  ast because both an ast and a bast were reserved
		  to get to this point.  the res->spinlock will not be
 putting lock on list, add a ref 
 only updates if this node masters the lockres 
 check the lksb flags for the direction 
		 Do nothing for lvb put requests - they should be done in
 		  place when the lock is downconverted - otherwise we risk
 		  racing gets and puts which could result in old lvb data
 		  being propagated. We leave the put flag set and clear it
 		  here. In the future we might want to clear it at the time
 		  the put is actually done.
 reset any lvb flags on the lksb 
	 lock request came from another node
 cannot get a proxy ast message if this node owns it 
 try convert queue for both astbast 
 if not on convert, try blocked for ast, granted for bast 
 if lock is found but unlock is pending ignore the bast 
 do not alter lock refcount.  switching lists. 
 should already be there....
 if we requested the lvb, fetch it into our lksb now 
 ignore it 
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmdomain.c
  defines domain join  leave apis
  Copyright (C) 2004 Oracle.  All rights reserved.
  ocfs2 node maps are array of long int, which limits to send them freely
  across the wire due to endianness issues. To workaround this, we convert
  long ints to byte arrays. Following 3 routines are helper functions to
  settestcopy bits within those array of bytes
  spinlock lock ordering: if multiple locks are needed, obey this ordering:
     dlm_domain_lock
     struct dlm_ctxt->spinlock
     struct dlm_lock_resource->spinlock
     struct dlm_ctxt->master_lock
     struct dlm_ctxt->ast_lock
     dlm_master_list_entry->spinlock
     dlm_lock->spinlock
  The supported protocol version for DLM communication.  Running domains
  will have a negotiated version with the same major number and a minor
  number equal or smaller.  The dlm_ctxt->dlm_locking_proto field should
  be used to determine what a running domain is actually using.
  New in version 1.1:
 	- Message DLM_QUERY_REGION added to support global heartbeat
 	- Message DLM_QUERY_NODEINFO added to allow online node removes
  New in version 1.2:
  	- Message DLM_BEGIN_EXIT_DOMAIN_MSG added to mark start of exit domain
  New in version 1.3:
 	- Message DLM_DEREF_LOCKRES_DONE added to inform non-master that the
 	  refmap is cleared
 get a reference for our hashtable 
 intended to be called by functions which do not care about lock
  resources which are being purged (most net _handler functions).
  this will return NULL for any lock resource which is found but
  currently in the process of dropping its mastery reference.
  use __dlm_lookup_lockres_full when you need the lock resource
	 tmp->name here is always NULL terminated,
 For null terminated domain strings ONLY 
 returns true on one of two conditions:
  1) the domain does not exist
 A little strange - this function will be called while holding
  dlm_domain_lock and is expected to be holding it on the way out. We
 we may still be in the list if we hit an error during join. 
 given a questionable reference to a dlm object, gets a reference if
  it can find it in the list, otherwise returns NULL in which case
	 We've left the domain. Now we can take ourselves out of the
	  list and allow the kref stuff to help us free the
 Wake up anyone waiting for us to remove this domain 
			 migrate, if necessary.  this will drop the dlm
	 let the dlm thread take care of purging, keep scanning until
	 Yikes, a double spinlock! I need domain_lock for the dlm
 notify anything attached to the heartbeat events 
 Support for begin exit domain was added in 1.2 
	
	  Unlike DLM_EXIT_DOMAIN_MSG, DLM_BEGIN_EXIT_DOMAIN_MSG is purely
	  informational. Meaning if a node does not receive the message,
	  so be it.
	 At this point we've migrated away all our locks and won't
	  accept mastership of new ones. The dlm is responsible for
	  almost nothing now. We make sure not to confuse any joining
 Clear ourselves from the domain map 
		 Drop the dlm spinlock. This is safe wrt the domain_map.
		  -nodes cannot be added now as the
		    query_join_handlers knows to respond with OK_NO_MAP
		  -we catch the right network errors if a node is
		    removed from the map while we're sending him the
			 Not sure what to do here but lets sleep for
			  a bit in case this was a transient
		 If we're not clearing the node bit then we intend
		 We mark it "in shutdown" now so new register
		  requests wait until we've completely left the
		  domain. Don't use DLM_CTXT_LEAVING yet as we still
		  want new domain joins to communicate with us at
		  least until we've completed migration of our
 We changed dlm state, notify the thread 
 Give dlm_thread time to purge the lockres' 
 This list should be empty. If not, print remaining lockres 
  struct dlm_query_join_packet is made up of four one-byte fields.  They
  are effectively in big-endian order already.  However, little-endian
  machines swap them before putting the packet on the wire (because
  query_join's response is a status, and that status is treated as a u32
  on the wire).  Thus, a big-endian and little-endian machines will treat
  this structure differently.
  The solution is to have little-endian machines swap the structure when
  converting from the structure to the u32 representation.  This will
  result in the structure having the correct format on the wire no matter
  the host endian format.
	
	  If heartbeat doesn't consider the node live, tell it
	  to back off and try again.  This gives heartbeat a chance
	  to catch up.
	
	  There is a small window where the joining node may not see the
	  node(s) that just left but still part of the cluster. DISALLOW
	  join request if joining node has different node map.
	 Once the dlm ctxt is marked as leaving then we don't want
	  to be put in someone's domain map.
	  Also, explicitly disallow joining at certain troublesome
			If this is a brand new context and we
			  haven't started our join process yet, then
 Disallow parallel joins. 
			 Alright we're fully a part of this domain
			  so we keep some state as to who's joining
			  and indicate to him that needs to be fixed
 Make sure we speak compatible locking protocols.  
 XXX should we consider no dlm ctxt an error? 
		 Alright, this node has officially joined our
		  domain. Set him in the map and clean up our
 notify anything attached to the heartbeat events 
 compare local regions with remote 
 compare remote with local regions 
 if local hb, the numregions will be zero 
 buffer used in dlm_mast_regions() 
 Support for global heartbeat was added in 1.1 
 Support for node query was added in 1.1 
		 Yikes, this guy wants to cancel his join. No
 map_size should be in bytes. 
 copy live node map to join message 
	 -ENOPROTOOPT from the net code means the other side isn't
	    listening for our message type -- that's fine, it means
	    his dlm isn't up, so we can consider him a 'yes' but not
 Use the same locking protocol as the remote node 
 Reset response to JOIN_DISALLOW 
			 It is very important that this message be
			  received so we spin until either the node
 give us some time between errors... 
	 For now, we restart the process if the node maps have
	 group sem locking should work for us here -- we're already
	  registered for heartbeat events so filling this should be
		 Ok, either we got a response or the node doesn't have a
	 Yay, everyone agree's we can join the domain. My domain is
	  comprised of all nodes who were put in the
	  yes_resp_map. Copy that into our domain map and send a join
 Support for global heartbeat and node info was added in 1.1 
	 Joined state must be set before the joining node
	  information, otherwise the query_join handler may read no
	  current joiner but a state of NEW and tell joining nodes
 Do we need to send a cancel message to any nodes? 
		 If we're racing another node to the join, then we
		  need to back off temporarily and let them
			
			  <chip> After you!
			  <dale> No, after you!
			  <chip> I insist!
			  <dale> But you first!
			  ...
  Compare a requested locking protocol version against the current one.
  If the major numbers are different, they are incompatible.
  If the current minor is greater than the request, they are incompatible.
  If the current minor is less than or equal to the request, they are
  compatible, and the requester should run at the current minor version.
  dlm_register_domain: one-time setup per "domain".
  The filesystem passes in the requested locking version via proto.
  If registration was successful, proto will contain the negotiated
  locking protocol.
 doesn't exist 
 a little variable switch-a-roo here... 
 add the new domain 
	
	  Pass the locking protocol version into the join.  If the join
	  succeeds, it will have the negotiated protocol set.
 Tell the caller what locking protocol we negotiated 
 Domain eviction callback handling.
  The file system requires notification of node death before the
  dlm completes it's recovery work, otherwise it may be able to
  acquire locks on resources requiring recovery. Since the dlm can
  evict a node from it's domain before heartbeat fires, a similar
 Eviction is not expected to happen often, so a per-domain lock is
  not necessary. Eviction callbacks are allowed to sleep for short
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmthread.c
  standalone DLM module
  Copyright (C) 2004 Oracle.  All rights reserved.
 will exit holding res->spinlock, but may drop in function 
 waits until flags are cleared on res->state 
 "unused": the lockres has no locks, is not on the dirty list,
  has no inflight locks (in the gap between mastery and acquiring
  the first lock), and has no bits in its refmap.
 Locks are in the process of being created 
 Another node has this resource with this node as the master 
 Call whenever you may have added or deleted something from one of
  the lockres queue's. This will figure out whether it belongs on the
  Do the real purge work:
      unhash the lockres, and
      clear flag DLM_LOCK_RES_DROPPING_REF.
  It requires dlm and lockres spinlock to be taken.
	
	  lockres is not in the hash now. drop the flag and wake up
	  any processes waiting in dlm_get_lock_resource.
 drop spinlock...  retake below 
 This ensures that clear refmap is sent after the set 
 clear our bit from the master's refmap, ignore errors 
	 lockres is not in the hash now.  drop the flag and wake up
		 Make sure that we want to be processing this guy at
			 Since resources are added to the purge list
			  in tail order, we can stop at the first
			  unpurgable resource -- anyone added after
		 Status of the lockres might change so double
		  check. If the lockres is unused, holding the dlm
		  spinlock will prevent people from getting and more
 Avoid adding any scheduling latencies 
	
	  Because this function is called with the lockres
	  spinlock, and because we know that it is not migrating
	  recoveringin-progress, it is fine to reserve asts and
	  basts right before queueing them all throughout
 queue the BAST if not already 
 update the highest_blocked if needed 
 we can convert the lock 
 go back and check for more 
	 we can grant the blocked lock (only
 target->ml.type is already correct 
 go back and check for more 
 must have NO locks when calling this with res !=NULL  
 don't shuffle secondary queues 
 ref for dirty_list 
 Launch the NM thread for the mounted volume 
 get an extra ref on lock 
 remove from list (including ref) 
		 possible that another ast was queued while
		 drop the extra ref.
 get an extra ref on lock 
 get the highest blocked lock, and reset 
 remove from list (including ref) 
		 possible that another bast was queued while
		 drop the extra ref.
		 dlm_shutting_down is very point-in-time, but that
		  doesn't matter as we'll just loop back around if we
		  get false on the leading edge of a state
		 We really don't want to hold dlm->spinlock while
		  calling dlm_shuffle_lists on each lockres that
		  needs to have its queues adjusted and ASTBASTs
		  run.  So let's pull each entry off the dirty_list
		  and drop dlm->spinlock ASAP.  Once off the list,
		  res->spinlock needs to be taken again to protect
			 peel a lockres off, remove it from the list,
 We clear the DLM_LOCK_RES_DIRTY state once we shuffle lists below 
 Drop dirty_list ref 
		 	 lockres can be re-dirtiedre-added to the
			 it is now ok to move lockreses in these states
			  to the dirty list, assuming that they will only be
 move it to the tail and keep going 
			 at this point the lockres is not migrating
			  recoveringin-progress.  we have the lockres
			  spinlock and do NOT have the dlm lock.
 called while holding lockres lock 
			 if the lock was in-progress, stick
			 unlikely, but we may need to give time to
 yield and continue right away if there is more work to do 
 SPDX-License-Identifier: GPL-2.0-or-later
  dlmconvert.c
  underlying calls for lock conversion
  Copyright (C) 2004 Oracle.  All rights reserved.
 NOTE: __dlmconvert_master is the only function in here that
  needs a spinlock held on entry (res->spinlock) and it is the
  only one that holds a lock on exit (res->spinlock).
  All other functions in here need no locks and drop all of
  this is only called directly by dlmlock(), and only when the
  local node is the owner of the lockres
  locking:
    caller needs:  none
    taken:         takes and drops res->spinlock
    held on exit:  none
  returns: see __dlmconvert_master
 we are not in a network handler, this is fine 
 either queue the ast or release it 
 performs lock conversion at the lockres master site
  locking:
    caller needs:  res->spinlock
    taken:         takes and drops lock->spinlock
    held on exit:  res->spinlock
  returns: DLM_NORMAL, DLM_NOTQUEUED, DLM_DENIED
    call_ast: whether ast should be called for this lock
    kick_thread: whether dlm_kick_thread should be called
 already converting? 
 must be on grant queue to convert 
 EX + LKM_VALBLK + convert == set lvb 
 refetch if new level is not NL 
 in-place downconvert? 
 upconvert from here on 
 existing conversion requests take precedence 
 fall thru to grant 
 immediately grant the new lock type 
	
	  Move the lock to the tail because it may be the only lock which has
	  an invalid lvb.
 do not alter lock refcount.  switching lists. 
 do not alter lock refcount.  switching lists. 
 messages the master site to do lock conversion
  locking:
    caller needs:  none
    taken:         takes and drops res->spinlock, uses DLM_LOCK_RES_IN_PROGRESS
    held on exit:  none
  returns: DLM_NORMAL, DLM_RECOVERING, status from remote node
 __dlm_print_one_lock_resource(res); 
 will exit this call with spinlock held 
 move lock to local convert queue 
 do not alter lock refcount.  switching lists. 
	 no locks held here.
	 if it failed, move it back to granted queue.
	  if master returns DLM_NORMAL and then down before sending ast,
	  it may have already been moved to granted queue, reset to
 TODO: should this be a wake_one? 
 wake up any IN_PROGRESS waiters 
 sends DLM_CONVERT_LOCK_MSG to master site
  locking:
    caller needs:  none
    taken:         none
    held on exit:  none
  returns: DLM_NOLOCKMGR, status from remote node
 extra data to send if we are updating lvb 
 successfully sent and received
 this is already a dlm_status
			 instead of logging the same network error over
			  and over, sleep here and wait for the heartbeat
 handler for DLM_CONVERT_LOCK_MSG on master site
  locking:
    caller needs:  none
    taken:         takes and drop res->spinlock
    held on exit:  none
  returns: DLM_NORMAL, DLM_IVLOCKID, DLM_BADARGS,
           status from __dlmconvert_master
 found the lock 
 see if caller needed to getput lvb 
 either queue the ast or release it, if reserved 
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsnamei.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   adding & removing files & directories
dee.archive = 0;
de->hidden = de->system = 0;
 no space for deleting 
 order doesn't matter, due to VFS exclusion 
 Erm? Moving over the empty non-busy directory is perfectly legal 
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsdentry.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   dcache operations
  Note: the dentry argument is the parent dentry.
if (hpfs_chk_name(qstr->name,&l))
return -ENAMETOOLONG;
return -ENOENT;
hpfs_adjust_length(b->name, &bl);
	
	  'str' is the nane of an already existing dentry, so the name
	  must be valid. 'name' must be validated first.
 SPDX-License-Identifier: GPL-2.0-only
   linuxfshpfssuper.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   mounting, unmounting, error handling
 Mark the filesystem dirty, so that chkdsk checks it when os2 booted 
 Mark the filesystem clean (mark it dirty for chkdsk if chkdsk==2 or if there
 Filesystem error... 
  A little trick to detect cycles in many hpfs structures and don't let the
  kernel crash on corrupted filesystem. When first called, set c2 to 0.
  BTW. chkdsk doesn't detect cycles correctly. When I had 2 lost directories
  nested each in other, chkdsk locked up happilly.
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
  A tiny parser for option strings, stolen from dosfs.
  Stolen again from read-only hpfs.
  And updated for table-driven option parsing.
pr_info("Parsing opts: '%s'\n",opts);
 Super operations 
sbi->sb_mounting = 1;
 Check magics 
	if (le16_to_cpu(bootblock->magic) != BB_MAGIC
 Check version 
artax.karlin.mff.cuni.cz~mikulasvyplodyhpfsindex-e.cgi and if it still can't understand this format, contact author - mikulas@artax.karlin.mff.cuni.cz\n");
 Fill superblock stuff 
 Load bitmap directory 
 Check for general fs errors
 Load code page table 
	
	  find the root directory's . pointer & finish filling in the inode
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsanode.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   handling HPFS anode tree that contains file allocation info
 Find a sector in allocation tree 
 Add a sector to tree 
a0, &ra, &bh2))) {
fs-1);
anode->up = cpu_to_le32(up != -1 ? up : ra);
  Remove allocation tree. Recursion would look much nicer but
  I want to avoid it because it can cause stack overflow.
 Just a wrapper around hpfs_bplus_lookup .. used for reading eas 
 Truncate allocation tree. Doesn't join anodes - I hope it doesn't matter 
 I hope gcc optimizes this :-) 
 Remove file or directory and it's eas - note that directory must
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsinode.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   inode VFS functions
		i->i_mode |= S_IFREG;
		i->i_mode &= ~0111;
		i->i_op = &hpfs_file_iops;
		i->i_fop = &hpfs_file_ops;
	if (le32_to_cpu(fnode->acl_size_l) || le16_to_cpu(fnode->acl_size_s)) {
		   Some unknown structures like ACL may be in fnode,
		   we'd better not overwrite them
		hpfs_error(i->i_sb, "fnode %08x has some unknown HPFS386 structures", i->i_ino);
 sick, but legal 
hpfs_inode->i_ea_size0);
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsdnode.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   handling directory dnode tree - adding, deleteing & searching for dirents
	pr_warn("position pointer %p->%08x not found\n",
void hpfs_hpfs_pos_substd(loff_t p, loff_t f, loff_t t)
{
	if ((p & ~0x3f) == (f & ~0x3f)) p = (t & ~0x3f) | (p & 0x3f);
 Add an entry to dnode and don't care if it grows over 2048 bytes 
 Delete dirent and don't care about its subtree 
 Add an entry to dnode and do dnode splitting if required 
		 0x924 is a max size of dnode after adding a dirent with
		   max name length. We alloc this only once. There must
		   not be any error while splitting dnodes, otherwise the
		   whole directory, not only file we're adding, would
  Add an entry to directory btree.
  I hate such crazy directory structure.
  It's easy to read but terrible to write.
  I wrote this directory code 4 times.
  I hope, now it's finally bug-free.
  Find dirent with higher name in 'from' subtree and move it to 'to' dnode.
  Return the dnode we moved from (to be checked later if it's empty)
  Check if a dnode is empty and delete it from the tree
  (chkdsk doesn't like empty dnodes)
		pr_info("UP-TO-DNODE: %08x (ndown = %08x, down = %08x, dno = %08x)\n",
 Delete dirent from directory 
 Going to the next dirent 
 We're going down the tree 
 Going up 
 Find a dirent in tree 
  Remove empty directory. In normal cases it is only one dnode with two
  entries, but we must handle also such obscure cases when it's a tree
  of empty dnodes.
  Find dirent for specified fnode. Use truncated 15-char name in fnode as
  a help for searching.
name2[15] = 0xff;
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsbuffer.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   general buffer io
 Map a sector into a buffer and return pointers to it and to the buffer. 
 Like hpfs_map_sector but don't read anything 
return hpfs_map_sector(s, secno, bhp, 0);
 Map 4 sectors into a 4buffer and return pointers to it and to the buffer. 
 Don't read sectors 
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsdir.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   directory VFS functions
hpfs_write_if_changed(inode);
 This is slow, but it's not used often 
 Somebody else will have to figure out what to do here 
pr_info("dir lseek\n");
pr_warn("illegal lseek: %016llx\n", new_off);
 diff -r requires this (note, that diff -r 
 also fails on msdos filesystem in 2.0) 
		 This won't work when cycle is longer than number of dirents
		   accepted by filldir, but what can I do?
  lookup.  Search the specified directory for the specified name, set
  result to the corresponding inode.
  lookup uses the inode number to tell read_inode whether it is reading
  the inode of a directory or a file -- file ino's are odd, directory
  ino's are even.  read_inode avoids io for file inodes; everything
  needed is up here in the directory.  (And file fnodes are out in
  the boondocks.)
     - M.P.: this is over, sometimes we've got to read file's fnode for eas
 	      inode numbers are just fnode sector numbers; iget lock is used
 	      to tell read_inode to read fnode or not.
	
	  '.' and '..' will never be passed here.
	
	  This is not really a bailout, just means file not found.
	
	  Get inode number, what we're after.
	
	  Go find or make an inode.
	
	  Fill in the info from the directory if this is a newly created
	  inode.
			
			  i_blocks should count the fnode and any anodes.
			  We count 1 for the fnode and don't bother about
			  anodes -- the disk heads are on the directory band
			  and we want them to stay there.
	
	  Made it.
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsfile.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   file VFS functions
  generic_file_read often calls bmap with non-existing sector,
  so we must ignore such errors.
-EPERM;
 make sure we write it on close, if not earlier 
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsea.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   handling extended attributes
 Remove external extended attributes. ano specifies whether a is a 
 Read an extended attribute named 'key' into the provided buffer 
 Read an extended attribute named 'key' 
  Update or create extended attribute 'key' with value 'data'. Note that
  when this ea exists, it MUST have the same size as size of data.
  This driver can't change sizes of eas ('cause I just don't need it).
		if (le16_to_cpu(fnode->ea_size_s)) {
			hpfs_error(s, "fnode %08x: ea_size_s == %03x, ea_offs == 0",
				inode->i_ino, le16_to_cpu(fnode->ea_size_s));
			return;
	 Most the code here is 99.9993422% unused. I hope there are no bugs.
 Aargh... don't know how to create ea anodes :-( 
				struct buffer_head bh;
				struct anode anode;
				anode_secno a_s;
				if (!(anode = hpfs_alloc_anode(s, fno, &a_s, &bh)))
					goto bail;
				anode->up = cpu_to_le32(fno);
				anode->btree.fnode_parent = 1;
				anode->btree.n_free_nodes--;
				anode->btree.n_used_nodes++;
				anode->btree.first_free = cpu_to_le16(le16_to_cpu(anode->btree.first_free) + 12);
				anode->u.external[0].disk_secno = cpu_to_le32(le32_to_cpu(fnode->ea_secno));
				anode->u.external[0].file_secno = cpu_to_le32(0);
				anode->u.external[0].length = cpu_to_le32(len);
				mark_buffer_dirty(bh);
				brelse(bh);
				fnode->flags |= FNODE_anode;
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsname.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   operations with filenames
 Characters that are allowed in HPFS but not in DOS 
 OS2 clears dots and spaces at the end of file name, so we have to 
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsmap.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   mapping structures to memory with some minimal checks
  Load first code page into kernel memory, return pointer to 256-byte array,
  first 128 bytes are uppercasing table for chars 128-255, next 128 bytes are
  lowercasing table
 Try to build lowercasing table from uppercasing one 
  Load fnode to memory
  Load dnode to memory and do some checks
			 Check dirents - bad dirents would cause infinite
 SPDX-License-Identifier: GPL-2.0
   linuxfshpfsalloc.c
   Mikulas Patocka (mikulas@artax.karlin.mff.cuni.cz), 1998-1999
   HPFS bitmap operations
  Check if a sector is allocated in bitmap
  This is really slow. Turned on only if chk==2
  Check if sector(s) have proper number and additionally check if they're
  allocated in bitmap.
unsigned mnr;
for (i = nr + 1; i != nr; i++, i &= 0x1ff) 
  Allocation strategy:	1) search place near the sector specified
 			2) search bitmap where free sectors last found
 			3) search all bitmaps
 			4) search all bitmaps ignoring number of pre-allocated
 				sectors
	
	if (b != -1) {
		if ((sec = alloc_in_bmp(s, b<<14, n, f_p ? forward : forward2))) {
			b &= 0x0fffffff;
			goto ret;
		}
		if (b > 0x10000000) if ((sec = alloc_in_bmp(s, (b&0xfffffff)<<14, n, f_p ? forward : 0))) goto ret;
 Alloc sector if it's free 
 Free sectors in bitmaps 
pr_info("2 - ");
  Check if there are at least n free dnodes on the filesystem.
  Called before adding to dnode. If we run out of space while
  splitting dnodes, it would corrupt dnode tree.
 SPDX-License-Identifier: LGPL-2.1
  Copyright IBM Corporation, 2010
  Author Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
 get the defaultaccess acl values and cache them 
	
	  9p Always cache the acl value when
	  instantiating the inode (v9fs_inode_from_fid)
		
		  On access = client  and acl = on mode get the acl
		  values from the server
 Set a setxattr request to server 
	
	  We allow setgetlist of acl when access=client is not specified
	
	  set the attribute on the remote. Without even looking at the
	  xattr value. We leave it to the server to validate
 update the cached acl value 
				
				  ACL can be represented
				  by the mode bits. So don't
				  update ACL.
			 FIXME should we update ctime ?
			  What is the following setxattr update the
			  mode ?
 SPDX-License-Identifier: GPL-2.0-only
  V9FS FID Management
   Copyright (C) 2007 by Latchesar Ionkov <lucho@ionkov.net>
   Copyright (C) 2005, 2006 by Eric Van Hensbergen <ericvh@gmail.com>
  v9fs_fid_add - add a fid to a dentry
  @dentry: dentry that the fid is being added to
  @fid: fid to add
  v9fs_fid_find_inode - search for an open fid off of the inode list
  @inode: return a fid pointing to a specific inode
  @uid: return a fid belonging to the specified user
  v9fs_open_fid_add - add an open fid to an inode
  @inode: inode that the fid is being added to
  @fid: fid to add
  v9fs_fid_find - retrieve a fid that belongs to the specified uid
  @dentry: dentry to look for fid in
  @uid: return fid that belongs to the specified user
  @any: if non-zero, return any fid associated with the dentry
 we'll recheck under lock if there's anything to look in 
  We need to hold v9ses->rename_sem as long as we hold references
  to returned path array. Array element contain pointers to
  dentry names.
	
	  we don't have a matching fid. To do a TWALK we need
	  parent fid. We need to prevent rename when we want to
	  look at the parent.
 Found the parent fid do a lookup with that 
 start from the root and try to do a lookup 
 the user is not attached to the fs yet 
 If we are root ourself just return that 
	
	  Do a multipath walk with attached root.
	  When walking parent we need to make sure we
	  don't have a parallel rename happening
		
		  We need to hold rename lock when doing a multipath
		  walk to ensure none of the patch component change
				
				  If we fail, clunk fid which are mapping
				  to path component and not the last component
				  of the path.
  v9fs_fid_lookup - lookup for a fid, try to walk if not found
  @dentry: dentry to look for fid in
  Look for a fid in the specified dentry for the current user.
  If no fid is found, try to create one walking from a fid from the parent
  dentry (if it has one), or the root dentry. If the user haven't accessed
  the fs yet, attach now and walk from the root.
	
	  writeback fid will only be used to write back the
	  dirty pages. We always request for the open fid in read-write
	  mode so that a partial page write which result in page
	  read can work.
 SPDX-License-Identifier: LGPL-2.1
  Copyright IBM Corporation, 2010
  Author Aneesh Kumar K.V <aneesh.kumar@linux.vnet.ibm.com>
 request to get the attr_size 
  v9fs_xattr_get()
  Copy an extended attribute into the buffer
  provided, or compute the buffer size required.
  Buffer is NULL to compute the size of the buffer required.
  Returns a negative error number on failure, or the number of bytes
  used  required on success.
  v9fs_xattr_set()
  Create, replace or remove an extended attribute for this inode. Buffer
  is NULL to remove an existing extended attribute, and non-NULL to
  either replace an existing extended attribute, or create a new extended
  attribute. The flags XATTR_REPLACE and XATTR_CREATE
  specify that an extended attribute must exist and must not exist
  previous to the call, respectively.
  Returns 0, or a negative error number on failure.
 Clone it 
	
	  On success fid points to xattr
 SPDX-License-Identifier: GPL-2.0-only
  This file contains vfs inode ops for the 9P2000 protocol.
   Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  unixmode2p9mode - convert unix mode bits to plan 9
  @v9ses: v9fs session information
  @mode: mode to convert
  p9mode2perm- convert plan9 mode bits to unix permission bits
  @v9ses: v9fs session information
  @stat: p9_wstat from which mode need to be derived
  p9mode2unixmode- convert plan9 mode bits to unix mode bits
  @v9ses: v9fs session information
  @stat: p9_wstat from which mode need to be derived
  @rdev: major number, minor number in case of device files.
  v9fs_uflags2omode- convert posix open flags to plan 9 mode bits
  @uflags: flags to convert
  @extended: if .u extensions are active
  v9fs_blank_wstat - helper function to setup a 9P stat structure
  @wstat: structure to initialize
  v9fs_alloc_inode - helper function to allocate an inode
  @sb: The superblock to allocate the inode from
  v9fs_free_inode - destroy an inode
  @inode: The inode to be freed
  v9fs_get_inode - helper function to setup an inode
  @sb: superblock
  @mode: mode to setup inode with
  @rdev: The device numbers to set
  v9fs_evict_inode - Remove an inode from the inode cache
  @inode: inode to release
 clunk the fid stashed in writeback_fid 
 don't match inode of different type 
 compare qid details 
	
	  initialize the inode with the stat info
	  FIXME!! we may need support for stale inodes
	  later.
  v9fs_at_to_dotl_flags- convert Linux specific AT flags to
  plan 9 AT flag.
  @flags: flags to convert
  v9fs_dec_count - helper functon to drop i_nlink.
  If a directory had nlink <= 2 (including . and ..), then we should not drop
  the link count, which indicates the underlying exported fs doesn't maintain
  nlink accurately. e.g.
  - overlayfs sets nlink to 1 for merged dir
  - ext4 (with dir_nlink feature enabled) sets nlink to 1 if a dir has more
    than EXT4_LINK_MAX (65000) links.
  @inode: inode whose nlink is being dropped
  v9fs_remove - helper function to remove files and directories
  @dir: directory inode that is being deleted
  @dentry:  dentry that is being deleted
  @flags: removing a directory
 Try the one based on path 
		
		  directories on unlink should have zero
		  link count
 invalidate all fids associated with dentry 
 NOTE: This will not include open fids 
  v9fs_create - Create a file
  @v9ses: session information
  @dir: directory that dentry is being created in
  @dentry:  dentry that is being created
  @extension: 9p2000.u extension string to support devices, etc.
  @perm: create permissions
  @mode: open mode
 clone a fid to use for creation 
 now walk from the parent so we can get unopened fid 
		
		  instantiate inode and assign the unopened fid to the dentry
  v9fs_vfs_create - VFS hook to create a regular file
  @mnt_userns: The user namespace of the mount
  @dir: The parent directory
  @dentry: The name of file to be created
  @mode: The UNIX file mode to set
  @excl: True if the file must not yet exist
  open(.., O_CREAT) is handled in v9fs_vfs_atomic_open().  This is only called
  for mknod(2).
 P9_OEXCL? 
  v9fs_vfs_mkdir - VFS mkdir hook to create a directory
  @mnt_userns: The user namespace of the mount
  @dir:  inode that is being unlinked
  @dentry: dentry that is being unlinked
  @mode: mode for new directory
  v9fs_vfs_lookup - VFS lookup hook to "walk" to a new inode
  @dir:  inode that is being walked from
  @dentry: dentry that is being walked to?
  @flags: lookup flags (unused)
 We can walk d_parent because we hold the dir->i_mutex 
	
	  Make sure we don't use a wrong inode due to parallel
	  unlink. For cached mode create calls request for new
	  inode. But with cache disabled, lookup should do this.
	
	  If we had a rename on the server and a parallel lookup
	  for the new name, then make sure we instantiate with
	  the new name. ie look up for ab, while on server somebody
	  moved b under k and client parallely did a lookup for
	  kb.
 Only creates 
		
		  clone a fid and add it to writeback_fid
		  we do it during open time instead of
		  page dirty time via write_beginpage_mkwrite
		  because we want write after unlink usecase
		  to work.
  v9fs_vfs_unlink - VFS unlink hook to delete an inode
  @i:  inode that is being unlinked
  @d: dentry that is being unlinked
  v9fs_vfs_rmdir - VFS unlink hook to delete a directory
  @i:  inode that is being unlinked
  @d: dentry that is being unlinked
  v9fs_vfs_rename - VFS hook to rename an inode
  @mnt_userns: The user namespace of the mount
  @old_dir:  old dir inode
  @old_dentry: old dentry
  @new_dir: new dir inode
  @new_dentry: new dentry
  @flags: RENAME_ flags
		
		  9P .u can only handle file rename in the same directory
 successful rename 
  v9fs_vfs_getattr - retrieve file metadata
  @mnt_userns: The user namespace of the mount
  @path: Object to query
  @stat: metadata structure to populate
  @request_mask: Mask of STATX_xxx flags indicating the caller's interests
  @flags: AT_STATX_xxx setting
  v9fs_vfs_setattr - set file metadata
  @mnt_userns: The user namespace of the mount
  @dentry: file whose metadata to set
  @iattr: metadata assignment structure
 Write all dirty data 
  v9fs_stat2inode - populate an inode structure with mistat info
  @stat: Plan 9 metadata (mistat) structure
  @inode: inode to populate
  @sb: superblock of filesystem
  @flags: control flags (e.g. V9FS_STAT2INODE_KEEP_ISIZE)
			
			  Hadlink support got added later to the .u extension.
			  So there can be a server out there that doesn't
			  support this even with .u extension. That would
			  just leave us with stat->extension being an empty
			  string, though.
 HARDLINKCOUNT %u 
 not real number of blocks, but 512 byte ones ... 
  v9fs_qid2ino - convert qid into inode number
  @qid: qid to hash
  BUG: potential for inode number collisions?
  v9fs_vfs_get_link - follow a symlink path
  @dentry: dentry for symlink
  @inode: inode for symlink
  @done: delayed call for when we are done with the return value
  v9fs_vfs_mkspecial - create a special file
  @dir: inode to create special file in
  @dentry: dentry to create
  @perm: mode to create special file
  @extension: 9p2000.u format extension string representing special file
  v9fs_vfs_symlink - helper function to create symlinks
  @mnt_userns: The user namespace of the mount
  @dir: directory inode containing symlink
  @dentry: dentry for symlink
  @symname: symlink data
  See Also: 9P2000.u RFC for more information
  v9fs_vfs_link - create a hardlink
  @old_dentry: dentry for file to link to
  @dir: inode destination for new link
  @dentry: dentry for link
 sign + number + \n + \0 
  v9fs_vfs_mknod - create a special file
  @mnt_userns: The user namespace of the mount
  @dir: inode destination for new link
  @dentry: dentry for file
  @mode: mode for creation
  @rdev: device associated with special file
 build extension 
	
	  Don't update inode if the file type is different
	
	  We don't want to refresh inode->i_size,
	  because we may have cached data
 SPDX-License-Identifier: GPL-2.0-only
  This file contians vfs dentry ops for the 9P2000 protocol.
   Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  v9fs_cached_dentry_delete - called when dentry refcount equals 0
  @dentry:  dentry in question
 Don't cache negative dentries 
  v9fs_dentry_release - called when dentry is going to be freed
  @dentry:  dentry that is being release
 SPDX-License-Identifier: GPL-2.0-only
  This file contains vfs directory ops for the 9P2000 protocol.
   Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  struct p9_rdir - readdir accounting
  @head: start offset of current dirread buffer
  @tail: end offset of current dirread buffer
  @buf: dirread buffer
  private structure for keeping track of readdir
  allocated on demand
  dt_type - return file type
  @mistat: mistat structure
  v9fs_alloc_rdir_buf - Allocate buffer used for read and readdir
  @filp: opened file structure
  @buflen: Length in bytes of buffer to allocate
  v9fs_dir_readdir - iterate through a directory
  @file: opened file structure
  @ctx: actor we feed the entries to
  v9fs_dir_readdir_dotl - iterate through a directory
  @file: opened file structure
  @ctx: actor we feed the entries to
  v9fs_dir_release - close a directory
  @inode: inode of the directory
  @filp: file pointer to a directory
 SPDX-License-Identifier: GPL-2.0-only
  This file contians vfs address (mmap) ops for 9P2000.
   Copyright (C) 2005 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  v9fs_req_issue_op - Issue a read from 9P
  @subreq: The read to make
  v9fs_init_rreq - Initialise a read request
  @rreq: The read request
  @file: The file being read from
  v9fs_req_cleanup - Cleanup request initialized by v9fs_init_rreq
  @mapping: unused mapping of request to cleanup
  @priv: private data to cleanup, a fid, guaranted non-null.
  v9fs_is_cache_enabled - Determine if caching is enabled for an inode
  @inode: The inode to check
  v9fs_begin_cache_operation - Begin a cache operation for a read
  @rreq: The read request
  v9fs_vfs_readpage - read an entire page in from 9P
  @file: file being read
  @page: structure to page
  v9fs_vfs_readahead - read a set of pages from 9P
  @ractl: The readahead parameters
  v9fs_release_page - release the private state associated with a page
  @page: The page to be released
  @gfp: The caller's allocation restrictions
  Returns 1 if the page can be released, false otherwise.
  v9fs_invalidate_page - Invalidate a page completely or partially
  @page: The page to be invalidated
  @offset: offset of the invalidated region
  @length: length of the invalidated region
 Simultaneous truncation occurred 
 We should have writeback_fid always set 
  v9fs_launder_page - Writeback a dirty page
  @page: The page to be cleaned up
  Returns 0 on success.
  v9fs_direct_IO - 9P address space operation for direct IO
  @iocb: target IO control block
  @iter: The databuffer to use
  The presence of v9fs_direct_IO() in the address space ops vector
  allowes open() O_DIRECT flags which would have failed otherwise.
  In the non-cached mode, we shunt off direct read and write requests before
  the VFS gets them, so this method should never be called.
  Direct IO is not 'yet' supported in the cached mode. Hence when
  this routine is called through generic_file_aio_read(), the readwrite fails
  with an error.
	 Prefetch area to be written into the cache if we're caching this
	  file.  We need to do this before we get a lock on the page in case
	  there's more than one writer competing for the same cache block.
	
	  No need to use i_size_read() here, the i_size
	  cannot change under us because we hold the i_mutex.
 SPDX-License-Identifier: GPL-2.0-only
  V9FS cache definitions.
   Copyright (C) 2009 by Abhishek Kulkarni <adkulkar@umail.iu.edu>
  v9fs_random_cachetag - Generate a random tag to be associated
 			  with a new cache session.
  The value of jiffies is used for a fairly randomly cache tag.
 If no cache session tag was specified, we generate a random one. 
 SPDX-License-Identifier: GPL-2.0-only
  This file contians vfs file ops for 9P2000.
   Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  v9fs_file_open - open a file (or directory)
  @inode: inode to be opened
  @file: file being opened
		
		  clone a fid and add it to writeback_fid
		  we do it during open time instead of
		  page dirty time via write_beginpage_mkwrite
		  because we want write after unlink usecase
		  to work.
  v9fs_file_lock - lock a file (or directory)
  @filp: file to be locked
  @cmd: lock command
  @fl: file lock structure
  Bugs: this looks like a local only lock, we should extend into 9P
        by using open exclusive
 convert posix lock to p9 tlock args 
 map the lock type 
	
	  if its a blocked request and we get P9_LOCK_BLOCKED as the status
	  for lock request, keep on trying
		
		  p9_client_lock_dotl overwrites flock.client_id with the
		  server message, free and reuse the client name
 map 9p status to VFS status 
	
	  incase server returned error for lock request, revert
	  it locally
 Even if this fails we want to return the remote error 
	
	  if we have a conflicting lock locally, no need to validate
	  with server
 convert posix lock to p9 tgetlock args 
 map 9p lock type to os lock type 
  v9fs_file_lock_dotl - lock a file (or directory)
  @filp: file to be locked
  @cmd: lock command
  @fl: file lock structure
  v9fs_file_flock_dotl - lock a file
  @filp: file to be locked
  @cmd: lock command
  @fl: file lock structure
 Convert flock to posix lock 
  v9fs_file_read_iter - read from a file
  @iocb: The operation parameters
  @to: The buffer to read into
  v9fs_file_write_iter - write to a file
  @iocb: The operation parameters
  @from: The data to write
			
			  Need to serialize against i_size_write() in
			  v9fs_stat2inode()
		
		  clone a fid and add it to writeback_fid
		  we do it during mmap instead of
		  page dirty time via write_beginpage_mkwrite
		  because we want write after unlink usecase
		  to work.
	 Wait for the page to be written to the cache before we allow it to
	  be modified.  We then assume the entire page will need writing back.
 Update file times before taking page lock 
  v9fs_mmap_file_read_iter - read from a file
  @iocb: The operation parameters
  @to: The buffer to read into
 TODO: Check if there are dirty pages 
  v9fs_mmap_file_write_iter - write to a file
  @iocb: The operation parameters
  @from: The data to write
	
	  TODO: invalidate mmaps on filp's inode between
	  offset and offset+count
 absolute end, byte at end included 
 SPDX-License-Identifier: GPL-2.0-only
   Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  v9fs_set_super - set the superblock
  @s: super block
  @data: file system specific data
  v9fs_fill_super - populate superblock with info
  @sb: superblock
  @v9ses: session information
  @flags: flags propagated from v9fs_mount()
  v9fs_mount - mount a superblock
  @fs_type: file system type
  @flags: mount flags
  @dev_name: device name that was mounted
  @data: mount options
	
	  we will do the session_close and root dentry release
	  in the below call. But we need to clunk fid, because we haven't
	  attached the fid to dentry so it won't get clunked
	  automatically.
  v9fs_kill_super - Kill Superblock
  @s: superblock
	
	  in case of non cached mode always drop the
	  inode because we want the inode attribute
	  to always match that on the server.
	
	  send an fsync request to server irrespective of
	  wbc->sync_mode.
	
	  send an fsync request to server irrespective of
	  wbc->sync_mode.
 SPDX-License-Identifier: GPL-2.0-only
   This file contains functions assisting in mapping VFS to 9P2000
   Copyright (C) 2004-2008 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  Option Parsing (code inspired by NFS code)
   NOTE: each transport will parse its own options
 Options that take integer arguments 
 String options 
 Options that take no arguments 
 Cache options 
 Access options 
 Lock timeout option 
 Error token 
 Interpret mount options for cache mode 
  Display the mount options in procmounts.
  v9fs_parse_options - parse mount options into session structure
  @v9ses: existing v9fs session information
  @opts: The mount option string
  Return 0 upon success, -ERRNO upon failure.
 setup defaults 
  v9fs_session_init - initialize session
  @v9ses: session information structure
  @dev_name: device being mounted
  @data: options
		
		  We support ACCESS_CLIENT only for dotl.
		  Fall back to ACCESS_USER
FIXME !! 
 for legacy mode, fall back to V9FS_ACCESS_ANY 
		
		  We support ACL checks on clinet only if the protocol is
		  9P2000.L and access is V9FS_ACCESS_CLIENT.
 register the session for caching 
  v9fs_session_close - shutdown a session
  @v9ses: session information structure
  v9fs_session_cancel - terminate a session
  @v9ses: session to terminate
  mark transport as disconnected and cancel all pending requests.
  v9fs_session_begin_cancel - Begin terminate of a session
  @v9ses: session to terminate
  After this call we don't allow any request other than clunk.
  List caches associated with a session
 CONFIG_9P_FSCACHE 
  v9fs_sysfs_init - Initialize the v9fs sysfs interface
  v9fs_sysfs_cleanup - Unregister the v9fs sysfs interface
  v9fs_init_inode_cache - initialize a cache for 9P
  Returns 0 on success.
  v9fs_destroy_inode_cache - destroy the cache of 9P inode
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
  init_v9fs - Initialize module
 TODO: Setup list of registered trasnport modules 
  exit_v9fs - shutdown module
 SPDX-License-Identifier: GPL-2.0-only
  This file contains vfs inode ops for the 9P2000.L protocol.
   Copyright (C) 2004 by Eric Van Hensbergen <ericvh@gmail.com>
   Copyright (C) 2002 by Ron Minnich <rminnich@lanl.gov>
  v9fs_get_fsgid_for_create - Helper function to get the gid for a new object
  @dir_inode: The directory inode
  Helper function to get the gid for creating a
  new file system object. This checks the S_ISGID to determine the owning
  group of the new file system object.
 set_gid bit is set.
 don't match inode of different type 
 compare qid details 
 Always get a new inode 
	
	  initialize the inode with the stat info
	  FIXME!! we may need support for stale inodes
	  later.
  v9fs_open_to_dotl_flags- convert Linux specific open flags to
  plan 9 open flag.
  @flags: flags to convert
	
	  We have same bits for P9_DOTL_READONLY, P9_DOTL_WRONLY
	  and P9_DOTL_NOACCESS
  v9fs_vfs_create_dotl - VFS hook to create files for 9P2000.L protocol.
  @mnt_userns: The user namespace of the mount
  @dir: directory inode that is being created
  @dentry:  dentry that is being deleted
  @omode: create permissions
  @excl: True if the file must not yet exist
 Only creates 
 clone a fid to use for creation 
 Update mode based on ACL value 
 instantiate inode and assign the unopened fid to the dentry 
 Now set the ACL based on the default value 
		
		  clone a fid and add it to writeback_fid
		  we do it during open time instead of
		  page dirty time via write_beginpage_mkwrite
		  because we want write after unlink usecase
		  to work.
 Since we are opening a file, assign the open fid to the file 
  v9fs_vfs_mkdir_dotl - VFS mkdir hook to create a directory
  @mnt_userns: The user namespace of the mount
  @dir:  inode that is being unlinked
  @dentry: dentry that is being unlinked
  @omode: mode for new directory
 Update mode based on ACL value 
 instantiate inode and assign the unopened fid to the dentry 
		
		  Not in cached mode. No need to populate
		  inode with stat. We need to get an inode
		  so that we can set the acl with dentry
	 Ask for all the fields in stat structure. Server will return
	  whatever it supports
 Change block size to what the server returned 
  Attribute flags.
  v9fs_vfs_setattr_dotl - set file metadata
  @mnt_userns: The user namespace of the mount
  @dentry: file whose metadata to set
  @iattr: metadata assignment structure
 Write all dirty data 
 We also want to update ACL when we update mode bits 
  v9fs_stat2inode_dotl - populate an inode structure with stat info
  @stat: stat structure
  @inode: inode to populate
  @flags: ctrl flags (e.g. V9FS_STAT2INODE_KEEP_ISIZE)
	 Currently we don't support P9_STATS_BTIME and P9_STATS_DATA_VERSION
	  because the inode structure does not have fields for them.
 Server doesn't alter fid on TSYMLINK. Hence no need to clone it. 
 Now walk from the parent so we can get an unopened fid. 
 instantiate inode and assign the unopened fid to dentry 
 Not in cached mode. No need to populate inode with stat 
  v9fs_vfs_link_dotl - create a hardlink for dotl
  @old_dentry: dentry for file to link to
  @dir: inode destination for new link
  @dentry: dentry for link
 Get the latest stat info from server. 
  v9fs_vfs_mknod_dotl - create a special file
  @mnt_userns: The user namespace of the mount
  @dir: inode destination for new link
  @dentry: dentry for file
  @omode: mode for creation
  @rdev: device associated with special file
 Update mode based on ACL value 
 instantiate inode and assign the unopened fid to the dentry 
		
		  Not in cached mode. No need to populate inode with stat.
		  socket syscall returns a fd, so we need instantiate
  v9fs_vfs_get_link_dotl - follow a symlink path
  @dentry: dentry for symlink
  @inode: inode for symlink
  @done: destructor for return value
	
	  Don't update inode if the file type is different
	
	  We don't want to refresh inode->i_size,
	  because we may have cached data
 SPDX-License-Identifier: GPL-2.0-only
 	fsbfsinode.c
 	BFS superblock and inode operations.
 	Copyright (C) 1999-2018 Tigran Aivazian <aivazian.tigran@gmail.com>
 	From fsminix, Copyright (C) 1991, 1992 Linus Torvalds.
 	Made endianness-clean by Andrew Stribblehill <ads@wompom.org>, 2005.
 clear on-disk inode 
	
	  If this was the last file, make the previous block
	  "last block of the last file" even if there is no
	  real file there, saves us 1 gap.
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 can we read the last block? 
 test if filesystem is not corrupted 
 SPDX-License-Identifier: GPL-2.0
 	fsbfsdir.c
 	BFS directory operations.
 	Copyright (C) 1999-2018  Tigran Aivazian <aivazian.tigran@gmail.com>
   Made endianness-clean by Andrew Stribblehill <ads@wompom.org> 2005
 SPDX-License-Identifier: GPL-2.0
 	fsbfsfile.c
 	BFS file operations.
 	Copyright (C) 1999-2018 Tigran Aivazian <aivazian.tigran@gmail.com>
 	Make the file block allocation algorithm understand the size
 	of the underlying block device.
 	Copyright (C) 2007 Dmitri Vorobiev <dmitri.vorobiev@gmail.com>
	
	  If the file is not empty and the requested block is within the
	  range of blocks allocated for this file, we can grant it.
 The file will be extended, so let's see if there is enough space. 
 The rest has to be protected against itself. 
	
	  If the last data block for this file is the last allocated
	  block, we can extend the file trivially, without moving it
	  anywhere.
 Ok, we have to move this entire file to the next free block. 
	
	  This assumes nothing can write the inode back while we are here
	  and thus update inode->i_blocks! (XXX)
 SPDX-License-Identifier: GPL-2.0
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
	
	  Is it quota file? Do not allow user to mess with it
  reiserfs_ioctl - handler for ioctl for inode
  supported commands:
   1) REISERFS_IOC_UNPACK - try to unpack tail from direct item into indirect
                            and prevent packing file (argument arg has t
 			      be non-zero)
   2) REISERFS_IOC_[GS]ETFLAGS, REISERFS_IOC_[GS]ETVERSION
   3) That's all for a while ...
		
		  following two cases are taken from fsext2ioctl.c by Remy
		  Card (card@masi.ibp.fr)
	
	  These are just misnamed, they actually
	  getput fromto user an int
  reiserfs_unpack
  Function try to convert tail from direct item into indirect.
  It set up nopack attribute in the REISERFS_I(inode)->nopack
 ioctl already done 
 we need to make sure nobody is changing the file size beneath us 
 if we are on a block boundary, we are already unpacked.  
	
	  we unpack by finding the page with the tail, and calling
	  __reiserfs_write_begin on that page.  This will force a
	  reiserfs_get_block to unpack the tail for us.
 conversion can change page contents, must flush 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
 find where objectid map starts 
 FIXME: add something else here 
  When we allocate objectids we allocate the first unused objectid.
  Each sequence of objectids in use (the odd sequences) is followed
  by a sequence of objectids not in use (the even sequences).  We
  only need to record the last objectid in each of these sequences
  (both the odd and even sequences) in order to fully define the
  boundaries of the sequences.  A consequence of allocating the first
  objectid not in use is that under most conditions this scheme is
  extremely compact.  The exception is immediately after a sequence
  of operations which deletes a large number of objects of
  non-sequential objectids, and even then it will become compact
  again as soon as more objects are created.  Note that many
  interesting optimizations of layout could result from complicating
  objectid assignment, but we have deferred making them for now.
 get unique object identifier 
 comment needed -Hans 
	
	  This incrementation allocates the first unused objectid. That
	  is to say, the first entry on the objectid map is the first
	  unused objectid, and by incrementing it we use it.  See below
	  where we check to see if we eliminated a sequence of unused
	  objectids....
	
	  Now we check to see if we eliminated the last remaining member of
	  the first even sequence (and can eliminate the sequence by
	  eliminating its last objectid from oids), and can collapse the
	  first two odd sequences into one sequence.  If so, then the net
	  result is to eliminate a pair of objectids from oids.  We do this
	  by shifting the entire map to the left.
 makes object identifier unused 
return; 
	
	  start at the beginning of the objectid map (i = 0) and go to
	  the end of it (i = disk_sb->s_oid_cursize).  Linear search is
	  what we use, though it is possible that binary search would be
	  more efficient after performing lots of deletions (which is
	  when oids is large.)  We only check even i's.
 This incrementation unallocates the objectid. 
			
			  Did we unallocate the last member of an
			  odd sequence, and can shrink oids?
 shrink objectid map 
 size of objectid map is not changed 
			
			  JDM comparing two little-endian values for
			  equality -- safe
			
			  objectid map must be expanded, but
			  there is no space
 expand the objectid map 
		
		  mark everyone used that was listed as free at
		  the end of the objectid map
 move the smaller objectid map past the end of the new super 
 set the max size so we don't overflow later 
 Zero out label and generate random UUID 
 finally, zero out the unused chunk of the new super 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  Trivial changes by Alan Cox to remove EHASHCOLLISION for compatibility
  Trivial Changes:
  Rights granted to Hans Reiser to redistribute under other terms providing
  he accepts all liability including but not limited to patent, fitness
  for purpose, and direct or indirect claims arising from failure to perform.
  NO WARRANTY
  directory item contains array of entry headers. This performs
  binary search through that array
 this is not name found, but matched third key component 
  comment?  maybe something like set de to point to what the path points to?
  de_bh, de_ih, de_deh (points to first element of array), de_item_num is set
 what entry points to 
 store key of the found entry 
  We assign a key to each directory item, and place multiple entries in a
  single directory item.  A directory item has a key equal to the key of
  the first directory entry in it.
  This function first calls search_by_key, then, if item whose first entry
  matches is not found it looks for the entry inside directory item found
  by search_by_key. Fills the path to the entry, and to the entry position
  in the item
 The function is NOT SCHEDULE-SAFE! 
 CONFIG_REISERFS_CHECK 
	
	  binary search in directory item by third component of the
	  key. sets de->de_entry_num of de
		
		  ugly, but rename needs de_bh, de_deh, de_name,
		  de_namelen, de_objectid set
 Keyed 32-bit hash function using TEA in a Davis-Meyer function 
  The third component is hashed, and you can choose from more than
  one hash function.  Per directory hashes are not yet implemented
  but are thought about. This function should be moved to hashes.c
  Jedi, please do so.  -Hans
 take bits from 7-th to 30-th including both bounds 
		
		  needed to have no names before "." and ".." those have hash
		  value == 0 and generation conters 1 and 2 accordingly
 de's de_bh, de_ih, de_deh, de_item_num, de_entry_num are set already 
 used when hash collisions exist 
 hash value does not match, no need to check whole name 
 mark that this generation number is used 
 calculate pointer to name and namelen 
		
		  de's de_name, de_namelen, de_recordlen are set.
		  Fill the rest.
 key of pointed object 
 retval can be NAME_FOUND or NAME_FOUND_INVISIBLE 
		
		  we have reached left most entry in the node. In common we
		  have to go to the left neighbor, but if generation counter
		  is 0 already, we know for sure, that there is no name with
		  the same hash value
		
		  FIXME: this work correctly only because hash value can not
		   be 0. Btw, in case of Yura's hash it is probably possible,
		  so, this is a bug
  may return NAME_FOUND, NAME_FOUND_INVISIBLE, NAME_NOT_FOUND
  FIXME: should add something like IOERROR
 we will search for this key in the tree 
 compare names for all entries having given hash value 
		
		  there is no need to scan directory anymore.
		  Given entry found or does not exist
		
		  there is left neighboring item of this directory
		  and given entry can be there
 while (1) 
		
		  Propagate the private flag so we know we're
		  in the priv tree.  Also clear IOP_XATTR
		  since we don't have xattrs on xattr files.
  looks up the dentry of the parent directory for child.
  taken from ext2_get_parent
 add entry to the directory (entry can be hidden).
insert definition of when hidden directories are used here -Hans
	
	  48 bytes now and we avoid kmalloc if we
	  create file with short name
 cannot allow items to be added into a busy deleted directory 
 each entry has unique key. compose it 
 get memory for composing the entry 
	
	  fill buffer : directory entry head, name[, dir objectid | ,
	  stat data | ,stat data, dir objectid ]
 JDM Endian safe if 0 
 JDM Endian safe if 0 
 put key (ino analog) to de 
 safe: k_dir_id is le 
 safe: k_objectid is le 
 copy name 
 padd by 0s to the 4 byte boundary 
	
	  entry is ready to be pasted into tree, set 'visibility'
	  and 'stat data in entry' attributes
 find the proper place for the new entry 
 there is no free generation number 
 adjust offset of directory enrty 
 update max-hash-collisions counter in reiserfs_sb_info 
 we need to re-search for the insertion point 
 perform the insertion of the entry that we have prepared 
 reiserfs_mkdir or reiserfs_rename will do that by itself 
  quota utility function, call if you've had to abort after calling
  new_inode_init, and have not called reiserfs_new_inode yet.
  This should only be called on inodes that do not have stat data
  inserted into the tree yet.
  utility function that does setup for reiserfs_new_inode.
  dquot_initialize needs lots of credits so it's better to have it
  outside of a transaction, so we had to pull some bits of
  reiserfs_new_inode out into this func.
	
	  Make inode invalid - just in case we are going to drop it before
	  the initialization happens
	
	  the quota init calls have to know who to charge the quota to, so
	  we have to set uid and gid here
	
	  We need blocks for transaction + (user+group)(quotas
	  for new inode + update of quota for directory owner)
i_size  , dentry,
visible  );
	
	  We need blocks for transaction + (user+group)(quotas
	  for new inode + update of quota for directory owner)
i_size  , dentry,
 FIXME: needed for block and char devices only 
visible  );
	
	  We need blocks for transaction + (user+group)(quotas
	  for new inode + update of quota for directory owner)
	
	  set flag that new packing locality created and new blocks
	  for the content of that directory are not displaced yet
	
	  inc the link count now, so another writer doesn't overflow
	  it while we sleep later on.
symlink ,
 note, _this_ add_entry will not update dir's stat data 
visible  );
 the above add_entry did not update dir's stat data 
	
	  we can cheat because an old format dir cannot have
	  EMPTY_DIR_SIZE, and a new format dir cannot have
	  EMPTY_DIR_SIZE_V1.  So, if the inode is either size,
	  regardless of disk format version, the directory is empty.
	
	  we will be doing 2 balancings and update 2 stat data, we
	  change quotas of the owner of the directory and of the owner
	  of the parent directory.  The quota structure is possibly
	  deleted only on last iput => outside of this transaction
		
		  FIXME: compare key of an object and a key found in the entry
 cut entry from dir directory 
 page 
new file size - not used here  );
 prevent empty directory from getting lost 
 not truncate  );
	
	  we must release path, because we did not call
	  reiserfs_cut_from_item, or reiserfs_cut_from_item does not
	  release path if operation was not complete
	
	  in this transaction we can be doing at max two balancings and
	  update two stat datas, we change quotas of the owner of the
	  directory and of the owner of the parent directory. The quota
	  structure is possibly deleted only on iput => outside of
	  this transaction
		
		  FIXME: compare key of an object and a key found in the entry
	
	  we schedule before doing the add_save_link call, save the link
	  count so we don't race
 prevent file from getting lost 
 not truncate  );
	
	  We need blocks for transaction + (user+group)(quotas for
	  new inode + update of quota for directory owner)
 reiserfs_new_inode iputs for us 
visible  );
	
	  We need blocks for transaction + update of quotas for
	  the owners of the directory
 FIXME: sd_nlink is 32 bit for new files 
 inc before scheduling so reiserfs_unlink knows we are here 
 create new entry 
visible  );
 de contains information pointing to an entry which 
 recalculate pointer to name and name length 
 FIXME: could check more 
 this must be added hidden entry 
 sets key of objectid the entry has to point to 
 JDM These operations are endian safe - both are le 
  process, that is going to call fix_nodesdo_balance must hold only
  one path. If it holds 2 or more, it can get into endless waiting in
  get_empty_nodes or its clones
	
	  three balancings: (1) old name removal, (2) new name insertion
	  and (3) maybe "save" link insertion
	  stat data updates: (1) old directory,
	  (2) new directory and (3) maybe old object stat data (when it is
	  directory) and (4) maybe stat data of object to which new entry
	  pointed initially and (5) maybe block containing ".." of
	  renamed directory
	  quota updates: two parent directories
	
	  make sure that oldname still exists and points to an object we
	  are going to rename
		
		  make sure that directory being renamed has correct ".."
		  and that its new parent directory has not too many links
		  already
		
		  directory is renamed, its parent directory will be changed,
		  so find ".." entry
 inode number of .. must equal old_dir->i_ino 
 add new entry (or find the existing one) 
	
	  this makes it so an fsync on an open fd for the old name will
	  commit the rename operation
		
		  look for old name using corresponding entry key
		  (found by reiserfs_find_entry)
 look for new name by reiserfs_find_entry 
		
		  reiserfs_add_entry should not return IO_ERROR,
		  because it is called with essentially same parameters from
		  reiserfs_add_entry above, and we'll catch any io errors
		  before we get here.
 node containing ".." gets into transaction 
		
		  we should check seals here, not do
		  this stuff, yes? Then, having
		  gathered everything into RAM we
		  should lock the buffers, yes?  -Hans
		
		  probably.  our rename needs to hold more
		  than one path at once.  The seals would
		  have to be written to deal with multi-path
		  issues -chris
		
		  sanity checking before doing the rename - avoid races many
		  of the above checks could have scheduled.  We have to be
		  sure our items haven't been shifted by another process.
	
	  ok, all the changes can be done in one fell swoop when we
	  have claimed all the buffers needed.
	
	  thanks to Alex Adriaanse <alex_a@caltech.edu> for patch
	  which adds ctime update of renamed object
 adjust link number of the victim 
 adjust ".." of renamed directory 
		
		  there (in new_dir) was no directory, so it got new link
		  (".."  of renamed directory)
 old directory lost one link - ".. " of renamed directory 
	
	  looks like in 2.3.99pre3 brelse is atomic.
	  so we can use pathrelse
	
	  FIXME: this reiserfs_cut_from_item's return value may screw up
	  anybody, but it will panic if will not be able to find the
	  entry. This needs one more clean up
 not truncate  );
 directories can handle most operations...  
  symlink operations.. same as page_symlink_inode_operations, with xattr
  stuff added
  special file operations.. just xattracl stuff
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  Trivial changes by Alan Cox to add the LFS fixes
  Trivial Changes:
  Rights granted to Hans Reiser to redistribute under other terms providing
  he accepts all liability including but not limited to patent, fitness
  for purpose, and direct or indirect claims arising from failure to perform.
  NO WARRANTY
	
	  Writeback quota in non-journalled quota case - journalled quota has
	  no dirty dquots
	
	  We need s_umount for protecting quota writeback. We have to use
	  trylock as reiserfs_cancel_old_flush() may be waiting for this work
	  to complete with s_umount held.
 Requeue work if we are not cancelling it 
 Avoid clobbering the cancel state... 
	
	  Avoid scheduling flush when sb is being shut down. It can race
	  with journal shutdown and free still queued delayed work.
 Make sure no new flushes will be queued 
 Allow old_work to run again 
  this is used to delete "save link" when there are no items of a
  file it points to. It can either happen if unlink is completed but
  "save unlink" removal, or if file has both unlink and truncate
  pending and as unlink completes first (because key of "save link"
  protecting unlink is bigger that a key lf "save link" which
  protects truncate), so there left no items to make truncate
  completion on
 we are going to do one balancing 
 removals are protected by direct items 
  Look for uncompleted unlinks and truncates and complete them
  Called with superblock write locked.  If quotas are enabled, we have to
  releaseretake lest we call dquot_quota_on_mount(), proceed to
  schedule_on_each_cpu() in invalidate_bdev() and deadlock waiting for the per
  cpu worklets to complete flush_async_commits() that in turn wait for the
  superblock write lock.
 compose key to look for "save" links 
 Needed for iput() to work correctly and not trash data 
 Turn on quotas so that they are updated correctly 
 there are no "save" links anymore 
 reiserfs_iget needs k_dirid and k_objectid only 
			
			  the unlink almost completed, it just did not
			  manage to remove "save" link and release objectid
 file is not unlinked 
			
			  We got a truncate request for a dir which
			  is impossible.  The only imaginable way is to
			  execute unfinished truncate request then boot
			  into old kernel, remove the file and create dir
			  with the same key.
			
			  not completed truncate found. New size was
			  committed together with "save" link
 don't update modification time 
 not completed unlink (rmdir) found 
 removal gets completed in iput 
 Turn quotas off 
 Restore the flag back 
  to protect file being unlinked from getting lost we "safe" link files
  being unlinked. This link will be deleted in the same transaction with last
  item of file. mounting the filesystem we scan all these links and remove
  files which almost got lost
 file can only get one "save link" of each kind 
 setup key of "save" link 
 unlink, rmdir, rename 
 item head of "safe" link 
length  , 0xffff 
 truncate 
 item head of "safe" link 
length  , 0 
 look for its place in the tree 
 body of "save" link 
 put "save" link into tree, don't charge quota to anyone 
 this opens transaction unlike add_save_link 
 we are going to do one balancing only 
 setup key of "save" link 
 unlink, rmdir, rename 
 truncate 
 don't take quota bytes from anywhere 
		
		  Force any pending inode evictions to occur now. Any
		  inodes to be removed that have extended attributes
		  associated with them need to clean them up before
		  we can release the extended attribute root dentries.
		  shrink_dcache_for_umount will BUG if we don't release
		  those before it's called so ->put_super is too late.
	
	  change file system state to current state if it was mounted
	  with read-write permissions
	
	  note, journal_release checks for readonly mount, and can
	  decide not to do a journal_end
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 we don't mark inodes dirty, we just log them 
	
	  this is really only used for atime updates, so they don't have
	  to be included in O_SYNC or fsync
 tails=small is default so we don't show it 
 barrier=flush is default so we don't show it 
 errors=ro is default so we don't show it 
 data=ordered is default so we don't show it 
 Block allocator options 
  this struct is used in reiserfs_getopt () for containing the value for
  those mount options that have values rather than being toggles.
	
	  bitmask which is to set on mount_options bitmask
	  when this value is found, 0 is no bits are to be changed.
	
	  bitmask which is to clear on mount_options bitmask
	  when this value is found, 0 is no bits are to be changed.
	  This is applied BEFORE setmask
 Set this bit in arg_required to allow empty arguments 
  this struct is used in reiserfs_getopt() for describing the
  set of reiserfs mount options
 0 if argument is not required, not 0 otherwise 
 list of values accepted by an option 
	
	  bitmask which is to set on mount_options bitmask
	  when this value is found, 0 is no bits are to be changed.
	
	  bitmask which is to clear on mount_options bitmask
	  when this value is found, 0 is no bits are to be changed.
	  This is applied BEFORE setmask
 possible values for -o data= 
 possible values for -o barrier= 
  possible values for "-o block-allocator=" and bits which are to be set in
  s_mount_opt of reiserfs specific part of in-core super block
  proceed only one option from a list cur - string containing of mount
  options
  opts - array of options which are accepted
  opt_arg - if option is found and requires an argument and if it is specifed
  in the input - pointer to the argument is stored here
  bit_flags - if option requires to set a certain bit - it is set here
  return -1 if unknown option is found, opt->arg_required otherwise
	
	  foo=bar,
	  ^   ^  ^
	  |   |  +-- option_end
	  |   +-- arg_start
	  +-- option_start
 assume argument cannot contain commas 
		
		  Ugly special case, probably we should redo options
		  parser so that it can understand several arguments for
		  some options, also so that it can fill several bitfields
		  with option values.
 for every option in the list 
	
	  move to the argument, or to next option if argument is not
	  required
 this catches "option=," if not allowed 
 =NULLopt_arg contains pointer to argument 
 values possible for this option are listed in opt->values 
 returns 0 if something is wrong in option string, 1 - otherwise 
 string given via mount's -o 
				  
				    after the parsing phase, contains the
				    collection of bitflags defining what
				    mount options were selected.
 strtol-ed from NNN of resize=NNN 
		
		  Compatibility stuff, so that -o notail for old
		  setups still work
		
		  use default configuration: create tails, journaling on, no
		  conversion to newest format
 wrong option is given 
 "resize=NNN" or "resize=auto" 
 From JFS code, to auto-get the size. 
 NNN does not look like a number 
 commit=NNN (time in seconds) 
 Hm, already assigned? 
 Some filename specified? 
 Add options that are safe here 
	
	  Update the bitmask, taking care to keep
	  the bits we're not allowed to change here
 0 means restore defaults. 
 remount read-only 
 it is read-only already 
 try to remount file system with read-only permissions 
 Mounting a rw partition read-only. 
 remount read-write 
 We are read-write already 
 now it is safe to call journal_begin 
 Mount a partition which is read-only, read-write 
 mark_buffer_dirty (SB_BUFFER_WITH_SB (s), 1); 
 this will force a full flush of all journal lists 
	
	  ok, reiserfs signature (old or new) found in at the given offset
	
	  magic is of non-standard journal filesystem, look at s_version to
	  find which format is in use
		
		  s_version of standard format may contain incorrect
		  information, so we just look at the magic string
	
	  new format is limited by the 32 bit wide i_blocks field, want to
	  be one full block below that.
 after journal replay, reread all bitmap and super blocks 
 hash detection stuff 
  if root directory is empty - we set default - Yura's - hash and
  warn about it
  FIXME: we look for only one name in a directory. If tea and yura
  both have the same value - we ask user to send report to the
  mailing list
 allow override in this case 
 finds out which hash names are sorted with 
	
	  reiserfs_hash_detect() == true if any of the hash mount options
	  were used.  We must check them to make sure the user isn't
	  using a bad hash value
		
		  detection has found the hash, and we must check against the
		  mount options
		
		  find_hash_out was not called or
		  could not determine the hash
	
	  if we are mounted RW, and we have a new valid hash code, update
	  the super
 return pointer to appropriate function 
 this is used to set up correct value for old partitions 
 should never happen 
 Set default values for options: non-aggressive tails, RO on errors 
 no preallocation minimum, be smart in reiserfs_file_write instead 
 Preallocate by 16 blocks (17-1) at once 
 setup default block allocator options 
	
	  try old format (undistributed bitmap, super block in 8-th 1k
	  block of a device)
	
	  try new format (64-th 1k block), which can contain reiserfs
	  super block
	
	  Let's do basic sanity check to verify that underlying device is not
	  smaller than the filesystem. If the check fails then abort and
	  scream, because bad stuff will happen otherwise.
 make data=ordered the default 
		
		  once this is set, journal_release must be called
		  if we error out of the mount
	
	  This path assumed to be called with the BKL in the old times.
	  Now we have inherited the big reiserfs lock from it and many
	  reiserfs helpers called in the mount path and elsewhere require
	  this lock to be held even if it's not always necessary. Let's be
	  conservative and hold it early. The window can be reduced after
	  careful review of the code.
 define and initialize hash function 
		
		  Clear out s_bmap_nr if it would wrap. We can handle this
		  case, but older revisions can't. This will cause the
		  file system to fail mount on those older implementations,
		  avoiding corruption. -jeffm
			
			  filesystem of format 3.5 either with standard
			  or non-standard journal
 and -o conv is given 
					
					  put magic string of 3.6 format.
					  2.2 will not be able to
					  mount this filesystem anymore
		
		  look for files which were to be removed in previous session
	
	  mark hash in super block: it could be unset. overwrite should be ok
 kill the commit thread, free journal ram 
 changed to accommodate gcc folks. 
 Release dquot anyway to avoid endless cycle in dqput() 
 Are we journaling quotas? 
 Data block + inode block 
  Turn on quotas during mount time - we need to find the quota file and such...
  Standard function to be called on quota_on
 Quotafile not on the same filesystem? 
	
	  We must not pack tails for quota files on reiserfs for quota
	  IO to work
 Journaling quota? 
 Quotafile not of fs root? 
	
	  When we journal data on quota file, we have to flush journal to see
	  all updates to the file when we bypass pagecache...
 Just start temporary transaction and finish it 
  Read data from quotafile - avoid pagecache and such because we cannot afford
  acquiring the locks... As quota files are never truncated and quota code
  itself serializes the operations (and no one else should touch the files)
  we don't have to be afraid of races
		
		  Quota files are without tails so we can safely
		  use this function
 A hole? 
  Write to quotafile (we know the transaction is already started and has
  enough credits)
 SPDX-License-Identifier: GPL-2.0
  linuxfsreiserfsxattr.c
  Copyright (c) 2002 by Jeff Mahoney, <jeffm@suse.com>
  In order to implement EAACLs in a clean, backwards compatible manner,
  they are implemented as files in a "private" directory.
  Each EA is in it's own file, with the directory layout like so ( is assumed
  to be relative to fs root). Inside the .reiserfs_privxattrs directory,
  directories named using the capital-hex form of the objectid and
  generation number are used. Inside each directory are individual files
  named with the name of the extended attribute.
  So, for objectid 12648430, we could have:
  .reiserfs_privxattrsC0FFEE.0system.posix_acl_access
  .reiserfs_privxattrsC0FFEE.0system.posix_acl_default
  .reiserfs_privxattrsC0FFEE.0user.Content-Type
  .. or similar.
  The file contents are the text of the EA. The size is known based on the
  stat data describing the file.
  In the case of system.posix_acl_access and system.posix_acl_default, since
  these are special cases for filesystem ACLs, they are interpreted by the
  kernel, in addition, they are negatively and positively cached and attached
  to the inode so that unnecessary lookups are avoided.
  Locking works like so:
  Directory components (xattr root, xattr dir) are protectd by their i_mutex.
  The xattrs themselves are protected by the xattr_sem.
  Helpers for inode ops. We do this so that we don't have all the VFS
  overhead and also for proper i_mutex annotation.
  dir->i_mutex must be held for all of them.
  We use I_MUTEX_CHILD here to silence lockdep. It's safe because xattr
  mutation ops aren't called during rename or splace, which are the
  only other users of I_MUTEX_CHILD. It violates the ordering, but that's
  better than allocating another subclass just for this code.
  The following are side effects of other operations that aren't explicitly
  modifying extended attributes. This includes operations such as permissions
  or ownership changes, object deletions, etc.
 A directory entry exists, but no file? 
 Skip out, an xattr has no xattrs associated with it 
		
		  We start a transaction here to avoid a ABBA situation
		  between the xattr root's i_mutex and the journal lock.
		  This doesn't incur much additional overhead since the
		  new transaction will just nest inside the
		  outer transaction.
	
	  -ENODATA: this object doesn't have any xattrs
	  -EOPNOTSUPP: this file system doesn't have xattrs enabled on disk.
	  Neither are errors
 This is the xattr dir, handle specially. 
	
	  We only want the ownership bits. Otherwise, we'll do
	  things like change a directory to a regular file if
	  ATTR_MODE is set.
 No i_mutex, but the inode is unconnected. 
 inode->i_mutex: down 
  Returns a dentry corresponding to a specific extended attribute file
  for the inode. If flags allow, the file is created. Otherwise, a
  valid or negative dentry, or an error is returned.
 Internal operations on file data 
	
	  We can deadlock if we try to free dentries,
	  and an unlinkrmdir has just occurred - GFP_NOFS avoids this
	
	  csum_partial() gives different results for little-endian and
	  big endian hosts. Images created on little-endian hosts and
	  mounted on big-endian hosts(and vice versa) will see csum mismatches
	  when trying to fetch xattrs. Treating the hash as __wsum_t would
	  lower the frequency of mismatch.  This is an endianness bug in
	  reiserfs.  The return statement would result in a sparse warning. Do
	  not fix the sparse warning so as to not hide a reminder of the bug.
 Generic extended attribute operations that can be used by xa plugins 
  inode->i_mutex: down
 We need to start a transaction to maintain lock ordering 
 Check before we start a transaction and then do nothing. 
  inode->i_mutex: down
	
	  We can't have xattrs attached to v1 items since they don't have
	  generation numbers
	
	  priv_root needn't be initialized during mount so allow initial
	  lookups to succeed.
 Just return the size needed 
 Magic doesn't match up.. 
  In order to implement different sets of xattr operations for each xattr
  prefix with the generic xattr API, a filesystem should create a
  null-terminated array of struct xattr_handler (one for each prefix) and
  hang a pointer to it off of the s_xattr field of the superblock.
  The generic_fooxattr() functions will use this list to dispatch xattr
  operations to the correct xattr_handler.
 This is the implementation for the xattr plugin infrastructure 
 Unsupported xattr name  ||
  Inode operation listxattr()
  We totally ignore the generic listxattr here because it would be stupid
  not to. Since the xattrs are organized in a directory, we can just
  readdir to find them.
 Not an error if there aren't any xattrs 
 Actual operations that are exported to VFS-land 
	
	  We need generation numbers to ensure that the oid mapping is correct
	  v3.5 filesystems don't have them.
			
			  Old format filesystem, but optional xattrs have
			  been enabled. Error out.
	
	  We don't do permission checks on the internal objects.
	  Permissions are determined by the "owning" object.
 If we don't have the privroot located yet - go find it 
  We need to take a copy of the mount flags since things like
  SB_RDONLY don't get set until after we're called.
  mount_flags != mount_options
 The super_block SB_POSIXACL must mirror the (no)acl mount option. 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
 this is one and only function that is used outside (do_balance.c) 
  modes of internal_shift_left, internal_shift_right and
  internal_insert_childs
 define dest, src, dest parent, dest position 
 used in internal_shift_left 
 dest position is analog of dest->b_item_order 
 used in internal_shift_left 
  Insert count node pointers into buffer cur before position to + 1.
  Insert count items into buffer cur before position to.
  Items and node pointers are specified by inserted and bh respectively.
 prepare space for count disk_child 
 copy to_be_insert disk children 
 prepare space for count items  
 copy item headers (keys) 
 sizes, item number 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
  Delete del_num items and node pointers from buffer cur starting from
  the first_i'th item and first_p'th pointers respectively.
 deleting 
 sizes, item number 
&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
 delete n node pointers and items starting from given position 
	
	  delete n pointers starting from `from' position in CUR;
	  delete n keys starting from 'i_from' position in CUR;
  copy cpy_num node pointers and cpy_num - 1 items from buffer src to buffer
  dest
  last_first == FIRST_TO_LAST means that we copy first items
                              from src to tail of dest
  last_first == LAST_TO_FIRST means that we copy last items
                              from src to head of dest
	
	  ATTENTION! Number of node pointers in DEST is equal to number
	  of items in DEST  as delimiting key have already inserted to
	  buffer dest.
 coping 
dest_order = (last_first == LAST_TO_FIRST) ? 0 : nr_dest; 
src_order = (last_first == LAST_TO_FIRST) ? (nr_src - cpy_num + 1) : 0; 
 prepare space for cpy_num pointers 
 insert pointers 
 prepare space for cpy_num - 1 item headers 
 insert headers 
 sizes, item number 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
  Copy cpy_num node pointers and cpy_num - 1 items from buffer src to
  buffer dest.
  Delete cpy_num - del_par items and node pointers from buffer src.
  last_first == FIRST_TO_LAST means, that we copydelete first items from src.
  last_first == LAST_TO_FIRST means, that we copydelete last items from src.
 shift_left occurs 
		
		  delete cpy_num - del_par pointers and keys starting for
		  pointers with first_pointer, for key - with first_item
 shift_right occurs 
 Insert n_src'th key of buffer src before n_dest'th key of buffer dest. 
 insert key before key with n_dest number 
 prepare space for inserting key 
 insert key 
 Change dirt, free space, item number fields. 
  Insert d_key'th (delimiting) key from buffer cfl to tail of dest.
  Copy pointer_amount node pointers and pointer_amount - 1 items from
  buffer src to buffer dest.
  Replace  d_key'th key in buffer cfl.
  Delete pointer_amount items and node pointers from buffer src.
 this can be invoked both to shift from S to L and from R to S 
				
				  INTERNAL_FROM_S_TO_L | INTERNAL_FROM_R_TO_S
printk("pointer_amount = %d\n",pointer_amount); 
		
		  insert delimiting key from common father of dest and
		  src to node dest into position B_NR_ITEM(dest)
src->b_item_order   == 0)
src->b_parent  , 0);
 last parameter is del_parameter 
  Insert delimiting key to L[h].
  Copy n node pointers and n - 1 items from buffer S[h] to L[h].
  Delete n - 1 items and node pointers from buffer S[h].
 it always shifts from S[h] to L[h] 
 insert lkey[h]-th key  from CFL[h] to left neighbor L[h] 
 last parameter is del_parameter 
  Insert d_key'th (delimiting) key from buffer cfr to head of dest.
  Copy n node pointers and n - 1 items from buffer src to buffer dest.
  Replace  d_key'th key in buffer cfr.
  Delete n items and node pointers from buffer src.
				 
				   INTERNAL_FROM_S_TO_R | INTERNAL_FROM_L_TO_S
		
		  insert delimiting key from common father of dest
		  and src to dest node into position 0
tb->S[h]  ||
 when S[h] disappers replace left delemiting key as well 
 last parameter is del_parameter 
  Insert delimiting key to R[h].
  Copy n node pointers and n - 1 items from buffer S[h] to R[h].
  Delete n - 1 items and node pointers from buffer S[h].
 it always shift from S[h] to R[h] 
 insert rkey from CFR[h] to right neighbor R[h] 
 last parameter is del_parameter 
  Delete insert_num node pointers together with their left items
  and balance current node.
 delete child-node-pointer(s) together with their left item(s) 
 node S[h] (root of the tree) is empty now 
 choose a new root 
			
			  switch super block's tree root block
REISERFS_SB(tb->tb_sb)->s_rs->s_tree_height --; 
&&&&&&&&&&&&&&&&&&&&&& 
 use check_internal if new root is an internal node 
&&&&&&&&&&&&&&&&&&&&&& 
 do what is needed for buffer thrown from tree 
 join S[h] with L[h] 
 join S[h] with R[h] 
 borrow from left neighbor L[h] 
 borrow from right neighbor R[h] 
tb->S[h], tb->CFR[h], tb->rkey[h], tb->R[h], -tb->rnum[h]); 
 split S[h] into two parts and put them into neighbors 
tb->L[h], tb->CFL[h], tb->lkey[h], tb->S[h], tb->lnum[h]); 
 Replace delimiting key of buffers L[h] and S[h] by the given key.
 Replace delimiting key of buffers S[h] and R[h] by the given key.
  if insertingpasting {
    child_pos is the position of the node-pointer in S[h] that
    pointed to S[h-1] before balancing of the h-1 level;
    this means that new pointers and items must be inserted AFTER
    child_pos
  } else {
    it is the position of the leftmost pointer that must be deleted
    (together with its corresponding key to the left of the pointer)
    as a result of the previous level's balancing.
  }
 level of the tree 
 key for insertion on higher level    
 node for insertion on higher level 
	
	  we return this: it is 0 if there is no S[h],
	  else it is tb->S[h]->b_item_order
tb->S[h]->b_item_order  : 0;
	
	  Using insert_size[h] calculate the number insert_num of items
	  that must be inserted to or deleted from S[h].
 Check whether insert_num is proper  
 Make balance in case insert_num < 0 
		
		  shift lnum[h] items from S[h] to the left neighbor L[h].
		  check how many of new items fall into L[h] or CFL[h] after
		  shifting
 number of items in L[h] 
 new items don't fall into L[h] or CFL[h] 
 all new items fall into L[h] 
 insert insert_num keys and node-pointers into L[h] 
tb->L[h], tb->S[h-1]->b_next 
			
			  some items fall into L[h] or CFL[h],
			  but some don't fall
 calculate number of new items that fall into L[h] 
tb->L[h], tb->S[h-1]->b_next, 
			
			  replace the first node-ptr in S[h] by
			  node-ptr to insert_ptr[k]
 tb->lnum[h] > 0 
shift rnum[h] items from S[h] to the right neighbor R[h] 
		
		  check how many of new items fall into R or CFR
		  after shifting
 number of items in S[h] 
 new items fall into S[h] 
 all new items fall into R[h] 
 insert insert_num keys and node-pointers into R[h] 
tb->R[h],tb->S[h-1]->b_next 
 one of the items falls into CFR[h] 
 calculate number of new items that fall into R[h] 
tb->R[h], tb->R[h]->b_child, 
			
			  replace the first node-ptr in R[h] by
			  node-ptr insert_ptr[insert_num-k-1]
 Fill new node that appears instead of S[h] 
 node S[h] is empty now 
 do what is needed for buffer thrown from tree 
 create new root 
 S[h] = empty buffer from the list FEB. 
 Put the unique node-pointer to S[h] that points to S[h-1]. 
&&&&&&&&&&&&&&&&&&&&&&&& 
&&&&&&&&&&&&&&&&&&&&&&&& 
 put new root into path structure 
 Change root in structure super block. 
 S_new = free buffer from list FEB 
 number of items in S[h] 
 new items don't fall into S_new 
  store the delimiting key for the next level 
 new_insert_key = (n - snum)'th key in S[h] 
 last parameter is del_par 
 all new items fall into S_new 
  store the delimiting key for the next level 
			
			  new_insert_key = (n + insert_item - snum)'th
			  key in S[h]
 last parameter is del_par 
			
			  insert insert_num keys and node-pointers
			  into S_new
S_new,tb->S[h-1]->b_next, 
 some items fall into S_new, but some don't fall 
 last parameter is del_par 
 calculate number of new items that fall into S_new 
S_new,  0, k,
 new_insert_key = insert_key[insert_num - k - 1] 
			
			  replace first node-ptr in S_new by node-ptr
			  to insert_ptr[insert_num-k-1]
 new_insert_ptr = node_pointer to S_new 
 S_new is released in unfix_nodes 
number of items in S[h] 
tbSh, 
          ( tb->S[h-1]->b_parent == tb->S[h] ) ? tb->S[h-1]->b_next :  tb->S[h]->b_child->b_next, 
   Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
   Written by Anatoly P. Pinchuk pap@namesys.botik.ru
   Programm System Institute
   Pereslavl-Zalessky Russia
 Does the buffer contain a disk block which is in the tree. 
 to get item head in le form 
  k1 is pointer to on-disk structure which is stored in little-endian
  form. k2 is pointer to cpu variable. For key of items of the same
  object this returns 0.
  Returns: -1 if key1 < key2
  0 if key1 == key2
  1 if key1 > key2
  k1 is pointer to on-disk structure which is stored in little-endian
  form. k2 is pointer to cpu variable.
  Compare keys using all 4 key fields.
  Returns: -1 if key1 < key2 0
  if key1 = key2 1 if key1 > key2
 this part is needed only when tail conversion is in progress 
 find out version of the key 
  this does not say which one is bigger, it only returns 1 if keys
  are not equal, 0 otherwise
   Binary search toolkit function                                        
   Search for an item in the array by the item key                       
   Returns:    1 if found,  0 if not found;                              
         pos = number of the searched element if found, else the        
         number of the first element that is larger than key.            
  For those not familiar with binary search: lbound is the leftmost item
  that it could be, rbound the rightmost item that it could be.  We examine
  the item halfway between lbound and rbound, and that tells us either
  that we can increase lbound, or decrease rbound, or that we have found it,
  or if lbound <= rbound that there are no possible items, and we have not
  found it. With each examination we cut the number of possible items it
  could be by one more than half rounded down, or we find it.
 Key to search for. 
 First item in the array. 
 Number of items in the array. 
			     
			       Item size in the array.  searched. Lest the
			       reader be confused, note that this is crafted
			       as a general function, and when it is applied
			       specifically to the array of item headers in a
			       node, width is actually the item header size
			       not the item size.
 Number of the searched for element. 
 Key found in the array.  
	
	  bin_search did not find given key, it returns position of key,
	  that is minimal and greater than the given one.
 Minimal possible key. It is never in the tree. 
 Maximal possible key. It is never in the tree. 
  Get delimiting key of the buffer by looking for it in the buffers in the
  path, starting from the bottom of the path, and going upwards.  We must
  check the path's validity at each step.  If the key is not in the path,
  there is no delimiting key in the tree (buffer is first or last buffer
  in tree), and in this case we return a special key, either MIN_KEY or
  MAX_KEY.
 While not higher in path than first element. 
 Parent at the path is not in the tree now. 
 Check whether position in the parent is correct. 
 Check whether parent at the path really points to the child. 
		
		  Return delimiting key if position in the parent
		  is not equal to zero.
 Return MIN_KEY if we are in the root of the buffer tree. 
 Get delimiting key of the buffer at the path and its right neighbor. 
 Parent at the path is not in the tree now. 
 Check whether position in the parent is correct. 
		
		  Check whether parent at the path really points
		  to the child.
		
		  Return delimiting key if position in the parent
		  is not the last one.
 Return MAX_KEY if we are in the root of the buffer tree. 
  Check whether a key is contained in the tree rooted from a buffer at a path.
  This works by looking at the left and right delimiting keys for the buffer
  in the last path_element in the path.  These delimiting keys are stored
  at least one level above that buffer in the tree. If the buffer is the
  first or last node in the tree order then one of the delimiting keys may
  be absent, and in this case get_lkey and get_rkey return a special key
  which is MIN_KEY or MAX_KEY.
 Path which should be checked. 
 Key which should be checked. 
 left delimiting key is bigger, that the key we look for 
  if ( comp_keys(key, get_rkey(chk_path, sb)) != -1 ) 
 key must be less than right delimitiing key 
  Drop the reference to each buffer in a path and restore
  dirty bits clean when preparing the buffer for the log.
  This version should only be called from fix_nodes()
 Drop the reference to each buffer in a path 
 item number is too big or too small 
 free space does not match to calculated amount of use space 
	
	  FIXME: it is_leaf will hit performance too much - we may have
	  return 1 here
 check tables of item heads 
 one may imagine many more checks 
 returns 1 if buf looks like an internal node, 0 otherwise 
 this level is not possible for internal nodes 
 for internal which is not root we might check min number of keys 
 one may imagine many more checks 
  make sure that bh contains formatted node of reiserfs tree of
  'level'-th level
  The function is NOT SCHEDULE-SAFE!
  It might unlock the write lock if we needed to wait for a block
  to be read. Note that in this case it won't recover the lock to avoid
  high contention resulting from too much lock requests, especially
  the caller (search_by_key) will perform other schedule-unsafe
  operations just after calling this function.
  @return depth of lock to be restored after read completes
	
	  We are going to read some blocks on which we
	  have a reference. It's safe, though we might be
	  reading blocks concurrently changed if we release
	  the lock. But it's still fine because we check later
	  if the tree changed
		
		  note, this needs attention if we are getting rid of the BKL
		  you have to make sure the prepared bit isn't set on this
		  buffer
  This function fills up the path from the root to the leaf as it
  descends the tree looking for the key.  It uses reiserfs_bread to
  try to find buffers in the cache given their block number.  If it
  does not find them in the cache it reads them from disk.  For each
  node search_by_key finds using reiserfs_bread it then uses
  bin_search to look through that node.  bin_search will find the
  position of the block_number of the next node if it is looking
  through an internal node.  If it is looking through a leaf node
  bin_search will find the position of the item which has key either
  equal to given key, or which is the maximal key less than the given
  key.  search_by_key returns a path that must be checked for the
  correctness of the top of the path but need not be checked for the
  correctness of the bottom of the path
  search_by_key - search for key (and item) in stree
  @sb: superblock
  @key: pointer to key to search for
  @search_path: Allocated and initialized struct treepath; Returned filled
 		 on success.
  @stop_level: How far down the tree to search, Use DISK_LEAF_NODE_LEVEL to
 		stop at leaf level.
  The function is NOT SCHEDULE-SAFE!
	
	  As we add each node to a path we increase its count.  This means
	  that we must be careful to release all nodes in a path before we
	  either discard the path struct or re-use the path struct, as we
	  do here.
	
	  With each iteration of this loop we search through the items in the
	  current node, and calculate the next current node(next path element)
	  for the next iteration of this loop..
 prep path to have another element added to it. 
		
		  Read the next tree node, and set the last element
		  in the path to have a pointer to it.
			
			  We'll need to drop the lock if we encounter any
			  buffers that need to be read. If all of them are
			  already up to date, we don't need to drop the lock.
		
		  It is possible that schedule occurred. We must check
		  whether the key to search is still in the tree rooted
		  from the current buffer. If not then repeat search
		  from the root.
			
			  Get the root block number so that we can
			  repeat the search starting from the root.
 repeat search from the root 
		
		  only check that the key is in the buffer if key is not
		  equal to the MAX_KEY. Latter case is only possible in
		  "finish_unfinished()" processing during mount.
		
		  make sure, that the node contents look like a node of
		  certain level
 ok, we have acquired next formatted node in the tree 
 we are not in the stop level 
		
		  item has been found, so we choose the pointer which
		  is to the right of the found one
		
		  if item was not found we choose the position which is to
		  the left of the found item. This requires no code,
		  bin_search did it already.
		
		  So we have chosen a position in the current node which is
		  an internal node.  Now we calculate child block number by
		  position in the node.
		
		  if we are going to read leaf nodes, try for read
		  ahead as well
				
				  check to make sure we're in the same object
  Form the path to an item and position in this item which contains
  file byte defined by key. If there is no such item
  corresponding to the key, we point the path to the item with
  maximal key less than key, and pos_in_item is set to one
  past the last entrybyte in the item.  If searching for entry in a
  directory item, and it is not found, pos_in_item is set to one
  entry more than the entry with maximal key which is less than the
  sought key.
  Note that if there is no entry in this same node which is one more,
  then we point to an imaginary entry.  for direct items, the
  position is in units of bytes, for indirect items the position is
  in units of blocknr entries, for directory items the position is in
  units of directory entries.
 The function is NOT SCHEDULE-SAFE! 
 Key to search (cpu variable) 
 Filled up by this function. 
 pointer to on-disk structure 
 If searching for directory entry. 
 If not searching for directory entry. 
 If item is found. 
 Item is not found. Set path to the previous item. 
 FIXME: quite ugly this far 
 Needed byte is contained in the item pointed to by the path. 
	
	  Needed byte is not contained in the item pointed to by the
	  path. Set pos_in_item out of the item.
 Compare given item and item pointed to by the path. 
 Last buffer at the path is not in the tree. 
 Last path position is invalid. 
 we need only to know, whether it is the same item 
 prepare for delete or cut of direct item 
 item has to be deleted 
 new file gets truncated 
 this was new_file_length < le_ih ... 
 Delete this item. 
 Calculate first position and size for cutting from item. 
 Cut from this item. 
 old file: items may have any length 
 Delete this item. 
 Calculate first position and size for cutting from item. 
 Cut from this item. 
 Delete the directory item containing "." and ".." entry. 
		
		  Delete the directory item such as there is one record only
		  in this item
 Cut one record from the directory item. 
  If the path points to a directory or direct item, calculate mode
  and the size cut, for balance.
  If the path points to an indirect item, remove some number of its
  unformatted nodes.
  In case of file truncate calculate whether this item must be
  deletedtruncated or last unformatted node of this item will be
  converted to a direct item.
  This function returns a determination of what balance mode the
  calling function should employ.
				      
				        Number of unformatted nodes
				        which were removed from end
				        of the file.
 MAX_KEY_OFFSET in case of delete. 
 Stat_data item. 
 Directory item. 
 Direct item. 
 Case of an indirect item. 
		
		  prepare_for_delete_or_cut() is called by
		  reiserfs_delete_item()
		    
		      Each unformatted block deletion may involve
		      one additional bitmap block into the transaction,
		      thereby the initial journal space reservation
		      might not be enough.
		
		  a trick.  If the buffer has been logged, this will
		  do nothing.  If we've broken the loop without logging
		  it, it will restore the buffer
		
		  Nothing was cut. maybe convert last unformatted node to the
		  direct item?
 Calculate number of bytes which will be deleted or cut during balance 
		
		  return EMPTY_DIR_SIZE; We delete emty directories only.
		  we can't use EMPTY_DIR_SIZE, as old format dirs have a
		  different empty size.  ick. FIXME, is this right?
  Delete object item.
  th       - active transaction handle
  path     - path to the deleted item
  item_key - key to search for the deleted item
  indode   - used for updating i_blocks and quotas
  un_bh    - NULL or unformatted node pointer
size is unknown  );
 file system changed, repeat search 
 while (1) 
 reiserfs_delete_item returns item length when success 
	
	  hack so the quota code doesn't have to guess if the file has a
	  tail.  On tail insert, we allocate quota for 1 unformatted node.
	  We test the offset because the tail might have been
	  split into multiple items, and we only want to decrement for
	  the unfm node once
		
		  We are in direct2indirect conversion, so move tail contents
		  to the unformatted node
		
		  note, we do the copy before preparing the buffer because we
		  don't care about the contents of the unformatted node yet.
		  the only thing we really care about is the direct item's
		  data is in the unformatted node.
		 
		  Otherwise, we would have to call
		  reiserfs_prepare_for_journal on the unformatted node,
		  which might schedule, meaning we'd have to loop all the
		  way back up to the start of the while loop.
		 
		  The unformatted node must be dirtied later on.  We can't be
		  sure here if the entire tail has been deleted yet.
		 
		  un_bh is from the page cache (all unformatted nodes are
		  from the page cache) and might be a highmem page.  So, we
		  can't use un_bh->b_data.
		  -clm
 Perform balancing after all resources have been collected at once. 
 Return deleted body length 
  Summary Of Mechanisms For Handling Collisions Between Processes:
   deletion of the body of the object is performed by iput(), with the
   result that if multiple processes are operating on a file, the
   deletion of the body of the file is deferred until the last process
   that has an open inode performs its iput().
   writes and truncates are protected from collisions by use of
   semaphores.
   creates, linking, and mknod are protected from collisions with other
   processes by making the reiserfs_add_entry() the last step in the
   creation, and then rolling back all changes if there was a collision.
   - Hans
 this deletes item which never gets split 
			
			  No need for a warning, if there is just no free
			  space to insert '..' item into the
			  newly-created subdir
			
			  Should we count quota for item? (we don't
			  count quotas for save-links)
 IO_ERROR, NO_DISK_SPACE, etc 
 for directory this deletes item containing "." and ".." 
no timestamp updates  );
 USE_INODE_GENERATION_COUNTER 
				
				  we want to unmap the buffers that contain
				  the tail, and all the buffers after it
				  (since the tail must be at the end of the
				  file).  We don't want to unmap file data
				  before the tail, since it might be dirty
				  and waiting to reach disk
	
	  the page being sent in could be NULL if there was an io error
	  reading in the last block.  The user will hit problems trying to
	  read the file, but for now we just skip the indirect2direct
 leave tail in an unformatted node 
 Perform the conversion to a direct_item. 
  we did indirect_to_direct conversion. And we have inserted direct
  item successesfully, but there were no disk space to cut unfm
  pointer being converted. Therefore we have to delete inserted
  direct item(s)
 look for the last byte of the tail 
unbh not needed  );
 (Truncate or cut entry) or delete object item. Returns < 0 on failure 
	
	  Every function which is going to call do_balance must first
	  create a tree_balance structure.  Then it must fill up this
	  structure by using the init_tb_struct and fix_nodes functions.
	  After that we can make tree balancing.
 Amount to be cut. 
 Number of the removed unformatted nodes. 
 Mode of the balance. 
	
	  Repeat this loop until we either cut the item without needing
	  to balance, or we fix_nodes without schedule occurring
		
		  Determine the balance mode, position of the first byte to
		  be cut, and size to be cut.  In case of the indirect item
		  free unformatted nodes which are pointed to by the cut
		  pointers.
			
			  convert last unformatted node to direct item or
			  leave tail in the unformatted node
 tail has been left in the unformatted node 
			
			  removing of last unformatted node will
			  change value we have to return to truncate.
			  Save it
			
			  So, we have performed the first part of the
			  conversion:
			  inserting the new direct item.  Now we are
			  removing the last unformatted node pointer.
			  Set key to search for it.
 while 
 check fix_nodes results (IO_ERROR or NO_DISK_SPACE) 
			
			  FIXME: this seems to be not needed: we are always
			  able to cut item
 go ahead and perform balancing 
 Calculate number of bytes that need to be cut from the item. 
	
	  For direct items, we only change the quota when deleting the last
	  item.
 FIXME: this is to keep 3.5 happy 
		
		  we are going to complete indirect2direct conversion. Make
		  sure, that we exactly remove last unformatted node pointer
		  of the item
		
		  it would be useful to make sure, that right neighboring
		  item is direct item of this file
		
		  we've done an indirect->direct conversion.  when the
		  data block was freed, it was removed from the list of
		  blocks that must be flushed before the transaction
		  commits, make sure to unmap and invalidate it
  Truncate file to the new size. Note, this must be called with a
  transaction already started
 ->i_size contains new size 
 up to date for last block 
			 
			   when it is called by file_release to convert
			   the tail - no timestamps should be updated
 Path to the current object item. 
 Pointer to an item header. 
 Key to search for a previous file item. 
 Old file size. 
 New file size. 
 Number of deleted or truncated bytes. 
 deletion of directory - no need to update timestamps 
 Get new file size. 
 FIXME: note, that key type is unimportant here 
 Get real file size (total length of all file items) 
		
		  this may mismatch with real file size: if last direct item
		  had no padding zeros and last unformatted node had no free
		  space, this file would have this file size
	
	  are we doing a full truncate or delete, if so
	  kick in the reada code
 Update key to search for the last file item. 
 Cut or delete file item. 
 Change key to search the last file item. 
		
		  While there are bytes to truncate and previous
		  file item is presented in the tree.
		
		  This loop could take a really long time, and could log
		  many more blocks than a transaction can hold.  So, we do
		  a polite journal end here, and if the transaction needs
		  ending, we make sure the file is consistent before ending
		  the current trans and starting a new one
 this is truncate, not file closing 
 this makes sure, that we __append__, not overwrite or add holes 
 config reiserfs check 
  Paste bytes to the existing item.
  Returns bytes number pasted into the item.
 Path to the pasted item. 
 Key to search for the needed item. 
 Inode item belongs to 
 Pointer to the bytes to paste. 
 Size of pasted bytes. 
 DQUOT_ can schedule, must check before the fix_nodes 
 file system changed while we were in the fix_nodes 
	
	  Perform balancing after all resources are collected by fix_nodes,
	  and accessing them will not risk triggering schedule.
ih  , body, M_PASTE);
 this also releases the path 
  Insert new item into the buffer at the path.
  th   - active transaction handle
  path - path to the inserted item
  ih   - pointer to the item header to insert
  body - pointer to the bytes to insert
 Do we count quotas for item? 
		
		  hack so the quota code doesn't have to guess
		  if the file has a tail, links are always tails,
		  so there's no guessing needed
		
		  We can't dirty inode here. It would be immediately
		  written but appropriate stat item isn't inserted yet...
	
	  DQUOT_ can schedule, must check to be sure calling
	  fix_nodes is safe
 file system changed while we were in the fix_nodes 
 make balancing after all resources will be collected at a time 
 also releases the path 
 SPDX-License-Identifier: GPL-2.0
  Write ahead logging implementation copyright Chris Mason 2000
  The background commits make this code very interrelated, and
  overly complex.  I need to rethink things a bit....The major players:
  journal_begin -- call with the number of blocks you expect to log.
                   If the current transaction is too
 		    old, it will block until the current transaction is
 		    finished, and then start a new one.
 		    Usually, your transaction will get joined in with
                   previous ones for speed.
  journal_join  -- same as journal_begin, but won't block on the current
                   transaction regardless of age.  Don't ever call
                   this.  Ever.  There are only two places it should be
                   called from, and they are both inside this file.
  journal_mark_dirty -- adds blocks into this transaction.  clears any flags
                        that might make them get sent to disk
                        and then marks them BH_JDirty.  Puts the buffer head
                        into the current transaction hash.
  journal_end -- if the current transaction is batchable, it does nothing
                    otherwise, it could do an asyncsynchronous commit, or
                    a full flush of all log and real blocks in the
                    transaction.
  flush_old_commits -- if the current transaction is too old, it is ended and
                       commit blocks are sent to disk.  Forces commit blocks
                       to disk for all backgrounded commits that have been
                       around too long.
 		     -- Note, if you call this as an immediate flush from
 		        within kupdate, it will ignore the immediate flag
 gets a struct reiserfs_journal_list  from a list head 
 must be correct to keep the desc and commit structs at 4k 
read ahead 
 cnode stat bits.  Move these into reiserfs_fs.h 
 this block was freed, and can't be written.  
 this block was freed during this transaction, and can't be written 
 used in flush_journal_list 
 journal list state bits 
 someone will commit this list 
 flags for do_journal_end 
 flush commit and real blocks 
 end and commit this transaction 
 wait for the log blocks to hit the disk 
 values for join in do_journal_begin_r 
 regular journal begin 
 join the running transaction if at all possible 
 called from cleanup code, ignores aborted flag 
  clears BH_Dirty and sticks the buffer on the clean list.  Called because
  I can't allow refile_buffer to make schedule happen after I've freed a
  block.  Look at remove_from_transaction and journal_mark_freed for
  more details.
 this is ok, we'll try again when more are needed 
  only call this on FS unmount.
  get memory for JOURNAL_NUM_BITMAPS worth of bitmaps.
  jb_array is the array to be filled in.
  find an available list bitmap.  If you can't find one, flush a commit list
  and try again
 double check to make sure if flushed correctly 
  allocates a new chunk of X nodes, and links them all together as a list.
  Uses the cnode->next and cnode->prev pointers
  returns NULL on failure
 if last one, overwrite it after the if 
 pulls a cnode off the free list, or returns NULL on failure 
  returns a cnode to the free list
 memset(cn, 0, sizeof(struct reiserfs_journal_cnode)) ; 
 not needed with the memset, but I might kill the memset, and forget to do this 
  return a cnode with same dev, block number and size in table,
  or null if not found
  this actually means 'can this block be reallocated yet?'.  If you set
  search_all, a block can only be allocated if it is not in the current
  transaction, was not freed by the current transaction, and has no chance
  of ever being overwritten by a replay after crashing.
  If you don't set search_all, a block can only be allocated if it is not
  in the current transaction.  Since deleting a block removes it from the
  current transaction, this case should never happen.  If you don't set
  search_all, make sure you never write the block without logging it.
  next_zero_bit is a suggestion about the next block to try for find_forward.
  when bl is rejected because it is set in a journal list bitmap, we search
  for the next zero bit in the bitmap that rejected bl.  Then, we return
  that through next_zero_bit for find_forward to try.
  Just because we return something in next_zero_bit does not mean we won't
  reject it on the next call to reiserfs_in_journal
 always start this at zero. 
	
	  If we aren't doing a search_all, this is a metablock, and it
	  will be logged before use.  if we crash before the transaction
	  that freed it commits,  this transaction won't have committed
	  either, and the block will never be written
 is it in any old transactions? 
 is it in the current transaction.  This should never happen 
 safe for reuse 
 insert cn into table 
 lock the current transaction 
 unlock the current transaction 
  this used to be much more involved, and I'm keeping it just in case
  things get ugly again.  it gets called by flush_commit_list, and
  cleans up any data stored about blocks freed during a transaction.
  If page->mapping was null, we failed to truncate this page for
  some reason.  Most likely because it was truncated after being
  logged via data=journal.
  This does a check to see if the buffer belongs to one of these
  lost pages before doing the final put_bh.  If page->mapping was
  null, it tries to free buffers on the page, which should make the
  final put_page drop the page from the lru.
  we want to free the jh when the buffer has been written
  and waited on
		
		  buffer must be locked for __add_jh, should be able to have
		  two adds at the same time
		
		  in theory, dirty non-uptodate buffers should never get here,
		  but the upper layer io error paths still have a few quirks.
		  Handle them here as gracefully as we can
		
		  ugly interaction with invalidatepage here.
		  reiserfs_invalidate_page will pin any buffer that has a
		  valid journal head from an older transaction.  If someone
		  else sets our buffer dirty after we write it in the first
		  loop, and then someone truncates the page away, nobody
		  will ever write the buffer. We're safe if we write the
		  page one last time after freeing the journal header.
	
	  first we walk backwards to find the oldest uncommitted transation
 if we didn't find any older uncommitted transactions, return now 
 list we were called with is gone, return 
				
				  the one we just flushed is gone, this means
				  all older lists are also gone, so first_jl
				  is no longer valid either.  Go back to the
				  beginning.
  if this journal list still has commit blocks unflushed, send them to disk.
  log areas must be flushed in order (transaction 2 can't commit before
  transaction 1) Before the commit block can by written, every other log
  block must be safely on disk
	
	  before we can put our commit blocks on disk, we have to make
	  sure everyone older than us is on disk too
			
			  list disappeared during flush_older_commits.
			  return
 make sure nobody is trying to flush this one at the same time 
 this commit is done, exit 
		
		  We might sleep in numerous places inside
		  write_ordered_buffers. Relax the write lock.
	
	  for the description block and all the log blocks, submit any buffers
	  that haven't already reached the disk.  Try to write at least 256
	  log blocks. later on, we will only wait on blocks that correspond
	  to this transaction, but while we're unplugging we might as well
	  get a chunk of data on there.
		
		  since we're using ll_rw_blk above, it might have skipped
		  over a locked buffer.  Double check here
 redundant, sync_dirty_buffer() checks 
 once for journal_find_get_block 
 once due to original getblk in do_journal_end 
	
	  If there was a write error in the journal - we can't commit
	  this transaction - it will be invalid and, if successful,
	  will just end up propagating the write error out to
	  the file system.
	
	  If there was a write error in the journal - we can't commit this
	  transaction - it will be invalid and, if successful, will just end
	  up propagating the write error out to the filesystem.
	
	  now, every commit block is on the disk.  It is safe to allow
	  blocks freed during this transaction to be reallocated
 mark the metadata dirty 
  flush_journal_list frequently needs to find a newer transaction for a
  given block.  This does that, or returns NULL if it can't find anything
  once all the real blocks have been flushed, it is safe to remove them
  from the journal list for this transaction.  Aside from freeing the
  cnode, this also allows the block to be reallocated for data blocks
  if it had been deleted.
	
	  which is better, to lock once around the whole loop, or
	  to lock for each call to remove_journal_hash?
  if this timestamp is greater than the timestamp we wrote last to the
  header block, write it to the header block.  once this is done, I can
  safely say the log area for this transaction won't ever be replayed,
  and I can start releasing blocks in this transaction for reuse as data
  blocks.  called by flush_journal_list, before it calls
  remove_all_from_journal_list
 flush any and all journal lists older than you are
 can only be called from flush_journal_list
	
	  we know we are the only ones flushing things, no extra race
	  protection is required.
 Did we wrap? 
 do not flush all 
 other_jl is now deleted from the list 
  flush a journal list, both commit and real blocks
  always set flushall to 1, unless you are calling from inside
  flush_journal_list
  IMPORTANT.  This can only be called while there are no journal writers,
  and the journal is locked.  That means it can only be called from
  do_journal_end, or by journal_release
 if flushall == 0, the lock is already held 
 if all the work is already done, get out of here 
	
	  start by putting the commit list on disk.  This will also flush
	  the commit lists of any olders transactions
 are we done now? 
	
	  loop through each cnode, see if we need to write it,
	  or wait on a more recent transaction, or just ignore it
 blocknr of 0 is no longer in the hash, ignore it 
		
		  This transaction failed commit.
		  Don't write out to the disk
		
		  the order is important here.  We check pjl to make sure we
		  don't clear BH_JDirty_wait if we aren't the one writing this
		  block to disk
			
			  we do this to make sure nobody releases the
			  buffer while we are working with it
				
				  everything with !pjl && jwait
				  should be writable
		
		  if someone has this block in a newer transaction, just make
		  sure they are committed, and don't try writing it to disk
		
		  bh == NULL when the block got to disk on its own, OR,
		  the block got freed in a future transaction
		
		  this should never happen.  kupdate_one_transaction has
		  this list locked while it works, so we should never see a
		  buffer here that is not marked JDirty_wait
			
			  we inc again because saved_bh gets decremented
			  at free_cnode
			
			  we incremented this to keep others from
			  taking the buffer head away
				
				  note, we must clear the JDirty_wait bit
				  after the up to date check, otherwise we
				  race against our flushpage routine
 drop one ref for us 
 drop one ref for journal_mark_dirty 
	
	  before we can update the journal header block, we _must_ flush all
	  real blocks from all older transactions to disk.  This is because
	  once the header block is updated, this transaction will not be
	  replayed after a crash
	
	  before we can remove everything from the hash tables for this
	  transaction, we must make sure it can never be replayed
	 
	  since we are only called from do_journal_end, we know for sure there
	  are no allocations going on while we are flushing journal lists.  So,
	  we only need to update the journal header block for the last list
	  being flushed
	
	  not strictly required since we are freeing the list, but it should
	  help find code using dead lists later on
		
		  if the blocknr == 0, this has been cleared from the hash,
		  skip it
			
			  we can race against journal_mark_freed when we try
			  to lock_buffer(cn->bh), so we have to inc the buffer
			  count, and recheck things after locking
 note, cn->bh might be null now 
 used by flush_commit_list 
		
		  look for a more recent transaction that logged this
		  buffer.  Only the most recent transaction with a buffer in
		  it is allowed to send that buffer to disk
			
			  if the buffer is prepared, it will either be logged
			  or restored.  If restored, we need to make sure
			  it actually gets marked dirty
	
	  we've got j_flush_mutex held, nobody is going to delete any
	  of these lists out from underneath us
 did we wrap? 
 don't bother with older transactions 
  for o_sync and fsync heavy applications, they tend to use
  all the journa list slots with tiny transactions.  These
  trigger lots and lots of calls to update the header block, which
  adds seeks and slows things down.
  This function tries to clear out a large chunk of the journal lists
  at once, which makes everything faster since only the newest journal
  list updates the header block
 in data logging mode, try harder to flush a lot of blocks 
 flush for 256 transactions or limit blocks, whichever comes first 
	
	  try to find a group of blocks we can flush across all the
	  transactions, but only bother if we've actually spanned
	  across multiple lists
  removes any nodes in table with name block and dev as bh.
  only touchs the hnext and hprev pointers.
			
			  anybody who clears the cur->bh will also
			  dec the nonzerolen
 must be after free_list_bitmaps 
	
	  j_header_bh is on the journal dev, make sure
	  not to release the journal dev until we brelse j_header_bh
  call on unmount.  Only set error to 1 if you haven't made your way out
  of read_super() yet.  Any other caller must keep error at 0.
	
	  we only want to flush out transactions if we were
	  called with error == 0
 end the current trans 
		
		  make sure something gets logged to force
		  our way into the flush code
 this also catches errors during the do_journal_end above 
	
	  We must release the write lock here because
	  the workqueue job (flush_async_commit) needs this lock
	
	  Cancel flushing of old commits. Note that neither of these works
	  will be requeued because superblock is being shutdown and doesn't
	  have SB_ACTIVE set.
 wait for all commits to finish 
  call on unmount.  flush all journal trans, release all alloc'd ram 
 only call from an error condition inside reiserfs_read_super!  
  compares description block with commit block.
  returns 1 if they differ, 0 if they are the same
  returns 0 if it did not find a description block
  returns -1 if it found a corrupt commit block
  returns 1 if both desc and commit were valid
  NOTE: only called during fs mount
		
		  ok, we have a journal description block,
		  let's see if the transaction was valid
  given the start, and values for the oldest acceptable transactions,
  this either reads in a replays a transaction, or returns because the
  transaction is invalid, or too old.
  NOTE: only called during fs mount
	
	  now we know we've got a good transaction, and it was
	  inside the valid time ranges
 get all the buffer heads 
 make sure we don't try to replay onto log or reserved area 
 read in the log blocks, memcpy to the corresponding real block 
 flush out the real blocks 
	
	  init starting values for the first transaction, in case
	  this is the last transaction to be replayed.
 check for trans_id overflow 
  This function reads blocks starting from block and to max_block of bufsize
  size (but no more than BUFNR blocks at a time). This proved to improve
  mounting speed on self-rebuilding raid5 arrays at least.
  Right now it is only used from journal code. But later we might use it
  from other places.
  Note: Do not use journal_getblksb_getblk functions here!
  read and replay the log
  on a clean unmount, the journal header's next unflushed pointer will be
  to an invalid transaction.  This tests that before finding all the
  transactions in the log, which makes normal mount times fast.
  After a crash, this starts with the next unflushed transaction, and
  replays until it finds one too old, or invalid.
  On exit, it sets things up so the first transaction will work correctly.
  NOTE: only called during fs mount
	
	  step 1, read in the journal header block.  Check the transaction
	  it says is the first unflushed, and if that transaction is not
	  valid, replay is done
		
		  now, we try to read the first unflushed offset.  If it
		  is not valid, there is nothing more we can do, and it
		  makes no sense to read through the whole log.
	
	  ok, there are transactions that need to be replayed.  start
	  with the first log block, find all the valid transactions, and
	  pick out the oldest.
		
		  Note that it is required for blocksize of primary fs
		  device and journal device to be the same
 init all oldest_ values 
 one we just read was older 
	
	  j_start does not get set correctly if we don't replay any
	  transactions.  if we had a valid journal_header, set j_start
	  to the first unflushed transaction value, copy the trans_id
	  from the header
 check for trans_id overflow 
 needed to satisfy the locking in _update_journal_header_block 
		
		  replay failed, caller must call free_journal_ram and abort
		  the mount
 there is no "jdev" option and journal is on separate device 
  When creatingtuning a file system user can assign some
  journal params within boundaries which depend on the ratio
  blocksizestandard_blocksize.
  For blocks >= standard_blocksize transaction size should
  be not less then JOURNAL_TRANS_MIN_DEFAULT, and not more
  then JOURNAL_TRANS_MAX_DEFAULT.
  For blocks < standard_blocksize these boundaries should be
  decreased proportionally.
 Non-default journal params.  Do sanity check for them. 
		
		  Default journal params.
		  The file system was created by old version
		  of mkreiserfs, so some fields contain zeros,
		  and we need to advise proper values for them
 must be called once on fs mount.  calls journal_read for you 
 reserved for journal area support 
	
	  Sanity check to see is the standard journal fitting
	  within first bitmap (actual for small blocksizes)
	
	  Sanity check to see if journal first block is correct.
	  If journal first block is invalid it can cause
	  zeroing important superblock members.
 read journal header 
 make sure that journal matches to the super block 
	
	  get_list_bitmap() may call flush_commit_list() which
	  requires the lock. Calling flush_commit_list() shouldn't happen
	  this early but I like to be paranoid.
  test for a polite end of the current transaction.  Used by file_write,
  and should be used by delete to make sure they don't write more than
  can fit inside a single transaction
 cannot restart while nested 
 this must be called inside a transaction 
 this must be called without a transaction started 
 this must be called without a transaction started 
	
	  we don't want to use wait_event here because
	  we only want to wait once.
  join == true if you must join an existing transaction.
  join == false if you can deal with waiting for others to finish
  this will block until the transaction is joinable.  send the number of
  blocks you expect to use in nblocks.
 set here for journal_join 
	
	  if there is no room in the journal OR
	  if this transaction is too old, and we weren't called joinable,
	  wait for it to finish before beginning we don't sleep if there
	  aren't other writers
 allow others to finish this transaction 
		
		  don't mess with joining the transaction if all we
		  have to do is wait for someone else to do a commit
 someone might have ended the transaction while we joined 
 we are the first writer, set trans_id 
	
	  Re-set th->t_super, so we can properly keep track of how many
	  persistent transactions there are. We need to do this so if this
	  call is part of a failed restart_transaction, we can free it later
	
	  if we're nesting into an existing transaction.  It will be
	  persistent on its own
	
	  this keeps do_journal_end from NULLing out the
	  current->journal_info pointer
	
	  this keeps do_journal_end from NULLing out the
	  current->journal_info pointer
 we are nesting into the current transaction 
			
			  we've ended up with a handle from a different
			  filesystem.  save it and restore on journal_end.
			  This should never really happen...
	
	  I guess this boils down to being the reciprocal of clm-2100 above.
	  If do_journal_begin_r fails, we need to put it back, since
  puts bh into the current transaction.  If it was already there, reorders
  removes the old pointers from the hash, and puts new ones in (to make
  sure replay happen in the right order).
  if it was dirty, cleans and files onto the clean list.  I can't let it
  be dirty again until the transaction is committed.
  if j_len, is bigger than j_len_alloc, it pushes j_len_alloc to 10 + j_len.
 already in this transaction, we are done 
	
	  this must be turned into a panic instead of a warning.  We can't
	  allow a dirty or journal_dirty or locked buffer to be logged, as
	  some changes could get to disk too early.  NOT GOOD.
	
	  this error means I've screwed up, and we've overflowed
	  the transaction.  Nothing can be done here, except make the
	  FS readonly or panic.
 now put this guy on the end 
		
		  we aren't allowed to close a nested transaction on a
		  different filesystem from the one in the task struct
  removes from the current transaction, relsing and descrementing any counters.
  also files the removed buffer directly onto the clean list
  called by journal_mark_freed when a block has been deleted
  returns 1 if it cleaned and relsed the buffer. 0 otherwise
 don't log this one 
  for any cnode in a journal list, it can only be dirtied of all the
  transactions that include it are committed to disk.
  this checks through each transaction, and returns 1 if you are allowed
  to dirty, and 0 if you aren't
  it is called by dirty_journal_list, which is called after
  flush_commit_list has gotten all the log blocks for a given
  transaction on disk
	
	  first test hprev.  These are all newer than cn, so any node here
	  with the same block number and dev means this node can't be sent
	  to disk right now.
	
	  then test hnext.  These are all older than cn.  As long as they
	  are committed to the log, it is safe to write cn to disk
  syncs the commit blocks, but does not force the real buffers to disk
  will wait until the current transaction is donecommitted before returning
 you can sync while nested, very, very bad 
 writeback the pending async commits to disk 
 last entry is the youngest, commit it and you get everything 
  flushes any old transactions to disk
  ends the current transaction if it is too old
	
	  safety check so we don't flush while we are replaying the log during
	  mount
	
	  check the current transaction.  If there are no writers, and it is
	  too old, finish it, and force the commit blocks to disk
			
			  we're only being called from kreiserfsd, it makes
			  no sense to do an async commit so that kreiserfsd
			  can do it later
  returns 0 if do_journal_end should return right away, returns 1 if
  do_journal_end should finish the commit
  if the current transaction is too old, but still has writers, this will
  wait on j_join_wait until all the writers are done.  By the time it
  wakes up, the transaction it was called has already ended, so it just
  flushes the commit list and returns 0.
  Won't batch when flush or commit_now is set.  Also won't batch when
  others are waiting on j_join_wait.
  Note, we can't allow the journal_end to proceed while there are still
  writers in the log.
 <= 0 is allowed.  unmounting might not call begin 
	
	  BUG, deal with case where j_len is 0, but people previously
	  freed blocks need to be released will be dealt with by next
	  transaction that actually writes something, but should be taken
	  care of in this trans
	
	  if wcount > 0, and we are called to with flush or commit_now,
	  we wait on j_join_wait.  We will wake up when the last writer has
	  finished the transaction, and started it on its way to the disk.
	  Then, we flush the commit or journal list, and just return 0
	  because the rest of journal end was already done for this
	  transaction.
			
			  sleep while the current transaction is
			  still j_jlocked
 deal with old transactions where we are the last writers 
 don't batch when someone is waiting on j_join_wait 
 don't batch when syncing the commit or flushing the whole trans 
  Does all the work that makes deleting blocks safe.
  when deleting a block mark BH_JNew, just remove it from the current
  transaction, clean it's buffer_head and move on.
  otherwise:
  set a bit for the block in the journal bitmap.  That will prevent it from
  being allocated for unformatted nodes before this transaction has finished.
  mark any cnodes for this block as BLOCK_FREED, and clear their bh pointers.
  That will prevent any old transactions with this block from trying to flush
  to the real location.  Since we aren't removing the cnode from the
  journal_list_hash, the block can't be reallocated yet.
  Then remove it from the current transaction, decrementing any counters and
  filing it on the clean list.
 if it is journal new, we just remove it from this transaction 
		
		  set the bit for this block in the journal bitmap
		  for this transaction
 Note, the entire while loop is not allowed to schedule.  
		
		  find all older transactions with this block,
		  make sure they don't try to write it out
					
					  remove_from_transaction will brelse
					  the buffer if it was in the current
					  trans
					
					  since we are clearing the bh,
					  we MUST dec nonzerolen
 get_hash grabs the buffer 
  returns -1 on error, 0 if no commitsbarriers were done and 1
  if a transaction was actually committed and the barrier was done
	
	  is it from the current transaction,
	  or from an unknown transaction?
		
		  try to let other writers come in and
		  grow this transaction
 someone might have ended this transaction while we joined 
		
		  this gets tricky, we have to make sure the journal list in
		  the inode still exists.  We know the list is still around
		  if we've got a larger transaction id than the oldest list
			
			  we only set ret to 1 when we know for sure
			  the barrier hasn't been started yet on the commit
			  block.
 otherwise the list is gone, and long since committed 
	
	  for the whole inode, assume unset id means it was
	  changed in the current transaction.  More conservative
 jl will be updated in __commit_trans_jl 
  before we can change a metadata block, we have to make sure it won't
  be written to disk while we are altering it.  So, we must:
  clean it
  wait on it.
  long and ugly.  If flush, will not return until all commit
  blocks and all real buffers in the trans are on disk.
  If no_async, won't return until all commit blocks are on disk.
  keep reading, there are comments as you go along
  If the journal is aborted, we just clean up. Things like flushing
  journal lists, etc just won't happen.
 commit bh 
 desc bh 
 start index of current log write 
	
	  protect flush_older_commits from doing mistakes if the
	  transaction ID counter gets overflowed.
	
	  check_journal_end locks the journal, and unlocks if it does
	  not return 1 it tells us if we should continue with the
	  journal_end, or just return
 check_journal_end might set these, check again 
	
	  j must wait means we have to flush the log blocks, and the
	  real blocks for this transaction
	
	  quota ops might need to nest, setup the journal_info pointer
	  for them and raise the refcount so that it is > 0.
 it should not involve new blocks into the transaction 
 setup description block 
	
	  setup commit block.  Don't write (keep it clean too) this one
	  until after everyone else is written
 init this journal list 
	
	  we lock the commit before doing anything because
	  we want to make sure nobody tries to run flush_commit_list until
	  the new transaction is fully setup, and we've already flushed the
	  ordered bh list
 save the transaction id in case we need to commit it later 
	
	  The ENTIRE FOR LOOP MUST not cause schedule to occur.
	  for each real block, add it to the journal list hash,
	  copy into real block index array in the commit or desc block
			
			  make sure the block we are trying to log
			  is not a block of journal or reserved area
	
	  special check in case all buffers in the journal
	  were marked for not logging
	
	  we're about to dirty all the log blocks, mark the description block
	  dirty now too.  Don't mark the commit block dirty until all the
	  others are on disk
	
	  first data block is j_start + 1, so add one to
	  cur_write_start wherever you use it
 start at one so we don't get the desc again 
 copy all the real blocks into log area.  dirty log blocks 
			
			  JDirty cleared sometime during transaction.
			  don't log this one
	
	  we are done with both the c_bh and d_bh, but
	  c_bh must be written after all other commit blocks,
	  so we dirtyrelse c_bh in flush_commit_list, with commit_left <= 1.
 now it is safe to insert this transaction on the main list 
 reset journal values for the next transaction 
 check for trans_id overflow 
	
	  make sure reiserfs_add_jh sees the new current_jl before we
	  write out the tails
	
	  tail conversion targets have to hit the disk before we end the
	  transaction.  Otherwise a later transaction might repack the tail
	  before this transaction commits, leaving the data block unflushed
	  and clean, if we crash before the later transaction commits, the
	  data block is lost.
	
	  honor the flush wishes from the caller, simple commits can
	  be done outside the journal lock, they are done below
	 
	  if we don't flush the commit list right now, we put it into
	  the work queue so the people waiting on the async progress work
	  queue don't wait for this proc to flush journal lists and such.
		
		  Avoid queueing work when sb is being shut down. Transaction
		  will be flushed on journal shutdown.
	
	  if the next transaction has any chance of wrapping, flush
	  transactions that might get overwritten.  If any journal lists
	  are very old flush them as well.
				
				  if we don't cross into the next
				  transaction and we don't wrap, there is
				  no way we can overlap any later transactions
				  break now
				
				 we don't overlap anything from out start
				 to the end of the log, and our wrapped
				 portion doesn't overlap anything at
				 the start of the log.  We can break
 wake up any body waiting to join. 
	
	  Re-set th->t_super, so we can properly keep track of how many
	  persistent transactions there are. We need to do this so if this
	  call is part of a failed restart_transaction, we can free it later
 Send the file system read only and refuse new transactions 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
	
	  We need blocks for transaction + (user+group) quota
	  update (possibly delete)
	
	  The = 0 happens when we abort creating a new inode
	  for some reason like lack of space..
	  also handles bad_inode case
		
		  Do quota update inside a transaction for journaled quotas.
		  We must do that after delete_object so that quota updates
		  go into the same transaction as stat data deletion
		
		  check return value from reiserfs_delete_object after
		  ending the transaction
		
		  all items of file are deleted, so we can remove
		  "save" link
		  we can't do anything about an error here
 not truncate );
 no object items are in the tree 
 note this must go after the journal_end to prevent deadlock 
  take base of inode_key (it comes from inode always) (dirid, objectid)
  and version from an inode, set offset and type of key
 when key is 0, do not set version and short key 
or ih_free_space  )
    set_ih_free_space (ih, 0); 
	
	  for directory items it is entry count, for directs and stat
	  datas - 0xffff, for indirects - 0
  FIXME: we might cache recently accessed indirect item
  Ugh.  Not too eager for that....
  I cut the code until such time as I see a convincing argument (benchmark).
  I don't want a bloated inode struct..., and I don't like code complexity....
  cutting the code is fine, since it really isn't in use yet and is easy
  to add back in.  But, Vladimir has a really good idea here.  Think
  about what happens for reading a file.  For each page,
  The VFS layer calls reiserfs_readpage, who searches the tree to find
  an indirect item.  This indirect item has X number of pointers, where
  X is a big number if we've done the block allocation right.  But,
  we only use one or two of these pointers during each call to readpage,
  needlessly researching again later on.
  The size of the cache could be dynamic based on the size of the file.
  I'd also like to see us cache the location the stat data item, since
  we are needlessly researching for that frequently.
  --chris
  If this page has a file tail in it, and
  it was read in by get_block_create_0, the page data is valid,
  but tail is still sitting in a direct item, and we can't write to
  it.  So, look through this page, and check all the mapped buffers
  to make sure they have valid block numbers.  Any that don't need
  to be unmapped, so that __block_write_begin will correctly call
  reiserfs_get_block to convert the tail into an unformatted node
  reiserfs_get_block does not need to allocate a block only if it has been
  done already or non-hole position has been found in the indirect item
  files which were created in the earlier version can not be longer,
  than 2 gb
 it is new file. 
 old file, but 'block' is inside of 2gb 
 we cannot restart while nested 
  it is called by get_block when create == 0. Returns block number
  for 'block'-th logical block of file. When it hits direct item it
  returns 0 (being called from bmap) or read direct item into piece
  of page (bh_result)
  Please improve the englishclarity in the comment above, as it is
  hard to understand.
 prepare the key to look for the 'block'-th block of file 
		
		  We do not return -ENOENT if there is a hole but page is
		  uptodate, because it means that there is some MMAPED data
		  associated with it that is yet to be written to disk.
		
		  FIXME: here we could cache indirect item or part of it in
		  the inode to avoid search_by_key in case of subsequent
		  access to file
			
			  We do not return -ENOENT if there is a hole but
			  page is uptodate, because it means that there is
			  some MMAPED data associated with it that is
			  yet to be written to disk.
 requested data are in direct item(s) 
		
		  we are called by bmap. FIXME: we can not map block of file
		  when it is stored in direct item(s)
	
	  if we've got a direct item, and the buffer or page was uptodate,
	  we don't want to pull data off disk again.  skip to the
	  end, where we map the buffer and return
		
		  grab_tail_page can trigger calls to reiserfs_get_block on
		  up to date pages without any buffers.  If the page is up
		  to date, we don't want read old data off disk.  Set the up
		  to date bit on the buffer instead and jump to the end
 read file tail into part of page 
	
	  we only want to kmap if we are reading the tail into the page.
	  this is not the common case, so we don't kmap until we are
	  sure we need to.  But, this means the item might move if
	  kmap schedules
		
		  make sure we don't read more bytes than actually exist in
		  the file.  This can happen in odd cases where i_size isn't
		  correct, and when direct item padding results in a few
		  extra bytes at the end of the direct item
		
		  we done, if read direct item is not the last item of
		  node FIXME: we could try to check right delimiting key
		  to see whether direct item continues in the right
		  neighbor or rely on i_size
 update key to look for the next piece 
 io error most likely 
	
	  this buffer has valid data, but isn't valid for io.  mapping it to
	  block #0 tells the rest of reiserfs it just has a tail in it
  this is called to create file map. So, _get_block_create_0 will not
  read direct item
 do not read the direct item 
  special version of get_block that is only used by grab_tail_page right
  now.  It is sent to __block_write_begin, and when you try to get a
  block past the end of the file (or a block from a hole) it returns
  -ENOENT instead of a valid buffer.  __block_write_begin expects to
  be able to do io on the buffers returned, unless an error value
  is also returned.
  So, this allows __block_write_begin to be used for reading a single block
  in a page.  Where it does not produce a valid page for holes, or past the
  end of the file.  This turns out to be exactly what we need for reading
  tails for conversion.
  The point of the wrapper is forcing a certain value for create, even
  though the VFS layer is calling this function with create==1.  If you
  don't want to send create == GET_BLOCK_NO_HOLE to reiserfs_get_block,
  don't use this function.
  This is special helper for reiserfs_get_block in case we are executing
  direct_IO request.
	
	  We set the b_size before reiserfs_get_block call since it is
	  referenced in convert_tail_for_hole() that may be called from
	  reiserfs_get_block()
 don't allow direct io onto tail pages 
		
		  make sure future calls to the direct io funcs for this
		  offset in the file fail by unmapping the buffer
	
	  Possible unpacked tail. Flush the data before pages have
	  disappeared
  helper function for when reiserfs_get_block is called for a hole
  but the file tail is still in a direct item
  bh_result is the buffer head for the hole
  tail_offset is the offset of the start of the tail in the file
  This calls prepare_write, which will start a new transaction
  you should not be in a transaction, or have any paths held when you
  call this.
 always try to read until the end of the block 
	
	  hole_page can be zero in case of direct_io, we are sure
	  that we cannot get here if we write with O_DIRECT into tail page
	
	  we don't have to make sure the conversion did not happen while
	  we were locking the page because anyone that could convert
	  must first take i_mutex.
	 
	  We must fix the tail page for writing because it might have buffers
	  that are mapped, but have a block number of 0.  This indicates tail
	  data that has been read directly into the page, and
	  __block_write_begin won't trigger a get_block in this case.
 tail conversion might change the data in the page 
 b_blocknr_t is (unsigned) 32 bit int
	
	  space reserved in transaction batch:
	  . 3 balancings in direct->indirect conversion
	  . 1 block involved into reiserfs_update_sd()
	  XXX in practically impossible worst case direct2indirect()
	  can incur (much) more than 3 balancings.
	  quota update for user, group
	
	  if !create, we aren't changing the FS, so we don't need to
	  log anything, so we don't need to start a transaction
 find number of block-th logical block of the file 
	
	  if we're already in a transaction, make sure to close
	  any new transactions we start in this func
	
	  If file is of such a size, that it might have a tail and
	  tails are enabled  we should mark it as possibly needing
	  tail packing on close
 set the key of the first byte in the 'block'-th block of file 
key length  );
 we have to allocate block for the unformatted node 
		
		  restart the transaction to give the journal a chance to free
		  some blocks.  releases the path, so we have to go back to
		  research if we succeed on the second try
		
		  'block'-th block is in the file already (there is
		  corresponding cell in some indirect item). But it may be
		  zero unformatted node pointer (hole)
 use allocated block to plug the hole 
		
		  the item was found, so new blocks were not added to the file
		  there is no need to make sure the inode is updated with this
		  transaction
	
	  desired position is not found or is in the direct item. We have
	  to append file with holes up to 'block'-th block converting
	  direct items to indirect one if necessary
 indirect item has to be inserted 
 free_space  );
			
			  we are going to add 'block'-th block to the file.
			  Use allocated block for that
 ;) 
				
				  retval == -ENOSPC, -EDQUOT or -EIO
				  or -EEXIST
 direct item has to be converted 
			
			  direct item we just found fits into block we have
			  to map. Convert it into unformatted node: use
			  bh_result for the conversion
				
				  we have to pad file tail stored in direct
				  item(s) up to block size and convert it
				  to unformatted node. FIXME: this should
				  also get into page cache
				
				  ugly, but we can only end the transaction if
				  we aren't nested
						
						  the bitmap, the super,
						  and the stat data == 3
			
			  it is important the set_buffer_uptodate is done
			  after the direct2indirect.  The buffer might
			  contain valid data newer than the data on disk
			  (read by readpage, changed, and then sent here by
			  writepage).  direct2indirect needs to know if unbh
			  was already up to date, so it can decide if the
			  data in unbh needs to be replaced with data from
			  the disk
			
			  unbh->b_page == NULL in case of DIRECT_IO request,
			  this means buffer will disappear shortly, so it
			  should not be added to
				
				  we've converted the tail, so we must
				  flush unbh before the transaction commits
				
				  mark it dirty now to prevent commit_write
				  from adding this buffer to the inode's
				  dirty buffer list
				
				  AKPM: changed __mark_buffer_dirty to
				  mark_buffer_dirty().  It's still atomic,
				  but it sets the page dirty too, which makes
				  it eligible for writeback at any time by the
				  VM (which was also the case with
				  __mark_buffer_dirty())
			
			  append indirect item with holes if needed, when
			  appending pointer to 'block'-th block use block,
			  which is already allocated
			
			  We use this in case we need to allocate
			  only one block which is a fastpath
			
			  indirect item has to be appended,
			  set up key of that position
			  (key type is unimportant)
				
				  we are going to add target block to
				  the file. Use allocated block for that
 paste hole to the indirect item 
				
				  If kcalloc failed, max_to_insert becomes
				  zero and it means we only have space for
				  one block
				
				  We need to mark new file size in case
				  this function will be interruptedaborted
				  later on. And we may do this only for
				  holes.
		
		  this loop could log more blocks than we had originally
		  asked for.  So, we have to allow the transaction to end
		  if it is too big or too full.  Update the inode so things
		  are consistent if we crash before the function returns
		  release the path so that anybody waiting on the path before
		  ending their transaction will be able to continue.
		
		  inserting indirect pointers for a hole can take a
		  long time.  reschedule if needed and also release the write
		  lock for others.
  Compute real number of used bytes by file
  Following three functions can go away when we'll have enough space in
  stat item
	
	  End of file is also in full block with indirect reference, so round
	  up to the next block.
	 
	  there is just no way to know if the tail is actually packed
	  on the file, so we have to assume it isn't.  When we pack the
	  tail, we add 4 bytes to pretend there really is an unformatted
	  node pointer
 Compute number of blocks used by file in ReiserFS counting 
 keeps fsck and non-quota versions of reiserfs happy 
	
	  files from before the quota patch might i_blocks such that
	  bytes < real_space.  Deal with that here to prevent it from
	  going negative.
  BAD: new directories have stat data of new type and all other items
  of old type. Version stored in the inode says about body items, so
  in update_stat_data we can not rely on inode, but have to check
  item version directly
 called by read_locked_inode 
		
		  there was a bug in <=3.5.23 when i_blocks could take
		  negative values. Starting from 3.5.17 this value could
		  even be stored in stat data. For such files we set
		  i_blocks based on file size. Just 2 notes: this can be
		  wrong for sparse files. On-disk value will be only
		  updated if file's inode will ever change
		
		  an early bug in the quota code can give us an odd
		  number for the block count.  This is incorrect, fix it here.
		
		  nopack is initially zero for v1 objects. For v2 objects,
		  nopack is initialised from sd_attrs
		
		  new stat data found, but object may have old items
		  (directories and symlinks)
		
		  read persistent inode attributes from sd and initialise
		  generic inode flags from them
 update new stat data with inode fields 
 used to copy inode's fields to old stat data 
 Sigh. i_first_direct_byte is back 
  NOTE, you must prepare the buffer head before sending it here,
  and then log it after the call
 path points to old stat data 
 key type is unimportant 
 look for the object's stat data 
reiserfs_warning (inode->i_sb, "vs-13050: reiserfs_update_sd: i_nlink == 0, stat data not found"); 
		
		  sigh, prepare_for_journal might schedule.  When it
		  schedules the FS might change.  We have to detect that,
		  and loop back to the search if the stat data item has moved
 Stat_data item has been moved after scheduling. 
  reiserfs_read_locked_inode is called to read the inode off disk, and it
  does a make_bad_inode when things go wrong.  But, we need to make sure
  and clear the key in the private portion of the inode, otherwise a
  corresponding iput might try to delete whatever object the inode last
  represented.
  initially this function was derived from minix or ext2's analog and
  evolved as the prototype did
  looks for stat data in the tree, and fills up the fields of in-core
  inode stat data fields
	
	  set version 1, version 2 could be used too, because stat data
	  key is the same in both versions
 look for the object's stat data 
 a stale NFS handle can trigger this without it being an error 
	
	  It is possible that knfsd is trying to access inode of a file
	  that is being removed from the disk by some other thread. As we
	  update sd on unlink all that is required is to check for nlink
	  here. This bug was first found by Sizif when debugging
	  SquidNGButterfly, forgotten, and found again after Philippe
	  Gramoulle <philippe.gramoulle@mmania.com> reproduced it.
	  More logical fix would require changes in fsinode.c:iput() to
	  remove inode from hash-table _after_ fs cleaned disk stuff up and
	  in iget() to return NULL if I_FREEING inode is found in
	  hash-table.
	
	  Currently there is one place where it's ok to meet inode with
	  nlink==0: processing of open-unlinked and half-truncated files
	  during mount (fsreiserfssuper.c:finish_unfinished()).
 init inode should be relsing 
	
	  Stat data v1 doesn't support ACLs.
  reiserfs_find_actor() - "find actor" reiserfs supplies to iget5_locked().
  @inode:    inode from hash table to check
  @opaque:   "cookie" passed to iget5_locked(). This is &reiserfs_iget_args.
  This function is called by iget5_locked() to distinguish reiserfs inodes
  having the same inode numbers. Such inodes can only exist due to some
  error condition. One of them should be bad. Inodes with identical
  inode numbers (objectids) are distinguished by parent directory ids.
 args is already in CPU order 
 either due to io error or a stale NFS handle 
	
	  fhtype happens to reflect the number of u32s encoded.
	  due to a bug in earlier code, fhtype might indicate there
	  are more u32s then actually fitted.
	  so if fhtype seems to be more than len, reduce fhtype.
	  Valid types are:
	    2 - objectid + dir_id - legacy support
	    3 - objectid + dir_id + generation
	    4 - objectid + dir_id + objectid and dirid of parent - legacy
	    5 - objectid + dir_id + generation + objectid and dirid of parent
	    6 - as above plus generation of directory
	  6 does not fit in NFSv2 handles
  looks for stat data, then copies fields to it, marks the buffer
  containing stat data as dirty
  reiserfs inodes are never really dirty, since the dirty inode call
  always logs them.  This call allows the VFS inode marking routines
  to properly mark inodes for datasync and such, but only actually
  does something when called for a synchronous update.
	
	  memory pressure can sometimes initiate write_inode calls with
	  sync == 1,
	  these cases are just when the system needs ram, not when the
	  inode needs to reach disk for safety, and they can safely be
	  ignored because the altered inode has already been logged.
  stat data of new object is inserted already, this inserts the item
  containing "." and ".." entries
key length  );
	
	  compose item head for new item. Directories consist of items of
	  old type (ITEM_VERSION_1). Do not set key (second arg is 0), it
	  is done by reiserfs_new_inode
 look for place in the tree for new item 
 insert item, that is empty directory item 
  stat data of object has been inserted, this inserts the item
  containing the body of symlink
key length  );
free_space  );
 look for place in the tree for new item 
 insert item, that is body of symlink 
  inserts the stat data into the tree, and then calls
  reiserfs_new_directory (to insert ".", ".." item if new object is
  directory) or reiserfs_new_symlink (to insert symlink body if new
  object is symlink) or nothing (if new object is regular file)
  NOTE! uid and gid must already be set in the inode.  If we return
  non-zero due to an error, we have to drop the quota previously allocated
  for the fresh inode.  This can only be done outside a transaction, so
  if we return non-zero, we also end the transaction.
  @th: active transaction handle
  @dir: parent directory for new inode
  @mode: mode of new inode
  @symname: symlink contents if inode is symlink
  @isize: 0 for regular file, EMPTY_DIR_SIZE for dirs, strlen(symname) for
          symlinks
  @inode: inode to be filled
  @security: optional security context to associate with this inode
		        0 for regular, EMTRY_DIR_SIZE for dirs,
 item head of new item 
		
		  not a perfect generation count, as object ids can be reused,
		  but this is as good as reiserfs can do right now.
		  note that the private part of inode isn't filled in yet,
		  we have to use the directory.
 fill stat data 
 uid and gid must already be set by the caller for quota init 
NO_BYTES_IN_DIRECT_ITEM  ;
 key to search for correct place for new stat data 
key length  );
 find proper place for inserting of stat data 
 i_uid or i_gid is too big to be stored in stat data v3.5 
	
	  store in in-core inode the key of stat data and version all
	  object items will have (directory items will have old offset
	  format, other new objects will consist of new items)
 insert the stat data into the tree 
 insert item with "." and ".." 
 insert body of symlink 
	
	  Mark it private if we're creating the privroot
	  or something under it.
 Invalidate the object, nothing was inserted yet 
 Quota change must be inside a transaction for journaling 
	
	  Drop can be outside and it needs more credits so it's better
	  to have it outside
 so the caller can't use this handle later 
  finds the tail page in the page cache,
  reads the last block in.
  On success, page_result is set to a locked, pinned page, and bh_result
  is set to an up to date buffer for the last block in the file.  returns 0.
  tail conversion is not done, so bh_result might not be valid for writing
  check buffer_mapped(bh_result) and bh_result->b_blocknr != 0 before
  trying to write the block.
  on failure, nonzero is returned, page_result and bh_result are untouched.
	
	  we want the page with the last byte in the file,
	  not the page that will hold the next byte for appending
	
	  we know that we are only called with inode->i_size > 0.
	  we also know that a file tail can never be as big as a block
	  If i_size % blocksize == 0, our file is currently block aligned
	  and it won't need converting or zeroing after a truncate.
 start within the page of the last block in the file 
		
		  note, this should never happen, prepare_write should be
		  taking care of this for us.  If the buffer isn't up to
		  date, I've screwed up the code to find the buffer, or the
		  code to call prepare_write
  vfs version of truncate file.  Must NOT be called with
  a transaction already started.
  some code taken from block_truncate_page
 we want the offset for the first byte after the end of the file 
			
			  -ENOENT means we truncated past the end of the
			  file, and get_block_create_0 could not find a
			  block to read in, which is ok.
	
	  so, if page != NULL, we have a buffer head for the offset at
	  the end of the file. if the bh is mapped, and bh->b_blocknr != 0,
	  then we have an unformatted node.  Otherwise, we have a direct item,
	  and no zeroing is required on disk.  We zero after the truncate,
	  because the truncate might pack the item anyway
	  (it will unmap bh if it packs).
	 
	  it is enough to reserve space in transaction for 2 balancings:
	  one for "save" link adding and another for the first
	  cut_from_item. 1 is for update_sd
		
		  we are doing real truncate: if the system crashes
		  before the last transaction of truncating gets committed
		  - on reboot the file either appears truncated properly
		  or not truncated at all
 check reiserfs_do_truncate after ending the transaction 
 truncate );
 if we are not on a block boundary 
	
	  catch places below that try to log something without
	  starting a trans
 we've found an unformatted node 
 crap, we are writing to a hole 
 vs-3050 is gone, no need to drop the path 
 are there still bytes left? 
 this is where we fill in holes in the file. 
 get_block failed to find a mapped unformatted node. 
		
		  we've copied data from the page into the direct item, so the
		  buffer in the page is now clean, mark it to reflect that.
  mason@suse.com: updated in 2.5.54 to follow the same general io
  startrecovery path as __block_write_full_page, along with special
  code to handle reiserfs tails.
 no logging allowed when nonblocking or from PF_MEMALLOC 
	
	  The page dirty bit is cleared before writepage is called, which
	  means we have to tell create_empty_buffers to make dirty buffers
	  The page really should be up to date at this point, so tossing
	  in the BH_Uptodate is just a sanity check.
	
	  last page in the file, zero out any contents past the
	  last byte in the file
 no file contents in this page 
 first map all the buffers, logging any direct items we find 
			
			  This can happen when the block size is less than
			  the page size.  The corresponding bytes in the page
			  were zero filled above
			
			  not mapped yet, or it points to a direct item, search
			  the btree for the mapping info, and log any direct
			  items found
	
	  we start the transaction after map_block_for_writepage,
	  because it can create holes in the file (an unbounded operation).
	  starting it here, we can make a reliable estimate for how many
	  blocks we're going to log
 now go through and lock any dirty buffers on the page 
		
		  from this point on, we know the buffer is mapped to a
		  real block and not a direct item
	
	  since any buffer might be the only dirty buffer on the page,
	  the first submit_bh can bring the page out of writeback.
	  be careful with the buffers.
		
		  if this page only had a direct item, it is very possible for
		  no io to be required without there being an error.  Or,
		  someone else could have locked them and sent them down the
		  pipe without locking the page
	
	  catches various errors, we need to make sure any valid dirty blocks
	  get to the media.  The page is currently locked and not marked for
	  writeback
			
			  clear any dirty bits that might have come from
			  getting attached to a dirty page
		
		  this gets a little ugly.  If reiserfs_get_block returned an
		  error and left a transacstion running, we've got to close
		  it, and we've got to free handle if it was a persistent
		  transaction.
		 
		  But, if we had nested into an existing transaction, we need
		  to just drop the ref count on the handle.
		 
		  If old_ref == 0, the transaction is from reiserfs_get_block,
		  and it was a persistent trans.  Otherwise, it was nested
		  above.
 Truncate allocated blocks 
		
		  this gets a little ugly.  If reiserfs_get_block returned an
		  error and left a transacstion running, we've got to close
		  it, and we've got to free handle if it was a persistent
		  transaction.
		 
		  But, if we had nested into an existing transaction, we need
		  to just drop the ref count on the handle.
		 
		  If old_ref == 0, the transaction is from reiserfs_get_block,
		  and it was a persistent trans.  Otherwise, it was nested
		  above.
	
	  generic_commit_write does this for us, but does not update the
	  transaction tracking stuff when the size changes.  So, we have
	  to do the i_size updates here.
		
		  If the file have grown beyond the border where it
		  can have a tail, unmark it as needing a tail
		  packing
		
		  this will just nest into our transaction.  It's important
		  to use mark_inode_dirty so the inode gets pushed around on
		  the dirty lists, and so that O_SYNC works as expected
	
	  generic_commit_write does this for us, but does not update the
	  transaction tracking stuff when the size changes.  So, we have
	  to do the i_size updates here.
		
		  If the file have grown beyond the border where it
		  can have a tail, unmark it as needing a tail
		  packing
		
		  this will just nest into our transaction.  It's important
		  to use mark_inode_dirty so the inode gets pushed around
		  on the dirty lists, and so that O_SYNC works as expected
  decide if this buffer needs to stay around for data logging or ordered
  write purposes
	
	  the page is locked, and the only places that log a data buffer
	  also lock the page.
		
		  very conservative, leave the buffer pinned if
		  anyone might need it.
		
		  why is this safe?
		  reiserfs_setattr updates i_size in the on disk
		  stat data before allowing vmtruncate to be called.
		 
		  If buffer was put onto the ordered list for this
		  transaction, we know for sure either this transaction
		  or an older one already has updated i_size on disk,
		  and this ordered data won't be referenced in the file
		  if we crash.
		 
		  if the buffer was put onto the ordered list for an older
		  transaction, we need to leave it around
 clm -- taken from fsbuffer.c:block_invalidate_page 
		
		  is this block fully invalidated?
	
	  We release buffers only if the entire page is being invalidated.
	  The get_block cached value has been unconditionally invalidated,
	  so real IO is not possible anymore.
 maybe should BUG_ON(!ret); - neilb 
  Returns 1 if the page's buffers were dropped.  The page is locked.
  Takes j_dirty_buffers_lock to protect the b_assoc_buffers list_heads
  in the buffers at page_buffers(page).
  even in -o notail mode, we can't be sure an old mount without -o notail
  didn't create files with tails.
  We thank Mingming Cao for helping us understand in great detail what
  to do in this section of the code.
	
	  In case of error extending write may have instantiated a few
	  blocks outside i_size. Trim these off again.
 must be turned off for recursive notify_change calls 
		
		  version 2 items will be caught by the s_maxbytes check
		  done for us in vmtruncate
 fill in hole pointers in the expanding truncate case. 
 we're changing at most 2 bitmaps, inode + super 
			
			  file size is changed, ctime and mtime are
			  to be updated
 stat data of format v3.5 has 16 bit uid and gid 
		
		  (user+group)(old+new) structure - we count quota
		  info and , inode write (sb, inode)
		
		  Update corresponding info in inode so that everything
		  is in one transaction
			
			  Could race against reiserfs_file_release
			  if called from NFS, so take tailpack mutex.
 SPDX-License-Identifier: GPL-2.0
	
	  Pessimism: We can't assume that anything from the xattr root up
	  has been created.
  Convert from filesystem to in-memory representation.
  Convert from in-memory to filesystem representation.
  Inode operation get_posix_acl().
  inode->i_mutex: down
  BKL held [before 2.5.x]
		
		  This shouldn't actually happen as it should have
		  been caught above.. but just in case
  Inode operation set_posix_acl().
  inode->i_mutex: down
  BKL held [before 2.5.x]
	
	  Ensure that the inode gets dirtied if we're only using
	  the mode bits and an old ACL didn't exist. We don't need
	  to check if the inode is hashed here since we won't get
	  called by reiserfs_inherit_default_acl().
  dir->i_mutex: locked,
  inode is new and not released into the wild yet
 ACLs only get applied to files and directories 
	
	  ACLs can only be used on "new" objects, so if it's an old object
	  there is nothing to inherit from
	
	  Don't apply ACLs to objects in the .reiserfs_priv tree.. This
	  would be useless since permissions are ignored, and a pain because
	  it introduces locking cycles
 no ACL, apply umask 
 This is used to cache the default acl before a new object is created.
  The biggest reason for this is to get an idea of how many blocks will
  actually be required for the create operation if we must inherit an ACL.
  An ACL write can add up to 3 object creations and an additional file write
  so we'd prefer not to reserve that many blocks in the journal if we can.
  It also has the advantage of not loading the ACL with a transaction open,
  this may seem silly, but if the owner of the directory is doing the
  creation, the ACL may not be loaded since the permissions wouldn't require
  it.
  We return the number of blocks required for the transaction.
		 Other xattrs can be created during inode creation. We don't
		  want to claim too many blocks, so we check to see if we
		  need to create the tree to the xattrs, and then we
 We need to account for writes + bitmaps for two files 
  Called under i_mutex
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
 key of current position in the directory (key of directory entry) 
 avoid kmalloc if we can 
	
	  form key for search the next directory entry using
	  f_pos field of file structure
		
		  search the directory item, containing entry with
		  specified key
			
			  FIXME: we could just skip part of directory
			  which could not be read
 we must have found item, that is item of this directory, 
		
		  and entry must be not more than number of entries
		  in the item
		
		  go through all entries in the directory item beginning
		  from the entry, that has been found
 it is hidden entry 
					
					  There is corrupted data in entry,
					  We'd better stop here
 too big to send back to VFS 
 Ignore the .reiserfs_priv entry 
				
				  Note, that we copy name to user space via
				  temporary buffer (local_buf) because
				  filldir will block if user space buffer is
				  swapped out. At that time entry can move to
				  somewhere else
				
				  Since filldir might sleep, we can release
				  the write lock here for other waiters
 deh_offset(deh) may be invalid now. 
 for 
 end of directory has been reached 
		
		  item we went through is last item of node. Using right
		  delimiting key check is it directory end
			
			  set pos_key to key, that is the smallest and greater
			  that key of the last entry in the item
 end of directory has been reached 
 directory continues in the right neighboring block 
 while 
  compose directory item containing "." and ".." entries (entries are
  not aligned to 4 byte boundary)
 direntry header of "." 
 these two are from make_le_item_head, and are LE 
 Endian safe if 0 
 direntry header of ".." 
 key of ".." for the root directory 
 these two are from the inode, and are LE 
 Endian safe if 0 
 copy ".." and "." 
 compose directory item containing "." and ".." entries 
 direntry header of "." 
 these two are from make_le_item_head, and are LE 
 Endian safe if 0 
 direntry header of ".." 
 key of ".." for the root directory 
 these two are from the inode, and are LE 
 Endian safe if 0 
 copy ".." and "." 
 SPDX-License-Identifier: GPL-2.0
  Copyright 1999 Hans Reiser, see reiserfsREADME for licensing and copyright
  details
  access to tail : when one is going to read tail it must make sure, that is
  not running.  direct2indirect and indirect2direct can not run concurrently
  Converts direct items to an unformatted node. Panics if file has no
  tail. -ENOSPC if no disk space for conversion
  path points to first direct item of the file regardless of how many of
  them are there
 Key to search for the last byte of the converted item. 
	
	  new indirect item to be inserted or key
	  of unfm pointer to be pasted
 returned value for reiserfs_insert_item and clones 
 Handle on an unformatted node that will be inserted in the tree. 
	
	  and key to search for append or insert pointer to the new
	  unformatted node.
 Set the key to search for the place for new unfm pointer 
 FIXME: we could avoid this 
 Insert new indirect item. 
 delete at nearest future 
 Paste into last indirect item of an object. 
	
	  note: from here there are two keys which have matching first
	   three key components. They only differ by the fourth one.
 Set the key to search for the direct items of the file 
	
	  Move bytes from the direct items to the new unformatted node
	  and delete them.
		
		  end_key.k_offset is set so, that we will always have found
		  last item of the file
		
		  we only send the unbh pointer if the buffer is not
		  up to date.  this avoids overwriting good data from
		  writepage() with old data from the disk or buffer cache
		  Special case: unbh->b_page will be NULL if we are coming
		  through DIRECT_IO handler here.
 done: file does not have direct items anymore 
	
	  if we've copied bytes from disk into the page, we need to zero
	  out the unused part of the block (it was not up to date before)
 stolen from fsbuffer.c 
	
	  Remove the buffer from whatever list it belongs to. We are mostly
	  interested in removing it from per-sb j_dirty_buffers list, to avoid
	  BUG() on attempt to write not mapped buffer
  this first locks inode (neither reads nor sync are permitted),
  reads tail through page cache, insert direct item. When direct item
  inserted successfully inode is left locked. Return value is always
  what we expect from it (number of cut bytes). But when tail remains
  in the unformatted node, we set mode to SKIP_BALANCING and unlock
  inode
 path to the indirect item. 
		    const struct cpu_key item_key,	 Key to look for
							  unformatted node
 New file size. 
 position of first byte of the tail 
 store item head path points to. 
	
	  we are protected by i_mutex. The tail can not disapper, not
	  append can be done either
	  we are in truncate or packing tail in file_release
 this can schedule 
 re-search indirect item 
 Set direct item header to insert. 
ih_free_space  );
	
	  we want a pointer to the first byte of the tail in the page.
	  the page was locked and this part of the page was up to date when
	  indirect2direct was called, so we know the bytes are still valid
 Insert tail as new direct item in the tree 
		
		  No disk memory. So we can not convert last unformatted node
		  to the direct item.  In this case we used to adjust
		  indirect items's ih_free_space. Now ih_free_space is not
		  used, it would be ideal to write zeros to corresponding
		  unformatted node. For now i_size is considered as guard for
		  going out of file size
 make sure to get the i_blocks changes from reiserfs_insert_item 
	
	  note: we have now the same as in above direct2indirect
	  conversion: there are two keys which have matching first three
	  key components. They only differ by the fourth one.
	
	  We have inserted new direct item and must remove last
	  unformatted node.
 we store position of first direct item in the in-core inode 
 mark_file_with_tail (inode, pos1 + 1); 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  Now we have all buffers that must be used in balancing of the tree
  Further calculations can not cause schedule(), and thus the buffer
  tree will be stable until the balancing will be finished
  balance the tree according to the analysis made before,
  and using buffers obtained after all above.
  summary:
   if deleting something ( tb->insert_size[0] < 0 )
     return(balance_leaf_when_delete()); (flag d handled here)
   else
     if lnum is larger than 0 we put items into the left node
     if rnum is larger than 0 we put items into the right node
     if snum1 is larger than 0 we put items into the new node s1
     if snum2 is larger than 0 we put items into the new node s2
  Note that all num count new items being created.
 cut item in S[0] 
		
		  UFS unlink semantics are such that you can only
		  delete one directory entry at a time.
		 
		  when we cut a directory tb->insert_size[0] means
		  number of entries to be cut (always 1)
 L[0] must be joined with S[0] 
 R[0] must be also joined with S[0] 
				
				  all contents of all the
				  3 buffers will be in L[0]
 all contents of all the 3 buffers will be in R[0] 
 right_delimiting_key is correct in R[0] 
 all contents of L[0] and S[0] will be in L[0] 
	
	  a part of contents of S[0] will be in L[0] and
	  the rest part of S[0] will be in R[0]
  Balance leaf node in case of delete or cut: insert_size[0] < 0
  lnum, rnum can have values >= -1
 	-1 means that the neighbor must be joined with S
 	 0 means that nothing should be done with the neighbor
 	>0 means to shift entirely or partly the specified number of items
          to the neighbor
 Delete or truncate the item 
 M_CUT 
	
	  the rule is that no shifting occurs unless by shifting
	  a node can be freed
 L[0] takes part in balancing 
 all contents of R[0] and S[0] will be in R[0] 
 part of new item falls into L[0] 
 Calculate item length to insert to S[0] 
 Calculate and check item length to insert to L[0] 
 Insert new item into L[0] 
		
		  Calculate key component, item length and body to
		  insert into S[0]
 new item in whole falls into L[0] 
 Shift lnum[0]-1 items to L[0] 
 Insert new item into L[0] 
 directory item 
 new directory entry falls into L[0] 
		
		  Shift lnum[0] - 1 items in whole.
		  Shift lbytes - 1 entries from given directory item
 Append given directory entry to directory item 
		
		  previous string prepared space for pasting new entry,
		  following string pastes this entry
		
		  when we have merge directory item, pos_in_item
		  has been changed too
 paste new directory entry. 1 is entry number 
 new directory item doesn't fall into L[0] 
		
		  Shift lnum[0]-1 items in whole. Shift lbytes
		  directory entries from directory item number lnum[0]
 Calculate new position to append in item body 
 appended item will be in L[0] in whole 
		
		  this bytes number must be appended
		  to the last item of L[h]
 Calculate new insert_size[0] 
 Append to body of item in L[0] 
		
		  0-th item in S0 can be only of DIRECT type
		  when l_n != 0
 update key of first item in S0 
 update left delimiting key 
		
		  Calculate new body, position in item and
		  insert_size[0]
 only part of the appended item will be in L[0] 
 Calculate position in item for append in S[0] 
		
		  Shift lnum[0] - 1 items in whole.
		  Shift lbytes - 1 byte from item number lnum[0]
 appended item will be in L[0] in whole 
 if we paste into first item of S[0] and it is left mergable 
		
		  then increment pos_in_item by the size of the
		  last item in L[0]
	
	  Shift lnum[0] - 1 items in whole.
	  Shift lbytes - 1 byte from item number lnum[0]
 Append to body of item in L[0] 
 if appended item is directory, paste entry 
	
	  if appended item is indirect item, put unformatted node
	  into un list
 we must shift the part of the appended item 
 Shift lnum[0] items from S[0] to the left neighbor L[0] 
 new item or it part falls to L[0], shift it too 
 M_PASTE 
 new item doesn't fall into L[0] 
 new item or part of it doesn't fall into R[0] 
 new item or its part falls to R[0] 
 part of new item falls into R[0] 
 Remember key component and item length 
		
		  Calculate key component and item length to insert
		  into R[0]
 Insert part of the item into R[0] 
 Replace right delimiting key by first key in R[0] 
		
		  Calculate key component and item length to
		  insert into S[0]
 whole new item falls into R[0] 
 Shift rnum[0]-1 items to R[0] 
 Insert new item into R[0] 
 new directory entry falls into R[0] 
		
		  Shift rnum[0]-1 items in whole.
		  Shift rbytes-1 directory entries from directory
		  item number rnum[0]
 Paste given directory entry to directory item 
 paste entry 
 change delimiting keys 
 new directory entry doesn't fall into R[0] 
 we append to directory item 
 regular object 
	
	  Calculate number of bytes which must be shifted
	  from appended item
	
	  Calculate number of bytes which must remain in body
	  after appending to R[0]
 Append part of body into R[0] 
 append item in R[0] 
 paste new entry, if item is directory item 
 update delimiting keys 
 new item doesn't fall into R[0] 
 pasted item or part of it falls to R[0] 
 we must shift the part of the appended item 
 pasted item in whole falls into R[0] 
 shift rnum[0] items from S[0] to the right neighbor R[0] 
 M_PASTE 
 new item or it part don't falls into S_new[i] 
 new item or it's part falls to first new node S_new[i] 
 part of new item falls into S_new[i] 
 Move snum[i]-1 items from S[0] to S_new[i] 
 Remember key component and item length 
		
		  Calculate key component and item length to insert
		  into S_new[i]
 Insert part of the item into S_new[i] before 0-th item 
		
		  Calculate key component and item length to
		  insert into S[i]
 whole new item falls into S_new[i] 
		
		  Shift snum[0] - 1 items to S_new[i]
		  (sbytes[i] of split item)
 Insert new item into S_new[i] 
 we append to directory item 
 new directory entry falls into S_new[i] 
		
		  Shift snum[i]-1 items in whole.
		  Shift sbytes[i] directory entries
		  from directory item number snum[i]
		
		  Paste given directory entry to
		  directory item
 paste new directory entry 
 new directory entry doesn't fall into S_new[i] 
 regular object 
	
	  Calculate number of bytes which must be shifted from appended item
	
	  Calculate number of bytes which must remain in body after
	  append to S_new[i]
 Append part of body into S_new[0] 
 paste into item 
 if we paste to indirect item update ih_free_space 
 pasted item doesn't fall into S_new[i] 
 pasted item or part if it falls to S_new[i] 
 we must shift part of the appended item 
 item falls wholly into S_new[i] 
 Fill new nodes that appear in place of S[0] 
 here we shift from S to S_new nodes 
 initialized block type and tree level 
 M_PASTE 
 If we insert the first key change the delimiting key 
 can be 0 in reiserfsck 
 prepare space 
 paste entry 
 when directory, may be new entry already pasted 
 regular object 
  if the affected item was not wholly shifted then we
  perform all necessary operations on that part or whole
  of the affected item which remains in S
 if we must insert or append into buffer S[0] 
 M_PASTE 
  balance_leaf - reiserfs tree balancing algorithm
  @tb: tree balance state
  @ih: item header of inserted item (little endian)
  @body: body of inserted item or bytes to paste
  @flag: i - insert, d - delete, c - cut, p - paste (see do_balance)
  passed back:
  @insert_key: key to insert new nodes
  @insert_ptr: array of nodes to insert at the next level
  In our processing of one level we sometimes determine what must be
  inserted into the next higher level.  This insertion consists of a
  key or two keys and their corresponding pointers.
 Make balance in case insert_size[0] < 0 
	
	  for indirect item pos_in_item is measured in unformatted node
	  pointers. Recalculate to bytes
 tb->lnum[0] > 0 
 Calculate new item position 
 tb->rnum[0] > 0 
	
	  if while adding to a node we discover that it is possible to split
	  it in two, and merge the left part into the left neighbor and the
	  right part into the right neighbor, eliminating the node
 node S[0] is empty now 
		
		  if insertion was done before 0-th position in R[0], right
		  delimiting key of the tb->L[0]'s and left delimiting key are
		  not set correctly
 Leaf level of the tree is balanced (end of balance_leaf) 
 Make empty node 
 Endian safe if 0 
 Get first empty buffer 
 This is now used because reiserfs_free_block has to be able to schedule. 
 free_thrown puts this 
 incremented in store_thrown 
 Replace n_dest'th key in buffer dest by n_src'th key of buffer src.
 source buffer contains leaf node 
	
	  double check that buffers that we will modify are unlocked.
	  (fix_nodes should already have prepped all of these for us).
 check all internal nodes 
  Now we have all of the buffers that must be used in balancing of
  the tree.  We rely on the assumption that schedule() will not occur
  while do_balance works. ( Only interrupt handlers are acceptable.)
  We balance the tree according to the analysis made before this,
  using buffers already obtained.  For SMP support it will someday be
  necessary to add ordered locking of tb.
  Some interesting rules of balancing:
  we delete a maximum of two nodes per level per balancing: we never
  delete R, when we delete two of three nodes L, S, R then we move
  them into R.
  we only delete L if we are deleting two nodes, if we delete only
  one node we delete S
  if we shift leaves then we shift as much as we can: this is a
  deliberate policy of extremism in node packing which results in
  higher average utilization after repeated random balance operations
  at the cost of more memory copies and more balancing as a result of
  small insertions to full nodes.
  if we shift internal nodes we try to evenly balance the node
  utilization, with consequent less balancing at the cost of lower
  utilization.
  one could argue that the policy for directories in leaves should be
  that of internal nodes, but we will wait until another day to
  evaluate this....  It would be nice to someday measure and prove
  these assumptions as to what is optimal....
 use print_cur_tb() to see initial state of struct tree_balance 
 store_print_tb (tb); 
 do not delete, just comment it out 
	
	print_tb(flag, PATH_LAST_POSITION(tb->tb_path),
		 tb->tb_path->pos_in_item, tb, "check");
	
	  reiserfs_free_block is no longer schedule safe.  So, we need to
	  put the buffers we want freed on the thrown list during do_balance,
	  and then free them now
 release all nodes hold to perform the balancing 
  do_balance - balance the tree
  @tb: tree_balance structure
  @ih: item header of inserted item
  @body: body of inserted item or bytes to paste
  @flag: 'i' - insert, 'd' - delete, 'c' - cut, 'p' paste
  Cut means delete part of an item (includes removing an entry from a
  directory).
  Delete means delete whole item.
  Insert means add a new item into the tree.
  Paste means to append to the end of an existing file or to
  insert a directory entry.
 position of a child node in its parent 
 level of the tree being processed 
	
	  in our processing of one level we sometimes determine what
	  must be inserted into the next higher level.  This insertion
	  consists of a key or two keys and their corresponding
	  pointers
 inserted node-ptrs for the next level 
 if we have no real work to do  
	
	  balance_leaf returns 0 except if combining L R and S into
	  one node.  see balance_internal() for explanation of this
	  line of code.
 Balance internal level of the tree. 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
 %k 
 %K 
  debugging reiserfs we used to print out a lot of different
  variables, like keys, item headers, buffer heads etc. Values of
  most fields matter. So it took a long time just to write
  appropriative printk. With this reiserfs_warning you can use format
  specification for complex structures like you used to do with
  printfs for integers, doubles and pointers. For instance, to print
  out key structure you have to write just:
  reiserfs_warning ("bad key %k", key);
  instead of
  printk ("bad key %lu %lu %lu %lu", key->k_dir_id, key->k_objectid,
          key->k_offset, key->k_uniqueness);
  in addition to usual conversion specifiers this accepts reiserfs
  specific conversion specifiers:
  %k to print little endian key,
  %K to print cpu key,
  %h to print item_head,
  %t to print directory entry
  %z to print block head (arg must be struct buffer_head 
  %b to print buffer_head
 No newline.. reiserfs_info calls can be followed by printk's 
 No newline.. reiserfs_printk calls can be followed by printk's 
  The format:
           maintainer-errorid: [function-name:] message
    where errorid is unique to the maintainer and function-name is
    optional, is recommended, so that anyone can easily find the bug
    with a simple grep for the short to type string
    maintainer-errorid.  Don't bother with reusing errorids, there are
    lots of numbers out there.
    Example:
    reiserfs_panic(
      p_sb, "reiser-29: reiserfs_new_blocknrs: "
      "one of search_start or rn(%d) is equal to MAX_B_NUM,"
      "which means that we are optimizing location based on the "
      "bogus location of a temp buffer (%p).",
      rn, bh
    );
    Regular panic()s sometimes clear the screen before the message can
    be read, thus the need for the while loop.
    Numbering scheme for panic used by Vladimir and Anatoly( Hans completely
    ignores this scheme, and considers it pointless complexity):
    panics in reiserfs_fs.h have numbers from 1000 to 1999
    super.c			2000 to 2999
    preserve.c (unused)	3000 to 3999
    bitmap.c			4000 to 4999
    stree.c			5000 to 5999
    prints.c			6000 to 6999
    namei.c			7000 to 7999
    fix_nodes.c		8000 to 8999
    dir.c			9000 to 9999
    lbalance.c			10000 to 10999
    ibalance.c			11000 to 11999 not ready
    do_balan.c			12000 to 12999
    inode.c			13000 to 13999
    file.c			14000 to 14999
    objectid.c			15000 - 15999
    buffer.c			16000 - 16999
    symlink.c			17000 - 17999
  this prints internal nodes (4 keysitems in line) (dc_number,
  dc_size)[k_dirid, k_objectid, k_offset, k_uniqueness](dc_number,
  dc_size)...
 return 1 if this is not super block 
	
	  FIXME: this would be confusing if
	  someone stores reiserfs super block in some data block ;)
    skipped = (bh->b_blocknr  bh->b_size)  sb_blocksize(rs);
 ..., int print_mode, int first, int last) 
 this stores initial state of tree balance in the print_tb_buf 
 this prints balance parameters for non-leaf levels 
 print FEB list (list of buffers in form (bh (b_blocknr, b_count), that will be used for new nodes) 
	
	   printk ("reiserfs_put_super: session statistics: balances %d, fix_nodes %d, \
	   bmap with search %d, without %d, dir2ind %d, ind2dir %d\n",
	   REISERFS_SB(s)->s_do_balance, REISERFS_SB(s)->s_fix_nodes,
	   REISERFS_SB(s)->s_bmaps, REISERFS_SB(s)->s_bmaps_without_search,
	   REISERFS_SB(s)->s_direct2indirect, REISERFS_SB(s)->s_indirect2direct);
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  Written by Alexander Zarochentcev.
  The kernel part of the (on-line) reiserfs resizer.
 check the device size 
	
	  old disk layout detection; those partitions can be mounted, but
	  cannot be resized
 count used bits in last bitmap block 
 count bitmap blocks in new fs 
 save old values 
 resizing of reiserfs bitmaps (journal and real), if needed 
 reallocate journal bitmaps 
		
		  the new journal bitmaps are zero filled, now we copy i
		  the bitmap node pointers from the old journal bitmap
		  structs, and then transfer the new data structures
		  into the journal struct.
		 
		  using the copy_size var below allows this code to work for
		  both shrinking and expanding the FS.
			
			  just in case vfree schedules on us, copy the new
			  pointer into the journal struct before freeing the
			  old one
		
		  allocate additional bitmap blocks, reallocate
		  array of bitmap block pointers
			
			  Journal bitmaps are still supersized, but the
			  memory isn't leaked, so I guess it's ok
		
		  This doesn't go through the journal, but it doesn't have to.
		  The changes are still atomic: We're synced up when the
		  journal transaction begins, and the new bitmaps don't
		  matter if the transaction fails.
			
			  don't use read_bitmap_block since it will cache
			  the uninitialized bitmap
 update bitmap_info stuff 
 free old bitmap blocks array 
	
	  begin transaction, if there was an error, it's fine. Yes, we have
	  incorrect bitmaps now, but none of it is ever going to touch the
	  disk anyway.
 Extend old last bitmap block - new blocks have been made available 
 Correct new last bitmap block - It may not be full 
 update super 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  We pack the tails of files on file close, not at the time they are written.
  This implies an unnecessary copy of the tail and an unnecessary indirect item
  insertionbalancing, for files that are written in one write.
  It avoids unnecessary tail packings (balances) for files that are written in
  multiple writes and are small enough to have tails.
  file_release is called by the VFS layer when the file is closed.  If
  this is the last open file descriptor, and the file
  small enough to have a tail, and the tail is currently in an
  unformatted node, the tail is converted back into a direct item.
  We use reiserfs_truncate_file to pack the tail, since it already has
  all the conditions coded.
 fast out for when nothing needs to be done 
	
	  freeing preallocation only involves relogging blocks that
	  are already in the current transaction.  preallocation gets
	  freed at the end of each transaction, so it is impossible for
	  us to log any additional blocks (including quota blocks)
		
		  uh oh, we can't allow the inode to go away while there
		  is still preallocation blocks pending.  Try to join the
		  aborted transaction
			
			  hmpf, our choices here aren't good.  We can pin
			  the inode which will disallow unmount from ever
			  happening, we can do nothing, which will corrupt
			  random memory on unmount, or we can forcibly
			  remove the file from the preallocation list, which
			  will leak blocks on disk.  Lets pin the inode
			  and let the admin know what is going on.
 copy back the error code from journal_begin 
		
		  if regular file is released by last holder and it has been
		  appended (we append by unformatted node only) or its direct
		  item(s) had to be converted, then it may have to be
		  indirect2direct converted
 somebody might be tailpacking on final close; wait for it 
 Sync a reiserfs file. 
  FIXME: sync_mapping_buffers() never has anything to sync.  Can
  be removed...
 taken fsbuffer.c:__block_commit_write 
				
				  do data=ordered on any page past the end
				  of file and any buffer marked BH_New.
	
	  If this is a partial write which happened to make all buffers
	  uptodate then we can optimize away a bogus readpage() for
	  the next read(). Here we 'discover' whether the page went
	  uptodate as a result of this (potentially partial) write.
  Keyed 32-bit hash function using TEA in a Davis-Meyer function
    H0 = Key
    Hi = E Mi(Hi-1) + Hi-1
  (see Applied Cryptography, 2nd edition, p448).
  Jeremy Fitzhardinge <jeremy@zip.com.au> 1998
  Jeremy has agreed to the contents of reiserfsREADME. -Hans
  Yura's function is added (04072000)
 32 is overkill, 16 is strong crypto 
 6 gets complete mixing 
 a, b, c, d - data; h0, h1 - accumulated hash 
      assert(len >= 0 && len < 256); 
	return 0;
  What follows in this file is copyright 2000 by Hans Reiser, and the
  licensing of what follows is governed by reiserfsREADME
 SPDX-License-Identifier: GPL-2.0
  The previous reiserfs locking scheme was heavily based on
  the tricky properties of the Bkl:
  - it was acquired recursively by a same task
  - the performances relied on the release-while-schedule() property
  Now that we replace it by a mutex, we still want to keep the same
  recursive property to avoid big changes in the code structure.
  We use our own lock_owner here because the owner field on a mutex
  is only available in SMP or mutex debugging, also we only need this field
  for this mutex, no need for a system wide mutex facility.
  Also this lock is often released before a call that could block because
  reiserfs performances were partially based on the release while schedule()
  property of the Bkl.
 No need to protect it, only the current task touches it 
	
	  Are we unlocking without even holding the lock?
	  Such a situation must raise a BUG() if we don't want
	  to corrupt the data.
 this can happen when the lock isn't always held 
 this can happen when the lock isn't always held 
  Utility function to force a BUG if it is called without the superblock
  write lock held.  caller is the string printed just before calling BUG()
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  this contains item handlers for old item types: sd, direct,
  indirect, directory
  and where are the comments? how about saying where we can find an
  explanation of each item handler method? -Hans
 stat data functions 
 unused 
 direct item functions 
 FIXME: this should probably switch to indirect as well 
    return; 
 unused 
 indirect item functions 
 decrease offset, if it becomes 0, change type to stat data 
 if it is not first item of the body, then it is mergeable 
 printing of indirect item 
 unused 
  return size in bytes of 'units' units. If first == 0 - calculate
  from the head (left), otherwise - from tail (right)
 unit of indirect item is byte (yet) 
 unit of indirect item is byte (yet) 
 direntry functions 
 unused 
  function returns old entry number in directory item in real node
  using new entry number in virtual item in virtual node
 cut or paste is applied to another item 
  Create an array of sizes of directory entries for virtual
  item. Return space used by an item. FIXME: no control over
  consuming of space used by this item handler
 virtual directory item have this amount of entry after 
 set size of pasted entry 
 compare total size of entries with item length 
  return number of entries which may fit into specified amount of
  free space, or -1 if free space is not enough even for 1 entry
 i-th entry doesn't fit into the remaining free space 
 "." and ".." can not be separated from each other 
 i-th entry doesn't fit into the remaining free space 
 "." and ".." can not be separated from each other 
 sum of entry sizes between from-th and to-th entries including both edges 
 Error catching functions to catch errors caused by incorrect item types. 
	
	  We might return -1 here as well, but it won't help as
	  create_virtual_node() from where this operation is called
	  from is of return type void.
 This is to catch errors with invalid type (15th entry for TYPE_ANY) 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
 Reiserfs block (de)allocator, bitmap-based. 
 different reiserfs block allocator options 
	
	  It is in the bitmap block number equal to the block
	  number divided by the number of bits in a block.
 Within that bitmap block it is located at bit offset offset. 
	
	  Old format filesystem? Unlikely, but the bitmaps are all
	  up front so we need to account for it.
  Searches in journal structures for a given block number (bmap, off).
  If block is found in reiserfs journal it suggests next free block
  candidate to test.
 hint supplied 
 inc offset to avoid looping. 
  Searches for a window of zero bits with given minimum and maximum
  lengths in one bitmap block
 No free blocks in this bitmap 
 search for a first zero bit -- beginning of a window 
		
		  search for a zero bit fails or the rest of bitmap block
		  cannot contain a zero window of minimum size
 first zero bit found; we check next bits 
			
			  finding the other end of zero bit window requires
			  looking into journal structures (in case of
			  searching for free blocks for unformatted nodes)
		
		  now (beg) points to beginning of zero bits window,
		  (end) points to one bit after the window end
 found window of proper size 
			
			  try to set all blocks used checking are
			  they still free
 Don't check in journal again. 
					
					  bit was set by another process while
					  we slept in prepare_for_journal()
					
					  we can continue with smaller set
					  of allocated blocks, if length of
					  this set is more or equal to `min'
					
					  otherwise we clear all bit
					  were set ...
					
					  Search again in current block
					  from beginning
 free block count calculation 
 this can only be true when SB_BMAP_NR = 1 
  hashes the id and then returns > 0 if the block group for the
  corresponding hash is full
	
	  If we don't have cached information on this bitmap block, we're
	  going to have to load it later anyway. Loading it here allows us
	  to make a better decision. This favors long-term performance gain
	  with a better on-disk layout vs. a short term gain of skipping the
	  read and potentially having a bad placement.
  the packing is returned in disk byte order
		
		  some versions of reiserfsck expect packing locality 1 to be
		  special
  Tries to find contiguous zero bit window (given size) in given region of
  bitmap and place new blocks there. Returns number of allocated blocks.
 No point in looking for more free blocks 
	
	  When the bitmap is more than 10% free, anyone can allocate.
	  When it's less than 10% free, only files that already use the
	  bitmap are allowed. Once we pass 80% full, this restriction
	  is lifted.
	 
	  We do this so that files that grow later still have space close to
	  their original allocation. This improves locality, and presumably
	  performance as a result.
	 
	  This is only an allocation policy and does not make up for getting a
	  bad hint. Decent hinting must be implemented for this to work well.
 we know from above that start is a reasonable number 
 clear bit for the given block in bit map 
 update super block 
 mark it before we clear it, just in case 
 preallocated blocks don't need to be run through journal_mark_freed 
		
		  reiserfs_free_prealloc_block can drop the write lock,
		  which could allow another caller to free the same block.
		  We can protect against it by modifying the prealloc
		  state before calling it.
 FIXME: It should be inline function 
 block allocator related options are parsed here 
 clear default settings 
hint->search_start = hint->beg;
  Relocation based on dirid, hashing them into a given bitmap block
  files. Formatted nodes are unaffected, a separate policy covers them
 give a portion of the block group to metadata 
  Relocation based on oid, hashing them into a given bitmap block
  files. Formatted nodes are unaffected, a separate policy covers them
		
		  keep the root dir and it's first set of subdirs close to
		  the start of the disk
  returns 1 if it finds an indirect item and gets valid hint info
  from it, otherwise 0
	
	  reiserfs code can call this function wo pointer to path
	  structure supplied; then we rely on supplied search_start
	
	  for indirect item: go to left and look for the first non-hole entry
	  in the indirect item
 does result value fit into specified region? 
  should be, if formatted node, then try to put on first part of the device
  specified as number of percent with mount option device, else try to put
  on last of device.  This is not to say it is good code to do so,
  but the effect should be measured.
 This is former border algorithm. Now with tunable border offset 
	
	  whenever we create a new directory, we displace it.  At first
	  we will hash for location, later we might look for a moderately
	  empty place for it
		
		  we do not continue determine_search_start,
		  if new packing locality is being displaced
	
	  all persons should feel encouraged to add more special cases
	  here and test them
	
	  if none of our special cases is relevant, use the left
	  neighbor in the tree order of the new node we are allocating for
	
	  Mimic old block allocator behaviour, that is if VFS allowed for
	  preallocation, new blocks are displaced based on directory ID.
	  Also, if suggested search_start is less than last preallocated
	  block, we start searching from it, assuming that HDD dataflow
	  is faster in forward direction
 This is an approach proposed by Hans 
 old_hashed_relocation only works on unformatted 
 new_hashed_relocation works with both formattedunformatted nodes 
 dirid grouping works only on unformatted nodes 
 oid grouping works only on unformatted nodes 
 make minimum size a mount option and benchmark both ways 
 we preallocate blocks only for regular files, specific size 
 benchmark preallocating always and see what happens 
 no new blocks allocated, return 
 fill free_blocknrs array first 
 do we have something to fill prealloc. array also ? 
			
			  it means prealloc_size was greater that 0 and
			  we do preallocation
 Quota exceeded? 
 for unformatted nodes, force large allocations 
 Search from hint->search_start to end of disk 
 Search from hint->beg to hint->search_start 
 Last chance: Search from 0 to hint->beg 
 We've tried searching everywhere, not enough space 
 Free the blocks 
 Free not allocated blocks 
 Some of preallocation blocks were not allocated 
 grab new blocknrs from preallocated list 
 return amount still needed after using them 
 return amount still needed after using preallocated blocks 
 Amount of blocks we have already reserved 
 Check if there is enough space, taking into account reserved space 
 should this be if !hint->inode &&  hint->preallocate? 
 do you mean hint->formatted_node can be removed ? - Zam 
	
	  hint->formatted_node cannot be removed because we try to access
	  inode information here, and there is often no inode associated with
	  metadata allocations - green
		
		  We have all the block numbers we need from the
		  prealloc list
 find search start and save it in hint structure 
 allocation itself; fill new_blocknrs and preallocation arrays 
	
	  We used prealloc. list to fill (partially) new_blocknrs array.
	  If final allocation fails we need to return blocks back to
	  prealloc. list or just free them. -- Zam (I chose second
	  variant)
 The first bit must ALWAYS be 1 
 0 and ~0 are special, we can optimize for them 
 A mix, investigate 
	
	  Way old format filesystems had the bitmaps packed up front.
	  I doubt there are any of these left, but just in case...
 SPDX-License-Identifier: GPL-2.0
 SPDX-License-Identifier: GPL-2.0
 Initializes the security context for a new inode and returns the number
  of blocks needed for the transaction. If successful, reiserfs_security
 Don't add selinux attributes on xattrs - they'll never get used 
		 We don't want to count the directories twice if we have
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  To make any changes in the tree we find a node that contains item
  to be changeddeleted or position in the node we insert a new item
  to. We call this node S. To do balancing we need to decide what we
  will shift to leftright neighbor, or to a new node, where new item
  will be etc. To make this analysis simpler we build virtual
  node. Virtual node is an array of items, that will replace items of
  node S. (For instance if we are going to delete an item, virtual
  node does not contain it). Virtual node keeps information about
  item sizes and types, mergeability of first and last items, sizes
  of all entries in directory item. We use this array of items when
  calculating what we can shift to neighbors and how many nodes we
  have to have if we do not any shiftings, if we shift to leftright
  neighbor or to both.
  Takes item number in virtual node, returns number of item
  that it has in source buffer
 delete mode 
 this comes from tb->S[h] 
 size of changed node 
 for internal nodes array if virtual items is not created 
 number of items in virtual node  
 first virtual item 
 first item in the node 
 define the mergeability for 0-th item (if it is not being deleted) 
	
	  go through all items that remain in the virtual
	  node (except for the new (inserted) one)
 get item number in source node 
		
		  FIXME: there is no check that item operation did not
		  consume too much memory
 this is not being changed 
 pointer to data which is going to be pasted 
 virtual inserted item is not defined yet 
not pasted or cut  ,
	
	  set right merge flag we take right delimiting key and
	  check whether it is a mergeable item
			
			  we delete last item and it could be merged
			  with right neighbor's first item
				
				  node contains more than 1 item, or item
				  is not directory item, or this item
				  contains more than 1 entry
  Using virtual node check, how many items can be
  shifted to left neighbor
 internal level 
 leaf level 
 no free space or nothing to move 
 all contents of S[0] fits into L[0] 
 first item may be merge with last item in left neighbor 
 the item can be shifted entirely 
 the item cannot be shifted entirely, try to split it 
		
		  check whether L[0] can hold ih and at least one byte
		  of the item body
 cannot shift even a part of the current item 
 count partially shifted item 
  Using virtual node check, how many items can be
  shifted to right neighbor
 internal level 
 leaf level 
 no free space  
 all contents of S[0] fits into R[0] 
 last item may be merge with first item in right neighbor 
 the item can be shifted entirely 
		
		  check whether R[0] can hold ih and at least one
		  byte of the item body
 cannot shift even a part of the current item 
		
		  R[0] can hold the header of the item and at least
		  one byte of its body
 cur_free is still > 0 
 count partially shifted item 
  from - number of items, which are shifted to left neighbor entirely
  to - number of item, which are shifted to right neighbor entirely
  from_bytes - number of bytes of boundary item (or directory entries)
               which are shifted to left neighbor
  to_bytes - number of bytes of boundary item (or directory entries)
             which are shifted to right neighbor
 position of item we start filling node from 
 position of item we finish filling node by 
	
	  number of first bytes (entries for directory) of start_item-th item
	  we do not include into node that is being filled
	
	  number of last bytes (entries for directory) of end_item-th item
	  we do node include into node that is being filled
	
	  these are positions in virtual item of items, that are split
	  between S[0] and S1new and S1new and S2new
	
	  We only create additional nodes if we are in insert or paste mode
	  or we are in replace mode at the internal level. If h is 0 and
	  the mode is M_REPLACE then in fix_nodes we change the mode to
	  paste or insert before we get here in the code.
	
	  snum012 [0-2] - number of items, that lay
	  to S[0], first new node and second new node
 s1bytes 
 s2bytes 
 internal level 
 leaf level 
 start from 'from'-th item 
 skip its first 'start_bytes' units 
 last included item is the 'end_item'-th one 
 do not count last 'end_bytes' units of 'end_item'-th item 
	
	  go through all item beginning from the start_item-th item
	  and ending by the end_item-th item. Do not count first
	  'start_bytes' units of 'start_item'-th item and last
	  'end_bytes' of 'end_item'-th item
 get size of current item 
		
		  do not take in calculation head part (from_bytes)
		  of from-th item
from start  , start_bytes);
 do not take in calculation tail part of last item 
from end  , skip_from_end);
 if item fits into current node entierly 
		
		  virtual item length is longer, than max size of item in
		  a node. It is impossible for direct item
 we will try to split it 
 as we do not split items, take new node and continue 
		
		  calculate number of item units which fit into node being
		  filled
			
			  nothing fits into current node, take new
			  node and continue
 something fits into the current node 
 continue from the same item with start_bytes != -1 
	
	  sum012[4] (if it is not -1) contains number of units of which
	  are to be in S1new, snum012[3] - to be in S0. They are supposed
	  to be S1bytes and S2bytes correspondingly, so recalculate
 s2bytes 
 now we know S2bytes, calculate S1bytes 
 s1bytes 
  Set parameters for balancing.
  Performs write of results of analysis of balancing into structure tb,
  where it will later be used by the functions that actually do the balancing.
  Parameters:
 	tb	tree_balance structure;
 	h	current level of the node;
 	lnum	number of items from S[h] that must be shifted to L[h];
 	rnum	number of items from S[h] that must be shifted to R[h];
 	blk_num	number of blocks that S[h] will be splitted into;
 	s012	number of items that fall into splitted nodes.
 	lbytes	number of bytes which flow to the left neighbor from the
               item that is not shifted entirely
 	rbytes	number of bytes which flow to the right neighbor from the
               item that is not shifted entirely
 	s1bytes	number of bytes which flow to the first  new node when
               S[0] splits (this number is contained in s012 array)
 only for leaf level 
  check if node disappears if we shift tb->lnum[0] items to left
  neighbor and tb->rnum[0] to the right one.
	
	  number of items that will be shifted to left (right) neighbor
	  entirely
 how many items remain in S[0] after shiftings to neighbors 
 all content of node can be shifted to neighbors 
 S[0] is not removable 
 check whether we can divide 1 remaining item between neighbors 
 get size of remaining item (in item units) 
 check whether L, S, R can be joined in one node 
 there was only one item and it will be deleted 
			
			  Directory must be in correct state here: that is
			  somewhere at the left side should exist first
			  directory item. But the item being deleted can
			  not be that first one because its right neighbor
			  is item of the same directory. (But first item
			  always gets deleted in last turn). So, neighbors
			  of deleted item can be merged, so we can save
			  ih_size
				
				  we might check that left neighbor exists
				  and is of the same directory
 when we do not split item, lnum and rnum are numbers of entire items 
  Get new buffers for storing new nodes that are created while balancing.
  Returns:	SCHEDULE_OCCURRED - schedule occurred while the function worked;
 	        CARRY_ON - schedule didn't occur while the function worked;
 	        NO_DISK_SPACE - no disk space.
 The function is NOT SCHEDULE-SAFE! 
 number of needed empty blocks 
	
	  number_of_freeblk is the number of empty blocks which have been
	  acquired for use by the balancing algorithm minus the number of
	  empty blocks used in the previous levels of the analysis,
	  number_of_freeblk = tb->cur_blknum can be non-zero if a schedule
	  occurs after empty blocks are acquired, and the balancing analysis
	  is then restarted, amount_needed is the number needed by this
	  level (h) of the balancing analysis.
	 
	  Note that for systems with many processes writing, it would be
	  more layout optimal to calculate the total number needed by all
	  levels and then to run reiserfs_new_blocks to get all of them at
	  once.
	
	  Initiate number_of_freeblk to the amount acquired prior to the
	  restart of the analysis or 0 if not restarted, then subtract the
	  amount needed by all of the levels of the tree below h.
 blknum includes S[h], so we subtract 1 in this calculation 
 Allocate missing empty blocks. 
 if Sh == 0  then we are getting a new root 
	
	  Amount_needed = the amount that we need more than the
	  amount that we have.
 If we have enough already then there is nothing to do. 
	
	  No need to check quota - is not allocated for blocks used
	  for formatted nodes
 for each blocknumber we just got, get a buffer and stick it on FEB 
 Put empty buffers into the array. 
  Get free space of the left neighbor, which is stored in the parent
  node of the left neighbor.
  Get free space of the right neighbor,
  which is stored in the parent node of the right neighbor.
 Check whether left neighbor is in memory. 
 Father of the left neighbor does not exist. 
 Calculate father of the node to be balanced. 
	
	  Get position of the pointer to the left neighbor
	  into the left father.
 Get left neighbor block number. 
 Look for the left neighbor in the cache. 
 call item specific function for this key 
  Calculate far leftright parent of the leftright neighbor of the
  current node, that is calculate the leftright (FL[h]FR[h]) neighbor
  of the parent F[h].
  Calculate leftright common parent of the current node and L[h]R[h].
  Calculate leftright delimiting key position.
  Returns:	PATH_INCORRECT    - path in the tree is not correct
 		SCHEDULE_OCCURRED - schedule occurred while the function worked
 	        CARRY_ON          - schedule didn't occur while the function
 				    worked
	
	  Starting from F[h] go upwards in the tree, and look for the common
	  ancestor of F[h], and its neighbor lr, that should be obtained.
		
		  Check whether parent of the current buffer in the path
		  is really parent in the tree.
 Check whether position in the parent is correct. 
		
		  Check whether parent at the path really points
		  to the child.
		
		  Return delimiting key if position in the parent is not
		  equal to firstlast one.
(pcom_father = parent)->b_count++; 
 if we are in the root of the tree, then there is no common father 
		
		  Check whether first buffer in the path is the
		  root of the tree.
 Check whether the common parent is locked. 
 Release the write lock while the buffer is busy 
	
	  So, we got common parent of the current node and its
	  leftright neighbor.  Now we are getting the parent of the
	  leftright neighbor.
 Form key to get parent of the leftright neighbor. 
 path is released 
  Get parents of neighbors of node in the path(S[path_offset]) and
  common parents of S[path_offset] and L[path_offset]R[path_offset]:
  F[path_offset], FL[path_offset], FR[path_offset], CFL[path_offset],
  CFR[path_offset].
  Calculate numbers of left and right delimiting keys position:
  lkey[path_offset], rkey[path_offset].
  Returns:	SCHEDULE_OCCURRED - schedule occurred while the function worked
 	        CARRY_ON - schedule didn't occur while the function worked
 Current node is the root of the tree or will be root of the tree 
		
		  The root can not have parents.
		  Release nodes which previously were obtained as
		  parents of the current node neighbors.
 Get parent FL[path_offset] of L[path_offset]. 
 Current node is not the first child of its parent. 
		
		  Calculate current parent of L[path_offset], which is the
		  left neighbor of the current node.  Calculate current
		  common parent of L[path_offset] and the current node.
		  Note that CFL[path_offset] not equal FL[path_offset] and
		  CFL[path_offset] not equal F[path_offset].
		  Calculate lkey[path_offset].
 New initialization of FL[h]. 
 New initialization of CFL[h]. 
 Get parent FR[h] of R[h]. 
 Current node is the last child of F[h]. FR[h] != F[h]. 
		
		  Calculate current parent of R[h], which is the right
		  neighbor of F[h].  Calculate current common parent of
		  R[h] and current node. Note that CFR[h] not equal
		  FR[path_offset] and CFR[h] not equal F[h].
 Current node is not the last child of its parent F[h]. 
 New initialization of FR[path_offset]. 
 New initialization of CFR[path_offset]. 
  it is possible to remove node as result of shiftings to
  neighbors even when we insert or paste item.
 shifting may merge items which might save space 
 node can not be removed 
 new item fits into node S[h] without any shifting 
  Check whether current node S[h] is balanced when increasing its size by
  Inserting or Pasting.
  Calculate parameters for balancing for current level h.
  Parameters:
 	tb	tree_balance structure;
 	h	current level of the node;
 	inum	item number in S[h];
 	mode	i - insert, p - paste;
  Returns:	1 - schedule occurred;
 	        0 - balancing for higher levels needed;
 	       -1 - no balancing for higher levels needed;
 	       -2 - no disk space.
 ip means Inserting or Pasting 
	
	  Number of bytes that must be inserted into (value is negative
	  if bytes are deleted) buffer which contains node being balanced.
	  The mnemonic is that the attempted change in node space used
	  level is levbytes bytes.
 free space in L, S and R  ;
	
	  nver is short for number of vertixes, and lnver is the number if
	  we shift to the left, rnver is the number if we shift to the
	  right, and lrnver is the number if we shift in both directions.
	  The goal is to minimize first the number of vertixes, and second,
	  the number of vertixes whose contents are changed by shifting,
	  and third the number of uncached vertixes whose contents are
	  changed by shifting and must be read from disk.
	
	  used at leaf level only, S0 = S[0] is the node being balanced,
	  sInum [ I = 0,1,2 ] is the number of items that will
	  remain in node SI after balancing.  S1 and S2 are new
	  nodes that might be created.
	
	  we perform 8 calls to get_num_ver().  For each call we
	  calculate five parameters.  where 4th parameter is s1bytes
	  and 5th - s2bytes
	 
	  s0num, s1num, s2num for 8 cases
	  0,1 - do not shift and do not shift but bottle
	  2   - shift only whole item to left
	  3   - shift to left and bottle as much as possible
	  4,5 - shift to right (whole items and as much as possible
	  6,7 - shift to both directions (whole items and as much as possible)
 Sh is the node whose balance is currently being checked 
 Calculate balance parameters for creating new root. 
 no balancing for higher levels needed 
 get parents of S[h] neighbors. 
 get free space of neighbors 
 and new item fits into node S[h] without any shifting 
	
	  determine maximal number of items we can shift to the left
	  neighbor (in tb structure) and the maximal number of bytes
	  that can flow to the left neighbor from the left most liquid
	  item that cannot be shifted from S[0] entirely (returned value)
	
	  determine maximal number of items we can shift to the right
	  neighbor (in tb structure) and the maximal number of bytes
	  that can flow to the right neighbor from the right most liquid
	  item that cannot be shifted from S[0] entirely (returned value)
	
	  all contents of internal node S[h] can be moved into its
	  neighbors, S[h] will be removed after balancing
		
		  Since we are working on internal nodes, and our internal
		  nodes have fixed size entries, then we can balance by the
		  number of items rather than the space they consume.  In this
		  routine we set the left node equal to the right node,
		  allowing a difference of less than or equal to 1 child
		  pointer.
	
	  this checks balance condition, that any two neighboring nodes
	  can not fit in one node
	
	  all contents of S[0] can be moved into its neighbors
	  S[0] will be removed after balancing.
	
	  why do we perform this check here rather than earlier??
	  Answer: we can win 1 node in some cases above. Moreover we
	  checked it above, when we checked, that S[0] is not removable
	  in principle
 new item fits into node S[h] without any shifting 
 regular overflowing of the node 
		
		  get_num_ver works in 2 modes (FLOW & NO_FLOW)
		  lpar, rpar - number of items we can shift to leftright
		               neighbor (including splitting item)
		  nset, lset, rset, lrset - shows, whether flowing items
		                            give better packing
 do not any splitting 
 we choose one of the following 
		
		  calculate number of blocks S[h] must be split into when
		  nothing is shifted to the neighbors, as well as number of
		  items in each part of the split node (s012 numbers),
		  and number of bytes (s1bytes) of the shared drop which
		  flow to S1 if any
			
			  note, that in this case we try to bottle
			  between S[0] and S1 (S1 - the first new node)
		
		  calculate number of blocks S[h] must be split into when
		  l_shift_num first items and l_shift_bytes of the right
		  most liquid item to be shifted are shifted to the left
		  neighbor, as well as number of items in each part of the
		  splitted node (s012 numbers), and number of bytes
		  (s1bytes) of the shared drop which flow to S1 if any
		
		  calculate number of blocks S[h] must be split into when
		  r_shift_num first items and r_shift_bytes of the left most
		  liquid item to be shifted are shifted to the right neighbor,
		  as well as number of items in each part of the splitted
		  node (s012 numbers), and number of bytes (s1bytes) of the
		  shared drop which flow to S1 if any
		
		  calculate number of blocks S[h] must be split into when
		  items are shifted in both directions, as well as number
		  of items in each part of the splitted node (s012 numbers),
		  and number of bytes (s1bytes) of the shared drop which
		  flow to S1 if any
		
		  Our general shifting strategy is:
		  1) to minimized number of new nodes;
		  2) to minimized number of neighbors involved in shifting;
		  3) to minimized number of disk reads;
 we can win TWO or ONE nodes by shifting in both directions 
		
		  if shifting doesn't lead to better packing
		  then don't shift
		
		  now we know that for better packing shifting in only one
		  direction either to the left or to the right is required
		
		  if shifting to the left is better than
		  shifting to the right
		
		  if shifting to the right is better than
		  shifting to the left
		
		  now shifting in either direction gives the same number
		  of nodes and we can make use of the cached neighbors
		
		  shift to the right independently on whether the
		  right neighbor in cache or not
  Check whether current node S[h] is balanced when Decreasing its size by
  Deleting or Cutting for INTERNAL node of S+tree.
  Calculate parameters for balancing for current level h.
  Parameters:
 	tb	tree_balance structure;
 	h	current level of the node;
 	inum	item number in S[h];
 	mode	i - insert, p - paste;
  Returns:	1 - schedule occurred;
 	        0 - balancing for higher levels needed;
 	       -1 - no balancing for higher levels needed;
 	       -2 - no disk space.
  Note: Items of internal nodes have fixed size, so the balance condition for
  the internal part of S+tree is as for the B-trees.
	
	  Sh is the node whose balance is currently being checked,
	  and Fh is its father.
 free space in L and R  ;
	
	  using tb->insert_size[h], which is negative in this case,
	  create_virtual_node calculates:
	  new_nr_item = number of items node would have if operation is
	  performed without balancing (new_nr_item);
 S[h] is the root. 
 no balancing for higher levels needed 
		
		  new_nr_item == 0.
		  Current root will be deleted resulting in
		  decrementing the tree height.
 get free space of neighbors 
 determine maximal number of items we can fit into neighbors 
	
	  Balance condition for the internal node is valid.
	  In this case we balance only if it leads to better packing.
		
		  Here we join S[h] with one of its neighbors,
		  which is impossible with greater values of new_nr_item.
 All contents of S[h] can be moved to L[h]. 
 All contents of S[h] can be moved to R[h]. 
		
		  All contents of S[h] can be moved to the neighbors
		  (L[h] & R[h]).
 Balancing does not lead to better packing. 
	
	  Current node contain insufficient number of items.
	  Balancing is required.
 Check whether we can merge S[h] with left neighbor. 
 Check whether we can merge S[h] with right neighbor. 
 All contents of S[h] can be moved to the neighbors (L[h] & R[h]). 
 For internal nodes try to borrow item from a neighbor 
 Borrow one or two items from caching neighbor 
  Check whether current node S[h] is balanced when Decreasing its size by
  Deleting or Truncating for LEAF node of S+tree.
  Calculate parameters for balancing for current level h.
  Parameters:
 	tb	tree_balance structure;
 	h	current level of the node;
 	inum	item number in S[h];
 	mode	i - insert, p - paste;
  Returns:	1 - schedule occurred;
 	        0 - balancing for higher levels needed;
 	       -1 - no balancing for higher levels needed;
 	       -2 - no disk space.
	
	  Number of bytes that must be deleted from
	  (value is negative if bytes are deleted) buffer which
	  contains node being balanced.  The mnemonic is that the
	  attempted change in node space used level is levbytes bytes.
 the maximal item size 
	
	  S0 is the node whose balance is currently being checked,
	  and F0 is its father.
 free space in L and R  ;
 maximal possible size of an item 
 S[0] is the root now. 
 get free space of neighbors 
 if 3 leaves can be merge to one, set parameters and return 
	
	  determine maximal number of items we can shift to the leftright
	  neighbor and the maximal number of bytes that can flow to the
	  leftright neighbor from the leftright most liquid item that
	  cannot be shifted from S[0] entirely
 check whether we can merge S with left neighbor. 
 S can not be merged with R 
 set parameter to merge S[0] with its left neighbor 
 check whether we can merge S[0] with right neighbor. 
	
	  All contents of S[0] can be moved to the neighbors (L[0] & R[0]).
	  Set parameters and return
 Balancing is not required. 
  Check whether current node S[h] is balanced when Decreasing its size by
  Deleting or Cutting.
  Calculate parameters for balancing for current level h.
  Parameters:
 	tb	tree_balance structure;
 	h	current level of the node;
 	inum	item number in S[h];
 	mode	d - delete, c - cut.
  Returns:	1 - schedule occurred;
 	        0 - balancing for higher levels needed;
 	       -1 - no balancing for higher levels needed;
 	       -2 - no disk space.
  Check whether current node S[h] is balanced.
  Calculate parameters for balancing for current level h.
  Parameters:
 	tb	tree_balance structure:
               tb is a large structure that must be read about in the header
 		file at the same time as this procedure if the reader is
 		to successfully understand this procedure
 	h	current level of the node;
 	inum	item number in S[h];
 	mode	i - insert, p - paste, d - delete, c - cut.
  Returns:	1 - schedule occurred;
 	        0 - balancing for higher levels needed;
 	       -1 - no balancing for higher levels needed;
 	       -2 - no disk space.
 Calculate balance parameters when size of node is increasing. 
 Calculate balance parameters when  size of node is decreasing. 
 Check whether parent at the path is the really parent of the current node.
 We are in the root or in the new root. 
 Root is not changed. 
 Root is changed and we must recalculate the path. 
 Parent in the path is not in the tree. 
 Parent in the path is not parent of the current node in the tree. 
	
	  Parent in the path is unlocked and really parent
	  of the current node.
  Using lnum[h] and rnum[h] we should determine what neighbors
  of S[h] we
  need in order to balance S[h], and get them if necessary.
  Returns:	SCHEDULE_OCCURRED - schedule occurred while the function worked;
 	        CARRY_ON - schedule didn't occur while the function worked;
 We need left neighbor to balance S[h]. 
 We need right neighbor to balance S[path_offset]. 
  maybe we should fail balancing we are going to perform when kmalloc
  fails several times. But now it will loop until kmalloc gets
  required memory
 we have to allocate more memory for virtual node 
 free memory allocated before 
 this is not needed if kfree is atomic 
 virtual node requires now more memory 
 get memory for virtual item 
			
			  getting memory with GFP_KERNEL priority may involve
			  balancing now (due to indirect_to_direct conversion
			  on dcache shrinking). So, release path and collected
			  resources here
				
				  if I understand correctly, we can only
				  be sure the last buffer in the path is
				  in the tree --clm
		
		  as far as I can tell, this is not required.  The FEB list
		  seems to be full of newly allocated nodes, which will
		  never be locked, dirty, or anything else.
		  To be safe, I'm putting in the checks and waits in.
		  For the moment, they are needed to keep the code in
		  journal.c from complaining about the buffer.
		  That code is inside CONFIG_REISERFS_CHECK as well.  --clm
 Don't loop forever.  Try to recover from possible error. 
  Prepare for balancing, that is
 	get all necessary parents, and neighbors;
 	analyze what and where should be moved;
 	get sufficient number of new nodes;
  Balancing will start only after all resources will be collected at a time.
  When ported to SMP kernels, only at the last moment after all needed nodes
  are collected in cache, will the resources be locked using the usual
  textbook ordered lock acquisition algorithms.  Note that ensuring that
  this code neither write locks what it does not need to write lock nor locks
  out of order will be a pain in the butt that could have been avoided.
  Grumble grumble. -Hans
  fix is meant in the sense of render unchanging
  Latency might be improved by first gathering a list of what buffers
  are needed and then getting as many of them in parallel as possible? -Hans
  Parameters:
 	op_mode	i - insert, d - delete, c - cut (truncate), p - paste (append)
 	tb	tree_balance structure;
 	inum	item number in S[h];
       pos_in_item - comment this if you can
       ins_ih	item head of item being inserted
 	data	inserted item or data to be pasted
  Returns:	1 - schedule occurred while the function worked;
 	        0 - schedule didn't occur while the function worked;
              -1 - if no_disk_space
	
	  we set wait_tb_buffers_run when we have to restore any dirty
	  bits cleared during wait_tb_buffers_run
	
	  we prepare and log the super here so it will already be in the
	  transaction when do_balance needs to change it.
	  This way do_balance won't have to schedule when trying to prepare
	  the super for logging
 if it possible in indirect_to_direct conversion 
 Check parameters. 
 FIXME: maybe -ENOMEM when tb->vn_buf == 0? Now just repeat 
 Starting from the leaf level; for all levels h of the tree. 
 No balancing for higher levels needed. 
				
				  ok, analysis and resource gathering
				  are complete
		
		  No disk space, or schedule occurred and analysis may be
		  invalid and needs to be redone.
		
		  We have a positive insert size but no nodes exist on this
		  level, this means that we are creating a new root.
			
			  The tree needs to be grown, so this node S[h]
			  which is the root node is split into two nodes,
			  and a new node (S[h+1]) will be created to
			  become the root node.
	
	  fix_nodes was unable to perform its calculation due to
	  filesystem got changed under us, lack of free disk space or io
	  failure. If the first is the case - the search will be
	  repeated. For now - free all resources acquired so far except
	  for the new allocated nodes
 Release path buffers. 
 brelse all resources collected for balancing 
 Release path buffers. 
 brelse all resources collected for balancing 
 deal with list of allocated (used and unused) nodes 
			
			  de-allocated block which was not used by
			  balancing and bforget about buffer for it
 release used as new nodes including a new root 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
  copy copy_count entries from source directory item to dest buffer
  (creating new item if needed)
	
	  either the number of target item, or if we must create a
	  new item, the number of the item we will create it next to
 length of all records in item to be copied 
	
	  length of all record to be copied and first byte of
	  the last of them
 when copy last to first, dest buffer can contain 0 items 
	
	  if there are no items in dest or the firstlast item in
	  dest is not item of the same directory
COMP_SHORT_KEYS  (&ih->ih_key,
 create new item in dest 
 form item header 
 calculate item len 
 form key by the following way 
				
				  no entries will be copied to this
				  item in this function
				
				  this item is not yet valid, but we
				  want I_IS_DIRECTORY_ITEM to return 1
				  for it, so we -1
 insert item into dest buffer 
 prepare space for entries 
  Copy the first (if last_first == FIRST_TO_LAST) or last
  (last_first == LAST_TO_FIRST) item or part of it or nothing
  (see the return 0 below) from SOURCE to the end (if last_first)
  or beginning (!last_first) of the DEST
 returns 1 if anything was copied, else 0 
 number of items in the source and destination buffers 
	
	  if ( DEST is empty or first item of SOURCE and last item of
	  DEST are the items of different objects or of different types )
	  then there is no need to treat this item differently from the
	  other items that we copy, so we return
 there is nothing to merge 
 copy all entries to dest 
		
		  copy part of the body of the first item of SOURCE
		  to the end of the body of the last item of the DEST
		  part defined by 'bytes_or_entries'; if bytes_or_entries
		  == -1 copy whole body; don't create new item header
		
		  merge first item (or its part) of src buffer with the last
		  item of dest buffer. Both are of the same file
 copy boundary item to right (last_first == LAST_TO_FIRST) 
	
	  (DEST is empty or last item of SOURCE and first item of DEST
	  are the items of different object or of different types)
		
		  bytes_or_entries = entries number in last
		  item body of SOURCE
	
	  copy part of the body of the last item of SOURCE to the
	  begin of the body of the first item of the DEST; part defined
	  by 'bytes_or_entries'; if byte_or_entriess == -1 copy whole body;
	  change first item key of the DEST; don't create new item header
 bytes_or_entries = length of last item body of SOURCE 
 change first item key of the DEST 
 item becomes non-mergeable 
 or mergeable if left item was 
 merge to right only part of item 
 change first item key of the DEST 
  copy cpy_mun items from buffer src to buffer dest
  last_first == FIRST_TO_LAST means, that we copy cpy_num items beginning
                              from first-th item in src to tail of dest
  last_first == LAST_TO_FIRST means, that we copy cpy_num items beginning
                              from first-th item in src to head of dest
	
	  we will insert items before 0-th or nr-th item in dest buffer.
	  It depends of last_first parameter
 location of head of first new item 
 prepare space for headers 
 copy item headers 
 location of unmovable item 
 prepare space for items 
 check free space 
 copy items 
 sizes, item number 
  This function splits the (liquid) item into two items (useful when
  shifting part of an item into another node.)
		
		  if ( if item in position item_num in buffer SOURCE
		  is directory item )
			
			  copy part of the body of the item number 'item_num'
			  of SOURCE to the end of the DEST part defined by
			  'cpy_bytes'; create new item header; change old
			  item_header (????); n_ih = new item_header;
 JDM Endian safe, both le 
		
		  if ( if item in position item_num in buffer
		  SOURCE is directory item )
			
			  copy part of the body of the item number 'item_num'
			  of SOURCE to the begin of the DEST part defined by
			  'cpy_bytes'; create new item header;
			  n_ih = new item_header;
 Endian safe, both le 
 indirect item 
 set item length 
 Endian safe, both le 
  If cpy_bytes equals minus one than copy cpy_num whole items from SOURCE
  to DEST.  If cpy_bytes not equal to minus one than copy cpy_num-1 whole
  items from SOURCE to DEST.  From last item copy cpy_num bytes for regular
  item and cpy_num directory entries for directory item.
 copy items to left 
		
		  copy the first item or it part or nothing to the end of
		  the DEST (i = leaf_copy_boundary_item(DEST,SOURCE,0,bytes))
			
			  copy first cpy_num items starting from position
			  'pos' of SOURCE to end of DEST
			
			  copy first cpy_num-1 items starting from position
			  'pos-1' of the SOURCE to the end of the DEST
			
			  copy part of the item which number is
			  cpy_num+pos-1 to the end of the DEST
 copy items to right 
		
		  copy the last item or it part or nothing to the
		  begin of the DEST
		  (i = leaf_copy_boundary_item(DEST,SOURCE,1,bytes));
			
			  starting from position 'pos' copy last cpy_num
			  items of SOURCE to begin of DEST
			
			  copy last cpy_num-1 items starting from position
			  'pos+1' of the SOURCE to the begin of the DEST;
			
			  copy part of the item which number is pos to
			  the begin of the DEST
  there are types of coping: from S[0] to L[0], from S[0] to R[0],
  from R[0] to L[0]. for each of these we have to define parent and
  positions of destination and source buffers
 define dest, src, dest parent, dest position 
 it is used in leaf_shift_left 
 src->b_item_order 
 it is used in leaf_shift_right 
 it is used in balance_leaf_when_delete 
 it is used in balance_leaf_when_delete 
  copy mov_num items and mov_bytes of the (mov_num-1)th item to
  neighbor. Delete them from source
  Shift shift_num items (and shift_bytes of last shifted item if
  shift_bytes != -1) from S[0] to L[0] and replace the delimiting key
	
	  move shift_num (and shift_bytes bytes) items from S[0]
	  to left neighbor L[0]
 number of items in S[0] == 0 
 replace lkey in CFL[0] by 0-th key from S[0]; 
 CLEANING STOPPED HERE 
  Shift shift_num (shift_bytes) items from S[0] to the right neighbor,
  and replace the delimiting key
	
	  move shift_num (and shift_bytes) items from S[0] to
	  right neighbor R[0]
 replace rkey in CFR[0] by the 0-th key from R[0] 
  If del_bytes == -1, starting from position 'first' delete del_num
  items in whole in buffer CUR.
    If not.
    If last_first == 0. Starting from position 'first' delete del_num-1
    items in whole. Delete part of body of the first item. Part defined by
    del_bytes. Don't delete first item header
    If last_first == 1. Starting from position 'first+1' delete del_num-1
    items in whole. Delete part of body of the last item . Part defined by
    del_bytes. Don't delete last item header.
 delete del_num items beginning from item in position first 
			
			  delete del_num-1 items beginning from
			  item in position first
			
			  delete the part of the first item of the bh
			  do not delete item header
			
			  delete del_num-1 items beginning from
			  item in position first+1
 the last item is directory  
				
				  len = numbers of directory entries
				  in this item
 len = body len of item 
			
			  delete the part of the last item of the bh
			  do not delete item header
 insert item into the leaf node in position before 
 check free space 
 get item new item must be inserted before 
 prepare space for the body of new item 
 copy body to prepared space 
 insert item header 
 change locations 
 sizes, free space, item number 
  paste paste_size bytes to affected_item_num-th item.
  When item is a directory, this only prepare space for new entries
 check free space 
 CONFIG_REISERFS_CHECK 
 item to be appended 
 prepare space 
 change locations 
 shift data to right 
 paste data in the head of item 
 change free space 
  cuts DEL_COUNT entries beginning from FROM-th entry. Directory item
  does not have free space, so it moves DEHs and remaining records as
  necessary. Return value is size of removed part of directory item
  in bytes.
 offset of record, that is (from-1)th 
 length of all removed records 
	
	  make sure that item is directory and there are enough entries to
	  remove
 first byte of item 
 entry head array 
	
	  first byte of remaining entries, those are BEFORE cut entries
	  (prev_record) and length of all removed records (cut_records_len)
from_record   -
 adjust locations of remaining entries 
 shift entry head array and entries those are AFTER removed entries 
 shift records, those are BEFORE removed entries 
  when cut item is part of regular file
       pos_in_item - first byte that must be cut
       cut_size - number of bytes to be cut beginning from pos_in_item
  when cut item is part of directory
       pos_in_item - number of first deleted entry
       cut_size - count of deleted entries
 item head of truncated item 
 first cut entry () 
 change key 
 change item key by key of first entry in the item 
 item is direct or indirect 
 shift item body to left if cut is from the head of item 
 change key of item 
 location of the last item 
 location of the item, which is remaining at the same place 
 shift 
 change item length 
 change locations 
 size, free space 
 delete del_num items from buffer starting from the first'th item 
 this does not work 
 location of unmovable item 
 delete items 
 delete item headers 
 change item location 
 sizes, item number 
  paste new_entry_count entries (new_dehs, records) into position
  before to item_num-th item
	
	  make sure, that item is directory, and there are enough
	  records in it
 first byte of dest item 
 entry head array 
 new records will be pasted at this point 
 adjust locations of records that will be AFTER new records 
 adjust locations of records that will be BEFORE new records 
 prepare space for pasted records 
 copy new records 
 prepare space for new entry heads 
 copy new entry heads 
 set locations of new records 
 change item key if necessary (when we paste before 0-th entry 
 check record locations 
 -- linux-c -- 
 fsreiserfsprocfs.c 
  Copyright 2000 by Hans Reiser, licensing governed by reiserfsREADME
 proc info support a la one created by Sizif@Botik.RU for PGC 
  LOCKING:
  These guys are evicted from procfs as the very first step in ->kill_sb().
 on-disk fields 
 incore fields 
 reiserfs_proc_info_data_t.journal fields 
 Some block devices use 's 
 Some block devices use 's 
  Revision 1.1.8.2  20010715 17:08:42  god
   . use get_super() in procfs.c
   . remove remove_save_link() from reiserfs_do_truncate()
  I accept terms and conditions stated in the Legal Agreement
  (available at http:www.namesys.comlegalese.html)
  Revision 1.1.8.1  20010711 16:48:50  god
  proc info support
  I accept terms and conditions stated in the Legal Agreement
  (available at http:www.namesys.comlegalese.html)
 SPDX-License-Identifier: GPL-2.0-or-later
 CacheFiles path walking and related routines
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  dump debugging info about an object
  dump debugging info about a pair of objects
  mark the owner of a dentry, if there is one, to indicate that that dentry
  has been preemptively deleted
  - the caller must hold the i_mutex on the dentry's parent as required to
    call vfs_unlink(), vfs_rmdir() or vfs_rename()
 found the dentry for  
  record the fact that an object is now active
	 an old object from a previous incarnation is hogging the slot - we
		 if the object we're waiting for is queued for processing,
		 otherwise we sleep until either the object we're waiting for
  Mark an object as being inactive.
	 This object can now be culled, so we need to let the daemon know
	  that there is something it can remove if it needs to.
  delete an object representation from the cache
  - file backed objects are unlinked
  - directory backed objects are stuffed into the graveyard for userspace to
    delete
  - unlocks the directory mutex
 non-directories can just be unlinked 
 directories have to be moved to the graveyard 
 first step is to make up a grave dentry in the graveyard 
 do the multiway lock magic 
 do some checks before getting the grave dentry 
		 the entry was probably culled when we dropped the parent dir
 target should not be an ancestor of source 
 attempt the rename 
  delete an object representation from the cache
		 object allocation for the same key preemptively deleted this
		 we need to check that our parent is _still_ our parent - it
			 it got moved, presumably by cachefilesd culling it,
			  so it's no longer in the key path and we can ignore
  walk from the parent object to the child object through the backing
  filesystem, creating directories as we go
 TODO: convert file to dir
 attempt to transit the first directory component 
 key ends in a double NUL 
 search the current directory for the element name 
	 if this element of the path doesn't exist, then the lookup phase
	  failed, and we can release any readers in the certain knowledge that
 we need to create the object if it's negative 
 index objects and intervening tree levels must be subdirs 
 non-index objects start out life as files 
 process the next component 
 we've found the object we were looking for 
	 if we've found that the terminal object exists, then we need to
			 delete the object (the deleter drops the directory
 note that we're now using this object 
 attach data to a newly constructed terminal object 
		 always update the atime on an object we've just looked up
		  (this is used to keep track of culling, and atimes are only
		  updated by read, write and readdir but not lookup or
 open a file interface onto a data file 
 TODO: open file in data-class subdir
  get a subdirectory
 search the current directory for the element name 
 we need to create the subdir if it doesn't exist yet 
 we need to make sure the subdir is a directory 
  find out if an object is in use or not
  - if finds object and it's not in use:
    - returns a pointer to the object and a reference on it
    - returns with the directory locked
_enter(",%pd,%s",
       dir, filename);
 look up the victim 
_debug("victim -> %pd %s",
       victim, d_backing_inode(victim) ? "positive" : "negative");
	 if the object is no longer there then we probably retired the object
	  at the netfs's request whilst the cull was in progress
 check to see if we're using this object 
_leave(" = %pd", victim);
_leave(" = -EBUSY [in use]");
 file or dir now absent - probably retired by netfs 
  cull an object if it's not in use
  - called only by cache manager daemon
	 okay... the victim is not being used so we can cull it
	  - start by marking it as stale
  actually remove the victim (drops the dir mutex) 
 file or dir now absent - probably retired by netfs 
  find out if an object is in use or not
  - called only by cache manager daemon
  - returns -EBUSY or 0 to indicate whether an object is in use or not
_enter(",%pd,%s",
       dir, filename);
_leave(" = 0");
 SPDX-License-Identifier: GPL-2.0-or-later
 kiocb-using readwrite
  Copyright (C) 2021 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  Handle completion of a read from the cache.
  Initiate a read from the cache.
	 If the caller asked us to seek for data before doing the read, then
	  we should do that now.  If we find a gap, we fill it with zeros.
			 The region is beyond the EOF or there's no more data
			  in the region, so clear the rest of the buffer and
			  return success.
		 There's no easy way to restart the syscall since other AIO's
		  may be already running. Just fail this IO with EINTR.
  Handle completion of a write to the cache.
 Tell lockdep we inherited freeze protection from submission thread 
  Initiate a write to the cache.
	 Open-code file_start_write here to grab freeze protection, which
	  will be released by another thread in aio_complete_rw().  Fool
	  lockdep by telling it the lock got released so that it doesn't
	  complain about the held lock when we return to userspace.
		 There's no easy way to restart the syscall since other AIO's
		  may be already running. Just fail this IO with EINTR.
  Prepare a read operation, shortening it to a cacheduncached
  boundary as appropriate.
  Prepare for a write to occur.
 Round to DIO size 
  Clean up an operation.
  Open the cache file when beginning a cache operation.
 SPDX-License-Identifier: GPL-2.0-or-later
 CacheFiles extended attribute management
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  check the type label on an object
  - done using xattrs
 attempt to install a type label directly 
 we succeeded 
 read the current type label 
 check the type is what we're expecting 
  set the state xattr on a cache file
 attempt to install the cache metadata directly 
  update the state xattr on a cache file
 attempt to install the cache metadata directly 
  check the consistency between the backing cache and the FS-Cache cookie
  check the state xattr on a cache file
  - return -ESTALE if the object should be deleted
 read the current type label 
			goto stale;  no attribute - power went off
 check the on-disk object 
 consult the netfs 
 entry okay as is 
 entry requires update 
 entry requires deletion 
 update the current label 
  remove the object's xattr to mark it stale
 SPDX-License-Identifier: GPL-2.0-or-later
 CacheFiles security management
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  determine the security context within which we access the cache from within
  the kernel
  see if mkdir and create can be performed in the root directory
  check the security details of the on-disk cache
  - must be called with security override in force
  - must return with a security override in force - even in the case of an
    error
	 duplicate the cache creds for COW (the override is currently in
	 use the cache root dir's security context as the basis with
 SPDX-License-Identifier: GPL-2.0-or-later
 Key to pathname encoder
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
 0 - 9 
 10 - 35 
 36 - 61 
 62 - 63 
 we skip space and tab and control chars 
 '!' -> '.' 
 we skip '' as it's significant to pathwalk 
 '0' -> '~' 
  turn the raw key into something cooked
  - the raw key should include the length in the two bytes at the front
  - the key may be up to 514 bytes in length (including the length word)
    - "base64" encode the strange keys, mapping 3 bytes of raw to four of
      cooked
    - need to cut the cooked key into 252 char lengths (189 raw bytes)
 if the path is usable ASCII, then we render it directly 
 two base64'd length chars on the front 
 @checksumM 
		max += 3  2;	 maximum number of segment dividers ("...M")
				  is ((514 + 251)  252) = 3
 NUL on end 
 calculate the maximum length of the cooked key 
 @checksumM 
		max += 3  2;	 maximum number of segment dividers ("...M")
				  is ((514 + 188)  189) = 3
 NUL on end 
 2nd NUL on end 
 build the cooked key 
 SPDX-License-Identifier: GPL-2.0-or-later
 Bind and unbind a cache from the filesystem backing it
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  bind a directory as a cache
 start by checking things over 
 don't permit already bound caches to be re-bound 
 make sure we have copies of the tag and dirname strings 
		 the tag string is released by the fops->release()
 add the cache 
  add a cache
 we want to work under the module's security ID 
 allocate the root index object 
 look up the directory at the root of the cache 
 check parameters 
	 determine the security of the on-disk cache as this governs
 get the cache size and blocksize 
 set up caching limits 
 get the cache directory and check its type 
 get the graveyard directory 
 publish the cache 
 done 
 check how much space the cache has 
  unbind a cache on fd release
 SPDX-License-Identifier: GPL-2.0-or-later
 Storage object readwrite
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  detect wake up events generated by the unlocking of pages in which we're
  interested
  - we use this to detect read completion of backing pages
  - the caller holds the waitqueue lock
 unlocked, not uptodate and not erronous? 
 remove from the waitqueue 
 move onto the action list and queue for FS-Cache thread pool 
	 We need to temporarily bump the usage count as we don't own a ref
	  here otherwise cachefiles_read_copier() may free the op between the
	  monitor being enqueued on the op->to_do list and the op getting
	  enqueued on the work queue.
  handle a probably truncated page
  - check to see if the page is still relevant and reissue the read if
    possible
  - return -EIO on error, -ENODATA if the page is gone, -EINPROGRESS if we
    must wait again and 0 if successful
 skip if the page was truncated away completely 
	 the page is still there and we already have a ref on it, so we don't
	 but the page may have been read before the monitor was installed, so
	  the monitor may miss the event - so we have to ensure that we do get
 it'll reappear on the todo list 
  copy data from backing pages to netfs pages to complete a read operation
  - driven by FS-Cache's thread pool
 the page has probably been truncated 
 let the thread pool have some air occasionally 
  read the corresponding page to the given set from the backing file
  - an uncertain page is simply discarded, to be tried again another time
 attempt to get hold of the backing page 
	 we've installed a new backing page, so now we need to start
 set the monitor to transfer the data across 
 install the monitor 
	 but the page may have been read before the monitor was installed, so
	  the monitor may miss the event - so we have to ensure that we do get
	 if the backing page is already present, it can be in one of
	 the backing page is already up to date, attach the netfs
  read a page from the cache or allocate a block in which to store it
  - cache withdrawal is prevented by the caller
  - returns -EINTR if interrupted
  - returns -ENOMEM if ran out of memory
  - returns -ENOBUFS if no buffers can be made available
  - returns -ENOBUFS if page is beyond EOF
  - if the page is backed by a block in the cache:
    - a read will be started which will call the callback on completion
    - 0 will be returned
  - else if the page is unbacked:
    - the metadata will be retained
    - -ENODATA will be returned
 calculate the shift required to use bmap 
	 we assume the absence or presence of the first block is a good
	  enough indication for the page as a whole
	  - TODO: don't use bmap() for this as it is _not_ actually good
	    enough for this as it doesn't indicate errors, but it's all we've
	    got for the moment
		 submit the apparently valid page to the backing fs to be
 there's space in the cache we can use 
  read the corresponding pages to the given set from the backing file
  - any uncertain pages are simply discarded, to be tried again another time
		 we've installed a new backing page, so now we need
		 add the netfs page to the pagecache and LRU, and set the
 install a monitor 
		 but the page may have been read before the monitor was
		  installed, so the monitor may miss the event - so we have to
		 if the backing page is already present, it can be in one of
		 we've locked a page that's neither up to date nor erroneous,
		 the backing page is already up to date, attach the netfs
 the netpage is unlocked and marked up to date here 
 tidy up 
  read a list of pages from the cache or allocate blocks in which to store
  them
 calculate the shift required to use bmap 
		 we assume the absence or presence of the first block is a
		  good enough indication for the page as a whole
		  - TODO: don't use bmap() for this as it is _not_ actually
		    good enough for this as it doesn't indicate errors, but
		    it's all we've got for the moment
			 we have data - add it to the list to give to the
	 submit the apparently valid pages to the backing fs to be read from
  allocate a block in the cache in which to store a page
  - cache withdrawal is prevented by the caller
  - returns -EINTR if interrupted
  - returns -ENOMEM if ran out of memory
  - returns -ENOBUFS if no buffers can be made available
  - returns -ENOBUFS if page is beyond EOF
  - otherwise:
    - the metadata will be retained
    - 0 will be returned
  allocate blocks in the cache in which to store a set of pages
  - cache withdrawal is prevented by the caller
  - returns -EINTR if interrupted
  - returns -ENOMEM if ran out of memory
  - returns -ENOBUFS if some buffers couldn't be made available
  - returns -ENOBUFS if some pages are beyond EOF
  - otherwise:
    - -ENODATA will be returned
  - metadata will be retained for any page marked
  request a page be stored in the cache
  - cache withdrawal is prevented by the caller
  - this request may be ignored if there's no cache block available, in which
    case -ENOBUFS will be returned
  - if the op is in progress, 0 will be returned
	 We mustn't write more data than we have, so we have to beware of a
	  partial page at EOF.
	 write the page to the backing filesystem and let it store it in its
  detach a backing block from a page
  - cache withdrawal is prevented by the caller
 SPDX-License-Identifier: GPL-2.0-or-later
 Daemon interface
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  do various checks
 only the superuser may do this 
 the cachefiles device may only be open once at a time 
 allocate a cache record 
	 set default caching limits
	  - limit at 1% free space andor free files
	  - cull below 5% free space andor free files
	  - cease culling above 7% free space andor free files
  release a cache
 clean up the control file interface 
  read the cache state
_enter(",,%zu,", buflen);
 check how much space the cache has 
 summarise 
  command the cache
_enter(",,%zu,", datalen);
 drag the command string into the kernel so we can parse it 
 strip any newline 
 parse the command 
 run the appropriate command handler 
_leave(" = %zd", ret);
  poll for culling state
  - use EPOLLOUT to indicate culling state
  give a range error for cache space constraints
  - can be tail-called
  set the percentage of files at which to stop culling
  - command: "frun <N>%"
  set the percentage of files at which to start culling
  - command: "fcull <N>%"
  set the percentage of files at which to stop allocating
  - command: "fstop <N>%"
  set the percentage of blocks at which to stop culling
  - command: "brun <N>%"
  set the percentage of blocks at which to start culling
  - command: "bcull <N>%"
  set the percentage of blocks at which to stop allocating
  - command: "bstop <N>%"
  set the cache directory
  - command: "dir <name>"
  set the cache security context
  - command: "secctx <ctx>"
  set the cache tag
  - command: "tag <name>"
  request a node in the cache be culled from the current working directory
  - command: "cull <name>"
 extract the directory dentry from the cwd 
  set debugging mode
  - command: "debug <mask>"
  find out whether an object in the current working directory is in use or not
  - command: "inuse <name>"
_enter(",%s", args);
 extract the directory dentry from the cwd 
_leave(" = %d", ret);
  see if we have space for a number of pages andor a number of files in the
  cache
_enter("{%llu,%llu,%llu,%llu,%llu,%llu},%u,%u",
       (unsigned long long) cache->frun,
       (unsigned long long) cache->fcull,
       (unsigned long long) cache->fstop,
       (unsigned long long) cache->brun,
       (unsigned long long) cache->bcull,
       (unsigned long long) cache->bstop,
       fnr, bnr);
 find out how many pages of blockdev are available 
_debug("avail %llu,%llu",
       (unsigned long long) stats.f_ffree,
       (unsigned long long) stats.f_bavail);
 see if there is sufficient space 
_leave(" = 0");
 SPDX-License-Identifier: GPL-2.0-or-later
 FS-Cache interface to CacheFiles
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
 auxiliary data 
 key path 
  allocate an object record for a cookie lookup and prepare the lookup data
 create a new object record and a temporary leaf image 
	 get hold of the raw key
	  - stick the length on the front and leave space on the back for the
	    encoder
 turn the raw key into something that can work with as a filename 
 get hold of the auxiliary data and prepend the object type 
  attempt to look up the nominated node in this cache
  - return -ETIMEDOUT to be scheduled again
 look up the key, creating any missing bits 
 polish off by setting the attributes of non-index files 
  indication of lookup completion
  increment the usage count on an inode object (may fail if unmounting)
  update the auxiliary data for an object object on disk
  discard the resources pinned by an object and effect retirement if
  requested
	 We need to tidy the object up if we did in fact manage to open it.
	  It's possible for us to get here before the object is fully
	  initialised if the parent goes away or the object gets retired
	  before we set it up.
 delete retired objects 
 close the filesystem stuff attached to the object 
 note that the object is now inactive 
  dispose of a reference to an object
  sync a cache
	 make sure all pages pinned by operations on behalf of the netfs are
  check if the backing cache is updated to FS-Cache
  - called by FS-Cache when evaluates if need to invalidate the cache
  notification the attributes on an object have changed
  - called with readswrites excluded by FS-Cache
	 if there's an extension to a partial page at the end of the backing
	  file, we need to discard the partial page so that we pick up new
  Invalidate an object
  dissociate a cache from all the pages it was backing
 SPDX-License-Identifier: GPL-2.0-or-later
 Network filesystem caching backend to use cache files on a premounted
  filesystem
  Copyright (C) 2007 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  initialise the fs caching module
 create an object jar 
  clean up on module removal
 SPDX-License-Identifier: GPL-2.0
  Implementation of the diskquota system for the LINUX operating system. QUOTA
  is implemented using the BSD system call interface as the means of
  communication with the user level. This file contains the generic routines
  called by the different filesystems on allocation of an inode or block.
  These routines take care of the administration needed to have a consistent
  diskquota tracking system. The ideas of both user and group quotas are based
  on the Melbourne quota system as used on BSD derived systems. The internal
  implementation is based on one of the several variants of the LINUX
  inode-subsystem with added complexity of the diskquota system.
  Author:	Marco van Wieringen <mvw@planets.elm.net>
  Fixes:   Dmitry Gorodchanin <pgmdsg@ibi.com>, 11 Feb 96
 		Revised list management to avoid races
 		-- Bill Hawes, <whawes@star.net>, 998
 		Fixed races in dquot_transfer(), dqget() and dquot_alloc_...().
 		As the consequence the locking was moved from dquot_decr_...(),
 		dquot_incr_...() to calling functions.
 		invalidate_dquots() now writes modified dquots.
 		Serialized quota_off() and quota_on() for mount point.
 		Fixed a few bugs in grow_dquots().
 		Fixed deadlock in write_dquot() - we no longer account quotas on
 		quota files
 		remove_dquot_ref() moved to inode.c - it now traverses through inodes
 		add_dquot_ref() restarts after blocking
 		Added check for bogus uid and fixed check for group in quotactl.
 		Jan Kara, <jack@suse.cz>, sponsored by SuSE CR, 10-1199
 		Used struct list_head instead of own list struct
 		Invalidation of referenced dquots is no longer possible
 		Improved free_dquots list management
 		Quota and i_blocks are now updated in one place to avoid races
 		Warnings are now delayed so we won't block in critical section
 		Write updated not to require dquot lock
 		Jan Kara, <jack@suse.cz>, 92000
 		Added dynamic quota structure allocation
 		Jan Kara <jack@suse.cz> 122000
 		Rewritten quota interface. Implemented new quota format and
 		formats registering.
 		Jan Kara, <jack@suse.cz>, 2001,2002
 		New SMP locking.
 		Jan Kara, <jack@suse.cz>, 102002
 		Added journalled quota support, fix lock inversion problems
 		Jan Kara, <jack@suse.cz>, 2003,2004
  (C) Copyright 1994 - 1997 Marco van Wieringen
 ugh 
  There are five quota SMP locks:
   dq_list_lock protects all lists with quotas and quota formats.
   dquot->dq_dqb_lock protects data from dq_dqb
   inode->i_lock protects inode->i_blocks, i_bytes and also guards
    consistency of dquot->dq_dqb with inode->i_blocks, i_bytes so that
    dquot_transfer() can stabilize amount it transfers
   dq_data_lock protects mem_dqinfo structures and modifications of dquot
    pointers in the inode
   dq_state_lock protects modifications of quota state (on quotaon and
    quotaoff) and readers who care about latest values take it as well.
  The spinlock ordering is hence:
    dq_data_lock > dq_list_lock > i_lock > dquot->dq_dqb_lock,
    dq_list_lock > dq_state_lock
  Note that some things (eg. sb pointer, type, id) doesn't change during
  the life of the dquot structure and so needn't to be protected by a lock
  Operation accessing dquots via inode pointers are protected by dquot_srcu.
  Operation of reading pointer needs srcu_read_lock(&dquot_srcu), and
  synchronize_srcu(&dquot_srcu) is called after clearing pointers from
  inode and before dropping dquot references to avoid use of dquots after
  they are freed. dq_data_lock is used to serialize the pointer setting and
  clearing operations.
  Special care needs to be taken about S_NOQUOTA inode flag (marking that
  inode is a quota file). Functions adding pointers from inode to dquots have
  to check this flag under dq_data_lock and then (if S_NOQUOTA is not set) they
  have to do all pointer modifications before dropping dq_data_lock. This makes
  sure they cannot race with quotaon which first sets S_NOQUOTA flag and
  then drops all pointers to dquots from an inode.
  Each dquot has its dq_lock mutex.  Dquot is locked when it is being read to
  memory (or space for it is being allocated) on the first dqget(), when it is
  being written out, and when it is being released on the last dqput(). The
  allocation and release operations are serialized by the dq_lock and by
  checking the use count in dquot_release().
  Lock ordering (including related VFS locks) is the following:
    s_umount > i_mutex > journal_lock > dquot->dq_lock > dqio_sem
 List of registered formats 
 SLAB cache for dquot structures 
  Dquot List Management:
  The quota code uses four lists for dquot management: the inuse_list,
  free_dquots, dqi_dirty_list, and dquot_hash[] array. A single dquot
  structure may be on some of those lists, depending on its current state.
  All dquots are placed to the end of inuse_list when first created, and this
  list is used for invalidate operation, which must look at every dquot.
  Unused dquots (dq_count == 0) are added to the free_dquots list when freed,
  and this list is searched whenever we need an available dquot.  Dquots are
  removed from the list as soon as they are used again, and
  dqstats.free_dquots gives the number of dquots on the list. When
  dquot is invalidated it's completely released from memory.
  Dirty dquots are added to the dqi_dirty_list of quota_info when mark
  dirtied, and this list is searched when writing dirty dquots back to
  quota file. Note that some filesystems do dirty dquot tracking on their
  own (e.g. in a journal) and thus don't use dqi_dirty_list.
  Dquots with a specific identity (device, type and id) are placed on
  one of the dquot_hash[] hash chains. The provides an efficient search
  mechanism to locate a specific dquot.
  Following list functions expect dq_list_lock to be held
 Add a dquot to the tail of the free list 
	 We add to the back of inuse list so we don't have to restart
  End of list functions needing dq_list_lock
 Mark dquot dirty in atomic manner, and return it's old dirty flag state 
 If quota is dirty already, we don't have to acquire dq_list_lock 
 Dirtify all the dquots - this can block when journalling 
 Even in case of error we have to continue 
 	Read dquot from disk and alloc space for it
 Make sure flags update is visible after dquot has been filled 
 Instantiate dquot if needed 
 Write the info if needed 
	
	  Make sure flags update is visible after on-disk struct has been
	  allocated. Paired with smp_rmb() in dqget().
 	Write dquot to disk
	 Inactive dquot can be only if there was error during readinit
 	Release dquot
 Check whether we are not racing with some other dqget() 
 Write the info 
 Invalidate all dquots on the list. Note that this function is called after
  quota is disabled and pointers from inodes removed so there cannot be new
  quota users. There can still be some users of quotas due to inodes being
  just deleted or pruned by prune_icache() (those are not attached to any
  list) or parallel quotactl call. We have to wait for such users.
 Wait for dquot users 
			
			  Once dqput() wakes us up, we know it's time to free
			  the dquot.
			  IMPORTANT: we rely on the fact that there is always
			  at most one process waiting for dquot to free.
			  Otherwise dq_count would be > 1 and we would never
			  wake up.
			 At this moment dquot() need not exist (it could be
			  reclaimed by prune_dqcache(). Hence we must
		
		  Quota now has no users and it has been written on last
		  dqput()
 Call callback for every active dquot on given filesystem 
 Now we have active dquot so we can just increase use count 
		
		  ->release_dquot() can be racing with us. Our reference
		  protects us from new calls to it so just wait for any
		  outstanding call and recheck the DQ_ACTIVE_B after that.
		 We are safe to continue now because our dquot could not
 Write all dquot structures to quota files 
 Move list away to avoid livelock. 
			 Now we have active dquot from which someone is
 			  holding reference so we can safely just increase
				
				  Clear dirty bit anyway to avoid infinite
				  loop here.
 Write all dquot structures to disk and make them visible from userspace 
	 This is not very clever (and fast) but currently I don't know about
	  any other simple way of getting quota data to disk and we must get
	
	  Now when everything is written we can discard the pagecache so
	  that userspace sees the changes.
  Put reference to dquot
 We have more than one user... nothing to do 
 Releasing dquot during quotaoff phase? 
 Need to release dquot? 
 Commit dquot before releasing 
			
			  We clear dirty bit anyway, so that we avoid
			  infinite loop here
 sanity check 
  Get reference to dquot
  Locking is slightly tricky here. We are guarded from parallel quotaoff()
  destroying our dquot by:
    a) checking for quota flags under dq_list_lock and
    b) getting a reference to dquot before we release dq_list_lock
 Try to wait for a moment... 
 all dquots go on the inuse_list 
 hash it first so it can be found 
	 Wait for dq_lock - after this we know that either dquot_release() is
 Read the dquot  allocate space in quota file 
	
	  Make sure following reads see filled structure - paired with
	  smp_mb__before_atomic() in dquot_acquire().
 Has somebody invalidated entry under us? 
 This routine is guarded by s_umount semaphore 
		
		  We hold a reference to 'inode' so it couldn't have been
		  removed from s_inodes list while we dropped the
		  s_inode_list_lock. We cannot iput the inode now as we can be
		  holding the last reference and we cannot iput it under
		  s_inode_list_lock. So we keep the reference and iput it
		  later.
  Remove references to dquots from inode and add dquot to list for freeing
  if we have the last reference to dquot
		
		  The inode still has reference to dquot so it can't be in the
		  free list
		
		  Dquot is already in a list to put so we won't drop the last
		  reference here.
  Free list of dquots
  Dquots are removed from inodes and no new references can be got so we are
  the only ones holding reference
 Remove dquot from the list so we won't have problems... 
		
		   We have to scan also I_NEW inodes because they can already
		   have quota pointer initialized. Luckily, we need to touch
		   only quota pointers and these have separate locking
		   (dq_data_lock).
 Gather all references from inodes and drop them 
 Print warning to user which exceeded quota 
  Write warnings to the console and send warning messages over netlink.
  Note that this function can call into tty and networking code.
			
			  We don't allow preallocation to exceed softlimit so exceeding will
			  be always printed
	
	  We have to be careful and go through warning generation & grace time
	  setting even if DQUOT_SPACE_NOFAIL is set. That's why we check it
	  only here...
  Initialize quota pointers in inode
  It is better to call this function outside of any transaction as it
  might need a lot of space in journal for dquot structure allocation.
 First get references to structures we might need. 
		
		  The i_dquot should have been initialized in most cases,
		  we check it without locking here to avoid unnecessary
		  dqget()dqput() calls.
 We raced with somebody turning quotas off... 
 All required i_dquot has been initialized 
 Avoid races with quotaoff() 
 We could race with quotaon or dqget() could have failed 
			
			  Make quota reservation system happy if someone
			  did a write before quota was turned on
 Get reservation again under proper lock 
 Drop unused references 
  Release all quotas referenced by inode.
  This function only be called on inode free or converting
  a file to quota file, no other users for the i_dquot in
  both cases, so we needn't call synchronize_srcu() after
  clearing i_dquot.
	
	  Test before calling to rule out calls from proc and such
	  where we are not allowed to block. Note that this is
	  actually reliable test even without the lock - the caller
	  must assure that nobody can come after the DQUOT_DROP and
	  add quota pointers back anyway.
  inode_reserved_space is managed internally by quota, and protected by
  i_lock similar to i_blocks+i_bytes.
	 Filesystem must explicitly define it's own method in order to use
  This functions updates i_blocks+i_bytes fields and quota information
  (together with appropriate checks).
  NOTE: We absolutely rely on the fact that caller dirties the inode
  (usually helpers in quotaops.h care about this) and holds a handle for
  the current transaction so that dquot write and inode write go into the
  same transaction.
  This operation can block, but only after everything is updated
 Back out changes we already did 
  This operation can block, but only after everything is updated
 Back out changes we already did 
  Convert in-memory reserved quotas to real consumed quotas
 Claim reserved quotas to allocated quotas 
 Update inode bytes 
  Convert allocated space back to in-memory reserved quotas
 Claim reserved quotas to allocated quotas 
 Update inode bytes 
  This operation can block, but only after everything is updated
  This operation can block, but only after everything is updated
  Transfer the number of inode and blocks from one diskquota to an other.
  On success, dquot references in transfer_to are consumed and references
  to original dquots that need to be released are placed there. On failure,
  references are kept untouched.
  This operation can block, but only after everything is updated
  A transaction must be started when entering this function.
  We are holding reference on transfer_from & transfer_to, no need to
  protect them by srcu_read_lock().
 Initialize the arrays 
 File without quota accounting? 
	
	  Build the transfer_from list, check limits, and update usage in
	  the target structures.
		
		  Skip changes for same uid or gid or for turned off quota-type.
 Avoid races with quotaoff() 
 Decrease usage for source structures and update quota pointers 
 Due to IO error we might not have transfer_from[] structure 
 Pass back references to put 
 Back out changes we already did 
 Wrapper for transferring ownership of an inode for uidgid only
  Called from FSXXX_setattr()
  Write info of quota file to disk
  Definitions of diskquota operations.
  Generic helper for ->open on filesystems supporting disk quotas.
  Turn quota off on a device. type == -1 ==> quotaoff for all types (umount)
 s_umount should be held in exclusive mode 
	 Cannot turn off usage accounting without turning off limits, or
	
	  Skip everything if there's nothing to do. We have to do this because
	  sometimes we are called when fill_super() failed and calling
	  sync_fs() in such cases does no good.
 Turning off suspended quotas? 
 We still have to keep quota loaded? 
 Note: these are blocking operations 
		
		  Now all dquots should be invalidated, all writes done so we
		  should be only users of the info. No locks needed.
 Skip syncing and setting flags if quota files are hidden 
	 Sync the superblock so that buffers with quota data are written to
	 Now the quota files are just ordinary files and we can set the
	  inode flags back. Moreover we discard the pagecache so that
	  userspace sees the writes we did bypassing the pagecache. We
	  must also discard the blockdev buffers so that we see the
 We are done when suspending quotas 
 	Turn quotas on on a device
		 We don't want quota and atime on quota files (deadlocks
		  possible) Also nobody should write to the file - we use
		
		  When S_NOQUOTA is set, remove dquot references as no more
		  references can be added
 Just unsuspend quotas? 
 s_umount should be held in exclusive mode 
 Filesystems outside of init_user_ns not yet supported 
 Usage always has to be set... 
		 As we bypass the pagecache we must now flush all the
		  dirty data and invalidate caches so that kernel sees
		  changes from userspace. It is not enough to just flush
		  the quota file since if blocksize < pagesize, invalidation
		  of the cache could fail because of other unrelated dirty
  More powerful function for turning on quotas on given quota inode allowing
  setting of individual quota flags
 Reenable quotas on remount RW 
 s_umount should be held in exclusive mode 
 Quota file not on the same filesystem? 
  This function is used when filesystem needs to initialize quotas
  during mount time.
 Accounting cannot be turned on while fs is mounted 
 Can't enforce without accounting 
 Backout enforcement enablement we already did 
 Error code translation for better compatibility with XFS 
	
	  We don't support turning off accounting via quotactl. In principle
	  quota infrastructure can do this but filesystems don't expect
	  userspace to be able to do it.
 Filter out limits not enabled 
 Nothing left? 
 Backout enforcement disabling we already did 
 Generic routine for getting common part of quota structure 
 Generic routine for setting common part of quota structure 
 Set grace only if user hasn't provided his own... 
 Set grace only if user hasn't provided his own... 
 Generic routine for getting common part of quota file information 
 We don't know... 
 Generic routine for setting common part of quota file information 
 Force write to disk 
 Filter negative values for non-monotonic counters 
 Update global table 
 Find power-of-two hlist_heads which can fit into allocation 
 SPDX-License-Identifier: GPL-2.0-only
 Set structure to 0s in case read failsis after end of file 
 Magics of new quota format 
 USRQUOTA \
 GRPQUOTA \
 Header of new quota format 
 Magic number identifying file 
 File version 
	 Doublecheck whether we didn't get file with new format - with old
 Probably not new format 
 Definitely not new format 
 Seems like a new format file -> refuse it 
 limits are stored as unsigned 32-bit data 
 SPDX-License-Identifier: GPL-2.0
  Quota code necessary even when VFS quota support is not compiled
  into the kernel.  The interesting stuff is over in dquot.c, here
  we have symbols for initial quotactl(2) handling, the sysctl(2)
  variables, etc - things needed even when quota support disabled.
 these commands do not require any special privilegues 
 allow to query information for dquots we "own" 
  Return quota for next active quota >= this id, if any exists,
  otherwise return -ENOENT via ->get_nextdqblk
 struct if_nextdqblk is a superset of struct if_dqblk 
 No quota enabled? 
 Inodes may be allocated even if inactive; copy out if present 
		
		  Q_XGETQSTAT doesn't have room for both group and project
		  quotas.  So, allow the project quota values to be copied out
		  only if there is no group quota information available.
 No quota enabled? 
 Inodes may be allocated even if inactive; copy out if present 
 Just read qs_version 
 If this kernel doesn't support user specified version, fail 
  XFS defines BBTOB and BTOBB macros inside fsxfs and we cannot move them
  out of there as xfsprogs rely on definitions being in that header file. So
  just define same functions here for quota purposes.
 Are we actually setting timer  warning limits for all users? 
 These are already done 
  Return quota for next active quota >= this id, if any exists,
  otherwise return -ENOENT via ->get_nextdqblk.
 Copy parameters and call proper function 
	
	  Quota not supported on this fs? Check this before s_quota_types
	  since they needn't be set if quota is not supported at all.
 XFS quotas are fully coherent now, making this call a noop 
 Return 1 if 'cmd' will block on frozen filesystem 
	
	  We cannot allow Q_GETQUOTA and Q_GETNEXTQUOTA without write access
	  as dquot_acquire() may allocate space for new structure and OCFS2
	  needs to increment on-disk use count.
 Return true if quotactl command is manipulating quota onoff state 
  look up a superblock on which quota ops will be performed
  - use the name of a block device to find the superblock thereon
  This is the system call interface. This communicates with
  the user-level programs. Currently this only supports diskquota
  calls. Maybe we need to add the process quotas etc. in the future,
  but we probably should use rlimits for that.
	
	  As a special case Q_SYNC can be called without a specific device.
	  It will iterate all superblocks that have quota enabled and call
	  the sync action on each of them.
	
	  Path for quotaon has to be resolved before grabbing superblock
	  because that gets s_umount sem which is also possibly needed by path
	  resolution (think about autofs) and thus deadlocks could arise.
 SPDX-License-Identifier: GPL-2.0-only
 	vfsv0 quota IO operations on file
 Number of entries in one blocks 
 Remove empty block from list and return it 
 Assure block allocation... 
 Insert empty block to the list 
 Remove given block from the list of blocks with free entries 
 No matter whether write succeeds block is out of list 
 Insert given block to the beginning of list with free entries 
 Is the entry in the block free? 
 Find space for dquot 
		 This is enough as the block is already zeroed and the entry
 Block will be full? 
 Find free structure in block 
 Insert reference to structure into the trie 
 Wrapper for inserting quota structure into tree 
  We don't have to be afraid of deadlocks as we never have quotas on quota
  files...
 dq_off is guarded by dqio_sem 
 Free dquot entry in data block 
 Block got free? 
 Insert will write block itself 
 Quota is now unattached 
 Remove reference to dquot from tree 
 Block got empty? 
 Don't put the root block into the free block list 
 Delete dquot from tree 
 Even not allocated? 
 Find entry in block 
 Find entry for given id in the tree 
 No reference? 
 Find entry for given id in the tree - wrapper function 
 Invalidated quota? 
 Do we know offset of the dquot entry in the quota file? 
 Entry not present? 
 Check whether dquot should not be deleted. We know we are
 SPDX-License-Identifier: GPL-2.0
 Netlink family structure for quota 
  quota_send_warning - Send warning to userspace about exceeded quota
  @qid: The kernel internal quota identifier.
  @dev: The device on which the fs is mounted (sb->s_dev)
  @warntype: The type of the warning: QUOTA_NL_...
  This can be used by filesystems (including those which don't use
  dquot) to send a message to userspace relating to quota limits.
	 We have to allocate using GFP_NOFS as we are called from a
	  filesystem performing write and thus further recursion into
 SPDX-License-Identifier: GPL-2.0-only
 	vfsv0 quota IO operations on file
 Check whether given file is really vfsv0 quotafile 
 Read information header from quota file 
 limits are stored as unsigned 32-bit data 
		
		  Used space is stored as unsigned 64-bit value in bytes but
		  quota core supports only signed 64-bit values so use that
		  as a limit
 2^63-1 
 No flags currently supported 
 Some sanity checks of the read headers... 
 Write information header to quota file 
 No flags currently supported 
 We need to escape back all-zero structure 
 We need to escape back all-zero structure 
	
	  If space for dquot is already allocated, we don't need any
	  protection as we'll only overwrite the place of dquot. We are
	  still protected by concurrent writes of the same dquot by
	  dquot->dq_lock.
 SPDX-License-Identifier: GPL-2.0
 	qid_eq - Test to see if to kquid values are the same
 	@left: A qid value
 	@right: Another quid value
 	Return true if the two qid values are equal and false otherwise.
 	qid_lt - Test to see if one qid value is less than another
 	@left: The possibly lesser qid value
 	@right: The possibly greater qid value
 	Return true if left is less than right and false otherwise.
 	from_kqid - Create a qid from a kqid user-namespace pair.
 	@targ: The user namespace we want a qid in.
 	@kqid: The kernel internal quota identifier to start with.
 	Map @kqid into the user-namespace specified by @targ and
 	return the resulting qid.
 	There is always a mapping into the initial user_namespace.
 	If @kqid has no mapping in @targ (qid_t)-1 is returned.
 	from_kqid_munged - Create a qid from a kqid user-namespace pair.
 	@targ: The user namespace we want a qid in.
 	@kqid: The kernel internal quota identifier to start with.
 	Map @kqid into the user-namespace specified by @targ and
 	return the resulting qid.
 	There is always a mapping into the initial user_namespace.
 	Unlike from_kqid from_kqid_munged never fails and always
 	returns a valid projid.  This makes from_kqid_munged
 	appropriate for use in places where failing to provide
 	a qid_t is not a good option.
 	If @kqid has no mapping in @targ the kqid.type specific
 	overflow identifier is returned.
 	qid_valid - Report if a valid value is stored in a kqid.
 	@qid: The kernel internal quota identifier to test.
 SPDX-License-Identifier: GPL-2.0
  linuxfsufsnamei.c
  Migration to usage of "page cache" on May 2006 by
  Evgeniy Dushistov <dushistov@mail.ru> based on ext2 code base.
  Copyright (C) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
   from
   linuxfsext2namei.c
  Copyright (C) 1992, 1993, 1994, 1995
  Remy Card (card@masi.ibp.fr)
  Laboratoire MASI - Institut Blaise Pascal
  Universite Pierre et Marie Curie (Paris VI)
   from
   linuxfsminixnamei.c
   Copyright (C) 1991, 1992  Linus Torvalds
   Big-endian to little-endian byte-swappingbitmaps by
         David S. Miller (davem@caip.rutgers.edu), 1995
  By the time this is called, we already have created
  the directory cache entry for the new file, but it
  is so far negative - it has no inode.
  If the create succeeds, we fill in the inode information
  with d_instantiate(). 
 slow symlink 
 fast symlink 
	
	  Like most other Unix systems, set the ctime for inodes on a
 	  rename.
 SPDX-License-Identifier: GPL-2.0-only
   linuxfsufssuper.c
  Copyright (C) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
 Derived from
   linuxfsext2super.c
  Copyright (C) 1992, 1993, 1994, 1995
  Remy Card (card@masi.ibp.fr)
  Laboratoire MASI - Institut Blaise Pascal
  Universite Pierre et Marie Curie (Paris VI)
   from
   linuxfsminixinode.c
   Copyright (C) 1991, 1992  Linus Torvalds
   Big-endian to little-endian byte-swappingbitmaps by
         David S. Miller (davem@caip.rutgers.edu), 1995
  Inspired by
   linuxfsufssuper.c
  Copyright (C) 1996
  Adrian Rodriguez (adrian@franklins-tower.rutgers.edu)
  Laboratory for Computer Science Research Computing Facility
  Rutgers, The State University of New Jersey
  Copyright (C) 1996  Eddie C. Dost  (ecd@skynet.be)
  Kernel module support added on 960426 by
  Stefan Reinauer <stepan@home.culture.mipt.ru>
  Module usage counts added on 960429 by
  Gertjan van Wingerde <gwingerde@gmail.com>
  Clean swab support on 19970406 by
  Francois-Rene Rideau <fare@tunes.org>
  4.4BSD (FreeBSD) support added on February 1st 1998 by
  Niels Kristian Bech Jensen <nkbj@image.dk> partially based
  on code by Martin von Loewis <martin@mira.isdn.cs.tu-berlin.de>.
  NeXTstep support added on February 5th 1998 by
  Niels Kristian Bech Jensen <nkbj@image.dk>.
  write support Daniel Pirkl <daniel.pirkl@email.cz> 1998
  HPUX hfs filesystem support added by
  Martin K. Petersen <mkp@mkp.net>, August 1999
  UFS2 (of FreeBSD 5.x) support added by
  Niraj Kumar <niraj17@iitbombay.org>, Jan 2004
  UFS2 write support added by
  Evgeniy Dushistov <dushistov@mail.ru>, 2007
  Print contents of ufs_super_block, useful for debugging
  Print contents of ufs_cylinder_group, useful for debugging
 CONFIG_UFS_DEBUG 
end of possible ufs types 
  Different types of UFS hold fs_cstotal in different
  places, and use different data structure for it.
  To make things simpler we just copy fs_cstotal to ufs_sb_private_info
we have statistic in different place, then usual
  Read on-disk structures associated with cylinder groups
	
	  Read cs structures from (usually) first data block
	  on the device. 
	
	  Read cylinder group (we read only first fragment from block
	  at this time) and prepare internal data structures for cg caching.
  Sync our internal copy of fs_cstotal with disk
we have statistic in different place, then usual
 store stats in both old and new places 
  ufs_put_super_internal() - put on-disk intrenal structures
  @sb: pointer to super_block structure
  Put on-disk structures associated with cylinder groups
  and write them back to disk, also update cs_total on disk
	
	  Set default mount options
	  Parse mount options
 Not supported on disk 
 Not supported on disk 
 Not supported on disk 
	
	  read ufs super block from device
 Sort out mod used on SunOS 4.1.3 for fs_state 
	
	  Check ufs magic number
	
	  Check block and fragment sizes
after that line some functions use s_flags
	
	  Check, if file system was correctly unmounted.
	  If not, make it read only.
	
	  Read ufs_super_block into internal data structures
 s_bsize already set 
 s_fsize already set 
 s_sbsize already set 
	
	  Compute another frequently used values
	
	  Read cylinder group structures
	
	  Allow the "check" option to be passed as a remount option.
	  It is not possible to change ufstype option during remount
	
	  fs was mouted as rw, remounting ro
	
	  fs was mounted as ro, remounting rw
	
	  Make sure all delayed rcu free inodes are flushed before we
	  destroy cache.
 SPDX-License-Identifier: GPL-2.0
   linuxfsufsialloc.c
  Copyright (c) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
   from
   linuxfsext2ialloc.c
  Copyright (C) 1992, 1993, 1994, 1995
  Remy Card (card@masi.ibp.fr)
  Laboratoire MASI - Institut Blaise Pascal
  Universite Pierre et Marie Curie (Paris VI)
   BSD ufs-inspired inode and directory allocation by 
   Stephen Tweedie (sct@dcs.ed.ac.uk), 1993
   Big-endian to little-endian byte-swappingbitmaps by
         David S. Miller (davem@caip.rutgers.edu), 1995
  UFS2 write support added by
  Evgeniy Dushistov <dushistov@mail.ru>, 2007
  NOTE! When we get the inode, we're the only people
  that have access to it, and as such there are no
  race conditions we have to worry about. The inode
  is not on the hash-lists, and it cannot be reached
  through the filesystem because the directory entry
  has been deleted earlier.
  HOWEVER: we must make sure that we get no aliases,
  which means that we have to call "clear_inode()"
  _before_ we mark the inode not in use in the inode
  bitmaps. Otherwise a newly created file might use
  the same inode number (not actually the same pointer
  though), and then we'd have two inodes sharing the
  same inode number and space on the harddisk.
  Nullify new chunk of inodes,
  BSD people also set ui_gen field of inode
  during nullification, but we not care about
  that because of linux ufs do not support NFS
  There are two policies for allocating an inode.  If the new inode is
  a directory, then a forward search is made for a block group with both
  free space and a low directory-to-inode ratio; if that fails, then of
  the groups with above-average free space, that group with the fewest
  directories already is chosen.
  For other inodes, search forward from the parent directory's block
  group to find a free inode.
 Cannot create files in a deleted directory 
	
	  Try to place the inode in its parent directory
	
	  Use a quadratic hash to find a group with a free inode
	
	  That failed: try linear search for a free inode
		
		  setup birth date, we do it here because of there is no sense
		  to hold it in struct ufs_inode_info, and lose 64 bit
 SPDX-License-Identifier: GPL-2.0
   linuxfsufsinode.c
  Copyright (C) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
   from
   linuxfsext2inode.c
  Copyright (C) 1992, 1993, 1994, 1995
  Remy Card (card@masi.ibp.fr)
  Laboratoire MASI - Institut Blaise Pascal
  Universite Pierre et Marie Curie (Paris VI)
   from
   linuxfsminixinode.c
   Copyright (C) 1991, 1992  Linus Torvalds
   Goal-directed block allocation by Stephen Tweedie (sct@dcs.ed.ac.uk), 1993
   Big-endian to little-endian byte-swappingbitmaps by
         David S. Miller (davem@caip.rutgers.edu), 1995
  Returns the location of the fragment from
  the beginning of the filesystem.
  Unpacking tails: we have a file with partial final block and
  we had been asked to extend it.  If the fragment being written
  is within the same block, we need to extend the tail just to cover
  that fragment.  Otherwise the tail is extended to full block.
  Note that we might need to create a _new_ tail, but that will
  be handled elsewhere; this is strictly for resizing old
  ones.
 it's a short file, so unsigned is enough 
  ufs_inode_getfrag() - allocate new fragment(s)
  @inode: pointer to inode
  @index: number of block pointer within the inode's array.
  @new_fragment: number of new allocated fragment(s)
  @err: we set it if something wrong
  @new: we set it if we allocate new block
  @locked_page: for ufs_new_fragments()
         TODO : to be done for write support
        if ( (flags & UFS_TYPE_MASK) == UFS_TYPE_UFS2)
             goto ufs2;
 will that be a new tail? 
      This part : To be implemented ....
        Required only for writing, not required for READ-ONLY.
ufs2:
	u2_block = ufs_fragstoblks(fragment);
	u2_blockoff = ufs_fragnum(fragment);
	p = ufsi->i_u1.u2_i_data + block;
	goal = 0;
repeat2:
	tmp = fs32_to_cpu(sb, p);
	lastfrag = ufsi->i_lastfrag;
  ufs_inode_getblock() - allocate new block
  @inode: pointer to inode
  @ind_block: block number of the indirect block
  @index: number of pointer within the indirect block
  @new_fragment: number of new allocated fragment
   (block will hold this fragment and also uspi->s_fpb-1)
  @err: see ufs_inode_getfrag()
  @new: see ufs_inode_getfrag()
  @locked_page: see ufs_inode_getfrag()
  ufs_getfrag_block() - `get_block_t' function, interface between UFS and
  readpage, writepage and so on
 This code entered only while writing ....? 
	
	  Copy data to the in-core inode.
	
	  Linux now has 32-bit uid and gid, so we can support EFT.
	
	  Copy data to the in-core inode.
          Linux now has 32-bit uid and gid, so we can support EFT.
	
	ufsi->i_shadow = fs32_to_cpu(sb, ufs_inode->ui_u3.ui_sun.ui_shadow);
	ufsi->i_oeftflag = fs32_to_cpu(sb, ufs_inode->ui_u3.ui_sun.ui_oeftflag);
 ufs_inode->ui_u2.ui_addr.ui_db[0] = cpu_to_fs32(sb, inode->i_rdev); 
 ufs_inode->ui_u2.ui_addr.ui_db[0] = cpu_to_fs32(sb, inode->i_rdev); 
	
	  Free first free fragments
	
	  Free whole blocks
	
	  Free last free fragments
	       
		 we do not zeroize fragment, because of
		 if it maped to hole, it already contains zeroes
 get the blocks that should be partially emptied 
 SPDX-License-Identifier: GPL-2.0
   linuxfsufsufs_dir.c
  Copyright (C) 1996
  Adrian Rodriguez (adrian@franklins-tower.rutgers.edu)
  Laboratory for Computer Science Research Computing Facility
  Rutgers, The State University of New Jersey
  swab support by Francois-Rene Rideau <fare@tunes.org> 19970406
  4.4BSD (FreeBSD) support added on February 1st 1998 by
  Niels Kristian Bech Jensen <nkbj@image.dk> partially based
  on code by Martin von Loewis <martin@mira.isdn.cs.tu-berlin.de>.
  Migration to usage of "page cache" on May 2006 by
  Evgeniy Dushistov <dushistov@mail.ru> based on ext2 code base.
  NOTE! unlike strncmp, ufs_match returns 1 for success, 0 for failure.
  len <= UFS_MAXNAMLEN and de != NULL are guaranteed by caller.
 Releases the page 
 Too bad, we had an error 
  Return the offset into page `page_nr' of the last valid
  byte in that page, plus one.
 	ufs_find_entry()
  finds an entry in the specified directory with the wanted name. It
  returns the page in which the entry was found, and the entry itself
  (as a parameter - res_dir). Page is returned mapped and unlocked.
  Entry is guaranteed to be valid.
 OFFSET_CACHE 
 	Parent is locked.
	
	  We take care of directory expansion in the same loop.
	  This code plays outside i_size, so it locks the page
	  to protect that region.
 We hit i_size 
 OFFSET_CACHE 
  This is blatantly stolen from ext2fs
  ufs_delete_entry deletes a directory entry by merging it with the
  previous entry.
  routine to check that the specified directory is empty (for rmdir)
 check for . and .. 
 SPDX-License-Identifier: GPL-2.0
   linuxfsufsballoc.c
  Copyright (C) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
  UFS2 write support Evgeniy Dushistov <dushistov@mail.ru>, 2007
  Free 'count' fragments from fragment number 'fragment'
	
	  Trying to reassemble free fragments into block
  Free 'count' fragments from fragment number 'fragment' (free whole blocks)
  Modify inode page cache in such way:
  have - blocks with b_blocknr equal to oldb...oldb+count-1
  get - blocks with b_blocknr equal to newb...newb+count-1
  also we suppose that oldb...oldb+count-1 blocks
  situated at the end of file.
  We can come here from ufs_writepage or ufs_prepare_write,
  locked_page is argument of these functions, so we already lock it.
 it was truncated 
 or EIO 
	
	  Somebody else has just allocated our fragments
	
	  There is not enough space for user on the device
	
	  allocate new fragment
	
	  resize block
	
	  allocate new block and move data
	
	  Block can be extended
	
	  1. searching on preferred cylinder group
	
	  2. quadratic rehash
	
	  3. brute force search
	  We start at i = 2 ( 0 is checked at 1.step, 1 at 2.step )
	
	  If the requested block is available, use it.
  Find a block of the specified size in the specified cylinder group.
  @sp: pointer to super block
  @ucpi: pointer to cylinder group info
  @goal: near which block we want find new one
  @count: specified size
	
	  Bit patterns for identifying fragments in the block map
	  used as ((map & mask_arr) == want_arr)
	
	  found the byte in the map
	
	  Find the size of the cluster going forward.
	
	  Find the size of the cluster going backward.
	
	  Account for old cluster and the possibly new forward and
	  back clusters.
 SPDX-License-Identifier: GPL-2.0
   linuxfsufscylinder.c
  Copyright (C) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
   ext2 - inode (block) bitmap caching inspired
  Read cylinder group into cache. The memory space for ufs_cg_private_info
  structure is already allocated during ufs_read_super.
	
	  We have already the first fragment of cylinder group block in buffer
  Remove cylinder group from cache, doesn't release memory
  allocated for cylinder group (this is done at ufs_put_super only).
	
	  rotor is not so important data, so we put it to disk 
	  at the end of working with cylinder
  Find cylinder group in cache and return it as pointer.
  If cylinder group is not in cache, we will load it from disk.
  The cache is managed by LRU algorithm. 
	
	  Cylinder group number cg it in cache and it was last used
	
	  Number of cylinder groups is not higher than UFS_MAX_GROUP_LOADED
	
	  Cylinder group number cg is in cache but it was not last used, 
	  we will move to the first position
	
	  Cylinder group number cg is not in cache, we will read it from disk
	  and put it to the first position
 SPDX-License-Identifier: GPL-2.0
   linuxfsufsfile.c
  Copyright (C) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
   from
   linuxfsext2file.c
  Copyright (C) 1992, 1993, 1994, 1995
  Remy Card (card@masi.ibp.fr)
  Laboratoire MASI - Institut Blaise Pascal
  Universite Pierre et Marie Curie (Paris VI)
   from
   linuxfsminixfile.c
   Copyright (C) 1991, 1992  Linus Torvalds
   ext2 fs regular file handling primitives
  We have mostly NULL's here: the current defaults are ok for
  the ufs filesystem.
 SPDX-License-Identifier: GPL-2.0
   linuxfsufsutil.c
  Copyright (C) 1998
  Daniel Pirkl <daniel.pirkl@email.cz>
  Charles University, Faculty of Mathematics and Physics
  ufs_get_locked_page() - locate, pin and lock a pagecache page, if not exist
  read it from disk.
  @mapping: the address_space to search
  @index: the page index
  Locates the desired pagecache page, if not exist we'll read it,
  locks it, increments its reference
  count and returns its address.
 Truncate got there first 
  Compressed rom filesystem for Linux.
  Copyright (C) 1999 Linus Torvalds.
  This file is released under the GPL.
  These are the VFS interfaces to the compressed rom filesystem.
  The actual compression is based on zlib, see the other files.
  cramfs super-block data in memory
 These macros may change in future, to provide better st_ino semantics. 
	
	  The file mode test fixes buggy mkcramfs implementations where
	  cramfs_inode->offset is set to a non zero value for entries
	  which did not contain data, like devices node and fifos.
 if the lower 2 bits are zero, the inode contains data 
 Struct copy intentional 
	 inode->i_nlink is left 1 - arguably wrong for directories,
	   but it's the best we can do without reading the directory
	   contents.  1 yields the right result in GNU find, even
  We have our own block cache: don't fill up the buffer cache
  with the rom-image, because the way the filesystem is set
  up the accesses should be fairly regular and cached in the
  page cache and dentry tree anyway..
  This also acts as a way to guarantee contiguous areas of up to
  BLKS_PER_BUFPAGE_SIZE, so that the caller doesn't need to
  worry about end-of-buffer issues even when decompressing a full
  page cache.
  Note: This is all optimized away at compile time when
        CONFIG_CRAMFS_BLOCKDEV=n.
 NEXT_BUFFER(): Loop over [0..(READ_BUFFERS-1)]. 
  BLKS_PER_BUF_SHIFT should be at least 2 to allow for "compressed"
  data that takes up more space than the original and with unlucky
  alignment.
  Populate our block cache and return a pointer to it.
 Check if an existing buffer already has the data.. 
 Ok, read in BLKS_PER_BUF pages completely first. 
 synchronous error? 
 asynchronous error 
  Return a pointer to the linearly addressed cramfs image in memory.
  Returns a pointer to a buffer containing at least LEN bytes of
  filesystem starting at byte offset OFFSET into the filesystem.
  For a mapping to be possible, we need a range of uncompressed and
  contiguous blocks. Return the offset for the first block and number of
  valid blocks for which that is true, or zero otherwise.
	
	  We can dereference memory directly here as this code may be
	  reached only when there is a direct filesystem image mapping
	  available in memory.
  Return true if the last page of a file in the filesystem image contains
  some other data that doesn't belong to that file. It is assumed that the
  last block is CRAMFS_BLK_FLAG_DIRECT_PTR | CRAMFS_BLK_FLAG_UNCOMPRESSED
  (verified by cramfs_get_block_range() and directly accessible in memory.
	
	  Now try to pre-populate ptes for this vma with a direct
	  mapping avoiding memory allocation when possible.
 Could COW work here? 
 Don't map the last page if it contains some other data 
		
		  The entire vma is mappable. remap_pfn_range() will
		  make it distinguishable from a non-direct mapping
		  in proc<pid>maps by substituting the file offset
		  with the actual physical address.
		
		  Let's create a mixed map if we can't map it all.
		  The normal paging machinery will take care of the
		  unpopulated ptes via cramfs_readpage().
 Didn't manage any direct map, but normal paging is still possible 
 CONFIG_MMU 
 CONFIG_MMU 
 We don't know the real size yet 
 Read the first block and get the superblock from it 
 Do sanity checks on the superblock 
 check for wrong endianness 
 check at 512 byte offset 
 get feature flags first 
 Check that the root inode is in a sane state 
 correct strange, hard-coded permissions of mkcramfs 
 Set it all up.. 
 Invalidate the read buffers on mount: think disk change.. 
 Map only one page for now.  Will remap it when fs size is known. 
 Remap the whole filesystem now 
  Read a cramfs directory entry.
 Offset within the thing. 
 Directory entries are always 4-byte aligned 
		
		  Namelengths on disk are shifted by two
		  and the name padded out to 4-byte boundaries
		  with zeroes.
  Lookup and fill in the inode data..
 Try to take advantage of sorted directories 
 Quick check that the name is roughly the right length 
 else (retval < 0) 
			
			  The block pointer is an absolute start pointer,
			  shifted by 2 bits. The size is included in the
			  first 2 bytes of the data block when compressed,
			  or PAGE_SIZE otherwise.
 if last block: cap to file length 
			
			  The block pointer indicates one past the end of
			  the current block (start of next block). If this
			  is the first block then it starts where the block
			  pointer table ends, otherwise its start comes
			  from the previous block's pointer.
 Beware... previous ptr might be a direct ptr 
 See comments on earlier code. 
 hole 
  Our operations:
  A directory can only readdir
  Set up the filesystem mount context.
 SPDX-License-Identifier: GPL-2.0
  uncompress.c
  (C) Copyright 1999 Linus Torvalds
  cramfs interfaces to the uncompression library. There's really just
  three entrypoints:
   - cramfs_uncompress_init() - called to initialize the thing.
   - cramfs_uncompress_exit() - tell me when you're done
   - cramfs_uncompress_block() - uncompress a block.
  NOTE NOTE NOTE! The uncompression is entirely single-threaded. We
  only have one stream, and we'll initialize it only once even if it
  then is used by multiple filesystems.
 Returns length of decompressed data. 
 file-mmu.c: ramfs MMU-based file operations
  Resizable simple ram filesystem for Linux.
  Copyright (C) 2000 Linus Torvalds.
                2000 Transmeta Corp.
  Usage limits added by David Gibson, Linuxcare Australia.
  This file is released under the GPL.
  NOTE! This filesystem is probably most useful
  not as a real filesystem, but as an example of
  how virtual filesystems can be written.
  It doesn't get much simpler than this. Consider
  that this file implements the full semantics of
  a POSIX-compliant read-write filesystem.
  Note in particular how the filesystem does not
  need to implement any data structures of its own
  to keep track of the virtual data: using the VFS
  caches is sufficient.
  Resizable simple ram filesystem for Linux.
  Copyright (C) 2000 Linus Torvalds.
                2000 Transmeta Corp.
  Usage limits added by David Gibson, Linuxcare Australia.
  This file is released under the GPL.
  NOTE! This filesystem is probably most useful
  not as a real filesystem, but as an example of
  how virtual filesystems can be written.
  It doesn't get much simpler than this. Consider
  that this file implements the full semantics of
  a POSIX-compliant read-write filesystem.
  Note in particular how the filesystem does not
  need to implement any data structures of its own
  to keep track of the virtual data: using the VFS
  caches is sufficient.
 directory inodes start off with i_nlink == 2 (for "." entry) 
  File creation. Allocate an inode, and we're done..
 SMP-safe 
 Extra count - pin the dentry in core 
  Display the mount options in procmounts.
		
		  We might like to report bad mount options here;
		  but traditionally ramfs has ignored all mount options,
		  and as it is used as a !CONFIG_SHMEM simple substitute
		  for tmpfs, better continue to ignore other mount options.
 SPDX-License-Identifier: GPL-2.0-or-later
 file-nommu.c: no-MMU version of ramfs
  Copyright (C) 2005 Red Hat, Inc. All Rights Reserved.
  Written by David Howells (dhowells@redhat.com)
  add a contiguous set of pages into a ramfs inode when it's truncated from
  size 0 on the assumption that it's going to be used for an mmap of shared
  memory
 make various checks 
	 allocate enough contiguous pages to be able to satisfy the
 split the high-order page into an array of single pages 
 trim off any pages we don't actually require 
 clear the memory we allocated 
 attach all the pages to the inode's address space 
 prevent the page from being discarded on memory pressure 
	 assume a truncate from zero size is going to be for the purposes of
 check that a decrease in size doesn't cut off any shared mappings 
  handle a change of attributes
  - we're specifically interested in a change of size
 POSIX UIDGID verification for setting inode attributes 
 pick out size-changing events 
			 we skipped the truncate but must still update
			  timestamps
  try to determine where a shared mapping can be made
  - we require that:
    - the pages to be mapped must exist
    - the pages be physically contiguous in sequence
 the mapping mustn't extend beyond the EOF 
 gang-find the pages 
 leave if some pages were missing 
 check the pages for physical adjacency 
 okay - all conditions fulfilled 
  set up a mapping for shared memory segments
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2016-2021 Christoph Hellwig.
 skip holes 
 success 
 extent array full 
 error 
 inode with no (attribute) mapping will give ENOENT 
 legacy ->bmap interface.  0 is the error return (!) 
 leave iter.processed unset to abort loop 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2010 Red Hat, Inc.
  Copyright (C) 2016-2019 Christoph Hellwig.
  Structure allocated for each page or THP when block size < page size
  to track sub-page uptodate status and IO completions.
	
	  per-block data is stored in the head page.  Callers should
	  not be dealing with tail pages, and if they are, they can
	  call thp_head() first.
  Calculate the range inside the page that we actually need to read.
	
	  If the block size is smaller than the page size, we need to check the
	  per-block uptodate status and adjust the offset and length if needed
	  to avoid reading in already uptodate ranges.
 move forward for each leading block marked uptodate 
 truncate len if we find any trailing uptodate block(s) 
	
	  If the extent spans the block that contains the i_size, we need to
	  handle both halves separately so that we properly zero data in the
	  page cache for blocks that are entirely outside of i_size.
 zero post-eof blocks as the page may be mapped 
 same as readahead_gfp_mask 
		
		  If the bio_alloc fails, try it again for a single page to
		  avoid having to deal with partial page reads.  This emulates
		  what do_mpage_readpage does.
	
	  Move the caller beyond our range so that it keeps making progress.
	  For that, we have to include any leading non-uptodate ranges, but
	  we can skip trailing ones as they will be handled in the next
	  iteration.
	
	  Just like mpage_readahead and block_read_full_page, we always
	  return 0 and just mark the page as PageError on errors.  This
	  should be cleaned up throughout the stack eventually.
  iomap_readahead - Attempt to read pages from a file.
  @rac: Describes the pages to be read.
  @ops: The operations vector for the filesystem.
  This function is for filesystems to call to implement their readahead
  address_space operation.
  Context: The @ops callbacks may submit IO (eg to read the addresses of
  blocks from disc), and may wait for it.  The caller may be trying to
  access a different page, and so sleeping excessively should be avoided.
  It may allocate memory, but should avoid costly allocations.  This
  function is called with memalloc_nofs set, so allocations will not cause
  the filesystem to be reentered.
  iomap_is_partially_uptodate checks whether blocks within a page are
  uptodate or not.
  Returns true if all blocks which correspond to a file portion
  we want to read within the page are uptodate.
 Limit range to one page 
 First and last blocks in range within page 
	
	  mm accommodates an old ext3 case where clean pages might not have had
	  the dirty bit cleared. Thus, it can send actual dirty pages to
	  ->releasepage() via shrink_active_list(); skip those here.
	
	  If we're invalidating the entire page, clear the dirty state from it
	  and release it to avoid unnecessary buildup of the LRU.
 CONFIG_MIGRATION 
	
	  Only truncate newly allocated pages beyoned EOF, even if the
	  write started inside the existing inode size.
 needs more work for the tailpacking case; disable for now 
	
	  The blocks that were entirely written will now be uptodate, so we
	  don't have to worry about a readpage reading them and overwriting a
	  partial write.  However, if we've encountered a short write and only
	  partially written into a block, it will not be marked uptodate, so a
	  readpage might come in and destroy our partial write.
	 
	  Do the simplest thing and just treat any short write to a
	  non-uptodate page as a zero-length write, and force the caller to
	  redo the whole thing.
 Returns the number of bytes copied.  May be 0.  Cannot be an errno. 
	
	  Update the in-memory inode size after copying the data into the page
	  cache.  It's up to the file system to write the updated size to disk,
	  preferably after IO completion so that no stale data is exposed.
 Offset into pagecache page 
 Bytes to write to page 
 Bytes copied from user 
		
		  Bring in the user page that we'll copy from _first_.
		  Otherwise there's a nasty deadlock on copying from the
		  same page as we're writing to, without it being marked
		  up-to-date.
			
			  A short copy made iomap_write_end() reject the
			  thing entirely.  Might be memory poisoning
			  halfway through, might be a race with munmap,
			  might be severe memory pressure.
 don't bother with blocks that are not shared to start with 
 don't bother with holes or unwritten extents 
 already zeroed?  we're done. 
 Block boundary? Nothing to do 
  We're now finished for good with this ioend structure.  Update the page
  state, release holds on bios, and finally free up memory.  Do not use the
  ioend after this.
		
		  For the last bio, bi_private points to the ioend, so we
		  need to explicitly end the iteration here.
 walk each page on bio, ending page IO on them 
 The ioend has been freed by bio_put() 
  We can merge two adjacent ioends if they have the same set of work to do.
  Submit the final bio for an ioend.
  If @error is non-zero, it means that we have a situation where some part of
  the submission process has failed after we've marked pages for writeback
  and unlocked them.  In this situation, we need to fail the bio instead of
  submitting it.  This typically only happens on a filesystem shutdown.
		
		  If we're failing the IO now, just mark the ioend with an
		  error and finish it.  This will run IO completion immediately
		  as there is only one reference to the ioend at this point in
		  time.
  Allocate a new bio, and chain the old bio to the new one.
  Note that we have to perform the chaining in this unintuitive order
  so that the bi_private linkage is set up in the right direction for the
  traversal in iomap_finish_ioend().
 also copies over blkcg information 
 for iomap_finish_ioend 
  Test to see if we have an existing ioend structure that we could append to
  first; otherwise finish off the current ioend and start another.
  We implement an immediate ioend submission policy here to avoid needing to
  chain multiple ioends and hence nest mempool allocations which can violate
  the forward progress guarantees we need to provide. The current ioend we're
  adding blocks to is cached in the writepage context, and if the new block
  doesn't append to the cached ioend, it will create a new ioend and cache that
  instead.
  If a new ioend is created and cached, the old ioend is returned and queued
  locally for submission once the entire page is processed or an error has been
  detected.  While ioends are submitted immediately after they are completed,
  batching optimisations are provided by higher level block plugging.
  At the end of a writeback pass, there will be a cached ioend remaining on the
  writepage context that the caller will need to submit.
 file offset of page 
	
	  Walk through the page to find areas to write back. If we run off the
	  end of the current map or find the current map invalid, grab a new
	  one.
	
	  We cannot cancel the ioend directly here on error.  We may have
	  already set other pages under writeback and hence we have to run IO
	  completion to mark the error state of the pages under writeback
	  appropriately.
		
		  Let the filesystem know what portion of the current page
		  failed to map. If the page hasn't been added to ioend, it
		  won't be affected by IO completion and we must unlock it
		  now.
	
	  Preserve the original error if there was one; catch
	  submission errors here and propagate into subsequent ioend
	  submissions.
	
	  We can end up here with no error and nothing to write only if we race
	  with a partial page truncate on a sub-page block sized filesystem.
  Write out a dirty page.
  For delalloc space on the page, we need to allocate space and flush it.
  For unwritten space on the page, we need to start the conversion to
  regular allocated space.
	
	  Refuse to write the page out if we're called from reclaim context.
	 
	  This avoids stack overflows when called from deeply used stacks in
	  random callers for direct reclaim or memcg reclaim.  We explicitly
	  allow reclaim from kswapd as the stack usage there is relatively low.
	 
	  This should never happen except in the case of a VM regression so
	  warn about it.
	
	  Is this page beyond the end of the file?
	 
	  The page index is less than the end_index, adjust the end_offset
	  to the highest offset that this page should represent.
	  -----------------------------------------------------
	  |			file mapping	       | <EOF> |
	  -----------------------------------------------------
	  | Page ... | Page N-2 | Page N-1 |  Page N  |       |
	  ^--------------------------------^----------|--------
	  |     desired writeback range    |      see else    |
	  ---------------------------------^------------------|
		
		  Check whether the page to write out is beyond or straddles
		  i_size or not.
		  -------------------------------------------------------
		  |		file mapping		        | <EOF>  |
		  -------------------------------------------------------
		  | Page ... | Page N-2 | Page N-1 |  Page N   | Beyond |
		  ^--------------------------------^-----------|---------
		  |				    |      Straddles     |
		  ---------------------------------^-----------|--------|
		
		  Skip the page if it's fully outside i_size, e.g. due to a
		  truncate operation that's in progress. We must redirty the
		  page so that reclaim stops reclaiming it. Otherwise
		  iomap_vm_releasepage() is called on it and gets confused.
		 
		  Note that the end_index is unsigned long.  If the given
		  offset is greater than 16TB on a 32-bit system then if we
		  checked if the page is fully outside i_size with
		  "if (page->index >= end_index + 1)", "end_index + 1" would
		  overflow and evaluate to 0.  Hence this page would be
		  redirtied and written out repeatedly, which would result in
		  an infinite loop; the user program performing this operation
		  would hang.  Instead, we can detect this situation by
		  checking if the page is totally beyond i_size or if its
		  offset is just equal to the EOF.
		
		  The page straddles i_size.  It must be zeroed out on each
		  and every writepage invocation because it may be mmapped.
		  "A file is mapped in multiples of the page size.  For a file
		  that is not a multiple of the page size, the remaining
		  memory is zeroed when mapped, and writes to that region are
		  not written out to the file."
 Adjust the end_offset to the end of file 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2018 Oracle.  All Rights Reserved.
  Author: Darrick J. Wong <darrick.wong@oracle.com>
 Swapfile activation 
 accumulated iomap 
 lowest physical addr seen (pages) 
 highest physical addr seen (pages) 
 number of pages collected 
 extent count 
  Collect physical extents for this swap file.  Physical extents reported to
  the swap code must be trimmed to align to a page boundary.  The logical
  offset within the file is irrelevant since the swapfile code maps logical
  page numbers of the swap device to the physical page-aligned extents.
	
	  Round the start up and the end down so that the physical
	  extent aligns to a page boundary.
 Skip too-short physical extents. 
	
	  Calculate how much swap space we're adding; the first page contains
	  the swap header and doesn't count.  The mm still wants that first
	  page fed to add_swap_extent, however.
 Add extent, set up for the next call. 
  Accumulate iomaps for this swap file.  We have to accumulate iomaps because
  swap only cares about contiguous page-aligned physical extents and makes no
  distinction between written and unwritten extents.
 Only real or unwritten extents. 
 No inline data. 
 No uncommitted metadata or shared blocks. 
 Only one bdev per swap file. 
 No accumulated extent, so just store it. 
 Append this to the accumulated extent. 
 Otherwise, add the retained iomap and store this one. 
  Iterate a swap file's iomaps to construct physical extents that can be
  passed to the swapfile subsystem.
	
	  Persist all file mapping metadata so that we won't have any
	  IOMAP_F_DIRTY iomaps.
	
	  If this swapfile doesn't contain even a single page-aligned
	  contiguous range of blocks, reject this useless swapfile to
	  prevent confusion later on.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2010 Red Hat, Inc.
  Copyright (c) 2016-2021 Christoph Hellwig.
 handle the previous iteration (if any) 
 clear the state for the next iteration 
  iomap_iter - iterate over a ranges in a file
  @iter: iteration structue
  @ops: iomap ops provided by the file system
  Iterate over filesystem-provided space mappings for the provided file range.
  This function handles cleanup of resources acquired for iteration when the
  filesystem indicates there are no more space mappings, which means that this
  function must be called in a loop that continues as long it returns a
  positive value.  If 0 or a negative value is returned, the caller must not
  return to the loop body.  Within a loop body, there are two ways to break out
  of the loop body:  leave @iter.processed unchanged, or set it to a negative
  errno.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2010 Red Hat, Inc.
  Copyright (c) 2016-2021 Christoph Hellwig.
  Private flags for iomap_dio, must not overlap with the public ones in
  iomap.h:
 used during submission and for synchronous completion: 
 used for aio completion: 
 check for short read 
	
	  Try again to invalidate clean pages which might have been cached by
	  non-direct readahead, or faulted in by get_user_pages() if the source
	  of the write was an mmap'ed region of the file we're writing.  Either
	  one is a pretty crazy thing to do, so we don't support it 100%.  If
	  this invalidation fails, tough, the write still worked...
	 
	  And this page cache invalidation has to be after ->end_io(), as some
	  filesystems convert unwritten extents to real allocations in
	  ->end_io() when necessary, otherwise a racing buffer read would cache
	  zeros from unwritten extents.
	
	  If this is a DSYNC write, make sure we push it to stable storage now
	  that we've written data.
  Set an error in the dio if none is set yet.  We have to use cmpxchg
  as the submission context and the completion context(s) can race to
  update the error.
  Figure out the bio's operation flags from the dio request, the
  mapping, and whether or not we want FUA.  Note that we can end up
  clearing the WRITE_FUA flag in the dio request.
		
		  Use a FUA write if we need datasync semantics, this is a pure
		  data IO that doesn't require any metadata updates (including
		  after IO completion such as unwritten extent conversion) and
		  the underlying device supports FUA. This allows us to avoid
		  cache flushes on IO completion.
	
	  Save the original count and trim the iter to just the extent we
	  are operating on right now.  The iter will be re-expanded once
	  we are done.
	
	  We can only poll for single bio IOs.
 zero out from the start of the block to the write offset 
	
	  Set the operation flags early so that bio_iov_iter_get_pages
	  can set up the page vector appropriately for a ZONE_APPEND
	  operation.
			
			  We have to stop part way through an IO. We must fall
			  through to the sub-block tail zeroing here, otherwise
			  this short IO may expose stale data in the tail of
			  the block we haven't written data to.
		
		  We can only poll for single bio IOs.
	
	  We need to zeroout the tail of a sub-block write if the extent type
	  requires zeroing or the write extends beyond EOF. If we don't zero
	  the block tail in the latter case, we can expose stale data via mmap
	  reads of the EOF block.
 zero out from the end of the write to the end of the block 
 Undo iter limitation to current extent 
		
		  DIO is not serialised against mmap() access at all, and so
		  if the page_mkwrite occurs between the writeback and the
		  iomap_iter() call in the DIO path, then it will see the
		  DELALLOC block that the page-mkwrite allocated.
  iomap_dio_rw() always completes O_[D]SYNC writes regardless of whether the IO
  is being issued as AIO or not.  This allows us to optimise pure data writes
  to use REQ_FUA rather than requiring generic_write_sync() to issue a
  REQ_FLUSH post write. This is slightly tricky because a single request here
  can be mapped into multiple disjoint IOs and only a subset of the IOs issued
  may be pure data writes. In that case, we still need to do a full data sync
  completion.
  When page faults are disabled and @dio_flags includes IOMAP_DIO_PARTIAL,
  __iomap_dio_rw can return a partial result if it encounters a non-resident
  page in @iter after preparing a transfer.  In that case, the non-resident
  pages can be faulted in and the request resumed with @done_before set to the
  number of bytes previously transferred.  The request will then complete with
  the correct total number of bytes transferred; this is essential for
  completing partial requests asynchronously.
  Returns -ENOTBLK In case of a page invalidation invalidation failure for
  writes.  The callers needs to fall back to buffered IO in this case.
 for data sync or sync, we need sync completion processing 
		
		  For datasync only writes, we optimistically try using FUA for
		  this IO.  Any non-FUA write that occurs will clear this flag,
		  hence we know before completion whether a cache flush is
		  necessary.
		
		  Try to invalidate cache pages for the range we are writing.
		  If this invalidation fails, let the caller fall back to
		  buffered IO.
		
		  We can only poll for single bio IOs.
	
	  We only report that we've read data up to i_size.
	  Revert iter to a state corresponding to that as some callers (such
	  as the splice code) rely on it.
 magic error code to fall back to buffered IO 
	
	  If all the writes we issued were FUA, we don't need to flush the
	  cache on IO completion. Clear the sync flag for this case.
	
	  We are about to drop our additional submission reference, which
	  might be the last reference to the dio.  There are three different
	  ways we can progress here:
	 
	   (a) If this is the last reference we will always complete and free
	 	the dio ourselves.
	   (b) If this is not the last reference, and we serve an asynchronous
	 	iocb, we must never touch the dio after the decrement, the
	 	IO completion handler will complete and free it.
	   (c) If this is not the last reference, but we serve a synchronous
	 	iocb, the IO completion handler will wake us up on the drop
	 	of the final reference, and we will complete and free it here
	 	after we got woken by the IO completion handler.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2017 Red Hat, Inc.
  Copyright (c) 2018-2021 Christoph Hellwig.
 Nothing to be found before or beyond the end of the file. 
 found hole before EOF 
 Nothing to be found before or beyond the end of the file. 
 found data before EOF 
 We've reached the end of the file without finding data 
 SPDX-License-Identifier: GPL-2.0
  Copyright (c) 2019 Christoph Hellwig
  We include this last to have the helpers above available for the trace
  event implementations.
  hugetlbpage-backed filesystem.  Based on ramfs.
  Nadia Yvette Chambers, 2002
  Copyright (C) 2002 Linus Torvalds.
  License: GPL
 remove ASAP 
  Mask used when checking the page offset value passed in via system
  calls.  This value will be converted to a loff_t which is signed.
  Therefore, we want to check the upper PAGE_SHIFT + 1 bits of the
  value.  The extra bit (- 1 in the shift value) is to take the sign
  bit into account.
	
	  vma address alignment (but not the pgoff alignment) has
	  already been checked by prepare_hugepage_range.  If you add
	  any error returns here, do so after setting VM_HUGETLB, so
	  is_vm_hugetlb_page tests below unmap_region go the right
	  way when do_mmap unwinds (may be important on powerpc
	  and ia64).
	
	  page based offset in vm_pgoff could be sufficiently large to
	  overflow a loff_t when converted to byte offset.  This can
	  only happen on architectures where sizeof(loff_t) ==
	  sizeof(unsigned long).  So, only check in those instances.
 must be huge page aligned 
 check for overflow 
  Called under mmap_write_lock(mm).
	
	  A failed mmap() very likely causes application failure,
	  so fall back to the bottom-up function here. This scenario
	  can happen with large stack limits and large mmap()
	  allocations.
	
	  Use mm->get_unmapped_area value as a hint to use topdown routine.
	  If architectures have special needs, they should define their own
	  version of hugetlb_get_unmapped_area.
 Find which 4k chunk and offset with in that chunk 
  Support for read() - Find the page attached to f_mapping and copy out the
  data. Its very similar to generic_file_buffered_read(), we can't use that
  since it has PAGE_SIZE assumptions.
 nr is the maximum number of bytes to copy from this page 
 Find the page 
			
			  We have a HOLE, zero out the user-buffer for the
			  length of the hole or request.
			
			  We have the page, copy it to user space buffer.
	
	  end == 0 indicates that the entire range after
	  start should be unmapped.
		
		  Can the expression below overflow on 32-bit arches?
		  No, because the interval tree returns us only those vmas
		  which overlap the truncated area starting at pgoff,
		  and no vma on a 32-bit arch can span beyond the 4GB.
  remove_inode_hugepages handles two distinct cases: truncation and hole
  punch.  There are subtle differences in operation for each case.
  truncation is indicated by end of range being LLONG_MAX
 	In this case, we first scan the range and release found pages.
 	After releasing pages, hugetlb_unreserve_pages cleans up regionreserve
 	maps and global counts.  Page faults can not race with truncation
 	in this routine.  hugetlb_no_page() holds i_mmap_rwsem and prevents
 	page faults in the truncated range by checking i_size.  i_size is
 	modified while holding i_mmap_rwsem.
  hole punch is indicated if end is not LLONG_MAX
 	In the hole punch case we scan the range and release found pages.
 	Only when releasing a page is the associated regionreserve map
 	deleted.  The regionreserve map for ranges without associated
 	pages are not modified.  Page faults can race with hole punch.
 	This is indicated if we find a mapped page.
  Note: If the passed end of range value is beyond the end of file, but
  not LLONG_MAX this routine still performs a hole punch operation.
		
		  When no more pages are found, we are done.
				
				  Only need to hold the fault mutex in the
				  hole punch case.  This prevents races with
				  page faults.  Races are not possible in the
				  case of truncation.
			
			  If page is mapped, it was faulted in after being
			  unmapped in caller.  Unmap (again) now after taking
			  the fault mutex.  The mutex will prevent faults
			  until we finish removing the page.
			 
			  This race can only happen in the hole punch case.
			  Getting here in a truncate operation is a bug.
			
			  We must free the huge page and remove from page
			  cache (remove_huge_page) BEFORE removing the
			  regionreserve map (hugetlb_unreserve_pages).  In
			  rare out of memory conditions, removal of the
			  regionreserve map could fail. Correspondingly,
			  the subpool and global reserve usage count can need
			  to be adjusted.
	
	  Get the resv_map from the address space embedded in the inode.
	  This is the address space which points to any resv_map allocated
	  at inode creation time.  If this is a device special inode,
	  i_mapping may not point to the original address space.
 Only regular and link inodes have associated reserve maps 
	
	  For hole punch round up the beginning offset of the hole and
	  round down the end.
 protected by i_rwsem 
	
	  Default preallocate case.
	  For this range, start is rounded down and end is rounded up
	  as well as being converted to page offsets.
 We need to check rlimit even when FALLOC_FL_KEEP_SIZE 
	
	  Initialize a pseudo vma as this is required by the huge page
	  allocation routines.  If NUMA is configured, use page index
	  as input to create an allocation policy.
		
		  This is supposed to be the vaddr where the page is being
		  faulted in, but we have no vaddr here.
		
		  fallocate(2) manpage permits EINTR; we may have been
		  interrupted because we are using up too much memory.
 Set numa allocation policy based on index 
 addr is the offset within the file (zero based) 
		
		  fault mutex taken here, protects against fault path
		  and hole punch.  inode_lock previously taken protects
		  against truncation.
 See if already present in mapping to avoid allocfree 
		
		  Allocate page without setting the avoid_reserve argument.
		  There certainly are no reserves associated with the
		  pseudo_vma.  However, there could be shared mappings with
		  reserves for the file at the inode level.  If we fallocate
		  pages in these areas, we need to consume the reserves
		  to keep reservation accounting consistent.
		
		  unlock_page because locked by add_to_page_cache()
		  put_page() due to reference from alloc_huge_page()
 protected by i_rwsem 
 directory inodes start off with i_nlink == 2 (for "." entry) 
  Hugetlbfs is not reclaimable; therefore its i_mmap_rwsem will never
  be taken from reclaim -- unlike regular filesystems. This needs an
  annotation because huge_pmd_share() does an allocation under hugetlb's
  i_mmap_rwsem.
	
	  Reserve maps are only needed for inodes that can have associated
	  page allocations.
 directory inodes start off with i_nlink == 2 (for "." entry) 
  File creation. Allocate an inode, and we're done..
 Extra count - pin the dentry in core 
  Display the mount options in procmounts.
		 If no limits set, just report 0 for maxfreeused
	
	  Any time after allocation, hugetlbfs_destroy_inode can be called
	  for the inode.  mpol_free_shared_policy is unconditionally called
	  as part of hugetlbfs_destroy_inode.  So, initialize policy here
	  in case of a quick call to destroy.
	 
	  Note that the policy is initialized even if we are creating a
	  private inode.  This simplifies hugetlbfs_destroy_inode.
  Convert size option passed from command line to number of huge pages
  in the pool specified by hstate.  Size option could be in bytes
  (val_type == SIZE_STD) or percentage of the pool (val_type == SIZE_PERCENT).
  Parse one mount parameter.
 memparse() will accept a KMG without a digit 
 memparse() will accept a KMG without a digit 
 memparse() will accept a KMG without a digit 
  Validate the parsed options.
	
	  Use huge page pool size (in hstate) to convert the size
	  options to number of huge pages.  If NO_SIZE, -1 is returned.
	
	  If max_size was specified, then min_size must be smaller
	
	  Allocate and initialize subpool if maximum or minimum size is
	  specified.  Any needed reservations (for minimum size) are taken
	  taken when the subpool is created.
	
	  Due to the special and limited functionality of hugetlbfs, it does
	  not work well as a stacking filesystem.
 No limit on size by default 
 No limit on number of inodes by default 
 No default minimum size 
  Note that size should be aligned to proper hugepage size in caller side,
  otherwise hugetlb_reserve_pages reserves one less hugepages than intended.
 default hstate mount is required 
 other hstates are optional 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2007 Red Hat.  All rights reserved.
		
		  We're holding a transaction handle, so use a NOFS memory
		  allocation context to avoid deadlock if reclaim happens.
 this happens with subvols 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2007 Oracle.  All rights reserved.
 If we have a 32-bit userspace and 64-bit kernel, then the UAPI
  structures are incorrect, as the timespec structure from userspace
  is 4 bytes too small. We define these alternatives here to teach
  the kernel about the 32-bit struct packing.
 in 
 in 
 out 
 in 
 out 
 in 
 in 
 in 
 in 
 in 
 in 
 in 
 in 
 in 
 Mask out flags that are inappropriate for the given type of inode. 
  Export internal inode flags to the format expected by the FS_IOC_GETFLAGS
  ioctl.
  Update inode->i_flags based on the btrfs internal flags.
  Check if @flags are a supported and valid set of FS__FL flags and that
  the old and new flags are not conflicting
 COMPR and NOCOMP on newold are valid 
 NOCOW and compression options are mutually exclusive 
  Set flagsxflags from the internal inode flags. The remaining items of
  fsxattr are zeroed.
 If coming from FS_IOC_FSSETXATTR then skip unconverted flags 
 1 item for the inode 
			
			  It's safe to turn csums off here, no extents exist.
			  Otherwise we want the flag to reflect the real COW
			  status of the file and will not set it.
		
		  Revert back under same assumptions as above
	
	  The COMPRESS flag can only be changed by users, while the NOCOMPRESS
	  flag may be changed automatically if compression code won't make
	  things smaller.
	
	  1 for inode item
	  2 for properties
  Start exclusive operation @type, return true on success
  Conditionally allow to enter the exclusive operation in case it's compatible
  with the running one.  This must be paired with btrfs_exclop_start_unlock and
  btrfs_exclop_finish.
  Compatibility:
  - the same type is already running
  - not BTRFS_EXCLOP_NONE - this is intentionally incompatible and the caller
    must check the condition first that would allow none -> @type
	
	  btrfs_trim_block_group() depends on space cache, which is not
	  available in zoned filesystem. So, disallow fitrim on a zoned
	  filesystem for now.
	
	  If the fs is mounted with nologreplay, which requires it to be
	  mounted in RO mode as well, we can not allow discard on free space
	  inside block groups, because log trees refer to extents that are not
	  pinned in a block group's free space cache (pinning the extents is
	  precisely the first phase of replaying a log tree).
	
	  NOTE: Don't truncate the range using super->total_bytes.  Bytenr of
	  block group is in the logical address space, which can be any
	  sectorsize aligned bytenr in  the range [0, U64_MAX].
	
	  Don't create subvolume whose level is not zero. Or qgroup will be
	  screwed up since it assumes subvolume qgroup's level to be 0.
	
	  The same as the snapshot creation, please see the comment
	  of create_snapshot().
		
		  Since we don't abort the transaction in this case, free the
		  tree block so that we don't leak space and leave the
		  filesystem in an inconsistent state (an extent item in the
		  extent tree without backreferences). Also no need to have
		  the tree block locked since it is not in any tree at this
		  point, so no other task can find it and use it.
 Freeing will be done in btrfs_put_root() of new_root 
 We potentially lose an unused inode item here 
	
	  insert the directory item
	
	  1 - parent dir inode
	  2 - dir entries
	  1 - root item
	  2 - root refbackref
	  1 - root of snapshot
	  1 - UUID item
 Prevent double freeing of anon_dev 
  copy of may_delete in fsnamei.c()
 	Check whether we can remove a link victim from directory dir, check
   whether the type of victim is right.
   1. We can't do it if dir is read-only (done in permission())
   2. We should have write and exec permissions on dir
   3. We can't remove anything from append-only dir
   4. We can't do anything with immutable dir (done in permission())
   5. If the sticky bit on dir is set we should either
 	a. be owner of dir, or
 	b. be owner of victim, or
 	c. have CAP_FOWNER capability
   6. If the victim is append-only or immutable we can't do anything with
      links pointing to it.
   7. If we were asked to remove a directory and victim isn't one - ENOTDIR.
   8. If we were asked to remove a non-directory and victim isn't one - EISDIR.
   9. We can't remove a root or mountpoint.
  10. We don't allow removal of NFS sillyrenamed files; it's handled by
      nfs_async_unlink().
 copy of may_create in fsnamei.c() 
  Create a new subvolume below @parent.  This is largely modeled after
  sys_mkdirat and vfs_mkdir, but we only do a single component lookup
  inside this filesystem so it's quite a bit simpler.
	
	  even if this name doesn't exist, we may get hash collisions.
	  check for them now when we can safely fail
	
	  Force new buffered writes to reserve space even when NOCOW is
	  possible. This is to avoid later writeback (running dealloc) to
	  fallback to COW mode and unexpectedly fail with ENOSPC.
	
	  All previous writes have started writeback in NOCOW mode, so now
	  we force future writes to fallback to COW mode during snapshot
	  creation.
	
	  hopefully we have this extent in the tree already, try without
	  the full extent lock
 get the big lock and read metadata off disk 
 this is the last extent 
  Prepare one page to be defragged.
  This will ensure:
  - Returned page is locked and has been set up properly.
  - No ordered extent exists in the page.
  - The page is uptodate.
  NOTE: Caller should also wait for page writeback after the cluster is
  prepared, here we don't do writeback wait for each page.
	
	  Since we can defragment files opened read-only, we can encounter
	  transparent huge pages here (see CONFIG_READ_ONLY_THP_FOR_FS). We
	  can't do IO using huge pages yet, so return an error for now.
	  Filesystem transparent huge pages are typically only used for
	  executables that explicitly enable them, so this isn't very
	  restrictive.
 Wait for any existing ordered extent in the range 
		
		  We unlocked the page above, so we need check if it was
		  released or not.
	
	  Now the page range has no ordered extent any more.  Read the page to
	  make it uptodate.
  Collect all valid target extents.
  @start:	   file offset to lookup
  @len:	   length to lookup
  @extent_thresh: file extent size threshold, any extent size >= this value
 		   will be ignored
  @newer_than:    only defrag extents newer than this value
  @do_compress:   whether the defrag is doing compression
 		   if true, @extent_thresh will be ignored and all regular
 		   file extents meeting @newer_than will be targets.
  @locked:	   if the range has already held extent lock
  @target_list:   list of targets file extents
 Skip holeinlinepreallocated extents 
 Skip older extent 
		
		  For do_compress case, we want to compress all valid file
		  extents, thus no @extent_thresh or mergeable check.
 Skip too large extent 
 Empty target list, no way to merge with last entry 
 Not mergeable with last entry 
 Mergeable, fall through to add it to @target_list. 
		
		  This one is a good target, check if it can be merged into
		  last range of the target list.
 Mergeable, enlarge the last entry 
 Fall through to allocate a new entry 
 Allocate new defrag_target_range 
  Defrag one contiguous target range.
  @inode:	target inode
  @target:	target range to defrag
  @pages:	locked pages covering the defrag range
  @nr_pages:	number of locked pages
  Caller should ensure:
  - Pages are prepared
    Pages should be locked, no ordered extent in the pages range,
    no writeback.
  - Extent bits are locked
 Update the page status 
 Prepare all pages 
 Lock the pages range 
	
	  Now we have a consistent view about the extent map, re-check
	  which range really needs to be defragged.
	 
	  And this time we have extent locked already, pass @locked = true
	  so that we won't relock the extent range and cause deadlock.
 Reached the limit 
		
		  Here we may not defrag any range if holes are punched before
		  we locked the pages.
		  But that's fine, it only affects the @sectors_defragged
		  accounting.
  Entry point to file defragmentation.
  @inode:	   inode to be defragged
  @ra:		   readahead state (can be NUL)
  @range:	   defrag options including range and flags
  @newer_than:	   minimum transid to defrag
  @max_to_defrag: max number of sectors to be defragged, if 0, the whole inode
 		   will be defragged.
 Got a specific range 
 Defrag until file end 
	
	  If we were not given a ra, allocate a readahead context. As
	  readahead is just an optimization, defrag will work without it so
	  we don't error out.
 Align the range 
 The cluster size 256K should always be page aligned 
 We want the cluster end at page boundary when possible 
		
		  We have defragged some sectors, for compression case they
		  need to be written back immediately.
  Try to start exclusive operation @type or cancel it if it's running.
  Return:
    0        - normal mode, newly claimed op started
   >0        - normal mode, something else is running,
               return BTRFS_ERROR_DEV_EXCL_RUN_IN_PROGRESS to user space
  ECANCELED  - cancel mode, successful cancel
  ENOTCONN   - cancel mode, operation not running anymore
 Start normal op 
 Exclusive operation is now claimed 
 Cancel running op 
		
		  This blocks any exclop finish from setting it to NONE, so we
		  request cancellation. Either it runs and we will wait for it,
		  or it has finished and no waiting will happen.
 Something else is running or none 
	
	  Read the arguments before checking exclusivity to be able to
	  distinguish regular resize and cancel
 Exclusive operation is now claimed 
 equal, nothing need to do 
			
			  Subvolume creation is not restricted, but snapshots
			  are limited to own subvolumes only
 nothing to do 
		
		  Block RO -> RW transition if this subvolume is involved in
		  send
			
			  return one empty item back for v1, which does not
			  handle -EOVERFLOW
		
		  Copy search result header. If we fault then loop again so we
		  can fault in the pages and -EFAULT there if there's a
		  problem. Otherwise we'll fault and then copy the buffer in
		  properly this next time through
			
			  Copy the item, same behavior as above, but reset the
			   sk_offset so we copy the full thing again.
 -EOVERFLOW from above 
	
	   0: all items from this leaf copied, continue with next
	   1:  more items can be copied, but unused buffer is too small
	       all items were found
	      Either way, it will stops the loop which iterates to the next
	      leaf
	   -EOVERFLOW: item was to large for buffer
	   -EFAULT: could not copy extent buffer back to userspace
 search the root of the inode that was passed 
	
	  In the origin implementation an overflow is handled by returning a
	  search header with a len of zero, so reset ret.
 copy search header and buffer size 
 limit result size to 16MB 
  Search INODE_REFs to identify path name of 'dirid' directory
  in a 'tree_id' tree. and sets path name to 'name'.
	
	  If the bottom subvolume does not exist directly under upper_limit,
	  construct the path in from the bottom up.
 Check the read+exec permission of this directory 
 Get the bottom subvolume's name from ROOT_REF 
 Check if dirid in ROOT_REF corresponds to passed dirid 
 Copy subvolume's name 
	
	  Unprivileged query to obtain the containing subvolume root id. The
	  path is reset so it's consistent with btrfs_search_path_in_tree.
  Version of ino_lookup ioctl (unprivileged)
  The main differences from ino_lookup ioctl are:
    1. Read + Exec permission will be checked using inode_permission() during
       path construction. -EACCES will be returned in case of failure.
    2. Path construction will be stopped at the inode number which corresponds
       to the fd with which this ioctl is called. If constructed path does not
       exist under fd's inode, -EACCES will be returned.
    3. The name of bottom subvolume is also searched and filled.
		
		  The subvolume does not exist under fd with which this is
		  called
 Get the subvolume information in BTRFS_ROOT_ITEM and BTRFS_ROOT_BACKREF 
 Get root_item of inode's subvolume 
 Search root tree for ROOT_BACKREF of this subvolume 
  Return ROOT_REF information of the subvolume containing this inode
  except the subvolume name.
 update min_treeid for next search 
		
		  If SPEC_BY_ID is not set, we are looking for the subvolume by
		  name, same as v1 currently does.
			
			  Change the default parent since the subvolume being
			  deleted can be outside of the current mount point.
			
			  At this point dentry->d_name can point to '' if the
			  subvolume we want to destroy is outsite of the
			  current mount point, so we need to release the
			  current dentry and execute the lookup to return a new
			  one with ->d_name pointing to the
			  <mount point>subvol_name.
			
			  If v2 was used with SPEC_BY_ID, a new parent was
			  allocated since the subvolume can be outside of the
			  current mount point. Later on we need to release this
			  new parent dentry.
			
			  On idmapped mounts, deletion via subvolid is
			  restricted to subvolumes that are immediate
			  ancestors of the inode referenced by the file
			  descriptor in the ioctl. Otherwise the idmapping
			  could potentially be abused to delete subvolumes
			  anywhere in the filesystem the user wouldn't be able
			  to delete without an idmapped mount.
 subvol_name_ptr is already nul terminated 
		
		  Regular user.  Only allow this with a special mount
		  option, when the user has write+exec access to the
		  subvol root, and when rmdir(2) would have been
		  allowed.
		 
		  Note that this is _not_ check that the subvol is
		  empty or doesn't contain data that we wouldn't
		  otherwise be able to delete.
		 
		  Users who want to delete empty subvols should try
		  rmdir(2).
		
		  Do not allow deletion if the parent dir is the same
		  as the dir to be deleted.  That means the ioctl
		  must be called on the dentry referencing the root
		  of the subvol, not a random directory contained
		  within it.
 check if subvolume may be deleted by a user 
		
		  Note that this does not check the file descriptor for write
		  access. This prevents defragmenting executables that are
		  running and allows defrag on files open in read-only mode.
 compression requires us to start the IO 
 the rest are all set to zero by kzalloc 
 Exclusive operation is now claimed 
	
	  Global block reserve, exported as a space_info
 space_slots == 0 means they are asking for a count 
	 we generally have at most 6 or so space infos, one for each raid
	  level.  So, a whole page should be more than enough for everyone
 now we have a buffer to copy into 
	
	  Add global block reserve
 No running transaction, don't bother 
 current trans 
	
	  Copy scrub args to user space even if btrfs_scrub_dev() returned an
	  error. This is important as it allows user space to know how much
	  progress scrub has done. For example, if scrub is canceled we get
	  -ECANCELED from btrfs_scrub_dev() and return that error back to user
	  space. Later user space can inspect the progress from the structure
	  btrfs_ioctl_scrub_args and resume scrub from where it left off
	  previously (btrfs-progs does this).
	  If we fail to copy the btrfs_ioctl_scrub_args structure to user space
	  then return -EFAULT to signal the structure was not copied or it may
	  be corrupt and unreliable due to a partial copy.
 All reserved bits must be 0 for now 
 Only accept flags we have defined so far 
 for mut. excl. ops lock 
	
	  mut. excl. ops lock is locked.  Three possibilities:
	    (1) some other op is running
	    (2) balance is running
	    (3) balance is paused -- special case (think resume)
 this is either (2) or (3) 
			
			  Lock released to allow other waiters to continue,
			  we'll reexamine the status again.
 this is (3) 
 this is (2) 
 this is (1) 
 balance everything - no filters 
	
	  Ownership of bctl and exclusive operation goes to btrfs_balance.
	  bctl is freed in reset_balance_state, or, if restriper was paused
	  all the way until unmount, in free_fs_info.  The flag should be
	  cleared after reset_balance_state.
 update qgroup status and info 
 take the current subvol as qgroup 
	
	  1 - root item
	  2 - uuid items (received uuid + subvol uuid)
 Nothing to do 
		
		  The transaction thread may want to do more work,
		  namely it pokes the cleaner kthread that will start
		  processing uncleaned subvols.
	
	  These all access 32-bit values anyway so no further
	  handling is necessary.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2008 Red Hat.  All rights reserved.
 JDM: Really? 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2008 Oracle.  All rights reserved.
		
		  This can happen when compression races with remount setting
		  it to 'no compress', while caller doesn't call
		  inode_need_compress() to check if we really need to
		  compress.
		 
		  Not a big deal, just need to inform caller that we
		  haven't allocated any pages yet.
		
		  This can't happen, the type is validated several times
		  before we get here.
		
		  This can't happen, the type is validated several times
		  before we get here.
 Determine the remaining bytes inside the page first 
 Hash through the page sector by sector 
  Reduce bio and io accounting for a compressed_bio with its corresponding bio.
  Return true if there is no pending bio nor io.
  Return false otherwise.
	
	  At endio time, bi_iter.bi_size doesn't represent the real bio size.
	  Thus here we have to iterate through all segments to grab correct
	  bio size.
	
	  Here we must wake up the possible error handler after all other
	  operations on @cb finished, or we can race with
	  finish_compressed_bio_() which may free @cb.
 Release the compressed pages 
 Do io completion on the original bio 
		
		  We have verified the checksum already, set page checked so
		  the end_io handlers know about it
 Finally free the cb struct 
 when we finish reading compressed pages from the disk, we
  decompress them and then run the bio end_io routines on the
  decompressed pages (in the inode address space).
  This allows the checksumming and other IO error handling routines
  to work normally
  The compressed pages are freed here, and it must be run
  in process context
	
	  Record the correct mirror_num in cb->orig_bio so that
	  read-repair can work properly.
	
	  Some IO in this cb have failed, just skip checksum as there
	  is no way it could be correct.
	 ok, we're the last bio for this extent, lets start
	  the decompression.
  Clear the writeback bits on all of the file
  pages for a compressed write
 the inode may be gone now 
	
	  Ok, we're the last bio for this extent, step one is to call back
	  into the FS and do all the end_io operations.
 Note, our inode could be gone now 
	
	  Release the compressed pages, these came from alloc_page and
	  are not attached to the inode at all
 Finally free the cb struct 
  Do the cleanup once all the compressed pages hit the disk.  This will clear
  writeback on the file pages and free the compressed pages.
  This also calls the writeback end hooks for the file pages so that metadata
  and checksums can be updated in the file.
  Allocate a compressed_bio, which will be used to readwrite on-disk
  (aka, compressed)  data.
  @cb:                 The compressed_bio structure, which records all the needed
                       information to bind the compressed data to the uncompressed
                       page cache.
  @disk_byten:         The logical bytenr where the compressed data will be read
                       from or written to.
  @endio_func:         The endio function to call after the IO for compressed data
                       is finished.
  @next_stripe_start:  Return value of logical bytenr of where next stripe starts.
                       Let the caller know to only fill the bio up to the stripe
                       boundary.
  worker function to build and submit bios for previously compressed pages.
  The corresponding pages in the inode should be marked for writeback
  and the compressed pages should have a reference on them for dropping
  when the IO is complete.
  This also checksums the file bytes and gets things ready for
  the end io hooks.
 Allocate new bio if submitted or not yet allocated 
		
		  We should never reach next_stripe_start start as we will
		  submit comp_bio when reach the boundary immediately.
		
		  We have various limits on the real read size:
		  - stripe boundary
		  - page boundary
		  - compressed length boundary
 Reached zoned boundary 
 Reached stripe boundary 
 Finished the range 
 Last byte of @cb is submitted, endio will free @cb 
	
	  Even with previous bio ended, we should still have io not yet
	  submitted, thus need to finish manually.
 Now we are the only one referring @cb, can finish it safely. 
  Add extra pages in the same compressed file extent so that we don't need to
  re-read the same extent again and again.
  NOTE: this won't work well for subpage, as for subpage read, we lock the
  full page then submit bio for each compressedregular extents.
  This means, if we have several sectors in the same page points to the same
  on-disk compressed data, we will re-read the same extent many times and
  this function can only help for the next page.
	
	  For current subpage support, we only support 64K page size,
	  which means maximum compressed extent size (128K) is just 2x page
	  size.
	  This makes readahead less effective, so here disable readahead for
	  subpage for now, until full compressed write is supported.
 Beyond threshold, no need to continue 
			
			  Jump to next page start as we already have page for
			  current offset.
 There is already a page, skip to page end 
		
		  At this point, we have a locked page in the page cache for
		  these bytes in the file.  But, we have to make sure they map
		  to this compressed extent on disk.
		
		  If it's subpage, we also need to increase its
		  subpage::readers number, as at endio we will decrease
		  subpage::readers and to unlock the page.
  for a compressed read, the bio we get passed has all the inode pages
  in it.  We don't actually do IO on those pages but allocate new ones
  to hold the compressed pages on disk.
  bio->bi_iter.bi_sector points to the compressed extent on disk
  bio->bi_io_vec points to all of the inode pages
  After the compressed pages are read, we copy the bytes into the
  bio we were passed and then call the bio end_io calls
 we need the actual starting offset of this extent in the file 
 include any pages we added in add_ra-bio_pages 
 Allocate new bio if submitted or not yet allocated 
		
		  We should never reach next_stripe_start start as we will
		  submit comp_bio when reach the boundary immediately.
		
		  We have various limit on the real read size:
		  - stripe boundary
		  - page boundary
		  - compressed length boundary
		
		  Maximum compressed extent is smaller than bio size limit,
		  thus bio_add_page() should always success.
 Reached stripe boundary, need to submit 
 Has finished the range, need to submit 
 All bytes of @cb is submitted, endio will free @cb 
	
	  Even with previous bio ended, we should still have io not yet
	  submitted, thus need to finish @cb manually.
 Now we are the only one referring @cb, can finish it safely. 
  Heuristic uses systematic sampling to collect data from the input data
  range, the logic can be tuned by the following constants:
  @SAMPLING_READ_SIZE - how many bytes will be copied from for each sample
  @SAMPLING_INTERVAL  - range from which the sampled data can be collected
  For statistical analysis of the input data we consider bytes that form a
  Galois Field of 256 objects. Each object has an attribute count, ie. how
  many times the object appeared in the sample.
  The size of the sample is based on a statistical sampling rule of thumb.
  The common way is to perform sampling tests as long as the number of
  elements in each cell is at least 5.
  Instead of 5, we choose 32 to obtain more accurate results.
  If the data contain the maximum number of symbols, which is 256, we obtain a
  sample size bound by 8192.
  For a sample of at most 8KB of data per data range: 16 consecutive bytes
  from up to 512 locations.
 Partial copy of input data 
 Buckets store counters for each byte value 
 Sorting buffer 
 The heuristic is represented as compression type 0 
		
		  This can't happen, the type is validated several times
		  before we get here.
		
		  This can't happen, the type is validated several times
		  before we get here.
	
	  Preallocate one workspace for each compression type so we can
	  guarantee forward progress in the worst case
  This finds an available workspace or allocates a new one.
  If it's not possible to allocate a new one, waits until there's one.
  Preallocation makes a forward progress guarantees and we do not return
  errors.
	
	  Allocation helpers call vmalloc that can't use GFP_NOFS, so we have
	  to turn it off here because we might get called from the restricted
	  context of btrfs_compress_biobtrfs_compress_pages
		
		  Do not return the error but go back to waiting. There's a
		  workspace preallocated for each type and the compression
		  time is bounded so we get to a workspace eventually. This
		  makes our caller's life easier.
		 
		  To prevent silent and low-probability deadlocks (when the
		  initial preallocation fails), check if there are any
		  workspaces at all.
 once per minute  60  HZ,
 no burst  1);
		
		  This can't happen, the type is validated several times
		  before we get here.
  put a workspace struct back on the list or free it if we have enough
  idle ones sitting around
		
		  This can't happen, the type is validated several times
		  before we get here.
  Adjust @level according to the limits of the compression algorithm or
  fallback to default
  Given an address space and start and length, compress the bytes into @pages
  that are allocated on demand.
  @type_level is encoded algorithm and level, where level 0 means whatever
  default the algorithm chooses and is opaque here;
  - compression algo are 0-3
  - the level are bits 4-7
  @out_pages is an inout parameter, holds maximum number of pages to allocate
  and returns number of actually allocated pages
  @total_in is used to return the number of bytes actually read.  It
  may be smaller than the input length if we had to exit early because we
  ran out of room in the pages array or because we cross the
  max_out threshold.
  @total_out is an inout parameter, must be set to the input length and will
  be also used to return the total number of compressed bytes
  a less complex decompression routine.  Our compressed data fits in a
  single page, and we want to read a single page out of it.
  start_byte tells us the offset into the compressed data we're interested in
  Copy decompressed data from working buffer to pages.
  @buf:		The decompressed data buffer
  @buf_len:		The decompressed data length
  @decompressed:	Number of bytes that are already decompressed inside the
  			compressed extent
  @cb:			The compressed extent descriptor
  @orig_bio:		The original bio that the caller wants to read for
  An easier to understand graph is like below:
  		|<- orig_bio ->|     |<- orig_bio->|
  	|<-------      full decompressed extent      ----->|
  	|<-----------    @cb range   ---->|
  	|			|<-- @buf_len -->|
  	|<--- @decompressed --->|
  Note that, @cb can be a subpage of the full decompressed extent, but
  @cb->start always has the same as the orig_file_offset value of the full
  decompressed extent.
  When reading compressed extent, we have to read the full compressed extent,
  while @orig_bio may only want part of the range.
  Thus this function will ensure only data covered by @orig_bio will be copied
  to.
  Return 0 if we have copied all needed contents for @orig_bio.
  Return >0 if we need continue decompress.
 Offset inside the full decompressed extent 
 The main loop to do the copy 
 Offset inside the full decompressed extent 
		
		  cb->start may underflow, but subtracting that value can still
		  give us correct offset inside the full decompressed extent.
 Haven't reached the bvec range, exit 
		
		  Extra range check to ensure we didn't go beyond
		  @buf + @buf_len.
 Finished the bio 
  Shannon Entropy calculation
  Pure byte distribution analysis fails to determine compressibility of data.
  Try calculating entropy to estimate the average minimum number of bits
  needed to encode the sampled data.
  For convenience, return the percentage of needed bits, instead of amount of
  bits directly.
  @ENTROPY_LVL_ACEPTABLE - below that threshold, sample has low byte entropy
 			    and can be compressible with high probability
  @ENTROPY_LVL_HIGH - data are not compressible with high probability
  Use of ilog2() decreases precision, we lower the LVL to 5 to compensate.
  For increasead precision in shannon_entropy calculation,
  let's do pow(n, M) to save more digits after comma:
  - maximum int bit length is 64
  - ilog2(MAX_SAMPLE_SIZE)	-> 13
  - 13  4 = 52 < 64		-> M = 4
  So use pow(n, 4).
 Reverse order 
  Use 4 bits as radix base
  Use 16 u32 counters for calculating new position in buf array
  @array     - array that will be sorted
  @array_buf - buffer array to store sorting results
               must be equal in size to @array
  @num       - array size
	
	  Try avoid useless loop iterations for small numbers stored in big
	  counters.  Example: 48 33 4 ... in 64bit array
		
		  Normal radix expects to move data from a temporary array, to
		  the main one.  But that requires some CPU time. Avoid that
		  by doing another sort iteration to original array instead of
		  memcpy()
  Size of the core byte set - how many bytes cover 90% of the sample
  There are several types of structured binary data that use nearly all byte
  values. The distribution can be uniform and counts in all buckets will be
  nearly the same (eg. encrypted data). Unlikely to be compressible.
  Other possibility is normal (Gaussian) distribution, where the data could
  be potentially compressible, but we have to take a few more steps to decide
  how much.
  @BYTE_CORE_SET_LOW  - main part of byte values repeated frequently,
                        compression algo can easy fix that
  @BYTE_CORE_SET_HIGH - data have uniform distribution and with high
                        probability is not compressible
 Sort in reverse order 
  Count byte values in buckets.
  This heuristic can detect textual data (configs, xml, json, html, etc).
  Because in most text-like data byte set is restricted to limited number of
  possible characters, and that restriction in most cases makes data easy to
  compress.
  @BYTE_SET_THRESHOLD - consider all data within this byte set size:
 	less - compressible
 	more - need additional analysis
	
	  Continue collecting count of byte values in buckets.  If the byte
	  set size is bigger then the threshold, it's pointless to continue,
	  the detection technique would fail for this type of data.
	
	  Compression handles the input data by chunks of 128KiB
	  (defined by BTRFS_MAX_UNCOMPRESSED)
	 
	  We do the same for the heuristic and loop over the whole range.
	 
	  MAX_SAMPLE_SIZE - calculated under assumption that heuristic will
	  process no more than BTRFS_MAX_UNCOMPRESSED at a time.
 Don't miss unaligned end 
 Handle case where the start is not aligned to PAGE_SIZE 
 Don't sample any garbage from the last page 
  Compression heuristic.
  For now is's a naive and optimistic 'return true', we'll extend the logic to
  quickly (compared to direct compression) detect data characteristics
  (compressibleuncompressible) to avoid wasting CPU time on uncompressible
  data.
  The following types of analysis can be performed:
  - detect mostly zero data
  - detect data with low "byte set" size (text, etc)
  - detect data with lowhigh "core byte" set
  Return non-zero if the compression should be done, 0 otherwise.
	
	  For the levels below ENTROPY_LVL_HIGH, additional analysis would be
	  needed to give green light to compression.
	 
	  For now just assume that compression at that level is not worth the
	  resources because:
	 
	  1. it is possible to defrag the data later
	 
	  2. the data would turn out to be hardly compressible, eg. 150 byte
	  values, every bucket has counter at level ~54. The heuristic would
	  be confused. This can happen when data have some internal repeated
	  patterns like "abbacbbc...". This can be detected by analyzing
	  pairs of bytes, which is too costly.
  Convert the compression suffix (eg. after "zlib" starting with ":") to
  level, unrecognized string will set the default level
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2007 Oracle.  All rights reserved.
  Defrag all the leaves in a given btree.
  Read all the leaves and try to get key order to
  better reflect disk order
		
		  there's recursion here right now in the tree locking,
		  we can't defrag the extent root without deadlock
 from above we know this is not a leaf 
	
	  We don't need a lock on a leaf. btrfs_realloc_node() will lock all
	  leafs from path->nodes[1], so set lowest_level to 1 to avoid later
	  a deadlock (attempting to write lock an already write locked leaf).
	
	  The node at level 1 must always be locked when our path has
	  keep_locks set and lowest_level is 1, regardless of the value of
	  path->slots[1].
	
	  Now that we reallocated the node we can find the next key. Note that
	  btrfs_find_next_key() can release our path and do another search
	  without COWing, this is because even with path->keep_locks = 1,
	  btrfs_search_slot()  ctree.c:unlock_up() does not keeps a lock on a
	  node when path->slots[node_level - 1] does not point to the last
	  item or a slot beyond the last item (ctree.c:unlock_up()). Therefore
	  we search for the next key after reallocating our node.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2008 Oracle.  All rights reserved.
 magic values for the inode_only field in btrfs_log_inode:
  LOG_INODE_ALL means to log everything
  LOG_INODE_EXISTS means to log just enough to recreate the inode
  during log replay
  directory trouble cases
  1) on rename or unlink, if the inode being unlinked isn't in the fsync
  log, we must force a full commit before doing an fsync of the directory
  where the unlink was done.
  ---> record transid of last unlinkrename per directory
  mkdir foosome_dir
  normal commit
  rename foosome_dir foo2some_dir
  mkdir foosome_dir
  fsync foosome_dirsome_file
  The fsync above will unlink the original some_dir without recording
  it in its new location (foo2).  After a crash, some_dir will be gone
  unless the fsync of some_file forces a full commit
  2) we must log any new names for any file or dir that is in the fsync
  log. ---> check inode while renaminglinking.
  2a) we must log any new names for any file or dir during rename
  when the directory they are being removed from was logged.
  ---> check inode and old parent dir during rename
   2a is actually the more important variant.  With the extra logging
   a crash might unlink the old name without recreating the new one
  3) after a crash, we must go through any directories with a link count
  of zero and redo the rm -rf
  mkdir f1foo
  normal commit
  rm -rf f1foo
  fsync(f1)
  The directory f1 was fully removed from the FS, but fsync was never
  called on f1, only its parent dir.  After a crash the rm -rf must
  be replayed.  This must be able to recurse down the entire
  directory tree.  The inode link count fixup code takes care of the
  ugly details.
  stages for the tree walking.  The first
  stage (0) is to only pin down the blocks we find
  the second stage (1) is to make sure that all the inodes
  we find in the log are created in the subvolume.
  The last stage is to deal with directories and links and extents
  and all the other fun semantics
  tree logging is a special write ahead log used to make sure that
  fsyncs and O_SYNCs can happen without doing full tree commits.
  Full tree commits are expensive because they require commonly
  modified blocks to be recowed, creating many dirty pages in the
  extent tree an 4x-6x higher write load than ext3.
  Instead of doing a tree commit on every fsync, we use the
  key ranges and transaction ids to find items for a given file or directory
  that have changed in this transaction.  Those items are copied into
  a special tree (one per subvolume root), that tree is written to disk
  and then the fsync is considered complete.
  After a crash, items are copied out of the log-tree back into the
  subvolume tree.  Any file data extents found are recorded in the extent
  allocation tree, and the log-tree freed.
  The log tree is read three times, once to pin down all the extents it is
  using in ram and once, once to create all the inodes logged in the tree
  and once to do all the other items.
  start a sub transaction and setup the log tree
  this increments the log tree writer count to make the people
  syncing the tree wait for us to finish
	
	  First check if the log root tree was already created. If not, create
	  it before locking the root's log_mutex, just to keep lockdep happy.
		
		  This means fs_info->log_root_tree was already created
		  for some other FS trees. Do the full commit not to mix
		  nodes from multiple log transactions to do sequential
		  writing.
  returns 0 if there was a log transaction running and we were able
  to join, or returns -ENOENT if there were not transactions
  in progress
  This either makes the current running log transaction wait
  until you call btrfs_end_log_trans() or it makes any future
  log transactions wait until you call btrfs_end_log_trans()
  indicate we're done making changes to the log tree
  and wake up anyone waiting to do a sync
 atomic_dec_and_test implies a barrier 
  the walk control struct is used to pass state down the chain when
  processing the log tree.  The stage field tells us which part
  of the log tree processing we are currently doing.  The others
  are state fields used for that specific part
	 should we free the extent on disk when done?  This is used
	  at transaction commit time while freeing a log tree
	 should we write out the extent buffer?  This is used
	  while flushing the log tree to disk during a sync
	 should we wait for the extent buffer io to finish?  Also used
	  while flushing the log tree to disk for a sync
	 pin only walk, we record which extents on disk belong to the
	  log trees
 what stage of the replay code we're currently in 
	
	  Ignore any items from the inode currently being processed. Needs
	  to be set every time we find a BTRFS_INODE_ITEM_KEY and we are in
	  the LOG_WALK_REPLAY_INODES stage.
 the root we are currently replaying 
 the trans handle for the current replay 
	 the function that gets used to process blocks we find in the
	  tree.  Note the extent_buffer might not be up to date when it is
	  passed in, and it must be checked or read if you need the data
	  inside it
  process_func used to pin down extents, write them or wait on them
	
	  If this fs is mixed then we need to be able to process the leaves to
	  pin down any logged extents, so we have to read the block.
 Our caller must have done a search for the key for us. 
	
	  And the slot must point to the exact key or the slot where the key
	  should be at (the first item with a key greater than 'key')
		
		  they have the same contents, just return, this saves
		  us from cowing blocks in the destination tree and doing
		  extra writes that may not have been done by a previous
		  sync
		
		  We need to load the old nbytes into the inode so when we
		  replay the extents we've logged we get the right nbytes.
			
			  If this is a directory we need to reset the i_size to
			  0 so that we can set it up properly when replaying
			  the rest of the items in this log.
		
		  New inode, set nbytes to 0 so that the nbytes comes out
		  properly when we replay the extents.
		
		  If this is a directory we need to reset the i_size to 0 so
		  that we can set it up properly when replaying the rest of
		  the items in this log.
 try to insert the key into the destination tree 
 make sure any existing item is the correct size 
	 don't overwrite an existing inode if the generation number
	  was logged as zero.  This is done when the tree logging code
	  is just logging an inode to make sure it exists after recovery.
	 
	  Also, don't overwrite i_size on directories during replay.
	  log replay inserts and removes directory items based on the
	  state of the tree found in the subvolume, and i_size is modified
	  as it goes
			
			  For regular files an ino_size == 0 is used only when
			  logging that an inode exists, as part of a directory
			  fsync, and the inode wasn't fsynced before. In this
			  case don't set the size of the inode in the fssubvol
			  tree, otherwise we would be throwing valid data away.
 make sure the generation is filled in 
  Item overwrite used by replay and tree logging.  eb, slot and key all refer
  to the src data we are copying out.
  root is the tree we are copying into, and path is a scratch
  path for use in this function (it should be released on entry and
  will be released on exit).
  If the key is already in the destination tree the existing item is
  overwritten.  If the existing item isn't big enough, it is extended.
  If it is too large, it is truncated.
  If the key isn't in the destination yet, a new item is inserted.
 Look for the key in the destination tree. 
  simple helper to read an inode off the disk from a given root
  This can only be called for subvolume roots and not for the log
 replays a single extent in 'eb' at 'slot' with 'key' into the
  subvolume 'root'.  path is released on entry and should be released
  on exit.
  extents in the log tree have not been allocated out of the extent
  tree yet.  So, this completes the allocation, taking a reference
  as required if the extent already exists or creating a new extent
  if it isn't in the extent allocation tree yet.
  The extent is inserted into the file, dropping any existing extents
  from the file that overlap the new one.
		
		  We don't add to the inodes nbytes if we are prealloc or a
		  hole.
	
	  first check to see if we already have this extent in the
	  file.  This must be done before the btrfs_drop_extents run
	  so we don't try to drop this extent.
		
		  we already have a pointer to this exact extent,
		  we don't have to do anything
 drop any overlapping extents 
		
		  Manually record dirty extent, as here we did a shallow
		  file extent item copy and skip normal backref update,
		  but modifying extent tree all by ourselves.
		  So need to manually record dirty extent for qgroup,
		  as the owner of the file extent changed from log tree
		  (doesn't affect qgroup) to fsfile tree(affects qgroup)
			
			  is this extent already allocated in the extent
			  allocation tree?  If so, just add a reference
				
				  insert the extent pointer in the extent
				  allocation tree
			
			  Now delete all existing cums in the csum root that
			  cover our range. We do this because we can have an
			  extent that is completely referenced by one file
			  extent item and partially referenced by another
			  file extent item (like after using the clone or
			  extent_same ioctls). In this case if we end up doing
			  the replay of the one that partially references the
			  extent first, and we do not do the csum deletion
			  below, we can get 2 csum items in the csum tree that
			  overlap each other. For example, imagine our log has
			  the two following file extent items:
			 
			  key (257 EXTENT_DATA 409600)
			      extent data disk byte 12845056 nr 102400
			      extent data offset 20480 nr 20480 ram 102400
			 
			  key (257 EXTENT_DATA 819200)
			      extent data disk byte 12845056 nr 102400
			      extent data offset 0 nr 102400 ram 102400
			 
			  Where the second one fully references the 100K extent
			  that starts at disk byte 12845056, and the log tree
			  has a single csum item that covers the entire range
			  of the extent:
			 
			  key (EXTENT_CSUM EXTENT_CSUM 12845056) itemsize 100
			 
			  After the first file extent item is replayed, the
			  csum tree gets the following csum item:
			 
			  key (EXTENT_CSUM EXTENT_CSUM 12865536) itemsize 20
			 
			  Which covers the 20K sub-range starting at offset 20K
			  of our extent. Now when we replay the second file
			  extent item, if we do not delete existing csum items
			  that cover any of its blocks, we end up getting two
			  csum items in our csum tree that overlap each other:
			 
			  key (EXTENT_CSUM EXTENT_CSUM 12845056) itemsize 100
			  key (EXTENT_CSUM EXTENT_CSUM 12865536) itemsize 20
			 
			  Which is a problem, because after this anyone trying
			  to lookup up for the checksum of any block of our
			  extent starting at an offset of 40K or higher, will
			  end up looking at the second csum item only, which
			  does not contain the checksum for any block starting
			  at offset 40K or higher of our extent.
 inline extents are easy, we just overwrite them 
  when cleaning up conflicts between the directory names in the
  subvolume, directory names in the log and directory names in the
  inode back references, we may have to unlink inodes from directories.
  This is a helper function to do the unlink of a specific directory
  item
  See if a given name and sequence number found in an inode back reference are
  already in a directory and correctly point to this inode.
  Returns: < 0 on error, 0 if the directory entry does not exists and 1 if it
  exists.
  helper function to check a log tree for a named back reference in
  an inode.  This is used to decide if a back reference that is
  found in the subvolume conflicts with what we find in the log.
  inode backreferences may have multiple refs in a single item,
  during replay we process one reference at a time, and we don't
  want to delete valid links to a file from the subvolume if that
  link is also in the log.
 Search old style refs 
		 are we trying to overwrite a back ref for the root directory
		  if so, just jump out, we're done
		 check all the names in this back reference to see
		  if they are in the log.  if so, we allow them to stay
		  otherwise they must be unlinked as a conflict
		
		  NOTE: we have searched root tree and checked the
		  corresponding ref, it does not need to check again.
 Same search but for extended refs 
 look for a conflicting sequence number 
 look for a conflicting name 
  Take an inode reference item from the log tree and iterate all names from the
  inode reference item in the subvolume tree with the same key (if it exists).
  For any name that is not in the inode reference item from the log tree, do a
  proper unlink of that name (that is, remove its entry from the inode
  reference item and both dir index keys).
	
	  Our inode's dentry collides with the dentry of another inode which is
	  in the log but not yet processed since it has a higher inode number.
	  So delete that other dentry.
	
	  If we dropped the link count to 0, bump it so that later the iput()
	  on the inode will not free it. We will fixup the link count later.
  replay one inode back reference item found in the log tree.
  eb, slot and key refer to the buffer and key found in the log tree.
  root is the destination we are replaying into, and path is for temp
  use by this function.  (it should be released on return).
	
	  it is possible that we didn't log all the parent directories
	  for a given inode.  If we don't find the dir, just don't
	  copy the back ref in.  The link count fixup code will take
	  care of the rest
			
			  parent object can change from one array
			  item to another.
			
			  look for a conflicting back reference in the
			  metadata. if we find one we have to unlink that name
			  of the file before we add our new link.  Later on, we
			  overwrite any existing back reference, and we don't
			  want to create dangling pointers in the directory.
			
			  If a reference item already exists for this inode
			  with the same parent and name, but different index,
			  drop it and the corresponding directory index entries
			  from the parent before adding the new reference item
			  and dir index entries, otherwise we would fail with
			  -EEXIST returned from btrfs_add_link() below.
				
				  If we dropped the link count to 0, bump it so
				  that later the iput() on the inode will not
				  free it. We will fixup the link count later.
 insert our name 
 Else, ret == 1, we already have a perfect match, we're done. 
	
	  Before we overwrite the inode reference item in the subvolume tree
	  with the item from the log tree, we must unlink all names from the
	  parent directory that are in the subvolume's tree inode reference
	  item, otherwise we end up with an inconsistent subvolume tree where
	  dir index entries exist for a name but there is no inode reference
	  item with the same name.
 finally write the back reference in the inode 
  There are a few corners where the link count of the file can't
  be properly maintained during replay.  So, instead of adding
  lots of complexity to the log code, we just scan the backrefs
  for any file that has been through replay.
  The scan will update the link count on the inode to reflect the
  number of back refs found.  If it goes down to zero, the iput
  will free the inode.
		
		  fixup on a directory may create new entries,
		  make sure we always look for the highset possible
		  offset
  record a given inode in the fixup dir so we can check its link
  count when replay is done.  The link count is incremented here
  so the inode won't go away until we check it
  when replaying the log for a directory, we only insert names
  for inodes that actually exist.  This means an fsync on a directory
  does not implicitly fsync all the new files in it
 FIXME, put inode into FIXUP list 
  take a single entry in a log directory item and replay it into
  the subvolume.
  if a conflicting item exists in the subdirectory already,
  the inode it points to is unlinked and put into the link count
  fix up tree.
  If a name from the log points to a file or directory that does
  not exist in the FS, it is skipped.  fsyncs on directories
  do not force down inodes inside that directory, just changes to the
  names or unlinks in a directory.
  Returns < 0 on error, 0 if the name wasn't replayed (dentry points to a
  non-existing inode) and 1 if the name was replayed.
 Corruption 
		 we need a sequence number to insert, so we only
		  do inserts for the BTRFS_DIR_INDEX_KEY types
 the existing item matches the logged item 
	
	  don't drop the conflicting directory entry if the inode
	  for the new entry doesn't exist
	
	  Check if the inode reference exists in the log for the given name,
	  inode and parent inode
 The dentry will be added later. 
 The dentry will be added later. 
  find all the names in a directory item and reconcile them into
  the subvolume.  Only BTRFS_DIR_ITEM_KEY types will have more than
  one name in a directory item, but the same code gets used for
  both directory index types
		
		  If this entry refers to a non-directory (directories can not
		  have a link count > 1) and it was added in the transaction
		  that was not committed, make sure we fixup the link count of
		  the inode it the entry points to. Otherwise something like
		  the following would result in a directory pointing to an
		  inode with a wrong link that does not account for this dir
		  entry:
		 
		  mkdir testdir
		  touch testdirfoo
		  touch testdirbar
		  sync
		 
		  ln testdirbar testdirbar_link
		  ln testdirfoo testdirfoo_link
		  xfs_io -c "fsync" testdirbar
		 
		  <power failure>
		 
		  mount fs, log replay happens
		 
		  File foo would remain with a link count of 1 when it has two
		  entries pointing to it in the directory testdir. This would
		  make it impossible to ever delete the parent directory has
		  it would result in stale dentries that can never be deleted.
  directory replay has two parts.  There are the standard directory
  items in the log copied from the subvolume, and range items
  created in the log while the subvolume was logged.
  The range items tell us which parts of the key space the log
  is authoritative for.  During replay, if a key in the subvolume
  directory is in a logged range item, but not actually in the log
  that means it was deleted from the directory before the fsync
  and should be removed.
 check the next slot in the tree to see if it is a valid item 
  this looks for a given directory item in the log.  If the directory
  item is not in the log, the item is removed and the inode it points
  to is unlinked
			 there might still be more names under this key
			  check and repeat if required
 Doesn't exist in log tree, so delete it. 
  deletion replay happens before we copy any new directory items
  out of the log or out of backreferences from inodes.  It
  scans the log to find ranges of keys that log is authoritative for,
  and then scans the directory to find items in those ranges that are
  not present in the log.
  Anything we don't find in the log is unlinked and removed from the
  directory.
	 it isn't an error if the inode isn't there, that can happen
	  because we replay the deletes before we copy in the inode item
	  from the log
  the process_func used to replay items from the log tree.  This
  gets called in two different stages.  The first stage just looks
  for inodes and makes sure they are all copied into the subvolume.
  The second stage copies all the other item types from the log into
  the subvolume.  The two stage approach is slower, but gets rid of
  lots of complexity around inodes referencing other inodes that exist
  only in the log (references come from either directory items or inode
  back refs).
 inode keys are done during the first stage 
			
			  If we have a tmpfile (O_TMPFILE) that got fsync'ed
			  and never got linked before the fsync, skip it, as
			  replaying it is pointless since it would be deleted
			  later. We skip logging tmpfiles, but it's always
			  possible we are replaying a log created with a kernel
			  that used to log tmpfiles.
			
			  Before replaying extents, truncate the inode to its
			  size. We need to do it now and not after log replay
			  because before an fsync we can have prealloc extents
			  added beyond the inode's i_size. If we did it after,
			  through orphan cleanup for example, we would drop
			  those prealloc extents just after replaying them.
 Update the inode's nbytes. 
 these keys are simply copied 
  Correctly adjust the reserved bytes occupied by a log tree extent buffer
  drop the reference count on the tree rooted at 'snap'.  This traverses
  the tree freeing any blocks that have a ref count of zero after being
  decremented.
 was the root node processed? if not, catch it here 
  helper function to update the item for a given subvolumes log root
  in the tree of log roots
 insert root item on the first sync 
	
	  we only allow two pending log transactions at a time,
	  so we know that if ours is more than 2 older than the
	  current transaction, we're done
  Invoked in log mutex context, or be sure there is no other task which
  can access the list.
  btrfs_sync_log does sends a given tree log down to the disk and
  updates the super blocks to record it.  When this call is done,
  you know that any inodes previously logged are safely on disk only
  if it returns 0.
  Any other return value means you need to call btrfs_commit_transaction.
  Some of the edge cases for fsyncing directories that have had unlinks
  or renames done in the past mean that sometimes the only safe
  fsync is to commit the whole FS.  When btrfs_sync_log returns -EAGAIN,
  that has happened.
 wait for previous tree log sync to complete 
 when we're on an ssd, just kick the log commit out 
 bail out if we need to do a full commit 
	 we start IO on  all the marked extents here, but we don't actually
	  wait for them until later.
	
	  -EAGAIN happens when someone, e.g., a concurrent transaction
	   commit, writes a dirty extent in this tree-log commit. This
	   concurrent write will create a hole writing out the extents,
	   and we cannot proceed on a zoned filesystem, requiring
	   sequential writing. While we can bail out to a full commit
	   here, but we can continue hoping the concurrent writing fills
	   the hole.
	
	  We _must_ update under the root->log_mutex in order to make sure we
	  have a consistent view of the log root we are trying to commit at
	  this moment.
	 
	  We _must_ copy this into a local copy, because we are not holding the
	  log_root_tree->log_mutex yet.  This is important because when we
	  commit the log_root_tree we must have a consistent view of the
	  log_root_tree when we update the super block to point at the
	  log_root_tree bytenr.  If we update the log_root_tree here we'll race
	  with the commit and possibly point at the new block which we may not
	  have written out.
	
	  IO has been started, blocks of the log tree have WRITTEN flag set
	  in their headers. new modifications of the log will be written to
	  new positions. so it's safe to allow log writers to go in.
	
	  Now we are safe to update the log_root_tree because we're under the
	  log_mutex, and we're a current writer so we're holding the commit
	  open until we drop the log_mutex.
	
	  now that we've moved on to the tree of log tree roots,
	  check the full commit flag again
	
	  As described above, -EAGAIN indicates a hole in the extents. We
	  cannot wait for these write outs since the waiting cause a
	  deadlock. Bail out to the full commit instead.
	
	  Here we are guaranteed that nobody is going to write the superblock
	  for the current transaction before us and that neither we do write
	  our superblock before the previous transaction finishes its commit
	  and writes its superblock, because:
	 
	  1) We are holding a handle on the current transaction, so no body
	     can commit it until we release the handle;
	 
	  2) Before writing our superblock we acquire the tree_log_mutex, so
	     if the previous transaction is still committing, and hasn't yet
	     written its superblock, we wait for it to do it, because a
	     transaction commit acquires the tree_log_mutex when the commit
	     begins and releases it only after writing its superblock.
	
	  The previous transaction writeout phase could have failed, and thus
	  marked the fs in an error state.  We must not commit here, as we
	  could have updated our generation in the super_for_commit and
	  writing the super here would result in transid mismatches.  If there
	  is an error here just bail.
	
	  We know there can only be one task here, since we have not yet set
	  root->log_commit[index1] to 0 and any task attempting to sync the
	  log must wait for the previous log transaction to commit if it's
	  still in progress or wait for the current log transaction commit if
	  someone else already started it. We use <= and not < because the
	  first log transaction has an ID of 0.
	
	  The barrier before waitqueue_active (in cond_wake_up) is needed so
	  all the updates above are seen by the woken threads. It might not be
	  necessary, but proving that seems to be hard.
	
	  The barrier before waitqueue_active (in cond_wake_up) is needed so
	  all the updates above are seen by the woken threads. It might not be
	  necessary, but proving that seems to be hard.
  free all the extents used by the tree log.  This should be called
  at commit time of the full transaction
  Check if an inode was logged in the current transaction. This may often
  return some false positives, because logged_trans is an in memory only field,
  not persisted anywhere. This is meant to be used in contexts where a false
  positive has no functional consequences.
	
	  The inode's logged_trans is always 0 when we load it (because it is
	  not persisted in the inode item or elsewhere). So if it is 0, the
	  inode was last modified in the current transaction then the inode may
	  have been logged before in the current transaction, then evicted and
	  loaded again in the current transaction - or may have never been logged
	  in the current transaction, but since we can not be sure, we have to
	  assume it was, otherwise our callers can leave an inconsistent log.
  If both a file and directory are logged, and unlinks or renames are
  mixed in, we have a few interesting corners:
  create file X in dir Y
  link file X to X.link in dir Y
  fsync file X
  unlink file X but leave X.link
  fsync dir Y
  After a crash we would expect only X.link to exist.  But file X
  didn't get fsync'd again so the log has back refs for X and X.link.
  We solve this by removing directory entries and inode backrefs from the
  log when a file that was logged in the current transaction is
  unlinked.  Any later fsync will include the updated log entries, and
  we'll be able to reconstruct the proper directory items from backrefs.
  This optimizations allows us to avoid relogging the entire inode
  or the entire directory.
	
	  We do not need to update the size field of the directory's inode item
	  because on log replay we update the field to reflect all existing
	  entries in the directory (see overwrite_item()).
 see comments for btrfs_del_dir_entries_in_log 
  creates a range item in the log for 'dirid'.  first_offset and
  last_offset tell us which parts of the key space the log should
  be considered authoritative for.
	
	  Copy all the items in bulk, in a single copy operation. Item data is
	  organized such that it's placed at the end of a leaf and from right
	  to left. For example, the data for the second item ends at an offset
	  that matches the offset where the data for the first item starts, the
	  data for the third item ends at an offset that matches the offset
	  where the data of the second items starts, and so on.
	  Therefore our source and destination start offsets for copy match the
	  offsets of the last items (highest slots).
		
		  We must make sure that when we log a directory entry, the
		  corresponding inode, after log replay, has a matching link
		  count. For example:
		 
		  touch foo
		  mkdir mydir
		  sync
		  ln foo mydirbar
		  xfs_io -c "fsync" mydir
		  <crash>
		  <mount fs and log replay>
		 
		  Would result in a fsync log that when replayed, our file inode
		  would have a link count of 1, but we get two directory entries
		  pointing to the same inode. After removing one of the names,
		  it would not be possible to remove the other name, which
		  resulted always in stale file handle errors, and would not be
		  possible to rmdir the parent directory, since its i_size could
		  never be decremented to the value BTRFS_EMPTY_DIR_SIZE,
		  resulting in -ENOTEMPTY errors.
		
		  If we were logged before and have logged dir items, we can skip
		  checking if any item with a key offset larger than the last one
		  we logged is in the log tree, saving time and avoiding adding
		  contention on the log tree.
		
		  Check if the key was already logged before. If not we can add
		  it to a batch for bulk insertion.
		
		  Item exists in the log. Overwrite the item in the log if it
		  has different content or do nothing if it has exactly the same
		  content. And then flush the current batch if any - do it after
		  overwriting the current item, or we would deadlock otherwise,
		  since we are holding a path for the existing item.
  log all the items included in the current transaction for a given
  directory.  This also creates the range items in the log tree required
  to replay anything deleted before the fsync
	
	  we didn't find anything from this transaction, see if there
	  is anything at all
		 if ret == 0 there are items for this type,
		  create a range to tell us the last key of this type.
		  otherwise, there are no items in this directory after
		  min_offset, and we create a range to indicate that.
 go backward to find any previous key 
	
	  Find the first key from this transaction again.  See the note for
	  log_new_dir_dentries, if we're logging a directory recursively we
	  won't be holding its i_mutex, which means we can modify the directory
	  while we're logging it.  If we remove an entry between our first
	  search and this search we'll not find the key again and can just
	  bail.
	
	  we have a block from this transaction, log every item in it
	  from our directory
		
		  look ahead to the next item and see if it is also
		  from this directory and from this transaction
		
		  insert the log range keys to indicate where the log
		  is valid
  logging directories is very similar to logging inodes, We find all the items
  from the current transaction and write them to the log.
  The recovery code scans the directory in the subvolume, and if it finds a
  key in the range logged that is not present in the log tree, then it means
  that dir entry was unlinked during the transaction.
  In order for that scan to work, we must include one key smaller than
  the smallest logged by this transaction and one key larger than the largest
  key logged by this transaction.
	
	  If this is the first time we are being logged in the current
	  transaction, or we were logged before but the inode was evicted and
	  reloaded later, in which case its logged_trans is 0, reset the values
	  of the last logged key offsets. Note that we don't use the helper
	  function inode_logged() here - that is because the function returns
	  true after an inode eviction, assuming the worst case as it can not
	  know for sure if the inode was logged before. So we can not skip key
	  searches in the case the inode was evicted, because it may not have
	  been logged in this transaction and may have been logged in a past
	  transaction, so we need to reset the last dir item and index offsets
	  to (u64)-1.
  a helper function to drop items from the log before we relog an
  inode.  max_key_type indicates the highest item type to remove.
  This cannot be run for file data extents because it does not
  free the extents they point to.
 Logic error 
		
		  If start slot isn't 0 then we don't need to re-search, we've
		  found the last guy with the objectid in this tree.
		 set the generation to zero so the recover code
		  can tell the difference between an logging
		  just to say 'this inode exists' and a logging
		  to say 'update this inode with these values'
	
	  We do not need to set the nbytes field, in fact during a fast fsync
	  its value may not even be correct, since a fast fsync does not wait
	  for ordered extent completion, which is where we update nbytes, it
	  only waits for writeback to complete. During log replay as we find
	  file extent items and replay them, we adjust the nbytes field of the
	  inode item in subvolume tree as needed (see overwrite_item()).
	
	  If we are doing a fast fsync and the inode was logged before in the
	  current transaction, then we know the inode was previously logged and
	  it exists in the log tree. For performance reasons, in this case use
	  btrfs_search_slot() directly with ins_len set to 0 so that we never
	  attempt a write lock on the leaf's parent, which adds unnecessary lock
	  contention in case there are concurrent fsyncs for other inodes of the
	  same subvolume. Using btrfs_insert_empty_item() when the inode item
	  already exists can also result in unnecessarily splitting a leaf.
		
		  This means it is the first fsync in the current transaction,
		  so the inode item is not in the log and we need to insert it.
		  We can never get -EEXIST because we are only called for a fast
		  fsync and in case an inode eviction happens after the inode was
		  logged before in the current transaction, when we load again
		  the inode, we set BTRFS_INODE_NEEDS_FULL_SYNC on its runtime
		  flags and set ->logged_trans to 0.
	
	  If this inode was not used for reflink operations in the current
	  transaction with new extents, then do the fast path, no need to
	  worry about logging checksum items with overlapping ranges.
	
	  Serialize logging for checksums. This is to avoid racing with the
	  same checksum being logged by another task that is logging another
	  file which happens to refer to the same extent as well. Such races
	  can leave checksum items in the log with overlapping ranges.
	
	  Due to extent cloning, we might have logged a csum item that covers a
	  subrange of a cloned extent, and later we can end up logging a csum
	  item for a larger subrange of the same extent or the entire range.
	  This would leave csum items in the log tree that cover the same range
	  and break the searches for checksums in the log tree, resulting in
	  some checksums missing in the fssubvolume tree. So just delete (or
	  trim and adjust) any existing csum items in the log for this range.
		 take a reference on file data extents so that truncates
		  or deletes of this inode don't have to relog the inode
		  again
 ds == 0 is a hole 
	
	  we have to do this after the loop above to avoid changing the
	  log tree while trying to change the log tree.
		
		  We are going to copy all the csums on this ordered extent, so
		  go ahead and adjust mod_start and mod_len in case this ordered
		  extent has already been logged.
			
			  If we have this case
			 
			  |--------- logged extent ---------|
			        |----- ordered extent ----|
			 
			  Just don't mess with mod_start and mod_len, we'll
			  just end up logging more csums than we need and it
			  will be ok.
		
		  To keep us from looping for the above case of an ordered
		  extent that falls inside of the logged extent.
 We're done, found all csums in the ordered extents. 
 If we're compressed we have to save the entire range of csums. 
 block start is already adjusted for the file extent offset. 
	
	  If this is the first time we are logging the inode in the current
	  transaction, we can avoid btrfs_drop_extents(), which is expensive
	  because it does a deletion search, which always acquires write locks
	  for extent buffers at levels 2, 1 and 0. This not only wastes time
	  but also adds significant contention in a log tree, since log trees
	  are small, with a root at level 2 or 3 at most, due to their short
	  life span.
  Log all prealloc extents beyond the inode's i_size to make sure we do not
  lose them after doing a fast fsync and replaying the log. We scan the
  subvolume's root instead of iterating the inode's extent map tree because
  otherwise we can log incorrect extent items based on extent map conversion.
  That can happen due to the fact that extent maps are merged when they
  are not in the extent map tree's list of modified extents.
	
	  We must check if there is a prealloc extent that starts before the
	  i_size and crosses the i_size boundary. This is to ensure later we
	  truncate down to the end of that extent and not to the i_size, as
	  otherwise we end up losing part of the prealloc extent after a log
	  replay and with an implicit hole if there is another prealloc extent
	  that starts at an offset beyond i_size.
			
			  Avoid logging extent items logged in past fsync calls
			  and leading to duplicate keys in the log tree.
		
		  Just an arbitrary number, this can be really CPU intensive
		  once we start getting a lot of extents, and really once we
		  have a bunch of extents we just want to commit since it will
		  be faster.
 We log prealloc extents beyond eof later. 
 Need a ref to keep it from getting evicted from cache 
		
		  If we had an error we just need to delete everybody from our
		  private list.
	
	  We have logged all extents successfully, now make sure the commit of
	  the current transaction waits for the ordered extents to complete
	  before it commits and wipes out the log trees, otherwise we would
	  lose data if an ordered extents completes after the transaction
	  commits and a power failure happens after the transaction commit.
		
		  If the in-memory inode's i_size is smaller then the inode
		  size stored in the btree, return the inode's i_size, so
		  that we get a correct inode size after replaying the log
		  when before a power failure we had a shrinking truncate
		  followed by addition of a new name (rename  new hard link).
		  Otherwise return the inode size from the btree, to avoid
		  data loss when replaying a log due to previously doing a
		  write that expands the inode's size and logging a new name
		  immediately after.
  At the moment we always log all xattrs. This is to figure out at log replay
  time which xattrs must have their deletion replayed. If a xattr is missing
  in the log tree and exists in the fssubvol tree, we delete it. This is
  because if a xattr is deleted, the inode is fsynced and a power failure
  happens, causing the log to be replayed the next time the fs is mounted,
  we want the xattr to not exist anymore (same behaviour as other filesystems
  with a journal, ext34, xfs, f2fs, etc).
  When using the NO_HOLES feature if we punched a hole that causes the
  deletion of entire leafs or all the extent items of the first leaf (the one
  that contains the inode item and references) we may end up not processing
  any extents, because there are no leafs with a generation matching the
  current transaction that have extent items for our inode. So we need to find
  if any holes exist and then log them. We also need to log holes after any
  truncate operation that changes the inode's size.
 We have a hole, log it. 
			
			  Release the path to avoid deadlocks with other code
			  paths that search the root while holding locks on
			  leafs from the log root.
			
			  Search for the same key again in the root. Since it's
			  an extent item and we are holding the inode lock, the
			  key must still exist. If it doesn't just emit warning
			  and return an error to fall back to a transaction
			  commit.
  When we are logging a new inode X, check if it doesn't have a reference that
  matches the reference from some other inode Y created in a past transaction
  and that was renamed in the current transaction. If we don't do this, then at
  log replay time we can lose inode Y (and all its files if it's a directory):
  mkdir mntx
  echo "hello world" > mntxfoobar
  sync
  mv mntx mnty
  mkdir mntx                 # or touch mntx
  xfs_io -c fsync mntx
  <power fail>
  mount fs, trigger log replay
  After the log replay procedure, we would lose the first directory and all its
  files (file foobar).
  For the case where inode Y is not a directory we simply end up losing it:
  echo "123" > mntfoo
  sync
  mv mntfoo mntbar
  echo "abc" > mntfoo
  xfs_io -c fsync mntfoo
  <power fail>
  We also need this for cases where a snapshot entry is replaced by some other
  entry (file or directory) otherwise we end up with an unreplayable log due to
  attempts to delete the snapshot entry (entry of type BTRFS_ROOT_ITEM_KEY) as
  if it were a regular entry:
  mkdir mntx
  btrfs subvolume snapshot mnt mntxsnap
  btrfs subvolume delete mntxsnap
  rmdir mntx
  mkdir mntx
  fsync mntx or fsync some new file inside it
  <power fail>
  The snapshot delete, rmdir of x, mkdir of a new x and the fsync all happen in
  the same transaction.
		
		  If the other inode that had a conflicting dir entry was
		  deleted in the current transaction, we need to log its parent
		  directory.
		
		  If the inode was already logged skip it - otherwise we can
		  hit an infinite loop. Example:
		 
		  From the commit root (previous transaction) we have the
		  following inodes:
		 
		  inode 257 a directory
		  inode 258 with references "zz" and "zz_link" on inode 257
		  inode 259 with reference "a" on inode 257
		 
		  And in the current (uncommitted) transaction we have:
		 
		  inode 257 a directory, unchanged
		  inode 258 with references "a" and "a2" on inode 257
		  inode 259 with reference "zz_link" on inode 257
		  inode 261 with reference "zz" on inode 257
		 
		  When logging inode 261 the following infinite loop could
		  happen if we don't skip already logged inodes:
		 
		  - we detect inode 258 as a conflicting inode, with inode 261
		    on reference "zz", and log it;
		 
		  - we detect inode 259 as a conflicting inode, with inode 258
		    on reference "a", and log it;
		 
		  - we detect inode 258 as a conflicting inode, with inode 259
		    on reference "zz_link", and log it - again! After this we
		    repeat the above steps forever.
		
		  Check the inode's logged_trans only instead of
		  btrfs_inode_in_log(). This is because the last_log_commit of
		  the inode is not updated when we only log that it exists (see
		  btrfs_log_inode()).
		
		  We are safe logging the other inode without acquiring its
		  lock as long as we log with the LOG_INODE_EXISTS mode. We
		  are safe against concurrent renames of the other inode as
		  well because during a rename we pin the log and update the
		  log with the new name before we unpin it.
 Note, ins_nr might be > 0 here, cleanup outside the loop 
 Skip xattrs, we log them later with btrfs_log_all_xattrs() 
 log a single inode in the tree log.
  At least one parent directory for this inode must exist in the tree
  or be logged already.
  Any items from this inode changed by the current transaction are copied
  to the log tree.  An extra reference is taken on any extents in this
  file, allowing us to avoid a whole pile of corner cases around logging
  blocks that have been removed from the tree.
  See LOG_INODE_ALL and related defines for a description of what inode_only
  does.
  This handles both files and directories.
 today the code can only do partial logging of directories 
	
	  Only run delayed items if we are a directory. We want to make sure
	  all directory indexes hit the fssubvolume tree so we can find them
	  and figure out which index ranges have to be logged.
	
	  This is for cases where logging a directory could result in losing a
	  a file after replaying the log. For example, if we move a file from a
	  directory A to a directory B, then fsync directory A, we have no way
	  to known the file was moved from A to B, so logging just A would
	  result in losing the file after a log replay.
	
	  a brute force approach to making sure we get the most uptodate
	  copies of everything.
			
			  Make sure the new inode item we write to the log has
			  the same isize as the current one (if it exists).
			  This is necessary to prevent data loss after log
			  replay, and also to prevent doing a wrong expanding
			  truncate - for e.g. create file, write 4K into offset
			  0, fsync, write 4K into offset 4096, add hard link,
			  fsync some other file (to sync log), power fail - if
			  we use the inode's current i_size, after log replay
			  we get a 8Kb file, with the last 4Kb extent as a hole
			  (zeroes), as if an expanding truncate happened,
			  instead of getting a file of 4Kb only.
		
		  If we are doing a fast fsync and the inode was logged before
		  in this transaction, we don't need to log the xattrs because
		  they were logged before. If xattrs were added, changed or
		  deleted since the last time we logged the inode, then we have
		  already logged them because the inode had the runtime flag
		  BTRFS_INODE_COPY_EVERYTHING set.
	
	  Don't update last_log_commit if we logged that an inode exists.
	  We do this for three reasons:
	 
	  1) We might have had buffered writes to this inode that were
	     flushed and had their ordered extents completed in this
	     transaction, but we did not previously log the inode with
	     LOG_INODE_ALL. Later the inode was evicted and after that
	     it was loaded again and this LOG_INODE_EXISTS log operation
	     happened. We must make sure that if an explicit fsync against
	     the inode is performed later, it logs the new extents, an
	     updated inode item, etc, and syncs the log. The same logic
	     applies to direct IO writes instead of buffered writes.
	 
	  2) When we log the inode with LOG_INODE_EXISTS, its inode item
	     is logged with an i_size of 0 or whatever value was logged
	     before. If later the i_size of the inode is increased by a
	     truncate operation, the log is synced through an fsync of
	     some other inode and then finally an explicit fsync against
	     this inode is made, we must make sure this fsync logs the
	     inode with the new i_size, the hole between old i_size and
	     the new i_size, and syncs the log.
	 
	  3) If we are logging that an ancestor inode exists as part of
	     logging a new name from a link or rename operation, don't update
	     its last_log_commit - otherwise if an explicit fsync is made
	     against an ancestor, the fsync considers the inode in the log
	     and doesn't sync the log, resulting in the ancestor missing after
	     a power failure unless the log was synced as part of an fsync
	     against any other unrelated inode.
  Check if we need to log an inode. This is used in contexts where while
  logging an inode we need to log another inode (either that it exists or in
  full mode). This is used instead of btrfs_inode_in_log() because the later
  requires the inode to be in the log and have the log transaction committed,
  while here we do not care if the log transaction was already committed - our
  caller will commit the log later - and we want to avoid logging an inode
  multiple times when multiple tasks have joined the same log transaction.
	
	  If a directory was not modified, no dentries added or removed, we can
	  and should avoid logging it.
	
	  If this inode does not have newupdateddeleted xattrs since the last
	  time it was logged and is flagged as logged in the current transaction,
	  we can skip logging it. As for newdeleted names, those are updated in
	  the log by linkunlinkrename operations.
	  In case the inode was logged and then evicted and reloaded, its
	  logged_trans will be 0, in which case we have to fully log it since
	  logged_trans is a transient field, not persisted.
  Log the inodes of the new dentries of a directory. See log_dir_items() for
  details about the why it is needed.
  This is a recursive operation - if an existing dentry corresponds to a
  directory, that directory's new entries are logged too (same behaviour as
  ext34, xfs, f2fs, reiserfs, nilfs2). Note that when logging the inodes
  the dentries point to we do not lock their i_mutex, otherwise lockdep
  complains about the following circular lock dependency  possible deadlock:
         CPU0                                        CPU1
         ----                                        ----
  lock(&type->i_mutex_dir_key#32);
                                             lock(sb_internal#2);
                                             lock(&type->i_mutex_dir_key#32);
  lock(&sb->s_type->i_mutex_key#14);
  Where sb_internal is the lock (a counter that works as a lock) acquired by
  sb_start_intwrite() in btrfs_start_transaction().
  Not locking i_mutex of the inodes is still safe because:
  1) For regular files we log with a mode of LOG_INODE_EXISTS. It's possible
     that while logging the inode new references (names) are added or removed
     from the inode, leaving the logged inode item with a link count that does
     not match the number of logged inode reference items. This is fine because
     at log replay time we compute the real number of links and correct the
     link count in the inode item (see replay_one_buffer() and
     link_to_fixup_dir());
  2) For directories we log with a mode of LOG_INODE_ALL. It's possible that
     while logging the inode's items new items with keys BTRFS_DIR_ITEM_KEY and
     BTRFS_DIR_INDEX_KEY are added to fssubvol tree and the logged inode item
     has a size that doesn't match the sum of the lengths of all the logged
     names. This does not result in a problem because if a dir_item key is
     logged but its matching dir_index key is not logged, at log replay time we
     don't use it to replay the respective name (see replay_one_name()). On the
     other hand if only the dir_index key ends up being logged, the respective
     name is added to the fssubvol tree with both the dir_item and dir_index
     keys created (see replay_one_name()).
     The directory's inode item with a wrong i_size is not a problem as well,
     since we don't use it at log replay time to set the i_size in the inode
     item of the fssubvol tree (see overwrite_item()).
	
	  If we are logging a new name, as part of a link or rename operation,
	  don't bother logging new dentries, as we just want to log the names
	  of an inode and that any new parents exist.
 BTRFS_INODE_EXTREF_KEY is BTRFS_INODE_REF_KEY + 1 
			
			  If the parent inode was deleted, return an error to
			  fallback to a transaction commit. This is to prevent
			  getting an inode that was moved from one parent A to
			  a parent B, got its former parent A deleted and then
			  it got fsync'ed, from existing at both parents after
			  a log replay (and the old parent still existing).
			  Example:
			 
			  mkdir mntA
			  mkdir mntB
			  touch mntBbar
			  sync
			  mv mntBbar mntAbar
			  mv -T mntA mntB
			  fsync mntBbar
			  <power fail>
			 
			  If we ignore the old parent B which got deleted,
			  after a log replay we would have file bar linked
			  at both parents and the old parent B would still
			  exist.
	
	  For a single hard link case, go through a fast path that does not
	  need to iterate the fssubvolume tree.
		
		  Don't deal with extended references because they are rare
		  cases and too complex to deal with (we would need to keep
		  track of which subitem we are processing for each item in
		  this loop, etc). So just return some error to fallback to
		  a transaction commit.
		
		  Logging ancestors needs to do more searches on the fssubvol
		  tree, so it releases the path as needed to avoid deadlocks.
		  Keep track of the last inode ref key and resume from that key
		  after logging all new ancestors for the current hard link.
  helper function around btrfs_log_inode to make sure newly created
  parent directories also end up in the log.  A minimal inode and backref
  only logging is done of any parent directories that are older than
  the last committed transaction
	
	  Skip already logged inodes or inodes corresponding to tmpfiles
	  (since logging them is pointless, a link count of 0 means they
	  will never be accessible).
	
	  for regular files, if its inode is already on disk, we don't
	  have to worry about the parents at all.  This is because
	  we can use the last_unlink_trans field to record renames
	  and other fun in this file.
	
	  On unlink we must make sure all our current and old parent directory
	  inodes are fully logged. This is to prevent leaving dangling
	  directory index entries in directories that were our parents but are
	  not anymore. Not doing this results in old parent directory being
	  impossible to delete after log replay (rmdir will always fail with
	  error -ENOTEMPTY).
	 
	  Example 1:
	 
	  mkdir testdir
	  touch testdirfoo
	  ln testdirfoo testdirbar
	  sync
	  unlink testdirbar
	  xfs_io -c fsync testdirfoo
	  <power failure>
	  mount fs, triggers log replay
	 
	  If we don't log the parent directory (testdir), after log replay the
	  directory still has an entry pointing to the file inode using the bar
	  name, but a matching BTRFS_INODE_[REF|EXTREF]_KEY does not exist and
	  the file inode has a link count of 1.
	 
	  Example 2:
	 
	  mkdir testdir
	  touch foo
	  ln foo testdirfoo2
	  ln foo testdirfoo3
	  sync
	  unlink testdirfoo3
	  xfs_io -c fsync foo
	  <power failure>
	  mount fs, triggers log replay
	 
	  Similar as the first example, after log replay the parent directory
	  testdir still has an entry pointing to the inode file with name foo3
	  but the file inode does not have a matching BTRFS_INODE_REF_KEY item
	  and has a link count of 2.
  it is not safe to log dentry if the chunk root has added new
  chunks.  This returns 0 if the dentry was logged, and 1 otherwise.
  If this returns 1, you must commit the transaction to safely get your
  data on disk.
  should be called during mount to recover any replay any log trees
  from the FS
			
			  We didn't find the subvol, likely because it was
			  deleted.  This is ok, simply skip this log and go to
			  the next one.
			 
			  We need to exclude the root because we can't have
			  other log replays overwriting this log as we'll read
			  it back in a few more times.  This will keep our
			  block from being modified, and we'll just bail for
			  each subsequent pass.
 The loop needs to continue due to the root refs 
			
			  We have just replayed everything, and the highest
			  objectid of fs roots probably has changed in case
			  some inode_item's got replayed.
			 
			  root->objectid_mutex is not acquired as log replay
			  could only happen during mount.
 step one is to pin it all, step two is to replay just inodes 
 step three is to replay everything 
 step 4: commit the transaction, which also unpins the blocks 
  there are some corner cases where we want to force a full
  commit instead of allowing a directory to be logged.
  They revolve around files there were unlinked from the directory, and
  this function updates the parent directory so that a full commit is
  properly done if it is fsync'd later after the unlinks are done.
  Must be called before the unlink operations (updates to the subvolume tree,
  inodes, etc) are done.
	
	  when we're logging a file, if it hasn't been renamed
	  or unlinked, and its inode is fully committed on disk,
	  we don't have to worry about walking up the directory chain
	  to log its parents.
	 
	  So, we use the last_unlink_trans field to put this transid
	  into the file.  When the file is logged we check it and
	  don't log the parents if the file is fully on disk.
	
	  if this directory was already logged any new
	  names for this filedir will get recorded
	
	  if the inode we're about to unlink was logged,
	  the log will be properly updated for any new names
	
	  when renaming files across directories, if the directory
	  there we're unlinking from gets fsync'd later on, there's
	  no way to find the destination directory later and fsync it
	  properly.  So, we have to be conservative and force commits
	  so the new name gets discovered.
 we can safely do the unlink without any special recording 
  Make sure that if someone attempts to fsync the parent directory of a deleted
  snapshot, it ends up triggering a transaction commit. This is to guarantee
  that after replaying the log tree of the parent directory's root we will not
  see the snapshot anymore and at log replay time we will not see any log tree
  corresponding to the deleted snapshot's root, which could lead to replaying
  it after replaying the log tree of the parent directory (which would replay
  the snapshot delete operation).
  Must be called before the actual snapshot destroy operation (updates to the
  parent root and tree of tree roots trees, etc) are done.
  Call this after adding a new name for a file and it will properly
  update the log to reflect the new name.
	
	  this will force the logging code to walk the dentry chain
	  up for the file
	
	  if this inode hasn't been logged and directory we're renaming it
	  from hasn't been logged, we don't need to log it
	
	  If we are doing a rename (old_dir is not NULL) from a directory that
	  was previously logged, make sure the next log attempt on the directory
	  is not skipped and logs the inode again. This is because the log may
	  not currently be authoritative for a range including the old
	  BTRFS_DIR_ITEM_KEY and BTRFS_DIR_INDEX_KEY keys, so we want to make
	  sure after a log replay we do not end up with both the new and old
	  dentries around (in case the inode is a directory we would have a
	  directory with two hard links and 2 inode references for different
	  parents). The next log attempt of old_dir will happen at
	  btrfs_log_all_parents(), called through btrfs_log_inode_parent()
	  below, because we have previously set inode->last_unlink_trans to the
	  current transaction ID, either here or at btrfs_record_unlink_dir() in
	  case inode is a directory.
	
	  We don't care about the return value. If we fail to log the new name
	  then we know the next attempt to sync the log will fallback to a full
	  transaction commit (due to a call to btrfs_set_log_full_commit()), so
	  we don't need to worry about getting a log committed that has an
	  inconsistent state after a rename operation.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2007 Oracle.  All rights reserved.
  Copyright (C) 2014 Fujitsu.  All rights reserved.
 File system this workqueue services 
 List head pointing to ordered work list 
 Spinlock for ordered_list 
 Thresholding related variants 
 Up limit of concurrency workers 
 Current number of concurrency workers 
 Threshold to change current_active 
	
	  We could compare wq->normal->pending with num_online_cpus()
	  to support "thresh == NO_THRESHOLD" case, but it requires
	  moving up atomic_incdec in thresh_queueexec_hook. Let's
	  postpone it until someone needs the support of that case.
 For low threshold, disabling threshold is a better choice 
		
		  For threshold-able wq, let its concurrency grow on demand.
		  Use minimal max_active at alloc time to reduce resource
		  usage.
  Hook for threshold which will be called in btrfs_queue_work.
  This hook WILL be called in IRQ handler context,
  so workqueue_set_max_active MUST NOT be called in this hook
  Hook for threshold which will be called before executing the work,
  This hook is called in kthread content.
  So workqueue_set_max_active is called here.
	
	  Use wq->count to limit the calling frequency of
	  workqueue_set_max_active.
	
	  pending may be changed later, but it's OK since we really
	  don't need it so accurate to calculate new_max_active.
		
		  Orders all subsequent loads after reading WORK_DONE_BIT,
		  paired with the smp_mb__before_atomic in btrfs_work_helper
		  this guarantees that the ordered function will see all
		  updates from ordinary work function.
		
		  we are going to call the ordered done function, but
		  we leave the work item on the list as a barrier so
		  that later work items that are done don't have their
		  functions called before this one returns
 now take the lock again and drop our item from the list 
			
			  This is the work item that the worker is currently
			  executing.
			 
			  The kernel workqueue code guarantees non-reentrancy
			  of work items. I.e., if a work item with the same
			  address and work function is queued twice, the second
			  execution is blocked until the first one finishes. A
			  work item may be freed and recycled with the same
			  work function; the workqueue code assumes that the
			  original work item cannot depend on the recycled work
			  item in that case (see find_worker_executing_work()).
			 
			  Note that different types of Btrfs work can depend on
			  each other, and one type of work on one Btrfs
			  filesystem may even depend on the same type of work
			  on another Btrfs filesystem via, e.g., a loop device.
			  Therefore, we must not allow the current work item to
			  be recycled until we are really done, otherwise we
			  break the above assumption and can deadlock.
			
			  We don't want to call the ordered free functions with
			  the lock held.
 NB: work must not be dereferenced past this point. 
 NB: self must not be dereferenced past this point. 
	
	  We should not touch things inside work in the following cases:
	  1) after work->func() if it has no ordered_free
	     Since the struct is freed in work->func().
	  2) after setting WORK_DONE_BIT
	     The work may be freed in other threads almost instantly.
	  So we save the needed things here.
		
		  Ensures all memory accesses done in the work function are
		  ordered before setting the WORK_DONE_BIT. Ensuring the thread
		  which is going to executed the ordered work sees them.
		  Pairs with the smp_rmb in run_ordered_work.
 NB: work must not be dereferenced past this point. 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2011 STRATO.  All rights reserved.
 TODO XXX FIXME
   - subvol delete -> delete when ref goes to 0? delete limits also?
   - reorganize keys
   - compressed
   - sync
   - copy also limits on subvol creation
   - limit
   - caches for ulists
   - performance benchmarks
   - check all ioctl parameters
  Helpers to access qgroup reservation
  Callers should ensure the lock context and type are valid
  glue structure to represent the relations between qgroups.
 must be called with qgroup_ioctl_lock held 
 must be called with qgroup_lock held 
 must be called with qgroup_lock held 
 must be called with qgroup_lock held 
 must be called with qgroup_lock held 
  The full config is read in one go, only called from open_ctree()
  It doesn't use any locking, as at this point we're still single-threaded
 default this to quota off, in case no status key is found 
	
	  pass 1: read status, all qgroup infos and limits
 generation currently unused 
	
	  pass 2: read all qgroup relations
 parent <- member, not needed to build config 
 FIXME should we omit the key completely? 
 ignore the error 
  Called in close_ctree() when quota is still enabled.  This verifies we don't
  leak some reserved space.
  Return false if no reserved space is left.
  Return true if some reserved space is leaked.
	
	  Since we're unmounting, there is no race and no need to grab qgroup
	  lock.  And here we don't go post-order to provide a more user
	  friendly sorted result.
  This is called from close_ctree() or open_ctree() or btrfs_quota_disable(),
  first two are in single-threaded paths.And for the third one, we have set
  quota_root to be null with qgroup_lock held before, so it is safe to clean
  up the in-memory structures without qgroup_lock held.
	
	  We call btrfs_free_qgroup_config() when unmounting
	  filesystem and disabling quota, so we set qgroup_ulist
	  to be null here to avoid double free.
	
	  Avoid a transaction abort by catching -EEXIST here. In that
	  case, we proceed by re-initializing the existing structure
	  on disk.
  called with qgroup_lock held
		
		  delete the leaf one by one
		  since the whole tree is going
		  to be deleted.
	
	  Unlock qgroup_ioctl_lock before starting the transaction. This is to
	  avoid lock acquisition inversion problems (reported by lockdep) between
	  qgroup_ioctl_lock and the vfs freeze semaphores, acquired when we
	  start a transaction.
	  After we started the transaction lock qgroup_ioctl_lock again and
	  check if someone else created the quota root in the meanwhile. If so,
	  just return success and release the transaction handle.
	 
	  Also we don't need to worry about someone else calling
	  btrfs_sysfs_add_qgroups() after we unlock and getting an error because
	  that function returns 0 (success) when the sysfs entries already exist.
	
	  1 for quota root item
	  1 for BTRFS_QGROUP_STATUS item
	 
	  Yet we also need 2n items for a QGROUP_INFOQGROUP_LIMIT items
	  per subvolume. However those are not currently reserved since it
	  would be a lot of overkill.
	
	  initially create the quota tree
 Release locks on tree_root before we access quota_root 
				
				  Shouldn't happen, but in case it does we
				  don't need to do the btrfs_next_item, just
				  continue.
	
	  Set quota enabled flag after committing the transaction, to avoid
	  deadlocks on fs_info->qgroup_ioctl_lock with concurrent snapshot
	  creation.
	
	  1 For the root item
	 
	  We should also reserve enough items for the quota tree deletion in
	  btrfs_clean_quota_tree but this is not done.
	 
	  Also, we must always start a transaction without holding the mutex
	  qgroup_ioctl_lock, see btrfs_quota_enable().
  The easy accounting, we're updating qgroup relationship whose child qgroup
  only has exclusive extents.
  In this case, all exclusive extents will also be exclusive for parent, so
  exclrfer just get addedremoved.
  So is qgroup reservation space, which should also be addedremoved to
  parent.
  Or when child tries to release reservation space, parent will underflow its
  reservation (for relationship adding case).
  Caller should hold fs_info->qgroup_lock.
 Get all of the parent groups that contain this qgroup 
 Iterate all of the parents and adjust their reference counts 
 Add any parents of the parents 
  Quick path for updating qgroup with only excl refs.
  In that case, just update all parent will be enough.
  Or we needs to do a full rescan.
  Caller should also hold fs_info->qgroup_lock.
  Return 0 for quick update, return >0 for need to full rescan
  and mark INCONSISTENT flag.
  Return < 0 for other error.
 Check the level of src and dst first 
 We hold a transaction handle open, must do a NOFS allocation. 
 check if such qgroup relation exist firstly 
 We hold a transaction handle open, must do a NOFS allocation. 
	
	  The parentmember pair doesn't exist, then try to delete the dead
	  relation items only.
 check if such qgroup relation exist firstly 
 At least one deletion succeeded, return 0 
 Check if there are no children of this qgroup 
	
	  Remove the qgroup from sysfs now without holding the qgroup_lock
	  spinlock, since the sysfs_remove_group() function needs to take
	  the mutex kernfs_mutex through kernfs_remove_by_name_ns().
	 Sometimes we would want to clear the limit on this qgroup.
	  To meet this requirement, we treat the -1 as a special value
	  which tell kernel to clear the limit on this qgroup.
	
	  We are always called in a context where we are already holding a
	  transaction handle. Often we are called when adding a data delayed
	  reference from btrfs_truncate_inode_items() (truncating or unlinking),
	  in which case we will be holding a write lock on extent buffer from a
	  subvolume tree. In this case we can't allow btrfs_find_all_roots() to
	  acquire fs_info->commit_root_sem, because that is a higher level lock
	  that must be acquired before locking any extent buffers.
	 
	  So we want btrfs_find_all_roots() to not acquire the commit_root_sem
	  but we can't pass it a non-NULL transaction handle, because otherwise
	  it would not use commit roots and would lock extent buffers, causing
	  a deadlock if it ends up trying to read lock the same extent buffer
	  that was previously write locked at btrfs_truncate_inode_items().
	 
	  So pass a NULL transaction handle to btrfs_find_all_roots() and
	  explicitly tell it to not acquire the commit_root_sem - if we are
	  holding a transaction handle we don't need its protection.
	
	  Here we don't need to get the lock of
	  trans->transaction->delayed_refs, since inserted qrecord won't
	  be deleted, only qrecord->node may be modified (new qrecord insert)
	 
	  So modifying qrecord->old_roots is safe here
 We can be called directly from walk_up_proc() 
 filter out non qgroup-accountable extents  
  Walk up the tree from the bottom, freeing leaves and any interior
  nodes which have had all slots visited. If a node (leaf or
  interior) is freed, the node above it will have it's slot
  incremented. The root node will never be freed.
  At the end of this function, we should have a path which has all
  slots incremented to the next position for a search. If we need to
  read a new node it will be NULL and the node above it will have the
  correct slot selected for a later read.
  If we increment the root nodes slot counter past the number of
  elements, 1 is returned to signal completion of the search.
			
			  Don't free the root -  we will detect this
			  condition after our loop and return a
			  positive value for caller to stop walking the tree.
			
			  We have a valid slot to walk back down
			  from. Stop here so caller can process these
			  new nodes.
  Helper function to trace a subtree tree block swap.
  The swap will happen in highest tree block, but there may be a lot of
  tree blocks involved.
  For example:
   OO = Old tree blocks
   NN = New tree blocks allocated during balance
            File tree (257)                  Reloc tree for 257
  L2              OO                                NN
                    \                                \
  L1          OO      OO (a)                    OO      NN (a)
              \      \                        \      \
  L0       OO   OO OO   OO                   OO   OO NN   NN
                   (b)  (c)                          (b)  (c)
  When calling qgroup_trace_extent_swap(), we will pass:
  @src_eb = OO(a)
  @dst_path = [ nodes[1] = NN(a), nodes[0] = NN(c) ]
  @dst_level = 0
  @root_level = 1
  In that case, qgroup_trace_extent_swap() will search from OO(a) to
  reach OO(c), then mark both OO(c) and NN(c) as qgroup dirty.
  The main work of qgroup_trace_extent_swap() can be split into 3 parts:
  1) Tree search from @src_eb
     It should acts as a simplified btrfs_search_slot().
     The key for search can be extracted from @dst_path->nodes[dst_level]
     (first key).
  2) Mark the final tree blocks in @src_path and @dst_path qgroup dirty
     NOTE: In above case, OO(a) and NN(a) won't be marked qgroup dirty.
     They should be marked during previous (@dst_level = 1) iteration.
  3) Mark file extents in leaves dirty
     We don't have good way to pick out new file extents only.
     So we still follow the old method by scanning all file extents in
     the leave.
  This function can free us from keeping two paths, thus later we only need
  to care about how to iterate all new tree blocks in reloc tree.
 Level mismatch 
 For src_path 
 A simplified version of btrfs_search_slot() 
 Content mismatch, something went wrong 
	
	  Now both @dst_path and @src_path have been populated, record the tree
	  blocks for qgroup accounting.
 Record leaf file extents 
  Helper function to do recursive generation-aware depth-first search, to
  locate all new tree blocks in a subtree of reloc tree.
  E.g. (OO = Old tree blocks, NN = New tree blocks, whose gen == last_snapshot)
          reloc tree
  L2         NN (a)
               \
  L1    OO        NN (b)
         \        \
  L0  OO  OO    OO  NN
                (c) (d)
  If we pass:
  @dst_path = [ nodes[1] = NN(b), nodes[0] = NULL ],
  @cur_level = 1
  @root_level = 1
  We will iterate through tree blocks NN(b), NN(d) and info qgroup to trace
  above tree blocks along with their counter parts in file tree.
  While during search, old tree blocks OO(c) will be skipped as tree block swap
  won't affect OO(c).
 Level sanity check 
 Read the tree block if needed 
		
		  dst_path->nodes[root_level] must be initialized before
		  calling this function.
		
		  We need to get child blockptrgen from parent before we can
		  read it.
 This node is old, no need to trace 
 Now record this tree block and its counter part for qgroups 
 Iterate all child tree blocks 
 Skip old tree blocks as they won't be swapped 
 Recursive call (at most 7 times) 
 Clean up 
 Wrong parameter order 
 For dst_path 
 Do the generation aware breadth-first search 
	
	  Walk down the tree.  Missing extent blocks are filled in as
	  we go. Metadata is accounted every time we read a new
	  extent block.
	 
	  When we reach a leaf, we account for file extent items in it,
	  walk back up the tree (adjusting slot pointers as we go)
	  and restart the search process.
 For path 
 so release_path doesn't try to unlock 
			
			  We need to get child blockptr from parent before we
			  can read it.
 Nonzero return here means we completed our search 
 Restart search with new slots 
  Walk all of the roots that points to the bytenr and adjust their refcnts.
  Update qgroup rferexcl counters.
  Rfer update is easy, codes can explain themselves.
  Excl update is tricky, the update is split into 2 parts.
  Part 1: Possible exclusive <-> sharing detect:
 	|	A	|	!A	|
   -------------------------------------
   B	|		|	-	|
   -------------------------------------
   !B	|	+	|		|
   -------------------------------------
  Conditions:
  A:	cur_old_roots < nr_old_roots	(not exclusive before)
  !A:	cur_old_roots == nr_old_roots	(possible exclusive before)
  B:	cur_new_roots < nr_new_roots	(not exclusive now)
  !B:	cur_new_roots == nr_new_roots	(possible exclusive now)
  Results:
  +: Possible sharing -> exclusive	-: Possible exclusive -> sharing
  : Definitely not changed.		: Possible unchanged.
  For !A and !B condition, the exception is cur_oldnew_roots == 0 case.
  To make the logic clear, we first use condition A and B to split
  combination into 4 results.
  Then, for result "+" and "-", check oldnew_roots == 0 case, as in them
  only on variant maybe 0.
  Lastly, check result , since there are 2 variants maybe 0, split them
  again(2x2).
  But this time we don't need to consider other things, the codes and logic
  is easy to understand now.
 Rfer update part 
 Excl update part 
 Exclusivenone -> shared case 
 Exclusive -> shared 
 Shared -> exclusivenone case 
 Shared->exclusive 
 Exclusivenone -> exclusivenone case 
 None -> exclusivenone 
 None -> exclusive 
 None -> none, nothing changed 
 Exclusive -> exclusivenone 
 Exclusive -> none 
 Exclusive -> exclusive, nothing changed 
  Check if the @roots potentially is a list of fs tree roots
  Return 0 for definitely not a fssubvol tree roots ulist
  Return 1 for possible fssubvol tree roots in the list (considering an empty
           one as well)
 Empty one, still possible for fs roots 
	
	  If it contains fs tree roots, then it must belong to fssubvol
	  trees.
	  If it contains a non-fs tree, it won't be shared with fssubvol trees.
	
	  If quotas get disabled meanwhile, the resources need to be freed and
	  we can't just exit here.
 Quick exit, either not fs tree roots, or won't affect any qgroup 
 Update old refcnts using old_roots 
 Update new refcnts using new_roots 
	
	  Bump qgroup_seq to avoid seq overlap
			
			  Old roots should be searched when inserting qgroup
			  extent record
 Search commit root to find old_roots 
 Free the reserved data space 
			
			  Use BTRFS_SEQ_LAST as time_seq to do special search,
			  which doesn't lock tree or delayed_refs and search
			  current root. It's safe inside commit_transaction().
  called from commit_transaction. Writes all changed qgroups to disk.
  Copy the accounting information between qgroups. This is necessary
  when a snapshot or a subvolume is created. Throwing an error will
  cause a transaction abort so we take extra care here to only error
  when a readonly fs is a reasonable outcome.
	
	  There are only two callers of this function.
	 
	  One in create_subvol() in the ioctl context, which needs to hold
	  the qgroup_ioctl_lock.
	 
	  The other one in create_pending_snapshot() where no other qgroup
	  code can modify the fs as they all need to either start a new trans
	  or hold a trans handler, thus we don't need to hold
	  qgroup_ioctl_lock.
	  This would avoid long and complex lock chain and make lockdep happy.
			
			  Zero out invalid groups so we can ignore
			  them later.
	
	  create a tracking group for the subvol itself
	
	  add qgroup to all inherited groups
		
		  We call inherit after we clone the root in order to make sure
		  our counts don't go crazy, so at this point the only
		  difference between the two roots should be the root node.
 inherit the limit info 
		
		  If we're doing a snapshot, and adding the snapshot to a new
		  qgroup, the numbers are guaranteed to be incorrect.
 Manually tweaking numbers certainly needs a rescan 
	
	  in a first step, we check all affected qgroups if any limits would
	  be exceeded
	
	  no limits exceeded, now record the reservation into all qgroups
  Free @num_bytes of reserved space with @type for qgroup.  (Normally level 0
  qgroup).
  Will handle all higher level qgroup too.
  NOTE: If @num_bytes is (u64)-1, this means to free all bytes of this qgroup.
  This special case is only used for META_PERTRANS type.
		
		  We're freeing all pertrans rsv, get reserved value from
		  level 0 qgroup as real num_bytes to free.
  Check if the leaf is the last leaf. Which means all node pointers
  are at their last position.
  returns < 0 on error, 0 when more leafs are to be scanned.
  returns 1 when done.
		
		  The rescan is about to end, we will not be scanning any
		  further blocks. We cannot unset the RESCAN flag here, because
		  we want to commit the transaction if everything went well.
		  To make the live accounting work in this phase, we set our
		  scan progress pointer such that every real extent objectid
		  will be smaller.
 For rescan, just pass old_roots as NULL 
	
	  Rescan should only search for commit root, and any later difference
	  should be recorded by qgroup
	
	  only update status, since the previous part has already updated the
	  qgroup info.
  Checks that (a) no rescan is running and (b) quota is enabled. Allocates all
  memory required for the rescan context.
 we're resuming qgroup rescan at mount time 
 clear all current qgroup tracking information 
	
	  We have set the rescan_progress to 0, which means no more
	  delayed refs will be accounted by btrfs_qgroup_account_ref.
	  However, btrfs_qgroup_account_ref may be right after its call
	  to btrfs_find_all_roots, in which case it would still do the
	  accounting.
	  To solve this, we're committing the transaction, which will
	  ensure we run all delayed refs and only after that, we are
	  going to clear all tracking information for a clean start.
  this is only called from open_ctree where we're still single threaded, thus
  locking is omitted here.
		
		  Now the entry is in [start, start + len), revert the
		  EXTENT_QGROUP_RESERVED bit.
  Try to free some space for qgroup.
  For qgroup, there are only 3 ways to free qgroup space:
  - Flush nodatacow write
    Any nodatacow write will free its reserved data space at run_delalloc_range().
    In theory, we should only flush nodatacow inodes, but it's not yet
    possible, so we need to flush the whole root.
  - Wait for ordered extents
    When ordered extents are finished, their reserved metadata is finally
    converted to per_trans status, which can be freed by later commit
    transaction.
  - Commit transaction
    This would free the meta_per_trans space.
    In theory this shouldn't provide much space, but any more qgroup space
    is needed.
 Can't hold an open transaction or we run the risk of deadlocking. 
	
	  We don't want to run flush again and again, so if there is a running
	  one, we won't try to start a new flush, but exit directly.
 @reserved parameter is mandatory for qgroup 
 Record already reserved space 
 Newly reserved space 
  Reserve qgroup space for range [start, start + len).
  This function will either reserve space from related qgroups or do nothing
  if the range is already reserved.
  Return 0 for successful reservation
  Return <0 for error (including -EQUOT)
  NOTE: This function may sleep for memory allocation, dirty page flushing and
 	 commit transaction. So caller should not hold any dirty page locked.
 Free ranges specified by @reserved, normally in error path 
 unode->aux is the inclusive end 
 Only free range in range [start, start + len) 
		
		  TODO: To also modify reserved->ranges_reserved to reflect
		  the modification.
		 
		  However as long as we free qgroup reserved according to
		  EXTENT_QGROUP_RESERVED, we won't double free.
		  So not need to rush.
 In release case, we shouldn't have @reserved 
  Free a reserved space range from io_tree and related qgroups
  Should be called when a range of pages get invalidated before reaching disk.
  Or for error cleanup case.
  if @reserved is given, only reserved range in [@start, @start + @len) will
  be freed.
  For data written to disk, use btrfs_qgroup_release_data().
  NOTE: This function may sleep for memory allocation.
  Release a reserved space range from io_tree only.
  Should be called when a range of pages get written to disk and corresponding
  FILE_EXTENT is inserted into corresponding root.
  Since new qgroup accounting framework will only update qgroup numbers at
  commit_transaction() time, its reserved space shouldn't be freed from
  related qgroups.
  But we should release the range from io_tree, to allow further write to be
  COWed.
  NOTE: This function may sleep for memory allocation.
	
	  Record what we have reserved into root.
	 
	  To avoid quota disabled->enabled underflow.
	  In that case, we may try to free space we haven't reserved
	  (since quota was disabled), so record what we reserved into root.
	  And ensure later release won't underflow this number.
 TODO: Update trace point to handle such free 
 Special value -1 means to free all reserved space 
	
	  reservation for META_PREALLOC can happen before quota is enabled,
	  which can lead to underflow.
	  Here ensure we will only free what we really have reserved.
 Same as btrfs_qgroup_free_meta_prealloc() 
  Check qgroup reserved space leaking, normally at destroy inode
  time
  Delete all swapped blocks record of @root.
  Every record here means we skipped a full subtree scan for qgroup.
  Gets called when committing one transaction.
  Add subtree roots record into @subvol_root.
  @subvol_root:	tree root of the subvolume tree get swapped
  @bg:			block group under balance
  @subvol_parentslot:	pointer to the subtree root in subvolume tree
  @reloc_parentslot:	pointer to the subtree root in reloc tree
 			BOTH POINTERS ARE BEFORE TREE SWAP
  @last_snapshot:	last snapshot generation of the subvolume tree
	
	  @reloc_parentslot is still before swap, while @block is going to
	  record the bytenr after swap, so we do the swap here.
	
	  If we have bg == NULL, we're called from btrfs_recover_relocation(),
	  no one else can modify tree blocks thus we qgroup will not change
	  no matter the value of trace_leaf.
 Insert @block into @blocks 
				
				  Duplicated but mismatch entry found.
				  Shouldn't happen.
				 
				  Marking qgroup inconsistent should be enough
				  for end users.
  Check if the tree block is a subtree root, and if so do the needed
  delayed subtree trace for qgroup.
  This is called during btrfs_cow_block().
 Found one, remove it from @blocks first and update blocks->swapped 
 Read out reloc subtree root 
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2007 Oracle.  All rights reserved.
  Types for mounting the default subvolume and a subvolume explicitly
  requested by subvol=path. That way the callchain is straightforward and we
  don't have to play tricks with the mount options and recursive calls to
  btrfs_mount.
  The new btrfs_root_fs_type also servers as a tag for the bdev_holder.
  Generally the error codes correspond to their respective errors, but there
  are a few special cases.
  EUCLEAN: Any sort of corruption that we encounter.  The tree-checker for
           instance will return EUCLEAN if any of the blocks are corrupted in
           a way that is problematic.  We want to reserve EUCLEAN for these
           sort of corruptions.
  EROFS: If we check BTRFS_FS_STATE_ERROR and fail out with a return error, we
         need to use EROFS for this case.  We will have no idea of the
         original failure, that will have been reported at the time we tripped
         over the error.  Each subsequent error that doesn't have any context
         of the original error should use EROFS when handling BTRFS_FS_STATE_ERROR.
 -2 
 -5 
 -12
 -17 
 -28 
 -30 
 -95 
 -117 
 -122 
  __btrfs_handle_fs_error decodes expected errors from the caller and
  invokes the appropriate error response.
	
	  Special case: if the error is EROFS, and we're already
	  under SB_RDONLY, then it is safe here.
	
	  Today we only save the error info to memory.  Long term we'll
	  also send it down to the disk
 Don't go through full error handling during mount 
 btrfs handle error by forcing the filesystem readonly 
	
	  Note that a running device replace operation is not canceled here
	  although there is no way to update the progress. It would add the
	  risk of a deadlock, therefore the canceling is omitted. The only
	  penalty is that some IO remains active until the procedure
	  completes. The next time when the filesystem is mounted writable
	  again, the device replace operation continues.
  Use one ratelimit state per log level so that a flood of less important
  messages doesn't cause more important ones to be dropped.
  We only mark the transaction aborted and then set the file system read-only.
  This will prevent new transactions from starting or trying to join this
  one.
  This means that error recovery at the call site is limited to freeing
  any local memory allocations and passing the error code up without
  further cleanup. The transaction should complete as it normally would
  in the call path but will return -EIO.
  We'll complete the cleanup in btrfs_end_transaction and
  btrfs_commit_transaction.
 Wake up anybody who may be waiting on this transaction 
  __btrfs_panic decodes unexpected, fatal errors from the caller,
  issues an alert, and either panics or BUGs, depending on mount options.
 Caller calls BUG() 
 Rescue options 
 Deprecated options 
 Debugging options 
 Rescue options 
 Deprecated, with alias rescue=nologreplay 
 Deprecated, with alias rescue=usebackuproot 
 Deprecated options 
 Debugging options 
  Regular mount options parser.  Everything that is needed only when
  reading in a new superblock is parsed here.
  XXX JDM: This needs to be cleaned up for remount.
	
	  Even the options are empty, we still need to do extra check
	  against new flags
			
			  These are parsed by btrfs_parse_subvol_options or
			  btrfs_parse_device_options and can be ignored here.
				
				  args[0] contains uninitialized data since
				  for these tokens we don't expect any
				  parameter.
				
				  If we remount from compress-force=xxx to
				  compress=xxx, we need clear FORCE_COMPRESS
				  flag, otherwise, there is no way for users
				  to disable forcible compression separately.
 We're read-only, don't have to check. 
  Parse mount options that are required early in the mount process.
  All other options will be parsed on much later in the mount process and
  only when we need to allocate a new super block.
	
	  strsep changes the string, duplicate it because btrfs_parse_options
	  gets called later
  Parse mount options that are related to subvolume id
  The value is later passed to mount_subvol()
	
	  strsep changes the string, duplicate it because
	  btrfs_parse_device_options gets called later
 we want the original fs_tree 
	
	  Walk up the subvolume trees in the tree of tree roots by root
	  backrefs until we hit the top-level subvolume.
		
		  Walk up the filesystem tree by inode refs until we hit the
		  root directory.
	
	  Find the "default" dir item which points to the root item that we
	  will mount by default if we haven't been given a specific subvolume
	  to mount.
		
		  Ok the default dir item isn't there.  This is weird since
		  it's always been there, but don't freak out, just try and
		  mount the top-level subvolume.
 no transaction, don't bother 
			
			  Exit unless we have some pending changes
			  that need to go through commit
			
			  A non-blocking test if the fs is frozen. We must not
			  start a new transaction here otherwise a deadlock
			  happens. The pending operations are delayed to the
			  next commit after thawing.
  subvolumes are identified by ino 256
 mount_subtree() drops our reference on the vfsmount. 
			
			  This will also catch a race condition where a
			  subvolume which was passed by ID is renamed and
			  another subvolume is renamed over the old location.
  Find a superblock for the given device  mount point.
  Note: This is based on mount_bdev from fssuper.c with a few additions
        for multiple device setup.  Make sure to keep it in sync.
	
	  Setup a dummy root and fs_info for testset super.  This is because
	  we don't actually fill this stuff out until open_ctree, but we need
	  then open_ctree will properly initialize the file system specific
	  settings later.  btrfs_init_fs_info initializes the static elements
	  of the fs_info (locks and such) to make cleanup easier if we find a
	  superblock with our given fs_devices later on at sget() time.
  Mount function which is called by VFS layer.
  In order to allow mounting a subvolume directly, btrfs uses mount_subtree()
  which needs vfsmount of device's root ().  This means device's root has to
  be mounted internally in any case.
  Operation flow:
    1. Parse subvol id related options for later use in mount_subvol().
    2. Mount device's root () by calling vfs_kern_mount().
       NOTE: vfs_kern_mount() is used by VFS to call btrfs_mount() in the
       first place. In order to avoid calling btrfs_mount() again, we use
       different file_system_type which is not registered to VFS by
       register_filesystem() (btrfs_root_fs_type). As a result,
       btrfs_mount_root() is called. The return value will be used by
       mount_subtree() in mount_subvol().
    3. Call mount_subvol() to get the dentry of subvolume. Since there is
       "btrfs subvolume set-default", mount_subvol() is called always.
 mount device's root () 
 mount_subvol() will free subvol_name and mnt_root 
 wait for any defraggers to finish 
	
	  We need to cleanup all defragable inodes if the autodefragment is
	  close or the filesystem is read only.
 If we toggled discard async 
 If we toggled space cache 
 Make sure free space cache options match the state on disk 
		
		  this also happens on 'umount -rf' or on shutdown, when
		  the filesystem is busy.
 wait for the uuid_scan task to finish 
 avoid complains from lockdep et al. 
		
		  Setting SB_RDONLY will put the cleaner thread to
		  sleep at the next loop if it's already active.
		  If it's already asleep, we'll leave unused block
		  groups on disk until we're mounted read-write again
		  unless we clean them up here.
		
		  The cleaner task could be already running before we set the
		  flag BTRFS_FS_STATE_RO (and SB_RDONLY in the superblock).
		  We must make sure that after we finish the remount, i.e. after
		  we call btrfs_commit_super(), the cleaner can no longer start
		  a transaction - either because it was dropping a dead root,
		  running delayed iputs or deleting an unused block group (the
		  cleaner picked a block group from the list of unused block
		  groups before we were able to in the previous call to
		  btrfs_delete_unused_bgs()).
		
		  We've set the superblock to RO mode, so we might have made
		  the cleaner task sleep without running all pending delayed
		  iputs. Go through all the delayed iputs here, so that if an
		  unmount happens without remounting RW we don't end up at
		  finishing close_ctree() with a non-empty list of delayed
		  iputs.
		
		  Pause the qgroup rescan worker if it is running. We don't want
		  it to be still running after we are in RO mode, as after that,
		  by the time we unmount, it might have left a transaction open,
		  so we would leak the transaction andor crash.
		
		  NOTE: when remounting with a change that does writes, don't
		  put it anywhere above this point, as we are not sure to be
		  safe to write until we pass the above checks.
	
	  We need to set SB_I_VERSION here otherwise it'll get cleared by VFS,
	  since the absence of the flag means it can be toggled off by remount.
 We've hit an error - don't reset SB_RDONLY 
 Used to sort the devices by max_avail(descending sort) 
  sort the devices by max_avail, in which max free extent size of each device
  is stored.(Descending Sort)
  The helper to calc the free space on the devices that can be used to store
  file data.
	
	  We aren't under the device list lock, so this is racy-ish, but good
	  enough for our purposes.
 calc min stripe number for data space allocation 
 Adjust for more than 1 stripe per device 
 align with stripe_len 
		
		  In order to avoid overwriting the superblock on the drive,
		  btrfs starts at an offset of at least 1MB when doing chunk
		  allocation.
		 
		  This ensures we have at least min_stripe_size free space
		  after excluding 1MB.
  Calculate numbers for 'df', pessimistic in case of mixed raid profiles.
  If there's a redundant raid level at DATA block groups, use the respective
  multiplier to scale the sizes.
  Unused device space usage is based on simulating the chunk allocator
  algorithm that respects the device sizes and order of allocations.  This is
  a close approximation of the actual use but there are other factors that may
  change the result (like a new metadata chunk).
  If metadata is exhausted, f_bavail will be 0.
		
		  Metadata in mixed block goup profiles are accounted in data
 Account global block reserve as used, it's in logical size already 
 Mixed block groups accounting is not byte-accurate, avoid overflow 
	
	  We calculate the remaining metadata space minus global reserve. If
	  this is (supposedly) smaller than zero, there's no space. But this
	  does not hold in practice, the exhausted state happens where's still
	  some positive delta. So we apply some guesswork and compare the
	  delta to a 4M threshold.  (Practically observed delta was ~2M.)
	 
	  We probably cannot calculate the exact threshold value because this
	  depends on the internal reservations requested by various
	  operations, so some operations that consume a few metadata will
	  succeed even if the Avail is zero. But this is better than the other
	  way around.
	
	  We only want to claim there's no available space if we can no longer
	  allocate chunks for our metadata profile and our global reserve will
	  not fit in the free metadata space.  If we aren't ->full then we
	  still can allocate chunks and thus are fine using the currently
	  calculated f_bavail.
	 We treat it as constant endianness (it doesn't matter _which_)
	   because we want the fsid to come out the same whether mounted
 Mask in the root object ID too, to disambiguate subvols 
	
	  The control file's private_data is used to hold the
	  transaction when it is started and is used to keep
	  track of whether a transaction is already in progress.
  Used by devbtrfs-control for devices ioctls.
	
	  We don't need a barrier here, we'll wait for any transaction that
	  could be in progress on other threads (and do delayed iputs that
	  we want to avoid on a frozen filesystem), or do the commit
	  ourselves.
 no transaction, don't bother 
	
	  There should be always a valid pointer in latest_dev, it may be stale
	  for a short moment in case it's being deleted but still valid until
	  the end of RCU grace period.
 SPDX-License-Identifier: GPL-2.0
  Copyright (C) 2015 Facebook.  All rights reserved.
	
	  We convert to bitmaps when the disk space required for using extents
	  exceeds that required for using bitmaps.
	
	  We allow for a small buffer between the high threshold and low
	  threshold to avoid thrashing back and forth between the two formats.
  btrfs_search_slot() but we're looking for the greatest key less than the
  passed key.
	
	  GFP_NOFS doesn't work with kvmalloc(), but we really can't recurse
	  into the filesystem as the free space bitmap can be modified in the
	  critical section of a transaction commit.
	 
	  TODO: push the memalloc_nofs_{save,restore}() to the caller where we
	  know that recursion is unsafe.
  We can't use btrfs_next_item() in modify_free_space_bitmap() because
  btrfs_next_leaf() doesn't get the path for writing. We can forgo the fancy
  tree walking in btrfs_next_leaf() anyways because we know exactly what we're
  looking for.
  If remove is 1, then we are removing free space, thus clearing bits in the
  bitmap. If remove is 0, then we are adding free space, thus setting bits in
  the bitmap.
	
	  Read the bit for the block immediately before the extent of space if
	  that block is within the block group.
 The previous block may have been in the previous bitmap. 
	
	  Iterate over all of the bitmaps overlapped by the extent of space,
	  clearingsetting bits as required.
	
	  Read the bit for the block immediately after the extent of space if
	  that block is within the block group.
 The next block may be in the next bitmap. 
 Leftover on the left. 
 Leftover on the right. 
 Merging with neighbor on the left. 
 Merging with neighbor on the right. 
	
	  Okay, now that we've found the free space extent which contains the
	  free space that we are removing, there are four cases:
	 
	  1. We're using the whole extent: delete the key we found and
	  decrement the free space extent count.
	  2. We are using part of the extent starting at the beginning: delete
	  the key we found and insert a new key representing the leftover at
	  the end. There is no net change in the number of extents.
	  3. We are using part of the extent ending at the end: delete the key
	  we found and insert a new key representing the leftover at the
	  beginning. There is no net change in the number of extents.
	  4. We are using part of the extent in the middle: delete the key we
	  found and insert two new keys representing the leftovers on each
	  side. Where we used to have one extent, we now have two, so increment
	  the extent count. We may need to convert the block group to bitmaps
	  as a result.
 Delete the existing key (cases 1-4). 
 Add a key for leftovers at the beginning (cases 3 and 4). 
 Add a key for leftovers at the end (cases 2 and 4). 
	
	  We are adding a new extent of free space, but we need to merge
	  extents. There are four cases here:
	 
	  1. The new extent does not have any immediate neighbors to merge
	  with: add the new key and increment the free space extent count. We
	  may need to convert the block group to bitmaps as a result.
	  2. The new extent has an immediate neighbor before it: remove the
	  previous key and insert a new key combining both of them. There is no
	  net change in the number of extents.
	  3. The new extent has an immediate neighbor after it: remove the next
	  key and insert a new key combining both of them. There is no net
	  change in the number of extents.
	  4. The new extent has immediate neighbors on both sides: remove both
	  of the keys and insert a new key combining all of them. Where we used
	  to have two extents, we now have one, so decrement the extent count.
 Search for a neighbor on the left. 
	
	  Delete the neighbor on the left and absorb it into the new key (cases
	  2 and 4).
 Search for a neighbor on the right. 
	
	  Delete the neighbor on the right and absorb it into the new key
	  (cases 3 and 4).
 Insert the new key (cases 1-4). 
  Populate the free space tree by walking the extent tree. Operations on the
  extent tree that happen as a result of writes to the free space tree will go
  through the normal addremove hooks.
	
	  Iterate through all of the extent and metadata items in this block
	  group, adding the free space between them and the free space at the
	  end. Note that EXTENT_ITEM and METADATA_ITEM are less than
	  BLOCK_GROUP_ITEM, so an extent may precede the block group that it's
	  contained in.
	
	  Now that we've committed the transaction any reading of our commit
	  root will be safe, so we can cache from the free space tree now.
 We never added this block group to the free space tree. 
 Initialize to silence GCC. 
	
	  Just like caching_thread() doesn't want to deadlock on the extent
	  tree, we don't want to deadlock on the free space tree.
	
	  We left path pointing to the free space info item, so now
	  load_free_space_foo can just iterate through the free space tree from
	  there.
 SPDX-License-Identifier: GPL-2.0
  HOW DOES THIS WORK
  There are two stages to data reservations, one for data and one for metadata
  to handle the new extents and checksums generated by writing data.
  DATA RESERVATION
    The general flow of the data reservation is as follows
    -> Reserve
      We call into btrfs_reserve_data_bytes() for the user request bytes that
      they wish to write.  We make this reservation and add it to
      space_info->bytes_may_use.  We set EXTENT_DELALLOC on the inode io_tree
      for the range and carry on if this is buffered, or follow up trying to
      make a real allocation if we are pre-allocating or doing O_DIRECT.
    -> Use
      At writepages()preallocO_DIRECT time we will call into
      btrfs_reserve_extent() for some part or all of this range of bytes.  We
      will make the allocation and subtract space_info->bytes_may_use by the
      original requested length and increase the space_info->bytes_reserved by
      the allocated length.  This distinction is important because compression
      may allocate a smaller on disk extent than we previously reserved.
    -> Allocation
      finish_ordered_io() will insert the new file extent item for this range,
      and then add a delayed ref update for the extent tree.  Once that delayed
      ref is written the extent size is subtracted from
      space_info->bytes_reserved and added to space_info->bytes_used.
    Error handling
    -> By the reservation maker
      This is the simplest case, we haven't completed our operation and we know
      how much we reserved, we can simply call
      btrfs_free_reserved_data_space() and it will be removed from
      space_info->bytes_may_use.
    -> After the reservation has been made, but before cow_file_range()
      This is specifically for the delalloc case.  You must clear
      EXTENT_DELALLOC with the EXTENT_CLEAR_DATA_RESV bit, and the range will
      be subtracted from space_info->bytes_may_use.
  METADATA RESERVATION
    The general metadata reservation lifetimes are discussed elsewhere, this
    will just focus on how it is used for delalloc space.
    We keep track of two things on a per inode bases
    ->outstanding_extents
      This is the number of file extent items we'll need to handle all of the
      outstanding DELALLOC space we have in this inode.  We limit the maximum
      size of an extent, so a large contiguous dirty area may require more than
      one outstanding_extent, which is why count_max_extents() is used to
      determine how many outstanding_extents get added.
    ->csum_bytes
      This is essentially how many dirty bytes we have for this inode, so we
      can calculate the number of checksum items we would have to add in order
      to checksum our outstanding data.
    We keep a per-inode block_rsv in order to make it easier to keep track of
    our reservation.  We use btrfs_calculate_inode_block_rsv_size() to
    calculate the current theoretical maximum reservation we would need for the
    metadata for this inode.  We call this and then adjust our reservation as
    necessary, either by attempting to reserve more space, or freeing up excess
    space.
  OUTSTANDING_EXTENTS HANDLING
   ->outstanding_extents is used for keeping track of how many extents we will
   need to use for this inode, and it will fluctuate depending on where you are
   in the life cycle of the dirty data.  Consider the following normal case for
   a completely clean inode, with a num_bytes < our maximum allowed extent size
   -> reserve
     ->outstanding_extents += 1 (current value is 1)
   -> set_delalloc
     ->outstanding_extents += 1 (current value is 2)
   -> btrfs_delalloc_release_extents()
     ->outstanding_extents -= 1 (current value is 1)
     We must call this once we are done, as we hold our reservation for the
     duration of our operation, and then assume set_delalloc will update the
     counter appropriately.
   -> add ordered extent
     ->outstanding_extents += 1 (current value is 2)
   -> btrfs_clear_delalloc_extent
     ->outstanding_extents -= 1 (current value is 1)
   -> finish_ordered_iobtrfs_remove_ordered_extent
     ->outstanding_extents -= 1 (current value is 0)
   Each stage is responsible for their own accounting of the extent, thus
   making error handling and cleanup easier.
 Make sure bytes are sectorsize aligned 
 align the range 
 Use new btrfs_qgroup_reserve_data to reserve precious data space. 
  Called if we need to clear a data reservation for this inode
  Normally in a error case.
  This one will NOT use accurate qgroup reserved space API, just for case
  which we can't sleep and is sure it won't affect qgroup reserved space.
  Like clear_bit_hook().
  Called if we need to clear a data reservation for this inode
  Normally in a error case.
  This one will handle the per-inode data rsv map for accurate reserved
  space framework.
 Make sure the range is aligned to sectorsize 
  Release any excessive reservation
  @inode:       the inode we need to release from
  @qgroup_free: free or convert qgroup meta. Unlike normal operation, qgroup
                meta reservation needs to know if we are freeing qgroup
                reservation or just converting it into per-trans.  Normally
                @qgroup_free is true for error handling, and false for normal
                release.
  This is the same as btrfs_block_rsv_release, except that it handles the
  tracepoint for the reservation.
	
	  Since we statically set the block_rsv->size we just want to say we
	  are releasing 0 bytes, and then we'll just get the reservation over
	  the size free'd.
	
	  Insert size for the number of outstanding extents, 1 normal size for
	  updating the inode.
	
	  For qgroup rsv, the calculation is very simple:
	  account one nodesize for each outstanding extent
	 
	  This is overestimating in most cases.
	
	  finish_ordered_io has to update the inode, so add the space required
	  for an inode update.
	
	  If we are a free space inode we need to not flush since we will be in
	  the middle of a transaction commit.  We also don't need the delalloc
	  mutex since we won't race with anybody.  We need this mostly to make
	  lockdep shut its filthy mouth.
	 
	  If we have a transaction open (can happen if we call truncate_block
	  from truncate), then we need FLUSH_LIMIT so we don't deadlock.
	
	  We always want to do it this way, every other way is wrong and ends
	  in tears.  Pre-reserving the amount we are going to add will always
	  be the right way, because otherwise if we have enough parallelism we
	  could end up with thousands of inodes all holding little bits of
	  reservations they were able to make previously and the only way to
	  reclaim that space is to ENOSPC out the operations and clear
	  everything out and try again, which is bad.  This way we just
	  over-reserve slightly, and clean up the mess when we are done.
	
	  Now we need to update our outstanding extents and csum bytes _first_
	  and then add the reservation to the block_rsv.  This keeps us from
	  racing with an ordered completion or some such that would think it
	  needs to free the reservation we just made.
 Now we can safely add our space to our block rsv 
  Release a metadata reservation for an inode
  @inode: the inode to release the reservation for.
  @num_bytes: the number of bytes we are releasing.
  @qgroup_free: free qgroup reservation or convert it to per-trans reservation
  This will release the metadata reservation for an inode.  This can be called
  once we complete IO for a given set of bytes to release their metadata
  reservations, or on error for the same reason.
  btrfs_delalloc_release_extents - release our outstanding_extents
  @inode: the inode to balance the reservation for.
  @num_bytes: the number of bytes we originally reserved with
  When we reserve space we increase outstanding_extents for the extents we may
  add.  Once we've set the range as delalloc or created our ordered extents we
  have outstanding_extents to track the real usage, so we use this to free our
  temporarily tracked outstanding_extents.  This _must_ be used in conjunction
  with btrfs_delalloc_reserve_metadata.
  btrfs_delalloc_reserve_space - reserve data and metadata space for
  delalloc
  @inode: inode we're writing to
  @start: start range we are writing to
  @len: how long the range we are writing to
  @reserved: mandatory parameter, record actually reserved qgroup ranges of
  	      current reservation.
  This will do the following things
  - reserve space in data space info for num bytes
    and reserve precious corresponding qgroup space
    (Done in check_data_free_space)
  - reserve space for metadata space, based on the number of outstanding
    extents and how much csums will be needed
    also reserve metadata space in a per root over-reserve method.
  - add to the inodes->delalloc_bytes
  - add it to the fs_info's delalloc inodes list.
    (Above 3 all done in delalloc_reserve_metadata)
  Return 0 for success
  Return <0 for error(-ENOSPC or -EQUOT)
  Release data and metadata space for delalloc
  @inode:       inode we're releasing space for
  @reserved:    list of changedreserved ranges
  @start:       start position of the space already reserved
  @len:         length of the space already reserved
  @qgroup_free: should qgroup reserved-space also be freed
  This function will release the metadata space that was not used and will
  decrement ->delalloc_bytes and remove it from the fs_info delalloc_inodes
  list if there are no delalloc bytes left.
  Also it will handle the qgroup reserved space.
